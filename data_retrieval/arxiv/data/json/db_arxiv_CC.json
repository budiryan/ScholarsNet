[{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9301111v1", 
    "title": "Nested satisfiability", 
    "arxiv-id": "cs/9301111v1", 
    "author": "Donald E. Knuth", 
    "publish": "1990-01-01T00:00:00Z", 
    "summary": "A special case of the satisfiability problem, in which the clauses have a\nhierarchical structure, is shown to be solvable in linear time, assuming that\nthe clauses have been represented in a convenient way."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9301113v1", 
    "title": "Textbook examples of recursion", 
    "arxiv-id": "cs/9301113v1", 
    "author": "Donald E. Knuth", 
    "publish": "1991-08-01T00:00:00Z", 
    "summary": "We discuss properties of recursive schemas related to McCarthy's ``91\nfunction'' and to Takeuchi's triple recursion. Several theorems are proposed as\ninteresting candidates for machine verification, and some intriguing open\nquestions are raised."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9808002v1", 
    "title": "Downward Collapse from a Weaker Hypothesis", 
    "arxiv-id": "cs/9808002v1", 
    "author": "Harald Hempel", 
    "publish": "1998-08-24T21:37:54Z", 
    "summary": "Hemaspaandra et al. proved that, for $m > 0$ and $0 < i < k - 1$: if\n$\\Sigma_i^p \\BoldfaceDelta DIFF_m(\\Sigma_k^p)$ is closed under complementation,\nthen $DIFF_m(\\Sigma_k^p) = coDIFF_m(\\Sigma_k^p)$. This sharply asymmetric\nresult fails to apply to the case in which the hypothesis is weakened by\nallowing the $\\Sigma_i^p$ to be replaced by any class in its difference\nhierarchy. We so extend the result by proving that, for $s,m > 0$ and $0 < i <\nk - 1$: if $DIFF_s(\\Sigma_i^p) \\BoldfaceDelta DIFF_m(\\Sigma_k^p)$ is closed\nunder complementation, then $DIFF_m(\\Sigma_k^p) = coDIFF_m(\\Sigma_k^p)$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9809001v1", 
    "title": "Immunity and Simplicity for Exact Counting and Other Counting Classes", 
    "arxiv-id": "cs/9809001v1", 
    "author": "Joerg Rothe", 
    "publish": "1998-09-01T11:16:45Z", 
    "summary": "Ko [RAIRO 24, 1990] and Bruschi [TCS 102, 1992] showed that in some\nrelativized world, PSPACE (in fact, ParityP) contains a set that is immune to\nthe polynomial hierarchy (PH). In this paper, we study and settle the question\nof (relativized) separations with immunity for PH and the counting classes PP,\nC_{=}P, and ParityP in all possible pairwise combinations. Our main result is\nthat there is an oracle A relative to which C_{=}P contains a set that is\nimmune to BPP^{ParityP}. In particular, this C_{=}P^A set is immune to PH^{A}\nand ParityP^{A}. Strengthening results of Tor\\'{a}n [J.ACM 38, 1991] and Green\n[IPL 37, 1991], we also show that, in suitable relativizations, NP contains a\nC_{=}P-immune set, and ParityP contains a PP^{PH}-immune set. This implies the\nexistence of a C_{=}P^{B}-simple set for some oracle B, which extends results\nof Balc\\'{a}zar et al. [SIAM J.Comp. 14, 1985; RAIRO 22, 1988] and provides the\nfirst example of a simple set in a class not known to be contained in PH. Our\nproof technique requires a circuit lower bound for ``exact counting'' that is\nderived from Razborov's [Mat. Zametki 41, 1987] lower bound for majority."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9809002v1", 
    "title": "Tally NP Sets and Easy Census Functions", 
    "arxiv-id": "cs/9809002v1", 
    "author": "Joerg Rothe", 
    "publish": "1998-09-01T12:15:55Z", 
    "summary": "We study the question of whether every P set has an easy (i.e.,\npolynomial-time computable) census function. We characterize this question in\nterms of unlikely collapses of language and function classes such as the\ncontainment of #P_1 in FP, where #P_1 is the class of functions that count the\nwitnesses for tally NP sets. We prove that every #P_{1}^{PH} function can be\ncomputed in FP^{#P_{1}^{#P_{1}}}. Consequently, every P set has an easy census\nfunction if and only if every set in the polynomial hierarchy does. We show\nthat the assumption of #P_1 being contained in FP implies P = BPP and that PH\nis contained in MOD_{k}P for each k \\geq 2, which provides further evidence\nthat not all sets in P have an easy census function. We also relate a set's\nproperty of having an easy census function to other well-studied properties of\nsets, such as rankability and scalability (the closure of the rankable sets\nunder P-isomorphisms). Finally, we prove that it is no more likely that the\ncensus function of any set in P can be approximated (more precisely, can be\nn^{\\alpha}-enumerated in time n^{\\beta} for fixed \\alpha and \\beta) than that\nit can be precisely computed in polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9809114v1", 
    "title": "The descriptive complexity approach to LOGCFL", 
    "arxiv-id": "cs/9809114v1", 
    "author": "Heribert Vollmer", 
    "publish": "1998-09-28T07:57:32Z", 
    "summary": "Building upon the known generalized-quantifier-based first-order\ncharacterization of LOGCFL, we lay the groundwork for a deeper investigation.\nSpecifically, we examine subclasses of LOGCFL arising from varying the arity\nand nesting of groupoidal quantifiers. Our work extends the elaborate theory\nrelating monoidal quantifiers to NC1 and its subclasses. In the absence of the\nBIT predicate, we resolve the main issues: we show in particular that no single\noutermost unary groupoidal quantifier with FO can capture all the context-free\nlanguages, and we obtain the surprising result that a variant of Greibach's\n``hardest context-free language'' is LOGCFL-complete under quantifier-free\nBIT-free projections. We then prove that FO with unary groupoidal quantifiers\nis strictly more expressive with the BIT predicate than without. Considering a\nparticular groupoidal quantifier, we prove that first-order logic with majority\nof pairs is strictly more expressive than first-order with majority of\nindividuals. As a technical tool of independent interest, we define the notion\nof an aperiodic nondeterministic finite automaton and prove that FO\ntranslations are precisely the mappings computed by single-valued aperiodic\nnondeterministic finite transducers."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9809115v1", 
    "title": "A Generalized Quantifier Concept in Computational Complexity Theory", 
    "arxiv-id": "cs/9809115v1", 
    "author": "Heribert Vollmer", 
    "publish": "1998-09-28T08:20:25Z", 
    "summary": "A notion of generalized quantifier in computational complexity theory is\nexplored and used to give a unified treatment of leaf language definability,\noracle separations, type 2 operators, and circuits with monoidal gates.\nRelations to Lindstroem quantifiers are pointed out."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9809116v1", 
    "title": "The Complexity of Computing Optimal Assignments of Generalized   Propositional Formulae", 
    "arxiv-id": "cs/9809116v1", 
    "author": "Heribert Vollmer", 
    "publish": "1998-09-28T08:38:27Z", 
    "summary": "We consider the problems of finding the lexicographically minimal (or\nmaximal) satisfying assignment of propositional formulae for different\nrestricted formula classes. It turns out that for each class from our\nframework, the above problem is either polynomial time solvable or complete for\nOptP. We also consider the problem of deciding if in the optimal assignment the\nlargest variable gets value 1. We show that this problem is either in P or P^NP\ncomplete."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9809117v2", 
    "title": "Hard instance generation for SAT", 
    "arxiv-id": "cs/9809117v2", 
    "author": "Osamu Watanabe", 
    "publish": "1998-09-28T10:50:03Z", 
    "summary": "We propose an algorithm of generating hard instances for the Satisfying\nAssignment Search Problem (in short, SAT). The algorithm transforms instances\nof the integer factorization problem into SAT instances efficiently by using\nthe Chinese Remainder Theorem. For example, it is possible to construct SAT\ninstances with about 5,600 variables that is as hard as factorizing 100 bit\nintegers."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9906017v1", 
    "title": "Generalization of automatic sequences for numeration systems on a   regular language", 
    "arxiv-id": "cs/9906017v1", 
    "author": "Michel Rigo", 
    "publish": "1999-06-22T10:01:27Z", 
    "summary": "Let L be an infinite regular language on a totally ordered alphabet (A,<).\nFeeding a finite deterministic automaton (with output) with the words of L\nenumerated lexicographically with respect to < leads to an infinite sequence\nover the output alphabet of the automaton. This process generalizes the concept\nof k-automatic sequence for abstract numeration systems on a regular language\n(instead of systems in base k). Here, I study the first properties of these\nsequences and their relations with numeration systems."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9906028v1", 
    "title": "On the Power of Positive Turing Reductions", 
    "arxiv-id": "cs/9906028v1", 
    "author": "Edith Hemaspaandra", 
    "publish": "1999-06-26T23:31:10Z", 
    "summary": "In the early 1980s, Selman's seminal work on positive Turing reductions\nshowed that positive Turing reduction to NP yields no greater computational\npower than NP itself. Thus, positive Turing and Turing reducibility to NP\ndiffer sharply unless the polynomial hierarchy collapses.\n  We show that the situation is quite different for DP, the next level of the\nboolean hierarchy. In particular, positive Turing reduction to DP already\nyields all (and only) sets Turing reducibility to NP. Thus, positive Turing and\nTuring reducibility to DP yield the same class. Additionally, we show that an\neven weaker class, P(NP[1]), can be substituted for DP in this context."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9906033v1", 
    "title": "Robust Reductions", 
    "arxiv-id": "cs/9906033v1", 
    "author": "Gerd Wechsung", 
    "publish": "1999-06-29T18:26:12Z", 
    "summary": "We continue the study of robust reductions initiated by Gavalda and Balcazar.\nIn particular, a 1991 paper of Gavalda and Balcazar claimed an optimal\nseparation between the power of robust and nondeterministic strong reductions.\nUnfortunately, their proof is invalid. We re-establish their theorem.\n  Generalizing robust reductions, we note that robustly strong reductions are\nbuilt from two restrictions, robust underproductivity and robust\noverproductivity, both of which have been separately studied before in other\ncontexts. By systematically analyzing the power of these reductions, we explore\nthe extent to which each restriction weakens the power of reductions. We show\nthat one of these reductions yields a new, strong form of the Karp-Lipton\nTheorem."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907033v1", 
    "title": "Unambiguous Computation: Boolean Hierarchies and Sparse Turing-Complete   Sets", 
    "arxiv-id": "cs/9907033v1", 
    "author": "Joerg Rothe", 
    "publish": "1999-07-26T10:09:58Z", 
    "summary": "It is known that for any class C closed under union and intersection, the\nBoolean closure of C, the Boolean hierarchy over C, and the symmetric\ndifference hierarchy over C all are equal. We prove that these equalities hold\nfor any complexity class closed under intersection; in particular, they thus\nhold for unambiguous polynomial time (UP). In contrast to the NP case, we prove\nthat the Hausdorff hierarchy and the nested difference hierarchy over UP both\nfail to capture the Boolean closure of UP in some relativized worlds.\n  Karp and Lipton proved that if nondeterministic polynomial time has sparse\nTuring-complete sets, then the polynomial hierarchy collapses. We establish the\nfirst consequences from the assumption that unambiguous polynomial time has\nsparse Turing-complete sets: (a) UP is in Low_2, where Low_2 is the second\nlevel of the low hierarchy, and (b) each level of the unambiguous polynomial\nhierarchy is contained one level lower in the promise unambiguous polynomial\nhierarchy than is otherwise known to be the case."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907034v1", 
    "title": "Polynomial-Time Multi-Selectivity", 
    "arxiv-id": "cs/9907034v1", 
    "author": "Osamu Watanabe", 
    "publish": "1999-07-25T20:55:21Z", 
    "summary": "We introduce a generalization of Selman's P-selectivity that yields a more\nflexible notion of selectivity, called (polynomial-time) multi-selectivity, in\nwhich the selector is allowed to operate on multiple input strings. Since our\nintroduction of this class, it has been used to prove the first known (and\noptimal) lower bounds for generalized selectivity-like classes in terms of\nEL_2, the second level of the extended low hierarchy. We study the resulting\nselectivity hierarchy, denoted by SH, which we prove does not collapse. In\nparticular, we study the internal structure and the properties of SH and\ncompletely establish, in terms of incomparability and strict inclusion, the\nrelations between our generalized selectivity classes and Ogihara's P-mc\n(polynomial-time membership-comparable) classes. Although SH is a strictly\nincreasing infinite hierarchy, we show that the core results that hold for the\nP-selective sets and that prove them structurally simple also hold for SH. In\nparticular, all sets in SH have small circuits; the NP sets in SH are in Low_2,\nthe second level of the low hierarchy within NP; and SAT cannot be in SH unless\nP = NP. Finally, it is known that P-Sel, the class of P-selective sets, is not\nclosed under union or intersection. We provide an extended selectivity\nhierarchy that is based on SH and that is large enough to capture those\nclosures of the P-selective sets, and yet, in contrast with the P-mc classes,\nis refined enough to distinguish them."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907035v1", 
    "title": "Easy Sets and Hard Certificate Schemes", 
    "arxiv-id": "cs/9907035v1", 
    "author": "Gerd Wechsung", 
    "publish": "1999-07-25T21:05:19Z", 
    "summary": "Can easy sets only have easy certificate schemes? In this paper, we study the\nclass of sets that, for all NP certificate schemes (i.e., NP machines), always\nhave easy acceptance certificates (i.e., accepting paths) that can be computed\nin polynomial time. We also study the class of sets that, for all NP\ncertificate schemes, infinitely often have easy acceptance certificates.\n  In particular, we provide equivalent characterizations of these classes in\nterms of relative generalized Kolmogorov complexity, showing that they are\nrobust. We also provide structural conditions---regarding immunity and class\ncollapses---that put upper and lower bounds on the sizes of these two classes.\nFinally, we provide negative results showing that some of our positive claims\nare optimal with regard to being relativizable. Our negative results are proven\nusing a novel observation: we show that the classical ``wide spacing'' oracle\nconstruction technique yields instant non-bi-immunity results. Furthermore, we\nestablish a result that improves upon Baker, Gill, and Solovay's classical\nresult that NP \\neq P = NP \\cap coNP holds in some relativized world."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907036v1", 
    "title": "Exact Analysis of Dodgson Elections: Lewis Carroll's 1876 Voting System   is Complete for Parallel Access to NP", 
    "arxiv-id": "cs/9907036v1", 
    "author": "Joerg Rothe", 
    "publish": "1999-07-25T21:16:56Z", 
    "summary": "In 1876, Lewis Carroll proposed a voting system in which the winner is the\ncandidate who with the fewest changes in voters' preferences becomes a\nCondorcet winner---a candidate who beats all other candidates in pairwise\nmajority-rule elections. Bartholdi, Tovey, and Trick provided a lower\nbound---NP-hardness---on the computational complexity of determining the\nelection winner in Carroll's system. We provide a stronger lower bound and an\nupper bound that matches our lower bound. In particular, determining the winner\nin Carroll's system is complete for parallel access to NP, i.e., it is complete\nfor $\\thetatwo$, for which it becomes the most natural complete problem known.\nIt follows that determining the winner in Carroll's elections is not\nNP-complete unless the polynomial hierarchy collapses."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907037v1", 
    "title": "Boolean Operations, Joins, and the Extended Low Hierarchy", 
    "arxiv-id": "cs/9907037v1", 
    "author": "Osamu Watanabe", 
    "publish": "1999-07-25T21:30:10Z", 
    "summary": "We prove that the join of two sets may actually fall into a lower level of\nthe extended low hierarchy than either of the sets. In particular, there exist\nsets that are not in the second level of the extended low hierarchy, EL_2, yet\ntheir join is in EL_2. That is, in terms of extended lowness, the join operator\ncan lower complexity. Since in a strong intuitive sense the join does not lower\ncomplexity, our result suggests that the extended low hierarchy is unnatural as\na complexity measure. We also study the closure properties of EL_ and prove\nthat EL_2 is not closed under certain Boolean operations. To this end, we\nestablish the first known (and optimal) EL_2 lower bounds for certain notions\ngeneralizing Selman's P-selectivity, which may be regarded as an interesting\nresult in its own right."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907038v1", 
    "title": "A Second Step Towards Complexity-Theoretic Analogs of Rice's Theorem", 
    "arxiv-id": "cs/9907038v1", 
    "author": "Joerg Rothe", 
    "publish": "1999-07-25T21:39:03Z", 
    "summary": "Rice's Theorem states that every nontrivial language property of the\nrecursively enumerable sets is undecidable. Borchert and Stephan initiated the\nsearch for complexity-theoretic analogs of Rice's Theorem. In particular, they\nproved that every nontrivial counting property of circuits is UP-hard, and that\na number of closely related problems are SPP-hard.\n  The present paper studies whether their UP-hardness result itself can be\nimproved to SPP-hardness. We show that their UP-hardness result cannot be\nstrengthened to SPP-hardness unless unlikely complexity class containments\nhold. Nonetheless, we prove that every P-constructibly bi-infinite counting\nproperty of circuits is SPP-hard. We also raise their general lower bound from\nunambiguous nondeterminism to constant-ambiguity nondeterminism."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907039v1", 
    "title": "Raising NP Lower Bounds to Parallel NP Lower Bounds", 
    "arxiv-id": "cs/9907039v1", 
    "author": "Joerg Rothe", 
    "publish": "1999-07-25T21:47:02Z", 
    "summary": "A decade ago, a beautiful paper by Wagner developed a ``toolkit'' that in\ncertain cases allows one to prove problems hard for parallel access to NP.\nHowever, the problems his toolkit applies to most directly are not overly\nnatural. During the past year, problems that previously were known only to be\nNP-hard or coNP-hard have been shown to be hard even for the class of sets\nsolvable via parallel access to NP. Many of these problems are longstanding and\nextremely natural, such as the Minimum Equivalent Expression problem (which was\nthe original motivation for creating the polynomial hierarchy), the problem of\ndetermining the winner in the election system introduced by Lewis Carroll in\n1876, and the problem of determining on which inputs heuristic algorithms\nperform well. In the present article, we survey this recent progress in raising\nlower bounds."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9907041v1", 
    "title": "Restrictive Acceptance Suffices for Equivalence Problems", 
    "arxiv-id": "cs/9907041v1", 
    "author": "Joerg Rothe", 
    "publish": "1999-07-26T10:50:48Z", 
    "summary": "One way of suggesting that an NP problem may not be NP-complete is to show\nthat it is in the class UP. We suggest an analogous new approach---weaker in\nstrength of evidence but more broadly applicable---to suggesting that\nconcrete~NP problems are not NP-complete. In particular we introduce the class\nEP, the subclass of NP consisting of those languages accepted by NP machines\nthat when they accept always have a number of accepting paths that is a power\nof two. Since if any NP-complete set is in EP then all NP sets are in EP, it\nfollows---with whatever degree of strength one believes that EP differs from\nNP---that membership in EP can be viewed as evidence that a problem is not\nNP-complete.\n  We show that the negation equivalence problem for OBDDs (ordered binary\ndecision diagrams) and the interchange equivalence problem for 2-dags are in\nEP. We also show that for boolean negation the equivalence problem is in\nEP^{NP}, thus tightening the existing NP^{NP} upper bound. We show that FewP,\nbounded ambiguity polynomial time, is contained in EP, a result that is not\nknown to follow from the previous SPP upper bound. For the three problems and\nclasses just mentioned with regard to EP, no proof of membership/containment in\nUP is known, and for the problem just mentioned with regard to EP^{NP}, no\nproof of membership in UP^{NP} is known. Thus, EP is indeed a tool that gives\nevidence against NP-completeness in natural cases where UP cannot currently be\napplied."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9908018v1", 
    "title": "Construction of regular languages and recognizability of polynomials", 
    "arxiv-id": "cs/9908018v1", 
    "author": "Michel Rigo", 
    "publish": "1999-08-27T07:33:28Z", 
    "summary": "A generalization of numeration system in which the set N of the natural\nnumbers is recognizable by finite automata can be obtained by describing a\nlexicographically ordered infinite regular language. Here we show that if P\nbelonging to Q[x] is a polynomial such that P(N) is a subset of N then we can\nconstruct a numeration system in which the set of representations of P(N) is\nregular. The main issue in this construction is to setup a regular language\nwith a density function equals to P(n+1)-P(n) for n large enough."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9909020v1", 
    "title": "Query Order", 
    "arxiv-id": "cs/9909020v1", 
    "author": "Gerd Wechsung", 
    "publish": "1999-09-30T17:06:40Z", 
    "summary": "We study the effect of query order on computational power, and show that\n$\\pjk$-the languages computable via a polynomial-time machine given one query\nto the jth level of the boolean hierarchy followed by one query to the kth\nlevel of the boolean hierarchy-equals $\\redttnp{j+2k-1}$ if j is even and k is\nodd, and equals $\\redttnp{j+2k}$ otherwise. Thus, unless the polynomial\nhierarchy collapses, it holds that for each $1\\leq j \\leq k$: $\\pjk = \\pkj \\iff\n(j=k) \\lor (j{is even} \\land k=j+1)$. We extend our analysis to apply to more\ngeneral query classes."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910002v1", 
    "title": "What's Up with Downward Collapse: Using the Easy-Hard Technique to Link   Boolean and Polynomial Hierarchy Collapses", 
    "arxiv-id": "cs/9910002v1", 
    "author": "Harald Hempel", 
    "publish": "1999-10-01T15:45:25Z", 
    "summary": "During the past decade, nine papers have obtained increasingly strong\nconsequences from the assumption that boolean or bounded-query hierarchies\ncollapse. The final four papers of this nine-paper progression actually achieve\ndownward collapse---that is, they show that high-level collapses induce\ncollapses at (what beforehand were thought to be) lower complexity levels. For\nexample, for each $k\\geq 2$ it is now known that if $\\psigkone=\\psigktwo$ then\n$\\ph=\\sigmak$. This article surveys the history, the results, and the\ntechnique---the so-called easy-hard method---of these nine papers."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910003v1", 
    "title": "R_{1-tt}^{SN}(NP) Distinguishes Robust Many-One and Turing Completeness", 
    "arxiv-id": "cs/9910003v1", 
    "author": "Harald Hempel", 
    "publish": "1999-10-01T18:55:20Z", 
    "summary": "Do complexity classes have many-one complete sets if and only if they have\nTuring-complete sets? We prove that there is a relativized world in which a\nrelatively natural complexity class-namely a downward closure of NP, \\rsnnp -\nhas Turing-complete sets but has no many-one complete sets. In fact, we show\nthat in the same relativized world this class has 2-truth-table complete sets\nbut lacks 1-truth-table complete sets. As part of the groundwork for our\nresult, we prove that \\rsnnp has many equivalent forms having to do with\nordered and parallel access to $\\np$ and $\\npinterconp$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910004v1", 
    "title": "An Introduction to Query Order", 
    "arxiv-id": "cs/9910004v1", 
    "author": "Harald Hempel", 
    "publish": "1999-10-01T19:08:32Z", 
    "summary": "Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] raised the following\nquestions: If one is allowed one question to each of two different information\nsources, does the order in which one asks the questions affect the class of\nproblems that one can solve with the given access? If so, which order yields\nthe greater computational power?\n  The answers to these questions have been learned-inasfar as they can be\nlearned without resolving whether or not the polynomial hierarchy collapses-for\nboth the polynomial hierarchy and the boolean hierarchy. In the polynomial\nhierarchy, query order never matters. In the boolean hierarchy, query order\nsometimes does not matter and, unless the polynomial hierarchy collapses,\nsometimes does matter. Furthermore, the study of query order has yielded\ndividends in seemingly unrelated areas, such as bottleneck computations and\ndownward translation of equality.\n  In this article, we present some of the central results on query order. The\narticle is written in such a way as to encourage the reader to try his or her\nown hand at proving some of these results. We also give literature pointers to\nthe quickly growing set of related results and applications."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910005v2", 
    "title": "Query Order and the Polynomial Hierarchy", 
    "arxiv-id": "cs/9910005v2", 
    "author": "Harald Hempel", 
    "publish": "1999-10-01T19:20:07Z", 
    "summary": "Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] initiated the field of\nquery order, which studies the ways in which computational power is affected by\nthe order in which information sources are accessed. The present paper studies,\nfor the first time, query order as it applies to the levels of the polynomial\nhierarchy. We prove that the levels of the polynomial hierarchy are\norder-oblivious. Yet, we also show that these ordered query classes form new\nlevels in the polynomial hierarchy unless the polynomial hierarchy collapses.\nWe prove that all leaf language classes - and thus essentially all standard\ncomplexity classes - inherit all order-obliviousness results that hold for P."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910006v1", 
    "title": "Self-Specifying Machines", 
    "arxiv-id": "cs/9910006v1", 
    "author": "Gerd Wechsung", 
    "publish": "1999-10-01T19:29:53Z", 
    "summary": "We study the computational power of machines that specify their own\nacceptance types, and show that they accept exactly the languages that\n$\\manyonesharp$-reduce to NP sets. A natural variant accepts exactly the\nlanguages that $\\manyonesharp$-reduce to P sets. We show that these two classes\ncoincide if and only if $\\psone = \\psnnoplusbigohone$, where the latter class\ndenotes the sets acceptable via at most one question to $\\sharpp$ followed by\nat most a constant number of questions to $\\np$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910007v1", 
    "title": "A Downward Collapse within the Polynomial Hierarchy", 
    "arxiv-id": "cs/9910007v1", 
    "author": "Harald Hempel", 
    "publish": "1999-10-01T19:48:25Z", 
    "summary": "Downward collapse (a.k.a. upward separation) refers to cases where the\nequality of two larger classes implies the equality of two smaller classes. We\nprovide an unqualified downward collapse result completely within the\npolynomial hierarchy. In particular, we prove that, for k > 2, if $\\psigkone =\n\\psigktwo$ then $\\sigmak = \\pik = \\ph$. We extend this to obtain a more general\ndownward collapse result."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9910008v2", 
    "title": "Translating Equality Downwards", 
    "arxiv-id": "cs/9910008v2", 
    "author": "Harald Hempel", 
    "publish": "1999-10-01T19:58:41Z", 
    "summary": "Downward translation of equality refers to cases where a collapse of some\npair of complexity classes would induce a collapse of some other pair of\ncomplexity classes that (a priori) one expects are smaller. Recently, the first\ndownward translation of equality was obtained that applied to the polynomial\nhierarchy-in particular, to bounded access to its levels [cs.CC/9910007]. In\nthis paper, we provide a much broader downward translation that extends not\nonly that downward translation but also that translation's elegant enhancement\nby Buhrman and Fortnow. Our work also sheds light on previous research on the\nstructure of refined polynomial hierarchies, and strengthens the connection\nbetween the collapse of bounded query hierarchies and the collapse of the\npolynomial hierarchy."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/9911002v2", 
    "title": "Numeration systems on a regular language: Arithmetic operations,   Recognizability and Formal power series", 
    "arxiv-id": "cs/9911002v2", 
    "author": "Michel Rigo", 
    "publish": "1999-11-08T13:03:50Z", 
    "summary": "Generalizations of numeration systems in which N is recognizable by a finite\nautomaton are obtained by describing a lexicographically ordered infinite\nregular language L over a finite alphabet A. For these systems, we obtain a\ncharacterization of recognizable sets of integers in terms of rational formal\nseries. We also show that, if the complexity of L is Theta (n^q) (resp. if L is\nthe complement of a polynomial language), then multiplication by an integer k\npreserves recognizability only if k=t^{q+1} (resp. if k is not a power of the\ncardinality of A) for some integer t. Finally, we obtain sufficient conditions\nfor the notions of recognizability and U-recognizability to be equivalent,\nwhere U is some positional numeration system related to a sequence of integers."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0004009v2", 
    "title": "Separating the complexity classes NL and NP", 
    "arxiv-id": "cs/0004009v2", 
    "author": "David B. Benson", 
    "publish": "2000-04-17T22:17:33Z", 
    "summary": "Withdrawn since -order- was overlooked. First order reductions without order\nare much too weak to separate."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0007025v1", 
    "title": "A Moment of Perfect Clarity I: The Parallel Census Technique", 
    "arxiv-id": "cs/0007025v1", 
    "author": "Lane A. Hemaspaandra", 
    "publish": "2000-07-13T22:14:04Z", 
    "summary": "We discuss the history and uses of the parallel census technique---an elegant\ntool in the study of certain computational objects having polynomially bounded\ncensus functions. A sequel will discuss advances (including Cai, Naik, and\nSivakumar [CNS95] and Glasser [Gla00]), some related to the parallel census\ntechnique and some due to other approaches, in the complexity-class collapses\nthat follow if NP has sparse hard sets under reductions weaker than (full)\ntruth-table reductions."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0010005v1", 
    "title": "Low Ambiguity in Strong, Total, Associative, One-Way Functions", 
    "arxiv-id": "cs/0010005v1", 
    "author": "Christopher M. Homan", 
    "publish": "2000-10-02T05:25:20Z", 
    "summary": "Rabi and Sherman present a cryptographic paradigm based on associative,\none-way functions that are strong (i.e., hard to invert even if one of their\narguments is given) and total. Hemaspaandra and Rothe proved that such powerful\none-way functions exist exactly if (standard) one-way functions exist, thus\nshowing that the associative one-way function approach is as plausible as\nprevious approaches. In the present paper, we study the degree of ambiguity of\none-way functions. Rabiand Sherman showed that no associative one-way function\n(over a universe having at least two elements) can be unambiguous (i.e.,\none-to-one). Nonetheless, we prove that if standard, unambiguous, one-way\nfunctions exist, then there exist strong, total, associative, one-way functions\nthat are $\\mathcal{O}(n)$-to-one. This puts a reasonable upper bound on the\nambiguity."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0010011v1", 
    "title": "If P \\neq NP then Some Strongly Noninvertible Functions are Invertible", 
    "arxiv-id": "cs/0010011v1", 
    "author": "J\u00f6rg Rothe", 
    "publish": "2000-10-06T18:45:21Z", 
    "summary": "Rabi, Rivest, and Sherman alter the standard notion of noninvertibility to a\nnew notion they call strong noninvertibility, and show -- via explicit\ncryptographic protocols for secret-key agreement ([RS93,RS97] attribute this to\nRivest and Sherman) and digital signatures [RS93,RS97] -- that strongly\nnoninvertible functions would be very useful components in protocol design.\nTheir definition of strong noninvertibility has a small twist (``respecting the\nargument given'') that is needed to ensure cryptographic usefulness. In this\npaper, we show that this small twist has a large, unexpected consequence:\nUnless P=NP, some strongly noninvertible functions are invertible."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0102024v1", 
    "title": "P-Immune Sets with Holes Lack Self-Reducibility Properties", 
    "arxiv-id": "cs/0102024v1", 
    "author": "Harald Hempel", 
    "publish": "2001-02-23T17:10:50Z", 
    "summary": "No P-immune set having exponential gaps is positive-Turing self-reducible."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0106037v1", 
    "title": "Using the No-Search Easy-Hard Technique for Downward Collapse", 
    "arxiv-id": "cs/0106037v1", 
    "author": "Harald Hempel", 
    "publish": "2001-06-15T11:07:02Z", 
    "summary": "The top part of the preceding figure [figure appears in actual paper] shows\nsome classes from the (truth-table) bounded-query and boolean hierarchies. It\nis well-known that if either of these hierarchies collapses at a given level,\nthen all higher levels of that hierarchy collapse to that same level. This is a\nstandard ``upward translation of equality'' that has been known for over a\ndecade. The issue of whether these hierarchies can translate equality {\\em\ndownwards\\/} has proven vastly more challenging. In particular, with regard to\nthe figure above, consider the following claim:\n  $$P_{m-tt}^{\\Sigma_k^p} = P_{m+1-tt}^{\\Sigma_k^p} \\implies\n  DIFF_m(\\Sigma_k^p) coDIFF_m(\\Sigma_k^p) = BH(\\Sigma_k^p). (*) $$\n  This claim, if true, says that equality translates downwards between levels\nof the bounded-query hierarchy and the boolean hierarchy levels that (before\nthe fact) are immediately below them.\n  Until recently, it was not known whether (*) {\\em ever\\/} held, except for\nthe degenerate cases $m=0$ and $k=0$. Then Hemaspaandra, Hemaspaandra, and\nHempel \\cite{hem-hem-hem:j:downward-translation} proved that (*) holds for all\n$m$, for $k > 2$. Buhrman and Fortnow~\\cite{buh-for:j:two-queries} then showed\nthat, when $k=2$, (*) holds for the case $m = 1$. In this paper, we prove that\nfor the case $k=2$, (*) holds for all values of $m$. Since there is an oracle\nrelative to which ``for $k=1$, (*) holds for all $m$'' fails\n\\cite{buh-for:j:two-queries}, our achievement of the $k=2$ case cannot to be\nstrengthened to $k=1$ by any relativizable proof technique. The new downward\ntranslation we obtain also tightens the collapse in the polynomial hierarchy\nimplied by a collapse in the bounded-query hierarchy of the second level of the\npolynomial hierarchy."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0106041v1", 
    "title": "Computing Complete Graph Isomorphisms and Hamiltonian Cycles from   Partial Ones", 
    "arxiv-id": "cs/0106041v1", 
    "author": "Gerd Wechsung", 
    "publish": "2001-06-19T16:10:55Z", 
    "summary": "We prove that computing a single pair of vertices that are mapped onto each\nother by an isomorphism $\\phi$ between two isomorphic graphs is as hard as\ncomputing $\\phi$ itself. This result optimally improves upon a result of\nG\\'{a}l et al. We establish a similar, albeit slightly weaker, result about\ncomputing complete Hamiltonian cycles of a graph from partial Hamiltonian\ncycles."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0106045v2", 
    "title": "A Note on the Complexity of Computing the Smallest Four-Coloring of   Planar Graphs", 
    "arxiv-id": "cs/0106045v2", 
    "author": "Gerd Wechsung", 
    "publish": "2001-06-21T07:04:31Z", 
    "summary": "We show that computing the lexicographically first four-coloring for planar\ngraphs is P^{NP}-hard. This result optimally improves upon a result of Khuller\nand Vazirani who prove this problem to be NP-hard, and conclude that it is not\nself-reducible in the sense of Schnorr, assuming P \\neq NP. We discuss this\napplication to non-self-reducibility and provide a general related result."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0106049v2", 
    "title": "Recursively Undecidable Properties of NP", 
    "arxiv-id": "cs/0106049v2", 
    "author": "V. G. Naidenko", 
    "publish": "2001-06-25T13:37:59Z", 
    "summary": "We show that there cannot be any algorithm that for a given nondeterministic\npolynomial-time Turing machine determinates whether or not the language\nrecognized by this machine belongs to P"
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0108010v3", 
    "title": "A Note on Tiling under Tomographic Constraints", 
    "arxiv-id": "cs/0108010v3", 
    "author": "Gerhard Woeginger", 
    "publish": "2001-08-21T10:29:32Z", 
    "summary": "Given a tiling of a 2D grid with several types of tiles, we can count for\nevery row and column how many tiles of each type it intersects. These numbers\nare called the_projections_. We are interested in the problem of reconstructing\na tiling which has given projections. Some simple variants of this problem,\ninvolving tiles that are 1x1 or 1x2 rectangles, have been studied in the past,\nand were proved to be either solvable in polynomial time or NP-complete. In\nthis note we make progress toward a comprehensive classification of various\ntiling reconstruction problems, by proving NP-completeness results for several\nsets of tiles."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0109018v1", 
    "title": "Exact Complexity of Exact-Four-Colorability", 
    "arxiv-id": "cs/0109018v1", 
    "author": "J\u00f6rg Rothe", 
    "publish": "2001-09-14T15:07:08Z", 
    "summary": "Let $M_k \\seq \\nats$ be a given set that consists of $k$ noncontiguous\nintegers. Define $\\exactcolor{M_k}$ to be the problem of determining whether\n$\\chi(G)$, the chromatic number of a given graph $G$, equals one of the $k$\nelements of the set $M_k$ exactly. In 1987, Wagner \\cite{wag:j:min-max} proved\nthat $\\exactcolor{M_k}$ is $\\bhlevel{2k}$-complete, where $M_k = \\{6k+1, 6k+3,\n>..., 8k-1 \\}$ and $\\bhlevel{2k}$ is the $2k$th level of the boolean hierarchy\nover $\\np$. In particular, for $k = 1$, it is DP-complete to determine whether\n$\\chi(G) = 7$, where $\\DP = \\bhlevel{2}$. Wagner raised the question of how\nsmall the numbers in a $k$-element set $M_k$ can be chosen such that\n$\\exactcolor{M_k}$ still is $\\bhlevel{2k}$-complete. In particular, for $k =\n1$, he asked if it is DP-complete to determine whether $\\chi(G) = 4$. In this\nnote, we solve this question of Wagner and determine the precise threshold $t\n\\in \\{4, 5, 6, 7\\}$ for which the problem $\\exactcolor{\\{t\\}}$ jumps from NP to\nDP-completeness: It is DP-complete to determine whether $\\chi(G) = 4$, yet\n$\\exactcolor{\\{3\\}}$ is in $\\np$. More generally, for each $k \\geq 1$, we show\nthat $\\exactcolor{M_k}$ is $\\bhlevel{2k}$-complete for $M_k = \\{3k+1, 3k+3,...,\n5k-1\\}$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0110025v2", 
    "title": "Recognizing When Heuristics Can Approximate Minimum Vertex Covers Is   Complete for Parallel Access to NP", 
    "arxiv-id": "cs/0110025v2", 
    "author": "Holger Spakowski", 
    "publish": "2001-10-10T15:02:35Z", 
    "summary": "For both the edge deletion heuristic and the maximum-degree greedy heuristic,\nwe study the problem of recognizing those graphs for which that heuristic can\napproximate the size of a minimum vertex cover within a constant factor of r,\nwhere r is a fixed rational number. Our main results are that these problems\nare complete for the class of problems solvable via parallel access to NP. To\nachieve these main results, we also show that the restriction of the vertex\ncover problem to those graphs for which either of these heuristics can find an\noptimal solution remains NP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0110039v1", 
    "title": "Two heads are better than two tapes", 
    "arxiv-id": "cs/0110039v1", 
    "author": "Paul Vitanyi", 
    "publish": "2001-10-18T14:58:26Z", 
    "summary": "We show that a Turing machine with two single-head one-dimensional tapes\ncannot recognize the set {x2x'| x \\in {0,1}^* and x' is a prefix of x} in real\ntime, although it can do so with three tapes, two two-dimensional tapes, or one\ntwo-head tape, or in linear time with just one tape. In particular, this\nsettles the longstanding conjecture that a two-head Turing machine can\nrecognize more languages in real time if its heads are on the same\none-dimensional tape than if they are on separate one-dimensional tapes."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0110040v1", 
    "title": "A New Approach to Formal Language Theory by Kolmogorov Complexity", 
    "arxiv-id": "cs/0110040v1", 
    "author": "Paul Vitanyi", 
    "publish": "2001-10-18T16:43:09Z", 
    "summary": "We present a new approach to formal language theory using Kolmogorov\ncomplexity. The main results presented here are an alternative for pumping\nlemma(s), a new characterization for regular languages, and a new method to\nseparate deterministic context-free languages and nondeterministic context-free\nlanguages. The use of the new `incompressibility arguments' is illustrated by\nmany examples. The approach is also successful at the high end of the Chomsky\nhierarchy since one can quantify nonrecursiveness in terms of Kolmogorov\ncomplexity. (This is a preliminary uncorrected version. The final version is\nthe one published in SIAM J. Comput., 24:2(1995), 398-410.)"
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0111009v1", 
    "title": "On the complexity of inducing categorical and quantitative association   rules", 
    "arxiv-id": "cs/0111009v1", 
    "author": "Luigi Palopoli", 
    "publish": "2001-11-06T15:42:06Z", 
    "summary": "Inducing association rules is one of the central tasks in data mining\napplications. Quantitative association rules induced from databases describe\nrich and hidden relationships holding within data that can prove useful for\nvarious application purposes (e.g., market basket analysis, customer profiling,\nand others). Even though such association rules are quite widely used in\npractice, a thorough analysis of the computational complexity of inducing them\nis missing. This paper intends to provide a contribution in this setting. To\nthis end, we first formally define quantitative association rule mining\nproblems, which entail boolean association rules as a special case, and then\nanalyze their computational complexities, by considering both the standard\ncases, and a some special interesting case, that is, association rule induction\nover databases with null values, fixed-size attribute set databases, sparse\ndatabases, fixed threshold problems."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0111052v1", 
    "title": "A comparison of Zeroes and Ones of a Boolean Polynomial", 
    "arxiv-id": "cs/0111052v1", 
    "author": "M. N. Vyalyi", 
    "publish": "2001-11-20T15:03:19Z", 
    "summary": "In this paper we consider the computational complexity of the following\nproblem. Let $f$ be a Boolean polynomial. What value of $f$, 0 or 1, is taken\nmore frequently? The problem is solved in polynomial time for polynomials of\ndegrees 1,2. The next case of degree 3 appears to be PP-complete under\npolynomial reductions in the class of promise problems. The proof is based on\ntechniques of quantum computation."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0112001v8", 
    "title": "An Average Case NP-Complete Graph Coloring Problem", 
    "arxiv-id": "cs/0112001v8", 
    "author": "Ramarathnam Venkatesan", 
    "publish": "2001-12-02T21:44:23Z", 
    "summary": "NP-complete problems should be hard on some instances but those may be\nextremely rare. On generic instances many such problems, especially related to\nrandom graphs, have been proven easy. We show the intractability of random\ninstances of a graph coloring problem: this graph problem is hard on average\nunless all NP problem under all samplable (i.e., generatable in polynomial\ntime) distributions are easy. Worst case reductions use special gadgets and\ntypically map instances into a negligible fraction of possible outputs. Ours\nmust output nearly random graphs and avoid any super-polynomial distortion of\nprobabilities. This poses significant technical difficulty."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0112021v1", 
    "title": "Exact Complexity of the Winner Problem for Young Elections", 
    "arxiv-id": "cs/0112021v1", 
    "author": "J\u00f6rg Vogel", 
    "publish": "2001-12-20T11:37:33Z", 
    "summary": "In 1977, Young proposed a voting scheme that extends the Condorcet Principle\nbased on the fewest possible number of voters whose removal yields a Condorcet\nwinner. We prove that both the winner and the ranking problem for Young\nelections is complete for the class of problems solvable in polynomial time by\nparallel access to NP. Analogous results for Lewis Carroll's 1876 voting scheme\nwere recently established by Hemaspaandra et al. In contrast, we prove that the\nwinner and ranking problems in Fishburn's homogeneous variant of Carroll's\nvoting scheme can be solved efficiently by linear programming."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0201001v1", 
    "title": "Lower Bounds for Matrix Product", 
    "arxiv-id": "cs/0201001v1", 
    "author": "Amir Shpilka", 
    "publish": "2002-01-02T09:50:57Z", 
    "summary": "We prove lower bounds on the number of product gates in bilinear and\nquadratic circuits that compute the product of two $n \\cross n$ matrices over\nfinite fields. In particular we obtain the following results:\n  1. We show that the number of product gates in any bilinear (or quadratic)\ncircuit that computes the product of two $n \\cross n$ matrices over $F_2$ is at\nleast $3 n^2 - o(n^2)$.\n  2. We show that the number of product gates in any bilinear circuit that\ncomputes the product of two $n \\cross n$ matrices over $F_p$ is at least $(2.5\n+ \\frac{1.5}{p^3 -1})n^2 -o(n^2)$.\n  These results improve the former results of Bshouty '89 and Blaser '99 who\nproved lower bounds of $2.5 n^2 - o(n^2)$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0203016v1", 
    "title": "Dimension in Complexity Classes", 
    "arxiv-id": "cs/0203016v1", 
    "author": "Jack H. Lutz", 
    "publish": "2002-03-12T20:16:27Z", 
    "summary": "A theory of resource-bounded dimension is developed using gales, which are\nnatural generalizations of martingales. When the resource bound \\Delta (a\nparameter of the theory) is unrestricted, the resulting dimension is precisely\nthe classical Hausdorff dimension (sometimes called fractal dimension). Other\nchoices of the parameter \\Delta yield internal dimension theories in E, E2,\nESPACE, and other complexity classes, and in the class of all decidable\nproblems. In general, if C is such a class, then every set X of languages has a\ndimension in C, which is a real number dim(X|C) in [0,1]. Along with the\nelements of this theory, two preliminary applications are presented:\n  1. For every real number \\alpha in (0,1/2), the set FREQ(<=\\alpha),\nconsisting of all languages that asymptotically contain at most \\alpha of all\nstrings, has dimension H(\\alpha) -- the binary entropy of \\alpha -- in E and in\nE2.\n  2. For every real number \\alpha in (0,1), the set SIZE(\\alpha* (2^n)/n),\nconsisting of all languages decidable by Boolean circuits of at most\n\\alpha*(2^n)/n gates, has dimension \\alpha in ESPACE."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0203017v1", 
    "title": "The Dimensions of Individual Strings and Sequences", 
    "arxiv-id": "cs/0203017v1", 
    "author": "Jack H. Lutz", 
    "publish": "2002-03-12T20:28:19Z", 
    "summary": "A constructive version of Hausdorff dimension is developed using constructive\nsupergales, which are betting strategies that generalize the constructive\nsupermartingales used in the theory of individual random sequences. This\nconstructive dimension is used to assign every individual (infinite, binary)\nsequence S a dimension, which is a real number dim(S) in the interval [0,1].\nSequences that are random (in the sense of Martin-Lof) have dimension 1, while\nsequences that are decidable, \\Sigma^0_1, or \\Pi^0_1 have dimension 0. It is\nshown that for every \\Delta^0_2-computable real number \\alpha in [0,1] there is\na \\Delta^0_2 sequence S such that \\dim(S) = \\alpha.\n  A discrete version of constructive dimension is also developed using\ntermgales, which are supergale-like functions that bet on the terminations of\n(finite, binary) strings as well as on their successive bits. This discrete\ndimension is used to assign each individual string w a dimension, which is a\nnonnegative real number dim(w). The dimension of a sequence is shown to be the\nlimit infimum of the dimensions of its prefixes.\n  The Kolmogorov complexity of a string is proven to be the product of its\nlength and its dimension. This gives a new characterization of algorithmic\ninformation and a new proof of Mayordomo's recent theorem stating that the\ndimension of a sequence is the limit infimum of the average Kolmogorov\ncomplexity of its first n bits.\n  Every sequence that is random relative to any computable sequence of\ncoin-toss biases that converge to a real number \\beta in (0,1) is shown to have\ndimension \\H(\\beta), the binary entropy of \\beta."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0203029v20", 
    "title": "Forbidden Information", 
    "arxiv-id": "cs/0203029v20", 
    "author": "Leonid A. Levin", 
    "publish": "2002-03-27T17:28:22Z", 
    "summary": "Goedel Incompleteness Theorem leaves open a way around it, vaguely perceived\nfor a long time but not clearly identified. (Thus, Goedel believed informal\narguments can answer any math question.) Closing this loophole does not seem\nobvious and involves Kolmogorov complexity. (This is unrelated to, well studied\nbefore, complexity quantifications of the usual Goedel effects.) I consider\nextensions U of the universal partial recursive predicate (or, say, Peano\nArithmetic). I prove that any U either leaves an n-bit input (statement)\nunresolved or contains nearly all information about the n-bit prefix of any\nr.e. real r (which is n bits for some r). I argue that creating significant\ninformation about a SPECIFIC math sequence is impossible regardless of the\nmethods used. Similar problems and answers apply to other unsolvability results\nfor tasks allowing multiple solutions, e.g. non-recursive tilings."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0205031v1", 
    "title": "Lecture Notes on Evasiveness of Graph Properties", 
    "arxiv-id": "cs/0205031v1", 
    "author": "Neal E. Young", 
    "publish": "2002-05-18T01:20:37Z", 
    "summary": "This report presents notes from the first eight lectures of the class Many\nModels of Complexity taught by Laszlo Lovasz at Princeton University in the\nfall of 1990. The topic is evasiveness of graph properties: given a graph\nproperty, how many edges of the graph an algorithm must check in the worst case\nbefore it knows whether the property holds."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0205056v1", 
    "title": "Parameterized Intractability of Motif Search Problems", 
    "arxiv-id": "cs/0205056v1", 
    "author": "Rolf Niedermeier", 
    "publish": "2002-05-21T10:23:18Z", 
    "summary": "We show that Closest Substring, one of the most important problems in the\nfield of biological sequence analysis, is W[1]-hard when parameterized by the\nnumber k of input strings (and remains so, even over a binary alphabet). This\nproblem is therefore unlikely to be solvable in time O(f(k)\\cdot n^{c}) for any\nfunction f of k and constant c independent of k. The problem can therefore be\nexpected to be intractable, in any practical sense, for k>=3. Our result\nsupports the intuition that Closest Substring is computationally much harder\nthan the special case of Closest String, although both problems are\nNP-complete. We also prove W[1]-hardness for other parameterizations in the\ncase of unbounded alphabet size. Our W[1]-hardness result for Closest Substring\ngeneralizes to Consensus Patterns, a problem of similar significance in\ncomputational biology."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0205064v3", 
    "title": "A polynomial time (heuristic) SAT algorithm", 
    "arxiv-id": "cs/0205064v3", 
    "author": "Charles Sauerbier", 
    "publish": "2002-05-24T21:09:09Z", 
    "summary": "A hole has been found in the algorithm as given, where an eleventh hour\nchange admits a path inconsistency. The inconsistency arises due to an improper\nclosure of a path to a cycle against a root not supportive of the path. The\nmathematical basis of the algorithm remains supportive of the intended\nsolution, and a revision of the algorithm is underway."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0208006v1", 
    "title": "Rectangle Size Bounds and Threshold Covers in Communication Complexity", 
    "arxiv-id": "cs/0208006v1", 
    "author": "Hartmut Klauck", 
    "publish": "2002-08-05T14:36:27Z", 
    "summary": "We investigate the power of the most important lower bound technique in\nrandomized communication complexity, which is based on an evaluation of the\nmaximal size of approximately monochromatic rectangles, minimized over all\ndistributions on the inputs. While it is known that the 0-error version of this\nbound is polynomially tight for deterministic communication, nothing in this\ndirection is known for constant error and randomized communication complexity.\nWe first study a one-sided version of this bound and obtain that its value lies\nbetween the MA- and AM-complexities of the considered function. Hence the lower\nbound actually works for a (communication complexity) class between MA cap\nco-MA and AM cap co-AM. We also show that the MA-complexity of the disjointness\nproblem is Omega(sqrt(n)). Following this we consider the conjecture that the\nlower bound method is polynomially tight for randomized communication\ncomplexity. First we disprove a distributional version of this conjecture. Then\nwe give a combinatorial characterization of the value of the lower bound\nmethod, in which the optimization over all distributions is absent. This\ncharacterization is done by what we call a uniform threshold cover. We also\nstudy relaxations of this notion, namely approximate majority covers and\nmajority covers, and compare these three notions in power, exhibiting\nexponential separations. Each of these covers captures a lower bound method\npreviously used for randomized communication complexity."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0208018v2", 
    "title": "Does P = NP?", 
    "arxiv-id": "cs/0208018v2", 
    "author": "C. Sauerbier", 
    "publish": "2002-08-12T04:32:36Z", 
    "summary": "This paper considers the question of P = NP in context of the polynomial time\nSAT algorithm. It posits proposition dependent on existence of conjectured\nproblem that even where the algorithm is shown to solve SAT in polynomial time\nit remains theoretically possible for there to yet exist a\nnon-deterministically polynomial (NP) problem for which the algorithm does not\nprovide a polynomial (P) time solution. The paper leaves open as subject of\ncontinuing research the question of existence of instance of conjectured\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0208043v1", 
    "title": "Gales Suffice for Constructive Dimension", 
    "arxiv-id": "cs/0208043v1", 
    "author": "John M. Hitchcock", 
    "publish": "2002-08-29T20:48:14Z", 
    "summary": "Supergales, generalizations of supermartingales, have been used by Lutz\n(2002) to define the constructive dimensions of individual binary sequences.\nHere it is shown that gales, the corresponding generalizations of martingales,\ncan be equivalently used to define constructive dimension."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0208044v1", 
    "title": "Gales and supergales are equivalent for defining constructive Hausdorff   dimension", 
    "arxiv-id": "cs/0208044v1", 
    "author": "Stephen A. Fenner", 
    "publish": "2002-08-29T21:25:47Z", 
    "summary": "We show that for a wide range of probability measures, constructive gales are\ninterchangable with constructive supergales for defining constructive Hausdorff\ndimension, thus generalizing a previous independent result of Hitchcock\n(cs.CC/0208043) and partially answering an open question of Lutz\n(cs.CC/0203017)."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0209015v2", 
    "title": "Does NP not equal P?", 
    "arxiv-id": "cs/0209015v2", 
    "author": "C. Sauerbier", 
    "publish": "2002-09-10T16:08:21Z", 
    "summary": "Stephen Cook posited SAT is NP-Complete in 1971. If SAT is NP-Complete then,\nas is generally accepted, any polynomial solution of it must also present a\npolynomial solution of all NP decision problems. It is here argued, however,\nthat NP is not of necessity equivalent to P where it is shown that SAT is\ncontained in P. This due to a paradox, of nature addressed by both Godel and\nRussell, in regards to the P-NP system in total."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0210008v1", 
    "title": "Cellular automata and communication complexity", 
    "arxiv-id": "cs/0210008v1", 
    "author": "Guillaume Theyssier", 
    "publish": "2002-10-11T16:29:19Z", 
    "summary": "The model of cellular automata is fascinating because very simple local rules\ncan generate complex global behaviors. The relationship between local and\nglobal function is subject of many studies. We tackle this question by using\nresults on communication complexity theory and, as a by-product, we provide\n(yet another) classification of cellular automata."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0211012v2", 
    "title": "Phase Transitions and all that", 
    "arxiv-id": "cs/0211012v2", 
    "author": "Gabriel Istrate", 
    "publish": "2002-11-12T21:56:15Z", 
    "summary": "The paper (as posted originally) contains several errors. It has been\nsubsequently split into two papers, the corrected (and accepted for\npublication) versions appear in the archive as papers cs.CC/0503082 and\ncs.DM/0503083."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0211025v3", 
    "title": "Effective Strong Dimension, Algorithmic Information, and Computational   Complexity", 
    "arxiv-id": "cs/0211025v3", 
    "author": "Elvira Mayordomo", 
    "publish": "2002-11-21T04:46:02Z", 
    "summary": "The two most important notions of fractal dimension are {\\it Hausdorff\ndimension}, developed by Hausdorff (1919), and {\\it packing dimension},\ndeveloped by Tricot (1982).\n  Lutz (2000) has recently proven a simple characterization of Hausdorff\ndimension in terms of {\\it gales}, which are betting strategies that generalize\nmartingales. Imposing various computability and complexity constraints on these\ngales produces a spectrum of effective versions of Hausdorff dimension.\n  In this paper we show that packing dimension can also be characterized in\nterms of gales. Moreover, even though the usual definition of packing dimension\nis considerably more complex than that of Hausdorff dimension, our gale\ncharacterization of packing dimension is an exact dual of -- and every bit as\nsimple as -- the gale characterization of Hausdorff dimension.\n  Effectivizing our gale characterization of packing dimension produces a\nvariety of {\\it effective strong dimensions}, which are exact duals of the\neffective dimensions mentioned above.\n  We develop the basic properties of effective strong dimensions and prove a\nnumber of results relating them to fundamental aspects of randomness,\nKolmogorov complexity, prediction, Boolean circuit-size complexity,\npolynomial-time degrees, and data compression."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0211026v2", 
    "title": "How long is a Proof? - A short note", 
    "arxiv-id": "cs/0211026v2", 
    "author": "A. G. Yaneff", 
    "publish": "2002-11-21T10:26:44Z", 
    "summary": "Withdrawn. Silly notion and out of context."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0211032v2", 
    "title": "Solution Bounds for a Hypothetical Polynomial Time Aproximation   Algorithm for the TSP", 
    "arxiv-id": "cs/0211032v2", 
    "author": "A. G. Yaneff", 
    "publish": "2002-11-25T08:24:37Z", 
    "summary": "Bounds for the optimal tour length for a hypothetical TSP algorithm are\nderived."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0212001v1", 
    "title": "Traveling Salesmen in the Presence of Competition", 
    "arxiv-id": "cs/0212001v1", 
    "author": "Matthias Schmitt", 
    "publish": "2002-12-03T17:42:08Z", 
    "summary": "We propose the ``Competing Salesmen Problem'' (CSP), a 2-player competitive\nversion of the classical Traveling Salesman Problem. This problem arises when\nconsidering two competing salesmen instead of just one. The concern for a\nshortest tour is replaced by the necessity to reach any of the customers before\nthe opponent does. In particular, we consider the situation where players take\nturns, moving along one edge at a time within a graph G=(V,E). The set of\ncustomers is given by a subset V_C V of the vertices. At any given time, both\nplayers know of their opponent's position. A player wins if he is able to reach\na majority of the vertices in V_C before the opponent does. We prove that the\nCSP is PSPACE-complete, even if the graph is bipartite, and both players start\nat distance 2 from each other. We show that the starting player may lose the\ngame, even if both players start from the same vertex. For bipartite graphs, we\nshow that the starting player always can avoid a loss. We also show that the\nsecond player can avoid to lose by more than one customer, when play takes\nplace on a graph that is a tree T, and V_C consists of leaves of T. For the\ncase where T is a star and V_C consists of n leaves of T, we give a simple and\nfast strategy which is optimal for both players. If V_C consists not only of\nleaves, the situation is more involved."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0212016v3", 
    "title": "Complexity of the Exact Domatic Number Problem and of the Exact Conveyor   Flow Shop Problem", 
    "arxiv-id": "cs/0212016v3", 
    "author": "J\u00f6rg Rothe", 
    "publish": "2002-12-09T19:46:02Z", 
    "summary": "We prove that the exact versions of the domatic number problem are complete\nfor the levels of the boolean hierarchy over NP. The domatic number problem,\nwhich arises in the area of computer networks, is the problem of partitioning a\ngiven graph into a maximum number of disjoint dominating sets. This number is\ncalled the domatic number of the graph. We prove that the problem of\ndetermining whether or not the domatic number of a given graph is {\\em exactly}\none of k given values is complete for the 2k-th level of the boolean hierarchy\nover NP. In particular, for k = 1, it is DP-complete to determine whether or\nnot the domatic number of a given graph equals exactly a given integer. Note\nthat DP is the second level of the boolean hierarchy over NP. We obtain similar\nresults for the exact versions of generalized dominating set problems and of\nthe conveyor flow shop problem. Our reductions apply Wagner's conditions\nsufficient to prove hardness for the levels of the boolean hierarchy over NP."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0212056v1", 
    "title": "On the Work of Madhu Sudan: the 2002 Nevalinna Prize Winner", 
    "arxiv-id": "cs/0212056v1", 
    "author": "Shafi Goldwasser", 
    "publish": "2002-12-01T00:00:00Z", 
    "summary": "Madhu Sudan's work spans many areas of computer science theory including\ncomputational complexity theory, the design of efficient algorithms,\nalgorithmic coding theory, and the theory of program checking and correcting.\n  Two results of Sudan stand out in the impact they have had on the mathematics\nof computation. The first work shows a probabilistic characterization of the\nclass NP -- those sets for which short and easily checkable proofs of\nmembership exist, and demonstrates consequences of this characterization to\nclassifying the complexity of approximation problems. The second work shows a\npolynomial time algorithm for list decoding the Reed Solomon error correcting\ncodes.\n  This short note will be devoted to describing Sudan's work on\nprobabilistically checkable proofs -- the so called {\\it PCP theorem} and its\nimplications."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0301012v1", 
    "title": "Hard satisfiable formulas for DPLL-type algorithms", 
    "arxiv-id": "cs/0301012v1", 
    "author": "Sergey I. Nikolenko", 
    "publish": "2003-01-15T08:44:21Z", 
    "summary": "We address lower bounds on the time complexity of algorithms solving the\npropositional satisfiability problem. Namely, we consider two DPLL-type\nalgorithms, enhanced with the unit clause and pure literal heuristics.\nExponential lower bounds for solving satisfiability on provably satisfiable\nformulas are proven."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0301013v1", 
    "title": "Independence Properties of Algorithmically Random Sequences", 
    "arxiv-id": "cs/0301013v1", 
    "author": "S. M. Kautz", 
    "publish": "2003-01-16T02:56:59Z", 
    "summary": "A bounded Kolmogorov-Loveland selection rule is an adaptive strategy for\nrecursively selecting a subsequence of an infinite binary sequence; such a\nsubsequence may be interpreted as the query sequence of a time-bounded Turing\nmachine. In this paper we show that if A is an algorithmically random sequence,\nA_0 is selected from A via a bounded Kolmogorov-Loveland selection rule, and\nA_1 denotes the sequence of nonselected bits of A, then A_1 is independent of\nA_0; that is, A_1 is algorithmically random relative to A_0. This result has\nbeen used by Kautz and Miltersen [1] to show that relative to a random oracle,\nNP does not have p-measure zero (in the sense of Lutz [2]).\n  [1] S. M. Kautz and P. B. Miltersen. Relative to a random oracle, NP is not\nsmall. Journal of Computer and System Sciences, 53:235-250, 1996.\n  [2] J. H. Lutz. Almost everywhere high nonuniform complexity. Journal of\nComputer and System Sciences, 44:220-258, 1992."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0301016v1", 
    "title": "Lower Bounds on the Bounded Coefficient Complexity of Bilinear Maps", 
    "arxiv-id": "cs/0301016v1", 
    "author": "Martin Lotz", 
    "publish": "2003-01-16T15:36:00Z", 
    "summary": "We prove lower bounds of order $n\\log n$ for both the problem to multiply\npolynomials of degree $n$, and to divide polynomials with remainder, in the\nmodel of bounded coefficient arithmetic circuits over the complex numbers.\nThese lower bounds are optimal up to order of magnitude. The proof uses a\nrecent idea of R. Raz [Proc. 34th STOC 2002] proposed for matrix\nmultiplication. It reduces the linear problem to multiply a random circulant\nmatrix with a vector to the bilinear problem of cyclic convolution. We treat\nthe arising linear problem by extending J. Morgenstern's bound [J. ACM 20, pp.\n305-306, 1973] in a unitarily invariant way. This establishes a new lower bound\non the bounded coefficient complexity of linear forms in terms of the singular\nvalues of the corresponding matrix. In addition, we extend these lower bounds\nfor linear and bilinear maps to a model of circuits that allows a restricted\nnumber of unbounded scalar multiplications."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304020v2", 
    "title": "A direct sum theorem in communication complexity via message compression", 
    "arxiv-id": "cs/0304020v2", 
    "author": "Pranab Sen", 
    "publish": "2003-04-12T02:26:26Z", 
    "summary": "We prove lower bounds for the direct sum problem for two-party bounded error\nrandomised multiple-round communication protocols. Our proofs use the notion of\ninformation cost of a protocol, as defined by Chakrabarti, Shi, Wirth and Yao\nand refined further by Bar-Yossef, Jayram, Kumar and Sivakumar. Our main\ntechnical result is a `compression' theorem saying that, for any probability\ndistribution $\\mu$ over the inputs, a $k$-round private coin bounded error\nprotocol for a function $f$ with information cost $c$ can be converted into a\n$k$-round deterministic protocol for $f$ with bounded distributional error and\ncommunication cost $O(kc)$. We prove this result using a substate theorem about\nrelative entropy and a rejection sampling argument. Our direct sum result\nfollows from this `compression' result via elementary information theoretic\narguments.\n  We also consider the direct sum problem in quantum communication. Using a\nprobabilistic argument, we show that messages cannot be compressed in this\nmanner even if they carry small information. Hence, new techniques may be\nnecessary to tackle the direct sum problem in quantum communication."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304026v1", 
    "title": "A New Multilayered PCP and the Hardness of Hypergraph Vertex Cover", 
    "arxiv-id": "cs/0304026v1", 
    "author": "Oded Regev", 
    "publish": "2003-04-19T17:59:33Z", 
    "summary": "Given a $k$-uniform hyper-graph, the E$k$-Vertex-Cover problem is to find the\nsmallest subset of vertices that intersects every hyper-edge. We present a new\nmultilayered PCP construction that extends the Raz verifier. This enables us to\nprove that E$k$-Vertex-Cover is NP-hard to approximate within factor\n$(k-1-\\epsilon)$ for any $k \\geq 3$ and any $\\epsilon>0$. The result is\nessentially tight as this problem can be easily approximated within factor $k$.\nOur construction makes use of the biased Long-Code and is analyzed using\ncombinatorial properties of $s$-wise $t$-intersecting families of subsets."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304030v1", 
    "title": "Small Spans in Scaled Dimension", 
    "arxiv-id": "cs/0304030v1", 
    "author": "John M. Hitchcock", 
    "publish": "2003-04-22T19:43:35Z", 
    "summary": "Juedes and Lutz (1995) proved a small span theorem for polynomial-time\nmany-one reductions in exponential time. This result says that for language A\ndecidable in exponential time, either the class of languages reducible to A\n(the lower span) or the class of problems to which A can be reduced (the upper\nspan) is small in the sense of resource-bounded measure and, in particular,\nthat the degree of A is small. Small span theorems have been proven for\nincreasingly stronger polynomial-time reductions, and a small span theorem for\npolynomial-time Turing reductions would imply BPP != EXP. In contrast to the\nprogress in resource-bounded measure, Ambos-Spies, Merkle, Reimann, and Stephan\n(2001) showed that there is no small span theorem for the resource-bounded\ndimension of Lutz (2000), even for polynomial-time many-one reductions.\n  Resource-bounded scaled dimension, recently introduced by Hitchcock, Lutz,\nand Mayordomo (2003), provides rescalings of resource-bounded dimension. We use\nscaled dimension to further understand the contrast between measure and\ndimension regarding polynomial-time spans and degrees. We strengthen prior\nresults by showing that the small span theorem holds for polynomial-time\nmany-one reductions in the -3rd-order scaled dimension, but fails to hold in\nthe -2nd-order scaled dimension. Our results also hold in exponential space.\n  As an application, we show that determining the -2nd- or -1st-order scaled\ndimension in ESPACE of the many-one complete languages for E would yield a\nproof of P = BPP or P != PSPACE. On the other hand, it is shown unconditionally\nthat the complete languages for E have -3rd-order scaled dimension 0 in ESPACE\nand -2nd- and -1st-order scaled dimension 1 in E."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304038v1", 
    "title": "How NP got a new definition: a survey of probabilistically checkable   proofs", 
    "arxiv-id": "cs/0304038v1", 
    "author": "Sanjeev Arora", 
    "publish": "2003-04-28T22:49:52Z", 
    "summary": "We survey a collective achievement of a group of researchers: the PCP\nTheorems. They give new definitions of the class \\np, and imply that computing\napproximate solutions to many \\np-hard problems is itself \\np-hard. Techniques\ndeveloped to prove them have had many other consequences."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304039v1", 
    "title": "Approximation thresholds for combinatorial optimization problems", 
    "arxiv-id": "cs/0304039v1", 
    "author": "Uriel Feige", 
    "publish": "2003-04-28T22:50:21Z", 
    "summary": "An NP-hard combinatorial optimization problem $\\Pi$ is said to have an {\\em\napproximation threshold} if there is some $t$ such that the optimal value of\n$\\Pi$ can be approximated in polynomial time within a ratio of $t$, and it is\nNP-hard to approximate it within a ratio better than $t$. We survey some of the\nknown approximation threshold results, and discuss the pattern that emerges\nfrom the known results."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304040v1", 
    "title": "Hardness as randomness: a survey of universal derandomization", 
    "arxiv-id": "cs/0304040v1", 
    "author": "Russell Impagliazzo", 
    "publish": "2003-04-28T22:50:34Z", 
    "summary": "We survey recent developments in the study of probabilistic complexity\nclasses. While the evidence seems to support the conjecture that probabilism\ncan be deterministically simulated with relatively low overhead, i.e., that\n$P=BPP$, it also indicates that this may be a difficult question to resolve. In\nfact, proving that probabilistic algorithms have non-trivial deterministic\nsimulations is basically equivalent to proving circuit lower bounds, either in\nthe algebraic or Boolean models."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304041v1", 
    "title": "$P \\ne NP$, propositional proof complexity, and resolution lower bounds   for the weak pigeonhole principle", 
    "arxiv-id": "cs/0304041v1", 
    "author": "Ran Raz", 
    "publish": "2003-04-28T22:51:57Z", 
    "summary": "Recent results established exponential lower bounds for the length of any\nResolution proof for the weak pigeonhole principle. More formally, it was\nproved that any Resolution proof for the weak pigeonhole principle, with $n$\nholes and any number of pigeons, is of length $\\Omega(2^{n^{\\epsilon}})$, (for\na constant $\\epsilon = 1/3$). One corollary is that certain propositional\nformulations of the statement $P \\ne NP$ do not have short Resolution proofs.\nAfter a short introduction to the problem of $P \\ne NP$ and to the research\narea of propositional proof complexity, I will discuss the above mentioned\nlower bounds for the weak pigeonhole principle and the connections to the\nhardness of proving $P \\ne NP$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0304044v1", 
    "title": "Hardness of approximating the weight enumerator of a binary linear code", 
    "arxiv-id": "cs/0304044v1", 
    "author": "M. N. Vyalyi", 
    "publish": "2003-04-30T03:13:23Z", 
    "summary": "We consider the problem of evaluation of the weight enumerator of a binary\nlinear code. We show that the exact evaluation is hard for polynomial\nhierarchy. More exactly, if WE is an oracle answering the solution of the\nevaluation problem then P^WE=P^GapP. Also we consider the approximative\nevaluation of the weight enumerator. In the case of approximation with additive\naccuracy $2^{\\alpha n}$, $\\alpha$ is constant the problem is hard in the above\nsense. We also prove that approximate evaluation at a single point $e^{\\pi\ni/4}$ is hard for $0<\\al<\\al_0\\approx0.88$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0305035v26", 
    "title": "The Computational Complexity of Computing the Permanent of a Matrix", 
    "arxiv-id": "cs/0305035v26", 
    "author": "Craig Alan Feinstein", 
    "publish": "2003-05-19T16:02:54Z", 
    "summary": "In this note, we show that there is no deterministic and exact algorithm that\ncomputes the permanent of a matrix in polynomial-time."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0306131v1", 
    "title": "Complexity of Cycle Length Modularity Problems in Graphs", 
    "arxiv-id": "cs/0306131v1", 
    "author": "Mayur Thakur", 
    "publish": "2003-06-25T15:37:43Z", 
    "summary": "The even cycle problem for both undirected and directed graphs has been the\ntopic of intense research in the last decade. In this paper, we study the\ncomputational complexity of \\emph{cycle length modularity problems}. Roughly\nspeaking, in a cycle length modularity problem, given an input (undirected or\ndirected) graph, one has to determine whether the graph has a cycle $C$ of a\nspecific length (or one of several different lengths), modulo a fixed integer.\nWe denote the two families (one for undirected graphs and one for directed\ngraphs) of problems by $(S,m)\\hbox{-}{\\rm UC}$ and $(S,m)\\hbox{-}{\\rm DC}$,\nwhere $m \\in \\mathcal{N}$ and $S \\subseteq \\{0,1, ..., m-1\\}$.\n$(S,m)\\hbox{-}{\\rm UC}$ (respectively, $(S,m)\\hbox{-}{\\rm DC}$) is defined as\nfollows: Given an undirected (respectively, directed) graph $G$, is there a\ncycle in $G$ whose length, modulo $m$, is a member of $S$? In this paper, we\nfully classify (i.e., as either polynomial-time solvable or as ${\\rm\nNP}$-complete) each problem $(S,m)\\hbox{-}{\\rm UC}$ such that $0 \\in S$ and\neach problem $(S,m)\\hbox{-}{\\rm DC}$ such that $0 \\notin S$. We also give a\nsufficient condition on $S$ and $m$ for the following problem to be\npolynomial-time computable: $(S,m)\\hbox{-}{\\rm UC}$ such that $0 \\notin S$."
},{
    "category": "cs.CC", 
    "doi": "10.5120/20564-2953", 
    "link": "http://arxiv.org/pdf/cs/0307020v1", 
    "title": "Defying Dimensions Mod 6", 
    "arxiv-id": "cs/0307020v1", 
    "author": "Vince Grolmusz", 
    "publish": "2003-07-08T15:10:37Z", 
    "summary": "We show that a certain representation of the matrix-product can be computed\nwith $n^{o(1)}$ multiplications. We also show, that siumilar representations of\nmatrices can be compressed enormously."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2004.02.001", 
    "link": "http://arxiv.org/pdf/cs/0309052v1", 
    "title": "Minimal DFAs for Testing Divisibility", 
    "arxiv-id": "cs/0309052v1", 
    "author": "Boris Alexeev", 
    "publish": "2003-09-29T19:34:36Z", 
    "summary": "We present and prove a theorem answering the question \"how many states does a\nminimal deterministic finite automaton (DFA) that recognizes the set of base-b\nnumbers divisible by k have?\""
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2004.02.001", 
    "link": "http://arxiv.org/pdf/cs/0310046v3", 
    "title": "Theory of One Tape Linear Time Turing Machines", 
    "arxiv-id": "cs/0310046v3", 
    "author": "Jack C. H. Lin", 
    "publish": "2003-10-23T21:08:22Z", 
    "summary": "A theory of one-tape (one-head) linear-time Turing machines is essentially\ndifferent from its polynomial-time counterpart since these machines are closely\nrelated to finite state automata. This paper discusses structural-complexity\nissues of one-tape Turing machines of various types (deterministic,\nnondeterministic, reversible, alternating, probabilistic, counting, and quantum\nTuring machines) that halt in linear time, where the running time of a machine\nis defined as the length of any longest computation path. We explore structural\nproperties of one-tape linear-time Turing machines and clarify how the\nmachines' resources affect their computational patterns and power."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2004.02.001", 
    "link": "http://arxiv.org/pdf/cs/0310060v19", 
    "title": "Puzzle: Zermelo-Fraenkel set theory is inconsistent", 
    "arxiv-id": "cs/0310060v19", 
    "author": "Craig Alan Feinstein", 
    "publish": "2003-10-31T18:32:00Z", 
    "summary": "In this note, we present a puzzle. We prove that Zermelo-Fraenkel set theory\nis inconsistent by proving, using Zermelo-Fraenkel set theory, the false\nstatement that any algorithm that determines whether any $n \\times n$ matrix\nover $\\mathbb F_2$, the finite field of order 2, is nonsingular must run in\nexponential time in the worst-case scenario. The object of the puzzle is to\nfind the error in the proof."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2004.02.001", 
    "link": "http://arxiv.org/pdf/cs/0312039v3", 
    "title": "Uniform test of algorithmic randomness over a general space", 
    "arxiv-id": "cs/0312039v3", 
    "author": "Peter Gacs", 
    "publish": "2003-12-17T19:25:30Z", 
    "summary": "The algorithmic theory of randomness is well developed when the underlying\nspace is the set of finite or infinite sequences and the underlying probability\ndistribution is the uniform distribution or a computable distribution. These\nrestrictions seem artificial. Some progress has been made to extend the theory\nto arbitrary Bernoulli distributions (by Martin-Loef), and to arbitrary\ndistributions (by Levin). We recall the main ideas and problems of Levin's\ntheory, and report further progress in the same framework.\n  - We allow non-compact spaces (like the space of continuous functions,\nunderlying the Brownian motion).\n  - The uniform test (deficiency of randomness) d_P(x) (depending both on the\noutcome x and the measure P should be defined in a general and natural way.\n  - We see which of the old results survive: existence of universal tests,\nconservation of randomness, expression of tests in terms of description\ncomplexity, existence of a universal measure, expression of mutual information\nas \"deficiency of independence.\n  - The negative of the new randomness test is shown to be a generalization of\ncomplexity in continuous spaces; we show that the addition theorem survives.\n  The paper's main contribution is introducing an appropriate framework for\nstudying these questions and related ones (like statistics for a general family\nof distributions)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0404044v2", 
    "title": "A note on dimensions of polynomial size circuits", 
    "arxiv-id": "cs/0404044v2", 
    "author": "Xiaoyang Gu", 
    "publish": "2004-04-22T14:45:48Z", 
    "summary": "In this paper, we use resource-bounded dimension theory to investigate\npolynomial size circuits. We show that for every $i\\geq 0$, $\\Ppoly$ has $i$th\norder scaled $\\pthree$-strong dimension 0. We also show that $\\Ppoly^\\io$ has\n$\\pthree$-dimension 1/2, $\\pthree$-strong dimension 1. Our results improve\nprevious measure results of Lutz (1992) and dimension results of Hitchcock and\nVinodchandran (2004)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0406009v1", 
    "title": "Implementation of Logical Functions in the Game of Life", 
    "arxiv-id": "cs/0406009v1", 
    "author": "J. -P. Rennard", 
    "publish": "2004-06-04T14:53:51Z", 
    "summary": "The Game of Life cellular automaton is a classical example of a massively\nparallel collision-based computing device. The automaton exhibits mobile\npatterns, gliders, and generators of the mobile patterns, glider guns, in its\nevolution. We show how to construct the basic logical operations, AND, OR, NOT\nin space-time configurations of the cellular automaton. Also decomposition of\ncomplicated Boolean functions is discussed. Advantages of our technique are\ndemonstrated on an example of binary adder, realized via collision of glider\nstreams."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0406044v4", 
    "title": "On the Computational Complexity of the Forcing Chromatic Number", 
    "arxiv-id": "cs/0406044v4", 
    "author": "Oleg Verbitsky", 
    "publish": "2004-06-23T15:21:46Z", 
    "summary": "We consider vertex colorings of graphs in which adjacent vertices have\ndistinct colors. A graph is $s$-chromatic if it is colorable in $s$ colors and\nany coloring of it uses at least $s$ colors. The forcing chromatic number\n$F(G)$ of an $s$-chromatic graph $G$ is the smallest number of vertices which\nmust be colored so that, with the restriction that $s$ colors are used, every\nremaining vertex has its color determined uniquely. We estimate the\ncomputational complexity of $F(G)$ relating it to the complexity class US\nintroduced by Blass and Gurevich. We prove that recognizing if $F(G)\\le 2$ is\nUS-hard with respect to polynomial-time many-one reductions. Moreover, this\nproblem is coNP-hard even under the promises that $F(G)\\le 3$ and $G$ is\n3-chromatic. On the other hand, recognizing if $F(G)\\le k$, for each constant\n$k$, is reducible to a problem in US via disjunctive truth-table reduction.\n  Similar results are obtained also for forcing variants of the clique and the\ndomination numbers of a graph."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0409012v3", 
    "title": "A New Look at Survey Propagation and its Generalizations", 
    "arxiv-id": "cs/0409012v3", 
    "author": "Martin J. Wainwright", 
    "publish": "2004-09-08T01:27:14Z", 
    "summary": "This paper provides a new conceptual perspective on survey propagation, which\nis an iterative algorithm recently introduced by the statistical physics\ncommunity that is very effective in solving random k-SAT problems even with\ndensities close to the satisfiability threshold. We first describe how any SAT\nformula can be associated with a novel family of Markov random fields (MRFs),\nparameterized by a real number \\rho \\in [0,1]. We then show that applying\nbelief propagation--a well-known ``message-passing'' technique for estimating\nmarginal probabilities--to this family of MRFs recovers a known family of\nalgorithms, ranging from pure survey propagation at one extreme (\\rho = 1) to\nstandard belief propagation on the uniform distribution over SAT assignments at\nthe other extreme (\\rho = 0). Configurations in these MRFs have a natural\ninterpretation as partial satisfiability assignments, on which a partial order\ncan be defined. We isolate cores as minimal elements in this partial ordering,\nwhich are also fixed points of survey propagation and the only assignments with\npositive probability in the MRF for \\rho=1. Our experimental results for k=3\nsuggest that solutions of random formulas typically do not possess non-trivial\ncores. This makes it necessary to study the structure of the space of partial\nassignments for \\rho<1 and investigate the role of assignments that are very\nclose to being cores. To that end, we investigate the associated lattice\nstructure, and prove a weight-preserving identity that shows how any MRF with\n\\rho>0 can be viewed as a ``smoothed'' version of the uniform distribution over\nsatisfying assignments (\\rho=0). Finally, we isolate properties of Gibbs\nsampling and message-passing algorithms that are typical for an ensemble of\nk-SAT problems."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0409043v1", 
    "title": "Inapproximability of Combinatorial Optimization Problems", 
    "arxiv-id": "cs/0409043v1", 
    "author": "Luca Trevisan", 
    "publish": "2004-09-24T02:13:23Z", 
    "summary": "We survey results on the hardness of approximating combinatorial optimization\nproblems."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0410035v1", 
    "title": "Overhead-Free Computation, DCFLs, and CFLs", 
    "arxiv-id": "cs/0410035v1", 
    "author": "Till Tantau", 
    "publish": "2004-10-15T18:18:22Z", 
    "summary": "We study Turing machines that are allowed absolutely no space overhead. The\nonly work space the machines have, beyond the fixed amount of memory implicit\nin their finite-state control, is that which they can create by cannibalizing\nthe input bits' own space. This model more closely reflects the fixed-sized\nmemory of real computers than does the standard complexity-theoretic model of\nlinear space.\n  Though some context-sensitive languages cannot be accepted by such machines,\nwe show that all context-free languages can be accepted nondeterministically in\npolynomial time with absolutely no space overhead, and that all deterministic\ncontext-free languages can be accepted deterministically in polynomial time\nwith absolutely no space overhead."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0410037v1", 
    "title": "Hardware-Oriented Group Solutions for Hard Problems", 
    "arxiv-id": "cs/0410037v1", 
    "author": "Mark Burgin", 
    "publish": "2004-10-15T23:12:12Z", 
    "summary": "Group and individual solutions are considered for hard problems such as\nsatisfiability problem. Time-space trade-off in a structured active memory\nprovides means to achieve lower time complexity for solutions of these\nproblems."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0410057v2", 
    "title": "Generalized Counters and Reversal Complexity", 
    "arxiv-id": "cs/0410057v2", 
    "author": "M. V. Panduranga Rao", 
    "publish": "2004-10-25T19:36:07Z", 
    "summary": "We generalize the definition of a counter and counter reversal complexity and\ninvestigate the power of generalized deterministic counter automata in terms of\nlanguage recognition."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0411007v1", 
    "title": "Basic properties for sand automata", 
    "arxiv-id": "cs/0411007v1", 
    "author": "Benoit Masson", 
    "publish": "2004-11-04T12:33:37Z", 
    "summary": "We prove several results about the relations between injectivity and\nsurjectivity for sand automata. Moreover, we begin the exploration of the\ndynamical behavior of sand automata proving that the property of nilpotency is\nundecidable. We believe that the proof technique used for this last result\nmight reveal useful for many other results in this context."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0411033v1", 
    "title": "On Invariance and Convergence in Time Complexity theory", 
    "arxiv-id": "cs/0411033v1", 
    "author": "Mircea Alexandru Popescu Moscu", 
    "publish": "2004-11-11T21:32:52Z", 
    "summary": "This article introduces three invariance principles under which P is\ndifferent from NP. In the second part a theorem of convergence is proven. This\ntheorem states that for any language L there exists an infinite sequence of\nlanguages from O(n) that converges to L."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0411037v2", 
    "title": "A Note on Bulk Quantum Turing Machine", 
    "arxiv-id": "cs/0411037v2", 
    "author": "Tetsushi Matsui", 
    "publish": "2004-11-12T18:56:15Z", 
    "summary": "Recently, among experiments for realization of quantum computers, NMR quantum\ncomputers have achieved the most impressive succession. There is a model of the\nNMR quantum computation,namely Atsumi and Nishino's bulk quantum Turing\nMachine. It assumes, however, an unnatural assumption with quantum mechanics.\nWe, then, define a more natural and quantum mechanically realizable modified\nbulk quantum Turing Machine, and show its computational ability by comparing\ncomplexity classes with quantum Turing Machine's counter part."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0412022v3", 
    "title": "Zeno machines and hypercomputation", 
    "arxiv-id": "cs/0412022v3", 
    "author": "Petrus H. Potgieter", 
    "publish": "2004-12-06T12:18:05Z", 
    "summary": "This paper reviews the Church-Turing Thesis (or rather, theses) with\nreference to their origin and application and considers some models of\n\"hypercomputation\", concentrating on perhaps the most straight-forward option:\nZeno machines (Turing machines with accelerating clock). The halting problem is\nbriefly discussed in a general context and the suggestion that it is an\ninevitable companion of any reasonable computational model is emphasised. It is\nhinted that claims to have \"broken the Turing barrier\" could be toned down and\nthat the important and well-founded role of Turing computability in the\nmathematical sciences stands unchallenged."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0412042v1", 
    "title": "The approximability of three-valued MAX CSP", 
    "arxiv-id": "cs/0412042v1", 
    "author": "Andrei Krokhin", 
    "publish": "2004-12-10T15:34:54Z", 
    "summary": "In the maximum constraint satisfaction problem (Max CSP), one is given a\nfinite collection of (possibly weighted) constraints on overlapping sets of\nvariables, and the goal is to assign values from a given domain to the\nvariables so as to maximize the number (or the total weight, for the weighted\ncase) of satisfied constraints. This problem is NP-hard in general, and,\ntherefore, it is natural to study how restricting the allowed types of\nconstraints affects the approximability of the problem. It is known that every\nBoolean (that is, two-valued) Max CSP problem with a finite set of allowed\nconstraint types is either solvable exactly in polynomial time or else\nAPX-complete (and hence can have no polynomial time approximation scheme unless\nP=NP. It has been an open problem for several years whether this result can be\nextended to non-Boolean Max CSP, which is much more difficult to analyze than\nthe Boolean case. In this paper, we make the first step in this direction by\nestablishing this result for Max CSP over a three-element domain. Moreover, we\npresent a simple description of all polynomial-time solvable cases of our\nproblem. This description uses the well-known algebraic combinatorial property\nof supermodularity. We also show that every hard three-valued Max CSP problem\ncontains, in a certain specified sense, one of the two basic hard Max CSP\nproblems which are the Maximum k-colourable subgraph problems for k=2,3."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0412048v1", 
    "title": "On computing fixed points for generalized sandpiles", 
    "arxiv-id": "cs/0412048v1", 
    "author": "Benoit Masson", 
    "publish": "2004-12-11T07:51:35Z", 
    "summary": "We prove fixed points results for sandpiles starting with arbitrary initial\nconditions. We give an effective algorithm for computing such fixed points, and\nwe refine it in the particular case of SPM."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2006.02.022", 
    "link": "http://arxiv.org/pdf/cs/0412062v2", 
    "title": "Isomorphic Implication", 
    "arxiv-id": "cs/0412062v2", 
    "author": "Edith Hemaspaandra", 
    "publish": "2004-12-14T17:15:29Z", 
    "summary": "We study the isomorphic implication problem for Boolean constraints. We show\nthat this is a natural analog of the subgraph isomorphism problem. We prove\nthat, depending on the set of constraints, this problem is in P, NP-complete,\nor NP-hard, coNP-hard, and in parallel access to NP. We show how to extend the\nNP-hardness and coNP-hardness to hardness for parallel access to NP for some\ncases, and conjecture that this can be done in all cases."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0412096v1", 
    "title": "Complexity of Self-Assembled Shapes", 
    "arxiv-id": "cs/0412096v1", 
    "author": "Erik Winfree", 
    "publish": "2004-12-21T10:30:46Z", 
    "summary": "The connection between self-assembly and computation suggests that a shape\ncan be considered the output of a self-assembly ``program,'' a set of tiles\nthat fit together to create a shape. It seems plausible that the size of the\nsmallest self-assembly program that builds a shape and the shape's\ndescriptional (Kolmogorov) complexity should be related. We show that when\nusing a notion of a shape that is independent of scale, this is indeed so: in\nthe Tile Assembly Model, the minimal number of distinct tile types necessary to\nself-assemble a shape, at some scale, can be bounded both above and below in\nterms of the shape's Kolmogorov complexity. As part of the proof of the main\nresult, we sketch a general method for converting a program outputting a shape\nas a list of locations into a set of tile types that self-assembles into a\nscaled up version of that shape. Our result implies, somewhat\ncounter-intuitively, that self-assembly of a scaled-up version of a shape often\nrequires fewer tile types. Furthermore, the independence of scale in\nself-assembly theory appears to play the same crucial role as the independence\nof running time in the theory of computability. This leads to an elegant\nformulation of languages of shapes generated by self-assembly. Considering\nfunctions from integers to shapes, we show that the running-time complexity,\nwith respect to Turing machines, is polynomially equivalent to the scale\ncomplexity of the same function implemented via self-assembly by a finite set\nof tile types. Our results also hold for shapes defined by Wang tiling -- where\nthere is no sense of a self-assembly process -- except that here time\ncomplexity must be measured with respect to non-deterministic Turing machines."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0412097v1", 
    "title": "The Computational Power of Benenson Automata", 
    "arxiv-id": "cs/0412097v1", 
    "author": "Erik Winfree", 
    "publish": "2004-12-21T10:57:15Z", 
    "summary": "The development of autonomous molecular computers capable of making\nindependent decisions in vivo regarding local drug administration may\nrevolutionize medical science. Recently Benenson at el (2004) have envisioned\none form such a ``smart drug'' may take by implementing an in vitro scheme, in\nwhich a long DNA state molecule is cut repeatedly by a restriction enzyme in a\nmanner dependent upon the presence of particular short DNA ``rule molecules.''\nTo analyze the potential of their scheme in terms of the kinds of computations\nit can perform, we study an abstraction assuming that a certain class of\nrestriction enzymes is available and reactions occur without error. We also\ndiscuss how our molecular algorithms could perform with known restriction\nenzymes. By exhibiting a way to simulate arbitrary circuits, we show that these\n``Benenson automata'' are capable of computing arbitrary Boolean functions.\nFurther, we show that they are able to compute efficiently exactly those\nfunctions computable by log-depth circuits. Computationally, we formalize a new\nvariant of limited width branching programs with a molecular implementation."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0501009v1", 
    "title": "On The Liniar Time Complexity of Finite Languages", 
    "arxiv-id": "cs/0501009v1", 
    "author": "Mircea Alexandru Popescu Moscu", 
    "publish": "2005-01-05T19:13:05Z", 
    "summary": "The present paper presents and proves a proposition concerning the time\ncomplexity of finite languages. It is shown herein, that for any finite\nlanguage (a language for which the set of words composing it is finite) there\nis a Turing machine that computes the language in such a way that for any input\nof length k the machine stops in, at most, k + 1 steps."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0501022v1", 
    "title": "Algebraic Properties for Selector Functions", 
    "arxiv-id": "cs/0501022v1", 
    "author": "Arfst Nickelsen", 
    "publish": "2005-01-11T23:55:17Z", 
    "summary": "The nondeterministic advice complexity of the P-selective sets is known to be\nexactly linear. Regarding the deterministic advice complexity of the\nP-selective sets--i.e., the amount of Karp--Lipton advice needed for\npolynomial-time machines to recognize them in general--the best current upper\nbound is quadratic [Ko, 1983] and the best current lower bound is linear\n[Hemaspaandra and Torenvliet, 1996].\n  We prove that every associatively P-selective set is commutatively,\nassociatively P-selective. Using this, we establish an algebraic sufficient\ncondition for the P-selective sets to have a linear upper bound (which thus\nwould match the existing lower bound) on their deterministic advice complexity:\nIf all P-selective sets are associatively P-selective then the deterministic\nadvice complexity of the P-selective sets is linear. The weakest previously\nknown sufficient condition was P=NP.\n  We also establish related results for algebraic properties of, and advice\ncomplexity of, the nondeterministically selective sets."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0501026v1", 
    "title": "On the Sensitivity of Cyclically-Invariant Boolean Functions", 
    "arxiv-id": "cs/0501026v1", 
    "author": "Sourav Chakraborty", 
    "publish": "2005-01-13T22:06:25Z", 
    "summary": "In this paper we construct a cyclically invariant Boolean function whose\nsensitivity is $\\Theta(n^{1/3})$. This result answers two previously published\nquestions. Tur\\'an (1984) asked if any Boolean function, invariant under some\ntransitive group of permutations, has sensitivity $\\Omega(\\sqrt{n})$. Kenyon\nand Kutin (2004) asked whether for a ``nice'' function the product of\n0-sensitivity and 1-sensitivity is $\\Omega(n)$. Our function answers both\nquestions in the negative.\n  We also prove that for minterm-transitive functions (a natural class of\nBoolean functions including our example) the sensitivity is $\\Omega(n^{1/3})$.\nHence for this class of functions sensitivity and block sensitivity are\npolynomially related."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0502030v36", 
    "title": "Fixed Type Theorems", 
    "arxiv-id": "cs/0502030v36", 
    "author": "Raju Renjit G", 
    "publish": "2005-02-05T17:13:40Z", 
    "summary": "This submission has been withdrawn at the request of the author."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0502068v1", 
    "title": "Limits of Rush Hour Logic Complexity", 
    "arxiv-id": "cs/0502068v1", 
    "author": "Rudi Cilibrasi", 
    "publish": "2005-02-15T14:22:35Z", 
    "summary": "Rush Hour Logic was introduced in [Flake&Baum99] as a model of computation\ninspired by the ``Rush Hour'' toy puzzle, in which cars can move horizontally\nor vertically within a parking lot. The authors show how the model supports\npolynomial space computation, using certain car configurations as building\nblocks to construct boolean circuits for a cpu and memory. They consider the\nuse of cars of length 3 crucial to their construction, and conjecture that cars\nof size 2 only, which we'll call `Size 2 Rush Hour', do not support polynomial\nspace computation. We settle this conjecture by showing that the required\nbuilding blocks are constructible in Size 2 Rush Hour. Furthermore, we consider\nUnit Rush Hour, which was hitherto believed to be trivial, show its relation to\nmaze puzzles, and provide empirical support for its hardness."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0503034v1", 
    "title": "Comment on \"Some non-conventional ideas about algorithmic complexity\"", 
    "arxiv-id": "cs/0503034v1", 
    "author": "Hugo Touchette", 
    "publish": "2005-03-16T11:09:06Z", 
    "summary": "We comment on a recent paper by D'Abramo [Chaos, Solitons & Fractals, 25\n(2005) 29], focusing on the author's statement that an algorithm can produce a\nlist of strings containing at least one string whose algorithmic complexity is\ngreater than that of the entire list. We show that this statement, although\nperplexing, is not as paradoxical as it seems when the definition of\nalgorithmic complexity is applied correctly."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0503049v3", 
    "title": "Enforcing and Defying Associativity, Commutativity, Totality, and Strong   Noninvertibility for One-Way Functions in Complexity Theory", 
    "arxiv-id": "cs/0503049v3", 
    "author": "Amitabh Saxena", 
    "publish": "2005-03-21T19:19:54Z", 
    "summary": "Rabi and Sherman [RS97,RS93] proved that the hardness of factoring is a\nsufficient condition for there to exist one-way functions (i.e., p-time\ncomputable, honest, p-time noninvertible functions; this paper is in the\nworst-case model, not the average-case model) that are total, commutative, and\nassociative but not strongly noninvertible. In this paper we improve the\nsufficient condition to ``P does not equal NP.''\n  More generally, in this paper we completely characterize which types of\none-way functions stand or fall together with (plain) one-way\nfunctions--equivalently, stand or fall together with P not equaling NP. We look\nat the four attributes used in Rabi and Sherman's seminal work on algebraic\nproperties of one-way functions (see [RS97,RS93]) and subsequent\npapers--strongness (of noninvertibility), totality, commutativity, and\nassociativity--and for each attribute, we allow it to be required to hold,\nrequired to fail, or ``don't care.'' In this categorization there are 3^4 = 81\npotential types of one-way functions. We prove that each of these 81\nfeature-laden types stand or fall together with the existence of (plain)\none-way functions."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0504088v1", 
    "title": "Time, Space, and Energy in Reversible Computing", 
    "arxiv-id": "cs/0504088v1", 
    "author": "Paul Vitanyi", 
    "publish": "2005-04-20T17:13:33Z", 
    "summary": "We survey results of a quarter century of work on computation by reversible\ngeneral-purpose computers (in this setting Turing machines), and general\nreversible simulation of irreversible computations, with respect to energy-,\ntime- and space requirements."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0504096v2", 
    "title": "P-Selectivity, Immunity, and the Power of One Bit", 
    "arxiv-id": "cs/0504096v2", 
    "author": "Leen Torenvliet", 
    "publish": "2005-04-25T15:18:17Z", 
    "summary": "We prove that P-sel, the class of all P-selective sets, is EXP-immune, but is\nnot EXP/1-immune. That is, we prove that some infinite P-selective set has no\ninfinite EXP-time subset, but we also prove that every infinite P-selective set\nhas some infinite subset in EXP/1. Informally put, the immunity of P-sel is so\nfragile that it is pierced by a single bit of information.\n  The above claims follow from broader results that we obtain about the\nimmunity of the P-selective sets. In particular, we prove that for every\nrecursive function f, P-sel is DTIME(f)-immune. Yet we also prove that P-sel is\nnot \\Pi_2^p/1-immune."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0505076v1", 
    "title": "On the Solution of Graph Isomorphism by Dynamical Algorithms", 
    "arxiv-id": "cs/0505076v1", 
    "author": "Marats Golovkins", 
    "publish": "2005-05-27T00:09:12Z", 
    "summary": "In the recent years, several polynomial algorithms of a dynamical nature have\nbeen proposed to address the graph isomorphism problem. In this paper we\npropose a generalization of an approach exposed in cond-mat/0209112 and find\nthat this dynamical algorithm is covered by a combinatorial approach. It is\npossible to infer that polynomial dynamical algorithms addressing graph\nisomorphism are covered by suitable polynomial combinatorial approaches and\nthus are tackled by the same weaknesses as the last ones."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0505079v1", 
    "title": "Application of Kolmogorov complexity and universal codes to identity   testing and nonparametric testing of serial independence for time series", 
    "arxiv-id": "cs/0505079v1", 
    "author": "Alex Gammerman", 
    "publish": "2005-05-29T17:12:47Z", 
    "summary": "We show that Kolmogorov complexity and such its estimators as universal codes\n(or data compression methods) can be applied for hypotheses testing in a\nframework of classical mathematical statistics. The methods for identity\ntesting and nonparametric testing of serial independence for time series are\nsuggested."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0506081v2", 
    "title": "Three lines proof of the lower bound for the matrix rigidity", 
    "arxiv-id": "cs/0506081v2", 
    "author": "Gatis Midrijanis", 
    "publish": "2005-06-20T19:54:48Z", 
    "summary": "The rigidity of a matrix describes the minimal number of entries one has to\nchange to reduce matrix's rank to r. We give very simple combinatorial proof of\nthe lower bound for the rigidity of Sylvester (special case of Hadamard) matrix\nthat matches the best known result by de Wolf(2005) for Hadamard matrices\nproved by quantum information theoretical arguments."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0506082v1", 
    "title": "Open Questions in the Theory of Semifeasible Computation", 
    "arxiv-id": "cs/0506082v1", 
    "author": "Lane A. Hemaspaandra", 
    "publish": "2005-06-20T22:33:51Z", 
    "summary": "The study of semifeasible algorithms was initiated by Selman's work a quarter\nof century ago [Sel79,Sel81,Sel82]. Informally put, this research stream\nstudies the power of those sets L for which there is a deterministic (or in\nsome cases, the function may belong to one of various nondeterministic function\nclasses) polynomial-time function f such that when at least one of x and y\nbelongs to L, then f(x,y) \\in L \\cap \\{x,y\\}. The intuition here is that it is\nsaying: ``Regarding membership in L, if you put a gun to my head and forced me\nto bet on one of x or y as belonging to L, my money would be on f(x,y).''\n  In this article, we present a number of open problems from the theory of\nsemifeasible algorithms. For each we present its background and review what\npartial results, if any, are known."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0506090v1", 
    "title": "An Exact 2.9416^n Algorithm for the Three Domatic Number Problem", 
    "arxiv-id": "cs/0506090v1", 
    "author": "J\u00f6rg Rothe", 
    "publish": "2005-06-24T12:58:15Z", 
    "summary": "The three domatic number problem asks whether a given undirected graph can be\npartitioned into at least three dominating sets, i.e., sets whose closed\nneighborhood equals the vertex set of the graph. Since this problem is\nNP-complete, no polynomial-time algorithm is known for it. The naive\ndeterministic algorithm for this problem runs in time 3^n, up to polynomial\nfactors. In this paper, we design an exact deterministic algorithm for this\nproblem running in time 2.9416^n. Thus, our algorithm can handle problem\ninstances of larger size than the naive algorithm in the same amount of time.\nWe also present another deterministic and a randomized algorithm for this\nproblem that both have an even better performance for graphs with small maximum\ndegree."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0506100v1", 
    "title": "On the NP-Completeness of Some Graph Cluster Measures", 
    "arxiv-id": "cs/0506100v1", 
    "author": "Satu Elisa Schaeffer", 
    "publish": "2005-06-29T18:12:28Z", 
    "summary": "Graph clustering is the problem of identifying sparsely connected dense\nsubgraphs (clusters) in a given graph. Proposed clustering algorithms usually\noptimize various fitness functions that measure the quality of a cluster within\nthe graph. Examples of such cluster measures include the conductance, the local\nand relative densities, and single cluster editing. We prove that the decision\nproblems associated with the optimization tasks of finding the clusters that\nare optimal with respect to these fitness measures are NP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0507057v1", 
    "title": "A new sibling of BQP", 
    "arxiv-id": "cs/0507057v1", 
    "author": "Tereza Tusarova", 
    "publish": "2005-07-21T22:36:41Z", 
    "summary": "We present a new quantum complexity class, called MQ^2, which is contained in\nAWPP. This class has a compact and simple mathematical definition, involving\nonly polynomial-time computable functions and a unitarity condition. It\ncontains both Deutsch-Jozsa's and Shor's algorithm, while its relation to BQP\nis unknown. This shows that in the complexity class hierarchy, BQP is not an\nextraordinary isolated island, but has ''siblings'' which as well can solve\nprime-factorization."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0508037v2", 
    "title": "The Phase Transition in Exact Cover", 
    "arxiv-id": "cs/0508037v2", 
    "author": "Cris Moore", 
    "publish": "2005-08-04T15:01:48Z", 
    "summary": "We study EC3, a variant of Exact Cover which is equivalent to Positive 1-in-3\nSAT. Random instances of EC3 were recently used as benchmarks for simulations\nof an adiabatic quantum algorithm. Empirical results suggest that EC3 has a\nphase transition from satisfiability to unsatisfiability when the number of\nclauses per variable r exceeds some threshold r* ~= 0.62 +- 0.01. Using the\nmethod of differential equations, we show that if r <= 0.546 w.h.p. a random\ninstance of EC3 is satisfiable. Combined with previous results this limits the\nlocation of the threshold, if it exists, to the range 0.546 < r* < 0.644."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0511085v2", 
    "title": "Proving that P is not equal to NP and that P is not equal to the   intersection of NP and co-NP", 
    "arxiv-id": "cs/0511085v2", 
    "author": "R. A. Cohen", 
    "publish": "2005-11-25T15:23:18Z", 
    "summary": "The open question, P=NP?, was presented by Cook (1971). In this paper, a\nproof that P is not equal to NP is presented. In addition, it is shown that P\nis not equal to the intersection of NP and co-NP. Finally, the exact inclusion\nrelationships between the classes P, NP and co-NP are presented."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0512035v1", 
    "title": "Semidefinite programming and arithmetic circuit evaluation", 
    "arxiv-id": "cs/0512035v1", 
    "author": "Mikhail N. Vyalyi", 
    "publish": "2005-12-09T16:01:16Z", 
    "summary": "A rational number can be naturally presented by an arithmetic computation\n(AC): a sequence of elementary arithmetic operations starting from a fixed\nconstant, say 1. The asymptotic complexity issues of such a representation are\nstudied e.g. in the framework of the algebraic complexity theory over arbitrary\nfield.\n  Here we study a related problem of the complexity of performing arithmetic\noperations and computing elementary predicates, e.g. ``='' or ``>'', on\nrational numbers given by AC.\n  In the first place, we prove that AC can be efficiently simulated by the\nexact semidefinite programming (SDP).\n  Secondly, we give a BPP-algorithm for the equality predicate.\n  Thirdly, we put ``>''-predicate into the complexity class PSPACE.\n  We conjecture that ``>''-predicate is hard to compute. This conjecture, if\ntrue, would clarify the complexity status of the exact SDP - a well known open\nproblem in the field of mathematical programming."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0601086v2", 
    "title": "Comments on Beckmann's Uniform Reducts", 
    "arxiv-id": "cs/0601086v2", 
    "author": "Stephen Cook", 
    "publish": "2006-01-19T22:56:49Z", 
    "summary": "Arnold Beckmann defined the uniform reduct of a propositional proof system f\nto be the set of those bounded arithmetical formulas whose propositional\ntranslations have polynomial size f-proofs. We prove that the uniform reduct of\nf + Extended Frege consists of all true bounded arithmetical formulas iff f +\nExtended Frege simulates every proof system."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0602001v1", 
    "title": "Query-Monotonic Turing Reductions", 
    "arxiv-id": "cs/0602001v1", 
    "author": "Mayur Thakur", 
    "publish": "2006-01-31T22:02:05Z", 
    "summary": "We study reductions that limit the extreme adaptivity of Turing reductions.\nIn particular, we study reductions that make a rapid, structured progression\nthrough the set to which they are reducing: Each query is strictly longer\n(shorter) than the previous one. We call these reductions query-increasing\n(query-decreasing) Turing reductions. We also study query-nonincreasing\n(query-nondecreasing) Turing reductions. These are Turing reductions in which\nthe sequence of query lengths is nonincreasing (nondecreasing). We ask whether\nthese restrictions in fact limit the power of reductions. We prove that\nquery-increasing and query-decreasing Turing reductions are incomparable with\n(that is, are neither strictly stronger than nor strictly weaker than)\ntruth-table reductions and are strictly weaker than Turing reductions. In\naddition, we prove that query-nonincreasing and query-nondecreasing Turing\nreductions are strictly stronger than truth-table reductions and strictly\nweaker than Turing reductions. Despite the fact that we prove query-increasing\nand query-decreasing Turing reductions to in the general case be strictly\nweaker than Turing reductions, we identify a broad class of sets A for which\nany set that Turing reduces to A will also reduce to A via both\nquery-increasing and query-decreasing Turing reductions. In particular, this\nholds for all tight paddable sets, where a set is said to be tight paddable\nexactly if it is paddable via a function whose output length is bounded tightly\nboth from above and from below in the length of the input. We prove that many\nnatural NP-complete problems such as satisfiability, clique, and vertex cover\nare tight paddable."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0602010v1", 
    "title": "Reducing Tile Complexity for Self-Assembly Through Temperature   Programming", 
    "arxiv-id": "cs/0602010v1", 
    "author": "Robert Schweller", 
    "publish": "2006-02-05T01:00:32Z", 
    "summary": "We consider the tile self-assembly model and how tile complexity can be\neliminated by permitting the temperature of the self-assembly system to be\nadjusted throughout the assembly process. To do this, we propose novel\ntechniques for designing tile sets that permit an arbitrary length $m$ binary\nnumber to be encoded into a sequence of $O(m)$ temperature changes such that\nthe tile set uniquely assembles a supertile that precisely encodes the\ncorresponding binary number. As an application, we show how this provides a\ngeneral tile set of size O(1) that is capable of uniquely assembling\nessentially any $n\\times n$ square, where the assembled square is determined by\na temperature sequence of length $O(\\log n)$ that encodes a binary description\nof $n$. This yields an important decrease in tile complexity from the required\n$\\Omega(\\frac{\\log n}{\\log\\log n})$ for almost all $n$ when the temperature of\nthe system is fixed. We further show that for almost all $n$, no tile system\ncan simultaneously achieve both $o(\\log n)$ temperature complexity and\n$o(\\frac{\\log n}{\\log\\log n})$ tile complexity, showing that both versions of\nan optimal square building scheme have been discovered. This work suggests that\ntemperature change can constitute a natural, dynamic method for providing input\nto self-assembly systems that is potentially superior to the current technique\nof designing large tile sets with specific inputs hardwired into the tileset."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0602047v3", 
    "title": "Approximability of Integer Programming with Generalised Constraints", 
    "arxiv-id": "cs/0602047v3", 
    "author": "Gustav Nordh", 
    "publish": "2006-02-13T18:48:52Z", 
    "summary": "We study a family of problems, called \\prob{Maximum Solution}, where the\nobjective is to maximise a linear goal function over the feasible integer\nassignments to a set of variables subject to a set of constraints. When the\ndomain is Boolean (i.e. restricted to $\\{0,1\\}$), the maximum solution problem\nis identical to the well-studied \\prob{Max Ones} problem, and the\napproximability is completely understood for all restrictions on the underlying\nconstraints [Khanna et al., SIAM J. Comput., 30 (2001), pp. 1863-1920]. We\ncontinue this line of research by considering domains containing more than two\nelements. We present two main results: a complete classification for the\napproximability of all maximal constraint languages over domains of cardinality\nat most 4, and a complete classification of the approximability of the problem\nwhen the set of allowed constraints contains all permutation constraints. Under\nthe assumption that a conjecture due to Szczepara holds, we give a complete\nclassification for all maximal constraint languages. These classes of languages\nare well-studied in universal algebra and computer science; they have, for\ninstance, been considered in connection with machine learning and constraint\nsatisfaction. Our results are proved by using algebraic results from clone\ntheory and the results indicates that this approach is very powerful for\nclassifying the approximability of certain optimisation problems."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0602075v1", 
    "title": "The approximability of MAX CSP with fixed-value constraints", 
    "arxiv-id": "cs/0602075v1", 
    "author": "Andrei Krokhin", 
    "publish": "2006-02-21T14:13:37Z", 
    "summary": "In the maximum constraint satisfaction problem (MAX CSP), one is given a\nfinite collection of (possibly weighted) constraints on overlapping sets of\nvariables, and the goal is to assign values from a given finite domain to the\nvariables so as to maximize the number (or the total weight, for the weighted\ncase) of satisfied constraints. This problem is NP-hard in general, and,\ntherefore, it is natural to study how restricting the allowed types of\nconstraints affects the approximability of the problem. In this paper, we show\nthat any MAX CSP problem with a finite set of allowed constraint types, which\nincludes all fixed-value constraints (i.e., constraints of the form x=a), is\neither solvable exactly in polynomial-time or else is APX-complete, even if the\nnumber of occurrences of variables in instances are bounded. Moreover, we\npresent a simple description of all polynomial-time solvable cases of our\nproblem. This description relies on the well-known algebraic combinatorial\nproperty of supermodularity."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0603017v2", 
    "title": "A Measure of Space for Computing over the Reals", 
    "arxiv-id": "cs/0603017v2", 
    "author": "Paulin Jacob\u00e9 De Naurois", 
    "publish": "2006-03-03T13:27:45Z", 
    "summary": "We propose a new complexity measure of space for the BSS model of\ncomputation. We define LOGSPACE\\_W and PSPACE\\_W complexity classes over the\nreals. We prove that LOGSPACE\\_W is included in NC^2\\_R and in P\\_W, i.e. is\nsmall enough for being relevant. We prove that the Real Circuit Decision\nProblem is P\\_R-complete under LOGSPACE\\_W reductions, i.e. that LOGSPACE\\_W is\nlarge enough for containing natural algorithms. We also prove that PSPACE\\_W is\nincluded in PAR\\_R."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0603060v1", 
    "title": "An Improved Exact Algorithm for the Domatic Number Problem", 
    "arxiv-id": "cs/0603060v1", 
    "author": "Masaki Yamamoto", 
    "publish": "2006-03-16T16:05:40Z", 
    "summary": "The 3-domatic number problem asks whether a given graph can be partitioned\nintothree dominating sets. We prove that this problem can be solved by a\ndeterministic algorithm in time 2.695^n (up to polynomial factors). This result\nimproves the previous bound of 2.8805^n, which is due to Fomin, Grandoni,\nPyatkin, and Stepanov. To prove our result, we combine an algorithm by Fomin et\nal. with Yamamoto's algorithm for the satisfiability problem. In addition, we\nshow that the 3-domatic number problem can be solved for graphs G with bounded\nmaximum degree Delta(G) by a randomized algorithm, whose running time is better\nthan the previous bound due to Riege and Rothe whenever Delta(G) >= 5. Our new\nrandomized algorithm employs Schoening's approach to constraint satisfaction\nproblems."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0604003v1", 
    "title": "Hypercomputing the Mandelbrot Set?", 
    "arxiv-id": "cs/0604003v1", 
    "author": "Petrus H. Potgieter", 
    "publish": "2006-04-02T15:31:32Z", 
    "summary": "The Mandelbrot set is an extremely well-known mathematical object that can be\ndescribed in a quite simple way but has very interesting and non-trivial\nproperties. This paper surveys some results that are known concerning the\n(non-)computability of the set. It considers two models of decidability over\nthe reals (which have been treated much more thoroughly and technically by\nHertling (2005), Blum, Shub and Smale, Brattka (2003) and Weihrauch (1999 and\n2003) among others), two over the computable reals (the Russian school and\nhypercomputation) and a model over the rationals."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0604014v2", 
    "title": "Towards Analog Reverse Time Computation", 
    "arxiv-id": "cs/0604014v2", 
    "author": "M. O. Dhar", 
    "publish": "2006-04-05T23:40:56Z", 
    "summary": "We report the consequences of a destabilization process on a simulated\nGeneral Purpose Analog Computer. This new technology overcomes problems linked\nwith serial ambiguity, and provides an analog bias to encode algorithms whose\ncomplexity is over polynomial. We also implicitly demonstrate how\ncountermesures of the Stochastic Aperture Degeneracy could efficiently reach\nhigher computational classes, and would open a road towards Analog Reverse Time\nComputation."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0604047v1", 
    "title": "Efficient algorithms for deciding the type of growth of products of   integer matrices", 
    "arxiv-id": "cs/0604047v1", 
    "author": "Vincent D. Blondel", 
    "publish": "2006-04-11T14:10:37Z", 
    "summary": "For a given finite set $\\Sigma$ of matrices with nonnegative integer entries\nwe study the growth of $$ \\max_t(\\Sigma) = \\max\\{\\|A_{1}... A_{t}\\|: A_i \\in\n\\Sigma\\}.$$ We show how to determine in polynomial time whether the growth with\n$t$ is bounded, polynomial, or exponential, and we characterize precisely all\npossible behaviors."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0604113v1", 
    "title": "One-in-Two-Matching Problem is NP-complete", 
    "arxiv-id": "cs/0604113v1", 
    "author": "Andrea Sportiello", 
    "publish": "2006-04-28T16:40:09Z", 
    "summary": "2-dimensional Matching Problem, which requires to find a matching of left- to\nright-vertices in a balanced $2n$-vertex bipartite graph, is a well-known\npolynomial problem, while various variants, like the 3-dimensional analogoue\n(3DM, with triangles on a tripartite graph), or the Hamiltonian Circuit Problem\n(HC, a restriction to ``unicyclic'' matchings) are among the main examples of\nNP-hard problems, since the first Karp reduction series of 1972. The same holds\nfor the weighted variants of these problems, the Linear Assignment Problem\nbeing polynomial, and the Numerical 3-Dimensional Matching and Travelling\nSalesman Problem being NP-complete.\n  In this paper we show that a small modification of the 2-dimensional Matching\nand Assignment Problems in which for each $i \\leq n/2$ it is required that\neither $\\pi(2i-1)=2i-1$ or $\\pi(2i)=2i$, is a NP-complete problem. The proof is\nby linear reduction from SAT (or NAE-SAT), with the size $n$ of the Matching\nProblem being four times the number of edges in the factor graph representation\nof the boolean problem. As a corollary, in combination with the simple linear\nreduction of One-in-Two Matching to 3-Dimensional Matching, we show that SAT\ncan be linearly reduced to 3DM, while the original Karp reduction was only\ncubic."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0606009v4", 
    "title": "The Consequences of Eliminating NP Solutions", 
    "arxiv-id": "cs/0606009v4", 
    "author": "Lane A. Hemaspaandra", 
    "publish": "2006-06-02T01:34:26Z", 
    "summary": "Given a function based on the computation of an NP machine, can one in\ngeneral eliminate some solutions? That is, can one in general decrease the\nambiguity? This simple question remains, even after extensive study by many\nresearchers over many years, mostly unanswered. However, complexity-theoretic\nconsequences and enabling conditions are known. In this tutorial-style article\nwe look at some of those, focusing on the most natural framings: reducing the\nnumber of solutions of NP functions, refining the solutions of NP functions,\nand subtracting from or otherwise shrinking #P functions. We will see how small\nadvice strings are important here, but we also will see how increasing advice\nsize to achieve robustness is central to the proof of a key ambiguity-reduction\nresult for NP functions."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0606033v2", 
    "title": "Natural Halting Probabilities, Partial Randomness, and Zeta Functions", 
    "arxiv-id": "cs/0606033v2", 
    "author": "Michael A. Stay", 
    "publish": "2006-06-07T20:18:13Z", 
    "summary": "We introduce the zeta number, natural halting probability and natural\ncomplexity of a Turing machine and we relate them to Chaitin's Omega number,\nhalting probability, and program-size complexity. A classification of Turing\nmachines according to their zeta numbers is proposed: divergent, convergent and\ntuatara. We prove the existence of universal convergent and tuatara machines.\nVarious results on (algorithmic) randomness and partial randomness are proved.\nFor example, we show that the zeta number of a universal tuatara machine is\nc.e. and random. A new type of partial randomness, asymptotic randomness, is\nintroduced. Finally we show that in contrast to classical (algorithmic)\nrandomness--which cannot be naturally characterised in terms of plain\ncomplexity--asymptotic randomness admits such a characterisation."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0606037v2", 
    "title": "Average-Case Complexity", 
    "arxiv-id": "cs/0606037v2", 
    "author": "Luca Trevisan", 
    "publish": "2006-06-08T18:40:21Z", 
    "summary": "We survey the average-case complexity of problems in NP.\n  We discuss various notions of good-on-average algorithms, and present\ncompleteness results due to Impagliazzo and Levin. Such completeness results\nestablish the fact that if a certain specific (but somewhat artificial) NP\nproblem is easy-on-average with respect to the uniform distribution, then all\nproblems in NP are easy-on-average with respect to all samplable distributions.\nApplying the theory to natural distributional problems remain an outstanding\nopen question. We review some natural distributional problems whose\naverage-case complexity is of particular interest and that do not yet fit into\nthis theory.\n  A major open question whether the existence of hard-on-average problems in NP\ncan be based on the P$\\neq$NP assumption or on related worst-case assumptions.\nWe review negative results showing that certain proof techniques cannot prove\nsuch a result. While the relation between worst-case and average-case\ncomplexity for general NP problems remains open, there has been progress in\nunderstanding the relation between different ``degrees'' of average-case\ncomplexity. We discuss some of these ``hardness amplification'' results."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0606057v1", 
    "title": "Approximability of Bounded Occurrence Max Ones", 
    "arxiv-id": "cs/0606057v1", 
    "author": "Fredrik Kuivinen", 
    "publish": "2006-06-13T06:44:21Z", 
    "summary": "We study the approximability of Max Ones when the number of variable\noccurrences is bounded by a constant. For conservative constraint languages\n(i.e., when the unary relations are included) we give a complete classification\nwhen the number of occurrences is three or more and a partial classification\nwhen the bound is two.\n  For the non-conservative case we prove that it is either trivial or\nequivalent to the corresponding conservative problem under polynomial-time\nmany-one reductions."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0606064v1", 
    "title": "Improved Exponential Time Lower Bound of Knapsack Problem under BT model", 
    "arxiv-id": "cs/0606064v1", 
    "author": "Jiaqi Zhu", 
    "publish": "2006-06-14T07:54:14Z", 
    "summary": "M.Alekhnovich et al. recently have proposed a model of algorithms, called BT\nmodel, which covers Greedy, Backtrack and Simple Dynamic Programming methods\nand can be further divided into fixed, adaptive and fully adaptive three kinds,\nand have proved exponential time lower bounds of exact and approximation\nalgorithms under adaptive BT model for Knapsack problem which are\n$\\Omega(2^{n/2}/\\sqrt n)=\\Omega(2^{0.5n}/\\sqrt n)$ and\n$\\Omega((1/\\epsilon)^{1/3.17})\\approx\\Omega((1/\\epsilon)^{0.315})$(for\napproximation ratio $1-\\epsilon$) respectively (M. Alekhovich, A. Borodin, J.\nBuresh-Oppenheim, R. Impagliazzo, A. Magen, and T. Pitassi, Toward a Model for\nBacktracking and Dynamic Programming, \\emph{Proceedings of Twentieth Annual\nIEEE Conference on Computational Complexity}, pp308-322, 2005). In this note,\nwe slightly improved their lower bounds to\n$\\Omega(2^{(2-\\epsilon)n/3}/\\sqrt{n})\\approx \\Omega(2^{0.66n}/\\sqrt{n})$ and\n$\\Omega((1/\\epsilon)^{1/2.38})\\approx\\Omega((1/\\epsilon)^{0.420})$, and\nproposed as an open question what is the best achievable lower bounds for\nknapsack under adaptive BT models."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0606080v1", 
    "title": "On the structure of linear-time reducibility", 
    "arxiv-id": "cs/0606080v1", 
    "author": "Philippe Chapdelaine", 
    "publish": "2006-06-19T08:48:58Z", 
    "summary": "In 1975, Ladner showed that under the hypothesis that P is not equal to NP,\nthere exists a language which is neither in P, nor NP-complete. This result was\nlatter generalized by Schoning and several authors to various polynomial-time\ncomplexity classes. We show here that such results also apply to linear-time\nreductions on RAMs (resp. Turing machines), and hence allow for separation\nresults in linear-time classes similar to Ladner's ones for polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0607054v1", 
    "title": "Elementary Proof of a Theorem of Jean Ville", 
    "arxiv-id": "cs/0607054v1", 
    "author": "Scott Weinstein", 
    "publish": "2006-07-11T19:52:56Z", 
    "summary": "Considerable thought has been devoted to an adequate definition of the class\nof infinite, random binary sequences (the sort of sequence that almost\ncertainly arises from flipping a fair coin indefinitely). The first\nmathematical exploration of this problem was due to R. Von Mises, and based on\nhis concept of a \"selection function.\" A decisive objection to Von Mises' idea\nwas formulated in a theorem offered by Jean Ville in 1939. It shows that some\nsequences admitted by Von Mises as \"random\" in fact manifest a certain kind of\nsystematicity. Ville's proof is challenging, and an alternative approach has\nappeared only in condensed form. We attempt to provide an expanded version of\nthe latter, alternative argument."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0607093v21", 
    "title": "An Elegant Argument that P is not NP", 
    "arxiv-id": "cs/0607093v21", 
    "author": "Craig Alan Feinstein", 
    "publish": "2006-07-19T19:01:09Z", 
    "summary": "In this note, we present an elegant argument that P is not NP by\ndemonstrating that the Meet-in-the-Middle algorithm must have the fastest\nrunning-time of all deterministic and exact algorithms which solve the\nSUBSET-SUM problem on a classical computer."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0607118v2", 
    "title": "A new function algebra of EXPTIME functions by safe nested recursion", 
    "arxiv-id": "cs/0607118v2", 
    "author": "Naohi Eguchi", 
    "publish": "2006-07-27T06:34:53Z", 
    "summary": "Bellantoni and Cook have given a function-algebra characterization of the\npolynomial-time computable functions via an unbounded recursion scheme which is\ncalled safe recursion. Inspired by their work, we characterize the\nexponential-time computable functions with the use of a safe variant of nested\nrecursion."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0608020v1", 
    "title": "Quasi-friendly sup-interpretations", 
    "arxiv-id": "cs/0608020v1", 
    "author": "Romain Pechoux", 
    "publish": "2006-08-03T13:05:32Z", 
    "summary": "In a previous paper, the sup-interpretation method was proposed as a new tool\nto control memory resources of first order functional programs with pattern\nmatching by static analysis. Basically, a sup-interpretation provides an upper\nbound on the size of function outputs. In this former work, a criterion, which\ncan be applied to terminating as well as non-terminating programs, was\ndeveloped in order to bound polynomially the stack frame size. In this paper,\nwe suggest a new criterion which captures more algorithms computing values\npolynomially bounded in the size of the inputs. Since this work is related to\nquasi-interpretations, we compare the two notions obtaining two main features.\nThe first one is that, given a program, we have heuristics for finding a\nsup-interpretation when we consider polynomials of bounded degree. The other\none consists in the characterizations of the set of function computable in\npolynomial time and in polynomial space."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0608036v1", 
    "title": "Reversal Complexity Revisited", 
    "arxiv-id": "cs/0608036v1", 
    "author": "Nicole Schweikardt", 
    "publish": "2006-08-07T11:37:11Z", 
    "summary": "We study a generalized version of reversal bounded Turing machines where,\napart from several tapes on which the number of head reversals is bounded by\nr(n), there are several further tapes on which head reversals remain\nunrestricted, but size is bounded by s(n). Recently, such machines were\nintroduced as a formalization of a computation model that restricts random\naccess to external memory and internal memory space. Here, each of the tapes\nwith a restriction on the head reversals corresponds to an external memory\ndevice, and the tapes of restricted size model internal memory. We use\nST(r(n),s(n),O(1)) to denote the class of all problems that can be solved by\ndeterministic Turing machines that comply to the above resource bounds.\nSimilarly, NST and RST, respectively, are used for the corresponding\nnondeterministic and randomized classes.\n  While previous papers focused on lower bounds for particular problems,\nincluding sorting, the set equality problem, and several query evaluation\nproblems, the present paper addresses the relations between the (R,N)ST-classes\nand classical complexity classes and investigates the structural complexity of\nthe (R,N)ST-classes. Our main results are (1) a trade-off between internal\nmemory space and external memory head reversals, (2) correspondences between\nthe (R,N)ST-classes and ``classical'' time-bounded, space-bounded,\nreversal-bounded, and circuit complexity classes, and (3) hierarchies of\n(R)ST-classes in terms of increasing numbers of head reversals on external\nmemory tapes."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0608067v1", 
    "title": "On Polynomial Time Computable Numbers", 
    "arxiv-id": "cs/0608067v1", 
    "author": "Tetsushi Matsui", 
    "publish": "2006-08-16T15:26:08Z", 
    "summary": "It will be shown that the polynomial time computable numbers form a field,\nand especially an algebraically closed field."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0608074v4", 
    "title": "From Invariants to Canonization in Parallel", 
    "arxiv-id": "cs/0608074v4", 
    "author": "Oleg Verbitsky", 
    "publish": "2006-08-18T09:46:09Z", 
    "summary": "A function $f$ of a graph is called a complete graph invariant if the\nisomorphism of graphs $G$ and $H$ is equivalent to the equality $f(G)=f(H)$.\nIf, in addition, $f(G)$ is a graph isomorphic to $G$, then $f$ is called a\ncanonical form for graphs. Gurevich proves that graphs have a polynomial-time\ncomputable canonical form exactly when they have a polynomial-time computable\ncomplete invariant. We extend this equivalence to the polylogarithmic-time\nmodel of parallel computation for classes of graphs with bounded rigidity index\nand for classes of graphs with small separators. In particular, our results\napply to three representative classes of graphs embeddable into a fixed\nsurface, namely, to 5-connected graphs, to 3-connected graphs admitting a\npolyhedral embedding, and 3-connected graphs admitting a large-edge-width\nembedding. Another application covers graphs with bounded treewidth. Since in\nthe latter case an NC complete-invariant algorithm is known, we conclude that\ngraphs of bounded treewidth have a canonical form (and even a canonical\nlabeling) computable in NC."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0608106v3", 
    "title": "Lp Computable Functions and Fourier Series", 
    "arxiv-id": "cs/0608106v3", 
    "author": "Philippe Moser", 
    "publish": "2006-08-28T12:50:36Z", 
    "summary": "This paper studies how well computable functions can be approximated by their\nFourier series. To this end, we equip the space of Lp-computable functions\n(computable Lebesgue integrable functions) with a size notion, by introducing\nLp-computable Baire categories.\n  We show that Lp-computable Baire categories satisfy the following three basic\nproperties. Singleton sets {f} (where f is Lp-computable) are meager, suitable\ninfinite unions of meager sets are meager, and the whole space of Lp-computable\nfunctions is not meager. We give an alternative characterization of meager sets\nvia Banach Mazur games.\n  We study the convergence of Fourier series for Lp-computable functions and\nshow that whereas for every p>1, the Fourier series of every Lp-computable\nfunction f converges to f in the Lp norm, the set of L1-computable functions\nwhose Fourier series does not diverge almost everywhere is meager."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0609012v1", 
    "title": "Baire Categories on Small Complexity Classes and Meager-Comeager Laws", 
    "arxiv-id": "cs/0609012v1", 
    "author": "Philippe Moser", 
    "publish": "2006-09-05T09:02:11Z", 
    "summary": "We introduce two resource-bounded Baire category notions on small complexity\nclasses such as P, SUBEXP, and PSPACE and on probabilistic classes such as BPP,\nwhich differ on how the corresponding finite extension strategies are computed.\nWe give an alternative characterization of small sets via resource-bounded\nBanach-Mazur games.\n  As an application of the first notion, we show that for almost every language\nA (i.e. all except a meager class) computable in subexponential time,\nP(A)=BPP(A). We also show that almost all languages in PSPACE do not have small\nnonuniform complexity.\n  We then switch to the second Baire category notion (called\nlocally-computable), and show that the class SPARSE is meager in P. We show\nthat in contrast to the resource-bounded measure case, meager-comeager laws can\nbe obtained for many standard complexity classes, relative to\nlocally-computable Baire category on BPP and PSPACE.\n  Another topic where locally-computable Baire categories differ from\nresource-bounded measure is regarding weak-completeness: we show that there is\nno weak-completeness notion in P based on locally-computable Baire categories,\ni.e. every P-weakly-complete set is complete for P. We also prove that the\nclass of complete sets for P under Turing-logspace reductions is meager in P,\nif P is not equal to DSPACE(log n), and that the same holds unconditionally for\nquasi-poly time.\n  Finally we observe that locally-computable Baire categories are incomparable\nwith all existing resource-bounded measure notions on small complexity classes,\nwhich might explain why those two settings seem to differ so fundamentally."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0609072v2", 
    "title": "The Connectivity of Boolean Satisfiability: Computational and Structural   Dichotomies", 
    "arxiv-id": "cs/0609072v2", 
    "author": "Christos H. Papadimitriou", 
    "publish": "2006-09-13T07:25:59Z", 
    "summary": "Boolean satisfiability problems are an important benchmark for questions\nabout complexity, algorithms, heuristics and threshold phenomena. Recent work\non heuristics, and the satisfiability threshold has centered around the\nstructure and connectivity of the solution space. Motivated by this work, we\nstudy structural and connectivity-related properties of the space of solutions\nof Boolean satisfiability problems and establish various dichotomies in\nSchaefer's framework.\n  On the structural side, we obtain dichotomies for the kinds of subgraphs of\nthe hypercube that can be induced by the solutions of Boolean formulas, as well\nas for the diameter of the connected components of the solution space. On the\ncomputational side, we establish dichotomy theorems for the complexity of the\nconnectivity and st-connectivity questions for the graph of solutions of\nBoolean formulas. Our results assert that the intractable side of the\ncomputational dichotomies is PSPACE-complete, while the tractable side - which\nincludes but is not limited to all problems with polynomial time algorithms for\nsatisfiability - is in P for the st-connectivity question, and in coNP for the\nconnectivity question. The diameter of components can be exponential for the\nPSPACE-complete cases, whereas in all other cases it is linear; thus, small\ndiameter and tractability of the connectivity problems are remarkably aligned.\nThe crux of our results is an expressibility theorem showing that in the\ntractable cases, the subgraphs induced by the solution space possess certain\ngood structural properties, whereas in the intractable cases, the subgraphs can\nbe arbitrary."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0610009v2", 
    "title": "VPSPACE and a Transfer Theorem over the Reals", 
    "arxiv-id": "cs/0610009v2", 
    "author": "Sylvain Perifel", 
    "publish": "2006-10-03T13:48:44Z", 
    "summary": "We introduce a new class VPSPACE of families of polynomials. Roughly\nspeaking, a family of polynomials is in VPSPACE if its coefficients can be\ncomputed in polynomial space. Our main theorem is that if (uniform,\nconstant-free) VPSPACE families can be evaluated efficiently then the class PAR\nof decision problems that can be solved in parallel polynomial time over the\nreal numbers collapses to P. As a result, one must first be able to show that\nthere are VPSPACE families which are hard to evaluate in order to separate over\nthe reals P from NP, or even from PAR."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0611082v6", 
    "title": "The Computational Complexity of the Traveling Salesman Problem", 
    "arxiv-id": "cs/0611082v6", 
    "author": "Craig Alan Feinstein", 
    "publish": "2006-11-17T18:03:58Z", 
    "summary": "In this note, we show that the Traveling Salesman Problem cannot be solved in\npolynomial-time on a classical computer."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0611147v9", 
    "title": "P is not equal to NP", 
    "arxiv-id": "cs/0611147v9", 
    "author": "Raju Renjit. G", 
    "publish": "2006-11-29T08:27:00Z", 
    "summary": "This submission has been withdrawn at the request of the author."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0701004v4", 
    "title": "An algebraic approach to complexity of data stream computations", 
    "arxiv-id": "cs/0701004v4", 
    "author": "Sumit Ganguly", 
    "publish": "2007-01-02T18:12:52Z", 
    "summary": "We consider a basic problem in the general data streaming model, namely, to\nestimate a vector $f \\in \\Z^n$ that is arbitrarily updated (i.e., incremented\nor decremented) coordinate-wise. The estimate $\\hat{f} \\in \\Z^n$ must satisfy\n$\\norm{\\hat{f}-f}_{\\infty}\\le \\epsilon\\norm{f}_1 $, that is, $\\forall i\n~(\\abs{\\hat{f}_i - f_i} \\le \\epsilon \\norm{f}_1)$. It is known to have\n$\\tilde{O}(\\epsilon^{-1})$ randomized space upper bound \\cite{cm:jalgo},\n$\\Omega(\\epsilon^{-1} \\log (\\epsilon n))$ space lower bound\n\\cite{bkmt:sirocco03} and deterministic space upper bound of\n$\\tilde{\\Omega}(\\epsilon^{-2})$ bits.\\footnote{The $\\tilde{O}$ and\n$\\tilde{\\Omega}$ notations suppress poly-logarithmic factors in $n, \\log\n\\epsilon^{-1}, \\norm{f}_{\\infty}$ and $\\log \\delta^{-1}$, where, $\\delta$ is\nthe error probability (for randomized algorithm).} We show that any\ndeterministic algorithm for this problem requires space $\\Omega(\\epsilon^{-2}\n(\\log \\norm{f}_1))$ bits."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0701008v1", 
    "title": "On the Computational Complexity of Defining Sets", 
    "arxiv-id": "cs/0701008v1", 
    "author": "Hossein Maserrat", 
    "publish": "2006-12-31T05:47:37Z", 
    "summary": "Suppose we have a family ${\\cal F}$ of sets. For every $S \\in {\\cal F}$, a\nset $D \\subseteq S$ is a {\\sf defining set} for $({\\cal F},S)$ if $S$ is the\nonly element of $\\cal{F}$ that contains $D$ as a subset. This concept has been\nstudied in numerous cases, such as vertex colorings, perfect matchings,\ndominating sets, block designs, geodetics, orientations, and Latin squares.\n  In this paper, first, we propose the concept of a defining set of a logical\nformula, and we prove that the computational complexity of such a problem is\n$\\Sigma_2$-complete.\n  We also show that the computational complexity of the following problem about\nthe defining set of vertex colorings of graphs is $\\Sigma_2$-complete:\n  {\\sc Instance:} A graph $G$ with a vertex coloring $c$ and an integer $k$.\n  {\\sc Question:} If ${\\cal C}(G)$ be the set of all $\\chi(G)$-colorings of\n$G$, then does $({\\cal C}(G),c)$ have a defining set of size at most $k$?\n  Moreover, we study the computational complexity of some other variants of\nthis problem."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0701014v2", 
    "title": "A Reply to Hofman On: \"Why LP cannot solve large instances of   NP-complete problems in polynomial time\"", 
    "arxiv-id": "cs/0701014v2", 
    "author": "Moustapha Diaby", 
    "publish": "2007-01-03T11:26:26Z", 
    "summary": "Using an approach that seems to be patterned after that of Yannakakis, Hofman\nargues that an NP-complete problem cannot be formulated as a polynomial\nbounded-sized linear programming problem. He then goes on to propose a\n\"construct\" that he claims to be a counter-example to recently published linear\nprogramming formulations of the Traveling Salesman Problem (TSP) and the\nQuadratic Assignment Problems (QAP), respectively. In this paper, we show that\nHofman's construct is flawed, and provide further proof that his\n\"counter-example\" is invalid."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0701033v1", 
    "title": "A Counterexample to a Proposed Proof of P=NP by S. Gubin", 
    "arxiv-id": "cs/0701033v1", 
    "author": "Blake Hegerle", 
    "publish": "2007-01-05T19:16:46Z", 
    "summary": "In a recent paper by S. Gubin [cs/0701023v1], a polynomial-time solution to\nthe 3SAT problem was presented as proof that P=NP. The proposed algorithm\ncannot be made to work, which I shall demonstrate."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0701049v2", 
    "title": "On the Complexity of a Derivative Chess Problem", 
    "arxiv-id": "cs/0701049v2", 
    "author": "Barnaby Martin", 
    "publish": "2007-01-08T16:45:55Z", 
    "summary": "We introduce QUEENS, a derivative chess problem based on the classical\nn-queens problem. We prove that QUEENS is NP-complete, with respect to\npolynomial-time reductions."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0701128v1", 
    "title": "Interference Automata", 
    "arxiv-id": "cs/0701128v1", 
    "author": "M. V. Panduranga Rao", 
    "publish": "2007-01-22T09:14:11Z", 
    "summary": "We propose a computing model, the Two-Way Optical Interference Automata\n(2OIA), that makes use of the phenomenon of optical interference. We introduce\nthis model to investigate the increase in power, in terms of language\nrecognition, of a classical Deterministic Finite Automaton (DFA) when endowed\nwith the facility of optical interference. The question is in the spirit of\nTwo-Way Finite Automata With Quantum and Classical States (2QCFA) [A. Ambainis\nand J. Watrous, Two-way Finite Automata With Quantum and Classical States,\nTheoretical Computer Science, 287 (1), 299-311, (2002)] wherein the classical\nDFA is augmented with a quantum component of constant size. We test the power\nof 2OIA against the languages mentioned in the above paper. We give efficient\n2OIA algorithms to recognize languages for which 2QCFA machines have been shown\nto exist, as well as languages whose status vis-a-vis 2QCFA has been posed as\nopen questions. Finally we show the existence of a language that cannot be\nrecognized by a 2OIA but can be recognized by an $O(n^3)$ space Turing machine."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0702047v1", 
    "title": "Hierarchical Unambiguity", 
    "arxiv-id": "cs/0702047v1", 
    "author": "Rahul Tripathi", 
    "publish": "2007-02-08T16:00:25Z", 
    "summary": "We develop techniques to investigate relativized hierarchical unambiguous\ncomputation. We apply our techniques to generalize known constructs involving\nrelativized unambiguity based complexity classes (UP and \\mathcal{UP}) to new\nconstructs involving arbitrary higher levels of the relativized unambiguous\npolynomial hierarchy (UPH). Our techniques are developed on constraints imposed\nby hierarchical arrangement of unambiguous nondeterministic polynomial-time\nTuring machines, and so they differ substantially, in applicability and in\nnature, from standard methods (such as the switching lemma [Hastad,\nComputational Limitations of Small-Depth Circuits, MIT Press, 1987]), which\nplay roles in carrying out similar generalizations.\n  Aside from achieving these generalizations, we resolve a question posed by\nCai, Hemachandra, and Vyskoc [J. Cai, L. Hemachandra, and J. Vyskoc, Promises\nand fault-tolerant database access, In K. Ambos-Spies, S. Homer, and U.\nSchoening, editors, Complexity Theory, pages 101-146. Cambridge University\nPress, 1993] on an issue related to nonadaptive Turing access to UP and\nadaptive smart Turing access to \\mathcal{UP}."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0702053v1", 
    "title": "The DFAs of Finitely Different Languages", 
    "arxiv-id": "cs/0702053v1", 
    "author": "Ian Shipman", 
    "publish": "2007-02-09T03:42:51Z", 
    "summary": "Two languages are \"finitely different\" if their symmetric difference is\nfinite. We consider the DFAs of finitely different regular languages and find\nmajor structural similarities. We proceed to consider the smallest DFAs that\nrecognize a language finitely different from some given DFA. Such \"f-minimal\"\nDFAs are not unique, and this non-uniqueness is characterized. Finally, we\noffer a solution to the minimization problem of finding such f-minimal DFAs."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0702058v1", 
    "title": "Exploring k-Colorability", 
    "arxiv-id": "cs/0702058v1", 
    "author": "Kia Kai Li", 
    "publish": "2007-02-09T23:07:30Z", 
    "summary": "An introductory paper to the graph k-colorability problem."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0702133v1", 
    "title": "Fast Exact Method for Solving the Travelling Salesman Problem", 
    "arxiv-id": "cs/0702133v1", 
    "author": "Vadim Yatsenko", 
    "publish": "2007-02-23T02:39:05Z", 
    "summary": "This paper describes TSP exact solution of polynomial complexity. It is\nconsidered properties of proposed method. Effectiveness of proposed solution is\nillustrated by outcomes of computer modeling."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0702160v1", 
    "title": "A Quantifier-Free String Theory for ALOGTIME Reasoning", 
    "arxiv-id": "cs/0702160v1", 
    "author": "Fran\u00e7ois Pitt", 
    "publish": "2007-02-28T02:59:36Z", 
    "summary": "The main contribution of this work is the definition of a quantifier-free\nstring theory T_1 suitable for formalizing ALOGTIME reasoning. After describing\nL_1 -- a new, simple, algebraic characterization of the complexity class\nALOGTIME based on strings instead of numbers -- the theory T_1 is defined\n(based on L_1), and a detailed formal development of T_1 is given.\n  Then, theorems of T_1 are shown to translate into families of propositional\ntautologies that have uniform polysize Frege proofs, T_1 is shown to prove the\nsoundness of a particular Frege system F, and F is shown to provably p-simulate\nany proof system whose soundness can be proved in T_1. Finally, T_1 is compared\nwith other theories for ALOGTIME reasoning in the literature.\n  To our knowledge, this is the first formal theory for ALOGTIME reasoning\nwhose basic objects are strings instead of numbers, and the first\nquantifier-free theory formalizing ALOGTIME reasoning in which a direct proof\nof the soundness of some Frege system has been given (in the case of\nfirst-order theories, such a proof was first given by Arai for his theory AID).\nAlso, the polysize Frege proofs we give for the propositional translations of\ntheorems of T_1 are considerably simpler than those for other theories, and so\nis our proof of the soundness of a particular F-system in T_1. Together with\nthe simplicity of T_1's recursion schemes, axioms, and rules these facts\nsuggest that T_1 is one of the most natural theories available for ALOGTIME\nreasoning."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0703085v1", 
    "title": "Dimension and Relative Frequencies", 
    "arxiv-id": "cs/0703085v1", 
    "author": "Jack H. Lutz", 
    "publish": "2007-03-16T02:42:53Z", 
    "summary": "We show how to calculate the finite-state dimension (equivalently, the\nfinite-state compressibility) of a saturated sets $X$ consisting of {\\em all}\ninfinite sequences $S$ over a finite alphabet $\\Sigma_m$ satisfying some given\ncondition $P$ on the asymptotic frequencies with which various symbols from\n$\\Sigma_m$ appear in $S$. When the condition $P$ completely specifies an\nempirical probability distribution $\\pi$ over $\\Sigma_m$, i.e., a limiting\nfrequency of occurrence for {\\em every} symbol in $\\Sigma_m$, it has been known\nsince 1949 that the Hausdorff dimension of $X$ is precisely $\\CH(\\pi)$, the\nShannon entropy of $\\pi$, and the finite-state dimension was proven to have\nthis same value in 2001.\n  The saturated sets were studied by Volkmann and Cajar decades ago. It got\nattention again only with the recent developments in multifractal analysis by\nBarreira, Saussol, Schmeling, and separately Olsen. However, the powerful\nmethods they used -- ergodic theory and multifractal analysis -- do not yield a\nvalue for the finite-state (or even computable) dimension in an obvious manner.\n  We give a pointwise characterization of finite-state dimensions of saturated\nsets. Simultaneously, we also show that their finite-state dimension and strong\ndimension coincide with their Hausdorff and packing dimension respectively,\nthough the techniques we use are completely elementary. Our results\nautomatically extend to less restrictive effective settings (e.g.,\nconstructive, computable, and polynomial-time dimensions)."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/cs/0703110v4", 
    "title": "Geometric Complexity Theory IV: nonstandard quantum group for the   Kronecker problem", 
    "arxiv-id": "cs/0703110v4", 
    "author": "Milind Sohoni", 
    "publish": "2007-03-22T15:35:29Z", 
    "summary": "The Kronecker coefficient g_{\\lambda \\mu \\nu} is the multiplicity of the\nGL(V)\\times GL(W)-irreducible V_\\lambda \\otimes W_\\mu in the restriction of the\nGL(X)-irreducible X_\\nu via the natural map GL(V)\\times GL(W) \\to GL(V \\otimes\nW), where V, W are \\mathbb{C}-vector spaces and X = V \\otimes W. A fundamental\nopen problem in algebraic combinatorics is to find a positive combinatorial\nformula for these coefficients.\n  We construct two quantum objects for this problem, which we call the\nnonstandard quantum group and nonstandard Hecke algebra. We show that the\nnonstandard quantum group has a compact real form and its representations are\ncompletely reducible, that the nonstandard Hecke algebra is semisimple, and\nthat they satisfy an analog of quantum Schur-Weyl duality.\n  Using these nonstandard objects as a guide, we follow the approach of Adsul,\nSohoni, and Subrahmanyam to construct, in the case dim(V) = dim(W) =2, a\nrepresentation \\check{X}_\\nu of the nonstandard quantum group that specializes\nto Res_{GL(V) \\times GL(W)} X_\\nu at q=1. We then define a global crystal basis\n+HNSTC(\\nu) of \\check{X}_\\nu that solves the two-row Kronecker problem: the\nnumber of highest weight elements of +HNSTC(\\nu) of weight (\\lambda,\\mu) is the\nKronecker coefficient g_{\\lambda \\mu \\nu}. We go on to develop the beginnings\nof a graphical calculus for this basis, along the lines of the U_q(\\sl_2)\ngraphical calculus, and use this to organize the crystal components of\n+HNSTC(\\nu) into eight families. This yields a fairly simple, explicit and\npositive formula for two-row Kronecker coefficients, generalizing a formula of\nBrown, van Willigenburg, and Zabrocki. As a byproduct of the approach, we also\nobtain a rule for the decomposition of Res_{GL_2 \\times GL_2 \\rtimes \\S_2}\nX_\\nu into irreducibles."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/0704.0108v1", 
    "title": "Reducing SAT to 2-SAT", 
    "arxiv-id": "0704.0108v1", 
    "author": "Sergey Gubin", 
    "publish": "2007-04-01T23:16:27Z", 
    "summary": "Description of a polynomial time reduction of SAT to 2-SAT of polynomial\nsize."
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/0704.0213v2", 
    "title": "Geometric Complexity Theory V: On deciding nonvanishing of a generalized   Littlewood-Richardson coefficient", 
    "arxiv-id": "0704.0213v2", 
    "author": "Ketan D. Mulmuley Hariharan Narayanan", 
    "publish": "2007-04-02T15:13:27Z", 
    "summary": "This article has been withdrawn because it has been merged with the earlier\narticle GCT3 (arXiv: CS/0501076 [cs.CC]) in the series. The merged article is\nnow available as:\n  Geometric Complexity Theory III: on deciding nonvanishing of a\nLittlewood-Richardson Coefficient, Journal of Algebraic Combinatorics, vol. 36,\nissue 1, 2012, pp. 103-110. (Authors: Ketan Mulmuley, Hari Narayanan and Milind\nSohoni)\n  The new article in this GCT5 slot in the series is:\n  Geometric Complexity Theory V: Equivalence between blackbox derandomization\nof polynomial identity testing and derandomization of Noether's Normalization\nLemma, in the Proceedings of FOCS 2012 (abstract), arXiv:1209.5993 [cs.CC]\n(full version) (Author: Ketan Mulmuley)"
},{
    "category": "cs.CC", 
    "doi": "10.1137/S0097539704446712", 
    "link": "http://arxiv.org/pdf/0704.0229v4", 
    "title": "Geometric Complexity Theory VI: the flip via saturated and positive   integer programming in representation theory and algebraic geometry", 
    "arxiv-id": "0704.0229v4", 
    "author": "Ketan D. Mulmuley", 
    "publish": "2007-04-02T16:41:38Z", 
    "summary": "This article belongs to a series on geometric complexity theory (GCT), an\napproach to the P vs. NP and related problems through algebraic geometry and\nrepresentation theory. The basic principle behind this approach is called the\nflip. In essence, it reduces the negative hypothesis in complexity theory (the\nlower bound problems), such as the P vs. NP problem in characteristic zero, to\nthe positive hypothesis in complexity theory (the upper bound problems):\nspecifically, to showing that the problems of deciding nonvanishing of the\nfundamental structural constants in representation theory and algebraic\ngeometry, such as the well known plethysm constants--or rather certain relaxed\nforms of these decision probelms--belong to the complexity class P. In this\narticle, we suggest a plan for implementing the flip, i.e., for showing that\nthese relaxed decision problems belong to P. This is based on the reduction of\nthe preceding complexity-theoretic positive hypotheses to mathematical\npositivity hypotheses: specifically, to showing that there exist positive\nformulae--i.e. formulae with nonnegative coefficients--for the structural\nconstants under consideration and certain functions associated with them. These\nturn out be intimately related to the similar positivity properties of the\nKazhdan-Lusztig polynomials and the multiplicative structural constants of the\ncanonical (global crystal) bases in the theory of Drinfeld-Jimbo quantum\ngroups. The known proofs of these positivity properties depend on the Riemann\nhypothesis over finite fields and the related results. Thus the reduction here,\nin conjunction with the flip, in essence, says that the validity of the P vs.\nNP conjecture in characteristic zero is intimately linked to the Riemann\nhypothesis over finite fields and related problems."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0704.0301v1", 
    "title": "Differential Recursion and Differentially Algebraic Functions", 
    "arxiv-id": "0704.0301v1", 
    "author": "Akitoshi Kawamura", 
    "publish": "2007-04-03T19:50:14Z", 
    "summary": "Moore introduced a class of real-valued \"recursive\" functions by analogy with\nKleene's formulation of the standard recursive functions. While his concise\ndefinition inspired a new line of research on analog computation, it contains\nsome technical inaccuracies. Focusing on his \"primitive recursive\" functions,\nwe pin down what is problematic and discuss possible attempts to remove the\nambiguity regarding the behavior of the differential recursion operator on\npartial functions. It turns out that in any case the purported relation to\ndifferentially algebraic functions, and hence to Shannon's model of analog\ncomputation, fails."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0705.0915v2", 
    "title": "Satisfiability Parsimoniously Reduces to the Tantrix(TM) Rotation Puzzle   Problem", 
    "arxiv-id": "0705.0915v2", 
    "author": "Joerg Rothe", 
    "publish": "2007-05-07T14:23:20Z", 
    "summary": "Holzer and Holzer (Discrete Applied Mathematics 144(3):345--358, 2004) proved\nthat the Tantrix(TM) rotation puzzle problem is NP-complete. They also showed\nthat for infinite rotation puzzles, this problem becomes undecidable. We study\nthe counting version and the unique version of this problem. We prove that the\nsatisfiability problem parsimoniously reduces to the Tantrix(TM) rotation\npuzzle problem. In particular, this reduction preserves the uniqueness of the\nsolution, which implies that the unique Tantrix(TM) rotation puzzle problem is\nas hard as the unique satisfiability problem, and so is DP-complete under\npolynomial-time randomized reductions, where DP is the second level of the\nboolean hierarchy over NP."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0705.1442v2", 
    "title": "Does P=NP?", 
    "arxiv-id": "0705.1442v2", 
    "author": "Karlen Garnik Gharibyan", 
    "publish": "2007-05-10T11:41:26Z", 
    "summary": "This paper has been withdrawn Abstract: This paper has been withdrawn by the\nauthor due to the publication."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0706.1477v1", 
    "title": "VPSPACE and a transfer theorem over the complex field", 
    "arxiv-id": "0706.1477v1", 
    "author": "Sylvain Perifel", 
    "publish": "2007-06-11T13:59:31Z", 
    "summary": "We extend the transfer theorem of [KP2007] to the complex field. That is, we\ninvestigate the links between the class VPSPACE of families of polynomials and\nthe Blum-Shub-Smale model of computation over C. Roughly speaking, a family of\npolynomials is in VPSPACE if its coefficients can be computed in polynomial\nspace. Our main result is that if (uniform, constant-free) VPSPACE families can\nbe evaluated efficiently then the class PAR of decision problems that can be\nsolved in parallel polynomial time over the complex field collapses to P. As a\nresult, one must first be able to show that there are VPSPACE families which\nare hard to evaluate in order to separate P from NP over C, or even from PAR."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0706.2035v1", 
    "title": "Critique of Feinstein's Proof that P is not Equal to NP", 
    "arxiv-id": "0706.2035v1", 
    "author": "Michael Silverman", 
    "publish": "2007-06-14T13:15:39Z", 
    "summary": "We examine a proof by Craig Alan Feinstein that P is not equal to NP. We\npresent counterexamples to claims made in his paper and expose a flaw in the\nmethodology he uses to make his assertions. The fault in his argument is the\nincorrect use of reduction. Feinstein makes incorrect assumptions about the\ncomplexity of a problem based on the fact that there is a more complex problem\nthat can be used to solve it. His paper introduces the terminology \"imaginary\nprocessor\" to describe how it is possible to beat the brute force reduction he\noffers to solve the Subset-Sum problem. The claims made in the paper would not\nbe validly established even were imaginary processors to exist."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0706.3412v1", 
    "title": "On Canonical Forms of Complete Problems via First-order Projections", 
    "arxiv-id": "0706.3412v1", 
    "author": "Blai Bonet", 
    "publish": "2007-06-22T21:27:06Z", 
    "summary": "The class of problems complete for NP via first-order reductions is known to\nbe characterized by existential second-order sentences of a fixed form. All\nsuch sentences are built around the so-called generalized IS-form of the\nsentence that defines Independent-Set. This result can also be understood as\nthat every sentence that defines a NP-complete problem P can be decomposed in\ntwo disjuncts such that the first one characterizes a fragment of P as hard as\nIndependent-Set and the second the rest of P. That is, a decomposition that\ndivides every such sentence into a quotient and residue modulo Independent-Set.\n  In this paper, we show that this result can be generalized over a wide\ncollection of complexity classes, including the so-called nice classes.\nMoreover, we show that such decomposition can be done for any complete problem\nwith respect to the given class, and that two such decompositions are\nnon-equivalent in general. Interestingly, our results are based on simple and\nwell-known properties of first-order reductions.ow that this result can be\ngeneralized over a wide collection of complexity classes, including the\nso-called nice classes. Moreover, we show that such decomposition can be done\nfor any complete problem with respect to the given class, and that two such\ndecompositions are non-equivalent in general. Interestingly, our results are\nbased on simple and well-known properties of first-order reductions."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0707.0430v1", 
    "title": "Assisted Problem Solving and Decompositions of Finite Automata", 
    "arxiv-id": "0707.0430v1", 
    "author": "Branislav Rovan", 
    "publish": "2007-07-03T14:54:53Z", 
    "summary": "A study of assisted problem solving formalized via decompositions of\ndeterministic finite automata is initiated. The landscape of new types of\ndecompositions of finite automata this study uncovered is presented. Languages\nwith various degrees of decomposability between undecomposable and perfectly\ndecomposable are shown to exist."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0707.1364v1", 
    "title": "Report on Generic Case Complexity", 
    "arxiv-id": "0707.1364v1", 
    "author": "Alexander Ushakov", 
    "publish": "2007-07-10T18:57:08Z", 
    "summary": "This article is a short introduction to generic case complexity, which is a\nrecently developed way of measuring the difficulty of a computational problem\nwhile ignoring atypical behavior on a small set of inputs. Generic case\ncomplexity applies to both recursively solvable and recursively unsolvable\nproblems."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0707.4489v1", 
    "title": "Small weakly universal Turing machines", 
    "arxiv-id": "0707.4489v1", 
    "author": "Damien Woods", 
    "publish": "2007-07-30T21:40:55Z", 
    "summary": "We give small universal Turing machines with state-symbol pairs of (6, 2),\n(3, 3) and (2, 4). These machines are weakly universal, which means that they\nhave an infinitely repeated word to the left of their input and another to the\nright. They simulate Rule 110 and are currently the smallest known weakly\nuniversal Turing machines."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0708.2105v1", 
    "title": "Attribute Estimation and Testing Quasi-Symmetry", 
    "arxiv-id": "0708.2105v1", 
    "author": "Nicholas Pippenger", 
    "publish": "2007-08-15T20:56:22Z", 
    "summary": "A Boolean function is symmetric if it is invariant under all permutations of\nits arguments; it is quasi-symmetric if it is symmetric with respect to the\narguments on which it actually depends. We present a test that accepts every\nquasi-symmetric function and, except with an error probability at most delta>0,\nrejects every function that differs from every quasi-symmetric function on at\nleast a fraction epsilon>0 of the inputs. For a function of n arguments, the\ntest probes the function at O((n/epsilon)\\log(n/delta)) inputs. Our\nquasi-symmetry test acquires information concerning the arguments on which the\nfunction actually depends. To do this, it employs a generalization of the\nproperty testing paradigm that we call attribute estimation. Like property\ntesting, attribute estimation uses random sampling to obtain results that have\nonly \"one-sided'' errors and that are close to accurate with high probability."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0708.3568v1", 
    "title": "A Polynomial-time Algorithm for Computing the Permanent in GF(3^q)", 
    "arxiv-id": "0708.3568v1", 
    "author": "Vadim Tarin", 
    "publish": "2007-08-27T15:47:49Z", 
    "summary": "A polynomial-time algorithm for computing the permanent in any field of\ncharacteristic 3 is presented in this article. The principal objects utilized\nfor that purpose are the Cauchy and Vandermonde matrices, the discriminant\nfunction and their generalizations of various types. Classical theorems on the\npermanent such as the Binet-Minc identity and Borchadt's formula are widely\napplied, while a special new technique involving the notion of limit re-defined\nfor fields of finite characteristics and corresponding computational methods\nwas developed in order to deal with a number of polynomial-time reductions. All\nthe constructions preserve a strictly algebraic nature ignoring the structure\nof the basic field, while applying its infinite extensions for calculating\nlimits.\n  A natural corollary of the polynomial-time computability of the permanent in\na field of a characteristic different from 2 is the non-uniform equality\nbetween the complexity classes P and NP what is equivalent to RP=NP (Ref. [1])."
},{
    "category": "cs.CC", 
    "doi": "10.1145/1507244.1507252", 
    "link": "http://arxiv.org/pdf/0708.4075v1", 
    "title": "Graph Isomorphism is PSPACE-complete", 
    "arxiv-id": "0708.4075v1", 
    "author": "Matthew Delacorte", 
    "publish": "2007-08-30T05:06:39Z", 
    "summary": "Combining the the results of A.R. Meyer and L.J. Stockmeyer \"The Equivalence\nProblem for Regular Expressions with Squaring Requires Exponential Space\", and\nK.S. Booth \"Isomorphism testing for graphs, semigroups, and finite automata are\npolynomiamlly equivalent problems\" shows that graph isomorphism is\nPSPACE-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-6596/95/1/012013", 
    "link": "http://arxiv.org/pdf/0709.0367v2", 
    "title": "Relationship between clustering and algorithmic phase transitions in the   random k-XORSAT model and its NP-complete extensions", 
    "arxiv-id": "0709.0367v2", 
    "author": "Francesco Zamponi", 
    "publish": "2007-09-04T08:56:27Z", 
    "summary": "We study the performances of stochastic heuristic search algorithms on\nUniquely Extendible Constraint Satisfaction Problems with random inputs. We\nshow that, for any heuristic preserving the Poissonian nature of the underlying\ninstance, the (heuristic-dependent) largest ratio $\\alpha_a$ of constraints per\nvariables for which a search algorithm is likely to find solutions is smaller\nthan the critical ratio $\\alpha_d$ above which solutions are clustered and\nhighly correlated. In addition we show that the clustering ratio can be reached\nwhen the number k of variables per constraints goes to infinity by the\nso-called Generalized Unit Clause heuristic."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-6596/95/1/012013", 
    "link": "http://arxiv.org/pdf/0709.0746v1", 
    "title": "Geometric Complexity Theory: Introduction", 
    "arxiv-id": "0709.0746v1", 
    "author": "Milind Sohoni", 
    "publish": "2007-09-05T21:54:52Z", 
    "summary": "These are lectures notes for the introductory graduate courses on geometric\ncomplexity theory (GCT) in the computer science department, the university of\nChicago. Part I consists of the lecture notes for the course given by the first\nauthor in the spring quarter, 2007. It gives introduction to the basic\nstructure of GCT. Part II consists of the lecture notes for the course given by\nthe second author in the spring quarter, 2003. It gives introduction to\ninvariant theory with a view towards GCT. No background in algebraic geometry\nor representation theory is assumed. These lecture notes in conjunction with\nthe article \\cite{GCTflip1}, which describes in detail the basic plan of GCT\nbased on the principle called the flip, should provide a high level picture of\nGCT assuming familiarity with only basic notions of algebra, such as groups,\nrings, fields etc."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-6596/95/1/012013", 
    "link": "http://arxiv.org/pdf/0709.0748v1", 
    "title": "On P vs. NP, Geometric Complexity Theory, and the Flip I: a high level   view", 
    "arxiv-id": "0709.0748v1", 
    "author": "Ketan D. Mulmuley", 
    "publish": "2007-09-05T22:10:31Z", 
    "summary": "Geometric complexity theory (GCT) is an approach to the $P$ vs. $NP$ and\nrelated problems through algebraic geometry and representation theory. This\narticle gives a high-level exposition of the basic plan of GCT based on the\nprinciple, called the flip, without assuming any background in algebraic\ngeometry or representation theory."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-6596/95/1/012013", 
    "link": "http://arxiv.org/pdf/0709.0749v2", 
    "title": "Geometric Complexity Theory VII: Nonstandard quantum group for the   plethysm problem", 
    "arxiv-id": "0709.0749v2", 
    "author": "Ketan D. Mulmuley", 
    "publish": "2007-09-05T22:23:15Z", 
    "summary": "This article describes a {\\em nonstandard} quantum group that may be used to\nderive a positive formula for the plethysm problem, just as the standard\n(Drinfeld-Jimbo) quantum group can be used to derive the positive\nLittlewood-Richardson rule for arbitrary complex semisimple Lie groups. The\nsequel \\cite{GCT8} gives conjecturally correct algorithms to construct\ncanonical bases of the coordinate rings of these nonstandard quantum groups and\ncanonical bases of the dually paired nonstandard deformations of the symmetric\ngroup algebra. A positive $#P$-formula for the plethysm constant follows from\nthe conjectural properties of these canonical bases and the duality and\nreciprocity conjectures herein."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-6596/95/1/012013", 
    "link": "http://arxiv.org/pdf/0709.0751v2", 
    "title": "Geometric Complexity Theory VIII: On canonical bases for the nonstandard   quantum groups", 
    "arxiv-id": "0709.0751v2", 
    "author": "Ketan D. Mulmuley", 
    "publish": "2007-09-05T22:30:50Z", 
    "summary": "This article gives conjecturally correct algorithms to construct canonical\nbases of the irreducible polynomial representations and the matrix coordinate\nrings of the nonstandard quantum groups in GCT4 and GCT7, and canonical bases\nof the dually paired nonstandard deformations of the symmetric group algebra\ntherein. These are generalizations of the canonical bases of the irreducible\npolynomial representations and the matrix coordinate ring of the standard\nquantum group, as constructed by Kashiwara and Lusztig, and the Kazhdan-Lusztig\nbasis of the Hecke algebra. A positive ($#P$-) formula for the well-known\nplethysm constants follows from their conjectural properties and the duality\nand reciprocity conjectures in \\cite{GCT7}."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-6596/95/1/012013", 
    "link": "http://arxiv.org/pdf/0709.1207v3", 
    "title": "The P versus NP Brief", 
    "arxiv-id": "0709.1207v3", 
    "author": "Mikael Franzen", 
    "publish": "2007-09-08T12:45:51Z", 
    "summary": "This paper discusses why P and NP are likely to be different. It analyses the\nessence of the concepts and points out that P and NP might be diverse by sheer\ndefinition. It also speculates that P and NP may be unequal due to natural\nlaws."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0709.4117v1", 
    "title": "Deciding Unambiguity and Sequentiality starting from a Finitely   Ambiguous Max-Plus Automaton", 
    "arxiv-id": "0709.4117v1", 
    "author": "Christophe Prieur", 
    "publish": "2007-09-26T09:51:28Z", 
    "summary": "Finite automata with weights in the max-plus semiring are considered. The\nmain result is: it is decidable in an effective way whether a series that is\nrecognized by a finitely ambiguous max-plus automaton is unambiguous, or is\nsequential. A collection of examples is given to illustrate the hierarchy of\nmax-plus series with respect to ambiguity."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0710.0360v1", 
    "title": "Interpolation in Valiant's theory", 
    "arxiv-id": "0710.0360v1", 
    "author": "Sylvain Perifel", 
    "publish": "2007-10-01T18:58:19Z", 
    "summary": "We investigate the following question: if a polynomial can be evaluated at\nrational points by a polynomial-time boolean algorithm, does it have a\npolynomial-size arithmetic circuit? We argue that this question is certainly\ndifficult. Answering it negatively would indeed imply that the constant-free\nversions of the algebraic complexity classes VP and VNP defined by Valiant are\ndifferent. Answering this question positively would imply a transfer theorem\nfrom boolean to algebraic complexity. Our proof method relies on Lagrange\ninterpolation and on recent results connecting the (boolean) counting hierarchy\nto algebraic complexity classes. As a byproduct we obtain two additional\nresults: (i) The constant-free, degree-unbounded version of Valiant's\nhypothesis that VP and VNP differ implies the degree-bounded version. This\nresult was previously known to hold for fields of positive characteristic only.\n(ii) If exponential sums of easy to compute polynomials can be computed\nefficiently, then the same is true of exponential products. We point out an\napplication of this result to the P=NP problem in the Blum-Shub-Smale model of\ncomputation over the field of complex numbers."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0710.0805v3", 
    "title": "On the Satisfiability Threshold and Clustering of Solutions of Random   3-SAT Formulas", 
    "arxiv-id": "0710.0805v3", 
    "author": "Alistair Sinclair", 
    "publish": "2007-10-03T19:04:44Z", 
    "summary": "We study the structure of satisfying assignments of a random 3-SAT formula.\nIn particular, we show that a random formula of density 4.453 or higher almost\nsurely has no non-trivial \"core\" assignments. Core assignments are certain\npartial assignments that can be extended to satisfying assignments, and have\nbeen studied recently in connection with the Survey Propagation heuristic for\nrandom SAT. Their existence implies the presence of clusters of solutions, and\nthey have been shown to exist with high probability below the satisfiability\nthreshold for k-SAT with k>8, by Achlioptas and Ricci-Tersenghi, STOC 2006. Our\nresult implies that either this does not hold for 3-SAT or the threshold\ndensity for satisfiability in 3-SAT lies below 4.453.\n  The main technical tool that we use is a novel simple application of the\nfirst moment method."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0710.2732v1", 
    "title": "Probabilistic communication complexity over the reals", 
    "arxiv-id": "0710.2732v1", 
    "author": "Dima Grigoriev", 
    "publish": "2007-10-15T08:03:38Z", 
    "summary": "Deterministic and probabilistic communication protocols are introduced in\nwhich parties can exchange the values of polynomials (rather than bits in the\nusual setting). It is established a sharp lower bound $2n$ on the communication\ncomplexity of recognizing the $2n$-dimensional orthant, on the other hand the\nprobabilistic communication complexity of its recognizing does not exceed 4. A\npolyhedron and a union of hyperplanes are constructed in $\\RR^{2n}$ for which a\nlower bound $n/2$ on the probabilistic communication complexity of recognizing\neach is proved. As a consequence this bound holds also for the EMPTINESS and\nthe KNAPSACK problems."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0710.3519v1", 
    "title": "P-matrix recognition is co-NP-complete", 
    "arxiv-id": "0710.3519v1", 
    "author": "Jan Foniok", 
    "publish": "2007-10-18T14:14:26Z", 
    "summary": "This is a summary of the proof by G.E. Coxson that P-matrix recognition is\nco-NP-complete. The result follows by a reduction from the MAX CUT problem\nusing results of S. Poljak and J. Rohn."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0710.3961v1", 
    "title": "On a New Type of Information Processing for Efficient Management of   Complex Systems", 
    "arxiv-id": "0710.3961v1", 
    "author": "Galina Korotkikh", 
    "publish": "2007-10-22T01:10:02Z", 
    "summary": "It is a challenge to manage complex systems efficiently without confronting\nNP-hard problems. To address the situation we suggest to use self-organization\nprocesses of prime integer relations for information processing.\nSelf-organization processes of prime integer relations define correlation\nstructures of a complex system and can be equivalently represented by\ntransformations of two-dimensional geometrical patterns determining the\ndynamics of the system and revealing its structural complexity. Computational\nexperiments raise the possibility of an optimality condition of complex systems\npresenting the structural complexity of a system as a key to its optimization.\n  From this perspective the optimization of a system could be all about the\ncontrol of the structural complexity of the system to make it consistent with\nthe structural complexity of the problem. The experiments also indicate that\nthe performance of a complex system may behave as a concave function of the\nstructural complexity. Therefore, once the structural complexity could be\ncontrolled as a single entity, the optimization of a complex system would be\npotentially reduced to a one-dimensional concave optimization irrespective of\nthe number of variables involved its description. This might open a way to a\nnew type of information processing for efficient management of complex systems."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0710.4272v2", 
    "title": "An approximation trichotomy for Boolean #CSP", 
    "arxiv-id": "0710.4272v2", 
    "author": "Mark Jerrum", 
    "publish": "2007-10-23T14:35:05Z", 
    "summary": "We give a trichotomy theorem for the complexity of approximately counting the\nnumber of satisfying assignments of a Boolean CSP instance. Such problems are\nparameterised by a constraint language specifying the relations that may be\nused in constraints. If every relation in the constraint language is affine\nthen the number of satisfying assignments can be exactly counted in polynomial\ntime. Otherwise, if every relation in the constraint language is in the\nco-clone IM_2 from Post's lattice, then the problem of counting satisfying\nassignments is complete with respect to approximation-preserving reductions in\nthe complexity class #RH\\Pi_1. This means that the problem of approximately\ncounting satisfying assignments of such a CSP instance is equivalent in\ncomplexity to several other known counting problems, including the problem of\napproximately counting the number of independent sets in a bipartite graph. For\nevery other fixed constraint language, the problem is complete for #P with\nrespect to approximation-preserving reductions, meaning that there is no fully\npolynomial randomised approximation scheme for counting satisfying assignments\nunless NP=RP."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0711.1827v3", 
    "title": "The Three-Color and Two-Color Tantrix(TM) Rotation Puzzle Problems are   NP-Complete via Parsimonious Reductions", 
    "arxiv-id": "0711.1827v3", 
    "author": "Joerg Rothe", 
    "publish": "2007-11-12T17:44:45Z", 
    "summary": "Holzer and Holzer (Discrete Applied Mathematics 144(3):345--358, 2004) proved\nthat the Tantrix(TM) rotation puzzle problem with four colors is NP-complete,\nand they showed that the infinite variant of this problem is undecidable. In\nthis paper, we study the three-color and two-color Tantrix(TM) rotation puzzle\nproblems (3-TRP and 2-TRP) and their variants. Restricting the number of\nallowed colors to three (respectively, to two) reduces the set of available\nTantrix(TM) tiles from 56 to 14 (respectively, to 8). We prove that 3-TRP and\n2-TRP are NP-complete, which answers a question raised by Holzer and Holzer in\nthe affirmative. Since our reductions are parsimonious, it follows that the\nproblems Unique-3-TRP and Unique-2-TRP are DP-complete under randomized\nreductions. We also show that the another-solution problems associated with\n4-TRP, 3-TRP, and 2-TRP are NP-complete. Finally, we prove that the infinite\nvariants of 3-TRP and 2-TRP are undecidable."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0711.2010v4", 
    "title": "A Polynomial Time Algorithm for Graph Isomorphism", 
    "arxiv-id": "0711.2010v4", 
    "author": "Reiner Czerwinski", 
    "publish": "2007-11-13T15:51:33Z", 
    "summary": "Algorithms testing two graphs for isomorphism known as yet in computer\nscience have exponential worst case complexity. In this paper we propose an\nalgorithm that has polynomial complexity and constructively supplies the\nevidence that the graph isomorphism lies in P."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0712.1532v1", 
    "title": "Hard constraint satisfaction problems have hard gaps at location 1", 
    "arxiv-id": "0712.1532v1", 
    "author": "Fredrik Kuivinen", 
    "publish": "2007-12-10T16:42:18Z", 
    "summary": "An instance of Max CSP is a finite collection of constraints on a set of\nvariables, and the goal is to assign values to the variables that maximises the\nnumber of satisfied constraints. Max CSP captures many well-known problems\n(such as Max k-SAT and Max Cut) and is consequently NP-hard. Thus, it is\nnatural to study how restrictions on the allowed constraint types (or\nconstraint languages) affect the complexity and approximability of Max CSP. The\nPCP theorem is equivalent to the existence of a constraint language for which\nMax CSP has a hard gap at location 1, i.e. it is NP-hard to distinguish between\nsatisfiable instances and instances where at most some constant fraction of the\nconstraints are satisfiable. All constraint languages, for which the CSP\nproblem (i.e., the problem of deciding whether all constraints can be\nsatisfied) is currently known to be NP-hard, have a certain algebraic property.\nWe prove that any constraint language with this algebraic property makes Max\nCSP have a hard gap at location 1 which, in particular, implies that such\nproblems cannot have a PTAS unless P = NP. We then apply this result to Max CSP\nrestricted to a single constraint type; this class of problems contains, for\ninstance, Max Cut and Max DiCut. Assuming P $\\neq$ NP, we show that such\nproblems do not admit PTAS except in some trivial cases. Our results hold even\nif the number of occurrences of each variable is bounded by a constant. We use\nthese results to partially answer open questions and strengthen results by\nEngebretsen et al. [Theor. Comput. Sci., 312 (2004), pp. 17--45], Feder et al.\n[Discrete Math., 307 (2007), pp. 386--392], Krokhin and Larose [Proc.\nPrinciples and Practice of Constraint Programming (2005), pp. 388--402], and\nJonsson and Krokhin [J. Comput. System Sci., 73 (2007), pp. 691--702]"
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0712.3348v2", 
    "title": "On Exponential Time Lower Bound of Knapsack under Backtracking", 
    "arxiv-id": "0712.3348v2", 
    "author": "Tian Liu", 
    "publish": "2007-12-20T09:15:17Z", 
    "summary": "M.Aleknovich et al. have recently proposed a model of algorithms, called BT\nmodel, which generalizes both the priority model of Borodin, Nielson and\nRackoff, as well as a simple dynamic programming model by Woeginger. BT model\ncan be further divided into three kinds of fixed, adaptive and fully adaptive\nones. They have proved exponential time lower bounds of exact and approximation\nalgorithms under adaptive BT model for Knapsack problem. Their exact lower\nbound is $\\Omega(2^{0.5n}/\\sqrt{n})$, in this paper, we slightly improve the\nexact lower bound to about $\\Omega(2^{0.69n}/\\sqrt{n})$, by the same technique,\nwith related parameters optimized."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0712.4279v2", 
    "title": "Disjointness is hard in the multi-party number on the forehead model", 
    "arxiv-id": "0712.4279v2", 
    "author": "Adi Shraibman", 
    "publish": "2007-12-27T20:45:53Z", 
    "summary": "We show that disjointness requires randomized communication\nOmega(n^{1/(k+1)}/2^{2^k}) in the general k-party number-on-the-forehead model\nof complexity. The previous best lower bound for k >= 3 was log(n)/(k-1). Our\nresults give a separation between nondeterministic and randomized multiparty\nnumber-on-the-forehead communication complexity for up to k=log log n - O(log\nlog log n) many players. Also by a reduction of Beame, Pitassi, and Segerlind,\nthese results imply subexponential lower bounds on the size of proofs needed to\nrefute certain unsatisfiable CNFs in a broad class of proof systems, including\ntree-like Lovasz-Schrijver proofs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.0474v1", 
    "title": "Analysis and Counterexamples Regarding Yatsenko's Polynomial-Time   Algorithm for Solving the Traveling Salesman Problem", 
    "arxiv-id": "0801.0474v1", 
    "author": "Corey Proscia", 
    "publish": "2008-01-03T04:46:16Z", 
    "summary": "Yatsenko gives a polynomial-time algorithm for solving the traveling salesman\nproblem. We examine the correctness of the algorithm and its construction. We\nalso comment on Yatsenko's evaluation of the algorithm."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.0514v1", 
    "title": "New results on Noncommutative and Commutative Polynomial Identity   Testing", 
    "arxiv-id": "0801.0514v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2008-01-03T12:32:41Z", 
    "summary": "Using ideas from automata theory we design a new efficient (deterministic)\nidentity test for the \\emph{noncommutative} polynomial identity testing problem\n(first introduced and studied in \\cite{RS05,BW05}). We also apply this idea to\nthe reconstruction of black-box noncommuting algebraic branching programs.\nAssuming the black-box model allows us to query the ABP for the output at any\ngiven gate, we can reconstruct an (equivalent) ABP in deterministic polynomial\ntime. Finally, we explore commutative identity testing when the coefficients of\nthe input polynomial come from an arbitrary finite commutative ring with unity."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.3624v3", 
    "title": "Multiparty Communication Complexity of Disjointness", 
    "arxiv-id": "0801.3624v3", 
    "author": "Anil Ada", 
    "publish": "2008-01-23T16:39:31Z", 
    "summary": "We obtain a lower bound of n^Omega(1) on the k-party randomized communication\ncomplexity of the Disjointness function in the `Number on the Forehead' model\nof multiparty communication when k is a constant. For k=o(loglog n), the bounds\nremain super-polylogarithmic i.e. (log n)^omega(1). The previous best lower\nbound for three players until recently was Omega(log n).\n  Our bound separates the communication complexity classes NP^{CC}_k and\nBPP^{CC}_k for k=o(loglog n). Furthermore, by the results of Beame, Pitassi and\nSegerlind \\cite{BPS07}, our bound implies proof size lower bounds for\ntree-like, degree k-1 threshold systems and superpolynomial size lower bounds\nfor Lovasz-Schrijver proofs.\n  Sherstov \\cite{She07b} recently developed a novel technique to obtain lower\nbounds on two-party communication using the approximate polynomial degree of\nboolean functions. We obtain our results by extending his technique to the\nmulti-party setting using ideas from Chattopadhyay \\cite{Cha07}.\n  A similar bound for Disjointness has been recently and independently obtained\nby Lee and Shraibman."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.3669v3", 
    "title": "Merkle Puzzles are Optimal", 
    "arxiv-id": "0801.3669v3", 
    "author": "Mohammad Mahmoody-Ghidary", 
    "publish": "2008-01-23T21:01:37Z", 
    "summary": "We prove that every key exchange protocol in the random oracle model in which\nthe honest users make at most n queries to the oracle can be broken by an\nadversary making O(n^2) queries to the oracle. This improves on the previous\nOmega(n^6) query attack given by Impagliazzo and Rudich (STOC '89). Our bound\nis optimal up to a constant factor since Merkle (CACM '78) gave an n query key\nexchange protocol in this model that cannot be broken by an adversary making\no(n^2) queries."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.4777v1", 
    "title": "Non-Deterministic Communication Complexity of Regular Languages", 
    "arxiv-id": "0801.4777v1", 
    "author": "Anil Ada", 
    "publish": "2008-01-30T21:55:13Z", 
    "summary": "In this thesis, we study the place of regular languages within the\ncommunication complexity setting. In particular, we are interested in the\nnon-deterministic communication complexity of regular languages.\n  We show that a regular language has either O(1) or Omega(log n)\nnon-deterministic complexity. We obtain several linear lower bound results\nwhich cover a wide range of regular languages having linear non-deterministic\ncomplexity. These lower bound results also imply a result in semigroup theory:\nwe obtain sufficient conditions for not being in the positive variety Pol(Com).\n  To obtain our results, we use algebraic techniques. In the study of regular\nlanguages, the algebraic point of view pioneered by Eilenberg (\\cite{Eil74})\nhas led to many interesting results. Viewing a semigroup as a computational\ndevice that recognizes languages has proven to be prolific from both semigroup\ntheory and formal languages perspectives. In this thesis, we provide further\ninstances of such mutualism."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.4911v1", 
    "title": "On the Double Coset Membership Problem for Permutation Groups", 
    "arxiv-id": "0801.4911v1", 
    "author": "Oleg Verbitsky", 
    "publish": "2008-01-31T16:19:20Z", 
    "summary": "We show that the Double Coset Membership problem for permutation groups\npossesses perfect zero-knowledge proofs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0801.4917v1", 
    "title": "Zero-Knowledge Proofs of the Conjugacy for Permutation Groups", 
    "arxiv-id": "0801.4917v1", 
    "author": "Oleg Verbitsky", 
    "publish": "2008-01-31T16:33:15Z", 
    "summary": "We design a perfect zero-knowledge proof system for recognition if two\npermutation groups are conjugate."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.0423v1", 
    "title": "Approximability Distance in the Space of H-Colourability Problems", 
    "arxiv-id": "0802.0423v1", 
    "author": "Johan Thapper", 
    "publish": "2008-02-04T14:32:45Z", 
    "summary": "A graph homomorphism is a vertex map which carries edges from a source graph\nto edges in a target graph. We study the approximability properties of the\nWeighted Maximum H-Colourable Subgraph problem (MAX H-COL). The instances of\nthis problem are edge-weighted graphs G and the objective is to find a subgraph\nof G that has maximal total edge weight, under the condition that the subgraph\nhas a homomorphism to H; note that for H=K_k this problem is equivalent to MAX\nk-CUT. To this end, we introduce a metric structure on the space of graphs\nwhich allows us to extend previously known approximability results to larger\nclasses of graphs. Specifically, the approximation algorithms for MAX CUT by\nGoemans and Williamson and MAX k-CUT by Frieze and Jerrum can be used to yield\nnon-trivial approximation results for MAX H-COL. For a variety of graphs, we\nshow near-optimality results under the Unique Games Conjecture. We also use our\nmethod for comparing the performance of Frieze & Jerrum's algorithm with\nHastad's approximation algorithm for general MAX 2-CSP. This comparison is, in\nmost cases, favourable to Frieze & Jerrum."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.1465v2", 
    "title": "3-Way Composition of Weighted Finite-State Transducers", 
    "arxiv-id": "0802.1465v2", 
    "author": "Mehryar Mohri", 
    "publish": "2008-02-11T16:18:40Z", 
    "summary": "Composition of weighted transducers is a fundamental algorithm used in many\napplications, including for computing complex edit-distances between automata,\nor string kernels in machine learning, or to combine different components of a\nspeech recognition, speech synthesis, or information extraction system. We\npresent a generalization of the composition of weighted transducers, 3-way\ncomposition, which is dramatically faster in practice than the standard\ncomposition algorithm when combining more than two transducers. The worst-case\ncomplexity of our algorithm for composing three transducers $T_1$, $T_2$, and\n$T_3$ resulting in $T$, \\ignore{depending on the strategy used, is $O(|T|_Q\nd(T_1) d(T_3) + |T|_E)$ or $(|T|_Q d(T_2) + |T|_E)$,} is $O(|T|_Q \\min(d(T_1)\nd(T_3), d(T_2)) + |T|_E)$, where $|\\cdot|_Q$ denotes the number of states,\n$|\\cdot|_E$ the number of transitions, and $d(\\cdot)$ the maximum out-degree.\nAs in regular composition, the use of perfect hashing requires a pre-processing\nstep with linear-time expected complexity in the size of the input transducers.\nIn many cases, this approach significantly improves on the complexity of\nstandard composition. Our algorithm also leads to a dramatically faster\ncomposition in practice. Furthermore, standard composition can be obtained as a\nspecial case of our algorithm. We report the results of several experiments\ndemonstrating this improvement. These theoretical and empirical improvements\nsignificantly enhance performance in the applications already mentioned."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.1699v1", 
    "title": "Longest paths in Planar DAGs in Unambiguous Logspace", 
    "arxiv-id": "0802.1699v1", 
    "author": "Prajakta Nimbhorkar", 
    "publish": "2008-02-12T20:08:39Z", 
    "summary": "We show via two different algorithms that finding the length of the longest\npath in planar directed acyclic graph (DAG) is in unambiguous logspace UL, and\nalso in the complement class co-UL. The result extends to toroidal DAGs as\nwell."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.1790v1", 
    "title": "SAT Has No Wizards", 
    "arxiv-id": "0802.1790v1", 
    "author": "Silvano Di Zenzo", 
    "publish": "2008-02-13T14:43:40Z", 
    "summary": "An (encoded) decision problem is a pair (E, F) where E=words that encode\ninstances of the problem, F=words to be accepted. We use \"strings\" in a\ntechnical sense. With an NP problem (E, F) we associate the \"logogram\" of F\nrelative to E, which conveys structural information on E, F, and how F is\nembedded in E. The kernel Ker(P) of a program P that solves (E, F) consists of\nthose strings in the logogram that are used by P. There are relations between\nKer(P) and the complexity of P. We develop an application to SAT that relies\nupon a property of internal independence of SAT. We show that SAT cannot have\nin its logogram strings serving as collective certificates. As consequence, all\nprograms that solve SAT have same kernel."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.1829v1", 
    "title": "A review of the Statistical Mechanics approach to Random Optimization   Problems", 
    "arxiv-id": "0802.1829v1", 
    "author": "Francesco Zamponi", 
    "publish": "2008-02-13T13:45:16Z", 
    "summary": "We review the connection between statistical mechanics and the analysis of\nrandom optimization problems, with particular emphasis on the random k-SAT\nproblem. We discuss and characterize the different phase transitions that are\nmet in these problems, starting from basic concepts. We also discuss how\nstatistical mechanics methods can be used to investigate the behavior of local\nsearch and decimation based algorithms."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.2300v1", 
    "title": "Approximation Resistant Predicates From Pairwise Independence", 
    "arxiv-id": "0802.2300v1", 
    "author": "Elchanan Mossel", 
    "publish": "2008-02-15T23:21:05Z", 
    "summary": "We study the approximability of predicates on $k$ variables from a domain\n$[q]$, and give a new sufficient condition for such predicates to be\napproximation resistant under the Unique Games Conjecture. Specifically, we\nshow that a predicate $P$ is approximation resistant if there exists a balanced\npairwise independent distribution over $[q]^k$ whose support is contained in\nthe set of satisfying assignments to $P$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.2833v1", 
    "title": "Limit complexities revisited", 
    "arxiv-id": "0802.2833v1", 
    "author": "Nikolay Vereshchagin", 
    "publish": "2008-02-20T14:13:31Z", 
    "summary": "The main goal of this paper is to put some known results in a common\nperspective and to simplify their proofs. We start with a simple proof of a\nresult from (Vereshchagin, 2002) saying that $\\limsup_n\\KS(x|n)$ (here\n$\\KS(x|n)$ is conditional (plain) Kolmogorov complexity of $x$ when $n$ is\nknown) equals $\\KS^{\\mathbf{0'}(x)$, the plain Kolmogorov complexity with\n$\\mathbf{0'$-oracle. Then we use the same argument to prove similar results for\nprefix complexity (and also improve results of (Muchnik, 1987) about limit\nfrequencies), a priori probability on binary tree and measure of effectively\nopen sets. As a by-product, we get a criterion of $\\mathbf{0'}$ Martin-L\\\"of\nrandomness (called also 2-randomness) proved in (Miller, 2004): a sequence\n$\\omega$ is 2-random if and only if there exists $c$ such that any prefix $x$\nof $\\omega$ is a prefix of some string $y$ such that $\\KS(y)\\ge |y|-c$. (In the\n1960ies this property was suggested in (Kolmogorov, 1968) as one of possible\nrandomness definitions; its equivalence to 2-randomness was shown in (Miller,\n2004) while proving another 2-randomness criterion (see also (Nies et al.\n2005)): $\\omega$ is 2-random if and only if $\\KS(x)\\ge |x|-c$ for some $c$ and\ninfinitely many prefixes $x$ of $\\omega$. Finally, we show that the low-basis\ntheorem can be used to get alternative proofs for these results and to improve\nthe result about effectively open sets; this stronger version implies the\n2-randomness criterion mentioned in the previous sentence."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.2860v1", 
    "title": "A Theory for Valiant's Matchcircuits (Extended Abstract)", 
    "arxiv-id": "0802.2860v1", 
    "author": "Mingji Xia", 
    "publish": "2008-02-20T14:31:38Z", 
    "summary": "The computational function of a matchgate is represented by its character\nmatrix. In this article, we show that all nonsingular character matrices are\nclosed under matrix inverse operation, so that for every $k$, the nonsingular\ncharacter matrices of $k$-bit matchgates form a group, extending the recent\nwork of Cai and Choudhary (2006) of the same result for the case of $k=2$, and\nthat the single and the two-bit matchgates are universal for matchcircuits,\nanswering a question of Valiant (2002)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.2868v1", 
    "title": "Efficient Algorithms for Membership in Boolean Hierarchies of Regular   Languages", 
    "arxiv-id": "0802.2868v1", 
    "author": "Victor Selivanov", 
    "publish": "2008-02-20T14:40:02Z", 
    "summary": "The purpose of this paper is to provide efficient algorithms that decide\nmembership for classes of several Boolean hierarchies for which efficiency (or\neven decidability) were previously not known. We develop new forbidden-chain\ncharacterizations for the single levels of these hierarchies and obtain the\nfollowing results: - The classes of the Boolean hierarchy over level $\\Sigma_1$\nof the dot-depth hierarchy are decidable in $NL$ (previously only the\ndecidability was known). The same remains true if predicates mod $d$ for fixed\n$d$ are allowed. - If modular predicates for arbitrary $d$ are allowed, then\nthe classes of the Boolean hierarchy over level $\\Sigma_1$ are decidable. - For\nthe restricted case of a two-letter alphabet, the classes of the Boolean\nhierarchy over level $\\Sigma_2$ of the Straubing-Th\\'erien hierarchy are\ndecidable in $NL$. This is the first decidability result for this hierarchy. -\nThe membership problems for all mentioned Boolean-hierarchy classes are\nlogspace many-one hard for $NL$. - The membership problems for quasi-aperiodic\nlanguages and for $d$-quasi-aperiodic languages are logspace many-one complete\nfor $PSPACE$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.2869v1", 
    "title": "Succinctness of the Complement and Intersection of Regular Expressions", 
    "arxiv-id": "0802.2869v1", 
    "author": "Frank Neven", 
    "publish": "2008-02-20T14:40:53Z", 
    "summary": "We study the succinctness of the complement and intersection of regular\nexpressions. In particular, we show that when constructing a regular expression\ndefining the complement of a given regular expression, a double exponential\nsize increase cannot be avoided. Similarly, when constructing a regular\nexpression defining the intersection of a fixed and an arbitrary number of\nregular expressions, an exponential and double exponential size increase,\nrespectively, can in worst-case not be avoided. All mentioned lower bounds\nimprove the existing ones by one exponential and are tight in the sense that\nthe target expression can be constructed in the corresponding time class, i.e.,\nexponential or double exponential time. As a by-product, we generalize a\ntheorem by Ehrenfeucht and Zeiger stating that there is a class of DFAs which\nare exponentially more succinct than regular expressions, to a fixed\nfour-letter alphabet. When the given regular expressions are one-unambiguous,\nas for instance required by the XML Schema specification, the complement can be\ncomputed in polynomial time whereas the bounds concerning intersection continue\nto hold. For the subclass of single-occurrence regular expressions, we prove a\ntight exponential lower bound for intersection."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.3254v1", 
    "title": "General Algorithms for Testing the Ambiguity of Finite Automata", 
    "arxiv-id": "0802.3254v1", 
    "author": "Ashish Rastogi", 
    "publish": "2008-02-22T05:20:08Z", 
    "summary": "This paper presents efficient algorithms for testing the finite, polynomial,\nand exponential ambiguity of finite automata with $\\epsilon$-transitions. It\ngives an algorithm for testing the exponential ambiguity of an automaton $A$ in\ntime $O(|A|_E^2)$, and finite or polynomial ambiguity in time $O(|A|_E^3)$.\nThese complexities significantly improve over the previous best complexities\ngiven for the same problem. Furthermore, the algorithms presented are simple\nand are based on a general algorithm for the composition or intersection of\nautomata. We also give an algorithm to determine the degree of polynomial\nambiguity of a finite automaton $A$ that is polynomially ambiguous in time\n$O(|A|_E^3)$. Finally, we present an application of our algorithms to an\napproximate computation of the entropy of a probabilistic automaton."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.3860v1", 
    "title": "Separating NOF communication complexity classes RP and NP", 
    "arxiv-id": "0802.3860v1", 
    "author": "Toniann Pitassi", 
    "publish": "2008-02-26T19:58:26Z", 
    "summary": "We provide a non-explicit separation of the number-on-forehead communication\ncomplexity classes RP and NP when the number of players is up to \\delta log(n)\nfor any \\delta<1. Recent lower bounds on Set-Disjointness [LS08,CA08] provide\nan explicit separation between these classes when the number of players is only\nup to o(loglog(n))."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0802.4312v2", 
    "title": "Curves That Must Be Retraced", 
    "arxiv-id": "0802.4312v2", 
    "author": "Elvira Mayordomo", 
    "publish": "2008-02-29T00:58:26Z", 
    "summary": "We exhibit a polynomial time computable plane curve GAMMA that has finite\nlength, does not intersect itself, and is smooth except at one endpoint, but\nhas the following property. For every computable parametrization f of GAMMA and\nevery positive integer n, there is some positive-length subcurve of GAMMA that\nf retraces at least n times. In contrast, every computable curve of finite\nlength that does not intersect itself has a constant-speed (hence\nnon-retracing) parametrization that is computable relative to the halting\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0803.0055v1", 
    "title": "A compact topology for sand automata", 
    "arxiv-id": "0803.0055v1", 
    "author": "Beno\u00eet Masson", 
    "publish": "2008-03-01T08:36:39Z", 
    "summary": "In this paper, we exhibit a strong relation between the sand automata\nconfiguration space and the cellular automata configuration space. This\nrelation induces a compact topology for sand automata, and a new context in\nwhich sand automata are homeomorphic to cellular automata acting on a specific\nsubshift. We show that the existing topological results for sand automata,\nincluding the Hedlund-like representation theorem, still hold. In this context,\nwe give a characterization of the cellular automata which are sand automata,\nand study some dynamical behaviors such as equicontinuity. Furthermore, we deal\nwith the nilpotency. We show that the classical definition is not meaningful\nfor sand automata. Then, we introduce a suitable new notion of nilpotency for\nsand automata. Finally, we prove that this simple dynamical behavior is\nundecidable."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0803.1030v3", 
    "title": "Robust Stochastic Chemical Reaction Networks and Bounded Tau-Leaping", 
    "arxiv-id": "0803.1030v3", 
    "author": "David Soloveichik", 
    "publish": "2008-03-07T17:36:54Z", 
    "summary": "The behavior of some stochastic chemical reaction networks is largely\nunaffected by slight inaccuracies in reaction rates. We formalize the\nrobustness of state probabilities to reaction rate deviations, and describe a\nformal connection between robustness and efficiency of simulation. Without\nrobustness guarantees, stochastic simulation seems to require computational\ntime proportional to the total number of reaction events. Even if the\nconcentration (molecular count per volume) stays bounded, the number of\nreaction events can be linear in the duration of simulated time and total\nmolecular count. We show that the behavior of robust systems can be predicted\nsuch that the computational work scales linearly with the duration of simulated\ntime and concentration, and only polylogarithmically in the total molecular\ncount. Thus our asymptotic analysis captures the dramatic speedup when\nmolecular counts are large, and shows that for bounded concentrations the\ncomputation time is essentially invariant with molecular count. Finally, by\nnoticing that even robust stochastic chemical reaction networks are capable of\nembedding complex computational problems, we argue that the linear dependence\non simulated time and concentration is likely optimal."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0803.4206v2", 
    "title": "Product theorems via semidefinite programming", 
    "arxiv-id": "0803.4206v2", 
    "author": "Rajat Mittal", 
    "publish": "2008-03-28T20:27:47Z", 
    "summary": "The tendency of semidefinite programs to compose perfectly under product has\nbeen exploited many times in complexity theory: for example, by Lovasz to\ndetermine the Shannon capacity of the pentagon; to show a direct sum theorem\nfor non-deterministic communication complexity and direct product theorems for\ndiscrepancy; and in interactive proof systems to show parallel repetition\ntheorems for restricted classes of games.\n  Despite all these examples of product theorems--some going back nearly thirty\nyears--it was only recently that Mittal and Szegedy began to develop a general\ntheory to explain when and why semidefinite programs behave perfectly under\nproduct. This theory captured many examples in the literature, but there were\nalso some notable exceptions which it could not explain--namely, an early\nparallel repetition result of Feige and Lovasz, and a direct product theorem\nfor the discrepancy method of communication complexity by Lee, Shraibman, and\nSpalek.\n  We extend the theory of Mittal and Szegedy to explain these cases as well.\nIndeed, to the best of our knowledge, our theory captures all examples of\nsemidefinite product theorems in the literature."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0803.4261v1", 
    "title": "Common Permutation Problem", 
    "arxiv-id": "0803.4261v1", 
    "author": "Mari\u00e1n Dvorsk\u00fd", 
    "publish": "2008-03-29T11:32:29Z", 
    "summary": "In this paper we show that the following problem is NP-complete: Given an\nalphabet $\\Sigma$ and two strings over $\\Sigma$, the question is whether there\nexists a permutation of $\\Sigma$ which is a subsequence of both of the given\nstrings."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0803.4516v1", 
    "title": "A Dual Polynomial for OR", 
    "arxiv-id": "0803.4516v1", 
    "author": "Robert Spalek", 
    "publish": "2008-03-31T18:20:53Z", 
    "summary": "We reprove that the approximate degree of the OR function on n bits is\nOmega(sqrt(n)). We consider a linear program which is feasible if and only if\nthere is an approximate polynomial for a given function, and apply the duality\ntheory. The duality theory says that the primal program has no solution if and\nonly if its dual has a solution. Therefore one can prove the nonexistence of an\napproximate polynomial by exhibiting a dual solution, coined the dual\npolynomial. We construct such a polynomial."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0804.0957v2", 
    "title": "Derandomizing the Isolation Lemma and Lower Bounds for Circuit Size", 
    "arxiv-id": "0804.0957v2", 
    "author": "Partha Mukhopadhyay", 
    "publish": "2008-04-07T04:04:21Z", 
    "summary": "The isolation lemma of Mulmuley et al \\cite{MVV87} is an important tool in\nthe design of randomized algorithms and has played an important role in several\nnontrivial complexity upper bounds. On the other hand, polynomial identity\ntesting is a well-studied algorithmic problem with efficient randomized\nalgorithms and the problem of obtaining efficient \\emph{deterministic} identity\ntests has received a lot of attention recently. The goal of this note is to\ncompare the isolation lemma with polynomial identity testing: 1. We show that\nderandomizing reasonably restricted versions of the isolation lemma implies\ncircuit size lower bounds. We derive the circuit lower bounds by examining the\nconnection between the isolation lemma and polynomial identity testing. We give\na randomized polynomial-time identity test for noncommutative circuits of\npolynomial degree based on the isolation lemma. Using this result, we show that\nderandomizing the isolation lemma implies noncommutative circuit size lower\nbounds. The restricted versions of the isolation lemma we consider are natural\nand would suffice for the standard applications of the isolation lemma. 2. From\nthe result of Klivans-Spielman \\cite{KS01} we observe that there is a\nrandomized polynomial-time identity test for commutative circuits of polynomial\ndegree, also based on a more general isolation lemma for linear forms.\nConsequently, derandomization of (a suitable version of) this isolation lemma\nalso implies circuit size lower bounds in the commutative setting."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0804.1079v12", 
    "title": "P is a proper subset of NP", 
    "arxiv-id": "0804.1079v12", 
    "author": "Jerrald Meek", 
    "publish": "2008-04-07T16:58:59Z", 
    "summary": "The purpose of this article is to examine and limit the conditions in which\nthe P complexity class could be equivalent to the NP complexity class. Proof is\nprovided by demonstrating that as the number of clauses in a NP-complete\nproblem approaches infinity, the number of input sets processed per computation\nperformed also approaches infinity when solved by a polynomial time solution.\nIt is then possible to determine that the only deterministic optimization of a\nNP-complete problem that could prove P = NP would be one that examines no more\nthan a polynomial number of input sets for a given problem.\n  It is then shown that subdividing the set of all possible input sets into a\nrepresentative polynomial search partition is a problem in the FEXP complexity\nclass. The findings of this article are combined with the findings of other\narticles in this series of 4 articles. The final conclusion will be\ndemonstrated that P =/= NP."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0805.0517v5", 
    "title": "Analysis of the Deterministic Polynomial Time Solvability of the   0-1-Knapsack Problem", 
    "arxiv-id": "0805.0517v5", 
    "author": "Jerrald Meek", 
    "publish": "2008-05-05T12:34:27Z", 
    "summary": "Previously the author has demonstrated that a representative polynomial\nsearch partition is required to solve a NP-complete problem in deterministic\npolynomial time. It has also been demonstrated that finding such a partition\ncan only be done in deterministic polynomial time if the form of the problem\nprovides a simple method for producing the partition. It is the purpose of this\narticle to demonstrate that no deterministic polynomial time method exists to\nproduce a representative polynomial search partition for the Knapsack problem."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0805.1385v3", 
    "title": "Almost-natural proofs", 
    "arxiv-id": "0805.1385v3", 
    "author": "Timothy Y. Chow", 
    "publish": "2008-05-09T18:14:43Z", 
    "summary": "Razborov and Rudich have shown that so-called \"natural proofs\" are not useful\nfor separating P from NP unless hard pseudorandom number generators do not\nexist. This famous result is widely regarded as a serious barrier to proving\nstrong lower bounds in circuit complexity theory.\n  By definition, a natural combinatorial property satisfies two conditions,\nconstructivity and largeness. Our main result is that if the largeness\ncondition is weakened slightly, then not only does the Razborov-Rudich proof\nbreak down, but such \"almost-natural\" (and useful) properties provably exist.\nSpecifically, under the same pseudorandomness assumption that Razborov and\nRudich make, a simple, explicit property that we call \"discrimination\" suffices\nto separate P/poly from NP; discrimination is nearly linear-time computable and\nalmost large, having density 2^{-q(n)} where q is a quasi-polynomial function.\nFor those who hope to separate P from NP using random function properties in\nsome sense, discrimination is interesting, because it is constructive, yet may\nbe thought of as a minor alteration of a property of a random function.\n  The proof relies heavily on the self-defeating character of natural proofs.\nOur proof technique also yields an unconditional result, namely that there\nexist almost-large and useful properties that are constructive, if we are\nallowed to call non-uniform low-complexity classes \"constructive.\" We note,\nthough, that this unconditional result can also be proved by a more\nconventional counting argument.\n  Finally, we give an alternative proof, communicated to us by Salil Vadhan at\nFOCS 2008, of one of our theorems, and we make some speculative remarks on the\nfuture prospects for proving strong circuit lower bounds."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0805.1765v1", 
    "title": "Efficiently Testing Sparse GF(2) Polynomials", 
    "arxiv-id": "0805.1765v1", 
    "author": "Andrew Wan", 
    "publish": "2008-05-13T00:51:30Z", 
    "summary": "We give the first algorithm that is both query-efficient and time-efficient\nfor testing whether an unknown function $f: \\{0,1\\}^n \\to \\{0,1\\}$ is an\n$s$-sparse GF(2) polynomial versus $\\eps$-far from every such polynomial. Our\nalgorithm makes $\\poly(s,1/\\eps)$ black-box queries to $f$ and runs in time $n\n\\cdot \\poly(s,1/\\eps)$. The only previous algorithm for this testing problem\n\\cite{DLM+:07} used poly$(s,1/\\eps)$ queries, but had running time exponential\nin $s$ and super-polynomial in $1/\\eps$.\n  Our approach significantly extends the ``testing by implicit learning''\nmethodology of \\cite{DLM+:07}. The learning component of that earlier work was\na brute-force exhaustive search over a concept class to find a hypothesis\nconsistent with a sample of random examples. In this work, the learning\ncomponent is a sophisticated exact learning algorithm for sparse GF(2)\npolynomials due to Schapire and Sellie \\cite{SchapireSellie:96}. A crucial\nelement of this work, which enables us to simulate the membership queries\nrequired by \\cite{SchapireSellie:96}, is an analysis establishing new\nproperties of how sparse GF(2) polynomials simplify under certain restrictions\nof ``low-influence'' sets of variables."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0805.2135v1", 
    "title": "Communication Lower Bounds Using Dual Polynomials", 
    "arxiv-id": "0805.2135v1", 
    "author": "Alexander A. Sherstov", 
    "publish": "2008-05-14T18:52:06Z", 
    "summary": "Representations of Boolean functions by real polynomials play an important\nrole in complexity theory. Typically, one is interested in the least degree of\na polynomial p(x_1,...,x_n) that approximates or sign-represents a given\nBoolean function f(x_1,...,x_n). This article surveys a new and growing body of\nwork in communication complexity that centers around the dual objects, i.e.,\npolynomials that certify the difficulty of approximating or sign-representing a\ngiven function. We provide a unified guide to the following results, complete\nwith all the key proofs:\n  (1) Sherstov's Degree/Discrepancy Theorem, which translates lower bounds on\nthe threshold degree of a Boolean function into upper bounds on the discrepancy\nof a related function;\n  (2) Two different methods for proving lower bounds on bounded-error\ncommunication based on the approximate degree: Sherstov's pattern matrix method\nand Shi and Zhu's block composition method;\n  (3) Extension of the pattern matrix method to the multiparty model, obtained\nby Lee and Shraibman and by Chattopadhyay and Ada, and the resulting improved\nlower bounds for DISJOINTNESS;\n  (4) David and Pitassi's separation of NP and BPP in multiparty communication\ncomplexity for k=(1-eps)log n players."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0805.2170v6", 
    "title": "Independence of P vs. NP in regards to oracle relativizations", 
    "arxiv-id": "0805.2170v6", 
    "author": "Jerrald Meek", 
    "publish": "2008-05-14T21:10:55Z", 
    "summary": "This is the third article in a series of four articles dealing with the P vs.\nNP question. The purpose of this work is to demonstrate that the methods used\nin the first two articles of this series are not affected by oracle\nrelativizations. Furthermore, the solution to the P vs. NP problem is actually\nindependent of oracle relativizations."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0805.3058v1", 
    "title": "A New Structural Property of SAT", 
    "arxiv-id": "0805.3058v1", 
    "author": "Silvano Di Zenzo", 
    "publish": "2008-05-20T12:07:51Z", 
    "summary": "We review a minimum set of notions from our previous paper on structural\nproperties of SAT at arXiv:0802.1790 that will allow us to define and discuss\nthe \"complete internal independence\" of a decision problem. This property is\nstrictly stronger than the independence property that was called \"strong\ninternal independence\" in cited paper. We show that SAT exhibits this property.\nWe argue that this form of independence of a decision problem is the strongest\npossible for a problem. By relying upon this maximally strong form of internal\nindependence, we reformulate in more strict terms the informal remarks on\npossible exponentiality of SAT that concluded our previous paper. The net\nresult of that reformulation is a hint for a proof for SAT being exponential.\nWe conjecture that a complete proof of that proposition can be obtained by\nstrictly following the line of given hint of proof."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0806.1041v1", 
    "title": "3-connected Planar Graph Isomorphism is in Log-space", 
    "arxiv-id": "0806.1041v1", 
    "author": "Prajakta Nimbhorkar", 
    "publish": "2008-06-05T19:33:29Z", 
    "summary": "We show that the isomorphism of 3-connected planar graphs can be decided in\ndeterministic log-space. This improves the previously known bound UL$\\cap$coUL\nof Thierauf and Wagner."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2004.02.049", 
    "link": "http://arxiv.org/pdf/0807.1412v1", 
    "title": "Quantum Query Complexity of Multilinear Identity Testing", 
    "arxiv-id": "0807.1412v1", 
    "author": "Partha Mukhopadhyay", 
    "publish": "2008-07-09T10:39:19Z", 
    "summary": "Motivated by the quantum algorithm in \\cite{MN05} for testing commutativity\nof black-box groups, we study the following problem: Given a black-box finite\nring $R=\\angle{r_1,...,r_k}$ where $\\{r_1,r_2,...,r_k\\}$ is an additive\ngenerating set for $R$ and a multilinear polynomial $f(x_1,...,x_m)$ over $R$\nalso accessed as a black-box function $f:R^m\\to R$ (where we allow the\nindeterminates $x_1,...,x_m$ to be commuting or noncommuting), we study the\nproblem of testing if $f$ is an \\emph{identity} for the ring $R$. More\nprecisely, the problem is to test if $f(a_1,a_2,...,a_m)=0$ for all $a_i\\in R$.\n  We give a quantum algorithm with query complexity $O(m(1+\\alpha)^{m/2}\nk^{\\frac{m}{m+1}})$ assuming $k\\geq (1+1/\\alpha)^{m+1}$. Towards a lower bound,\nwe also discuss a reduction from a version of $m$-collision to this problem.\n  We also observe a randomized test with query complexity $4^mmk$ and constant\nsuccess probability and a deterministic test with $k^m$ query complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0808.2662v3", 
    "title": "Multitask Efficiencies in the Decision Tree Model", 
    "arxiv-id": "0808.2662v3", 
    "author": "Andrew Drucker", 
    "publish": "2008-08-20T11:15:33Z", 
    "summary": "In Direct Sum problems [KRW], one tries to show that for a given\ncomputational model, the complexity of computing a collection of finite\nfunctions on independent inputs is approximately the sum of their individual\ncomplexities. In this paper, by contrast, we study the diversity of ways in\nwhich the joint computational complexity can behave when all the functions are\nevaluated on a common input. We focus on the deterministic decision tree model,\nwith depth as the complexity measure; in this model we prove a result to the\neffect that the 'obvious' constraints on joint computational complexity are\nessentially the only ones.\n  The proof uses an intriguing new type of cryptographic data structure called\na `mystery bin' which we construct using a small polynomial separation between\ndeterministic and unambiguous query complexity shown by Savicky. We also pose a\nvariant of the Direct Sum Conjecture of [KRW] which, if proved for a single\nfamily of functions, could yield an analogous result for models such as the\ncommunication model."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0808.3222v5", 
    "title": "Analysis of the postulates produced by Karp's Theorem", 
    "arxiv-id": "0808.3222v5", 
    "author": "Jerrald Meek", 
    "publish": "2008-08-24T02:59:29Z", 
    "summary": "This is the final article in a series of four articles. Richard Karp has\nproven that a deterministic polynomial time solution to K-SAT will result in a\ndeterministic polynomial time solution to all NP-Complete problems. However, it\nis demonstrated that a deterministic polynomial time solution to any\nNP-Complete problem does not necessarily produce a deterministic polynomial\ntime solution to all NP-Complete problems."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0809.0257v4", 
    "title": "Linear Kernelizations for Restricted 3-Hitting Set Problems", 
    "arxiv-id": "0809.0257v4", 
    "author": "Xuan Cai", 
    "publish": "2008-09-01T14:52:30Z", 
    "summary": "The 3-\\textsc{Hitting Set} problem is also called the \\textsc{Vertex Cover}\nproblem on 3-uniform hypergraphs. In this paper, we address kernelizations of\nthe \\textsc{Vertex Cover} problem on 3-uniform hypergraphs. We show that this\nproblem admits a linear kernel in three classes of 3-uniform hypergraphs. We\nalso obtain lower and upper bounds on the kernel size for them by the\nparametric duality."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0809.0352v3", 
    "title": "Instruction sequences and non-uniform complexity theory", 
    "arxiv-id": "0809.0352v3", 
    "author": "C. A. Middelburg", 
    "publish": "2008-09-02T05:45:48Z", 
    "summary": "We develop theory concerning non-uniform complexity in a setting in which the\nnotion of single-pass instruction sequence considered in program algebra is the\ncentral notion. We define counterparts of the complexity classes P/poly and\nNP/poly and formulate a counterpart of the complexity theoretic conjecture that\nNP is not included in P/poly. In addition, we define a notion of completeness\nfor the counterpart of NP/poly using a non-uniform reducibility relation and\nformulate complexity hypotheses which concern restrictions on the instruction\nsequences used for computation. We think that the theory developed opens up an\nadditional way of investigating issues concerning non-uniform complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0809.1836v1", 
    "title": "The complexity of counting solutions to Generalised Satisfiability   Problems modulo k", 
    "arxiv-id": "0809.1836v1", 
    "author": "John Faben", 
    "publish": "2008-09-10T16:23:53Z", 
    "summary": "Generalised Satisfiability Problems (or Boolean Constraint Satisfaction\nProblems), introduced by Schaefer in 1978, are a general class of problem which\nallow the systematic study of the complexity of satisfiability problems with\ndifferent types of constraints. In 1979, Valiant introduced the complexity\nclass parity P, the problem of counting the number of solutions to NP problems\nmodulo two. Others have since considered the question of counting modulo other\nintegers.\n  We give a dichotomy theorem for the complexity of counting the number of\nsolutions to Generalised Satisfiability Problems modulo integers. This follows\nfrom an earlier result of Creignou and Hermann which gave a counting dichotomy\nfor these types of problem, and the dichotomy itself is almost identical.\nSpecifically, counting the number of solutions to a Generalised Satisfiability\nProblem can be done in polynomial time if all the relations are affine.\nOtherwise, except for one special case with k = 2, it is #_kP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0809.2093v1", 
    "title": "An approximation algorithm for approximation rank", 
    "arxiv-id": "0809.2093v1", 
    "author": "Adi Shraibman", 
    "publish": "2008-09-11T20:06:56Z", 
    "summary": "One of the strongest techniques available for showing lower bounds on quantum\ncommunication complexity is the logarithm of the approximation rank of the\ncommunication matrix--the minimum rank of a matrix which is entrywise close to\nthe communication matrix. This technique has two main drawbacks: it is\ndifficult to compute, and it is not known to lower bound quantum communication\ncomplexity with entanglement.\n  Linial and Shraibman recently introduced a norm, called gamma_2^{alpha}, to\nquantum communication complexity, showing that it can be used to lower bound\ncommunication with entanglement. Here the parameter alpha is a measure of\napproximation which is related to the allowable error probability of the\nprotocol. This bound can be written as a semidefinite program and gives bounds\nat least as large as many techniques in the literature, although it is smaller\nthan the corresponding alpha-approximation rank, rk_alpha. We show that in fact\nlog gamma_2^{alpha}(A)$ and log rk_{alpha}(A)$ agree up to small factors. As\ncorollaries we obtain a constant factor polynomial time approximation algorithm\nto the logarithm of approximate rank, and that the logarithm of approximation\nrank is a lower bound for quantum communication complexity with entanglement."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0809.2319v2", 
    "title": "A Log-space Algorithm for Canonization of Planar Graphs", 
    "arxiv-id": "0809.2319v2", 
    "author": "Fabian Wagner", 
    "publish": "2008-09-15T06:22:39Z", 
    "summary": "Graph Isomorphism is the prime example of a computational problem with a wide\ndifference between the best known lower and upper bounds on its complexity. We\nbridge this gap for a natural and important special case, planar graph\nisomorphism, by presenting an upper bound that matches the known logspace\nhardness [Lindell'92]. In fact, we show the formally stronger result that\nplanar graph canonization is in logspace. This improves the previously known\nupper bound of AC1 [MillerReif'91].\n  Our algorithm first constructs the biconnected component tree of a connected\nplanar graph and then refines each biconnected component into a triconnected\ncomponent tree. The next step is to logspace reduce the biconnected planar\ngraph isomorphism and canonization problems to those for 3-connected planar\ngraphs, which are known to be in logspace by [DattaLimayeNimbhorkar'08]. This\nis achieved by using the above decomposition, and by making significant\nmodifications to Lindell's algorithm for tree canonization, along with changes\nin the space complexity analysis.\n  The reduction from the connected case to the biconnected case requires\nfurther new ideas, including a non-trivial case analysis and a group theoretic\nlemma to bound the number of automorphisms of a colored 3-connected planar\ngraph. This lemma is crucial for the reduction to work in logspace."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0809.3614v1", 
    "title": "Improved Monotone Circuit Depth Upper Bound for Directed Graph   Reachability", 
    "arxiv-id": "0809.3614v1", 
    "author": "Sergey Volkov", 
    "publish": "2008-09-22T15:14:06Z", 
    "summary": "We prove that the directed graph reachability problem (transitive closure)\ncan be solved by monotone fan-in 2 boolean circuits of depth (1/2+o(1))(log\nn)^2, where n is the number of nodes. This improves the previous known upper\nbound (1+o(1))(log n)^2. The proof is non-constructive, but we give a\nconstructive proof of the upper bound (7/8+o(1))(log n)^2."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0810.1018v1", 
    "title": "A simple constant-probability RP reduction from NP to Parity P", 
    "arxiv-id": "0810.1018v1", 
    "author": "Alexander Russell", 
    "publish": "2008-10-06T17:23:06Z", 
    "summary": "The proof of Toda's celebrated theorem that the polynomial hierarchy is\ncontained in $\\P^{# P}$ relies on the fact that, under mild technical\nconditions on the complexity class $C$, we have $\\exists C \\subset BP \\cdot\n\\oplus C$. More concretely, there is a randomized reduction which transforms\nnonempty sets and the empty set, respectively, into sets of odd or even size.\nThe customary method is to invoke Valiant's and Vazirani's randomized reduction\nfrom NP to UP, followed by amplification of the resulting success probability\nfrom $1/\\poly(n)$ to a constant by combining the parities of $\\poly(n)$ trials.\nHere we give a direct algebraic reduction which achieves constant success\nprobability without the need for amplification. Our reduction is very simple,\nand its analysis relies on well-known properties of the Legendre symbol in\nfinite fields."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0810.4249v1", 
    "title": "Ogden's Lemma for Regular Tree Languages", 
    "arxiv-id": "0810.4249v1", 
    "author": "Marco Kuhlmann", 
    "publish": "2008-10-23T19:43:26Z", 
    "summary": "We motivate and prove a strong pumping lemma for regular tree languages. The\nnew lemma can be seen as the natural correspondent of Ogden's lemma for\ncontext-free string languages."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0811.0463v2", 
    "title": "Solving the P/NP Problem under Intrinsic Uncertainty", 
    "arxiv-id": "0811.0463v2", 
    "author": "Stefan Jaeger", 
    "publish": "2008-11-04T10:08:47Z", 
    "summary": "Heisenberg's uncertainty principle states that it is not possible to compute\nboth the position and momentum of an electron with absolute certainty. However,\nthis computational limitation, which is central to quantum mechanics, has no\ncounterpart in theoretical computer science. Here, I will show that we can\ndistinguish between the complexity classes P and NP when we consider intrinsic\nuncertainty in our computations, and take uncertainty about whether a bit\nbelongs to the program code or machine input into account. Given intrinsic\nuncertainty, every output is uncertain, and computations become meaningful only\nin combination with a confidence level. In particular, it is impossible to\ncompute solutions with absolute certainty as this requires infinite run-time.\nConsidering intrinsic uncertainty, I will present a function that is in NP but\nnot in P, and thus prove that P is a proper subset of NP. I will also show that\nall traditional hard decision problems have polynomial-time algorithms that\nprovide solutions with confidence under uncertainty."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0811.0987v1", 
    "title": "Modular difference logic is hard", 
    "arxiv-id": "0811.0987v1", 
    "author": "Madan Musuvathi", 
    "publish": "2008-11-06T19:52:45Z", 
    "summary": "In connection with machine arithmetic, we are interested in systems of\nconstraints of the form x + k \\leq y + k'. Over integers, the satisfiability\nproblem for such systems is polynomial time. The problem becomes NP complete if\nwe restrict attention to the residues for a fixed modulus N."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0811.2586v1", 
    "title": "On models of a nondeterministic computation", 
    "arxiv-id": "0811.2586v1", 
    "author": "M. N. Vyalyi", 
    "publish": "2008-11-16T16:22:11Z", 
    "summary": "In this paper we consider a nondeterministic computation by deterministic\nmulti-head 2-way automata having a read-only access to an auxiliary memory. The\nmemory contains additional data (a guess) and computation is successful iff it\nis successful for some memory content. Also we consider the case of restricted\nguesses in which a guess should satisfy some constraint. We show that the\nstandard complexity classes such as L, NL, P, NP, PSPACE can be characterized\nin terms of these models of nondeterministic computation. These\ncharacterizations differ from the well-known ones by absence of alternation."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0811.3161v1", 
    "title": "An Almost Optimal Rank Bound for Depth-3 Identities", 
    "arxiv-id": "0811.3161v1", 
    "author": "C. Seshadhri", 
    "publish": "2008-11-19T17:41:06Z", 
    "summary": "We show that the rank of a depth-3 circuit (over any field) that is simple,\nminimal and zero is at most k^3\\log d. The previous best rank bound known was\n2^{O(k^2)}(\\log d)^{k-2} by Dvir and Shpilka (STOC 2005). This almost resolves\nthe rank question first posed by Dvir and Shpilka (as we also provide a simple\nand minimal identity of rank \\Omega(k\\log d)).\n  Our rank bound significantly improves (dependence on k exponentially reduced)\nthe best known deterministic black-box identity tests for depth-3 circuits by\nKarnin and Shpilka (CCC 2008). Our techniques also shed light on the\nfactorization pattern of nonzero depth-3 circuits, most strikingly: the rank of\nlinear factors of a simple, minimal and nonzero depth-3 circuit (over any\nfield) is at most k^3\\log d.\n  The novel feature of this work is a new notion of maps between sets of linear\nforms, called \"ideal matchings\", used to study depth-3 circuits. We prove\ninteresting structural results about depth-3 identities using these techniques.\nWe believe that these can lead to the goal of a deterministic polynomial time\nidentity test for these circuits."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0811.3859v1", 
    "title": "On the Complexity of Matroid Isomorphism Problem", 
    "arxiv-id": "0811.3859v1", 
    "author": "Jayalal M. N. Sarma", 
    "publish": "2008-11-24T14:19:02Z", 
    "summary": "We study the complexity of testing if two given matroids are isomorphic. The\nproblem is easily seen to be in $\\Sigma_2^p$. In the case of linear matroids,\nwhich are represented over polynomially growing fields, we note that the\nproblem is unlikely to be $\\Sigma_2^p$-complete and is $\\co\\NP$-hard. We show\nthat when the rank of the matroid is bounded by a constant, linear matroid\nisomorphism, and matroid isomorphism are both polynomial time many-one\nequivalent to graph isomorphism. We give a polynomial time Turing reduction\nfrom graphic matroid isomorphism problem to the graph isomorphism problem.\nUsing this, we are able to show that graphic matroid isomorphism testing for\nplanar graphs can be done in deterministic polynomial time. We then give a\npolynomial time many-one reduction from bounded rank matroid isomorphism\nproblem to graphic matroid isomorphism, thus showing that all the above\nproblems are polynomial time equivalent. Further, for linear and graphic\nmatroids, we prove that the automorphism problem is polynomial time equivalent\nto the corresponding isomorphism problems. In addition, we give a polynomial\ntime membership test algorithm for the automorphism group of a graphic matroid."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0811.3958v1", 
    "title": "Extractors and an efficient variant of Muchnik's theorem", 
    "arxiv-id": "0811.3958v1", 
    "author": "Daniil Musatov", 
    "publish": "2008-11-24T20:49:50Z", 
    "summary": "Muchnik's theorem about simple conditional descriprion states that for all\nwords $a$ and $b$ there exists a short program $p$ transforming $a$ to $b$ that\nhas the least possible length and is simple conditional on $b$. This paper\npresents a new proof of this theorem, based on extractors. Employing the\nextractor technique, two new versions of Muchnik's theorem for space- and\ntime-bounded Kolmogorov complexity are proven."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0812.0852v3", 
    "title": "Hierarchy and equivalence of multi-letter quantum finite automata", 
    "arxiv-id": "0812.0852v3", 
    "author": "Sheng Yu", 
    "publish": "2008-12-04T03:10:29Z", 
    "summary": "Multi-letter {\\it quantum finite automata} (QFAs) were a new one-way QFA\nmodel proposed recently by Belovs, Rosmanis, and Smotrovs (LNCS, Vol. 4588,\nSpringer, Berlin, 2007, pp. 60-71), and they showed that multi-letter QFAs can\naccept with no error some regular languages ($(a+b)^{*}b$) that are\nunacceptable by the one-way QFAs. In this paper, we continue to study\nmulti-letter QFAs. We mainly focus on two issues: (1) we show that\n$(k+1)$-letter QFAs are computationally more powerful than $k$-letter QFAs,\nthat is, $(k+1)$-letter QFAs can accept some regular languages that are\nunacceptable by any $k$-letter QFA. A comparison with the one-way QFAs is made\nby some examples; (2) we prove that a $k_{1}$-letter QFA ${\\cal A}_1$ and\nanother $k_{2}$-letter QFA ${\\cal A}_2$ are equivalent if and only if they are\n$(n_{1}+n_{2})^{4}+k-1$-equivalent, and the time complexity of determining the\nequivalence of two multi-letter QFAs using this method is\n$O(n^{12}+k^{2}n^{4}+kn^{8})$, where $n_{1}$ and $n_{2}$ are the numbers of\nstates of ${\\cal A}_{1}$ and ${\\cal A}_{2}$, respectively, and\n$k=\\max(k_{1},k_{2})$. Some other issues are addressed for further\nconsideration."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0812.1601v4", 
    "title": "Scarf is Ppad-Complete", 
    "arxiv-id": "0812.1601v4", 
    "author": "Shiva Kintali", 
    "publish": "2008-12-09T01:07:25Z", 
    "summary": "Scarf's lemma is one of the fundamental results in combinatorics, originally\nintroduced to study the core of an N-person game. Over the last four decades,\nthe usefulness of Scarf's lemma has been demonstrated in several important\ncombinatorial problems seeking \"stable\" solutions. However, the complexity of\nthe computational version of Scarf's lemma (SCARF) remained open. In this\npaper, we prove that SCARF is complete for the complexity class PPAD. This\nproves that SCARF is as hard as the computational versions of Brouwer's fixed\npoint theorem and Sperner's lemma. Hence, there is no polynomial-time algorithm\nfor SCARF unless PPAD \\subseteq P. We also show that fractional stable paths\nproblem and finding strong fractional kernels in digraphs are PPAD-hard."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0812.3214v2", 
    "title": "Two conjectures such that the proof of any one of them will lead to the   proof that P = NP", 
    "arxiv-id": "0812.3214v2", 
    "author": "Malay Dutta", 
    "publish": "2008-12-17T07:03:53Z", 
    "summary": "In this paper we define a construct called a time-graph. A complete\ntime-graph of order n is the cartesian product of a complete graph with n\nvertices and a linear graph with n vertices. A time-graph of order n is given\nby a subset of the set of edges E(n) of such a graph. The notion of a\nhamiltonian time-graph is defined in a natural way and we define the\nHamiltonian time-graph problem (HAMTG) as : Given a time-graph is it\nhamiltonian ? We show that the Hamiltonian path problem (HAMP) can be\ntransformed to HAMTG in polynomial time. We then define certain vector spaces\nof functions from E(n) and E(n)xE(n) to B = {0,1}, the field of two elements\nand derive certain properties of these spaces. We give two conjectures about\nthese spaces and prove that if any one of these conjectures is true, we get a\npolynomial time algorithm for the Hamiltonian path problem. Since the\nHamiltonian path problem is NP-complete we obtain the proof of P = NP provided\nany one of the two conjectures is true."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0812.4009v21", 
    "title": "Graph Field Automata", 
    "arxiv-id": "0812.4009v21", 
    "author": "Keith David Pedersen", 
    "publish": "2008-12-22T00:26:29Z", 
    "summary": "The Graph Automata have been the paradigm in the expression of utilizing\nGraphs as a language. Matrix Graph grammars \\cite{Pedro} are an algebratization\nof graph rewriting systems. Here we present the dual of this formalizm which\nsome extensions which we term Graph Field Automata The advantage to this\napproach is a framework for expressing machines that can use Matrix Graph\nGrammars."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0901.2703v2", 
    "title": "Language recognition by generalized quantum finite automata with   unbounded error (abstract & poster)", 
    "arxiv-id": "0901.2703v2", 
    "author": "A. C. Cem Say", 
    "publish": "2009-01-18T13:33:21Z", 
    "summary": "In this note, we generalize the results of arXiv:0901.2703v1 We show that all\none-way quantum finite automaton (QFA) models that are at least as general as\nKondacs-Watrous QFA's are equivalent in power to classical probabilistic finite\nautomata in this setting. Unlike their probabilistic counterparts, allowing the\ntape head to stay put for some steps during its traversal of the input does\nenlarge the class of languages recognized by such QFA's with unbounded error.\n(Note that, the proof of Theorem 1 in the abstract was presented in the\nprevious version (arXiv:0901.2703v1).)"
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0901.2906v1", 
    "title": "Measuring communication complexity using instance complexity with   oracles", 
    "arxiv-id": "0901.2906v1", 
    "author": "Andre Souto", 
    "publish": "2009-01-19T18:00:37Z", 
    "summary": "We establish a connection between non-deterministic communication complexity\nand instance complexity, a measure of information based on algorithmic entropy.\nLet $\\overline{x}$, $\\overline{y}$ and $Y_1(\\overline{x})$ be respectively the\ninput known by Alice, the input known by Bob, and the set of all values of $y$\nsuch that $f(\\overline{x},y)=1$; a string is a witness of the non-deterministic\ncommunication protocol iff it is a program $p$ that \"corresponds exactly\" to\nthe instance complexity $\\ic^{f,t}(\\overline{y}:Y_1(\\overline{x}))$."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0902.0047v1", 
    "title": "Bounds on the Size of Small Depth Circuits for Approximating Majority", 
    "arxiv-id": "0902.0047v1", 
    "author": "Kazuyuki Amano", 
    "publish": "2009-01-31T04:22:52Z", 
    "summary": "In this paper, we show that for every constant $0 < \\epsilon < 1/2$ and for\nevery constant $d \\geq 2$, the minimum size of a depth $d$ Boolean circuit that\n$\\epsilon$-approximates Majority function on $n$ variables is\nexp$(\\Theta(n^{1/(2d-2)}))$. The lower bound for every $d \\geq 2$ and the upper\nbound for $d=2$ have been previously shown by O'Donnell and Wimmer [ICALP'07],\nand the contribution of this paper is to give a matching upper bound for $d\n\\geq 3$."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0902.1609v1", 
    "title": "Asymptotically Optimal Lower Bounds on the NIH-Multi-Party Information", 
    "arxiv-id": "0902.1609v1", 
    "author": "Andr\u00e9 Gronemeier", 
    "publish": "2009-02-10T09:13:26Z", 
    "summary": "Here we prove an asymptotically optimal lower bound on the information\ncomplexity of the k-party disjointness function with the unique intersection\npromise, an important special case of the well known disjointness problem, and\nthe ANDk-function in the number in the hand model. Our (n/k) bound for\ndisjointness improves on an earlier (n/(k log k)) bound by Chakrabarti et al.\n(2003), who obtained an asymptotically tight lower bound for one-way protocols,\nbut failed to do so for the general case. Our result eliminates both the gap\nbetween the upper and the lower bound for unrestricted protocols and the gap\nbetween the lower bounds for one-way protocols and unrestricted protocols."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0902.1835v2", 
    "title": "Polynomial Kernelizations for MIN F^+Pi_1 and MAX NP", 
    "arxiv-id": "0902.1835v2", 
    "author": "Stefan Kratsch", 
    "publish": "2009-02-11T10:19:38Z", 
    "summary": "It has been observed in many places that constant-factor approximable\nproblems often admit polynomial or even linear problem kernels for their\ndecision versions, e.g., Vertex Cover, Feedback Vertex Set, and Triangle\nPacking. While there exist examples like Bin Packing, which does not admit any\nkernel unless P = NP, there apparently is a strong relation between these two\npolynomial-time techniques. We add to this picture by showing that the natural\ndecision versions of all problems in two prominent classes of constant-factor\napproximable problems, namely MIN F^+\\Pi_1 and MAX NP, admit polynomial problem\nkernels. Problems in MAX SNP, a subclass of MAX NP, are shown to admit kernels\nwith a linear base set, e.g., the set of vertices of a graph. This extends\nresults of Cai and Chen (JCSS 1997), stating that the standard\nparameterizations of problems in MAX SNP and MIN F^+\\Pi_1 are fixed-parameter\ntractable, and complements recent research on problems that do not admit\npolynomial kernelizations (Bodlaender et al. JCSS 2009)."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0902.1866v1", 
    "title": "A Superpolynomial Lower Bound on the Size of Uniform Non-constant-depth   Threshold Circuits for the Permanent", 
    "arxiv-id": "0902.1866v1", 
    "author": "Sylvain Perifel", 
    "publish": "2009-02-11T12:39:25Z", 
    "summary": "We show that the permanent cannot be computed by DLOGTIME-uniform threshold\nor arithmetic circuits of depth o(log log n) and polynomial size."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0902.2081v2", 
    "title": "Languages recognized by nondeterministic quantum finite automata", 
    "arxiv-id": "0902.2081v2", 
    "author": "A. C. Cem Say", 
    "publish": "2009-02-12T10:59:09Z", 
    "summary": "The nondeterministic quantum finite automaton (NQFA) is the only known case\nwhere a one-way quantum finite automaton (QFA) model has been shown to be\nstrictly superior in terms of language recognition power to its probabilistic\ncounterpart. We give a characterization of the class of languages recognized by\nNQFA's, demonstrating that it is equal to the class of exclusive stochastic\nlanguages. We also characterize the class of languages that are recognized\nnecessarily by two-sided error by QFA's. It is shown that these classes remain\nthe same when the QFA's used in their definitions are replaced by several\ndifferent model variants that have appeared in the literature. We prove several\nclosure properties of the related classes. The ramifications of these results\nabout classical and quantum sublogarithmic space complexity classes are\nexamined."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2009.33", 
    "link": "http://arxiv.org/pdf/0902.2146v1", 
    "title": "A Stronger LP Bound for Formula Size Lower Bounds via Clique Constraints", 
    "arxiv-id": "0902.2146v1", 
    "author": "Kenya Ueno", 
    "publish": "2009-02-12T16:01:09Z", 
    "summary": "We introduce a new technique proving formula size lower bounds based on the\nlinear programming bound originally introduced by Karchmer, Kushilevitz and\nNisan [11] and the theory of stable set polytope. We apply it to majority\nfunctions and prove their formula size lower bounds improved from the classical\nresult of Khrapchenko [13]. Moreover, we introduce a notion of unbalanced\nrecursive ternary majority functions motivated by a decomposition theory of\nmonotone self-dual functions and give integrally matching upper and lower\nbounds of their formula size. We also show monotone formula size lower bounds\nof balanced recursive ternary majority functions improved from the quantum\nadversary bound of Laplante, Lee and Szegedy [15]."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0902.2300v2", 
    "title": "A Dichotomy Theorem for Polynomial Evaluation", 
    "arxiv-id": "0902.2300v2", 
    "author": "Pascal Koiran", 
    "publish": "2009-02-13T12:34:27Z", 
    "summary": "A dichotomy theorem for counting problems due to Creignou and Hermann states\nthat or any nite set S of logical relations, the counting problem #SAT(S) is\neither in FP, or #P-complete. In the present paper we show a dichotomy theorem\nfor polynomial evaluation. That is, we show that for a given set S, either\nthere exists a VNP-complete family of polynomials associated to S, or the\nassociated families of polynomials are all in VP. We give a concise\ncharacterization of the sets S that give rise to \"easy\" and \"hard\" polynomials.\nWe also prove that several problems which were known to be #P-complete under\nTuring reductions only are in fact #P-complete under many-one reductions."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0902.2674v4", 
    "title": "Inseparability and Strong Hypotheses for Disjoint NP Pairs", 
    "arxiv-id": "0902.2674v4", 
    "author": "Elvira Mayordomo", 
    "publish": "2009-02-16T12:27:54Z", 
    "summary": "This paper investigates the existence of inseparable disjoint pairs of NP\nlanguages and related strong hypotheses in computational complexity. Our main\ntheorem says that, if NP does not have measure 0 in EXP, then there exist\ndisjoint pairs of NP languages that are P-inseparable, in fact\nTIME(2^(n^k))-inseparable. We also relate these conditions to strong hypotheses\nconcerning randomness and genericity of disjoint pairs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0902.3757v1", 
    "title": "Bounded Independence Fools Halfspaces", 
    "arxiv-id": "0902.3757v1", 
    "author": "Emanuele Viola", 
    "publish": "2009-02-21T21:01:21Z", 
    "summary": "We show that any distribution on {-1,1}^n that is k-wise independent fools\nany halfspace h with error \\eps for k = O(\\log^2(1/\\eps) /\\eps^2). Up to\nlogarithmic factors, our result matches a lower bound by Benjamini,\nGurel-Gurevich, and Peled (2007) showing that k = \\Omega(1/(\\eps^2 \\cdot\n\\log(1/\\eps))). Using standard constructions of k-wise independent\ndistributions, we obtain the first explicit pseudorandom generators G: {-1,1}^s\n--> {-1,1}^n that fool halfspaces. Specifically, we fool halfspaces with error\neps and seed length s = k \\log n = O(\\log n \\cdot \\log^2(1/\\eps) /\\eps^2).\n  Our approach combines classical tools from real approximation theory with\nstructural results on halfspaces by Servedio (Computational Complexity 2007)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0903.0050v2", 
    "title": "Succinctness of two-way probabilistic and quantum finite automata", 
    "arxiv-id": "0903.0050v2", 
    "author": "A. C. Cem Say", 
    "publish": "2009-02-28T07:33:50Z", 
    "summary": "We prove that two-way probabilistic and quantum finite automata (2PFA's and\n2QFA's) can be considerably more concise than both their one-way versions\n(1PFA's and 1QFA's), and two-way nondeterministic finite automata (2NFA's). For\nthis purpose, we demonstrate several infinite families of regular languages\nwhich can be recognized with some fixed probability greater than $ {1/2} $ by\njust tuning the transition amplitudes of a 2QFA (and, in one case, a 2PFA) with\na constant number of states, whereas the sizes of the corresponding 1PFA's,\n1QFA's and 2NFA's grow without bound. We also show that 2QFA's with mixed\nstates can support highly efficient probability amplification. The weakest\nknown model of computation where quantum computers recognize more languages\nwith bounded error than their classical counterparts is introduced."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0903.4728v2", 
    "title": "Graph Homomorphisms with Complex Values: A Dichotomy Theorem", 
    "arxiv-id": "0903.4728v2", 
    "author": "Pinyan Lu", 
    "publish": "2009-03-27T02:57:32Z", 
    "summary": "Graph homomorphism has been studied intensively. Given an m x m symmetric\nmatrix A, the graph homomorphism function is defined as \\[Z_A (G) =\n\\sum_{f:V->[m]} \\prod_{(u,v)\\in E} A_{f(u),f(v)}, \\] where G = (V,E) is any\nundirected graph. The function Z_A can encode many interesting graph\nproperties, including counting vertex covers and k-colorings. We study the\ncomputational complexity of Z_A for arbitrary symmetric matrices A with\nalgebraic complex values. Building on work by Dyer and Greenhill, Bulatov and\nGrohe, and especially the recent beautiful work by Goldberg, Grohe, Jerrum and\nThurley, we prove a complete dichotomy theorem for this problem. We show that\nZ_A is either computable in polynomial-time or #P-hard, depending explicitly on\nthe matrix A. We further prove that the tractability criterion on A is\npolynomial-time decidable."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0904.0698v3", 
    "title": "About the impossibility to prove P=NP and the pseudo-randomness in NP", 
    "arxiv-id": "0904.0698v3", 
    "author": "M. R\u00e9mon", 
    "publish": "2009-04-04T09:16:04Z", 
    "summary": "The relationship between the complexity classes P and NP is an unsolved\nquestion in the field of theoretical computer science. In this paper, we look\nat the link between the P - NP question and the \"Deterministic\" versus \"Non\nDeterministic\" nature of a problem, and more specifically at the temporal\nnature of the complexity within the NP class of problems. Let us remind that\nthe NP class is called the class of \"Non Deterministic Polynomial\" languages.\nUsing the meta argument that results in Mathematics should be \"time\nindependent\" as they are reproducible, the paper shows that the P!=NP assertion\nis impossible to prove in the a-temporal framework of Mathematics. In a\nprevious version of the report, we use a similar argument based on randomness\nto show that the P = NP assertion was also impossible to prove, but this part\nof the paper was shown to be incorrect. So, this version deletes it. In fact,\nthis paper highlights the time dependence of the complexity for any NP problem,\nlinked to some pseudo-randomness in its heart."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0904.3116v4", 
    "title": "Variations on Muchnik's Conditional Complexity Theorem", 
    "arxiv-id": "0904.3116v4", 
    "author": "Alexander Shen", 
    "publish": "2009-04-20T21:05:09Z", 
    "summary": "Muchnik's theorem about simple conditional descriptions states that for all\nstrings $a$ and $b$ there exists a short program $p$ transforming $a$ to $b$\nthat has the least possible length and is simple conditional on $b$. In this\npaper we present two new proofs of this theorem. The first one is based on the\non-line matching algorithm for bipartite graphs. The second one, based on\nextractors, can be generalized to prove a version of Muchnik's theorem for\nspace-bounded Kolmogorov complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0904.3912v2", 
    "title": "Refutation of Aslam's Proof that NP = P", 
    "arxiv-id": "0904.3912v2", 
    "author": "Andrew Wood", 
    "publish": "2009-04-24T18:01:54Z", 
    "summary": "Aslam presents an algorithm he claims will count the number of perfect\nmatchings in any incomplete bipartite graph with an algorithm in the\nfunction-computing version of NC, which is itself a subset of FP. Counting\nperfect matchings is known to be #P-complete; therefore if Aslam's algorithm is\ncorrect, then NP=P. However, we show that Aslam's algorithm does not correctly\ncount the number of perfect matchings and offer an incomplete bipartite graph\nas a concrete counter-example."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7", 
    "link": "http://arxiv.org/pdf/0904.3927v1", 
    "title": "A Critique of \"Solving the P/NP Problem Under Intrinsic Uncertainty\",   arXiv:0811.0463", 
    "arxiv-id": "0904.3927v1", 
    "author": "Cole Arthur Brown", 
    "publish": "2009-04-24T19:32:10Z", 
    "summary": "Although whether P equals NP is an important, open problem in computer\nscience, and although Jaeger's 2008 paper, \"Solving the P/NP Problem Under\nIntrinsic Uncertainty\" (arXiv:0811.0463) presents an attempt at tackling the\nproblem by discussing the possibility that all computation is uncertain to some\ndegree, there are a number of logical oversights present in that paper which\npreclude it from serious consideration toward having resolved P-versus-NP.\nThere are several differences between the model of computation presented in\nJaeger's paper and the standard model, as well as several bold assumptions that\nare not well supported in Jaeger's paper or in the literature. In addition, we\nfind several omissions of rigorous proof that ultimately weaken this paper to a\npoint where it cannot be considered a candidate solution to the P-versus-NP\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03816-7_26", 
    "link": "http://arxiv.org/pdf/0904.3941v1", 
    "title": "Representating groups on graphs", 
    "arxiv-id": "0904.3941v1", 
    "author": "Piyush P Kurur", 
    "publish": "2009-04-24T20:39:59Z", 
    "summary": "In this paper we formulate and study the problem of representing groups on\ngraphs. We show that with respect to polynomial time turing reducibility, both\nabelian and solvable group representability are all equivalent to graph\nisomorphism, even when the group is presented as a permutation group via\ngenerators. On the other hand, the representability problem for general groups\non trees is equivalent to checking, given a group $G$ and $n$, whether a\nnontrivial homomorphism from $G$ to $S_n$ exists. There does not seem to be a\npolynomial time algorithm for this problem, in spite of the fact that tree\nisomorphism has polynomial time algorithm."
},{
    "category": "cs.CC", 
    "doi": "10.5402/2012/321372", 
    "link": "http://arxiv.org/pdf/0906.1084v1", 
    "title": "Physical portrayal of computational complexity", 
    "arxiv-id": "0906.1084v1", 
    "author": "Arto Annila", 
    "publish": "2009-06-05T10:56:00Z", 
    "summary": "Computational complexity is examined using the principle of increasing\nentropy. To consider computation as a physical process from an initial instance\nto the final acceptance is motivated because many natural processes have been\nrecognized to complete in non-polynomial time (NP). The irreversible process\nwith three or more degrees of freedom is found intractable because, in terms of\nphysics, flows of energy are inseparable from their driving forces. In\ncomputational terms, when solving problems in the class NP, decisions will\naffect subsequently available sets of decisions. The state space of a\nnon-deterministic finite automaton is evolving due to the computation itself\nhence it cannot be efficiently contracted using a deterministic finite\nautomaton that will arrive at a solution in super-polynomial time. The solution\nof the NP problem itself is verifiable in polynomial time (P) because the\ncorresponding state is stationary. Likewise the class P set of states does not\ndepend on computational history hence it can be efficiently contracted to the\naccepting state by a deterministic sequence of dissipative transformations.\nThus it is concluded that the class P set of states is inherently smaller than\nthe set of class NP. Since the computational time to contract a given set is\nproportional to dissipation, the computational complexity class P is a subset\nof NP."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.1.10", 
    "link": "http://arxiv.org/pdf/0906.3119v1", 
    "title": "Computational Power of P Systems with Small Size Insertion and Deletion   Rules", 
    "arxiv-id": "0906.3119v1", 
    "author": "Sergey Verlan", 
    "publish": "2009-06-17T14:44:01Z", 
    "summary": "Recent investigations show insertion-deletion systems of small size that are\nnot complete and cannot generate all recursively enumerable languages. However,\nif additional computational distribution mechanisms like P systems are added,\nthen the computational completeness is achieved in some cases. In this article\nwe take two insertion-deletion systems that are not computationally complete,\nconsider them in the framework of P systems and show that the computational\npower is strictly increased by proving that any recursively enumerable language\ncan be generated. At the end some open problems are presented."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.1.10", 
    "link": "http://arxiv.org/pdf/0906.3162v1", 
    "title": "Are stable instances easy?", 
    "arxiv-id": "0906.3162v1", 
    "author": "Nathan Linial", 
    "publish": "2009-06-17T12:43:41Z", 
    "summary": "We introduce the notion of a stable instance for a discrete optimization\nproblem, and argue that in many practical situations only sufficiently stable\ninstances are of interest. The question then arises whether stable instances of\nNP--hard problems are easier to solve. In particular, whether there exist\nalgorithms that solve correctly and in polynomial time all sufficiently stable\ninstances of some NP--hard problem. The paper focuses on the Max--Cut problem,\nfor which we show that this is indeed the case."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.1.16", 
    "link": "http://arxiv.org/pdf/0906.3186v1", 
    "title": "A General Notion of Useful Information", 
    "arxiv-id": "0906.3186v1", 
    "author": "Philippe Moser", 
    "publish": "2009-06-17T14:09:03Z", 
    "summary": "In this paper we introduce a general framework for defining the depth of a\nsequence with respect to a class of observers. We show that our general\nframework captures all depth notions introduced in complexity theory so far. We\nreview most such notions, show how they are particular cases of our general\ndepth framework, and review some classical results about the different depth\nnotions."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.1.23", 
    "link": "http://arxiv.org/pdf/0906.3231v1", 
    "title": "New Choice for Small Universal Devices: Symport/Antiport P Systems", 
    "arxiv-id": "0906.3231v1", 
    "author": "Yurii Rogozhin", 
    "publish": "2009-06-17T16:14:54Z", 
    "summary": "Symport/antiport P systems provide a very simple machinery inspired by\ncorresponding operations in the living cell. It turns out that systems of small\ndescriptional complexity are needed to achieve the universality by these\nsystems. This makes them a good candidate for small universal devices replacing\nregister machines for different simulations, especially when a simulating\nparallel machinery is involved. This article contains survey of these systems\nand presents different trade-offs between parameters."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.1.6", 
    "link": "http://arxiv.org/pdf/0906.3251v1", 
    "title": "Limitations of Self-Assembly at Temperature One (extended abstract)", 
    "arxiv-id": "0906.3251v1", 
    "author": "Scott M. Summers", 
    "publish": "2009-06-17T17:06:51Z", 
    "summary": "We prove that if a subset X of the integer Cartesian plane weakly\nself-assembles at temperature 1 in a deterministic (Winfree) tile assembly\nsystem satisfying a natural condition known as *pumpability*, then X is a\nfinite union of doubly periodic sets. This shows that only the most simple of\ninfinite shapes and patterns can be constructed using pumpable temperature 1\ntile assembly systems, and gives strong evidence for the thesis that\ntemperature 2 or higher is required to carry out general-purpose computation in\na tile assembly system. Finally, we show that general-purpose computation is\npossible at temperature 1 if negative glue strengths are allowed in the tile\nassembly model."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.1.21", 
    "link": "http://arxiv.org/pdf/0906.3306v1", 
    "title": "Self-Assembly of Infinite Structures", 
    "arxiv-id": "0906.3306v1", 
    "author": "Scott M. Summers", 
    "publish": "2009-06-17T20:33:07Z", 
    "summary": "We review some recent results related to the self-assembly of infinite\nstructures in the Tile Assembly Model. These results include impossibility\nresults, as well as novel tile assembly systems in which shapes and patterns\nthat represent various notions of computation self-assemble. Several open\nquestions are also presented and motivated."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0906.3765v3", 
    "title": "Speedup for Natural Problems and Noncomputability", 
    "arxiv-id": "0906.3765v3", 
    "author": "Hunter Monroe", 
    "publish": "2009-06-20T02:58:26Z", 
    "summary": "A resource-bounded version of the statement \"no algorithm recognizes all\nnon-halting Turing machines\" is equivalent to an infinitely often (i.o.)\nsuperpolynomial speedup for the time required to accept any coNP-complete\nlanguage and also equivalent to a superpolynomial speedup in proof length in\npropositional proof systems for tautologies, each of which implies P!=NP. This\nsuggests a correspondence between the properties 'has no algorithm at all' and\n'has no best algorithm' which seems relevant to open problems in computational\nand proof complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0906.4431v4", 
    "title": "The Complexity of Probabilistic Lobbying", 
    "arxiv-id": "0906.4431v4", 
    "author": "J\u00f6rg Rothe", 
    "publish": "2009-06-24T10:14:13Z", 
    "summary": "We propose models for lobbying in a probabilistic environment, in which an\nactor (called \"The Lobby\") seeks to influence voters' preferences of voting for\nor against multiple issues when the voters' preferences are represented in\nterms of probabilities. In particular, we provide two evaluation criteria and\ntwo bribery methods to formally describe these models, and we consider the\nresulting forms of lobbying with and without issue weighting. We provide a\nformal analysis for these problems of lobbying in a stochastic environment, and\ndetermine their classical and parameterized complexity depending on the given\nbribery/evaluation criteria and on various natural parameterizations.\nSpecifically, we show that some of these problems can be solved in polynomial\ntime, some are NP-complete but fixed-parameter tractable, and some are\nW[2]-complete. Finally, we provide approximability and inapproximability\nresults for these problems and several variants."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0906.5112v3", 
    "title": "Response to Refutation of Aslam's Proof that NP = P", 
    "arxiv-id": "0906.5112v3", 
    "author": "Javaid Aslam", 
    "publish": "2009-06-28T16:07:06Z", 
    "summary": "This paper provides a further refinement to the previous response by\nintroducing new structures and algorithms for counting VMPs of common ER and\nhence for counting the perfect matchings. The sequential time complexity of\nthis $\\mathbf{\\#P}$-complete problem is shown to be $O(n^{33})$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.0691v1", 
    "title": "On the complexity of deciding whether the distinguishing chromatic   number of a graph is at most two", 
    "arxiv-id": "0907.0691v1", 
    "author": "Lorna Stewart", 
    "publish": "2009-07-03T18:34:38Z", 
    "summary": "In an article [3] published recently in this journal, it was shown that when\nk >= 3, the problem of deciding whether the distinguishing chromatic number of\na graph is at most k is NP-hard. We consider the problem when k = 2. In regards\nto the issue of solvability in polynomial time, we show that the problem is at\nleast as hard as graph automorphism but no harder than graph isomorphism."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.1307v1", 
    "title": "Reducing Tile Complexity for the Self-Assembly of Scaled Shapes Through   Temperature Programming", 
    "arxiv-id": "0907.1307v1", 
    "author": "Scott M. Summers", 
    "publish": "2009-07-07T21:37:11Z", 
    "summary": "This paper concerns the self-assembly of scaled-up versions of arbitrary\nfinite shapes. We work in the multiple temperature model that was introduced by\nAggarwal, Cheng, Goldwasser, Kao, and Schweller (Complexities for Generalized\nModels of Self-Assembly, SODA 2004). The multiple temperature model is a\nnatural generalization of Winfree's abstract tile assembly model, where the\ntemperature of a tile system is allowed to be shifted up and down as\nself-assembly proceeds. We first exhibit two constant-size tile sets in which\nscaled-up versions of arbitrary shapes self-assemble. Our first tile set has\nthe property that each scaled shape self-assembles via an asymptotically\n\"Kolmogorov-optimum\" temperature sequence but the scaling factor grows with the\nsize of the shape being assembled. In contrast, our second tile set assembles\neach scaled shape via a temperature sequence whose length is proportional to\nthe number of points in the shape but the scaling factor is a constant\nindependent of the shape being assembled. We then show that there is no\nconstant-size tile set that can uniquely assemble an arbitrary (non-scaled,\nconnected) shape in the multiple temperature model, i.e., the scaling is\nnecessary for self-assembly. This answers an open question of Kao and Schweller\n(Reducing Tile Complexity for Self-Assembly Through Temperature Programming,\nSODA 2006), who asked whether such a tile set existed."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.2324v1", 
    "title": "Separations of non-monotonic randomness notions", 
    "arxiv-id": "0907.2324v1", 
    "author": "Wolfgang Merkle", 
    "publish": "2009-07-14T10:41:08Z", 
    "summary": "In the theory of algorithmic randomness, several notions of random sequence\nare defined via a game-theoretic approach, and the notions that received most\nattention are perhaps Martin-Loef randomness and computable randomness. The\nlatter notion was introduced by Schnorr and is rather natural: an infinite\nbinary sequence is computably random if no total computable strategy succeeds\non it by betting on bits in order. However, computably random sequences can\nhave properties that one may consider to be incompatible with being random, in\nparticular, there are computably random sequences that are highly compressible.\nThe concept of Martin-Loef randomness is much better behaved in this and other\nrespects, on the other hand its definition in terms of martingales is\nconsiderably less natural. Muchnik, elaborating on ideas of Kolmogorov and\nLoveland, refined Schnorr's model by also allowing non-monotonic strategies,\ni.e. strategies that do not bet on bits in order. The subsequent\n``non-monotonic'' notion of randomness, now called Kolmogorov-Loveland\nrandomness, has been shown to be quite close to Martin-Loef randomness, but\nwhether these two classes coincide remains a fundamental open question. As\nsuggested by Miller and Nies, we study in this paper weak versions of\nKolmogorov-Loveland randomness, where the betting strategies are non-adaptive\n(i.e., the positions of the bits to bet on should be decided before the game).\nWe obtain a full classification of the different notions we consider."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.2621v1", 
    "title": "Homogeneous formulas and symmetric polynomials", 
    "arxiv-id": "0907.2621v1", 
    "author": "Amir Yehudayoff", 
    "publish": "2009-07-15T18:49:20Z", 
    "summary": "We investigate the arithmetic formula complexity of the elementary symmetric\npolynomials S(k,n). We show that every multilinear homogeneous formula\ncomputing S(k,n) has size at least k^(Omega(log k))n, and that product-depth d\nmultilinear homogeneous formulas for S(k,n) have size at least\n2^(Omega(k^{1/d}))n. Since S(n,2n) has a multilinear formula of size O(n^2), we\nobtain a superpolynomial separation between multilinear and multilinear\nhomogeneous formulas. We also show that S(k,n) can be computed by homogeneous\nformulas of size k^(O(log k))n, answering a question of Nisan and Wigderson.\nFinally, we present a superpolynomial separation between monotone and\nnon-monotone formulas in the noncommutative setting, answering a question of\nNisan."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.3117v1", 
    "title": "A Survey on Continuous Time Computations", 
    "arxiv-id": "0907.3117v1", 
    "author": "Manuel Campagnolo", 
    "publish": "2009-07-17T17:17:20Z", 
    "summary": "We provide an overview of theories of continuous time computation. These\ntheories allow us to understand both the hardness of questions related to\ncontinuous time dynamical systems and the computational power of continuous\ntime analog models. We survey the existing models, summarizing results, and\npoint to relevant references in the literature."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.3780v2", 
    "title": "On Lower Bounds for Constant Width Arithmetic Circuits", 
    "arxiv-id": "0907.3780v2", 
    "author": "Srikanth Srinivasan", 
    "publish": "2009-07-22T06:21:30Z", 
    "summary": "The motivation for this paper is to study the complexity of constant-width\narithmetic circuits. Our main results are the following.\n  1. For every k > 1, we provide an explicit polynomial that can be computed by\na linear-sized monotone circuit of width 2k but has no subexponential-sized\nmonotone circuit of width k. It follows, from the definition of the polynomial,\nthat the constant-width and the constant-depth hierarchies of monotone\narithmetic circuits are infinite, both in the commutative and the\nnoncommutative settings.\n  2. We prove hardness-randomness tradeoffs for identity testing constant-width\ncommutative circuits analogous to [KI03,DSY08]."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.3965v77", 
    "title": "P != NP Proof", 
    "arxiv-id": "0907.3965v77", 
    "author": "Andr\u00e9 Luiz Barbosa", 
    "publish": "2009-07-23T00:30:29Z", 
    "summary": "This paper demonstrates that P \\not= NP. The way was to generalize the\ntraditional definitions of the classes P and NP, to construct an artificial\nproblem (a generalization to SAT: The XG-SAT, much more difficult than the\nformer) and then to demonstrate that it is in NP but not in P (where the\nclasses P and NP are generalized and called too simply P and NP in this paper,\nand then it is explained why the traditional classes P and NP should be fixed\nand replaced by these generalized ones into Theory of Computer Science). The\ndemonstration consists of: 1. Definition of Restricted Type X Program; 2.\nDefinition of the General Extended Problem of Satisfiability of a Boolean\nFormula - XG-SAT; 3. Generalization to classes P and NP; 4. Demonstration that\nthe XG-SAT is in NP; 5. Demonstration that the XG-SAT is not in P; 6.\nDemonstration that the Baker-Gill-Solovay Theorem does not refute the proof; 7.\nDemonstration that the Razborov-Rudich Theorem does not refute the proof; 8.\nDemonstration that the Aaronson-Wigderson Theorem does not refute the proof."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.09.029", 
    "link": "http://arxiv.org/pdf/0907.4006v1", 
    "title": "Arithmetic Circuits and the Hadamard Product of Polynomials", 
    "arxiv-id": "0907.4006v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2009-07-23T08:52:50Z", 
    "summary": "Motivated by the Hadamard product of matrices we define the Hadamard product\nof multivariate polynomials and study its arithmetic circuit and branching\nprogram complexity. We also give applications and connections to polynomial\nidentity testing. Our main results are the following. 1. We show that\nnoncommutative polynomial identity testing for algebraic branching programs\nover rationals is complete for the logspace counting class $\\ceql$, and over\nfields of characteristic $p$ the problem is in $\\ModpL/\\Poly$. 2.We show an\nexponential lower bound for expressing the Raz-Yehudayoff polynomial as the\nHadamard product of two monotone multilinear polynomials. In contrast the\nPermanent can be expressed as the Hadamard product of two monotone multilinear\nformulas of quadratic size."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0907.4775v2", 
    "title": "Complexity Classes of Equivalence Problems Revisited", 
    "arxiv-id": "0907.4775v2", 
    "author": "Joshua A. Grochow", 
    "publish": "2009-07-27T21:30:02Z", 
    "summary": "To determine if two lists of numbers are the same set, we sort both lists and\nsee if we get the same result. The sorted list is a canonical form for the\nequivalence relation of set equality. Other canonical forms arise in graph\nisomorphism algorithms, and the equality of permutation groups given by\ngenerators. To determine if two graphs are cospectral (have the same\neigenvalues), however, we compute their characteristic polynomials and see if\nthey are the same; the characteristic polynomial is a complete invariant for\nthe equivalence relation of cospectrality. This is weaker than a canonical\nform, and it is not known whether a polynomial-time canonical form for\ncospectrality exists. Note that it is a priori possible for an equivalence\nrelation to be decidable in polynomial time without either a complete invariant\nor canonical form.\n  Blass and Gurevich (SIAM J. Comput., 1984) ask whether these conditions on\nequivalence relations -- having an FP canonical form, having an FP complete\ninvariant, and simply being in P -- are in fact different. They showed that\nthis question requires non-relativizing techniques to resolve. Here we extend\ntheir results, and give new connections to probabilistic and quantum\ncomputation."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0907.5575v2", 
    "title": "A hitting set construction, with application to arithmetic circuit lower   bounds", 
    "arxiv-id": "0907.5575v2", 
    "author": "Pascal Koiran", 
    "publish": "2009-07-31T16:51:06Z", 
    "summary": "A polynomial identity testing algorithm must determine whether a given input\npolynomial is identically equal to 0. We give a deterministic black-box\nidentity testing algorithm for univariate polynomials of the form $\\sum_{j=0}^t\nc_j X^{\\alpha_j} (a + b X)^{\\beta_j}$. From our algorithm we derive an\nexponential lower bound for representations of polynomials such as\n$\\prod_{i=1}^{2^n} (X^i-1)$ under this form. It has been conjectured that these\npolynomials are hard to compute by general arithmetic circuits. Our result\nshows that the \"hardness from derandomization\" approach to lower bounds is\nfeasible for a restricted class of arithmetic circuits. The proof is based on\ntechniques from algebraic number theory, and more precisely on properties of\nthe height function of algebraic numbers."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.1159v2", 
    "title": "On the Running Time of the Shortest Programs", 
    "arxiv-id": "0908.1159v2", 
    "author": "Norbert B\u00e1tfai", 
    "publish": "2009-08-10T14:07:47Z", 
    "summary": "The Kolmogorov complexity of the word w is equal to the length of the\nshortest concatenation of program Z and its input x with which the word w is\ncomputed by the universal turing machine U. The question introduced in this\npaper is the following: How long do the shortest programs run for?"
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.1397v3", 
    "title": "Matrix P-norms are NP-hard to approximate if p \\neq 1,2,\\infty", 
    "arxiv-id": "0908.1397v3", 
    "author": "Alex Olshevsky", 
    "publish": "2009-08-10T20:22:46Z", 
    "summary": "We show that for any rational p \\in [1,\\infty) except p = 1, 2, unless P =\nNP, there is no polynomial-time algorithm for approximating the matrix p-norm\nto arbitrary relative precision. We also show that for any rational p\\in\n[1,\\infty) including p = 1, 2, unless P = NP, there is no polynomial-time\nalgorithm approximates the \\infty, p mixed norm to some fixed relative\nprecision."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.1932v2", 
    "title": "On P vs. NP, Geometric Complexity Theory, Explicit Proofs and the   Complexity Barrier", 
    "arxiv-id": "0908.1932v2", 
    "author": "Ketan D. Mulmuley", 
    "publish": "2009-08-13T18:31:54Z", 
    "summary": "Geometric complexity theory (GCT) is an approach to the P vs. NP and related\nproblems. This article gives its complexity theoretic overview without assuming\nany background in algebraic geometry or representation theory."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.1936v2", 
    "title": "On P vs. NP, Geometric Complexity Theory, and the Riemann Hypothesis", 
    "arxiv-id": "0908.1936v2", 
    "author": "Ketan D. Mulmuley", 
    "publish": "2009-08-13T18:05:07Z", 
    "summary": "Geometric complexity theory (GCT) is an approach to the $P$ vs. $NP$ and\nrelated problems. A high level overview of this research plan and the results\nobtained so far was presented in a series of three lectures in the Institute of\nAdvanced study, Princeton, Feb 9-11, 2009. This article contains the material\ncovered in those lectures after some revision, and gives a mathematical\noverview of GCT. No background in algebraic geometry, representation theory or\nquantum groups is assumed."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.2122v1", 
    "title": "Approximate Counting and Quantum Computation", 
    "arxiv-id": "0908.2122v1", 
    "author": "D. Welsh", 
    "publish": "2009-08-14T19:29:07Z", 
    "summary": "Motivated by the result that an `approximate' evaluation of the Jones\npolynomial of a braid at a $5^{th}$ root of unity can be used to simulate the\nquantum part of any algorithm in the quantum complexity class BQP, and results\nrelating BQP to the counting class GapP, we introduce a form of additive\napproximation which can be used to simulate a function in BQP. We show that all\nfunctions in the classes #P and GapP have such an approximation scheme under\ncertain natural normalisations. However we are unable to determine whether the\nparticular functions we are motivated by, such as the above evaluation of the\nJones polynomial, can be approximated in this way. We close with some open\nproblems motivated by this work."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.2476v1", 
    "title": "Concurrent Knowledge-Extraction in the Public-Key Model", 
    "arxiv-id": "0908.2476v1", 
    "author": "Yunlei Zhao", 
    "publish": "2009-08-18T01:43:21Z", 
    "summary": "Knowledge extraction is a fundamental notion, modelling machine possession of\nvalues (witnesses) in a computational complexity sense. The notion provides an\nessential tool for cryptographic protocol design and analysis, enabling one to\nargue about the internal state of protocol players without ever looking at this\nsupposedly secret state. However, when transactions are concurrent (e.g., over\nthe Internet) with players possessing public-keys (as is common in\ncryptography), assuring that entities ``know'' what they claim to know, where\nadversaries may be well coordinated across different transactions, turns out to\nbe much more subtle and in need of re-examination. Here, we investigate how to\nformally treat knowledge possession by parties (with registered public-keys)\ninteracting over the Internet. Stated more technically, we look into the\nrelative power of the notion of ``concurrent knowledge-extraction'' (CKE) in\nthe concurrent zero-knowledge (CZK) bare public-key (BPK) model."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.2940v3", 
    "title": "A Strong Direct Product Theorem for Disjointness", 
    "arxiv-id": "0908.2940v3", 
    "author": "Hartmut Klauck", 
    "publish": "2009-08-20T14:59:24Z", 
    "summary": "A strong direct product theorem states that if we want to compute $k$\nindependent instances of a function, using less than $k$ times the resources\nneeded for one instance, then the overall success probability will be\nexponentially small in $k$. We establish such a theorem for the randomized\ncommunication complexity of the Disjointness problem, i.e., with communication\n$const\\cdot kn$ the success probability of solving $k$ instances of size $n$\ncan only be exponentially small in $k$. We show that this bound even holds for\n$AM$ communication protocols with limited ambiguity. This also implies a new\nlower bound for Disjointness in a restricted 3-player NOF protocol, and optimal\ncommunication-space tradeoffs for Boolean matrix product. Our main result\nfollows from a solution to the dual of a linear programming problem, whose\nfeasibility comes from a so-called Intersection Sampling Lemma that generalizes\na result by Razborov."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0908.4013v3", 
    "title": "Recombinations of Busy Beaver Machines", 
    "arxiv-id": "0908.4013v3", 
    "author": "Norbert B\u00e1tfai", 
    "publish": "2009-08-27T13:59:27Z", 
    "summary": "Many programmers belive that Turing-based machines cannot think. We also\nbelieve in this, however it is interesting to note that the most sophisticated\nmachines are not programmed by human beings. We have only discovered them. In\nthis paper, using well-known Busy Beaver and Placid Platypus machines, we\ngenerate further very similar, but not exactly the same machines. We have found\na recombinated BB_5 machine which can make 70.740.809 steps before halting."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0909.3466v3", 
    "title": "R\u00e9solution du \"partition problem\" par une approche arithm\u00e9tique", 
    "arxiv-id": "0909.3466v3", 
    "author": "Yann Dujardin", 
    "publish": "2009-09-18T15:25:32Z", 
    "summary": "This article has been withdrawn"
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0909.3868v2", 
    "title": "Method of resolution of 3SAT in polynomial time", 
    "arxiv-id": "0909.3868v2", 
    "author": "Luigi Salemi", 
    "publish": "2009-09-21T21:45:10Z", 
    "summary": "Presentation of a Method for determining whether a problem 3Sat has solution,\nand if yes to find one, in time max O(n^15). Is thus proved that the problem\n3Sat is fully resolved in polynomial time and therefore that it is in P, by the\nwork of Cook and Levin, and can transform a SAT problem in a 3Sat in polynomial\ntime (ref. Karp), it follows that P = NP. Open Source program is available at\nhttp://www.visainformatica.it/3sat"
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.ic.2011.01.006", 
    "link": "http://arxiv.org/pdf/0909.4607v1", 
    "title": "A note on the sign degree of formulas", 
    "arxiv-id": "0909.4607v1", 
    "author": "Troy Lee", 
    "publish": "2009-09-25T05:26:07Z", 
    "summary": "Recent breakthroughs in quantum query complexity have shown that any formula\nof size n can be evaluated with O(sqrt(n)log(n)/log log(n)) many quantum\nqueries in the bounded-error setting [FGG08, ACRSZ07, RS08b, Rei09]. In\nparticular, this gives an upper bound on the approximate polynomial degree of\nformulas of the same magnitude, as approximate polynomial degree is a lower\nbound on quantum query complexity [BBCMW01].\n  These results essentially answer in the affirmative a conjecture of O'Donnell\nand Servedio [O'DS03] that the sign degree--the minimal degree of a polynomial\nthat agrees in sign with a function on the Boolean cube--of every formula of\nsize n is O(sqrt(n)).\n  In this note, we show that sign degree is super-multiplicative under function\ncomposition. Combining this result with the above mentioned upper bounds on the\nquantum query complexity of formulas allows the removal of logarithmic factors\nto show that the sign degree of every size n formula is at most sqrt(n)."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.4", 
    "link": "http://arxiv.org/pdf/0909.5479v1", 
    "title": "Proceedings Fourth Athens Colloquium on Algorithms and Complexity", 
    "arxiv-id": "0909.5479v1", 
    "author": "Ioannis Milis", 
    "publish": "2009-09-30T02:05:28Z", 
    "summary": "ACAC 2009 is organized by the Athens University of Economics and Business\n(AUEB) and it is the fourth in a series of meetings that aim to bring together\nresearchers working on all areas of the theory of algorithms and computational\ncomplexity. These meetings are expected to serve as a lively forum for\npresenting results that are in a preliminary stage or have been recently\npresented in some major conference. For the first time this year all submitted\npapers were reviewed and ACAC also offered to the authors the choice of\npublishing their contribution (provided it has not been published anywhere else\nbefore) with the post-proceedings of EPTCS (Electronic Proceedings in\nTheoretical Computer Science)."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.4", 
    "link": "http://arxiv.org/pdf/0909.5684v1", 
    "title": "Partition Arguments in Multiparty Communication Complexity", 
    "arxiv-id": "0909.5684v1", 
    "author": "Enav Weinreb", 
    "publish": "2009-09-30T18:18:04Z", 
    "summary": "Consider the \"Number in Hand\" multiparty communication complexity model,\nwhere k players holding inputs x_1,...,x_k in {0,1}^n communicate to compute\nthe value f(x_1,...,x_k) of a function f known to all of them. The main lower\nbound technique for the communication complexity of such problems is that of\npartition arguments: partition the k players into two disjoint sets of players\nand find a lower bound for the induced two-party communication complexity\nproblem.\n  In this paper, we study the power of partition arguments. Our two main\nresults are very different in nature: (i) For randomized communication\ncomplexity, we show that partition arguments may yield bounds that are\nexponentially far from the true communication complexity. Specifically, we\nprove that there exists a 3-argument function f whose communication complexity\nis Omega(n), while partition arguments can only yield an Omega(log n) lower\nbound. The same holds for nondeterministic communication complexity. (ii) For\ndeterministic communication complexity, we prove that finding significant gaps\nbetween the true communication complexity and the best lower bound that can be\nobtained via partition arguments, would imply progress on a generalized version\nof the \"log-rank conjecture\" in communication complexity.\n  We conclude with two results on the multiparty \"fooling set technique\",\nanother method for obtaining communication complexity lower bounds."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-13182-0_21", 
    "link": "http://arxiv.org/pdf/0910.1427v1", 
    "title": "Balancing Bounded Treewidth Circuits", 
    "arxiv-id": "0910.1427v1", 
    "author": "Jayalal Sarma M. N", 
    "publish": "2009-10-08T06:56:50Z", 
    "summary": "Algorithmic tools for graphs of small treewidth are used to address questions\nin complexity theory. For both arithmetic and Boolean circuits, it is shown\nthat any circuit of size $n^{O(1)}$ and treewidth $O(\\log^i n)$ can be\nsimulated by a circuit of width $O(\\log^{i+1} n)$ and size $n^c$, where $c =\nO(1)$, if $i=0$, and $c=O(\\log \\log n)$ otherwise. For our main construction,\nwe prove that multiplicatively disjoint arithmetic circuits of size $n^{O(1)}$\nand treewidth $k$ can be simulated by bounded fan-in arithmetic formulas of\ndepth $O(k^2\\log n)$. From this we derive the analogous statement for\nsyntactically multilinear arithmetic circuits, which strengthens a theorem of\nMahajan and Rao. As another application, we derive that constant width\narithmetic circuits of size $n^{O(1)}$ can be balanced to depth $O(\\log n)$,\nprovided certain restrictions are made on the use of iterated multiplication.\nAlso from our main construction, we derive that Boolean bounded fan-in circuits\nof size $n^{O(1)}$ and treewidth $k$ can be simulated by bounded fan-in\nformulas of depth $O(k^2\\log n)$. This strengthens in the non-uniform setting\nthe known inclusion that $SC^0 \\subseteq NC^1$. Finally, we apply our\nconstruction to show that {\\sc reachability} for directed graphs of bounded\ntreewidth is in $LogDCFL$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-13182-0_21", 
    "link": "http://arxiv.org/pdf/0910.1443v1", 
    "title": "Weakening Assumptions for Deterministic Subexponential Time Non-Singular   Matrix Completion", 
    "arxiv-id": "0910.1443v1", 
    "author": "Maurice Jansen", 
    "publish": "2009-10-08T08:44:29Z", 
    "summary": "In (Kabanets, Impagliazzo, 2004) it is shown how to decide the circuit\npolynomial identity testing problem (CPIT) in deterministic subexponential\ntime, assuming hardness of some explicit multilinear polynomial family for\narithmetical circuits. In this paper, a special case of CPIT is considered,\nnamely low-degree non-singular matrix completion (NSMC). For this subclass of\nproblems it is shown how to obtain the same deterministic time bound, using a\nweaker assumption in terms of determinantal complexity.\n  Hardness-randomness tradeoffs will also be shown in the converse direction,\nin an effort to make progress on Valiant's VP versus VNP problem. To separate\nVP and VNP, it is known to be sufficient to prove that the determinantal\ncomplexity of the m-by-m permanent is $m^{\\omega(\\log m)}$. In this paper it is\nshown, for an appropriate notion of explicitness, that the existence of an\nexplicit multilinear polynomial family with determinantal complexity\nm^{\\omega(\\log m)}$ is equivalent to the existence of an efficiently computable\ngenerator $G_n$ for multilinear NSMC with seed length $O(n^{1/\\sqrt{\\log n}})$.\nThe latter is a combinatorial object that provides an efficient deterministic\nblack-box algorithm for NSMC. ``Multilinear NSMC'' indicates that $G_n$ only\nhas to work for matrices $M(x)$ of $poly(n)$ size in $n$ variables, for which\n$det(M(x))$ is a multilinear polynomial."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-13182-0_21", 
    "link": "http://arxiv.org/pdf/0910.1862v1", 
    "title": "The intersection of two halfspaces has high threshold degree", 
    "arxiv-id": "0910.1862v1", 
    "author": "Alexander A. Sherstov", 
    "publish": "2009-10-12T16:14:48Z", 
    "summary": "The threshold degree of a Boolean function f:{0,1}^n->{-1,+1} is the least\ndegree of a real polynomial p such that f(x)=sgn p(x). We construct two\nhalfspaces on {0,1}^n whose intersection has threshold degree Theta(sqrt n), an\nexponential improvement on previous lower bounds. This solves an open problem\ndue to Klivans (2002) and rules out the use of perceptron-based techniques for\nPAC learning the intersection of two halfspaces, a central unresolved challenge\nin computational learning. We also prove that the intersection of two majority\nfunctions has threshold degree Omega(log n), which is tight and settles a\nconjecture of O'Donnell and Servedio (2003).\n  Our proof consists of two parts. First, we show that for any nonconstant\nBoolean functions f and g, the intersection f(x)^g(y) has threshold degree O(d)\nif and only if ||f-F||_infty + ||g-G||_infty < 1 for some rational functions F,\nG of degree O(d). Second, we settle the least degree required for approximating\na halfspace and a majority function to any given accuracy by rational\nfunctions.\n  Our technique further allows us to make progress on Aaronson's challenge\n(2008) and contribute strong direct product theorems for polynomial\nrepresentations of composed Boolean functions of the form F(f_1,...,f_n). In\nparticular, we give an improved lower bound on the approximate degree of the\nAND-OR tree."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.2271v3", 
    "title": "Improved Inapproximability Results for Maximum k-Colorable Subgraph", 
    "arxiv-id": "0910.2271v3", 
    "author": "Ali Kemal Sinop", 
    "publish": "2009-10-12T23:49:08Z", 
    "summary": "We study the maximization version of the fundamental graph coloring problem.\nHere the goal is to color the vertices of a k-colorable graph with k colors so\nthat a maximum fraction of edges are properly colored (i.e. their endpoints\nreceive different colors). A random k-coloring properly colors an expected\nfraction 1-1/k of edges. We prove that given a graph promised to be\nk-colorable, it is NP-hard to find a k-coloring that properly colors more than\na fraction ~1-O(1/k} of edges. Previously, only a hardness factor of 1-O(1/k^2)\nwas known. Our result pins down the correct asymptotic dependence of the\napproximation factor on k. Along the way, we prove that approximating the\nMaximum 3-colorable subgraph problem within a factor greater than 32/33 is\nNP-hard. Using semidefinite programming, it is known that one can do better\nthan a random coloring and properly color a fraction 1-1/k +2 ln k/k^2 of edges\nin polynomial time. We show that, assuming the 2-to-1 conjecture, it is hard to\nproperly color (using k colors) more than a fraction 1-1/k + O(ln k/ k^2) of\nedges of a k-colorable graph."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.2649v1", 
    "title": "Polynomially Correlated Knapsack is NP-complete", 
    "arxiv-id": "0910.2649v1", 
    "author": "Chinmay Karande", 
    "publish": "2009-10-14T15:43:40Z", 
    "summary": "0-1 Knapsack is a fundamental NP-complete problem. In this article we prove\nthat it remains NP-complete even when the weights of the objects in the packing\nconstraints and their values in the objective function satisfy specific\nstringent conditions: the values are integral powers of the weights of the\nobjects."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.3282v1", 
    "title": "Adaptive Concurrent Non-Malleability with Bare Public-Keys", 
    "arxiv-id": "0910.3282v1", 
    "author": "Yunlei Zhao", 
    "publish": "2009-10-17T07:28:50Z", 
    "summary": "Concurrent non-malleability (CNM) is central for cryptographic protocols\nrunning concurrently in environments such as the Internet. In this work, we\nformulate CNM in the bare public-key (BPK) model, and show that round-efficient\nconcurrent non-malleable cryptography with full adaptive input selection can be\nestablished, in general, with bare public-keys (where, in particular, no\ntrusted assumption is made). Along the way, we clarify the various subtleties\nof adaptive concurrent non-malleability in the bare public-key model."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.3719v1", 
    "title": "Improved Approximation of Linear Threshold Functions", 
    "arxiv-id": "0910.3719v1", 
    "author": "Rocco A. Servedio", 
    "publish": "2009-10-19T23:11:46Z", 
    "summary": "We prove two main results on how arbitrary linear threshold functions $f(x) =\n\\sign(w\\cdot x - \\theta)$ over the $n$-dimensional Boolean hypercube can be\napproximated by simple threshold functions.\n  Our first result shows that every $n$-variable threshold function $f$ is\n$\\eps$-close to a threshold function depending only on $\\Inf(f)^2 \\cdot\n\\poly(1/\\eps)$ many variables, where $\\Inf(f)$ denotes the total influence or\naverage sensitivity of $f.$ This is an exponential sharpening of Friedgut's\nwell-known theorem \\cite{Friedgut:98}, which states that every Boolean function\n$f$ is $\\eps$-close to a function depending only on $2^{O(\\Inf(f)/\\eps)}$ many\nvariables, for the case of threshold functions. We complement this upper bound\nby showing that $\\Omega(\\Inf(f)^2 + 1/\\epsilon^2)$ many variables are required\nfor $\\epsilon$-approximating threshold functions.\n  Our second result is a proof that every $n$-variable threshold function is\n$\\eps$-close to a threshold function with integer weights at most $\\poly(n)\n\\cdot 2^{\\tilde{O}(1/\\eps^{2/3})}.$ This is a significant improvement, in the\ndependence on the error parameter $\\eps$, on an earlier result of\n\\cite{Servedio:07cc} which gave a $\\poly(n) \\cdot 2^{\\tilde{O}(1/\\eps^{2})}$\nbound. Our improvement is obtained via a new proof technique that uses strong\nanti-concentration bounds from probability theory. The new technique also gives\na simple and modular proof of the original \\cite{Servedio:07cc} result, and\nextends to give low-weight approximators for threshold functions under a range\nof probability distributions beyond just the uniform distribution."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.4122v5", 
    "title": "Pseudorandom Generators for Polynomial Threshold Functions", 
    "arxiv-id": "0910.4122v5", 
    "author": "David Zuckerman", 
    "publish": "2009-10-21T15:48:00Z", 
    "summary": "We study the natural question of constructing pseudorandom generators (PRGs)\nfor low-degree polynomial threshold functions (PTFs). We give a PRG with\nseed-length log n/eps^{O(d)} fooling degree d PTFs with error at most eps.\nPreviously, no nontrivial constructions were known even for quadratic threshold\nfunctions and constant error eps. For the class of degree 1 threshold functions\nor halfspaces, we construct PRGs with much better dependence on the error\nparameter eps and obtain a PRG with seed-length O(log n + log^2(1/eps)).\nPreviously, only PRGs with seed length O(log n log^2(1/eps)/eps^2) were known\nfor halfspaces. We also obtain PRGs with similar seed lengths for fooling\nhalfspaces over the n-dimensional unit sphere.\n  The main theme of our constructions and analysis is the use of invariance\nprinciples to construct pseudorandom generators. We also introduce the notion\nof monotone read-once branching programs, which is key to improving the\ndependence on the error rate eps for halfspaces. These techniques may be of\nindependent interest."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.4224v2", 
    "title": "Optimal bounds for sign-representing the intersection of two halfspaces   by polynomials", 
    "arxiv-id": "0910.4224v2", 
    "author": "Alexander A. Sherstov", 
    "publish": "2009-10-22T04:05:31Z", 
    "summary": "The threshold degree of a function f:{0,1}^n->{-1,+1} is the least degree of\na real polynomial p with f(x)=sgn p(x). We prove that the intersection of two\nhalfspaces on {0,1}^n has threshold degree Omega(n), which matches the trivial\nupper bound and completely answers a question due to Klivans (2002). The best\nprevious lower bound was Omega(sqrt n). Our result shows that the intersection\nof two halfspaces on {0,1}^n only admits a trivial 2^{Theta(n)}-time learning\nalgorithm based on sign-representation by polynomials, unlike the advances\nachieved in PAC learning DNF formulas and read-once Boolean formulas. The proof\nintroduces a new technique of independent interest, based on Fourier analysis\nand matrix theory."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.4266v2", 
    "title": "The Partition Bound for Classical Communication Complexity and Query   Complexity", 
    "arxiv-id": "0910.4266v2", 
    "author": "Hartmut Klauck", 
    "publish": "2009-10-22T09:40:58Z", 
    "summary": "We describe new lower bounds for randomized communication complexity and\nquery complexity which we call the partition bounds. They are expressed as the\noptimum value of linear programs. For communication complexity we show that the\npartition bound is stronger than both the rectangle/corruption bound and the\n\\gamma_2/generalized discrepancy bounds. In the model of query complexity we\nshow that the partition bound is stronger than the approximate polynomial\ndegree and classical adversary bounds. We also exhibit an example where the\npartition bound is quadratically larger than polynomial degree and classical\nadversary bounds."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0910.4518v1", 
    "title": "Preprocessing of Min Ones Problems: A Dichotomy", 
    "arxiv-id": "0910.4518v1", 
    "author": "Magnus Wahlstrom", 
    "publish": "2009-10-23T14:14:37Z", 
    "summary": "A parameterized problem consists of a classical problem and an additional\ncomponent, the so-called parameter. This point of view allows a formal\ndefinition of preprocessing: Given a parameterized instance (I,k), a polynomial\nkernelization computes an equivalent instance (I',k') of size and parameter\nbounded by a polynomial in k. We give a complete classification of Min Ones\nConstraint Satisfaction problems, i.e., Min Ones SAT(\\Gamma), with respect to\nadmitting or not admitting a polynomial kernelization (unless NP \\subseteq\ncoNP/poly). For this we introduce the notion of mergeability. If all relations\nof the constraint language \\Gamma are mergeable, then a new variant of\nsunflower kernelization applies, based on non-zero-closed cores. We obtain a\nkernel with O(k^{d+1}) variables and polynomial total size, where d is the\nmaximum arity of a constraint in \\Gamma, comparing nicely with the bound of\nO(k^{d-1}) vertices for the less general and arguably simpler d-Hitting Set\nproblem. Otherwise, any relation in \\Gamma that is not mergeable permits us to\nconstruct a log-cost selection formula, i.e., an n-ary selection formula with\nO(log n) true local variables. From this we can construct our lower bound using\nrecent results by Bodlaender et al. as well as Fortnow and Santhanam, proving\nthat there is no polynomial kernelization, unless NP \\subseteq coNP/poly and\nthe polynomial hierarchy collapses to the third level."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-03685-9_13", 
    "link": "http://arxiv.org/pdf/0911.0664v7", 
    "title": "Bounds on monotone switching networks for directed connectivity", 
    "arxiv-id": "0911.0664v7", 
    "author": "Aaron Potechin", 
    "publish": "2009-11-03T20:10:05Z", 
    "summary": "We separate monotone analogues of L and NL by proving that any monotone\nswitching network solving directed connectivity on $n$ vertices must have size\nat least $n^(\\Omega(\\lg(n)))$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.9.7", 
    "link": "http://arxiv.org/pdf/0911.2325v1", 
    "title": "Characterizing Polynomial Time Computability of Rational and Real   Functions", 
    "arxiv-id": "0911.2325v1", 
    "author": "Walid Gomaa", 
    "publish": "2009-11-12T08:50:28Z", 
    "summary": "Recursive analysis was introduced by A. Turing [1936], A. Grzegorczyk [1955],\nand D. Lacombe [1955]. It is based on a discrete mechanical framework that can\nbe used to model computation over the real numbers. In this context the\ncomputational complexity of real functions defined over compact domains has\nbeen extensively studied. However, much less have been done for other kinds of\nreal functions. This article is divided into two main parts. The first part\ninvestigates polynomial time computability of rational functions and the role\nof continuity in such computation. On the one hand this is interesting for its\nown sake. On the other hand it provides insights into polynomial time\ncomputability of real functions for the latter, in the sense of recursive\nanalysis, is modeled as approximations of rational computations. The main\nconclusion of this part is that continuity does not play any role in the\nefficiency of computing rational functions. The second part defines polynomial\ntime computability of arbitrary real functions, characterizes it, and compares\nit with the corresponding notion over rational functions. Assuming continuity,\nthe main conclusion is that there is a conceptual difference between polynomial\ntime computation over the rationals and the reals manifested by the fact that\nthere are polynomial time computable rational functions whose extensions to the\nreals are not polynomial time computable and vice versa."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.9.7", 
    "link": "http://arxiv.org/pdf/0911.3389v2", 
    "title": "Bounded Independence Fools Degree-2 Threshold Functions", 
    "arxiv-id": "0911.3389v2", 
    "author": "Jelani Nelson", 
    "publish": "2009-11-17T20:24:27Z", 
    "summary": "Let x be a random vector coming from any k-wise independent distribution over\n{-1,1}^n. For an n-variate degree-2 polynomial p, we prove that E[sgn(p(x))] is\ndetermined up to an additive epsilon for k = poly(1/epsilon). This answers an\nopen question of Diakonikolas et al. (FOCS 2009). Using standard constructions\nof k-wise independent distributions, we obtain a broad class of explicit\ngenerators that epsilon-fool the class of degree-2 threshold functions with\nseed length log(n)*poly(1/epsilon).\n  Our approach is quite robust: it easily extends to yield that the\nintersection of any constant number of degree-2 threshold functions is\nepsilon-fooled by poly(1/epsilon)-wise independence. Our results also hold if\nthe entries of x are k-wise independent standard normals, implying for example\nthat bounded independence derandomizes the Goemans-Williamson hyperplane\nrounding scheme.\n  To achieve our results, we introduce a technique we dub multivariate\nFT-mollification, a generalization of the univariate form introduced by Kane et\nal. (SODA 2010) in the context of streaming algorithms. Along the way we prove\na generalized hypercontractive inequality for quadratic forms which takes the\noperator norm of the associated matrix into account. These techniques may be of\nindependent interest."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.9.7", 
    "link": "http://arxiv.org/pdf/0911.3473v3", 
    "title": "Polynomial Threshold Functions: Structure, Approximation and   Pseudorandomness", 
    "arxiv-id": "0911.3473v3", 
    "author": "Ariel Yadin", 
    "publish": "2009-11-18T07:28:08Z", 
    "summary": "We study the computational power of polynomial threshold functions, that is,\nthreshold functions of real polynomials over the boolean cube. We provide two\nnew results bounding the computational power of this model.\n  Our first result shows that low-degree polynomial threshold functions cannot\napproximate any function with many influential variables. We provide a couple\nof examples where this technique yields tight approximation bounds.\n  Our second result relates to constructing pseudorandom generators fooling\nlow-degree polynomial threshold functions. This problem has received attention\nrecently, where Diakonikolas et al proved that $k$-wise independence suffices\nto fool linear threshold functions. We prove that any low-degree polynomial\nthreshold function, which can be represented as a function of a small number of\nlinear threshold functions, can also be fooled by $k$-wise independence. We\nview this as an important step towards fooling general polynomial threshold\nfunctions, and we discuss a plausible approach achieving this goal based on our\ntechniques.\n  Our results combine tools from real approximation theory, hyper-contractive\ninequalities and probabilistic methods. In particular, we develop several new\ntools in approximation theory which may be of independent interest."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0911.3492v2", 
    "title": "Towards a Dichotomy for the Possible Winner Problem in Elections Based   on Scoring Rules", 
    "arxiv-id": "0911.3492v2", 
    "author": "Britta Dorn", 
    "publish": "2009-11-18T10:02:39Z", 
    "summary": "To make a joint decision, agents (or voters) are often required to provide\ntheir preferences as linear orders. To determine a winner, the given linear\norders can be aggregated according to a voting protocol. However, in realistic\nsettings, the voters may often only provide partial orders. This directly leads\nto the Possible Winner problem that asks, given a set of partial votes, whether\na distinguished candidate can still become a winner. In this work, we consider\nthe computational complexity of Possible Winner for the broad class of voting\nprotocols defined by scoring rules. A scoring rule provides a score value for\nevery position which a candidate can have in a linear order. Prominent examples\ninclude plurality, k-approval, and Borda. Generalizing previous NP-hardness\nresults for some special cases, we settle the computational complexity for all\nbut one scoring rule. More precisely, for an unbounded number of candidates and\nunweighted voters, we show that Possible Winner is NP-complete for all pure\nscoring rules except plurality, veto, and the scoring rule defined by the\nscoring vector (2,1,...,1,0), while it is solvable in polynomial time for\nplurality and veto."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0911.4337v1", 
    "title": "Circuit Lower Bounds, Help Functions, and the Remote Point Problem", 
    "arxiv-id": "0911.4337v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2009-11-23T08:25:40Z", 
    "summary": "We investigate the power of Algebraic Branching Programs (ABPs) augmented\nwith help polynomials, and constant-depth Boolean circuits augmented with help\nfunctions. We relate the problem of proving explicit lower bounds in both these\nmodels to the Remote Point Problem (introduced by Alon, Panigrahy, and Yekhanin\n(RANDOM '09)). More precisely, proving lower bounds for ABPs with help\npolynomials is related to the Remote Point Problem w.r.t. the rank metric, and\nfor constant-depth circuits with help functions it is related to the Remote\nPoint Problem w.r.t. the Hamming metric. For algebraic branching programs with\nhelp polynomials with some degree restrictions we show exponential size lower\nbounds for explicit polynomials."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0912.0309v2", 
    "title": "Hardness Results for the Gapped Consecutive-Ones Property", 
    "arxiv-id": "0912.0309v2", 
    "author": "Murray Patterson", 
    "publish": "2009-12-02T00:26:17Z", 
    "summary": "Motivated by problems of comparative genomics and paleogenomics, in [Chauve\net al., 2009], the authors introduced the Gapped Consecutive-Ones Property\nProblem (k,delta)-C1P: given a binary matrix M and two integers k and delta,\ncan the columns of M be permuted such that each row contains at most k blocks\nof ones and no two consecutive blocks of ones are separated by a gap of more\nthan delta zeros. The classical C1P problem, which is known to be polynomial is\nequivalent to the (1,0)-C1P problem. They showed that the (2,delta)-C1P Problem\nis NP-complete for all delta >= 2 and that the (3,1)-C1P problem is\nNP-complete. They also conjectured that the (k,delta)-C1P Problem is\nNP-complete for k >= 2, delta >= 1 and (k,delta) =/= (2,1). Here, we prove that\nthis conjecture is true. The only remaining case is the (2,1)-C1P Problem,\nwhich could be polynomial-time solvable."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0912.0568v1", 
    "title": "Hardness Amplification in Proof Complexity", 
    "arxiv-id": "0912.0568v1", 
    "author": "Toniann Pitassi", 
    "publish": "2009-12-03T02:09:22Z", 
    "summary": "We present a general method for converting any family of unsatisfiable CNF\nformulas that is hard for one of the simplest proof systems, tree resolution,\ninto formulas that require large rank in any proof system that manipulates\npolynomials or polynomial threshold functions of degree at most k (known as\nTh(k) proofs). Such systems include Lovasz-Schrijver and Cutting Planes proof\nsystems as well as their high degree analogues.\n  These are based on analyzing two new proof systems, denoted by T^cc(k) and\nR^cc(k). The proof lines of T^cc(k) are arbitrary Boolean functions, each of\nwhich can be evaluated by an efficient k-party randomized communication\nprotocol. They include Th{k-1} proofs as a special case. R^cc(k) proofs are\nstronger and only require that each inference be locally checkable by an\nefficient k-party randomized communication protocol.\n  Our main results are the following:\n  (1) When k is O(loglogn), for any unsatisfiable CNF formula F requiring\nresolution rank r, there is a related CNF formula G=Lift_k(F) requiring\nrefutation rank r^Omega(1/k) log^O(1) n in all R^cc(k) systems.\n  (2) There are strict hierarchies for T^cc(k) and R^cc(k) systems with respect\nto k when k is O(loglogn in that there are unsatisfiable CNF formulas requiring\nlarge rank R^cc(k) refutations but having log^O(1) n rank Th(k) refutations.\n  (3) When k is O(loglogn) there are 2^(n^Omega(1/k)) lower bounds on the size\nof tree-like T^cc(k) refutations for large classes of lifted CNF formulas.\n  (4) A general method for producing integrality gaps for low rank R^cc(2)\ninference (and hence Cutting Planes and Th(1) inference) based on related gaps\nfor low rank resolution. These gaps are optimal for MAX-2t-SAT."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0912.0741v2", 
    "title": "A boundary between universality and non-universality in spiking neural P   systems", 
    "arxiv-id": "0912.0741v2", 
    "author": "Turlough Neary", 
    "publish": "2009-12-04T20:36:55Z", 
    "summary": "In this work we offer a significant improvement on the previous smallest\nspiking neural P systems and solve the problem of finding the smallest possible\nextended spiking neural P system. Paun and Paun gave a universal spiking neural\nP system with 84 neurons and another that has extended rules with 49 neurons.\nSubsequently, Zhang et al. reduced the number of neurons used to give\nuniversality to 67 for spiking neural P systems and to 41 for the extended\nmodel. Here we give a small universal spiking neural P system that has only 17\nneurons and another that has extended rules with 5 neurons. All of the above\nmentioned spiking neural P systems suffer from an exponential slow down when\nsimulating Turing machines. Using a more relaxed encoding technique we get a\nuniversal spiking neural P system that has extended rules with only 4 neurons.\nThis latter spiking neural P system simulates 2-counter machines in linear time\nand thus suffer from a double exponential time overhead when simulating Turing\nmachines. We show that extended spiking neural P systems with 3 neurons are\nsimulated by log-space bounded Turing machines, and so there exists no such\nuniversal system with 3 neurons. It immediately follows that our 4-neuron\nsystem is the smallest possible extended spiking neural P system that is\nuniversal. Finally, we show that if we generalise the output technique we can\ngive a universal spiking neural P system with extended rules that has only 3\nneurons. This system is also the smallest of its kind as a universal spiking\nneural P system with extended rules and generalised output is not possible with\n2 neurons."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0912.1776v1", 
    "title": "On the Optimality of a Class of LP-based Algorithms", 
    "arxiv-id": "0912.1776v1", 
    "author": "Nisheeth K. Vishnoi", 
    "publish": "2009-12-09T15:49:04Z", 
    "summary": "In this paper we will be concerned with a class of packing and covering\nproblems which includes Vertex Cover and Independent Set. Typically, one can\nwrite an LP relaxation and then round the solution. In this paper, we explain\nwhy the simple LP-based rounding algorithm for the \\\\VC problem is optimal\nassuming the UGC. Complementing Raghavendra's result, our result generalizes to\na class of strict, covering/packing type CSPs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2010.04.002", 
    "link": "http://arxiv.org/pdf/0912.2565v1", 
    "title": "Deterministic Identity Testing of Read-Once Algebraic Branching Programs", 
    "arxiv-id": "0912.2565v1", 
    "author": "Jayalal Sarma", 
    "publish": "2009-12-14T02:10:50Z", 
    "summary": "In this paper we study polynomial identity testing of sums of $k$ read-once\nalgebraic branching programs ($\\Sigma_k$-RO-ABPs), generalizing the work in\n(Shpilka and Volkovich 2008,2009), who considered sums of $k$ read-once\nformulas ($\\Sigma_k$-RO-formulas). We show that $\\Sigma_k$-RO-ABPs are strictly\nmore powerful than $\\Sigma_k$-RO-formulas, for any $k \\leq \\lfloor n/2\\rfloor$,\nwhere $n$ is the number of variables. We obtain the following results:\n  1) Given free access to the RO-ABPs in the sum, we get a deterministic\nalgorithm that runs in time $O(k^2n^7s) + n^{O(k)}$, where $s$ bounds the size\nof any largest RO-ABP given on the input. This implies we have a deterministic\npolynomial time algorithm for testing whether the sum of a constant number of\nRO-ABPs computes the zero polynomial.\n  2) Given black-box access to the RO-ABPs computing the individual polynomials\nin the sum, we get a deterministic algorithm that runs in time $k^2n^{O(\\log\nn)} + n^{O(k)}$.\n  3) Finally, given only black-box access to the polynomial computed by the sum\nof the $k$ RO-ABPs, we obtain an $n^{O(k + \\log n)}$ time deterministic\nalgorithm."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_42", 
    "link": "http://arxiv.org/pdf/0912.2607v3", 
    "title": "The Multivariate Resultant is NP-hard in any Characteristic", 
    "arxiv-id": "0912.2607v3", 
    "author": "Natacha Portier", 
    "publish": "2009-12-14T10:30:25Z", 
    "summary": "The multivariate resultant is a fundamental tool of computational algebraic\ngeometry. It can in particular be used to decide whether a system of n\nhomogeneous equations in n variables is satisfiable (the resultant is a\npolynomial in the system's coefficients which vanishes if and only if the\nsystem is satisfiable). In this paper we present several NP-hardness results\nfor testing whether a multivariate resultant vanishes, or equivalently for\ndeciding whether a square system of homogeneous equations is satisfiable. Our\nmain result is that testing the resultant for zero is NP-hard under\ndeterministic reductions in any characteristic, for systems of low-degree\npolynomials with coefficients in the ground field (rather than in an\nextension). We also observe that in characteristic zero, this problem is in the\nArthur-Merlin class AM if the generalized Riemann hypothesis holds true. In\npositive characteristic, the best upper bound remains PSPACE."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_42", 
    "link": "http://arxiv.org/pdf/0912.3162v1", 
    "title": "Derandomizing from Random Strings", 
    "arxiv-id": "0912.3162v1", 
    "author": "Bruno Loff", 
    "publish": "2009-12-16T15:15:20Z", 
    "summary": "In this paper we show that BPP is truth-table reducible to the set of\nKolmogorov random strings R_K. It was previously known that PSPACE, and hence\nBPP is Turing-reducible to R_K. The earlier proof relied on the adaptivity of\nthe Turing-reduction to find a Kolmogorov-random string of polynomial length\nusing the set R_K as oracle. Our new non-adaptive result relies on a new\nfundamental fact about the set R_K, namely each initial segment of the\ncharacteristic sequence of R_K is not compressible by recursive means. As a\npartial converse to our claim we show that strings of high\nKolmogorov-complexity when used as advice are not much more useful than\nrandomly chosen strings."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_42", 
    "link": "http://arxiv.org/pdf/0912.3627v1", 
    "title": "New Learning and Testing Problems for Read-Once Functions", 
    "arxiv-id": "0912.3627v1", 
    "author": "Andrey A. Voronenko", 
    "publish": "2009-12-18T09:58:55Z", 
    "summary": "In the paper, we consider several types of queries for classical and new\nproblems of learning and testing read-once functions. In several cases, the\nborder between polynomial and exponential complexities is obtained."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_42", 
    "link": "http://arxiv.org/pdf/0912.3730v2", 
    "title": "On the circuit-size of inverses", 
    "arxiv-id": "0912.3730v2", 
    "author": "Jean-Camille Birget", 
    "publish": "2009-12-18T16:34:15Z", 
    "summary": "We reprove a result of Boppana and Lagarias: If Pi_2^P is different from\nSigma_2^P then there exists a partial function f that is computable by a\npolynomial-size family of circuits, but no inverse of f is computable by a\npolynomial-size family of circuits. We strengthen this result by showing that\nthere exist length-preserving total functions that are one-way by circuit size\nand that are computable in uniform polynomial time. We also prove, if Pi_2^P is\ndifferent from Sigma_2^P, that there exist polynomially balanced total\nsurjective functions that are one-way by circuit size; here non-uniformity is\nused."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_42", 
    "link": "http://arxiv.org/pdf/0912.3802v3", 
    "title": "The complexity of the list homomorphism problem for graphs", 
    "arxiv-id": "0912.3802v3", 
    "author": "Pascal Tesson", 
    "publish": "2009-12-18T21:14:52Z", 
    "summary": "We completely classify the computational complexity of the list H-colouring\nproblem for graphs (with possible loops) in combinatorial and algebraic terms:\nfor every graph H the problem is either NP-complete, NL-complete, L-complete or\nis first-order definable; descriptive complexity equivalents are given as well\nvia Datalog and its fragments. Our algebraic characterisations match important\nconjectures in the study of constraint satisfaction problems."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_42", 
    "link": "http://arxiv.org/pdf/0912.4602v2", 
    "title": "Log-space Algorithms for Paths and Matchings in k-trees", 
    "arxiv-id": "0912.4602v2", 
    "author": "Prajakta Nimbhorkar", 
    "publish": "2009-12-23T10:58:08Z", 
    "summary": "Reachability and shortest path problems are NL-complete for general graphs.\nThey are known to be in L for graphs of tree-width 2 [JT07]. However, for\ngraphs of tree-width larger than 2, no bound better than NL is known. In this\npaper, we improve these bounds for k-trees, where k is a constant. In\nparticular, the main results of our paper are log-space algorithms for\nreachability in directed k-trees, and for computation of shortest and longest\npaths in directed acyclic k-trees.\n  Besides the path problems mentioned above, we also consider the problem of\ndeciding whether a k-tree has a perfect macthing (decision version), and if so,\nfinding a perfect match- ing (search version), and prove that these two\nproblems are L-complete. These problems are known to be in P and in RNC for\ngeneral graphs, and in SPL for planar bipartite graphs [DKR08].\n  Our results settle the complexity of these problems for the class of k-trees.\nThe results are also applicable for bounded tree-width graphs, when a\ntree-decomposition is given as input. The technique central to our algorithms\nis a careful implementation of divide-and-conquer approach in log-space, along\nwith some ideas from [JT07] and [LMR07]."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/0912.4935v4", 
    "title": "Inapproximability of maximal strip recovery", 
    "arxiv-id": "0912.4935v4", 
    "author": "Minghui Jiang", 
    "publish": "2009-12-25T03:25:15Z", 
    "summary": "In comparative genomic, the first step of sequence analysis is usually to\ndecompose two or more genomes into syntenic blocks that are segments of\nhomologous chromosomes. For the reliable recovery of syntenic blocks, noise and\nambiguities in the genomic maps need to be removed first. Maximal Strip\nRecovery (MSR) is an optimization problem proposed by Zheng, Zhu, and Sankoff\nfor reliably recovering syntenic blocks from genomic maps in the midst of noise\nand ambiguities. Given $d$ genomic maps as sequences of gene markers, the\nobjective of \\msr{d} is to find $d$ subsequences, one subsequence of each\ngenomic map, such that the total length of syntenic blocks in these\nsubsequences is maximized. For any constant $d \\ge 2$, a polynomial-time\n2d-approximation for \\msr{d} was previously known. In this paper, we show that\nfor any $d \\ge 2$, \\msr{d} is APX-hard, even for the most basic version of the\nproblem in which all gene markers are distinct and appear in positive\norientation in each genomic map. Moreover, we provide the first explicit lower\nbounds on approximating \\msr{d} for all $d \\ge 2$. In particular, we show that\n\\msr{d} is NP-hard to approximate within $\\Omega(d/\\log d)$. From the other\ndirection, we show that the previous 2d-approximation for \\msr{d} can be\noptimized into a polynomial-time algorithm even if $d$ is not a constant but is\npart of the input. We then extend our inapproximability results to several\nrelated problems including \\cmsr{d}, \\gapmsr{\\delta}{d}, and\n\\gapcmsr{\\delta}{d}."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/0912.5276v1", 
    "title": "Better Gap-Hamming Lower Bounds via Better Round Elimination", 
    "arxiv-id": "0912.5276v1", 
    "author": "Ronald de Wolf", 
    "publish": "2009-12-30T14:12:32Z", 
    "summary": "Gap Hamming Distance is a well-studied problem in communication complexity,\nin which Alice and Bob have to decide whether the Hamming distance between\ntheir respective n-bit inputs is less than n/2-sqrt(n) or greater than\nn/2+sqrt(n). We show that every k-round bounded-error communication protocol\nfor this problem sends a message of at least Omega(n/(k^2\\log k)) bits. This\nlower bound has an exponentially better dependence on the number of rounds than\nthe previous best bound, due to Brody and Chakrabarti. Our communication lower\nbound implies strong space lower bounds on algorithms for a number of data\nstream computations, such as approximating the number of distinct elements in a\nstream.\n  Subsequent to this result, the bound has been improved by some of us to the\noptimal Omega(n), independent of k, by using different techniques."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.0117v2", 
    "title": "Collapsing and Separating Completeness Notions under Average-Case and   Worst-Case Hypotheses", 
    "arxiv-id": "1001.0117v2", 
    "author": "A. Pavan", 
    "publish": "2010-01-04T20:55:05Z", 
    "summary": "This paper presents the following results on sets that are complete for NP.\n  1. If there is a problem in NP that requires exponential time at almost all\nlengths, then every many-one NP-complete set is complete under\nlength-increasing reductions that are computed by polynomial-size circuits. 2.\nIf there is a problem in coNP that cannot be solved by polynomial-size\nnondeterministic circuits, then every many-one complete set is complete under\nlength-increasing reductions that are computed by polynomial-size circuits. 3.\nIf there exist a one-way permutation that is secure against subexponential-size\ncircuits and there is a hard tally language in NP intersect coNP, then there is\na Turing complete language for NP that is not many-one complete. Our first two\nresults use worst-case hardness hypotheses whereas earlier work that showed\nsimilar results relied on average-case or almost-everywhere hardness\nassumptions. The use of average-case and worst-case hypotheses in the last\nresult is unique as previous results obtaining the same consequence relied on\nalmost-everywhere hardness results."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.0208v2", 
    "title": "Intrinsic Universality in Self-Assembly", 
    "arxiv-id": "1001.0208v2", 
    "author": "Damien Woods", 
    "publish": "2010-01-01T15:39:54Z", 
    "summary": "We show that the Tile Assembly Model exhibits a strong notion of universality\nwhere the goal is to give a single tile assembly system that simulates the\nbehavior of any other tile assembly system. We give a tile assembly system that\nis capable of simulating a very wide class of tile systems, including itself.\nSpecifically, we give a tile set that simulates the assembly of any tile\nassembly system in a class of systems that we call \\emph{locally consistent}:\neach tile binds with exactly the strength needed to stay attached, and that\nthere are no glue mismatches between tiles in any produced assembly.\n  Our construction is reminiscent of the studies of \\emph{intrinsic\nuniversality} of cellular automata by Ollinger and others, in the sense that\nour simulation of a tile system $T$ by a tile system $U$ represents each tile\nin an assembly produced by $T$ by a $c \\times c$ block of tiles in $U$, where\n$c$ is a constant depending on $T$ but not on the size of the assembly $T$\nproduces (which may in fact be infinite). Also, our construction improves on\nearlier simulations of tile assembly systems by other tile assembly systems (in\nparticular, those of Soloveichik and Winfree, and of Demaine et al.) in that we\nsimulate the actual process of self-assembly, not just the end result, as in\nSoloveichik and Winfree's construction, and we do not discriminate against\ninfinite structures. Both previous results simulate only temperature 1 systems,\nwhereas our construction simulates tile assembly systems operating at\ntemperature 2."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.0383v2", 
    "title": "Restricted Space Algorithms for Isomorphism on Bounded Treewidth Graphs", 
    "arxiv-id": "1001.0383v2", 
    "author": "Fabian Wagner", 
    "publish": "2010-01-03T15:44:56Z", 
    "summary": "The Graph Isomorphism problem restricted to graphs of bounded treewidth or\nbounded tree distance width are known to be solvable in polynomial time\n[Bod90],[YBFT99]. We give restricted space algorithms for these problems\nproving the following results: - Isomorphism for bounded tree distance width\ngraphs is in L and thus complete for the class. We also show that for this kind\nof graphs a canon can be computed within logspace. - For bounded treewidth\ngraphs, when both input graphs are given together with a tree decomposition,\nthe problem of whether there is an isomorphism which respects the\ndecompositions (i.e. considering only isomorphisms mapping bags in one\ndecomposition blockwise onto bags in the other decomposition) is in L. - For\nbounded treewidth graphs, when one of the input graphs is given with a tree\ndecomposition the isomorphism problem is in LogCFL. - As a corollary the\nisomorphism problem for bounded treewidth graphs is in LogCFL. This improves\nthe known TC1 upper bound for the problem given by Grohe and Verbitsky\n[GroVer06]."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.0464v3", 
    "title": "Holant Problems for Regular Graphs with Complex Edge Functions", 
    "arxiv-id": "1001.0464v3", 
    "author": "Jin-Yi Cai", 
    "publish": "2010-01-04T12:33:25Z", 
    "summary": "We prove a complexity dichotomy theorem for Holant Problems on 3-regular\ngraphs with an arbitrary complex-valued edge function. Three new techniques are\nintroduced: (1) higher dimensional iterations in interpolation; (2) Eigenvalue\nShifted Pairs, which allow us to prove that a pair of combinatorial gadgets in\ncombination succeed in proving #P-hardness; and (3) algebraic symmetrization,\nwhich significantly lowers the symbolic complexity of the proof for\ncomputational complexity. With holographic reductions the classification\ntheorem also applies to problems beyond the basic model."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.1593v1", 
    "title": "Fooling functions of halfspaces under product distributions", 
    "arxiv-id": "1001.1593v1", 
    "author": "D. Zuckerman", 
    "publish": "2010-01-11T06:11:56Z", 
    "summary": "We construct pseudorandom generators that fool functions of halfspaces\n(threshold functions) under a very broad class of product distributions. This\nclass includes not only familiar cases such as the uniform distribution on the\ndiscrete cube, the uniform distribution on the solid cube, and the multivariate\nGaussian distribution, but also includes any product of discrete distributions\nwith probabilities bounded away from 0.\n  Our first main result shows that a recent pseudorandom generator construction\nof Meka and Zuckerman [MZ09], when suitably modifed, can fool arbitrary\nfunctions of d halfspaces under product distributions where each coordinate has\nbounded fourth moment. To eps-fool any size-s, depth-d decision tree of\nhalfspaces, our pseudorandom generator uses seed length O((d log(ds/eps)+log n)\nlog(ds/eps)). For monotone functions of d halfspaces, the seed length can be\nimproved to O((d log(d/eps)+log n) log(d/eps)). We get better bounds for larger\neps; for example, to 1/polylog(n)-fool all monotone functions of (log n)= log\nlog n halfspaces, our generator requires a seed of length just O(log n). Our\nsecond main result generalizes the work of Diakonikolas et al. [DGJ+09] to show\nthat bounded independence suffices to fool functions of halfspaces under\nproduct distributions. Assuming each coordinate satisfies a certain stronger\nmoment condition, we show that any function computable by a size-s, depth-d\ndecision tree of halfspaces is eps-fooled by O(d^4s^2/eps^2)-wise independence."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.2034v1", 
    "title": "On the Power of Unambiguity in Logspace", 
    "arxiv-id": "1001.2034v1", 
    "author": "N. V. Vinodchandran", 
    "publish": "2010-01-12T22:13:31Z", 
    "summary": "We report progress on the \\NL vs \\UL problem. [-] We show unconditionally\nthat the complexity class $\\ReachFewL\\subseteq\\UL$. This improves on the\nearlier known upper bound $\\ReachFewL \\subseteq \\FewL$. [-] We investigate the\ncomplexity of min-uniqueness - a central notion in studying the \\NL vs \\UL\nproblem. We show that min-uniqueness is necessary and sufficient for showing\n$\\NL =\\UL$. We revisit the class $\\OptL[\\log n]$ and show that {\\sc\nShortestPathLength} - computing the length of the shortest path in a DAG, is\ncomplete for $\\OptL[\\log n]$. We introduce $\\UOptL[\\log n]$, an unambiguous\nversion of $\\OptL[\\log n]$, and show that (a) $\\NL =\\UL$ if and only if\n$\\OptL[\\log n] = \\UOptL[\\log n]$, (b) $\\LogFew \\leq \\UOptL[\\log n] \\leq \\SPL$.\n[-] We show that the reachability problem over graphs embedded on 3 pages is\ncomplete for \\NL. This contrasts with the reachability problem over graphs\nembedded on 2 pages which is logspace equivalent to the reachability problem in\nplanar graphs and hence is in \\UL."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.2052v1", 
    "title": "Block Sensitivity of Minterm-Transitive Functions", 
    "arxiv-id": "1001.2052v1", 
    "author": "Andrew Drucker", 
    "publish": "2010-01-13T20:29:28Z", 
    "summary": "Boolean functions with symmetry properties are interesting from a complexity\ntheory perspective; extensive research has shown that these functions, if\nnonconstant, must have high `complexity' according to various measures.\n  In recent work of this type, Sun gave bounds on the block sensitivity of\nnonconstant Boolean functions invariant under a transitive permutation group.\nSun showed that all such functions satisfy bs(f) = Omega(N^{1/3}), and that\nthere exists such a function for which bs(f) = O(N^{3/7}ln N). His example\nfunction belongs to a subclass of transitively invariant functions called the\nminterm-transitive functions (defined in earlier work by Chakraborty).\n  We extend these results in two ways. First, we show that nonconstant\nminterm-transitive functions satisfy bs(f) = Omega(N^{3/7}). Thus Sun's example\nfunction has nearly minimal block sensitivity for this subclass. Second, we\ngive an improved example: a minterm-transitive function for which bs(f) =\nO(N^{3/7}ln^{1/7}N)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.3485v1", 
    "title": "Randomness Testing of Compressed Data", 
    "arxiv-id": "1001.3485v1", 
    "author": "Xiangzhan Yu", 
    "publish": "2010-01-20T07:43:47Z", 
    "summary": "Random Number Generators play a critical role in a number of important\napplications. In practice, statistical testing is employed to gather evidence\nthat a generator indeed produces numbers that appear to be random. In this\npaper, we reports on the studies that were conducted on the compressed data\nusing 8 compression algorithms or compressors. The test results suggest that\nthe output of compression algorithms or compressors has bad randomness, the\ncompression algorithms or compressors are not suitable as random number\ngenerator. We also found that, for the same compression algorithm, there exists\npositive correlation relationship between compression ratio and randomness,\nincreasing the compression ratio increases randomness of compressed data. As\ntime permits, additional randomness testing efforts will be conducted."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.3816v2", 
    "title": "The P versus NP Problem", 
    "arxiv-id": "1001.3816v2", 
    "author": "Rakesh Dube", 
    "publish": "2010-01-21T14:37:36Z", 
    "summary": "Removed by arXiv administration.\n  This article was plagiarized directly from Stephen Cook's description of the\nproblem for the Clay Mathematics Institute. See\nhttp://gauss.claymath.org:8888/millennium/P_vs_NP/pvsnp.pdf for the original\ntext."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.4649v1", 
    "title": "Is Space a Stronger Resource than Time? Positive Answer for the   Nondeterministic at-Least-Quadratic Time Case", 
    "arxiv-id": "1001.4649v1", 
    "author": "Nicola Caporaso", 
    "publish": "2010-01-26T12:22:33Z", 
    "summary": "We show that all languages accepted in time f(n) >= n^2 can be accepted in\nspace O(f(n)^{1/2})_and_ in time O(f(n)). The proof is carried out by\nsimulation, based on the idea of guessing the sequences of internal states of\nthe simulated TM when entering certain critical cells, whose location is also\nguessed. Our method cannot be generalised easily to many-tapes TMs, and in no\ncase can it be relativised."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.4687v1", 
    "title": "m-sophistication", 
    "arxiv-id": "1001.4687v1", 
    "author": "Bruno Bauwens", 
    "publish": "2010-01-26T13:53:08Z", 
    "summary": "The m-sophistication of a finite binary string x is introduced as a\ngeneralization of some parameter in the proof that complexity of complexity is\nrare. A probabilistic near sufficient statistic of x is given which length is\nupper bounded by the m-sophistication of x within small additive terms. This\nshows that m-sophistication is lower bounded by coarse sophistication and upper\nbounded by sophistication within small additive terms. It is also shown that\nm-sophistication and coarse sophistication can not be approximated by an upper\nor lower semicomputable function, not even within very large error."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1001.4987v2", 
    "title": "The Complexity of Approximating Bounded-Degree Boolean #CSP (Extended   Abstract)", 
    "arxiv-id": "1001.4987v2", 
    "author": "David Richerby", 
    "publish": "2010-01-27T17:07:40Z", 
    "summary": "The degree of a CSP instance is the maximum number of times that a variable\nmay appear in the scope of constraints. We consider the approximate counting\nproblem for Boolean CSPs with bounded-degree instances, for constraint\nlanguages containing the two unary constant relations {0} and {1}. When the\nmaximum degree is at least 25 we obtain a complete classification of the\ncomplexity of this problem. It is exactly solvable in polynomial-time if every\nrelation in the constraint language is affine. It is equivalent to the problem\nof approximately counting independent sets in bipartite graphs if every\nrelation can be expressed as conjunctions of {0}, {1} and binary implication.\nOtherwise, there is no FPRAS unless NP=RP. For lower degree bounds, additional\ncases arise in which the complexity is related to the complexity of\napproximately counting independent sets in hypergraphs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1002.1496v1", 
    "title": "Deterministic Black-Box Identity Testing $\u03c0$-Ordered Algebraic   Branching Programs", 
    "arxiv-id": "1002.1496v1", 
    "author": "Jayalal Sarma", 
    "publish": "2010-02-07T22:40:21Z", 
    "summary": "In this paper we study algebraic branching programs (ABPs) with restrictions\non the order and the number of reads of variables in the program. Given a\npermutation $\\pi$ of $n$ variables, for a $\\pi$-ordered ABP ($\\pi$-OABP), for\nany directed path $p$ from source to sink, a variable can appear at most once\non $p$, and the order in which variables appear on $p$ must respect $\\pi$. An\nABP $A$ is said to be of read $r$, if any variable appears at most $r$ times in\n$A$. Our main result pertains to the identity testing problem. Over any field\n$F$ and in the black-box model, i.e. given only query access to the polynomial,\nwe have the following result: read $r$ $\\pi$-OABP computable polynomials can be\ntested in $\\DTIME[2^{O(r\\log r \\cdot \\log^2 n \\log\\log n)}]$.\n  Our next set of results investigates the computational limitations of OABPs.\nIt is shown that any OABP computing the determinant or permanent requires size\n$\\Omega(2^n/n)$ and read $\\Omega(2^n/n^2)$. We give a multilinear polynomial\n$p$ in $2n+1$ variables over some specifically selected field $G$, such that\nany OABP computing $p$ must read some variable at least $2^n$ times. We show\nthat the elementary symmetric polynomial of degree $r$ in $n$ variables can be\ncomputed by a size $O(rn)$ read $r$ OABP, but not by a read $(r-1)$ OABP, for\nany $0 < 2r-1 \\leq n$. Finally, we give an example of a polynomial $p$ and two\nvariables orders $\\pi \\neq \\pi'$, such that $p$ can be computed by a read-once\n$\\pi$-OABP, but where any $\\pi'$-OABP computing $p$ must read some variable at\nleast $2^n$"
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_8", 
    "link": "http://arxiv.org/pdf/1002.1606v4", 
    "title": "Derandomized Parallel Repetition via Structured PCPs", 
    "arxiv-id": "1002.1606v4", 
    "author": "Or Meir", 
    "publish": "2010-02-08T13:59:28Z", 
    "summary": "A PCP is a proof system for NP in which the proof can be checked by a\nprobabilistic verifier. The verifier is only allowed to read a very small\nportion of the proof, and in return is allowed to err with some bounded\nprobability. The probability that the verifier accepts a false proof is called\nthe soundness error, and is an important parameter of a PCP system that one\nseeks to minimize. Constructing PCPs with sub-constant soundness error and, at\nthe same time, a minimal number of queries into the proof (namely two) is\nespecially important due to applications for inapproximability.\n  In this work we construct such PCP verifiers, i.e., PCPs that make only two\nqueries and have sub-constant soundness error. Our construction can be viewed\nas a combinatorial alternative to the \"manifold vs. point\" construction, which\nis the only construction in the literature for this parameter range. The\n\"manifold vs. point\" PCP is based on a low degree test, while our construction\nis based on a direct product test. We also extend our construction to yield a\ndecodable PCP (dPCP) with the same parameters. By plugging in this dPCP into\nthe scheme of Dinur and Harsha (FOCS 2009) one gets an alternative construction\nof the result of Moshkovitz and Raz (FOCS 2008), namely: a construction of\ntwo-query PCPs with small soundness error and small alphabet size.\n  Our construction of a PCP is based on extending the derandomized direct\nproduct test of Impagliazzo, Kabanets and Wigderson (STOC 09) to a derandomized\nparallel repetition theorem. More accurately, our PCP construction is obtained\nin two steps. We first prove a derandomized parallel repetition theorem for\nspecially structured PCPs. Then, we show that any PCP can be transformed into\none that has the required structure, by embedding it on a de-Bruijn graph."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1002.1880v4", 
    "title": "Finding and counting vertex-colored subtrees", 
    "arxiv-id": "1002.1880v4", 
    "author": "Florian Sikora", 
    "publish": "2010-02-09T15:19:54Z", 
    "summary": "The problems studied in this article originate from the Graph Motif problem\nintroduced by Lacroix et al. in the context of biological networks. The problem\nis to decide if a vertex-colored graph has a connected subgraph whose colors\nequal a given multiset of colors $M$. It is a graph pattern-matching problem\nvariant, where the structure of the occurrence of the pattern is not of\ninterest but the only requirement is the connectedness. Using an algebraic\nframework recently introduced by Koutis et al., we obtain new FPT algorithms\nfor Graph Motif and variants, with improved running times. We also obtain\nresults on the counting versions of this problem, proving that the counting\nproblem is FPT if M is a set, but becomes W[1]-hard if M is a multiset with two\ncolors. Finally, we present an experimental evaluation of this approach on real\ndatasets, showing that its performance compares favorably with existing\nsoftware."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1002.3453v1", 
    "title": "On the complexity of stratified logics", 
    "arxiv-id": "1002.3453v1", 
    "author": "Luca Vercelli", 
    "publish": "2010-02-18T08:41:01Z", 
    "summary": "Our primary motivation is the comparison of two different traditions used in\nICC to characterize the class FPTIME of the polynomial time computable\nfunctions. On one side, FPTIME can be captured by Intuitionistic Light Affine\nLogic (ILAL), a logic derived from Linear Logic, characterized by the\nstructural invariant Stratification. On the other side, FPTIME can be captured\nby Safe Recursion on Notation (SRN), an algebra of functions based on\nPredicative Recursion, a restriction of the standard recursion schema used to\ndefiine primitive recursive functions. Stratifiication and Predicative\nRecursion seem to share common underlying principles, whose study is the main\nsubject of this work."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1002.3664v1", 
    "title": "A PCP Characterization of AM", 
    "arxiv-id": "1002.3664v1", 
    "author": "Andrew Drucker", 
    "publish": "2010-02-19T03:34:59Z", 
    "summary": "We introduce a 2-round stochastic constraint-satisfaction problem, and show\nthat its approximation version is complete for (the promise version of) the\ncomplexity class AM. This gives a `PCP characterization' of AM analogous to the\nPCP Theorem for NP. Similar characterizations have been given for higher levels\nof the Polynomial Hierarchy, and for PSPACE; however, we suggest that the\nresult for AM might be of particular significance for attempts to derandomize\nthis class.\n  To test this notion, we pose some `Randomized Optimization Hypotheses'\nrelated to our stochastic CSPs that (in light of our result) would imply\ncollapse results for AM. Unfortunately, the hypotheses appear over-strong, and\nwe present evidence against them. In the process we show that, if some language\nin NP is hard-on-average against circuits of size 2^{Omega(n)}, then there\nexist hard-on-average optimization problems of a particularly elegant form.\n  All our proofs use a powerful form of PCPs known as Probabilistically\nCheckable Proofs of Proximity, and demonstrate their versatility. We also use\nknown results on randomness-efficient soundness- and hardness-amplification. In\nparticular, we make essential use of the Impagliazzo-Wigderson generator; our\nanalysis relies on a recent Chernoff-type theorem for expander walks."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1002.3769v2", 
    "title": "Polyominoes Simulating Arbitrary-Neighborhood Zippers and Tilings", 
    "arxiv-id": "1002.3769v2", 
    "author": "Beno\u00eet Masson", 
    "publish": "2010-02-19T16:19:53Z", 
    "summary": "This paper provides a bridge between the classical tiling theory and the\ncomplex neighborhood self-assembling situations that exist in practice. The\nneighborhood of a position in the plane is the set of coordinates which are\nconsidered adjacent to it. This includes classical neighborhoods of size four,\nas well as arbitrarily complex neighborhoods. A generalized tile system\nconsists of a set of tiles, a neighborhood, and a relation which dictates which\nare the \"admissible\" neighboring tiles of a given tile. Thus, in correctly\nformed assemblies, tiles are assigned positions of the plane in accordance to\nthis relation. We prove that any validly tiled path defined in a given but\narbitrary neighborhood (a zipper) can be simulated by a simple \"ribbon\" of\nmicrotiles. A ribbon is a special kind of polyomino, consisting of a\nnon-self-crossing sequence of tiles on the plane, in which successive tiles\nstick along their adjacent edge. Finally, we extend this construction to the\ncase of traditional tilings, proving that we can simulate\narbitrary-neighborhood tilings by simple-neighborhood tilings, while preserving\nsome of their essential properties."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1002.4084v1", 
    "title": "Properties of Pseudo-Primitive Words and their Applications", 
    "arxiv-id": "1002.4084v1", 
    "author": "Shinnosuke Seki", 
    "publish": "2010-02-22T09:40:13Z", 
    "summary": "A pseudo-primitive word with respect to an antimorphic involution \\theta is a\nword which cannot be written as a catenation of occurrences of a strictly\nshorter word t and \\theta(t). Properties of pseudo-primitive words are\ninvestigated in this paper. These properties link pseudo-primitive words with\nessential notions in combinatorics on words such as primitive words,\n(pseudo)-palindromes, and (pseudo)-commutativity. Their applications include an\nimproved solution to the extended Lyndon-Sch\\\"utzenberger equation u_1 u_2 ...\nu_l = v_1 ... v_n w_1 ... w_m, where u_1, ..., u_l \\in {u, \\theta(u)}, v_1,\n..., v_n \\in {v, \\theta(v)}, and w_1, ..., w_m \\in {w, \\theata(w)} for some\nwords u, v, w, integers l, n, m \\ge 2, and an antimorphic involution \\theta. We\nprove that for l \\ge 4, n,m \\ge 3, this equation implies that u, v, w can be\nexpressed in terms of a common word t and its image \\theta(t). Moreover,\nseveral cases of this equation where l = 3 are examined."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1002.4676v1", 
    "title": "Pebbling and Branching Programs Solving the Tree Evaluation Problem", 
    "arxiv-id": "1002.4676v1", 
    "author": "Dustin Wehr", 
    "publish": "2010-02-25T01:41:38Z", 
    "summary": "We study restricted computation models related to the Tree Evaluation\nProblem}. The TEP was introduced in earlier work as a simple candidate for the\n(*very*) long term goal of separating L and LogDCFL. The input to the problem\nis a rooted, balanced binary tree of height h, whose internal nodes are labeled\nwith binary functions on [k] = {1,...,k} (each given simply as a list of k^2\nelements of [k]), and whose leaves are labeled with elements of [k]. Each node\nobtains a value in [k] equal to its binary function applied to the values of\nits children, and the output is the value of the root. The first restricted\ncomputation model, called Fractional Pebbling, is a generalization of the\nblack/white pebbling game on graphs, and arises in a natural way from the\nsearch for good upper bounds on the size of nondeterministic branching programs\n(BPs) solving the TEP - for any fixed h, if the binary tree of height h has\nfractional pebbling cost at most p, then there are nondeterministic BPs of size\nO(k^p) solving the height h TEP. We prove a lower bound on the fractional\npebbling cost of d-ary trees that is tight to within an additive constant for\neach fixed d. The second restricted computation model we study is a semantic\nrestriction on (non)deterministic BPs solving the TEP - Thrifty BPs.\nDeterministic (resp. nondeterministic) thrifty BPs suffice to implement the\nbest known algorithms for the TEP, based on black (resp. fractional) pebbling.\nIn earlier work, for each fixed h a lower bound on the size of deterministic\nthrifty BPs was proved that is tight for sufficiently large k. We give an\nalternative proof that achieves the same bound for all k. We show the same\nbound still holds in a less-restricted model, and also that gradually weaker\nlower bounds can be obtained for gradually weaker restrictions on the model."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1003.1164v1", 
    "title": "Repeating Patterns in Linear Programs that express NP-Complete Problems", 
    "arxiv-id": "1003.1164v1", 
    "author": "Deepak Ponvel Chermakani", 
    "publish": "2010-03-05T13:02:18Z", 
    "summary": "One of my recent papers transforms an NP-Complete problem into the question\nof whether or not a feasible real solution exists to some Linear Program. The\nunique feature of this Linear Program is that though there is no explicit bound\non the minimum required number of linear inequalities, which is most probably\nexponential to the size of the NP-Complete problem, the Linear Program can\nstill be described efficiently. The reason for this efficient description is\nthat coefficients keep repeating in some pattern, even as the number of\ninequalities is conveniently assumed to tend to Infinity. I discuss why this\nconvenient assumption does not change the feasibility result of the Linear\nProgram. I conclude with two Conjectures, which might help to make an efficient\ndecision on the feasibility of this Linear Program."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1003.3704v2", 
    "title": "On a variant of Monotone NAE-3SAT and the Triangle-Free Cut problem", 
    "arxiv-id": "1003.3704v2", 
    "author": "Peiyush Jain", 
    "publish": "2010-03-19T02:45:38Z", 
    "summary": "In this paper we define a restricted version of Monotone NAE-3SAT and show\nthat it remains NP-Complete even under that restriction. We expect this result\nwould be useful in proving NP-Completeness results for problems on\n$k$-colourable graphs ($k \\ge 5$). We also prove the NP-Completeness of the\nTriangle-Free Cut problem."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1003.3879v4", 
    "title": "An Effective Dichotomy for the Counting Constraint Satisfaction Problem", 
    "arxiv-id": "1003.3879v4", 
    "author": "David Richerby", 
    "publish": "2010-03-19T20:09:09Z", 
    "summary": "Bulatov (2008) gave a dichotomy for the counting constraint satisfaction\nproblem #CSP. A problem from #CSP is characterised by a constraint language,\nwhich is a fixed, finite set of relations over a finite domain D. An instance\nof the problem uses these relations to constrain the variables in a larger set.\nBulatov showed that the problem of counting the satisfying assignments of\ninstances of any problem from #CSP is either in polynomial time (FP) or is\n#P-complete. His proof draws heavily on techniques from universal algebra and\ncannot be understood without a secure grasp of that field. We give an\nelementary proof of Bulatov's dichotomy, based on succinct representations,\nwhich we call frames, of a class of highly structured relations, which we call\nstrongly rectangular. We show that these are precisely the relations which are\ninvariant under a Mal'tsev polymorphism. En route, we give a simplification of\na decision algorithm for strongly rectangular constraint languages, due to\nBulatov and Dalmau (2006). We establish a new criterion for the #CSP dichotomy,\nwhich we call strong balance, and we prove that this property is decidable. In\nfact, we establish membership in NP. Thus, we show that the dichotomy is\neffective, resolving the most important open question concerning the #CSP\ndichotomy."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-011-9600-8", 
    "link": "http://arxiv.org/pdf/1003.4029v3", 
    "title": "On Extractors and Exposure-Resilient Functions for Sublogarithmic   Entropy", 
    "arxiv-id": "1003.4029v3", 
    "author": "Salil Vadhan", 
    "publish": "2010-03-21T21:22:56Z", 
    "summary": "We study deterministic extractors for oblivious bit-fixing sources (a.k.a.\nresilient functions) and exposure-resilient functions with small min-entropy:\nof the function's n input bits, k << n bits are uniformly random and unknown to\nthe adversary. We simplify and improve an explicit construction of extractors\nfor bit-fixing sources with sublogarithmic k due to Kamp and Zuckerman (SICOMP\n2006), achieving error exponentially small in k rather than polynomially small\nin k. Our main result is that when k is sublogarithmic in n, the short output\nlength of this construction (O(log k) output bits) is optimal for extractors\ncomputable by a large class of space-bounded streaming algorithms.\n  Next, we show that a random function is an extractor for oblivious bit-fixing\nsources with high probability if and only if k is superlogarithmic in n,\nsuggesting that our main result may apply more generally. In contrast, we show\nthat a random function is a static (resp. adaptive) exposure-resilient function\nwith high probability even if k is as small as a constant (resp. log log n). No\nexplicit exposure-resilient functions achieving these parameters are known."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.03.027", 
    "link": "http://arxiv.org/pdf/1004.0436v1", 
    "title": "On the parity complexity measures of Boolean functions", 
    "arxiv-id": "1004.0436v1", 
    "author": "Yaoyun Shi", 
    "publish": "2010-04-03T10:59:30Z", 
    "summary": "The parity decision tree model extends the decision tree model by allowing\nthe computation of a parity function in one step. We prove that the\ndeterministic parity decision tree complexity of any Boolean function is\npolynomially related to the non-deterministic complexity of the function or its\ncomplement. We also show that they are polynomially related to an analogue of\nthe block sensitivity. We further study parity decision trees in their\nrelations with an intermediate variant of the decision trees, as well as with\ncommunication complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.03.027", 
    "link": "http://arxiv.org/pdf/1004.0803v1", 
    "title": "From Holant To #CSP And Back: Dichotomy For Holant$^c$ Problems", 
    "arxiv-id": "1004.0803v1", 
    "author": "Pinyan Lu", 
    "publish": "2010-04-06T09:07:21Z", 
    "summary": "We explore the intricate interdependent relationship among counting problems,\nconsidered from three frameworks for such problems: Holant Problems, counting\nCSP and weighted H-colorings. We consider these problems for general complex\nvalued functions that take boolean inputs. We show that results from one\nframework can be used to derive results in another, and this happens in both\ndirections. Holographic reductions discover an underlying unity, which is only\nrevealed when these counting problems are investigated in the complex domain\n$\\mathbb{C}$. We prove three complexity dichotomy theorems, leading to a\ngeneral theorem for Holant$^c$ problems. This is the natural class of Holant\nproblems where one can assign constants 0 or 1. More specifically, given any\nsignature grid on $G=(V,E)$ over a set ${\\mathscr F}$ of symmetric functions,\nwe completely classify the complexity to be in P or #P-hard, according to\n${\\mathscr F}$, of \\[\\sum_{\\sigma: E \\rightarrow \\{0,1\\}} \\prod_{v\\in V}\nf_v(\\sigma\\mid_{E(v)}),\\] where $f_v \\in {\\mathscr F} \\cup \\{{\\bf 0}, {\\bf\n1}\\}$ ({\\bf 0}, {\\bf 1} are the unary constant 0, 1 functions). Not only is\nholographic reduction the main tool, but also the final dichotomy can be only\nnaturally stated in the language of holographic transformations. The proof goes\nthrough another dichotomy theorem on boolean complex weighted #CSP."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2010.03.027", 
    "link": "http://arxiv.org/pdf/1004.0817v1", 
    "title": "A Separation of NP and coNP in Multiparty Communication Complexity", 
    "arxiv-id": "1004.0817v1", 
    "author": "Alexander A. Sherstov", 
    "publish": "2010-04-06T10:29:00Z", 
    "summary": "We prove that NP differs from coNP and coNP is not a subset of MA in the\nnumber-on-forehead model of multiparty communication complexity for up to k =\n(1-\\epsilon)log(n) players, where \\epsilon>0 is any constant. Specifically, we\nconstruct a function F with co-nondeterministic complexity O(log(n)) and\nMerlin-Arthur complexity n^{\\Omega(1)}. The problem was open for k > 2."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-13962-8_15", 
    "link": "http://arxiv.org/pdf/1004.0871v1", 
    "title": "On the Complexity of Local Search for Weighted Standard Set Problems", 
    "arxiv-id": "1004.0871v1", 
    "author": "Tim S\u00fc\u00df", 
    "publish": "2010-04-06T15:24:39Z", 
    "summary": "In this paper, we study the complexity of computing locally optimal solutions\nfor weighted versions of standard set problems such as SetCover, SetPacking,\nand many more. For our investigation, we use the framework of PLS, as defined\nin Johnson et al., [JPY88]. We show that for most of these problems, computing\na locally optimal solution is already PLS-complete for a simple neighborhood of\nsize one. For the local search versions of weighted SetPacking and SetCover, we\nderive tight bounds for a simple neighborhood of size two. To the best of our\nknowledge, these are one of the very few PLS results about local search for\nweighted standard set problems."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-13962-8_15", 
    "link": "http://arxiv.org/pdf/1004.2159v2", 
    "title": "Algebraic Proofs over Noncommutative Formulas", 
    "arxiv-id": "1004.2159v2", 
    "author": "Iddo Tzameret", 
    "publish": "2010-04-13T12:13:13Z", 
    "summary": "We study possible formulations of algebraic propositional proof systems\noperating with noncommutative formulas. We observe that a simple formulation\ngives rise to systems at least as strong as Frege---yielding a semantic way to\ndefine a Cook-Reckhow (i.e., polynomially verifiable) algebraic analog of Frege\nproofs, different from that given in [BIKPRS96,GH03]. We then turn to an\napparently weaker system, namely, polynomial calculus (PC) where polynomials\nare written as ordered formulas (PC over ordered formulas, for short): an\nordered polynomial is a noncommutative polynomial in which the order of\nproducts in every monomial respects a fixed linear order on variables; an\nalgebraic formula is ordered if the polynomial computed by each of its\nsubformulas is ordered. We show that PC over ordered formulas is strictly\nstronger than resolution, polynomial calculus and polynomial calculus with\nresolution (PCR) and admits polynomial-size refutations for the pigeonhole\nprinciple and the Tseitin's formulas. We conclude by proposing an approach for\nestablishing lower bounds on PC over ordered formulas proofs, and related\nsystems, based on properties of lower bounds on noncommutative formulas.\n  The motivation behind this work is developing techniques incorporating rank\narguments (similar to those used in algebraic circuit complexity) for\nestablishing lower bounds on propositional proofs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-13962-8_15", 
    "link": "http://arxiv.org/pdf/1004.2891v1", 
    "title": "On the approximability of robust spanning tree problems", 
    "arxiv-id": "1004.2891v1", 
    "author": "Pawel Zielinski", 
    "publish": "2010-04-16T17:40:01Z", 
    "summary": "In this paper the minimum spanning tree problem with uncertain edge costs is\ndiscussed. In order to model the uncertainty a discrete scenario set is\nspecified and a robust framework is adopted to choose a solution. The min-max,\nmin-max regret and 2-stage min-max versions of the problem are discussed. The\ncomplexity and approximability of all these problems are explored. It is proved\nthat the min-max and min-max regret versions with nonnegative edge costs are\nhard to approximate within $O(\\log^{1-\\epsilon} n)$ for any $\\epsilon>0$ unless\nthe problems in NP have quasi-polynomial time algorithms. Similarly, the\n2-stage min-max problem cannot be approximated within $O(\\log n)$ unless the\nproblems in NP have quasi-polynomial time algorithms. In this paper randomized\nLP-based approximation algorithms with performance ratio of $O(\\log^2 n)$ for\nmin-max and 2-stage min-max problems are also proposed."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.3020v1", 
    "title": "Enumeration of the Monomials of a Polynomial and Related Complexity   Classes", 
    "arxiv-id": "1004.3020v1", 
    "author": "Yann Strozecki", 
    "publish": "2010-04-18T13:11:32Z", 
    "summary": "We study the problem of generating monomials of a polynomial in the context\nof enumeration complexity. In this setting, the complexity measure is the delay\nbetween two solutions and the total time. We present two new algorithms for\nrestricted classes of polynomials, which have a good delay and the same global\nrunning time as the classical ones. Moreover they are simple to describe, use\nlittle evaluation points and one of them is parallelizable. We introduce three\nnew complexity classes, TotalPP, IncPP and DelayPP, which are probabilistic\ncounterparts of the most common classes for enumeration problems, hoping that\nrandomization will be a tool as strong for enumeration as it is for decision.\nOur interpolation algorithms proves that a lot of interesting problems are in\nthese classes like the enumeration of the spanning hypertrees of a 3-uniform\nhypergraph.\n  Finally we give a method to interpolate a degree 2 polynomials with an\nacceptable (incremental) delay. We also prove that finding a specified monomial\nin a degree 2 polynomial is hard unless RP = NP. It suggests that there is no\nalgorithm with a delay as good (polynomial) as the one we achieve for\nmultilinear polynomials."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.3659v1", 
    "title": "Parameterized Control Complexity in Fallback Voting", 
    "arxiv-id": "1004.3659v1", 
    "author": "Michael Fellows", 
    "publish": "2010-04-21T09:18:50Z", 
    "summary": "We study the parameterized control complexity of fallback voting, a voting\nsystem that combines preference-based with approval voting. Electoral control\nis one of many different ways for an external agent to tamper with the outcome\nof an election. We show that adding and deleting candidates in fallback voting\nare W[2]-hard for both the constructive and destructive case, parameterized by\nthe amount of action taken by the external agent. Furthermore, we show that\nadding and deleting voters in fallback voting are W[2]-hard for the\nconstructive case, parameterized by the amount of action taken by the external\nagent, and are in FPT for the destructive case."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.3777v1", 
    "title": "Improved Inapproximability For Submodular Maximization", 
    "arxiv-id": "1004.3777v1", 
    "author": "Per Austrin", 
    "publish": "2010-04-21T19:19:22Z", 
    "summary": "We show that it is Unique Games-hard to approximate the maximum of a\nsubmodular function to within a factor 0.695, and that it is Unique Games-hard\nto approximate the maximum of a symmetric submodular function to within a\nfactor 0.739. These results slightly improve previous results by Feige,\nMirrokni and Vondr\\'ak (FOCS 2007) who showed that these problems are NP-hard\nto approximate to within $3/4 + \\epsilon \\approx 0.750$ and $5/6 + \\epsilon\n\\approx 0.833$, respectively."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.3993v1", 
    "title": "An Oracle Strongly Separating Deterministic Time from Nondeterministic   Time, via Kolmogorov Complexity", 
    "arxiv-id": "1004.3993v1", 
    "author": "David Doty", 
    "publish": "2010-04-22T19:35:46Z", 
    "summary": "Hartmanis used Kolmogorov complexity to provide an alternate proof of the\nclassical result of Baker, Gill, and Solovay that there is an oracle relative\nto which P is not NP. We refine the technique to strengthen the result,\nconstructing an oracle relative to which a conjecture of Lipton is false."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.4383v2", 
    "title": "Self-Assembly of Arbitrary Shapes Using RNAse Enzymes: Meeting the   Kolmogorov Bound with Small Scale Factor (extended abstract)", 
    "arxiv-id": "1004.4383v2", 
    "author": "Scott M. Summers", 
    "publish": "2010-04-25T22:06:34Z", 
    "summary": "We consider a model of algorithmic self-assembly of geometric shapes out of\nsquare Wang tiles studied in SODA 2010, in which there are two types of tiles\n(e.g., constructed out of DNA and RNA material) and one operation that destroys\nall tiles of a particular type (e.g., an RNAse enzyme destroys all RNA tiles).\nWe show that a single use of this destruction operation enables much more\nefficient construction of arbitrary shapes. In particular, an arbitrary shape\ncan be constructed using an asymptotically optimal number of distinct tile\ntypes (related to the shape's Kolmogorov complexity), after scaling the shape\nby only a logarithmic factor. By contrast, without the destruction operation,\nthe best such result has a scale factor at least linear in the size of the\nshape, and is connected only by a spanning tree of the scaled tiles. We also\ncharacterize a large collection of shapes that can be constructed efficiently\nwithout any scaling."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.4960v4", 
    "title": "Shallow Circuits with High-Powered Inputs", 
    "arxiv-id": "1004.4960v4", 
    "author": "Pascal Koiran", 
    "publish": "2010-04-28T06:50:52Z", 
    "summary": "A polynomial identity testing algorithm must determine whether an input\npolynomial (given for instance by an arithmetic circuit) is identically equal\nto 0. In this paper, we show that a deterministic black-box identity testing\nalgorithm for (high-degree) univariate polynomials would imply a lower bound on\nthe arithmetic complexity of the permanent. The lower bounds that are known to\nfollow from derandomization of (low-degree) multivariate identity testing are\nweaker. To obtain our lower bound it would be sufficient to derandomize\nidentity testing for polynomials of a very specific norm: sums of products of\nsparse polynomials with sparse coefficients. This observation leads to new\nversions of the Shub-Smale tau-conjecture on integer roots of univariate\npolynomials. In particular, we show that a lower bound for the permanent would\nfollow if one could give a good enough bound on the number of real roots of\nsums of products of sparse polynomials (Descartes' rule of signs gives such a\nbound for sparse polynomials and products thereof). In this third version of\nour paper we show that the same lower bound would follow even if one could only\nprove a slightly superpolynomial upper bound on the number of real roots. This\nis a consequence of a new result on reduction to depth 4 for arithmetic\ncircuits which we establish in a companion paper. We also show that an even\nweaker bound on the number of real roots would suffice to obtain a lower bound\non the size of depth 4 circuits computing the permanent."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.5080v1", 
    "title": "Space Complexity of Perfect Matching in Bounded Genus Bipartite Graphs", 
    "arxiv-id": "1004.5080v1", 
    "author": "N. V. Vinodchandran", 
    "publish": "2010-04-28T16:57:16Z", 
    "summary": "We investigate the space complexity of certain perfect matching problems over\nbipartite graphs embedded on surfaces of constant genus (orientable or\nnon-orientable). We show that the problems of deciding whether such graphs have\n(1) a perfect matching or not and (2) a unique perfect matching or not, are in\nthe logspace complexity class \\SPL. Since \\SPL\\ is contained in the logspace\ncounting classes $\\oplus\\L$ (in fact in \\modk\\ for all $k\\geq 2$), \\CeqL, and\n\\PL, our upper bound places the above-mentioned matching problems in these\ncounting classes as well. We also show that the search version, computing a\nperfect matching, for this class of graphs is in $\\FL^{\\SPL}$. Our results\nextend the same upper bounds for these problems over bipartite planar graphs\nknown earlier. As our main technical result, we design a logspace computable\nand polynomially bounded weight function which isolates a minimum weight\nperfect matching in bipartite graphs embedded on surfaces of constant genus. We\nuse results from algebraic topology for proving the correctness of the weight\nfunction."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.5236v1", 
    "title": "Circuits with arbitrary gates for random operators", 
    "arxiv-id": "1004.5236v1", 
    "author": "G. Schnitger", 
    "publish": "2010-04-29T09:38:18Z", 
    "summary": "We consider boolean circuits computing n-operators f:{0,1}^n --> {0,1}^n. As\ngates we allow arbitrary boolean functions; neither fanin nor fanout of gates\nis restricted. An operator is linear if it computes n linear forms, that is,\ncomputes a matrix-vector product y=Ax over GF(2). We prove the existence of\nn-operators requiring about n^2 wires in any circuit, and linear n-operators\nrequiring about n^2/\\log n wires in depth-2 circuits, if either all output\ngates or all gates on the middle layer are linear."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1004.5329v3", 
    "title": "Settling the complexity of local max-cut (almost) completely", 
    "arxiv-id": "1004.5329v3", 
    "author": "Tobias Tscheuschner", 
    "publish": "2010-04-29T15:53:00Z", 
    "summary": "We consider the problem of finding a local optimum for Max-Cut with\nFLIP-neighborhood, in which exactly one node changes the partition. Schaeffer\nand Yannakakis (SICOMP, 1991) showed PLS-completeness of this problem on graphs\nwith unbounded degree. On the other side, Poljak (SICOMP, 1995) showed that in\ncubic graphs every FLIP local search takes O(n^2) steps, where n is the number\nof nodes. Due to the huge gap between degree three and unbounded degree,\nAckermann, Roeglin, and Voecking (JACM, 2008) asked for the smallest d for\nwhich the local Max-Cut problem with FLIP-neighborhood on graphs with maximum\ndegree d is PLS-complete. In this paper, we prove that the computation of a\nlocal optimum on graphs with maximum degree five is PLS-complete. Thus, we\nsolve the problem posed by Ackermann et al. almost completely by showing that d\nis either four or five (unless PLS is in P). On the other side, we also prove\nthat on graphs with degree O(log n) every FLIP local search has probably\npolynomial smoothed complexity. Roughly speaking, for any instance, in which\nthe edge weights are perturbated by a (Gaussian) random noise with variance\n\\sigma^2, every FLIP local search terminates in time polynomial in n and\n\\sigma^{-1}, with probability 1-n^{-\\Omega(1)}. Putting both results together,\nwe may conclude that although local Max-Cut is likely to be hard on graphs with\nbounded degree, it can be solved in polynomial time for slightly perturbated\ninstances with high probability."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_55", 
    "link": "http://arxiv.org/pdf/1005.0644v2", 
    "title": "Improved Direct Product Theorems for Randomized Query Complexity", 
    "arxiv-id": "1005.0644v2", 
    "author": "Andrew Drucker", 
    "publish": "2010-05-04T22:46:36Z", 
    "summary": "The direct product problem is a fundamental question in complexity theory\nwhich seeks to understand how the difficulty of computing a function on each of\nk independent inputs scales with k. We prove the following direct product\ntheorem (DPT) for query complexity: if every T-query algorithm has success\nprobability at most 1 - eps in computing the Boolean function f on input\ndistribution Mu, then for alpha <= 1, every (alpha eps Tk)-query algorithm has\nsuccess probability at most (2^{alpha eps}(1 - eps))^k in computing the k-fold\ndirect product f^k correctly on k independent inputs from Mu. In light of\nexamples due to Shaltiel, this statement gives an essentially optimal tradeoff\nbetween the query bound and the error probability. As a corollary, we show that\nfor an absolute constant alpha > 0, the worst-case success probability of any\n(alpha R_2(f)k)-query randomized algorithm for f^k falls exponentially with k.\nThe best previous statement of this type, due to Klauck, Spalek, and de Wolf,\nrequired a query bound of O(bs(f)k). The proof involves defining and analyzing\na collection of martingales associated with an algorithm attempting to solve\nf^k. Our method is quite general and yields a new XOR lemma and threshold DPT\nfor the query model, as well as DPTs for the query complexity of learning\ntasks, search problems, and tasks involving interaction with dyamic entities.\nWe also give a version of our DPT in which decision tree size is the resource\nof interest."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2009.09.003", 
    "link": "http://arxiv.org/pdf/1005.1009v1", 
    "title": "Min-Rank Conjecture for Log-Depth Circuits", 
    "arxiv-id": "1005.1009v1", 
    "author": "G. Schnitger", 
    "publish": "2010-05-06T14:30:51Z", 
    "summary": "A completion of an m-by-n matrix A with entries in {0,1,*} is obtained by\nsetting all *-entries to constants 0 or 1. A system of semi-linear equations\nover GF(2) has the form Mx=f(x), where M is a completion of A and f:{0,1}^n -->\n{0,1}^m is an operator, the i-th coordinate of which can only depend on\nvariables corresponding to *-entries in the i-th row of A. We conjecture that\nno such system can have more than 2^{n-c\\cdot mr(A)} solutions, where c>0 is an\nabsolute constant and mr(A) is the smallest rank over GF(2) of a completion of\nA. The conjecture is related to an old problem of proving super-linear lower\nbounds on the size of log-depth boolean circuits computing linear operators x\n--> Mx. The conjecture is also a generalization of a classical question about\nhow much larger can non-linear codes be than linear ones. We prove some special\ncases of the conjecture and establish some structural properties of solution\nsets."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2009.09.003", 
    "link": "http://arxiv.org/pdf/1005.2400v2", 
    "title": "A Short Introduction to Kolmogorov Complexity", 
    "arxiv-id": "1005.2400v2", 
    "author": "Volker Nannen", 
    "publish": "2010-05-13T19:22:14Z", 
    "summary": "This is a short introduction to Kolmogorov Complexity. The interested reader\nis referred to the text books by Cover & Thomas as well as Li & V\\'itanyi,\nwhich cover the fields of information theory and Kolmogorov complexity in depth\nand with all the necessary rigor."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_16", 
    "link": "http://arxiv.org/pdf/1005.2632v1", 
    "title": "On Tractable Exponential Sums", 
    "arxiv-id": "1005.2632v1", 
    "author": "Pinyan Lu", 
    "publish": "2010-05-14T21:31:11Z", 
    "summary": "We consider the problem of evaluating certain exponential sums. These sums\ntake the form $\\sum_{x_1,...,x_n \\in Z_N} e^{f(x_1,...,x_n) {2 \\pi i / N}} $,\nwhere each x_i is summed over a ring Z_N, and f(x_1,...,x_n) is a multivariate\npolynomial with integer coefficients. We show that the sum can be evaluated in\npolynomial time in n and log N when f is a quadratic polynomial. This is true\neven when the factorization of N is unknown. Previously, this was known for a\nprime modulus N. On the other hand, for very specific families of polynomials\nof degree \\ge 3, we show the problem is #P-hard, even for any fixed prime or\nprime power modulus. This leads to a complexity dichotomy theorem - a complete\nclassification of each problem to be either computable in polynomial time or\n#P-hard - for a class of exponential sums. These sums arise in the\nclassifications of graph homomorphisms and some other counting CSP type\nproblems, and these results lead to complexity dichotomy theorems. For the\npolynomial-time algorithm, Gauss sums form the basic building blocks. For the\nhardness results, we prove group-theoretic necessary conditions for\ntractability. These tests imply that the problem is #P-hard for even very\nrestricted families of simple cubic polynomials over fixed modulus N."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-14553-7_16", 
    "link": "http://arxiv.org/pdf/1005.2642v1", 
    "title": "Pebbles and Branching Programs for Tree Evaluation", 
    "arxiv-id": "1005.2642v1", 
    "author": "Rahul Santhanam", 
    "publish": "2010-05-15T00:23:45Z", 
    "summary": "We introduce the Tree Evaluation Problem, show that it is in logDCFL (and\nhence in P), and study its branching program complexity in the hope of\neventually proving a superlogarithmic space lower bound. The input to the\nproblem is a rooted, balanced d-ary tree of height h, whose internal nodes are\nlabeled with d-ary functions on [k] = {1,...,k}, and whose leaves are labeled\nwith elements of [k]. Each node obtains a value in [k] equal to its d-ary\nfunction applied to the values of its d children. The output is the value of\nthe root. We show that the standard black pebbling algorithm applied to the\nbinary tree of height h yields a deterministic k-way branching program with\nTheta(k^h) states solving this problem, and we prove that this upper bound is\ntight for h=2 and h=3. We introduce a simple semantic restriction called\n\"thrifty\" on k-way branching programs solving tree evaluation problems and show\nthat the same state bound of Theta(k^h) is tight (up to a constant factor) for\nall h >= 2 for deterministic thrifty programs. We introduce fractional pebbling\nfor trees and show that this yields nondeterministic thrifty programs with\nTheta(k^{h/2+1}) states solving the Boolean problem \"determine whether the root\nhas value 1\". We prove that this bound is tight for h=2,3,4, and tight for\nunrestricted nondeterministic k-way branching programs for h=2,3."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2011.12.002", 
    "link": "http://arxiv.org/pdf/1005.2678v2", 
    "title": "The complexity of weighted and unweighted #CSP", 
    "arxiv-id": "1005.2678v2", 
    "author": "David Richerby", 
    "publish": "2010-05-15T14:39:30Z", 
    "summary": "We give some reductions among problems in (nonnegative) weighted #CSP which\nrestrict the class of functions that needs to be considered in computational\ncomplexity studies. Our reductions can be applied to both exact and approximate\ncomputation. In particular, we show that a recent dichotomy for unweighted #CSP\ncan be extended to rational-weighted #CSP."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2011.12.002", 
    "link": "http://arxiv.org/pdf/1005.3010v4", 
    "title": "A Proof for P =? NP Problem", 
    "arxiv-id": "1005.3010v4", 
    "author": "Changlin Wan", 
    "publish": "2010-05-17T19:48:52Z", 
    "summary": "The \\textbf{P} =? \\textbf{NP} problem is an important problem in contemporary\nmathematics and theoretical computer science. Many proofs have been proposed to\nthis problem. This paper proposes a theoretic proof for \\textbf{P} =?\n\\textbf{NP} problem. The central idea of this proof is a recursive definition\nfor Turing machine (shortly TM) that accepts the encoding strings of valid TMs.\nBy the definition, an infinite sequence of TM is constructed, and it is proven\nthat the sequence includes all valid TMs. Based on these TMs, the class\n\\textbf{D} that includes all decidable languages is defined. By proving\n\\textbf{P}=\\textbf{D}, the result \\textbf{P}=\\textbf{NP} is proven."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2011.12.002", 
    "link": "http://arxiv.org/pdf/1005.4874v1", 
    "title": "Using a Skewed Hamming Distance to Speed Up Deterministic Local Search", 
    "arxiv-id": "1005.4874v1", 
    "author": "Dominik Scheder", 
    "publish": "2010-05-26T16:42:40Z", 
    "summary": "Schoening presents a simple randomized algorithm for (d,k)-CSP problems with\nrunning time (d(k-1)/k)^n poly(n). Here, d is the number of colors, k is the\nsize of the constraints, and n is the number of variables. A derandomized\nversion of this, given by Dantsin et al., achieves a running time of\n(dk/(k+1))^n poly(n), inferior to Schoening's. We come up with a simple\nmodification of the deterministic algorithm, achieving a running time of\n(d(k-1)/k * k^d/(k^d-1))^n \\poly(n). Though not completely eleminating the gap,\nthis comes very close to the randomized bound for all but very small values of\nd. Our main idea is to define a graph structure on the set of d colors to speed\nup local search."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.24.8", 
    "link": "http://arxiv.org/pdf/1006.0394v1", 
    "title": "On the Weak Computability of Continuous Real Functions", 
    "arxiv-id": "1006.0394v1", 
    "author": "Xizhong Zheng", 
    "publish": "2010-06-02T14:30:07Z", 
    "summary": "In computable analysis, sequences of rational numbers which effectively\nconverge to a real number x are used as the (rho-) names of x. A real number x\nis computable if it has a computable name, and a real function f is computable\nif there is a Turing machine M which computes f in the sense that, M accepts\nany rho-name of x as input and outputs a rho-name of f(x) for any x in the\ndomain of f. By weakening the effectiveness requirement of the convergence and\nclassifying the converging speeds of rational sequences, several interesting\nclasses of real numbers of weak computability have been introduced in\nliterature, e.g., in addition to the class of computable real numbers (EC), we\nhave the classes of semi-computable (SC), weakly computable (WC), divergence\nbounded computable (DBC) and computably approximable real numbers (CA). In this\npaper, we are interested in the weak computability of continuous real functions\nand try to introduce an analogous classification of weakly computable real\nfunctions. We present definitions of these functions by Turing machines as well\nas by sequences of rational polygons and prove these two definitions are not\nequivalent. Furthermore, we explore the properties of these functions, and\namong others, show their closure properties under arithmetic operations and\ncomposition."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.24.13", 
    "link": "http://arxiv.org/pdf/1006.0399v1", 
    "title": "The descriptive set-theoretic complexity of the set of points of   continuity of a multi-valued function (Extended Abstract)", 
    "arxiv-id": "1006.0399v1", 
    "author": "Vassilios Gregoriades", 
    "publish": "2010-06-02T14:30:31Z", 
    "summary": "In this article we treat a notion of continuity for a multi-valued function F\nand we compute the descriptive set-theoretic complexity of the set of all x for\nwhich F is continuous at x. We give conditions under which the latter set is\neither a G_\\delta set or the countable union of G_\\delta sets. Also we provide\na counterexample which shows that the latter result is optimum under the same\nconditions. Moreover we prove that those conditions are necessary in order to\nobtain that the set of points of continuity of F is Borel i.e., we show that if\nwe drop some of the previous conditions then there is a multi-valued function F\nwhose graph is a Borel set and the set of points of continuity of F is not a\nBorel set. Finally we give some analogue results regarding a stronger notion of\ncontinuity for a multi-valued function. This article is motivated by a question\nof M. Ziegler in \"Real Computation with Least Discrete Advice: A Complexity\nTheory of Nonuniform Computability with Applications to Linear Algebra\",\n(submitted)."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.24.14", 
    "link": "http://arxiv.org/pdf/1006.0400v1", 
    "title": "Computing the Solutions of the Combined Korteweg-de Vries Equation by   Turing Machines", 
    "arxiv-id": "1006.0400v1", 
    "author": "Rui Zheng", 
    "publish": "2010-06-02T14:30:36Z", 
    "summary": "In this paper, we study the computability of the initial value problem of the\nCombined KdV equation. It is shown that, for any integer s>2, the nonlinear\nsolution operator which maps an initial condition data to the solution of the\nCombined KdV equation can be computed by a Turing machine."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.24.20", 
    "link": "http://arxiv.org/pdf/1006.0406v1", 
    "title": "Complete Multi-Representations of Sets in a Computable Measure Space", 
    "arxiv-id": "1006.0406v1", 
    "author": "Yongcheng Wu", 
    "publish": "2010-06-02T14:31:06Z", 
    "summary": "In a recent paper, two multi-representations for the measurable sets in a\ncomputable measure space have been introduced, which prove to be topologically\ncomplete w.r.t. certain topological properties. In this contribution, we show\nthem recursively complete w.r.t. computability of measure and set-theoretical\noperations."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_61", 
    "link": "http://arxiv.org/pdf/1006.0701v1", 
    "title": "Impossibility of independence amplification in Kolmogorov complexity   theory", 
    "arxiv-id": "1006.0701v1", 
    "author": "Marius Zimand", 
    "publish": "2010-06-03T17:31:14Z", 
    "summary": "The paper studies randomness extraction from sources with bounded\nindependence and the issue of independence amplification of sources, using the\nframework of Kolmogorov complexity. The dependency of strings $x$ and $y$ is\n${\\rm dep}(x,y) = \\max\\{C(x) - C(x \\mid y), C(y) - C(y\\mid x)\\}$, where\n$C(\\cdot)$ denotes the Kolmogorov complexity. It is shown that there exists a\ncomputable Kolmogorov extractor $f$ such that, for any two $n$-bit strings with\ncomplexity $s(n)$ and dependency $\\alpha(n)$, it outputs a string of length\n$s(n)$ with complexity $s(n)- \\alpha(n)$ conditioned by any one of the input\nstrings. It is proven that the above are the optimal parameters a Kolmogorov\nextractor can achieve. It is shown that independence amplification cannot be\neffectively realized. Specifically, if (after excluding a trivial case) there\nexist computable functions $f_1$ and $f_2$ such that ${\\rm dep}(f_1(x,y),\nf_2(x,y)) \\leq \\beta(n)$ for all $n$-bit strings $x$ and $y$ with ${\\rm\ndep}(x,y) \\leq \\alpha(n)$, then $\\beta(n) \\geq \\alpha(n) - O(\\log n)$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1006.1315v1", 
    "title": "Counting dependent and independent strings", 
    "arxiv-id": "1006.1315v1", 
    "author": "Marius Zimand", 
    "publish": "2010-06-07T18:21:10Z", 
    "summary": "The paper gives estimations for the sizes of the the following sets: (1) the\nset of strings that have a given dependency with a fixed string, (2) the set of\nstrings that are pairwise \\alpha independent, (3) the set of strings that are\nmutually \\alpha independent. The relevant definitions are as follows: C(x) is\nthe Kolmogorov complexity of the string x. A string y has \\alpha -dependency\nwith a string x if C(y) - C(y|x) \\geq \\alpha. A set of strings {x_1, \\ldots,\nx_t} is pairwise \\alpha-independent if for all i different from j, C(x_i) -\nC(x_i | x_j) \\leq \\alpha. A tuple of strings (x_1, \\ldots, x_t) is mutually\n\\alpha-independent if C(x_{\\pi(1)} \\ldots x_{\\pi(t)}) \\geq C(x_1) + \\ldots +\nC(x_t) - \\alpha, for every permutation \\pi of [t]."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1006.4700v4", 
    "title": "Arithmetic circuits: the chasm at depth four gets wider", 
    "arxiv-id": "1006.4700v4", 
    "author": "Pascal Koiran", 
    "publish": "2010-06-24T07:22:19Z", 
    "summary": "In their paper on the \"chasm at depth four\", Agrawal and Vinay have shown\nthat polynomials in m variables of degree O(m) which admit arithmetic circuits\nof size 2^o(m) also admit arithmetic circuits of depth four and size 2^o(m).\nThis theorem shows that for problems such as arithmetic circuit lower bounds or\nblack-box derandomization of identity testing, the case of depth four circuits\nis in a certain sense the general case. In this paper we show that smaller\ndepth four circuits can be obtained if we start from polynomial size arithmetic\ncircuits. For instance, we show that if the permanent of n*n matrices has\ncircuits of size polynomial in n, then it also has depth 4 circuits of size\nn^O(sqrt(n)*log(n)). Our depth four circuits use integer constants of\npolynomial size. These results have potential applications to lower bounds and\ndeterministic identity testing, in particular for sums of products of sparse\nunivariate polynomials. We also give an application to boolean circuit\ncomplexity, and a simple (but suboptimal) reduction to polylogarithmic depth\nfor arithmetic circuits of polynomial size and polynomially bounded degree."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1008.0521v2", 
    "title": "Sensitivity versus block sensitivity of Boolean functions", 
    "arxiv-id": "1008.0521v2", 
    "author": "Madars Virza", 
    "publish": "2010-08-03T11:11:50Z", 
    "summary": "Determining the maximal separation between sensitivity and block sensitivity\nof Boolean functions is of interest for computational complexity theory. We\nconstruct a sequence of Boolean functions with bs(f) = 1/2 s(f)^2 + 1/2 s(f).\nThe best known separation previously was bs(f) = 1/2 s(f)^2 due to Rubinstein.\nWe also report results of computer search for functions with at most 12\nvariables."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1008.0683v1", 
    "title": "Holographic Algorithms with Matchgates Capture Precisely Tractable   Planar #CSP", 
    "arxiv-id": "1008.0683v1", 
    "author": "Mingji Xia", 
    "publish": "2010-08-04T01:24:36Z", 
    "summary": "Valiant introduced matchgate computation and holographic algorithms. A number\nof seemingly exponential time problems can be solved by this novel algorithmic\nparadigm in polynomial time. We show that, in a very strong sense, matchgate\ncomputations and holographic algorithms based on them provide a universal\nmethodology to a broad class of counting problems studied in statistical\nphysics community for decades. They capture precisely those problems which are\n#P-hard on general graphs but computable in polynomial time on planar graphs.\n  More precisely, we prove complexity dichotomy theorems in the framework of\ncounting CSP problems. The local constraint functions take Boolean inputs, and\ncan be arbitrary real-valued symmetric functions. We prove that, every problem\nin this class belongs to precisely three categories: (1) those which are\ntractable (i.e., polynomial time computable) on general graphs, or (2) those\nwhich are \\#P-hard on general graphs but ractable on planar graphs, or (3)\nthose which are #P-hard even on planar graphs. The classification criteria are\nexplicit. Moreover, problems in category (2) are tractable on planar graphs\nprecisely by holographic algorithms with matchgates."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1008.0915v1", 
    "title": "A Decidable Dichotomy Theorem on Directed Graph Homomorphisms with   Non-negative Weights", 
    "arxiv-id": "1008.0915v1", 
    "author": "Xi Chen", 
    "publish": "2010-08-05T05:53:19Z", 
    "summary": "The complexity of graph homomorphism problems has been the subject of intense\nstudy. It is a long standing open problem to give a (decidable) complexity\ndichotomy theorem for the partition function of directed graph homomorphisms.\nIn this paper, we prove a decidable complexity dichotomy theorem for this\nproblem and our theorem applies to all non-negative weighted form of the\nproblem: given any fixed matrix A with non-negative algebraic entries, the\npartition function Z_A(G) of directed graph homomorphisms from any directed\ngraph G is either tractable in polynomial time or #P-hard, depending on the\nmatrix A. The proof of the dichotomy theorem is combinatorial, but involves the\ndefinition of an infinite family of graph homomorphism problems. The proof of\nits decidability is algebraic using properties of polynomials."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1008.1555v1", 
    "title": "The complexity of conservative finite-valued CSPs", 
    "arxiv-id": "1008.1555v1", 
    "author": "Stanislav Zivny", 
    "publish": "2010-08-09T17:47:20Z", 
    "summary": "We study the complexity of valued constraint satisfaction problems (VCSP). A\nproblem from VCSP is characterised by a \\emph{constraint language}, a fixed set\nof cost functions over a finite domain. An instance of the problem is specified\nby a sum of cost functions from the language and the goal is to minimise the\nsum. We consider the case of so-called \\emph{conservative} languages; that is,\nlanguages containing all unary cost functions, thus allowing arbitrary\nrestrictions on the domains of the variables. This problem has been studied by\nBulatov [LICS'03] for $\\{0,\\infty\\}$-valued languages (i.e. CSP), by\nCohen~\\etal\\ (AIJ'06) for Boolean domains, by Deineko et al. (JACM'08) for\n$\\{0,1\\}$-valued cost functions (i.e. Max-CSP), and by Takhanov (STACS'10) for\n$\\{0,\\infty\\}$-valued languages containing all finite-valued unary cost\nfunctions (i.e. Min-Cost-Hom).\n  We give an elementary proof of a complete complexity classification of\nconservative finite-valued languages: we show that every conservative\nfinite-valued language is either tractable or NP-hard. This is the \\emph{first}\ndichotomy result for finite-valued VCSPs over non-Boolean domains."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-15155-2_60", 
    "link": "http://arxiv.org/pdf/1008.1789v1", 
    "title": "Understanding Space in Proof Complexity: Separations and Trade-offs via   Substitutions", 
    "arxiv-id": "1008.1789v1", 
    "author": "Jakob Nordstr\u00f6m", 
    "publish": "2010-08-10T20:02:24Z", 
    "summary": "For current state-of-the-art DPLL SAT-solvers the two main bottlenecks are\nthe amounts of time and memory used. In proof complexity, these resources\ncorrespond to the length and space of resolution proofs. There has been a long\nline of research investigating these proof complexity measures, but while\nstrong results have been established for length, our understanding of space and\nhow it relates to length has remained quite poor. In particular, the question\nwhether resolution proofs can be optimized for length and space simultaneously,\nor whether there are trade-offs between these two measures, has remained\nessentially open.\n  In this paper, we remedy this situation by proving a host of length-space\ntrade-off results for resolution. Our collection of trade-offs cover almost the\nwhole range of values for the space complexity of formulas, and most of the\ntrade-offs are superpolynomial or even exponential and essentially tight. Using\nsimilar techniques, we show that these trade-offs in fact extend to the\nexponentially stronger k-DNF resolution proof systems, which operate with\nformulas in disjunctive normal form with terms of bounded arity k. We also\nanswer the open question whether the k-DNF resolution systems form a strict\nhierarchy with respect to space in the affirmative.\n  Our key technical contribution is the following, somewhat surprising,\ntheorem: Any CNF formula F can be transformed by simple variable substitution\ninto a new formula F' such that if F has the right properties, F' can be proven\nin essentially the same length as F, whereas on the other hand the minimal\nnumber of lines one needs to keep in memory simultaneously in any proof of F'\nis lower-bounded by the minimal number of variables needed simultaneously in\nany proof of F. Applying this theorem to so-called pebbling formulas defined in\nterms of pebble games on directed acyclic graphs, we obtain our results."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1008.2688v3", 
    "title": "A Dichotomy Theorem for the Approximate Counting of Complex-Weighted   Bounded-Degree Boolean CSPs", 
    "arxiv-id": "1008.2688v3", 
    "author": "Tomoyuki Yamakami", 
    "publish": "2010-08-16T15:28:04Z", 
    "summary": "We determine the computational complexity of approximately counting the total\nweight of variable assignments for every complex-weighted Boolean constraint\nsatisfaction problem (or CSP) with any number of additional unary (i.e., arity\n1) constraints, particularly, when degrees of input instances are bounded from\nabove by a fixed constant. All degree-1 counting CSPs are obviously solvable in\npolynomial time. When the instance's degree is more than two, we present a\ndichotomy theorem that classifies all counting CSPs admitting free unary\nconstraints into exactly two categories. This classification theorem extends,\nto complex-weighted problems, an earlier result on the approximation complexity\nof unweighted counting Boolean CSPs of bounded degree. The framework of the\nproof of our theorem is based on a theory of signature developed from Valiant's\nholographic algorithms that can efficiently solve seemingly intractable\ncounting CSPs. Despite the use of arbitrary complex weight, our proof of the\nclassification theorem is rather elementary and intuitive due to an extensive\nuse of a novel notion of limited T-constructibility. For the remaining degree-2\nproblems, in contrast, they are as hard to approximate as Holant problems,\nwhich are a generalization of counting CSPs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1008.2952v1", 
    "title": "Motion planning with pull moves", 
    "arxiv-id": "1008.2952v1", 
    "author": "Marcus Ritt", 
    "publish": "2010-08-17T19:44:08Z", 
    "summary": "It is well known that Sokoban is PSPACE-complete (Culberson 1998) and several\nof its variants are NP-hard (Demaine et al. 2003). In this paper we prove the\nNP-hardness of some variants of Sokoban where the warehouse keeper can only\npull boxes."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1008.3104v1", 
    "title": "Generalising tractable VCSPs defined by symmetric tournament pair   multimorphisms", 
    "arxiv-id": "1008.3104v1", 
    "author": "Stanislav Zivny", 
    "publish": "2010-08-18T15:15:38Z", 
    "summary": "We study optimisation problems that can be formulated as valued constraint\nsatisfaction problems (VCSP). A problem from VCSP is characterised by a\n\\emph{constraint language}, a fixed set of cost functions taking finite and\ninfinite costs over a finite domain. An instance of the problem is specified by\na sum of cost functions from the language and the goal is to minimise the sum.\nWe are interested in \\emph{tractable} constraint languages; that is, languages\nthat give rise to VCSP instances solvable in polynomial time. Cohen et al.\n(AIJ'06) have shown that constraint languages that admit the MJN multimorphism\nare tractable. Moreover, using a minimisation algorithm for submodular\nfunctions, Cohen et al. (TCS'08) have shown that constraint languages that\nadmit an STP (symmetric tournament pair) multimorphism are tractable.\n  We generalise these results by showing that languages admitting the MJN\nmultimorphism on a subdomain and an STP multimorphisms on the complement of the\nsubdomain are tractable. The algorithm is a reduction to the algorithm for\nlanguages admitting an STP multimorphism."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1008.4035v1", 
    "title": "A dichotomy theorem for conservative general-valued CSPs", 
    "arxiv-id": "1008.4035v1", 
    "author": "Vladimir Kolmogorov", 
    "publish": "2010-08-24T13:07:29Z", 
    "summary": "We study the complexity of valued constraint satisfaction problems (VCSP). A\nproblem from VCSP is characterised by a \\emph{constraint language}, a fixed set\nof cost functions over a finite domain. An instance of the problem is specified\nby a sum of cost functions from the language and the goal is to minimise the\nsum. We consider the case of so-called \\emph{conservative} languages; that is,\nlanguages containing all unary cost functions, thus allowing arbitrary\nrestrictions on the domains of the variables. We prove a Schaefer-like\ndichotomy theorem for this case: if all cost functions in the language satisfy\na certain condition (specified by a complementary combination of \\emph{STP and\nMJN multimorphisms}) then any instance can be solved in polynomial time by the\nalgorithm of Kolmogorov and Zivny (arXiv:1008.3104v1), otherwise the language\nis NP-hard. This generalises recent results of Takhanov (STACS'10) who\nconsidered $\\{0,\\infty\\}$-valued languages containing additionally all\nfinite-valued unary cost functions, and Kolmogorov and Zivny\n(arXiv:1008.1555v1) who considered \\emph{finite-valued} conservative languages."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1008.4401v2", 
    "title": "Separations of Matroid Freeness Properties", 
    "arxiv-id": "1008.4401v2", 
    "author": "Ning Xie", 
    "publish": "2010-08-25T22:20:09Z", 
    "summary": "Properties of Boolean functions on the hypercube invariant with respect to\nlinear transformations of the domain are among the most well-studied properties\nin the context of property testing. In this paper, we study the fundamental\nclass of linear-invariant properties called matroid freeness properties. These\nproperties have been conjectured to essentially coincide with all testable\nlinear-invariant properties, and a recent sequence of works has established\ntestability for increasingly larger subclasses. One question left open,\nhowever, is whether the infinitely many syntactically different properties\nrecently shown testable in fact correspond to new, semantically distinct ones.\nThis is a crucial issue since it has also been shown that there exist\nsubclasses of these properties for which an infinite set of syntactically\ndifferent representations collapse into one of a small, finite set of\nproperties, all previously known to be testable.\n  An important question is therefore to understand the semantics of matroid\nfreeness properties, and in particular when two syntactically different\nproperties are truly distinct. We shed light on this problem by developing a\nmethod for determining the relation between two matroid freeness properties P\nand Q. Furthermore, we show that there is a natural subclass of matroid\nfreeness properties such that for any two properties P and Q from this\nsubclass, a strong dichotomy must hold: either P is contained in Q or the two\nproperties are \"well separated.\" As an application of this method, we exhibit\nnew, infinite hierarchies of testable matroid freeness properties such that at\neach level of the hierarchy, there are functions that are far from all\nfunctions lying in lower levels of the hierarchy. Our key technical tool is an\napparently new notion of maps between linear matroids, called matroid\nhomomorphisms, that might be of independent interest."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1009.0246v1", 
    "title": "Explicit Proofs and The Flip", 
    "arxiv-id": "1009.0246v1", 
    "author": "Ketan Mulmuley", 
    "publish": "2010-09-01T19:03:11Z", 
    "summary": "This article describes a formal strategy of geometric complexity theory (GCT)\nto resolve the {\\em self referential paradox} in the $P$ vs. $NP$ and related\nproblems. The strategy, called the {\\em flip}, is to go for {\\em explicit\nproofs} of these problems. By an explicit proof we mean a proof that constructs\nproof certificates of hardness that are easy to verify, construct and decode.\nThe main result in this paper says that (1) any proof of the arithmetic\nimplication of the $P$ vs. $NP$ conjecture is close to an explicit proof in the\nsense that it can be transformed into an explicit proof by proving in addition\nthat arithmetic circuit identity testing can be derandomized in a blackbox\nfashion, and (2) stronger forms of these arithmetic hardness and\nderandomization conjectures together imply a polynomial time algorithm for a\nformidable explicit construction problem in algebraic geometry. This may\nexplain why these conjectures, which look so elementary at the surface, have\nturned out to be so hard."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_24", 
    "link": "http://arxiv.org/pdf/1009.0884v1", 
    "title": "Knowledge Recognition Algorithm enables P = NP", 
    "arxiv-id": "1009.0884v1", 
    "author": "Han Xiao Wen", 
    "publish": "2010-09-05T02:11:50Z", 
    "summary": "This paper introduces a knowledge recognition algorithm (KRA) that is both a\nTuring machine algorithm and an Oracle Turing machine algorithm. By definition\nKRA is a non-deterministic language recognition algorithm. Simultaneously it\ncan be implemented as a deterministic Turing machine algorithm. KRA applies\nmirrored perceptual-conceptual languages to learn member-class relations\nbetween the two languages iteratively and retrieve information through\ndeductive and reductive recognition from one language to another. The novelty\nof KRA is that the conventional concept of relation is adjusted. The\ncomputation therefore becomes efficient bidirectional string mapping."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(3:31)2012", 
    "link": "http://arxiv.org/pdf/1009.1208v5", 
    "title": "Complexity classifications for different equivalence and audit problems   for Boolean circuits", 
    "arxiv-id": "1009.1208v5", 
    "author": "Heribert Vollmer", 
    "publish": "2010-09-07T07:19:16Z", 
    "summary": "We study Boolean circuits as a representation of Boolean functions and\nconsider different equivalence, audit, and enumeration problems. For a number\nof restricted sets of gate types (bases) we obtain efficient algorithms, while\nfor all other gate types we show these problems are at least NP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.2363v3", 
    "title": "The Exponential Time Complexity of Computing the Probability That a   Graph is Connected", 
    "arxiv-id": "1009.2363v3", 
    "author": "Nina Taslaman", 
    "publish": "2010-09-13T12:21:16Z", 
    "summary": "We show that for every probability p with 0 < p < 1, computation of\nall-terminal graph reliability with edge failure probability p requires time\nexponential in Omega(m/ log^2 m) for simple graphs of m edges under the\nExponential Time Hypothesis."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.3124v1", 
    "title": "Quantum function computation using sublogarithmic space (abstract &   poster)", 
    "arxiv-id": "1009.3124v1", 
    "author": "Abuzer Yakaryilmaz", 
    "publish": "2010-09-16T09:23:38Z", 
    "summary": "We prove that quantum Turing machines are strictly superior to probabilistic\nTuring machines in function computation for any space bound $ o(\\log(n)) $."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.3217v2", 
    "title": "The Complexity of Rerouting Shortest Paths", 
    "arxiv-id": "1009.3217v2", 
    "author": "Paul Bonsma", 
    "publish": "2010-09-16T16:26:51Z", 
    "summary": "The Shortest Path Reconfiguration problem has as input a graph G (with unit\nedge lengths) with vertices s and t, and two shortest st-paths P and Q. The\nquestion is whether there exists a sequence of shortest st-paths that starts\nwith P and ends with Q, such that subsequent paths differ in only one vertex.\nThis is called a rerouting sequence.\n  This problem is shown to be PSPACE-complete. For claw-free graphs and chordal\ngraphs, it is shown that the problem can be solved in polynomial time, and that\nshortest rerouting sequences have linear length. For these classes, it is also\nshown that deciding whether a rerouting sequence exists between all pairs of\nshortest st-paths can be done in polynomial time. Finally, a polynomial time\nalgorithm for counting the number of isolated paths is given."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.3687v12", 
    "title": "3-SAT Polynomial Solution of Knowledge Recognition Algorithm", 
    "arxiv-id": "1009.3687v12", 
    "author": "Cuifeng Zhou", 
    "publish": "2010-09-20T03:55:13Z", 
    "summary": "This paper introduces a knowledge recognition algorithm (KRA) for solving the\n3SAT problem in polynomial time. KRA learns member-class relations and\nretrieves information through deductive and reductive iterative reasoning. It\napplies the principle of Chinese COVA* (equivalent to a set of eight 3-variable\nconjunctive clauses) and eliminates the \"OR\" operation to solve 3-SAT problem.\nThat is, KRA does not search the assignment directly. It recognizes the\ncomplements as rejections at each level of the set through iterative set\nrelation recognition. KRA recognizes which conjunctive 3-variable-clause is not\nsatisfiable. If all the eight clauses of any set of 3-variable clauses are\nrejected, then there is not an assignment for the formula. If there is at least\none clause in each set that remains, then there is at least one assignment that\nis the union of clauses of each set. If there is more than one clause in each\nset that remains, then there are multiple assignments that are the unions of\nthe clauses of each set respectively."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.5019v1", 
    "title": "The Complexity of Counting Eulerian Tours in 4-Regular Graphs", 
    "arxiv-id": "1009.5019v1", 
    "author": "Daniel Stefankovic", 
    "publish": "2010-09-25T15:40:39Z", 
    "summary": "We investigate the complexity of counting Eulerian tours ({\\sc #ET}) and its\nvariations from two perspectives---the complexity of exact counting and the\ncomplexity w.r.t. approximation-preserving reductions (AP-reductions\n\\cite{MR2044886}). We prove that {\\sc #ET} is #P-complete even for planar\n4-regular graphs.\n  A closely related problem is that of counting A-trails ({\\sc #A-trails}) in\ngraphs with rotational embedding schemes (so called maps). Kotzig\n\\cite{MR0248043} showed that {\\sc #A-trails} can be computed in polynomial time\nfor 4-regular plane graphs (embedding in the plane is equivalent to giving a\nrotational embedding scheme). We show that for 4-regular maps the problem is\n#P-hard. Moreover, we show that from the approximation viewpoint {\\sc\n#A-trails} in 4-regular maps captures the essence of {\\sc #ET}, that is, we\ngive an AP-reduction from {\\sc #ET} in general graphs to {\\sc #A-trails} in\n4-regular maps. The reduction uses a fast mixing result for a card shuffling\nproblem \\cite{MR2023023}.\n  In order to understand whether #{\\sc A-trails} in 4-regular maps can\nAP-reduce to #{\\sc ET} in 4-regular graphs, we investigate a problem in which\ntransitions in vertices are weighted (this generalizes both #{\\sc A-trails} and\n#{\\sc ET}). In the 4-regular case we show that {\\sc A-trails} can be used to\nsimulate any vertex weights and provide evidence that {\\sc ET} can simulate\nonly a limited set of vertex weights."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.5108v4", 
    "title": "Improving the Space-Bounded Version of Muchnik's Conditional Complexity   Theorem via \"Naive\" Derandomization", 
    "arxiv-id": "1009.5108v4", 
    "author": "Daniil Musatov", 
    "publish": "2010-09-26T17:07:58Z", 
    "summary": "Many theorems about Kolmogorov complexity rely on existence of combinatorial\nobjects with specific properties. Usually the probabilistic method gives such\nobjects with better parameters than explicit constructions do. But the\nprobabilistic method does not give \"effective\" variants of such theorems, i.e.\nvariants for resource-bounded Kolmogorov complexity. We show that a \"naive\nderandomization\" approach of replacing these objects by the output of\nNisan-Wigderson pseudo-random generator may give polynomial-space variants of\nsuch theorems.\n  Specifically, we improve the preceding polynomial-space analogue of Muchnik's\nconditional complexity theorem. I.e., for all $a$ and $b$ there exists a\nprogram $p$ of least possible length that transforms $a$ to $b$ and is simple\nconditional on $b$. Here all programs work in polynomial space and all\ncomplexities are measured with logarithmic accuracy instead of polylogarithmic\none in the previous work."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1009.6105v1", 
    "title": "The Baire partial quasi-metric space: A mathematical tool for asymptotic   complexity analysis in Computer Science", 
    "arxiv-id": "1009.6105v1", 
    "author": "O. Valero", 
    "publish": "2010-09-30T11:43:33Z", 
    "summary": "In 1994, S.G. Matthews introduced the notion of partial metric space in order\nto obtain a suitable mathematical tool for program verification [Ann. New York\nAcad. Sci. 728 (1994), 183-197]. He gave an application of this new structure\nto parallel computing by means of a partial metric version of the celebrated\nBanach fixed point theorem [Theoret. Comput. Sci. 151 (1995), 195-205]. Later\non, M.P. Schellekens introduced the theory of complexity (quasi-metric) spaces\nas a part of the development of a topological foundation for the asymptotic\ncomplexity analysis of programs and algorithms [Elec- tronic Notes in Theoret.\nComput. Sci. 1 (1995), 211-232]. The applicability of this theory to the\nasymptotic complexity analysis of Divide and Conquer algorithms was also\nillustrated by Schellekens. In particular, he gave a new proof, based on the\nuse of the aforenamed Banach fixed point theorem, of the well-known fact that\nMergesort al- gorithm has optimal asymptotic average running time of computing.\nIn this paper, motivated by the utility of partial metrics in Computer Science,\nwe discuss whether the Matthews fixed point theorem is a suitable tool to\nanalyze the asymptotic complexity of algorithms in the spirit of Schellekens.\nSpecifically, we show that a slight modification of the well-known Baire\npartial metric on the set of all words over an alphabet constitutes an\nappropriate tool to carry out the asymptotic complexity analysis of algorithms\nvia fixed point methods without the need for assuming the convergence condition\ninherent to the defini- tion of the complexity space in the Shellekens\nframework. Finally, in order to illustrate and to validate the developed theory\nwe apply our results to analyze the asymptotic complexity of Quicksort,\nMergesort and Largesort algorithms."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1010.1128v3", 
    "title": "A Path Order for Rewrite Systems that Compute Exponential Time Functions   (Technical Report)", 
    "arxiv-id": "1010.1128v3", 
    "author": "Georg Moser", 
    "publish": "2010-10-06T11:48:44Z", 
    "summary": "In this paper we present a new path order for rewrite systems, the\nexponential path order EPOSTAR. Suppose a term rewrite system is compatible\nwith EPOSTAR, then the runtime complexity of this rewrite system is bounded\nfrom above by an exponential function. Furthermore, the class of function\ncomputed by a rewrite system compatible with EPOSTAR equals the class of\nfunctions computable in exponential time on a Turing maschine."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1010.1481v1", 
    "title": "A Simple Deterministic Reduction for the Gap Minimum Distance of Code   Problem", 
    "arxiv-id": "1010.1481v1", 
    "author": "Subhash Khot", 
    "publish": "2010-10-07T16:40:59Z", 
    "summary": "We present a simple deterministic gap-preserving reduction from SAT to the\nMinimum Distance of Code Problem over $\\F_2$. We also show how to extend the\nreduction to work over any finite field. Previously a randomized reduction was\nknown due to Dumer, Micciancio, and Sudan, which was recently derandomized by\nCheng and Wan. These reductions rely on highly non-trivial coding theoretic\nconstructions whereas our reduction is elementary.\n  As an additional feature, our reduction gives a constant factor hardness even\nfor asymptotically good codes, i.e., having constant rate and relative\ndistance. Previously it was not known how to achieve deterministic reductions\nfor such codes."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.0354v1", 
    "title": "Variations on the Sensitivity Conjecture", 
    "arxiv-id": "1011.0354v1", 
    "author": "Denis Pankratov", 
    "publish": "2010-11-01T15:44:49Z", 
    "summary": "We present a selection of known as well as new variants of the Sensitivity\nConjecture and point out some weaker versions that are also open."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.2586v1", 
    "title": "Reductions Between Expansion Problems", 
    "arxiv-id": "1011.2586v1", 
    "author": "Madhur Tulsiani", 
    "publish": "2010-11-11T07:39:48Z", 
    "summary": "The Small-Set Expansion Hypothesis (Raghavendra, Steurer, STOC 2010) is a\nnatural hardness assumption concerning the problem of approximating the edge\nexpansion of small sets in graphs. This hardness assumption is closely\nconnected to the Unique Games Conjecture (Khot, STOC 2002). In particular, the\nSmall-Set Expansion Hypothesis implies the Unique Games Conjecture\n(Raghavendra, Steurer, STOC 2010).\n  Our main result is that the Small-Set Expansion Hypothesis is in fact\nequivalent to a variant of the Unique Games Conjecture. More precisely, the\nhypothesis is equivalent to the Unique Games Conjecture restricted to instance\nwith a fairly mild condition on the expansion of small sets. Alongside, we\nobtain the first strong hardness of approximation results for the Balanced\nSeparator and Minimum Linear Arrangement problems. Before, no such hardness was\nknown for these problems even assuming the Unique Games Conjecture.\n  These results not only establish the Small-Set Expansion Hypothesis as a\nnatural unifying hypothesis that implies the Unique Games Conjecture, all its\nconsequences and, in addition, hardness results for other problems like\nBalanced Separator and Minimum Linear Arrangement, but our results also show\nthat the Small-Set Expansion Hypothesis problem lies at the combinatorial heart\nof the Unique Games Conjecture.\n  The key technical ingredient is a new way of exploiting the structure of the\nUnique Games instances obtained from the Small-Set Expansion Hypothesis via\n(Raghavendra, Steurer, 2010). This additional structure allows us to modify\nstandard reductions in a way that essentially destroys their local-gadget\nnature. Using this modification, we can argue about the expansion in the graphs\nproduced by the reduction without relying on expansion properties of the\nunderlying Unique Games instance (which would be impossible for a local-gadget\nreduction)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.2730v24", 
    "title": "A Solution to the P versus NP Problem", 
    "arxiv-id": "1011.2730v24", 
    "author": "Frank Vega Delgado", 
    "publish": "2010-11-11T18:19:07Z", 
    "summary": "The relationship between the complexity classes P and NP is a question that\nhas not yet been answered by the Theory of Computation. The existence of a\nlanguage in NP, proven not to belong to P, is sufficient evidence to establish\nthe separation of P from NP. If a language is not recursive, it can't belong to\nthe complexity class NP. We find a problem in NP which is not in P; because if\nit would be present in that class, then it will imply that some undecidable\nproblem will be in NP too. That's why it can be confirmed by reduction ad\nabsurdum the following result: P doesn't equal NP. This new problem named\nCertifying is to find a possible input given a particular deterministic Turing\nmachine named Certified Turing machine and its output."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.3840v1", 
    "title": "Realizable Paths and the NL vs L Problem", 
    "arxiv-id": "1011.3840v1", 
    "author": "Shiva Kintali", 
    "publish": "2010-11-16T21:51:53Z", 
    "summary": "A celebrated theorem of Savitch states that NSPACE(S) is contained in\nDSPACE(S^2). In particular, Savitch gave a deterministic algorithm to solve\nST-CONNECTIVITY (an NL-complete problem) using O(log^2{n}) space, implying NL\nis in DSPACE(log^2{n}). While Savitch's theorem itself has not been improved in\nthe last four decades, studying the space complexity of several special cases\nof ST-CONNECTIVITY has provided new insights into the space-bounded complexity\nclasses.\n  In this paper, we introduce new kind of graph connectivity problems which we\ncall graph realizability problems. All of our graph realizability problems are\ngeneralizations of UNDIRECTED ST-CONNECTIVITY. ST-REALIZABILITY, the most\ngeneral graph realizability problem, is LogCFL-complete. We define the\ncorresponding complexity classes that lie between L and LogCFL and study their\nrelationships.\n  As special cases of our graph realizability problems we define two natural\nproblems, BALANCED ST-CONNECTIVITY and POSITIVE BALANCED ST-CONNECTIVITY, that\nlie between L and NL. We present a deterministic O(lognloglogn) space algorithm\nfor BALANCED ST-CONNECTIVITY. More generally we prove that SGSLogCFL, a\ngeneralization of BALANCED ST-CONNECTIVITY, is contained in\nDSPACE(lognloglogn). To achieve this goal we generalize several concepts (such\nas graph squaring and transitive closure) and algorithms (such as parallel\nalgorithms) known in the context of UNDIRECTED ST-CONNECTIVITY."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.4224v2", 
    "title": "Cross-Composition: A New Technique for Kernelization Lower Bounds", 
    "arxiv-id": "1011.4224v2", 
    "author": "Stefan Kratsch", 
    "publish": "2010-11-18T16:30:44Z", 
    "summary": "We introduce a new technique for proving kernelization lower bounds, called\ncross-composition. A classical problem L cross-composes into a parameterized\nproblem Q if an instance of Q with polynomially bounded parameter value can\nexpress the logical OR of a sequence of instances of L. Building on work by\nBodlaender et al. (ICALP 2008) and using a result by Fortnow and Santhanam\n(STOC 2008) we show that if an NP-complete problem cross-composes into a\nparameterized problem Q then Q does not admit a polynomial kernel unless the\npolynomial hierarchy collapses. Our technique generalizes and strengthens the\nrecent techniques of using OR-composition algorithms and of transferring the\nlower bounds via polynomial parameter transformations. We show its\napplicability by proving kernelization lower bounds for a number of important\ngraphs problems with structural (non-standard) parameterizations, e.g.,\nChromatic Number, Clique, and Weighted Feedback Vertex Set do not admit\npolynomial kernels with respect to the vertex cover number of the input graphs\nunless the polynomial hierarchy collapses, contrasting the fact that these\nproblems are trivially fixed-parameter tractable for this parameter. We have\nsimilar lower bounds for Feedback Vertex Set."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.4744v1", 
    "title": "Complexity of Homogeneous Co-Boolean Constraint Satisfaction Problems", 
    "arxiv-id": "1011.4744v1", 
    "author": "Florian Richoux", 
    "publish": "2010-11-22T07:17:50Z", 
    "summary": "Constraint Satisfaction Problems (CSP) constitute a convenient way to capture\nmany combinatorial problems. The general CSP is known to be NP-complete, but\nits complexity depends on a template, usually a set of relations, upon which\nthey are constructed. Following this template, there exist tractable and\nintractable instances of CSPs. It has been proved that for each CSP problem\nover a given set of relations there exists a corresponding CSP problem over\ngraphs of unary functions belonging to the same complexity class. In this short\nnote we show a dichotomy theorem for every finite domain D of CSP built upon\ngraphs of homogeneous co-Boolean functions, i.e., unary functions sharing the\nBoolean range {0, 1}."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.5966v1", 
    "title": "Enumeration Order complexity Equivalency", 
    "arxiv-id": "1011.5966v1", 
    "author": "Farzad Didehvar", 
    "publish": "2010-11-27T11:24:21Z", 
    "summary": "Throughout this article we develop and change the definitions and the ideas\nin \"arXiv:1006.4939\", in order to consider the efficiency of functions and\ncomplexity time problems. The central idea here is effective enumeration and\nlisting, and efficiency of function which is defined between two sets proposed\nin basic definitions. More in detail, it might be that h and g were co-order\nbut the velocity of them be different."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1011.6021v1", 
    "title": "Border basis detection is NP-complete", 
    "arxiv-id": "1011.6021v1", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2010-11-28T08:22:42Z", 
    "summary": "Border basis detection (BBD) is described as follows: given a set of\ngenerators of an ideal, decide whether that set of generators is a border basis\nof the ideal with respect to some order ideal. The motivation for this problem\ncomes from a similar problem related to Gr\\\"obner bases termed as Gr\\\"obner\nbasis detection (GBD) which was proposed by Gritzmann and Sturmfels (1993). GBD\nwas shown to be NP-hard by Sturmfels and Wiegelmann (1996). In this paper, we\ninvestigate the computational complexity of BBD and show that it is\nNP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1012.0232v2", 
    "title": "Kolmogorov-Loveland Sets and Advice Complexity Classes", 
    "arxiv-id": "1012.0232v2", 
    "author": "Thomas Hugel", 
    "publish": "2010-12-01T15:57:48Z", 
    "summary": "Loveland complexity is a variant of Kolmogorov complexity, where it is asked\nto output separately the bits of the desired string, instead of the string\nitself. Similarly to the resource-bounded Kolmogorov sets we define Loveland\nsets. We highlight a structural connection between resource-bounded Loveland\nsets and some advice complexity classes. This structural connection enables us\nto map to advice complexity classes some properties of Kolmogorov sets first\nnoticed by Hartmanis and thoroughly investigated in Longpr\\'e's thesis: 1.\nNon-inclusion properties of Loveland sets result in hierarchy properties on the\ncorresponding advice complexity classes; 2. Immunity properties of Loveland\nsets result in the non-existence of natural proofs between the corresponding\nadvice complexity classes, in the sense of Razborov & Rudich."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17493-3_19", 
    "link": "http://arxiv.org/pdf/1012.0556v2", 
    "title": "A Note on Nonuniform versus Uniform ACC^k Circuits for NE", 
    "arxiv-id": "1012.0556v2", 
    "author": "Lane A. Hemaspaandra", 
    "publish": "2010-12-02T20:01:54Z", 
    "summary": "We note that for each k \\in {0,1,2, ...} the following holds: NE has\n(nonuniform) ACC^k circuits if and only if NE has P^{NE}-uniform ACC^k\ncircuits. And we mention how to get analogous results for other circuit and\ncomplexity classes."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.0821v3", 
    "title": "Interactive proofs with competing teams of no-signaling provers", 
    "arxiv-id": "1012.0821v3", 
    "author": "Gus Gutoski", 
    "publish": "2010-12-03T19:13:38Z", 
    "summary": "This paper studies a generalization of multi-prover interactive proofs in\nwhich a verifier interacts with two competing teams of provers: one team\nattempts to convince the verifier to accept while the other attempts to\nconvince the verifier to reject. Each team consists of two provers who jointly\nimplement a no-signaling strategy. No-signaling strategies are a curious class\nof joint strategy that cannot in general be implemented without communication\nbetween the provers, yet cannot be used as a black box to establish\ncommunication between them. Attention is restricted in this paper to two-turn\ninteractions in which the verifier asks questions of each of the four provers\nand decides whether to accept or reject based on their responses.\n  We prove that the complexity class of decision problems that admit two-turn\ninteractive proofs with competing teams of no-signaling provers is a subset of\nPSPACE. This upper bound matches existing PSPACE lower bounds on the following\ntwo disparate and weaker classes of interactive proof:\n  1. Two-turn multi-prover interactive proofs with only one team of\nno-signaling provers.\n  2. Two-turn competing-prover interactive proofs with only one prover per\nteam.\n  Our result implies that the complexity of these two models is unchanged by\nthe addition of a second competing team of no-signaling provers in the first\ncase and by the addition of a second no-signaling prover to each team in the\nsecond case. Moreover, our result unifies and subsumes prior PSPACE upper\nbounds on these classes."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.1336v2", 
    "title": "Unary Subset-Sum is in Logspace", 
    "arxiv-id": "1012.1336v2", 
    "author": "Daniel M. Kane", 
    "publish": "2010-12-06T21:10:05Z", 
    "summary": "We present a simple Logspace algorithm that solves the Unary Subset-Sum\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.2034v1", 
    "title": "Robust Simulations and Significant Separations", 
    "arxiv-id": "1012.2034v1", 
    "author": "Rahul Santhanam", 
    "publish": "2010-12-09T15:47:35Z", 
    "summary": "We define and study a new notion of \"robust simulations\" between complexity\nclasses which is intermediate between the traditional notions of\ninfinitely-often and almost-everywhere, as well as a corresponding notion of\n\"significant separations\". A language L has a robust simulation in a complexity\nclass C if there is a language in C which agrees with L on arbitrarily large\npolynomial stretches of input lengths. There is a significant separation of L\nfrom C if there is no robust simulation of L in C. The new notion of simulation\nis a cleaner and more natural notion of simulation than the infinitely-often\nnotion. We show that various implications in complexity theory such as the\ncollapse of PH if NP = P and the Karp-Lipton theorem have analogues for robust\nsimulations. We then use these results to prove that most known separations in\ncomplexity theory, such as hierarchy theorems, fixed polynomial circuit lower\nbounds, time-space tradeoffs, and the theorems of Allender and Williams, can be\nstrengthened to significant separations, though in each case, an almost\neverywhere separation is unknown.\n  Proving our results requires several new ideas, including a completely\ndifferent proof of the hierarchy theorem for non-deterministic polynomial time\nthan the ones previously known."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.2142v1", 
    "title": "NP-completeness Proof: RBCDN Reduction Problem", 
    "arxiv-id": "1012.2142v1", 
    "author": "Arunabha Sen", 
    "publish": "2010-12-09T23:39:32Z", 
    "summary": "Computational complexity of the design problem for a network with a target\nvalue of Region-Based Component Decomposition Number (RBCDN) has been proven to\nbe NP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.2377v1", 
    "title": "Multivariate Polynomial Integration and Derivative Are Polynomial Time   Inapproximable unless P=NP", 
    "arxiv-id": "1012.2377v1", 
    "author": "Bin Fu", 
    "publish": "2010-12-10T20:51:16Z", 
    "summary": "We investigate the complexity of integration and derivative for multivariate\npolynomials in the standard computation model. The integration is in the unit\ncube $[0,1]^d$ for a multivariate polynomial, which has format $f(x_1,\\cdots,\nx_d)=p_1(x_1,\\cdots, x_d)p_2(x_1,\\cdots, x_d)\\cdots p_k(x_1,\\cdots, x_d)$,\nwhere each $p_i(x_1,\\cdots, x_d)=\\sum_{j=1}^d q_j(x_j)$ with all single\nvariable polynomials $q_j(x_j)$ of degree at most two and constant\ncoefficients. We show that there is no any factor polynomial time approximation\nfor the integration $\\int_{[0,1]^d}f(x_1,\\cdots,x_d)d_{x_1}\\cdots d_{x_d}$\nunless $P=NP$. For the complexity of multivariate derivative, we consider the\nfunctions with the format $f(x_1,\\cdots, x_d)=p_1(x_1,\\cdots,\nx_d)p_2(x_1,\\cdots, x_d)\\cdots p_k(x_1,\\cdots, x_d),$ where each\n$p_i(x_1,\\cdots, x_d)$ is of degree at most $2$ and $0,1$ coefficients. We also\nshow that unless $P=NP$, there is no any factor polynomial time approximation\nto its derivative ${\\partial f^{(d)}(x_1,\\cdots, x_d)\\over \\partial x_1\\cdots\n\\partial x_d}$ at the origin point $(x_1,\\cdots, x_d)=(0,\\cdots,0)$. Our\nresults show that the derivative may not be easier than the integration in high\ndimension. We also give some tractable cases of high dimension integration and\nderivative."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.2394v1", 
    "title": "NE is not NP Turing Reducible to Nonexpoentially Dense NP Sets", 
    "arxiv-id": "1012.2394v1", 
    "author": "Bin Fu", 
    "publish": "2010-12-10T21:19:11Z", 
    "summary": "A long standing open problem in the computational complexity theory is to\nseparate NE from BPP, which is a subclass of $NP_T(NP\\cap P/poly)$. In this\npaper, we show that $NE\\not\\subseteq NP_(NP \\cap$\nNonexponentially-Dense-Class), where Nonexponentially-Dense-Class is the class\nof languages A without exponential density (for each constant c>0,$|A^{\\le\nn}|\\le 2^{n^c}$ for infinitely many integers n).\n  Our result implies $NE\\not\\subseteq NP_T({pad(NP, g(n))})$ for every time\nconstructible super-polynomial function g(n) such as\n$g(n)=n^{\\ceiling{\\log\\ceiling{\\log n}}}$, where Pad(NP, g(n)) is class of all\nlanguages $L_B=\\{s10^{g(|s|)-|s|-1}:s\\in B\\}$ for $B\\in NP$. We also show\n$NE\\not\\subseteq NP_T(P_{tt}(NP)\\cap Tally)$."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.2527v2", 
    "title": "Solving the Rural Postman problem using the Adleman-Lipton model", 
    "arxiv-id": "1012.2527v2", 
    "author": "Nicolaos Matsakis", 
    "publish": "2010-12-12T10:14:22Z", 
    "summary": "In this survey we investigate the application of the Adleman-Lipton model on\nRural Postman problem, which given an undirected graph $G=(V,E)$ with positive\ninteger lengths on each of its edges and a subset $E^{'}\\subseteq E$, asks\nwhether there exists a hamiltonian circuit that includes each edge of $E^{'}$\nand has total cost (sum of edge lengths) less or equal to a given integer B (we\nare allowed to use any edges of the set $E-E^{'}$, but we must use all edges of\nthe set $E'$). The Rural Postman problem (RPP) is a very interesting\nNP-complete problem used, especially, in network optimization. RPP is actually\na special case of the Route Inspection problem, where we need to traverse all\nedges of an undirected graph at a minimum total cost. As all NP-complete\nproblems, it currently admits no efficient solution and if actually $P\\neq NP$\nas it is widely accepted to be, it cannot admit a polynomial time algorithm to\nsolve it. The application of the Adleman-Lipton model on this problem, provides\nan efficient way to solve RPP, as it is the fact for many other hard problems\non which the Adleman-Lipton model has been applied. In this survey, we provide\na polynomial algorithm based on the Lipton-Adleman model, which solves the RPP\nin $\\mathcal{O}(n^{2})$ time, where n refers to the input of the problem."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.3000v1", 
    "title": "Random Generation and Approximate Counting of Combinatorial Structures", 
    "arxiv-id": "1012.3000v1", 
    "author": "Massimo Santini", 
    "publish": "2010-12-14T11:41:24Z", 
    "summary": "The aim of this thesis is to determine classes of NP relations for which\nrandom generation and approximate counting problems admit an efficient\nsolution. Since efficient rank implies efficient random generation, we first\ninvestigate some classes of NP relations admitting efficient ranking. On the\nother hand, there are situations in which efficient random generation is\npossible even when ranking is computationally infeasible. We introduce the\nnotion of ambiguous description as a tool for random generation and approximate\ncounting in such cases and show, in particular, some applications to the case\nof formal languages. Finally, we discuss a limit of an heuristic for\ncombinatorial optimization problems based on the random initialization of local\nsearch algorithms showing that derandomizing such heuristic can be, in some\ncases, #P-hard."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.3548v2", 
    "title": "On the polynomial depth of various sets of random strings", 
    "arxiv-id": "1012.3548v2", 
    "author": "Philippe Moser", 
    "publish": "2010-12-16T10:07:39Z", 
    "summary": "This paper proposes new notions of polynomial depth (called monotone poly\ndepth), based on a polynomial version of monotone Kolmogorov complexity. We\nshow that monotone poly depth satisfies all desirable properties of depth\nnotions i.e., both trivial and random sequences are not monotone poly deep,\nmonotone poly depth satisfies the slow growth law i.e., no simple process can\ntransform a non deep sequence into a deep one, and monotone poly deep sequences\nexist (unconditionally). We give two natural examples of deep sets, by showing\nthat both the set of Levin-random strings and the set of Kolmogorov random\nstrings are monotone poly deep."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.5130v1", 
    "title": "A Relation between the Protocol Partition Number and the Quasi-Additive   Bound", 
    "arxiv-id": "1012.5130v1", 
    "author": "Naoyuki Kamiyama", 
    "publish": "2010-12-23T01:57:18Z", 
    "summary": "In this note, we show that the linear programming for computing the\nquasi-additive bound of the formula size of a Boolean function presented by\nUeno [MFCS'10] is equivalent to the dual problem of the linear programming\nrelaxation of an integer programming for computing the protocol partition\nnumber. Together with the result of Ueno [MFCS'10], our results imply that\nthere exists no gap between our integer programming for computing the protocol\npartition number and its linear programming relaxation."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1012.5659v1", 
    "title": "Non-negative Weighted #CSPs: An Effective Complexity Dichotomy", 
    "arxiv-id": "1012.5659v1", 
    "author": "Pinyan Lu", 
    "publish": "2010-12-27T20:49:07Z", 
    "summary": "We prove a complexity dichotomy theorem for all non-negative weighted\ncounting Constraint Satisfaction Problems (CSP). This caps a long series of\nimportant results on counting problems including unweighted and weighted graph\nhomomorphisms and the celebrated dichotomy theorem for unweighted #CSP. Our\ndichotomy theorem gives a succinct criterion for tractability. If a set F of\nconstraint functions satisfies the criterion, then the counting CSP problem\ndefined by F is solvable in polynomial time; if it does not satisfy the\ncriterion, then the problem is #P-hard. We furthermore show that the question\nof whether F satisfies the criterion is decidable in NP.\n  Surprisingly, our tractability criterion is simpler than the previous\ncriteria for the more restricted classes of problems, although when specialized\nto those cases, they are logically equivalent. Our proof mainly uses Linear\nAlgebra, and represents a departure from Universal Algebra, the dominant\nmethodology in recent years."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1101.1169v1", 
    "title": "Almost Settling the Hardness of Noncommutative Determinant", 
    "arxiv-id": "1101.1169v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2011-01-06T09:14:42Z", 
    "summary": "In this paper, we study the complexity of computing the determinant of a\nmatrix over a non-commutative algebra. In particular, we ask the question,\n\"over which algebras, is the determinant easier to compute than the permanent?\"\nTowards resolving this question, we show the following hardness and easiness of\nnoncommutative determinant computation.\n  * [Hardness] Computing the determinant of an n \\times n matrix whose entries\nare themselves 2 \\times 2 matrices over a field is as hard as computing the\npermanent over the field. This extends the recent result of Arvind and\nSrinivasan, who proved a similar result which however required the entries to\nbe of linear dimension.\n  * [Easiness] Determinant of an n \\times n matrix whose entries are themselves\nd \\times d upper triangular matrices can be computed in poly(n^d) time.\n  Combining the above with the decomposition theorem of finite dimensional\nalgebras (in particular exploiting the simple structure of 2 \\times 2 matrix\nalgebras), we can extend the above hardness and easiness statements to more\ngeneral algebras as follows. Let A be a finite dimensional algebra over a\nfinite field with radical R(A).\n  * [Hardness] If the quotient A/R(A) is non-commutative, then computing the\ndeterminant over the algebra A is as hard as computing the permanent.\n  * [Easiness] If the quotient A/R(A) is commutative and furthermore, R(A) has\nnilpotency index d (i.e., the smallest d such that R(A)d = 0), then there\nexists a poly(n^d)-time algorithm that computes determinants over the algebra\nA.\n  In particular, for any constant dimensional algebra A over a finite field,\nsince the nilpotency index of R(A) is at most a constant, we have the following\ndichotomy theorem: if A/R(A) is commutative, then efficient determinant\ncomputation is feasible and otherwise determinant is as hard as permanent."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1101.2018v4", 
    "title": "The Complexity of 3SAT_N and the P versus NP Problem", 
    "arxiv-id": "1101.2018v4", 
    "author": "Ruijia Liao", 
    "publish": "2011-01-11T04:27:55Z", 
    "summary": "We introduce the NP-complete problem 3SAT_N and extend Tovey's results to a\nclassification theorem for this problem. This theorem leads us to generalize\nthe concept of truth assignments for SAT to aggressive truth assignments for\n3SAT_N. We introduce the concept of a set compatible with the P and NP problem,\nand prove that all aggressive truth assignments are pseudo-algorithms. We\ncombine algorithm, pseudo-algorithm and diagonalization method to study the\ncomplexity of 3SAT_N and the P versus NP problem. The main result is P != NP."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1101.2705v1", 
    "title": "Lower bound for deterministic semantic-incremental branching programs   solving GEN", 
    "arxiv-id": "1101.2705v1", 
    "author": "Dustin Wehr", 
    "publish": "2011-01-14T01:27:20Z", 
    "summary": "We answer a problem posed in (G\\'al, Kouck\\'y, McKenzie 2008) regarding a\nrestricted model of small-space computation, tailored for solving the GEN\nproblem. They define two variants of \"incremental branching programs\", the\nsyntactic variant defined by a restriction on the graph-theoretic paths in the\nprogram, and the more-general semantic variant in which the same restriction is\nenforced only on the consistent paths - those that are followed by at least one\ninput. They show that exponential size is required for the syntactic variant,\nbut leave open the problem of superpolynomial lower bounds for the semantic\nvariant. Here we give an exponential lower bound for the semantic variant by\ngeneralizing lower bound arguments, from earlier work, for a similar restricted\nmodel tailored for solving a special case of GEN called Tree Evaluation."
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.007", 
    "link": "http://arxiv.org/pdf/1101.3970v2", 
    "title": "Short Propositional Refutations for Dense Random 3CNF Formulas", 
    "arxiv-id": "1101.3970v2", 
    "author": "Iddo Tzameret", 
    "publish": "2011-01-20T17:09:14Z", 
    "summary": "Random 3CNF formulas constitute an important distribution for measuring the\naverage-case behavior of propositional proof systems. Lower bounds for random\n3CNF refutations in many propositional proof systems are known. Most notably\nare the exponential-size resolution refutation lower bounds for random 3CNF\nformulas with $\\Omega(n^{1.5-\\epsilon}) $ clauses [Chvatal and Szemeredi\n(1988), Ben-Sasson and Wigderson (2001)]. On the other hand, the only known\nnon-trivial upper bound on the size of random 3CNF refutations in a\nnon-abstract propositional proof system is for resolution with\n$\\Omega(n^{2}/\\log n) $ clauses, shown by Beame et al. (2002). In this paper we\nshow that already standard propositional proof systems, within the hierarchy of\nFrege proofs, admit short refutations for random 3CNF formulas, for\nsufficiently large clause-to-variable ratio. Specifically, we demonstrate\npolynomial-size propositional refutations whose lines are $TC^0$ formulas\n(i.e., $TC^0$-Frege proofs) for random 3CNF formulas with $ n $ variables and $\n\\Omega(n^{1.4}) $ clauses.\n  The idea is based on demonstrating efficient propositional correctness proofs\nof the random 3CNF unsatisfiability witnesses given by Feige, Kim and Ofek\n(2006). Since the soundness of these witnesses is verified using spectral\ntechniques, we develop an appropriate way to reason about eigenvectors in\npropositional systems. To carry out the full argument we work inside weak\nformal systems of arithmetic and use a general translation scheme to\npropositional proofs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-20877-5_39", 
    "link": "http://arxiv.org/pdf/1101.4555v1", 
    "title": "Tight bounds on the randomized communication complexity of symmetric XOR   functions in one-way and SMP models", 
    "arxiv-id": "1101.4555v1", 
    "author": "Shengyu Zhang", 
    "publish": "2011-01-24T14:53:10Z", 
    "summary": "We study the communication complexity of symmetric XOR functions, namely\nfunctions $f: \\{0,1\\}^n \\times \\{0,1\\}^n \\rightarrow \\{0,1\\}$ that can be\nformulated as $f(x,y)=D(|x\\oplus y|)$ for some predicate $D: \\{0,1,...,n\\}\n\\rightarrow \\{0,1\\}$, where $|x\\oplus y|$ is the Hamming weight of the bitwise\nXOR of $x$ and $y$. We give a public-coin randomized protocol in the\nSimultaneous Message Passing (SMP) model, with the communication cost matching\nthe known lower bound for the \\emph{quantum} and \\emph{two-way} model up to a\nlogarithm factor. As a corollary, this closes a quadratic gap between quantum\nlower bound and randomized upper bound for the one-way model, answering an open\nquestion raised in Shi and Zhang \\cite{SZ09}."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-20877-5_39", 
    "link": "http://arxiv.org/pdf/1101.4848v1", 
    "title": "A zero-one SUBEXP-dimension law for BPP", 
    "arxiv-id": "1101.4848v1", 
    "author": "Philippe Moser", 
    "publish": "2011-01-25T15:22:48Z", 
    "summary": "We show that BPP has either SUBEXP-dimension zero (randomness is easy) or\nBPP=EXP (randomness is intractable)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-20877-5_39", 
    "link": "http://arxiv.org/pdf/1101.5455v4", 
    "title": "Resource Bounded Measure", 
    "arxiv-id": "1101.5455v4", 
    "author": "Jack Lutz", 
    "publish": "2011-01-28T05:28:57Z", 
    "summary": "A general theory of resource-bounded measurability and measure is developed.\nStarting from any feasible probability measure $\\nu$ on the Cantor space $\\C$\nand any suitable complexity class $C \\subseteq \\C$, the theory identifies the\nsubsets of $\\C$ that are $\\nu$-measurable in $C$ and assigns measures to these\nsets, thereby endowing $C$ with internal measure-theoretic structure. Classes\nto which the theory applies include various exponential time and space\ncomplexity classes, the class of all decidable languages, and the Cantor space\nitself, on which the resource-bounded theory is shown to agree with the\nclassical theory.\n  The sets that are $\\nu$-measurable in $C$ are shown to form an algebra\nrelative to which $\\nu$-measure is well-behaved. This algebra is also shown to\nbe complete and closed under sufficiently uniform infinitary unions and\nintersections, and $\\nu$-measure in $C$ is shown to have the appropriate\nadditivity and monotone convergence properties with respect to such infinitary\noperations.\n  A generalization of the classical Kolmogorov zero-one law is proven, showing\nthat when $\\nu$ is any feasible coin-toss probability measure on $\\C$, every\nset that is $\\nu$-measurable in $C$ and (like most complexity classes)\ninvariant under finite alterations must have $\\nu$-measure 0 or $\\nu$-measure 1\nin $C$.\n  The theory is presented here is based on resource-bounded martingale\nsplitting operators, which are type-2 functionals, each of which maps $\\N\n\\times {\\cal D}_\\nu$ into ${\\cal D}_\\nu \\times {\\cal D}_\\nu$, where ${\\cal\nD}_\\nu$ is the set of all $\\nu$-martingales. This type-2 aspect of the theory\nappears to be essential for general $\\nu$-measure in complexity classes $C$,\nbut the sets of $\\nu$-measure 0 or 1 in C are shown to be characterized by the\nsuccess conditions for martingales (type-1 functions) that have been used in\nresource-bounded measure to date."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.0072v1", 
    "title": "Tensor Rank: Some Lower and Upper Bounds", 
    "arxiv-id": "1102.0072v1", 
    "author": "Jacob Tsimerman", 
    "publish": "2011-02-01T03:42:55Z", 
    "summary": "The results of Strassen and Raz show that good enough tensor rank lower\nbounds have implications for algebraic circuit/formula lower bounds.\n  We explore tensor rank lower and upper bounds, focusing on explicit tensors.\nFor odd d, we construct field-independent explicit 0/1 tensors T:[n]^d->F with\nrank at least 2n^(floor(d/2))+n-Theta(d log n). This matches (over F_2) or\nimproves (all other fields) known lower bounds for d=3 and improves (over any\nfield) for odd d>3.\n  We also explore a generalization of permutation matrices, which we denote\npermutation tensors. We show, by counting, that there exists an order-3\npermutation tensor with super-linear rank. We also explore a natural class of\npermutation tensors, which we call group tensors. For any group G, we define\nthe group tensor T_G^d:G^d->F, by T_G^d(g_1,...,g_d)=1 iff g_1 x ... x g_d=1_G.\nWe give two upper bounds for the rank of these tensors. The first uses\nrepresentation theory and works over large fields F, showing (among other\nthings) that rank_F(T_G^d)<= |G|^(d/2). We also show that if this upper bound\nis tight, then super-linear tensor rank lower bounds would follow. The second\nupper bound uses interpolation and only works for abelian G, showing that over\nany field F that rank_F(T_G^d)<= O(|G|^(1+log d)log^(d-1)|G|). In either case,\nthis shows that many permutation tensors have far from maximal rank, which is\nvery different from the matrix case and thus eliminates many natural candidates\nfor high tensor rank.\n  We also explore monotone tensor rank. We give explicit 0/1 tensors T:[n]^d->F\nthat have tensor rank at most dn but have monotone tensor rank exactly n^(d-1).\nThis is a nearly optimal separation."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.1208v1", 
    "title": "The hardness of Median in the synchronized bit communication model", 
    "arxiv-id": "1102.1208v1", 
    "author": "Karolina So\u0142tys", 
    "publish": "2011-02-06T22:53:32Z", 
    "summary": "The synchronized bit communication model, defined recently by Impagliazzo and\nWilliams in \\emph{Communication complexity with synchronized clocks}, CCC '10,\nis a communication model which allows the participants to share a common clock.\nThe main open problem posed in this paper was the following: does the\nsynchronized bit model allow a logarithmic speed-up for all functions over the\nstandard deterministic model of communication? We resolve this question in the\nnegative by showing that the Median function, whose communication complexity is\n$O(\\log n)$, does not admit polytime synchronized bit protocol with\ncommunication complexity $O\\left(\\log^{1-\\epsilon} n\\right)$ for any $\\epsilon\n> 0$. Our results follow by a new round-communication trade-off for the Median\nfunction in the standard model, which easily translates to its hardness in the\nsynchronized bit model."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.2300v1", 
    "title": "Spectral Algorithms for Unique Games", 
    "arxiv-id": "1102.2300v1", 
    "author": "Alexandra Kolla", 
    "publish": "2011-02-11T08:15:10Z", 
    "summary": "We give a new algorithm for Unique Games which is based on purely {\\em\nspectral} techniques, in contrast to previous work in the area, which relies\nheavily on semidefinite programming (SDP). Given a highly satisfiable instance\nof Unique Games, our algorithm is able to recover a good assignment. The\napproximation guarantee depends only on the completeness of the game, and not\non the alphabet size, while the running time depends on spectral properties of\nthe {\\em Label-Extended} graph associated with the instance of Unique Games.\n  We further show that on input the integrality gap instance of Khot and\nVishnoi, our algorithm runs in quasi-polynomial time and decides that the\ninstance if highly unsatisfiable. Notably, when run on this instance, the\nstandard SDP relaxation of Unique Games {\\em fails}. As a special case, we also\nre-derive a polynomial time algorithm for Unique Games on expander constraint\ngraphs.\n  The main ingredient of our algorithm is a technique to effectively use the\nfull spectrum of the underlying graph instead of just the second eigenvalue,\nwhich is of independent interest. The question of how to take advantage of the\nfull spectrum of a graph in the design of algorithms has been often studied,\nbut no significant progress was made prior to this work."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.2880v2", 
    "title": "Min CSP on Four Elements: Moving Beyond Submodularity", 
    "arxiv-id": "1102.2880v2", 
    "author": "Johan Thapper", 
    "publish": "2011-02-14T20:41:09Z", 
    "summary": "We report new results on the complexity of the valued constraint satisfaction\nproblem (VCSP). Under the unique games conjecture, the approximability of\nfinite-valued VCSP is fairly well-understood. However, there is yet no\ncharacterisation of VCSPs that can be solved exactly in polynomial time. This\nis unsatisfactory, since such results are interesting from a combinatorial\noptimisation perspective; there are deep connections with, for instance,\nsubmodular and bisubmodular minimisation. We consider the Min and Max CSP\nproblems (i.e. where the cost functions only attain values in {0,1}) over\nfour-element domains and identify all tractable fragments. Similar\nclassifications were previously known for two- and three-element domains. In\nthe process, we introduce a new class of tractable VCSPs based on a\ngeneralisation of submodularity. We also extend and modify a graph-based\ntechnique by Kolmogorov and Zivny (originally introduced by Takhanov) for\nefficiently obtaining hardness results in our setting. This allow us to prove\nthe result without relying on computer-assisted case analyses (which otherwise\nare fairly common when studying the complexity and approximability of VCSPs.)\nThe hardness results are further simplified by the introduction of powerful\nreduction techniques."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.4346v2", 
    "title": "BPP is in NP and coNP", 
    "arxiv-id": "1102.4346v2", 
    "author": "Rooholah Majdodin", 
    "publish": "2011-02-21T21:08:57Z", 
    "summary": "We show that the class BPP is in NP and coNP. This paper has been withdrawn\nby the author because B and B' are probabilistic and nonequalities 10 cannot be\nchecked in polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.4699v1", 
    "title": "The influence lower bound via query elimination", 
    "arxiv-id": "1102.4699v1", 
    "author": "Shengyu Zhang", 
    "publish": "2011-02-23T09:38:14Z", 
    "summary": "We give a simpler proof, via query elimination, of a result due to O'Donnell,\nSaks, Schramm and Servedio, which shows a lower bound on the zero-error\nrandomized query complexity of a function f in terms of the maximum influence\nof any variable of f. Our lower bound also applies to the two-sided error\ndistributional query complexity of f, and it allows an immediate extension\nwhich can be used to prove stronger lower bounds for some functions."
},{
    "category": "cs.CC", 
    "doi": "10.1109/CCC.2011.28", 
    "link": "http://arxiv.org/pdf/1102.5605v4", 
    "title": "On Unique Games with Negative Weights", 
    "arxiv-id": "1102.5605v4", 
    "author": "Peng Cui", 
    "publish": "2011-02-28T06:25:21Z", 
    "summary": "In this paper, the author defines Generalized Unique Game Problem (GUGP),\nwhere weights of the edges are allowed to be negative. Two special types of\nGUGP are illuminated, GUGP-NWA, where the weights of all edges are negative,\nand GUGP-PWT($\\rho$), where the total weight of all edges are positive and the\nnegative-positive ratio is at most $\\rho$. The author investigates the\ncounterpart of the Unique Game Conjecture on GUGP-PWT($\\rho$). The author shows\nthat Unique Game Conjecture on GUGP-PWT(1) holds true, and Unique Game\nConjecture on GUGP-PWT(1/2) holds true, if the 2-to-1 Conjecture holds true.\nThe author poses an open problem whether Unique Game Conjecture holds true on\nGUGP-PWT($\\rho$) with $0<\\rho<1$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1103.2809v1", 
    "title": "On Computational Power of Quantum Read-Once Branching Programs", 
    "arxiv-id": "1103.2809v1", 
    "author": "Alexander Vasiliev", 
    "publish": "2011-03-14T23:15:20Z", 
    "summary": "In this paper we review our current results concerning the computational\npower of quantum read-once branching programs. First of all, based on the\ncircuit presentation of quantum branching programs and our variant of quantum\nfingerprinting technique, we show that any Boolean function with linear\npolynomial presentation can be computed by a quantum read-once branching\nprogram using a relatively small (usually logarithmic in the size of input)\nnumber of qubits. Then we show that the described class of Boolean functions is\nclosed under the polynomial projections."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1103.5560v2", 
    "title": "On the Complexity of Edge Packing and Vertex Packing", 
    "arxiv-id": "1103.5560v2", 
    "author": "K. Murali Krishnan", 
    "publish": "2011-03-29T07:53:17Z", 
    "summary": "This paper studies the computational complexity of the Edge Packing problem\nand the Vertex Packing problem. The edge packing problem (denoted by\n$\\bar{EDS}$) and the vertex packing problem (denoted by $\\bar{DS} $) are linear\nprogramming duals of the edge dominating set problem and the dominating set\nproblem respectively. It is shown that these two problems are equivalent to the\nset packing problem with respect to hardness of approximation and parametric\ncomplexity. It follows that $\\bar{EDS}$ and $\\bar{DS}$ cannot be approximated\nasymptotically within a factor of $O(N^{1/2-\\epsilon})$ for any $\\epsilon>0$\nunless $NP=ZPP$ where, $N$ is the number of vertices in the given graph. This\nis in contrast with the fact that the edge dominating set problem is\n2-approximable where as the dominating set problem is known to have an $O(\\log$\n$|V|)$ approximation algorithm. It also follows from our proof that $\\bar{EDS}$\nand $\\bar{DS}$ are $W[1]$-complete."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1103.5669v1", 
    "title": "Symmetry of information and bounds on nonuniform randomness extraction   via Kolmogorov extractors", 
    "arxiv-id": "1103.5669v1", 
    "author": "Marius Zimand", 
    "publish": "2011-03-29T14:53:25Z", 
    "summary": "We prove a strong Symmetry of Information relation for random strings (in the\nsense of Kolmogorov complexity) and establish tight bounds on the amount on\nnonuniformity that is necessary for extracting a string with randomness rate 1\nfrom a single source of randomness. More precisely, as instantiations of more\ngeneral results, we show: (1) For all n-bit random strings x and y, x is random\nconditioned by y if and only if y is random conditioned by x, and (2) while\nO(1) amount of advice regarding the source is not enough for extracting a\nstring with randomness rate 1 from a source string with constant random rate,\n\\omega(1) amount of advice is. The proofs use Kolmogorov extractors as the main\ntechnical device."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1103.6212v1", 
    "title": "QCSP on partially reflexive forests", 
    "arxiv-id": "1103.6212v1", 
    "author": "Barnaby Martin", 
    "publish": "2011-03-31T15:33:37Z", 
    "summary": "We study the (non-uniform) quantified constraint satisfaction problem QCSP(H)\nas H ranges over partially reflexive forests. We obtain a complexity-theoretic\ndichotomy: QCSP(H) is either in NL or is NP-hard. The separating condition is\nrelated firstly to connectivity, and thereafter to accessibility from all\nvertices of H to connected reflexive subgraphs. In the case of partially\nreflexive paths, we give a refinement of our dichotomy: QCSP(H) is either in NL\nor is Pspace-complete."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1105.0433v1", 
    "title": "On Gr\u00f6bner Basis Detection for Zero-dimensional Ideals", 
    "arxiv-id": "1105.0433v1", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2011-05-02T20:13:41Z", 
    "summary": "The Gr\\\"obner basis detection (GBD) is defined as follows: Given a set of\npolynomials, decide whether there exists -and if \"yes\" find- a term order such\nthat the set of polynomials is a Gr\\\"obner basis. This problem was shown to be\nNP-hard by Sturmfels and Wiegelmann. We show that GBD when studied in the\ncontext of zero dimensional ideals is also NP-hard. An algorithm to solve GBD\nfor zero dimensional ideals is also proposed which runs in polynomial time if\nthe number of indeterminates is a constant."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1105.1999v1", 
    "title": "New Heuristic Rounding Approaches to the Quadratic Assignment Problem", 
    "arxiv-id": "1105.1999v1", 
    "author": "Yong Xia", 
    "publish": "2011-05-10T17:17:11Z", 
    "summary": "Quadratic assignment problem is one of the great challenges in combinatorial\noptimization. It has many applications in Operations research and Computer\nScience. In this paper, the author extends the most-used rounding approach to a\none-parametric optimization model for the quadratic assignment problems. A\nnear-optimum parameter is also predestinated. The numerical experiments confirm\nthe efficiency."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1105.3454v1", 
    "title": "Computing in the fractal cloud: modular generic solvers for SAT and   Q-SAT variants", 
    "arxiv-id": "1105.3454v1", 
    "author": "Maxime Senot", 
    "publish": "2011-05-17T19:12:32Z", 
    "summary": "Abstract geometrical computation can solve hard combinatorial problems\nefficiently: we showed previously how Q-SAT can be solved in bounded space and\ntime using instance-specific signal machines and fractal parallelization. In\nthis article, we propose an approach for constructing a particular generic\nmachine for the same task. This machine deploies the Map/Reduce paradigm over a\nfractal structure. Moreover our approach is modular: the machine is constructed\nby combining modules. In this manner, we can easily create generic machines for\nsolving satifiability variants, such as SAT, #SAT, MAX-SAT."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1105.5806v1", 
    "title": "A Combination of Testability and Decodability by Tensor Products", 
    "arxiv-id": "1105.5806v1", 
    "author": "Michael Viderman", 
    "publish": "2011-05-29T17:22:43Z", 
    "summary": "Ben-Sasson and Sudan (RSA 2006) showed that repeated tensor products of\nlinear codes with a very large distance are locally testable. Due to the\nrequirement of a very large distance the associated tensor products could be\napplied only over sufficiently large fields. Then Meir (SICOMP 2009) used this\nresult (as a black box) to present a combinatorial construction of locally\ntestable codes that match best known parameters. As a consequence, this\nconstruction was obtained over sufficiently large fields.\n  In this paper we improve the result of Ben-Sasson and Sudan and show that for\n\\emph{any} linear codes the associated tensor products are locally testable.\nConsequently, the construction of Meir can be taken over any field, including\nthe binary field.\n  Moreover, a combination of our result with the result of Spielman (IEEE IT,\n1996) implies a construction of linear codes (over any field) that combine the\nfollowing properties: have constant rate and constant relative distance; have\nblocklength $n$ and testable with $n^{\\epsilon}$ queries, for any constant\n$\\epsilon > 0$; linear time encodable and linear-time decodable from a constant\nfraction of errors.\n  Furthermore, a combination of our result with the result of Guruswami et al.\n(STOC 2009) implies a similar corollary regarding the list-decodable codes."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1106.0108v4", 
    "title": "Asymptotic Granularity Reduction and Its Application", 
    "arxiv-id": "1106.0108v4", 
    "author": "Xiubin Fan", 
    "publish": "2011-06-01T07:29:19Z", 
    "summary": "It is well known that the inverse function of y = x with the derivative y' =\n1 is x = y, the inverse function of y = c with the derivative y' = 0 is\ninexistent, and so on. Hence, on the assumption that the noninvertibility of\nthe univariate increasing function y = f(x) with x > 0 is in direct proportion\nto the growth rate reflected by its derivative, the authors put forward a\nmethod of comparing difficulties in inverting two functions on a continuous or\ndiscrete interval called asymptotic granularity reduction (AGR) which\nintegrates asymptotic analysis with logarithmic granularities, and is an\nextension and a complement to polynomial time (Turing) reduction (PTR). Prove\nby AGR that inverting y = x ^ x (mod p) is computationally harder than\ninverting y = g ^ x (mod p), and inverting y = g ^ (x ^ n) (mod p) is\ncomputationally equivalent to inverting y = g ^ x (mod p), which are compatible\nwith the results from PTR. Besides, apply AGR to the comparison of inverting y\n= x ^ n (mod p) with y = g ^ x (mod p), y = g ^ (g1 ^ x) (mod p) with y = g ^ x\n(mod p), and y = x ^ n + x + 1 (mod p) with y = x ^ n (mod p) in difficulty,\nand observe that the results are consistent with existing facts, which further\nillustrates that AGR is suitable for comparison of inversion problems in\ndifficulty. Last, prove by AGR that inverting y = (x ^ n)(g ^ x) (mod p) is\ncomputationally equivalent to inverting y = g ^ x (mod p) when PTR can not be\nutilized expediently. AGR with the assumption partitions the complexities of\nproblems more detailedly, and finds out some new evidence for the security of\ncryptosystems."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1106.0851v1", 
    "title": "A Dual Approach for Solving Nonlinear Infinite-Norm Minimization   Problems with Applications in Separable Cases", 
    "arxiv-id": "1106.0851v1", 
    "author": "Yong Xia", 
    "publish": "2011-06-04T19:17:30Z", 
    "summary": "In this paper, we focus on nonlinear infinite-norm minimization problems that\nhave many applications, especially in computer science and operations research.\nWe set a reliable Lagrangian dual aproach for solving this kind of problems in\ngeneral, and based on this method, we propose an algorithm for the mixed linear\nand nonlinear infinite-norm minimization cases with numerical results."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1106.1150v1", 
    "title": "Barbosa, Uniform Polynomial Time Bounds, and Promises", 
    "arxiv-id": "1106.1150v1", 
    "author": "Xiaoqing Tang", 
    "publish": "2011-06-06T18:59:06Z", 
    "summary": "This note is a commentary on, and critique of, Andre Luiz Barbosa's paper\nentitled \"P != NP Proof.\" Despite its provocative title, what the paper is\nseeking to do is not to prove P \\neq NP in the standard sense in which that\nnotation is used in the literature. Rather, Barbosa is (and is aware that he\nis) arguing that a different meaning should be associated with the notation P\n\\neq NP, and he claims to prove the truth of the statement P \\neq NP in his\nquite different sense of that statement. However, we note that (1) the paper\nfails even on its own terms, as due to a uniformity problem, the paper's proof\ndoes not establish, even in its unusual sense of the notation, that P \\neq NP;\nand (2) what the paper means by the claim P \\neq NP in fact implies that P \\neq\nNP holds even under the standard meaning that that notation has in the\nliterature (and so it is exceedingly unlikely that Barbosa's proof can be fixed\nany time soon)."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1106.1910v1", 
    "title": "A Novel Hybrid Algorithm for Task Graph Scheduling", 
    "arxiv-id": "1106.1910v1", 
    "author": "Evgueni Efimov", 
    "publish": "2011-06-09T20:26:22Z", 
    "summary": "One of the important problems in multiprocessor systems is Task Graph\nScheduling. Task Graph Scheduling is an NP-Hard problem. Both learning automata\nand genetic algorithms are search tools which are used for solving many NP-Hard\nproblems. In this paper a new hybrid method based on Genetic Algorithm and\nLearning Automata is proposed. The proposed algorithm begins with an initial\npopulation of randomly generated chromosomes and after some stages, each\nchromosome maps to an automaton. Experimental results show that superiority of\nthe proposed algorithm over the current approaches."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.52.1", 
    "link": "http://arxiv.org/pdf/1106.2104v1", 
    "title": "Zen Puzzle Garden is NP-complete", 
    "arxiv-id": "1106.2104v1", 
    "author": "Martyn Amos", 
    "publish": "2011-06-10T15:59:30Z", 
    "summary": "Zen Puzzle Garden (ZPG) is a one-player puzzle game. In this paper, we prove\nthat deciding the solvability of ZPG is NP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.3758/s13428-013-0416-0", 
    "link": "http://arxiv.org/pdf/1106.3059v3", 
    "title": "Algorithmic Complexity for Short Binary Strings Applied to Psychology: A   Primer", 
    "arxiv-id": "1106.3059v3", 
    "author": "Fernando Soler-Toscano", 
    "publish": "2011-06-15T19:25:10Z", 
    "summary": "Since human randomness production has been studied and widely used to assess\nexecutive functions (especially inhibition), many measures have been suggested\nto assess the degree to which a sequence is random-like. However, each of them\nfocuses on one feature of randomness, leading authors to have to use multiple\nmeasures. Here we describe and advocate for the use of the accepted universal\nmeasure for randomness based on algorithmic complexity, by means of a novel\npreviously presented technique using the the definition of algorithmic\nprobability. A re-analysis of the classical Radio Zenith data in the light of\nthe proposed measure and methodology is provided as a study case of an\napplication."
},{
    "category": "cs.CC", 
    "doi": "10.3758/s13428-013-0416-0", 
    "link": "http://arxiv.org/pdf/1106.3161v6", 
    "title": "Confronting Intractability via Parameters", 
    "arxiv-id": "1106.3161v6", 
    "author": "Dimitrios M. Thilikos", 
    "publish": "2011-06-16T07:19:22Z", 
    "summary": "One approach to confronting computational hardness is to try to understand\nthe contribution of various parameters to the running time of algorithms and\nthe complexity of computational tasks. Almost no computational tasks in real\nlife are specified by their size alone. It is not hard to imagine that some\nparameters contribute more intractability than others and it seems reasonable\nto develop a theory of computational complexity which seeks to exploit this\nfact. Such a theory should be able to address the needs of practicioners in\nalgorithmics. The last twenty years have seen the development of such a theory.\nThis theory has a large number of successes in terms of a rich collection of\nalgorithmic techniques both practical and theoretical, and a fine-grained\nintractability theory. Whilst the theory has been widely used in a number of\nareas of applications including computational biology, linguistics, VLSI\ndesign, learning theory and many others, knowledge of the area is highly\nvaried. We hope that this article will show both the basic theory and point at\nthe wide array of techniques available. Naturally the treatment is condensed,\nand the reader who wants more should go to the texts, Downey and Fellows, Flum\nand Grohe, Niedermeier, and the upcoming undergraduate text Downey and Fellows."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2011.127", 
    "link": "http://arxiv.org/pdf/1107.1434v1", 
    "title": "The Limited Power of Powering: Polynomial Identity Testing and a   Depth-four Lower Bound for the Permanent", 
    "arxiv-id": "1107.1434v1", 
    "author": "Yann Strozecki", 
    "publish": "2011-07-07T15:48:17Z", 
    "summary": "Polynomial identity testing and arithmetic circuit lower bounds are two\ncentral questions in algebraic complexity theory. It is an intriguing fact that\nthese questions are actually related. One of the authors of the present paper\nhas recently proposed a \"real {\\tau}-conjecture\" which is inspired by this\nconnection. The real {\\tau}-conjecture states that the number of real roots of\na sum of products of sparse univariate polynomials should be polynomially\nbounded. It implies a superpolynomial lower bound on the size of arithmetic\ncircuits computing the permanent polynomial. In this paper we show that the\nreal {\\tau}-conjecture holds true for a restricted class of sums of products of\nsparse polynomials. This result yields lower bounds for a restricted class of\ndepth-4 circuits: we show that polynomial size circuits from this class cannot\ncompute the permanent, and we also give a deterministic polynomial identity\ntesting algorithm for the same class of circuits."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2011.127", 
    "link": "http://arxiv.org/pdf/1107.1458v9", 
    "title": "Sets Have Simple Members", 
    "arxiv-id": "1107.1458v9", 
    "author": "Leonid A. Levin", 
    "publish": "2011-07-07T17:19:53Z", 
    "summary": "The combined Universal Probability M(D) of strings x in sets D is close to\nmax M({x}) over x in D: their ~logs differ by at most D's information j=I(D:H)\nabout the halting sequence H. Thus if all x have complexity K(x) >k, D carries\n>i bits of information on each its x where i+j ~ k. Note that there are no ways\nto generate D with significant I(D:H)."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1107.1963v3", 
    "title": "Intuitionistic implication makes model checking hard", 
    "arxiv-id": "1107.1963v3", 
    "author": "Felix Weiss", 
    "publish": "2011-07-11T08:41:55Z", 
    "summary": "We investigate the complexity of the model checking problem for\nintuitionistic and modal propositional logics over transitive Kripke models.\nMore specific, we consider intuitionistic logic IPC, basic propositional logic\nBPL, formal propositional logic FPL, and Jankov's logic KC. We show that the\nmodel checking problem is P-complete for the implicational fragments of all\nthese intuitionistic logics. For BPL and FPL we reach P-hardness even on the\nimplicational fragment with only one variable. The same hardness results are\nobtained for the strictly implicational fragments of their modal companions.\nMoreover, we investigate whether formulas with less variables and additional\nconnectives make model checking easier. Whereas for variable free formulas\noutside of the implicational fragment, FPL model checking is shown to be in\nLOGCFL, the problem remains P-complete for BPL."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1107.2256v5", 
    "title": "Complexity of Metric Dimension on Planar Graphs", 
    "arxiv-id": "1107.2256v5", 
    "author": "Erik Jan van Leeuwen", 
    "publish": "2011-07-12T12:07:33Z", 
    "summary": "The metric dimension of a graph $G$ is the size of a smallest subset $L\n\\subseteq V(G)$ such that for any $x,y \\in V(G)$ with $x\\not= y$ there is a $z\n\\in L$ such that the graph distance between $x$ and $z$ differs from the graph\ndistance between $y$ and $z$. Even though this notion has been part of the\nliterature for almost 40 years, prior to our work the computational complexity\nof determining the metric dimension of a graph was still very unclear. In this\npaper, we show tight complexity boundaries for the Metric Dimension problem. We\nachieve this by giving two complementary results. First, we show that the\nMetric Dimension problem on planar graphs of maximum degree $6$ is NP-complete.\nThen, we give a polynomial-time algorithm for determining the metric dimension\nof outerplanar graphs."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1107.2559v2", 
    "title": "Lower Bounds for Number-in-Hand Multiparty Communication Complexity,   Made Easy", 
    "arxiv-id": "1107.2559v2", 
    "author": "Qin Zhang", 
    "publish": "2011-07-13T14:29:18Z", 
    "summary": "In this paper we prove lower bounds on randomized multiparty communication\ncomplexity, both in the \\emph{blackboard model} (where each message is written\non a blackboard for all players to see) and (mainly) in the\n\\emph{message-passing model}, where messages are sent player-to-player. We\nintroduce a new technique for proving such bounds, called\n\\emph{symmetrization}, which is natural, intuitive, and often easy to use.\n  For example, for the problem where each of $k$ players gets a bit-vector of\nlength $n$, and the goal is to compute the coordinate-wise XOR of these\nvectors, we prove a tight lower bounds of $\\Omega(nk)$ in the blackboard model.\nFor the same problem with AND instead of XOR, we prove a lower bounds of\nroughly $\\Omega(nk)$ in the message-passing model (assuming $k \\le n/3200$) and\n$\\Omega(n \\log k)$ in the blackboard model. We also prove lower bounds for\nbit-wise majority, for a graph-connectivity problem, and for other problems;\nthe technique seems applicable to a wide range of other problems as well. All\nof our lower bounds allow randomized communication protocols with two-sided\nerror.\n  We also use the symmetrization technique to prove several direct-sum-like\nresults for multiparty communication."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1107.3767v1", 
    "title": "Computational Hardness of Enumerating Satisfying Spin-Assignments in   Triangulations", 
    "arxiv-id": "1107.3767v1", 
    "author": "Marcos Kiwi", 
    "publish": "2011-07-19T16:34:07Z", 
    "summary": "Satisfying spin-assignments in triangulations of a surface are states of\nminimum energy of the antiferromagnetic Ising model on triangulations which\ncorrespond (via geometric duality) to perfect matchings in cubic bridgeless\ngraphs. In this work we show that it is NP-complete to decide whether or not a\nsurface triangulation admits a satisfying spin-assignment, and that it is\n#P-complete to determine the number of such assignments. Both results are\nderived via an elaborate (and atypical) reduction that maps a Boolean formula\nin 3-conjunctive normal form into a triangulation of an orientable closed\nsurface."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1107.4150v1", 
    "title": "Analysis on the computability over the efficient utilization problem of   the four-dimensional space-time", 
    "arxiv-id": "1107.4150v1", 
    "author": "Kun He", 
    "publish": "2011-07-21T03:19:09Z", 
    "summary": "This paper formally proposes a problem about the efficient utilization of the\nfour dimensional space-time. Given a cuboid container, a finite number of rigid\ncuboid items, and the time length that each item should be continuous baked in\nthe container, the problem asks to arrange the starting time for each item\nbeing placed into the container and to arrange the position and orientation for\neach item at each instant during its continuous baking period such that the\ntotal time length the container be utilized is as short as possible. Here all\nside dimensions of the container and of the items are positive real numbers\narbitrarily given. Differs from the classical packing problems, the position\nand orientation of each item in the container could be changed over time.\nTherefore, according to above mathematical model, the four-dimensional\nspace-time can be utilized more truly and more fully. This paper then proves\nthat there exists an exact algorithm that could solve the problem by finite\noperations, so we say this problem is weak computable. Based on the\nunderstanding of this computability proof, it is expected to design effective\napproximate algorithms in the near future. A piggyback work completed is a\nstrict proof on the weak computability over general and natural case of the\nthree-dimensional cuboid packing decision problem that all parameters are\npositive real numbers."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1108.2385v1", 
    "title": "Width-parameterized SAT: Time-Space Tradeoffs", 
    "arxiv-id": "1108.2385v1", 
    "author": "Bangsheng Tang", 
    "publish": "2011-08-11T12:18:26Z", 
    "summary": "Width parameterizations of SAT, such as tree-width and path-width, enable the\nstudy of computationally more tractable and practical SAT instances. We give\ntwo simple algorithms. One that runs simultaneously in time-space\n$(O^*(2^{2tw(\\phi)}), O^*(2^{tw(\\phi)}))$ and another that runs in time-space\n$(O^*(3^{tw(\\phi)\\log{|\\phi|}}),|\\phi|^{O(1)})$, where $tw(\\phi)$ is the\ntree-width of a formula $\\phi$ with $|\\phi|$ many clauses and variables. This\npartially answers the question of Alekhnovitch and Razborov, who also gave\nalgorithms exponential both in time and space, and asked whether the space can\nbe made smaller. We conjecture that every algorithm for this problem that runs\nin time $2^{tw(\\phi)\\mathbf{o(\\log{|\\phi|})}}$ necessarily blows up the space\nto exponential in $tw(\\phi)$.\n  We introduce a novel way to combine the two simple algorithms that allows us\nto trade \\emph{constant} factors in the exponents between running time and\nspace. Our technique gives rise to a family of algorithms controlled by two\nparameters. By fixing one parameter we obtain an algorithm that runs in\ntime-space $(O^*(3^{1.441(1-\\epsilon)tw(\\phi)\\log{|\\phi|}}), O^*(2^{2\\epsilon\ntw(\\phi)}))$, for every $0<\\epsilon<1$. We systematically study the limitations\nof this technique, and show that these algorithmic results are the best\nachievable using this technique.\n  We also study further the computational complexity of width parameterizations\nof SAT. We prove non-sparsification lower bounds for formulas of path-width\n$\\omega(\\log|\\phi|)$, and a separation between the complexity of path-width and\ntree-width parametrized SAT modulo plausible complexity assumptions."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1108.3494v1", 
    "title": "New separation between $s(f)$ and $bs(f)$", 
    "arxiv-id": "1108.3494v1", 
    "author": "Xiaoming Sun", 
    "publish": "2011-08-17T14:41:21Z", 
    "summary": "In this note we give a new separation between sensitivity and block\nsensitivity of Boolean functions: $bs(f)=(2/3)s(f)^2-(1/3)s(f)$."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1108.3860v3", 
    "title": "A SWAR Approach to Counting Ones", 
    "arxiv-id": "1108.3860v3", 
    "author": "Holger Petersen", 
    "publish": "2011-08-18T21:39:20Z", 
    "summary": "We investigate the complexity of algorithms counting ones in different sets\nof operations. With addition and logical operations (but no shift)\n$O(\\log^2(n))$ steps suffice to count ones. Parity can be computed with\ncomplexity $O(\\log(n))$, which is the same bound as for methods using\nshift-operations. If multiplication is available, a solution of time complexity\n$O(\\log^*(n))$ is possible improving the known bound $O(\\log\\log(n))$."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-8(2:3)2012", 
    "link": "http://arxiv.org/pdf/1108.4436v2", 
    "title": "Taking the Final Step to a Full Dichotomy of the Possible Winner Problem   in Pure Scoring Rules", 
    "arxiv-id": "1108.4436v2", 
    "author": "Joerg Rothe", 
    "publish": "2011-08-22T20:49:21Z", 
    "summary": "The Possible Winner problem asks, given an election where the voters'\npreferences over the candidates are specified only partially, whether a\ndesignated candidate can become a winner by suitably extending all the votes.\nBetzler and Dorn [1] proved a result that is only one step away from a full\ndichotomy of this problem for the important class of pure scoring rules in the\ncase of unweighted voters and an unbounded number of candidates: Possible\nWinner is NP-complete for all pure scoring rules except plurality, veto, and\nthe scoring rule with vector (2,1,...,1,0), but is solvable in polynomial time\nfor plurality and veto. We take the final step to a full dichotomy by showing\nthat Possible Winner is NP-complete also for the scoring rule with vector\n(2,1,...,1,0)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1108.5288v4", 
    "title": "The expressibility of functions on the Boolean domain, with applications   to Counting CSPs", 
    "arxiv-id": "1108.5288v4", 
    "author": "Colin McQuillan", 
    "publish": "2011-08-26T12:54:13Z", 
    "summary": "An important tool in the study of the complexity of Constraint Satisfaction\nProblems (CSPs) is the notion of a relational clone, which is the set of all\nrelations expressible using primitive positive formulas over a particular set\nof base relations. Post's lattice gives a complete classification of all\nBoolean relational clones, and this has been used to classify the computational\ndifficulty of CSPs. Motivated by a desire to understand the computational\ncomplexity of (weighted) counting CSPs, we develop an analogous notion of\nfunctional clones and study the landscape of these clones. One of these clones\nis the collection of log-supermodular (lsm) functions, which turns out to play\na significant role in classifying counting CSPs. In the conservative case\n(where all nonnegative unary functions are available), we show that there are\nno functional clones lying strictly between the clone of lsm functions and the\ntotal clone (containing all functions). Thus, any counting CSP that contains a\nsingle nontrivial non-lsm function is computationally as hard to approximate as\nany problem in #P. Furthermore, we show that any non-trivial functional clone\n(in a sense that will be made precise) contains the binary function \"implies\".\nAs a consequence, in the conservative case, all non-trivial counting CSPs are\nas hard as #BIS, the problem of counting independent sets in a bipartite graph.\nGiven the complexity-theoretic results, it is natural to ask whether the\n\"implies\" clone is equivalent to the clone of lsm functions. We use the Mobius\ntransform and the Fourier transform to show that these clones coincide\nprecisely up to arity 3. It is an intriguing open question whether the lsm\nclone is finitely generated. Finally, we investigate functional clones in which\nonly restricted classes of unary functions are available."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.0200v5", 
    "title": "NP is not AL and P is not NC is not NL is not L", 
    "arxiv-id": "1110.0200v5", 
    "author": "Koji Kobayashi", 
    "publish": "2011-10-02T16:28:44Z", 
    "summary": "This paper talk about that NP is not AL and P, P is not NC, NC is not NL, and\nNL is not L. The point about this paper is the depend relation of the problem\nthat need other problem's result to compute it. I show the structure of depend\nrelation that could divide each complexity classes."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.0461v2", 
    "title": "LSM is not generated by binary functions", 
    "arxiv-id": "1110.0461v2", 
    "author": "Colin McQuillan", 
    "publish": "2011-10-03T19:58:32Z", 
    "summary": "The material in this note is now superseded by arXiv:1108.5288v4.\n  Bulatov et al. [1] defined the operation of (efficient)\npps_\\omega-definability in order to study the computational complexity of\ncertain approximate counting problems. They asked whether all log-supermodular\nfunctions can be defined by binary implication and unary functions in this\nsense. We give a negative answer to this question."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.1052v1", 
    "title": "Spider Solitaire is NP-Complete", 
    "arxiv-id": "1110.1052v1", 
    "author": "Jesse Stern", 
    "publish": "2011-10-05T17:32:00Z", 
    "summary": "This project investigates the potential of computers to solve complex tasks\nsuch as games. The paper proves that the complexity of a generalized version of\nspider solitaire is NP-Complete and uses much of structure of the proof that\nFreeCell is NP-Hard in the paper Helmert, M. \"Complexity Results for Standard\nBenchmark Domains in Planning.\" Artificial Intelligence 143.2 (2003): 219-62.\nPrint. A given decision problem falls in to the class NP-Complete if it is\nproven to be both in NP and in NP-Hard. To prove that this is the case the\npaper shows that, not only do the kinds of possible moves that can be reversed\nprove this, but it is also shown that no spider solitaire game of size n will\ntake more than a polynomial number of moves to complete if such a completion is\npossible. The paper reduces 3-SAT to SpiderSolitaire (the name used throughout\nthe proof when referring to the generalized version of popular solitaire\nvariant \"Spider Solitaire\") by showing that any 3-SAT instance can be\nreplicated using an appropriately arranged initial tableau. The example\nprovided reinforces the proof of NP-Hardness and helps to make the proof easier\nto understand, but the definitive proof lies in the equations providing\ninstruction on how to set up any 3-SAT instance of clause size C as a instance\nof SpiderSolitaire."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.1510v2", 
    "title": "NP-Hardness and Fixed-Parameter Tractability of Realizing Degree   Sequences with Directed Acyclic Graphs", 
    "arxiv-id": "1110.1510v2", 
    "author": "Andr\u00e9 Nichterlein", 
    "publish": "2011-10-07T12:52:19Z", 
    "summary": "In graph realization problems one is given a degree sequence and the task is\nto decide whether there is a graph whose vertex degrees match to the given\nsequence. This realization problem is known to be polynomial-time solvable when\nthe graph is directed or undirected. In contrary, we show NP-completeness for\nthe problem of realizing a given sequence of pairs of positive integers\n(representing indegrees and outdegrees) with a directed acyclic graph,\nanswering an open question of Berger and M\\\"uller-Hannemann [FCT 2011].\nFurthermore, we classify the problem as fixed-parameter tractable with respect\nto the parameter \"maximum degree\"."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.1658v2", 
    "title": "Algorithm that Solves 3-SAT in Polynomial Time", 
    "arxiv-id": "1110.1658v2", 
    "author": "Jason W. Steinmetz", 
    "publish": "2011-10-05T23:04:24Z", 
    "summary": "The question of whether the complexity class P is equal to the complexity\nclass NP has been a seemingly intractable problem for over 4 decades. It has\nbeen clear that if an algorithm existed that would solve the problems in the NP\nclass in polynomial time then P would equal NP. However, no one has yet been\nable to create that algorithm or to successfully prove that such an algorithm\ncannot exist. The algorithm that will be presented in this paper solves the\n3-satisfiability or 3-CNF-SAT problem, which has been proven to be NP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.1896v1", 
    "title": "Restricted Parameter Range Promise Set Cover Problems Are Easy", 
    "arxiv-id": "1110.1896v1", 
    "author": "Hao Chen", 
    "publish": "2011-10-10T00:40:28Z", 
    "summary": "Let $({\\bf U},{\\bf S},d)$ be an instance of Set Cover Problem, where ${\\bf\nU}=\\{u_1,...,u_n\\}$ is a $n$ element ground set, ${\\bf S}=\\{S_1,...,S_m\\}$ is a\nset of $m$ subsets of ${\\bf U}$ satisfying $\\bigcup_{i=1}^m S_i={\\bf U}$ and\n$d$ is a positive integer. In STOC 1993 M. Bellare, S. Goldwasser, C. Lund and\nA. Russell proved the NP-hardness to distinguish the following two cases of\n${\\bf GapSetCover_{\\eta}}$ for any constant $\\eta > 1$. The Yes case is the\ninstance for which there is an exact cover of size $d$ and the No case is the\ninstance for which any cover of ${\\bf U}$ from ${\\bf S}$ has size at least\n$\\eta d$. This was improved by R. Raz and S. Safra in STOC 1997 about the\nNP-hardness for ${\\bf GapSetCover}_{clogm}$ for some constant $c$. In this\npaper we prove that restricted parameter range subproblem is easy. For any\ngiven function of $n$ satisfying $\\eta(n) \\geq 1$, we give a polynomial time\nalgorithm not depending on $\\eta(n)$ to distinguish between\n  {\\bf YES:} The instance $({\\bf U},{\\bf S}, d)$ where $d>\\frac{2 |{\\bf\nS}|}{3\\eta(n)-1}$, for which there exists an exact cover of size at most $d$;\n  {\\bf NO:} The instance $({\\bf U},{\\bf S}, d)$ where $d>\\frac{2 |{\\bf\nS}|}{3\\eta(n)-1}$, for which any cover from ${\\bf S}$ has size larger than\n$\\eta(n) d$.\n  The polynomial time reduction of this restricted parameter range set cover\nproblem is constructed by using the lattice."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2528401", 
    "link": "http://arxiv.org/pdf/1110.2230v1", 
    "title": "The complexity of small universal Turing machines: a survey", 
    "arxiv-id": "1110.2230v1", 
    "author": "Damien Woods", 
    "publish": "2011-10-10T23:22:17Z", 
    "summary": "We survey some work concerned with small universal Turing machines, cellular\nautomata, tag systems, and other simple models of computation. For example it\nhas been an open question for some time as to whether the smallest known\nuniversal Turing machines of Minsky, Rogozhin, Baiocchi and Kudlek are\nefficient (polynomial time) simulators of Turing machines. These are some of\nthe most intuitively simple computational devices and previously the best known\nsimulations were exponentially slow. We discuss recent work that shows that\nthese machines are indeed efficient simulators. In addition, another related\nresult shows that Rule 110, a well-known elementary cellular automaton, is\nefficiently universal. We also discuss some old and new universal program size\nresults, including the smallest known universal Turing machines. We finish the\nsurvey with results on generalised and restricted Turing machine models\nincluding machines with a periodic background on the tape (instead of a blank\nsymbol), multiple tapes, multiple dimensions, and machines that never write to\ntheir tape. We then discuss some ideas for future work."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1110.2809v1", 
    "title": "The complexity of conservative valued CSPs", 
    "arxiv-id": "1110.2809v1", 
    "author": "Stanislav Zivny", 
    "publish": "2011-10-12T22:25:10Z", 
    "summary": "We study the complexity of valued constraint satisfaction problems (VCSP). A\nproblem from VCSP is characterised by a \\emph{constraint language}, a fixed set\nof cost functions over a finite domain. An instance of the problem is specified\nby a sum of cost functions from the language and the goal is to minimise the\nsum.\n  We consider the case of languages containing all possible unary cost\nfunctions. In the case of languages consisting of only $\\{0,\\infty\\}$-valued\ncost functions (i.e. relations), such languages have been called\n\\emph{conservative} and studied by Bulatov [LICS'03] and recently by Barto\n[LICS'11]. Since we study valued languages, we call a language conservative if\nit contains all finite-valued unary cost functions. The complexity of\nconservative valued languages has been studied by Cohen et al. [AIJ'06] for\nlanguages over Boolean domains, by Deineko et al. [JACM'08] for\n$\\{0,1\\}$-valued languages (a.k.a Max-CSP), and by Takhanov [STACS'10] for\n$\\{0,\\infty\\}$-valued languages containing all finite-valued unary cost\nfunctions (a.k.a. Min-Cost-Hom).\n  We prove a Schaefer-like dichotomy theorem for conservative valued languages:\nif all cost functions in the language satisfy a certain condition (specified by\na complementary combination of \\emph{STP and MJN multimorphisms}), then any\ninstance can be solved in polytime (via a new algorithm developed in this\npaper), otherwise the language is NP-hard. This is the \\emph{first} complete\ncomplexity classification of \\emph{general-valued constraint languages} over\nnon-Boolean domains.\n  This generalises previous results by Takhanov [STACS'10] and (a subset of\nresults) by Cohen et al. [AIJ'06] and Deineko et al. [JACM'08]. Moreover, our\nresults do not rely on any computer-assisted search as in Deineko et al.\n[JACM'08], and provide a powerful tool for proving hardness of finite- and\ngeneral-valued languages."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1110.2953v1", 
    "title": "Approximation for Maximum Surjective Constraint Satisfaction Problems", 
    "arxiv-id": "1110.2953v1", 
    "author": "Hang Zhou", 
    "publish": "2011-10-13T14:12:41Z", 
    "summary": "Maximum surjective constraint satisfaction problems (Max-Sur-CSPs) are\ncomputational problems where we are given a set of variables denoting values\nfrom a finite domain B and a set of constraints on the variables. A solution to\nsuch a problem is a surjective mapping from the set of variables to B such that\nthe number of satisfied constraints is maximized. We study the approximation\nperformance that can be acccchieved by algorithms for these problems, mainly by\ninvestigating their relation with Max-CSPs (which are the corresponding\nproblems without the surjectivity requirement). Our work gives a complexity\ndichotomy for Max-Sur-CSP(B) between PTAS and APX-complete, under the\nassumption that there is a complexity dichotomy for Max-CSP(B) between PO and\nAPX-complete, which has already been proved on the Boolean domain and 3-element\ndomains."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1110.3030v3", 
    "title": "Software Engineering and Complexity in Effective Algebraic Geometry", 
    "arxiv-id": "1110.3030v3", 
    "author": "Andres Rojas Paredes", 
    "publish": "2011-10-13T18:58:45Z", 
    "summary": "We introduce the notion of a robust parameterized arithmetic circuit for the\nevaluation of algebraic families of multivariate polynomials. Based on this\nnotion, we present a computation model, adapted to Scientific Computing, which\ncaptures all known branching parsimonious symbolic algorithms in effective\nAlgebraic Geometry. We justify this model by arguments from Software\nEngineering. Finally we exhibit a class of simple elimination problems of\neffective Algebraic Geometry which require exponential time to be solved by\nbranching parsimonious algorithms of our computation model."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1110.3189v1", 
    "title": "About set-theoretic properties of one-way functions", 
    "arxiv-id": "1110.3189v1", 
    "author": "Anatoly D. Plotnikov", 
    "publish": "2011-10-14T12:35:24Z", 
    "summary": "We investigate the problem of cryptanalysis as a problem belonging to the\nclass NP. A class of problems UF is defined for which the time constructing any\nfeasible solution is polynomial. The properties of the problems of NP, which\nmay be one-way functions, are established."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1110.6126v1", 
    "title": "A Counterexample to the Generalized Linial-Nisan Conjecture", 
    "arxiv-id": "1110.6126v1", 
    "author": "Scott Aaronson", 
    "publish": "2011-10-27T16:05:23Z", 
    "summary": "In earlier work, we gave an oracle separating the relational versions of BQP\nand the polynomial hierarchy, and showed that an oracle separating the decision\nversions would follow from what we called the Generalized Linial-Nisan (GLN)\nConjecture: that \"almost k-wise independent\" distributions are\nindistinguishable from the uniform distribution by constant-depth circuits. The\noriginal Linial-Nisan Conjecture was recently proved by Braverman; we offered a\n$200 prize for the generalized version. In this paper, we save ourselves $200\nby showing that the GLN Conjecture is false, at least for circuits of depth 3\nand higher. As a byproduct, our counterexample also implies that Pi2P is not\ncontained in P^NP relative to a random oracle with probability 1. It has been\nconjectured since the 1980s that PH is infinite relative to a random oracle,\nbut the highest levels of PH previously proved separate were NP and coNP.\nFinally, our counterexample implies that the famous results of Linial, Mansour,\nand Nisan, on the structure of AC0 functions, cannot be improved in several\ninteresting respects."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1110.6271v2", 
    "title": "Monomials in arithmetic circuits: Complete problems in the counting   hierarchy", 
    "arxiv-id": "1110.6271v2", 
    "author": "Stefan Mengel", 
    "publish": "2011-10-28T07:45:34Z", 
    "summary": "We consider the complexity of two questions on polynomials given by\narithmetic circuits: testing whether a monomial is present and counting the\nnumber of monomials. We show that these problems are complete for subclasses of\nthe counting hierarchy which had few or no known natural complete problems. We\nalso study these questions for circuits computing multilinear polynomials."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.0305v1", 
    "title": "Construction of an NP Problem with an Exponential Lower Bound", 
    "arxiv-id": "1111.0305v1", 
    "author": "Roman V. Yampolskiy", 
    "publish": "2011-10-28T21:25:12Z", 
    "summary": "In this paper we present a Hashed-Path Traveling Salesperson Problem (HPTSP),\na new type of problem which has the interesting property of having no\npolynomial time solutions. Next we show that HPTSP is in the class NP by\ndemonstrating that local information about sub-routes is insufficient to\ncompute the complete value of each route. As a consequence, via Ladner's\ntheorem, we show that the class NPI is non-empty."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.0405v1", 
    "title": "Making the long code shorter, with applications to the Unique Games   Conjecture", 
    "arxiv-id": "1111.0405v1", 
    "author": "David Steurer", 
    "publish": "2011-11-02T07:06:31Z", 
    "summary": "The long code is a central tool in hardness of approximation, especially in\nquestions related to the unique games conjecture. We construct a new code that\nis exponentially more efficient, but can still be used in many of these\napplications. Using the new code we obtain exponential improvements over\nseveral known results, including the following:\n  1. For any eps > 0, we show the existence of an n vertex graph G where every\nset of o(n) vertices has expansion 1 - eps, but G's adjacency matrix has more\nthan exp(log^delta n) eigenvalues larger than 1 - eps, where delta depends only\non eps. This answers an open question of Arora, Barak and Steurer (FOCS 2010)\nwho asked whether one can improve over the noise graph on the Boolean hypercube\nthat has poly(log n) such eigenvalues.\n  2. A gadget that reduces unique games instances with linear constraints\nmodulo K into instances with alphabet k with a blowup of K^polylog(K),\nimproving over the previously known gadget with blowup of 2^K.\n  3. An n variable integrality gap for Unique Games that that survives\nexp(poly(log log n)) rounds of the SDP + Sherali Adams hierarchy, improving on\nthe previously known bound of poly(log log n).\n  We show a connection between the local testability of linear codes and small\nset expansion in certain related Cayley graphs, and use this connection to\nderandomize the noise graph on the Boolean hypercube."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.0422v1", 
    "title": "Inclusion of Unambiguous RE#s is NP-Hard", 
    "arxiv-id": "1111.0422v1", 
    "author": "Pekka Kilpel\u00e4inen", 
    "publish": "2011-11-02T08:36:17Z", 
    "summary": "We show that testing inclusion between languages represented by regular\nexpressions with numerical occurrence indicators (RE#s) is NP-hard, even if the\nexpressions satisfy the requirement of \"unambiguity\", which is required for XML\nSchema content model expressions."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.0706v1", 
    "title": "Maximum Bounded Rooted-Tree Packing Problem", 
    "arxiv-id": "1111.0706v1", 
    "author": "Fen Zhou", 
    "publish": "2011-11-03T01:16:09Z", 
    "summary": "Given a graph and a root, the Maximum Bounded Rooted-Tree Packing (MBRTP)\nproblem aims at finding K rooted-trees that span the largest subset of\nvertices, when each vertex has a limited outdegree. This problem is motivated\nby peer-to-peer streaming overlays in under-provisioned systems. We prove that\nthe MBRTP problem is NP-complete. We present two polynomial-time algorithms\nthat computes an optimal solution on complete graphs and trees respectively."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.1261v1", 
    "title": "A Casual Tour Around a Circuit Complexity Bound", 
    "arxiv-id": "1111.1261v1", 
    "author": "Ryan Williams", 
    "publish": "2011-11-04T22:08:36Z", 
    "summary": "I will discuss the recent proof that the complexity class NEXP\n(nondeterministic exponential time) lacks nonuniform ACC circuits of polynomial\nsize. The proof will be described from the perspective of someone trying to\ndiscover it."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.2127v1", 
    "title": "Monotone switching networks for directed connectivity are strictly more   powerful than certain-knowledge switching networks", 
    "arxiv-id": "1111.2127v1", 
    "author": "Aaron Potechin", 
    "publish": "2011-11-09T08:18:23Z", 
    "summary": "L (Logarithmic space) versus NL (Non-deterministic logarithmic space) is one\nof the great open problems in computational complexity theory. In the paper\n\"Bounds on monotone switching networks for directed connectivity\", we separated\nmonotone analogues of L and NL using a model called the switching network\nmodel. In particular, by considering inputs consisting of just a path and\nisolated vertices, we proved that any monotone switching network solving\ndirected connectivity on $N$ vertices must have size at least\n$N^{\\Omega(\\lg(N))}$ and this bound is tight. If we could show a similar result\nfor general switching networks solving directed connectivity, then this would\nprove that $L \\neq NL$. However, proving lower bounds for general switching\nnetworks solving directed connectivity requires proving stronger lower bounds\non monotone switching networks for directed connectivity. To work towards this\ngoal, we investigated a different set of inputs which we believed to be hard\nfor monotone switching networks to solve and attempted to prove similar lower\nsize bounds. Instead, we found that this set of inputs is actually easy for\nmonotone switching networks for directed connectivity to solve, yet if we\nrestrict ourselves to certain-knowledge switching networks, which are a simple\nand intuitive subclass of monotone switching networks for directed\nconnectivity, then these inputs are indeed hard to solve. In this paper, we\ngive this set of inputs, demonstrate a \"weird\" polynomially-sized monotone\nswitching network for directed connectivity which solves this set of inputs,\nand prove that no polynomially-sized certain-knowledge switching network can\nsolve this set of inputs, thus proving that monotone switching networks for\ndirected connectivity are strictly more powerful than certain-knowledge\nswitching networks."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2450142.2450146", 
    "link": "http://arxiv.org/pdf/1111.2384v1", 
    "title": "Complexity of Counting CSP with Complex Weights", 
    "arxiv-id": "1111.2384v1", 
    "author": "Xi Chen", 
    "publish": "2011-11-10T02:42:57Z", 
    "summary": "We give a complexity dichotomy theorem for the counting Constraint\nSatisfaction Problem (#CSP in short) with complex weights. To this end, we give\nthree conditions for its tractability. Let F be any finite set of\ncomplex-valued functions, then we prove that #CSP(F) is solvable in polynomial\ntime if all three conditions are satisfied; and is #P-hard otherwise.\n  Our complexity dichotomy generalizes a long series of important results on\ncounting problems: (a) the problem of counting graph homomorphisms is the\nspecial case when there is a single symmetric binary function in F; (b) the\nproblem of counting directed graph homomorphisms is the special case when there\nis a single not-necessarily-symmetric binary function in F; and (c) the\nstandard form of #CSP is when all functions in F take values in {0,1}."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1111.3321v3", 
    "title": "Approximating Fixation Probabilities in the Generalized Moran Process", 
    "arxiv-id": "1111.3321v3", 
    "author": "Paul G. Spirakis", 
    "publish": "2011-11-14T18:51:42Z", 
    "summary": "We consider the Moran process, as generalized by Lieberman, Hauert and Nowak\n(Nature, 433:312--316, 2005). A population resides on the vertices of a finite,\nconnected, undirected graph and, at each time step, an individual is chosen at\nrandom with probability proportional to its assigned 'fitness' value. It\nreproduces, placing a copy of itself on a neighbouring vertex chosen uniformly\nat random, replacing the individual that was there. The initial population\nconsists of a single mutant of fitness $r>0$ placed uniformly at random, with\nevery other vertex occupied by an individual of fitness 1. The main quantities\nof interest are the probabilities that the descendants of the initial mutant\ncome to occupy the whole graph (fixation) and that they die out (extinction);\nalmost surely, these are the only possibilities. In general, exact computation\nof these quantities by standard Markov chain techniques requires solving a\nsystem of linear equations of size exponential in the order of the graph so is\nnot feasible. We show that, with high probability, the number of steps needed\nto reach fixation or extinction is bounded by a polynomial in the number of\nvertices in the graph. This bound allows us to construct fully polynomial\nrandomized approximation schemes (FPRAS) for the probability of fixation (when\n$r\\geq 1$) and of extinction (for all $r>0$)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1111.4121v2", 
    "title": "Unpredictability and Computational Irreducibility", 
    "arxiv-id": "1111.4121v2", 
    "author": "Jean-Paul Delahaye", 
    "publish": "2011-11-17T15:01:44Z", 
    "summary": "We explore several concepts for analyzing the intuitive notion of\ncomputational irreducibility and we propose a robust formal definition, first\nin the field of cellular automata and then in the general field of any\ncomputable function f from N to N. We prove that, through a robust definition\nof what means \"to be unable to compute the nth step without having to follow\nthe same path than simulating the automaton or the function\", this implies\ngenuinely, as intuitively expected, that if the behavior of an object is\ncomputationally irreducible, no computation of its nth state can be faster than\nthe simulation itself."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1111.4372v2", 
    "title": "An additivity theorem for plain Kolmogorov complexity", 
    "arxiv-id": "1111.4372v2", 
    "author": "Alexander Shen", 
    "publish": "2011-11-18T14:27:43Z", 
    "summary": "We prove the formula C(a,b) = K(a|C(a,b)) + C(b|a,C(a,b)) + O(1) that\nexpresses the plain complexity of a pair in terms of prefix and plain\nconditional complexities of its components."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1112.0987v17", 
    "title": "Small Jump with Negation-UTM Trampoline", 
    "arxiv-id": "1112.0987v17", 
    "author": "Koji Kobayashi", 
    "publish": "2011-12-05T16:45:26Z", 
    "summary": "This paper divide some complexity class by using fixpoint and fixpointless\narea of Decidable Universal Turing Machine (UTM). Decidable Deterministic\nTuring Machine (DTM) have fixpointless combinator that add no extra resources\n(like Negation), but UTM makes some fixpoint in the combinator. This means that\nwe can jump out of the fixpointless combinator system by making more complex\nproblem from diagonalisation argument of UTM.\n  As a concrete example, we proof L is not P . We can make Polynomial time UTM\nthat emulate all Logarithm space DTM (LDTM). LDTM set close under Negation,\ntherefore UTM does not close under LDTM set. (We can proof this theorem like\nhalting problem and time/space hierarchy theorem, and also we can extend this\nproof to divide time/space limited DTM set.) In the same way, we proof P is not\nNP. These are new hierarchy that use UTM and Negation."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1112.1040v1", 
    "title": "What makes normalized weighted satisfiability tractable", 
    "arxiv-id": "1112.1040v1", 
    "author": "Ge Xia", 
    "publish": "2011-12-05T19:56:11Z", 
    "summary": "We consider the weighted antimonotone and the weighted monotone\nsatisfiability problems on normalized circuits of depth at most $t \\geq 2$,\nabbreviated {\\sc wsat$^-[t]$} and {\\sc wsat$^+[t]$}, respectively. These\nproblems model the weighted satisfiability of antimonotone and monotone\npropositional formulas (including weighted anitmonoone/monotone {\\sc cnf-sat})\nin a natural way, and serve as the canonical problems in the definition of the\nparameterized complexity hierarchy. We characterize the parameterized\ncomplexity of {\\sc wsat$^-[t]$} and {\\sc wsat$^+[t]$} with respect to the genus\nof the circuit. For {\\sc wsat$^-[t]$}, which is $W[t]$-complete for odd $t$ and\n$W[t-1]$-complete for even $t$, the characterization is precise: We show that\n{\\sc wsat$^-[t]$} is fixed-parameter tractable (FPT) if the genus of the\ncircuit is $n^{o(1)}$ ($n$ is the number of the variables in the circuit), and\nthat it has the same $W$-hardness as the general {\\sc wsat$^-[t]$} problem\n(i.e., with no restriction on the genus) if the genus is $n^{O(1)}$. For {\\sc\nwsat$^+[2]$} (i.e., weighted monotone {\\sc cnf-sat}), which is $W[2]$-complete,\nthe characterization is also precise: We show that {\\sc wsat$^+[2]$} is FPT if\nthe genus is $n^{o(1)}$ and $W[2]$-complete if the genus is $n^{O(1)}$. For\n{\\sc wsat$^+[t]$} where $t > 2$, which is $W[t]$-complete for even $t$ and\n$W[t-1]$-complete for odd $t$, we show that it is FPT if the genus is\n$O(\\sqrt{\\log{n}})$, and that it has the same $W$-hardness as the general {\\sc\nwsat$^+[t]$} problem if the genus is $n^{O(1)}$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1112.1564v1", 
    "title": "Improved hardness results for unique shortest vector problem", 
    "arxiv-id": "1112.1564v1", 
    "author": "Chandan Dubey", 
    "publish": "2011-12-07T13:58:29Z", 
    "summary": "We give several improvements on the known hardness of the unique shortest\nvector problem. - We give a deterministic reduction from the shortest vector\nproblem to the unique shortest vector problem. As a byproduct, we get\ndeterministic NP-hardness for unique shortest vector problem in the\n$\\ell_\\infty$ norm. - We give a randomized reduction from SAT to\nuSVP_{1+1/poly(n)}. This shows that uSVP_{1+1/poly(n)} is NP-hard under\nrandomized reductions. - We show that if GapSVP_\\gamma \\in coNP (or coAM) then\nuSVP_{\\sqrt{\\gamma}} \\in coNP (coAM respectively). This simplifies previously\nknown uSVP_{n^{1/4}} \\in coAM proof by Cai \\cite{Cai98} to uSVP_{(n/\\log\nn)^{1/4}} \\in coAM, and additionally generalizes it to uSVP_{n^{1/4}} \\in coNP.\n- We give a deterministic reduction from search-uSVP_\\gamma to the\ndecision-uSVP_{\\gamma/2}. We also show that the decision-uSVP is {\\bf NP}-hard\nfor randomized reductions, which does not follow from Kumar-Sivakumar\n\\cite{KS01}."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00453-012-9722-7", 
    "link": "http://arxiv.org/pdf/1112.2000v3", 
    "title": "A discrepancy lower bound for information complexity", 
    "arxiv-id": "1112.2000v3", 
    "author": "Omri Weinstein", 
    "publish": "2011-12-09T02:02:56Z", 
    "summary": "This paper provides the first general technique for proving information lower\nbounds on two-party unbounded-rounds communication problems. We show that the\ndiscrepancy lower bound, which applies to randomized communication complexity,\nalso applies to information complexity. More precisely, if the discrepancy of a\ntwo-party function $f$ with respect to a distribution $\\mu$ is $Disc_\\mu f$,\nthen any two party randomized protocol computing $f$ must reveal at least\n$\\Omega(\\log (1/Disc_\\mu f))$ bits of information to the participants. As a\ncorollary, we obtain that any two-party protocol for computing a random\nfunction on $\\{0,1\\}^n\\times\\{0,1\\}^n$ must reveal $\\Omega(n)$ bits of\ninformation to the participants.\n  In addition, we prove that the discrepancy of the Greater-Than function is\n$\\Omega(1/\\sqrt{n})$, which provides an alternative proof to the recent proof\nof Viola \\cite{Viola11} of the $\\Omega(\\log n)$ lower bound on the\ncommunication complexity of this well-studied function and, combined with our\nmain result, proves the tight $\\Omega(\\log n)$ lower bound on its information\ncomplexity.\n  The proof of our main result develops a new simulation procedure that may be\nof an independent interest. In a very recent breakthrough work of Kerenidis et\nal. \\cite{kerenidis2012lower}, this simulation procedure was the main building\nblock for proving that almost all known lower bound techniques for\ncommunication complexity (and not just discrepancy) apply to information\ncomplexity."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1112.2127v1", 
    "title": "Efficiency Theory: a Unifying Theory for Information, Computation and   Intelligence", 
    "arxiv-id": "1112.2127v1", 
    "author": "Roman V. Yampolskiy", 
    "publish": "2011-12-08T16:41:59Z", 
    "summary": "The paper serves as the first contribution towards the development of the\ntheory of efficiency: a unifying framework for the currently disjoint theories\nof information, complexity, communication and computation. Realizing the\ndefining nature of the brute force approach in the fundamental concepts in all\nof the above mentioned fields, the paper suggests using efficiency or\nimprovement over the brute force algorithm as a common unifying factor\nnecessary for the creation of a unified theory of information manipulation. By\ndefining such diverse terms as randomness, knowledge, intelligence and\ncomputability in terms of a common denominator we are able to bring together\ncontributions from Shannon, Levin, Kolmogorov, Solomonoff, Chaitin, Yao and\nmany others under a common umbrella of the efficiency theory."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1112.2519v1", 
    "title": "Errors in Improved Polynomial Algorithm For 3 Sat Proposed By Narendra   Chaudhari", 
    "arxiv-id": "1112.2519v1", 
    "author": "Ritesh Vispute", 
    "publish": "2011-12-12T12:10:47Z", 
    "summary": "There are errors in the algorithm proposed by Narendra Chaudhari [2]\npurporting to solve the 3-sat problem in polynomial time. The present paper\npresent instances for which the algorithm outputs erroneous results."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1112.2974v1", 
    "title": "Constraint Satisfaction with Counting Quantifiers", 
    "arxiv-id": "1112.2974v1", 
    "author": "Juraj Stacho", 
    "publish": "2011-12-13T17:41:52Z", 
    "summary": "We initiate the study of constraint satisfaction problems (CSPs) in the\npresence of counting quantifiers, which may be seen as variants of CSPs in the\nmould of quantified CSPs (QCSPs). We show that a single counting quantifier\nstrictly between exists^1:=exists and exists^n:=forall (the domain being of\nsize n) already affords the maximal possible complexity of QCSPs (which have\nboth exists and forall), being Pspace-complete for a suitably chosen template.\nNext, we focus on the complexity of subsets of counting quantifiers on clique\nand cycle templates. For cycles we give a full trichotomy -- all such problems\nare in L, NP-complete or Pspace-complete. For cliques we come close to a\nsimilar trichotomy, but one case remains outstanding. Afterwards, we consider\nthe generalisation of CSPs in which we augment the extant quantifier\nexists^1:=exists with the quantifier exists^j (j not 1). Such a CSP is already\nNP-hard on non-bipartite graph templates. We explore the situation of this\ngeneralised CSP on bipartite templates, giving various conditions for both\ntractability and hardness -- culminating in a classification theorem for\ngeneral graphs. Finally, we use counting quantifiers to solve the complexity of\na concrete QCSP whose complexity was previously open."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1112.4295v1", 
    "title": "Computing Bits of Algebraic Numbers", 
    "arxiv-id": "1112.4295v1", 
    "author": "Rameshwar Pratap", 
    "publish": "2011-12-19T10:51:14Z", 
    "summary": "We initiate the complexity theoretic study of the problem of computing the\nbits of (real) algebraic numbers. This extends the work of Yap on computing the\nbits of transcendental numbers like \\pi, in Logspace.\n  Our main result is that computing a bit of a fixed real algebraic number is\nin C=NC1\\subseteq Logspace when the bit position has a verbose (unary)\nrepresentation and in the counting hierarchy when it has a succinct (binary)\nrepresentation.\n  Our tools are drawn from elementary analysis and numerical analysis, and\ninclude the Newton-Raphson method. The proof of our main result is entirely\nelementary, preferring to use the elementary Liouville's theorem over the much\ndeeper Roth's theorem for algebraic numbers.\n  We leave the possibility of proving non-trivial lower bounds for the problem\nof computing the bits of an algebraic number given the bit position in binary,\nas our main open question. In this direction we show very limited progress by\nproving a lower bound for rationals."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1112.4536v1", 
    "title": "Intractability of the Minimum-Flip Supertree problem and its variants", 
    "arxiv-id": "1112.4536v1", 
    "author": "Anke Truss", 
    "publish": "2011-12-20T00:32:15Z", 
    "summary": "Computing supertrees is a central problem in phylogenetics. The supertree\nmethod that is by far the most widely used today was introduced in 1992 and is\ncalled Matrix Representation with Parsimony analysis (MRP). Matrix\nRepresentation using Flipping (MRF)}, which was introduced in 2002, is an\ninteresting variant of MRP: MRF is arguably more relevant that MRP and various\nefficient implementations of MRF have been presented. From a theoretical point\nof view, implementing MRF or MRP is solving NP-hard optimization problems. The\naim of this paper is to study the approximability and the fixed-parameter\ntractability of the optimization problem corresponding to MRF, namely\nMinimum-Flip Supertree. We prove strongly negative results."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.1223v1", 
    "title": "Turing Machines and Understanding Computational Complexity", 
    "arxiv-id": "1201.1223v1", 
    "author": "P. M. B. Vitanyi", 
    "publish": "2012-01-05T17:24:33Z", 
    "summary": "We describe the Turing Machine, list some of its many influences on the\ntheory of computation and complexity of computations, and illustrate its\nimportance."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.1666v1", 
    "title": "A direct product theorem for bounded-round public-coin randomized   communication complexity", 
    "arxiv-id": "1201.1666v1", 
    "author": "Penghui Yao", 
    "publish": "2012-01-08T23:31:01Z", 
    "summary": "In this paper, we show a direct product theorm in the model of two-party\nbounded-round public-coin randomized communication complexity. For a relation f\nsubset of X times Y times Z (X,Y,Z are finite sets), let R^{(t), pub}_e (f)\ndenote the two-party t-message public-coin communication complexity of f with\nworst case error e. We show that for any relation f and positive integer k:\nR^{(t), pub}_{1 - 2^{-Omega(k/t^2)}}(f^k) = Omega(k/t (R^{(t), pub}_{1/3}(f) -\nO(t^2))) . In particular, it implies a strong direct product theorem for the\ntwo-party constant-message public-coin randomized communication complexity of\nall relations f.\n  Our result for example implies a strong direct product theorem for the\npointer chasing problem. This problem has been well studied for understanding\nround v/s communication trade-offs in both classical and quantum communication\nprotocols.\n  We show our result using information theoretic arguments. Our arguments and\ntechniques build on the ones used in [Jain 2011], where a strong direct product\ntheorem for the two-party one-way public-coin communication complexity of all\nrelations is shown (that is the special case of our result when t=1). One key\ntool used in our work and also in [Jain 2011] is a message compression\ntechnique due to [Braverman and Rao 2011], who used it to show a direct sum\ntheorem for the two-party bounded-round public-coin randomized communication\ncomplexity of all relations. Another important tool that we use is a correlated\nsampling protocol, which for example, has been used in [Holenstein 2007] for\nproving a parallel repetition theorem for two-prover games."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.2374v2", 
    "title": "Polynomial Time Algorithms for Multi-Type Branching Processes and   Stochastic Context-Free Grammars", 
    "arxiv-id": "1201.2374v2", 
    "author": "Mihalis Yannakakis", 
    "publish": "2012-01-11T18:42:46Z", 
    "summary": "We show that one can approximate the least fixed point solution for a\nmultivariate system of monotone probabilistic polynomial equations in time\npolynomial in both the encoding size of the system of equations and in\nlog(1/\\epsilon), where \\epsilon > 0 is the desired additive error bound of the\nsolution. (The model of computation is the standard Turing machine model.)\n  We use this result to resolve several open problems regarding the\ncomputational complexity of computing key quantities associated with some\nclassic and heavily studied stochastic processes, including multi-type\nbranching processes and stochastic context-free grammars."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.2553v2", 
    "title": "A New Order-theoretic Characterisation of the Polytime Computable   Functions", 
    "arxiv-id": "1201.2553v2", 
    "author": "Georg Moser", 
    "publish": "2012-01-12T12:57:40Z", 
    "summary": "We propose a new order, the small polynomial path order (sPOP* for short).\nThe order sPOP* provides a characterisation of the class of polynomial time\ncomputable function via term rewrite systems. Any polynomial time computable\nfunction gives rise to a rewrite system that is compatible with sPOP*. On the\nother hand any function defined by a rewrite system compatible with sPOP* is\npolynomial time computable. Technically sPOP* is a tamed recursive path order\nwith product status. Its distinctive feature is the precise control provided.\nFor any rewrite system that is compatible with sPOP* that makes use of\nrecursion up to depth d, the (innermost) runtime complexity is bounded from\nabove by a polynomial of degree d."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.3306v1", 
    "title": "Simulating Special but Natural Quantum Circuits", 
    "arxiv-id": "1201.3306v1", 
    "author": "Atri Rudra", 
    "publish": "2012-01-16T16:22:44Z", 
    "summary": "We identify a sub-class of BQP that captures certain structural commonalities\namong many quantum algorithms including Shor's algorithms. This class does not\ncontain all of BQP (e.g. Grover's algorithm does not fall into this class). Our\nmain result is that any algorithm in this class that measures at most O(log n)\nqubits can be simulated by classical randomized polynomial time algorithms.\nThis does not dequantize Shor's algorithm (as the latter measures n qubits) but\nour work also highlights a new potentially hard function for cryptographic\napplications.\n  Our main technical contribution is (to the best of our knowledge) a new exact\ncharacterization of certain sums of Fourier-type coefficients (with\nexponentially many summands)."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.4344v2", 
    "title": "On the intrinsic complexity of elimination problems in effective   Algebraic Geometry", 
    "arxiv-id": "1201.4344v2", 
    "author": "Andres Rojas Paredes", 
    "publish": "2012-01-20T17:16:22Z", 
    "summary": "The representation of polynomials by arithmetic circuits evaluating them is\nan alternative data structure which allowed considerable progress in polynomial\nequation solving in the last fifteen years. We present a circuit based\ncomputation model which captures all known symbolic elimination algorithms in\neffective algebraic geometry and show the intrinsically exponential complexity\ncharacter of elimination in this complexity model."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.4995v5", 
    "title": "Gaming is a hard job, but someone has to do it!", 
    "arxiv-id": "1201.4995v5", 
    "author": "Giovanni Viglietta", 
    "publish": "2012-01-24T14:56:45Z", 
    "summary": "We establish some general schemes relating the computational complexity of a\nvideo game to the presence of certain common elements or mechanics, such as\ndestroyable paths, collectible items, doors opened by keys or activated by\nbuttons or pressure plates, etc. Then we apply such \"metatheorems\" to several\nvideo games published between 1980 and 1998, including Pac-Man, Tron, Lode\nRunner, Boulder Dash, Deflektor, Mindbender, Pipe Mania, Skweek, Prince of\nPersia, Lemmings, Doom, Puzzle Bobble~3, and Starcraft. We obtain both new\nresults, and improvements or alternative proofs of previously known results."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1201.5298v1", 
    "title": "Scrabble is PSPACE-Complete", 
    "arxiv-id": "1201.5298v1", 
    "author": "Karolina So\u0142tys", 
    "publish": "2012-01-25T15:27:31Z", 
    "summary": "In this paper we study the computational complexity of the game of Scrabble.\nWe prove the PSPACE-completeness of a derandomized model of the game, answering\nan open question of Erik Demaine and Robert Hearn."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1202.1194v11", 
    "title": "Topological approach to solve P versus NP", 
    "arxiv-id": "1202.1194v11", 
    "author": "Koji Kobayashi", 
    "publish": "2012-02-06T16:26:23Z", 
    "summary": "This paper talks about difference between P and NP by using topological space\nthat mean resolution principle. I pay attention to restrictions of antecedent\nand consequent in resolution, and show what kind of influence the restrictions\nhave for difference of structure between P and NP regarding relations of\nrelation.\n  First, I show the restrictions of antecedent and consequent in resolution\nprinciple. Antecedents connect each other, and consequent become a linkage\nbetween these antecedents. And we can make consequent as antecedents product by\nusing some resolutions which have same joint variable. We can determine these\nconsequents reducible and irreducible.\n  Second, I introduce RCNF that mean topology of resolution principle in CNF.\nRCNF is HornCNF and that variable values are presence of restrictions of CNF\nformula clauses. RCNF is P-Complete.\n  Last, I introduce TCNF that have 3CNF's character which relate 2 variables\nrelations with 1 variable. I show CNF complexity by using CCNF that combine\nsome TCNF. TCNF is NP-Complete and product irreducible. I introduce CCNF that\nconnect TCNF like Moore graph. We cannot reduce CCNF to RCNF with polynomial\nsize. Therefore, TCNF is not in P."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1202.1936v2", 
    "title": "Smoothed Complexity Theory", 
    "arxiv-id": "1202.1936v2", 
    "author": "Bodo Manthey", 
    "publish": "2012-02-09T10:17:53Z", 
    "summary": "Smoothed analysis is a new way of analyzing algorithms introduced by Spielman\nand Teng (J. ACM, 2004). Classical methods like worst-case or average-case\nanalysis have accompanying complexity classes, like P and AvgP, respectively.\nWhile worst-case or average-case analysis give us a means to talk about the\nrunning time of a particular algorithm, complexity classes allows us to talk\nabout the inherent difficulty of problems.\n  Smoothed analysis is a hybrid of worst-case and average-case analysis and\ncompensates some of their drawbacks. Despite its success for the analysis of\nsingle algorithms and problems, there is no embedding of smoothed analysis into\ncomputational complexity theory, which is necessary to classify problems\naccording to their intrinsic difficulty.\n  We propose a framework for smoothed complexity theory, define the relevant\nclasses, and prove some first hardness results (of bounded halting and tiling)\nand tractability results (binary optimization problems, graph coloring,\nsatisfiability). Furthermore, we discuss extensions and shortcomings of our\nmodel and relate it to semi-random models."
},{
    "category": "cs.CC", 
    "doi": "10.1080/09720529.2013.821361", 
    "link": "http://arxiv.org/pdf/1202.3479v4", 
    "title": "Lower Bounds on Testing Functions of Low Fourier Degree", 
    "arxiv-id": "1202.3479v4", 
    "author": "Pooya Hatami", 
    "publish": "2012-02-16T00:23:15Z", 
    "summary": "We consider the problem of testing whether a Boolean function has Fourier\ndegree $\\leq k$ or it is $\\epsilon$-far from any Boolean function with Fourier\ndegree $\\leq k$. We improve the known lower bound of $\\Omega(k)$\n\\cite{BBM11,CGM10}, to $\\Omega(k/\\sqrt{\\epsilon})$. The lower bound uses the\nrecently discovered connections between property testing and communication\ncomplexity by Blais \\textit{et. al.} \\cite{BBM11}"
},{
    "category": "cs.CC", 
    "doi": "10.4086/cjtcs.2013.010", 
    "link": "http://arxiv.org/pdf/1202.3949v3", 
    "title": "On the complexity of solving linear congruences and computing nullspaces   modulo a constant", 
    "arxiv-id": "1202.3949v3", 
    "author": "Niel de Beaudrap", 
    "publish": "2012-02-17T16:18:46Z", 
    "summary": "We consider the problems of determining the feasibility of a linear\ncongruence, producing a solution to a linear congruence, and finding a spanning\nset for the nullspace of an integer matrix, where each problem is considered\nmodulo an arbitrary constant k>1. These problems are known to be complete for\nthe logspace modular counting classes {Mod_k L} = {coMod_k L} in special case\nthat k is prime (Buntrock et al, 1992). By considering variants of standard\nlogspace function classes --- related to #L and functions computable by UL\nmachines, but which only characterize the number of accepting paths modulo k\n--- we show that these problems of linear algebra are also complete for\n{coMod_k L} for any constant k>1.\n  Our results are obtained by defining a class of functions FUL_k which are low\nfor {Mod_k L} and {coMod_k L} for k>1, using ideas similar to those used in the\ncase of k prime in (Buntrock et al, 1992) to show closure of Mod_k L under NC^1\nreductions (including {Mod_k L} oracle reductions). In addition to the results\nabove, we briefly consider the relationship of the class FUL_k for arbitrary\nmoduli k to the class {F.coMod_k L} of functions whose output symbols are\nverifiable by {coMod_k L} algorithms; and consider what consequences such a\ncomparison may have for oracle closure results of the form {Mod_k L}^{Mod_k L}\n= {Mod_k L} for composite k."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1202.5184v2", 
    "title": "Some results on more flexible versions of Graph Motif", 
    "arxiv-id": "1202.5184v2", 
    "author": "Florian Sikora", 
    "publish": "2012-02-23T14:11:29Z", 
    "summary": "The problems studied in this paper originate from Graph Motif, a problem\nintroduced in 2006 in the context of biological networks. Informally speaking,\nit consists in deciding if a multiset of colors occurs in a connected subgraph\nof a vertex-colored graph. Due to the high rate of noise in the biological\ndata, more flexible definitions of the problem have been outlined. We present\nin this paper two inapproximability results for two different optimization\nvariants of Graph Motif: one where the size of the solution is maximized, the\nother when the number of substitutions of colors to obtain the motif from the\nsolution is minimized. We also study a decision version of Graph Motif where\nthe connectivity constraint is replaced by the well known notion of graph\nmodularity. While the problem remains NP-complete, it allows algorithms in FPT\nfor biologically relevant parameterizations."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1202.5258v6", 
    "title": "Explicit Optimal Hardness via Gaussian stability results", 
    "arxiv-id": "1202.5258v6", 
    "author": "Elchanan Mossel", 
    "publish": "2012-02-23T18:28:22Z", 
    "summary": "The results of Raghavendra (2008) show that assuming Khot's Unique Games\nConjecture (2002), for every constraint satisfaction problem there exists a\ngeneric semi-definite program that achieves the optimal approximation factor.\nThis result is existential as it does not provide an explicit optimal rounding\nprocedure nor does it allow to calculate exactly the Unique Games hardness of\nthe problem.\n  Obtaining an explicit optimal approximation scheme and the corresponding\napproximation factor is a difficult challenge for each specific approximation\nproblem. An approach for determining the exact approximation factor and the\ncorresponding optimal rounding was established in the analysis of MAX-CUT (KKMO\n2004) and the use of the Invariance Principle (MOO 2005). However, this\napproach crucially relies on results explicitly proving optimal partitions in\nGaussian space. Until recently, Borell's result (Borell 1985) was the only\nnon-trivial Gaussian partition result known.\n  In this paper we derive the first explicit optimal approximation algorithm\nand the corresponding approximation factor using a new result on Gaussian\npartitions due to Isaksson and Mossel (2012). This Gaussian result allows us to\ndetermine exactly the Unique Games Hardness of MAX-3-EQUAL. In particular, our\nresults show that Zwick algorithm for this problem achieves the optimal\napproximation factor and prove that the approximation achieved by the algorithm\nis $\\approx 0.796$ as conjectured by Zwick.\n  We further use the previously known optimal Gaussian partitions results to\nobtain a new Unique Games Hardness factor for MAX-k-CSP : Using the well known\nfact that jointly normal pairwise independent random variables are fully\nindependent, we show that the the UGC hardness of Max-k-CSP is $\\frac{\\lceil\n(k+1)/2 \\rceil}{2^{k-1}}$, improving on results of Austrin and Mossel (2009)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1202.6043v2", 
    "title": "On the computational complexity of a game of cops and robbers", 
    "arxiv-id": "1202.6043v2", 
    "author": "Marcello Mamino", 
    "publish": "2012-02-27T20:22:56Z", 
    "summary": "We study the computational complexity of a perfect-information two-player\ngame proposed by Aigner and Fromme. The game takes place on an undirected graph\nwhere n simultaneously moving cops attempt to capture a single robber, all\nmoving at the same speed. The players are allowed to pick their starting\npositions at the first move. The question of the computational complexity of\ndeciding this game was raised in the '90s by Goldstein and Reingold. We prove\nthat the game is hard for PSPACE."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1202.6395v1", 
    "title": "Functions that preserve p-randomness", 
    "arxiv-id": "1202.6395v1", 
    "author": "Stephen A. Fenner", 
    "publish": "2012-02-28T22:03:38Z", 
    "summary": "We show that polynomial-time randomness (p-randomness) is preserved under a\nvariety of familiar operations, including addition and multiplication by a\nnonzero polynomial-time computable real number. These results follow from a\ngeneral theorem: If $I$ is an open interval in the reals, $f$ is a function\nmapping $I$ into the reals, and $r$ in $I$ is p-random, then $f(r)$ is p-random\nprovided\n  1. $f$ is p-computable on the dyadic rational points in $I$, and\n  2. $f$ varies sufficiently at $r$, i.e., there exists a real constant $C > 0$\nsuch that either (a) $(f(x) - f(r))/(x-r) > C$ for all $x$ in $I$ with $x \\ne\nr$, or (b) $(f(x) - f(r))(x-r) < -C$ for all $x$ in $I$ with $x \\ne r$.\n  Our theorem implies in particular that any analytic function about a\np-computable point whose power series has uniformly p-computable coefficients\npreserves p-randomness in its open interval of absolute convergence. Such\nfunctions include all the familiar functions from first-year calculus."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1202.6668v2", 
    "title": "Complexity of complexity and strings with maximal plain and prefix   Kolmogorov complexity", 
    "arxiv-id": "1202.6668v2", 
    "author": "Alexander Shen", 
    "publish": "2012-02-29T20:09:17Z", 
    "summary": "Peter Gacs showed (Gacs 1974) that for every n there exists a bit string x of\nlength n whose plain complexity C(x) has almost maximal conditional complexity\nrelative to x, i.e., C(C(x)|x) > log n - log^(2) n - O(1). (Here log^(2) i =\nlog log i.) Following Elena Kalinina (Kalinina 2011), we provide a simple\ngame-based proof of this result; modifying her argument, we get a better (and\ntight) bound log n - O(1). We also show the same bound for prefix-free\ncomplexity.\n  Robert Solovay showed (Solovay 1975) that infinitely many strings x have\nmaximal plain complexity but not maximal prefix complexity (among the strings\nof the same length): for some c there exist infinitely many x such that |x| -\nC(x) < c and |x| + K(|x|) - K(x) > log^(2) |x| - c log^(3) |x|. In fact, the\nresults of Solovay and Gacs are closely related. Using the result above, we\nprovide a short proof for Solovay's result. We also generalize it by showing\nthat for some c and for all n there are strings x of length n with n - C (x) <\nc and n + K(n) - K(x) > K(K(n)|n) - 3 K(K(K(n)|n)|n) - c. We also prove a close\nupper bound K(K(n)|n) + O(1).\n  Finally, we provide a direct game proof for Joseph Miller's generalization\n(Miller 2006) of the same Solovay's theorem: if a co-enumerable set (a set with\nc.e. complement) contains for every length a string of this length, then it\ncontains infinitely many strings x such that |x| + K(|x|) - K(x) > log^(2) |x|\n+ O(log^(3) |x|)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1203.1335v1", 
    "title": "A Turing Machine Resisting Isolated Bursts Of Faults", 
    "arxiv-id": "1203.1335v1", 
    "author": "Peter Gacs", 
    "publish": "2012-03-06T21:22:00Z", 
    "summary": "We consider computations of a Turing machine under noise that causes\nconsecutive violations of the machine's transition function. Given a constant\nupper bound B on the size of bursts of faults, we construct a Turing machine\nM(B) subject to faults that can simulate any fault-free machine under the\ncondition that bursts are not closer to each other than V for an appropriate V\n= O(B^2)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-014-9564-6", 
    "link": "http://arxiv.org/pdf/1203.1633v1", 
    "title": "The Complexity of the Puzzles of Final Fantasy XIII-2", 
    "arxiv-id": "1203.1633v1", 
    "author": "Nathaniel Johnston", 
    "publish": "2012-03-07T21:05:24Z", 
    "summary": "We analyze the computational complexity of solving the three \"temporal rift\"\npuzzles in the recent popular video game Final Fantasy XIII-2. We show that the\nTile Trial puzzle is NP-hard and we provide an efficient algorithm for solving\nthe Crystal Bonds puzzle. We also show that slight generalizations of the\nCrystal Bonds and Hands of Time puzzles are NP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.5121/ijcsa.2012.2107", 
    "link": "http://arxiv.org/pdf/1203.1792v1", 
    "title": "Calculation of the minimum computational complexity based on information   entropy", 
    "arxiv-id": "1203.1792v1", 
    "author": "Xue Wu", 
    "publish": "2012-03-08T13:26:14Z", 
    "summary": "In order to find out the limiting speed of solving a specific problem using\ncomputer, this essay provides a method based on information entropy. The\nrelationship between the minimum computational complexity and information\nentropy change is illustrated. A few examples are served as evidence of such\nconnection. Meanwhile some basic rules of modeling problems are established.\nFinally, the nature of solving problems with computer programs is disclosed to\nsupport this theory and a redefinition of information entropy in this filed is\nproposed. This will develop a new field of science."
},{
    "category": "cs.CC", 
    "doi": "10.5121/ijcsa.2012.2107", 
    "link": "http://arxiv.org/pdf/1203.2168v1", 
    "title": "Relativized Propositional Calculus", 
    "arxiv-id": "1203.2168v1", 
    "author": "Stephen Cook", 
    "publish": "2012-03-09T20:20:06Z", 
    "summary": "Proof systems for the Relativized Propositional Calculus are defined and\ncompared."
},{
    "category": "cs.CC", 
    "doi": "10.5121/ijcsa.2012.2107", 
    "link": "http://arxiv.org/pdf/1203.3249v1", 
    "title": "Revisiting the Complexity of And/Or Graph Solution", 
    "arxiv-id": "1203.3249v1", 
    "author": "U\u00e9verton dos Santos Souza", 
    "publish": "2012-03-15T01:16:32Z", 
    "summary": "This paper presents a study on two data structures that have been used to\nmodel several problems in computer science: and/or graphs and x-y graphs. An\nand/or graph is an acyclic digraph containing a source, such that every vertex\nv has a label f(v) \\in {and,or} and edges represent dependency relations\nbetween vertices: a vertex labeled and depends on all of its out-neighbors,\nwhile a vertex labeled or depends on only one of its out-neighbors. X-y graphs\nare defined as a natural generalization of and/or graphs: every vertex vi of an\nx-y graph has a label xi-yi to mean that vi depends on xi of its yi\nout-neighbors. We analyze the complexity of the optimization problems\nMin-and/or and Min-x-y, which consist of finding solution subgraphs of optimal\nweight for and/or and x-y graphs, respectively. Motivated by the large\napplicability as well as the hardness of Min-and/or and Min-x-y, we study new\ncomplexity aspects of such problems, both from a classical and a parameterized\npoint of view. We prove that Min-and/or remains NP-hard even for a very\nrestricted family of and/or graphs where edges have weight one and or-vertices\nhave out-degree at most two (apart from other property related to some\nin-degrees), and that deciding whether there is a solution subtree with weight\nexactly k of a given x-y tree is also NP-hard. We also show that: (i) the\nparameterized problem Min-and/or(k, r), which asks whether there is a solution\nsubgraph of weight at most k where every or-vertex has at most r out-edges with\nthe same weight, is FPT; (ii) the parameterized problem Min-and/or0(k), whose\ndomain includes and/or graphs allowing zero-weight edges, is W[2]-hard; (iii)\nthe parameterized problem Min-x-y(k) is W[1]-hard."
},{
    "category": "cs.CC", 
    "doi": "10.5121/ijcsa.2012.2107", 
    "link": "http://arxiv.org/pdf/1203.3674v1", 
    "title": "Space-Bounded Kolmogorov Extractors", 
    "arxiv-id": "1203.3674v1", 
    "author": "Daniil Musatov", 
    "publish": "2012-03-16T11:41:35Z", 
    "summary": "An extractor is a function that receives some randomness and either\n\"improves\" it or produces \"new\" randomness. There are statistical and\nalgorithmical specifications of this notion. We study an algorithmical one\ncalled Kolmogorov extractors and modify it to resource-bounded version of\nKolmogorov complexity. Following Zimand we prove the existence of such objects\nwith certain parameters. The utilized technique is \"naive\" derandomization: we\nreplace random constructions employed by Zimand by pseudo-random ones obtained\nby Nisan-Wigderson generator."
},{
    "category": "cs.CC", 
    "doi": "10.5121/ijcsa.2012.2107", 
    "link": "http://arxiv.org/pdf/1203.4063v1", 
    "title": "Homomorphic Hashing for Sparse Coefficient Extraction", 
    "arxiv-id": "1203.4063v1", 
    "author": "Jesper Nederlof", 
    "publish": "2012-03-19T09:30:28Z", 
    "summary": "We study classes of Dynamic Programming (DP) algorithms which, due to their\nalgebraic definitions, are closely related to coefficient extraction methods.\nDP algorithms can easily be modified to exploit sparseness in the DP table\nthrough memorization. Coefficient extraction techniques on the other hand are\nboth space-efficient and parallelisable, but no tools have been available to\nexploit sparseness.\n  We investigate the systematic use of homomorphic hash functions to combine\nthe best of these methods and obtain improved space-efficient algorithms for\nproblems including LINEAR SAT, SET PARTITION, and SUBSET SUM. Our algorithms\nrun in time proportional to the number of nonzero entries of the last segment\nof the DP table, which presents a strict improvement over sparse DP. The last\nproperty also gives an improved algorithm for CNF SAT with sparse projections."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-38236-9_16", 
    "link": "http://arxiv.org/pdf/1203.4667v2", 
    "title": "Turing machines can be efficiently simulated by the General Purpose   Analog Computer", 
    "arxiv-id": "1203.4667v2", 
    "author": "Daniel S. Gra\u00e7a", 
    "publish": "2012-03-21T07:48:23Z", 
    "summary": "The Church-Turing thesis states that any sufficiently powerful computational\nmodel which captures the notion of algorithm is computationally equivalent to\nthe Turing machine. This equivalence usually holds both at a computability\nlevel and at a computational complexity level modulo polynomial reductions.\nHowever, the situation is less clear in what concerns models of computation\nusing real numbers, and no analog of the Church-Turing thesis exists for this\ncase. Recently it was shown that some models of computation with real numbers\nwere equivalent from a computability perspective. In particular it was shown\nthat Shannon's General Purpose Analog Computer (GPAC) is equivalent to\nComputable Analysis. However, little is known about what happens at a\ncomputational complexity level. In this paper we shed some light on the\nconnections between this two models, from a computational complexity level, by\nshowing that, modulo polynomial reductions, computations of Turing machines can\nbe simulated by GPACs, without the need of using more (space) resources than\nthose used in the original Turing computation, as long as we are talking about\nbounded computations. In other words, computations done by the GPAC are as\nspace-efficient as computations done in the context of Computable Analysis."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-38236-9_16", 
    "link": "http://arxiv.org/pdf/1203.6020v2", 
    "title": "How to solve kSAT in polynomial time", 
    "arxiv-id": "1203.6020v2", 
    "author": "Algirdas Antano Maknickas", 
    "publish": "2012-03-23T15:37:22Z", 
    "summary": "With using of multi-nary logic analytic formulas proposition that \"kSAT is in\nP and could be solved in $O(n^{3.5})$\" was proved"
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-38236-9_16", 
    "link": "http://arxiv.org/pdf/1203.6878v1", 
    "title": "Complexity Information Flow in a Multi-threaded Imperative Language", 
    "arxiv-id": "1203.6878v1", 
    "author": "Romain P\u00e9choux", 
    "publish": "2012-03-30T18:13:25Z", 
    "summary": "We propose a type system to analyze the time consumed by multi-threaded\nimperative programs with a shared global memory, which delineates a class of\nsafe multi-threaded programs. We demonstrate that a safe multi-threaded program\nruns in polynomial time if (i) it is strongly terminating wrt a\nnon-deterministic scheduling policy or (ii) it terminates wrt a deterministic\nand quiet scheduling policy. As a consequence, we also characterize the set of\npolynomial time functions. The type system presented is based on the\nfundamental notion of data tiering, which is central in implicit computational\ncomplexity. It regulates the information flow in a computation. This aspect is\ninteresting in that the type system bears a resemblance to typed based\ninformation flow analysis and notions of non-interference. As far as we know,\nthis is the first characterization by a type system of polynomial time\nmulti-threaded programs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-38236-9_16", 
    "link": "http://arxiv.org/pdf/1205.0314v1", 
    "title": "Analysis of Boolean Functions", 
    "arxiv-id": "1205.0314v1", 
    "author": "Li-Yang Tan", 
    "publish": "2012-05-02T03:51:56Z", 
    "summary": "Scribe notes from the 2012 Barbados Workshop on Computational Complexity. A\nseries of lectures on Analysis of Boolean Functions by Ryan O'Donnell, with a\nguest lecture by Per Austrin."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.0606v3", 
    "title": "Tight Bounds for Low Dimensional Star Stencils in the Parallel External   Memory Model", 
    "arxiv-id": "1205.0606v3", 
    "author": "Riko Jacob", 
    "publish": "2012-05-03T03:27:41Z", 
    "summary": "Stencil computations on low dimensional grids are kernels of many scientific\napplications including finite difference methods used to solve partial\ndifferential equations. On typical modern computer architectures, such stencil\ncomputations are limited by the performance of the memory subsystem, namely by\nthe bandwidth between main memory and the cache. This work considers the\ncomputation of star stencils, like the 5-point and 7-point stencil, in the\nexternal memory model and parallel external memory model and analyses the\nconstant of the leading term of the non-compulsory I/Os. While optimizing\nstencil computations is an active field of research, there has been a\nsignificant gap between the lower bounds and the performance of the algorithms\nso far. In two dimensions, this work provides matching constants for lower and\nupper bounds closing a multiplicative gap of 4. In three dimensions, the bounds\nmatch up to a factor of $\\sqrt{2}$ improving the known results by a factor of\n$2 \\sqrt{3}\\sqrt{B}$, where $B$ is the block (cache line) size of the external\nmemory model. For dimensions $d\\geq 4$, the lower bound is improved between a\nfactor of $4$ and $6$. For arbitrary dimension~$d$, the first analysis of the\nconstant of the leading term of the non-compulsory I/Os is presented. For\n$d\\geq 3$ the lower and upper bound match up to a factor of\n$\\sqrt[d-1]{d!}\\approx \\frac{d}{e}$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.0903v1", 
    "title": "A note on a problem in communication complexity", 
    "arxiv-id": "1205.0903v1", 
    "author": "Henning Wunderlich", 
    "publish": "2012-05-04T10:15:03Z", 
    "summary": "In this note, we prove a version of Tarui's Theorem in communication\ncomplexity, namely $PH^{cc} \\subseteq BP\\cdot PP^{cc}$. Consequently, every\nmeasure for $PP^{cc}$ leads to a measure for $PH^{cc}$, subsuming a result of\nLinial and Shraibman that problems with high mc-rigidity lie outside the\npolynomial hierarchy. By slightly changing the definition of mc-rigidity\n(arbitrary instead of uniform distribution), it is then evident that the class\n$M^{cc}$ of problems with low mc-rigidity equals $BP\\cdot PP^{cc}$. As $BP\\cdot\nPP^{cc} \\subseteq PSPACE^{cc}$, this rules out the possibility, that had been\nleft open, that even polynomial space is contained in $M^{cc}$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.1015v3", 
    "title": "A Wronskian Approach to the real \u03c4-conjecture", 
    "arxiv-id": "1205.1015v3", 
    "author": "S\u00e9bastien Tavenas", 
    "publish": "2012-05-04T17:40:44Z", 
    "summary": "According to the real \\tau-conjecture, the number of real roots of a sum of\nproducts of sparse polynomials should be polynomially bounded in the size of\nsuch an expression. It is known that this conjecture implies a superpolynomial\nlower bound on the arithmetic circuit complexity of the permanent.\n  In this paper, we use the Wronksian determinant to give an upper bound on the\nnumber of real roots of sums of products of sparse polynomials. The proof\ntechnique is quite versatile; it can in particular be applied to some sparse\ngeometric problems that do not originate from arithmetic circuit complexity.\nThe paper should therefore be of interest to researchers from these two\ncommunities (complexity theory and sparse polynomial systems)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.2934v1", 
    "title": "Inapproximability After Uniqueness Phase Transition in Two-Spin Systems", 
    "arxiv-id": "1205.2934v1", 
    "author": "Pinyan Lu", 
    "publish": "2012-05-14T03:10:28Z", 
    "summary": "A two-state spin system is specified by a 2 x 2 matrix\n  A = {A_{0,0} A_{0,1}, A_{1,0} A_{1,1}} = {\\beta 1, 1 \\gamma} where \\beta,\n\\gamma \\ge 0. Given an input graph G=(V,E), the partition function Z_A(G) of a\nsystem is defined as\n  Z_A(G) = \\sum_{\\sigma: V -> {0,1}} \\prod_{(u,v) \\in E} A_{\\sigma(u),\n\\sigma(v)}\n  We prove inapproximability results for the partition function in the region\nspecified by the non-uniqueness condition from phase transition for the Gibbs\nmeasure. More specifically, assuming NP \\ne RP, for any fixed \\beta, \\gamma in\nthe unit square, there is no randomized polynomial-time algorithm that\napproximates Z_A(G) for d-regular graphs G with relative error \\epsilon =\n10^{-4}, if d = \\Omega(\\Delta(\\beta,\\gamma)), where \\Delta(\\beta,\\gamma) >\n1/(1-\\beta\\gamma) is the uniqueness threshold. Up to a constant factor, this\nhardness result confirms the conjecture that the uniqueness phase transition\ncoincides with the transition from computational tractability to intractability\nfor Z_A(G). We also show a matching inapproximability result for a region of\nparameters \\beta, \\gamma outside the unit square, and all our results\ngeneralize to partition functions with an external field."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.3534v1", 
    "title": "DNF Sparsification and a Faster Deterministic Counting Algorithm", 
    "arxiv-id": "1205.3534v1", 
    "author": "Omer Reingold", 
    "publish": "2012-05-16T00:36:34Z", 
    "summary": "Given a DNF formula on n variables, the two natural size measures are the\nnumber of terms or size s(f), and the maximum width of a term w(f). It is\nfolklore that short DNF formulas can be made narrow. We prove a converse,\nshowing that narrow formulas can be sparsified. More precisely, any width w DNF\nirrespective of its size can be $\\epsilon$-approximated by a width $w$ DNF with\nat most $(w\\log(1/\\epsilon))^{O(w)}$ terms.\n  We combine our sparsification result with the work of Luby and Velikovic to\ngive a faster deterministic algorithm for approximately counting the number of\nsatisfying solutions to a DNF. Given a formula on n variables with poly(n)\nterms, we give a deterministic $n^{\\tilde{O}(\\log \\log(n))}$ time algorithm\nthat computes an additive $\\epsilon$ approximation to the fraction of\nsatisfying assignments of f for $\\epsilon = 1/\\poly(\\log n)$. The previous best\nresult due to Luby and Velickovic from nearly two decades ago had a run-time of\n$n^{\\exp(O(\\sqrt{\\log \\log n}))}$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.3655v5", 
    "title": "P versus UP", 
    "arxiv-id": "1205.3655v5", 
    "author": "Asia Furones", 
    "publish": "2012-05-16T12:26:51Z", 
    "summary": "Admin note: withdrawn by arXiv admin because of the use of a pseudonym, in\nviolation of arXiv policy."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.3813v2", 
    "title": "An NP-Complete Problem in Grid Coloring", 
    "arxiv-id": "1205.3813v2", 
    "author": "Kevin Lawler", 
    "publish": "2012-05-16T21:23:47Z", 
    "summary": "A c-coloring of G(n,m)=n x m is a mapping of G(n,m) into {1,...,c} such that\nno four corners forming a rectangle have the same color. In 2009 a challenge\nwas proposed via the internet to find a 4-coloring of G(17,17). This attracted\nconsiderable attention from the popular mathematics community. A coloring was\nproduced; however, finding it proved to be difficult. The question arises: is\nthe problem of grid coloring is difficult in general? We present three results\nthat support this conjecture, (1) an NP completeness result, (2) a lower bound\non Tree-resolution, (3) a lower bound on Tree-CP proofs. Note that items (2)\nand (3) yield statements from Ramsey Theory which are of size polynomial in\ntheir parameters and require exponential size in various proof systems."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.4124v1", 
    "title": "The permanent, graph gadgets and counting solutions for certain types of   planar formulas", 
    "arxiv-id": "1205.4124v1", 
    "author": "Christian Schridde", 
    "publish": "2012-05-18T10:03:17Z", 
    "summary": "In this paper, we build on the idea of Valiant \\cite{Val79a} and\nBen-Dor/Halevi \\cite{Ben93}, that is, to count the number of satisfying\nsolutions of a boolean formula via computing the permanent of a specially\nconstructed matrix. We show that the Desnanot-Jacobi identity ($\\dji$) prevents\nValiant's original approach to achieve a parsimonious reduction to the\npermanent over a field of characteristic two. As the next step, since the\ncomputation of the permanent is $#\\classP$-complete, we make use of the\nequality of the permanent and the number of perfect matchings in an unweighted\ngraph's bipartite double cover. Whenever this bipartite double cover (BDC) is\nplanar, the number of perfect matchings can be counted in polynomial time using\nKasteleyn's algorithm \\cite{Kas67}. To enforce planarity of the BDC, we replace\nValiant's original gadgets with new gadgets and describe what properties these\ngadgets must have. We show that the property of \\textit{circular planarity}\nplays a crucial role to find the correct gadgets for a counting problem. To\ncircumvent the $\\dji$-barrier, we switch over to fields\n$\\mathbb{Z}/p\\mathbb{Z}$, for a prime $p > 2$.\n  With this approach we are able to count the number of solutions for\n$\\forestdreisat$ formulas in randomized polynomial time. Finally, we present a\nconjecture that states which kind of generalized gadgets can not be found,\nsince otherwise one could prove $\\classRP = \\classNP$. The conjecture\nestablishes a relationship between the determinants of the minors of a graph\n$\\grG$'s adjacency matrix and the \\textit{circular planar} structure of\n$\\grG$'s BDC regarding a given set of nodes."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.4821v1", 
    "title": "Translating the Cantor set by a random", 
    "arxiv-id": "1205.4821v1", 
    "author": "Jason Teutsch", 
    "publish": "2012-05-22T07:12:49Z", 
    "summary": "We determine the constructive dimension of points in random translates of the\nCantor set. The Cantor set \"cancels randomness\" in the sense that some of its\nmembers, when added to Martin-Lof random reals, identify a point with lower\nconstructive dimension than the random itself. In particular, we find the\nHausdorff dimension of the set of points in a Cantor set translate with a given\nconstructive dimension."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1205.6658v3", 
    "title": "Solving satisfiability by statistical estimation", 
    "arxiv-id": "1205.6658v3", 
    "author": "Michel Feldmann", 
    "publish": "2012-05-30T13:06:28Z", 
    "summary": "We propose to solve any algorithm on discrete variables by a technique of\nstatistical estimation using deterministic convex analysis. In this framework,\nthe variables are represented by their probability and the distinction between\nthe complexity classes vanishes. The method is illustrated by solving the 3-SAT\nproblem in polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1206.0206v1", 
    "title": "Streaming algorithms for recognizing nearly well-parenthesized   expressions", 
    "arxiv-id": "1206.0206v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2012-06-01T14:49:42Z", 
    "summary": "We study the streaming complexity of the membership problem of 1-turn-Dyck2\nand Dyck2 when there are a few errors in the input string.\n  1-turn-Dyck2 with errors: We prove that there exists a randomized one-pass\nalgorithm that given x checks whether there exists a string x' in 1-turn-Dyck2\nsuch that x is obtained by flipping at most $k$ locations of x' using:\n  - O(k log n) space, O(k log n) randomness, and poly(k log n) time per item\nand with error at most 1/poly(n). - O(k^{1+epsilon} + log n) space for every 0\n<= epsilon <= 1, O(log n) randomness, O(polylog(n) + poly(k)) time per item,\nwith error at most 1/8.\n  Here, we also prove that any randomized one-pass algorithm that makes error\nat most k/n requires at least Omega(k log(n/k)) space to accept strings which\nare exactly k-away from strings in 1-turn-Dyck2 and to reject strings which are\nexactly (k+2)-away from strings in 1-turn-Dyck2. Since 1-turn-Dyck2 and the\nHamming Distance problem are closely related we also obtain new upper and lower\nbounds for this problem.\n  Dyck2 with errors: We prove that there exists a randomized one-pass algorithm\nthat given x checks whether there exists a string x' in Dyck2 such that x is\nobtained from x' by changing (in some restricted manner) at most k positions\nusing:\n  - O(k log n + sqrt(n log n)) space, O(k log n) randomness, poly(k log n) time\nper element and with error at most 1/poly(n). - O(k^(1+epsilon)+ sqrt(n log n))\nspace for every 0 <= epsilon <= 1, O(log n) randomness, O(polylog(n) + poly(k))\ntime per element, with error at most 1/8."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1206.2436v2", 
    "title": "A Proof Checking View of Parameterized Complexity", 
    "arxiv-id": "1206.2436v2", 
    "author": "Luke Mathieson", 
    "publish": "2012-06-12T04:12:14Z", 
    "summary": "The PCP Theorem is one of the most stunning results in computational\ncomplexity theory, a culmination of a series of results regarding proof\nchecking it exposes some deep structure of computational problems. As a\nsurprising side-effect, it also gives strong non-approximability results. In\nthis paper we initiate the study of proof checking within the scope of\nParameterized Complexity. In particular we adapt and extend the PCP[n log log\nn, n log log n] result of Feige et al. to several parameterized classes, and\ndiscuss some corollaries."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1206.2497v1", 
    "title": "Improved Inapproximability for TSP", 
    "arxiv-id": "1206.2497v1", 
    "author": "Michael Lampis", 
    "publish": "2012-06-12T11:38:32Z", 
    "summary": "The Traveling Salesman Problem is one of the most studied problems in\ncomputational complexity and its approximability has been a long standing open\nquestion. Currently, the best known inapproximability threshold known is\n220/219 due to Papadimitriou and Vempala. Here, using an essentially different\nconstruction and also relying on the work of Berman and Karpinski on bounded\noccurrence CSPs, we give an alternative and simpler inapproximability proof\nwhich improves the bound to 185/184."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1206.2893v1", 
    "title": "Decomposition of Kolmogorov Complexity And Link To Geometry", 
    "arxiv-id": "1206.2893v1", 
    "author": "Dara O Shayda", 
    "publish": "2012-06-13T18:49:20Z", 
    "summary": "A link between Kolmogorov Complexity and geometry is uncovered. A similar\nconcept of projection and vector decomposition is described for Kolmogorov\nComplexity. By using a simple approximation to the Kolmogorov Complexity, coded\nin Mathematica, the derived formulas are tested and used to study the geometry\nof Light Cone."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1206.3408v1", 
    "title": "Hardness of Vertex Deletion and Project Scheduling", 
    "arxiv-id": "1206.3408v1", 
    "author": "Ola Svensson", 
    "publish": "2012-06-15T09:23:35Z", 
    "summary": "Assuming the Unique Games Conjecture, we show strong inapproximability\nresults for two natural vertex deletion problems on directed graphs: for any\ninteger $k\\geq 2$ and arbitrary small $\\epsilon > 0$, the Feedback Vertex Set\nproblem and the DAG Vertex Deletion problem are inapproximable within a factor\n$k-\\epsilon$ even on graphs where the vertices can be almost partitioned into\n$k$ solutions. This gives a more structured and therefore stronger UGC-based\nhardness result for the Feedback Vertex Set problem that is also simpler\n(albeit using the \"It Ain't Over Till It's Over\" theorem) than the previous\nhardness result.\n  In comparison to the classical Feedback Vertex Set problem, the DAG Vertex\nDeletion problem has received little attention and, although we think it is a\nnatural and interesting problem, the main motivation for our inapproximability\nresult stems from its relationship with the classical Discrete Time-Cost\nTradeoff Problem. More specifically, our results imply that the deadline\nversion is NP-hard to approximate within any constant assuming the Unique Games\nConjecture. This explains the difficulty in obtaining good approximation\nalgorithms for that problem and further motivates previous alternative\napproaches such as bicriteria approximations."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1206.5501v2", 
    "title": "On bilinear algorithms for multiplication in quaternion algebras", 
    "arxiv-id": "1206.5501v2", 
    "author": "Vladimir Lysikov", 
    "publish": "2012-06-24T14:22:45Z", 
    "summary": "We show that the bilinear complexity of multiplication in a non-split\nquaternion algebra over a field of characteristic distinct from 2 is 8. This\nquestion is motivated by the problem of characterising algebras of almost\nminimal rank studied by Blaeser and de Voltaire in [1].\n  This paper is a translation of a report submitted by the author to the XI\ninternational seminar \"Discrete mathematics and applications\" (in Russian)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-40104-6_36", 
    "link": "http://arxiv.org/pdf/1208.0954v37", 
    "title": "P = NP", 
    "arxiv-id": "1208.0954v37", 
    "author": "Sergey V. Yakhontov", 
    "publish": "2012-08-04T19:45:03Z", 
    "summary": "The present work proves that P=NP. The proof, presented in this work, is a\nconstructive one: the program of a polynomial time deterministic multi-tape\nTuring machine M_ExistsAcceptingPath, that determines if there exists an\naccepting computational path of a polynomial time non-deterministic single-tape\nTuring machine M_NP, is constructed (machine M_ExistsAcceptingPath is different\nfor each Turing machine M_NP). Machine M_ExistsAcceptingPath is based on\nreduction to problem LP (linear programming) instead of reduction to problem\n3-CNF-SAT which is commonly used. In more detail, machine M_AcceptingPath uses\na reduction of the initial string problem to another string problem TCPE\n(defined in the paper) that is NP-complete and decidable in polynomial time.\nThe time complexity of machine M_ExistsAcceptingPath is O(t(n)^{272}) wherein\nt(n) is an upper bound of the time complexity of machine M_NP."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.006", 
    "link": "http://arxiv.org/pdf/1208.1783v3", 
    "title": "The complexity of approximating conservative counting CSPs", 
    "arxiv-id": "1208.1783v3", 
    "author": "David Richerby", 
    "publish": "2012-08-08T21:07:20Z", 
    "summary": "We study the complexity of approximately solving the weighted counting\nconstraint satisfaction problem #CSP(F). In the conservative case, where F\ncontains all unary functions, there is a classification known for the case in\nwhich the domain of functions in F is Boolean. In this paper, we give a\nclassification for the more general problem where functions in F have an\narbitrary finite domain. We define the notions of weak log-modularity and weak\nlog-supermodularity. We show that if F is weakly log-modular, then #CSP(F)is in\nFP. Otherwise, it is at least as difficult to approximate as #BIS, the problem\nof counting independent sets in bipartite graphs. #BIS is complete with respect\nto approximation-preserving reductions for a logically-defined complexity class\n#RHPi1, and is believed to be intractable. We further sub-divide the #BIS-hard\ncase. If F is weakly log-supermodular, then we show that #CSP(F) is as easy as\na (Boolean) log-supermodular weighted #CSP. Otherwise, we show that it is\nNP-hard to approximate. Finally, we give a full trichotomy for the arity-2\ncase, where #CSP(F) is in FP, or is #BIS-equivalent, or is equivalent in\ndifficulty to #SAT, the problem of approximately counting the satisfying\nassignments of a Boolean formula in conjunctive normal form. We also discuss\nthe algorithmic aspects of our classification."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.006", 
    "link": "http://arxiv.org/pdf/1208.2217v1", 
    "title": "Space-Efficient Circuit Evaluation", 
    "arxiv-id": "1208.2217v1", 
    "author": "Dmytro Taranovsky", 
    "publish": "2012-08-10T17:02:20Z", 
    "summary": "We prove that uniform circuits of size n can be evaluated in space O(n/log\nn). Thus, Space(O(n)) is not in uniform Size(o(n*log n)). For uniformity, we\nonly require that the circuit is O(n/log n)-Space uniform. We also generalize\nthe construction to prove that a machine with O(n^delta) (delta<1) internal\nstorage and O(2^n^delta) length single-bit-access read-write RAM that does only\nO(n) RAM reads (1 bit per read) can be simulated in space O(n * log log n / log\nn)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.006", 
    "link": "http://arxiv.org/pdf/1208.2559v5", 
    "title": "Revisiting the enumeration of all models of a Boolean 2-CNF", 
    "arxiv-id": "1208.2559v5", 
    "author": "Marcel Wild", 
    "publish": "2012-08-13T11:54:35Z", 
    "summary": "An O(Nn^2 + n^2) time algorithm to enumerate all N models of a Boolean 2-CNF\nwith n variables is presented. Using don't care symbols the models are output\nin clusters rather than one by one. Computer experiments confirm the high\nefficiency of the method."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.006", 
    "link": "http://arxiv.org/pdf/1208.2561v1", 
    "title": "The Relative Exponential Time Complexity of Approximate Counting   Satisfying Assignments", 
    "arxiv-id": "1208.2561v1", 
    "author": "Patrick Traxler", 
    "publish": "2012-08-13T12:08:11Z", 
    "summary": "We study the exponential time complexity of approximate counting satisfying\nassignments of CNFs. We reduce the problem to deciding satisfiability of a CNF.\nOur reduction preserves the number of variables of the input formula and thus\nalso preserves the exponential complexity of approximate counting.\n  Our algorithm is also similar to an algorithm which works particular well in\npractice for which however no approximation guarantee was known. Towards an\nanalysis of our reduction we provide a new inequality similar to the\nBonami-Beckner hypercontractive inequality."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.006", 
    "link": "http://arxiv.org/pdf/1208.2721v3", 
    "title": "The Complexity of the Comparator Circuit Value Problem", 
    "arxiv-id": "1208.2721v3", 
    "author": "Dai Tri Man Le", 
    "publish": "2012-08-13T22:24:45Z", 
    "summary": "In 1990 Subramanian defined the complexity class CC as the set of problems\nlog-space reducible to the comparator circuit value problem (CCV). He and Mayr\nshowed that NL \\subseteq CC \\subseteq P, and proved that in addition to CCV\nseveral other problems are complete for CC, including the stable marriage\nproblem, and finding the lexicographically first maximal matching in a\nbipartite graph. We are interested in CC because we conjecture that it is\nincomparable with the parallel class NC which also satisfies NL \\subseteq NC\n\\subseteq P, and note that this conjecture implies that none of the CC-complete\nproblems has an efficient polylog time parallel algorithm. We provide evidence\nfor our conjecture by giving oracle settings in which relativized CC and\nrelativized NC are incomparable.\n  We give several alternative definitions of CC, including (among others) the\nclass of problems computed by uniform polynomial-size families of comparator\ncircuits supplied with copies of the input and its negation, the class of\nproblems AC^0-reducible to CCV, and the class of problems computed by uniform\nAC^0 circuits with CCV gates. We also give a machine model for CC, which\ncorresponds to its characterization as log-space uniform polynomial-size\nfamilies of comparator circuits. These various characterizations show that CC\nis a robust class. The main technical tool we employ is universal comparator\ncircuits.\n  Other results include a simpler proof of NL \\subseteq CC, and an explanation\nof the relation between the Gale-Shapley algorithm and Subramanian's algorithm\nfor stable marriage.\n  This paper continues the previous work of Cook, L\\^e and Ye which focused on\nCook-Nguyen style uniform proof complexity, answering several open questions\nraised in that paper."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.90.3", 
    "link": "http://arxiv.org/pdf/1208.2756v1", 
    "title": "On Derivatives and Subpattern Orders of Countable Subshifts", 
    "arxiv-id": "1208.2756v1", 
    "author": "Ilkka T\u00f6rm\u00e4", 
    "publish": "2012-08-14T01:54:35Z", 
    "summary": "We study the computational and structural aspects of countable\ntwo-dimensional SFTs and other subshifts. Our main focus is on the topological\nderivatives and subpattern posets of these objects, and our main results are\nconstructions of two-dimensional countable subshifts with interesting\nproperties. We present an SFT whose iterated derivatives are maximally complex\nfrom the computational point of view, a sofic shift whose subpattern poset\ncontains an infinite descending chain, a family of SFTs whose finite subpattern\nposets contain arbitrary finite posets, and a natural example of an SFT with\ninfinite Cantor-Bendixon rank."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.90.3", 
    "link": "http://arxiv.org/pdf/1208.2955v7", 
    "title": "Enumerable Distributions, Randomness, Dependence", 
    "arxiv-id": "1208.2955v7", 
    "author": "Leonid A. Levin", 
    "publish": "2012-08-14T19:45:14Z", 
    "summary": "Kolmogorov-Martin-Lof Randomness concept is extended from computable to\nenumerable distributions. This allows definitions of various other properties,\nsuch as mutual information in infinite sequences. Enumerable distributions (as\nwell as distributions faced in some finite multi-party settings) are\nsemimeasures; handling those requires some amount of care."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1208.4987v3", 
    "title": "Approximating the partition function of planar two-state spin systems", 
    "arxiv-id": "1208.4987v3", 
    "author": "Colin McQuillan", 
    "publish": "2012-08-24T14:19:10Z", 
    "summary": "We consider the problem of approximating the partition function of the\nhard-core model on planar graphs of degree at most 4. We show that when the\nactivity lambda is sufficiently large, there is no fully polynomial randomised\napproximation scheme for evaluating the partition function unless NP=RP. The\nresult extends to a nearby region of the parameter space in a more general\ntwo-state spin system with three parameters. We also give a polynomial-time\nrandomised approximation scheme for the logarithm of the partition function."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.0263v3", 
    "title": "A strong direct product theorem in terms of the smooth rectangle bound", 
    "arxiv-id": "1209.0263v3", 
    "author": "Penghui Yao", 
    "publish": "2012-09-03T08:02:29Z", 
    "summary": "A strong direct product theorem states that, in order to solve k instances of\na problem, if we provide less than k times the resource required to compute one\ninstance, then the probability of overall success is exponentially small in k.\nIn this paper, we consider the model of two-way public-coin communication\ncomplexity and show a strong direct product theorem for all relations in terms\nof the smooth rectangle bound, introduced by Jain and Klauck as a generic lower\nbound method in this model. Our result therefore uniformly implies a strong\ndirect product theorem for all relations for which an (asymptotically) optimal\nlower bound can be provided using the smooth rectangle bound, for example Inner\nProduct, Greater-Than, Set-Disjointness, Gap-Hamming Distance etc. Our result\nalso implies near optimal direct product results for several important\nfunctions and relations used to show exponential separations between classical\nand quantum communication complexity, for which near optimal lower bounds are\nprovided using the rectangle bound, for example by Raz [1999], Gavinsky [2008]\nand Klartag and Regev [2011]. In fact we are not aware of any relation for\nwhich it is known that the smooth rectangle bound does not provide an optimal\nlower bound. This lower bound subsumes many of the other lower bound methods,\nfor example the rectangle bound (a.k.a the corruption bound), the smooth\ndiscrepancy bound (a.k.a the \\gamma_2 bound) which in turn subsumes the\ndiscrepancy bound, the subdistribution bound and the conditional min-entropy\nbound.\n  We show our result using information theoretic arguments. A key tool we use\nis a sampling protocol due to Braverman [2012], in fact a modification of it\nused by Kerenidis, Laplante, Lerays, Roland and Xiao [2012]."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.2333v1", 
    "title": "Quasi-polynomial Hitting-set for Set-depth-Delta Formulas", 
    "arxiv-id": "1209.2333v1", 
    "author": "Nitin Saxena", 
    "publish": "2012-09-11T14:39:37Z", 
    "summary": "We call a depth-4 formula C set-depth-4 if there exists a (unknown) partition\n(X_1,...,X_d) of the variable indices [n] that the top product layer respects,\ni.e. C(x) = \\sum_{i=1}^k \\prod_{j=1}^{d} f_{i,j}(x_{X_j}), where f_{i,j} is a\nsparse polynomial in F[x_{X_j}]. Extending this definition to any depth - we\ncall a depth-Delta formula C (consisting of alternating layers of Sigma and Pi\ngates, with a Sigma-gate on top) a set-depth-Delta formula if every Pi-layer in\nC respects a (unknown) partition on the variables; if Delta is even then the\nproduct gates of the bottom-most Pi-layer are allowed to compute arbitrary\nmonomials.\n  In this work, we give a hitting-set generator for set-depth-Delta formulas\n(over any field) with running time polynomial in exp(({Delta}^2 log s)^{Delta -\n1}), where s is the size bound on the input set-depth-Delta formula. In other\nwords, we give a quasi-polynomial time blackbox polynomial identity test for\nsuch constant-depth formulas. Previously, the very special case of Delta=3\n(also known as set-multilinear depth-3 circuits) had no known sub-exponential\ntime hitting-set generator. This was declared as an open problem by Shpilka &\nYehudayoff (FnT-TCS 2010); the model being first studied by Nisan & Wigderson\n(FOCS 1995). Our work settles this question, not only for depth-3 but, up to\ndepth epsilon.log s / loglog s, for a fixed constant epsilon < 1.\n  The technique is to investigate depth-Delta formulas via depth-(Delta-1)\nformulas over a Hadamard algebra, after applying a `shift' on the variables. We\npropose a new algebraic conjecture about the low-support rank-concentration in\nthe latter formulas, and manage to prove it in the case of set-depth-Delta\nformulas."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.2408v2", 
    "title": "Quasipolynomial-time Identity Testing of Non-Commutative and Read-Once   Oblivious Algebraic Branching Programs", 
    "arxiv-id": "1209.2408v2", 
    "author": "Amir Shpilka", 
    "publish": "2012-09-11T19:52:41Z", 
    "summary": "We study the problem of obtaining deterministic black-box polynomial identity\ntesting algorithms (PIT) for algebraic branching programs (ABPs) that are\nread-once and oblivious. This class has an deterministic white-box polynomial\nidentity testing algorithm (due to Raz and Shpilka), but prior to this work\nthere was no known such black-box algorithm.\n  The main result of this work gives the first quasi-polynomial sized hitting\nsets for size S circuits from this class, when the order of the variables is\nknown. As our hitting set is of size exp(lg^2 S), this is analogous (in the\nterminology of boolean pseudorandomness) to a seed-length of lg^2 S, which is\nthe seed length of the pseudorandom generators of Nisan and\nImpagliazzo-Nisan-Wigderson for read-once oblivious boolean branching programs.\n  Our results are stronger for branching programs of bounded width, where we\ngive a hitting set of size exp(lg^2 S/lglg S), corresponding to a seed length\nof lg^2 S/lglg S. This is in stark contrast to the known results for read-once\noblivious boolean branching programs of bounded width, where no pseudorandom\ngenerator (or hitting set) with seed length o(lg^2 S) is known.\n  In follow up work, we strengthened a result of Mulmuley, and showed that\nderandomizing a particular case of the Noether Normalization Lemma is reducible\nto black-box PIT of read-once oblivious ABPs. Using the results of the present\nwork, this gives a derandomization of Noether Normalization in that case, which\nMulmuley conjectured would difficult due to its relations to problems in\nalgebraic geometry.\n  We also show that several other circuit classes can be black-box reduced to\nread-once oblivious ABPs, including set-multilinear ABPs (a generalization of\ndepth-3 set-multilinear formulas), non-commutative ABPs (generalizing\nnon-commutative formulas), and (semi-)diagonal depth-4 circuits (as introduced\nby Saxena)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.2875v1", 
    "title": "Notes on random reals", 
    "arxiv-id": "1209.2875v1", 
    "author": "Scott Weinstein", 
    "publish": "2012-09-13T12:46:58Z", 
    "summary": "The theory of random real numbers is exceedingly well-developed, and\nfascinating from many points of view. It is also quite challenging\nmathematically. The present notes are intended as no more than a gateway to the\nlarger theory. They review just the most elementary part of the theory (bearing\non Kolmogorov- and ML-randomness). We hope that the simple arguments presented\nhere will encourage the enterprising student to examine richer treatments of\nthe subject available elsewhere, notably, in Downey and Hirschfeldt (2010)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.3793v1", 
    "title": "Polynomial Path Orders: A Maximal Model", 
    "arxiv-id": "1209.3793v1", 
    "author": "Georg Moser", 
    "publish": "2012-09-17T20:38:54Z", 
    "summary": "This paper is concerned with the automated complexity analysis of term\nrewrite systems (TRSs for short) and the ramification of these in implicit\ncomputational complexity theory (ICC for short). We introduce a novel path\norder with multiset status, the polynomial path order POP*. Essentially relying\non the principle of predicative recursion as proposed by Bellantoni and Cook,\nits distinct feature is the tight control of resources on compatible TRSs: The\n(innermost) runtime complexity of compatible TRSs is polynomially bounded. We\nhave implemented the technique, as underpinned by our experimental evidence our\napproach to the automated runtime complexity analysis is not only feasible, but\ncompared to existing methods incredibly fast. As an application in the context\nof ICC we provide an order-theoretic characterisation of the polytime\ncomputable functions. To be precise, the polytime computable functions are\nexactly the functions computable by an orthogonal constructor TRS compatible\nwith POP*."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.4865v1", 
    "title": "The arithmetic complexity of tensor contractions", 
    "arxiv-id": "1209.4865v1", 
    "author": "Stefan Mengel", 
    "publish": "2012-09-21T17:19:03Z", 
    "summary": "We investigate the algebraic complexity of tensor calulus. We consider a\ngeneralization of iterated matrix product to tensors and show that the\nresulting formulas exactly capture VP, the class of polynomial families\nefficiently computable by arithmetic circuits. This gives a natural and robust\ncharacterization of this complexity class that despite its naturalness is not\nvery well understood so far."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2014.06.007", 
    "link": "http://arxiv.org/pdf/1209.5192v1", 
    "title": "Probabilistic verifiers for asymmetric debates", 
    "arxiv-id": "1209.5192v1", 
    "author": "Abuzer Yakary\u0131lmaz", 
    "publish": "2012-09-24T08:44:46Z", 
    "summary": "We examine the power of silent constant-space probabilistic verifiers that\nwatch asymmetric debates (where one side is unable to see some of the messages\nof the other) between two deterministic provers, and try to determine who is\nright. We prove that probabilistic verifiers outperform their deterministic\ncounterparts as asymmetric debate checkers. It is shown that the membership\nproblem for every language in NSPACE(s(n)) has a 2^{s(n)}-time debate where one\nprover is completely blind to the other one, for polynomially bounded space\nconstructible s(n). When partial information is allowed to be seen by the\nhandicapped prover, the class of languages debatable in 2^{s(n)} time contains\nTIME(2^{s(n)}), so a probabilistic finite automaton can solve any decision\nproblem in P with small error in polynomial time with the aid of such a debate.\nWe also compare our systems with those with a single prover, and with\ncompeting-prover interactive proof systems."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-06089-7_7", 
    "link": "http://arxiv.org/pdf/1209.5267v2", 
    "title": "The Parameterized Complexity of Domination-type Problems and Application   to Linear Codes", 
    "arxiv-id": "1209.5267v2", 
    "author": "Simon Perdrix", 
    "publish": "2012-09-24T13:41:25Z", 
    "summary": "We study the parameterized complexity of domination-type problems.\n(sigma,rho)-domination is a general and unifying framework introduced by Telle:\na set D of vertices of a graph G is (sigma,rho)-dominating if for any v in D,\n|N(v)\\cap D| in sigma and for any $v\\notin D, |N(v)\\cap D| in rho. We mainly\nshow that for any sigma and rho the problem of (sigma,rho)-domination is W[2]\nwhen parameterized by the size of the dominating set. This general statement is\noptimal in the sense that several particular instances of\n(sigma,rho)-domination are W[2]-complete (e.g. Dominating Set). We also prove\nthat (sigma,rho)-domination is W[2] for the dual parameterization, i.e. when\nparameterized by the size of the dominated set. We extend this result to a\nclass of domination-type problems which do not fall into the\n(sigma,rho)-domination framework, including Connected Dominating Set. We also\nconsider problems of coding theory which are related to domination-type\nproblems with parity constraints. In particular, we prove that the problem of\nthe minimal distance of a linear code over Fq is W[2] for both standard and\ndual parameterizations, and W[1]-hard for the dual parameterization.\n  To prove W[2]-membership of the domination-type problems we extend the\nTuring-way to parameterized complexity by introducing a new kind of non\ndeterministic Turing machine with the ability to perform `blind' transitions,\ni.e. transitions which do not depend on the content of the tapes. We prove that\nthe corresponding problem Short Blind Multi-Tape Non-Deterministic Turing\nMachine is W[2]-complete. We believe that this new machine can be used to prove\nW[2]-membership of other problems, not necessarily related to domination"
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-06089-7_7", 
    "link": "http://arxiv.org/pdf/1210.0049v1", 
    "title": "Better Pseudorandom Generators from Milder Pseudorandom Restrictions", 
    "arxiv-id": "1210.0049v1", 
    "author": "Salil Vadhan", 
    "publish": "2012-09-28T21:58:10Z", 
    "summary": "We present an iterative approach to constructing pseudorandom generators,\nbased on the repeated application of mild pseudorandom restrictions. We use\nthis template to construct pseudorandom generators for combinatorial rectangles\nand read-once CNFs and a hitting set generator for width-3 branching programs,\nall of which achieve near-optimal seed-length even in the low-error regime: We\nget seed-length O(log (n/epsilon)) for error epsilon. Previously, only\nconstructions with seed-length O(\\log^{3/2} n) or O(\\log^2 n) were known for\nthese classes with polynomially small error.\n  The (pseudo)random restrictions we use are milder than those typically used\nfor proving circuit lower bounds in that we only set a constant fraction of the\nbits at a time. While such restrictions do not simplify the functions\ndrastically, we show that they can be derandomized using small-bias spaces."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-06089-7_7", 
    "link": "http://arxiv.org/pdf/1210.2260v1", 
    "title": "Extensions of the Minimum Cost Homomorphism Problem", 
    "arxiv-id": "1210.2260v1", 
    "author": "Rustem Takhanov", 
    "publish": "2012-10-08T12:39:06Z", 
    "summary": "Assume $D$ is a finite set and $R$ is a finite set of functions from $D$ to\nthe natural numbers. An instance of the minimum $R$-cost homomorphism problem\n($MinHom_R$) is a set of variables $V$ subject to specified constraints\ntogether with a positive weight $c_{vr}$ for each combination of $v \\in V$ and\n$r \\in R$. The aim is to find a function $f:V \\rightarrow D$ such that $f$\nsatisfies all constraints and $\\sum_{v \\in V} \\sum_{r \\in R} c_{vr}r(f(v))$ is\nminimized.\n  This problem unifies well-known optimization problems such as the minimum\ncost homomorphism problem and the maximum solution problem, and this makes it a\ncomputationally interesting fragment of the valued CSP framework for\noptimization problems. We parameterize $MinHom_R\\left(\\Gamma\\right)$ by {\\em\nconstraint languages}, i.e. sets $\\Gamma$ of relations that are allowed in\nconstraints. A constraint language is called {\\em conservative} if every unary\nrelation is a member of it; such constraint languages play an important role in\nunderstanding the structure of constraint problems. The dichotomy conjecture\nfor $MinHom_R$ is the following statement: if $\\Gamma$ is a constraint\nlanguage, then $MinHom_R\\left(\\Gamma\\right)$ is either polynomial-time solvable\nor NP-complete. For $MinHom$ the dichotomy result has been recently obtained\n[Takhanov, STACS, 2010] and the goal of this paper is to expand this result to\nthe case of $MinHom_R$ with conservative constraint language. For arbitrary $R$\nthis problem is still open, but assuming certain restrictions on $R$ we prove a\ndichotomy. As a consequence of this result we obtain a dichotomy for the\nconservative maximum solution problem."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2974019", 
    "link": "http://arxiv.org/pdf/1210.2987v4", 
    "title": "The complexity of finite-valued CSPs", 
    "arxiv-id": "1210.2987v4", 
    "author": "Stanislav Zivny", 
    "publish": "2012-10-10T17:17:43Z", 
    "summary": "We study the computational complexity of exact minimisation of\nrational-valued discrete functions. Let $\\Gamma$ be a set of rational-valued\nfunctions on a fixed finite domain; such a set is called a finite-valued\nconstraint language. The valued constraint satisfaction problem,\n$\\operatorname{VCSP}(\\Gamma)$, is the problem of minimising a function given as\na sum of functions from $\\Gamma$. We establish a dichotomy theorem with respect\nto exact solvability for all finite-valued constraint languages defined on\ndomains of arbitrary finite size.\n  We show that every constraint language $\\Gamma$ either admits a binary\nsymmetric fractional polymorphism in which case the basic linear programming\nrelaxation solves any instance of $\\operatorname{VCSP}(\\Gamma)$ exactly, or\n$\\Gamma$ satisfies a simple hardness condition that allows for a\npolynomial-time reduction from Max-Cut to $\\operatorname{VCSP}(\\Gamma)$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2974019", 
    "link": "http://arxiv.org/pdf/1210.4321v2", 
    "title": "A quantum algorithm for solving the 3-SAT problem", 
    "arxiv-id": "1210.4321v2", 
    "author": "Lily Chen", 
    "publish": "2012-10-16T09:16:13Z", 
    "summary": "The method in this paper is wrong."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2974019", 
    "link": "http://arxiv.org/pdf/1210.4408v1", 
    "title": "On efficient constructions of short lists containing mostly Ramsey   graphs", 
    "arxiv-id": "1210.4408v1", 
    "author": "Marius Zimand", 
    "publish": "2012-10-16T13:48:53Z", 
    "summary": "One of the earliest and best-known application of the probabilistic method is\nthe proof of existence of a 2 log n$-Ramsey graph, i.e., a graph with n nodes\nthat contains no clique or independent set of size 2 log n. The explicit\nconstruction of such a graph is a major open problem. We show that a reasonable\nhardness assumption implies that in polynomial time one can construct a list\ncontaining polylog(n) graphs such that most of them are 2 log n-Ramsey."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2974019", 
    "link": "http://arxiv.org/pdf/1210.5083v1", 
    "title": "An Improved Lower Bound of The Spark With Application", 
    "arxiv-id": "1210.5083v1", 
    "author": "Wajeb Gharibi", 
    "publish": "2012-10-18T10:29:51Z", 
    "summary": "Spark plays a great role in studying uniqueness of sparse solutions of the\nunderdetermined linear equations. In this article, we derive a new lower bound\nof spark. As an application, we obtain a new criterion for the uniqueness of\nsparse solutions of linear equations."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2974019", 
    "link": "http://arxiv.org/pdf/1210.5648v2", 
    "title": "New NP-hardness results for 3-Coloring and 2-to-1 Label Cover", 
    "arxiv-id": "1210.5648v2", 
    "author": "John Wright", 
    "publish": "2012-10-20T19:34:22Z", 
    "summary": "We show that given a 3-colorable graph, it is NP-hard to find a 3-coloring\nwith $(16/17 + \\eps)$ of the edges bichromatic. In a related result, we show\nthat given a satisfiable instance of the 2-to-1 Label Cover problem, it is\nNP-hard to find a $(23/24 + \\eps)$-satisfying assignment."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1210.7136v1", 
    "title": "Synthesis of sup-interpretations: a survey", 
    "arxiv-id": "1210.7136v1", 
    "author": "Romain P\u00e9choux", 
    "publish": "2012-10-26T13:15:42Z", 
    "summary": "In this paper, we survey the complexity of distinct methods that allow the\nprogrammer to synthesize a sup-interpretation, a function providing an upper-\nbound on the size of the output values computed by a program. It consists in a\nstatic space analysis tool without consideration of the time consumption.\nAlthough clearly related, sup-interpretation is independent from termination\nsince it only provides an upper bound on the terminating computations. First,\nwe study some undecidable properties of sup-interpretations from a theoretical\npoint of view. Next, we fix term rewriting systems as our computational model\nand we show that a sup-interpretation can be obtained through the use of a\nwell-known termination technique, the polynomial interpretations. The drawback\nis that such a method only applies to total functions (strongly normalizing\nprograms). To overcome this problem we also study sup-interpretations through\nthe notion of quasi-interpretation. Quasi-interpretations also suffer from a\ndrawback that lies in the subterm property. This property drastically restricts\nthe shape of the considered functions. Again we overcome this problem by\nintroducing a new notion of interpretations mainly based on the dependency\npairs method. We study the decidability and complexity of the\nsup-interpretation synthesis problem for all these three tools over sets of\npolynomials. Finally, we take benefit of some previous works on termination and\nruntime complexity to infer sup-interpretations."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1210.7641v1", 
    "title": "A Dichotomy Theorem for Homomorphism Polynomials", 
    "arxiv-id": "1210.7641v1", 
    "author": "Nicolas de Rugy-Altherre", 
    "publish": "2012-10-29T12:37:54Z", 
    "summary": "In the present paper we show a dichotomy theorem for the complexity of\npolynomial evaluation. We associate to each graph H a polynomial that encodes\nall graphs of a fixed size homomorphic to H. We show that this family is\ncomputable by arithmetic circuits in constant depth if H has a loop or no edge\nand that it is hard otherwise (i.e., complete for VNP, the arithmetic class\nrelated to #P). We also demonstrate the hardness over the rational field of cut\neliminator, a polynomial defined by B\\\"urgisser which is known to be neither VP\nnor VNP-complete in the field of two elements, if VP is not equal to VNP (VP is\nthe class of polynomials computable by arithmetic circuit of polynomial size)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.0665v1", 
    "title": "Hidden cliques and the certification of the restricted isometry property", 
    "arxiv-id": "1211.0665v1", 
    "author": "Anastasios Zouzias", 
    "publish": "2012-11-04T07:24:50Z", 
    "summary": "Compressed sensing is a technique for finding sparse solutions to\nunderdetermined linear systems. This technique relies on properties of the\nsensing matrix such as the restricted isometry property. Sensing matrices that\nsatisfy this property with optimal parameters are mainly obtained via\nprobabilistic arguments. Deciding whether a given matrix satisfies the\nrestricted isometry property is a non-trivial computational problem. Indeed, we\nshow in this paper that restricted isometry parameters cannot be approximated\nin polynomial time within any constant factor under the assumption that the\nhidden clique problem is hard. Moreover, on the positive side we propose an\nimprovement on the brute-force enumeration algorithm for checking the\nrestricted isometry property."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.1490v3", 
    "title": "New results on stabbing segments with a polygon", 
    "arxiv-id": "1211.1490v3", 
    "author": "Rodrigo I. Silveira", 
    "publish": "2012-11-07T09:22:51Z", 
    "summary": "We consider a natural variation of the concept of stabbing a segment by a\nsimple polygon: a segment is stabbed by a simple polygon $\\mathcal{P}$ if at\nleast one of its two endpoints is contained in $\\mathcal{P}$. A segment set $S$\nis stabbed by $\\mathcal{P}$ if every segment of $S$ is stabbed by\n$\\mathcal{P}$. We show that if $S$ is a set of pairwise disjoint segments, the\nproblem of computing the minimum perimeter polygon stabbing $S$ can be solved\nin polynomial time. We also prove that for general segments the problem is\nNP-hard. Further, an adaptation of our polynomial-time algorithm solves an open\nproblem posed by L\\\"offler and van Kreveld [Algorithmica 56(2), 236--269\n(2010)] about finding a maximum perimeter convex hull for a set of imprecise\npoints modeled as line segments."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.1636v1", 
    "title": "On the Parameterized and Approximation Hardness of Metric Dimension", 
    "arxiv-id": "1211.1636v1", 
    "author": "Andr\u00e9 Nichterlein", 
    "publish": "2012-11-07T18:50:44Z", 
    "summary": "The NP-hard Metric Dimension problem is to decide for a given graph G and a\npositive integer k whether there is a vertex subset of size at most k that\nseparates all vertex pairs in G. Herein, a vertex v separates a pair {u,w} if\nthe distance (length of a shortest path) between v and u is different from the\ndistance of v and w. We give a polynomial-time computable reduction from the\nBipartite Dominating Set problem to Metric Dimension on maximum degree three\ngraphs such that there is a one-to-one correspondence between the solution sets\nof both problems. There are two main consequences of this: First, it proves\nthat Metric Dimension on maximum degree three graphs is W[2]-complete with\nrespect to the parameter k. This answers an open question concerning the\nparameterized complexity of Metric Dimension posed by D\\'iaz et al. [ESA'12]\nand already mentioned by Lokshtanov [Dagstuhl seminar, 2009]. Additionally, it\nimplies that Metric Dimension cannot be solved in n^{o(k)} time, unless the\nassumption FPT \\neq W[1] fails. This proves that a trivial n^{O(k)} algorithm\nis probably asymptotically optimal.\n  Second, as Bipartite Dominating Set is inapproximable within o(log n), it\nfollows that Metric Dimension on maximum degree three graphs is also\ninapproximable by a factor of o(log n), unless NP=P. This strengthens the\nresult of Hauptmann et al. [JDA 2012] who proved APX-hardness on bounded-degree\ngraphs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.1958v1", 
    "title": "Approximability and proof complexity", 
    "arxiv-id": "1211.1958v1", 
    "author": "Yuan Zhou", 
    "publish": "2012-11-08T19:59:30Z", 
    "summary": "This work is concerned with the proof-complexity of certifying that\noptimization problems do \\emph{not} have good solutions. Specifically we\nconsider bounded-degree \"Sum of Squares\" (SOS) proofs, a powerful algebraic\nproof system introduced in 1999 by Grigoriev and Vorobjov. Work of Shor,\nLasserre, and Parrilo shows that this proof system is automatizable using\nsemidefinite programming (SDP), meaning that any $n$-variable degree-$d$ proof\ncan be found in time $n^{O(d)}$. Furthermore, the SDP is dual to the well-known\nLasserre SDP hierarchy, meaning that the \"$d/2$-round Lasserre value\" of an\noptimization problem is equal to the best bound provable using a degree-$d$ SOS\nproof. These ideas were exploited in a recent paper by Barak et al.\\ (STOC\n2012) which shows that the known \"hard instances\" for the Unique-Games problem\nare in fact solved close to optimally by a constant level of the Lasserre SDP\nhierarchy.\n  We continue the study of the power of SOS proofs in the context of difficult\noptimization problems. In particular, we show that the Balanced-Separator\nintegrality gap instances proposed by Devanur et al.\\ can have their optimal\nvalue certified by a degree-4 SOS proof. The key ingredient is an SOS proof of\nthe KKL Theorem. We also investigate the extent to which the Khot--Vishnoi\nMax-Cut integrality gap instances can have their optimum value certified by an\nSOS proof. We show they can be certified to within a factor .952 ($> .878$)\nusing a constant-degree proof. These investigations also raise an interesting\nmathematical question: is there a constant-degree SOS proof of the Central\nLimit Theorem?"
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.2627v3", 
    "title": "Computational Aspects of Nearly Single-Peaked Electorates", 
    "arxiv-id": "1211.2627v3", 
    "author": "Andreas Pfandler", 
    "publish": "2012-11-12T14:24:55Z", 
    "summary": "Manipulation, bribery, and control are well-studied ways of changing the\noutcome of an election. Many voting rules are, in the general case,\ncomputationally resistant to some of these manipulative actions. However when\nrestricted to single-peaked electorates, these rules suddenly become easy to\nmanipulate. Recently, Faliszewski, Hemaspaandra, and Hemaspaandra (2014)\nstudied the complexity of dishonest behavior in nearly single-peaked\nelectorates. These are electorates that are not single-peaked but close to it\naccording to some distance measure. In this paper we introduce several new\ndistance measures regarding single-peakedness. We prove that determining\nwhether a given profile is nearly single-peaked is NP-complete in many cases.\nFor one case we present a polynomial-time algorithm. In case the single-peaked\naxis is given, we show that determining the distance is always computable in\npolynomial time. Furthermore, we explore the relations between the new notions\nintroduced in this paper and existing notions from the literature."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.3439v1", 
    "title": "Optimal Hitting Sets for Combinatorial Shapes", 
    "arxiv-id": "1211.3439v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2012-11-14T21:45:31Z", 
    "summary": "We consider the problem of constructing explicit Hitting sets for\nCombinatorial Shapes, a class of statistical tests first studied by Gopalan,\nMeka, Reingold, and Zuckerman (STOC 2011). These generalize many well-studied\nclasses of tests, including symmetric functions and combinatorial rectangles.\nGeneralizing results of Linial, Luby, Saks, and Zuckerman (Combinatorica 1997)\nand Rabani and Shpilka (SICOMP 2010), we construct hitting sets for\nCombinatorial Shapes of size polynomial in the alphabet, dimension, and the\ninverse of the error parameter. This is optimal up to polynomial factors. The\nbest previous hitting sets came from the Pseudorandom Generator construction of\nGopalan et al., and in particular had size that was quasipolynomial in the\ninverse of the error parameter.\n  Our construction builds on natural variants of the constructions of Linial et\nal. and Rabani and Shpilka. In the process, we construct fractional perfect\nhash families and hitting sets for combinatorial rectangles with stronger\nguarantees. These might be of independent interest."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.3492v1", 
    "title": "On the principal impossibility to prove P=NP", 
    "arxiv-id": "1211.3492v1", 
    "author": "Natalia L. Malinina", 
    "publish": "2012-11-15T05:11:56Z", 
    "summary": "The material of the article is devoted to the most complicated and\ninteresting problem -- a problem of P = NP?. This research was presented to\nmathematical community in Hyderabad during International Congress of\nMathematicians. But there it was published in a very brief form, so this\narticle is an attempt to give those, who are interested in the problem, my\nreasoning on the theme. It is not a proof in full, because it is very difficult\nto prove something, which is not provable, but it seems that these reasoning\nwill help us to understand the problem of the combinatorial explosion more\ndeeply and to realize in full all the problems to which we are going because of\nthe combinatorial explosion. Maybe we will realize that the combinatorial\nexplosion is somehow a law, such a law, which influences the World, as Newton's\nlaw of gravitation influences the fall of each thing."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.5773v1", 
    "title": "Value Constraint and Monotone circuit", 
    "arxiv-id": "1211.5773v1", 
    "author": "Koji Kobayashi", 
    "publish": "2012-11-25T16:22:03Z", 
    "summary": "This paper talks about that monotone circuit is P-Complete.\n  Decision problem that include P-Complete is mapping that classify input with\na similar property. Therefore equivalence relation of input value is important\nfor computation. But monotone circuit cannot compute the equivalence relation\nof the value because monotone circuit can compute only monotone function.\nTherefore, I make the value constraint explicitly in the input and monotone\ncircuit can compute equivalence relation. As a result, we can compute\nP-Complete problem with monotone circuit. We can reduce implicit value\nconstraint to explicit with logarithm space. Therefore, monotone circuit is\nP-Complete."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.7161v1", 
    "title": "Unshuffling a Square is NP-Hard", 
    "arxiv-id": "1211.7161v1", 
    "author": "Michael Soltys", 
    "publish": "2012-11-30T06:14:06Z", 
    "summary": "A shuffle of two strings is formed by interleaving the characters into a new\nstring, keeping the characters of each string in order. A string is a square if\nit is a shuffle of two identical strings. There is a known polynomial time\ndynamic programming algorithm to determine if a given string z is the shuffle\nof two given strings x,y; however, it has been an open question whether there\nis a polynomial time algorithm to determine if a given string z is a square. We\nresolve this by proving that this problem is NP-complete via a many-one\nreduction from 3- Partition."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1211.7346v1", 
    "title": "Checking generalized debates with small space and randomness", 
    "arxiv-id": "1211.7346v1", 
    "author": "A. C. Cem Say", 
    "publish": "2012-11-30T19:25:03Z", 
    "summary": "We introduce a model of probabilistic debate checking, where a silent\nresource-bounded verifier reads a dialogue about the membership of the string\nin the language under consideration between a prover and a refuter. Our model\ncombines and generalizes the concepts of one-way interactive proof systems,\ngames of incomplete information, and probabilistically checkable\ncomplete-information debate systems. We consider debates of partial and zero\ninformation, where the prover is prevented from seeing some or all of the\nmessages of the refuter, as well as those of complete information. The classes\nof languages with debates checkable by verifiers operating under severe bounds\non the memory and randomness are studied.\n  We give full characterizations of versions of these classes corresponding to\nsimultaneous bounds of O(1) space and O(1) random bits, and of logarithmic\nspace and polynomial time. It turns out that constant-space verifiers, which\ncan only check complete-information debates for regular languages\ndeterministically, can check for membership in any language in P when allowed\nto use a constant number of random bits. Similar increases also occur for zero-\nand partial- information debates, from NSPACE(n) to PSPACE, and from E to\nEXPTIME, respectively. Adding logarithmic space to these constant-randomness\nverifiers does not change their power. When logspace debate checkers are\nrestricted to run in polynomial time without a bound on the number of random\nbits, the class of debatable languages equals PSPACE for all debate types. We\nalso present a result on the hardness of approximating the quantified max word\nproblem for matrices that is a corollary of this characterization."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1212.0191v3", 
    "title": "Finite and infinite basis in P and NP", 
    "arxiv-id": "1212.0191v3", 
    "author": "Koji Kobayashi", 
    "publish": "2012-12-02T07:32:43Z", 
    "summary": "This article provide new approach to solve P vs NP problem by using\ncardinality of bases function. About NP-Complete problems, we can divide to\ninfinite disjunction of P-Complete problems. These P-Complete problems are\nindependent of each other in disjunction. That is, NP-Complete problem is in\ninfinite dimension function space that bases are P-Complete. The other hand,\nany P-Complete problem have at most a finite number of P-Complete basis. The\nreason is that each P problems have at most finite number of Least fixed point\noperator. Therefore, we cannot describe NP-Complete problems in P. We can also\nprove this result from incompleteness of P."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1212.1891v3", 
    "title": "Natural Proofs Versus Derandomization", 
    "arxiv-id": "1212.1891v3", 
    "author": "Ryan Williams", 
    "publish": "2012-12-09T14:20:18Z", 
    "summary": "We study connections between Natural Proofs, derandomization, and the problem\nof proving \"weak\" circuit lower bounds such as ${\\sf NEXP} \\not\\subset {\\sf\nTC^0}$. Natural Proofs have three properties: they are constructive (an\nefficient algorithm $A$ is embedded in them), have largeness ($A$ accepts a\nlarge fraction of strings), and are useful ($A$ rejects all strings which are\ntruth tables of small circuits). Strong circuit lower bounds that are\n\"naturalizing\" would contradict present cryptographic understanding, yet the\nvast majority of known circuit lower bound proofs are naturalizing. So it is\nimperative to understand how to pursue un-Natural Proofs. Some heuristic\narguments say constructivity should be circumventable: largeness is inherent in\nmany proof techniques, and it is probably our presently weak techniques that\nyield constructivity. We prove:\n  $\\bullet$ Constructivity is unavoidable, even for $\\sf NEXP$ lower bounds.\nInformally, we prove for all \"typical\" non-uniform circuit classes ${\\cal C}$,\n${\\sf NEXP} \\not\\subset {\\cal C}$ if and only if there is a polynomial-time\nalgorithm distinguishing some function from all functions computable by ${\\cal\nC}$-circuits. Hence ${\\sf NEXP} \\not\\subset {\\cal C}$ is equivalent to\nexhibiting a constructive property useful against ${\\cal C}$.\n  $\\bullet$ There are no $\\sf P$-natural properties useful against ${\\cal C}$\nif and only if randomized exponential time can be \"derandomized\" using truth\ntables of circuits from ${\\cal C}$ as random seeds. Therefore the task of\nproving there are no $\\sf P$-natural properties is inherently a derandomization\nproblem, weaker than but implied by the existence of strong pseudorandom\nfunctions.\n  These characterizations are applied to yield several new results, including\nimproved ${\\sf ACC}^0$ lower bounds and new unconditional derandomizations."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2012.11.003", 
    "link": "http://arxiv.org/pdf/1212.2549v1", 
    "title": "Subtraction makes computing integers faster", 
    "arxiv-id": "1212.2549v1", 
    "author": "Gorav Jindal", 
    "publish": "2012-12-11T17:36:29Z", 
    "summary": "We show some facts regarding the question whether, for any number $n$, the\nlength of the shortest Addition Multiplications Chain (AMC) computing $n$ is\npolynomial in the length of the shortest division-free Straight Line Program\n(SLP) that computes $n$.\n  If the answer to this question is \"yes\", then we can show a stronger upper\nbound for $\\mathrm{PosSLP}$, the important problem which essentially captures\nthe notion of efficient computation over the reals. If the answer is \"no\", then\nthis would demonstrate how subtraction helps generating integers\nsuper-polynomially faster, given that addition and multiplication can be done\nin unit time.\n  In this paper, we show that, for almost all numbers, AMCs and SLPs need same\nasymptotic length for computation. However, for one specific form of numbers,\nSLPs are strictly more powerful than AMCs by at least one step of computation."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1212.3282v2", 
    "title": "AND and/or OR: Uniform Polynomial-Size Circuits", 
    "arxiv-id": "1212.3282v2", 
    "author": "Damien Woods", 
    "publish": "2012-12-13T19:35:12Z", 
    "summary": "We investigate the complexity of uniform OR circuits and AND circuits of\npolynomial-size and depth. As their name suggests, OR circuits have OR gates as\ntheir computation gates, as well as the usual input, output and constant (0/1)\ngates. As is the norm for Boolean circuits, our circuits have multiple sink\ngates, which implies that an OR circuit computes an OR function on some subset\nof its input variables. Determining that subset amounts to solving a number of\nreachability questions on a polynomial-size directed graph (which input gates\nare connected to the output gate?), taken from a very sparse set of graphs.\nHowever, it is not obvious whether or not this (restricted) reachability\nproblem can be solved, by say, uniform AC^0 circuits (constant depth,\npolynomial-size, AND, OR, NOT gates). This is one reason why characterizing the\npower of these simple-looking circuits in terms of uniform classes turns out to\nbe intriguing. Another is that the model itself seems particularly natural and\nworthy of study.\n  Our goal is the systematic characterization of uniform polynomial-size OR\ncircuits, and AND circuits, in terms of known uniform machine-based complexity\nclasses. In particular, we consider the languages reducible to such uniform\nfamilies of OR circuits, and AND circuits, under a variety of reduction types.\nWe give upper and lower bounds on the computational power of these language\nclasses. We find that these complexity classes are closely related to tallyNL,\nthe set of unary languages within NL, and to sets reducible to tallyNL.\nSpecifically, for a variety of types of reductions (many-one, conjunctive truth\ntable, disjunctive truth table, truth table, Turing) we give characterizations\nof languages reducible to OR circuit classes in terms of languages reducible to\ntallyNL classes. Then, some of these OR classes are shown to coincide, and some\nare proven to be distinct. We give analogous results for AND circuits. Finally,\nfor many of our OR circuit classes, and analogous AND circuit classes, we prove\nwhether or not the two classes coincide, although we leave one such inclusion\nopen."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1212.4548v2", 
    "title": "A Satisfiability Algorithm for Sparse Depth Two Threshold Circuits", 
    "arxiv-id": "1212.4548v2", 
    "author": "Stefan Schneider", 
    "publish": "2012-12-19T01:13:45Z", 
    "summary": "We give a nontrivial algorithm for the satisfiability problem for cn-wire\nthreshold circuits of depth two which is better than exhaustive search by a\nfactor 2^{sn} where s= 1/c^{O(c^2)}. We believe that this is the first\nnontrivial satisfiability algorithm for cn-wire threshold circuits of depth\ntwo. The independently interesting problem of the feasibility of sparse 0-1\ninteger linear programs is a special case. To our knowledge, our algorithm is\nthe first to achieve constant savings even for the special case of Integer\nLinear Programming. The key idea is to reduce the satisfiability problem to the\nVector Domination Problem, the problem of checking whether there are two\nvectors in a given collection of vectors such that one dominates the other\ncomponent-wise.\n  We also provide a satisfiability algorithm with constant savings for depth\ntwo circuits with symmetric gates where the total weighted fan-in is at most\ncn.\n  One of our motivations is proving strong lower bounds for TC^0 circuits,\nexploiting the connection (established by Williams) between satisfiability\nalgorithms and lower bounds. Our second motivation is to explore the connection\nbetween the expressive power of the circuits and the complexity of the\ncorresponding circuit satisfiability problem."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1212.5324v3", 
    "title": "Hypercontractive inequalities via SOS, and the Frankl--R\u00f6dl graph", 
    "arxiv-id": "1212.5324v3", 
    "author": "Yuan Zhou", 
    "publish": "2012-12-21T03:28:28Z", 
    "summary": "Our main result is a formulation and proof of the reverse hypercontractive\ninequality in the sum-of-squares (SOS) proof system. As a consequence we show\nthat for any constant $0 < \\gamma \\leq 1/4$, the SOS/Lasserre SDP hierarchy at\ndegree $4\\lceil \\frac{1}{4\\gamma}\\rceil$ certifies the statement \"the maximum\nindependent set in the Frankl--R\\\"odl graph $\\mathrm{FR}^{n}_{\\gamma}$ has\nfractional size~$o(1)$\". Here $\\mathrm{FR}^{n}_{\\gamma} = (V,E)$ is the graph\nwith $V = \\{0,1\\}^n$ and $(x,y) \\in E$ whenever $\\Delta(x,y) = (1-\\gamma)n$ (an\neven integer). In particular, we show the degree-$4$ SOS algorithm certifies\nthe chromatic number lower bound \"$\\chi(\\mathrm{FR}^{n}_{1/4}) = \\omega(1)$\",\neven though $\\mathrm{FR}^{n}_{1/4}$ is the canonical integrality gap instance\nfor which standard SDP relaxations cannot even certify\n\"$\\chi(\\mathrm{FR}^{n}_{1/4}) > 3$\". Finally, we also give an SOS proof of (a\ngeneralization of) the sharp $(2,q)$-hypercontractive inequality for any even\ninteger $q$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1212.6104v5", 
    "title": "Short lists for shortest descriptions in short time", 
    "arxiv-id": "1212.6104v5", 
    "author": "Jason Teutsch", 
    "publish": "2012-12-26T00:15:53Z", 
    "summary": "Is it possible to find a shortest description for a binary string? The\nwell-known answer is \"no, Kolmogorov complexity is not computable.\" Faced with\nthis barrier, one might instead seek a short list of candidates which includes\na laconic description. Remarkably such approximations exist. This paper\npresents an efficient algorithm which generates a polynomial-size list\ncontaining an optimal description for a given input string. Along the way, we\nemploy expander graphs and randomness dispersers to obtain an Explicit Online\nMatching Theorem for bipartite graphs and a refinement of Muchnik's Conditional\nComplexity Theorem. Our main result extends recent work by Bauwens, Mahklin,\nVereschchagin, and Zimand."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1212.6725v1", 
    "title": "Solvability of HornSAT and CNFSAT", 
    "arxiv-id": "1212.6725v1", 
    "author": "Koji Kobayashi", 
    "publish": "2012-12-30T14:11:39Z", 
    "summary": "This article describes the solvability of HornSAT and CNFSAT.\n  Unsatisfiable HornCNF have partially ordered set that is made by causation of\neach clauses. In this partially ordered set, Truth value assignment that is\nfalse in each clauses become simply connected space. Therefore, if we reduce\nCNFSAT to HornSAT, we must make such partially ordered set in HornSAT. But\nCNFSAT have correlations of each clauses, the partially ordered set is not in\npolynomial size.\n  Therefore, we cannot reduce CNFSAT to HornSAT in polynomial size."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1212.6935v1", 
    "title": "The ODD EVEN DELTA problem is #P-hard", 
    "arxiv-id": "1212.6935v1", 
    "author": "Giorgio Camerani", 
    "publish": "2012-12-31T17:47:52Z", 
    "summary": "Let G=(V,E) be a graph. Let k < |V| be an integer. Let O_k be the number of\nedge induced subgraphs of G having k vertices and an odd number of edges. Let\nE_k be the number of edge induced subgraphs of G having k vertices and an even\nnumber of edges. Let D_k = O_k - E_k. The ODD EVEN DELTA problem consists in\ncomputing D_k, given G and k. We show that such problem is #P-hard, even on\n3-regular bipartite planar graphs."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.20", 
    "link": "http://arxiv.org/pdf/1302.0067v1", 
    "title": "A direct reduction of PPAD Lemke-verified linear complementarity   problems to bimatrix games", 
    "arxiv-id": "1302.0067v1", 
    "author": "Sushil Verma", 
    "publish": "2013-02-01T03:39:51Z", 
    "summary": "The linear complementarity problem, LCP(q,M), is defined as follows. For\ngiven M,q find z such that q+Mz>=0, z>=0, z(q + M z)=0,or certify that there is\nno such z. It is well known that the problem of finding a Nash equilibrium for\na bimatrix game (2-NASH) can be formulated as a linear complementarity problem\n(LCP). In addition, 2-NASH is known to be complete in the complexity class PPAD\n(Polynomial-time Parity Argument Directed). However, the ingeniously\nconstructed reduction (which is designed for any PPAD problem) is very\ncomplicated, so while of great theoretical significance, it is not practical\nfor actually solving an LCP via 2-NASH, and it may not provide the potential\ninsight that can be gained from studying the game obtained from a problem\nformulated as an LCP (e.g. market equilibrium). The main goal of this paper is\nthe construction of a simple explicit reduction of any LCP(q,M) that can be\nverified as belonging to PPAD via the graph induced by the generic Lemke\nalgorithm with some positive covering vector d, to a symmetric 2-NASH. In\nparticular, any endpoint of this graph (with the exception of the initial point\nof the algorithm) corresponds to either a solution or to a so-called secondary\nray. Thus, an LCP problem is verified as belonging to PPAD if any secondary ray\ncan be used to construct, in polynomial time, a certificate that there is no\nsolution to the problem. We achieve our goal by showing that for any M,q and a\npositive d satisfying a certain nondegeneracy assumption with respect to M, we\ncan simply and directly construct a symmetric 2-NASH whose Nash equilibria\ncorrespond one-to-one to the end points of the graph induced by LCP(q,M) and\nthe Lemke algorithm with a covering vector d. We note that for a given M the\nreduction works for all positive d with the exception of a subset of measure 0."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.0275v6", 
    "title": "A strong direct product theorem for the tribes function via the   smooth-rectangle bound", 
    "arxiv-id": "1302.0275v6", 
    "author": "Rahul Jain", 
    "publish": "2013-02-01T20:47:07Z", 
    "summary": "The main result of this paper is an optimal strong direct product result for\nthe two-party public-coin randomized communication complexity of the Tribes\nfunction. This is proved by providing an alternate proof of the optimal lower\nbound of \\Omega(n) for the randomised communication complexity of the Tribes\nfunction using the so-called smooth-rectangle bound, introduced by Jain and\nKlauck [JK10]. The optimal \\Omega(n) lower bound for Tribes was originally\nproved by Jayram, Kumar and Sivakumar [JKS03], using a more powerful lower\nbound technique, namely the information complexity bound. The information\ncomplexity bound is known to be at least as strong a lower bound method as the\nsmooth-rectangle bound [KLL+12]. On the other hand, we are not aware of any\nfunction or relation for which the smooth-rectangle bound is (asymptotically)\nsmaller than its public-coin randomized communication complexity. The optimal\ndirect product for Tribes is obtained by combining our smooth-rectangle bound\nfor tribes with the strong direct product result of Jain and Yao [JY12] in\nterms of smooth-rectangle bound."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.0566v2", 
    "title": "Orbit Problem Revisited", 
    "arxiv-id": "1302.0566v2", 
    "author": "Nengkun Yu", 
    "publish": "2013-02-04T01:48:32Z", 
    "summary": "In this letter, we revisit the {\\em orbit problem}, which was studied in\n\\cite{HAR69,SHA79,KL86}. In \\cite{KL86}, Kannan and Lipton proved that this\nproblem is decidable in polynomial time. In this paper, we study the {\\em\napproximate orbit problem}, and show that this problem is decidable except for\none case."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.0973v1", 
    "title": "A Combination Framework for Complexity", 
    "arxiv-id": "1302.0973v1", 
    "author": "Georg Moser", 
    "publish": "2013-02-05T09:39:06Z", 
    "summary": "In this paper we present a combination framework for polynomial complexity\nanalysis of term rewrite systems. The framework covers both derivational and\nruntime complexity analysis. We present generalisations of powerful complexity\ntechniques, notably a generalisation of complexity pairs and (weak) dependency\npairs. Finally, we also present a novel technique, called dependency graph\ndecomposition, that in the dependency pair setting greatly increases\nmodularity. We employ the framework in the automated complexity tool TCT. TCT\nimplements a majority of the techniques found in the literature, witnessing\nthat our framework is general enough to capture a very brought setting."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.1109v1", 
    "title": "Short lists with short programs in short time - a short proof", 
    "arxiv-id": "1302.1109v1", 
    "author": "Marius Zimand", 
    "publish": "2013-02-05T16:45:59Z", 
    "summary": "Bauwens, Mahklin, Vereshchagin and Zimand [ECCC TR13-007] and Teutsch\n[arxiv:1212.6104] have shown that given a string x it is possible to construct\nin polynomial time a list containing a short description of it. We simplify\ntheir technique and present a shorter proof of this result."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.3308v1", 
    "title": "Arithmetic Circuit Lower Bounds via MaxRank", 
    "arxiv-id": "1302.3308v1", 
    "author": "Jayalal Sarma M. N", 
    "publish": "2013-02-14T04:25:56Z", 
    "summary": "We introduce the polynomial coefficient matrix and identify maximum rank of\nthis matrix under variable substitution as a complexity measure for\nmultivariate polynomials. We use our techniques to prove super-polynomial lower\nbounds against several classes of non-multilinear arithmetic circuits. In\nparticular, we obtain the following results :\n  As our main result, we prove that any homogeneous depth-3 circuit for\ncomputing the product of $d$ matrices of dimension $n \\times n$ requires\n$\\Omega(n^{d-1}/2^d)$ size. This improves the lower bounds by Nisan and\nWigderson(1995) when $d=\\omega(1)$.\n  There is an explicit polynomial on $n$ variables and degree at most\n$\\frac{n}{2}$ for which any depth-3 circuit $C$ of product dimension at most\n$\\frac{n}{10}$ (dimension of the space of affine forms feeding into each\nproduct gate) requires size $2^{\\Omega(n)}$. This generalizes the lower bounds\nagainst diagonal circuits proved by Saxena(2007). Diagonal circuits are of\nproduct dimension 1.\n  We prove a $n^{\\Omega(\\log n)}$ lower bound on the size of product-sparse\nformulas. By definition, any multilinear formula is a product-sparse formula.\nThus, our result extends the known super-polynomial lower bounds on the size of\nmultilinear formulas by Raz(2006).\n  We prove a $2^{\\Omega(n)}$ lower bound on the size of partitioned arithmetic\nbranching programs. This result extends the known exponential lower bound on\nthe size of ordered arithmetic branching programs given by Jansen(2008)."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.3673v2", 
    "title": "Global Optimal Solutions to General Sensor Network Localization Problem", 
    "arxiv-id": "1302.3673v2", 
    "author": "David Y Gao", 
    "publish": "2013-02-15T04:47:58Z", 
    "summary": "Sensor network localization problem is to determine the position of the\nsensor nodes in a network given pairwise distance measurements. Such problem\ncan be formulated as a polynomial minimization via the least squares method.\nThis paper presents a canonical duality theory for solving this challenging\nproblem. It is shown that the nonconvex minimization problem can be\nreformulated as a concave maximization dual problem over a convex set in a\nsymmetrical matrix space, and hence can be solved efficiently by combining a\ngeneral (linear or quadratic) perturbation technique with existing optimization\ntechniques. Applications are illustrated by solving some relatively large-scale\nproblems. Our results show that the general sensor network localization problem\nis not NP-hard unless its canonical dual problem has no solution."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.4207v1", 
    "title": "A composition theorem for decision tree complexity", 
    "arxiv-id": "1302.4207v1", 
    "author": "Ashley Montanaro", 
    "publish": "2013-02-18T10:12:29Z", 
    "summary": "We completely characterise the complexity in the decision tree model of\ncomputing composite relations of the form h = g(f^1,...,f^n), where each\nrelation f^i is boolean-valued. Immediate corollaries include a direct sum\ntheorem for decision tree complexity and a tight characterisation of the\ndecision tree complexity of iterated boolean functions."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.4625v4", 
    "title": "On the sum of $L1$ influences", 
    "arxiv-id": "1302.4625v4", 
    "author": "Mohammad Bavarian", 
    "publish": "2013-02-19T14:45:48Z", 
    "summary": "For a function $f$ over the discrete cube, the total $L_1$ influence of $f$\nis defined as $\\sum_{i=1}^n \\|\\partial_i f\\|_1$, where $\\partial_i f$ denotes\nthe discrete derivative of $f$ in the direction $i$. In this work, we show that\nthe total $L_1$ influence of a $[-1,1]$-valued function $f$ can be upper\nbounded by a polynomial in the degree of $f$, resolving affirmatively an open\nproblem of Aaronson and Ambainis (ITCS 2011). The main challenge here is that\nthe $L_1$ influences do not admit an easy Fourier analytic representation. In\nour proof, we overcome this problem by introducing a new analytic quantity\n$\\mathcal I_p(f)$, relating this new quantity to the total $L_1$ influence of\n$f$. This new quantity, which roughly corresponds to an average of the total\n$L_1$ influences of some ensemble of functions related to $f$, has the benefit\nof being much easier to analyze, allowing us to resolve the problem of Aaronson\nand Ambainis. We also give an application of the theorem to graph theory, and\ndiscuss the connection between the study of bounded functions over the cube and\nthe quantum query complexity of partial functions where Aaronson and Ambainis\nencountered this question."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.5898v3", 
    "title": "Towards Randomized Testing of $q$-Monomials in Multivariate Polynomials", 
    "arxiv-id": "1302.5898v3", 
    "author": "Quanhai Yang", 
    "publish": "2013-02-24T11:58:20Z", 
    "summary": "Given any fixed integer $q\\ge 2$, a $q$-monomial is of the format\n$\\displaystyle x^{s_1}_{i_1}x^{s_2}_{i_2}...x_{i_t}^{s_t}$ such that $1\\le s_j\n\\le q-1$, $1\\le j \\le t$. $q$-monomials are natural generalizations of\nmultilinear monomials. Recent research on testing multilinear monomials and\n$q$-monomails for prime $q$ in multivariate polynomials relies on the property\nthat $Z_q$ is a field when $q\\ge 2 $ is prime. When $q>2$ is not prime, it\nremains open whether the problem of testing $q$-monomials can be solved in some\ncompatible complexity. In this paper, we present a randomized $O^*(7.15^k)$\nalgorithm for testing $q$-monomials of degree $k$ that are found in a\nmultivariate polynomial that is represented by a tree-like circuit with a\npolynomial size, thus giving a positive, affirming answer to the above\nquestion. Our algorithm works regardless of the primality of $q$ and improves\nupon the time complexity of the previously known algorithm for testing\n$q$-monomials for prime $q>7$."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1302.6191v3", 
    "title": "Dual Lower Bounds for Approximate Degree and Markov-Bernstein   Inequalities", 
    "arxiv-id": "1302.6191v3", 
    "author": "Justin Thaler", 
    "publish": "2013-02-25T18:53:47Z", 
    "summary": "The $\\epsilon$-approximate degree of a Boolean function $f: \\{-1, 1\\}^n \\to\n\\{-1, 1\\}$ is the minimum degree of a real polynomial that approximates $f$ to\nwithin $\\epsilon$ in the $\\ell_\\infty$ norm. We prove several lower bounds on\nthis important complexity measure by explicitly constructing solutions to the\ndual of an appropriate linear program. Our first result resolves the\n$\\epsilon$-approximate degree of the two-level AND-OR tree for any constant\n$\\epsilon > 0$. We show that this quantity is $\\Theta(\\sqrt{n})$, closing a\nline of incrementally larger lower bounds. The same lower bound was recently\nobtained independently by Sherstov using related techniques. Our second result\ngives an explicit dual polynomial that witnesses a tight lower bound for the\napproximate degree of any symmetric Boolean function, addressing a question of\n\\v{S}palek. Our final contribution is to reprove several Markov-type\ninequalities from approximation theory by constructing explicit dual solutions\nto natural linear programs. These inequalities underly the proofs of many of\nthe best-known approximate degree lower bounds, and have important uses\nthroughout theoretical computer science."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1303.0041v1", 
    "title": "QCSP on partially reflexive cycles - the wavy line of tractability", 
    "arxiv-id": "1303.0041v1", 
    "author": "Barnaby Martin", 
    "publish": "2013-02-28T23:18:19Z", 
    "summary": "We study the (non-uniform) quantified constraint satisfaction problem QCSP(H)\nas H ranges over partially reflexive cycles. We obtain a complexity-theoretic\ndichotomy: QCSP(H) is either in NL or is NP-hard. The separating conditions are\nsomewhat esoteric hence the epithet \"wavy line of tractability\"."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.FSTTCS.2013.141", 
    "link": "http://arxiv.org/pdf/1303.0478v2", 
    "title": "Monomial Testing and Applications", 
    "arxiv-id": "1303.0478v2", 
    "author": "Shenshi Chen", 
    "publish": "2013-03-03T09:11:24Z", 
    "summary": "In this paper, we devise two algorithms for the problem of testing\n$q$-monomials of degree $k$ in any multivariate polynomial represented by a\ncircuit, regardless of the primality of $q$. One is an $O^*(2^k)$ time\nrandomized algorithm. The other is an $O^*(12.8^k)$ time deterministic\nalgorithm for the same $q$-monomial testing problem but requiring the\npolynomials to be represented by tree-like circuits. Several applications of\n$q$-monomial testing are also given, including a deterministic $O^*(12.8^{mk})$\nupper bound for the $m$-set $k$-packing problem."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.1347v2", 
    "title": "Constant Unary Constraints and Symmetric Real-Weighted Counting   Constraint Satisfaction Problems", 
    "arxiv-id": "1303.1347v2", 
    "author": "Tomoyuki Yamakami", 
    "publish": "2013-03-06T15:07:08Z", 
    "summary": "A unary constraint (on the Boolean domain) is a function from {0,1} to the\nset of real numbers. A free use of auxiliary unary constraints given besides\ninput instances has proven to be useful in establishing a complete\nclassification of the computational complexity of approximately solving\nweighted counting Boolean constraint satisfaction problems (or #CSPs). In\nparticular, two special constant unary constraints are a key to an arity\nreduction of arbitrary constraints, sufficient for the desired classification.\nIn an exact counting model, both constant unary constraints are always assumed\nto be available since they can be eliminated efficiently using an arbitrary\nnonempty set of constraints. In contrast, we demonstrate in an approximate\ncounting model, that at least one of them is efficiently approximated and thus\neliminated approximately by a nonempty constraint set. This fact directly leads\nto an efficient construction of polynomial-time randomized\napproximation-preserving Turing reductions (or AP-reductions) from #CSPs with\ndesignated constraints to any given #CSPs composed of symmetric real-valued\nconstraints of arbitrary arities even in the presence of arbitrary extra unary\nconstraints."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.1969v1", 
    "title": "Arithmetic Branching Programs with Memory", 
    "arxiv-id": "1303.1969v1", 
    "author": "Stefan Mengel", 
    "publish": "2013-03-08T12:23:55Z", 
    "summary": "We extend the well known characterization of $\\vpws$ as the class of\npolynomials computed by polynomial size arithmetic branching programs to other\ncomplexity classes. In order to do so we add additional memory to the\ncomputation of branching programs to make them more expressive. We show that\nallowing different types of memory in branching programs increases the\ncomputational power even for constant width programs. In particular, this leads\nto very natural and robust characterizations of $\\vp$ and $\\vnp$ by branching\nprograms with memory."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.2580v1", 
    "title": "Proof of the hypothesis Edmonds's, not polynomial of NPC-problems and   classification of the problems with polynomial certificates", 
    "arxiv-id": "1303.2580v1", 
    "author": "B. S. Kochkarev", 
    "publish": "2013-03-07T11:24:04Z", 
    "summary": "We show that the affirmation $P\\subseteq NP$ (in computer science)\nerroneously and we prove the justice of the hypotesis J.Edmonds's $P\\neq NP$.\nWe show further that all the $NP$-complete problems is not polynomial and we\ngive the classification of the problems with the polynomial certificates."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.3166v1", 
    "title": "The complexity of proving that a graph is Ramsey", 
    "arxiv-id": "1303.3166v1", 
    "author": "Neil Thapen", 
    "publish": "2013-03-13T14:15:31Z", 
    "summary": "We say that a graph with $n$ vertices is $c$-Ramsey if it does not contain\neither a clique or an independent set of size $c \\log n$. We define a CNF\nformula which expresses this property for a graph $G$. We show a\nsuperpolynomial lower bound on the length of resolution proofs that $G$ is\n$c$-Ramsey, for every graph $G$. Our proof makes use of the fact that every\nRamsey graph must contain a large subgraph with some of the statistical\nproperties of the random graph."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.4315v1", 
    "title": "On the computational complexity of Data Flow Analysis", 
    "arxiv-id": "1303.4315v1", 
    "author": "K. Murali Krishnan", 
    "publish": "2013-03-18T16:44:20Z", 
    "summary": "We consider the problem of Data Flow Analysis over monotone data flow\nframeworks with a finite lattice. The problem of computing the Maximum Fixed\nPoint (MFP) solution is shown to be P-complete even when the lattice has just\nfour elements. This shows that the problem is unlikely to be efficiently\nparallelizable. It is also shown that the problem of computing the Meet Over\nall Paths (MOP) solution is NL-complete (and hence efficiently parallelizable)\nwhen the lattice is finite even for non-monotone data flow frameworks. These\nresults appear in contrast with the fact that when the lattice is not finite,\nsolving the MOP problem is undecidable and hence significantly harder than the\nMFP problem which is polynomial time computable for lattices of finite height."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.4408v4", 
    "title": "Computing in the Limit", 
    "arxiv-id": "1303.4408v4", 
    "author": "Antony Van der Mude", 
    "publish": "2013-03-18T20:24:03Z", 
    "summary": "We define a class of functions termed \"Computable in the Limit\", based on the\nMachine Learning paradigm of \"Identification in the Limit\". A function is\nComputable in the Limit if it defines a property P_p of a recursively\nenumerable class A of recursively enumerable data sequences S in A, such that\neach data sequence S is generated by a total recursive function s that\nenumerates . Let the index s represent the data sequence S. The property\nP_p(s)=x is computed by a partial recursive function f_p(s,t) such that there\nexists a u where f_p(s,u)=x and for all t>=u, f_p(s,t)=x if it converges. Since\nthe index s is known, this is not an identification problem - instead it is\ncomputing a common property of the sequences in A. We give a Normal Form\nTheorem for properties that are Computable in the Limit, similar to Kleene's\nNormal Form Theorem. We also give some examples of sets that are Computable in\nthe Limit, and derive some properties of Canonical and Complexity Bound\nEnumerations of classes of total functions, and show that no full enumeration\nof all indices of Turing machines TM_i that compute a given total function can\nbe Computable in the Limit."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.5305v2", 
    "title": "Projection onto the Cosparse Set is NP-Hard", 
    "arxiv-id": "1303.5305v2", 
    "author": "Marc E. Pfetsch", 
    "publish": "2013-03-21T15:42:18Z", 
    "summary": "The computational complexity of a problem arising in the context of sparse\noptimization is considered, namely, the projection onto the set of $k$-cosparse\nvectors w.r.t. some given matrix $\\Omeg$. It is shown that this projection\nproblem is (strongly) \\NP-hard, even in the special cases in which the matrix\n$\\Omeg$ contains only ternary or bipolar coefficients. Interestingly, this is\nin contrast to the projection onto the set of $k$-sparse vectors, which is\ntrivially solved by keeping only the $k$ largest coefficients."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.6729v2", 
    "title": "Matchgates Revisited", 
    "arxiv-id": "1303.6729v2", 
    "author": "Aaron Gorenstein", 
    "publish": "2013-03-27T02:29:59Z", 
    "summary": "We study a collection of concepts and theorems that laid the foundation of\nmatchgate computation. This includes the signature theory of planar matchgates,\nand the parallel theory of characters of not necessarily planar matchgates. Our\naim is to present a unified and, whenever possible, simplified account of this\nchallenging theory. Our results include: (1) A direct proof that Matchgate\nIdentities (MGI) are necessary and sufficient conditions for matchgate\nsignatures. This proof is self-contained and does not go through the character\ntheory. More importantly it rectifies a gap in the existing proof. (2) A proof\nthat Matchgate Identities already imply the Parity Condition. (3) A simplified\nconstruction of a crossover gadget. This is used in the proof of sufficiency of\nMGI for matchgate signatures. This is also used to give a proof of equivalence\nbetween the signature theory and the character theory which permits omittable\nnodes. (4) A direct construction of matchgates realizing all\nmatchgate-realizable symmetric signatures."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1303.7361v1", 
    "title": "Holographaic Alogorithms on Bases of Rank 2", 
    "arxiv-id": "1303.7361v1", 
    "author": "Fengqin Yang", 
    "publish": "2013-03-29T11:03:40Z", 
    "summary": "An essential problem in the design of holographic algorithms is to decide\nwhether the required signatures can be realized by matchgates under a suitable\nbasis transformation (SRP). For holographic algorithms on domain size 2, [1, 2,\n4, 5] have built a systematical theory. In this paper, we reduce SRP on domain\nsize k>2 to SRP on domain size 2 for holographic algorithms on bases of rank 2.\nFurthermore, we generalize the collapse theorem of [3] to domain size k>2."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.0211v2", 
    "title": "On Kolmogorov Complexity of Random Very Long Braided Words", 
    "arxiv-id": "1308.0211v2", 
    "author": "Dara O Shayda", 
    "publish": "2013-08-01T14:03:45Z", 
    "summary": "Any positive word comprised of random sequence of tokens form a finite\nalphabet can be reduced (without change of length) using an appropriate size\nBraid group relationships. Surprisingly the Braid relations dramatically reduce\nthe Kolmogorov Complexity of the original random word and do so in distinct\nbands of (rate of change) values with gaps in between. Distribution of these\nbands are estimated and empirical statistics collected by actually coding\napproximations to the Kolmogorov Complexity (in Mathematica 9.0).\nLempel-Ziv-Welch lossless compression algorithm techniques used to estimate the\ndistribution for gaped bands. Evidence provided that such distributions of\nreduction in Kolmogorov Complexity based upon Braid groups are universal i.e.\nthey can model more general algebraic structures other than Braid groups."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.0497v1", 
    "title": "A note on T\u00fcring's 1936", 
    "arxiv-id": "1308.0497v1", 
    "author": "Paola Cattabriga", 
    "publish": "2013-07-31T11:28:30Z", 
    "summary": "T\\\"uring's argument that there can be no machine computing the diagonal on\nthe enumeration of the computable sequences is not a demonstration."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.1394v2", 
    "title": "Computational Complexity of the Minimum Cost Homomorphism Problem on   Three-Element Domains", 
    "arxiv-id": "1308.1394v2", 
    "author": "Hannes Uppman", 
    "publish": "2013-08-06T19:59:34Z", 
    "summary": "In this paper we study the computational complexity of the (extended) minimum\ncost homomorphism problem (Min-Cost-Hom) as a function of a constraint\nlanguage, i.e. a set of constraint relations and cost functions that are\nallowed to appear in instances. A wide range of natural combinatorial\noptimisation problems can be expressed as Min-Cost-Homs and a classification of\ntheir complexity would be highly desirable, both from a direct, applied point\nof view as well as from a theoretical perspective.\n  Min-Cost-Hom can be understood either as a flexible optimisation version of\nthe constraint satisfaction problem (CSP) or a restriction of the\n(general-valued) valued constraint satisfaction problem (VCSP). Other\noptimisation versions of CSPs such as the minimum solution problem (Min-Sol)\nand the minimum ones problem (Min-Ones) are special cases of Min-Cost-Hom.\n  The study of VCSPs has recently seen remarkable progress. A complete\nclassification for the complexity of finite-valued languages on arbitrary\nfinite domains has been obtained Thapper and Zivny [STOC'13]. However,\nunderstanding the complexity of languages that are not finite-valued appears to\nbe more difficult. Min-Cost-Hom allows us to study problematic languages of\nthis type without having to deal with with the full generality of the VCSP. A\nrecent classification for the complexity of three-element Min-Sol, Uppman\n[ICALP'13], takes a step in this direction. In this paper we extend this result\nconsiderably by determining the complexity of three-element Min-Cost-Hom."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.1640v4", 
    "title": "Depth-4 Lower Bounds, Determinantal Complexity : A Unified Approach", 
    "arxiv-id": "1308.1640v4", 
    "author": "Partha Mukhopadhyay", 
    "publish": "2013-08-07T17:21:16Z", 
    "summary": "Tavenas has recently proved that any n^{O(1)}-variate and degree n polynomial\nin VP can be computed by a depth-4 circuit of size 2^{O(\\sqrt{n}\\log n)}. So to\nprove VP not equal to VNP, it is sufficient to show that an explicit polynomial\nin VNP of degree n requires 2^{\\omega(\\sqrt{n}\\log n)} size depth-4 circuits.\nSoon after Tavenas's result, for two different explicit polynomials, depth-4\ncircuit size lower bounds of 2^{\\Omega(\\sqrt{n}\\log n)} have been proved Kayal\net al. and Fournier et al. In particular, using combinatorial design Kayal et\nal.\\ construct an explicit polynomial in VNP that requires depth-4 circuits of\nsize 2^{\\Omega(\\sqrt{n}\\log n)} and Fournier et al.\\ show that iterated matrix\nmultiplication polynomial (which is in VP) also requires 2^{\\Omega(\\sqrt{n}\\log\nn)} size depth-4 circuits.\n  In this paper, we identify a simple combinatorial property such that any\npolynomial f that satisfies the property would achieve similar circuit size\nlower bound for depth-4 circuits. In particular, it does not matter whether f\nis in VP or in VNP. As a result, we get a very simple unified lower bound\nanalysis for the above mentioned polynomials.\n  Another goal of this paper is to compare between our current knowledge of\ndepth-4 circuit size lower bounds and determinantal complexity lower bounds. We\nprove the that the determinantal complexity of iterated matrix multiplication\npolynomial is \\Omega(dn) where d is the number of matrices and n is the\ndimension of the matrices. So for d=n, we get that the iterated matrix\nmultiplication polynomial achieves the current best known lower bounds in both\nfronts: depth-4 circuit size and determinantal complexity. To the best of our\nknowledge, a \\Theta(n) bound for the determinantal complexity for the iterated\nmatrix multiplication polynomial was known only for constant d>1 by Jansen."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.2286v2", 
    "title": "A tau-conjecture for Newton polygons", 
    "arxiv-id": "1308.2286v2", 
    "author": "St\u00e9phan Thomass\u00e9", 
    "publish": "2013-08-10T07:36:00Z", 
    "summary": "One can associate to any bivariate polynomial P(X,Y) its Newton polygon. This\nis the convex hull of the points (i,j) such that the monomial X^i Y^j appears\nin P with a nonzero coefficient. We conjecture that when P is expressed as a\nsum of products of sparse polynomials, the number of edges of its Newton\npolygon is polynomially bounded in the size of such an expression. We show that\nthis \"tau-conjecture for Newton polygons,\" even in a weak form, implies that\nthe permanent polynomial is not computable by polynomial size arithmetic\ncircuits. We make the same observation for a weak version of an earlier \"real\ntau-conjecture.\" Finally, we make some progress toward the tau-conjecture for\nNewton polygons using recent results from combinatorial geometry."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.2892v1", 
    "title": "Completeness Results for Parameterized Space Classes", 
    "arxiv-id": "1308.2892v1", 
    "author": "Till Tantau", 
    "publish": "2013-08-13T15:10:03Z", 
    "summary": "The parameterized complexity of a problem is considered \"settled\" once it has\nbeen shown to lie in FPT or to be complete for a class in the W-hierarchy or a\nsimilar parameterized hierarchy. Several natural parameterized problems have,\nhowever, resisted such a classification. At least in some cases, the reason is\nthat upper and lower bounds for their parameterized space complexity have\nrecently been obtained that rule out completeness results for parameterized\ntime classes. In this paper, we make progress in this direction by proving that\nthe associative generability problem and the longest common subsequence problem\nare complete for parameterized space classes. These classes are defined in\nterms of different forms of bounded nondeterminism and in terms of simultaneous\ntime--space bounds. As a technical tool we introduce a \"union operation\" that\ntranslates between problems complete for classical complexity classes and for\nW-classes."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.2970v1", 
    "title": "Gap Theorems for the Delay of Circuits Simulating Finite Automata", 
    "arxiv-id": "1308.2970v1", 
    "author": "Nicholas Pippenger", 
    "publish": "2013-08-13T20:09:06Z", 
    "summary": "We study the delay (also known as depth) of circuits that simulate finite\nautomata, showing that only certain growth rates (as a function of the number\n$n$ of steps simulated) are possible. A classic result due to Ofman\n(rediscovered and popularized by Ladner and Fischer) says that delay $O(\\log\nn)$ is always sufficient. We show that if the automaton is \"generalized\ndefinite\", then delay O(1) is sufficient, but otherwise delay $\\Omega(\\log n)$\nis necessary; there are no intermediate growth rates. We also consider\n\"physical\" (rather than \"logical\") delay, whereby we consider the lengths of\nwires when inputs and outputs are laid out along a line. In this case, delay\nO(n) is clearly always sufficient. We show that if the automaton is \"definite\",\nthen delay O(1) is sufficient, but otherwise delay $\\Omega(n)$ is necessary;\nagain there are no intermediate growth rates. Inspired by an observation of\nBurks, Goldstein and von Neumann concerning the average delay due to carry\npropagation in ripple-carry adders, we derive conditions for the average\nphysical delay to be reduced from O(n) to $O(\\log n)$, or to O(1), when the\ninputs are independent and uniformly distributed random variables; again there\nare no intermediate growth rates. Finally we consider an extension of this last\nresult to a situation in which the inputs are not independent and uniformly\ndistributed, but rather are produced by a non-stationary Markov process, and in\nwhich the computation is not performed by a single automaton, but rather by a\nsequence of automata acting in alternating directions."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.3247v2", 
    "title": "Hardness of Finding Independent Sets in 2-Colorable and Almost   2-Colorable Hypergraphs", 
    "arxiv-id": "1308.3247v2", 
    "author": "Rishi Saket", 
    "publish": "2013-08-14T20:34:05Z", 
    "summary": "This work studies the hardness of finding independent sets in hypergraphs\nwhich are either 2-colorable or are almost 2-colorable, i.e. can be 2-colored\nafter removing a small fraction of vertices and the incident hyperedges. To be\nprecise, say that a hypergraph is (1-eps)-almost 2-colorable if removing an eps\nfraction of its vertices and all hyperedges incident on them makes the\nremaining hypergraph 2-colorable. In particular we prove the following results.\n  For an arbitrarily small constant gamma > 0, there is a constant xi > 0, such\nthat, given a 4-uniform hypergraph on n vertices which is (1 - eps)-almost\n2-colorable for eps = 2^{-(log n)^xi}, it is quasi-NP-hard to find an\nindependent set of n/(2^{(log n)^{1-gamma}}) vertices.\n  For any constants eps, delta > 0, given as input a 3-uniform hypergraph on\n$n$ vertices which is (1-eps)-almost 2-colorable, it is NP-hard to find an\nindependent set of delta n vertices. Assuming the d-to-1 Games Conjecture the\nfollowing holds.\n  For any constant delta > 0, given a 2-colorable 3-uniform hypergraph on n\nvertices, it is NP-hard to find an independent set of delta n vertices.\n  The hardness result on independent set in almost 2-colorable 3-uniform\nhypergraphs was earlier known only assuming the Unique Games Conjecture. In\nthis work we prove the result unconditionally. For independent sets in\n2-colorable 3-uniform hypergaphs we prove the first strong hardness result,\nalbeit assuming the d-to-1 Games Conjecture. Our result on almost 2-colorable\n4-uniform hypergraphs gives the first nearly polynomial hardness factor for\nindependent set in hypergraphs which are (almost) colorable with constantly\nmany colors. It partially bridges the gap between the previous best lower bound\nof poly(log n) and the algorithmic upper bounds of n^{Omega(1)}."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.5158v1", 
    "title": "Locally Testable Codes and Cayley Graphs", 
    "arxiv-id": "1308.5158v1", 
    "author": "Yuan Zhou", 
    "publish": "2013-08-23T15:31:57Z", 
    "summary": "We give two new characterizations of ($\\F_2$-linear) locally testable\nerror-correcting codes in terms of Cayley graphs over $\\F_2^h$:\n  \\begin{enumerate} \\item A locally testable code is equivalent to a Cayley\ngraph over $\\F_2^h$ whose set of generators is significantly larger than $h$\nand has no short linear dependencies, but yields a shortest-path metric that\nembeds into $\\ell_1$ with constant distortion. This extends and gives a\nconverse to a result of Khot and Naor (2006), which showed that codes with\nlarge dual distance imply Cayley graphs that have no low-distortion embeddings\ninto $\\ell_1$.\n  \\item A locally testable code is equivalent to a Cayley graph over $\\F_2^h$\nthat has significantly more than $h$ eigenvalues near 1, which have no short\nlinear dependencies among them and which \"explain\" all of the large\neigenvalues. This extends and gives a converse to a recent construction of\nBarak et al. (2012), which showed that locally testable codes imply Cayley\ngraphs that are small-set expanders but have many large eigenvalues.\n\\end{enumerate}"
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.5506v1", 
    "title": "Algorithmic randomness and Ramsey properties of countable homogeneous   structures", 
    "arxiv-id": "1308.5506v1", 
    "author": "Willem L. Fouch\u00e9", 
    "publish": "2013-08-26T08:08:28Z", 
    "summary": "We study, in the context of algorithmic randomness, the closed amenable\nsubgroups of the symmetric group $S_\\infty$ of a countable set. In this paper\nwe address this problem by investigating a link between the symmetries\nassociated with Ramsey Fra\\\"iss\\'e order classes and algorithmic randomness."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1308.6505v1", 
    "title": "Oracle Tractability of Skew Bisubmodular Functions", 
    "arxiv-id": "1308.6505v1", 
    "author": "Andrei Krokhin", 
    "publish": "2013-08-29T16:03:49Z", 
    "summary": "In this paper we consider skew bisubmodular functions as introduced in [9].\nWe construct a convex extension of a skew bisubmodular function which we call\nLov\\'asz extension in correspondence to the submodular case. We use this\nextension to show that skew bisubmodular functions given by an oracle can be\nminimised in polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1309.0296v1", 
    "title": "A new kind of complexity", 
    "arxiv-id": "1309.0296v1", 
    "author": "Rade Vuckovac", 
    "publish": "2013-09-02T03:50:06Z", 
    "summary": "A new class of functions is presented. The structure of the algorithm,\nparticularly the selection criteria (branching), is used to define the\nfundamental property of the new class. The most interesting property of the new\nfunctions is that instances are easy to compute but if input to the function is\nvague the description of a function is exponentially complex. This property\nputs a new light on randomness especially on the random oracle model with a\ncouple of practical examples of random oracle implementation. Consequently,\nthere is a new interesting viewpoint on computational complexity in general."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-013-9518-4", 
    "link": "http://arxiv.org/pdf/1309.1089v1", 
    "title": "Randomness-efficient Curve Samplers", 
    "arxiv-id": "1309.1089v1", 
    "author": "Zeyu Guo", 
    "publish": "2013-09-04T16:17:44Z", 
    "summary": "Curve samplers are sampling algorithms that proceed by viewing the domain as\na vector space over a finite field, and randomly picking a low-degree curve in\nit as the sample. Curve samplers exhibit a nice property besides the sampling\nproperty: the restriction of low-degree polynomials over the domain to the\nsampled curve is still low-degree. This property is often used in combination\nwith the sampling property and has found many applications, including PCP\nconstructions, local decoding of codes, and algebraic PRG constructions.\n  The randomness complexity of curve samplers is a crucial parameter for its\napplications. It is known that (non-explicit) curve samplers using $O(\\log\nN+\\log(1/\\delta))$ random bits exist, where $N$ is the domain size and $\\delta$\nis the confidence error. The question of explicitly constructing\nrandomness-efficient curve samplers was first raised in \\cite{TU06} where they\nobtained curve samplers with near-optimal randomness complexity.\n  We present an explicit construction of low-degree curve samplers with {\\em\noptimal} randomness complexity (up to a constant factor), sampling curves of\ndegree $\\left(m\\log_q(1/\\delta)\\right)^{O(1)}$ in $\\mathbb{F}_q^m$. Our\nconstruction is a delicate combination of several components, including\nextractor machinery, limited independence, iterated sampling, and\nlist-recoverable codes."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.1269v1", 
    "title": "Topology and Non-Deterministic Polynomial Time Computation : Avoidance   of The Misbehaviour of Hub-Free Diagrams and Consequences", 
    "arxiv-id": "1309.1269v1", 
    "author": "Anthony Gasperin", 
    "publish": "2013-09-05T08:07:32Z", 
    "summary": "To study groups with small Dehn's function, Olshanskii and Sapir developed a\nnew invariant of bipartite chords diagrams and applied it to hub-free\nrealization of S-machines. In this paper we consider this new invariant\ntogether with groups constructed from S-machines containing the hub relation.\nThe idea is to study the links between the topology of the asymptotic cones and\npolynomial time computations. Indeed it is known that the topology of such\nmetric space depends on diagrams without hubs that do not correspond to the\ncomputations of the considered S-machine. This work gives sufficient conditions\nthat avoid this misbehaviour, but as we shall see the method has a significant\ndrawback."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.1779v6", 
    "title": "Fractal dimension versus process complexity", 
    "arxiv-id": "1309.1779v6", 
    "author": "Hector Zenil", 
    "publish": "2013-09-06T21:32:36Z", 
    "summary": "Complexity measures are designed to capture complex behavior and quantify\n*how* complex, according to that measure, that particular behavior is. It can\nbe expected that different complexity measures from possibly entirely different\nfields are related to each other in a non-trivial fashion. Here we study small\nTuring machines (TMs) with two symbols, and two and three states. For any\nparticular such machine $\\tau$ and any particular input $x$ we consider what we\ncall the 'space-time' diagram which is the collection of consecutive tape\nconfigurations of the computation $\\tau(x)$. In our setting, we define fractal\ndimension of a Turing machine as the limiting fractal dimension of the\ncorresponding space-time diagram. It turns out that there is a very strong\nrelation between the fractal dimension of a Turing machine of the\nabove-specified type and its runtime complexity. In particular, a TM with three\nstates and two colors runs in at most linear time iff its dimension is 2, and\nits dimension is 1 iff it runs in super-polynomial time and it uses polynomial\nspace. If a TM runs in time $O(x^n)$ we have empirically verified that the\ncorresponding dimension is $(n+1)/n$, a result that we can only partially\nprove. We find the results presented here remarkable because they relate two\ncompletely different complexity measures: the geometrical fractal dimension on\nthe one side versus the time complexity of a computation on the other side."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.2156v1", 
    "title": "Determinant versus Permanent: salvation via generalization? The   algebraic complexity of the Fermionant and the Immanant", 
    "arxiv-id": "1309.2156v1", 
    "author": "Nicolas de Rugy-Altherre", 
    "publish": "2013-09-09T13:47:49Z", 
    "summary": "The fermionant can be seen as a generalization of both the permanent (for\n$k=-1$) and the determinant. We demonstrate that it is VNP-complete for most\ncases. Furthermore it is #P-complete for the cases. The immanant is also a\ngeneralization of the permanent (for a Young diagram with a single line) and of\nthe determinant (when the Young diagram is a column). We demonstrate that the\nimmanant of any family of Young diagrams with bounded width and at least n\nboxes at the right of the first column is VNP-complete."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.3690v1", 
    "title": "Element Distinctness, Frequency Moments, and Sliding Windows", 
    "arxiv-id": "1309.3690v1", 
    "author": "Widad Machmouchi", 
    "publish": "2013-09-14T18:33:51Z", 
    "summary": "We derive new time-space tradeoff lower bounds and algorithms for exactly\ncomputing statistics of input data, including frequency moments, element\ndistinctness, and order statistics, that are simple to calculate for sorted\ndata. We develop a randomized algorithm for the element distinctness problem\nwhose time T and space S satisfy T in O (n^{3/2}/S^{1/2}), smaller than\nprevious lower bounds for comparison-based algorithms, showing that element\ndistinctness is strictly easier than sorting for randomized branching programs.\nThis algorithm is based on a new time and space efficient algorithm for finding\nall collisions of a function f from a finite set to itself that are reachable\nby iterating f from a given set of starting points. We further show that our\nelement distinctness algorithm can be extended at only a polylogarithmic factor\ncost to solve the element distinctness problem over sliding windows, where the\ntask is to take an input of length 2n-1 and produce an output for each window\nof length n, giving n outputs in total. In contrast, we show a time-space\ntradeoff lower bound of T in Omega(n^2/S) for randomized branching programs to\ncompute the number of distinct elements over sliding windows. The same lower\nbound holds for computing the low-order bit of F_0 and computing any frequency\nmoment F_k, k neq 1. This shows that those frequency moments and the decision\nproblem F_0 mod 2 are strictly harder than element distinctness. We complement\nthis lower bound with a T in O(n^2/S) comparison-based deterministic RAM\nalgorithm for exactly computing F_k over sliding windows, nearly matching both\nour lower bound for the sliding-window version and the comparison-based lower\nbounds for the single-window version. We further exhibit a quantum algorithm\nfor F_0 over sliding windows with T in O(n^{3/2}/S^{1/2}). Finally, we consider\nthe computations of order statistics over sliding windows."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.4718v3", 
    "title": "Parameterized Exact and Approximation Algorithms for Maximum $k$-Set   Cover and Related Satisfiability Problems", 
    "arxiv-id": "1309.4718v3", 
    "author": "Florian Sikora", 
    "publish": "2013-09-18T17:40:53Z", 
    "summary": "Given a family of subsets $\\mathcal S$ over a set of elements~$X$ and two\nintegers~$p$ and~$k$, Max k-Set Cover consists of finding a subfamily~$\\mathcal\nT \\subseteq \\mathcal S$ of cardinality at most~$k$, covering at least~$p$\nelements of~$X$. This problem is W[2]-hard when parameterized by~$k$, and FPT\nwhen parameterized by $p$. We investigate the parameterized approximability of\nthe problem with respect to parameters~$k$ and~$p$. Then, we show that Max\nSat-k, a satisfiability problem generalizing Max k-Set Cover, is also FPT with\nrespect to parameter~$p$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.5668v1", 
    "title": "Pseudorandomness for Multilinear Read-Once Algebraic Branching Programs,   in any Order", 
    "arxiv-id": "1309.5668v1", 
    "author": "Amir Shpilka", 
    "publish": "2013-09-22T23:56:03Z", 
    "summary": "We give deterministic black-box polynomial identity testing algorithms for\nmultilinear read-once oblivious algebraic branching programs (ROABPs), in\nn^(lg^2 n) time. Further, our algorithm is oblivious to the order of the\nvariables. This is the first sub-exponential time algorithm for this model.\nFurthermore, our result has no known analogue in the model of read-once\noblivious boolean branching programs with unknown order, as despite recent work\nthere is no known pseudorandom generator for this model with sub-polynomial\nseed-length (for unbounded-width branching programs).\n  This result extends and generalizes the result of Forbes and Shpilka that\nobtained a n^(lg n)-time algorithm when given the order. We also extend and\nstrengthen the work of Agrawal, Saha and Saxena that gave a black-box algorithm\nrunning in time exp((lg n)^d) for set-multilinear formulas of depth d. We note\nthat the model of multilinear ROABPs contains the model of set-multilinear\nalgebraic branching programs, which itself contains the model of\nset-multilinear formulas of arbitrary depth. We obtain our results by\nrecasting, and improving upon, the ideas of Agrawal, Saha and Saxena. We phrase\nthe ideas in terms of rank condensers and Wronskians, and show that our results\nimprove upon the classical multivariate Wronskian, which may be of independent\ninterest.\n  In addition, we give the first n^(lglg n) black-box polynomial identity\ntesting algorithm for the so called model of diagonal circuits. This model,\nintroduced by Saxena has recently found applications in the work of Mulmuley,\nas well as in the work of Gupta, Kamath, Kayal, Saptharishi. Previously work\nhad given n^(lg n)-time algorithms for this class. More generally, our result\nholds for any model computing polynomials whose partial derivatives (of all\norders) span a low dimensional linear space."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.5862v1", 
    "title": "On Regular Sets of Bounds and Determinism versus Nondeterminism", 
    "arxiv-id": "1309.5862v1", 
    "author": "Armin Hemmerling", 
    "publish": "2013-09-23T16:20:47Z", 
    "summary": "This paper illustrates the richness of the concept of regular sets of time\nbounds and demonstrates its application to problems of computational\ncomplexity. There is a universe of bounds whose regular subsets allow to\nrepresent several time complexity classes of common interest and are linearly\nordered with respect to the confinality relation which implies the inclusion\nbetween the corresponding complexity classes. By means of classical results of\ncomplexity theory, the separation of determinism from nondeterminism is\npossible for a variety of sets of bounds below $n\\cdot\\log^*(n)$. The system of\nall regular bound sets ordered by confinality allows the order-isomorphic\nembedding of, e.g., the ordered set of real numbers or the Cantor discontinuum."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.7288v1", 
    "title": "Small Polynomial Time Universal Petri Nets", 
    "arxiv-id": "1309.7288v1", 
    "author": "Dmitry A. Zaitsev", 
    "publish": "2013-09-27T16:24:18Z", 
    "summary": "The time complexity of the presented in 2013 by the author small universal\nPetri nets with the pairs of places/transitions numbers (14,42) and (14,29) was\nestimated as exponential. In the present paper, it is shown, that their slight\nmodification and interpretation as timed Petri nets with multichannel\ntransitions, introduced by the author in 1991, allows obtaining polynomial time\ncomplexity. The modification concerns using only inhibitor arcs to control\ntransitions' firing in multiple instances and employing an inverse control flow\nrepresented by moving zero. Thus, small universal Petri nets are efficient that\njustifies their application as models of high performance computations."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1309.7457v1", 
    "title": "On the Tape-Number Problem for Deterministic Time Classes", 
    "arxiv-id": "1309.7457v1", 
    "author": "Armin Hemmerling", 
    "publish": "2013-09-28T13:18:26Z", 
    "summary": "For any time bound f, let H(f) denote the hierarchy conjecture which means\nthat the restriction of the numbers of work tapes of deterministic Turing\nmachines to some b generates an infinite hierarchy of proper subclasses\nDTIME_b(f) \\subset \\DTIME(f). We show that H(f) implies separations of\ndeterministic from nondeterministic time classes. H(f) follows from the gap\nproperty, G(f), which says that there is a time-constructible bound f_2 such\nthat f \\in o(f_2) and DTIME(f)=DTIME(f_2). G(f) implies further separations.\nAll these relationships relativize."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1311.0293v1", 
    "title": "Pebbling Arguments for Tree Evaluation", 
    "arxiv-id": "1311.0293v1", 
    "author": "David Liu", 
    "publish": "2013-11-01T20:13:47Z", 
    "summary": "The Tree Evaluation Problem was introduced by Cook et al. in 2010 as a\ncandidate for separating P from L and NL. The most general space lower bounds\nknown for the Tree Evaluation Problem require a semantic restriction on the\nbranching programs and use a connection to well-known pebble games to generate\na bottleneck argument. These bounds are met by corresponding upper bounds\ngenerated by natural implementations of optimal pebbling algorithms. In this\npaper we extend these ideas to a variety of restricted families of both\ndeterministic and non-deterministic branching programs, proving tight lower\nbounds under these restricted models. We also survey and unify known lower\nbounds in our \"pebbling argument\" framework."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1311.1616v4", 
    "title": "Hardness Amplification and the Approximate Degree of Constant-Depth   Circuits", 
    "arxiv-id": "1311.1616v4", 
    "author": "Justin Thaler", 
    "publish": "2013-11-07T09:26:48Z", 
    "summary": "We establish a generic form of hardness amplification for the approximability\nof constant-depth Boolean circuits by polynomials. Specifically, we show that\nif a Boolean circuit cannot be pointwise approximated by low-degree polynomials\nto within constant error in a certain one-sided sense, then an OR of disjoint\ncopies of that circuit cannot be pointwise approximated even with very high\nerror. As our main application, we show that for every sequence of degrees\n$d(n)$, there is an explicit depth-three circuit $F: \\{-1,1\\}^n \\to \\{-1,1\\}$\nof polynomial-size such that any degree-$d$ polynomial cannot pointwise\napproximate $F$ to error better than\n$1-\\exp\\left(-\\tilde{\\Omega}(nd^{-3/2})\\right)$. As a consequence of our main\nresult, we obtain an $\\exp\\left(-\\tilde{\\Omega}(n^{2/5})\\right)$ upper bound on\nthe the discrepancy of a function in AC$^0$, and an\n$\\exp\\left(\\tilde{\\Omega}(n^{2/5})\\right)$ lower bound on the threshold weight\nof AC$^0$, improving over the previous best results of\n$\\exp\\left(-\\Omega(n^{1/3})\\right)$ and $\\exp\\left(\\Omega(n^{1/3})\\right)$\nrespectively.\n  Our techniques also yield a new lower bound of\n$\\Omega\\left(n^{1/2}/\\log^{(d-2)/2}(n)\\right)$ on the approximate degree of the\nAND-OR tree of depth $d$, which is tight up to polylogarithmic factors for any\nconstant $d$, as well as new bounds for read-once DNF formulas. In turn, these\nresults imply new lower bounds on the communication and circuit complexity of\nthese classes, and demonstrate strong limitations on existing PAC learning\nalgorithms."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1311.2355v2", 
    "title": "Communication Lower Bounds via Critical Block Sensitivity", 
    "arxiv-id": "1311.2355v2", 
    "author": "Toniann Pitassi", 
    "publish": "2013-11-11T05:19:30Z", 
    "summary": "We use critical block sensitivity, a new complexity measure introduced by\nHuynh and Nordstr\\\"om (STOC 2012), to study the communication complexity of\nsearch problems. To begin, we give a simple new proof of the following central\nresult of Huynh and Nordstr\\\"om: if $S$ is a search problem with critical block\nsensitivity $b$, then every randomised two-party protocol solving a certain\ntwo-party lift of $S$ requires $\\Omega(b)$ bits of communication. Besides\nsimplicity, our proof has the advantage of generalising to the multi-party\nsetting. We combine these results with new critical block sensitivity lower\nbounds for Tseitin and Pebbling search problems to obtain the following\napplications:\n  (1) Monotone Circuit Depth: We exhibit a monotone $n$-variable function in NP\nwhose monotone circuits require depth $\\Omega(n/\\log n)$; previously, a bound\nof $\\Omega(\\sqrt{n})$ was known (Raz and Wigderson, JACM 1992). Moreover, we\nprove a $\\Theta(\\sqrt{n})$ monotone depth bound for a function in monotone P.\n  (2) Proof Complexity: We prove new rank lower bounds as well as obtain the\nfirst length--space lower bounds for semi-algebraic proof systems, including\nLov\\'asz--Schrijver and Lasserre (SOS) systems. In particular, these results\nextend and simplify the works of Beame et al. (SICOMP 2007) and Huynh and\nNordstr\\\"om."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1311.2358v1", 
    "title": "Derandomizing Polynomial Identity over Finite Fields Implies   Super-Polynomial Circuit Lower Bounds for NEXP", 
    "arxiv-id": "1311.2358v1", 
    "author": "Bin Fu", 
    "publish": "2013-11-11T05:38:30Z", 
    "summary": "We show that derandomizing polynomial identity testing over an arbitrary\nfinite field implies that NEXP does not have polynomial size boolean circuits.\nIn other words, for any finite field F(q) of size q, $PIT_q\\in\nNSUBEXP\\Rightarrow NEXP\\not\\subseteq P/poly$, where $PIT_q$ is the polynomial\nidentity testing problem over F(q), and NSUBEXP is the nondeterministic\nsubexpoential time class of languages. Our result is in contract to Kabanets\nand Impagliazzo's existing theorem that derandomizing the polynomial identity\ntesting in the integer ring Z implies that NEXP does have polynomial size\nboolean circuits or permanent over Z does not have polynomial size arithmetic\ncircuits."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.128.15", 
    "link": "http://arxiv.org/pdf/1311.3171v3", 
    "title": "Local reductions", 
    "arxiv-id": "1311.3171v3", 
    "author": "Emanuele Viola", 
    "publish": "2013-11-13T15:28:37Z", 
    "summary": "We reduce non-deterministic time $T \\ge 2^n$ to a 3SAT instance $\\phi$ of\nquasilinear size $|\\phi| = T \\cdot \\log^{O(1)} T$ such that there is an\nexplicit circuit $C$ that on input an index $i$ of $\\log |\\phi|$ bits outputs\nthe $i$th clause, and each output bit of $C$ depends on $O(1)$ input bits. The\nprevious best result was $C$ in NC$^1$. Even in the simpler setting of\npolynomial size $|\\phi| = \\poly(T)$ the previous best result was $C$ in AC$^0$.\n  More generally, for any time $T \\ge n$ and parameter $r \\leq n$ we obtain\n$\\log_2 |\\phi| = \\max(\\log T, n/r) + O(\\log n) + O(\\log\\log T)$ and each output\nbit of $C$ is a decision tree of depth $O(\\log r)$.\n  As an application, we tighten Williams' connection between satisfiability\nalgorithms and circuit lower bounds (STOC 2010; SIAM J. Comput. 2013)."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s10107-016-0989-3", 
    "link": "http://arxiv.org/pdf/1311.4001v4", 
    "title": "Average case polyhedral complexity of the maximum stable set problem", 
    "arxiv-id": "1311.4001v4", 
    "author": "Sebastian Pokutta", 
    "publish": "2013-11-15T23:28:58Z", 
    "summary": "We study the minimum number of constraints needed to formulate random\ninstances of the maximum stable set problem via linear programs (LPs), in two\ndistinct models. In the uniform model, the constraints of the LP are not\nallowed to depend on the input graph, which should be encoded solely in the\nobjective function. There we prove a $2^{\\Omega(n/ \\log n)}$ lower bound with\nprobability at least $1 - 2^{-2^n}$ for every LP that is exact for a randomly\nselected set of instances; each graph on at most n vertices being selected\nindependently with probability $p \\geq 2^{-\\binom{n/4}{2}+n}$. In the\nnon-uniform model, the constraints of the LP may depend on the input graph, but\nwe allow weights on the vertices. The input graph is sampled according to the\nG(n, p) model. There we obtain upper and lower bounds holding with high\nprobability for various ranges of p. We obtain a super-polynomial lower bound\nall the way from $p = \\Omega(\\log^{6+\\varepsilon} / n)$ to $p = o (1 / \\log\nn)$. Our upper bound is close to this as there is only an essentially quadratic\ngap in the exponent, which currently also exists in the worst-case model.\nFinally, we state a conjecture that would close this gap, both in the\naverage-case and worst-case models."
},{
    "category": "cs.CC", 
    "doi": "10.1137/130945648", 
    "link": "http://arxiv.org/pdf/1311.4219v3", 
    "title": "The power of linear programming for general-valued CSPs", 
    "arxiv-id": "1311.4219v3", 
    "author": "Stanislav Zivny", 
    "publish": "2013-11-17T21:37:51Z", 
    "summary": "Let $D$, called the domain, be a fixed finite set and let $\\Gamma$, called\nthe valued constraint language, be a fixed set of functions of the form\n$f:D^m\\to\\mathbb{Q}\\cup\\{\\infty\\}$, where different functions might have\ndifferent arity $m$. We study the valued constraint satisfaction problem\nparametrised by $\\Gamma$, denoted by VCSP$(\\Gamma)$. These are minimisation\nproblems given by $n$ variables and the objective function given by a sum of\nfunctions from $\\Gamma$, each depending on a subset of the $n$ variables.\nFinite-valued constraint languages contain functions that take on only rational\nvalues and not infinite values.\n  Our main result is a precise algebraic characterisation of valued constraint\nlanguages whose instances can be solved exactly by the basic linear programming\nrelaxation (BLP). For a valued constraint language $\\Gamma$, BLP is a decision\nprocedure for $\\Gamma$ if and only if $\\Gamma$ admits a symmetric fractional\npolymorphism of every arity. For a finite-valued constraint language $\\Gamma$,\nBLP is a decision procedure if and only if $\\Gamma$ admits a symmetric\nfractional polymorphism of some arity, or equivalently, if $\\Gamma$ admits a\nsymmetric fractional polymorphism of arity 2.\n  Using these results, we obtain tractability of several novel classes of\nproblems, including problems over valued constraint languages that are: (1)\nsubmodular on arbitrary lattices; (2) $k$-submodular on arbitrary finite\ndomains; (3) weakly (and hence strongly) tree-submodular on arbitrary trees."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.4451v4", 
    "title": "#BIS-Hardness for 2-Spin Systems on Bipartite Bounded Degree Graphs in   the Tree Nonuniqueness Region", 
    "arxiv-id": "1311.4451v4", 
    "author": "Eric Vigoda", 
    "publish": "2013-11-18T17:03:51Z", 
    "summary": "Counting independent sets on bipartite graphs (#BIS) is considered a\ncanonical counting problem of intermediate approximation complexity. It is\nconjectured that #BIS neither has an FPRAS nor is as hard as #SAT to\napproximate. We study #BIS in the general framework of two-state spin systems\non bipartite graphs. We define two notions, nearly-independent phase-correlated\nspins and unary symmetry breaking. We prove that it is #BIS-hard to approximate\nthe partition function of any 2-spin system on bipartite graphs supporting\nthese two notions. As a consequence, we classify the complexity of\napproximating the partition function of antiferromagnetic 2-spin systems on\nbounded-degree bipartite graphs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.5467v1", 
    "title": "Challenges in computational lower bounds", 
    "arxiv-id": "1311.5467v1", 
    "author": "Emanuele Viola", 
    "publish": "2013-11-21T16:28:48Z", 
    "summary": "We draw two incomplete, biased maps of challenges in computational complexity\nlower bounds."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.5622v2", 
    "title": "Improved Extractors for Affine Lines", 
    "arxiv-id": "1311.5622v2", 
    "author": "Ariel Gabizon", 
    "publish": "2013-11-22T00:01:53Z", 
    "summary": "Let $F$ be the field of $q$ elements.\n  We investigate the following Ramsey coloring problem for vector spaces: Given\na vector space $\\F^n$, give a coloring of the points of $F^n$ with two colors\nsuch that no affine line (i.e., affine subspace of dimension $1$) is\nmonochromatic. Our main result is as follows:\n  For any $q\\geq 25\\cdot n$ and $n>4$, we give an explicit coloring $D:F^n\\ar\n\\set{0,1}$ such that for every affine line $l\\subseteq F^n$, $D(l)=\\set{0,1}$.\nPreviously this was known only for $q\\geq c\\cdot n^2$ for some constant $c$\n\\cite{GR05}. We note that this beats the random coloring for which the expected\nnumber of monochromatic lines will be 0 only when $q\\geq c\\cdot n\\log n$ for\nsome constant $c$. Furthermore, our coloring will be `almost balanced' on every\naffine line. Let us state this formally in the lanuage of \\emph{extractors}. We\nsay that a function $D:F^n\\mapsto \\set{0,1}$ is a \\afsext{1}{\\eps} if for every\naffine line $l\\subseteq \\F^n$, $D(X)$ is $\\eps$-close to uniform when $X$ is\nuniformly distributed over $l$. We construct a \\afsext{1}{\\eps} with $\\eps =\n\\Omega(\\sqrt{n/q})$ whenever $q\\geq c\\cdot n$ for some constant $c$.\n  The previous result of \\cite{GR05} gave a \\afsext{1}{\\eps} only for\n$q=\\Omega(n^2)$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.5690v1", 
    "title": "The Ergodicity of the Collatz Process in Positive Integer Field", 
    "arxiv-id": "1311.5690v1", 
    "author": "Li Kuang", 
    "publish": "2013-11-22T09:59:26Z", 
    "summary": "The $3x+1$ problem, also called the Collatz conjecture, is a very interesting\nunsolved mathematical problem related to computer science. This paper\ngeneralized this problem by relaxing the constraints, i.e., generalizing this\ndeterministic process to non-deterministic process, and set up three models.\nThis paper analyzed the ergodicity of these models and proved that the\nergodicity of the Collatz process in positive integer field holds, i.e., all\nthe positive integers can be transformed to 1 by the iterations of the Collatz\nfunction."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.6671v3", 
    "title": "A Deterministic Polynomial Space Construction for eps-nets under any   Norm", 
    "arxiv-id": "1311.6671v3", 
    "author": "Daniel Dadush", 
    "publish": "2013-11-26T14:00:52Z", 
    "summary": "We give a deterministic polynomial space construction for nearly optimal\neps-nets with respect to any input n-dimensional convex body K and norm |.|.\nMore precisely, our algorithm can build and iterate over an eps-net of K with\nrespect to |.| in time 2^O(n) x (size of the optimal net) using only\npoly(n)-space. This improves on previous constructions of Alon et al [STOC\n2013] which achieve either a 2^O(n) approximation or an n^O(n) approximation of\nthe optimal net size using 2^n space and poly(n)-space respectively. As in\ntheir work, our algorithm relies on the mathematically classical approach of\nbuilding thin lattice coverings of space, which reduces the task of\nconstructing eps-nets to the problem of enumerating lattice points. Our main\ntechnical contribution is a deterministic 2^O(n)-time and poly(n)-space\nconstruction of thin lattice coverings of space with respect to any convex\nbody, where enumeration in these lattices can be efficiently performed using\npoly(n)-space. This also yields the first existential construction of\npoly(n)-space enumerable thin covering lattices for general convex bodies,\nwhich we believe is of independent interest. Our construction combines the use\nof the M-ellipsoid from convex geometry with lattice sparsification and\ndensification techniques.\n  As an application, we give a 2^O(n)(1+1/eps)^n time and poly(n)-space\ndeterministic algorithm for computing a (1+eps)^n approximation to the volume\nof a general convex body, which nearly matches the lower bounds for volume\nestimation in the oracle model (the dependence on eps is larger by a factor 2\nin the exponent). This improves on the previous results of Dadush and Vempala\n[PNAS 2013], which gave the above result only for symmetric bodies and achieved\na dependence on eps of (1+log^{5/2}(1/eps)/eps^2)^n."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.6716v1", 
    "title": "The Limits of Depth Reduction for Arithmetic Formulas: It's all about   the top fan-in", 
    "arxiv-id": "1311.6716v1", 
    "author": "Shubhangi Saraf", 
    "publish": "2013-11-26T15:58:05Z", 
    "summary": "In recent years, a very exciting and promising method for proving lower\nbounds for arithmetic circuits has been proposed. This method combines the\nmethod of {\\it depth reduction} developed in the works of Agrawal-Vinay [AV08],\nKoiran [Koi12] and Tavenas [Tav13], and the use of the shifted partial\nderivative complexity measure developed in the works of Kayal [Kay12] and Gupta\net al [GKKS13a]. These results inspired a flurry of other beautiful results and\nstrong lower bounds for various classes of arithmetic circuits, in particular a\nrecent work of Kayal et al [KSS13] showing superpolynomial lower bounds for\n{\\it regular} arithmetic formulas via an {\\it improved depth reduction} for\nthese formulas. It was left as an intriguing question if these methods could\nprove superpolynomial lower bounds for general (homogeneous) arithmetic\nformulas, and if so this would indeed be a breakthrough in arithmetic circuit\ncomplexity.\n  In this paper we study the power and limitations of depth reduction and\nshifted partial derivatives for arithmetic formulas. We do it via studying the\nclass of depth 4 homogeneous arithmetic circuits. We show: (1) the first {\\it\nsuperpolynomial lower bounds} for the class of homogeneous depth 4 circuits\nwith top fan-in $o(\\log n)$. The core of our result is to show {\\it improved\ndepth reduction} for these circuits. (2) We show that improved depth reduction\n{\\it is not possible} when the top fan-in is $\\Omega(\\log n)$. In particular\nthis shows that the depth reduction procedure of Koiran and Tavenas [Koi12,\nTav13] cannot be improved even for homogeneous formulas, thus strengthening the\nresults of Fournier et al [FLMS13] who showed that depth reduction is tight for\ncircuits, and answering some of the main open questions of [KSS13, FLMS13]."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.7229v1", 
    "title": "Hierarchies", 
    "arxiv-id": "1311.7229v1", 
    "author": "Kamil Swierkot", 
    "publish": "2013-11-28T07:29:30Z", 
    "summary": "We study the complexity theory for the local distributed setting introduced\nby Korman, Peleg and Fraigniaud. They have defined three complexity classes LD\n(Local Decision), NLD (Nondeterministic Local Decision) and NLD^#n. The class\nLD consists of all languages which can be decided with a constant number of\ncommunication rounds. The class NLD consists of all languages which can be\nverified by a nondeterministic algorithm with a constant number of\ncommunication rounds. In order to define the nondeterministic classes, they\nhave transferred the notation of nondeterminism into the distributed setting by\nthe use of certificates and verifiers. The class NLD^#n consists of all\nlanguages which can be verified by a nondeterministic algorithm where each node\nhas access to an oracle for the number of nodes. They have shown the hierarchy\nLD subset NLD subset NLD^#n.\n  Our main contributions are strict hierarchies within the classes defined by\nKorman, Peleg and Fraigniaud. We define additional complexity classes: the\nclass LD(t) consists of all languages which can be decided with at most t\ncommunication rounds. The class NLD-O(f) consists of all languages which can be\nverified by a local verifier such that the size of the certificates that are\nneeded to verify the language are bounded by a function from O(f). Our main\nresults are refined strict hierarchies within these nondeterministic classes."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jcss.2015.11.009", 
    "link": "http://arxiv.org/pdf/1311.7278v2", 
    "title": "Linear list-approximation for short programs (or the power of a few   random bits)", 
    "arxiv-id": "1311.7278v2", 
    "author": "Marius Zimand", 
    "publish": "2013-11-28T11:28:31Z", 
    "summary": "A $c$-short program for a string $x$ is a description of $x$ of length at\nmost $C(x) + c$, where $C(x)$ is the Kolmogorov complexity of $x$. We show that\nthere exists a randomized algorithm that constructs a list of $n$ elements that\ncontains a $O(\\log n)$-short program for $x$. We also show a polynomial-time\nrandomized construction that achieves the same list size for $O(\\log^2\nn)$-short programs. These results beat the lower bounds shown by Bauwens et al.\n\\cite{bmvz:c:shortlist} for deterministic constructions of such lists. We also\nprove tight lower bounds for the main parameters of our result. The\nconstructions use only $O(\\log n)$ ($O(\\log^2 n)$ for the polynomial-time\nresult) random bits . Thus using only few random bits it is possible to do\ntasks that cannot be done by any deterministic algorithm regardless of its\nrunning time."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140995520", 
    "link": "http://arxiv.org/pdf/1311.7407v1", 
    "title": "Super-polylogarithmic hypergraph coloring hardness via low-degree long   codes", 
    "arxiv-id": "1311.7407v1", 
    "author": "Girish Varma", 
    "publish": "2013-11-28T19:44:53Z", 
    "summary": "We prove improved inapproximability results for hypergraph coloring using the\nlow-degree polynomial code (aka, the 'short code' of Barak et. al. [FOCS 2012])\nand the techniques proposed by Dinur and Guruswami [FOCS 2013] to incorporate\nthis code for inapproximability results. In particular, we prove\nquasi-NP-hardness of the following problems on $n$-vertex hyper-graphs:\n  * Coloring a 2-colorable 8-uniform hypergraph with\n$2^{2^{\\Omega(\\sqrt{\\log\\log n})}}$ colors.\n  * Coloring a 4-colorable 4-uniform hypergraph with\n$2^{2^{\\Omega(\\sqrt{\\log\\log n})}}$ colors.\n  * Coloring a 3-colorable 3-uniform hypergraph with $(\\log\nn)^{\\Omega(1/\\log\\log\\log n)}$ colors.\n  In each of these cases, the hardness results obtained are (at least)\nexponentially stronger than what was previously known for the respective cases.\nIn fact, prior to this result, polylog n colors was the strongest quantitative\nbound on the number of colors ruled out by inapproximability results for\nO(1)-colorable hypergraphs.\n  The fundamental bottleneck in obtaining coloring inapproximability results\nusing the low- degree long code was a multipartite structural restriction in\nthe PCP construction of Dinur-Guruswami. We are able to get around this\nrestriction by simulating the multipartite structure implicitly by querying\njust one partition (albeit requiring 8 queries), which yields our result for\n2-colorable 8-uniform hypergraphs. The result for 4-colorable 4-uniform\nhypergraphs is obtained via a 'query doubling' method. For 3-colorable\n3-uniform hypergraphs, we exploit the ternary domain to design a test with an\nadditive (as opposed to multiplicative) noise function, and analyze its\nefficacy in killing high weight Fourier coefficients via the pseudorandom\nproperties of an associated quadratic form."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140995520", 
    "link": "http://arxiv.org/pdf/1402.0146v1", 
    "title": "Remarks on AKS Primality Testing Algorithm and A Flaw in the Definition   of P", 
    "arxiv-id": "1402.0146v1", 
    "author": "Lihua Liu", 
    "publish": "2014-02-02T03:12:24Z", 
    "summary": "We remark that the AKS primality testing algorithm [Annals of Mathematics 160\n(2), 2004] needs about 1,000,000,000 G (gigabyte) storage space for a number of\n1024 bits. The requirement is very hard to meet. The complexity class P which\ncontains all decision problems that can be solved by a deterministic Turing\nmachine using a polynomial amount of computation time, is generally believed to\nbe ``easy\". We point out that the time is estimated only in terms of the amount\nof arithmetic operations. It does not comprise the time for reading and writing\ndata on the tape in a Turing machine. The flaw makes some deterministic\npolynomial time algorithms impractical, and humbles the importance of P=NP\nquestion."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140995520", 
    "link": "http://arxiv.org/pdf/1402.0532v1", 
    "title": "Approximate Computation of DFT without Performing Any Multiplications:   Applications to Radar Signal Processing", 
    "arxiv-id": "1402.0532v1", 
    "author": "A. Enis \u00c7etin", 
    "publish": "2014-02-03T21:59:49Z", 
    "summary": "In many practical problems it is not necessary to compute the DFT in a\nperfect manner including some radar problems. In this article a new\nmultiplication free algorithm for approximate computation of the DFT is\nintroduced. All multiplications $(a\\times b)$ in DFT are replaced by an\noperator which computes $sign(a\\times b)(|a|+|b|)$. The new transform is\nespecially useful when the signal processing algorithm requires correlations.\nAmbiguity function in radar signal processing requires high number of\nmultiplications to compute the correlations. This new additive operator is used\nto decrease the number of multiplications. Simulation examples involving\npassive radars are presented."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140995520", 
    "link": "http://arxiv.org/pdf/1402.0858v1", 
    "title": "Robust Satisfiability of Systems of Equations", 
    "arxiv-id": "1402.0858v1", 
    "author": "Marek Krcal", 
    "publish": "2014-02-04T20:51:37Z", 
    "summary": "We study the problem of \\emph{robust satisfiability} of systems of nonlinear\nequations, namely, whether for a given continuous function\n$f:\\,K\\to\\mathbb{R}^n$ on a~finite simplicial complex $K$ and $\\alpha>0$, it\nholds that each function $g:\\,K\\to\\mathbb{R}^n$ such that $\\|g-f\\|_\\infty \\leq\n\\alpha$, has a root in $K$. Via a reduction to the extension problem of maps\ninto a sphere, we particularly show that this problem is decidable in\npolynomial time for every fixed $n$, assuming $\\dim K \\le 2n-3$. This is a\nsubstantial extension of previous computational applications of\n\\emph{topological degree} and related concepts in numerical and interval\nanalysis. Via a reverse reduction we prove that the problem is undecidable when\n$\\dim K\\ge 2n-2$, where the threshold comes from the \\emph{stable range} in\nhomotopy theory. For the lucidity of our exposition, we focus on the setting\nwhen $f$ is piecewise linear. Such functions can approximate general continuous\nfunctions, and thus we get approximation schemes and undecidability of the\nrobust satisfiability in other possible settings."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140995520", 
    "link": "http://arxiv.org/pdf/1402.2175v1", 
    "title": "A Characterization of Locally Testable Affine-Invariant Properties via   Decomposition Theorems", 
    "arxiv-id": "1402.2175v1", 
    "author": "Yuichi Yoshida", 
    "publish": "2014-02-10T15:03:42Z", 
    "summary": "Let $\\mathcal{P}$ be a property of function $\\mathbb{F}_p^n \\to \\{0,1\\}$ for\na fixed prime $p$. An algorithm is called a tester for $\\mathcal{P}$ if, given\na query access to the input function $f$, with high probability, it accepts\nwhen $f$ satisfies $\\mathcal{P}$ and rejects when $f$ is \"far\" from satisfying\n$\\mathcal{P}$. In this paper, we give a characterization of affine-invariant\nproperties that are (two-sided error) testable with a constant number of\nqueries. The characterization is stated in terms of decomposition theorems,\nwhich roughly claim that any function can be decomposed into a structured part\nthat is a function of a constant number of polynomials, and a pseudo-random\npart whose Gowers norm is small. We first give an algorithm that tests whether\nthe structured part of the input function has a specific form. Then we show\nthat an affine-invariant property is testable with a constant number of queries\nif and only if it can be reduced to the problem of testing whether the\nstructured part of the input function is close to one of a constant number of\ncandidates."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140995520", 
    "link": "http://arxiv.org/pdf/1402.3543v2", 
    "title": "Inequalities and tail bounds for elementary symmetric polynomial with   applications", 
    "arxiv-id": "1402.3543v2", 
    "author": "Amir Yehudayoff", 
    "publish": "2014-02-14T18:17:42Z", 
    "summary": "We study the extent of independence needed to approximate the product of\nbounded random variables in expectation, a natural question that has\napplications in pseudorandomness and min-wise independent hashing.\n  For random variables whose absolute value is bounded by $1$, we give an error\nbound of the form $\\sigma^{\\Omega(k)}$ where $k$ is the amount of independence\nand $\\sigma^2$ is the total variance of the sum. Previously known bounds only\napplied in more restricted settings, and were quanitively weaker. We use this\nto give a simpler and more modular analysis of a construction of min-wise\nindependent hash functions and pseudorandom generators for combinatorial\nrectangles due to Gopalan et al., which also slightly improves their\nseed-length.\n  Our proof relies on a new analytic inequality for the elementary symmetric\npolynomials $S_k(x)$ for $x \\in \\mathbb{R}^n$ which we believe to be of\nindependent interest. We show that if $|S_k(x)|,|S_{k+1}(x)|$ are small\nrelative to $|S_{k-1}(x)|$ for some $k>0$ then $|S_\\ell(x)|$ is also small for\nall $\\ell > k$. From these, we derive tail bounds for the elementary symmetric\npolynomials when the inputs are only $k$-wise independent."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-44465-8_4", 
    "link": "http://arxiv.org/pdf/1402.5078v2", 
    "title": "A Tight Lower Bound on Certificate Complexity in Terms of Block   Sensitivity and Sensitivity", 
    "arxiv-id": "1402.5078v2", 
    "author": "Kri\u0161j\u0101nis Pr\u016bsis", 
    "publish": "2014-02-20T17:16:23Z", 
    "summary": "Sensitivity, certificate complexity and block sensitivity are widely used\nBoolean function complexity measures. A longstanding open problem, proposed by\nNisan and Szegedy, is whether sensitivity and block sensitivity are\npolynomially related. Motivated by the constructions of functions which achieve\nthe largest known separations, we study the relation between 1-certificate\ncomplexity and 0-sensitivity and 0-block sensitivity.\n  Previously the best known lower bound was $C_1(f)\\geq \\frac{bs_0(f)}{2\ns_0(f)}$, achieved by Kenyon and Kutin. We improve this to $C_1(f)\\geq \\frac{3\nbs_0(f)}{2 s_0(f)}$. While this improvement is only by a constant factor, this\nis quite important, as it precludes achieving a superquadratic separation\nbetween $bs(f)$ and $s(f)$ by iterating functions which reach this bound. In\naddition, this bound is tight, as it matches the construction of Ambainis and\nSun up to an additive constant."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-44465-8_4", 
    "link": "http://arxiv.org/pdf/1402.5311v1", 
    "title": "On the Power of Multiplexing in Number-on-the-Forehead Protocols", 
    "arxiv-id": "1402.5311v1", 
    "author": "Eyal Kushilevitz", 
    "publish": "2014-02-21T14:53:11Z", 
    "summary": "We study the direct-sum problem for $k$-party ``Number On the Forehead''\n(NOF) deterministic communication complexity. We prove several positive\nresults, showing that the complexity of computing a function $f$ in this model,\non $\\ell$ instances, may be significantly cheaper than $\\ell$ times the\ncomplexity of computing $f$ on a single instance. Quite surprisingly, we show\nthat this is the case for ``most'' (boolean, $k$-argument) functions. We then\nformalize two-types of sufficient conditions on a NOF protocol $Q$, for a\nsingle instance, each of which guarantees some communication complexity savings\nwhen appropriately extending $Q$ to work on $\\ell$ instances. One such\ncondition refers to what each party needs to know about inputs of the other\nparties, and the other condition, additionally, refers to the communication\npattern that the single-instance protocol $Q$ uses. In both cases, the tool\nthat we use is ``multiplexing'': we combine messages sent in parallel\nexecutions of protocols for a single instance, into a single message for the\nmulti-instance (direct-sum) case, by xoring them with each other."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-44465-8_4", 
    "link": "http://arxiv.org/pdf/1402.6800v1", 
    "title": "An Improved Interactive Streaming Algorithm for the Distinct Elements   Problem", 
    "arxiv-id": "1402.6800v1", 
    "author": "Ved Prakash", 
    "publish": "2014-02-27T06:31:42Z", 
    "summary": "The exact computation of the number of distinct elements (frequency moment\n$F_0$) is a fundamental problem in the study of data streaming algorithms. We\ndenote the length of the stream by $n$ where each symbol is drawn from a\nuniverse of size $m$. While it is well known that the moments $F_0,F_1,F_2$ can\nbe approximated by efficient streaming algorithms, it is easy to see that exact\ncomputation of $F_0,F_2$ requires space $\\Omega(m)$. In previous work, Cormode\net al. therefore considered a model where the data stream is also processed by\na powerful helper, who provides an interactive proof of the result. They gave\nsuch protocols with a polylogarithmic number of rounds of communication between\nhelper and verifier for all functions in NC. This number of rounds\n$\\left(O(\\log^2 m) \\;\\text{in the case of} \\;F_0 \\right)$ can quickly make such\nprotocols impractical.\n  Cormode et al. also gave a protocol with $\\log m +1$ rounds for the exact\ncomputation of $F_0$ where the space complexity is $O\\left(\\log m \\log n+\\log^2\nm\\right)$ but the total communication $O\\left(\\sqrt{n}\\log m\\left(\\log n+ \\log\nm \\right)\\right)$. They managed to give $\\log m$ round protocols with\n$\\operatorname{polylog}(m,n)$ complexity for many other interesting problems\nincluding $F_2$, Inner product, and Range-sum, but computing $F_0$ exactly with\npolylogarithmic space and communication and $O(\\log m)$ rounds remained open.\n  In this work, we give a streaming interactive protocol with $\\log m$ rounds\nfor exact computation of $F_0$ using $O\\left(\\log m \\left(\\,\\log n + \\log m\n\\log\\log m\\,\\right)\\right)$ bits of space and the communication is $O\\left(\n\\log m \\left(\\,\\log n +\\log^3 m (\\log\\log m)^2 \\,\\right)\\right)$. The update\ntime of the verifier per symbol received is $O(\\log^2 m)$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.0075v1", 
    "title": "Ray tracing -- computing the incomputable?", 
    "arxiv-id": "1404.0075v1", 
    "author": "Ed Blakey", 
    "publish": "2014-04-01T00:37:14Z", 
    "summary": "We recall from previous work a model-independent framework of computational\ncomplexity theory. Notably for the present paper, the framework allows\nformalization of the issues of precision that present themselves when one\nconsiders physical, error-prone (especially analogue rather than digital)\ncomputational systems. We take as a case study the ray-tracing problem, a\nTuring-machine-incomputable problem that can, in apparent violation of the\nChurch-Turing thesis, nonetheless be said to be solved by certain optical\ncomputers; however, we apply the framework of complexity theory so as to\nformalize the intuition that the purported super-Turing power of these\ncomputers in fact vanishes once precision is properly considered."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.0654v1", 
    "title": "Two Structural Results for Low Degree Polynomials and Applications", 
    "arxiv-id": "1404.0654v1", 
    "author": "Avishay Tal", 
    "publish": "2014-04-02T19:05:04Z", 
    "summary": "In this paper, two structural results concerning low degree polynomials over\nfinite fields are given. The first states that over any finite field\n$\\mathbb{F}$, for any polynomial $f$ on $n$ variables with degree $d \\le\n\\log(n)/10$, there exists a subspace of $\\mathbb{F}^n$ with dimension $\\Omega(d\n\\cdot n^{1/(d-1)})$ on which $f$ is constant. This result is shown to be tight.\nStated differently, a degree $d$ polynomial cannot compute an affine disperser\nfor dimension smaller than $\\Omega(d \\cdot n^{1/(d-1)})$. Using a recursive\nargument, we obtain our second structural result, showing that any degree $d$\npolynomial $f$ induces a partition of $F^n$ to affine subspaces of dimension\n$\\Omega(n^{1/(d-1)!})$, such that $f$ is constant on each part.\n  We extend both structural results to more than one polynomial. We further\nprove an analog of the first structural result to sparse polynomials (with no\nrestriction on the degree) and to functions that are close to low degree\npolynomials. We also consider the algorithmic aspect of the two structural\nresults.\n  Our structural results have various applications, two of which are:\n  * Dvir [CC 2012] introduced the notion of extractors for varieties, and gave\nexplicit constructions of such extractors over large fields. We show that over\nany finite field, any affine extractor is also an extractor for varieties with\nrelated parameters. Our reduction also holds for dispersers, and we conclude\nthat Shaltiel's affine disperser [FOCS 2011] is a disperser for varieties over\n$F_2$.\n  * Ben-Sasson and Kopparty [SIAM J. C 2012] proved that any degree 3 affine\ndisperser over a prime field is also an affine extractor with related\nparameters. Using our structural results, and based on the work of Kaufman and\nLovett [FOCS 2008] and Haramaty and Shpilka [STOC 2010], we generalize this\nresult to any constant degree."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.0967v1", 
    "title": "Binary pattern tile set synthesis is NP-hard", 
    "arxiv-id": "1404.0967v1", 
    "author": "Shinnosuke Seki", 
    "publish": "2014-04-03T15:26:13Z", 
    "summary": "In the field of algorithmic self-assembly, a long-standing unproven\nconjecture has been that of the NP-hardness of binary pattern tile set\nsynthesis (2-PATS). The $k$-PATS problem is that of designing a tile assembly\nsystem with the smallest number of tile types which will self-assemble an input\npattern of $k$ colors. Of both theoretical and practical significance, $k$-PATS\nhas been studied in a series of papers which have shown $k$-PATS to be NP-hard\nfor $k = 60$, $k = 29$, and then $k = 11$. In this paper, we close the\nfundamental conjecture that 2-PATS is NP-hard, concluding this line of study.\n  While most of our proof relies on standard mathematical proof techniques, one\ncrucial lemma makes use of a computer-assisted proof, which is a relatively\nnovel but increasingly utilized paradigm for deriving proofs for complex\nmathematical problems. This tool is especially powerful for attacking\ncombinatorial problems, as exemplified by the proof of the four color theorem\nby Appel and Haken (simplified later by Robertson, Sanders, Seymour, and\nThomas) or the recent important advance on the Erd\\H{o}s discrepancy problem by\nKonev and Lisitsa using computer programs. We utilize a massively parallel\nalgorithm and thus turn an otherwise intractable portion of our proof into a\nprogram which requires approximately a year of computation time, bringing the\nuse of computer-assisted proofs to a new scale. We fully detail the algorithm\nemployed by our code, and make the code freely available online."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.1103v1", 
    "title": "A Polylogarithmic PRG for Degree $2$ Threshold Functions in the Gaussian   Setting", 
    "arxiv-id": "1404.1103v1", 
    "author": "Daniel M. Kane", 
    "publish": "2014-04-03T21:34:15Z", 
    "summary": "We devise a new pseudorandom generator against degree 2 polynomial threshold\nfunctions in the Gaussian setting. We manage to achieve $\\epsilon$ error with\nseed length polylogarithmic in $\\epsilon$ and the dimension, and exponential\nimprovement over previous constructions."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.1741v13", 
    "title": "Tighter Fourier Transform Complexity Tradeoffs", 
    "arxiv-id": "1404.1741v13", 
    "author": "Nir Ailon", 
    "publish": "2014-04-07T11:01:15Z", 
    "summary": "The Fourier Transform is one of the most important linear transformations\nused in science and engineering. Cooley and Tukey's Fast Fourier Transform\n(FFT) from 1964 is a method for computing this transformation in time $O(n\\log\nn)$. Achieving a matching lower bound in a reasonable computational model is\none of the most important open problems in theoretical computer science.\n  In 2014, improving on his previous work, Ailon showed that if an algorithm\nspeeds up the FFT by a factor of $b=b(n)\\geq 1$, then it must rely on\ncomputing, as an intermediate \"bottleneck\" step, a linear mapping of the input\nwith condition number $\\Omega(b(n))$. Our main result shows that a factor $b$\nspeedup implies existence of not just one but $\\Omega(n)$ $b$-ill conditioned\nbottlenecks occurring at $\\Omega(n)$ different steps, each causing information\nfrom independent (orthogonal) components of the input to either overflow or\nunderflow. This provides further evidence that beating FFT is hard. Our result\nalso gives the first quantitative tradeoff between computation speed and\ninformation loss in Fourier computation on fixed word size architectures. The\nmain technical result is an entropy analysis of the Fourier transform under\ntransformations of low trace, which is interesting in its own right."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.1950v1", 
    "title": "On the power of homogeneous depth 4 arithmetic circuits", 
    "arxiv-id": "1404.1950v1", 
    "author": "Shubhangi Saraf", 
    "publish": "2014-04-07T21:23:25Z", 
    "summary": "We prove exponential lower bounds on the size of homogeneous depth 4\narithmetic circuits computing an explicit polynomial in $VP$. Our results hold\nfor the {\\it Iterated Matrix Multiplication} polynomial - in particular we show\nthat any homogeneous depth 4 circuit computing the $(1,1)$ entry in the product\nof $n$ generic matrices of dimension $n^{O(1)}$ must have size\n$n^{\\Omega(\\sqrt{n})}$.\n  Our results strengthen previous works in two significant ways.\n  Our lower bounds hold for a polynomial in $VP$. Prior to our work, Kayal et\nal [KLSS14] proved an exponential lower bound for homogeneous depth 4 circuits\n(over fields of characteristic zero) computing a poly in $VNP$. The best known\nlower bounds for a depth 4 homogeneous circuit computing a poly in $VP$ was the\nbound of $n^{\\Omega(\\log n)}$ by [LSS, KLSS14].Our exponential lower bounds\nalso give the first exponential separation between general arithmetic circuits\nand homogeneous depth 4 arithmetic circuits. In particular they imply that the\ndepth reduction results of Koiran [Koi12] and Tavenas [Tav13] are tight even\nfor reductions to general homogeneous depth 4 circuits (without the restriction\nof bounded bottom fanin).\n  Our lower bound holds over all fields. The lower bound of [KLSS14] worked\nonly over fields of characteristic zero. Prior to our work, the best lower\nbound for homogeneous depth 4 circuits over fields of positive characteristic\nwas $n^{\\Omega(\\log n)}$ [LSS, KLSS14]."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.2962v1", 
    "title": "Computing Minimum Tile Sets to Self-Assemble Colors Patterns", 
    "arxiv-id": "1404.2962v1", 
    "author": "Shinnosuke Seki", 
    "publish": "2014-04-10T22:48:39Z", 
    "summary": "Patterned self-assembly tile set synthesis (PATS) aims at finding a minimum\ntile set to uniquely self-assemble a given rectangular color pattern. For $k\n\\ge 1$, $k$-PATS is a variant of PATS that restricts input patterns to those\nwith at most $k$ colors. We prove the {\\bf NP}-hardness of 29-PATS, where the\nbest known is that of 60-PATS."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.3396v3", 
    "title": "On the sum of the L1 influences of bounded functions", 
    "arxiv-id": "1404.3396v3", 
    "author": "Noam Lifshitz", 
    "publish": "2014-04-13T15:57:37Z", 
    "summary": "Let $f\\colon \\{-1,1\\}^n \\to [-1,1]$ have degree $d$ as a multilinear\npolynomial. It is well-known that the total influence of $f$ is at most $d$.\nAaronson and Ambainis asked whether the total $L_1$ influence of $f$ can also\nbe bounded as a function of $d$. Ba\\v{c}kurs and Bavarian answered this\nquestion in the affirmative, providing a bound of $O(d^3)$ for general\nfunctions and $O(d^2)$ for homogeneous functions. We improve on their results\nby providing a bound of $d^2$ for general functions and $O(d\\log d)$ for\nhomogeneous functions. In addition, we prove a bound of $d/(2 \\pi)+o(d)$ for\nmonotone functions, and provide a matching example."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.3684v1", 
    "title": "Diameter Constrained Reliability: Computational Complexity in terms of   the diameter and number of terminals", 
    "arxiv-id": "1404.3684v1", 
    "author": "Pablo Romero", 
    "publish": "2014-04-14T18:29:48Z", 
    "summary": "Let $G=(V,E)$ be a simple graph with $|V|=n$ nodes and $|E|=m$ links, a\nsubset $K \\subseteq V$ of \\emph{terminals}, a vector $p=(p_1,\\ldots,p_m) \\in\n[0,1]^m$ and a positive integer $d$, called \\emph{diameter}. We assume nodes\nare perfect but links fail stochastically and independently, with probabilities\n$q_i=1-p_i$. The \\emph{diameter-constrained reliability} (DCR for short), is\nthe probability that the terminals of the resulting subgraph remain connected\nby paths composed by $d$ links, or less. This number is denoted by\n$R_{K,G}^{d}(p)$.\n  The general DCR computation is inside the class of\n$\\mathcal{N}\\mathcal{P}$-Hard problems, since is subsumes the complexity that a\nrandom graph is connected. In this paper, the computational complexity of\nDCR-subproblems is discussed in terms of the number of terminal nodes $k=|K|$\nand diameter $d$. Either when $d=1$ or when $d=2$ and $k$ is fixed, the DCR is\ninside the class $\\mathcal{P}$ of polynomial-time problems. The DCR turns\n$\\mathcal{N}\\mathcal{P}$-Hard when $k \\geq 2$ is a fixed input parameter and\n$d\\geq 3$.\n  The case where $k=n$ and $d \\geq 2$ is fixed are not studied in prior\nliterature. Here, the $\\mathcal{N}\\mathcal{P}$-Hardness of this case is\nestablished."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.4020v1", 
    "title": "The Complexity of Counting Edge Colorings and a Dichotomy for Some   Higher Domain Holant Problems", 
    "arxiv-id": "1404.4020v1", 
    "author": "Tyson Williams", 
    "publish": "2014-04-15T18:52:42Z", 
    "summary": "We show that an effective version of Siegel's Theorem on finiteness of\ninteger solutions and an application of elementary Galois theory are key\ningredients in a complexity classification of some Holant problems. These\nHolant problems, denoted by Holant(f), are defined by a symmetric ternary\nfunction f that is invariant under any permutation of the k >= 3 domain\nelements. We prove that Holant(f) exhibits a complexity dichotomy. This\ndichotomy holds even when restricted to planar graphs. A special case of this\nresult is that counting edge k-colorings is #P-hard over planar 3-regular\ngraphs for k >= 3. In fact, we prove that counting edge k-colorings is #P-hard\nover planar r-regular graphs for all k >= r >= 3. The problem is\npolynomial-time computable in all other parameter settings. The proof of the\ndichotomy theorem for Holant(f) depends on the fact that a specific polynomial\np(x,y) has an explicitly listed finite set of integer solutions, and the\ndetermination of the Galois groups of some specific polynomials. In the\nprocess, we also encounter the Tutte polynomial, medial graphs, Eulerian\npartitions, Puiseux series, and a certain lattice condition on the (logarithm\nof) the roots of polynomials."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.4852v2", 
    "title": "Polynomials Modulo Composite Numbers: Ax-Katz type theorems for the   structure of their solution sets", 
    "arxiv-id": "1404.4852v2", 
    "author": "Kenneth W. Regan", 
    "publish": "2014-04-18T18:37:40Z", 
    "summary": "We extend the Ax-Katz theorem for a single polynomial from finite fields to\nthe rings Z_m with m composite. This extension not only yields the analogous\nresult, but gives significantly higher divisibility bounds. We conjecture what\ncomputer runs suggest is the optimal result for any m, and prove a special case\nof it. The special case is for m = 2^r and polynomials of degree 2. Our results\nalso yield further properties of the solution spaces. Polynomials modulo\ncomposites are the focus of some computational complexity lower bound\nfrontiers, while those modulo 2^r arise in the simulation of quantum circuits.\nWe give some prospective applications of this research."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.5169v1", 
    "title": "On Uniform Reductions between Direct Product and XOR Lemmas", 
    "arxiv-id": "1404.5169v1", 
    "author": "Ragesh Jaiswal", 
    "publish": "2014-04-21T10:41:32Z", 
    "summary": "There is a close connection between Direct Product and XOR lemmas in the\nsense that in many settings, we can prove one given the other. The known\nreductions that are used for the above purpose are either in the non-uniform\nsetting or give non-matching parameters. By non-matching parameter we mean that\n$k$-wise Direct Product lemma implies $k'$-wise XOR lemma (and vice versa) for\n$k \\neq k'$. In this work, we discuss reductions between $k$-wise Direct\nProduct and $k$-wise XOR lemmas. That is, we show that if the $k$-wise direct\nproduct lemma holds, then so does the $k$-wise XOR lemma and vice versa. We\nshow that even though there is a perfectly uniform reduction in one direction,\nthe reduction in the other direction requires some amount of non-uniformity. We\ngive reductions in both directions matching information-theoretic bounds up to\npolynomial factors. Our techniques also give a small quantitative improvement\nover the known results about proving $k$-wise XOR lemma using $2k$-wise Direct\nProduct lemma."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.5352v2", 
    "title": "Critique of J. Kim's \"P is not equal to NP by Modus Tollens\"", 
    "arxiv-id": "1404.5352v2", 
    "author": "Yibo Zhou", 
    "publish": "2014-04-22T00:05:19Z", 
    "summary": "This paper is a critique of version three of Joonmo Kim's paper entitled \"P\nis not equal to NP by Modus Tollens. [arXiv:1403.4143v3]\" After summarizing\nKim's proof, we note that the logic that Kim uses is inconsistent, which\nprovides evidence that the proof is invalid. To show this, we will consider two\nreasonable interpretations of Kim's definitions, and show that \"P is not equal\nto NP\" does not seem to follow in an obvious way using any of them."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.7053v1", 
    "title": "Computable real function F such that F is not polynomial time computable   on [0,1]", 
    "arxiv-id": "1404.7053v1", 
    "author": "Sergey V. Yakhontov", 
    "publish": "2014-04-25T02:31:06Z", 
    "summary": "A computable real function F on [0,1] is constructed such that there exists\nan exponential time algorithm for the evaluation of the function on [0,1] on\nTuring machine but there does not exist any polynomial time algorithm for the\nevaluation of the function on [0,1] on Turing machine (moreover, it holds for\nany rational point on (0,1))"
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.143.3", 
    "link": "http://arxiv.org/pdf/1404.7443v2", 
    "title": "Depth Lower Bounds against Circuits with Sparse Orientation", 
    "arxiv-id": "1404.7443v2", 
    "author": "Jayalal Sarma", 
    "publish": "2014-04-29T17:57:47Z", 
    "summary": "We study depth lower bounds against non-monotone circuits, parametrized by a\nnew measure of non-monotonicity: the orientation of a function $f$ is the\ncharacteristic vector of the minimum sized set of negated variables needed in\nany DeMorgan circuit computing $f$. We prove trade-off results between the\ndepth and the weight/structure of the orientation vectors in any circuit $C$\ncomputing the Clique function on an $n$ vertex graph. We prove that if $C$ is\nof depth $d$ and each gate computes a Boolean function with orientation of\nweight at most $w$ (in terms of the inputs to $C$), then $d \\times w$ must be\n$\\Omega(n)$. In particular, if the weights are $o(\\frac{n}{\\log^k n})$, then\n$C$ must be of depth $\\omega(\\log^k n)$. We prove a barrier for our general\ntechnique. However, using specific properties of the Clique function and the\nKarchmer-Wigderson framework (Karchmer and Wigderson, 1988), we go beyond the\nlimitations and obtain lower bounds when the weight restrictions are less\nstringent. We then study the depth lower bounds when the structure of the\norientation vector is restricted. Asymptotic improvements to our results (in\nthe restricted setting), separates NP from NC. As our main tool, we generalize\nKarchmer-Wigderson gamefor monotone functions to work for non-monotone circuits\nparametrized by the weight/structure of the orientation. We also prove\nstructural results about orientation and prove connections between number of\nnegations and weight of orientations required to compute a function."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-17142-5_12", 
    "link": "http://arxiv.org/pdf/1406.0073v3", 
    "title": "Size of Sets with Small Sensitivity: a Generalization of Simon's Lemma", 
    "arxiv-id": "1406.0073v3", 
    "author": "Jevg\u0113nijs Vihrovs", 
    "publish": "2014-05-31T12:31:08Z", 
    "summary": "We study the structure of sets $S\\subseteq\\{0, 1\\}^n$ with small sensitivity.\nThe well-known Simon's lemma says that any $S\\subseteq\\{0, 1\\}^n$ of\nsensitivity $s$ must be of size at least $2^{n-s}$. This result has been useful\nfor proving lower bounds on sensitivity of Boolean functions, with applications\nto the theory of parallel computing and the \"sensitivity vs. block sensitivity\"\nconjecture.\n  In this paper, we take a deeper look at the size of such sets and their\nstructure. We show an unexpected \"gap theorem\": if $S\\subseteq\\{0, 1\\}^n$ has\nsensitivity $s$, then we either have $|S|=2^{n-s}$ or $|S|\\geq \\frac{3}{2}\n2^{n-s}$. This is shown via classifying such sets into sets that can be\nconstructed from low-sensitivity subsets of $\\{0, 1\\}^{n'}$ for $n'<n$ and\nirreducible sets which cannot be constructed in such a way and then proving a\nlower bound on the size of irreducible sets.\n  This provides new insights into the structure of low sensitivity subsets of\nthe Boolean hypercube $\\{0, 1\\}^n$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-17142-5_12", 
    "link": "http://arxiv.org/pdf/1406.0879v3", 
    "title": "Computing rank of finite algebraic structures with limited   nondeterminism", 
    "arxiv-id": "1406.0879v3", 
    "author": "Jeffrey Finkelstein", 
    "publish": "2014-06-03T21:08:56Z", 
    "summary": "The rank of a finite algebraic structure with a single binary operation is\nthe minimum number of elements needed to express every other element under the\nclosure of the operation. In the case of groups, the previous best algorithm\nfor computing rank used polylogarithmic space. We reduce the best upper bounds\non the complexity of computing rank for groups and for quasigroups. This paper\nproves that the rank problem for these algebraic structures can be verified by\nhighly restricted models of computation given only very short certificates of\ncorrectness.\n  Specifically, we prove that the problem of deciding whether the rank of a\nfinite quasigroup, given as a Cayley table, is smaller than a specified number\nis decidable by a circuit of depth $O(\\log \\log n)$ augmented with $O(\\log^2\nn)$ nondeterministic bits. Furthermore, if the quasigroup is a group, then the\nproblem is also decidable by a Turing machine using $O(\\log n)$ space and\n$O(\\log^2 n)$ bits of nondeterminism with the ability to read the\nnondeterministic bits multiple times. Finally, we provide similar results for\nrelated problems on other algebraic structures and other kinds of rank. These\nnew upper bounds are significant improvements, especially for groups. In\ngeneral, the lens of limited nondeterminism provides an easy way to improve\nmany simple algorithms, like the ones presented here, and we suspect it will be\nespecially useful for other algebraic algorithms."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-17142-5_12", 
    "link": "http://arxiv.org/pdf/1406.3065v2", 
    "title": "Lower Bounds for Tropical Circuits and Dynamic Programs", 
    "arxiv-id": "1406.3065v2", 
    "author": "Stasys Jukna", 
    "publish": "2014-06-11T20:58:10Z", 
    "summary": "Tropical circuits are circuits with Min and Plus, or Max and Plus operations\nas gates. Their importance stems from their intimate relation to dynamic\nprogramming algorithms. The power of tropical circuits lies somewhere between\nthat of monotone boolean circuits and monotone arithmetic circuits. In this\npaper we present some lower bounds arguments for tropical circuits, and hence,\nfor dynamic programs."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-17142-5_12", 
    "link": "http://arxiv.org/pdf/1406.3247v1", 
    "title": "Relating the Time Complexity of Optimization Problems in Light of the   Exponential-Time Hypothesis", 
    "arxiv-id": "1406.3247v1", 
    "author": "Hannes Uppman", 
    "publish": "2014-06-12T14:13:20Z", 
    "summary": "Obtaining lower bounds for NP-hard problems has for a long time been an\nactive area of research. Recent algebraic techniques introduced by Jonsson et\nal. (SODA 2013) show that the time complexity of the parameterized SAT($\\cdot$)\nproblem correlates to the lattice of strong partial clones. With this ordering\nthey isolated a relation $R$ such that SAT($R$) can be solved at least as fast\nas any other NP-hard SAT($\\cdot$) problem. In this paper we extend this method\nand show that such languages also exist for the max ones problem\n(MaxOnes($\\Gamma$)) and the Boolean valued constraint satisfaction problem over\nfinite-valued constraint languages (VCSP($\\Delta$)). With the help of these\nlanguages we relate MaxOnes and VCSP to the exponential time hypothesis in\nseveral different ways."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-319-17142-5_12", 
    "link": "http://arxiv.org/pdf/1406.3700v2", 
    "title": "The Parameterized Complexity of k-Biclique", 
    "arxiv-id": "1406.3700v2", 
    "author": "Bingkai Lin", 
    "publish": "2014-06-14T08:20:39Z", 
    "summary": "Given a graph $G$ and a parameter $k$, the $k$-biclique problem asks whether\n$G$ contains a complete bipartite subgraph $K_{k,k}$. This is the most easily\nstated problem on graphs whose parameterized complexity is still unknown. We\nprovide an fpt-reduction from $k$-clique to $k$-biclique, thus solving this\nlongstanding open problem.\n  Our reduction use a class of bipartite graphs with a threshold property of\nindependent interest. More specifically, for positive integers $n$, $s$ and\n$t$, we consider a bipartite graph $G=(A\\;\\dot\\cup\\;B, E)$ such that $A$ can be\npartitioned into $A=V_1\\;\\dot\\cup \\;V_2\\;\\dot\\cup\\cdots\\dot\\cup\\; V_n$ and for\nevery $s$ distinct indices $i_1\\cdots i_s$, there exist $v_{i_1}\\in\nV_{i_1}\\cdots v_{i_s}\\in V_{i_s}$ such that $v_{i_1}\\cdots v_{i_s}$ have at\nleast $t+1$ common neighbors in $B$; on the other hand, every $s+1$ distinct\nvertices in $A$ have at most $t$ common neighbors in $B$.\n  Using the Paley-type graphs and Weil's character sum theorem, we show that\nfor $t=(s+1)!$ and $n$ large enough, such threshold bipartite graphs can be\ncomputed in $n^{O(1)}$. One corollary of our reduction is that there is no\n$f(k)\\cdot n^{o(k)}$ time algorithm to decide whether a graph contains a\nsubgraph isomorphic to $K_{k!,k!}$ unless the ETH(Exponential Time Hypothesis)\nfails. We also provide a probabilistic construction with better parameters\n$t=\\Theta(s^2)$, which indicates that $k$-biclique has no $f(k)\\cdot\nn^{o(\\sqrt{k})}$-time algorithm unless 3-SAT with $m$ clauses can be solved in\n$2^{o(m)}$-time with high probability. Our result also implies the dichotomy\nclassification of the parameterized complexity of cardinality constrain\nsatisfaction problem and the inapproximability of maximum $k$-intersection\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.3715v2", 
    "title": "Fourier spectra of measures associated with algorithmically random   Brownian motion", 
    "arxiv-id": "1406.3715v2", 
    "author": "George Davie", 
    "publish": "2014-06-14T10:48:44Z", 
    "summary": "In this paper we study the behaviour at infinity of the Fourier transform of\nRadon measures supported by the images of fractal sets under an algorithmically\nrandom Brownian motion. We show that, under some computability conditions on\nthese sets, the Fourier transform of the associated measures have, relative to\nthe Hausdorff dimensions of these sets, optimal asymptotic decay at infinity.\nThe argument relies heavily on a direct characterisation, due to Asarin and\nPokrovskii, of algorithmically random Brownian motion in terms of the prefix\nfree Kolmogorov complexity of finite binary sequences. The study also\nnecessitates a closer look at the potential theory over fractals from a\ncomputable point of view."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.4106v2", 
    "title": "Beautiful Structures: An Appreciation of the Contributions of Alan   Selman", 
    "arxiv-id": "1406.4106v2", 
    "author": "Lane A. Hemaspaandra", 
    "publish": "2014-06-16T19:16:33Z", 
    "summary": "Professor Alan Selman has been a giant in the field of computational\ncomplexity for the past forty years. This article is an appreciation, on the\noccasion of his retirement, of some of the most lovely concepts and results\nthat Alan has contributed to the field."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.5336v1", 
    "title": "On the Complexity of Trial and Error for Constraint Satisfaction   Problems", 
    "arxiv-id": "1406.5336v1", 
    "author": "Aarthi Sundaram", 
    "publish": "2014-06-20T09:49:08Z", 
    "summary": "In a recent work of Bei, Chen and Zhang (STOC 2013), a trial and error model\nof computing was introduced, and applied to some constraint satisfaction\nproblems. In this model the input is hidden by an oracle which, for a candidate\nassignment, reveals some information about a violated constraint if the\nassignment is not satisfying. In this paper we initiate a systematic study of\nconstraint satisfaction problems in the trial and error model. To achieve this,\nwe first adopt a formal framework for CSPs, and based on this framework we\ndefine several types of revealing oracles. Our main contribution is to develop\na transfer theorem for each type of the revealing oracle, under a broad class\nof parameters. To any hidden CSP with a specific type of revealing oracle, the\ntransfer theorem associates another, potentially harder CSP in the normal\nsetting, such that their complexities are polynomial time equivalent. This in\nprinciple transfers the study of a large class of hidden CSPs, possibly with a\npromise on the instances, to the study of CSPs in the normal setting. We then\napply the transfer theorems to get polynomial-time algorithms or hardness\nresults for hidden CSPs, including satisfaction problems, monotone graph\nproperties, isomorphism problems, and the exact version of the Unique Games\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.5791v1", 
    "title": "Computational Complexity of Certifying Restricted Isometry Property", 
    "arxiv-id": "1406.5791v1", 
    "author": "Yi Wu", 
    "publish": "2014-06-23T02:08:08Z", 
    "summary": "Given a matrix $A$ with $n$ rows, a number $k<n$, and $0<\\delta < 1$, $A$ is\n$(k,\\delta)$-RIP (Restricted Isometry Property) if, for any vector $x \\in\n\\mathbb{R}^n$, with at most $k$ non-zero co-ordinates, $$(1-\\delta) \\|x\\|_2\n\\leq \\|A x\\|_2 \\leq (1+\\delta)\\|x\\|_2$$ In many applications, such as\ncompressed sensing and sparse recovery, it is desirable to construct RIP\nmatrices with a large $k$ and a small $\\delta$. Given the efficacy of random\nconstructions in generating useful RIP matrices, the problem of certifying the\nRIP parameters of a matrix has become important.\n  In this paper, we prove that it is hard to approximate the RIP parameters of\na matrix assuming the Small-Set-Expansion-Hypothesis. Specifically, we prove\nthat for any arbitrarily large constant $C>0$ and any arbitrarily small\nconstant $0<\\delta<1$, there exists some $k$ such that given a matrix $M$, it\nis SSE-Hard to distinguish the following two cases:\n  - (Highly RIP) $M$ is $(k,\\delta)$-RIP.\n  - (Far away from RIP) $M$ is not $(k/C, 1-\\delta)$-RIP.\n  Most of the previous results on the topic of hardness of RIP certification\nonly hold for certification when $\\delta=o(1)$. In practice, it is of interest\nto understand the complexity of certifying a matrix with $\\delta$ being close\nto $\\sqrt{2}-1$, as it suffices for many real applications to have matrices\nwith $\\delta = \\sqrt{2}-1$. Our hardness result holds for any constant\n$\\delta$. Specifically, our result proves that even if $\\delta$ is indeed very\nsmall, i.e. the matrix is in fact \\emph{strongly RIP}, certifying that the\nmatrix exhibits \\emph{weak RIP} itself is SSE-Hard.\n  In order to prove the hardness result, we prove a variant of the Cheeger's\nInequality for sparse vectors."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.5970v1", 
    "title": "A Lower Bound for Boolean Satisfiability on Turing Machines", 
    "arxiv-id": "1406.5970v1", 
    "author": "Samuel C. Hsieh", 
    "publish": "2014-06-23T16:30:57Z", 
    "summary": "We establish a lower bound for deciding the satisfiability of the conjunction\nof any two Boolean formulas from a set called a full representation of Boolean\nfunctions of $n$ variables - a set containing a Boolean formula to represent\neach Boolean function of $n$ variables. The contradiction proof first assumes\nthat there exists a Turing machine with $k$ symbols in its tape alphabet that\ncorrectly decides the satisfiability of the conjunction of any two Boolean\nformulas from such a set by making fewer than $2^nlog_k2$ moves. By using\nmultiple runs of this Turing machine, with one run for each Boolean function of\n$n$ variables, the proof derives a contradiction by showing that this Turing\nmachine is unable to correctly decide the satisfiability of the conjunction of\nat least one pair of Boolean formulas from a full representation of\n$n$-variable Boolean functions if the machine makes fewer than $2^nlog_k2$\nmoves. This lower bound holds for any full representation of Boolean functions\nof $n$ variables, even if a full representation consists solely of minimized\nBoolean formulas derived by a Boolean minimization method. We discuss why the\nlower bound fails to hold for satisfiability of certain restricted formulas,\nsuch as 2CNF satisfiability, XOR-SAT, and HORN-SAT. We also relate the lower\nbound to 3CNF satisfiability. The lower bound does not depend on sequentiality\nof access to the tape squares and will hold even if a machine is capable of\nnon-sequential access."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.6353v1", 
    "title": "A Lower Bound of $2^n$ Conditional Branches for Boolean Satisfiability   on Post Machines", 
    "arxiv-id": "1406.6353v1", 
    "author": "Samuel C. Hsieh", 
    "publish": "2014-06-24T19:50:27Z", 
    "summary": "We establish a lower bound of $2^n$ conditional branches for deciding the\nsatisfiability of the conjunction of any two Boolean formulas from a set called\na full representation of Boolean functions of $n$ variables - a set containing\na Boolean formula to represent each Boolean function of $n$ variables. The\ncontradiction proof first assumes that there exists a Post machine (Post's\nFormulation 1) that correctly decides the satisfiability of the conjunction of\nany two Boolean formulas from such a set by following an execution path that\nincludes fewer than $2^n$ conditional branches. By using multiple runs of this\nPost machine, with one run for each Boolean function of $n$ variables, the\nproof derives a contradiction by showing that this Post machine is unable to\ncorrectly decide the satisfiability of the conjunction of at least one pair of\nBoolean formulas from a full representation of $n$-variable Boolean functions\nif the machine executes fewer than $2^n$ conditional branches. This lower bound\nof $2^n$ conditional branches holds for any full representation of Boolean\nfunctions of $n$ variables, even if a full representation consists solely of\nminimized Boolean formulas derived by a Boolean minimization method. We discuss\nwhy the lower bound fails to hold for satisfiability of certain restricted\nformulas, such as 2CNF satisfiability, XOR-SAT, and HORN-SAT. We also relate\nthe lower bound to 3CNF satisfiability. The lower bound does not depend on\nsequentiality of access to the boxes in the symbol space and will hold even if\na machine is capable of non-sequential access."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.7398v2", 
    "title": "A framework for good SAT translations, with applications to CNF   representations of XOR constraints", 
    "arxiv-id": "1406.7398v2", 
    "author": "Oliver Kullmann", 
    "publish": "2014-06-28T13:28:10Z", 
    "summary": "We present a general framework for good CNF-representations of boolean\nconstraints, to be used for translating decision problems into SAT problems\n(i.e., deciding satisfiability for conjunctive normal forms). We apply it to\nthe representation of systems of XOR-constraints, also known as systems of\nlinear equations over the two-element field, or systems of parity constraints.\n  The general framework defines the notion of \"representation\", and provides\nseveral methods to measure the quality of the representation by the complexity\n(\"hardness\") needed for making implicit \"knowledge\" of the representation\nexplicit (to a SAT-solving mechanism). We obtain general upper and lower\nbounds.\n  Applied to systems of XOR-constraints, we show a super-polynomial lower bound\non \"good\" representations under very general circumstances. A corresponding\nupper bound shows fixed-parameter tractability in the number of constraints.\n  The measurement underlying this upper bound ignores the auxiliary variables\nneeded for shorter representations of XOR-constraints. Improved upper bounds\n(for special cases) take them into account, and a rich picture begins to\nemerge, under the various hardness measurements."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1406.7535v1", 
    "title": "Hitting-sets for ROABP and Sum of Set-Multilinear circuits", 
    "arxiv-id": "1406.7535v1", 
    "author": "Nitin Saxena", 
    "publish": "2014-06-29T18:36:11Z", 
    "summary": "We give a $n^{O(\\log n)}$-time ($n$ is the input size) blackbox polynomial\nidentity testing algorithm for unknown-order read-once oblivious algebraic\nbranching programs (ROABP). The best result known for this class was\n$n^{O(\\log^2 n)}$ due to Forbes-Saptharishi-Shpilka (STOC 2014), and that too\nonly for multilinear ROABP. We get rid of their exponential dependence on the\nindividual degree. With this, we match the time-complexity for the unknown\norder ROABP with the known order ROABP (due to Forbes-Shpilka (FOCS 2013)) and\nalso with the depth-$3$ set-multilinear circuits (due to Agrawal-Saha-Saxena\n(STOC 2013)). Our proof is simpler and involves a new technique called basis\nisolation.\n  The depth-$3$ model has recently gained much importance, as it has become a\nstepping-stone to understanding general arithmetic circuits. Its restriction to\nmultilinearity has known exponential lower bounds but no nontrivial blackbox\nidentity tests. In this paper, we take a step towards designing such\nhitting-sets. We give the first subexponential whitebox PIT for the sum of\nconstantly many set-multilinear depth-$3$ circuits. To achieve this, we define\nnotions of distance and base sets. Distance, for a multilinear depth-$3$\ncircuit, measures how far are the partitions from a mere refinement. We design\na hitting-set in time $n^{O(d \\log n)}$ for $d$-distance. Further, we give an\nextension of our result to models where the distance is large but it is small\nwhen restricted to certain base sets (of variables).\n  We also explore a new model of ROABP where the factor-matrices are invertible\n(called invertible-factor ROABP). We design a hitting-set in time\npoly($n^{w^2}$) for width-$w$ invertible-factor ROABP. Further, we could do\nwithout the invertibility restriction when $w=2$. Previously, the best result\nfor width-$2$ ROABP was quasi-polynomial time (Forbes-Saptharishi-Shpilka, STOC\n2014)."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1408.0262v4", 
    "title": "Reducing uniformity in Khot-Saket hypergraph coloring hardness   reductions", 
    "arxiv-id": "1408.0262v4", 
    "author": "Girish Varma", 
    "publish": "2014-08-01T18:49:47Z", 
    "summary": "In a recent result, Khot and Saket [FOCS 2014] proved the quasi-NP-hardness\nof coloring a 2-colorable 12-uniform hypergraph with $2^{(\\log n)^{\\Omega(1)}}$\ncolors. This result was proved using a novel outer PCP verifier which had a\nstrong soundness guarantee. In this note, we show that we can reduce the arity\nof their result by modifying their 12-query inner verifier to an 8-query inner\nverifier based on the hypergraph coloring hardness reductions of Guruswami et.\nal. [STOC 2014]. More precisely, we prove quasi-NP-hardness of the following\nproblems on n-vertex hypergraphs.\n  - Coloring a 2-colorable 8-uniform hypergraph with $2^{(\\log n)^{\\Omega(1)}}$\ncolors.\n  - Coloring a 4-colorable 4-uniform hypergraph with $2^{(\\log n)^{\\Omega(1)}}$\ncolors."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1408.0828v1", 
    "title": "Pre-Reduction Graph Products: Hardnesses of Properly Learning DFAs and   Approximating EDP on DAGs", 
    "arxiv-id": "1408.0828v1", 
    "author": "Danupon Nanongkai", 
    "publish": "2014-08-04T22:01:59Z", 
    "summary": "The study of graph products is a major research topic and typically concerns\nthe term $f(G*H)$, e.g., to show that $f(G*H)=f(G)f(H)$. In this paper, we\nstudy graph products in a non-standard form $f(R[G*H]$ where $R$ is a\n\"reduction\", a transformation of any graph into an instance of an intended\noptimization problem. We resolve some open problems as applications.\n  (1) A tight $n^{1-\\epsilon}$-approximation hardness for the minimum\nconsistent deterministic finite automaton (DFA) problem, where $n$ is the\nsample size. Due to Board and Pitt [Theoretical Computer Science 1992], this\nimplies the hardness of properly learning DFAs assuming $NP\\neq RP$ (the\nweakest possible assumption).\n  (2) A tight $n^{1/2-\\epsilon}$ hardness for the edge-disjoint paths (EDP)\nproblem on directed acyclic graphs (DAGs), where $n$ denotes the number of\nvertices.\n  (3) A tight hardness of packing vertex-disjoint $k$-cycles for large $k$.\n  (4) An alternative (and perhaps simpler) proof for the hardness of properly\nlearning DNF, CNF and intersection of halfspaces [Alekhnovich et al., FOCS 2004\nand J. Comput.Syst.Sci. 2008]."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1408.2362v4", 
    "title": "FP//LINSPACE computability of Riemann zeta function in Ko-Friedman model", 
    "arxiv-id": "1408.2362v4", 
    "author": "Sergey V. Yakhontov", 
    "publish": "2014-08-11T10:26:23Z", 
    "summary": "In the present paper, we construct an algorithm for the evaluation of real\nRiemann zeta function $\\zeta(s)$ for all real $s$, $s>1$, in polynomial time\nand linear space on Turing machines in Ko-Friedman model. The algorithms is\nbased on a series expansion of real Riemann zeta function $\\zeta(s)$ (the\nseries globally convergents) and uses algorithms for the evaluation of real\nfunction $(1+x)^h$ and hypergeometric series in polynomial time and linear\nspace.\n  The algorithm from the present paper modified in an obvious way to work with\nthe complex numbers can be used to evaluate complex Riemann zeta function\n$\\zeta(s)$ for $s=\\sigma+\\mathbf{i}t$, $\\sigma\\ne 1$ (so, also for the case of\n$\\sigma<1$), in polynomial time and linear space in $n$ wherein $2^{-n}$ is a\nprecision of the computation; the modified algorithm will be also polynomial\ntime and linear space in $\\lceil \\log_2(t)\\rceil$ and exponential time and\nexponential space in $\\lceil \\log_2(\\sigma)\\rceil$."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-10(3:20)2014", 
    "link": "http://arxiv.org/pdf/1408.2364v3", 
    "title": "Notes on space complexity of integration of computable real functions in   Ko-Friedman model", 
    "arxiv-id": "1408.2364v3", 
    "author": "Sergey V. Yakhontov", 
    "publish": "2014-08-11T10:26:50Z", 
    "summary": "In the present paper it is shown that real function $g(x)=\\int_{0}^{x}f(t)dt$\nis a linear-space computable real function on interval $[0,1]$ if $f$ is a\nlinear-space computable $C^2[0,1]$ real function on interval $[0,1]$, and this\nresult does not depend on any open question in the computational complexity\ntheory. The time complexity of computable real functions and integration of\ncomputable real functions is considered in the context of Ko-Friedman model\nwhich is based on the notion of Cauchy functions computable by Turing machines.\n  In addition, a real computable function $f$ is given such that\n$\\int_{0}^{1}f\\in FDSPACE(n^2)_{C[a,b]}$ but $\\int_{0}^{1}f\\notin FP_{C[a,b]}$\nif $FP\\ne#P$."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1408.2685v3", 
    "title": "Computing with Coloured Tangles", 
    "arxiv-id": "1408.2685v3", 
    "author": "Daniel Moskovich", 
    "publish": "2014-08-12T10:33:23Z", 
    "summary": "We suggest a diagrammatic model of computation based on an axiom of\ndistributivity. A diagram of a decorated coloured tangle, similar to those that\nappear in low dimensional topology, plays the role of a circuit diagram.\nEquivalent diagrams represent bisimilar computations. We prove that our model\nof computation is Turing complete, and that with bounded resources it can\nmoreover decide any language in complexity class IP, sometimes with better\nperformance parameters than corresponding classical protocols."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1408.3510v1", 
    "title": "Faster FPT Algorithm for Graph Isomorphism Parameterized by Eigenvalue   Multiplicity", 
    "arxiv-id": "1408.3510v1", 
    "author": "Gaurav Rattan", 
    "publish": "2014-08-15T11:21:46Z", 
    "summary": "We give a $O^*(k^{O(k)})$ time isomorphism testing algorithm for graphs of\neigenvalue multiplicity bounded by $k$ which improves on the previous best\nrunning time bound of $O^*(2^{O(k^2/\\log k)})$."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1408.3690v1", 
    "title": "Conservative constraint satisfaction re-revisited", 
    "arxiv-id": "1408.3690v1", 
    "author": "Andrei A. Bulatov", 
    "publish": "2014-08-16T01:10:16Z", 
    "summary": "Conservative constraint satisfaction problems (CSPs) constitute an important\nparticular case of the general CSP, in which the allowed values of each\nvariable can be restricted in an arbitrary way. Problems of this type are well\nstudied for graph homomorphisms. A dichotomy theorem characterizing\nconservative CSPs solvable in polynomial time and proving that the remaining\nones are NP-complete was proved by Bulatov in 2003. Its proof, however, is\nquite long and technical. A shorter proof of this result based on the absorbing\nsubuniverses technique was suggested by Barto in 2011. In this paper we give a\nshort elementary prove of the dichotomy theorem for the conservative CSP."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1408.5282v7", 
    "title": "On the Tractability of Un/Satisfiability", 
    "arxiv-id": "1408.5282v7", 
    "author": "Latif Salum", 
    "publish": "2014-08-22T12:31:37Z", 
    "summary": "The Petri net approach proves to be effective to tackle the $P$ vs $NP$\nproblem. A safe acyclic Petri net (PN) is associated with some Exactly-1 3SAT\nformula, in which a clause is an exactly-1 disjunction $\\dot{\\vee}$ of\nliterals. A clause also corresponds to a set of conflicting transitions in the\nPN. Some 2SAT/XOR-SAT formula arisen in the inversed PN checks if the truth\nassignment of a literal (a transition firing) $z_v$ is \"incompatible\" for the\nsatisfiability of the 3SAT formula (the reachability of the target state in the\ninversed PN). If $z_v$ is incompatible, then $z_v$ is discarded and\n$\\overline{z}_v$ becomes true. Therefore, a clause $(\\overline{z}_v \\dot{\\vee}\nz_i \\dot{\\vee} z_j)$ reduces to the conjunction $(\\overline{z}_v \\wedge\n\\overline{z}_i \\wedge \\overline{z}_j)$, and a 3-literal clause $(z_v \\dot{\\vee}\nz_u \\dot{\\vee} z_x)$ reduces to the 2-literal clause $(z_u \\oplus z_x)$. This\nreduction facilitates checking un/satisfiability; the 3SAT formula is\nun/satisfiable iff the target state of the inversed PN is un/reachable. The\nsolution complexity is $O(n^5)$. Therefore, $P = NP = \\text{co}NP$."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1408.6315v1", 
    "title": "2048 is (PSPACE) Hard, but Sometimes Easy", 
    "arxiv-id": "1408.6315v1", 
    "author": "Rahul Mehta", 
    "publish": "2014-08-27T05:23:43Z", 
    "summary": "We prove that a variant of 2048, a popular online puzzle game, is\nPSPACE-Complete. Our hardness result holds for a version of the problem where\nthe player has oracle access to the computer player's moves. Specifically, we\nshow that for an $n \\times n$ game board $\\mathcal{G}$, computing a sequence of\nmoves to reach a particular configuration $\\mathbb{C}$ from an initial\nconfiguration $\\mathbb{C}_0$ is PSPACE-Complete. Our reduction is from\nNondeterministic Constraint Logic (NCL). We also show that determining whether\nor not there exists a fixed sequence of moves $\\mathcal{S} \\in \\{\\Uparrow,\n\\Downarrow, \\Leftarrow, \\Rightarrow\\}^k$ of length $k$ that results in a\nwinning configuration for an $n \\times n$ game board is fixed-parameter\ntractable (FPT). We describe an algorithm to solve this problem in $O(4^k n^2)$\ntime."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1408.6334v2", 
    "title": "A constructive proof presenting languages in $\u03a3_2^P$ that cannot be   decided by circuit families of size $n^k$", 
    "arxiv-id": "1408.6334v2", 
    "author": "Sunny Daniels", 
    "publish": "2014-08-27T07:30:50Z", 
    "summary": "As far as I know, at the time that I originally devised this result (1998),\nthis was the first constructive proof that, for any integer $k$, there is a\nlanguage in $\\Sigma_2^P$ that cannot be simulated by a family of logic circuits\nof size $n^k$. However, this result had previously been proved\nnon-constructively: see Cai and Watanabe [CW08] for more information on the\nhistory of this problem.\n  This constructive proof is based upon constructing a language $\\Gamma$\nderived from the satisfiabiility problem, and a language $\\Lambda_k$ defined by\nan alternating Turing machine. We show that the union of $\\Gamma$ and\n$\\Lambda_k$ cannot be simulated by circuits of size $n^k$."
},{
    "category": "cs.CC", 
    "doi": "10.3390/sym7031289", 
    "link": "http://arxiv.org/pdf/1409.0375v3", 
    "title": "Polynomial solvability of $NP$-complete problems", 
    "arxiv-id": "1409.0375v3", 
    "author": "Anatoly Panyukov", 
    "publish": "2014-09-01T12:02:51Z", 
    "summary": "A polynomial algorithm for solving \"Hamiltonian circuit\" problem is presented\nin the paper. Computational complexity of the algorithm is equal\n$O(n^{8}{\\log_2}^2n)$ where $n$ is the cardinality of the observed graph vertex\nset. Thus the polynomial solvability for ${\\mathcal NP}$-complete problems is\nproved."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2016.02.002", 
    "link": "http://arxiv.org/pdf/1409.0451v4", 
    "title": "Computational complexity of solving polynomial differential equations   over unbounded domains", 
    "arxiv-id": "1409.0451v4", 
    "author": "Daniel S. Gra\u00e7a", 
    "publish": "2014-09-01T15:22:54Z", 
    "summary": "In this paper we investigate the computational complexity of solving ordinary\ndifferential equations (ODEs) $y^{\\prime}=p(y)$ over \\emph{unbounded time\ndomains}, where $p$ is a vector of polynomials. Contrarily to the bounded\n(compact) time case, this problem has not been well-studied, apparently due to\nthe \"intuition\" that it can always be reduced to the bounded case by using\nrescaling techniques. However, as we show in this paper, rescaling techniques\ndo not seem to provide meaningful insights on the complexity of this problem,\nsince the use of such techniques introduces a dependence on parameters which\nare hard to compute.\n  We present algorithms which numerically solve these ODEs over unbounded time\ndomains. These algorithms have guaranteed accuracy, i.e. given some arbitrarily\nlarge time $t$ and error bound $\\varepsilon$ as input, they will output a value\n$\\tilde{y}$ which satisfies $\\|y(t)-\\tilde{y}\\|\\leq\\varepsilon$. We analyze the\ncomplexity of these algorithms and show that they compute $\\tilde{y}$ in time\npolynomial in several quantities including the time $t$, the accuracy of the\noutput $\\varepsilon$ and the length of the curve $y$ from $0$ to $t$, assuming\nit exists until time $t$. We consider both algebraic complexity and bit\ncomplexity."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2016.02.002", 
    "link": "http://arxiv.org/pdf/1409.0742v3", 
    "title": "New Algorithms and Hard Instances for Non-Commutative Computation", 
    "arxiv-id": "1409.0742v3", 
    "author": "B. V. Raghavendra Rao", 
    "publish": "2014-09-02T15:05:07Z", 
    "summary": "Motivated by the recent developments on the complexity of\nnon-com\\-mu\\-ta\\-tive determinant and permanent [Chien et al.\\ STOC 2011,\nBl\\\"aser ICALP 2013, Gentry CCC 2014] we attempt at obtaining a tight\ncharacterization of hard instances of non-commutative permanent.\n  We show that computing Cayley permanent and determinant on weight\\-ed\nadjacency matrices of graphs of component size six is $\\#{\\sf P}$ complete on\nalgebras that contain $2\\times 2$ matrices and the permutation group $S_3$.\nAlso, we prove a lower bound of $2^{\\Omega(n)}$ on the size of branching\nprograms computing the Cayley permanent on adjacency matrices of graphs with\ncomponent size bounded by two. Further, we observe that the lower bound holds\nfor almost all graphs of component size two.\n  On the positive side, we show that the Cayley permanent on graphs of\ncomponent size $c$ can be computed in time $n^{c{\\sf poly}(t)}$, where $t$ is a\nparameter depending on the labels of the vertices.\n  Finally, we exhibit polynomials that are equivalent to the Cayley permanent\npolynomial but are easy to compute over commutative domains."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1409.1060v1", 
    "title": "Kolmogorov complexity and the geometry of Brownian motion", 
    "arxiv-id": "1409.1060v1", 
    "author": "Willem L. Fouche", 
    "publish": "2014-09-03T12:30:24Z", 
    "summary": "In this paper, we continue the study of the geometry of Brownian motions\nwhich are encoded by Kolmogorov-Chaitin random reals (complex oscillations). We\nunfold Kolmogorov-Chaitin complexity in the context of Brownian motion and\nspecifically to phenomena emerging from the random geometric patterns generated\nby a Brownian motion."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1409.3865v1", 
    "title": "On Stability Property of Probability Laws with Respect to Small   Violations of Algorithmic Randomness", 
    "arxiv-id": "1409.3865v1", 
    "author": "Vladimir V. V'yugin", 
    "publish": "2014-09-12T21:06:48Z", 
    "summary": "We study a stability property of probability laws with respect to small\nviolations of algorithmic randomness. A sufficient condition of stability is\npresented in terms of Schnorr tests of algorithmic randomness. Most probability\nlaws, like the strong law of large numbers, the law of iterated logarithm, and\neven Birkhoff's pointwise ergodic theorem for ergodic transformations, are\nstable in this sense. Nevertheless, the phenomenon of instability occurs in\nergodic theory. Firstly, the stability property of the Birkhoff's ergodic\ntheorem is non-uniform. Moreover, a computable non-ergodic measure preserving\ntransformation can be constructed such that ergodic theorem is non-stable. We\nalso show that any universal data compression scheme is also non-stable with\nrespect to the class of all computable ergodic measures."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1409.4035v1", 
    "title": "The Corruption Bound, Log Rank, and Communication Complexity", 
    "arxiv-id": "1409.4035v1", 
    "author": "Adi Shraibman", 
    "publish": "2014-09-14T09:12:07Z", 
    "summary": "We prove that for every sign matrix $A$ there is a deterministic\ncommunication protocol that uses $O(corr_{1/4}(A)\\log^2 rk(A))$ bits of\ncommunication, where $corr_{1/4}(A)$ is the corruption/rectangle bound with\nerror $1/4$. This bound generalizes several of the known upper bounds on\ndeterministic communication complexity, involving nondeterministic complexity,\nrandomized complexity, information complexity notions, and rank.\n  It also implies that the corruption bound is a lower bound on exact quantum\ncommunication complexity, if and only if quantum communication is polynomially\nequivalent to deterministic communication complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1409.7790v1", 
    "title": "Parameterized Analogues of Probabilistic Computation", 
    "arxiv-id": "1409.7790v1", 
    "author": "B. V. Raghavendra Rao", 
    "publish": "2014-09-27T10:39:15Z", 
    "summary": "We study structural aspects of randomized parameterized computation. We\nintroduce a new class ${\\sf W[P]}$-${\\sf PFPT}$ as a natural parameterized\nanalogue of ${\\sf PP}$. Our definition uses the machine based characterization\nof the parameterized complexity class ${\\sf W[P]}$ obtained by Chen et.al [TCS\n2005]. We translate most of the structural properties and characterizations of\nthe class ${\\sf PP}$ to the new class ${W[P]}$-${\\sf PFPT}$.\n  We study a parameterization of the polynomial identity testing problem based\non the degree of the polynomial computed by the arithmetic circuit. We obtain a\nparameterized analogue of the well known Schwartz-Zippel lemma [Schwartz, JACM\n80 and Zippel, EUROSAM 79].\n  Additionally, we introduce a parameterized variant of permanent, and prove\nits $\\#W[1]$ completeness."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1409.8254v1", 
    "title": "About accuracy of the solution of NP-complete tasks", 
    "arxiv-id": "1409.8254v1", 
    "author": "Rustem Valeyev", 
    "publish": "2014-07-04T05:35:16Z", 
    "summary": "On example of tasks of class NP the questions concerning accuracy of work of\nalready existing and possible in the future algorithms for the solution of\ntasks on discrete structures are considered."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.00265v1", 
    "title": "On the complexity of finite valued functions", 
    "arxiv-id": "1501.00265v1", 
    "author": "I. Damyanov", 
    "publish": "2015-01-01T09:47:02Z", 
    "summary": "The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.00671v1", 
    "title": "On the Complexity of Noncommutative Polynomial Factorization", 
    "arxiv-id": "1501.00671v1", 
    "author": "Gaurav Rattan", 
    "publish": "2015-01-04T12:56:47Z", 
    "summary": "In this paper we study the complexity of factorization of polynomials in the\nfree noncommutative ring $\\mathbb{F}\\langle x_1,x_2,\\dots,x_n\\rangle$ of\npolynomials over the field $\\mathbb{F}$ and noncommuting variables\n$x_1,x_2,\\ldots,x_n$. Our main results are the following.\n  Although $\\mathbb{F}\\langle x_1,x_2,\\dots,x_n \\rangle$ is not a unique\nfactorization ring, we note that variable-disjoint factorization in\n$\\mathbb{F}\\langle x_1,x_2,\\dots,x_n \\rangle$ has the uniqueness property.\nFurthermore, we prove that computing the variable-disjoint factorization is\npolynomial-time equivalent to Polynomial Identity Testing (both when the input\npolynomial is given by an arithmetic circuit or an algebraic branching\nprogram). We also show that variable-disjoint factorization in the black-box\nsetting can be efficiently computed (where the factors computed will be also\ngiven by black-boxes, analogous to the work [KT91] in the commutative setting).\n  As a consequence of the previous result we show that homogeneous\nnoncommutative polynomials and multilinear noncommutative polynomials have\nunique factorizations in the usual sense, which can be efficiently computed.\n  Finally, we discuss a polynomial decomposition problem in $\\mathbb{F}\\langle\nx_1,x_2,\\dots,x_n\\rangle$ which is a natural generalization of homogeneous\npolynomial factorization and prove some complexity bounds for it."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.00734v2", 
    "title": "Sum of Squares Lower Bounds from Pairwise Independence", 
    "arxiv-id": "1501.00734v2", 
    "author": "Pravesh Kothari", 
    "publish": "2015-01-04T23:27:12Z", 
    "summary": "We prove that for every $\\epsilon>0$ and predicate $P:\\{0,1\\}^k\\rightarrow\n\\{0,1\\}$ that supports a pairwise independent distribution, there exists an\ninstance $\\mathcal{I}$ of the $\\mathsf{Max}P$ constraint satisfaction problem\non $n$ variables such that no assignment can satisfy more than a\n$\\tfrac{|P^{-1}(1)|}{2^k}+\\epsilon$ fraction of $\\mathcal{I}$'s constraints but\nthe degree $\\Omega(n)$ Sum of Squares semidefinite programming hierarchy cannot\ncertify that $\\mathcal{I}$ is unsatisfiable. Similar results were previously\nonly known for weaker hierarchies."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.00894v1", 
    "title": "On Sharing, Memoization, and Polynomial Time (Long Version)", 
    "arxiv-id": "1501.00894v1", 
    "author": "Ugo Dal Lago", 
    "publish": "2015-01-05T15:34:07Z", 
    "summary": "We study how the adoption of an evaluation mechanism with sharing and\nmemoization impacts the class of functions which can be computed in polynomial\ntime. We first show how a natural cost model in which lookup for an already\ncomputed value has no cost is indeed invariant. As a corollary, we then prove\nthat the most general notion of ramified recurrence is sound for polynomial\ntime, this way settling an open problem in implicit computational complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.01598v1", 
    "title": "Combinatorial Optimization Algorithms via Polymorphisms", 
    "arxiv-id": "1501.01598v1", 
    "author": "Prasad Raghavendra", 
    "publish": "2015-01-07T19:17:25Z", 
    "summary": "An elegant characterization of the complexity of constraint satisfaction\nproblems has emerged in the form of the the algebraic dichotomy conjecture of\n[BKJ00]. Roughly speaking, the characterization asserts that a CSP {\\Lambda} is\ntractable if and only if there exist certain non-trivial operations known as\npolymorphisms to combine solutions to {\\Lambda} to create new ones. In an\nentirely separate line of work, the unique games conjecture yields a\ncharacterization of approximability of Max-CSPs. Surprisingly, this\ncharacterization for Max-CSPs can also be reformulated in the language of\npolymorphisms.\n  In this work, we study whether existence of non-trivial polymorphisms implies\ntractability beyond the realm of constraint satisfaction problems, namely in\nthe value-oracle model. Specifically, given a function f in the value-oracle\nmodel along with an appropriate operation that never increases the value of f ,\nwe design algorithms to minimize f . In particular, we design a randomized\nalgorithm to minimize a function f that admits a fractional polymorphism which\nis measure preserving and has a transitive symmetry.\n  We also reinterpret known results on MaxCSPs and thereby reformulate the\nunique games conjecture as a characterization of approximability of max-CSPs in\nterms of their approximate polymorphisms."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.01906v1", 
    "title": "What is NP? - Interpretation of a Chinese paradox \"white horse is not   horse\"", 
    "arxiv-id": "1501.01906v1", 
    "author": "Yu Li", 
    "publish": "2015-01-08T17:25:18Z", 
    "summary": "The notion of nondeterminism has disappeared from the current definition of\nNP, which has led to ambiguities in understanding NP, and caused fundamental\ndifficulties in studying the relation P versus NP. In this paper, we question\nthe equivalence of the two definitions of NP, the one defining NP as the class\nof problems solvable by a nondeterministic Turing machine in polynomial time,\nand the other defining NP as the class of problems verifiable by a\ndeterministic Turing machine in polynomial time, and reveal cognitive biases in\nthis equivalence. Inspired from a famous Chinese paradox white horse is not\nhorse, we further analyze these cognitive biases. The work shows that these\ncognitive biases arise from the confusion between different levels of\nnondeterminism and determinism, due to the lack of understanding about the\nessence of nondeterminism. Therefore, we argue that fundamental difficulties in\nunderstanding P versus NP lie firstly at cognition level, then logic level."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.01910v1", 
    "title": "What is Cook's theorem?", 
    "arxiv-id": "1501.01910v1", 
    "author": "Yu Li", 
    "publish": "2015-01-08T17:41:21Z", 
    "summary": "In this paper, we make a preliminary interpretation of Cook's theorem\npresented in [1]. This interpretation reveals cognitive biases in the proof of\nCook's theorem that arise from the attempt of constructing a formula in CNF to\nrepresent a computation of a nondeterministic Turing machine. Such cognitive\nbiases are due to the lack of understanding about the essence of\nnondeterminism, and lead to the confusion between different levels of\nnondeterminism and determinism, thus cause the loss of nondeterminism from the\nNP-completeness theory. The work shows that Cook's theorem is the origin of the\nloss of nondeterminism in terms of the equivalence of the two definitions of\nNP, the one defining NP as the class of problems solvable by a nondeterministic\nTuring machine in polynomial time, and the other defining NP as the class of\nproblems verifiable by a deterministic Turing machine in polynomial time.\nTherefore, we argue that fundamental difficulties in understanding P versus NP\nlie firstly at cognition level, then logic level."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.02212v1", 
    "title": "Efficient Computation by Three Counter Machines", 
    "arxiv-id": "1501.02212v1", 
    "author": "Holger Petersen", 
    "publish": "2015-01-09T18:02:01Z", 
    "summary": "We show that multiplication can be done in polynomial time on a three counter\nmachine that receives its input as the contents of two counters. The technique\nis generalized to functions of two variables computable by deterministic Turing\nmachines in linear space."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.03837v1", 
    "title": "On the Complexity of Slide-and-Merge Games", 
    "arxiv-id": "1501.03837v1", 
    "author": "Philip Dasler", 
    "publish": "2015-01-15T21:56:05Z", 
    "summary": "We study the complexity of a particular class of board games, which we call\n`slide and merge' games. Namely, we consider 2048 and Threes, which are among\nthe most popular games of their type. In both games, the player is required to\nslide all rows or columns of the board in one direction to create a high value\ntile by merging pairs of equal tiles into one with the sum of their values.\nThis combines features from both block pushing and tile matching puzzles, like\nPush and Bejeweled, respectively. We define a number of natural decision\nproblems on a suitable generalization of these games and prove NP-hardness for\n2048 by reducing from 3SAT. Finally, we discuss the adaptation of our reduction\nto Threes and conjecture a similar result."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.04558v2", 
    "title": "From complexity to algebra and back: digraph classes, collapsibility and   the PGP", 
    "arxiv-id": "1501.04558v2", 
    "author": "Barnaby Martin", 
    "publish": "2015-01-19T16:58:39Z", 
    "summary": "Inspired by computational complexity results for the quantified constraint\nsatisfaction problem, we study the clones of idempotent polymorphisms of\ncertain digraph classes. Our first results are two algebraic dichotomy, even\n\"gap\", theorems. Building on and extending [Martin CP'11], we prove that\npartially reflexive paths bequeath a set of idempotent polymorphisms whose\nassociated clone algebra has: either the polynomially generated powers property\n(PGP); or the exponentially generated powers property (EGP). Similarly, we\nbuild on [DaMM ICALP'14] to prove that semicomplete digraphs have the same\nproperty.\n  These gap theorems are further motivated by new evidence that PGP could be\nthe algebraic explanation that a QCSP is in NP even for unbounded alternation.\nAlong the way we also effect a study of a concrete form of PGP known as\ncollapsibility, tying together the algebraic and structural threads from [Chen\nSicomp'08], and show that collapsibility is equivalent to its\n$\\Pi_2$-restriction. We also give a decision procedure for $k$-collapsibility\nfrom a singleton source of a finite structure (a form of collapsibility which\ncovers all known examples of PGP for finite structures).\n  Finally, we present a new QCSP trichotomy result, for partially reflexive\npaths with constants. Without constants it is known these QCSPs are either in\nNL or Pspace-complete [Martin CP'11], but we prove that with constants they\nattain the three complexities NL, NP-complete and Pspace-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.06323v2", 
    "title": "The Parity Hamiltonian Cycle Problem", 
    "arxiv-id": "1501.06323v2", 
    "author": "Masafumi Yamashita", 
    "publish": "2015-01-26T10:49:26Z", 
    "summary": "Motivated by a relaxed notion of the celebrated Hamiltonian cycle, this paper\ninvestigates its variant, parity Hamiltonian cycle (PHC): A PHC of a graph is a\nclosed walk which visits every vertex an odd number of times, where we remark\nthat the walk may use an edge more than once. First, we give a complete\ncharacterization of the graphs which have PHCs, and give a linear time\nalgorithm to find a PHC, in which every edge appears at most four times, in\nfact. In contrast, we show that finding a PHC is NP-hard if a closed walk is\nallowed to use each edge at most z times for each z=1,2,3 (PHCz for short),\neven when a given graph is two-edge connected. We then further investigate the\nPHC3 problem, and show that the problem is in P when an input graph is\nfour-edge connected. Finally, we are concerned with three (or two)-edge\nconnected graphs, and show that the PHC3 is in P for any C_>=5-free or P6-free\ngraphs. Note that the Hamiltonian cycle problem is known to be NP-hard for\nthose graph classes."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1501.06729v2", 
    "title": "The Complexity of the Kth Largest Subset Problem and Related Problems", 
    "arxiv-id": "1501.06729v2", 
    "author": "Stefan Kiefer", 
    "publish": "2015-01-27T10:33:56Z", 
    "summary": "We show that the Kth largest subset problem and the Kth largest m-tuple\nproblem are in PP and hard for PP under polynomial-time Turing reductions.\nSeveral problems from the literature were previously shown NP-hard via\nreductions from those two problems, and by our main result they become PP-hard\nas well. We also provide complementary PP-upper bounds for some of them."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1007.0391v4", 
    "title": "Approximate Counting for Complex-Weighted Boolean Constraint   Satisfaction Problems", 
    "arxiv-id": "1007.0391v4", 
    "author": "Tomoyuki Yamakami", 
    "publish": "2010-07-02T16:01:39Z", 
    "summary": "Constraint satisfaction problems (or CSPs) have been extensively studied in,\nfor instance, artificial intelligence, database theory, graph theory, and\nstatistical physics. From a practical viewpoint, it is beneficial to\napproximately solve those CSPs. When one tries to approximate the total number\nof truth assignments that satisfy all Boolean-valued constraints for\n(unweighted) Boolean CSPs, there is a known trichotomy theorem by which all\nsuch counting problems are neatly classified into exactly three categories\nunder polynomial-time (randomized) approximation-preserving reductions. In\ncontrast, we obtain a dichotomy theorem of approximate counting for\ncomplex-weighted Boolean CSPs, provided that all complex-valued unary\nconstraints are freely available to use. It is the expressive power of free\nunary constraints that enables us to prove such a stronger, complete\nclassification theorem. This discovery makes a step forward in the quest for\nthe approximation-complexity classification of all counting CSPs. To deal with\ncomplex weights, we employ proof techniques of factorization and arity\nreduction along the line of solving Holant problems. Moreover, we introduce a\nnovel notion of T-constructibility that naturally induces\napproximation-preserving reducibility. Our result also gives an approximation\nanalogue of the dichotomy theorem on the complexity of exact counting for\ncomplex-weighted Boolean CSPs."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1007.1073v1", 
    "title": "Learning Read-Once Functions Using Subcube Identity Queries", 
    "arxiv-id": "1007.1073v1", 
    "author": "Andrey A. Voronenko", 
    "publish": "2010-07-07T08:23:15Z", 
    "summary": "We consider the problem of exact identification for read-once functions over\narbitrary Boolean bases. We introduce a new type of queries (subcube identity\nones), discuss its connection to previously known ones, and study the\ncomplexity of the problem in question. Besides these new queries, learning\nalgorithms are allowed to use classic membership ones. We present a technique\nof modeling an equivalence query with a polynomial number of membership and\nsubcube identity ones, thus establishing (under certain conditions) a\npolynomial upper bound on the complexity of the problem. We show that in some\ncircumstances, though, equivalence queries cannot be modeled with a polynomial\nnumber of subcube identity and membership ones. We construct an example of an\ninfinite Boolean basis with an exponential lower bound on the number of\nmembership and subcube identity queries required for exact identification. We\nprove that for any finite subset of this basis, the problem remains polynomial."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1007.1841v1", 
    "title": "Communication Complexity", 
    "arxiv-id": "1007.1841v1", 
    "author": "D\u00f6m\u00f6t\u00f6r P\u00e1lv\u00f6lgyi", 
    "publish": "2010-07-12T08:32:36Z", 
    "summary": "The first section starts with the basic definitions following mainly the\nnotations of the book written by E. Kushilevitz and N. Nisan. At the end of the\nfirst section I examine tree-balancing.\n  In the second section I summarize the well-known lower bound methods and\nprove the exact complexity of certain functions.\n  In the first part of the third section I introduce the random complexity and\nprove the basic lemmas about it. In the second part I prove a better lower\nbound for the complexity of all random functions. In the third part I introduce\nand compare several upper bounds for the complexity of the identity function.\n  In the fourth section I examine the well-known Direct-sum conjecture. I\nintroduce a different model of computation then prove that it is the same as\nthe original one up to a constant factor. This new model is used to bound the\nAmortized Time Complexity of a function by the number of the leaves of its\nprotocol-tree. After this I examine the Direct-sum problem in case of Partial\nInformation and in the Random case.\n  In the last section I introduce the well-known hierarchy classes, the\nreducibility and the completeness of series of functions. Then I define the\nclass PSPACE and Oracles in the communication complexity model and prove some\nbasic claims about them."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1007.1868v2", 
    "title": "NP=PSPACE", 
    "arxiv-id": "1007.1868v2", 
    "author": "Norichika Matsuki", 
    "publish": "2010-07-12T11:10:04Z", 
    "summary": "This paper has been withdrawn by the author due to a misunderstanding about\n3QBF."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1007.2673v1", 
    "title": "The Complexity of Testing Monomials in Multivariate Polynomials", 
    "arxiv-id": "1007.2673v1", 
    "author": "Bin Fu", 
    "publish": "2010-07-15T22:52:46Z", 
    "summary": "The work in this paper is to initiate a theory of testing monomials in\nmultivariate polynomials. The central question is to ask whether a polynomial\nrepresented by certain economically compact structure has a multilinear\nmonomial in its sum-product expansion. The complexity aspects of this problem\nand its variants are investigated with two folds of objectives. One is to\nunderstand how this problem relates to critical problems in complexity, and if\nso to what extent. The other is to exploit possibilities of applying algebraic\nproperties of polynomials to the study of those problems. A series of results\nabout $\\Pi\\Sigma\\Pi$ and $\\Pi\\Sigma$ polynomials are obtained in this paper,\nlaying a basis for further study along this line."
},{
    "category": "cs.CC", 
    "doi": "10.1017/S0960129513000273", 
    "link": "http://arxiv.org/pdf/1007.2675v1", 
    "title": "Algorithms for Testing Monomials in Multivariate Polynomials", 
    "arxiv-id": "1007.2675v1", 
    "author": "Robert Schweller", 
    "publish": "2010-07-15T23:04:24Z", 
    "summary": "This paper is our second step towards developing a theory of testing\nmonomials in multivariate polynomials. The central question is to ask whether a\npolynomial represented by an arithmetic circuit has some types of monomials in\nits sum-product expansion. The complexity aspects of this problem and its\nvariants have been investigated in our first paper by Chen and Fu (2010),\nlaying a foundation for further study. In this paper, we present two pairs of\nalgorithms. First, we prove that there is a randomized $O^*(p^k)$ time\nalgorithm for testing $p$-monomials in an $n$-variate polynomial of degree $k$\nrepresented by an arithmetic circuit, while a deterministic $O^*(6.4^k + p^k)$\ntime algorithm is devised when the circuit is a formula, here $p$ is a given\nprime number. Second, we present a deterministic $O^*(2^k)$ time algorithm for\ntesting multilinear monomials in $\\Pi_m\\Sigma_2\\Pi_t\\times \\Pi_k\\Pi_3$\npolynomials, while a randomized $O^*(1.5^k)$ algorithm is given for these\npolynomials. The first algorithm extends the recent work by Koutis (2008) and\nWilliams (2009) on testing multilinear monomials. Group algebra is exploited in\nthe algorithm designs, in corporation with the randomized polynomial identity\ntesting over a finite field by Agrawal and Biswas (2003), the deterministic\nnoncommunicative polynomial identity testing by Raz and Shpilka (2005) and the\nperfect hashing functions by Chen {\\em at el.} (2007). Finally, we prove that\ntesting some special types of multilinear monomial is W[1]-hard, giving\nevidence that testing for specific monomials is not fixed-parameter tractable."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1007.2678v1", 
    "title": "Approximating Multilinear Monomial Coefficients and Maximum Multilinear   Monomials in Multivariate Polynomials", 
    "arxiv-id": "1007.2678v1", 
    "author": "Bin Fu", 
    "publish": "2010-07-15T23:12:11Z", 
    "summary": "This paper is our third step towards developing a theory of testing monomials\nin multivariate polynomials and concentrates on two problems: (1) How to\ncompute the coefficients of multilinear monomials; and (2) how to find a\nmaximum multilinear monomial when the input is a $\\Pi\\Sigma\\Pi$ polynomial. We\nfirst prove that the first problem is \\#P-hard and then devise a $O^*(3^ns(n))$\nupper bound for this problem for any polynomial represented by an arithmetic\ncircuit of size $s(n)$. Later, this upper bound is improved to $O^*(2^n)$ for\n$\\Pi\\Sigma\\Pi$ polynomials. We then design fully polynomial-time randomized\napproximation schemes for this problem for $\\Pi\\Sigma$ polynomials. On the\nnegative side, we prove that, even for $\\Pi\\Sigma\\Pi$ polynomials with terms of\ndegree $\\le 2$, the first problem cannot be approximated at all for any\napproximation factor $\\ge 1$, nor {\\em \"weakly approximated\"} in a much relaxed\nsetting, unless P=NP. For the second problem, we first give a polynomial time\n$\\lambda$-approximation algorithm for $\\Pi\\Sigma\\Pi$ polynomials with terms of\ndegrees no more a constant $\\lambda \\ge 2$. On the inapproximability side, we\ngive a $n^{(1-\\epsilon)/2}$ lower bound, for any $\\epsilon >0,$ on the\napproximation factor for $\\Pi\\Sigma\\Pi$ polynomials. When terms in these\npolynomials are constrained to degrees $\\le 2$, we prove a $1.0476$ lower\nbound, assuming $P\\not=NP$; and a higher $1.0604$ lower bound, assuming the\nUnique Games Conjecture."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1007.4660v1", 
    "title": "About functions where function input describes inner working of the   function", 
    "arxiv-id": "1007.4660v1", 
    "author": "Rade Vuckovac", 
    "publish": "2010-07-27T09:58:22Z", 
    "summary": "This paper argues an existence of a class of functions where function own\ninput makes function description. That fact have impact to the wide spectrum of\nphenomena such as negative findings of Random Oracle Model in cryptography,\ncomplexity in some rules of cellular automata (Wolfram rule 30) and determinism\nin the true randomness to name just a few."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.0872v2", 
    "title": "Possibilities and impossibilities in Kolmogorov complexity extraction", 
    "arxiv-id": "1104.0872v2", 
    "author": "Marius Zimand", 
    "publish": "2011-04-05T15:45:08Z", 
    "summary": "Randomness extraction is the process of constructing a source of randomness\nof high quality from one or several sources of randomness of lower quality. The\nproblem can be modeled using probability distributions and min-entropy to\nmeasure their quality and also by using individual strings and Kolmogorov\ncomplexity to measure their quality. Complexity theorists are more familiar\nwith the first approach. In this paper we survey the second approach. We\npresent the connection between extractors and Kolmogorov extractors and the\nbasic positive and negative results concerning Kolmogorov complexity\nextraction."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.1209v1", 
    "title": "A Small PRG for Polynomial Threshold Functions of Gaussians", 
    "arxiv-id": "1104.1209v1", 
    "author": "Daniel M. Kane", 
    "publish": "2011-04-06T22:43:07Z", 
    "summary": "We develop a pseudo-random generator to fool degree-$d$ polynomial threshold\nfunctions with respect to the Gaussian distribution. For $c>0$ any constant, we\nconstruct a pseudo-random generator that fools such functions to within\n$\\epsilon$ and has seed length $\\log(n) 2^{O(d)} \\epsilon^{-4-c}$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.2312v1", 
    "title": "Minimization for Generalized Boolean Formulas", 
    "arxiv-id": "1104.2312v1", 
    "author": "Henning Schnoor", 
    "publish": "2011-04-12T19:38:32Z", 
    "summary": "The minimization problem for propositional formulas is an important\noptimization problem in the second level of the polynomial hierarchy. In\ngeneral, the problem is Sigma-2-complete under Turing reductions, but\nrestricted versions are tractable. We study the complexity of minimization for\nformulas in two established frameworks for restricted propositional logic: The\nPost framework allowing arbitrarily nested formulas over a set of Boolean\nconnectors, and the constraint setting, allowing generalizations of CNF\nformulas. In the Post case, we obtain a dichotomy result: Minimization is\nsolvable in polynomial time or coNP-hard. This result also applies to Boolean\ncircuits. For CNF formulas, we obtain new minimization algorithms for a large\nclass of formulas, and give strong evidence that we have covered all\npolynomial-time cases."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.2538v1", 
    "title": "Computational Complexity on Signed Numbers", 
    "arxiv-id": "1104.2538v1", 
    "author": "Stefan Jaeger", 
    "publish": "2011-04-13T16:09:49Z", 
    "summary": "This paper presents a new representation of natural numbers and discusses its\nconsequences for computability and computational complexity. The paper argues\nthat the introduction of the first Peano axiom in the traditional definition of\nnatural numbers is not essential. It claims that natural numbers remain usable\nin traditional ways without assuming the existence of at least one natural\nnumber. However, the uncertainty about the existence of natural numbers\ntranslates into every computation and introduces intrinsic uncertainty that\ncannot be avoided. The uncertainty in the output of a computation can be\nreduced, though, at the expense of a longer runtime and thus higher complexity.\nFor the new representation of natural numbers, the paper claims that, with the\nfirst Peano axiom, P is equal to NP, and that without the first Peano axiom, P\nbecomes a proper subset of NP."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.2816v1", 
    "title": "On the optimal compression of sets in PSPACE", 
    "arxiv-id": "1104.2816v1", 
    "author": "Marius Zimand", 
    "publish": "2011-04-14T16:11:38Z", 
    "summary": "We show that if DTIME[2^{O(n)}] is not included in DSPACE[2^{o(n)}], then,\nfor every set B in PSPACE, all strings x in B of length n can be represented by\na string compressed(x) of length at most log (|B^{=n}|) + O(log n), such that a\npolynomial-time algorithm, given compressed(x), can distinguish x from all the\nother strings in B^{=n}. Modulo the O(log n) additive trem, this achieves the\ninformation-theoretical optimum for string compression."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.3025v1", 
    "title": "Storage Enforcement with Kolmogorov Complexity and List Decoding", 
    "arxiv-id": "1104.3025v1", 
    "author": "Steve Uurtamo", 
    "publish": "2011-04-15T11:54:41Z", 
    "summary": "We consider the following problem that arises in outsourced storage: a user\nstores her data $x$ on a remote server but wants to audit the server at some\nlater point to make sure it actually did store $x$. The goal is to design a\n(randomized) verification protocol that has the property that if the server\npasses the verification with some reasonably high probability then the user can\nrest assured that the server is storing $x$.\n  In this work we present an optimal solution (in terms of the user's storage\nand communication) while at the same time ensuring that a server that passes\nthe verification protocol with any reasonable probability will store, to within\na small \\textit{additive} factor, $C(x)$ bits of information, where $C(x)$ is\nthe plain Kolmogorov complexity of $x$. (Since we cannot prevent the server\nfrom compressing $x$, $C(x)$ is a natural upper bound.) The proof of security\nof our protocol combines Kolmogorov complexity with list decoding and unlike\nprevious work that relies upon cryptographic assumptions, we allow the server\nto have unlimited computational power. To the best of our knowledge, this is\nthe first work that combines Kolmogorov complexity and list decoding.\n  Our framework is general enough to capture extensions where the user splits\nup $x$ and stores the fragment across multiple servers and our verification\nprotocol can handle non-responsive servers and colluding servers. As a\nby-product, we also get a proof of retrievability. Finally, our results also\nhave an application in `storage enforcement' schemes, which in turn have an\napplication in trying to update a remote server that is potentially infected\nwith a virus."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.3056v1", 
    "title": "Numbers as Data Structures: The Prime Successor Function as Primitive", 
    "arxiv-id": "1104.3056v1", 
    "author": "Ross D. King", 
    "publish": "2011-04-15T13:46:47Z", 
    "summary": "The symbolic representation of a number should be considered as a data\nstructure, and the choice of data structure depends on the arithmetic\noperations that are to be performed. Numbers are almost universally represented\nusing position based notations based on exponential powers of a base number -\nusually 10. This representations is computationally efficient for the standard\narithmetic operations, but it is not efficient for factorisation. This has led\nto a common confusion that factorisation is inherently computationally hard. We\npropose a new representation of the natural numbers based on bags and using the\nprime successor function as a primitive - prime bags (PBs). This data structure\nis more efficient for most arithmetic operations, and enables numbers can be\nefficiently factored. However, it also has the interesting feature that\naddition appears to be computationally hard. PBs have an interesting\nalternative interpretation as partitions of numbers represented in the standard\nway, and this reveals a novel relationship between prime numbers and the\npartition function. The PB representation can be extended to rational and\nirrational numbers, and this provides the most direct proof of the\nirrationality of the square root of 2. I argue that what needs to be ultimately\nunderstood is not the peculiar computation complexity properties of the decimal\nsystem (e.g. factorisation), but rather what arithmetical operator trade-offs\nare generally possible."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.3335v2", 
    "title": "Correlation Testing for Affine Invariant Properties on $\\mathbb{F}_p^n$   in the High Error Regime", 
    "arxiv-id": "1104.3335v2", 
    "author": "Shachar Lovett", 
    "publish": "2011-04-17T18:56:55Z", 
    "summary": "Recently there has been much interest in Gowers uniformity norms from the\nperspective of theoretical computer science. This is mainly due to the fact\nthat these norms provide a method for testing whether the maximum correlation\nof a function $f:\\mathbb{F}_p^n \\rightarrow \\mathbb{F}_p$ with polynomials of\ndegree at most $d \\le p$ is non-negligible, while making only a constant number\nof queries to the function. This is an instance of {\\em correlation testing}.\nIn this framework, a fixed test is applied to a function, and the acceptance\nprobability of the test is dependent on the correlation of the function from\nthe property. This is an analog of {\\em proximity oblivious testing}, a notion\ncoined by Goldreich and Ron, in the high error regime. In this work, we study\ngeneral properties which are affine invariant and which are correlation\ntestable using a constant number of queries. We show that any such property (as\nlong as the field size is not too small) can in fact be tested by Gowers\nuniformity tests, and hence having correlation with the property is equivalent\nto having correlation with degree $d$ polynomials for some fixed $d$. We stress\nthat our result holds also for non-linear properties which are affine\ninvariant. This completely classifies affine invariant properties which are\ncorrelation testable. The proof is based on higher-order Fourier analysis.\nAnother ingredient is a nontrivial extension of a graph theoretical theorem of\nErd\\\"os, Lov\\'asz and Spencer to the context of additive number theory."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.3421v3", 
    "title": "Empirical Encounters with Computational Irreducibility and   Unpredictability", 
    "arxiv-id": "1104.3421v3", 
    "author": "Joost J. Joosten", 
    "publish": "2011-04-18T10:00:45Z", 
    "summary": "There are several forms of irreducibility in computing systems, ranging from\nundecidability to intractability to nonlinearity. This paper is an exploration\nof the conceptual issues that have arisen in the course of investigating\nspeed-up and slowdown phenomena in small Turing machines. We present the\nresults of a test that may spur experimental approaches to the notion of\ncomputational irreducibility. The test involves a systematic attempt to outrun\nthe computation of a large number of small Turing machines (all 3 and 4 state,\n2 symbol) by means of integer sequence prediction using a specialized function\nfinder program. This massive experiment prompts an investigation into rates of\nconvergence of decision procedures and the decidability of sets in addition to\na discussion of the (un)predictability of deterministic computing systems in\npractice. We think this investigation constitutes a novel approach to the\ndiscussion of an epistemological question in the context of a computer\nsimulation, and thus represents an interesting exploration at the boundary\nbetween philosophical concerns and computational experiments."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.4433v1", 
    "title": "Arc-preserving subsequences of arc-annotated sequences", 
    "arxiv-id": "1104.4433v1", 
    "author": "Vladimir Yu. Popov", 
    "publish": "2011-04-22T13:13:19Z", 
    "summary": "Arc-annotated sequences are useful in representing the structural information\nof RNA and protein sequences. The longest arc-preserving common subsequence\nproblem has been introduced as a framework for studying the similarity of\narc-annotated sequences. In this paper, we consider arc-annotated sequences\nwith various arc structures. We consider the longest arc preserving common\nsubsequence problem. In particular, we show that the decision version of the\n1-{\\sc fragment LAPCS(crossing,chain)} and the decision version of the 0-{\\sc\ndiagonal LAPCS(crossing,chain)} are {\\bf NP}-complete for some fixed alphabet\n$\\Sigma$ such that $|\\Sigma| = 2$. Also we show that if $|\\Sigma| = 1$, then\nthe decision version of the 1-{\\sc fragment LAPCS(unlimited, plain)} and the\ndecision version of the 0-{\\sc diagonal LAPCS(unlimited, plain)} are {\\bf\nNP}-complete."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.4490v2", 
    "title": "The 3-satisfiability problem", 
    "arxiv-id": "1104.4490v2", 
    "author": "Amar Mukherjee", 
    "publish": "2011-04-22T19:29:22Z", 
    "summary": "We present a deterministic polynomial-time algorithm that solves the\n3-satisfiability problem."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.4779v3", 
    "title": "The Computational Complexity of Disconnected Cut and 2K2-Partition", 
    "arxiv-id": "1104.4779v3", 
    "author": "Daniel Paulusma", 
    "publish": "2011-04-25T19:49:40Z", 
    "summary": "For a connected graph G=(V,E), a subset U of V is called a disconnected cut\nif U disconnects the graph and the subgraph induced by U is disconnected as\nwell. We show that the problem to test whether a graph has a disconnected cut\nis NP-complete. This problem is polynomially equivalent to the following\nproblems: testing if a graph has a 2K2-partition, testing if a graph allows a\nvertex-surjective homomorphism to the reflexive 4-cycle and testing if a graph\nhas a spanning subgraph that consists of at most two bicliques. Hence, as an\nimmediate consequence, these three decision problems are NP-complete as well.\nThis settles an open problem frequently posed in each of the four settings."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1104.5257v2", 
    "title": "The Complexity of Surjective Homomorphism Problems -- a Survey", 
    "arxiv-id": "1104.5257v2", 
    "author": "Barnaby Martin", 
    "publish": "2011-04-27T21:42:53Z", 
    "summary": "We survey known results about the complexity of surjective homomorphism\nproblems, studied in the context of related problems in the literature such as\nlist homomorphism, retraction and compaction. In comparison with these\nproblems, surjective homomorphism problems seem to be harder to classify and we\nexamine especially three concrete problems that have arisen from the\nliterature, two of which remain of open complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1109.2162v1", 
    "title": "The Complexity of the Empire Colouring Problem", 
    "arxiv-id": "1109.2162v1", 
    "author": "Michele Zito", 
    "publish": "2011-09-09T21:13:39Z", 
    "summary": "We investigate the computational complexity of the empire colouring problem\n(as defined by Percy Heawood in 1890) for maps containing empires formed by\nexactly $r > 1$ countries each. We prove that the problem can be solved in\npolynomial time using $s$ colours on maps whose underlying adjacency graph has\nno induced subgraph of average degree larger than $s/r$. However, if $s \\geq\n3$, the problem is NP-hard even if the graph is a forest of paths of arbitrary\nlengths (for any $r \\geq 2$, provided $s < 2r - \\sqrt{2r + 1/4+ 3/2).\nFurthermore we obtain a complete characterization of the problem's complexity\nfor the case when the input graph is a tree, whereas our result for arbitrary\nplanar graphs fall just short of a similar dichotomy. Specifically, we prove\nthat the empire colouring problem is NP-hard for trees, for any $r \\geq 2$, if\n$3 \\leq s \\leq 2r-1$ (and polynomial time solvable otherwise). For arbitrary\nplanar graphs we prove NP-hardness if $s<7$ for $r=2$, and $s < 6r-3$, for $r\n\\geq 3$. The result for planar graphs also proves the NP-hardness of colouring\nwith less than 7 colours graphs of thickness two and less than $6r-3$ colours\ngraphs of thickness $r \\geq 3$."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1109.3367v4", 
    "title": "Various complexity results for computational mass spectrometry problems", 
    "arxiv-id": "1109.3367v4", 
    "author": "Sebastian B\u00f6cker", 
    "publish": "2011-09-15T14:42:48Z", 
    "summary": "Define Minimum Soapy Union (MinSU) as the following optimization problem:\ngiven a $k$-tuple $(X_1, X_2,..., X_k)$ of finite integer sets, find a\n$k$-tuple $(t_1, t_2,..., t_k)$ of integers that minimizes the cardinality of\n$(X_1 + t_1) \\cup (X_2 + t_2) \\cup ... \\cup (X_n + t_k)$. We show that MinSU is\nNP-complete, APX-hard, and polynomial for fixed $k$. MinSU appears naturally in\nthe context of protein shotgun sequencing: Here, the protein is cleaved into\nshort and overlapping peptides, which are then analyzed by tandem mass\nspectrometry. To improve the quality of such spectra, one then asks for the\nmass of the unknown prefix (the shift) of the spectrum, such that the resulting\nshifted spectra show a maximum agreement. For real-world data the problem is\neven more complicated than our definition of MinSU; but our intractability\nresults clearly indicate that it is unlikely to find a polynomial time\nalgorithm for shotgun protein sequencing."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1109.3651v1", 
    "title": "Optimization, Randomized Approximability, and Boolean Constraint   Satisfaction Problems", 
    "arxiv-id": "1109.3651v1", 
    "author": "Tomoyuki Yamakami", 
    "publish": "2011-09-16T15:56:06Z", 
    "summary": "We give a unified treatment to optimization problems that can be expressed in\nthe form of nonnegative-real-weighted Boolean constraint satisfaction problems.\nCreignou, Khanna, Sudan, Trevisan, and Williamson studied the complexity of\napproximating their optimal solutions whose optimality is measured by the sums\nof outcomes of constraints. To explore a wider range of optimization constraint\nsatisfaction problems, following an early work of Marchetti-Spaccamela and\nRomano, we study the case where the optimality is measured by products of\nconstraints' outcomes. We completely classify those problems into three\ncategories: PO problems, NPO-hard problems, and intermediate problems that lie\nbetween the former two categories. To prove this trichotomy theorem, we analyze\ncharacteristics of nonnegative-real-weighted constraints using a variant of the\nnotion of T-constructibility developed earlier for complex-weighted counting\nconstraint satisfaction problems."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1109.5282v1", 
    "title": "Aut\u00f3matas celulares elementales aplicados a la encriptaci\u00f3n de datos", 
    "arxiv-id": "1109.5282v1", 
    "author": "Francisco Cruz Ordaz Salazar", 
    "publish": "2011-09-24T16:14:07Z", 
    "summary": "For data ciphering a key is usually needed as a base, so it is indispensable\nto have one that is strong and trustworthy, so as to keep others from accessing\nthe ciphered data. This requires a pseudo-random number generator that would\nprovide such a key, so it is proposed to work with cellular automata helped\nalong with \\emph{Mathematica} to check that the rules and to what level are\nactually pseudo-random. This project centers on the examination of possible\nmathematical rules, analyzing their characteristics in a detailed manner, and\nsubmitting them to a set of randomness tests with the end of knowing which of\nthem will enable us to obtain those pseudo-random numbers that will conform the\nkey for data ciphering."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-642-17458-2_26", 
    "link": "http://arxiv.org/pdf/1109.5789v1", 
    "title": "Approximation Complexity of Complex-Weighted Degree-Two Counting   Constraint Satisfaction Problems", 
    "arxiv-id": "1109.5789v1", 
    "author": "Tomoyuki Yamakami", 
    "publish": "2011-09-27T06:52:37Z", 
    "summary": "Constraint satisfaction problems have been studied in numerous fields with\npractical and theoretical interests. In recent years, major breakthroughs have\nbeen made in a study of counting constraint satisfaction problems (or #CSPs).\nIn particular, a computational complexity classification of bounded-degree\n#CSPs has been discovered for all degrees except for two, where the \"degree\" of\nan input instance is the maximal number of times that each input variable\nappears in a given set of constraints. Despite the efforts of recent studies,\nhowever, a complexity classification of degree-2 #CSPs has eluded from our\nunderstandings. This paper challenges this open problem and gives its partial\nsolution by applying two novel proof techniques--T_{2}-constructibility and\nparametrized symmetrization--which are specifically designed to handle\n\"arbitrary\" constraints under randomized approximation-preserving reductions.\nWe partition entire constraints into four sets and we classify the\napproximation complexity of all degree-2 #CSPs whose constraints are drawn from\ntwo of the four sets into two categories: problems computable in\npolynomial-time or problems that are at least as hard as #SAT. Our proof\nexploits a close relationship between complex-weighted degree-2 #CSPs and\nHolant problems, which are a natural generalization of complex-weighted #CSPs."
},{
    "category": "cs.CC", 
    "doi": "10.1109/FOCS.2012.25", 
    "link": "http://arxiv.org/pdf/1204.1079v2", 
    "title": "The Power of Linear Programming for Valued CSPs", 
    "arxiv-id": "1204.1079v2", 
    "author": "Stanislav Zivny", 
    "publish": "2012-04-04T21:12:26Z", 
    "summary": "A class of valued constraint satisfaction problems (VCSPs) is characterised\nby a valued constraint language, a fixed set of cost functions on a finite\ndomain. An instance of the problem is specified by a sum of cost functions from\nthe language with the goal to minimise the sum. This framework includes and\ngeneralises well-studied constraint satisfaction problems (CSPs) and maximum\nconstraint satisfaction problems (Max-CSPs).\n  Our main result is a precise algebraic characterisation of valued constraint\nlanguages whose instances can be solved exactly by the basic linear programming\nrelaxation. Using this result, we obtain tractability of several novel and\npreviously widely-open classes of VCSPs, including problems over valued\nconstraint languages that are: (1) submodular on arbitrary lattices; (2)\nbisubmodular (also known as k-submodular) on arbitrary finite domains; (3)\nweakly (and hence strongly) tree-submodular on arbitrary trees."
},{
    "category": "cs.CC", 
    "doi": "10.1109/FOCS.2012.25", 
    "link": "http://arxiv.org/pdf/1204.1196v2", 
    "title": "The Complexity of Monotone Hybrid Logics over Linear Frames and the   Natural Numbers", 
    "arxiv-id": "1204.1196v2", 
    "author": "Felix Weiss", 
    "publish": "2012-04-05T12:15:24Z", 
    "summary": "Hybrid logic with binders is an expressive specification language. Its\nsatisfiability problem is undecidable in general. If frames are restricted to N\nor general linear orders, then satisfiability is known to be decidable, but of\nnon-elementary complexity. In this paper, we consider monotone hybrid logics\n(i.e., the Boolean connectives are conjunction and disjunction only) over N and\ngeneral linear orders. We show that the satisfiability problem remains\nnon-elementary over linear orders, but its complexity drops to\nPSPACE-completeness over N. We categorize the strict fragments arising from\ndifferent combinations of modal and hybrid operators into NP-complete and\ntractable (i.e. complete for NC1or LOGSPACE). Interestingly, NP-completeness\ndepends only on the fragment and not on the frame. For the cases above NP,\nsatisfiability over linear orders is harder than over N, while below NP it is\nat most as hard. In addition we examine model-theoretic properties of the\nfragments in question."
},{
    "category": "cs.CC", 
    "doi": "10.1109/FOCS.2012.25", 
    "link": "http://arxiv.org/pdf/1204.2026v6", 
    "title": "Strengthened Hardness for Approximating Minimum Unique Game and Small   Set Expansion", 
    "arxiv-id": "1204.2026v6", 
    "author": "Peng Cui", 
    "publish": "2012-04-10T02:11:49Z", 
    "summary": "In this paper, the author puts forward a variation of Feige's Hypothesis,\nwhich claims that it is hard on average refuting Unbalanced Max 3-XOR under\nbiased assignments on a natural distribution. Under this hypothesis, the author\nstrengthens the previous known hardness for approximating Minimum Unique Game,\n$5/4-\\epsilon$, by proving that Min 2-Lin-2 is hard to within $3/2-\\epsilon$\nand strengthens the previous known hardness for approximating Small Set\nExpansion, $4/3-\\epsilon$, by proving that Min Bisection is hard to approximate\nwithin $3-\\epsilon$. In addition, the author discusses the limitation of this\nmethod to show that it can strengthen the hardness for approximating Minimum\nUnique Game to $2-\\kappa$ where $\\kappa$ is a small absolute positive, but is\nshort of proving $\\omega_k(1)$ hardness for Minimum Unique Game (or Small Set\nExpansion), by assuming a generalization of this hypothesis on Unbalanced Max\nk-CSP with Samorodnitsky-Trevisan hypergraph predicate."
},{
    "category": "cs.CC", 
    "doi": "10.1109/FOCS.2012.25", 
    "link": "http://arxiv.org/pdf/1204.2040v1", 
    "title": "A New Reduction from Search SVP to Optimization SVP", 
    "arxiv-id": "1204.2040v1", 
    "author": "Yanbin Pan", 
    "publish": "2012-04-10T04:23:24Z", 
    "summary": "It is well known that search SVP is equivalent to optimization SVP. However,\nthe former reduction from search SVP to optimization SVP by Kannan needs\npolynomial times calls to the oracle that solves the optimization SVP. In this\npaper, a new rank-preserving reduction is presented with only one call to the\noptimization SVP oracle. It is obvious that the new reduction needs the least\ncalls, and improves Kannan's classical result. What's more, the idea also leads\na similar direct reduction from search CVP to optimization CVP with only one\ncall to the oracle."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.2652v3", 
    "title": "Lower Bound on Weights of Large Degree Threshold Functions", 
    "arxiv-id": "1204.2652v3", 
    "author": "Vladimir V. Podolskii", 
    "publish": "2012-04-12T08:23:35Z", 
    "summary": "An integer polynomial $p$ of $n$ variables is called a \\emph{threshold gate}\nfor a Boolean function $f$ of $n$ variables if for all $x \\in \\zoon$ $f(x)=1$\nif and only if $p(x)\\geq 0$. The \\emph{weight} of a threshold gate is the sum\nof its absolute values.\n  In this paper we study how large a weight might be needed if we fix some\nfunction and some threshold degree. We prove $2^{\\Omega(2^{2n/5})}$ lower bound\non this value. The best previous bound was $2^{\\Omega(2^{n/8})}$ (Podolskii,\n2009).\n  In addition we present substantially simpler proof of the weaker\n$2^{\\Omega(2^{n/4})}$ lower bound. This proof is conceptually similar to other\nproofs of the bounds on weights of nonlinear threshold gates, but avoids a lot\nof technical details arising in other proofs. We hope that this proof will help\nto show the ideas behind the construction used to prove these lower bounds."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.4659v1", 
    "title": "The computational complexity of Minesweeper", 
    "arxiv-id": "1204.4659v1", 
    "author": "Michiel de Bondt", 
    "publish": "2012-04-20T15:57:40Z", 
    "summary": "We show that the Minesweeper game is PP-hard, when the object is to locate\nall mines with the highest probability. When the probability of locating all\nmines may be infinitesimal, the Minesweeper game is even PSPACE-complete. In\nour construction, the player can reveal a boolean circuit in polynomial time,\nafter guessing an initial square with no surrounding mines, a guess that has 99\npercent probability of success. Subsequently, the mines must be located with a\nmaximum probability of success.\n  Furthermore, we show that determining the solvability of a partially\nuncovered Minesweeper board is NP-complete with hexagonal and triangular grids\nas well as a square grid, extending a similar result for square grids only by\nR. Kaye. Actually finding the mines with a maximum probability of success is\nagain PP-hard or PSPACE-complete respectively.\n  Our constructions are in such a way that the number of mines can be computed\nin polynomial time and hence a possible mine counter does not provide\nadditional information. The results are obtained by replacing the dyadic gates\nin [3] by two primitives which makes life more easy in this context."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.5447v2", 
    "title": "Kolmogorov Complexity, Causality And Spin", 
    "arxiv-id": "1204.5447v2", 
    "author": "Dara O. Shayda", 
    "publish": "2012-04-24T17:50:58Z", 
    "summary": "A novel topological and computational method for 'motion' is described.\nMotion is constrained by inequalities in terms of Kolmogorov Complexity.\nCausality is obtained as the output of a high-pass filter, passing through only\nhigh values of Kolmogorov Complexity. Motion under the electromagnetic field\ndescribed with immediate relationship with Subscript[G, 2] Holonomy group and\nits corresponding dense free 2-subgroup. Similar to Causality, Spin emerges as\nan immediate and inevitable consequence of high values of Kolmogorov\nComplexity. Consequently, the physical laws are nothing but a low-pass filter\nfor small values of Kolmogorov Complexity."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.5508v1", 
    "title": "Relativizing Small Complexity Classes and their Theories", 
    "arxiv-id": "1204.5508v1", 
    "author": "Phuong Nguyen", 
    "publish": "2012-04-24T22:44:53Z", 
    "summary": "Existing definitions of the relativizations of \\NCOne, \\L\\ and \\NL\\ do not\npreserve the inclusions $\\NCOne \\subseteq \\L$, $\\NL\\subseteq \\ACOne$. We start\nby giving the first definitions that preserve them. Here for \\L\\ and \\NL\\ we\ndefine their relativizations using Wilson's stack oracle model, but limit the\nheight of the stack to a constant (instead of $\\log(n)$). We show that the\ncollapse of any two classes in $\\{\\ACZm, \\TCZ, \\NCOne, \\L, \\NL\\}$ implies the\ncollapse of their relativizations. Next we exhibit an oracle $\\alpha$ that\nmakes $\\ACk(\\alpha)$ a proper hierarchy. This strengthens and clarifies the\nseparations of the relativized theories in [Takeuti, 1995]. The idea is that a\ncircuit whose nested depth of oracle gates is bounded by $k$ cannot compute\ncorrectly the $(k+1)$ compositions of every oracle function. Finally we develop\ntheories that characterize the relativizations of subclasses of \\Ptime\\ by\nmodifying theories previously defined by the second two authors. A function is\nprovably total in a theory iff it is in the corresponding relativized class,\nand hence the oracle separations imply separations for the relativized\ntheories."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.5576v2", 
    "title": "Efficient programs of NPC problems should be length upper-bounded, and a   thought experiment to search for them by machine enumeration", 
    "arxiv-id": "1204.5576v2", 
    "author": "YuQian Zhou", 
    "publish": "2012-04-25T07:20:41Z", 
    "summary": "This paper proposes a thought experiment to search for efficient bounded\nalgorithms of NPC problems by machine enumeration. The key contributions are:\n  -- On Universal Turing Machines, a program's time complexity should be\ncharacterized as: execution time(n) = loading time(n) + running time(n).\n  -- Introduces the concept of bounded algorithms; proposes a comparison based\ncriterion to decide if a bounded algorithm is inefficient; and establishes the\nlength upper bound of efficient bounded programs.\n  -- Introduces the growth rate characteristic function to evaluate program\ncomplexity, which is more easily machine checkable based on observations.\n  -- Raises the theoretical question: if there exists any bounded algorithm\nwith polynomial execution time for NPC problems."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.5662v1", 
    "title": "On the Usefulness of Predicates", 
    "arxiv-id": "1204.5662v1", 
    "author": "Johan H\u00e5stad", 
    "publish": "2012-04-25T14:12:06Z", 
    "summary": "Motivated by the pervasiveness of strong inapproximability results for\nMax-CSPs, we introduce a relaxed notion of an approximate solution of a\nMax-CSP. In this relaxed version, loosely speaking, the algorithm is allowed to\nreplace the constraints of an instance by some other (possibly real-valued)\nconstraints, and then only needs to satisfy as many of the new constraints as\npossible.\n  To be more precise, we introduce the following notion of a predicate $P$\nbeing \\emph{useful} for a (real-valued) objective $Q$: given an almost\nsatisfiable Max-$P$ instance, there is an algorithm that beats a random\nassignment on the corresponding Max-$Q$ instance applied to the same sets of\nliterals. The standard notion of a nontrivial approximation algorithm for a\nMax-CSP with predicate $P$ is exactly the same as saying that $P$ is useful for\n$P$ itself.\n  We say that $P$ is useless if it is not useful for any $Q$. This turns out to\nbe equivalent to the following pseudo-randomness property: given an almost\nsatisfiable instance of Max-$P$ it is hard to find an assignment such that the\ninduced distribution on $k$-bit strings defined by the instance is not\nessentially uniform.\n  Under the Unique Games Conjecture, we give a complete and simple\ncharacterization of useful Max-CSPs defined by a predicate: such a Max-CSP is\nuseless if and only if there is a pairwise independent distribution supported\non the satisfying assignments of the predicate. It is natural to also consider\nthe case when no negations are allowed in the CSP instance, and we derive a\nsimilar complete characterization (under the UGC) there as well.\n  Finally, we also include some results and examples shedding additional light\non the approximability of certain Max-CSPs."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.5666v1", 
    "title": "A new point of NP-hardness for 2-to-1 Label Cover", 
    "arxiv-id": "1204.5666v1", 
    "author": "John Wright", 
    "publish": "2012-04-25T14:20:23Z", 
    "summary": "We show that given a satisfiable instance of the 2-to-1 Label Cover problem,\nit is NP-hard to find a $(23/24 + \\eps)$-satisfying assignment."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.5714v1", 
    "title": "Degree two approximate Boolean #CSPs with variable weights", 
    "arxiv-id": "1204.5714v1", 
    "author": "Colin McQuillan", 
    "publish": "2012-04-25T17:40:10Z", 
    "summary": "A counting constraint satisfaction problem (#CSP) asks for the number of ways\nto satisfy a given list of constraints, drawn from a fixed constraint language\n\\Gamma. We study how hard it is to evaluate this number approximately. There is\nan interesting partial classification, due to Dyer, Goldberg, Jalsenius and\nRicherby, of Boolean constraint languages when the degree of instances is\nbounded by d>=3 - every variable appears in at most d constraints - under the\nassumption that \"pinning\" is allowed as part of the instance. We study the d=2\ncase under the stronger assumption that \"variable weights\" are allowed as part\nof the instance. We give a dichotomy: in each case, either the #CSP is\ntractable, or one of two important open problems, #BIS or #PM, reduces to the\n#CSP."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.6445v2", 
    "title": "A Complete Dichotomy Rises from the Capture of Vanishing Signatures", 
    "arxiv-id": "1204.6445v2", 
    "author": "Tyson Williams", 
    "publish": "2012-04-29T00:22:39Z", 
    "summary": "We prove a complexity dichotomy theorem for Holant problems over an arbitrary\nset of complex-valued symmetric constraint functions F on Boolean variables.\nThis extends and unifies all previous dichotomies for Holant problems on\nsymmetric constraint functions (taking values without a finite modulus). We\ndefine and characterize all symmetric vanishing signatures. They turned out to\nbe essential to the complete classification of Holant problems. The dichotomy\ntheorem has an explicit tractability criterion expressible in terms of\nholographic transformations. A Holant problem defined by a set of constraint\nfunctions F is solvable in polynomial time if it satisfies this tractability\ncriterion, and is #P-hard otherwise. The tractability criterion can be\nintuitively stated as follows: A set F is tractable if (1) every function in F\nhas arity at most two, or (2) F is transformable to an affine type, or (3) F is\ntransformable to a product type, or (4) F is vanishing, combined with the right\ntype of binary functions, or (5) F belongs to a special category of vanishing\ntype Fibonacci gates. The proof of this theorem utilizes many previous\ndichotomy theorems on Holant problems and Boolean #CSP. Holographic\ntransformations play an indispensable role as both a proof technique and in the\nstatement of the tractability criterion."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.6484v1", 
    "title": "Universal Factor Graphs", 
    "arxiv-id": "1204.6484v1", 
    "author": "Shlomo Jozeph", 
    "publish": "2012-04-29T15:05:40Z", 
    "summary": "The factor graph of an instance of a symmetric constraint satisfaction\nproblem on n Boolean variables and m constraints (CSPs such as k-SAT, k-AND,\nk-LIN) is a bipartite graph describing which variables appear in which\nconstraints. The factor graph describes the instance up to the polarity of the\nvariables, and hence there are up to 2km instances of the CSP that share the\nsame factor graph. It is well known that factor graphs with certain structural\nproperties make the underlying CSP easier to either solve exactly (e.g., for\ntree structures) or approximately (e.g., for planar structures). We are\ninterested in the following question: is there a factor graph for which if one\ncan solve every instance of the CSP with this particular factor graph, then one\ncan solve every instance of the CSP regardless of the factor graph (and\nsimilarly, for approximation)? We call such a factor graph universal. As one\nneeds different factor graphs for different values of n and m, this gives rise\nto the notion of a family of universal factor graphs. We initiate a systematic\nstudy of universal factor graphs, and present some results for max-kSAT. Our\nwork has connections with the notion of preprocessing as previously studied for\nclosest codeword and closest lattice-vector problems, with proofs for the PCP\ntheorem, and with tests for the long code. Many questions remain open."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.6588v1", 
    "title": "A note on: No need to choose: How to get both a PTAS and Sublinear Query   Complexity", 
    "arxiv-id": "1204.6588v1", 
    "author": "Zohar Karnin", 
    "publish": "2012-04-30T10:34:58Z", 
    "summary": "We revisit various PTAS's (Polynomial Time Approximation Schemes) for\nminimization versions of dense problems, and show that they can be performed\nwith sublinear query complexity. This means that not only do we obtain a\n(1+eps)-approximation to the NP-Hard problems in polynomial time, but also\navoid reading the entire input. This setting is particularly advantageous when\nthe price of reading parts of the input is high, as is the case, for examples,\nwhere humans provide the input. Trading off query complexity with approximation\nis the raison d'etre of the field of learning theory, and of the ERM (Empirical\nRisk Minimization) setting in particular. A typical ERM result, however, does\nnot deal with computational complexity. We discuss two particular problems for\nwhich (a) it has already been shown that sublinear querying is sufficient for\nobtaining a (1 + eps)-approximation using unlimited computational power (an ERM\nresult), and (b) with full access to input, we could get a\n(1+eps)-approximation in polynomial time (a PTAS). Here we show that neither\nbenefit need be sacrificed. We get a PTAS with efficient query complexity."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1204.6696v1", 
    "title": "Nonuniform Kolmogorov extractors", 
    "arxiv-id": "1204.6696v1", 
    "author": "Marius Zimand", 
    "publish": "2012-04-30T16:42:34Z", 
    "summary": "We establish tight bounds on the amount on nonuniformity that is necessary\nfor extracting a string with randomness rate 1 from a single source of\nrandomness with lower randomness rate. More precisely, as instantiations of\nmore general results, we show that while O(1) amount of advice regarding the\nsource is not enough for extracting a string with randomness rate 1 from a\nsource string with constant subunitary random rate, \\omega(1) amount of advice\nis."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.0255v2", 
    "title": "Extending Partial Representations of Subclasses of Chordal Graphs", 
    "arxiv-id": "1207.0255v2", 
    "author": "Toshiki Saitoh", 
    "publish": "2012-07-01T23:47:02Z", 
    "summary": "Chordal graphs are intersection graphs of subtrees of a tree T. We\ninvestigate the complexity of the partial representation extension problem for\nchordal graphs. A partial representation specifies a tree T' and some pre-drawn\nsubtrees of T'. It asks whether it is possible to construct a representation\ninside a modified tree T which extends the partial representation (i.e, keeps\nthe pre-drawn subtrees unchanged).\n  We consider four modifications of T' and get vastly different problems. In\nsome cases, it is interesting to consider the complexity even if just T' is\ngiven and no subtree is pre-drawn. Also, we consider three well-known\nsubclasses of chordal graphs: Proper interval graphs, interval graphs and path\ngraphs. We give an almost complete complexity characterization.\n  We further study the parametrized complexity of the problems when\nparametrized by the number of pre-drawn subtrees, the number of components and\nthe size of the tree T'. We describe an interesting relation with integer\npartition problems. The problem Partition is used for all NP-completeness\nreductions. The extension of interval graphs when the space in T' is limited is\n\"equivalent\" to the BinPacking problem."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.0634v1", 
    "title": "Optimization of Quadratic Forms: NP Hard Problems : Neural Networks", 
    "arxiv-id": "1207.0634v1", 
    "author": "Garimella Rama Murthy", 
    "publish": "2012-07-03T11:08:21Z", 
    "summary": "In this research paper, the problem of optimization of a quadratic form over\nthe convex hull generated by the corners of hypercube is attempted and solved.\nSome results related to stable states/vectors, anti-stable states/vectors (over\nthe hypercube) are discussed. Some results related to the computation of global\noptimum stable state (an NP hard problem) are discussed. It is hoped that the\nresults shed light on resolving the P \\neq NP problem."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.2171v6", 
    "title": "Relationship between circuit complexity and symmetry", 
    "arxiv-id": "1207.2171v6", 
    "author": "Satoshi Tazawa", 
    "publish": "2012-07-06T19:45:23Z", 
    "summary": "It is already shown that a Boolean function for a NP-complete problem can be\ncomputed by a polynomial-sized circuit if its variables have enough number of\nautomorphisms. Looking at this previous study from the different perspective\ngives us the idea that the small number of automorphisms might be a barrier for\na polynomial time solution for NP-complete problems. Here I show that by\ninterpreting a Boolean circuit as a graph, the small number of graph\nautomorphisms and the large number of subgraph automorphisms in the circuit\nestablishes the exponential circuit lower bound for NP-complete problems. As\nthis strategy violates the largeness condition in Natural proof, this result\nshows that P!=NP without any contradictions to the existence of pseudorandom\nfunctions."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.2354v1", 
    "title": "Dichotomy for Holant* Problems with a Function on Domain Size 3", 
    "arxiv-id": "1207.2354v1", 
    "author": "Mingji Xia", 
    "publish": "2012-07-10T13:52:15Z", 
    "summary": "Holant problems are a general framework to study the algorithmic complexity\nof counting problems. Both counting constraint satisfaction problems and graph\nhomomorphisms are special cases. All previous results of Holant problems are\nover the Boolean domain. In this paper, we give the first dichotomy theorem for\nHolant problems for domain size $>2$. We discover unexpected tractable families\nof counting problems, by giving new polynomial time algorithms. This paper also\ninitiates holographic reductions in domains of size $>2$. This is our main\nalgorithmic technique, and is used for both tractable families and hardness\nreductions. The dichotomy theorem is the following: For any complex-valued\nsymmetric function ${\\bf F}$ with arity 3 on domain size 3, we give an explicit\ncriterion on ${\\bf F}$, such that if ${\\bf F}$ satisfies the criterion then the\nproblem ${\\rm Holant}^*({\\bf F})$ is computable in polynomial time, otherwise\n${\\rm Holant}^*({\\bf F})$ is #P-hard."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.4710v1", 
    "title": "Complexity of Canadian Traveler Problem Variants", 
    "arxiv-id": "1207.4710v1", 
    "author": "Cenny Wenner", 
    "publish": "2012-07-19T15:39:52Z", 
    "summary": "The Canadian traveler problem (CTP) is the problem of traversing a given\ngraph, where some of the edges may be blocked - a state which is revealed only\nupon reaching an incident vertex. Originally stated by Papadimitriou and\nYannakakis (1991), the adversarial version of CTP was shown to be\nPSPACE-complete, with the stochastic version shown to be #P-hard. We show that\nstochastic CTP is also PSPACE-complete: initially proving PSPACE-hardness for\nthe dependent version of stochastic CTP,and proceeding with gadgets that allow\nus to extend the proof to the independent case. Since for disjoint-path graphs,\nCTP can be solved in polynomial time, we examine the complexity of the more\ngeneral remote-sensing CTP, and show that it is NP-hard even for disjoint-path\ngraphs."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.4715v1", 
    "title": "\"Two betting strategies that predict all compressible sequences\"   presentation", 
    "arxiv-id": "1207.4715v1", 
    "author": "Tomislav Petrovi\u0107", 
    "publish": "2012-07-19T15:59:15Z", 
    "summary": "Presentation for a talk \"Two betting strategies that predict all compressible\nsequences\" given at Seventh International Conference on Computability,\nComplexity and Randomness (CCR 2012)\nhttp://www.newton.ac.uk/programmes/SAS/seminars/070217001.html"
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.5321v1", 
    "title": "Cancellation-free circuits: An approach for proving superlinear lower   bounds for linear Boolean operators", 
    "arxiv-id": "1207.5321v1", 
    "author": "Magnus Find", 
    "publish": "2012-07-23T08:50:09Z", 
    "summary": "We continue to study the notion of cancellation-free linear circuits. We show\nthat every matrix can be computed by a cancellation- free circuit, and almost\nall of these are at most a constant factor larger than the optimum linear\ncircuit that computes the matrix. It appears to be easier to prove statements\nabout the structure of cancellation-free linear circuits than for linear\ncircuits in general. We prove two nontrivial superlinear lower bounds. We show\nthat a cancellation-free linear circuit computing the $n\\times n$ Sierpinski\ngasket matrix must use at least 1/2 n logn gates, and that this is tight. This\nsupports a conjecture by Aaronson. Furthermore we show that a proof strategy\nfor proving lower bounds on monotone circuits can be almost directly converted\nto prove lower bounds on cancellation-free linear circuits. We use this\ntogether with a result from extremal graph theory due to Andreev to prove a\nlower bound of {\\Omega}(n^(2- \\epsilon)) for infinitely many $n \\times n$\nmatrices for every $\\epsilon > 0$ for. These lower bounds for concrete matrices\nare almost optimal since all matrices can be computed with $O(n^2/\\log n)$\ngates."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1207.7213v4", 
    "title": "The power of linear programming for valued CSPs: a constructive   characterization", 
    "arxiv-id": "1207.7213v4", 
    "author": "Vladimir Kolmogorov", 
    "publish": "2012-07-31T11:44:23Z", 
    "summary": "A class of valued constraint satisfaction problems (VCSPs) is characterised\nby a valued constraint language, a fixed set of cost functions on a finite\ndomain. An instance of the problem is specified by a sum of cost functions from\nthe language with the goal to minimise the sum.\n  We study which classes of finite-valued languages can be solved exactly by\nthe basic linear programming relaxation (BLP). Thapper and Zivny showed [20]\nthat if BLP solves the language then the language admits a binary commutative\nfractional polymorphism. We prove that the converse is also true. This leads to\na necessary and a sufficient condition which can be checked in polynomial time\nfor a given language. In contrast, the previous necessary and sufficient\ncondition due to [20] involved infinitely many inequalities.\n  More recently, Thapper and Zivny [21] showed (using, in particular, a\ntechnique introduced in this paper) that core languages that do not satisfy our\ncondition are NP-hard. Taken together, these results imply that a finite-valued\nlanguage can either be solved using Linear Programming or is NP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.0027v5", 
    "title": "Three-Element Min-Sol and Conservative Min-Cost-Hom", 
    "arxiv-id": "1301.0027v5", 
    "author": "Hannes Uppman", 
    "publish": "2012-12-31T22:57:41Z", 
    "summary": "Thapper and Zivny [STOC'13] recently classified the complexity of VCSP for\nall finite-valued constraint languages. However, the complexity of VCSPs for\nconstraint languages that are not finite-valued remains poorly understood. In\nthis paper we study the complexity of two such VCSPs, namely Min-Cost-Hom and\nMin-Sol. We obtain a full classification for the complexity of Min-Sol on\ndomains that contain at most three elements and for the complexity of\nconservative Min-Cost-Hom on arbitrary finite domains. Our results answer a\nquestion raised by Takhanov [STACS'10, COCOON'10]."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.0862v1", 
    "title": "On Lower Bound Methods for Tree-like Cutting Plane Proofs", 
    "arxiv-id": "1301.0862v1", 
    "author": "Daniel Apon", 
    "publish": "2013-01-05T03:10:49Z", 
    "summary": "In the book Boolean Function Complexity by Stasys Jukna, two lower bound\ntechniques for Tree-like Cutting Plane proofs (henceforth, \"Tree-CP proofs\")\nusing Karchmer-Widgerson type communication games (henceforth, \"KW games\") are\npresented: The first, applicable to Tree-CP proofs with bounded coefficients,\ntranslates Omega(t) deterministic lower bounds on KW games to 2^Omega(t/log n)\nlower bounds on Tree-CP proof size. The second, applicable to Tree-CP proofs\nwith unbounded coefficients, translates Omega(t) randomized lower bounds on KW\ngames to 2^Omega(t/log^2 n) lower bounds on Tree-CP proof size.\n  The textbook proof in the latter case uses a O(log^2 n)-bit randomized\nprotocol for the GreaterThan function. However, Nisan mentioned using the ideas\nof Feige, et al. to construct a O(log n + log(1/epsilon))-bit randomized\nprotocol for GreaterThan. Nisan did not explicitly give the proof, though later\nresults in his paper assume such a protocol.\n  In this short exposition, we present the full O(log n + log(1/epsilon))-bit\nrandomized protocol for the GreaterThan function based on the ideas of Feige,\net al. for \"noisy binary search.\" As an application, we show how to translate\nOmega(t) randomized lower bounds on KW games to 2^Omega(t/log n) lower bounds\non Tree-CP proof size in the unbounded coefficient case. This equates\nrandomness with coefficient size for the Tree-CP/KW game lower bound method.\n  We believe that, while the O(log n + log(1/epsilon))-bit randomized protocol\nfor GreaterThan is a \"known\" result, the explicit connection to Tree-CP proof\nsize lower bounds given here is new."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.1425v2", 
    "title": "Pebbling, Entropy and Branching Program Size Lower Bounds", 
    "arxiv-id": "1301.1425v2", 
    "author": "Jayalal Sarma M. N", 
    "publish": "2013-01-08T06:52:06Z", 
    "summary": "We contribute to the program of proving lower bounds on the size of branching\nprograms solving the Tree Evaluation Problem introduced by Cook et. al. (2012).\nProving a super-polynomial lower bound for the size of nondeterministic thrifty\nbranching programs (NTBP) would separate $NL$ from $P$ for thrifty models\nsolving the tree evaluation problem. First, we show that {\\em Read-Once NTBPs}\nare equivalent to whole black-white pebbling algorithms thus showing a tight\nlower bound (ignoring polynomial factors) for this model.\n  We then introduce a weaker restriction of NTBPs called {\\em Bitwise\nIndependence}. The best known NTBPs (of size $O(k^{h/2+1})$) for the tree\nevaluation problem given by Cook et. al. (2012) are Bitwise Independent. As our\nmain result, we show that any Bitwise Independent NTBP solving $TEP_{2}^{h}(k)$\nmust have at least $\\frac{1}{2}k^{h/2}$ states. Prior to this work, lower\nbounds were known for NTBPs only for fixed heights $h=2,3,4$ (See Cook et. al.\n(2012)). We prove our results by associating a fractional black-white pebbling\nstrategy with any bitwise independent NTBP solving the Tree Evaluation Problem.\nSuch a connection was not known previously even for fixed heights.\n  Our main technique is the entropy method introduced by Jukna and Z{\\'a}k\n(2001) originally in the context of proving lower bounds for read-once\nbranching programs. We also show that the previous lower bounds given by Cook\net. al. (2012) for deterministic branching programs for Tree Evaluation Problem\ncan be obtained using this approach. Using this method, we also show tight\nlower bounds for any $k$-way deterministic branching program solving Tree\nEvaluation Problem when the instances are restricted to have the same group\noperation in all internal nodes."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.2729v1", 
    "title": "On the Power of Many One-Bit Provers", 
    "arxiv-id": "1301.2729v1", 
    "author": "Rafael Pass", 
    "publish": "2013-01-12T23:02:05Z", 
    "summary": "We study the class of languages, denoted by $\\MIP[k, 1-\\epsilon, s]$, which\nhave $k$-prover games where each prover just sends a \\emph{single} bit, with\ncompleteness $1-\\epsilon$ and soundness error $s$. For the case that $k=1$\n(i.e., for the case of interactive proofs), Goldreich, Vadhan and Wigderson\n({\\em Computational Complexity'02}) demonstrate that $\\SZK$ exactly\ncharacterizes languages having 1-bit proof systems with\"non-trivial\" soundness\n(i.e., $1/2 < s \\leq 1-2\\epsilon$). We demonstrate that for the case that\n$k\\geq 2$, 1-bit $k$-prover games exhibit a significantly richer structure:\n  + (Folklore) When $s \\leq \\frac{1}{2^k} - \\epsilon$, $\\MIP[k, 1-\\epsilon, s]\n= \\BPP$;\n  + When $\\frac{1}{2^k} + \\epsilon \\leq s < \\frac{2}{2^k}-\\epsilon$, $\\MIP[k,\n1-\\epsilon, s] = \\SZK$;\n  + When $s \\ge \\frac{2}{2^k} + \\epsilon$, $\\AM \\subseteq \\MIP[k, 1-\\epsilon,\ns]$;\n  + For $s \\le 0.62 k/2^k$ and sufficiently large $k$, $\\MIP[k, 1-\\epsilon, s]\n\\subseteq \\EXP$;\n  + For $s \\ge 2k/2^{k}$, $\\MIP[k, 1, 1-\\epsilon, s] = \\NEXP$.\n  As such, 1-bit $k$-prover games yield a natural \"quantitative\" approach to\nrelating complexity classes such as $\\BPP$,$\\SZK$,$\\AM$, $\\EXP$, and $\\NEXP$.\nWe leave open the question of whether a more fine-grained hierarchy (between\n$\\AM$ and $\\NEXP$) can be established for the case when $s \\geq \\frac{2}{2^k} +\n\\epsilon$."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.2731v1", 
    "title": "A Characterization of Approximation Resistance for Even $k$-Partite CSPs", 
    "arxiv-id": "1301.2731v1", 
    "author": "Subhash Khot", 
    "publish": "2013-01-12T23:04:32Z", 
    "summary": "A constraint satisfaction problem (CSP) is said to be \\emph{approximation\nresistant} if it is hard to approximate better than the trivial algorithm which\npicks a uniformly random assignment. Assuming the Unique Games Conjecture, we\ngive a characterization of approximation resistance for $k$-partite CSPs\ndefined by an even predicate."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.4269v2", 
    "title": "One-Round Multi-Party Communication Complexity of Distinguishing Sums", 
    "arxiv-id": "1301.4269v2", 
    "author": "Alex J. Malozemoff", 
    "publish": "2013-01-17T23:15:27Z", 
    "summary": "We consider an instance of the following problem: Parties P_1,..., P_k each\nreceive an input x_i, and a coordinator (distinct from each of these parties)\nwishes to compute f(x_1,..., x_k) for some predicate f. We are interested in\none-round protocols where each party sends a single message to the coordinator;\nthere is no communication between the parties themselves. What is the minimum\ncommunication complexity needed to compute f, possibly with bounded error?\n  We prove tight bounds on the one-round communication complexity when f\ncorresponds to the promise problem of distinguishing sums (namely, determining\nwhich of two possible values the {x_i} sum to) or the problem of determining\nwhether the {x_i} sum to a particular value. Similar problems were studied\npreviously by Nisan and in concurrent work by Viola. Our proofs rely on basic\ntheorems from additive combinatorics, but are otherwise elementary."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.4451v2", 
    "title": "On the logical depth function", 
    "arxiv-id": "1301.4451v2", 
    "author": "P. M. B. Vitanyi", 
    "publish": "2013-01-18T18:20:34Z", 
    "summary": "For a finite binary string $x$ its logical depth $d$ for significance $b$ is\nthe shortest running time of a program for $x$ of length $K(x)+b$. There is\nanother definition of logical depth. We give a new proof that the two versions\nare close. There is an infinite sequence of strings of consecutive lengths such\nthat for every string there is a $b$ such that incrementing $b$ by 1 makes the\nassociated depths go from incomputable to computable. The maximal gap between\ndepths resulting from incrementing appropriate $b$'s by 1 is incomputable. The\nsize of this gap is upper bounded by the Busy Beaver function. Both the upper\nand the lower bound hold for the depth with significance 0. As a consequence,\nthe minimal computation time of the associated shortest programs rises faster\nthan any computable function but not so fast as the Busy Beaver function."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1301.5216v3", 
    "title": "Improved Hardness of Approximating Chromatic Number", 
    "arxiv-id": "1301.5216v3", 
    "author": "Sangxia Huang", 
    "publish": "2013-01-22T15:57:59Z", 
    "summary": "We prove that for sufficiently large K, it is NP-hard to color K-colorable\ngraphs with less than 2^{K^{1/3}} colors. This improves the previous result of\nK versus K^{O(log K)} in Khot [14]."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.0513v2", 
    "title": "Separating OR, SUM, and XOR Circuits", 
    "arxiv-id": "1304.0513v2", 
    "author": "Janne H. Korhonen", 
    "publish": "2013-04-02T01:25:48Z", 
    "summary": "Given a boolean n by n matrix A we consider arithmetic circuits for computing\nthe transformation x->Ax over different semirings. Namely, we study three\ncircuit models: monotone OR-circuits, monotone SUM-circuits (addition of\nnon-negative integers), and non-monotone XOR-circuits (addition modulo 2). Our\nfocus is on \\emph{separating} these models in terms of their circuit\ncomplexities. We give three results towards this goal:\n  (1) We prove a direct sum type theorem on the monotone complexity of tensor\nproduct matrices. As a corollary, we obtain matrices that admit OR-circuits of\nsize O(n), but require SUM-circuits of size \\Omega(n^{3/2}/\\log^2n).\n  (2) We construct so-called \\emph{k-uniform} matrices that admit XOR-circuits\nof size O(n), but require OR-circuits of size \\Omega(n^2/\\log^2n).\n  (3) We consider the task of \\emph{rewriting} a given OR-circuit as a\nXOR-circuit and prove that any subquadratic-time algorithm for this task\nviolates the strong exponential time hypothesis."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.0713v1", 
    "title": "Represent MOD function by low degree polynomial with unbounded one-sided   error", 
    "arxiv-id": "1304.0713v1", 
    "author": "Yuan Li", 
    "publish": "2013-04-02T17:50:54Z", 
    "summary": "In this paper, we prove tight lower bounds on the smallest degree of a\nnonzero polynomial in the ideal generated by $MOD_q$ or $\\neg MOD_q$ in the\npolynomial ring $F_p[x_1, \\ldots, x_n]/(x_1^2 = x_1, \\ldots, x_n^2 = x_n)$,\n$p,q$ are coprime, which is called \\emph{immunity} over $F_p$. The immunity of\n$MOD_q$ is lower bounded by $\\lfloor (n+1)/2 \\rfloor$, which is achievable when\n$n$ is a multiple of $2q$; the immunity of $\\neg MOD_q$ is exactly $\\lfloor\n(n+q-1)/q \\rfloor$ for every $q$ and $n$. Our result improves the previous\nbound $\\lfloor \\frac{n}{2(q-1)} \\rfloor$ by Green.\n  We observe how immunity over $F_p$ is related to $\\acc$ circuit lower bound.\nFor example, if the immunity of $f$ over $F_p$ is lower bounded by $n/2 -\no(\\sqrt{n})$, and $|1_f| = \\Omega(2^n)$, then $f$ requires $\\acc$ circuit of\nexponential size to compute."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1005v1", 
    "title": "On optimal language compression for sets in PSPACE/poly", 
    "arxiv-id": "1304.1005v1", 
    "author": "Marius Zimand", 
    "publish": "2013-04-03T16:37:02Z", 
    "summary": "We show that if DTIME[2^O(n)] is not included in DSPACE[2^o(n)], then, for\nevery set B in PSPACE/poly, all strings x in B of length n can be represented\nby a string compressed(x) of length at most log(|B^{=n}|)+O(log n), such that a\npolynomial-time algorithm, given compressed(x), can distinguish x from all the\nother strings in B^{=n}. Modulo the O(log n) additive term, this achieves the\ninformation-theoretic optimum for string compression. We also observe that\noptimal compression is not possible for sets more complex than PSPACE/poly\nbecause for any time-constructible superpolynomial function t, there is a set A\ncomputable in space t(n) such that at least one string x of length n requires\ncompressed(x) to be of length 2 log(|A^=n|)."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1217v1", 
    "title": "On the communication complexity of sparse set disjointness and   exists-equal problems", 
    "arxiv-id": "1304.1217v1", 
    "author": "Gabor Tardos", 
    "publish": "2013-04-04T00:20:31Z", 
    "summary": "In this paper we study the two player randomized communication complexity of\nthe sparse set disjointness and the exists-equal problems and give matching\nlower and upper bounds (up to constant factors) for any number of rounds for\nboth of these problems. In the sparse set disjointness problem, each player\nreceives a k-subset of [m] and the goal is to determine whether the sets\nintersect. For this problem, we give a protocol that communicates a total of\nO(k\\log^{(r)}k) bits over r rounds and errs with very small probability. Here\nwe can take r=\\log^{*}k to obtain a O(k) total communication \\log^{*}k-round\nprotocol with exponentially small error probability, improving on the O(k)-bits\nO(\\log k)-round constant error probability protocol of Hastad and Wigderson\nfrom 1997.\n  In the exist-equal problem, the players receive vectors x,y\\in [t]^n and the\ngoal is to determine whether there exists a coordinate i such that x_i=y_i.\nNamely, the exists-equal problem is the OR of n equality problems. Observe that\nexists-equal is an instance of sparse set disjointness with k=n, hence the\nprotocol above applies here as well, giving an O(n\\log^{(r)}n) upper bound. Our\nmain technical contribution in this paper is a matching lower bound: we show\nthat when t=\\Omega(n), any r-round randomized protocol for the exists-equal\nproblem with error probability at most 1/3 should have a message of size\n\\Omega(n\\log^{(r)}n). Our lower bound holds even for super-constant r <=\n\\log^*n, showing that any O(n) bits exists-equal protocol should have \\log^*n -\nO(1) rounds."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1245v2", 
    "title": "Fourier sparsity, spectral norm, and the Log-rank conjecture", 
    "arxiv-id": "1304.1245v2", 
    "author": "Shengyu Zhang", 
    "publish": "2013-04-04T04:59:41Z", 
    "summary": "We study Boolean functions with sparse Fourier coefficients or small spectral\nnorm, and show their applications to the Log-rank Conjecture for XOR functions\nf(x\\oplus y) --- a fairly large class of functions including well studied ones\nsuch as Equality and Hamming Distance. The rank of the communication matrix M_f\nfor such functions is exactly the Fourier sparsity of f. Let d be the F2-degree\nof f and D^CC(f) stand for the deterministic communication complexity for\nf(x\\oplus y). We show that 1. D^CC(f) = O(2^{d^2/2} log^{d-2} ||\\hat f||_1). In\nparticular, the Log-rank conjecture holds for XOR functions with constant\nF2-degree. 2. D^CC(f) = O(d ||\\hat f||_1) = O(\\sqrt{rank(M_f)}\\logrank(M_f)).\nWe obtain our results through a degree-reduction protocol based on a variant of\npolynomial rank, and actually conjecture that its communication cost is already\n\\log^{O(1)}rank(M_f). The above bounds also hold for the parity decision tree\ncomplexity of f, a measure that is no less than the communication complexity\n(up to a factor of 2).\n  Along the way we also show several structural results about Boolean functions\nwith small F2-degree or small spectral norm, which could be of independent\ninterest. For functions f with constant F2-degree: 1) f can be written as the\nsummation of quasi-polynomially many indicator functions of subspaces with\n\\pm-signs, improving the previous doubly exponential upper bound by Green and\nSanders; 2) being sparse in Fourier domain is polynomially equivalent to having\na small parity decision tree complexity; 3) f depends only on polylog||\\hat\nf||_1 linear functions of input variables. For functions f with small spectral\nnorm: 1) there is an affine subspace with co-dimension O(||\\hat f||_1) on which\nf is a constant; 2) there is a parity decision tree with depth O(||\\hat f||_1\nlog ||\\hat f||_0)."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1307v1", 
    "title": "On the structure of the class NP", 
    "arxiv-id": "1304.1307v1", 
    "author": "Anatoly D. Plotnikov", 
    "publish": "2013-04-04T10:26:49Z", 
    "summary": "A new class UF of problems is introduced, strictly included in the class NP,\nwhich arises in the analysis of the time verifying the intermediate results of\ncomputations. The implications of the introduction of this class are\nconsidered. First of all, we prove that $P\\not= NP$ and establish that it needs\nto consider the problem \"P vs UF\" instead the problem \"P vs NP\". Also, we\ndetermine the set-theoretical of properties of a one-way functions that used in\ncryptology."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1347v1", 
    "title": "A composition theorem for the Fourier Entropy-Influence conjecture", 
    "arxiv-id": "1304.1347v1", 
    "author": "Li-Yang Tan", 
    "publish": "2013-04-04T12:28:49Z", 
    "summary": "The Fourier Entropy-Influence (FEI) conjecture of Friedgut and Kalai [FK96]\nseeks to relate two fundamental measures of Boolean function complexity: it\nstates that $H[f] \\leq C Inf[f]$ holds for every Boolean function $f$, where\n$H[f]$ denotes the spectral entropy of $f$, $Inf[f]$ is its total influence,\nand $C > 0$ is a universal constant. Despite significant interest in the\nconjecture it has only been shown to hold for a few classes of Boolean\nfunctions.\n  Our main result is a composition theorem for the FEI conjecture. We show that\nif $g_1,...,g_k$ are functions over disjoint sets of variables satisfying the\nconjecture, and if the Fourier transform of $F$ taken with respect to the\nproduct distribution with biases $E[g_1],...,E[g_k]$ satisfies the conjecture,\nthen their composition $F(g_1(x^1),...,g_k(x^k))$ satisfies the conjecture. As\nan application we show that the FEI conjecture holds for read-once formulas\nover arbitrary gates of bounded arity, extending a recent result [OWZ11] which\nproved it for read-once decision trees. Our techniques also yield an explicit\nfunction with the largest known ratio of $C \\geq 6.278$ between $H[f]$ and\n$Inf[f]$, improving on the previous lower bound of 4.615."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1679v2", 
    "title": "Intrinsic universality in tile self-assembly requires cooperation", 
    "arxiv-id": "1304.1679v2", 
    "author": "Damien Woods", 
    "publish": "2013-04-05T11:11:26Z", 
    "summary": "We prove a negative result on the power of a model of algorithmic\nself-assembly for which it has been notoriously difficult to find general\ntechniques and results. Specifically, we prove that Winfree's abstract Tile\nAssembly Model, when restricted to use noncooperative tile binding, is not\nintrinsically universal. This stands in stark contrast to the recent result\nthat, via cooperative binding, the abstract Tile Assembly Model is indeed\nintrinsically universal. Noncooperative self-assembly, also known as\n\"temperature 1\", is where tiles bind to each other if they match on one or more\nsides, whereas cooperative binding requires binding on multiple sides. Our\nresult shows that the change from single- to multi-sided binding qualitatively\nimproves the kinds of dynamics and behavior that these models of nanoscale\nself-assembly are capable of. Our lower bound on simulation power holds in both\ntwo and three dimensions; the latter being quite surprising given that\nthree-dimensional noncooperative tile assembly systems simulate Turing\nmachines. On the positive side, we exhibit a three-dimensional noncooperative\nself-assembly tile set capable of simulating any two-dimensional noncooperative\nself-assembly system.\n  Our negative result can be interpreted to mean that Turing universal\nalgorithmic behavior in self-assembly does not imply the ability to simulate\narbitrary algorithmic self-assembly processes."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1796v2", 
    "title": "The Round Complexity of Small Set Intersection", 
    "arxiv-id": "1304.1796v2", 
    "author": "Grigory Yaroslavtsev", 
    "publish": "2013-04-05T19:53:52Z", 
    "summary": "The set disjointness problem is one of the most fundamental and well-studied\nproblems in communication complexity. In this problem Alice and Bob hold sets\n$S, T \\subseteq [n]$, respectively, and the goal is to decide if $S \\cap T =\n\\emptyset$. Reductions from set disjointness are a canonical way of proving\nlower bounds in data stream algorithms, data structures, and distributed\ncomputation. In these applications, often the set sizes $|S|$ and $|T|$ are\nbounded by a value $k$ which is much smaller than $n$. This is referred to as\nsmall set disjointness. A major restriction in the above applications is the\nnumber of rounds that the protocol can make, which, e.g., translates to the\nnumber of passes in streaming applications. A fundamental question is thus in\nunderstanding the round complexity of the small set disjointness problem. For\nan essentially equivalent problem, called OR-Equality, Brody et. al showed that\nwith $r$ rounds of communication, the randomized communication complexity is\n$\\Omega(k \\ilog^r k)$, where$\\ilog^r k$ denotes the $r$-th iterated logarithm\nfunction. Unfortunately their result requires the error probability of the\nprotocol to be $1/k^{\\Theta(1)}$. Since na\\\"ive amplification of the success\nprobability of a protocol from constant to $1-1/k^{\\Theta(1)}$ blows up the\ncommunication by a $\\Theta(\\log k)$ factor, this destroys their improvements\nover the well-known lower bound of $\\Omega(k)$ which holds for any number of\nrounds. They pose it as an open question to achieve the same $\\Omega(k \\ilog^r\nk)$ lower bound for protocols with constant error probability. We answer this\nopen question by showing that the $r$-round randomized communication complexity\nof ${\\sf OREQ}_{n,k}$, and thus also of small set disjointness, with {\\it\nconstant error probability} is $\\Omega(k \\ilog^r k)$, asymptotically matching\nknown upper bounds for ${\\sf OREQ}_{n,k}$ and small set disjointness."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.1996v1", 
    "title": "On the Subexponential Time Complexity of CSP", 
    "arxiv-id": "1304.1996v1", 
    "author": "Stefan Szeider", 
    "publish": "2013-04-07T13:19:18Z", 
    "summary": "A CSP with n variables ranging over a domain of d values can be solved by\nbrute-force in d^n steps (omitting a polynomial factor). With a more careful\napproach, this trivial upper bound can be improved for certain natural\nrestrictions of the CSP. In this paper we establish theoretical limits to such\nimprovements, and draw a detailed landscape of the subexponential-time\ncomplexity of CSP.\n  We first establish relations between the subexponential-time complexity of\nCSP and that of other problems, including CNF-Sat. We exploit this connection\nto provide tight characterizations of the subexponential-time complexity of CSP\nunder common assumptions in complexity theory. For several natural CSP\nparameters, we obtain threshold functions that precisely dictate the\nsubexponential-time complexity of CSP with respect to the parameters under\nconsideration.\n  Our analysis provides fundamental results indicating whether and when one can\nsignificantly improve on the brute-force search approach for solving CSP."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.2026v1", 
    "title": "Resolution structure in HornSAT and CNFSAT", 
    "arxiv-id": "1304.2026v1", 
    "author": "Koji Kobayashi", 
    "publish": "2013-04-07T17:06:29Z", 
    "summary": "This article describes about the difference of resolution structure and size\nbetween HornSAT and CNFSAT. We can compute HornSAT by using clauses causality.\nTherefore we can compute proof diagram by using Log space reduction. But we\nmust compute CNFSAT by using clauses correlation. Therefore we cannot compute\nproof diagram by using Log space reduction, and reduction of CNFSAT is not\nP-Complete."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.2557v3", 
    "title": "The H-index can be easily manipulated", 
    "arxiv-id": "1304.2557v3", 
    "author": "Krzysztof R. Apt", 
    "publish": "2013-04-09T12:39:20Z", 
    "summary": "We prove two complexity results about the H-index concerned with the Google\nscholar merge operation on one's scientific articles. The results show that,\nalthough it is hard to merge one's articles in an optimal way, it is easy to\nmerge them in such a way that one's H-index increases. This suggests the need\nfor an alternative scientific performance measure that is resistant to this\ntype of manipulation."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.3139v3", 
    "title": "The Complexity of Approximating Vertex Expansion", 
    "arxiv-id": "1304.3139v3", 
    "author": "Santosh Vempala", 
    "publish": "2013-04-10T20:31:28Z", 
    "summary": "We study the complexity of approximating the vertex expansion of graphs $G =\n(V,E)$, defined as \\[ \\Phi^V := \\min_{S \\subset V} n \\cdot \\frac{|N(S)|}{|S| |V\n\\backslash S|}. \\]\n  We give a simple polynomial-time algorithm for finding a subset with vertex\nexpansion $O(\\sqrt{OPT \\log d})$ where $d$ is the maximum degree of the graph.\nOur main result is an asymptotically matching lower bound: under the Small Set\nExpansion (SSE) hypothesis, it is hard to find a subset with expansion less\nthan $C\\sqrt{OPT \\log d}$ for an absolute constant $C$. In particular, this\nimplies for all constant $\\epsilon > 0$, it is SSE-hard to distinguish whether\nthe vertex expansion $< \\epsilon$ or at least an absolute constant. The\nanalogous threshold for edge expansion is $\\sqrt{OPT}$ with no dependence on\nthe degree; thus our results suggest that vertex expansion is harder to\napproximate than edge expansion. In particular, while Cheeger's algorithm can\ncertify constant edge expansion, it is SSE-hard to certify constant vertex\nexpansion in graphs.\n  Our proof is via a reduction from the {\\it Unique Games} instance obtained\nfrom the \\SSE hypothesis to the vertex expansion problem. It involves the\ndefinition of a smoother intermediate problem we call {\\sf Analytic Vertex\nExpansion} which is representative of both the vertex expansion and the\nconductance of the graph. Both reductions (from the UGC instance to this\nproblem and from this problem to vertex expansion) use novel proof ideas."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.3872v2", 
    "title": "All Sampling Methods Produce Outliers", 
    "arxiv-id": "1304.3872v2", 
    "author": "Samuel Epstein", 
    "publish": "2013-04-14T02:16:32Z", 
    "summary": "Given a computable probability measure P over natural numbers or infinite\nbinary sequences, there is no method that can produce an arbitrarily large\nsample such that all its members are typical of P. This paper also contains\nupper bounds on the minimal encoding length of a predicate (over the set of\nnatural numbers) consistent with another predicate over a finite domain."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5247v3", 
    "title": "Computational Irreducibility and Computational Analogy", 
    "arxiv-id": "1304.5247v3", 
    "author": "Herve Zwirn", 
    "publish": "2013-04-18T20:27:26Z", 
    "summary": "In a previous paper, we provided a formal definition for the concept of\ncomputational irreducibility (CIR), i.e. the fact for a function f from N to N\nthat it is impossible to compute f(n) without following approximately the same\npath than computing successively all the values f(i) from i=1 to n. Our\ndefinition is based on the concept of E Turing machines (for Enumerating Turing\nMachines) and on the concept of approximation of E Turing machines for which we\nalso gave a formal definition. We precise here these definitions through some\nmodifications intended to improve the robustness of the concept. We introduce\nthen a new concept: the Computational Analogy and prove some properties of\ncomputationally analog functions. Computational Analogy is an equivalence\nrelation which allows partitioning the set of computable functions in classes\nwhose members have the same properties regarding to their computational\nirreducibility and their computational complexity."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5388v2", 
    "title": "Complexity Classifications for logic-based Argumentation", 
    "arxiv-id": "1304.5388v2", 
    "author": "Johannes Schmidt", 
    "publish": "2013-04-19T12:10:51Z", 
    "summary": "We consider logic-based argumentation in which an argument is a pair (Fi,al),\nwhere the support Fi is a minimal consistent set of formulae taken from a given\nknowledge base (usually denoted by De) that entails the claim al (a formula).\nWe study the complexity of three central problems in argumentation: the\nexistence of a support Fi ss De, the validity of a support and the relevance\nproblem (given psi is there a support Fi such that psi ss Fi?). When arguments\nare given in the full language of propositional logic these problems are\ncomputationally costly tasks, the validity problem is DP-complete, the others\nare SigP2-complete. We study these problems in Schaefer's famous framework\nwhere the considered propositional formulae are in generalized conjunctive\nnormal form. This means that formulae are conjunctions of constraints build\nupon a fixed finite set of Boolean relations Ga (the constraint language). We\nshow that according to the properties of this language Ga, deciding whether\nthere exists a support for a claim in a given knowledge base is either\npolynomial, NP-complete, coNP-complete or SigP2-complete. We present a\ndichotomous classification, P or DP-complete, for the verification problem and\na trichotomous classification for the relevance problem into either polynomial,\nNP-complete, or SigP2-complete. These last two classifications are obtained by\nmeans of algebraic tools."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5429v3", 
    "title": "A note on the complexity of comparing succinctly represented integers,   with an application to maximum probability parsing", 
    "arxiv-id": "1304.5429v3", 
    "author": "Mihalis Yannakakis", 
    "publish": "2013-04-19T14:34:47Z", 
    "summary": "The following two decision problems capture the complexity of comparing\nintegers or rationals that are succinctly represented in\nproduct-of-exponentials notation, or equivalently, via arithmetic circuits\nusing only multiplication and division gates, and integer inputs:\n  Input instance: four lists of positive integers: a_1, ...., a_n ; b_1,....,\nb_n ; c_1,....,c_m ; d_1, ...., d_m ; where each of the integers is represented\nin binary.\n  Problem 1 (equality testing): Decide whether a_1^{b_1} a_2^{b_2} ....\na_n^{b_n} = c_1^{d_1} c_2^{d_2} .... c_m^{d_m} .\n  Problem 2 (inequality testing): Decide whether a_1^{b_1} a_2^{b_2} ...\na_n^{b_n} >= c_1^{d_1} c_2^{d_2} .... c_m^{d_m} .\n  Problem 1 is easily decidable in polynomial time using a simple iterative\nalgorithm. Problem 2 is much harder. We observe that the complexity of Problem\n2 is intimately connected to deep conjectures and results in number theory. In\nparticular, if a refined form of the ABC conjecture formulated by Baker in 1998\nholds, or if the older Lang-Waldschmidt conjecture (formulated in 1978) on\nlinear forms in logarithms holds, then Problem 2 is decidable in P-time (in the\nstandard Turing model of computation). Moreover, it follows from the best\navailable quantitative bounds on linear forms in logarithms, e.g., by Baker and\nW\\\"{u}stholz (1993) or Matveev (2000), that if m and n are fixed universal\nconstants then Problem 2 is decidable in P-time (without relying on any\nconjectures). This latter fact was observed earlier by Shub (1993).\n  We describe one application: P-time maximum probability parsing for arbitrary\nstochastic context-free grammars (where \\epsilon-rules are allowed)."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5604v1", 
    "title": "La machine \u03b1: mod\u00e8le g\u00e9n\u00e9rique pour les algorithmes naturels", 
    "arxiv-id": "1304.5604v1", 
    "author": "Ivan Lavallee", 
    "publish": "2013-04-20T08:39:03Z", 
    "summary": "So far, following the works of A.M. Turing, the algorithms were considered as\nthe mathematical abstraction from which we could write programs for computers\nwhose principle was based on the theoretical concept of Turing machine. We\nstart here from the observation that natural algorithms or rather algorithms of\nthe nature which are massively parallel, autoadaptative and reproductible, and\nfor which we do not know how they really work, nor why, are not easily\nspecified by the current theoretical model of Universal Turing machine, or\nUniversal Computer. In particular the aspects of communications, evolutionary\nrules (rulers), random (unpredictable) events, just like the genetic code, are\ntaken into account only by subtleties which oblige to break the theory. We\nshall propose one \\textit{universal model} of algorithm called machine-alpha\nwhich contains and generalizes the existing models. --- Jusqu'ici, suite aux\ntravaux de A.M.Turing [Turing, 1936], les algorithmes ont \\'et\\'e vus comme\nl'abstraction \\`a partir de laquelle on pouvait \\'ecrire des programmes pour\ndes ordinateurs dont le principe \\'etait lui-m\\^eme issu du concept th\\'eorique\nde machine de Turing. Nous partons ici du constat que les algorithmes naturels\nou plut\\^ot les algorithmes de la nature, massivement parall\\`eles,\nautoadaptatifs et auto reproductibles, dont on ne sait pas comment ils\nfonctionnent r\\'eellement, ni pourquoi, ne sont pas ais\\'ement sp\\'ecifi\\'es\npar le mod\\`ele th\\'eorique actuel de Machine de Turing Universelle, ou de\nCalculateur Universel ; en particulier les aspects de communications, de\nr\\`egles \\'evolutives, d' \\'ev\\'enements al\\'eatoires, \\`a l'image du code\ng\\'en\\'etique, ne sont pris en compte que par ajout d'artifices \\`a la\nth\\'eorie. Nous nous proposons ici de montrer comment aborder ces probl\\`emes\nen repensant le mod\\`ele th\\'eorique. Nous proposerons un mod\\`ele\nd'algorithme, appel\\'e ici machine-\\alpha qui contient et g\\'en\\'eralise les\nmod\\`eles existants."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5617v2", 
    "title": "Another Asymptotic Notation : \"Almost\"", 
    "arxiv-id": "1304.5617v2", 
    "author": "Partha P. Ghosh", 
    "publish": "2013-04-20T09:26:59Z", 
    "summary": "Asymptotic notations are heavily used while analysing runtimes of algorithms.\nPresent paper argues that some of these usages are non trivial, therefore\nincurring errors in communication of ideas. After careful reconsidera- tion of\nthe various existing notations a new notation is proposed. This notation has\nsimilarities with the other heavily used notations like Big-Oh, Big Theta,\nwhile being more accurate when describing the order relationship. It has been\nargued that this notation is more suitable for describing algorithm runtime\nthan Big-Oh."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5777v2", 
    "title": "Improved bounds for reduction to depth 4 and depth 3", 
    "arxiv-id": "1304.5777v2", 
    "author": "S\u00e9bastien Tavenas", 
    "publish": "2013-04-21T18:53:23Z", 
    "summary": "Koiran showed that if a $n$-variate polynomial of degree $d$ (with\n$d=n^{O(1)}$) is computed by a circuit of size $s$, then it is also computed by\na homogeneous circuit of depth four and of size\n$2^{O(\\sqrt{d}\\log(d)\\log(s))}$. Using this result, Gupta, Kamath, Kayal and\nSaptharishi gave a $\\exp(O(\\sqrt{d\\log(d)\\log(n)\\log(s)}))$ upper bound for the\nsize of the smallest depth three circuit computing a $n$-variate polynomial of\ndegree $d=n^{O(1)}$ given by a circuit of size $s$.\n  We improve here Koiran's bound. Indeed, we show that if we reduce an\narithmetic circuit to depth four, then the size becomes\n$\\exp(O(\\sqrt{d\\log(ds)\\log(n)}))$. Mimicking Gupta, Kamath, Kayal and\nSaptharishi's proof, it also implies the same upper bound for depth three\ncircuits.\n  This new bound is not far from optimal in the sense that Gupta, Kamath, Kayal\nand Saptharishi also showed a $2^{\\Omega(\\sqrt{d})}$ lower bound for the size\nof homogeneous depth four circuits such that gates at the bottom have fan-in at\nmost $\\sqrt{d}$. Finally, we show that this last lower bound also holds if the\nfan-in is at least $\\sqrt{d}$."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.5910v1", 
    "title": "On fixed-polynomial size circuit lower bounds for uniform polynomials in   the sense of Valiant", 
    "arxiv-id": "1304.5910v1", 
    "author": "R\u00e9mi de Verclos", 
    "publish": "2013-04-22T10:42:03Z", 
    "summary": "Assuming the Generalised Riemann Hypothesis (GRH), we show that for all k,\nthere exist polynomials with coefficients in $\\MA$ having no arithmetic\ncircuits of size O(n^k) over the complex field (allowing any complex constant).\nWe also build a family of polynomials that can be evaluated in AM having no\narithmetic circuits of size O(n^k). Then we investigate the link between\nfixed-polynomial size circuit bounds in the Boolean and arithmetic settings. In\ncharacteristic zero, it is proved that $\\NP \\not\\subset \\size(n^k)$, or $\\MA\n\\subset \\size(n^k)$, or NP=MA imply lower bounds on the circuit size of uniform\npolynomials in n variables from the class VNP over the complex field, assuming\nGRH. In positive characteristic p, uniform polynomials in VNP have circuits of\nfixed-polynomial size if and only if both VP=VNP over F_p and Mod_pP has\ncircuits of fixed-polynomial size."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.6333v1", 
    "title": "Unifying and generalizing known lower bounds via geometric complexity   theory", 
    "arxiv-id": "1304.6333v1", 
    "author": "Joshua A. Grochow", 
    "publish": "2013-04-23T15:44:45Z", 
    "summary": "We show that most arithmetic circuit lower bounds and relations between lower\nbounds naturally fit into the representation-theoretic framework suggested by\ngeometric complexity theory (GCT), including: the partial derivatives technique\n(Nisan-Wigderson), the results of Razborov and Smolensky on $AC^0[p]$,\nmultilinear formula and circuit size lower bounds (Raz et al.), the degree\nbound (Strassen, Baur-Strassen), the connected components technique (Ben-Or),\ndepth 3 arithmetic circuit lower bounds over finite fields\n(Grigoriev-Karpinski), lower bounds on permanent versus determinant\n(Mignon-Ressayre, Landsberg-Manivel-Ressayre), lower bounds on matrix\nmultiplication (B\\\"{u}rgisser-Ikenmeyer) (these last two were already known to\nfit into GCT), the chasms at depth 3 and 4 (Gupta-Kayal-Kamath-Saptharishi;\nAgrawal-Vinay; Koiran), matrix rigidity (Valiant) and others. That is, the\noriginal proofs, with what is often just a little extra work, already provide\nrepresentation-theoretic obstructions in the sense of GCT for their respective\nlower bounds. This enables us to expose a new viewpoint on GCT, whereby it is a\nnatural unification and broad generalization of known results. It also shows\nthat the framework of GCT is at least as powerful as known methods, and gives\nmany new proofs-of-concept that GCT can indeed provide significant asymptotic\nlower bounds. This new viewpoint also opens up the possibility of fruitful\ntwo-way interactions between previous results and the new methods of GCT; we\nprovide several concrete suggestions of such interactions. For example, the\nrepresentation-theoretic viewpoint of GCT naturally provides new properties to\nconsider in the search for new lower bounds."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1304.6685v2", 
    "title": "Distance-Sensitive Property Testing Lower Bounds", 
    "arxiv-id": "1304.6685v2", 
    "author": "Pooya Hatami", 
    "publish": "2013-04-24T18:07:07Z", 
    "summary": "In this paper, we consider several property testing problems and ask how the\nquery complexity depends on the distance parameter $\\eps$. We achieve new lower\nbounds in this setting for the problems of testing whether a function is\nmonotone and testing whether the function has low Fourier degree. For\nmonotonicity testing, our lower bound matches the recent upper bound of\nChakrabarty and Seshadhri."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1305.0948v3", 
    "title": "Sparser Random 3SAT Refutation Algorithms and the Interpolation Problem", 
    "arxiv-id": "1305.0948v3", 
    "author": "Iddo Tzameret", 
    "publish": "2013-05-04T19:22:46Z", 
    "summary": "We formalize a combinatorial principle, called the 3XOR principle, due to\nFeige, Kim and Ofek (2006), as a family of unsatisfiable propositional formulas\nfor which refutations of small size in any propositional proof system that\npossesses the feasible interpolation property imply an efficient deterministic\nrefutation algorithm for random 3SAT with n variables and \\Omega(n^{1.4})\nclauses. Such small size refutations would improve the state-of-the-art (with\nrespect to the clause density) efficient refutation algorithm, which works only\nfor \\Omega(n^{1.5}) many clauses (Feige and Ofek (2007)).\n  We demonstrate polynomial-size refutations of the 3XOR principle in\nresolution operating with disjunctions of quadratic equations with small\ninteger coefficients, denoted R(quad); this is a weak extension of cutting\nplanes with small coefficients. We show that R(quad) is weakly automatizable\niff R(lin) is weakly automatizable, where R(lin) is similar to R(quad) but with\nlinear instead of quadratic equations (introduced in Raz and Tzameret (2008)).\nThis reduces the problem of refuting random 3CNF with n variables and\n\\Omega(n^{1.4}) clauses to the interpolation problem of R(quad) and to the weak\nautomatizability of R(lin)."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1305.1409v2", 
    "title": "A Collapse Theorem for Holographic Algorithms with Matchgates on Domain   Size at Most 4", 
    "arxiv-id": "1305.1409v2", 
    "author": "Zhiguo Fu", 
    "publish": "2013-05-07T05:19:48Z", 
    "summary": "Holographic algorithms with matchgates are a novel approach to design\npolynomial time computation. It uses Kasteleyn's algorithm for perfect\nmatchings, and more importantly a holographic reduction . The two fundamental\nparameters of a holographic reduction are the domain size $k$ of the underlying\nproblem, and the basis size $\\ell$. A holographic reduction transforms the\ncomputation to matchgates by a linear transformation that maps to (a tensor\nproduct space of) a linear space of dimension $2^{\\ell}$. We prove a sharp\nbasis collapse theorem, that shows that for domain size 3 and 4, all\nnon-trivial holographic reductions have basis size $\\ell$ collapse to 1 and 2\nrespectively. The main proof techniques are Matchgates Identities, and a Group\nProperty of matchgates signatures."
},{
    "category": "cs.CC", 
    "doi": "10.2168/LMCS-9(2:13)2013", 
    "link": "http://arxiv.org/pdf/1305.1979v3", 
    "title": "Analytical Approach to Parallel Repetition", 
    "arxiv-id": "1305.1979v3", 
    "author": "David Steurer", 
    "publish": "2013-05-09T00:22:17Z", 
    "summary": "We propose an analytical framework for studying parallel repetition, a basic\nproduct operation for one-round two-player games. In this framework, we\nconsider a relaxation of the value of a game, $\\mathrm{val}_+$, and prove that\nfor projection games, it is both multiplicative (under parallel repetition) and\na good approximation for the true value.\n  These two properties imply a parallel repetition bound as $$\n\\mathrm{val}(G^{\\otimes k}) \\approx \\mathrm{val}_+(G^{\\otimes k}) =\n\\mathrm{val}_+(G)^{k} \\approx \\mathrm{val}(G)^{k}. $$\n  Using this framework, we can also give a short proof for the NP-hardness of\nLabel-Cover$(1,\\delta)$ for all $\\delta>0$, starting from the basic PCP\ntheorem.\n  We prove the following new results:\n  - A parallel repetition bound for projection games with small soundness.\nPreviously, it was not known whether parallel repetition decreases the value of\nsuch games. This result implies stronger inapproximability bounds for Set-Cover\nand Label-Cover.\n  - An improved bound for few parallel repetitions of projection games, showing\nthat Raz's counterexample is tight even for a small number of repetitions.\n  Our techniques also allow us to bound the value of the direct product of\nmultiple games, namely, a bound on $\\mathrm{val}(G_1\\otimes ...\\otimes G_k)$\nfor different projection games $G_1,...,G_k$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.3041v2", 
    "title": "Cancellation-Free Circuits in Unbounded and Bounded Depth", 
    "arxiv-id": "1305.3041v2", 
    "author": "Magnus Find", 
    "publish": "2013-05-14T07:13:03Z", 
    "summary": "We study the notion of \"cancellation-free\" circuits. This is a restriction of\nlinear Boolean circuits (XOR circuits), but can be considered as being\nequivalent to previously studied models of computation. The notion was coined\nby Boyar and Peralta in a study of heuristics for a particular circuit\nminimization problem. They asked how large a gap there can be between the\nsmallest cancellation-free circuit and the smallest linear circuit. We show\nthat the difference can be a factor $\\Omega(n/\\log^{2}n)$. This improves on a\nrecent result by Sergeev and Gashkov who have studied a similar problem.\nFurthermore, our proof holds for circuits of constant depth. We also study the\ncomplexity of computing the Sierpinski matrix using cancellation-free circuits\nand give a tight $\\Omega(n\\log n)$ lower bound."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.3218v2", 
    "title": "Computing Cliques is Intractable", 
    "arxiv-id": "1305.3218v2", 
    "author": "Junichiro Fukuyama", 
    "publish": "2013-05-14T17:40:10Z", 
    "summary": "The class P is in fact a proper sub-class of NP. We explore topological\nproperties of the Hamming space 2^[n] where [n]={1, 2,..., n}. With the\ndeveloped theory, we show: (i) a theorem that is closely related to Erdos and\nRado's sunflower lemma, and claims a stronger statement in most cases, (ii) a\nnew approach to prove the exponential monotone circuit complexity of the clique\nproblem, (iii) NC \\ne NP through the impossibility of a Boolean circuit with\npoly-log depth to compute cliques, based on the construction of (ii), and (iv)\nP \\ne NP through the exponential circuit complexity of the clique problem,\nbased on the construction of (iii). Item (i) leads to the existence of a\nsunflower with a small core in certain families of sets, which is not an\nobvious consequence of the sunflower lemma. In (iv), we show that any Boolean\ncircuit computing the clique function CLIQUE_{n,k} (k=n^{1/4}) has a size\nexponential in n. Thus, we will separate P/poly from NP also. Razborov and\nRudich showed strong evidence that no natural proof can prove exponential\ncircuit complexity of a Boolean function. We confirm that the proofs for (iii)\nand (iv) are not natural."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.3944v1", 
    "title": "An exponential lower bound for Cunningham's rule", 
    "arxiv-id": "1305.3944v1", 
    "author": "Oliver Friedmann", 
    "publish": "2013-05-16T21:57:38Z", 
    "summary": "In this paper we give an exponential lower bound for Cunningham's least\nrecently considered (round-robin) rule as applied to parity games, Markhov\ndecision processes and linear programs. This improves a recent subexponential\nbound of Friedmann for this rule on these problems. The round-robin rule fixes\na cyclical order of the variables and chooses the next pivot variable starting\nfrom the previously chosen variable and proceeding in the given circular order.\nIt is perhaps the simplest example from the class of history-based pivot rules.\nOur results are based on a new lower bound construction for parity games. Due\nto the nature of the construction we are also able to obtain an exponential\nlower bound for the round-robin rule applied to acyclic unique sink\norientations of hypercubes (AUSOs). Furthermore these AUSOs are realizable as\npolytopes. We believe these are the first such results for history based rules\nfor AUSOs, realizable or not. The paper is self-contained and requires no\nprevious knowledge of parity games."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.4029v1", 
    "title": "Computability vs. Nondeterministic and P vs. NP", 
    "arxiv-id": "1305.4029v1", 
    "author": "Jian-Ming Zhou", 
    "publish": "2013-05-17T09:38:27Z", 
    "summary": "This paper demonstrates the relativity of Computability and Nondeterministic;\nthe nondeterministic is just Turing's undecidable Decision rather than the\nNondeterministic Polynomial time.\n  Based on analysis about TM, UM, DTM, NTM, Turing Reducible, beta-reduction,\nP-reducible, isomorph, tautology, semi-decidable, checking relation, the oracle\nand NP-completeness, etc., it reinterprets The Church-Turing Thesis that is\nequivalent of the Polynomial time and actual time; it redefines the NTM based\non its undecidable set of its internal state. It comes to the conclusions: The\nP-reducible is misdirected from the Turing Reducible with its oracle; The\nNP-completeness is a reversal to The Church-Turing Thesis; The Cook-Levin\ntheorem is an equipollent of two uncertains. This paper brings forth new\nconcepts: NP (nondeterministic problem) and NP-algorithm (defined as the\noptimal algorithm to get the best fit approximation value of NP). P versus NP\nis the relativity of Computability and Nondeterministic, P/=NP. The\nNP-algorithm is effective approximate way to NP by TM."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.4745v1", 
    "title": "A Lower Bound for Fourier Transform Computation in a Linear Model Over   2x2 Unitary Gates Using Matrix Entropy", 
    "arxiv-id": "1305.4745v1", 
    "author": "Nir Ailon", 
    "publish": "2013-05-21T07:58:28Z", 
    "summary": "Obtaining a non-trivial (super-linear) lower bound for computation of the\nFourier transform in the linear circuit model has been a long standing open\nproblem. All lower bounds so far have made strong restrictions on the\ncomputational model. One of the most well known results, by Morgenstern from\n1973, provides an $\\Omega(n \\log n)$ lower bound for the \\emph{unnormalized}\nFFT when the constants used in the computation are bounded. The proof uses a\npotential function related to a determinant. The determinant of the\nunnormalized Fourier transform is $n^{n/2}$, and thus by showing that it can\ngrow by at most a constant factor after each step yields the result.\n  This classic result, however, does not explain why the \\emph{normalized}\nFourier transform, which has a unit determinant, should take $\\Omega(n\\log n)$\nsteps to compute. In this work we show that in a layered linear circuit model\nrestricted to unitary $2\\times 2$ gates, one obtains an $\\Omega(n\\log n)$ lower\nbound. The well known FFT works in this model. The main argument concluded from\nthis work is that a potential function that might eventually help proving the\n$\\Omega(n\\log n)$ conjectured lower bound for computation of Fourier transform\nis not related to matrix determinant, but rather to a notion of matrix entropy."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.5561v2", 
    "title": "The Promise Polynomial Hierarchy", 
    "arxiv-id": "1305.5561v2", 
    "author": "David Petrie Moulton", 
    "publish": "2013-05-23T20:37:31Z", 
    "summary": "The polynomial hierarchy is a grading of problems by difficulty, including P,\nNP and coNP as the best known classes. The promise polynomial hierarchy is\nsimilar, but extended to include promise problems. It turns out that the\npromise polynomial hierarchy is considerably simpler to work with, and many\nopen questions about the polynomial hierarchy can be resolved in the promise\npolynomial hierarchy.\n  Our main theorem is that, in the world of promise problems, if phi has a weak\n(Turing, Cook) reduction to SAT then phi has a strong (Karp, many-one)\nreduction to UVAL2, where UVAL2(f) is the promise problem of finding the unique\nx such that f(x,y)=1 for all y. We also give a complete promise problem for the\npromise problem equivalent of UP intersect coUP."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.tcs.2014.10.014", 
    "link": "http://arxiv.org/pdf/1305.5713v1", 
    "title": "Computing with and without arbitrary large numbers", 
    "arxiv-id": "1305.5713v1", 
    "author": "Michael Brand", 
    "publish": "2013-05-24T12:38:18Z", 
    "summary": "In the study of random access machines (RAMs) it has been shown that the\navailability of an extra input integer, having no special properties other than\nbeing sufficiently large, is enough to reduce the computational complexity of\nsome problems. However, this has only been shown so far for specific problems.\nWe provide a characterization of the power of such extra inputs for general\nproblems. To do so, we first correct a classical result by Simon and Szegedy\n(1992) as well as one by Simon (1981). In the former we show mistakes in the\nproof and correct these by an entirely new construction, with no great change\nto the results. In the latter, the original proof direction stands with only\nminor modifications, but the new results are far stronger than those of Simon\n(1981). In both cases, the new constructions provide the theoretical tools\nrequired to characterize the power of arbitrary large numbers."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1305.6306v2", 
    "title": "The Complexity of Approximately Counting Tree Homomorphisms", 
    "arxiv-id": "1305.6306v2", 
    "author": "Mark Jerrum", 
    "publish": "2013-05-27T19:49:05Z", 
    "summary": "We study two computational problems, parameterised by a fixed tree H.\n#HomsTo(H) is the problem of counting homomorphisms from an input graph G to H.\n#WHomsTo(H) is the problem of counting weighted homomorphisms to H, given an\ninput graph G and a weight function for each vertex v of G. Even though H is a\ntree, these problems turn out to be sufficiently rich to capture all of the\nknown approximation behaviour in #P. We give a complete trichotomy for\n#WHomsTo(H). If H is a star then #WHomsTo(H) is in FP. If H is not a star but\nit does not contain a certain induced subgraph J_3 then #WHomsTo(H) is\nequivalent under approximation-preserving (AP) reductions to #BIS, the problem\nof counting independent sets in a bipartite graph. This problem is complete for\nthe class #RHPi_1 under AP-reductions. Finally, if H contains an induced J_3\nthen #WHomsTo(H) is equivalent under AP-reductions to #SAT, the problem of\ncounting satisfying assignments to a CNF Boolean formula. Thus, #WHomsTo(H) is\ncomplete for #P under AP-reductions. The results are similar for #HomsTo(H)\nexcept that a rich structure emerges if H contains an induced J_3. We show that\nthere are trees H for which #HomsTo(H) is #SAT-equivalent (disproving a\nplausible conjecture of Kelk). There is an interesting connection between these\nhomomorphism-counting problems and the problem of approximating the partition\nfunction of the ferromagnetic Potts model. In particular, we show that for a\nfamily of graphs J_q, parameterised by a positive integer q, the problem\n#HomsTo(H) is AP-interreducible with the problem of approximating the partition\nfunction of the q-state Potts model. It was not previously known that the Potts\nmodel had a homomorphism-counting interpretation. We use this connection to\nobtain some additional upper bounds for the approximation complexity of\n#HomsTo(J_q)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.0153v1", 
    "title": "Lower Bounds for RAMs and Quantifier Elimination", 
    "arxiv-id": "1306.0153v1", 
    "author": "Miklos Ajtai", 
    "publish": "2013-06-01T21:40:19Z", 
    "summary": "We are considering RAMs $N_{n}$, with wordlength $n=2^{d}$, whose arithmetic\ninstructions are the arithmetic operations multiplication and addition modulo\n$2^{n}$, the unary function $ \\min\\lbrace 2^{x}, 2^{n}-1\\rbrace$, the binary\nfunctions $\\lfloor x/y\\rfloor $ (with $\\lfloor x/0 \\rfloor =0$), $\\max(x,y)$,\n$\\min(x,y)$, and the boolean vector operations $\\wedge,\\vee,\\neg$ defined on\n$0,1$ sequences of length $n$. It also has the other RAM instructions. The size\nof the memory is restricted only by the address space, that is, it is $2^{n}$\nwords. The RAMs has a finite instruction set, each instruction is encoded by a\nfixed natural number independently of $n$. Therefore a program $P$ can run on\neach machine $N_{n}$, if $n=2^{d}$ is sufficiently large. We show that there\nexists an $\\epsilon>0$ and a program $P$, such that it satisfies the following\ntwo conditions.\n  (i) For all sufficiently large $n=2^{d}$, if $P$ running on $N_{n}$ gets an\ninput consisting of two words $a$ and $b$, then, in constant time, it gives a\n$0,1$ output $P_{n}(a,b)$.\n  (ii) Suppose that $Q$ is a program such that for each sufficiently large\n$n=2^{d}$, if $Q$, running on $N_{n}$, gets a word $a$ of length $n$ as an\ninput, then it decides whether there exists a word $b$ of length $n$ such that\n$P_{n}(a,b)=0$. Then, for infinitely many positive integers $d$, there exists a\nword $a$ of length $n=2^{d}$, such that the running time of $Q$ on $N_{n}$ at\ninput $a$ is at least $\\epsilon (\\log d)^{\\frac{1}{2}} (\\log \\log d)^{-1}$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.0630v1", 
    "title": "Composition limits and separating examples for some Boolean function   complexity measures", 
    "arxiv-id": "1306.0630v1", 
    "author": "Srikanth Srinivasan", 
    "publish": "2013-06-04T01:26:36Z", 
    "summary": "Block sensitivity ($bs(f)$), certificate complexity ($C(f)$) and fractional\ncertificate complexity ($C^*(f)$) are three fundamental combinatorial measures\nof complexity of a boolean function $f$. It has long been known that $bs(f)\n\\leq C^{\\ast}(f) \\leq C(f) =O(bs(f)^2)$. We provide an infinite family of\nexamples for which $C(f)$ grows quadratically in $C^{\\ast}(f)$ (and also\n$bs(f)$) giving optimal separations between these measures. Previously the\nbiggest separation known was $C(f)=C^{\\ast}(f)^{\\log_{4.5}5}$. We also give a\nfamily of examples for which $C^{\\ast}(f)=\\Omega(bs(f)^{3/2})$.\n  These examples are obtained by composing boolean functions in various ways.\nHere the composition $f \\circ g$ of $f$ with $g$ is obtained by substituting\nfor each variable of $f$ a copy of $g$ on disjoint sets of variables. To\nconstruct and analyse these examples we systematically investigate the\nbehaviour under function composition of these measures and also the sensitivity\nmeasure $s(f)$. The measures $s(f)$, $C(f)$ and $C^{\\ast}(f)$ behave nicely\nunder composition: they are submultiplicative (where measure $m$ is\nsubmultiplicative if $m(f \\circ g) \\leq m(f)m(g)$) with equality holding under\nsome fairly general conditions. The measure $bs(f)$ is qualitatively different:\nit is not submultiplicative. This qualitative difference was not noticed in the\nprevious literature and we correct some errors that appeared in previous\npapers. We define the composition limit of a measure $m$ at function $f$,\n$m^{\\lim}(f)$ to be the limit as $k$ grows of $m(f^{(k)})^{1/k}$, where\n$f^{(k)}$ is the iterated composition of $f$ with itself $k$-times. For any\nfunction $f$ we show that $bs^{\\lim}(f) = (C^*)^{\\lim}(f)$ and characterize\n$s^{\\lim}(f), (C^*)^{\\lim}(f)$, and $C^{\\lim}(f)$ in terms of the largest\neigenvalue of a certain set of $2\\times 2$ matrices associated with $f$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.0649v1", 
    "title": "Estimating the distance from testable affine-invariant properties", 
    "arxiv-id": "1306.0649v1", 
    "author": "Shachar Lovett", 
    "publish": "2013-06-04T04:10:08Z", 
    "summary": "Let $\\cal{P}$ be an affine invariant property of functions $\\mathbb{F}_p^n\n\\to [R]$ for fixed $p$ and $R$. We show that if $\\cal{P}$ is locally testable\nwith a constant number of queries, then one can estimate the distance of a\nfunction $f$ from $\\cal{P}$ with a constant number of queries. This was\npreviously unknown even for simple properties such as cubic polynomials over\n$\\mathbb{F}_2$.\n  Our test is simple: take a restriction of $f$ to a constant dimensional\naffine subspace, and measure its distance from $\\cal{P}$. We show that by\nchoosing the dimension large enough, this approximates with high probability\nthe global distance of $f$ from $\\cP$. The analysis combines the approach of\nFischer and Newman [SIAM J. Comp 2007] who established a similar result for\ngraph properties, with recently developed tools in higher order Fourier\nanalysis, in particular those developed in Bhattacharyya et al. [STOC 2013]."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.1360v1", 
    "title": "Some properties are not even partially testable", 
    "arxiv-id": "1306.1360v1", 
    "author": "Oded Lachish", 
    "publish": "2013-06-06T09:52:09Z", 
    "summary": "For a property $P$ and a sub-property $P'$, we say that $P$ is $P'$-partially\ntestable with $q$ queries if there exists an algorithm that distinguishes, with\nhigh probability, inputs in $P'$ from inputs $\\epsilon$-far from $P$ by using\n$q$ queries. There are natural properties that require many queries to test,\nbut can be partitioned into a small number of subsets for which they are\npartially testable with very few queries.\n  We prove the existence of a property $P$ such that the only subsets $P'$ for\nwhich $P$ is $P'$-partially testable are very small. To prove this we introduce\nnew techniques for proving property testing lower bounds. In addition to\nobtaining some broad-brush criteria for non-testability, this implies a lower\nbound on the possibility of PCPPs with a sublinear proof. This also implies\nlower bounds on MAPs, a notion newly defined by Gur and Rothblum.\n  The new techniques rely on analyzing a proposed partial tester. We show that\nthe queries performed by a tester must, with high probability, query indexes\nwhere a uniformly random member of the sub-property has low entropy. We then\nshow how one can aggregate the \"entropy loss\" to deduce that a random choice in\nthe sub-property must have low entropy, and therefore the sub-property must be\nsmall.\n  We develop two techniques for aggregating the entropy loss. A simpler\ntechnique that applies to non-adaptive testers is based on partitioning the\ninput bits into high query probability parts and parts where there is an\nentropy loss when conditioned on the high probability parts. Against adaptive\ntesters we develop a technique based on constructing a decision tree. The\nroot-to-leaf paths in this tree rearrange the input into parts where each\nexhibits entropy loss when conditioned on the path prefix. This decision tree\nis constructed by combining carefully selected decision trees from those used\nby the adaptive testing algorithm."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.2484v3", 
    "title": "Generalization of Boole-Shannon expansion, consistency of Boolean   equations and elimination by orthonormal expansion", 
    "arxiv-id": "1306.2484v3", 
    "author": "Virendra Sule", 
    "publish": "2013-06-11T10:50:57Z", 
    "summary": "The well known Boole-Shannon expansion of Boolean functions in several\nvariables (with co-efficients in a Boolean algebra $B$) is also known in more\ngeneral form in terms of expansion in a set $\\Phi$ of orthonormal functions.\nHowever, unlike the one variable step of this expansion an analogous\nelimination theorem and consistency is not well known. This article proves such\nan elimination theorem for a special class of Boolean functions denoted\n$B(\\Phi)$. When the orthonormal set $\\Phi$ is of polynomial size in number $n$\nof variables, the consistency of a Boolean equation $f=0$ can be determined in\npolynomial number of $B$-operations. A characterization of $B(\\Phi)$ is also\nshown and an elimination based procedure for computing consistency of Boolean\nequations is proposed."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.3004v2", 
    "title": "Pseudorandomness for Regular Branching Programs via Fourier Analysis", 
    "arxiv-id": "1306.3004v2", 
    "author": "Salil Vadhan", 
    "publish": "2013-06-13T01:41:14Z", 
    "summary": "We present an explicit pseudorandom generator for oblivious, read-once,\npermutation branching programs of constant width that can read their input bits\nin any order. The seed length is $O(\\log^2 n)$, where $n$ is the length of the\nbranching program. The previous best seed length known for this model was\n$n^{1/2+o(1)}$, which follows as a special case of a generator due to\nImpagliazzo, Meka, and Zuckerman (FOCS 2012) (which gives a seed length of\n$s^{1/2+o(1)}$ for arbitrary branching programs of size $s$). Our techniques\nalso give seed length $n^{1/2+o(1)}$ for general oblivious, read-once branching\nprograms of width $2^{n^{o(1)}}$, which is incomparable to the results of\nImpagliazzo et al.Our pseudorandom generator is similar to the one used by\nGopalan et al. (FOCS 2012) for read-once CNFs, but the analysis is quite\ndifferent; ours is based on Fourier analysis of branching programs. In\nparticular, we show that an oblivious, read-once, regular branching program of\nwidth $w$ has Fourier mass at most $(2w^2)^k$ at level $k$, independent of the\nlength of the program."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.3257v1", 
    "title": "3-color Bounded Patterned Self-assembly", 
    "arxiv-id": "1306.3257v1", 
    "author": "Shinnosuke Seki", 
    "publish": "2013-06-13T21:09:48Z", 
    "summary": "Patterned self-assembly tile set synthesis PATS is the problem of finding a\nminimal tile set which uniquely self-assembles into a given pattern. Czeizler\nand Popa proved the NP-completeness of PATS and Seki showed that the PATS\nproblem is already NP-complete for patterns with 60 colors. In search for the\nminimal number of colors such that PATS remains NP-complete, we introduce\nmultiple bound PATS (mbPATS) where we allow bounds for the numbers of tile\ntypes of each color. We show that mbPATS is NP-complete for patterns with just\nthree colors and, as a byproduct of this result, we also obtain a novel proof\nfor the NP-completeness of PATS which is more concise than the previous proofs."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.3766v1", 
    "title": "Truth Table Minimization of Computational Models", 
    "arxiv-id": "1306.3766v1", 
    "author": "Netanel Raviv", 
    "publish": "2013-06-17T08:34:50Z", 
    "summary": "Complexity theory offers a variety of concise computational models for\ncomputing boolean functions - branching programs, circuits, decision trees and\nordered binary decision diagrams to name a few. A natural question that arises\nin this context with respect to any such model is this:\n  Given a function f:{0,1}^n \\to {0,1}, can we compute the optimal complexity\nof computing f in the computational model in question? (according to some\ndesirable measure).\n  A critical issue regarding this question is how exactly is f given, since a\nmore elaborate description of f allows the algorithm to use more computational\nresources. Among the possible representations are black-box access to f (such\nas in computational learning theory), a representation of f in the desired\ncomputational model or a representation of f in some other model. One might\nconjecture that if f is given as its complete truth table (i.e., a list of f's\nvalues on each of its 2^n possible inputs), the most elaborate description\nconceivable, then any computational model can be efficiently computed, since\nthe algorithm computing it can run poly(2^n) time. Several recent studies show\nthat this is far from the truth - some models have efficient and simple\nalgorithms that yield the desired result, others are believed to be hard, and\nfor some models this problem remains open.\n  In this thesis we will discuss the computational complexity of this question\nregarding several common types of computational models. We shall present\nseveral new hardness results and efficient algorithms, as well as new proofs\nand extensions for known theorems, for variants of decision trees, formulas and\nbranching programs."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.4029v1", 
    "title": "Satisfiability Algorithms for Restricted Circuit Classes", 
    "arxiv-id": "1306.4029v1", 
    "author": "Stefan Schneider", 
    "publish": "2013-06-17T21:58:09Z", 
    "summary": "In recent years, finding new satisfiability algorithms for various circuit\nclasses has been a very active line of research. Despite considerable progress,\nwe are still far away from a definite answer on which circuit classes allow\nfast satisfiability algorithms. This survey takes a (far from exhaustive) look\nat some recent satisfiability algorithms for a range of circuit classes and\nhigh- lights common themes. A special focus is given to connections between\nsatisfiability algorithms and circuit lower bounds. A second focus is on\nreductions from satisfiability algorithms to a range of polynomial time\nproblems, such as matrix multiplication and the Vector Domination Problem."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.4466v2", 
    "title": "New upper bound on block sensitivity and certificate complexity in terms   of sensitivity", 
    "arxiv-id": "1306.4466v2", 
    "author": "Song Zuo", 
    "publish": "2013-06-19T09:23:54Z", 
    "summary": "Sensitivity \\cite{CD82,CDR86} and block sensitivity \\cite{Nisan91} are two\nimportant complexity measures of Boolean functions. A longstanding open problem\nin decision tree complexity, the \"Sensitivity versus Block Sensitivity\"\nquestion, proposed by Nisan and Szegedy \\cite{Nisan94} in 1992, is whether\nthese two complexity measures are polynomially related, i.e., whether\n$bs(f)=O(s(f)^{O(1)})$.\n  We prove an new upper bound on block sensitivity in terms of sensitivity:\n$bs(f) \\leq 2^{s(f)-1} s(f)$. Previously, the best upper bound on block\nsensitivity was $bs(f) \\leq (\\frac{e}{\\sqrt{2\\pi}}) e^{s(f)} \\sqrt{s(f)}$ by\nKenyon and Kutin \\cite{KK}. We also prove that if $\\min\\{s_0(f),s_1(f)\\}$ is a\nconstant, then sensitivity and block sensitivity are linearly related, i.e.\n$bs(f)=O(s(f))$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1306.5176v3", 
    "title": "Counting list matrix partitions of graphs", 
    "arxiv-id": "1306.5176v3", 
    "author": "Tomoyuki Yamakami", 
    "publish": "2013-06-21T15:41:59Z", 
    "summary": "Given a symmetric D*D matrix M over {0,1,*}, a list M-partition of a graph G\nis a partition of G's vertices into D parts associated with the rows of M. The\npart of each vertex is chosen from a given list so that no edge of G maps to a\n0 in M and no non-edge of G maps to a 1 in M. Many important graph-theoretic\nstructures can be represented as list M-partitions, such as graph colourings,\nsplit graphs and homogeneous sets and pairs, which arise in the proofs of the\nweak and strong perfect graph conjectures. There has been quite a bit of work\non determining for which matrices M computations involving list M-partitions\nare tractable. We focus on counting list M-partitions, given a graph G and a\nlist for each vertex of G. We identify a set of \"tractable\" matrices and give\nan algorithm that counts list M-partitions in polynomial time for every (fixed)\nmatrix M in this set. The algorithm uses data structures such as sparse-dense\npartitions and subcube decompositions to reduce each instance to a sequence of\ninstances in which the lists restrict access to portions of M in which the\ninteraction of 0s and 1s is controlled. We solve the resulting restricted\ninstances by converting them into counting constraint satisfaction problems\n(#CSPs) which we solve using arc-consistency. For every matrix M for which our\nalgorithm fails, we show that counting list M-partitions is #P-complete.\nFurther, we give an explicit characterisation of the dichotomy theorem:\ncounting list M-partitions is in FP if M has a structure called a\nderectangularising sequence; otherwise, counting list M-partitions is #P-hard.\nWe show that the meta-problem of determining whether a given matrix has a\nderectangularising sequence is NP-complete. Finally, we show that lists can be\nused to encode cardinality restrictions in M-partitions problems and use this\nto give a polynomial-time algorithm for counting homogeneous pairs in graphs."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.0189v1", 
    "title": "Rational series and asymptotic expansion for linear homogeneous   divide-and-conquer recurrences", 
    "arxiv-id": "1307.0189v1", 
    "author": "Philippe Dumas", 
    "publish": "2013-06-30T09:44:27Z", 
    "summary": "Among all sequences that satisfy a divide-and-conquer recurrence, the\nsequences that are rational with respect to a numeration system are certainly\nthe most immediate and most essential. Nevertheless, until recently they have\nnot been studied from the asymptotic standpoint. We show how a mechanical\nprocess permits to compute their asymptotic expansion. It is based on linear\nalgebra, with Jordan normal form, joint spectral radius, and dilation\nequations. The method is compared with the analytic number theory approach,\nbased on Dirichlet series and residues, and new ways to compute the Fourier\nseries of the periodic functions involved in the expansion are developed. The\narticle comes with an extended bibliography."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.1353v2", 
    "title": "One Hierarchy Spawns Another: Graph Deconstructions and the Complexity   Classification of Conjunctive Queries", 
    "arxiv-id": "1307.1353v2", 
    "author": "Moritz M\u00fcller", 
    "publish": "2013-07-04T14:35:18Z", 
    "summary": "We study the problem of conjunctive query evaluation relative to a class of\nqueries; this problem is formulated here as the relational homomorphism problem\nrelative to a class of structures A, wherein each instance must be a pair of\nstructures such that the first structure is an element of A. We present a\ncomprehensive complexity classification of these problems, which strongly links\ngraph-theoretic properties of A to the complexity of the corresponding\nhomomorphism problem. In particular, we define a binary relation on graph\nclasses, which is a preorder, and completely describe the resulting hierarchy\ngiven by this relation. This relation is defined in terms of a notion which we\ncall graph deconstruction and which is a variant of the well-known notion of\ntree decomposition. We then use this hierarchy of graph classes to infer a\ncomplexity hierarchy of homomorphism problems which is comprehensive up to a\ncomputationally very weak notion of reduction, namely, a parameterized version\nof quantifier-free first-order reduction. In doing so, we obtain a\nsignificantly refined complexity classification of homomorphism problems, as\nwell as a unifying, modular, and conceptually clean treatment of existing\ncomplexity classifications. We then present and develop the theory of\nEhrenfeucht-Fraisse-style pebble games which solve the homomorphism problems\nwhere the cores of the structures in A have bounded tree depth. Finally, we use\nour framework to classify the complexity of model checking existential\nsentences having bounded quantifier rank."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.3184v4", 
    "title": "Randomness Conservation over Algorithms", 
    "arxiv-id": "1307.3184v4", 
    "author": "Samuel Epstein", 
    "publish": "2013-07-11T16:58:37Z", 
    "summary": "Current discrete randomness and information conservation inequalities are\nover total recursive functions, i.e. restricted to deterministic processing.\nThis restriction implies that an algorithm can break algorithmic randomness\nconservation inequalities. We address this issue by proving tight bounds of\nrandomness and information conservation with respect to recursively enumerable\ntransformations, i.e. processing by algorithms. We also show conservation of\nrandomness of finite strings with respect to enumerable distributions, i.e.\nsemicomputable semi-measures."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.3682v1", 
    "title": "A reduction of 3-SAT problem to Buchberger algorithm", 
    "arxiv-id": "1307.3682v1", 
    "author": "Maiia Bakhova", 
    "publish": "2013-07-13T21:56:52Z", 
    "summary": "There is a number of known NP class problems, and majority of them have been\nshown to be equivalent to others. In particular now it is clear that\nconstruction of a Gr\\\"{o}bner basis (or Buchberger algorithm) must be one of\nequivalent problems, but there was no example. In the following paper the\nreduction is constructed."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.3863v2", 
    "title": "Algebraic Complexity Classes", 
    "arxiv-id": "1307.3863v2", 
    "author": "Meena Mahajan", 
    "publish": "2013-07-15T09:31:15Z", 
    "summary": "This survey describes, at an introductory level, the algebraic complexity\nframework originally proposed by Leslie Valiant in 1979, and some of the\ninsights that have been obtained more recently."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.3975v1", 
    "title": "Some Improvements to Total Degree Tests", 
    "arxiv-id": "1307.3975v1", 
    "author": "Madhu Sudan", 
    "publish": "2013-07-15T14:50:59Z", 
    "summary": "A low-degree test is a collection of simple, local rules for checking the\nproximity of an arbitrary function to a low-degree polynomial. Each rule\ndepends on the function's values at a small number of places. If a function\nsatisfies many rules then it is close to a low-degree polynomial. Low-degree\ntests play an important role in the development of probabilistically checkable\nproofs.\n  In this paper we present two improvements to the efficiency of low-degree\ntests. Our first improvement concerns the smallest field size over which a\nlow-degree test can work. We show how to test that a function is a degree $d$\npolynomial over prime fields of size only $d+2$.\n  Our second improvement shows a better efficiency of the low-degree test of\nRubinfeld and Sudan (Proc. SODA 1992) than previously known. We show concrete\napplications of this improvement via the notion of \"locally checkable codes\".\nThis improvement translates into better tradeoffs on the size versus probe\ncomplexity of probabilistically checkable proofs than previously known."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.4897v1", 
    "title": "Small Depth Proof Systems", 
    "arxiv-id": "1307.4897v1", 
    "author": "Karteek Sreenivasaiah", 
    "publish": "2013-07-18T10:31:44Z", 
    "summary": "A proof system for a language L is a function f such that Range(f) is exactly\nL. In this paper, we look at proofsystems from a circuit complexity point of\nview and study proof systems that are computationally very restricted. The\nrestriction we study is: they can be computed by bounded fanin circuits of\nconstant depth (NC^0), or of O(log log n) depth but with O(1) alternations\n(polylog AC^0). Each output bit depends on very few input bits; thus such proof\nsystems correspond to a kind of local error-correction on a theorem-proof pair.\n  We identify exactly how much power we need for proof systems to capture all\nregular languages. We show that all regular language have polylog AC^0 proof\nsystems, and from a previous result (Beyersdorff et al, MFCS 2011, where NC^0\nproof systems were first introduced), this is tight. Our technique also shows\nthat MAJ has polylog AC^0 proof system. We explore the question of whether TAUT\nhas NC^0 proof systems. Addressing this question about 2TAUT, and since 2TAUT\nis closely related to reachability in graphs, we ask the same question about\nReachability. We show that both Undirected Reachability and Directed\nUnReachability have NC^0 proof systems, but Directed Reachability is still\nopen.\n  In the context of how much power is needed for proof systems for languages in\nNP, we observe that proof systems for a good fraction of languages in NP do not\nneed the full power of AC^0; they have SAC^0 or coSAC^0 proof systems."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.5090v1", 
    "title": "On the NP-Hardness of Approximating Ordering Constraint Satisfaction   Problems", 
    "arxiv-id": "1307.5090v1", 
    "author": "Cenny Wenner", 
    "publish": "2013-07-18T21:54:04Z", 
    "summary": "We show improved NP-hardness of approximating Ordering Constraint\nSatisfaction Problems (OCSPs). For the two most well-studied OCSPs, Maximum\nAcyclic Subgraph and Maximum Betweenness, we prove inapproximability of\n$14/15+\\epsilon$ and $1/2+\\epsilon$.\n  An OCSP is said to be approximation resistant if it is hard to approximate\nbetter than taking a uniformly random ordering. We prove that the Maximum\nNon-Betweenness Problem is approximation resistant and that there are width-$m$\napproximation-resistant OCSPs accepting only a fraction $1 / (m/2)!$ of\nassignments. These results provide the first examples of\napproximation-resistant OCSPs subject only to P $\\neq$ \\NP."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.5776v2", 
    "title": "An exact algorithm for 1-in-3 SAT", 
    "arxiv-id": "1307.5776v2", 
    "author": "Vangelis Th. Paschos", 
    "publish": "2013-07-22T17:02:36Z", 
    "summary": "1-in-3 SAT is an NP-complete variant of 3-SAT\\ where a \"clause\" is satisfied\niff exactly one of its three literal is satisfied. We present here an exact\nalgorithm solving \\oit\\ in time $O^*(1.260^n)$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1307.6738v1", 
    "title": "Efficient quantum protocols for XOR functions", 
    "arxiv-id": "1307.6738v1", 
    "author": "Shengyu Zhang", 
    "publish": "2013-07-25T13:37:44Z", 
    "summary": "We show that for any Boolean function f on {0,1}^n, the bounded-error quantum\ncommunication complexity of XOR functions $f\\circ \\oplus$ satisfies that\n$Q_\\epsilon(f\\circ \\oplus) = O(2^d (\\log\\|\\hat f\\|_{1,\\epsilon} + \\log\n\\frac{n}{\\epsilon}) \\log(1/\\epsilon))$, where d is the F2-degree of f, and\n$\\|\\hat f\\|_{1,\\epsilon} = \\min_{g:\\|f-g\\|_\\infty \\leq \\epsilon} \\|\\hat f\\|_1$.\nThis implies that the previous lower bound $Q_\\epsilon(f\\circ \\oplus) =\n\\Omega(\\log\\|\\hat f\\|_{1,\\epsilon})$ by Lee and Shraibman \\cite{LS09} is tight\nfor f with low F2-degree. The result also confirms the quantum version of the\nLog-rank Conjecture for low-degree XOR functions. In addition, we show that the\nexact quantum communication complexity satisfies $Q_E(f) = O(2^d \\log \\|\\hat\nf\\|_0)$, where $\\|\\hat f\\|_0$ is the number of nonzero Fourier coefficients of\nf. This matches the previous lower bound $Q_E(f(x,y)) = \\Omega(\\log rank(M_f))$\nby Buhrman and de Wolf \\cite{BdW01} for low-degree XOR functions."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1310.3674v1", 
    "title": "Weak Bases of Boolean Co-Clones", 
    "arxiv-id": "1310.3674v1", 
    "author": "Victor Lagerkvist", 
    "publish": "2013-10-14T13:24:03Z", 
    "summary": "Universal algebra and clone theory have proven to be a useful tool in the\nstudy of constraint satisfaction problems since the complexity, up to logspace\nreductions, is determined by the set of polymorphisms of the constraint\nlanguage. For classifications where primitive positive definitions are\nunsuitable, such as size-preserving reductions, weaker closure operations may\nbe necessary. In this article we consider strong partial clones which can be\nseen as a more fine-grained framework than Post's lattice where each clone\nsplits into an interval of strong partial clones. We investigate these\nintervals and give simple relational descriptions, weak bases, of the largest\nelements. The weak bases have a highly regular form and are in many cases\neasily relatable to the smallest members in the intervals, which suggests that\nthe lattice of strong partial clones is considerably simpler than the full\nlattice of partial clones."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1310.5576v1", 
    "title": "Parameterized (in)approximability of subset problems", 
    "arxiv-id": "1310.5576v1", 
    "author": "Vangelis Th. Paschos", 
    "publish": "2013-10-21T14:46:23Z", 
    "summary": "We discuss approximability and inapproximability in FPT-time for a large\nclass of subset problems where a feasible solution $S$ is a subset of the input\ndata and the value of $S$ is $|S|$. The class handled encompasses many\nwell-known graph, set, or satisfiability problems such as Dominating Set,\nVertex Cover, Set Cover, Independent Set, Feedback Vertex Set, etc. In a first\ntime, we introduce the notion of intersective approximability that generalizes\nthe one of safe approximability and show strong parameterized inapproximability\nresults for many of the subset problems handled. Then, we study approximability\nof these problems with respect to the dual parameter $n-k$ where $n$ is the\nsize of the instance and $k$ the standard parameter. More precisely, we show\nthat under such a parameterization, many of these problems, while\nW[$\\cdot$]-hard, admit parameterized approximation schemata."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1310.5746v2", 
    "title": "Trading inference effort versus size in CNF Knowledge Compilation", 
    "arxiv-id": "1310.5746v2", 
    "author": "Oliver Kullmann", 
    "publish": "2013-10-21T22:20:02Z", 
    "summary": "Knowledge Compilation (KC) studies compilation of boolean functions f into\nsome formalism F, which allows to answer all queries of a certain kind in\npolynomial time. Due to its relevance for SAT solving, we concentrate on the\nquery type \"clausal entailment\" (CE), i.e., whether a clause C follows from f\nor not, and we consider subclasses of CNF, i.e., clause-sets F with special\nproperties. In this report we do not allow auxiliary variables (except of the\nOutlook), and thus F needs to be equivalent to f.\n  We consider the hierarchies UC_k <= WC_k, which were introduced by the\nauthors in 2012. Each level allows CE queries. The first two levels are\nwell-known classes for KC. Namely UC_0 = WC_0 is the same as PI as studied in\nKC, that is, f is represented by the set of all prime implicates, while UC_1 =\nWC_1 is the same as UC, the class of unit-refutation complete clause-sets\nintroduced by del Val 1994. We show that for each k there are (sequences of)\nboolean functions with polysize representations in UC_{k+1}, but with an\nexponential lower bound on representations in WC_k. Such a separation was\npreviously only know for k=0. We also consider PC < UC, the class of\npropagation-complete clause-sets. We show that there are (sequences of) boolean\nfunctions with polysize representations in UC, while there is an exponential\nlower bound for representations in PC. These separations are steps towards a\ngeneral conjecture determining the representation power of the hierarchies PC_k\n< UC_k <= WC_k. The strong form of this conjecture also allows auxiliary\nvariables, as discussed in depth in the Outlook."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1310.6383v2", 
    "title": "The Frequent Paucity of Trivial Strings", 
    "arxiv-id": "1310.6383v2", 
    "author": "Jack H. Lutz", 
    "publish": "2013-10-23T20:33:14Z", 
    "summary": "A 1976 theorem of Chaitin can be used to show that arbitrarily dense sets of\nlengths n have a paucity of trivial strings (only a bounded number of strings\nof length n having trivially low plain Kolmogorov complexities). We use the\nprobabilistic method to give a new proof of this fact. This proof is much\nsimpler than previously published proofs, and it gives a tighter paucity bound."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1310.6976v1", 
    "title": "On Logical Depth and the Running Time of Shortest Programs", 
    "arxiv-id": "1310.6976v1", 
    "author": "P. M. B. Vitanyi", 
    "publish": "2013-10-25T16:50:06Z", 
    "summary": "The logical depth with significance $b$ of a finite binary string $x$ is the\nshortest running time of a binary program for $x$ that can be compressed by at\nmost $b$ bits. There is another definition of logical depth. We give two\ntheorems about the quantitative relation between these versions: the first\ntheorem concerns a variation of a known fact with a new proof, the second\ntheorem and its proof are new. We select the above version of logical depth and\nshow the following. There is an infinite sequence of strings of increasing\nlength such that for each $j$ there is a $b$ such that the logical depth of the\n$j$th string as a function of $j$ is incomputable (it rises faster than any\ncomputable function) but with $b$ replaced by $b+1$ the resuling function is\ncomputable. Hence the maximal gap between the logical depths resulting from\nincrementing appropriate $b$'s by 1 rises faster than any computable function.\nAll functions mentioned are upper bounded by the Busy Beaver function. Since\nfor every string its logical depth is nonincreasing in $b$, the minimal\ncomputation time of the shortest programs for the sequence of strings as a\nfunction of $j$ rises faster than any computable function but not so fast as\nthe Busy Beaver function."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1310.8317v1", 
    "title": "Power of Nondetreministic JAGs on Cayley graphs", 
    "arxiv-id": "1310.8317v1", 
    "author": "Ramyaa Ramyaa", 
    "publish": "2013-10-30T20:44:03Z", 
    "summary": "The Immerman-Szelepcsenyi Theorem uses an algorithm for co-st- connectivity\nbased on inductive counting to prove that NLOGSPACE is closed un- der\ncomplementation. We want to investigate whether counting is necessary for this\ntheorem to hold. Concretely, we show that Nondeterministic Jumping Graph\nAutmata (ND-JAGs) (pebble automata on graphs), on several families of Cayley\ngraphs, are equal in power to nondeterministic logspace Turing machines that\nare given such graphs as a linear encoding. In particular, it follows that\nND-JAGs can solve co-st-connectivity on those graphs. This came as a surprise\nsince Cook and Rackoff showed that deterministic JAGs cannot solve\nst-connectivity on many Cayley graphs due to their high self-similarity (every\nneighbourhood looks the same). Thus, our results show that on these graphs,\nnondeterminism provably adds computational power. The families of Cayley graphs\nwe consider include Cayley graphs of abelian groups and of all finite simple\ngroups irrespective of how they are presented and graphs corresponding to\ngroups generated by various product constructions, in- cluding iterated ones.\nWe remark that assessing the precise power of nondeterministic JAGs and in par-\nticular whether they can solve co-st-connectivity on arbitrary graphs is left\nas an open problem by Edmonds, Poon and Achlioptas. Our results suggest a\npositive answer to this question and in particular considerably limit the\nsearch space for a potential counterexample."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.0355v1", 
    "title": "Formulas vs. Circuits for Small Distance Connectivity", 
    "arxiv-id": "1312.0355v1", 
    "author": "Benjamin Rossman", 
    "publish": "2013-12-02T07:10:02Z", 
    "summary": "We give the first super-polynomial separation in the power of bounded-depth\nboolean formulas vs. circuits. Specifically, we consider the problem Distance\n$k(n)$ Connectivity, which asks whether two specified nodes in a graph of size\n$n$ are connected by a path of length at most $k(n)$. This problem is solvable\n(by the recursive doubling technique) on {\\bf circuits} of depth $O(\\log k)$\nand size $O(kn^3)$. In contrast, we show that solving this problem on {\\bf\nformulas} of depth $\\log n/(\\log\\log n)^{O(1)}$ requires size $n^{\\Omega(\\log\nk)}$ for all $k(n) \\leq \\log\\log n$. As corollaries:\n  (i) It follows that polynomial-size circuits for Distance $k(n)$ Connectivity\nrequire depth $\\Omega(\\log k)$ for all $k(n) \\leq \\log\\log n$. This matches the\nupper bound from recursive doubling and improves a previous $\\Omega(\\log\\log\nk)$ lower bound of Beame, Pitassi and Impagliazzo [BIP98].\n  (ii) We get a tight lower bound of $s^{\\Omega(d)}$ on the size required to\nsimulate size-$s$ depth-$d$ circuits by depth-$d$ formulas for all $s(n) =\nn^{O(1)}$ and $d(n) \\leq \\log\\log\\log n$. No lower bound better than\n$s^{\\Omega(1)}$ was previously known for any $d(n) \\nleq O(1)$.\n  Our proof technique is centered on a new notion of pathset complexity, which\nroughly speaking measures the minimum cost of constructing a set of (partial)\npaths in a universe of size $n$ via the operations of union and relational\njoin, subject to certain density constraints. Half of our proof shows that\nbounded-depth formulas solving Distance $k(n)$ Connectivity imply upper bounds\non pathset complexity. The other half is a combinatorial lower bound on pathset\ncomplexity."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.1718v1", 
    "title": "Upper semicomputable sumtests for lower semicomputable semimeasures", 
    "arxiv-id": "1312.1718v1", 
    "author": "Bruno Bauwens", 
    "publish": "2013-12-05T22:15:43Z", 
    "summary": "A sumtest for a discrete semimeasure $P$ is a function $f$ mapping bitstrings\nto non-negative rational numbers such that \\[\n  \\sum P(x)f(x) \\le 1 \\,.\n  \\] Sumtests are the discrete analogue of Martin-L\\\"of tests. The behavior of\nsumtests for computable $P$ seems well understood, but for some applications\nlower semicomputable $P$ seem more appropriate. In the case of tests for\nindependence, it is natural to consider upper semicomputable tests (see\n[B.Bauwens and S.Terwijn, Theory of Computing Systems 48.2 (2011): 247-268]).\n  In this paper, we characterize upper semicomputable sumtests relative to any\nlower semicomputable semimeasures using Kolmogorov complexity. It is studied to\nwhat extend such tests are pathological: can upper semicomputable sumtests for\n$m(x)$ be large? It is shown that the logarithm of such tests does not exceed\n$\\log |x| + O(\\log^{(2)} |x|)$ (where $|x|$ denotes the length of $x$ and\n$\\log^{(2)} = \\log\\log$) and that this bound is tight, i.e. there is a test\nwhose logarithm exceeds $\\log |x| - O(\\log^{(2)} |x|$) infinitely often.\nFinally, it is shown that for each such test $e$ the mutual information of a\nstring with the Halting problem is at least $\\log e(x)-O(1)$; thus $e$ can only\nbe large for ``exotic'' strings."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.1826v1", 
    "title": "Hitting-sets for low-distance multilinear depth-3", 
    "arxiv-id": "1312.1826v1", 
    "author": "Nitin Saxena", 
    "publish": "2013-12-06T10:46:21Z", 
    "summary": "The depth-$3$ model has recently gained much importance, as it has become a\nstepping-stone to understanding general arithmetic circuits. Its restriction to\nmultilinearity has known exponential lower bounds but no nontrivial blackbox\nidentity tests. In this paper we take a step towards designing such\nhitting-sets. We define a notion of distance for multilinear depth-$3$ circuits\n(say, in $n$ variables and $k$ product gates) that measures how far are the\npartitions from a mere refinement. The $1$-distance strictly subsumes the\nset-multilinear model, while $n$-distance captures general multilinear\ndepth-$3$. We design a hitting-set in time poly($n^{\\delta\\log k}$) for\n$\\delta$-distance. Further, we give an extension of our result to models where\nthe distance is large (close to $n$) but it is small when restricted to certain\nvariables. This implies the first subexponential whitebox PIT for the sum of\nconstantly many set-multilinear depth-$3$ circuits.\n  We also explore a new model of read-once algebraic branching programs (ROABP)\nwhere the factor-matrices are invertible (called invertible-factor ROABP). We\ndesign a hitting-set in time poly($\\text{size}^{w^2}$) for width-$w$\ninvertible-factor ROABP. Further, we could do without the invertibility\nrestriction when $w=2$. Previously, the best result for width-$2$ ROABP was\nquasi-polynomial time (Forbes-Saptharishi-Shpilka, arXiv 2013).\n  The common thread in all these results is the phenomenon of low-support `rank\nconcentration'. We exploit the structure of these models to prove\nrank-concentration after a `small shift' in the variables. Our proof techniques\nare stronger than the results of Agrawal-Saha-Saxena (STOC 2013) and\nForbes-Saptharishi-Shpilka (arXiv 2013); giving us quasi-polynomial-time\nhitting-sets for models where no subexponential whitebox algorithms were known\nbefore."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.2143v1", 
    "title": "A composition theorem for parity kill number", 
    "arxiv-id": "1312.2143v1", 
    "author": "Yu Zhao", 
    "publish": "2013-12-07T21:40:43Z", 
    "summary": "In this work, we study the parity complexity measures\n${\\mathsf{C}^{\\oplus}_{\\min}}[f]$ and ${\\mathsf{DT^{\\oplus}}}[f]$.\n${\\mathsf{C}^{\\oplus}_{\\min}}[f]$ is the \\emph{parity kill number} of $f$, the\nfewest number of parities on the input variables one has to fix in order to\n\"kill\" $f$, i.e. to make it constant. ${\\mathsf{DT^{\\oplus}}}[f]$ is the depth\nof the shortest \\emph{parity decision tree} which computes $f$. These\ncomplexity measures have in recent years become increasingly important in the\nfields of communication complexity \\cite{ZS09, MO09, ZS10, TWXZ13} and\npseudorandomness \\cite{BK12, Sha11, CT13}.\n  Our main result is a composition theorem for ${\\mathsf{C}^{\\oplus}_{\\min}}$.\nThe $k$-th power of $f$, denoted $f^{\\circ k}$, is the function which results\nfrom composing $f$ with itself $k$ times. We prove that if $f$ is not a parity\nfunction, then ${\\mathsf{C}^{\\oplus}_{\\min}}[f^{\\circ k}] \\geq\n\\Omega({\\mathsf{C}_{\\min}}[f]^{k}).$ In other words, the parity kill number of\n$f$ is essentially supermultiplicative in the \\emph{normal} kill number of $f$\n(also known as the minimum certificate complexity).\n  As an application of our composition theorem, we show lower bounds on the\nparity complexity measures of $\\mathsf{Sort}^{\\circ k}$ and $\\mathsf{HI}^{\\circ\nk}$. Here $\\mathsf{Sort}$ is the sort function due to Ambainis \\cite{Amb06},\nand $\\mathsf{HI}$ is Kushilevitz's hemi-icosahedron function \\cite{NW95}. In\ndoing so, we disprove a conjecture of Montanaro and Osborne \\cite{MO09} which\nhad applications to communication complexity and computational learning theory.\nIn addition, we give new lower bounds for conjectures of \\cite{MO09,ZS10} and\n\\cite{TWXZ13}."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.2915v1", 
    "title": "Hardness of Finding Independent Sets in 2-Colorable Hypergraphs and of   Satisfiable CSPs", 
    "arxiv-id": "1312.2915v1", 
    "author": "Rishi Saket", 
    "publish": "2013-12-10T19:04:24Z", 
    "summary": "This work revisits the PCP Verifiers used in the works of Hastad [Has01],\nGuruswami et al.[GHS02], Holmerin[Hol02] and Guruswami[Gur00] for satisfiable\nMax-E3-SAT and Max-Ek-Set-Splitting, and independent set in 2-colorable\n4-uniform hypergraphs. We provide simpler and more efficient PCP Verifiers to\nprove the following improved hardness results: Assuming that NP\\not\\subseteq\nDTIME(N^{O(loglog N)}),\n  There is no polynomial time algorithm that, given an n-vertex 2-colorable\n4-uniform hypergraph, finds an independent set of n/(log n)^c vertices, for\nsome constant c > 0.\n  There is no polynomial time algorithm that satisfies 7/8 + 1/(log n)^c\nfraction of the clauses of a satisfiable Max-E3-SAT instance of size n, for\nsome constant c > 0.\n  For any fixed k >= 4, there is no polynomial time algorithm that finds a\npartition splitting (1 - 2^{-k+1}) + 1/(log n)^c fraction of the k-sets of a\nsatisfiable Max-Ek-Set-Splitting instance of size n, for some constant c > 0.\n  Our hardness factor for independent set in 2-colorable 4-uniform hypergraphs\nis an exponential improvement over the previous results of Guruswami et\nal.[GHS02] and Holmerin[Hol02]. Similarly, our inapproximability of (log\nn)^{-c} beyond the random assignment threshold for Max-E3-SAT and\nMax-Ek-Set-Splitting is an exponential improvement over the previous bounds\nproved in [Has01], [Hol02] and [Gur00]. The PCP Verifiers used in our results\navoid the use of a variable bias parameter used in previous works, which leads\nto the improved hardness thresholds in addition to simplifying the analysis\nsubstantially. Apart from standard techniques from Fourier Analysis, for the\nfirst mentioned result we use a mixing estimate of Markov Chains based on\nuniform reverse hypercontractivity over general product spaces from the work of\nMossel et al.[MOS13]."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.3003v1", 
    "title": "Decision Trees, Protocols, and the Fourier Entropy-Influence Conjecture", 
    "arxiv-id": "1312.3003v1", 
    "author": "Chenggang Wu", 
    "publish": "2013-12-11T00:15:28Z", 
    "summary": "Given $f:\\{-1, 1\\}^n \\rightarrow \\{-1, 1\\}$, define the \\emph{spectral\ndistribution} of $f$ to be the distribution on subsets of $[n]$ in which the\nset $S$ is sampled with probability $\\widehat{f}(S)^2$. Then the Fourier\nEntropy-Influence (FEI) conjecture of Friedgut and Kalai (1996) states that\nthere is some absolute constant $C$ such that $\\operatorname{H}[\\widehat{f}^2]\n\\leq C\\cdot\\operatorname{Inf}[f]$. Here, $\\operatorname{H}[\\widehat{f}^2]$\ndenotes the Shannon entropy of $f$'s spectral distribution, and\n$\\operatorname{Inf}[f]$ is the total influence of $f$. This conjecture is one\nof the major open problems in the analysis of Boolean functions, and settling\nit would have several interesting consequences.\n  Previous results on the FEI conjecture have been largely through direct\ncalculation. In this paper we study a natural interpretation of the conjecture,\nwhich states that there exists a communication protocol which, given subset $S$\nof $[n]$ distributed as $\\widehat{f}^2$, can communicate the value of $S$ using\nat most $C\\cdot\\operatorname{Inf}[f]$ bits in expectation.\n  Using this interpretation, we are able show the following results:\n  1. First, if $f$ is computable by a read-$k$ decision tree, then\n$\\operatorname{H}[\\widehat{f}^2] \\leq 9k\\cdot \\operatorname{Inf}[f]$.\n  2. Next, if $f$ has $\\operatorname{Inf}[f] \\geq 1$ and is computable by a\ndecision tree with expected depth $d$, then $\\operatorname{H}[\\widehat{f}^2]\n\\leq 12d\\cdot \\operatorname{Inf}[f]$.\n  3. Finally, we give a new proof of the main theorem of O'Donnell and Tan\n(ICALP 2013), i.e. that their FEI$^+$ conjecture composes.\n  In addition, we show that natural improvements to our decision tree results\nwould be sufficient to prove the FEI conjecture in its entirety. We believe\nthat our methods give more illuminating proofs than previous results about the\nFEI conjecture."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.3193v1", 
    "title": "Iterated group products and leakage resilience against NC^1", 
    "arxiv-id": "1312.3193v1", 
    "author": "Eric Miles", 
    "publish": "2013-12-11T14:48:42Z", 
    "summary": "We show that if NC$^1 \\neq$ L, then for every element $\\alpha$ of the\nalternating group $A_t$, circuits of depth $O(\\log t)$ cannot distinguish\nbetween a uniform vector over $(A_t)^t$ with product $= \\alpha$ and one with\nproduct $=$ identity. Combined with a recent construction by the author and\nViola in the setting of leakage-resilient cryptography [STOC '13], this gives a\ncompiler that produces circuits withstanding leakage from NC$^1$ (assuming\nNC$^1 \\neq$ L). For context, leakage from NC$^1$ breaks nearly all previous\nconstructions, and security against leakage from P is impossible. %In the\nmulti-query setting, circuits produced by this compiler use a simple secure\nhardware component.\n  We build on work by Cook and McKenzie [J.\\ Algorithms '87] establishing the\nrelationship between L $=$ logarithmic space and the symmetric group $S_t$. Our\ntechniques include a novel algorithmic use of commutators to manipulate the\ncycle structure of permutations in $A_t$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.4428v2", 
    "title": "On Constraint Satisfaction Problems below P", 
    "arxiv-id": "1312.4428v2", 
    "author": "Laszlo Egri", 
    "publish": "2013-12-16T16:59:49Z", 
    "summary": "Symmetric Datalog, a fragment of the logic programming language Datalog, is\nconjectured to capture all constraint satisfaction problems (CSP) in L.\nTherefore developing tools that help us understand whether or not a CSP can be\ndefined in symmetric Datalog is an important task. It is widely known that a\nCSP is definable in Datalog and linear Datalog if and only if that CSP has\nbounded treewidth and bounded pathwidth duality, respectively. In the case of\nsymmetric Datalog, Bulatov, Krokhin and Larose ask for such a duality (2008).\nWe provide two such dualities, and give applications. In particular, we give a\nshort and simple new proof of the result of Dalmau and Larose that \"Maltsev +\nDatalog -> symmetric Datalog\" (2008).\n  In the second part of the paper, we provide some evidence for the conjecture\nof Dalmau (2002) that every CSP in NL is definable in linear Datalog. Our\nresults also show that a wide class of CSPs-CSPs which do not have bounded\npathwidth duality (e.g., the P-complete Horn-3Sat problem)-cannot be defined by\nany polynomial size family of monotone read-once nondeterministic branching\nprograms."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.5937v2", 
    "title": "On the dynamic width of the 3-colorability problem", 
    "arxiv-id": "1312.5937v2", 
    "author": "Oleg Verbitsky", 
    "publish": "2013-12-20T13:42:06Z", 
    "summary": "A graph $G$ is 3-colorable if and only if it maps homomorphically to the\ncomplete 3-vertex graph $K_3$. The last condition can be checked by a\n$k$-consistency algorithm where the parameter $k$ has to be chosen large\nenough, dependent on $G$. Let $W(G)$ denote the minimum $k$ sufficient for this\npurpose. For a non-3-colorable graph $G$, $W(G)$ is equal to the minimum $k$\nsuch that $G$ can be distinguished from $K_3$ in the $k$-variable\nexistential-positive first-order logic. We define the dynamic width of the\n3-colorability problem as the function $W(n)=\\max_G W(G)$, where the maximum is\ntaken over all non-3-colorable $G$ with $n$ vertices.\n  The assumption $\\mathrm{NP}\\ne\\mathrm{P}$ implies that $W(n)$ is unbounded.\nIndeed, a lower bound $W(n)=\\Omega(\\log\\log n/\\log\\log\\log n)$ follows\nunconditionally from the work of Nesetril and Zhu on bounded treewidth duality.\nThe Exponential Time Hypothesis implies a much stronger bound\n$W(n)=\\Omega(n/\\log n)$ and indeed we unconditionally prove that\n$W(n)=\\Omega(n)$. In fact, an even stronger statement is true: A first-order\nsentence distinguishing any 3-colorable graph on $n$ vertices from any\nnon-3-colorable graph on $n$ vertices must have $\\Omega(n)$ variables.\n  On the other hand, we observe that $W(G)\\le 3\\,\\alpha(G)+1$ and $W(G)\\le\nn-\\alpha(G)+1$ for every non-3-colorable graph $G$ with $n$ vertices, where\n$\\alpha(G)$ denotes the independence number of $G$. This implies that\n$W(n)\\le\\frac34\\,n+1$, improving on the trivial upper bound $W(n)\\le n$.\n  We also show that $W(G)>\\frac1{16}\\, g(G)$ for every non-3-colorable graph\n$G$, where $g(G)$ denotes the girth of $G$.\n  Finally, we consider the function $W(n)$ over planar graphs and prove that\n$W(n)=\\Theta(\\sqrt n)$ in the case."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.5978v1", 
    "title": "Superpolynomial lower bounds for general homogeneous depth 4 arithmetic   circuits", 
    "arxiv-id": "1312.5978v1", 
    "author": "Shubhangi Saraf", 
    "publish": "2013-12-20T15:03:16Z", 
    "summary": "In this paper, we prove superpolynomial lower bounds for the class of\nhomogeneous depth 4 arithmetic circuits. We give an explicit polynomial in VNP\nof degree $n$ in $n^2$ variables such that any homogeneous depth 4 arithmetic\ncircuit computing it must have size $n^{\\Omega(\\log \\log n)}$.\n  Our results extend the works of Nisan-Wigderson [NW95] (which showed\nsuperpolynomial lower bounds for homogeneous depth 3 circuits),\nGupta-Kamath-Kayal-Saptharishi and Kayal-Saha-Saptharishi [GKKS13, KSS13]\n(which showed superpolynomial lower bounds for homogeneous depth 4 circuits\nwith bounded bottom fan-in), Kumar-Saraf [KS13a] (which showed superpolynomial\nlower bounds for homogeneous depth 4 circuits with bounded top fan-in) and\nRaz-Yehudayoff and Fournier-Limaye-Malod-Srinivasan [RY08, FLMS13] (which\nshowed superpolynomial lower bounds for multilinear depth 4 circuits). Several\nof these results in fact showed exponential lower bounds.\n  The main ingredient in our proof is a new complexity measure of {\\it bounded\nsupport} shifted partial derivatives. This measure allows us to prove\nexponential lower bounds for homogeneous depth 4 circuits where all the\nmonomials computed at the bottom layer have {\\it bounded support} (but possibly\nunbounded degree/fan-in), strengthening the results of Gupta et al and Kayal et\nal [GKKS13, KSS13]. This new lower bound combined with a careful \"random\nrestriction\" procedure (that transforms general depth 4 homogeneous circuits to\ndepth 4 circuits with bounded support) gives us our final result."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2600917", 
    "link": "http://arxiv.org/pdf/1312.6242v4", 
    "title": "Generating Matrix Identities and Proof Complexity", 
    "arxiv-id": "1312.6242v4", 
    "author": "Iddo Tzameret", 
    "publish": "2013-12-21T11:32:41Z", 
    "summary": "Motivated by the fundamental lower bounds questions in proof complexity, we\ninitiate the study of matrix identities as hard instances for strong proof\nsystems. A matrix identity of $d \\times d$ matrices over a field $\\mathbb{F}$,\nis a non-commutative polynomial $f(x_1,\\ldots,x_n)$ over $\\mathbb{F}$ such that\n$f$ vanishes on every $d \\times d$ matrix assignment to its variables.\n  We focus on arithmetic proofs, which are proofs of polynomial identities\noperating with arithmetic circuits and whose axioms are the polynomial-ring\naxioms (these proofs serve as an algebraic analogue of the Extended Frege\npropositional proof system; and over $GF(2)$ they constitute formally a\nsub-system of Extended Frege [HT12]). We introduce a decreasing in strength\nhierarchy of proof systems within arithmetic proofs, in which the $d$th level\nis a sound and complete proof system for proving $d \\times d$ matrix identities\n(over a given field). For each level $d>2$ in the hierarchy, we establish a\nproof-size lower bound in terms of the number of variables in the matrix\nidentity proved: we show the existence of a family of matrix identities $f_n$\nwith $n$ variables, such that any proof of $f_n=0$ requires $\\Omega(n^{2d})$\nnumber of lines. The lower bound argument uses fundamental results from the\ntheory of algebras with polynomial identities together with a generalization of\nthe arguments in [Hru11].\n  We then set out to study matrix identities as hard instances for (full)\narithmetic proofs. We present two conjectures, one about non-commutative\narithmetic circuit complexity and the other about proof complexity, under which\nup to exponential-size lower bounds on arithmetic proofs (in terms of the\narithmetic circuit size of the identities proved) hold. Finally, we discuss the\napplicability of our approach to strong propositional proof systems such as\nExtended Frege."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1312.7615v1", 
    "title": "Reachability in Cooperating Systems with Architectural Constraints is   PSPACE-Complete", 
    "arxiv-id": "1312.7615v1", 
    "author": "Nils Semmelrock", 
    "publish": "2013-12-30T03:13:09Z", 
    "summary": "The reachability problem in cooperating systems is known to be\nPSPACE-complete. We show here that this problem remains PSPACE-complete when we\nrestrict the communication structure between the subsystems in various ways.\nFor this purpose we introduce two basic and incomparable subclasses of\ncooperating systems that occur often in practice and provide respective\nreductions. The subclasses we consider consist of cooperating systems the\ncommunication structure of which forms a line respectively a star."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.0189v1", 
    "title": "On the Limits of Depth Reduction at Depth 3 Over Small Finite Fields", 
    "arxiv-id": "1401.0189v1", 
    "author": "Partha Mukhopadhyay", 
    "publish": "2013-12-31T17:08:36Z", 
    "summary": "Recently, Gupta et.al. [GKKS2013] proved that over Q any $n^{O(1)}$-variate\nand $n$-degree polynomial in VP can also be computed by a depth three\n$\\Sigma\\Pi\\Sigma$ circuit of size $2^{O(\\sqrt{n}\\log^{3/2}n)}$. Over fixed-size\nfinite fields, Grigoriev and Karpinski proved that any $\\Sigma\\Pi\\Sigma$\ncircuit that computes $Det_n$ (or $Perm_n$) must be of size $2^{\\Omega(n)}$\n[GK1998]. In this paper, we prove that over fixed-size finite fields, any\n$\\Sigma\\Pi\\Sigma$ circuit for computing the iterated matrix multiplication\npolynomial of $n$ generic matrices of size $n\\times n$, must be of size\n$2^{\\Omega(n\\log n)}$. The importance of this result is that over fixed-size\nfields there is no depth reduction technique that can be used to compute all\nthe $n^{O(1)}$-variate and $n$-degree polynomials in VP by depth 3 circuits of\nsize $2^{o(n\\log n)}$. The result [GK1998] can only rule out such a possibility\nfor depth 3 circuits of size $2^{o(n)}$.\n  We also give an example of an explicit polynomial ($NW_{n,\\epsilon}(X)$) in\nVNP (not known to be in VP), for which any $\\Sigma\\Pi\\Sigma$ circuit computing\nit (over fixed-size fields) must be of size $2^{\\Omega(n\\log n)}$. The\npolynomial we consider is constructed from the combinatorial design. An\ninteresting feature of this result is that we get the first examples of two\npolynomials (one in VP and one in VNP) such that they have provably stronger\ncircuit size lower bounds than Permanent in a reasonably strong model of\ncomputation.\n  Next, we prove that any depth 4\n$\\Sigma\\Pi^{[O(\\sqrt{n})]}\\Sigma\\Pi^{[\\sqrt{n}]}$ circuit computing\n$NW_{n,\\epsilon}(X)$ (over any field) must be of size $2^{\\Omega(\\sqrt{n}\\log\nn)}$. To the best of our knowledge, the polynomial $NW_{n,\\epsilon}(X)$ is the\nfirst example of an explicit polynomial in VNP such that it requires\n$2^{\\Omega(\\sqrt{n}\\log n)}$ size depth four circuits, but no known matching\nupper bound."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.2436v1", 
    "title": "Hardness of robust graph isomorphism, Lasserre gaps, and asymmetry of   random graphs", 
    "arxiv-id": "1401.2436v1", 
    "author": "Yuan Zhou", 
    "publish": "2014-01-10T19:50:15Z", 
    "summary": "Building on work of Cai, F\\\"urer, and Immerman \\cite{CFI92}, we show two\nhardness results for the Graph Isomorphism problem. First, we show that there\nare pairs of nonisomorphic $n$-vertex graphs $G$ and $H$ such that any\nsum-of-squares (SOS) proof of nonisomorphism requires degree $\\Omega(n)$. In\nother words, we show an $\\Omega(n)$-round integrality gap for the Lasserre SDP\nrelaxation. In fact, we show this for pairs $G$ and $H$ which are not even\n$(1-10^{-14})$-isomorphic. (Here we say that two $n$-vertex, $m$-edge graphs\n$G$ and $H$ are $\\alpha$-isomorphic if there is a bijection between their\nvertices which preserves at least $\\alpha m$ edges.) Our second result is that\nunder the {\\sc R3XOR} Hypothesis \\cite{Fei02} (and also any of a class of\nhypotheses which generalize the {\\sc R3XOR} Hypothesis), the \\emph{robust}\nGraph Isomorphism problem is hard. I.e.\\ for every $\\epsilon > 0$, there is no\nefficient algorithm which can distinguish graph pairs which are\n$(1-\\epsilon)$-isomorphic from pairs which are not even\n$(1-\\epsilon_0)$-isomorphic for some universal constant $\\epsilon_0$. Along the\nway we prove a robust asymmetry result for random graphs and hypergraphs which\nmay be of independent interest."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.3063v3", 
    "title": "Lines Missing Every Random Point", 
    "arxiv-id": "1401.3063v3", 
    "author": "Neil Lutz", 
    "publish": "2014-01-14T04:45:17Z", 
    "summary": "We prove that there is, in every direction in Euclidean space, a line that\nmisses every computably random point. We also prove that there exist, in every\ndirection in Euclidean space, arbitrarily long line segments missing every\ndouble exponential time random point."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.3687v2", 
    "title": "$2^3$ Quantified Boolean Formula Games and Their Complexities", 
    "arxiv-id": "1401.3687v2", 
    "author": "Kyle Burke", 
    "publish": "2014-01-15T17:55:42Z", 
    "summary": "Consider QBF, the Quantified Boolean Formula problem, as a combinatorial game\nruleset. The problem is rephrased as determining the winner of the game where\ntwo opposing players take turns assigning values to boolean variables. In this\npaper, three common variations of games are applied to create seven new games:\nwhether each player is restricted to where they may play, which values they may\nset variables to, or the condition they are shooting for at the end of the\ngame. The complexity for determining which player can win is analyzed for all\ngames. Of the seven, two are trivially in P and the other five are\nPSPACE-complete. These varying properties are common for combinatorial games;\nreductions from these five hard games can simplify the process for showing the\nPSPACE-hardness of other games."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.3714v2", 
    "title": "Testing Equivalence of Polynomials under Shifts", 
    "arxiv-id": "1401.3714v2", 
    "author": "Amir Shpilka", 
    "publish": "2014-01-15T19:29:48Z", 
    "summary": "Two polynomials $f, g \\in \\mathbb{F}[x_1, \\ldots, x_n]$ are called\nshift-equivalent if there exists a vector $(a_1, \\ldots, a_n) \\in \\mathbb{F}^n$\nsuch that the polynomial identity $f(x_1+a_1, \\ldots, x_n+a_n) \\equiv\ng(x_1,\\ldots,x_n)$ holds. Our main result is a new randomized algorithm that\ntests whether two given polynomials are shift equivalent. Our algorithm runs in\ntime polynomial in the circuit size of the polynomials, to which it is given\nblack box access. This complements a previous work of Grigoriev (Theoretical\nComputer Science, 1997) who gave a deterministic algorithm running in time\n$n^{O(d)}$ for degree $d$ polynomials.\n  Our algorithm uses randomness only to solve instances of the Polynomial\nIdentity Testing (PIT) problem. Hence, if one could de-randomize PIT (a\nlong-standing open problem in complexity) a de-randomization of our algorithm\nwould follow. This establishes an equivalence between de-randomizing\nshift-equivalence testing and de-randomizing PIT (both in the black-box and the\nwhite-box setting). For certain restricted models, such as Read Once Branching\nPrograms, we already obtain a deterministic algorithm using existing PIT\nresults."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.4512v1", 
    "title": "A quadratically tight partition bound for classical communication   complexity and query complexity", 
    "arxiv-id": "1401.4512v1", 
    "author": "Nisheeth K. Vishnoi", 
    "publish": "2014-01-18T02:39:29Z", 
    "summary": "In this work we introduce, both for classical communication complexity and\nquery complexity, a modification of the 'partition bound' introduced by Jain\nand Klauck [2010]. We call it the 'public-coin partition bound'. We show that\n(the logarithm to the base two of) its communication complexity and query\ncomplexity versions form, for all relations, a quadratically tight lower bound\non the public-coin randomized communication complexity and randomized query\ncomplexity respectively."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.4879v2", 
    "title": "On the Computing Power of $+$, $-$, and $\\times$", 
    "arxiv-id": "1401.4879v2", 
    "author": "Marcello Mamino", 
    "publish": "2014-01-20T12:54:33Z", 
    "summary": "Modify the Blum-Shub-Smale model of computation replacing the permitted\ncomputational primitives (the real field operations) with any finite set $B$ of\nreal functions semialgebraic over the rationals. Consider the class of boolean\ndecision problems that can be solved in polynomial time in the new model by\nmachines with no machine constants. How does this class depend on $B$? We prove\nthat it is always contained in the class obtained for $B = \\{+, -, \\times\\}$.\nMoreover, if $B$ is a set of continuous semialgebraic functions containing $+$\nand $-$, and such that arbitrarily small numbers can be computed using $B$,\nthen we have the following dichotomy: either our class is $\\mathsf P$ or it\ncoincides with the class obtained for $B = \\{+, -, \\times\\}$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.5781v1", 
    "title": "Partition Expanders", 
    "arxiv-id": "1401.5781v1", 
    "author": "Pavel Pudl\u00e1k", 
    "publish": "2014-01-22T20:40:28Z", 
    "summary": "We introduce a new concept, which we call partition expanders. The basic idea\nis to study quantitative properties of graphs in a slightly different way than\nit is in the standard definition of expanders. While in the definition of\nexpanders it is required that the number of edges between any pair of\nsufficiently large sets is close to the expected number, we consider partitions\nand require this condition only for most of the pairs of blocks. As a result,\nthe blocks can be substantially smaller.\n  We show that for some range of parameters, to be a partition expander a\nrandom graph needs exponentially smaller degree than any expander would require\nin order to achieve similar expanding properties.\n  We apply the concept of partition expanders in communication complexity.\nFirst, we give a PRG for the SMP model of the optimal seed length, n+O(log k).\nSecond, we compare the model of SMP to that of Simultaneous Two-Way\nCommunication, and give a new separation that is stronger both qualitatively\nand quantitatively than the previously known ones."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.6030v2", 
    "title": "The Effective Solving of the Tasks from NP by a Quantum Computer", 
    "arxiv-id": "1401.6030v2", 
    "author": "Sergey Sysoev", 
    "publish": "2014-01-23T16:10:16Z", 
    "summary": "The new model of quantum computation is proposed, for which an effective\nalgorithm of solving any task in NP is described. The work is based and\ninspired be the Grover's algorithm for solving NP-tasks with quadratic speedup\ncompared to the classical computation model. The provided model and algorithm\nexhibit the exponential speedup over that described by Grover."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.6520v24", 
    "title": "Approximation Resistance by Disguising Biased Distributions", 
    "arxiv-id": "1401.6520v24", 
    "author": "Peng Cui", 
    "publish": "2014-01-25T11:21:08Z", 
    "summary": "In this short note, the author shows that the gap problem of some 3-XOR is\nNP-hard and can be solved by running Charikar\\&Wirth's SDP algorithm for two\nrounds. To conclude, the author proves that $P=NP$."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1401.7480v3", 
    "title": "NP is contained in DTIME(n^O(log^{gamma}))", 
    "arxiv-id": "1401.7480v3", 
    "author": "Bruce Litow", 
    "publish": "2014-01-29T12:07:54Z", 
    "summary": "We use existential Diophantine predicates carefully reinterpreted over the\nreals and the time complexity of Tarski algebra to show that 3-CNF SAT is in\nn^O(log^{gamma} n) time for an absolute positive constant gamma."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.138.1", 
    "link": "http://arxiv.org/pdf/1403.0417v1", 
    "title": "On the Complexity of Computing Two Nonlinearity Measures", 
    "arxiv-id": "1403.0417v1", 
    "author": "Magnus Gausdal Find", 
    "publish": "2014-03-03T12:53:57Z", 
    "summary": "We study the computational complexity of two Boolean nonlinearity measures:\nthe nonlinearity and the multiplicative complexity. We show that if one-way\nfunctions exist, no algorithm can compute the multiplicative complexity in time\n$2^{O(n)}$ given the truth table of length $2^n$, in fact under the same\nassumption it is impossible to approximate the multiplicative complexity within\na factor of $(2-\\epsilon)^{n/2}$. When given a circuit, the problem of\ndetermining the multiplicative complexity is in the second level of the\npolynomial hierarchy. For nonlinearity, we show that it is #P hard to compute\ngiven a function represented by a circuit."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-47672-7_69", 
    "link": "http://arxiv.org/pdf/1403.0476v3", 
    "title": "Algebraic Properties of Valued Constraint Satisfaction Problem", 
    "arxiv-id": "1403.0476v3", 
    "author": "Joanna Ochremiak", 
    "publish": "2014-03-03T16:22:16Z", 
    "summary": "The paper presents an algebraic framework for optimization problems\nexpressible as Valued Constraint Satisfaction Problems. Our results generalize\nthe algebraic framework for the decision version (CSPs) provided by Bulatov et\nal. [SICOMP 2005]. We introduce the notions of weighted algebras and varieties\nand use the Galois connection due to Cohen et al. [SICOMP 2013] to link VCSP\nlanguages to weighted algebras. We show that the difficulty of VCSP depends\nonly on the weighted variety generated by the associated weighted algebra.\nParalleling the results for CSPs we exhibit a reduction to cores and rigid\ncores which allows us to focus on idempotent weighted varieties. Further, we\npropose an analogue of the Algebraic CSP Dichotomy Conjecture; prove the\nhardness direction and verify that it agrees with known results for VCSPs on\ntwo-element sets [Cohen et al. 2006], finite-valued VCSPs [Thapper and Zivny\n2013] and conservative VCSPs [Kolmogorov and Zivny 2013]."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-47672-7_69", 
    "link": "http://arxiv.org/pdf/1403.1307v5", 
    "title": "An n\\log n Lower Bound for Fourier Transform Computation in the Well   Conditioned Model", 
    "arxiv-id": "1403.1307v5", 
    "author": "Nir Ailon", 
    "publish": "2014-03-06T01:02:54Z", 
    "summary": "Obtaining a non-trivial (super-linear) lower bound for computation of the\nFourier transform in the linear circuit model has been a long standing open\nproblem for over 40 years.\n  An early result by Morgenstern from 1973, provides an $\\Omega(n \\log n)$\nlower bound for the unnormalized Fourier transform when the constants used in\nthe computation are bounded. The proof uses a potential function related to a\ndeterminant. The result does not explain why the normalized Fourier transform\n(of unit determinant) should be difficult to compute in the same model. Hence,\nthe result is not scale insensitive.\n  More recently, Ailon (2013) showed that if only unitary 2-by-2 gates are\nused, and additionally no extra memory is allowed, then the normalized Fourier\ntransform requires $\\Omega(n\\log n)$ steps. This rather limited result is also\nsensitive to scaling, but highlights the complexity inherent in the Fourier\ntransform arising from introducing entropy, unlike, say, the identity matrix\n(which is as complex as the Fourier transform using Morgenstern's arguments,\nunder proper scaling).\n  In this work we extend the arguments of Ailon (2013). In the first extension,\nwhich is also the main contribution, we provide a lower bound for computing any\nscaling of the Fourier transform. Our restriction is that, the composition of\nall gates up to any point must be a well conditioned linear transformation. The\nlower bound is $\\Omega(R^{-1}n\\log n)$, where $R$ is the uniform condition\nnumber. Second, we assume extra space is allowed, as long as it contains\ninformation of bounded norm at the end of the computation.\n  The main technical contribution is an extension of matrix entropy used in\nAilon (2013) for unitary matrices to a potential function computable for any\nmatrix, using Shannon entropy on \"quasi-probabilities\"."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-47672-7_69", 
    "link": "http://arxiv.org/pdf/1403.1911v1", 
    "title": "Candy Crush is NP-hard", 
    "arxiv-id": "1403.1911v1", 
    "author": "Toby Walsh", 
    "publish": "2014-03-08T01:25:16Z", 
    "summary": "We prove that playing Candy Crush to achieve a given score in a fixed number\nof swaps is NP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.1007/978-3-662-47672-7_69", 
    "link": "http://arxiv.org/pdf/1403.3431v2", 
    "title": "Minimal TSP Tour is coNP-Complete", 
    "arxiv-id": "1403.3431v2", 
    "author": "Marzio De Biasi", 
    "publish": "2014-03-13T21:00:36Z", 
    "summary": "The problem of deciding if a Traveling Salesman Problem (TSP) tour is minimal\nwas proved to be coNP-complete by Papadimitriou and Steiglitz. We give an\nalternative proof based on a polynomial time reduction from 3SAT. Like the\noriginal proof, our reduction also shows that given a graph $G$ and an\nHamiltonian path of $G$, it is NP-complete to check if $G$ contains an\nHamiltonian cycle (Restricted Hamiltonian Cycle problem)."
},{
    "category": "cs.CC", 
    "doi": "10.3233/COM-140030", 
    "link": "http://arxiv.org/pdf/1403.3565v2", 
    "title": "Parameterized Inapproximability of Target Set Selection and   Generalizations", 
    "arxiv-id": "1403.3565v2", 
    "author": "Florian Sikora", 
    "publish": "2014-03-14T13:09:20Z", 
    "summary": "In this paper, we consider the Target Set Selection problem: given a graph\nand a threshold value $thr(v)$ for any vertex $v$ of the graph, find a minimum\nsize vertex-subset to \"activate\" s.t. all the vertices of the graph are\nactivated at the end of the propagation process. A vertex $v$ is activated\nduring the propagation process if at least $thr(v)$ of its neighbors are\nactivated. This problem models several practical issues like faults in\ndistributed networks or word-to-mouth recommendations in social networks. We\nshow that for any functions $f$ and $\\rho$ this problem cannot be approximated\nwithin a factor of $\\rho(k)$ in $f(k) \\cdot n^{O(1)}$ time, unless FPT = W[P],\neven for restricted thresholds (namely constant and majority thresholds). We\nalso study the cardinality constraint maximization and minimization versions of\nthe problem for which we prove similar hardness results."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-5468/2015/04/P04002", 
    "link": "http://arxiv.org/pdf/1403.4010v2", 
    "title": "Organization mechanism and counting algorithm on Vertex-Cover solutions", 
    "arxiv-id": "1403.4010v2", 
    "author": "Zhiming Zheng", 
    "publish": "2014-03-17T06:44:35Z", 
    "summary": "Counting the solution number of combinational optimization problems is an\nimportant topic in the study of computational complexity, especially on the\n#P-complete complexity class. In this paper, we first investigate some\norganizations of Vertex-Cover unfrozen subgraphs by the underlying connectivity\nand connected components of unfrozen vertices. Then, a Vertex-Cover Solution\nNumber Counting Algorithm is proposed and its complexity analysis is provided,\nthe results of which fit very well with the simulations and have better\nperformance than those by 1-RSB in a neighborhood of c = e for random graphs.\nBase on the algorithm, variation and fluctuation on the solution number\nstatistics are studied to reveal the evolution mechanism of the solution\nnumbers. Besides, marginal probability distributions on the solution space are\ninvestigated on both random graph and scale-free graph to illustrate different\nevolution characteristics of their solution spaces. Thus, doing solution number\ncounting based on graph expression of solution space should be an alternative\nand meaningful way to study the hardness of NP-complete and #P-complete\nproblems, and appropriate algorithm design can help to achieve better\napproximations of solving combinational optimization problems and the\ncorresponding counting problems."
},{
    "category": "cs.CC", 
    "doi": "10.1088/1742-5468/2015/04/P04002", 
    "link": "http://arxiv.org/pdf/1403.4143v6", 
    "title": "P is not equal to NP by Modus Tollens", 
    "arxiv-id": "1403.4143v6", 
    "author": "Joonmo Kim", 
    "publish": "2014-03-17T15:59:32Z", 
    "summary": "An artificially designed Turing Machine algorithm $\\mathbf{M}_{}^{o}$\ngenerates the instances of the satisfiability problem, and check their\nsatisfiability. Under the assumption $\\mathcal{P}=\\mathcal{NP}$, we show that\n$\\mathbf{M}_{}^{o}$ has a certain property, which, without the assumption,\n$\\mathbf{M}_{}^{o}$ does not have. This leads to $\\mathcal{P}\\neq\\mathcal{NP}$\n$ $ by modus tollens."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1403.4539v2", 
    "title": "Occam Bound on Lowest Complexity of Elements", 
    "arxiv-id": "1403.4539v2", 
    "author": "Leonid A. Levin", 
    "publish": "2014-02-27T18:56:40Z", 
    "summary": "The combined universal probability M(D) of strings x in sets D is close to\nmax_{x \\in D} M({x}): their ~ logs differ by at most D's information j = I(D:H)\nabout the halting sequence H. Thus if all x have complexity K(x) > k, D carries\n> i bits of information on each x where i+j ~ k. Note, there are no ways\n(whether natural or artificial) to generate D with significant I(D:H)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1403.5830v1", 
    "title": "Bejeweled, Candy Crush and other Match-Three Games are (NP-)Hard", 
    "arxiv-id": "1403.5830v1", 
    "author": "Emanuele Natale", 
    "publish": "2014-03-24T01:51:19Z", 
    "summary": "The twentieth century has seen the rise of a new type of video games targeted\nat a mass audience of \"casual\" gamers. Many of these games require the player\nto swap items in order to form matches of three and are collectively known as\n\\emph{tile-matching match-three games}. Among these, the most influential one\nis arguably \\emph{Bejeweled} in which the matched items (gems) pop and the\nabove gems fall in their place. Bejeweled has been ported to many different\nplatforms and influenced an incredible number of similar games. Very recently\none of them, named \\emph{Candy Crush Saga} enjoyed a huge popularity and\nquickly went viral on social networks. We generalize this kind of games by only\nparameterizing the size of the board, while all the other elements (such as the\nrules or the number of gems) remain unchanged. Then, we prove that answering\nmany natural questions regarding such games is actually \\NP-Hard. These\nquestions include determining if the player can reach a certain score, play for\na certain number of turns, and others. We also\n\\href{http://candycrush.isnphard.com}{provide} a playable web-based\nimplementation of our reduction."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1403.6518v1", 
    "title": "Havannah and TwixT are PSPACE-complete", 
    "arxiv-id": "1403.6518v1", 
    "author": "Abdallah Saffidine", 
    "publish": "2014-03-25T21:55:25Z", 
    "summary": "Numerous popular abstract strategy games ranging from Hex and Havannah to\nLines of Action belong to the class of connection games. Still, very few\ncomplexity results on such games have been obtained since Hex was proved\nPSPACE-complete in the early eighties. We study the complexity of two\nconnection games among the most widely played. Namely, we prove that Havannah\nand TwixT are PSPACE-complete. The proof for Havannah involves a reduction from\nGeneralized Geography and is based solely on ring-threats to represent the\ninput graph. On the other hand, the reduction for TwixT builds up on previous\nwork as it is a straightforward encoding of Hex."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1405.7028v1", 
    "title": "Pseudorandomness and Fourier Growth Bounds for Width 3 Branching   Programs", 
    "arxiv-id": "1405.7028v1", 
    "author": "Andrew Wan", 
    "publish": "2014-05-27T19:42:29Z", 
    "summary": "We present an explicit pseudorandom generator for oblivious, read-once,\nwidth-$3$ branching programs, which can read their input bits in any order. The\ngenerator has seed length $\\tilde{O}( \\log^3 n ).$ The previously best known\nseed length for this model is $n^{1/2+o(1)}$ due to Impagliazzo, Meka, and\nZuckerman (FOCS '12). Our work generalizes a recent result of Reingold,\nSteinke, and Vadhan (RANDOM '13) for \\textit{permutation} branching programs.\nThe main technical novelty underlying our generator is a new bound on the\nFourier growth of width-3, oblivious, read-once branching programs.\nSpecifically, we show that for any $f:\\{0,1\\}^n\\rightarrow \\{0,1\\}$ computed by\nsuch a branching program, and $k\\in [n],$ $$\\sum_{s\\subseteq [n]: |s|=k} \\left|\n\\hat{f}[s] \\right| \\leq n^2 \\cdot (O(\\log n))^k,$$ where $\\widehat{f}[s] =\n\\mathbb{E}\\left[f[U] \\cdot (-1)^{s \\cdot U}\\right]$ is the standard Fourier\ntransform over $\\mathbb{Z}_2^n$. The base $O(\\log n)$ of the Fourier growth is\ntight up to a factor of $\\log \\log n$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1405.7596v1", 
    "title": "On total communication complexity of collapsing protocols for pointer   jumping problem", 
    "arxiv-id": "1405.7596v1", 
    "author": "Micha\u0142 Jastrz\u0119bski", 
    "publish": "2014-05-29T15:57:36Z", 
    "summary": "This paper focuses on bounding the total communication complexity of\ncollapsing protocols for multiparty pointer jumping problem ($MPJ_k^n$). Brody\nand Chakrabati in \\cite{bc08} proved that in such setting one of the players\nmust communicate at least $n - 0.5\\log{n}$ bits. Liang in \\cite{liang} has\nshown protocol matching this lower bound on maximum complexity. His protocol,\nhowever, was behaving worse than the trivial one in terms of total complexity\n(number of bits sent by all players). He conjectured that achieving total\ncomplexity better then the trivial one is impossible. In this paper we prove\nthis conjecture. Namely, we show that for a collapsing protocol for $MPJ_k^n$,\nthe total communication complexity is at least $n-2$ which closes the gap\nbetween lower and upper bound for total complexity of $MPJ_k^n$ in collapsing\nsetting."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1405.7849v1", 
    "title": "Very narrow quantum OBDDs and width hierarchies for classical OBDDs", 
    "arxiv-id": "1405.7849v1", 
    "author": "Abuzer Yakarylmaz", 
    "publish": "2014-05-30T13:05:28Z", 
    "summary": "We present several results on comparative complexity for different variants\nof OBDD models.\n  - We present some results on comparative complexity of classical and quantum\nOBDDs. We consider a partial function depending on parameter k such that for\nany k > 0 this function is computed by an exact quantum OBDD of width 2 but any\nclassical OBDD (deterministic or stable bounded error probabilistic) needs\nwidth 2k+1.\n  - We consider quantum and classical nondeterminism. We show that quantum\nnondeterminism can be more efficient than classical one. In particular, an\nexplicit function is presented which is computed by a quantum nondeterministic\nOBDD with constant width but any classical nondeterministic OBDD for this\nfunction needs non-constant width.\n  - We also present new hierarchies on widths of deterministic and\nnon-deterministic OBDDs. We focus both on small and large widths."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1407.1889v2", 
    "title": "The Polyhedron-Hitting Problem", 
    "arxiv-id": "1407.1889v2", 
    "author": "James Worrell", 
    "publish": "2014-07-07T21:21:56Z", 
    "summary": "We consider polyhedral versions of Kannan and Lipton's Orbit Problem (STOC\n'80 and JACM '86)---determining whether a target polyhedron V may be reached\nfrom a starting point x under repeated applications of a linear transformation\nA in an ambient vector space Q^m. In the context of program verification, very\nsimilar reachability questions were also considered and left open by Lee and\nYannakakis in (STOC '92). We present what amounts to a complete\ncharacterisation of the decidability landscape for the Polyhedron-Hitting\nProblem, expressed as a function of the dimension m of the ambient space,\ntogether with the dimension of the polyhedral target V: more precisely, for\neach pair of dimensions, we either establish decidability, or show hardness for\nlongstanding number-theoretic open problems."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1407.1891v2", 
    "title": "On Termination of Integer Linear Loops", 
    "arxiv-id": "1407.1891v2", 
    "author": "James Worrell", 
    "publish": "2014-07-07T21:29:28Z", 
    "summary": "A fundamental problem in program verification concerns the termination of\nsimple linear loops of the form x := u ; while Bx >= b do {x := Ax + a} where x\nis a vector of variables, u, a, and c are integer vectors, and A and B are\ninteger matrices. Assuming the matrix A is diagonalisable, we give a decision\nprocedure for the problem of whether, for all initial integer vectors u, such a\nloop terminates. The correctness of our algorithm relies on sophisticated tools\nfrom algebraic and analytic number theory, Diophantine geometry, and real\nalgebraic geometry. To the best of our knowledge, this is the first substantial\nadvance on a 10-year-old open problem of Tiwari (2004) and Braverman (2006)."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1407.3500v1", 
    "title": "Sub-linear Upper Bounds on Fourier dimension of Boolean Functions in   terms of Fourier sparsity", 
    "arxiv-id": "1407.3500v1", 
    "author": "Swagato Sanyal", 
    "publish": "2014-07-13T19:05:53Z", 
    "summary": "We prove that the Fourier dimension of any Boolean function with Fourier\nsparsity $s$ is at most $O\\left(s^{2/3}\\right)$. Our proof method yields an\nimproved bound of $\\widetilde{O}(\\sqrt{s})$ assuming a conjecture of\nTsang~\\etal~\\cite{tsang}, that for every Boolean function of sparsity $s$ there\nis an affine subspace of $\\mathbb{F}_2^n$ of co-dimension $O(\\poly\\log s)$\nrestricted to which the function is constant. This conjectured bound is tight\nupto poly-logarithmic factors as the Fourier dimension and sparsity of the\naddress function are quadratically separated. We obtain these bounds by\nobserving that the Fourier dimension of a Boolean function is equivalent to its\nnon-adaptive parity decision tree complexity, and then bounding the latter."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1407.4626v1", 
    "title": "On relative OR-complexity of Boolean matrices and their complements", 
    "arxiv-id": "1407.4626v1", 
    "author": "Igor S. Sergeev", 
    "publish": "2014-07-17T10:47:10Z", 
    "summary": "We construct explicit Boolean square matrices whose rectifier complexity\n(OR-complexity) differs significantly from the complexity of their complement\nmatrices."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1407.4972v1", 
    "title": "Into the Square - On the Complexity of Quadratic-Time Solvable Problems", 
    "arxiv-id": "1407.4972v1", 
    "author": "Michel Habib", 
    "publish": "2014-07-18T12:39:18Z", 
    "summary": "This paper will analyze several quadratic-time solvable problems, and will\nclassify them into two classes: problems that are solvable in truly\nsubquadratic time (that is, in time $O(n^{2-\\epsilon})$ for some $\\epsilon>0$)\nand problems that are not, unless the well known Strong Exponential Time\nHypothesis (SETH) is false. In particular, we will prove that some\nquadratic-time solvable problems are indeed easier than expected. We will\nprovide an algorithm that computes the transitive closure of a directed graph\nin time $O(mn^{\\frac{\\omega+1}{4}})$, where $m$ denotes the number of edges in\nthe transitive closure and $\\omega$ is the exponent for matrix multiplication.\nAs a side effect, we will prove that our algorithm runs in time\n$O(n^{\\frac{5}{3}})$ if the transitive closure is sparse. The same time bounds\nhold if we want to check whether a graph is transitive, by replacing m with the\nnumber of edges in the graph itself. As far as we know, this is the fastest\nalgorithm for sparse transitive digraph recognition. Finally, we will apply our\nalgorithm to the comparability graph recognition problem (dating back to 1941),\nobtaining the first truly subquadratic algorithm. The second part of the paper\ndeals with hardness results. Starting from an artificial quadratic-time\nsolvable variation of the k-SAT problem, we will construct a graph of Karp\nreductions, proving that a truly subquadratic-time algorithm for any of the\nproblems in the graph falsifies SETH. The analyzed problems are the following:\ncomputing the subset graph, finding dominating sets, computing the betweenness\ncentrality of a vertex, computing the minimum closeness centrality, and\ncomputing the hyperbolicity of a pair of vertices. We will also be able to\ninclude in our framework three proofs already appeared in the literature,\nconcerning the graph diameter computation, local alignment of strings and\northogonality of vectors."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.apal.2014.01.006", 
    "link": "http://arxiv.org/pdf/1407.6169v2", 
    "title": "Multiplicative Complexity of Vector Valued Boolean Functions", 
    "arxiv-id": "1407.6169v2", 
    "author": "Joan Boyar", 
    "publish": "2014-07-23T10:52:32Z", 
    "summary": "We consider the multiplicative complexity of Boolean functions with multiple\nbits of output, studying how large a multiplicative complexity is necessary and\nsufficient to provide a desired nonlinearity. For so-called $\\Sigma\\Pi\\Sigma$\ncircuits, we show that there is a tight connection between error correcting\ncodes and circuits computing functions with high nonlinearity. Combining this\nwith known coding theory results, we show that functions with $n$ inputs and\n$n$ outputs with the highest possible nonlinearity must have at least $2.32n$\nAND gates. We further show that one cannot prove stronger lower bounds by only\nappealing to the nonlinearity of a function; we show a bilinear circuit\ncomputing a function with almost optimal nonlinearity with the number of AND\ngates being exactly the length of such a shortest code.\n  Additionally we provide a function which, for general circuits, has\nmultiplicative complexity at least $2n-3$.\n  Finally we study the multiplicative complexity of \"almost all'' functions. We\nshow that every function with $n$ bits of input and $m$ bits of output can be\ncomputed using at most $2.5(1+o(1))\\sqrt{m2^n}$ AND gates."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1407.7799v4", 
    "title": "Counting $4\\times 4$ Matrix Partitions of Graphs", 
    "arxiv-id": "1407.7799v4", 
    "author": "David Richerby", 
    "publish": "2014-07-29T17:54:05Z", 
    "summary": "Given a symmetric matrix $M\\in \\{0,1,*\\}^{D\\times D}$, an $M$-partition of a\ngraph $G$ is a function from $V(G)$ to $D$ such that no edge of $G$ is mapped\nto a $0$ of $M$ and no non-edge to a $1$. We give a computer-assisted proof\nthat, when $|D|=4$, the problem of counting the $M$-partitions of an input\ngraph is either in FP or is #P-complete. Tractability is proved by reduction to\nthe related problem of counting list $M$-partitions; intractability is shown\nusing a gadget construction and interpolation. We use a computer program to\ndetermine which of the two cases holds for all but a small number of matrices,\nwhich we resolve manually to establish the dichotomy. We conjecture that the\ndichotomy also holds for $|D|>4$. More specifically, we conjecture that, for\nany symmetric matrix $M\\in\\{0,1,*\\}^{D\\times D}$, the complexity of counting\n$M$-partitions is the same as the related problem of counting list\n$M$-partitions."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.1318v2", 
    "title": "Constructive Relationships Between Algebraic Thickness and Normality", 
    "arxiv-id": "1410.1318v2", 
    "author": "Magnus Gausdal Find", 
    "publish": "2014-10-06T11:07:53Z", 
    "summary": "We study the relationship between two measures of Boolean functions;\n\\emph{algebraic thickness} and \\emph{normality}. For a function $f$, the\nalgebraic thickness is a variant of the \\emph{sparsity}, the number of nonzero\ncoefficients in the unique GF(2) polynomial representing $f$, and the normality\nis the largest dimension of an affine subspace on which $f$ is constant. We\nshow that for $0 < \\epsilon<2$, any function with algebraic thickness\n$n^{3-\\epsilon}$ is constant on some affine subspace of dimension\n$\\Omega\\left(n^{\\frac{\\epsilon}{2}}\\right)$. Furthermore, we give an algorithm\nfor finding such a subspace. We show that this is at most a factor of\n$\\Theta(\\sqrt{n})$ from the best guaranteed, and when restricted to the\ntechnique used, is at most a factor of $\\Theta(\\sqrt{\\log n})$ from the best\nguaranteed. We also show that a concrete function, majority, has algebraic\nthickness $\\Omega\\left(2^{n^{1/6}}\\right)$."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.2456v1", 
    "title": "On Circuit Complexity of Parity and Majority Functions in Antichain   Basis", 
    "arxiv-id": "1410.2456v1", 
    "author": "Olga Podolskaya", 
    "publish": "2014-10-09T13:43:30Z", 
    "summary": "We study the circuit complexity of boolean functions in a certain infinite\nbasis. The basis consists of all functions that take value $1$ on antichains\nover the boolean cube. We prove that the circuit complexity of the parity\nfunction and the majority function of $n$ variables in this basis is $\\lfloor\n\\frac{n+1}{2} \\rfloor$ and $\\left\\lfloor \\frac{n}{2} \\right \\rfloor +1$\nrespectively. We show that the asymptotic of the maximum complexity of\n$n$-variable boolean functions in this basis equals $n.$"
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.4135v1", 
    "title": "Mutual Dimension", 
    "arxiv-id": "1410.4135v1", 
    "author": "Jack H. Lutz", 
    "publish": "2014-10-15T16:57:38Z", 
    "summary": "We define the lower and upper mutual dimensions $mdim(x:y)$ and $Mdim(x:y)$\nbetween any two points $x$ and $y$ in Euclidean space. Intuitively these are\nthe lower and upper densities of the algorithmic information shared by $x$ and\n$y$. We show that these quantities satisfy the main desiderata for a\nsatisfactory measure of mutual algorithmic information. Our main theorem, the\ndata processing inequality for mutual dimension, says that, if $f:\\mathbb{R}^m\n\\rightarrow \\mathbb{R}^n$ is computable and Lipschitz, then the inequalities\n$mdim(f(x):y) \\leq mdim(x:y)$ and $Mdim(f(x):y) \\leq Mdim(x:y)$ hold for all $x\n\\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^t$. We use this inequality and related\ninequalities that we prove in like fashion to establish conditions under which\nvarious classes of computable functions on Euclidean space preserve or\notherwise transform mutual dimensions between points."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.5169v2", 
    "title": "Hardness of Peeling with Stashes", 
    "arxiv-id": "1410.5169v2", 
    "author": "Vikram Nathan", 
    "publish": "2014-10-20T07:29:19Z", 
    "summary": "The analysis of several algorithms and data structures can be framed as a\npeeling process on a random hypergraph: vertices with degree less than k and\ntheir adjacent edges are removed until no vertices of degree less than k are\nleft. Often the question is whether the remaining hypergraph, the k-core, is\nempty or not. In some settings, it may be possible to remove either vertices or\nedges from the hypergraph before peeling, at some cost. For example, in hashing\napplications where keys correspond to edges and buckets to vertices, one might\nuse an additional side data structure, commonly referred to as a stash, to\nseparately handle some keys in order to avoid collisions. The natural question\nin such cases is to find the minimum number of edges (or vertices) that need to\nbe stashed in order to realize an empty k-core. We show that both these\nproblems are NP-complete for all $k \\geq 2$ on graphs and regular hypergraphs,\nwith the sole exception being that the edge variant of stashing is solvable in\npolynomial time for $k = 2$ on standard (2-uniform) graphs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.5369v3", 
    "title": "Proof Complexity Modulo the Polynomial Hierarchy: Understanding   Alternation as a Source of Hardness", 
    "arxiv-id": "1410.5369v3", 
    "author": "Hubie Chen", 
    "publish": "2014-10-20T17:43:24Z", 
    "summary": "We present and study a framework in which one can present alternation-based\nlower bounds on proof length in proof systems for quantified Boolean formulas.\nA key notion in this framework is that of proof system ensemble, which is\n(essentially) a sequence of proof systems where, for each, proof checking can\nbe performed in the polynomial hierarchy. We introduce a proof system ensemble\ncalled relaxing QU-res which is based on the established proof system\nQU-resolution. Our main results include an exponential separation of the\ntree-like and general versions of relaxing QU-res, and an exponential lower\nbound for relaxing QU-res; these are analogs of classical results in\npropositional proof complexity."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.5845v1", 
    "title": "Zig-Zag Numberlink is NP-Complete", 
    "arxiv-id": "1410.5845v1", 
    "author": "Blair D. Sullivan", 
    "publish": "2014-10-21T20:27:20Z", 
    "summary": "When can $t$ terminal pairs in an $m \\times n$ grid be connected by $t$\nvertex-disjoint paths that cover all vertices of the grid? We prove that this\nproblem is NP-complete. Our hardness result can be compared to two previous\nNP-hardness proofs: Lynch's 1975 proof without the ``cover all vertices''\nconstraint, and Kotsuma and Takenaga's 2010 proof when the paths are restricted\nto have the fewest possible corners within their homotopy class. The latter\nrestriction is a common form of the famous Nikoli puzzle \\emph{Numberlink}; our\nproblem is another common form of Numberlink, sometimes called \\emph{Zig-Zag\nNumberlink} and popularized by the smartphone app \\emph{Flow Free}."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.6396v2", 
    "title": "Permutation Reconstruction from Differences", 
    "arxiv-id": "1410.6396v2", 
    "author": "Marzio De Biasi", 
    "publish": "2014-10-23T15:28:42Z", 
    "summary": "We prove that the problem of reconstructing a permutation\n$\\pi_1,\\dotsc,\\pi_n$ of the integers $[1\\dotso n]$ given the absolute\ndifferences $|\\pi_{i+1}-\\pi_i|$, $i = 1,\\dotsc,n-1$ is NP-complete. As an\nintermediate step we first prove the NP-completeness of the decision version of\na new puzzle game that we call Crazy Frog Puzzle. The permutation\nreconstruction from differences is one of the simplest combinatorial problems\nthat have been proved to be computationally intractable."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.6663v1", 
    "title": "Computing an Evolutionary Ordering is Hard", 
    "arxiv-id": "1410.6663v1", 
    "author": "Blerina Sinaimeri", 
    "publish": "2014-10-24T12:39:08Z", 
    "summary": "We prove that computing an evolutionary ordering of a family of sets, i.e. an\nordering where each set intersects with --but is not included in-- the union\nearlier sets, is NP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.dam.2016.05.001", 
    "link": "http://arxiv.org/pdf/1410.7253v1", 
    "title": "Deterministic Extractors for Additive Sources", 
    "arxiv-id": "1410.7253v1", 
    "author": "David Zuckerman", 
    "publish": "2014-10-27T14:29:33Z", 
    "summary": "We propose a new model of a weakly random source that admits randomness\nextraction. Our model of additive sources includes such natural sources as\nuniform distributions on arithmetic progressions (APs), generalized arithmetic\nprogressions (GAPs), and Bohr sets, each of which generalizes affine sources.\nWe give an explicit extractor for additive sources with linear min-entropy over\nboth $\\mathbb{Z}_p$ and $\\mathbb{Z}_p^n$, for large prime $p$, although our\nresults over $\\mathbb{Z}_p^n$ require that the source further satisfy a\nlist-decodability condition. As a corollary, we obtain explicit extractors for\nAPs, GAPs, and Bohr sources with linear min-entropy, although again our results\nover $\\mathbb{Z}_p^n$ require the list-decodability condition. We further\nexplore special cases of additive sources. We improve previous constructions of\nline sources (affine sources of dimension 1), requiring a field of size linear\nin $n$, rather than $\\Omega(n^2)$ by Gabizon and Raz. This beats the\nnon-explicit bound of $\\Theta(n \\log n)$ obtained by the probabilistic method.\nWe then generalize this result to APs and GAPs."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.laa.2016.04.027", 
    "link": "http://arxiv.org/pdf/1410.8202v2", 
    "title": "Binary Determinantal Complexity", 
    "arxiv-id": "1410.8202v2", 
    "author": "Christian Ikenmeyer", 
    "publish": "2014-10-29T23:57:38Z", 
    "summary": "We prove that for writing the 3 by 3 permanent polynomial as a determinant of\na matrix consisting only of zeros, ones, and variables as entries, a 7 by 7\nmatrix is required. Our proof is computer based and uses the enumeration of\nbipartite graphs. Furthermore, we analyze sequences of polynomials that are\ndeterminants of polynomially sized matrices consisting only of zeros, ones, and\nvariables. We show that these are exactly the sequences in the complexity class\nof constant free polynomially sized (weakly) skew circuits."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.laa.2016.04.027", 
    "link": "http://arxiv.org/pdf/1410.8816v5", 
    "title": "Affine reductions for LPs and SDPs", 
    "arxiv-id": "1410.8816v5", 
    "author": "Daniel Zink", 
    "publish": "2014-10-31T17:12:00Z", 
    "summary": "We define a reduction mechanism for LP and SDP formulations that degrades\napproximation factors in a controlled fashion. Our reduction mechanism is a\nminor restriction of classical reductions establishing inapproximability in the\ncontext of PCP theorems. As a consequence we establish strong linear\nprogramming inapproximability (for LPs with a polynomial number of constraints)\nfor many problems. In particular we obtain a $3/2-\\varepsilon$\ninapproximability for VertexCover answering an open question in\n[arXiv:1309.0563] and we answer a weak version of our sparse graph conjecture\nposed in [arXiv:1311.4001] showing an inapproximability factor of\n$1/2+\\varepsilon$ for bounded degree IndependentSet. In the case of SDPs, we\nobtain inapproximability results for these problems relative to the\nSDP-inapproximability of MaxCUT. Moreover, using our reduction framework we are\nable to reproduce various results for CSPs from [arXiv:1309.0563] via simple\nreductions from Max-2-XOR."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.laa.2016.04.027", 
    "link": "http://arxiv.org/pdf/1411.0821v1", 
    "title": "NP-hardness of hypercube 2-segmentation", 
    "arxiv-id": "1411.0821v1", 
    "author": "Uriel Feige", 
    "publish": "2014-11-04T08:08:17Z", 
    "summary": "The hypercube 2-segmentation problem is a certain biclustering problem that\nwas previously claimed to be NP-hard, but for which there does not appear to be\na publicly available proof of NP-hardness. This manuscript provides such a\nproof."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.laa.2016.04.027", 
    "link": "http://arxiv.org/pdf/1411.1995v3", 
    "title": "A Strongly Exponential Separation of DNNFs from CNF Formulas", 
    "arxiv-id": "1411.1995v3", 
    "author": "Friedrich Slivovsky", 
    "publish": "2014-11-07T17:43:33Z", 
    "summary": "Decomposable Negation Normal Forms (DNNFs) are Boolean circuits in negation\nnormal form where the subcircuits leading into each AND gate are defined on\ndisjoint sets of variables. We prove a strongly exponential lower bound on the\nsize of DNNFs for a class of CNF formulas built from expander graphs. As a\ncorollary, we obtain a strongly exponential separation between DNNFs and CNF\nformulas in prime implicates form. This settles an open problem in the area of\nknowledge compilation (Darwiche and Marquis, 2002)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.2286v1", 
    "title": "On Characterizing the Data Access Complexity of Programs", 
    "arxiv-id": "1411.2286v1", 
    "author": "P. Sadayappan", 
    "publish": "2014-11-09T21:40:41Z", 
    "summary": "Technology trends will cause data movement to account for the majority of\nenergy expenditure and execution time on emerging computers. Therefore,\ncomputational complexity will no longer be a sufficient metric for comparing\nalgorithms, and a fundamental characterization of data access complexity will\nbe increasingly important. The problem of developing lower bounds for data\naccess complexity has been modeled using the formalism of Hong & Kung's\nred/blue pebble game for computational directed acyclic graphs (CDAGs).\nHowever, previously developed approaches to lower bounds analysis for the\nred/blue pebble game are very limited in effectiveness when applied to CDAGs of\nreal programs, with computations comprised of multiple sub-computations with\ndiffering DAG structure. We address this problem by developing an approach for\neffectively composing lower bounds based on graph decomposition. We also\ndevelop a static analysis algorithm to derive the asymptotic data-access lower\nbounds of programs, as a function of the problem size and cache size."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.3010v1", 
    "title": "Computational Complexity of Functions", 
    "arxiv-id": "1411.3010v1", 
    "author": "Leonid A. Levin", 
    "publish": "2014-11-11T22:50:51Z", 
    "summary": "Below is a translation from my Russian paper. I added references, unavailable\nto me in Moscow. Similar results have been also given in [Schnorr Stumpf 75]\n(see also [Lynch 75]). Earlier relevant work (classical theorems like\nCompression, Speed-up, etc.) was done in [Tseitin 56, Rabin 59, Hartmanis\nStearns 65, Blum 67, Trakhtenbrot 67, Meyer Fischer 72].\n  I translated only the part with the statement of the results. Instead of the\nproof part I appended a later (1979, unpublished) proof sketch of a slightly\ntighter version. The improvement is based on the results of [Meyer Winklmann\n78, Sipser 78]. Meyer and Winklmann extended earlier versions to machines with\na separate input and working tape, thus allowing complexities smaller than the\ninput length (down to its log). Sipser showed the space-bounded Halting Problem\nto require only additive constant overhead. The proof in the appendix below\nemploys both advances to extend the original proofs to machines with a fixed\nalphabet and a separate input and working space. The extension has no (even\nlogarithmic) restrictions on complexity and no overhead (beyond an additive\nconstant). The sketch is very brief and a more detailed exposition is expected\nlater: [Seiferas Meyer]."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.3419v1", 
    "title": "Tighter Relations Between Sensitivity and Other Complexity Measures", 
    "arxiv-id": "1411.3419v1", 
    "author": "Song Zuo", 
    "publish": "2014-11-13T02:25:53Z", 
    "summary": "Sensitivity conjecture is a longstanding and fundamental open problem in the\narea of complexity measures of Boolean functions and decision tree complexity.\nThe conjecture postulates that the maximum sensitivity of a Boolean function is\npolynomially related to other major complexity measures. Despite much attention\nto the problem and major advances in analysis of Boolean functions in the past\ndecade, the problem remains wide open with no positive result toward the\nconjecture since the work of Kenyon and Kutin from 2004.\n  In this work, we present new upper bounds for various complexity measures in\nterms of sensitivity improving the bounds provided by Kenyon and Kutin.\nSpecifically, we show that deg(f)^{1-o(1)}=O(2^{s(f)}) and C(f) < 2^{s(f)-1}\ns(f); these in turn imply various corollaries regarding the relation between\nsensitivity and other complexity measures, such as block sensitivity, via known\nresults. The gap between sensitivity and other complexity measures remains\nexponential but these results are the first improvement for this difficult\nproblem that has been achieved in a decade."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.3517v2", 
    "title": "Derandomized Graph Product Results using the Low Degree Long Code", 
    "arxiv-id": "1411.3517v2", 
    "author": "Girish Varma", 
    "publish": "2014-11-13T12:21:55Z", 
    "summary": "In this paper, we address the question of whether the recent derandomization\nresults obtained by the use of the low-degree long code can be extended to\nother product settings. We consider two settings: (1) the graph product results\nof Alon, Dinur, Friedgut and Sudakov [GAFA, 2004] and (2) the \"majority is\nstablest\" type of result obtained by Dinur, Mossel and Regev [SICOMP, 2009] and\nDinur and Shinkar [In Proc. APPROX, 2010] while studying the hardness of\napproximate graph coloring.\n  In our first result, we show that there exists a considerably smaller\nsubgraph of $K_3^{\\otimes R}$ which exhibits the following property (shown for\n$K_3^{\\otimes R}$ by Alon et al.): independent sets close in size to the\nmaximum independent set are well approximated by dictators.\n  The \"majority is stablest\" type of result of Dinur et al. and Dinur and\nShinkar shows that if there exist two sets of vertices $A$ and $B$ in\n$K_3^{\\otimes R}$ with very few edges with one endpoint in $A$ and another in\n$B$, then it must be the case that the two sets $A$ and $B$ share a single\ninfluential coordinate. In our second result, we show that a similar \"majority\nis stablest\" statement holds good for a considerably smaller subgraph of\n$K_3^{\\otimes R}$. Furthermore using this result, we give a more efficient\nreduction from Unique Games to the graph coloring problem, leading to improved\nhardness of approximation results for coloring."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.4584v1", 
    "title": "Pseudorandomness for concentration bounds and signed majorities", 
    "arxiv-id": "1411.4584v1", 
    "author": "Raghu Meka", 
    "publish": "2014-11-17T18:42:56Z", 
    "summary": "The problem of constructing pseudorandom generators that fool halfspaces has\nbeen studied intensively in recent times. For fooling halfspaces over the\nhypercube with polynomially small error, the best construction known requires\nseed-length O(log^2 n) (MekaZ13). Getting the seed-length down to O(log(n)) is\na natural challenge in its own right, which needs to be overcome in order to\nderandomize RL. In this work we make progress towards this goal by obtaining\nnear-optimal generators for two important special cases:\n  1) We give a near optimal derandomization of the Chernoff bound for\nindependent, uniformly random bits. Specifically, we show how to generate a x\nin {1,-1}^n using $\\tilde{O}(\\log (n/\\epsilon))$ random bits such that for any\nunit vector u, <u,x> matches the sub-Gaussian tail behaviour predicted by the\nChernoff bound up to error eps.\n  2) We construct a generator which fools halfspaces with {0,1,-1} coefficients\nwith error eps with a seed-length of $\\tilde{O}(\\log(n/\\epsilon))$. This\nincludes the important special case of majorities.\n  In both cases, the best previous results required seed-length of $O(\\log n +\n\\log^2(1/\\epsilon))$.\n  Technically, our work combines new Fourier-analytic tools with the iterative\ndimension reduction techniques and the gradually increasing independence\nparadigm of previous works (KaneMN11, CelisRSW13, GopalanMRTV12)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.5765v1", 
    "title": "TrackMania is NP-complete", 
    "arxiv-id": "1411.5765v1", 
    "author": "Franck Dernoncourt", 
    "publish": "2014-11-21T04:08:28Z", 
    "summary": "We prove that completing an untimed, unbounded track in TrackMania Nations\nForever is NP-complete by using a reduction from 3-SAT and showing that a\nsolution can be checked in polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.5951v1", 
    "title": "PSPACE-completeness of Bloxorz and of Games with 2-Buttons", 
    "arxiv-id": "1411.5951v1", 
    "author": "Hans L. Bodlaender", 
    "publish": "2014-11-21T16:46:40Z", 
    "summary": "Bloxorz is an online puzzle game where players move a 1 by 1 by 2 block by\ntilting it on a subset of the two dimensional grid. Bloxorz features switches\nthat open and close trapdoors. The puzzle is to move the block from its initial\nposition to an upright position on the destination square. We show that the\nproblem of deciding whether a given Bloxorz level is solvable is\nPSPACE-complete and that this remains so even when all trapdoors are initially\nclosed or all trapdoors are initially open. We also answer an open question of\nViglietta, showing that 2-buttons are sufficient for PSPACE-hardness of general\npuzzle games. We also examine the hardness of some variants of Bloxorz,\nincluding variants where the block is a 1 by 1 by 1 cube, and variants with\nsingle-use tiles."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.6299v2", 
    "title": "Almost Optimal Pseudorandom Generators for Spherical Caps", 
    "arxiv-id": "1411.6299v2", 
    "author": "Raghu Meka", 
    "publish": "2014-11-23T21:19:14Z", 
    "summary": "Halfspaces or linear threshold functions are widely studied in complexity\ntheory, learning theory and algorithm design. In this work we study the natural\nproblem of constructing pseudorandom generators (PRGs) for halfspaces over the\nsphere, aka spherical caps, which besides being interesting and basic geometric\nobjects, also arise frequently in the analysis of various randomized algorithms\n(e.g., randomized rounding). We give an explicit PRG which fools spherical caps\nwithin error $\\epsilon$ and has an almost optimal seed-length of $O(\\log n +\n\\log(1/\\epsilon) \\cdot \\log\\log(1/\\epsilon))$. For an inverse-polynomially\ngrowing error $\\epsilon$, our generator has a seed-length optimal up to a\nfactor of $O( \\log \\log {(n)})$. The most efficient PRG previously known (due\nto Kane, 2012) requires a seed-length of $\\Omega(\\log^{3/2}{(n)})$ in this\nsetting. We also obtain similar constructions to fool halfspaces with respect\nto the Gaussian distribution.\n  Our construction and analysis are significantly different from previous works\non PRGs for halfspaces and build on the iterative dimension reduction ideas of\nKane et. al. (2011) and Celis et. al. (2013), the \\emph{classical moment\nproblem} from probability theory and explicit constructions of \\emph{orthogonal\ndesigns} based on the seminal work of Bourgain and Gamburd (2011) on expansion\nin Lie groups."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.6549v2", 
    "title": "Complexity of Secure Sets", 
    "arxiv-id": "1411.6549v2", 
    "author": "Stefan Woltran", 
    "publish": "2014-11-24T17:55:05Z", 
    "summary": "A secure set $S$ in a graph is defined as a set of vertices such that for any\n$X\\subseteq S$ the majority of vertices in the neighborhood of $X$ belongs to\n$S$. It is known that deciding whether a set $S$ is secure in a graph is\nco-NP-complete. However, it is still open how this result contributes to the\nactual complexity of deciding whether for a given graph $G$ and integer $k$, a\nnon-empty secure set for $G$ of size at most $k$ exists. In this work, we\npinpoint the complexity of this problem by showing that it is\n$\\Sigma^P_2$-complete. Furthermore, the problem has so far not been subject to\na parameterized complexity analysis that considers structural parameters. In\nthe present work, we prove that the problem is $W[1]$-hard when parameterized\nby treewidth. This is surprising since the problem is known to be FPT when\nparameterized by solution size and \"subset problems\" that satisfy this property\nusually tend to be FPT for bounded treewidth as well. Finally, we give an upper\nbound by showing membership in XP, and we provide a positive result in the form\nof an FPT algorithm for checking whether a given set is secure on graphs of\nbounded treewidth."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.6829v3", 
    "title": "Approximately counting locally-optimal structures", 
    "arxiv-id": "1411.6829v3", 
    "author": "John Lapinskas", 
    "publish": "2014-11-25T12:12:31Z", 
    "summary": "A locally-optimal structure is a combinatorial structure such as a maximal\nindependent set that cannot be improved by certain (greedy) local moves, even\nthough it may not be globally optimal. It is trivial to construct an\nindependent set in a graph. It is easy to (greedily) construct a maximal\nindependent set. However, it is NP-hard to construct a globally-optimal\n(maximum) independent set. In general, constructing a locally-optimal structure\nis somewhat more difficult than constructing an arbitrary structure, and\nconstructing a globally-optimal structure is more difficult than constructing a\nlocally-optimal structure. The same situation arises with listing. The\ndifferences between the problems become obscured when we move from listing to\ncounting because nearly everything is #P-complete. However, we highlight an\ninteresting phenomenon that arises in approximate counting, where the situation\nis apparently reversed. Specifically, we show that counting maximal independent\nsets is complete for #P with respect to approximation-preserving reductions,\nwhereas counting all independent sets, or counting maximum independent sets is\ncomplete for an apparently smaller class, $\\mathrm{\\#RH}\\Pi_1$ which has a\nprominent role in the complexity of approximate counting. Motivated by the\ndifficulty of approximately counting maximal independent sets in bipartite\ngraphs, we also study the problem of approximately counting other\nlocally-optimal structures that arise in algorithmic applications, particularly\nproblems involving minimal separators and minimal edge separators. Minimal\nseparators have applications via fixed-parameter-tractable algorithms for\nconstructing triangulations and phylogenetic trees. Although exact\n(exponential-time) algorithms exist for listing these structures, we show that\nthe counting problems are #P-complete with respect to both exact and\napproximation-preserving reductions."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.7341v2", 
    "title": "Deterministic Identity Testing for Sum of Read-Once Oblivious Arithmetic   Branching Programs", 
    "arxiv-id": "1411.7341v2", 
    "author": "Thomas Thierauf", 
    "publish": "2014-11-26T19:24:14Z", 
    "summary": "A read-once oblivious arithmetic branching program (ROABP) is an arithmetic\nbranching program (ABP) where each variable occurs in at most one layer. We\ngive the first polynomial time whitebox identity test for a polynomial computed\nby a sum of constantly many ROABPs. We also give a corresponding blackbox\nalgorithm with quasi-polynomial time complexity $n^{O(\\log n)}$. In both the\ncases, our time complexity is double exponential in the number of ROABPs.\n  ROABPs are a generalization of set-multilinear depth-$3$ circuits. The prior\nresults for the sum of constantly many set-multilinear depth-$3$ circuits were\nonly slightly better than brute-force, i.e. exponential-time.\n  Our techniques are a new interplay of three concepts for ROABP: low\nevaluation dimension, basis isolating weight assignment and low-support rank\nconcentration. We relate basis isolation to rank concentration and extend it to\na sum of two ROABPs using evaluation dimension (or partial derivatives)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.7455v1", 
    "title": "Dimension Expanders via Rank Condensers", 
    "arxiv-id": "1411.7455v1", 
    "author": "Venkatesan Guruswami", 
    "publish": "2014-11-27T03:11:11Z", 
    "summary": "An emerging theory of \"linear-algebraic pseudorandomness\" aims to understand\nthe linear-algebraic analogs of fundamental Boolean pseudorandom objects where\nthe rank of subspaces plays the role of the size of subsets. In this work, we\nstudy and highlight the interrelationships between several such algebraic\nobjects such as subspace designs, dimension expanders, seeded rank condensers,\ntwo-source rank condensers, and rank-metric codes. In particular, with the\nrecent construction of near-optimal subspace designs by Guruswami and Kopparty\nas a starting point, we construct good (seeded) rank condensers (both lossless\nand lossy versions), which are a small collection of linear maps $\\mathbb{F}^n\n\\to \\mathbb{F}^t$ for $t \\ll n$ such that for every subset of $\\mathbb{F}^n$ of\nsmall rank, its rank is preserved (up to a constant factor in the lossy case)\nby at least one of the maps.\n  We then compose a tensoring operation with our lossy rank condenser to\nconstruct constant-degree dimension expanders over polynomially large fields.\nThat is, we give $O(1)$ explicit linear maps $A_i:\\mathbb{F}^n\\to \\mathbb{F}^n$\nsuch that for any subspace $V \\subseteq \\mathbb{F}^n$ of dimension at most\n$n/2$, $\\dim\\bigl( \\sum_i A_i(V)\\bigr) \\ge (1+\\Omega(1)) \\dim(V)$. Previous\nconstructions of such constant-degree dimension expanders were based on\nKazhdan's property $T$ (for the case when $\\mathbb{F}$ has characteristic zero)\nor monotone expanders (for every field $\\mathbb{F}$); in either case the\nconstruction was harder than that of usual vertex expanders. Our construction,\non the other hand, is simpler.\n  Via an equivalence to linear rank-metric codes, we then construct optimal\nlossless two-source condensers. We then use our seeded rank condensers to\nobtain near-optimal lossy two-source condensers for constant rank sources."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.7492v1", 
    "title": "Subexponential Size Hitting Sets for Bounded Depth Multilinear Formulas", 
    "arxiv-id": "1411.7492v1", 
    "author": "Ben Lee Volk", 
    "publish": "2014-11-27T07:56:43Z", 
    "summary": "In this paper we give subexponential size hitting sets for bounded depth\nmultilinear arithmetic formulas. Using the known relation between black-box PIT\nand lower bounds we obtain lower bounds for these models.\n  For depth-3 multilinear formulas, of size $\\exp(n^\\delta)$, we give a hitting\nset of size $\\exp(\\tilde{O}(n^{2/3 + 2\\delta/3}))$. This implies a lower bound\nof $\\exp(\\tilde{\\Omega}(n^{1/2}))$ for depth-3 multilinear formulas, for some\nexplicit polynomial.\n  For depth-4 multilinear formulas, of size $\\exp(n^\\delta)$, we give a hitting\nset of size $\\exp(\\tilde{O}(n^{2/3 + 4\\delta/3}))$. This implies a lower bound\nof $\\exp(\\tilde{\\Omega}(n^{1/4}))$ for depth-4 multilinear formulas, for some\nexplicit polynomial.\n  A regular formula consists of alternating layers of $+,\\times$ gates, where\nall gates at layer $i$ have the same fan-in. We give a hitting set of size\n(roughly) $\\exp\\left(n^{1- \\delta} \\right)$, for regular depth-$d$ multilinear\nformulas of size $\\exp(n^\\delta)$, where $\\delta = O(\\frac{1}{\\sqrt{5}^d})$.\nThis result implies a lower bound of roughly\n$\\exp(\\tilde{\\Omega}(n^{\\frac{1}{\\sqrt{5}^d}}))$ for such formulas.\n  We note that better lower bounds are known for these models, but also that\nnone of these bounds was achieved via construction of a hitting set. Moreover,\nno lower bound that implies such PIT results, even in the white-box model, is\ncurrently known.\n  Our results are combinatorial in nature and rely on reducing the underlying\nformula, first to a depth-4 formula, and then to a read-once algebraic\nbranching program (from depth-3 formulas we go straight to read-once algebraic\nbranching programs)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1411.7747v2", 
    "title": "A Characterization of hard-to-cover CSPs", 
    "arxiv-id": "1411.7747v2", 
    "author": "Girish Varma", 
    "publish": "2014-11-28T04:21:41Z", 
    "summary": "We continue the study of covering complexity of constraint satisfaction\nproblems (CSPs) initiated by Guruswami, Hastad and Sudan [SIAM J. Computing,\n31(6):1663--1686, 2002] and Dinur and Kol [In Proc. $28$th IEEE Conference on\nComputational Complexity, 2013]. The covering number of a CSP instance $\\Phi$,\ndenoted by $\\nu(\\Phi)$ is the smallest number of assignments to the variables\nof $\\Phi$, such that each constraint of $\\Phi$ is satisfied by at least one of\nthe assignments. We show the following results regarding how well efficient\nalgorithms can approximate the covering number of a given CSP instance.\n  - Assuming a covering unique games conjecture, introduced by Dinur and Kol,\nwe show that for every non-odd predicate $P$ over any constant sized alphabet\nand every integer $K$, it is NP-hard to distinguish between $P$-CSP instances\n(i.e., CSP instances where all the constraints are of type $P$) which are\ncoverable by a constant number of assignments and those whose covering number\nis at least $K$. Previously, Dinur and Kol, using the same covering unique\ngames conjecture, had shown a similar hardness result for every non-odd\npredicate over the Boolean alphabet that supports a pairwise independent\ndistribution. Our generalization yields a complete characterization of CSPs\nover constant sized alphabet $\\Sigma$ that are hard to cover since CSP's over\nodd predicates are trivially coverable with $|\\Sigma|$ assignments.\n  - For a large class of predicates that are contained in the $2k$-LIN\npredicate, we show that it is quasi-NP-hard to distinguish between instances\nwhich have covering number at most two and covering number at least\n$\\Omega(\\log\\log n)$. This generalizes the $4$-LIN result of Dinur and Kol that\nstates it is quasi-NP-hard to distinguish between $4$-LIN-CSP instances which\nhave covering number at most two and covering number at least $\\Omega(\\log\n\\log\\log n)$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.0356v2", 
    "title": "An Algorithmic Separating Hyperplane Theorem and Its Applications", 
    "arxiv-id": "1412.0356v2", 
    "author": "Bahman Kalantari", 
    "publish": "2014-12-01T05:48:30Z", 
    "summary": "We first prove a new separating hyperplane theorem characterizing when a pair\nof compact convex subsets $K, K'$ of the Euclidean space intersect, and when\nthey are disjoint. The theorem is distinct from classical separation theorems.\nIt generalizes the {\\it distance duality} proved in our earlier work for\ntesting the membership of a distinguished point in the convex hull of a finite\npoint set. Next by utilizing the theorem, we develop a substantially\ngeneralized and stronger version of the {\\it Triangle Algorithm} introduced in\nthe previous work to perform any of the following three tasks: (1) To compute a\npair $(p,p') \\in K \\times K'$, where either the Euclidean distance $d(p,p')$ is\nto within a prescribed tolerance, or the orthogonal bisecting hyperplane of the\nline segment $pp'$ separates the two sets; (2) When $K$ and $K'$ are disjoint,\nto compute $(p,p') \\in K \\times K'$ so that $d(p,p')$ approximates $d(K,K')$ to\nwithin a prescribed tolerance; (3) When $K$ and $K'$ are disjoint, to compute a\npair of parallel supporting hyperplanes $H,H'$ so that $d(H,H')$ is to within a\nprescribed tolerance of the optimal margin. The worst-case complexity of each\niteration is solving a linear objective over $K$ or $K'$. The resulting\nalgorithm is a fully polynomial-time approximation scheme for such important\nspecial cases as when $K$ and $K'$ are convex hulls of finite points sets, or\nthe intersection of a finite number of halfspaces. The results find many\ntheoretical and practical applications, such as in machine learning,\nstatistics, linear, quadratic and convex programming. In particular, in a\nseparate article we report on a comparison of the Triangle Algorithm and SMO\nfor solving the hard margin problem. In future work we extend the applications\nto combinatorial and NP-complete problems."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.0423v1", 
    "title": "Dichotomy Theorems for Homomorphism Polynomials of Graph Classes", 
    "arxiv-id": "1412.0423v1", 
    "author": "Christian Engels", 
    "publish": "2014-12-01T11:01:14Z", 
    "summary": "In this paper, we will show dichotomy theorems for the computation of\npolynomials corresponding to evaluation of graph homomorphisms in Valiant's\nmodel. We are given a fixed graph $H$ and want to find all graphs, from some\ngraph class, homomorphic to this $H$. These graphs will be encoded by a family\nof polynomials.\n  We give dichotomies for the polynomials for cycles, cliques, trees,\nouterplanar graphs, planar graphs and graphs of bounded genus."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.0784v1", 
    "title": "Braid is undecidable", 
    "arxiv-id": "1412.0784v1", 
    "author": "Linus Hamilton", 
    "publish": "2014-12-02T05:29:18Z", 
    "summary": "Braid is a 2008 puzzle game centered around the ability to reverse time. We\nshow that Braid can simulate an arbitrary computation. Our construction makes\nno use of Braid's unique time mechanics, and therefore may apply to many other\nvideo games.\n  We also show that a plausible \"bounded\" variant of Braid lies within\n2-EXPSPACE. Our proof relies on a technical lemma about Turing machines which\nmay be of independent interest. Namely, define a braidlike Turing machine to be\na Turing machine that, when it writes to the tape, deletes all data on the tape\nto the right of the head. We prove that deciding the behavior of such a machine\nlies in EXPSPACE."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.1124v1", 
    "title": "Tree-like resolution complexity of two planar problems", 
    "arxiv-id": "1412.1124v1", 
    "author": "Dmitry Sokolov", 
    "publish": "2014-12-02T22:37:17Z", 
    "summary": "We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.1229v6", 
    "title": "SAT is a problem with exponential complexity measured by negentropy", 
    "arxiv-id": "1412.1229v6", 
    "author": "Feng Pan", 
    "publish": "2014-12-03T08:36:38Z", 
    "summary": "In this paper the reason why entropy reduction (negentropy) can be used to\nmeasure the complexity of any computation was first elaborated both in the\naspect of mathematics and informational physics. In the same time the\nequivalence of computation and information was clearly stated. Then the\ncomplexities of three specific problems: logical compare, sorting and SAT, were\nanalyzed and measured. The result showed SAT was a problem with exponential\ncomplexity which naturally leads to the conclusion that no efficient algorithm\nexists to solve it. That's to say: NP!=P."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.2470v1", 
    "title": "Bounded Treewidth and Space-Efficient Linear Algebra", 
    "arxiv-id": "1412.2470v1", 
    "author": "Samir Datta", 
    "publish": "2014-12-08T07:54:24Z", 
    "summary": "Motivated by a recent result of Elberfeld, Jakoby and Tantau showing that\n$\\mathsf{MSO}$ properties are Logspace computable on graphs of bounded\ntree-width, we consider the complexity of computing the determinant of the\nadjacency matrix of a bounded tree-width graph and as our main result prove\nthat it is in Logspace. It is important to notice that the determinant is\nneither an $\\mathsf{MSO}$-property nor counts the number of solutions of an\n$\\mathsf{MSO}$-predicate. This technique yields Logspace algorithms for\ncounting the number of spanning arborescences and directed Euler tours in\nbounded tree-width digraphs.\n  We demonstrate some linear algebraic applications of the determinant\nalgorithm by describing Logspace procedures for the characteristic polynomial,\nthe powers of a weighted bounded tree-width graph and feasibility of a system\nof linear equations where the underlying bipartite graph has bounded\ntree-width.\n  Finally, we complement our upper bounds by proving $\\mathsf{L}$-hardness of\nthe problems of computing the determinant, and of powering a bounded tree-width\nmatrix. We also show the $\\mathsf{GapL}$-hardness of Iterated Matrix\nMultiplication where each matrix has bounded tree-width."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.2497v1", 
    "title": "Homonym Population Protocols, or Providing a Small Space of Computation   Using a Few Identifiers", 
    "arxiv-id": "1412.2497v1", 
    "author": "Mika\u00ebl Rabie", 
    "publish": "2014-12-08T09:56:37Z", 
    "summary": "Population protocols have been introduced by Angluin et al. as a model in\nwhich n passively mobile anonymous finite-state agents stably compute a\npredicate on the multiset of their inputs via interactions by pairs. The model\nhas been extended by Guerraoui and Ruppert to yield the community protocol\nmodels where agents have unique identifiers but may only store a finite number\nof the identifiers they already heard about. The population protocol models can\nonly compute semi-linear predicates, whereas in the community protocol model\nthe whole community of agents provides collectively the power of a Turing\nmachine with a O(n log n) space. We consider variations on the above models and\nwe obtain a whole landscape that covers and extends already known results: By\nconsidering the case of homonyms, that is to say the case when several agents\nmay share the same identifier, we provide a hierarchy that goes from the case\nof no identifier (i.e. a single one for all, i.e. the population protocol\nmodel) to the case of unique identifiers (i.e. community protocol model). We\nobtain in particular that any Turing Machine on space O(logO(1) n) can be\nsimulated with at least O(logO(1) n) identifiers, a result filling a gap left\nopen in all previous studies. Our results also extend and revisit in particular\nthe hierarchy provided by Chatzigiannakis et al. on population protocols\ncarrying Turing Machines on limited space, solving the problem of the gap left\nby this work between per-agent space o(log log n) (proved to be equivalent to\npopulation protocols) and O(log n) (proved to be equivalent to Turing\nmachines)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2676726.2677010", 
    "link": "http://arxiv.org/pdf/1412.3095v1", 
    "title": "Scheduling with two non-unit task lengths is NP-complete", 
    "arxiv-id": "1412.3095v1", 
    "author": "Mathijs de Weerdt", 
    "publish": "2014-12-09T20:41:36Z", 
    "summary": "We consider the non-preemptive task scheduling problem with release times and\ndeadlines on a single machine parameterized by the set of task lengths the\ntasks can have. The identical task lengths case is known to be solvable in\npolynomial time. We prove that the problem with two task lengths is\nNP-complete, except for the case in which the short jobs have unit task length,\nwhich was already known to be efficiently solvable."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.3377v1", 
    "title": "Uniformity is weaker than semi-uniformity for some membrane systems", 
    "arxiv-id": "1412.3377v1", 
    "author": "Damien Woods", 
    "publish": "2014-12-10T17:30:22Z", 
    "summary": "We investigate computing models that are presented as families of finite\ncomputing devices with a uniformity condition on the entire family. Examples of\nsuch models include Boolean circuits, membrane systems, DNA computers, chemical\nreaction networks and tile assembly systems, and there are many others.\nHowever, in such models there are actually two distinct kinds of uniformity\ncondition. The first is the most common and well-understood, where each input\nlength is mapped to a single computing device (e.g. a Boolean circuit) that\ncomputes on the finite set of inputs of that length. The second, called\nsemi-uniformity, is where each input is mapped to a computing device for that\ninput (e.g. a circuit with the input encoded as constants). The former notion\nis well-known and used in Boolean circuit complexity, while the latter notion\nis frequently found in literature on nature-inspired computation from the past\n20 years or so.\n  Are these two notions distinct? For many models it has been found that these\nnotions are in fact the same, in the sense that the choice of uniformity or\nsemi-uniformity leads to characterisations of the same complexity classes. In\nother related work, we showed that these notions are actually distinct for\ncertain classes of Boolean circuits. Here, we give analogous results for\nmembrane systems by showing that certain classes of uniform membrane systems\nare strictly weaker than the analogous semi-uniform classes. This solves a\nknown open problem in the theory of membrane systems. We then go on to present\nresults towards characterising the power of these semi-uniform and uniform\nmembrane models in terms of NL and languages reducible to the unary languages\nin NL, respectively."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.4719v1", 
    "title": "Nonclassical polynomials as a barrier to polynomial lower bounds", 
    "arxiv-id": "1412.4719v1", 
    "author": "Shachar Lovett", 
    "publish": "2014-12-15T18:51:06Z", 
    "summary": "The problem of constructing explicit functions which cannot be approximated\nby low degree polynomials has been extensively studied in computational\ncomplexity, motivated by applications in circuit lower bounds,\npseudo-randomness, constructions of Ramsey graphs and locally decodable codes.\nStill, most of the known lower bounds become trivial for polynomials of\nsuper-logarithmic degree. Here, we suggest a new barrier explaining this\nphenomenon. We show that many of the existing lower bound proof techniques\nextend to nonclassical polynomials, an extension of classical polynomials which\narose in higher order Fourier analysis. Moreover, these techniques are tight\nfor nonclassical polynomials of logarithmic degree."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.4832v1", 
    "title": "Variable Selection is Hard", 
    "arxiv-id": "1412.4832v1", 
    "author": "Justin Thaler", 
    "publish": "2014-12-15T23:15:40Z", 
    "summary": "Variable selection for sparse linear regression is the problem of finding,\ngiven an m x p matrix B and a target vector y, a sparse vector x such that Bx\napproximately equals y. Assuming a standard complexity hypothesis, we show that\nno polynomial-time algorithm can find a k'-sparse x with ||Bx-y||^2<=h(m,p),\nwhere k'=k*2^{log^{1-delta} p} and h(m,p)<=p^(C_1)*m^(1-C_2), where delta>0,\nC_1>0,C_2>0 are arbitrary. This is true even under the promise that there is an\nunknown k-sparse vector x^* satisfying Bx^*=y. We prove a similar result for a\nstatistical version of the problem in which the data are corrupted by noise.\n  To the authors' knowledge, these are the first hardness results for sparse\nregression that apply when the algorithm simultaneously has k'>k and h(m,p)>0."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.4904v1", 
    "title": "New Bounds for the Garden-Hose Model", 
    "arxiv-id": "1412.4904v1", 
    "author": "Supartha Podder", 
    "publish": "2014-12-16T08:03:58Z", 
    "summary": "We show new results about the garden-hose model. Our main results include\nimproved lower bounds based on non-deterministic communication complexity\n(leading to the previously unknown $\\Theta(n)$ bounds for Inner Product mod 2\nand Disjointness), as well as an $O(n\\cdot \\log^3 n)$ upper bound for the\nDistributed Majority function (previously conjectured to have quadratic\ncomplexity). We show an efficient simulation of formulae made of AND, OR, XOR\ngates in the garden-hose model, which implies that lower bounds on the\ngarden-hose complexity $GH(f)$ of the order $\\Omega(n^{2+\\epsilon})$ will be\nhard to obtain for explicit functions. Furthermore we study a time-bounded\nvariant of the model, in which even modest savings in time can lead to\nexponential lower bounds on the size of garden-hose protocols."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.5655v1", 
    "title": "New algorithms and lower bounds for monotonicity testing", 
    "arxiv-id": "1412.5655v1", 
    "author": "Li-Yang Tan", 
    "publish": "2014-12-17T22:26:10Z", 
    "summary": "We consider the problem of testing whether an unknown Boolean function $f$ is\nmonotone versus $\\epsilon$-far from every monotone function. The two main\nresults of this paper are a new lower bound and a new algorithm for this\nwell-studied problem.\n  Lower bound: We prove an $\\tilde{\\Omega}(n^{1/5})$ lower bound on the query\ncomplexity of any non-adaptive two-sided error algorithm for testing whether an\nunknown Boolean function $f$ is monotone versus constant-far from monotone.\nThis gives an exponential improvement on the previous lower bound of\n$\\Omega(\\log n)$ due to Fischer et al. [FLN+02]. We show that the same lower\nbound holds for monotonicity testing of Boolean-valued functions over hypergrid\ndomains $\\{1,\\ldots,m\\}^n$ for all $m\\ge 2$.\n  Upper bound: We give an $\\tilde{O}(n^{5/6})\\text{poly}(1/\\epsilon)$-query\nalgorithm that tests whether an unknown Boolean function $f$ is monotone versus\n$\\epsilon$-far from monotone. Our algorithm, which is non-adaptive and makes\none-sided error, is a modified version of the algorithm of Chakrabarty and\nSeshadhri [CS13a], which makes $\\tilde{O}(n^{7/8})\\text{poly}(1/\\epsilon)$\nqueries."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.5657v1", 
    "title": "Boolean function monotonicity testing requires (almost) $n^{1/2}$   non-adaptive queries", 
    "arxiv-id": "1412.5657v1", 
    "author": "Li-Yang Tan", 
    "publish": "2014-12-17T22:37:54Z", 
    "summary": "We prove a lower bound of $\\Omega(n^{1/2 - c})$, for all $c>0$, on the query\ncomplexity of (two-sided error) non-adaptive algorithms for testing whether an\n$n$-variable Boolean function is monotone versus constant-far from monotone.\nThis improves a $\\tilde{\\Omega}(n^{1/5})$ lower bound for the same problem that\nwas recently given in [CST14] and is very close to $\\Omega(n^{1/2})$, which we\nconjecture is the optimal lower bound for this model."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.6268v1", 
    "title": "The simplified weighted sum function and its average sensitivity", 
    "arxiv-id": "1412.6268v1", 
    "author": "Chu Luo", 
    "publish": "2014-12-19T10:08:59Z", 
    "summary": "In this paper we simplify the definition of the weighted sum Boolean function\nwhich used to be inconvenient to compute and use. We show that the new function\nhas essentially the same properties as the previous one. In particular, the\nbound on the average sensitivity of the weighted sum Boolean function remains\nunchanged after the simplification."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1412.7979v1", 
    "title": "On the Lattice Smoothing Parameter Problem", 
    "arxiv-id": "1412.7979v1", 
    "author": "Chris Peikert", 
    "publish": "2014-12-26T19:50:58Z", 
    "summary": "The smoothing parameter $\\eta_{\\epsilon}(\\mathcal{L})$ of a Euclidean lattice\n$\\mathcal{L}$, introduced by Micciancio and Regev (FOCS'04; SICOMP'07), is\n(informally) the smallest amount of Gaussian noise that \"smooths out\" the\ndiscrete structure of $\\mathcal{L}$ (up to error $\\epsilon$). It plays a\ncentral role in the best known worst-case/average-case reductions for lattice\nproblems, a wealth of lattice-based cryptographic constructions, and\n(implicitly) the tightest known transference theorems for fundamental lattice\nquantities.\n  In this work we initiate a study of the complexity of approximating the\nsmoothing parameter to within a factor $\\gamma$, denoted $\\gamma$-${\\rm\nGapSPP}$. We show that (for $\\epsilon = 1/{\\rm poly}(n)$): $(2+o(1))$-${\\rm\nGapSPP} \\in {\\rm AM}$, via a Gaussian analogue of the classic\nGoldreich-Goldwasser protocol (STOC'98); $(1+o(1))$-${\\rm GapSPP} \\in {\\rm\ncoAM}$, via a careful application of the Goldwasser-Sipser (STOC'86) set size\nlower bound protocol to thin spherical shells; $(2+o(1))$-${\\rm GapSPP} \\in\n{\\rm SZK} \\subseteq {\\rm AM} \\cap {\\rm coAM}$ (where ${\\rm SZK}$ is the class\nof problems having statistical zero-knowledge proofs), by constructing a\nsuitable instance-dependent commitment scheme (for a slightly worse\n$o(1)$-term); $(1+o(1))$-${\\rm GapSPP}$ can be solved in deterministic\n$2^{O(n)} {\\rm polylog}(1/\\epsilon)$ time and $2^{O(n)}$ space.\n  As an application, we demonstrate a tighter worst-case to average-case\nreduction for basing cryptography on the worst-case hardness of the ${\\rm\nGapSPP}$ problem, with $\\tilde{O}(\\sqrt{n})$ smaller approximation factor than\nthe ${\\rm GapSVP}$ problem.\n  Central to our results are two novel, and nearly tight, characterizations of\nthe magnitude of discrete Gaussian sums."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1502.00357v2", 
    "title": "On Restricting No-Junta Boolean Function and Degree Lower Bounds by   Polynomial Method", 
    "arxiv-id": "1502.00357v2", 
    "author": "Ming-Chuan Yang", 
    "publish": "2015-02-02T04:45:21Z", 
    "summary": "Let $\\mathcal{F}_{n}^*$ be the set of Boolean functions depending on all $n$\nvariables. We prove that for any $f\\in \\mathcal{F}_{n}^*$, $f|_{x_i=0}$ or\n$f|_{x_i=1}$ depends on the remaining $n-1$ variables, for some variable $x_i$.\nThis existent result suggests a possible way to deal with general Boolean\nfunctions via its subfunctions of some restrictions.\n  As an application, we consider the degree lower bound of representing\npolynomials over finite rings. Let $f\\in \\mathcal{F}_{n}^*$ and denote the\nexact representing degree over the ring $\\mathbb{Z}_m$ (with the integer $m>2$)\nas $d_m(f)$. Let $m=\\Pi_{i=1}^{r}p_i^{e_i}$, where $p_i$'s are distinct primes,\nand $r$ and $e_i$'s are positive integers. If $f$ is symmetric, then $m\\cdot\nd_{p_1^{e_1}}(f)... d_{p_r^{e_r}}(f) > n$. If $f$ is non-symmetric, by the\nsecond moment method we prove almost always $m\\cdot d_{p_1^{e_1}}(f)...\nd_{p_r^{e_r}}(f) > \\lg{n}-1$. In particular, as $m=pq$ where $p$ and $q$ are\narbitrary distinct primes, we have $d_p(f)d_q(f)=\\Omega(n)$ for symmetric $f$\nand $d_p(f)d_q(f)=\\Omega(\\lg{n}-1)$ almost always for non-symmetric $f$. Hence\nany $n$-variate symmetric Boolean function can have exact representing degree\n$o(\\sqrt{n})$ in at most one finite field, and for non-symmetric functions,\nwith $o(\\sqrt{\\lg{n}})$-degree in at most one finite field."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2014-1095", 
    "link": "http://arxiv.org/pdf/1502.01865v1", 
    "title": "Lower Bounds for Monotone Counting Circuits", 
    "arxiv-id": "1502.01865v1", 
    "author": "Stasys Jukna", 
    "publish": "2015-02-06T11:55:33Z", 
    "summary": "A {+,x}-circuit counts a given multivariate polynomial f, if its values on\n0-1 inputs are the same as those of f; on other inputs the circuit may output\narbitrary values. Such a circuit counts the number of monomials of f evaluated\nto 1 by a given 0-1 input vector (with multiplicities given by their\ncoefficients). A circuit decides $f$ if it has the same 0-1 roots as f. We\nfirst show that some multilinear polynomials can be exponentially easier to\ncount than to compute them, and can be exponentially easier to decide than to\ncount them. Then we give general lower bounds on the size of counting circuits."
},{
    "category": "cs.CC", 
    "doi": "10.1137/140990346", 
    "link": "http://arxiv.org/pdf/1502.03482v2", 
    "title": "Necessary conditions for tractability of valued CSPs", 
    "arxiv-id": "1502.03482v2", 
    "author": "Stanislav Zivny", 
    "publish": "2015-02-11T23:11:42Z", 
    "summary": "The connection between constraint languages and clone theory has been a\nfruitful line of research on the complexity of constraint satisfaction\nproblems. In a recent result, Cohen et al. [SICOMP'13] have characterised a\nGalois connection between valued constraint languages and so-called weighted\nclones. In this paper, we study the structure of weighted clones. We extend the\nresults of Creed and Zivny from [CP'11/SICOMP'13] on types of weightings\nnecessarily contained in every nontrivial weighted clone. This result has\nimmediate computational complexity consequences as it provides necessary\nconditions for tractability of weighted clones and thus valued constraint\nlanguages. We demonstrate that some of the necessary conditions are also\nsufficient for tractability, while others are provably not."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.04226v2", 
    "title": "Width Hierarchy for k-OBDD of Small Width", 
    "arxiv-id": "1502.04226v2", 
    "author": "Kamil Khadiev", 
    "publish": "2015-02-14T17:20:06Z", 
    "summary": "In this paper was explored well known model k-OBDD. There are proven width\nbased hierarchy of classes of boolean functions which computed by k-OBDD. The\nproof of hierarchy is based on sufficient condition of Boolean function's non\nrepresentation as k-OBDD and complexity properties of Boolean function SAF.\nThis function is modification of known Pointer Jumping (PJ) and Indirect\nStorage Access (ISA) functions."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.04545v1", 
    "title": "Parallel Identity Testing for Skew Circuits with Big Powers and   Applications", 
    "arxiv-id": "1502.04545v1", 
    "author": "Markus Lohrey", 
    "publish": "2015-02-16T14:24:01Z", 
    "summary": "Powerful skew arithmetic circuits are introduced. These are skew arithmetic\ncircuits with variables, where input gates can be labelled with powers $x^n$\nfor binary encoded numbers $n$. It is shown that polynomial identity testing\nfor powerful skew arithmetic circuits belongs to $\\mathsf{coRNC}^2$, which\ngeneralizes a corresponding result for (standard) skew circuits. Two\napplications of this result are presented: (i) Equivalence of\nhigher-dimensional straight-line programs can be tested in $\\mathsf{coRNC}^2$;\nthis result is even new in the one-dimensional case, where the straight-line\nprograms produce strings. (ii) The compressed word problem (or circuit\nevaluation problem) for certain wreath products of finitely generated abelian\ngroups belongs to $\\mathsf{coRNC}^2$."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.04650v2", 
    "title": "Lower Bound for General Circuits Computing Clique Function", 
    "arxiv-id": "1502.04650v2", 
    "author": "Weimin Chen", 
    "publish": "2015-02-16T17:58:08Z", 
    "summary": "We prove an exponential lower bound for general circuits computing the clique\nfunction and hereby confirm that NP != P."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.05361v2", 
    "title": "Extended Formulation for CSP that is Compact for Instances of Bounded   Treewidth", 
    "arxiv-id": "1502.05361v2", 
    "author": "Martin Kouteck\u00fd", 
    "publish": "2015-02-18T20:00:10Z", 
    "summary": "In this paper we provide an extended formulation for the class of constraint\nsatisfaction problems and prove that its size is polynomial for instances whose\nconstraint graph has bounded treewidth. This implies new upper bounds on\nextension complexity of several important NP-hard problems on graphs of bounded\ntreewidth."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.06761v1", 
    "title": "Minimal Distance of Propositional Models", 
    "arxiv-id": "1502.06761v1", 
    "author": "Gernot Salzer", 
    "publish": "2015-02-24T11:06:04Z", 
    "summary": "We investigate the complexity of three optimization problems in Boolean\npropositional logic related to information theory: Given a conjunctive formula\nover a set of relations, find a satisfying assignment with minimal Hamming\ndistance to a given assignment that satisfies the formula\n($\\mathsf{NeareastOtherSolution}$, $\\mathsf{NOSol}$) or that does not need to\nsatisfy it ($\\mathsf{NearestSolution}$, $\\mathsf{NSol}$). The third problem\nasks for two satisfying assignments with a minimal Hamming distance among all\nsuch assignments ($\\mathsf{MinSolutionDistance}$, $\\mathsf{MSD}$).\n  For all three problems we give complete classifications with respect to the\nrelations admitted in the formula. We give polynomial time algorithms for\nseveral classes of constraint languages. For all other cases we prove hardness\nor completeness regarding APX, APX, NPO, or equivalence to well-known hard\noptimization problems."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.07258v2", 
    "title": "Identifying an Honest ${\\rm EXP}^{\\rm NP}$ Oracle Among Many", 
    "arxiv-id": "1502.07258v2", 
    "author": "Shuichi Hirahara", 
    "publish": "2015-02-25T17:16:44Z", 
    "summary": "We provide a general framework to remove short advice by formulating the\nfollowing computational task for a function $f$: given two oracles at least one\nof which is honest (i.e. correctly computes $f$ on all inputs) as well as an\ninput, the task is to compute $f$ on the input with the help of the oracles by\na probabilistic polynomial-time machine, which we shall call a selector. We\ncharacterize the languages for which short advice can be removed by the notion\nof selector: a paddable language has a selector if and only if short advice of\na probabilistic machine that accepts the language can be removed under any\nrelativized world. Previously, instance checkers have served as a useful tool\nto remove short advice of probabilistic computation. We indicate that existence\nof instance checkers is a property stronger than that of removing short advice:\nalthough no instance checker for ${\\rm EXP}^{\\rm NP}$-complete languages exists\nunless ${\\rm EXP}^{\\rm NP} = {\\rm NEXP}$, we prove that there exists a selector\nfor any ${\\rm EXP}^{\\rm NP}$-complete language, by building on the proof of\n${\\rm MIP} = {\\rm NEXP}$ by Babai, Fortnow, and Lund (1991)."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1502.07545v3", 
    "title": "SAT problem and statistical distance", 
    "arxiv-id": "1502.07545v3", 
    "author": "Feng Pan", 
    "publish": "2015-02-26T13:28:06Z", 
    "summary": "In this paper with two equivalent representations of the information\ncontained by a SAT formula, the reason why string generated by succinct SAT\nformula can be greatly compressed is firstly presented based on Kolmogorov\ncomplexity theory. Then what strings can be greatly compressed were classified\nand discussed. In this way we discovered the SAT problem was composed of a\nbasic distinguish problem: distinguish two different distributions induced\nunder the computer with certain SAT formula ensemble. We then tried to map this\nproblem into quantum mechanics, or the quantum version basic distinguish\nproblem: this time two different distributions are induced under quantum\nmechanics. Based on the equivalence of statistical distance between probability\nspace and Hilbert space, in the same time this distance is invariant under all\nunitary transformations. The quantum version basic problem cannot be\nefficiently solved by any quantum computer. In the worst case, any quantum\ncomputer must perform exponential times measurement in order to solve it. In\nthe end we proposed the main theorem : The statistical distance in program\nspace and probability space are identical. We tried to prove it using the\nrelationship of Kolmogorov complexity and entropy. It showed there is no\ndifference to solve the basic problem in SAT formula space or probability\nspace. In the worst case, exponential trials must be performed to solve it.\nNP!=P."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1503.00141v3", 
    "title": "Multinational War is Hard", 
    "arxiv-id": "1503.00141v3", 
    "author": "Jonathan Weed", 
    "publish": "2015-02-28T15:27:24Z", 
    "summary": "In this paper, we show that the problem of determining whether one player can\nforce a win in a multiplayer version of the children's card game War is\nPSPACE-hard. The same reduction shows that a related problem, asking whether a\nplayer can survive k rounds, is PSPACE-complete when k is polynomial in the\nsize of the input."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1503.00275v1", 
    "title": "Comparator Circuits over Finite Bounded Posets", 
    "arxiv-id": "1503.00275v1", 
    "author": "K. S. Sunil", 
    "publish": "2015-03-01T13:46:11Z", 
    "summary": "Comparator circuit model was originally introduced by Mayr and Subramanian\n(1992) (and further studied by Cook, Filmus and Le (2012)) to capture problems\nwhich are not known to be P-complete but still not known to admit efficient\nparallel algorithms. The class CC is the complexity class of problems many-one\nlogspace reducible to the Comparator Circuit Value Problem and we know that NL\nis contained in CC which is inturn contained in P. Cook, Filmus and Le (2012)\nshowed that CC is also the class of languages decided by polynomial size\ncomparator circuits.\n  We study generalizations of the comparator circuit model that work over fixed\nfinite bounded posets. We observe that there are universal comparator circuits\neven over arbitrary fixed finite bounded posets. Building on this, we show that\ngeneral (resp. skew) comparator circuits of polynomial size over fixed finite\ndistributive lattices characterizes CC (resp. L). Complementing this, we show\nthat general comparator circuits of polynomial size over arbitrary fixed finite\nlattices exactly characterizes P and that when the comparator circuit is skew\nthey characterize NL. In addition, we show a characterization of the class NP\nby a family of polynomial sized comparator circuits over fixed {\\em finite\nbounded posets}. These results generalize the results by Cook, Filmus and Le\n(2012) regarding the power of comparator circuits. As an aside, we consider\ngeneralizations of Boolean formulae over arbitrary lattices. We show that\nSpira's theorem (1971) can be extended to this setting as well and show that\npolynomial sized Boolean formulae over finite fixed lattices capture exactly\nNC^1.\n  Our results indicate potential new approaches towards the problems P vs CC\nand NL vs L using lattice theoretic methods."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1503.00753v2", 
    "title": "No Small Linear Program Approximates Vertex Cover within a Factor $2 -   \u03b5$", 
    "arxiv-id": "1503.00753v2", 
    "author": "Ola Svensson", 
    "publish": "2015-03-02T21:26:23Z", 
    "summary": "The vertex cover problem is one of the most important and intensively studied\ncombinatorial optimization problems. Khot and Regev (2003) proved that the\nproblem is NP-hard to approximate within a factor $2 - \\epsilon$, assuming the\nUnique Games Conjecture (UGC). This is tight because the problem has an easy\n2-approximation algorithm. Without resorting to the UGC, the best\ninapproximability result for the problem is due to Dinur and Safra (2002):\nvertex cover is NP-hard to approximate within a factor 1.3606. We prove the\nfollowing unconditional result about linear programming (LP) relaxations of the\nproblem: every LP relaxation that approximates vertex cover within a factor\n$2-\\epsilon$ has super-polynomially many inequalities. As a direct consequence\nof our methods, we also establish that LP relaxations (as well as SDP\nrelaxations) that approximate the independent set problem within any constant\nfactor have super-polynomial size."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1503.07310v4", 
    "title": "The Complexity of Phylogeny Constraint Satisfaction", 
    "arxiv-id": "1503.07310v4", 
    "author": "Trung Van Pham", 
    "publish": "2015-03-25T09:18:40Z", 
    "summary": "We systematically study the computational complexity of a broad class of\ncomputational problems in phylogenetic reconstruction. The class contains for\nexample the rooted triple consistency problem, forbidden subtree problems, the\nquartet consistency problem, and many other problems studied in the\nbioinformatics literature. The studied problems can be described as constraint\nsatisfaction problems where the constraints have a first-order definition over\nthe rooted triple relation. We show that every such phylogeny problem can be\nsolved in polynomial time or is NP-complete. On the algorithmic side, we\ngeneralize a well-known polynomial-time algorithm of Aho, Sagiv, Szymanski, and\nUllman for the rooted triple consistency problem. Our algorithm repeatedly\nsolves linear equation systems to construct a solution in polynomial time. We\nthen show that every phylogeny problem that cannot be solved by our algorithm\nis NP-complete. Our classification establishes a dichotomy for a large class of\ninfinite structures that we believe is of independent interest in universal\nalgebra, model theory, and topology. The proof of our main result combines\nresults and techniques from various research areas: a recent classification of\nthe model-complete cores of the reducts of the homogeneous binary branching\nC-relation, Leeb's Ramsey theorem for rooted trees, and universal algebra."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1503.07691v2", 
    "title": "Sensitivity versus Certificate Complexity of Boolean Functions", 
    "arxiv-id": "1503.07691v2", 
    "author": "Jevg\u0113nijs Vihrovs", 
    "publish": "2015-03-26T11:24:58Z", 
    "summary": "Sensitivity, block sensitivity and certificate complexity are basic\ncomplexity measures of Boolean functions. The famous sensitivity conjecture\nclaims that sensitivity is polynomially related to block sensitivity. However,\nit has been notoriously hard to obtain even exponential bounds. Since block\nsensitivity is known to be polynomially related to certificate complexity, an\nequivalent of proving this conjecture would be showing that certificate\ncomplexity is polynomially related to sensitivity. Previously, it has been\nshown that $bs(f) \\leq C(f) \\leq 2^{s(f)-1} s(f) - (s(f)-1)$. In this work, we\ngive a better upper bound of $bs(f) \\leq C(f) \\leq\n\\max\\left(2^{s(f)-1}\\left(s(f)-\\frac 1 3\\right), s(f)\\right)$ using a recent\ntheorem limiting the structure of function graphs. We also examine relations\nbetween these measures for functions with small 1-sensitivity $s_1(f)$ and\narbitrary 0-sensitivity $s_0(f)$."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.00151v1", 
    "title": "Bi-polynomial rank and determinantal complexity", 
    "arxiv-id": "1504.00151v1", 
    "author": "Akihiro Yabe", 
    "publish": "2015-04-01T09:03:00Z", 
    "summary": "The permanent vs. determinant problem is one of the most important problems\nin theoretical computer science, and is the main target of geometric complexity\ntheory proposed by Mulmuley and Sohoni. The current best lower bound for the\ndeterminantal complexity of the d by d permanent polynomial is d^2/2, due to\nMignon and Ressayre in 2004. Inspired by their proof method, we introduce a\nnatural rank concept of polynomials, called the bi-polynomial rank. The\nbi-polynomial rank is related to width of an arithmetic branching program. The\nbi-polynomial rank of a homogeneous polynomial p of even degree 2k is defined\nas the minimum n such that p can be written as a summation of n products of\npolynomials of degree k. We prove that the bi-polynomial rank gives a lower\nbound of the determinantal complexity. As a consequence, the above Mignon and\nRessayre bound is improved to (d-1)^2 + 1 over the field of reals. We show that\nthe computation of the bi-polynomial rank is formulated as a rank minimization\nproblem. Applying the concave minimization technique, we reduce the problem of\nlower-bounding determinantal complexity to that of proving the positive\nsemidefiniteness of matrices, and this is a new approach for the permanent vs.\ndeterminant problem. We propose a computational approach for giving a lower\nbound of this rank minimization, via techniques of the concave minimization.\nThis also yields a new strategy to attack the permanent vs. determinant\nproblem."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.00337v4", 
    "title": "Understanding SAT is in P", 
    "arxiv-id": "1504.00337v4", 
    "author": "Alejandro Sanchez Guinea", 
    "publish": "2015-04-01T18:54:44Z", 
    "summary": "We introduce the idea of an understanding with respect to a set of clauses as\na satisfying truth assignment explained by the contexts of the literals in the\nclauses. Following this idea, we present a mechanical process that obtains, if\nit exists, an understanding with respect to a 3-SAT problem instance based on\nthe contexts of each literal in the instance, otherwise it determines that none\nexists. We demonstrate that our process is correct and efficient in solving\n3-SAT."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.00442v8", 
    "title": "Refuting Unique Game Conjecture", 
    "arxiv-id": "1504.00442v8", 
    "author": "Peng Cui", 
    "publish": "2015-04-02T03:52:43Z", 
    "summary": "In this short note, the author shows that the gap problem of some $k$-CSPs\nwith the support of its predicate the ground of a balanced pairwise independent\ndistribution can be solved by a modified version of Hast's Algorithm BiLin that\ncalls Charikar\\&Wirth's SDP algorithm for two rounds in polynomial time, when\n$k$ is sufficiently large, the support of its predicate is combined by the\ngrounds of three biased homogeneous distributions and the three biases satisfy\ncertain conditions. To conclude, the author refutes Unique Game Conjecture,\nassuming $P\\ne NP$."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.00572v1", 
    "title": "Efficient indexing of necklaces and irreducible polynomials over finite   fields", 
    "arxiv-id": "1504.00572v1", 
    "author": "Michael Saks", 
    "publish": "2015-04-02T14:40:36Z", 
    "summary": "We study the problem of indexing irreducible polynomials over finite fields,\nand give the first efficient algorithm for this problem. Specifically, we show\nthe existence of poly(n, log q)-size circuits that compute a bijection between\n{1, ... , |S|} and the set S of all irreducible, monic, univariate polynomials\nof degree n over a finite field F_q. This has applications in pseudorandomness,\nand answers an open question of Alon, Goldreich, H{\\aa}stad and Peralta[AGHP].\n  Our approach uses a connection between irreducible polynomials and necklaces\n( equivalence classes of strings under cyclic rotation). Along the way, we give\nthe first efficient algorithm for indexing necklaces of a given length over a\ngiven alphabet, which may be of independent interest."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.00695v1", 
    "title": "Trading query complexity for sample-based testing and multi-testing   scalability", 
    "arxiv-id": "1504.00695v1", 
    "author": "Yadu Vasudev", 
    "publish": "2015-04-02T21:34:01Z", 
    "summary": "We show here that every non-adaptive property testing algorithm making a\nconstant number of queries, over a fixed alphabet, can be converted to a\nsample-based (as per [Goldreich and Ron, 2015]) testing algorithm whose average\nnumber of queries is a fixed, smaller than $1$, power of $n$. Since the query\ndistribution of the sample-based algorithm is not dependent at all on the\nproperty, or the original algorithm, this has many implications in scenarios\nwhere there are many properties that need to be tested for concurrently, such\nas testing (relatively large) unions of properties, or converting a\nMerlin-Arthur Proximity proof (as per [Gur and Rothblum, 2013]) to a proper\ntesting algorithm.\n  The proof method involves preparing the original testing algorithm for a\ncombinatorial analysis, which in turn involves a new result about the existence\nof combinatorial structures (essentially generalized sunflowers) that allow the\nsample-based tester to replace the original constant query complexity tester."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.00703v5", 
    "title": "The matching problem has no small symmetric SDP", 
    "arxiv-id": "1504.00703v5", 
    "author": "Daniel Zink", 
    "publish": "2015-04-02T22:31:41Z", 
    "summary": "Yannakakis showed that the matching problem does not have a small symmetric\nlinear program. Rothvo{\\ss} recently proved that any, not necessarily\nsymmetric, linear program also has exponential size. It is natural to ask\nwhether the matching problem can be expressed compactly in a framework such as\nsemidefinite programming (SDP) that is more powerful than linear programming\nbut still allows efficient optimization. We answer this question negatively for\nsymmetric SDPs: any symmetric SDP for the matching problem has exponential\nsize.\n  We also show that an O(k)-round Lasserre SDP relaxation for the metric\ntraveling salesperson problem yields at least as good an approximation as any\nsymmetric SDP relaxation of size $n^k$.\n  The key technical ingredient underlying both these results is an upper bound\non the degree needed to derive polynomial identities that hold over the space\nof matchings or traveling salesperson tours."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S1995080215020092", 
    "link": "http://arxiv.org/pdf/1504.01092v1", 
    "title": "Technical Notes on Complexity of the Satisfiability Problem", 
    "arxiv-id": "1504.01092v1", 
    "author": "Marek A. Suchenek", 
    "publish": "2015-04-05T07:45:31Z", 
    "summary": "These notes contain, among others, a proof that the average running time of\nan easy solution to the satisfiability problem for propositional calculus is,\nunder some reasonable assumptions, linear (with constant 2) in the size of the\ninput. Moreover, some suggestions are made about criteria for tractability of\ncomplex algorithms. In particular, it is argued that the distribution of\nprobability on the whole input space of an algorithm constitutes an\nnon-negligible factor in estimating whether the algorithm is tractable or not."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.01339v1", 
    "title": "Separating decision tree complexity from subcube partition complexity", 
    "arxiv-id": "1504.01339v1", 
    "author": "Miklos Santha", 
    "publish": "2015-04-06T17:56:16Z", 
    "summary": "The subcube partition model of computation is at least as powerful as\ndecision trees but no separation between these models was known. We show that\nthere exists a function whose deterministic subcube partition complexity is\nasymptotically smaller than its randomized decision tree complexity, resolving\nan open problem of Friedgut, Kahn, and Wigderson (2002). Our lower bound is\nbased on the information-theoretic techniques first introduced to lower bound\nthe randomized decision tree complexity of the recursive majority function.\n  We also show that the public-coin partition bound, the best known lower bound\nmethod for randomized decision tree complexity subsuming other general\ntechniques such as block sensitivity, approximate degree, randomized\ncertificate complexity, and the classical adversary bound, also lower bounds\nrandomized subcube partition complexity. This shows that all these lower bound\ntechniques cannot prove optimal lower bounds for randomized decision tree\ncomplexity, which answers an open question of Jain and Klauck (2010) and Jain,\nLee, and Vishnoi (2014)."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.01656v1", 
    "title": "Tight Size-Degree Bounds for Sums-of-Squares Proofs", 
    "arxiv-id": "1504.01656v1", 
    "author": "Jakob Nordstr\u00f6m", 
    "publish": "2015-04-07T16:15:22Z", 
    "summary": "We exhibit families of $4$-CNF formulas over $n$ variables that have\nsums-of-squares (SOS) proofs of unsatisfiability of degree (a.k.a. rank) $d$\nbut require SOS proofs of size $n^{\\Omega(d)}$ for values of $d = d(n)$ from\nconstant all the way up to $n^{\\delta}$ for some universal constant$\\delta$.\nThis shows that the $n^{O(d)}$ running time obtained by using the Lasserre\nsemidefinite programming relaxations to find degree-$d$ SOS proofs is optimal\nup to constant factors in the exponent. We establish this result by combining\n$\\mathsf{NP}$-reductions expressible as low-degree SOS derivations with the\nidea of relativizing CNF formulas in [Kraj\\'i\\v{c}ek '04] and [Dantchev and\nRiis'03], and then applying a restriction argument as in [Atserias, M\\\"uller,\nand Oliva '13] and [Atserias, Lauria, and Nordstr\\\"om '14]. This yields a\ngeneric method of amplifying SOS degree lower bounds to size lower bounds, and\nalso generalizes the approach in [ALN14] to obtain size lower bounds for the\nproof systems resolution, polynomial calculus, and Sherali-Adams from lower\nbounds on width, degree, and rank, respectively."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.03398v1", 
    "title": "An average-case depth hierarchy theorem for Boolean circuits", 
    "arxiv-id": "1504.03398v1", 
    "author": "Li-Yang Tan", 
    "publish": "2015-04-14T01:44:39Z", 
    "summary": "We prove an average-case depth hierarchy theorem for Boolean circuits over\nthe standard basis of $\\mathsf{AND}$, $\\mathsf{OR}$, and $\\mathsf{NOT}$ gates.\nOur hierarchy theorem says that for every $d \\geq 2$, there is an explicit\n$n$-variable Boolean function $f$, computed by a linear-size depth-$d$ formula,\nwhich is such that any depth-$(d-1)$ circuit that agrees with $f$ on $(1/2 +\no_n(1))$ fraction of all inputs must have size $\\exp({n^{\\Omega(1/d)}}).$ This\nanswers an open question posed by H{\\aa}stad in his Ph.D. thesis.\n  Our average-case depth hierarchy theorem implies that the polynomial\nhierarchy is infinite relative to a random oracle with probability 1,\nconfirming a conjecture of H{\\aa}stad, Cai, and Babai. We also use our result\nto show that there is no \"approximate converse\" to the results of Linial,\nMansour, Nisan and Boppana on the total influence of small-depth circuits, thus\nanswering a question posed by O'Donnell, Kalai, and Hatami.\n  A key ingredient in our proof is a notion of \\emph{random projections} which\ngeneralize random restrictions."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.03923v3", 
    "title": "$2^{(\\log N)^{1/10-o(1)}}$ Hardness for Hypergraph Coloring", 
    "arxiv-id": "1504.03923v3", 
    "author": "Sangxia Huang", 
    "publish": "2015-04-15T14:12:58Z", 
    "summary": "We show that it is quasi-NP-hard to color 2-colorable 8-uniform hypergraphs\nwith $2^{(\\log N)^{1/10-o(1)}}$ colors, where $N$ is the number of vertices.\nThere has been much focus on hardness of hypergraph coloring recently.\nGuruswami, H{\\aa}stad, Harsha, Srinivasan and Varma showed that it is\nquasi-NP-hard to color 2-colorable 8-uniform hypergraphs with\n$2^{2^{\\Omega(\\sqrt{\\log\\log N})}}$ colors. Their result is obtained by\ncomposing standard Label Cover with an inner-verifier based on Low Degree Long\nCode, using Reed-Muller code testing results by Dinur and Guruswami. Using a\ndifferent approach, Khot and Saket constructed a new variant of Label Cover,\nand composed it with Quadratic Code to show quasi-NP-hardness of coloring\n2-colorable 12-uniform hypergraphs with $2^{(\\log N)^c}$ colors, for some $c$\naround 1/20. Their construction of Label Cover is based on a new notion of\nsuperposition complexity for CSP instances. The composition with inner-verifier\nwas subsequently improved by Varma, giving the same hardness result for\n8-uniform hypergraphs.\n  Our construction uses both Quadratic Code and Low Degree Long Code, and\nbuilds upon the work by Khot and Saket. We present a different approach to\nconstruct CSP instances with superposition hardness by observing that when the\nnumber of assignments is odd, satisfying a constraint in superposition is the\nsame as \"odd-covering\" the constraint. We employ Low Degree Long Code in order\nto keep the construction efficient. In the analysis, we also adapt and\ngeneralize one of the key theorems by Dinur and Guruswami in the context of\nanalyzing probabilistically checkable proof systems."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.04675v2", 
    "title": "Pseudorandomness for Read-Once, Constant-Depth Circuits", 
    "arxiv-id": "1504.04675v2", 
    "author": "Salil Vadhan", 
    "publish": "2015-04-18T02:46:29Z", 
    "summary": "For Boolean functions computed by read-once, depth-$D$ circuits with\nunbounded fan-in over the de Morgan basis, we present an explicit pseudorandom\ngenerator with seed length $\\tilde{O}(\\log^{D+1} n)$. The previous best seed\nlength known for this model was $\\tilde{O}(\\log^{D+4} n)$, obtained by Trevisan\nand Xue (CCC `13) for all of $AC^0$ (not just read-once). Our work makes use of\nFourier analytic techniques for pseudorandomness introduced by Reingold,\nSteinke, and Vadhan (RANDOM `13) to show that the generator of Gopalan et al.\n(FOCS `12) fools read-once $AC^0$. To this end, we prove a new Fourier growth\nbound for read-once circuits, namely that for every $F: \\{0,1\\}^n\\to\\{0,1\\}$\ncomputed by a read-once, depth-$D$ circuit,\n\\begin{equation*}\\sum_{s\\subseteq[n], |s|=k}|\\hat{F}[s]|\\le\nO(\\log^{D-1}n)^k,\\end{equation*} where $\\hat{F}$ denotes the Fourier transform\nof $F$ over $\\mathbb{Z}^n_2$."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.05556v2", 
    "title": "On Fortification of Projection Games", 
    "arxiv-id": "1504.05556v2", 
    "author": "Rakesh Venkat", 
    "publish": "2015-04-21T19:09:25Z", 
    "summary": "A recent result of Moshkovitz \\cite{Moshkovitz14} presented an ingenious\nmethod to provide a completely elementary proof of the Parallel Repetition\nTheorem for certain projection games via a construction called fortification.\nHowever, the construction used in \\cite{Moshkovitz14} to fortify arbitrary\nlabel cover instances using an arbitrary extractor is insufficient to prove\nparallel repetition. In this paper, we provide a fix by using a stronger graph\nthat we call fortifiers. Fortifiers are graphs that have both $\\ell_1$ and\n$\\ell_2$ guarantees on induced distributions from large subsets. We then show\nthat an expander with sufficient spectral gap, or a bi-regular extractor with\nstronger parameters (the latter is also the construction used in an independent\nupdate \\cite{Moshkovitz15} of \\cite{Moshkovitz14} with an alternate argument),\nis a good fortifier. We also show that using a fortifier (in particular\n$\\ell_2$ guarantees) is necessary for obtaining the robustness required for\nfortification."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.05653v1", 
    "title": "High rate locally-correctable and locally-testable codes with   sub-polynomial query complexity", 
    "arxiv-id": "1504.05653v1", 
    "author": "Shubhangi Saraf", 
    "publish": "2015-04-22T04:52:50Z", 
    "summary": "In this work, we construct the first locally-correctable codes (LCCs), and\nlocally-testable codes (LTCs) with constant rate, constant relative distance,\nand sub-polynomial query complexity. Specifically, we show that there exist\nbinary LCCs and LTCs with block length $n$, constant rate (which can even be\ntaken arbitrarily close to 1), constant relative distance, and query complexity\n$\\exp(\\tilde{O}(\\sqrt{\\log n}))$. Previously such codes were known to exist\nonly with $\\Omega(n^{\\beta})$ query complexity (for constant $\\beta > 0$), and\nthere were several, quite different, constructions known.\n  Our codes are based on a general distance-amplification method of Alon and\nLuby~\\cite{AL96_codes}. We show that this method interacts well with local\ncorrectors and testers, and obtain our main results by applying it to suitably\nconstructed LCCs and LTCs in the non-standard regime of \\emph{sub-constant\nrelative distance}.\n  Along the way, we also construct LCCs and LTCs over large alphabets, with the\nsame query complexity $\\exp(\\tilde{O}(\\sqrt{\\log n}))$, which additionally have\nthe property of approaching the Singleton bound: they have almost the\nbest-possible relationship between their rate and distance. This has the\nsurprising consequence that asking for a large alphabet error-correcting code\nto further be an LCC or LTC with $\\exp(\\tilde{O}(\\sqrt{\\log n}))$ query\ncomplexity does not require any sacrifice in terms of rate and distance! Such a\nresult was previously not known for any $o(n)$ query complexity.\n  Our results on LCCs also immediately give locally-decodable codes (LDCs) with\nthe same parameters."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.05908v2", 
    "title": "Maximum Pagenumber-k Subgraph is NP-Complete", 
    "arxiv-id": "1504.05908v2", 
    "author": "Marco Kuhlmann", 
    "publish": "2015-04-21T06:36:48Z", 
    "summary": "Given a graph $G$ with a total order defined on its vertices, the Maximum\nPagenumber-$k$ Subgraph Problem asks for a maximum subgraph $G'$ of $G$ such\nthat $G'$ can be embedded into a $k$-book when the vertices are placed on the\nspine according to the specified total order. We show that this problem is\nNP-complete for $k \\geq 2$."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.06213v1", 
    "title": "Sums of products of polynomials in few variables : lower bounds and   polynomial identity testing", 
    "arxiv-id": "1504.06213v1", 
    "author": "Shubhangi Saraf", 
    "publish": "2015-04-23T15:02:44Z", 
    "summary": "We study the complexity of representing polynomials as a sum of products of\npolynomials in few variables. More precisely, we study representations of the\nform $$P = \\sum_{i = 1}^T \\prod_{j = 1}^d Q_{ij}$$ such that each $Q_{ij}$ is\nan arbitrary polynomial that depends on at most $s$ variables. We prove the\nfollowing results.\n  1. Over fields of characteristic zero, for every constant $\\mu$ such that $0\n\\leq \\mu < 1$, we give an explicit family of polynomials $\\{P_{N}\\}$, where\n$P_{N}$ is of degree $n$ in $N = n^{O(1)}$ variables, such that any\nrepresentation of the above type for $P_{N}$ with $s = N^{\\mu}$ requires $Td\n\\geq n^{\\Omega(\\sqrt{n})}$. This strengthens a recent result of Kayal and Saha\n[KS14a] which showed similar lower bounds for the model of sums of products of\nlinear forms in few variables. It is known that any asymptotic improvement in\nthe exponent of the lower bounds (even for $s = \\sqrt{n}$) would separate VP\nand VNP[KS14a].\n  2. We obtain a deterministic subexponential time blackbox polynomial identity\ntesting (PIT) algorithm for circuits computed by the above model when $T$ and\nthe individual degree of each variable in $P$ are at most $\\log^{O(1)} N$ and\n$s \\leq N^{\\mu}$ for any constant $\\mu < 1/2$. We get quasipolynomial running\ntime when $s < \\log^{O(1)} N$. The PIT algorithm is obtained by combining our\nlower bounds with the hardness-randomness tradeoffs developed in [DSY09, KI04].\nTo the best of our knowledge, this is the first nontrivial PIT algorithm for\nthis model (even for the case $s=2$), and the first nontrivial PIT algorithm\nobtained from lower bounds for small depth circuits."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.06602v1", 
    "title": "The Range of Topological Effects on Communication", 
    "arxiv-id": "1504.06602v1", 
    "author": "Atri Rudra", 
    "publish": "2015-04-24T19:12:30Z", 
    "summary": "We continue the study of communication cost of computing functions when\ninputs are distributed among $k$ processors, each of which is located at one\nvertex of a network/graph called a terminal. Every other node of the network\nalso has a processor, with no input. The communication is point-to-point and\nthe cost is the total number of bits exchanged by the protocol, in the worst\ncase, on all edges.\n  Chattopadhyay, Radhakrishnan and Rudra (FOCS'14) recently initiated a study\nof the effect of topology of the network on the total communication cost using\ntools from $L_1$ embeddings. Their techniques provided tight bounds for simple\nfunctions like Element-Distinctness (ED), which depend on the 1-median of the\ngraph. This work addresses two other kinds of natural functions. We show that\nfor a large class of natural functions like Set-Disjointness the communication\ncost is essentially $n$ times the cost of the optimal Steiner tree connecting\nthe terminals. Further, we show for natural composed functions like $\\text{ED}\n\\circ \\text{XOR}$ and $\\text{XOR} \\circ \\text{ED}$, the naive protocols\nsuggested by their definition is optimal for general networks. Interestingly,\nthe bounds for these functions depend on more involved topological parameters\nthat are a combination of Steiner tree and 1-median costs.\n  To obtain our results, we use some new tools in addition to ones used in\nChattopadhyay et. al. These include (i) viewing the communication constraints\nvia a linear program; (ii) using tools from the theory of tree embeddings to\nprove topology sensitive direct sum results that handle the case of composed\nfunctions and (iii) representing the communication constraints of certain\nproblems as a family of collection of multiway cuts, where each multiway cut\nsimulates the hardness of computing the function on the star topology."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.06731v1", 
    "title": "Lower Bounds for the Size of Nondeterministic Circuits", 
    "arxiv-id": "1504.06731v1", 
    "author": "Hiroki Morizumi", 
    "publish": "2015-04-25T14:32:56Z", 
    "summary": "Nondeterministic circuits are a nondeterministic computation model in circuit\ncomplexity theory. In this paper, we prove a $3(n-1)$ lower bound for the size\nof nondeterministic $U_2$-circuits computing the parity function. It is known\nthat the minimum size of (deterministic) $U_2$-circuits computing the parity\nfunction exactly equals $3(n-1)$. Thus, our result means that nondeterministic\ncomputation is useless to compute the parity function by $U_2$-circuits and\ncannot reduce the size from $3(n-1)$. To the best of our knowledge, this is the\nfirst nontrivial lower bound for the size of nondeterministic circuits\n(including formulas, constant depth circuits, and so on) with unlimited\nnondeterminism for an explicit Boolean function. We also discuss an approach to\nproving lower bounds for the size of deterministic circuits via lower bounds\nfor the size of nondeterministic restricted circuits."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.06830v1", 
    "title": "Information Complexity and the Quest for Interactive Compression (A   Survey)", 
    "arxiv-id": "1504.06830v1", 
    "author": "Omri Weinstein", 
    "publish": "2015-04-26T14:30:05Z", 
    "summary": "Information complexity is the interactive analogue of Shannon's classical\ninformation theory. In recent years this field has emerged as a powerful tool\nfor proving strong communication lower bounds, and for addressing some of the\nmajor open problems in communication complexity and circuit complexity. A\nnotable achievement of information complexity is the breakthrough in\nunderstanding of the fundamental direct sum and direct product conjectures,\nwhich aim to quantify the power of parallel computation. This survey provides a\nbrief introduction to information complexity, and overviews some of the recent\nprogress on these conjectures and their tight relationship with the fascinating\nproblem of compressing interactive protocols."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.06890v1", 
    "title": "A Refutation of the Clique-Based P=NP Proofs of LaPlante and   Tamta-Pande-Dhami", 
    "arxiv-id": "1504.06890v1", 
    "author": "Nathaniel S. Potrepka", 
    "publish": "2015-04-26T22:51:32Z", 
    "summary": "In this work, we critique two papers, \"A Polynomial-Time Solution to the\nClique Problem\" by Tamta, Pande, and Dhami, and \"A Polynomial-Time Algorithm\nFor Solving Clique Problems\" by LaPlante. We summarize and analyze both papers,\nnoting that the algorithms presented in both papers are flawed. We conclude\nthat neither author has successfully established that P = NP."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.08352v1", 
    "title": "ETH Hardness for Densest-$k$-Subgraph with Perfect Completeness", 
    "arxiv-id": "1504.08352v1", 
    "author": "Omri Weinstein", 
    "publish": "2015-04-30T19:31:16Z", 
    "summary": "We show that, assuming the (deterministic) Exponential Time Hypothesis,\ndistinguishing between a graph with an induced $k$-clique and a graph in which\nall k-subgraphs have density at most $1-\\epsilon$, requires $n^{\\tilde\n\\Omega(log n)}$ time. Our result essentially matches the quasi-polynomial\nalgorithms of Feige and Seltser [FS97] and Barman [Bar15] for this problem, and\nis the first one to rule out an additive PTAS for Densest $k$-Subgraph. We\nfurther strengthen this result by showing that our lower bound continues to\nhold when, in the soundness case, even subgraphs smaller by a near-polynomial\nfactor ($k' = k 2^{-\\tilde \\Omega (log n)}$) are assumed to be at most\n($1-\\epsilon$)-dense.\n  Our reduction is inspired by recent applications of the \"birthday repetition\"\ntechnique [AIM14,BKW15]. Our analysis relies on information theoretical\nmachinery and is similar in spirit to analyzing a parallel repetition of\ntwo-prover games in which the provers may choose to answer some challenges\nmultiple times, while completely ignoring other challenges."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1504.08361v3", 
    "title": "Rational Proofs with Multiple Provers", 
    "arxiv-id": "1504.08361v3", 
    "author": "Shikha Singh", 
    "publish": "2015-04-30T19:44:10Z", 
    "summary": "Interactive proofs model a world where a verifier delegates computation to an\nuntrustworthy prover, verifying the prover's claims before accepting them.\nRational proofs, introduced by Azar and Micali (STOC 2012), are an interactive\nproof model in which the prover is rational rather than untrustworthy---he may\nlie, but only to increase his payment (received from the verifier). This allows\nthe verifier to leverage the greed of the prover to obtain better protocols:\nwhile rational proofs are no more powerful than interactive proofs, the\nprotocols are simpler and more efficient. Azar and Micali posed as an open\nproblem whether multiple provers are more powerful than one for rational\nproofs.\n  We provide a model that extends rational proofs to allow multiple provers. In\nthis model, a verifier can crosscheck the answers received by asking several\nprovers. The verifier can pay the provers according to the quality of their\nwork, incentivizing them to provide correct information.\n  We analyze rational proofs with multiple provers from a complexity-theoretic\npoint of view. We fully characterize this model by giving tight upper and lower\nbounds on its power. On the way, we resolve Azar and Micali's open problem in\nthe affirmative, showing that multiple rational provers are strictly more\npowerful than one (under standard complexity-theoretic assumptions). We further\nshow that the full power of rational proofs with multiple provers can be\nachieved using only two provers and five rounds of interaction. Finally, we\nconsider more demanding models where the verifier wants the provers' payment to\ndecrease significantly when they are lying, and fully characterize the power of\nthe model when the payment gap must be noticeable (i.e., at least 1/p where p\nis a polynomial)."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1505.00058v1", 
    "title": "Transforming NP to P: An Approach to Solve NP Complete Problems", 
    "arxiv-id": "1505.00058v1", 
    "author": "Yaqiu Jiang", 
    "publish": "2015-04-28T18:27:10Z", 
    "summary": "NP complete problem is one of the most challenging issues. The question of\nwhether all problems in NP are also in P is generally considered one of the\nmost important open questions in mathematics and theoretical computer science\nas it has far-reaching consequences to other problems in mathematics, computer\nscience, biology, philosophy and cryptography. There are intensive research on\nproving `NP not equal to P' and `NP equals to P'. However, none of the `proved'\nresults is commonly accepted by the research community up to now. In this\npaper, instead of proving either one, we aim to provide new perspective:\ntransforming two typical NP complete problems to exactly solvable P problems in\npolynomial time. This approach helps to solve originally NP complete problems\nwith practical applications. It may shine light on solving other NP complete\nproblems in similar way."
},{
    "category": "cs.CC", 
    "doi": "10.4230/LIPIcs.APPROX-RANDOM.2015.915", 
    "link": "http://arxiv.org/pdf/1505.00090v1", 
    "title": "Finding the Median (Obliviously) with Bounded Space", 
    "arxiv-id": "1505.00090v1", 
    "author": "Mihai P\u01cetra\u015fcu", 
    "publish": "2015-05-01T05:12:23Z", 
    "summary": "We prove that any oblivious algorithm using space $S$ to find the median of a\nlist of $n$ integers from $\\{1,...,2n\\}$ requires time $\\Omega(n \\log\\log_S\nn)$. This bound also applies to the problem of determining whether the median\nis odd or even. It is nearly optimal since Chan, following Munro and Raman, has\nshown that there is a (randomized) selection algorithm using only $s$\nregisters, each of which can store an input value or $O(\\log n)$-bit counter,\nthat makes only $O(\\log\\log_s n)$ passes over the input. The bound also implies\na size lower bound for read-once branching programs computing the low order bit\nof the median and implies the analog of $P \\ne NP \\cap coNP$ for length $o(n\n\\log\\log n)$ oblivious branching programs."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1505.01340v1", 
    "title": "Universality and Almost Decidability", 
    "arxiv-id": "1505.01340v1", 
    "author": "Damien Desfontaines", 
    "publish": "2015-05-06T12:32:07Z", 
    "summary": "We present and study new definitions of universal and programmable universal\nunary functions and consider a new simplicity criterion: almost decidability of\nthe halting set. A set of positive integers S is almost decidable if there\nexists a decidable and generic (i.e. a set of natural density one) set whose\nintersection with S is decidable. Every decidable set is almost decidable, but\nthe converse implication is false. We prove the existence of infinitely many\nuniversal functions whose halting sets are generic (negligible, i.e. have\ndensity zero) and (not) almost decidable. One result - namely, the existence of\ninfinitely many universal functions whose halting sets are generic (negligible)\nand not almost decidable - solves an open problem in [9]. We conclude with some\nopen problems."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1505.04969v1", 
    "title": "Average-case complexity of a branch-and-bound algorithm for maximum   independent set, under the $\\mathcal{G}(n,p)$ random model", 
    "arxiv-id": "1505.04969v1", 
    "author": "V. Th. Paschos", 
    "publish": "2015-05-19T12:40:31Z", 
    "summary": "We study average-case complexity of branch-and-bound for maximum independent\nset in random graphs under the $\\mathcal{G}(n,p)$ distribution. In this model\nevery pair $(u,v)$ of vertices belongs to $E$ with probability $p$\nindependently on the existence of any other edge. We make a precise case\nanalysis, providing phase transitions between subexponential and exponential\ncomplexities depending on the probability $p$ of the random model."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1505.06025v1", 
    "title": "Incremental complexity of a bi-objective hypergraph transversal problem", 
    "arxiv-id": "1505.06025v1", 
    "author": "Marie-France Sagot", 
    "publish": "2015-05-22T11:06:52Z", 
    "summary": "The hypergraph transversal problem has been intensively studied, from both a\ntheoretical and a practical point of view. In particular , its incremental\ncomplexity is known to be quasi-polynomial in general and polynomial for\nbounded hypergraphs. Recent applications in computational biology however\nrequire to solve a generalization of this problem, that we call bi-objective\ntransversal problem. The instance is in this case composed of a pair of\nhypergraphs (A, B), and the aim is to find minimal sets which hit all the\nhyperedges of A while intersecting a minimal set of hyperedges of B. In this\npaper, we formalize this problem, link it to a problem on monotone boolean\n$\\land$ -- $\\lor$ formulae of depth 3 and study its incremental complexity."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1505.06362v1", 
    "title": "Polynomially Low Error PCPs with polyloglog n Queries via Modular   Composition", 
    "arxiv-id": "1505.06362v1", 
    "author": "Guy Kindler", 
    "publish": "2015-05-23T18:56:33Z", 
    "summary": "We show that every language in NP has a PCP verifier that tosses $O(\\log n)$\nrandom coins, has perfect completeness, and a soundness error of at most\n$1/\\text{poly}(n)$, while making at most $O(\\text{poly}\\log\\log n)$ queries\ninto a proof over an alphabet of size at most $n^{1/\\text{poly}\\log\\log n}$.\nPrevious constructions that obtain $1/\\text{poly}(n)$ soundness error used\neither $\\text{poly}\\log n $ queries or an exponential sized alphabet, i.e. of\nsize $2^{n^c}$ for some $c>0$. Our result is an exponential improvement in both\nparameters simultaneously.\n  Our result can be phrased as a polynomial-gap hardness for approximate CSPs\nwith arity $\\text{poly}\\log\\log n$ and alphabet size $n^{1/\\text{poly}\\log n}$.\nThe ultimate goal, in this direction, would be to prove polynomial hardness for\nCSPs with constant arity and polynomial alphabet size (aka the sliding scale\nconjecture for inverse polynomial soundness error).\n  Our construction is based on a modular generalization of previous PCP\nconstructions in this parameter regime, which involves a composition theorem\nthat uses an extra `consistency' query but maintains the inverse polynomial\nrelation between the soundness error and the alphabet size.\n  Our main technical/conceptual contribution is a new notion of soundness,\nwhich we refer to as {\\em distributional soundness}, that replaces the previous\nnotion of \"list decoding soundness\", and that allows us to prove a modular\ncomposition theorem with tighter parameters. This new notion of soundness\nallows us to invoke composition a super-constant number of times without\nincurring a blow-up in the soundness error."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1505.07416v2", 
    "title": "Combinatorial Game Complexity: An Introduction with Poset Games", 
    "arxiv-id": "1505.07416v2", 
    "author": "John Rogers", 
    "publish": "2015-05-27T17:49:10Z", 
    "summary": "Poset games have been the object of mathematical study for over a century,\nbut little has been written on the computational complexity of determining\nimportant properties of these games. In this introduction we develop the\nfundamentals of combinatorial game theory and focus for the most part on poset\ngames, of which Nim is perhaps the best-known example. We present the\ncomplexity results known to date, some discovered very recently."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.00479v1", 
    "title": "Constraint Satisfaction and Semilinear Expansions of Addition over the   Rationals and the Reals", 
    "arxiv-id": "1506.00479v1", 
    "author": "Johan Thapper", 
    "publish": "2015-06-01T12:53:56Z", 
    "summary": "A semilinear relation is a finite union of finite intersections of open and\nclosed half-spaces over, for instance, the reals, the rationals, or the\nintegers. Semilinear relations have been studied in connection with algebraic\ngeometry, automata theory, and spatiotemporal reasoning. We consider semilinear\nrelations over the rationals and the reals. Under this assumption, the\ncomputational complexity of the constraint satisfaction problem (CSP) is known\nfor all finite sets containing R+={(x,y,z) | x+y=z}, <=, and {1}. These\nproblems correspond to expansions of the linear programming feasibility\nproblem. We generalise this result and fully determine the complexity for all\nfinite sets of semilinear relations containing R+. This is accomplished in part\nby introducing an algorithm, based on computing affine hulls, which solves a\nnew class of semilinear CSPs in polynomial time. We further analyse the\ncomplexity of linear optimisation over the solution set and the existence of\ninteger solutions."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.00617v2", 
    "title": "On Slepian--Wolf Theorem with Interaction", 
    "arxiv-id": "1506.00617v2", 
    "author": "Alexander Kozachinskiy", 
    "publish": "2015-06-01T19:25:43Z", 
    "summary": "In this paper we study interactive \"one-shot\" analogues of the classical\nSlepian-Wolf theorem. Alice receives a value of a random variable $X$, Bob\nreceives a value of another random variable $Y$ that is jointly distributed\nwith $X$. Alice's goal is to transmit $X$ to Bob (with some error probability\n$\\varepsilon$). Instead of one-way transmission, which is studied in the\nclassical coding theory, we allow them to interact. They may also use shared\nrandomness.\n  We show, that Alice can transmit $X$ to Bob in expected $H(X|Y) +\n2\\sqrt{H(X|Y)} + O(\\log_2\\left(\\frac{1}{\\varepsilon}\\right))$ number of bits.\nMoreover, we show that every one-round protocol $\\pi$ with information\ncomplexity $I$ can be compressed to the (many-round) protocol with expected\ncommunication about $I + 2\\sqrt{I}$ bits. This improves a result by Braverman\nand Rao \\cite{braverman2011information}, where they had $5\\sqrt{I}$. Further,\nwe show how to solve this problem (transmitting $X$) using $3H(X|Y) +\nO(\\log_2\\left(\\frac{1}{\\varepsilon}\\right))$ bits and $4$ rounds on average.\nThis improves a result of~\\cite{brody2013towards}, where they had $4H(X|Y) +\nO(\\log1/\\varepsilon)$ bits and 10 rounds on average.\n  In the end of the paper we discuss how many bits Alice and Bob may need to\ncommunicate on average besides $H(X|Y)$. The main question is whether the upper\nbounds mentioned above are tight. We provide an example of $(X, Y)$, such that\ntransmission of $X$ from Alice to Bob with error probability $\\varepsilon$\nrequires $H(X|Y) + \\Omega\\left(\\log_2\\left(\\frac{1}{\\varepsilon}\\right)\\right)$\nbits on average."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.01083v1", 
    "title": "Dependent Random Graphs and Multiparty Pointer Jumping", 
    "arxiv-id": "1506.01083v1", 
    "author": "Mario Sanchez", 
    "publish": "2015-06-02T23:08:16Z", 
    "summary": "We initiate a study of a relaxed version of the standard Erdos-Renyi random\ngraph model, where each edge may depend on a few other edges. We call such\ngraphs \"dependent random graphs\". Our main result in this direction is a\nthorough understanding of the clique number of dependent random graphs. We also\nobtain bounds for the chromatic number. Surprisingly, many of the standard\nproperties of random graphs also hold in this relaxed setting. We show that\nwith high probability, a dependent random graph will contain a clique of size\n$\\frac{(1-o(1))\\log n}{\\log(1/p)}$, and the chromatic number will be at most\n$\\frac{n \\log(1/1-p)}{\\log n}$.\n  As an application and second main result, we give a new communication\nprotocol for the k-player Multiparty Pointer Jumping (MPJ_k) problem in the\nnumber-on-the-forehead (NOF) model. Multiparty Pointer Jumping is one of the\ncanonical NOF communication problems, yet even for three players, its\ncommunication complexity is not well understood. Our protocol for MPJ_3 costs\n$O(\\frac{n\\log\\log n}{\\log n})$ communication, improving on a bound of Brody\nand Chakrabarti [BC08]. We extend our protocol to the non-Boolean pointer\njumping problem $\\widehat{MPJ}_k$, achieving an upper bound which is o(n) for\nany $k >= 4$ players. This is the first o(n) bound for $\\widehat{MPJ}_k$ and\nimproves on a bound of Damm, Jukna, and Sgall [DJS98] which has stood for\nalmost twenty years."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.01652v2", 
    "title": "Polynomial Fixed-Parameter Algorithms: A Case Study for Longest Path on   Interval Graphs", 
    "arxiv-id": "1506.01652v2", 
    "author": "Rolf Niedermeier", 
    "publish": "2015-06-04T16:49:35Z", 
    "summary": "We study the design of fixed-parameter algorithms for problems already known\nto be solvable in polynomial time. The main motivation is to get more efficient\nalgorithms for problems with unattractive polynomial running times. Here, we\nfocus on a fundamental graph problem: Longest Path, that is, given an\nundirected graph, find a maximum-length path in $G$. Longest Path is NP-hard in\ngeneral but known to be solvable in $O(n^4)$ time on $n$-vertex interval\ngraphs. We show how to solve Longest Path on Interval Graphs, parameterized by\nvertex deletion number $k$ to proper interval graphs, in $O(k^{9} n)$ time.\nNotably, Longest Path is trivially solvable in linear time on proper interval\ngraphs, and the parameter value $k$ can be approximated up to a factor of 4 in\nlinear time. From a more general perspective, we believe that using\nparameterized complexity analysis may enable a refined understanding of\nefficiency aspects for polynomial-time solvable problems similarly to what\nclassical parameterized complexity analysis does for NP-hard problems."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.02936v3", 
    "title": "Parity Decision Tree Complexity and 4-Party Communication Complexity of   XOR-functions Are Polynomially Equivalent", 
    "arxiv-id": "1506.02936v3", 
    "author": "Penghui Yao", 
    "publish": "2015-06-09T14:42:20Z", 
    "summary": "In this note, we study the relation between the parity decision tree\ncomplexity of a boolean function $f$, denoted by $\\mathrm{D}_{\\oplus}(f)$, and\nthe $k$-party number-in-hand multiparty communication complexity of the XOR\nfunctions $F(x_1,\\ldots, x_k)= f(x_1\\oplus\\cdots\\oplus x_k)$, denoted by\n$\\mathrm{CC}^{(k)}(F)$. It is known that $\\mathrm{CC}^{(k)}(F)\\leq\nk\\cdot\\mathrm{D}_{\\oplus}(f)$ because the players can simulate the parity\ndecision tree that computes $f$. In this note, we show that\n\\[\\mathrm{D}_{\\oplus}(f)\\leq O\\big(\\mathrm{CC}^{(4)}(F)^5\\big).\\] Our main tool\nis a recent result from additive combinatorics due to Sanders. As\n$\\mathrm{CC}^{(k)}(F)$ is non-decreasing as $k$ grows, the parity decision tree\ncomplexity of $f$ and the communication complexity of the corresponding\n$k$-argument XOR functions are polynomially equivalent whenever $k\\geq 4$.\n  Remark: After the first version of this paper was finished, we discovered\nthat Hatami and Lovett had already discovered the same result a few years ago,\nwithout writing it up."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.04184v1", 
    "title": "Max-Closed Semilinear Constraint Satisfaction", 
    "arxiv-id": "1506.04184v1", 
    "author": "Marcello Mamino", 
    "publish": "2015-06-12T21:13:03Z", 
    "summary": "A semilinear relation S is max-closed if it is preserved by taking the\ncomponentwise maximum. The constraint satisfaction problem for max-closed\nsemilinear constraints is at least as hard as determining the winner in Mean\nPayoff Games, a notorious problem of open computational complexity. Mean Payoff\nGames are known to be in the intersection of NP and co-NP, which is not known\nfor max-closed semilinear constraints. Semilinear relations that are max-closed\nand additionally closed under translations have been called tropically convex\nin the literature. One of our main results is a new duality for open tropically\nconvex relations, which puts the CSP for tropically convex semilinaer\nconstraints in general into NP intersected co-NP. This extends the\ncorresponding complexity result for and-or precedence constraints aka the\nmax-atoms problem. To this end, we present a characterization of max-closed\nsemilinear relations in terms of syntactically restricted first-order logic,\nand another characterization in terms of a finite set of relations L that allow\nprimitive positive definitions of all other relations in the class. We also\npresent a subclass of max-closed constraints where the CSP is in P; this class\ngeneralizes the class of max-closed constraints over finite domains, and the\nfeasibility problem for max-closed linear inequalities. Finally, we show that\nthe class of max-closed semilinear constraints is maximal in the sense that as\nsoon as a single relation that is not max-closed is added to L, the CSP becomes\nNP-hard."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.04350v2", 
    "title": "Pseudorandomness via the discrete Fourier transform", 
    "arxiv-id": "1506.04350v2", 
    "author": "Raghu Meka", 
    "publish": "2015-06-14T04:49:43Z", 
    "summary": "We present a new approach to constructing unconditional pseudorandom\ngenerators against classes of functions that involve computing a linear\nfunction of the inputs. We give an explicit construction of a pseudorandom\ngenerator that fools the discrete Fourier transforms of linear functions with\nseed-length that is nearly logarithmic (up to polyloglog factors) in the input\nsize and the desired error parameter. Our result gives a single pseudorandom\ngenerator that fools several important classes of tests computable in logspace\nthat have been considered in the literature, including halfspaces (over general\ndomains), modular tests and combinatorial shapes. For all these classes, our\ngenerator is the first that achieves near logarithmic seed-length in both the\ninput length and the error parameter. Getting such a seed-length is a natural\nchallenge in its own right, which needs to be overcome in order to derandomize\nRL - a central question in complexity theory.\n  Our construction combines ideas from a large body of prior work, ranging from\na classical construction of [NN93] to the recent gradually increasing\nindependence paradigm of [KMN11, CRSW13, GMRTV12], while also introducing some\nnovel analytic machinery which might find other applications."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.04882v1", 
    "title": "The Complexity of the Path-following Solutions of Two-dimensional   Sperner/Brouwer Functions", 
    "arxiv-id": "1506.04882v1", 
    "author": "Paul W. Goldberg", 
    "publish": "2015-06-16T09:08:50Z", 
    "summary": "There are a number of results saying that for certain \"path-following\"\nalgorithms that solve PPAD-complete problems, the solution obtained by the\nalgorithm is PSPACE-complete to compute. We conjecture that these results are\nspecial cases of a much more general principle, that all such algorithms\ncompute PSPACE-complete solutions. Such a general result might shed new light\non the complexity class PPAD.\n  In this paper we present a new PSPACE-completeness result for an interesting\nchallenge instance for this conjecture. Chen and Deng~\\cite{CD} showed that it\nis PPAD-complete to find a trichromatic triangle in a concisely-represented\nSperner triangulation. The proof of Sperner's lemma --- that such a solution\nalways exists --- identifies one solution in particular, that is found via a\nnatural \"path-following\" approach. Here we show that it is PSPACE-complete to\ncompute this specific solution, together with a similar result for the\ncomputation of the path-following solution of two-dimensional discrete Brouwer\nfunctions."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.05079v2", 
    "title": "All Permutations Supersequence is coNP-complete", 
    "arxiv-id": "1506.05079v2", 
    "author": "Przemys\u0142aw Uzna\u0144ski", 
    "publish": "2015-06-16T19:12:08Z", 
    "summary": "We prove that deciding whether a given input word contains as subsequence\nevery possible permutation of integers $\\{1,2,\\ldots,n\\}$ is coNP-complete. The\ncoNP-completeness holds even when given the guarantee that the input word\ncontains as subsequences all of length $n-1$ sequences over the same set of\nintegers. We also show NP-completeness of a related problem of Partially\nNon-crossing Perfect Matching in Bipartite Graphs, i.e. to find a perfect\nmatching in an ordered bipartite graph where edges of the matching incident to\nselected vertices (even only from one side) are non-crossing."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.06399v2", 
    "title": "Towards Better Separation between Deterministic and Randomized Query   Complexity", 
    "arxiv-id": "1506.06399v2", 
    "author": "Swagato Sanyal", 
    "publish": "2015-06-21T18:36:24Z", 
    "summary": "We show that there exists a Boolean function $F$ which observes the following\nseparations among deterministic query complexity $(D(F))$, randomized zero\nerror query complexity $(R_0(F))$ and randomized one-sided error query\ncomplexity $(R_1(F))$: $R_1(F) = \\widetilde{O}(\\sqrt{D(F)})$ and\n$R_0(F)=\\widetilde{O}(D(F))^{3/4}$. This refutes the conjecture made by Saks\nand Wigderson that for any Boolean function $f$,\n$R_0(f)=\\Omega({D(f)})^{0.753..}$. This also shows widest separation between\n$R_1(f)$ and $D(f)$ for any Boolean function. The function $F$ was defined by\nG{\\\"{o}}{\\\"{o}}s, Pitassi and Watson who studied it for showing a separation\nbetween deterministic decision tree complexity and unambiguous\nnon-deterministic decision tree complexity. Independently of us, Ambainis et al\nproved that different variants of the function $F$ certify optimal (quadratic)\nseparation between $D(f)$ and $R_0(f)$, and polynomial separation between\n$R_0(f)$ and $R_1(f)$. Viewed as separation results, our results are subsumed\nby those of Ambainis et al. However, while the functions considerd in the work\nof Ambainis et al are different variants of $F$, we work with the original\nfunction $F$ itself."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.06456v1", 
    "title": "An $O(n^{0.4732})$ upper bound on the complexity of the GKS   communication game", 
    "arxiv-id": "1506.06456v1", 
    "author": "Mario Szegedy", 
    "publish": "2015-06-22T03:57:07Z", 
    "summary": "We give an $5\\cdot n^{\\log_{30}5}$ upper bund on the complexity of the\ncommunication game introduced by G. Gilmer, M. Kouck\\'y and M. Saks \\cite{saks}\nto study the Sensitivity Conjecture \\cite{linial}, improving on their\n$\\sqrt{999\\over 1000}\\sqrt{n}$ bound. We also determine the exact complexity of\nthe game up to $n\\le 9$."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.06540v2", 
    "title": "Hybrid (V)CSPs and algebraic reductions", 
    "arxiv-id": "1506.06540v2", 
    "author": "Rustem Takhanov", 
    "publish": "2015-06-22T10:29:46Z", 
    "summary": "Constraint Satisfaction Problem (CSP) can be stated as computing a\nhomomorphism $\\mbox{$\\bR \\rightarrow \\bGamma$}$ between two relational\nstructures, e.g.\\ between two directed graphs.\n  Recently, the {\\em hybrid} setting, where both sides are restricted\nsimultaneously, attracted some attention. It assumes that the right side\nstructure $\\bGamma$ is fixed and $\\bR$ belongs to a class of relational\nstructures $\\mathcal{H}$ (called a {\\em structural restriction}) that is,\nadditionally, {\\em closed under inverse homomorphisms}. The key tool that\nconnects hybrid CSPs with fixed-template CSPs is a construction called a\n\"lifted language,\" namely a multi-sorted language $\\bGamma_{\\bR}$ that can be\nconstructed from an input $\\bR$. The tractability of a language $\\bGamma_{\\bR}$\nfor any input $\\bR\\in\\mathcal{H}$ is a necessary condition for tractability of\nthe hybrid problem.\n  First we investigate the case when the last property is not only necessary,\nbut also is sufficient. It turns out that in the latter case, if\nBulatov-Jeavons-Krokhin characterization of tractable constraint languages is\ncorrect, a structural restriction $\\mathcal{H}$ is tractable if and only if it\nconsists of structures that can be homomorphically mapped to some fixed finite\nrelational structure $\\bGamma'$ (that depends only on $\\bGamma$).\n  In the second part we generalize the construction of $\\bGamma'$ and introduce\na finite structure $\\bGamma^{\\mathfrak{B}}$, indexed by some set of finite\nalgebras $\\mathfrak{B}$. We prove that under some natural conditions on\n$\\mathfrak{B}$, $\\textsc{CSP}(\\bGamma)$ is polynomial-time Turing reducible to\n$\\textsc{CSP}(\\bGamma^{\\mathfrak{B}})$ and some polymorphisms of $\\bGamma$ have\nanalogs in $\\pol(\\bGamma^{\\mathfrak{B}})$. This construction introduce a new\nset of algorithms for fixed-template CSPs and we suggest it as a tool to\napproach Feder-Vardi dichotomy conjecture."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.07204v1", 
    "title": "Complexity of a Tetris variant", 
    "arxiv-id": "1506.07204v1", 
    "author": "Oscar Temprano", 
    "publish": "2015-06-23T21:46:11Z", 
    "summary": "In this paper we are going to solve an open problem about the game tetris. We\nare going to give the first results in the complexity of a variant of offline\ntetris introduced by Erik Demaine, Susan Hohenberger and David Liben Nowell in\ntheir paper \"Tetris is hard, even to approximate\". In this variant, that\nfollows a model of movements introduced by John Brzustowsky, we can move and\nrotate a piece the number of times we want in the first row. But then, when we\nleft the piece fall, we cannot move it or rotate it anymore. We are going to\ndemonstrate that the problem of maximizing the number of cleared lines of this\nvariant on a particular game board, is NP-hard by reducing the 3-partition\nproblem to the problem of clearing the board in this variant of tetris"
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.07260v1", 
    "title": "Algorithmic Aspects of Upper Domination", 
    "arxiv-id": "1506.07260v1", 
    "author": "Vangelis Th. Paschos", 
    "publish": "2015-06-24T07:19:16Z", 
    "summary": "In this paper we study combinatorial and algorithmic resp. complexity\nquestions of upper domination, i.e., the maximum cardinality of a minimal\ndominating set in a graph. We give a full classification of the related\nmaximisation and minimisation problems, as well as the related parameterised\nproblems, on general graphs and on graphs of bounded degree, and we also study\nplanar graphs."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1506.08311v2", 
    "title": "On the H-Free Extension Complexity of the TSP", 
    "arxiv-id": "1506.08311v2", 
    "author": "Hans Raj Tiwary", 
    "publish": "2015-06-27T16:56:56Z", 
    "summary": "It is known that the extension complexity of the TSP polytope for the\ncomplete graph $K_n$ is exponential in $n$ even if the subtour inequalities are\nexcluded. In this article we study the polytopes formed by removing other\nsubsets $\\mathcal{H}$ of facet-defining inequalities of the TSP polytope. In\nparticular, we consider the case when $\\mathcal{H}$ is either the set of\nblossom inequalities or the simple comb inequalities. These inequalities are\nroutinely used in cutting plane algorithms for the TSP. We show that the\nextension complexity remains exponential even if we exclude these inequalities.\nIn addition we show that the extension complexity of polytope formed by all\ncomb inequalities is exponential. For our proofs, we introduce a subclass of\ncomb inequalities, called $(h,t)$-uniform inequalities, which may be of\nindependent interest."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.00026v3", 
    "title": "On the Communication Complexity of Distributed Clustering", 
    "arxiv-id": "1507.00026v3", 
    "author": "Qin Zhang", 
    "publish": "2015-06-30T20:29:01Z", 
    "summary": "In this paper we give a first set of communication lower bounds for\ndistributed clustering problems, in particular, for k-center, k-median and\nk-means. When the input is distributed across a large number of machines and\nthe number of clusters k is small, our lower bounds match the current best\nupper bounds up to a logarithmic factor. We have designed a new composition\nframework in our proofs for multiparty number-in-hand communication complexity\nwhich may be of independent interest."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.00177v1", 
    "title": "An exponential lower bound for homogeneous depth-5 circuits over finite   fields", 
    "arxiv-id": "1507.00177v1", 
    "author": "Ramprasad Saptharishi", 
    "publish": "2015-07-01T10:39:47Z", 
    "summary": "In this paper, we show exponential lower bounds for the class of homogeneous\ndepth-$5$ circuits over all small finite fields. More formally, we show that\nthere is an explicit family $\\{P_d : d \\in \\mathbb{N}\\}$ of polynomials in\n$\\mathsf{VNP}$, where $P_d$ is of degree $d$ in $n = d^{O(1)}$ variables, such\nthat over all finite fields $\\mathbb{F}_q$, any homogeneous depth-$5$ circuit\nwhich computes $P_d$ must have size at least $\\exp(\\Omega_q(\\sqrt{d}))$.\n  To the best of our knowledge, this is the first super-polynomial lower bound\nfor this class for any field $\\mathbb{F}_q \\neq \\mathbb{F}_2$.\n  Our proof builds up on the ideas developed on the way to proving lower bounds\nfor homogeneous depth-$4$ circuits [GKKS13, FLMS13, KLSS14, KS14] and for\nnon-homogeneous depth-$3$ circuits over finite fields [GK98, GR00]. Our key\ninsight is to look at the space of shifted partial derivatives of a polynomial\nas a space of functions from $\\mathbb{F}_q^n \\rightarrow \\mathbb{F}_q$ as\nopposed to looking at them as a space of formal polynomials and builds over a\ntighter analysis of the lower bound of Kumar and Saraf [KS14]."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.01776v1", 
    "title": "A Reduction from Valued CSP to Min Cost Homomorphism Problem for   Digraphs", 
    "arxiv-id": "1507.01776v1", 
    "author": "Andrei Krokhin", 
    "publish": "2015-07-07T12:23:23Z", 
    "summary": "In a valued constraint satisfaction problem (VCSP), the goal is to find an\nassignment of labels to variables that minimizes a given sum of functions. Each\nfunction in the sum depends on a subset of variables, takes values which are\nrational numbers or infinity, and is chosen from a fixed finite set of\nfunctions called a constraint language. The case when all functions take only\nvalues 0 and infinity is known as the constraint satisfaction problem (CSP). It\nis known that any CSP with fixed constraint language is polynomial-time\nequivalent to one where the constraint language contains a single binary\nrelation (i.e. a digraph). A recent proof of this by Bulin et al. gives such a\nreduction that preserves most of the algebraic properties of the constraint\nlanguage that are known to characterize the complexity of the corresponding\nCSP. We adapt this proof to the more general setting of VCSP to show that each\nVCSP with a fixed finite (valued) constraint language is equivalent to one\nwhere the constraint language consists of one $\\{0,\\infty\\}$-valued binary\nfunction (i.e. a digraph) and one finite-valued unary function, the latter\nproblem known as the (extended) Minimum Cost Homomorphism Problem for digraphs.\nWe also show that our reduction preserves some important algebraic properties\nof the (valued) constraint language."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.01906v1", 
    "title": "Towards Tight Lower Bounds for Scheduling Problems", 
    "arxiv-id": "1507.01906v1", 
    "author": "Ashkan Norouzi-Fard", 
    "publish": "2015-07-07T18:04:24Z", 
    "summary": "We show a close connection between structural hardness for $k$-partite graphs\nand tight inapproximability results for scheduling problems with precedence\nconstraints. Assuming a natural but nontrivial generalisation of the bipartite\nstructural hardness result of Bansal and Khot, we obtain a hardness of\n$2-\\epsilon$ for the problem of minimising the makespan for scheduling\nprecedence-constrained jobs with preemption on identical parallel machines.\nThis matches the best approximation guarantee for this problem. Assuming the\nsame hypothesis, we also obtain a super constant inapproximability result for\nthe problem of scheduling precedence-constrained jobs on related parallel\nmachines, making progress towards settling an open question in both lists of\nten open questions by Williamson and Shmoys, and by Schuurman and Woeginger.\n  The study of structural hardness of $k$-partite graphs is of independent\ninterest, as it captures the intrinsic hardness for a large family of\nscheduling problems. Other than the ones already mentioned, this generalisation\nalso implies tight inapproximability to the problem of minimising the weighted\ncompletion time for precedence-constrained jobs on a single machine, and the\nproblem of minimising the makespan of precedence-constrained jobs on identical\nparallel machine, and hence unifying the results of Bansal and Khot, and\nSvensson, respectively."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.02015v1", 
    "title": "Lower Bounds by Birkhoff Interpolation", 
    "arxiv-id": "1507.02015v1", 
    "author": "Pascal Koiran", 
    "publish": "2015-07-08T04:10:11Z", 
    "summary": "In this paper we give lower bounds for the representation of real univariate\npolynomials as sums of powers of degree 1 polynomials. We present two families\nof polynomials of degree d such that the number of powers that are required in\nsuch a representation must be at least of order d. This is clearly optimal up\nto a constant factor. Previous lower bounds for this problem were only of order\n$\\Omega$($\\sqrt$ d), and were obtained from arguments based on Wronskian\ndeterminants and \"shifted derivatives.\" We obtain this improvement thanks to a\nnew lower bound method based on Birkhoff interpolation (also known as \"lacunary\npolynomial interpolation\")."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.02723v1", 
    "title": "An NL-Complete Puzzle", 
    "arxiv-id": "1507.02723v1", 
    "author": "Holger Petersen", 
    "publish": "2015-07-09T22:03:56Z", 
    "summary": "We investigate the complexity of a puzzle that turns out to be NL-complete."
},{
    "category": "cs.CC", 
    "doi": "10.3233/FI-2012-0000", 
    "link": "http://arxiv.org/pdf/1507.03113v2", 
    "title": "The Complexity of Computing the Optimal Composition of Differential   Privacy", 
    "arxiv-id": "1507.03113v2", 
    "author": "Salil Vadhan", 
    "publish": "2015-07-11T14:58:34Z", 
    "summary": "In the study of differential privacy, composition theorems (starting with the\noriginal paper of Dwork, McSherry, Nissim, and Smith (TCC'06)) bound the\ndegradation of privacy when composing several differentially private\nalgorithms. Kairouz, Oh, and Viswanath (ICML'15) showed how to compute the\noptimal bound for composing $k$ arbitrary $(\\epsilon,\\delta)$-differentially\nprivate algorithms. We characterize the optimal composition for the more\ngeneral case of $k$ arbitrary\n$(\\epsilon_{1},\\delta_{1}),\\ldots,(\\epsilon_{k},\\delta_{k})$-differentially\nprivate algorithms where the privacy parameters may differ for each algorithm\nin the composition. We show that computing the optimal composition in general\nis $\\#$P-complete. Since computing optimal composition exactly is infeasible\n(unless FP=$\\#$P), we give an approximation algorithm that computes the\ncomposition to arbitrary accuracy in polynomial time. The algorithm is a\nmodification of Dyer's dynamic programming approach to approximately counting\nsolutions to knapsack problems (STOC'03)."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.03166v2", 
    "title": "On the Polytope Escape Problem for Continuous Linear Dynamical Systems", 
    "arxiv-id": "1507.03166v2", 
    "author": "James Worrell", 
    "publish": "2015-07-11T22:56:01Z", 
    "summary": "The Polyhedral Escape Problem for continuous linear dynamical systems\nconsists of deciding, given an affine function $f: \\mathbb{R}^{d} \\rightarrow\n\\mathbb{R}^{d}$ and a convex polyhedron $\\mathcal{P} \\subseteq \\mathbb{R}^{d}$,\nwhether, for some initial point $\\boldsymbol{x}_{0}$ in $\\mathcal{P}$, the\ntrajectory of the unique solution to the differential equation\n$\\dot{\\boldsymbol{x}}(t)=f(\\boldsymbol{x}(t))$,\n$\\boldsymbol{x}(0)=\\boldsymbol{x}_{0}$, is entirely contained in $\\mathcal{P}$.\nWe show that this problem is decidable, by reducing it in polynomial time to\nthe decision version of linear programming with real algebraic coefficients,\nthus placing it in $\\exists \\mathbb{R}$, which lies between NP and PSPACE. Our\nalgorithm makes use of spectral techniques and relies among others on tools\nfrom Diophantine approximation."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.03439v1", 
    "title": "Polynomial Kernels for Weighted Problems", 
    "arxiv-id": "1507.03439v1", 
    "author": "Heiko R\u00f6glin", 
    "publish": "2015-07-13T13:15:14Z", 
    "summary": "Kernelization is a formalization of efficient preprocessing for NP-hard\nproblems using the framework of parameterized complexity. Among open problems\nin kernelization it has been asked many times whether there are deterministic\npolynomial kernelizations for Subset Sum and Knapsack when parameterized by the\nnumber $n$ of items.\n  We answer both questions affirmatively by using an algorithm for compressing\nnumbers due to Frank and Tardos (Combinatorica 1987). This result had been\nfirst used by Marx and V\\'egh (ICALP 2013) in the context of kernelization. We\nfurther illustrate its applicability by giving polynomial kernels also for\nweighted versions of several well-studied parameterized problems. Furthermore,\nwhen parameterized by the different item sizes we obtain a polynomial\nkernelization for Subset Sum and an exponential kernelization for Knapsack.\nFinally, we also obtain kernelization results for polynomial integer programs."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.04391v1", 
    "title": "Sub-exponential Approximation Schemes for CSPs: from Dense to Almost   Sparse", 
    "arxiv-id": "1507.04391v1", 
    "author": "Vangelis Th. Paschos", 
    "publish": "2015-07-15T20:48:19Z", 
    "summary": "It has long been known, since the classical work of (Arora, Karger,\nKarpinski, JCSS~99), that \\MC\\ admits a PTAS on dense graphs, and more\ngenerally, \\kCSP\\ admits a PTAS on \"dense\" instances with $\\Omega(n^k)$\nconstraints. In this paper we extend and generalize their exhaustive sampling\napproach, presenting a framework for $(1-\\eps)$-approximating any \\kCSP\\\nproblem in \\emph{sub-exponential} time while significantly relaxing the\ndenseness requirement on the input instance. Specifically, we prove that for\nany constants $\\delta \\in (0, 1]$ and $\\eps > 0$, we can approximate \\kCSP\\\nproblems with $\\Omega(n^{k-1+\\delta})$ constraints within a factor of\n$(1-\\eps)$ in time $2^{O(n^{1-\\delta}\\ln n /\\eps^3)}$. The framework is quite\ngeneral and includes classical optimization problems, such as \\MC, {\\sc\nMax}-DICUT, \\kSAT, and (with a slight extension) $k$-{\\sc Densest Subgraph}, as\nspecial cases. For \\MC\\ in particular (where $k=2$), it gives an approximation\nscheme that runs in time sub-exponential in $n$ even for \"almost-sparse\"\ninstances (graphs with $n^{1+\\delta}$ edges). We prove that our results are\nessentially best possible, assuming the ETH. First, the density requirement\ncannot be relaxed further: there exists a constant $r < 1$ such that for all\n$\\delta > 0$, \\kSAT\\ instances with $O(n^{k-1})$ clauses cannot be approximated\nwithin a ratio better than $r$ in time $2^{O(n^{1-\\delta})}$. Second, the\nrunning time of our algorithm is almost tight \\emph{for all densities}. Even\nfor \\MC\\ there exists $r<1$ such that for all $\\delta' > \\delta >0$, \\MC\\\ninstances with $n^{1+\\delta}$ edges cannot be approximated within a ratio\nbetter than $r$ in time $2^{n^{1-\\delta'}}$."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.04820v1", 
    "title": "The Complexity of Switching and FACTS Maximum-Potential-Flow Problems", 
    "arxiv-id": "1507.04820v1", 
    "author": "Pascal Van Hentenryck", 
    "publish": "2015-07-17T02:37:58Z", 
    "summary": "This papers considers the problem of maximizing the load that can be served\nby a power network. We use the commonly accepted Linear DC power network model\nand consider wo configuration options: switching lines and using FACTS devices.\nWe present the first comprehensive complexity study of this optimization\nproblem. Our results show hat the problem is NP-complete and that there is no\nfully polynomial-time approximation scheme. For switching, these results extend\nto planar networks with a aximum-node degree of 3. Additionally, we demonstrate\nthat the optimization problems are still NP-hard if we restrict the network\nstructure to cacti with a maximum degree of 3."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.05230v1", 
    "title": "SoS and Planted Clique: Tight Analysis of MPW Moments at all Degrees and   an Optimal Lower Bound at Degree Four", 
    "arxiv-id": "1507.05230v1", 
    "author": "Aaron Potechin", 
    "publish": "2015-07-18T22:51:17Z", 
    "summary": "The problem of finding large cliques in random graphs and its \"planted\"\nvariant, where one wants to recover a clique of size $\\omega \\gg \\log{(n)}$\nadded to an \\Erdos-\\Renyi graph $G \\sim G(n,\\frac{1}{2})$, have been intensely\nstudied. Nevertheless, existing polynomial time algorithms can only recover\nplanted cliques of size $\\omega = \\Omega(\\sqrt{n})$. By contrast, information\ntheoretically, one can recover planted cliques so long as $\\omega \\gg\n\\log{(n)}$. In this work, we continue the investigation of algorithms from the\nsum of squares hierarchy for solving the planted clique problem begun by Meka,\nPotechin, and Wigderson (MPW, 2015) and Deshpande and Montanari (DM,2015). Our\nmain results improve upon both these previous works by showing:\n  1. Degree four SoS does not recover the planted clique unless $\\omega \\gg\n\\sqrt n poly \\log n$, improving upon the bound $\\omega \\gg n^{1/3}$ due to DM.\nA similar result was obtained independently by Raghavendra and Schramm (2015).\n  2. For $2 < d = o(\\sqrt{\\log{(n)}})$, degree $2d$ SoS does not recover the\nplanted clique unless $\\omega \\gg n^{1/(d + 1)} /(2^d poly \\log n)$, improving\nupon the bound due to MPW.\n  Our proof for the second result is based on a fine spectral analysis of the\ncertificate used in the prior works MPW,DM and Feige and Krauthgamer (2003) by\ndecomposing it along an appropriately chosen basis. Along the way, we develop\ncombinatorial tools to analyze the spectrum of random matrices with dependent\nentries and to understand the symmetries in the eigenspaces of the set\nsymmetric matrices inspired by work of Grigoriev (2001).\n  An argument of Kelner shows that the first result cannot be proved using the\nsame certificate. Rather, our proof involves constructing and analyzing a new\ncertificate that yields the nearly tight lower bound by \"correcting\" the\ncertificate of previous works."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.05841v3", 
    "title": "On the GI-Completeness of a Sorting Networks Isomorphism", 
    "arxiv-id": "1507.05841v3", 
    "author": "David Gregg", 
    "publish": "2015-07-21T14:12:29Z", 
    "summary": "The subitemset isomorphism problem is really important and there are\nexcellent practical solutions described in the literature. However, the\ncomputational complexity analysis and classification of the BZ (Bundala and\nZavodny) subitemset isomorphism problem is currently an open problem. In this\npaper we prove that checking whether two sorting networks are BZ isomorphic to\neach other is GI-Complete; the general GI (Graph Isomorphism) problem is known\nto be in NP and LWPP, but widely believed to be neither P nor NP-Complete;\nrecent research suggests that the problem is in QP. Moreover, we state the BZ\nsorting network isomorphism problem as a general isomorphism problem on\nitemsets --- because every sorting network is represented by Bundala and\nZavodny as an itemset. The complexity classification presented in this paper\napplies sorting networks, as well as the general itemset isomorphism problem.\nThe main consequence of our work is that currently no polynomial-time algorithm\nexists for solving the BZ sorting network subitemset isomorphism problem;\nhowever the CM (Choi and Moon) sorting network isomorphism problem can be\nefficiently solved in polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.06865v1", 
    "title": "All Colors Shortest Path Problem", 
    "arxiv-id": "1507.06865v1", 
    "author": "Cem Evrendilek", 
    "publish": "2015-07-24T14:57:02Z", 
    "summary": "All Colors Shortest Path problem defined on an undirected graph aims at\nfinding a shortest, possibly non-simple, path where every color occurs at least\nonce, assuming that each vertex in the graph is associated with a color known\nin advance. To the best of our knowledge, this paper is the first to define and\ninvestigate this problem. Even though the problem is computationally similar to\ngeneralized minimum spanning tree, and the generalized traveling salesman\nproblems, allowing for non-simple paths where a node may be visited multiple\ntimes makes All Colors Shortest Path problem novel and computationally unique.\nIn this paper we prove that All Colors Shortest Path problem is NP-hard, and\ndoes not lend itself to a constant factor approximation. We also propose\nseveral heuristic solutions for this problem based on LP-relaxation, simulated\nannealing, ant colony optimization, and genetic algorithm, and provide\nextensive simulations for a comparative analysis of them. The heuristics\npresented are not the standard implementations of the well known heuristic\nalgorithms, but rather sophisticated models tailored for the problem in hand.\nThis fact is acknowledged by the very promising results reported."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.07856v1", 
    "title": "A Classification of Connected f -factor Problems inside NP", 
    "arxiv-id": "1507.07856v1", 
    "author": "C. S. Rahul", 
    "publish": "2015-07-28T17:21:06Z", 
    "summary": "Given an undirected graph G = (V, E) with n vertices, and a function f : V ->\nN, we consider the problem of finding a connected f -factor in G. In this work\nwe design an algorithm to check for the existence of a connected f -factor, for\nthe case where f (v) >= n/g(n), for all v in V and g(n) is polylogarithmic in\nn. The running time of our algorithm is O(n^{2g(n)}. As a consequence of this\nalgorithm we conclude that the complexity of connected f -factor for the case\nwe consider is unlikely to be NP-Complete unless the Exponential Time\nHypothesis (ETH) is false. Secondly, under the assumption of the ETH, we show\nthat it is also unlikely to be in P for g(n) in O((log n)^{1+eps} ) for any\neps> 0. Therefore, our results show that for all eps> 0, connected f -factor\nfor f (v) >= n/O(log n)^{1+eps}) is in NP-Intermediate unless the ETH is false.\nFurther, for any constant c > 0, when g(n) = c, our algorithm for connected f\n-factor runs in polynomial time. Finally, we extend our algorithm to compute a\nminimum weight connected f -factor in edge weighted graphs in the same\nasymptotic time bounds."
},{
    "category": "cs.CC", 
    "doi": "10.1145/3049797.3049798", 
    "link": "http://arxiv.org/pdf/1507.08690v1", 
    "title": "The Complexity of Some Combinatorial Puzzles", 
    "arxiv-id": "1507.08690v1", 
    "author": "Holger Petersen", 
    "publish": "2015-07-30T21:04:54Z", 
    "summary": "We show that the decision versions of the puzzles Knossos and The Hour-Glass\nare complete for NP."
},lol]