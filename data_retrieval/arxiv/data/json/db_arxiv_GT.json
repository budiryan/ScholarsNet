[{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Bundling Equilibrium in Combinatorial auctions", 
    "publish": "2002-01-14T22:36:50Z", 
    "summary": "This paper analyzes individually-rational ex post equilibrium in the VC\n(Vickrey-Clarke) combinatorial auctions. If $\\Sigma$ is a family of bundles of\ngoods, the organizer may restrict the participants by requiring them to submit\ntheir bids only for bundles in $\\Sigma$. The $\\Sigma$-VC combinatorial auctions\n(multi-good auctions) obtained in this way are known to be\nindividually-rational truth-telling mechanisms. In contrast, this paper deals\nwith non-restricted VC auctions, in which the buyers restrict themselves to\nbids on bundles in $\\Sigma$, because it is rational for them to do so. That is,\nit may be that when the buyers report their valuation of the bundles in\n$\\Sigma$, they are in an equilibrium. We fully characterize those $\\Sigma$ that\ninduce individually rational equilibrium in every VC auction, and we refer to\nthe associated equilibrium as a bundling equilibrium. The number of bundles in\n$\\Sigma$ represents the communication complexity of the equilibrium. A special\ncase of bundling equilibrium is partition-based equilibrium, in which $\\Sigma$\nis a field, that is, it is generated by a partition. We analyze the tradeoff\nbetween communication complexity and economic efficiency of bundling\nequilibrium, focusing in particular on partition-based equilibrium.", 
    "link": "http://arxiv.org/pdf/cs/0201010v1", 
    "arxiv-id": "cs/0201010v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Combinatorial Auctions with Decreasing Marginal Utilities", 
    "publish": "2002-02-15T10:18:30Z", 
    "summary": "In most of microeconomic theory, consumers are assumed to exhibit decreasing\nmarginal utilities. This paper considers combinatorial auctions among such\nsubmodular buyers. The valuations of such buyers are placed within a hierarchy\nof valuations that exhibit no complementarities, a hierarchy that includes also\nOR and XOR combinations of singleton valuations, and valuations satisfying the\ngross substitutes property. Those last valuations are shown to form a\nzero-measure subset of the submodular valuations that have positive measure.\nWhile we show that the allocation problem among submodular valuations is\nNP-hard, we present an efficient greedy 2-approximation algorithm for this case\nand generalize it to the case of limited complementarities. No such\napproximation algorithm exists in a setting allowing for arbitrary\ncomplementarities. Some results about strategic aspects of combinatorial\nauctions among players with decreasing marginal utilities are also presented.", 
    "link": "http://arxiv.org/pdf/cs/0202015v2", 
    "arxiv-id": "cs/0202015v2"
},{
    "category": "cs.GT", 
    "author": "Yoav Shoham", 
    "title": "Truth Revelation in Approximately Efficient Combinatorial Auctions", 
    "publish": "2002-02-15T12:24:29Z", 
    "summary": "Some important classical mechanisms considered in Microeconomics and Game\nTheory require the solution of a difficult optimization problem. This is true\nof mechanisms for combinatorial auctions, which have in recent years assumed\npractical importance, and in particular of the gold standard for combinatorial\nauctions, the Generalized Vickrey Auction (GVA). Traditional analysis of these\nmechanisms - in particular, their truth revelation properties - assumes that\nthe optimization problems are solved precisely. In reality, these optimization\nproblems can usually be solved only in an approximate fashion. We investigate\nthe impact on such mechanisms of replacing exact solutions by approximate ones.\nSpecifically, we look at a particular greedy optimization method. We show that\nthe GVA payment scheme does not provide for a truth revealing mechanism. We\nintroduce another scheme that does guarantee truthfulness for a restricted\nclass of players. We demonstrate the latter property by identifying natural\nproperties for combinatorial auctions and showing that, for our restricted\nclass of players, they imply that truthful strategies are dominant. Those\nproperties have applicability beyond the specific auction studied.", 
    "link": "http://arxiv.org/pdf/cs/0202017v1", 
    "arxiv-id": "cs/0202017v1"
},{
    "category": "cs.GT", 
    "author": "Daniel Lehmann", 
    "title": "Expected Qualitative Utility Maximization", 
    "publish": "2002-02-18T14:55:49Z", 
    "summary": "A model for decision making that generalizes Expected Utility Maximization is\npresented. This model, Expected Qualitative Utility Maximization, encompasses\nthe Maximin criterion. It relaxes both the Independence and the Continuity\npostulates. Its main ingredient is the definition of a qualitative order on\nnonstandard models of the real numbers and the consideration of nonstandard\nutilities. Expected Qualitative Utility Maximization is characterized by an\noriginal weakening of von Neumann-Morgenstern's postulates. Subjective\nprobabilities may be defined from those weakened postulates, as Anscombe and\nAumann did from the original postulates. Subjective probabilities are numbers,\nnot matrices as in the Subjective Expected Lexicographic Utility approach. JEL\nno.: D81 Keywords: Utility Theory, Non-Standard Utilities, Qualitative Decision\nTheory", 
    "link": "http://arxiv.org/pdf/cs/0202023v2", 
    "arxiv-id": "cs/0202023v2"
},{
    "category": "cs.GT", 
    "author": "Daniel Lehmann", 
    "title": "Classes of service under perfect competition and technological change: a   model for the dynamics of the Internet?", 
    "publish": "2002-02-20T11:53:16Z", 
    "summary": "Certain services may be provided in a continuous, one-dimensional, ordered\nrange of different qualities and a customer requiring a service of quality q\ncan only be offered a quality superior or equal to q. Only a discrete set of\ndifferent qualities will be offered, and a service provider will provide the\nsame service (of fixed quality b) to all customers requesting qualities of\nservice inferior or equal to b. Assuming all services (of quality b) are priced\nidentically, a monopolist will choose the qualities of service and the prices\nthat maximize profit but, under perfect competition, a service provider will\nchoose the (inferior) quality of service that can be priced at the lowest\nprice. Assuming significant economies of scale, two fundamentally different\nregimes are possible: either a number of different classes of service are\noffered (DC regime), or a unique class of service offers an unbounded quality\nof service (UC regime). The DC regime appears in one of two sub-regimes: one,\nBDC, in which a finite number of classes is offered, the qualities of service\noffered are bounded and requests for high-quality services are not met, or UDC\nin which an infinite number of classes of service are offered and every request\nis met. The types of the demand curve and of the economies of scale, not the\npace of technological change, determine the regime and the class boundaries.\nThe price structure in the DC regime obeys very general laws.", 
    "link": "http://arxiv.org/pdf/cs/0202028v1", 
    "arxiv-id": "cs/0202028v1"
},{
    "category": "cs.GT", 
    "author": "Daniel Lehmann", 
    "title": "Nonstandard numbers for qualitative decision making", 
    "publish": "2002-02-20T12:59:53Z", 
    "summary": "The consideration of nonstandard models of the real numbers and the\ndefinition of a qualitative ordering on those models provides a generalization\nof the principle of maximization of expected utility. It enables the decider to\nassign probabilities of different orders of magnitude to different events or to\nassign utilities of different orders of magnitude to different outcomes. The\nproperties of this generalized notion of rationality are studied in the\nframeworks proposed by von Neumann and Morgenstern and later by Anscombe and\nAumann. It is characterized by an original weakening of their postulates in two\ndifferent situations: nonstandard probabilities and standard utilities on one\nhand and standard probabilities and nonstandard utilities on the other hand.\nThis weakening concerns both Independence and Continuity. It is orthogonal with\nthe weakening proposed by lexicographic orderings.", 
    "link": "http://arxiv.org/pdf/cs/0202029v1", 
    "arxiv-id": "cs/0202029v1"
},{
    "category": "cs.GT", 
    "author": "Tuomas Sandholm", 
    "title": "Complexity of Manipulating Elections with Few Candidates", 
    "publish": "2002-05-29T20:27:58Z", 
    "summary": "In multiagent settings where the agents have different preferences,\npreference aggregation is a central issue. Voting is a general method for\npreference aggregation, but seminal results have shown that all general voting\nprotocols are manipulable. One could try to avoid manipulation by using voting\nprotocols where determining a beneficial manipulation is hard. Especially among\ncomputational agents, it is reasonable to measure this hardness by\ncomputational complexity. Some earlier work has been done in this area, but it\nwas assumed that the number of voters and candidates is unbounded. We derive\nhardness results for practical multiagent settings where the number of\ncandidates is small but the number of voters can be large. We show that with\ncomplete information about the others' votes, individual manipulation is easy,\nand coalitional manipulation is easy with unweighted voters. However,\nconstructive coalitional manipulation with weighted voters is intractable for\nall of the voting protocols under study, except for the nonrandomized Cup.\nDestructive manipulation tends to be easier. Randomizing over instantiations of\nthe protocols (such as schedules of the Cup protocol) can be used to make\nmanipulation hard. Finally, we show that under weak assumptions, if weighted\ncoalitional manipulation with complete information about the others' votes is\nhard in some voting protocol, then individual and unweighted manipulation is\nhard when there is uncertainty about the others' votes.", 
    "link": "http://arxiv.org/pdf/cs/0205076v1", 
    "arxiv-id": "cs/0205076v1"
},{
    "category": "cs.GT", 
    "author": "James A. R. Marshall", 
    "title": "On the suitability of the 2 x 2 games for studying reciprocal   cooperation and kin selection", 
    "publish": "2003-06-24T14:13:46Z", 
    "summary": "The 2 x 2 games, in particular the Prisoner's Dilemma, have been extensively\nused in studies into reciprocal cooperation and, to a lesser extent, kin\nselection. This paper examines the suitability of the 2 x 2 games for modelling\nthe evolution of cooperation through reciprocation and kin selection. This\nexamination is not restricted to the Prisoner's Dilemma, but includes the other\nnon-trivial symmetric 2 x 2 games. We show that the popularity of the\nPrisoner's Dilemma for modelling social and biotic interaction is justified by\nits superiority according to these criteria. Indeed, the Prisoner's Dilemma is\nunique in providing the simplest support for reciprocal cooperation, and\nadditive kin-selected altruism. However, care is still required in choosing the\nparticular Prisoner's Dilemma payoff matrix to use. This paper reviews the\nimpact of non-linear payoffs for the application of Hamilton's rule to typical\naltruistic interactions, and derives new results for cases in which the roles\nof potential altruist and beneficiary are separated. In doing so we find the\nsame equilibrium condition holds in continuous games between relatives, and in\ndiscrete games with roles.", 
    "link": "http://arxiv.org/pdf/cs/0306128v3", 
    "arxiv-id": "cs/0306128v3"
},{
    "category": "cs.GT", 
    "author": "Subhash Suri", 
    "title": "A Game Theoretic Framework for Incentives in P2P Systems", 
    "publish": "2003-10-17T20:56:10Z", 
    "summary": "Peer-To-Peer (P2P) networks are self-organizing, distributed systems, with no\ncentralized authority or infrastructure. Because of the voluntary\nparticipation, the availability of resources in a P2P system can be highly\nvariable and unpredictable. In this paper, we use ideas from Game Theory to\nstudy the interaction of strategic and rational peers, and propose a\ndifferential service-based incentive scheme to improve the system's\nperformance.", 
    "link": "http://arxiv.org/pdf/cs/0310039v1", 
    "arxiv-id": "cs/0310039v1"
},{
    "category": "cs.GT", 
    "author": "Alvaro Francisco Huertas-Rosero", 
    "title": "A Cartography for 2x2 Symmetric Games", 
    "publish": "2003-12-02T15:52:46Z", 
    "summary": "A bidimensional representation of the space of 2x2 Symmetric Games in the\nstrategic representation is proposed. This representation provides a tool for\nthe classification of 2x2 symmetric games, quantification of the fraction of\nthem having a certain feature, and predictions of changes in the\ncharacteristics of a game when a change in done on the payoff matrix that\ndefines it.", 
    "link": "http://arxiv.org/pdf/cs/0312005v2", 
    "arxiv-id": "cs/0312005v2"
},{
    "category": "cs.GT", 
    "author": "D. Abbott", 
    "title": "Parrondo's games with chaotic switching", 
    "publish": "2004-04-07T06:15:41Z", 
    "summary": "This paper investigates the different effects of chaotic switching on\nParrondo's games, as compared to random and periodic switching. The rate of\nwinning of Parrondo's games with chaotic switching depends on coefficient(s)\ndefining the chaotic generator, initial conditions of the chaotic sequence and\nthe proportion of Game A played. Maximum rate of winning can be obtained with\nall the above mentioned factors properly set, and this occurs when chaotic\nswitching approaches periodic behavior.", 
    "link": "http://arxiv.org/pdf/cs/0404016v1", 
    "arxiv-id": "cs/0404016v1"
},{
    "category": "cs.GT", 
    "author": "Somdeb Lahiri", 
    "title": "Stable Outcomes for Two-Sided Contract Choice Problems", 
    "publish": "2004-06-27T11:40:12Z", 
    "summary": "We show, that a simple generalization of the Deferred Acceptance Procedure\nwith firms proposing due to Gale and Shapley(1962), yeild outcomes for a\ntwo-sided contract choice problem, which necessarily belong to the core and are\nWeakly Pareto Optimal for firms. Under additional assumptions: (a) given any\ntwo distinct workers, the set of yields acheivable by a firm with the first\nworker is disjoint from the set of yields acheivable by it with the second, and\n(b) the contract choice problem is pair-wise efficient, we prove that there is\nno stable outcome at which a firm can get more than what it gets at the unique\noutcome of our procedure.", 
    "link": "http://arxiv.org/pdf/cs/0406051v1", 
    "arxiv-id": "cs/0406051v1"
},{
    "category": "cs.GT", 
    "author": "Somdeb Lahiri", 
    "title": "The Core of Directed Network Problems with Quotas", 
    "publish": "2004-08-28T10:12:17Z", 
    "summary": "This paper proves the existence of non-empty cores for directed network\nproblems with quotas and for those combinatorial allocation problems which\npermit only exclusive allocations.", 
    "link": "http://arxiv.org/pdf/cs/0408065v6", 
    "arxiv-id": "cs/0408065v6"
},{
    "category": "cs.GT", 
    "author": "G. Savard", 
    "title": "An Approximation Algorithm for Stackelberg Network Pricing", 
    "publish": "2004-09-27T00:32:10Z", 
    "summary": "We consider the problem of maximizing the revenue raised from tolls set on\nthe arcs of a transportation network, under the constraint that users are\nassigned to toll-compatible shortest paths. We first prove that this problem is\nstrongly NP-hard. We then provide a polynomial time algorithm with a worst-case\nprecision guarantee of ${1/2}\\log_2 m_T+1$, where $m_T$ denotes the number of\ntoll arcs. Finally we show that the approximation is tight with respect to a\nnatural relaxation by constructing a family of instances for which the\nrelaxation gap is reached.", 
    "link": "http://arxiv.org/pdf/cs/0409054v1", 
    "arxiv-id": "cs/0409054v1"
},{
    "category": "cs.GT", 
    "author": "Shlomo Weber", 
    "title": "The egalitarian sharing rule in provision of public projects", 
    "publish": "2005-03-17T09:24:42Z", 
    "summary": "In this note we consider a society that partitions itself into disjoint\njurisdictions, each choosing a location of its public project and a taxation\nscheme to finance it. The set of public project is multi-dimensional, and their\ncosts could vary from jurisdiction to jurisdiction. We impose two principles,\negalitarianism, that requires the equalization of the total cost for all agents\nin the same jurisdiction, and efficiency, that implies the minimization of the\naggregate total cost within jurisdiction. We show that these two principles\nalways yield a core-stable partition but a Nash stable partition may fail to\nexist.", 
    "link": "http://arxiv.org/pdf/cs/0503035v1", 
    "arxiv-id": "cs/0503035v1"
},{
    "category": "cs.GT", 
    "author": "William Yurcik", 
    "title": "A Game Theoretic Economics Framework to understanding Information   Security Oursourcing Market", 
    "publish": "2005-06-10T23:58:37Z", 
    "summary": "On information security outsourcing market, an important reason that firms do\nnot want to let outside firms(usually called MSSPs-Managed Security Service\nProviders) to take care of their security need is that they worry about service\nquality MSSPs provide because they cannot monitor effort of the MSSPs. Since\nMSSPs action is unobservable to buyers, MSSPs can lower cost by working less\nhard than required in the contract and get higher profit. In the asymmetric\ninformation literature, this possible secret shirking behavior is termed as\nmoral hazard problem. This paper considers a game theoretic economic framework\nto show that under information asymmetry, an optimal contract can be designed\nso that MSSPs will stick to their promised effort level. We also show that the\noptimal contract should be performance-based, i.e., payment to MSSP should base\non performance of MSSP's security service period by period. For comparison, we\nalso showed that if the moral hazard problem does not exist, the optimal\ncontract does not depend on MSSP's performance. A contract that specifies\nconstant payment to MSSP will be optimal. Besides these, we show that for no\nmatter under perfect information scenario or imperfect information scenario,\nthe higher the transaction cost is, the lower payment to MSSPs will be.", 
    "link": "http://arxiv.org/pdf/cs/0506038v1", 
    "arxiv-id": "cs/0506038v1"
},{
    "category": "cs.GT", 
    "author": "John N. Tsitsiklis", 
    "title": "Efficiency Loss in a Network Resource Allocation Game: The Case of   Elastic Supply", 
    "publish": "2005-06-14T02:11:47Z", 
    "summary": "We consider a resource allocation problem where individual users wish to send\ndata across a network to maximize their utility, and a cost is incurred at each\nlink that depends on the total rate sent through the link. It is known that as\nlong as users do not anticipate the effect of their actions on prices, a simple\nproportional pricing mechanism can maximize the sum of users' utilities minus\nthe cost (called aggregate surplus). Continuing previous efforts to quantify\nthe effects of selfish behavior in network pricing mechanisms, we consider the\npossibility that users anticipate the effect of their actions on link prices.\nUnder the assumption that the links' marginal cost functions are convex, we\nestablish existence of a Nash equilibrium. We show that the aggregate surplus\nat a Nash equilibrium is no worse than a factor of 4*sqrt{2} - 5 times the\noptimal aggregate surplus; thus, the efficiency loss when users are selfish is\nno more than approximately 34%.", 
    "link": "http://arxiv.org/pdf/cs/0506054v1", 
    "arxiv-id": "cs/0506054v1"
},{
    "category": "cs.GT", 
    "author": "Ulrich Berger", 
    "title": "Strong normalisation for applied lambda calculi", 
    "publish": "2005-07-04T18:49:48Z", 
    "summary": "We consider the untyped lambda calculus with constructors and recursively\ndefined constants. We construct a domain-theoretic model such that any term not\ndenoting bottom is strongly normalising provided all its `stratified\napproximations' are. From this we derive a general normalisation theorem for\napplied typed lambda-calculi: If all constants have a total value, then all\ntypeable terms are strongly normalising. We apply this result to extensions of\nG\\\"odel's system T and system F extended by various forms of bar recursion for\nwhich strong normalisation was hitherto unknown.", 
    "link": "http://arxiv.org/pdf/cs/0507007v4", 
    "arxiv-id": "cs/0507007v4"
},{
    "category": "cs.GT", 
    "author": "Krzysztof R. Apt", 
    "title": "Order Independence and Rationalizability", 
    "publish": "2005-09-20T08:27:26Z", 
    "summary": "Two natural strategy elimination procedures have been studied for strategic\ngames. The first one involves the notion of (strict, weak, etc) dominance and\nthe second the notion of rationalizability. In the case of dominance the\ncriterion of order independence allowed us to clarify which notions and under\nwhat circumstances are robust. In the case of rationalizability this criterion\nhas not been considered. In this paper we investigate the problem of order\nindependence for rationalizability by focusing on three naturally entailed\nreduction relations on games. These reduction relations are distinguished by\nthe adopted reference point for the notion of a better response. Additionally,\nthey are parametrized by the adopted system of beliefs. We show that for one\nreduction relation the outcome of its (possibly transfinite) iterations does\nnot depend on the order of elimination of the strategies. This result does not\nhold for the other two reduction relations. However, under a natural assumption\nthe iterations of all three reduction relations yield the same outcome. The\nobtained order independence results apply to the frameworks considered in\nBernheim 84 and Pearce 84. For finite games the iterations of all three\nreduction relations coincide and the order independence holds for three natural\nsystems of beliefs considered in the literature.", 
    "link": "http://arxiv.org/pdf/cs/0509063v1", 
    "arxiv-id": "cs/0509063v1"
},{
    "category": "cs.GT", 
    "author": "Constantinos Daskalakis", 
    "title": "Computing Pure Nash Equilibria via Markov Random Fields", 
    "publish": "2005-10-13T04:42:51Z", 
    "summary": "In this paper we present a novel generic mapping between Graphical Games and\nMarkov Random Fields so that pure Nash equilibria in the former can be found by\nstatistical inference on the latter. Thus, the problem of deciding whether a\ngraphical game has a pure Nash equilibrium, a well-known intractable problem,\ncan be attacked by well-established algorithms such as Belief Propagation,\nJunction Trees, Markov Chain Monte Carlo and Simulated Annealing. Large classes\nof graphical games become thus tractable, including all classes already known,\nbut also new classes such as the games with O(log n) treewidth.", 
    "link": "http://arxiv.org/pdf/cs/0510031v1", 
    "arxiv-id": "cs/0510031v1"
},{
    "category": "cs.GT", 
    "author": "Jiangtao Meng", 
    "title": "New directions in mechanism design", 
    "publish": "2005-12-21T12:09:57Z", 
    "summary": "Mechanism design uses the tools of economics and game theory to design rules\nof interaction for economic transactions that will,in principle, yield some de-\nsired outcome. In the last few years this field has received much interest of\nresearchers in computer science, especially with the Internet developing as a\nplatform for communications and connections among enormous numbers of computers\nand humans. Arguably the most positive result in mechanism de- sign is truthful\nand there are only one general truthful mechanisms so far : the generalized\nVickrey-Clarke-Groves (VCG) mechanism. But VCG mecha- nism has one shortage:\nThe implementation of truthfulness is on the cost of decreasing the revenue of\nthe mechanism. (e.g., Ning Chen and Hong Zhu. [1999]). We introduce three new\ncharacters of mechanism:partly truthful, criti- cal, consistent, and introduce\na new mechanism: X mechanism that satisfy the above three characters. Like VCG\nmechanism, X mechanism also generalizes from Vickery Auction and is consistent\nwith Vickery auction in many ways, but the extended methods used in X mechanism\nis different from that in VCG mechanism . This paper will demonstrate that X\nmechanism better than VCG mechanism in optimizing utility of mechanism, which\nis the original intention of mechanism design. So partly truthful,critical and\nconsistent are at least as important as truthful in mechanism design, and they\nbeyond truthful in many situations.As a result, we conclude that partly\ntruthful,critical and consistent are three new directions in mechanism design.", 
    "link": "http://arxiv.org/pdf/cs/0512083v2", 
    "arxiv-id": "cs/0512083v2"
},{
    "category": "cs.GT", 
    "author": "Cristina Comaniciu", 
    "title": "Adaptive Channel Allocation Spectrum Etiquette for Cognitive Radio   Networks", 
    "publish": "2006-02-07T00:25:17Z", 
    "summary": "In this work, we propose a game theoretic framework to analyze the behavior\nof cognitive radios for distributed adaptive channel allocation. We define two\ndifferent objective functions for the spectrum sharing games, which capture the\nutility of selfish users and cooperative users, respectively. Based on the\nutility definition for cooperative users, we show that the channel allocation\nproblem can be formulated as a potential game, and thus converges to a\ndeterministic channel allocation Nash equilibrium point. Alternatively, a\nno-regret learning implementation is proposed for both scenarios and it is\nshown to have similar performance with the potential game when cooperation is\nenforced, but with a higher variability across users. The no-regret learning\nformulation is particularly useful to accommodate selfish users.\nNon-cooperative learning games have the advantage of a very low overhead for\ninformation exchange in the network.\n  We show that cooperation based spectrum sharing etiquette improves the\noverall network performance at the expense of an increased overhead required\nfor information exchange.", 
    "link": "http://arxiv.org/pdf/cs/0602019v1", 
    "arxiv-id": "cs/0602019v1"
},{
    "category": "cs.GT", 
    "author": "Somdeb Lahiri", 
    "title": "Market Equilibrium for Bundle Auctions and the Matching Core of   Nonnegative TU Games", 
    "publish": "2006-03-09T12:45:19Z", 
    "summary": "We discuss bundle auctions within the framework of an integer allocation\nproblem. We show that for multi-unit auctions, of which bundle auctions are a\nspecial case, market equilibrium and constrained market equilibrium are\nequivalent concepts. This equivalence, allows us to obtain a computable\nnecessary and sufficient condition for the existence of constrained market\nequilibrium for bundle auctions. We use this result to obtain a necessary and\nsufficient condition for the existence of market equilibrium for multi-unit\nauctions. After obtaining the induced bundle auction of a nonnegative TU game,\nwe show that the existence of market equilibrium implies the existence of a\npossibly different market equilibrium as well, which corresponds very naturally\nto an outcome in the matching core of the TU game. Consequently we show that\nthe matching core of the nonnegative TU game is non-empty if and only if the\ninduced market game has a market equilibrium.", 
    "link": "http://arxiv.org/pdf/cs/0603032v3", 
    "arxiv-id": "cs/0603032v3"
},{
    "category": "cs.GT", 
    "author": "Paul W. Goldberg", 
    "title": "Frugality ratios and improved truthful mechanisms for vertex cover", 
    "publish": "2006-06-09T20:48:31Z", 
    "summary": "In {\\em set-system auctions}, there are several overlapping teams of agents,\nand a task that can be completed by any of these teams. The buyer's goal is to\nhire a team and pay as little as possible. Recently, Karlin, Kempe and Tamir\nintroduced a new definition of {\\em frugality ratio} for this setting.\nInformally, the frugality ratio is the ratio of the total payment of a\nmechanism to perceived fair cost. In this paper, we study this together with\nalternative notions of fair cost, and how the resulting frugality ratios relate\nto each other for various kinds of set systems.\n  We propose a new truthful polynomial-time auction for the vertex cover\nproblem (where the feasible sets correspond to the vertex covers of a given\ngraph), based on the {\\em local ratio} algorithm of Bar-Yehuda and Even. The\nmechanism guarantees to find a winning set whose cost is at most twice the\noptimal. In this situation, even though it is NP-hard to find a lowest-cost\nfeasible set, we show that {\\em local optimality} of a solution can be used to\nderive frugality bounds that are within a constant factor of best possible. To\nprove this result, we use our alternative notions of frugality via a\nbootstrapping technique, which may be of independent interest.", 
    "link": "http://arxiv.org/pdf/cs/0606044v4", 
    "arxiv-id": "cs/0606044v4"
},{
    "category": "cs.GT", 
    "author": "Mukund Sundararajan", 
    "title": "Approximately Efficient Cost-Sharing Mechanisms", 
    "publish": "2006-06-30T02:24:01Z", 
    "summary": "We make three different types of contributions to cost-sharing: First, we\nidentify several new classes of combinatorial cost functions that admit\nincentive-compatible mechanisms achieving both a constant-factor approximation\nof budget-balance and a polylogarithmic approximation of the social cost\nformulation of efficiency. Second, we prove a new, optimal lower bound on the\napproximate efficiency of every budget-balanced Moulin mechanism for Steiner\ntree or SSRoB cost functions. This lower bound exposes a latent approximation\nhierarchy among different cost-sharing problems. Third, we show that weakening\nthe definition of incentive-compatibility to strategyproofness can permit\nexponentially more efficient approximately budget-balanced mechanisms, in\nparticular for set cover cost-sharing problems.", 
    "link": "http://arxiv.org/pdf/cs/0606127v1", 
    "arxiv-id": "cs/0606127v1"
},{
    "category": "cs.GT", 
    "author": "Jon Feldman", 
    "title": "Bidding to the Top: VCG and Equilibria of Position-Based Auctions", 
    "publish": "2006-07-26T15:42:49Z", 
    "summary": "Many popular search engines run an auction to determine the placement of\nadvertisements next to search results. Current auctions at Google and Yahoo!\nlet advertisers specify a single amount as their bid in the auction. This bid\nis interpreted as the maximum amount the advertiser is willing to pay per click\non its ad. When search queries arrive, the bids are used to rank the ads\nlinearly on the search result page. The advertisers pay for each user who\nclicks on their ad, and the amount charged depends on the bids of all the\nadvertisers participating in the auction. In order to be effective, advertisers\nseek to be as high on the list as their budget permits, subject to the market.\n  We study the problem of ranking ads and associated pricing mechanisms when\nthe advertisers not only specify a bid, but additionally express their\npreference for positions in the list of ads. In particular, we study \"prefix\nposition auctions\" where advertiser $i$ can specify that she is interested only\nin the top $b_i$ positions.\n  We present a simple allocation and pricing mechanism that generalizes the\ndesirable properties of current auctions that do not have position constraints.\nIn addition, we show that our auction has an \"envy-free\" or \"symmetric\" Nash\nequilibrium with the same outcome in allocation and pricing as the well-known\ntruthful Vickrey-Clarke-Groves (VCG) auction. Furthermore, we show that this\nequilibrium is the best such equilibrium for the advertisers in terms of the\nprofit made by each advertiser. We also discuss other position-based auctions.", 
    "link": "http://arxiv.org/pdf/cs/0607117v1", 
    "arxiv-id": "cs/0607117v1"
},{
    "category": "cs.GT", 
    "author": "Krzysztof R. Apt", 
    "title": "The Many Faces of Rationalizability", 
    "publish": "2006-08-02T09:57:54Z", 
    "summary": "The rationalizability concept was introduced in \\cite{Ber84} and\n  \\cite{Pea84} to assess what can be inferred by rational players in a\nnon-cooperative game in the presence of common knowledge. However, this notion\ncan be defined in a number of ways that differ in seemingly unimportant minor\ndetails. We shed light on these differences, explain their impact, and clarify\nfor which games these definitions coincide. Then we apply the same analysis to\nexplain the differences and similarities between various ways the iterated\nelimination of strictly dominated strategies was defined in the literature.\nThis allows us to clarify the results of \\cite{DS02} and \\cite{CLL05} and\nimprove upon them. We also consider the extension of these results to strict\ndominance by a mixed strategy. Our approach is based on a general study of the\noperators on complete lattices. We allow transfinite iterations of the\nconsidered operators and clarify the need for them. The advantage of such a\ngeneral approach is that a number of results, including order independence for\nsome of the notions of rationalizability and strict dominance, come for free.", 
    "link": "http://arxiv.org/pdf/cs/0608011v3", 
    "arxiv-id": "cs/0608011v3"
},{
    "category": "cs.GT", 
    "author": "Thierry Cachat", 
    "title": "Controller synthesis & Ordinal Automata", 
    "publish": "2006-08-30T09:58:08Z", 
    "summary": "Ordinal automata are used to model physical systems with Zeno behavior. Using\nautomata and games techniques we solve a control problem formulated and left\nopen by Demri and Nowak in 2005. It involves partial observability and a new\nsynchronization between the controller and the environment.", 
    "link": "http://arxiv.org/pdf/cs/0608120v2", 
    "arxiv-id": "cs/0608120v2"
},{
    "category": "cs.GT", 
    "author": "Wolfgang Kienreich", 
    "title": "On some winning strategies for the Iterated Prisoner's Dilemma or Mr.   Nice Guy and the Cosa Nostra", 
    "publish": "2006-09-05T18:42:00Z", 
    "summary": "We submitted two kinds of strategies to the iterated prisoner's dilemma (IPD)\ncompetitions organized by Graham Kendall, Paul Darwen and Xin Yao in 2004 and\n2005. Our strategies performed exceedingly well in both years. One type is an\nintelligent and optimistic enhanced version of the well known TitForTat\nstrategy which we named OmegaTitForTat. It recognizes common behaviour patterns\nand detects and recovers from repairable mutual defect deadlock situations,\notherwise behaving much like TitForTat. The second type consists of a set of\nstrategies working together as a team. These group strategies have one\ndistinguished individual Godfather strategy that plays OmegaTitForTat against\nnon-members while heavily profiting from the behaviour of the other members of\nhis group, the Hitman. The Hitman willingly let themselves being abused by\ntheir Godfather while themselves lowering the scores of all other players as\nmuch as possible, thus further maximizing the performance of their Godfather in\nrelation to other participants. The study of collusion in the simplified\nframework of the iterated prisoner's dilemma allows us to draw parallels to\nmany common aspects of reality both in Nature as well as Human Society, and\ntherefore further extends the scope of the iterated prisoner's dilemma as a\nmetaphor for the study of cooperative behaviour in a new and natural direction.\nWe further provide evidence that it will be unavoidable that such group\nstrategies will dominate all future iterated prisoner's dilemma competitions as\nthey can be stealthy camouflaged as non-group strategies with arbitrary\nsubtlety. Moreover, we show that the general problem of recognizing stealth\ncolluding strategies is undecidable in the theoretical sense.", 
    "link": "http://arxiv.org/pdf/cs/0609017v1", 
    "arxiv-id": "cs/0609017v1"
},{
    "category": "cs.GT", 
    "author": "Rob van Stee", 
    "title": "Covering selfish machines", 
    "publish": "2006-10-05T13:20:51Z", 
    "summary": "We consider the machine covering problem for selfish related machines. For a\nconstant number of machines, m, we show a monotone polynomial time\napproximation scheme (PTAS) with running time that is linear in the number of\njobs. It uses a new technique for reducing the number of jobs while remaining\nclose to the optimal solution. We also present an FPTAS for the classical\nmachine covering problem (the previous best result was a PTAS) and use this to\ngive a monotone FPTAS.\n  Additionally, we give a monotone approximation algorithm with approximation\nratio \\min(m,(2+\\eps)s_1/s_m) where \\eps>0 can be chosen arbitrarily small and\ns_i is the (real) speed of machine i. Finally we give improved results for two\nmachines.\n  Our paper presents the first results for this problem in the context of\nselfish machines.", 
    "link": "http://arxiv.org/pdf/cs/0610026v1", 
    "arxiv-id": "cs/0610026v1"
},{
    "category": "cs.GT", 
    "author": "Thierry Cachat", 
    "title": "Tree Automata Make Ordinal Theory Easy", 
    "publish": "2006-10-30T11:05:35Z", 
    "summary": "We give a new simple proof of the decidability of the First Order Theory of\n(omega^omega^i,+) and the Monadic Second Order Theory of (omega^i,<), improving\nthe complexity in both cases. Our algorithm is based on tree automata and a new\nrepresentation of (sets of) ordinals by (infinite) trees.", 
    "link": "http://arxiv.org/pdf/cs/0610166v1", 
    "arxiv-id": "cs/0610166v1"
},{
    "category": "cs.GT", 
    "author": "Anuj Kumar", 
    "title": "Characterizing Optimal Adword Auctions", 
    "publish": "2006-11-15T19:09:13Z", 
    "summary": "We present a number of models for the adword auctions used for pricing\nadvertising slots on search engines such as Google, Yahoo! etc. We begin with a\ngeneral problem formulation which allows the privately known valuation per\nclick to be a function of both the identity of the advertiser and the slot. We\npresent a compact characterization of the set of all deterministic incentive\ncompatible direct mechanisms for this model. This new characterization allows\nus to conclude that there are incentive compatible mechanisms for this auction\nwith a multi-dimensional type-space that are {\\em not} affine maximizers. Next,\nwe discuss two interesting special cases: slot independent valuation and slot\nindependent valuation up to a privately known slot and zero thereafter. For\nboth of these special cases, we characterize revenue maximizing and efficiency\nmaximizing mechanisms and show that these mechanisms can be computed with a\nworst case computational complexity $O(n^2m^2)$ and $O(n^2m^3)$ respectively,\nwhere $n$ is number of bidders and $m$ is number of slots. Next, we\ncharacterize optimal rank based allocation rules and propose a new mechanism\nthat we call the customized rank based allocation. We report the results of a\nnumerical study that compare the revenue and efficiency of the proposed\nmechanisms. The numerical results suggest that customized rank-based allocation\nrule is significantly superior to the rank-based allocation rules.", 
    "link": "http://arxiv.org/pdf/cs/0611063v1", 
    "arxiv-id": "cs/0611063v1"
},{
    "category": "cs.GT", 
    "author": "Fran\u00e7ois Charpillet", 
    "title": "Computing the Equilibria of Bimatrix Games using Dominance Heuristics", 
    "publish": "2006-12-06T15:55:21Z", 
    "summary": "We propose a formulation of a general-sum bimatrix game as a bipartite\ndirected graph with the objective of establishing a correspondence between the\nset of the relevant structures of the graph (in particular elementary cycles)\nand the set of the Nash equilibria of the game. We show that finding the set of\nelementary cycles of the graph permits the computation of the set of\nequilibria. For games whose graphs have a sparse adjacency matrix, this serves\nas a good heuristic for computing the set of equilibria. The heuristic also\nallows the discarding of sections of the support space that do not yield any\nequilibrium, thus serving as a useful pre-processing step for algorithms that\ncompute the equilibria through support enumeration.", 
    "link": "http://arxiv.org/pdf/cs/0612039v1", 
    "arxiv-id": "cs/0612039v1"
},{
    "category": "cs.GT", 
    "author": "Shang-Hua Teng", 
    "title": "A bounded-degree network formation game", 
    "publish": "2007-01-10T18:59:09Z", 
    "summary": "Motivated by applications in peer-to-peer and overlay networks we define and\nstudy the \\emph{Bounded Degree Network Formation} (BDNF) game. In an\n$(n,k)$-BDNF game, we are given $n$ nodes, a bound $k$ on the out-degree of\neach node, and a weight $w_{vu}$ for each ordered pair $(v,u)$ representing the\ntraffic rate from node $v$ to node $u$. Each node $v$ uses up to $k$ directed\nlinks to connect to other nodes with an objective to minimize its average\ndistance, using weights $w_{vu}$, to all other destinations. We study the\nexistence of pure Nash equilibria for $(n,k)$-BDNF games. We show that if the\nweights are arbitrary, then a pure Nash wiring may not exist. Furthermore, it\nis NP-hard to determine whether a pure Nash wiring exists for a given\n$(n,k)$-BDNF instance. A major focus of this paper is on uniform $(n,k)$-BDNF\ngames, in which all weights are 1. We describe how to construct a pure Nash\nequilibrium wiring given any $n$ and $k$, and establish that in all pure Nash\nwirings the cost of individual nodes cannot differ by more than a factor of\nnearly 2, whereas the diameter cannot exceed $O(\\sqrt{n \\log_k n})$. We also\nanalyze best-response walks on the configuration space defined by the uniform\ngame, and show that starting from any initial configuration, strong\nconnectivity is reached within $\\Theta(n^2)$ rounds. Convergence to a pure Nash\nequilibrium, however, is not guaranteed. We present simulation results that\nsuggest that loop-free best-response walks always exist, but may not be\npolynomially bounded. We also study a special family of \\emph{regular} wirings,\nthe class of Abelian Cayley graphs, in which all nodes imitate the same wiring\npattern, and show that if $n$ is sufficiently large no such regular wiring can\nbe a pure Nash equilibrium.", 
    "link": "http://arxiv.org/pdf/cs/0701071v2", 
    "arxiv-id": "cs/0701071v2"
},{
    "category": "cs.GT", 
    "author": "Willem Visser", 
    "title": "Predicate Abstraction with Under-approximation Refinement", 
    "publish": "2007-01-22T21:29:37Z", 
    "summary": "We propose an abstraction-based model checking method which relies on\nrefinement of an under-approximation of the feasible behaviors of the system\nunder analysis. The method preserves errors to safety properties, since all\nanalyzed behaviors are feasible by definition. The method does not require an\nabstract transition relation to be generated, but instead executes the concrete\ntransitions while storing abstract versions of the concrete states, as\nspecified by a set of abstraction predicates. For each explored transition the\nmethod checks, with the help of a theorem prover, whether there is any loss of\nprecision introduced by abstraction. The results of these checks are used to\ndecide termination or to refine the abstraction by generating new abstraction\npredicates. If the (possibly infinite) concrete system under analysis has a\nfinite bisimulation quotient, then the method is guaranteed to eventually\nexplore an equivalent finite bisimilar structure. We illustrate the application\nof the approach for checking concurrent programs.", 
    "link": "http://arxiv.org/pdf/cs/0701140v2", 
    "arxiv-id": "cs/0701140v2"
},{
    "category": "cs.GT", 
    "author": "Shang-Hua Teng", 
    "title": "Paths Beyond Local Search: A Nearly Tight Bound for Randomized   Fixed-Point Computation", 
    "publish": "2007-02-16T07:32:47Z", 
    "summary": "In 1983, Aldous proved that randomization can speedup local search. For\nexample, it reduces the query complexity of local search over [1:n]^d from\nTheta (n^{d-1}) to O (d^{1/2}n^{d/2}). It remains open whether randomization\nhelps fixed-point computation. Inspired by this open problem and recent\nadvances on equilibrium computation, we have been fascinated by the following\nquestion:\n  Is a fixed-point or an equilibrium fundamentally harder to find than a local\noptimum? In this paper, we give a nearly-tight bound of Omega(n)^{d-1} on the\nrandomized query complexity for computing a fixed point of a discrete Brouwer\nfunction over [1:n]^d. Since the randomized query complexity of global\noptimization over [1:n]^d is Theta (n^{d}), the randomized query model over\n[1:n]^d strictly separates these three important search problems: Global\noptimization is harder than fixed-point computation, and fixed-point\ncomputation is harder than local search. Our result indeed demonstrates that\nrandomization does not help much in fixed-point computation in the query model;\nthe deterministic complexity of this problem is Theta (n^{d-1}).", 
    "link": "http://arxiv.org/pdf/cs/0702088v1", 
    "arxiv-id": "cs/0702088v1"
},{
    "category": "cs.GT", 
    "author": "Raphael M. Jungers", 
    "title": "Linear time algorithms for Clobber", 
    "publish": "2007-03-12T17:04:08Z", 
    "summary": "We prove that the single-player game clobber is solvable in linear time when\nplayed on a line or on a cycle. For this purpose, we show that this game is\nequivalent to an optimization problem on a set of words defined by seven\nclasses of forbidden patterns. We also prove that, playing on the cycle, it is\nalways possible to remove at least 2n/3 pawns, and we give a conformation for\nwhich it is not possible to do better, answering questions recently asked by\nFaria et al.", 
    "link": "http://arxiv.org/pdf/cs/0703054v1", 
    "arxiv-id": "cs/0703054v1"
},{
    "category": "cs.GT", 
    "author": "Joseph Y. Halpern", 
    "title": "Computer Science and Game Theory: A Brief Survey", 
    "publish": "2007-03-29T18:43:58Z", 
    "summary": "There has been a remarkable increase in work at the interface of computer\nscience and game theory in the past decade. In this article I survey some of\nthe main themes of work in the area, with a focus on the work in computer\nscience. Given the length constraints, I make no attempt at being\ncomprehensive, especially since other surveys are also available, and a\ncomprehensive survey book will appear shortly.", 
    "link": "http://arxiv.org/pdf/cs/0703148v1", 
    "arxiv-id": "cs/0703148v1"
},{
    "category": "cs.GT", 
    "author": "Igor Walukiewicz", 
    "title": "The Complexity of Games on Higher Order Pushdown Automata", 
    "publish": "2007-05-02T11:48:52Z", 
    "summary": "We prove an n-EXPTIME lower bound for the problem of deciding the winner in a\nreachability game on Higher Order Pushdown Automata (HPDA) of level n. This\nbound matches the known upper bound for parity games on HPDA. As a consequence\nthe mu-calculus model checking over graphs given by n-HPDA is n-EXPTIME\ncomplete.", 
    "link": "http://arxiv.org/pdf/0705.0262v1", 
    "arxiv-id": "0705.0262v1"
},{
    "category": "cs.GT", 
    "author": "Arantza Est\u00e9vez-Fern\u00e1ndez", 
    "title": "Sequential mechanism design", 
    "publish": "2007-05-15T15:24:16Z", 
    "summary": "In the customary VCG (Vickrey-Clarke-Groves) mechanism truth-telling is a\ndominant strategy. In this paper we study the sequential VCG mechanism and show\nthat other dominant strategies may then exist. We illustrate how this fact can\nbe used to minimize taxes using examples concerned with Clarke tax and public\nprojects.", 
    "link": "http://arxiv.org/pdf/0705.2170v1", 
    "arxiv-id": "0705.2170v1"
},{
    "category": "cs.GT", 
    "author": "Ian Kash", 
    "title": "Efficiency and Nash Equilibria in a Scrip System for P2P Networks", 
    "publish": "2007-05-28T20:53:09Z", 
    "summary": "A model of providing service in a P2P network is analyzed. It is shown that\nby adding a scrip system, a mechanism that admits a reasonable Nash equilibrium\nthat reduces free riding can be obtained. The effect of varying the total\namount of money (scrip) in the system on efficiency (i.e., social welfare) is\nanalyzed, and it is shown that by maintaining the appropriate ratio between the\ntotal amount of money and the number of agents, efficiency is maximized. The\nwork has implications for many online systems, not only P2P networks but also a\nwide variety of online forums for which scrip systems are popular, but formal\nanalyses have been lacking.", 
    "link": "http://arxiv.org/pdf/0705.4094v1", 
    "arxiv-id": "0705.4094v1"
},{
    "category": "cs.GT", 
    "author": "Joseph Y. Halpern", 
    "title": "Optimizing Scrip Systems: Efficiency, Crashes, Hoarders, and Altruists", 
    "publish": "2007-05-28T21:14:04Z", 
    "summary": "We discuss the design of efficient scrip systems and develop tools for\nempirically analyzing them. For those interested in the empirical study of\nscrip systems, we demonstrate how characteristics of agents in a system can be\ninferred from the equilibrium distribution of money. From the perspective of a\nsystem designer, we examine the effect of the money supply on social welfare\nand show that social welfare is maximized by increasing the money supply up to\nthe point that the system experiences a ``monetary crash,'' where money is\nsufficiently devalued that no agent is willing to perform a service. We also\nexamine the implications of the presence of altruists and hoarders on the\nperformance of the system. While a small number of altruists may improve social\nwelfare, too many can also cause the system to experience a monetary crash,\nwhich may be bad for social welfare. Hoarders generally decrease social welfare\nbut, surprisingly, they also promote system stability by helping prevent\nmonetary crashes. In addition, we provide new technical tools for analyzing and\ncomputing equilibria by showing that our model exhibits strategic\ncomplementarities, which implies that there exist equilibria in pure strategies\nthat can be computed efficiently.", 
    "link": "http://arxiv.org/pdf/0705.4110v1", 
    "arxiv-id": "0705.4110v1"
},{
    "category": "cs.GT", 
    "author": "Krzysztof R. Apt", 
    "title": "Relative Strength of Strategy Elimination Procedures", 
    "publish": "2007-06-12T07:02:13Z", 
    "summary": "We compare here the relative strength of four widely used procedures on\nfinite strategic games: iterated elimination of weakly/strictly dominated\nstrategies by a pure/mixed strategy. A complication is that none of these\nprocedures is based on a monotonic operator. To deal with this problem we use\n'global' versions of these operators.", 
    "link": "http://arxiv.org/pdf/0706.1617v1", 
    "arxiv-id": "0706.1617v1"
},{
    "category": "cs.GT", 
    "author": "Corinne Touati", 
    "title": "How to measure efficiency?", 
    "publish": "2007-06-12T12:25:54Z", 
    "summary": "In the context of applied game theory in networking environments, a number of\nconcepts have been proposed to measure both efficiency and optimality of\nresource allocations, the most famous certainly being the price of anarchy and\nthe Jain index. Yet, very few have tried to question these measures and compare\nthem one to another, in a general framework, which is the aim of the present\narticle.", 
    "link": "http://arxiv.org/pdf/0706.1790v2", 
    "arxiv-id": "0706.1790v2"
},{
    "category": "cs.GT", 
    "author": "Behnam A. Rezaei", 
    "title": "Exploration via design and the cost of uncertainty in keyword auctions", 
    "publish": "2007-07-06T22:11:17Z", 
    "summary": "We present a deterministic exploration mechanism for sponsored search\nauctions, which enables the auctioneer to learn the relevance scores of\nadvertisers, and allows advertisers to estimate the true value of clicks\ngenerated at the auction site. This exploratory mechanism deviates only\nminimally from the mechanism being currently used by Google and Yahoo! in the\nsense that it retains the same pricing rule, similar ranking scheme, as well\nas, similar mathematical structure of payoffs. In particular, the estimations\nof the relevance scores and true-values are achieved by providing a chance to\nlower ranked advertisers to obtain better slots. This allows the search engine\nto potentially test a new pool of advertisers, and correspondingly, enables new\nadvertisers to estimate the value of clicks/leads generated via the auction.\nBoth these quantities are unknown a priori, and their knowledge is necessary\nfor the auction to operate efficiently. We show that such an exploration policy\ncan be incorporated without any significant loss in revenue for the auctioneer.\nWe compare the revenue of the new mechanism to that of the standard mechanism\nat their corresponding symmetric Nash equilibria and compute the cost of\nuncertainty, which is defined as the relative loss in expected revenue per\nimpression. We also bound the loss in efficiency, as well as, in user\nexperience due to exploration, under the same solution concept (i.e. SNE). Thus\nthe proposed exploration mechanism learns the relevance scores while\nincorporating the incentive constraints from the advertisers who are selfish\nand are trying to maximize their own profits, and therefore, the exploration is\nessentially achieved via mechanism design. We also discuss variations of the\nnew mechanism such as truthful implementations.", 
    "link": "http://arxiv.org/pdf/0707.1053v2", 
    "arxiv-id": "0707.1053v2"
},{
    "category": "cs.GT", 
    "author": "Behnam A. Rezaei", 
    "title": "For-profit mediators in sponsored search advertising", 
    "publish": "2007-07-07T03:18:26Z", 
    "summary": "A mediator is a well-known construct in game theory, and is an entity that\nplays on behalf of some of the agents who choose to use its services, while the\nrest of the agents participate in the game directly. We initiate a game\ntheoretic study of sponsored search auctions, such as those used by Google and\nYahoo!, involving {\\em incentive driven} mediators. We refer to such mediators\nas {\\em for-profit} mediators, so as to distinguish them from mediators\nintroduced in prior work, who have no monetary incentives, and are driven by\nthe altruistic goal of implementing certain desired outcomes. We show that in\nour model, (i) players/advertisers can improve their payoffs by choosing to use\nthe services of the mediator, compared to directly participating in the\nauction; (ii) the mediator can obtain monetary benefit by managing the\nadvertising burden of its group of advertisers; and (iii) the payoffs of the\nmediator and the advertisers it plays for are compatible with the incentive\nconstraints from the advertisers who do dot use its services. A simple\nintuition behind the above result comes from the observation that the mediator\nhas more information about and more control over the bid profile than any\nindividual advertiser, allowing her to reduce the payments made to the\nauctioneer, while still maintaining incentive constraints. Further, our results\nindicate that there are significant opportunities for diversification in the\ninternet economy and we should expect it to continue to develop richer\nstructure, with room for different types of agents to coexist.", 
    "link": "http://arxiv.org/pdf/0707.1057v2", 
    "arxiv-id": "0707.1057v2"
},{
    "category": "cs.GT", 
    "author": "Joseph Y. Halpern", 
    "title": "Generalized Solution Concepts in Games with Possibly Unaware Players", 
    "publish": "2007-07-12T23:21:16Z", 
    "summary": "Most work in game theory assumes that players are perfect reasoners and have\ncommon knowledge of all significant aspects of the game. In earlier work, we\nproposed a framework for representing and analyzing games with possibly unaware\nplayers, and suggested a generalization of Nash equilibrium appropriate for\ngames with unaware players that we called generalized Nash equilibrium. Here,\nwe use this framework to analyze other solution concepts that have been\nconsidered in the game-theory literature, with a focus on sequential\nequilibrium. We also provide some insight into the notion of generalized Nash\nequilibrium by proving that it is closely related to the notion of\nrationalizability when we restrict the analysis to games in normal form and no\nunawareness is involved.", 
    "link": "http://arxiv.org/pdf/0707.1904v1", 
    "arxiv-id": "0707.1904v1"
},{
    "category": "cs.GT", 
    "author": "Adrian Riskin", 
    "title": "A system for the simulation of simultaneous moves between two   noncolocational players", 
    "publish": "2007-08-31T16:03:21Z", 
    "summary": "We describe a new system for the simulation of simultaneous moves between\nnoncolocational players. This has applications in the burgeoning\nRock-Paper-Scissors by mail movement.", 
    "link": "http://arxiv.org/pdf/0708.4379v1", 
    "arxiv-id": "0708.4379v1"
},{
    "category": "cs.GT", 
    "author": "Behnam A. Rezaei", 
    "title": "Capacity constraints and the inevitability of mediators in adword   auctions", 
    "publish": "2007-09-03T12:09:56Z", 
    "summary": "One natural constraint in the sponsored search advertising framework arises\nfrom the fact that there is a limit on the number of available slots,\nespecially for the popular keywords, and as a result, a significant pool of\nadvertisers are left out. We study the emergence of diversification in the\nadword market triggered by such capacity constraints in the sense that new\nmarket mechanisms, as well as, new for-profit agents are likely to emerge to\ncombat or to make profit from the opportunities created by shortages in\nad-space inventory. We propose a model where the additional capacity is\nprovided by for-profit agents (or, mediators), who compete for slots in the\noriginal auction, draw traffic, and run their own sub-auctions. The quality of\nthe additional capacity provided by a mediator is measured by its {\\it fitness}\nfactor. We compute revenues and payoffs for all the different parties at a {\\it\nsymmetric Nash equilibrium} (SNE) when the mediator-based model is operated by\na mechanism currently being used by Google and Yahoo!, and then compare these\nnumbers with those obtained at a corresponding SNE for the same mechanism, but\nwithout any mediators involved in the auctions. Such calculations allow us to\ndetermine the value of the additional capacity. Our results show that the\nrevenue of the auctioneer, as well as the social value (i.e. efficiency),\nalways increase when mediators are involved; moreover even the payoffs of {\\em\nall} the bidders will increase if the mediator has a high enough fitness. Thus,\nour analysis indicates that there are significant opportunities for\ndiversification in the internet economy and we should expect it to continue to\ndevelop richer structure, with room for different types of agents and\nmechanisms to coexist.", 
    "link": "http://arxiv.org/pdf/0709.0204v1", 
    "arxiv-id": "0709.0204v1"
},{
    "category": "cs.GT", 
    "author": "Andreas Witzel", 
    "title": "A Generic Approach to Coalition Formation", 
    "publish": "2007-09-04T14:15:28Z", 
    "summary": "We propose an abstract approach to coalition formation that focuses on simple\nmerge and split rules transforming partitions of a group of players. We\nidentify conditions under which every iteration of these rules yields a unique\npartition. The main conceptual tool is a specific notion of a stable partition.\nThe results are parametrized by a preference relation between partitions of a\ngroup of players and naturally apply to coalitional TU-games, hedonic games and\nexchange economy games.", 
    "link": "http://arxiv.org/pdf/0709.0435v3", 
    "arxiv-id": "0709.0435v3"
},{
    "category": "cs.GT", 
    "author": "Andrea Goldsmith", 
    "title": "Competition in Wireless Systems via Bayesian Interference Games", 
    "publish": "2007-09-04T19:45:00Z", 
    "summary": "We study competition between wireless devices with incomplete information\nabout their opponents. We model such interactions as Bayesian interference\ngames. Each wireless device selects a power profile over the entire available\nbandwidth to maximize its data rate. Such competitive models represent\nsituations in which several wireless devices share spectrum without any central\nauthority or coordinated protocol.\n  In contrast to games where devices have complete information about their\nopponents, we consider scenarios where the devices are unaware of the\ninterference they cause to other devices. Such games, which are modeled as\nBayesian games, can exhibit significantly different equilibria. We first\nconsider a simple scenario of simultaneous move games, where we show that the\nunique Bayes-Nash equilibrium is where both devices spread their power equally\nacross the entire bandwidth. We then extend this model to a two-tiered spectrum\nsharing case where users act sequentially. Here one of the devices, called the\nprimary user, is the owner of the spectrum and it selects its power profile\nfirst. The second device (called the secondary user) then responds by choosing\na power profile to maximize its Shannon capacity. In such sequential move\ngames, we show that there exist equilibria in which the primary user obtains a\nhigher data rate by using only a part of the bandwidth.\n  In a repeated Bayesian interference game, we show the existence of reputation\neffects: an informed primary user can bluff to prevent spectrum usage by a\nsecondary user who suffers from lack of information about the channel gains.\nThe resulting equilibrium can be highly inefficient, suggesting that\ncompetitive spectrum sharing is highly suboptimal.", 
    "link": "http://arxiv.org/pdf/0709.0516v1", 
    "arxiv-id": "0709.0516v1"
},{
    "category": "cs.GT", 
    "author": "Edmund M. Yeh", 
    "title": "Pricing, Competition, and Routing for Selfish and Strategic Nodes in   Multi-hop Relay Networks", 
    "publish": "2007-09-17T20:52:29Z", 
    "summary": "We study a pricing game in multi-hop relay networks where nodes price their\nservices and route their traffic selfishly and strategically. In this game,\neach node (1) announces pricing functions which specify the payments it demands\nfrom its respective customers depending on the amount of traffic they route to\nit and (2) allocates the total traffic it receives to its service providers.\nThe profit of a node is the difference between the revenue earned from\nservicing others and the cost of using others' services. We show that the\nsocially optimal routing of such a game can always be induced by an equilibrium\nwhere no node can increase its profit by unilaterally changing its pricing\nfunctions or routing decision. On the other hand, there may also exist\ninefficient equilibria. We characterize the loss of efficiency by deriving the\nprice of anarchy at inefficient equilibria. We show that the price of anarchy\nis finite for oligopolies with concave marginal cost functions, while it is\ninfinite for general topologies and cost functions.", 
    "link": "http://arxiv.org/pdf/0709.2721v2", 
    "arxiv-id": "0709.2721v2"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "A New Perspective on Multi-user Power Control Games in Interference   Channels", 
    "publish": "2007-09-25T06:34:20Z", 
    "summary": "This paper considers the problem of how to allocate power among competing\nusers sharing a frequency-selective interference channel. We model the\ninteraction between selfish users as a non-cooperative game. As opposed to the\nexisting iterative water-filling algorithm that studies the myopic users, this\npaper studies how a foresighted user, who knows the channel state information\nand response strategies of its competing users, should optimize its\ntransmission strategy. To characterize this multi-user interaction, the\nStackelberg equilibrium is introduced, and the existence of this equilibrium\nfor the investigated non-cooperative game is shown. We analyze this interaction\nin more detail using a simple two-user example, where the foresighted user\ndetermines its transmission strategy by solving as a bi-level program which\nallows him to account for the myopic user's response. It is analytically shown\nthat a foresighted user can improve its performance, if it has the necessary\ninformation about its competitors. Since the optimal solution of Stackelberg\nequilibrium is computationally prohibitive, we propose a practical\nlow-complexity approach based on Lagrangian duality theory. Numerical\nsimulations verify the performance improvements. Possible ways to acquire the\nrequired information and to extend the formulation to more than two users are\nalso discussed.", 
    "link": "http://arxiv.org/pdf/0709.3880v2", 
    "arxiv-id": "0709.3880v2"
},{
    "category": "cs.GT", 
    "author": "Jonathan A. Zvesper", 
    "title": "Common Beliefs and Public Announcements in Strategic Games with   Arbitrary Strategy Sets", 
    "publish": "2007-10-18T15:28:58Z", 
    "summary": "We provide an epistemic analysis of arbitrary strategic games based on\npossibility correspondences. We first establish a generic result that links\ntrue common beliefs (and, respectively, common knowledge) of players'\nrationality defined by means of `monotonic' properties, with the iterated\nelimination of strategies that do not satisfy these properties. It allows us to\ndeduce the customary results concerned with true common beliefs of rationality\nand iterated elimination of strictly dominated strategies as simple\ncorollaries. This approach relies on Tarski's Fixpoint Theorem. We also provide\nan axiomatic presentation of this generic result. This allows us to clarify the\nproof-theoretic principles assumed in players' reasoning. Finally, we provide\nan alternative characterization of the iterated elimination of strategies based\non the concept of a public announcement. It applies to `global properties'.\nBoth classes of properties include the notions of rationalizability and the\niterated elimination of strictly dominated strategies.", 
    "link": "http://arxiv.org/pdf/0710.3536v2", 
    "arxiv-id": "0710.3536v2"
},{
    "category": "cs.GT", 
    "author": "Behnam A. Rezaei", 
    "title": "Diversification in the Internet Economy:The Role of For-Profit Mediators", 
    "publish": "2007-11-02T08:38:40Z", 
    "summary": "We investigate market forces that would lead to the emergence of new classes\nof players in the sponsored search market. We report a 3-fold diversification\ntriggered by two inherent features of the sponsored search market, namely,\ncapacity constraints and collusion-vulnerability of current mechanisms. In the\nfirst scenario, we present a comparative study of two models motivated by\ncapacity constraints - one where the additional capacity is provided by\nfor-profit agents, who compete for slots in the original auction, draw traffic,\nand run their own sub-auctions, and the other, where the additional capacity is\nprovided by the auctioneer herself, by essentially acting as a mediator and\nrunning a single combined auction. This study was initiated by us in\n\\cite{SRGR07}, where the mediator-based model was studied. In the present work,\nwe study the auctioneer-based model and show that this model seems inferior to\nthe mediator-based model in terms of revenue or efficiency guarantee due to\nadded capacity. In the second scenario, we initiate a game theoretic study of\ncurrent sponsored search auctions, involving incentive driven mediators who\nexploit the fact that these mechanisms are not collusion-resistant. In\nparticular, we show that advertisers can improve their payoffs by using the\nservices of the mediator compared to directly participating in the auction, and\nthat the mediator can also obtain monetary benefit, without violating incentive\nconstraints from the advertisers who do not use its services. We also point out\nthat the auctioneer can not do very much via mechanism design to avoid such\nfor-profit mediation without losing badly in terms of revenue, and therefore,\nthe mediators are likely to prevail.", 
    "link": "http://arxiv.org/pdf/0711.0259v1", 
    "arxiv-id": "0711.0259v1"
},{
    "category": "cs.GT", 
    "author": "P. Polpinit", 
    "title": "The Price of Selfish Stackelberg Leadership in a Network Game", 
    "publish": "2007-11-08T10:50:00Z", 
    "summary": "We study a class of games in which a finite number of agents each controls a\nquantity of flow to be routed through a network, and are able to split their\nown flow between multiple paths through the network. Recent work on this model\nhas contrasted the social cost of Nash equilibria with the best possible social\ncost. Here we show that additional costs are incurred in situations where a\nselfish ``leader'' agent allocates his flow, and then commits to that choice so\nthat other agents are compelled to minimise their own cost based on the first\nagent's choice. We find that even in simple networks, the leader can often\nimprove his own cost at the expense of increased social cost. Focusing on the\n2-player case, we give upper and lower bounds on the worst-case additional cost\nincurred.", 
    "link": "http://arxiv.org/pdf/0711.1242v1", 
    "arxiv-id": "0711.1242v1"
},{
    "category": "cs.GT", 
    "author": "Vwani P. Roychowdhury", 
    "title": "Capacity as a Fundamental Metric for Mechanism Design in the Information   Economy", 
    "publish": "2007-11-10T04:30:58Z", 
    "summary": "The auction theory literature has so far focused mostly on the design of\nmechanisms that takes the revenue or the efficiency as a yardstick. However,\nscenarios where the {\\it capacity}, which we define as \\textit{``the number of\nbidders the auctioneer wants to have a positive probability of getting the\nitem''}, is a fundamental concern are ubiquitous in the information economy.\nFor instance, in sponsored search auctions (SSA's) or in online ad-exchanges,\nthe true value of an ad-slot for an advertiser is inherently derived from the\nconversion-rate, which in turn depends on whether the advertiser actually\nobtained the ad-slot or not; thus, unless the capacity of the underlying\nauction is large, key parameters, such as true valuations and\nadvertiser-specific conversion rates, will remain unknown or uncertain leading\nto inherent inefficiencies in the system. In general, the same holds true for\nall information goods/digital goods. We initiate a study of mechanisms, which\ntake capacity as a yardstick, in addition to revenue/efficiency. We show that\nin the case of a single indivisible item one simple way to incorporate capacity\nconstraints is via designing mechanisms to sell probability distributions, and\nthat under certain conditions, such optimal probability distributions could be\nidentified using a Linear programming approach. We define a quantity called\n{\\it price of capacity} to capture the tradeoff between capacity and\nrevenue/efficiency. We also study the case of sponsored search auctions.\nFinally, we discuss how general such an approach via probability spikes can be\nmade, and potential directions for future investigations.", 
    "link": "http://arxiv.org/pdf/0711.1569v1", 
    "arxiv-id": "0711.1569v1"
},{
    "category": "cs.GT", 
    "author": "St\u00e9phane Le Roux", 
    "title": "Discrete Nondeterminism and Nash Equilibria for Strategy-Based Games", 
    "publish": "2007-12-10T15:53:54Z", 
    "summary": "Several notions of game enjoy a Nash-like notion of equilibrium without\nguarantee of existence. There are different ways of weakening a definition of\nNash-like equilibrium in order to guarantee the existence of a weakened\nequilibrium. Nash's approach to the problem for strategic games is\nprobabilistic, \\textit{i.e.} continuous, and static. CP and BR approaches for\nCP and BR games are discrete and dynamic. This paper proposes an approach that\nlies between those two different approaches: a discrete and static approach.\nmulti strategic games are introduced as a formalism that is able to express\nboth sequential and simultaneous decision-making, which promises a good\nmodelling power. multi strategic games are a generalisation of strategic games\nand sequential graph games that still enjoys a Cartesian product structure,\n\\textit{i.e.} where agent actually choose their strategies. A pre-fixed point\nresult allows guaranteeing existence of discrete and non deterministic\nequilibria. On the one hand, these equilibria can be computed with polynomial\n(low) complexity. On the other hand, they are effective in terms of\nrecommendation, as shown by a numerical example.", 
    "link": "http://arxiv.org/pdf/0712.1519v1", 
    "arxiv-id": "0712.1519v1"
},{
    "category": "cs.GT", 
    "author": "St\u00e9phane Le Roux", 
    "title": "Graphs and Path Equilibria", 
    "publish": "2007-12-10T15:56:13Z", 
    "summary": "The quest for optimal/stable paths in graphs has gained attention in a few\npractical or theoretical areas. To take part in this quest this chapter adopts\nan equilibrium-oriented approach that is abstract and general: it works with\n(quasi-arbitrary) arc-labelled digraphs, and it assumes very little about the\nstructure of the sought paths and the definition of equilibrium, \\textit{i.e.}\noptimality/stability. In this setting, this chapter presents a sufficient\ncondition for equilibrium existence for every graph; it also presents a\nnecessary condition for equilibrium existence for every graph. The necessary\ncondition does not imply the sufficient condition a priori. However, the\nchapter pinpoints their logical difference and thus identifies what work\nremains to be done. Moreover, the necessary and the sufficient conditions\ncoincide when the definition of optimality relates to a total order, which\nprovides a full-equivalence property. These results are applied to network\nrouting.", 
    "link": "http://arxiv.org/pdf/0712.1521v1", 
    "arxiv-id": "0712.1521v1"
},{
    "category": "cs.GT", 
    "author": "Florian Horn", 
    "title": "Solving Simple Stochastic Games with Few Random Vertices", 
    "publish": "2007-12-11T16:50:51Z", 
    "summary": "Simple stochastic games are two-player zero-sum stochastic games with\nturn-based moves, perfect information, and reachability winning conditions. We\npresent two new algorithms computing the values of simple stochastic games.\nBoth of them rely on the existence of optimal permutation strategies, a class\nof positional strategies derived from permutations of the random vertices. The\n\"permutation-enumeration\" algorithm performs an exhaustive search among these\nstrategies, while the \"permutation-improvement\" algorithm is based on\nsuccessive improvements, \\`a la Hoffman-Karp. Our algorithms improve previously\nknown algorithms in several aspects. First they run in polynomial time when the\nnumber of random vertices is fixed, so the problem of solving simple stochastic\ngames is fixed-parameter tractable when the parameter is the number of random\nvertices. Furthermore, our algorithms do not require the input game to be\ntransformed into a stopping game. Finally, the permutation-enumeration\nalgorithm does not use linear programming, while the permutation-improvement\nalgorithm may run in polynomial time.", 
    "link": "http://arxiv.org/pdf/0712.1765v6", 
    "arxiv-id": "0712.1765v6"
},{
    "category": "cs.GT", 
    "author": "J\u00e9r\u00f4me Puiss\u00e9gur", 
    "title": "Dynamic Logic of Common Knowledge in a Proof Assistant", 
    "publish": "2007-12-19T10:23:14Z", 
    "summary": "Common Knowledge Logic is meant to describe situations of the real world\nwhere a group of agents is involved. These agents share knowledge and make\nstrong statements on the knowledge of the other agents (the so called\n\\emph{common knowledge}). But as we know, the real world changes and overall\ninformation on what is known about the world changes as well. The changes are\ndescribed by dynamic logic. To describe knowledge changes, dynamic logic should\nbe combined with logic of common knowledge. In this paper we describe\nexperiments which we have made about the integration in a unique framework of\ncommon knowledge logic and dynamic logic in the proof assistant \\Coq. This\nresults in a set of fully checked proofs for readable statements. We describe\nthe framework and how a proof can be", 
    "link": "http://arxiv.org/pdf/0712.3146v1", 
    "arxiv-id": "0712.3146v1"
},{
    "category": "cs.GT", 
    "author": "Kerry Michael Soileau", 
    "title": "Nash bargaining with a nondeterministic threat", 
    "publish": "2007-12-29T21:39:31Z", 
    "summary": "We consider bargaining problems which involve two participants, with a\nnonempty closed, bounded convex bargaining set of points in the real plane\nrepresenting all realizable bargains. We also assume that there is no definite\nthreat or disagreement point which will provide the default bargain if the\nplayers cannot agree on some point in the bargaining set. However, there is a\nnondeterministic threat: if the players fail to agree on a bargain, one of them\nwill be chosen at random with equal probability, and that chosen player will\nselect any realizable bargain as the solution, subject to a reasonable\nrestriction.", 
    "link": "http://arxiv.org/pdf/0801.0092v2", 
    "arxiv-id": "0801.0092v2"
},{
    "category": "cs.GT", 
    "author": "Jennifer Wortman", 
    "title": "Complexity of Combinatorial Market Makers", 
    "publish": "2008-02-11T00:23:17Z", 
    "summary": "We analyze the computational complexity of market maker pricing algorithms\nfor combinatorial prediction markets. We focus on Hanson's popular logarithmic\nmarket scoring rule market maker (LMSR). Our goal is to implicitly maintain\ncorrect LMSR prices across an exponentially large outcome space. We examine\nboth permutation combinatorics, where outcomes are permutations of objects, and\nBoolean combinatorics, where outcomes are combinations of binary events. We\nlook at three restrictive languages that limit what traders can bet on. Even\nwith severely limited languages, we find that LMSR pricing is $\\SP$-hard, even\nwhen the same language admits polynomial-time matching without the market\nmaker. We then propose an approximation technique for pricing permutation\nmarkets based on a recent algorithm for online permutation learning. The\nconnections we draw between LMSR pricing and the vast literature on online\nlearning with expert advice may be of independent interest.", 
    "link": "http://arxiv.org/pdf/0802.1362v1", 
    "arxiv-id": "0802.1362v1"
},{
    "category": "cs.GT", 
    "author": "Heiko Roeglin", 
    "title": "Approximate Equilibria in Games with Few Players", 
    "publish": "2008-04-29T03:56:29Z", 
    "summary": "We study the problem of computing approximate Nash equilibria (epsilon-Nash\nequilibria) in normal form games, where the number of players is a small\nconstant. We consider the approach of looking for solutions with constant\nsupport size. It is known from recent work that in the 2-player case, a\n1/2-Nash equilibrium can be easily found, but in general one cannot achieve a\nsmaller value of epsilon than 1/2. In this paper we extend those results to the\nk-player case, and find that epsilon = 1-1/k is feasible, but cannot be\nimproved upon. We show how stronger results for the 2-player case may be used\nin order to slightly improve upon the epsilon = 1-1/k obtained in the k-player\ncase.", 
    "link": "http://arxiv.org/pdf/0804.4524v1", 
    "arxiv-id": "0804.4524v1"
},{
    "category": "cs.GT", 
    "author": "Martin Pal", 
    "title": "Sponsored Search Auctions with Markovian Users", 
    "publish": "2008-05-06T18:05:23Z", 
    "summary": "Sponsored search involves running an auction among advertisers who bid in\norder to have their ad shown next to search results for specific keywords.\nCurrently, the most popular auction for sponsored search is the \"Generalized\nSecond Price\" (GSP) auction in which advertisers are assigned to slots in the\ndecreasing order of their \"score,\" which is defined as the product of their bid\nand click-through rate. In the past few years, there has been significant\nresearch on the game-theoretic issues that arise in an advertiser's interaction\nwith the mechanism as well as possible redesigns of the mechanism, but this\nranking order has remained standard.\n  From a search engine's perspective, the fundamental question is: what is the\nbest assignment of advertisers to slots? Here \"best\" could mean \"maximizing\nuser satisfaction,\" \"most efficient,\" \"revenue-maximizing,\" \"simplest to\ninteract with,\" or a combination of these. To answer this question we need to\nunderstand the behavior of a search engine user when she sees the displayed\nads, since that defines the commodity the advertisers are bidding on, and its\nvalue. Most prior work has assumed that the probability of a user clicking on\nan ad is independent of the other ads shown on the page.\n  We propose a simple Markovian user model that does not make this assumption.\nWe then present an algorithm to determine the most efficient assignment under\nthis model, which turns out to be different than that of GSP. A truthful\nauction then follows from an application of the Vickrey-Clarke-Groves (VCG)\nmechanism. Further, we show that our assignment has many of the desirable\nproperties of GSP that makes bidding intuitive. At the technical core of our\nresult are a number of insights about the structure of the optimal assignment.", 
    "link": "http://arxiv.org/pdf/0805.0766v1", 
    "arxiv-id": "0805.0766v1"
},{
    "category": "cs.GT", 
    "author": "Heiko Roeglin", 
    "title": "On the Convergence Time of the Best Response Dynamics in Player-specific   Congestion Games", 
    "publish": "2008-05-08T10:21:09Z", 
    "summary": "We study the convergence time of the best response dynamics in\nplayer-specific singleton congestion games. It is well known that this dynamics\ncan cycle, although from every state a short sequence of best responses to a\nNash equilibrium exists. Thus, the random best response dynamics, which selects\nthe next player to play a best response uniformly at random, terminates in a\nNash equilibrium with probability one. In this paper, we are interested in the\nexpected number of best responses until the random best response dynamics\nterminates.\n  As a first step towards this goal, we consider games in which each player can\nchoose between only two resources. These games have a natural representation as\n(multi-)graphs by identifying nodes with resources and edges with players. For\nthe class of games that can be represented as trees, we show that the\nbest-response dynamics cannot cycle and that it terminates after O(n^2) steps\nwhere n denotes the number of resources. For the class of games represented as\ncycles, we show that the best response dynamics can cycle. However, we also\nshow that the random best response dynamics terminates after O(n^2) steps in\nexpectation.\n  Additionally, we conjecture that in general player-specific singleton\ncongestion games there exists no polynomial upper bound on the expected number\nof steps until the random best response dynamics terminates. We support our\nconjecture by presenting a family of games for which simulations indicate a\nsuper-polynomial convergence time.", 
    "link": "http://arxiv.org/pdf/0805.1130v1", 
    "arxiv-id": "0805.1130v1"
},{
    "category": "cs.GT", 
    "author": "S. Muthukrishnan", 
    "title": "Algorithmic Methods for Sponsored Search Advertising", 
    "publish": "2008-05-12T23:19:45Z", 
    "summary": "Modern commercial Internet search engines display advertisements along side\nthe search results in response to user queries. Such sponsored search relies on\nmarket mechanisms to elicit prices for these advertisements, making use of an\nauction among advertisers who bid in order to have their ads shown for specific\nkeywords. We present an overview of the current systems for such auctions and\nalso describe the underlying game-theoretic aspects. The game involves three\nparties--advertisers, the search engine, and search users--and we present\nexample research directions that emphasize the role of each. The algorithms for\nbidding and pricing in these games use techniques from three mathematical\nareas: mechanism design, optimization, and statistical estimation. Finally, we\npresent some challenges in sponsored search advertising.", 
    "link": "http://arxiv.org/pdf/0805.1759v1", 
    "arxiv-id": "0805.1759v1"
},{
    "category": "cs.GT", 
    "author": "Thomas A. Henzinger", 
    "title": "Stochastic Limit-Average Games are in EXPTIME", 
    "publish": "2008-05-16T20:55:08Z", 
    "summary": "The value of a finite-state two-player zero-sum stochastic game with\nlimit-average payoff can be approximated to within $\\epsilon$ in time\nexponential in a polynomial in the size of the game times polynomial in\nlogarithmic in $\\frac{1}{\\epsilon}$, for all $\\epsilon>0$.", 
    "link": "http://arxiv.org/pdf/0805.2622v1", 
    "arxiv-id": "0805.2622v1"
},{
    "category": "cs.GT", 
    "author": "M. Pinter", 
    "title": "Young's axiomatization of the Shapley value - a new proof", 
    "publish": "2008-05-19T07:11:04Z", 
    "summary": "We consider Young (1985)'s characterization of the Shapley value, and give a\nnew proof of this axiomatization. Moreover, as applications of the new proof,\nwe show that Young (1985)'s axiomatization of the Shapley value works on\nvarious well-known subclasses of TU games.", 
    "link": "http://arxiv.org/pdf/0805.2797v3", 
    "arxiv-id": "0805.2797v3"
},{
    "category": "cs.GT", 
    "author": "Marc Lelarge", 
    "title": "Marketing in Random Networks", 
    "publish": "2008-05-21T08:36:01Z", 
    "summary": "Viral marketing takes advantage of preexisting social networks among\ncustomers to achieve large changes in behaviour. Models of influence spread\nhave been studied in a number of domains, including the effect of \"word of\nmouth\" in the promotion of new products or the diffusion of technologies. A\nsocial network can be represented by a graph where the nodes are individuals\nand the edges indicate a form of social relationship. The flow of influence\nthrough this network can be thought of as an increasing process of active\nnodes: as individuals become aware of new technologies, they have the potential\nto pass them on to their neighbours. The goal of marketing is to trigger a\nlarge cascade of adoptions. In this paper, we develop a mathematical model that\nallows to analyze the dynamics of the cascading sequence of nodes switching to\nthe new technology. To this end we describe a continuous-time and a\ndiscrete-time models and analyse the proportion of nodes that adopt the new\ntechnology over time.", 
    "link": "http://arxiv.org/pdf/0805.3155v4", 
    "arxiv-id": "0805.3155v4"
},{
    "category": "cs.GT", 
    "author": "Miklos Pinter", 
    "title": "Every hierarchy of beliefs is a type", 
    "publish": "2008-05-26T19:43:18Z", 
    "summary": "When modeling game situations of incomplete information one usually considers\nthe players' hierarchies of beliefs, a source of all sorts of complications.\nHars\\'anyi (1967-68)'s idea henceforth referred to as the \"Hars\\'anyi program\"\nis that hierarchies of beliefs can be replaced by \"types\". The types constitute\nthe \"type space\". In the purely measurable framework Heifetz and Samet (1998)\nformalize the concept of type spaces and prove the existence and the uniqueness\nof a universal type space. Meier (2001) shows that the purely measurable\nuniversal type space is complete, i.e., it is a consistent object. With the aim\nof adding the finishing touch to these results, we will prove in this paper\nthat in the purely measurable framework every hierarchy of beliefs can be\nrepresented by a unique element of the complete universal type space.", 
    "link": "http://arxiv.org/pdf/0805.4007v3", 
    "arxiv-id": "0805.4007v3"
},{
    "category": "cs.GT", 
    "author": "Bobo Nick", 
    "title": "Network Connection Games with Disconnected Equilibria", 
    "publish": "2008-05-28T12:09:15Z", 
    "summary": "In this paper we extend a popular non-cooperative network creation game (NCG)\nto allow for disconnected equilibrium networks. There are n players, each is a\nvertex in a graph, and a strategy is a subset of players to build edges to. For\neach edge a player must pay a cost \\alpha, and the individual cost for a player\nrepresents a trade-off between edge costs and shortest path lengths to all\nother players. We extend the model to a penalized game (PCG), for which we\nreduce the penalty counted towards the individual cost for a pair of\ndisconnected players to a finite value \\beta. Our analysis concentrates on\nexistence, structure, and cost of disconnected Nash and strong equilibria.\nAlthough the PCG is not a potential game, pure Nash equilibria always and pure\nstrong equilibria very often exist. We provide tight conditions under which\ndisconnected Nash (strong) equilibria can evolve. Components of these\nequilibria must be Nash (strong) equilibria of a smaller NCG. However, in\ncontrast to the NCG, for almost all parameter values no tree is a stable\ncomponent. Finally, we present a detailed characterization of the price of\nanarchy that reveals cases in which the price of anarchy is \\Theta(n) and thus\nseveral orders of magnitude larger than in the NCG. Perhaps surprisingly, the\nstrong price of anarchy increases to at most 4. This indicates that global\ncommunication and coordination can be extremely valuable to overcome socially\ninferior topologies in distributed selfish network design.", 
    "link": "http://arxiv.org/pdf/0805.4323v2", 
    "arxiv-id": "0805.4323v2"
},{
    "category": "cs.GT", 
    "author": "Troels Bjerre S\u00f8rensen", 
    "title": "Approximability and parameterized complexity of minmax values", 
    "publish": "2008-06-26T15:31:53Z", 
    "summary": "We consider approximating the minmax value of a multi-player game in\nstrategic form. Tightening recent bounds by Borgs et al., we observe that\napproximating the value with a precision of epsilon log n digits (for any\nconstant epsilon>0 is NP-hard, where n is the size of the game. On the other\nhand, approximating the value with a precision of c log log n digits (for any\nconstant c >= 1) can be done in quasi-polynomial time. We consider the\nparameterized complexity of the problem, with the parameter being the number of\npure strategies k of the player for which the minmax value is computed. We show\nthat if there are three players, k=2 and there are only two possible rational\npayoffs, the minmax value is a rational number and can be computed exactly in\nlinear time. In the general case, we show that the value can be approximated\nwith any polynomial number of digits of accuracy in time n^(O(k)). On the other\nhand, we show that minmax value approximation is W[1]-hard and hence not likely\nto be fixed parameter tractable. Concretely, we show that if k-CLIQUE requires\ntime n^(Omega(k)) then so does minmax value computation.", 
    "link": "http://arxiv.org/pdf/0806.4344v1", 
    "arxiv-id": "0806.4344v1"
},{
    "category": "cs.GT", 
    "author": "Martin Pal", 
    "title": "General Auction Mechanism for Search Advertising", 
    "publish": "2008-07-08T17:16:29Z", 
    "summary": "In sponsored search, a number of advertising slots is available on a search\nresults page, and have to be allocated among a set of advertisers competing to\ndisplay an ad on the page. This gives rise to a bipartite matching market that\nis typically cleared by the way of an automated auction. Several auction\nmechanisms have been proposed, with variants of the Generalized Second Price\n(GSP) being widely used in practice.\n  A rich body of work on bipartite matching markets builds upon the stable\nmarriage model of Gale and Shapley and the assignment model of Shapley and\nShubik. We apply insights from this line of research into the structure of\nstable outcomes and their incentive properties to advertising auctions.\n  We model advertising auctions in terms of an assignment model with linear\nutilities, extended with bidder and item specific maximum and minimum prices.\nAuction mechanisms like the commonly used GSP or the well-known\nVickrey-Clarke-Groves (VCG) are interpreted as simply computing a\n\\emph{bidder-optimal stable matching} in this model, for a suitably defined set\nof bidder preferences. In our model, the existence of a stable matching is\nguaranteed, and under a non-degeneracy assumption a bidder-optimal stable\nmatching exists as well. We give an algorithm to find such matching in\npolynomial time, and use it to design truthful mechanism that generalizes GSP,\nis truthful for profit-maximizing bidders, implements features like\nbidder-specific minimum prices and position-specific bids, and works for rich\nmixtures of bidders and preferences.", 
    "link": "http://arxiv.org/pdf/0807.1297v1", 
    "arxiv-id": "0807.1297v1"
},{
    "category": "cs.GT", 
    "author": "Alexander Skopalik", 
    "title": "Altruism in Atomic Congestion Games", 
    "publish": "2008-07-13T05:58:36Z", 
    "summary": "This paper studies the effects of introducing altruistic agents into atomic\ncongestion games. Altruistic behavior is modeled by a trade-off between selfish\nand social objectives. In particular, we assume agents optimize a linear\ncombination of personal delay of a strategy and the resulting increase in\nsocial cost. Our model can be embedded in the framework of congestion games\nwith player-specific latency functions. Stable states are the Nash equilibria\nof these games, and we examine their existence and the convergence of\nsequential best-response dynamics. Previous work shows that for symmetric\nsingleton games with convex delays Nash equilibria are guaranteed to exist. For\nconcave delay functions we observe that there are games without Nash equilibria\nand provide a polynomial time algorithm to decide existence for symmetric\nsingleton games with arbitrary delay functions. Our algorithm can be extended\nto compute best and worst Nash equilibria if they exist. For more general\ncongestion games existence becomes NP-hard to decide, even for symmetric\nnetwork games with quadratic delay functions. Perhaps surprisingly, if all\ndelay functions are linear, then there is always a Nash equilibrium in any\ncongestion game with altruists and any better-response dynamics converges. In\naddition to these results for uncoordinated dynamics, we consider a scenario in\nwhich a central altruistic institution can motivate agents to act\naltruistically. We provide constructive and hardness results for finding the\nminimum number of altruists to stabilize an optimal congestion profile and more\ngeneral mechanisms to incentivize agents to adopt favorable behavior.", 
    "link": "http://arxiv.org/pdf/0807.2011v2", 
    "arxiv-id": "0807.2011v2"
},{
    "category": "cs.GT", 
    "author": "Angelina Vidali", 
    "title": "A characterization of 2-player mechanisms for scheduling", 
    "publish": "2008-07-22T09:20:01Z", 
    "summary": "We study the mechanism design problem of scheduling unrelated machines and we\ncompletely characterize the decisive truthful mechanisms for two players when\nthe domain contains both positive and negative values. We show that the class\nof truthful mechanisms is very limited: A decisive truthful mechanism\npartitions the tasks into groups so that the tasks in each group are allocated\nindependently of the other groups. Tasks in a group of size at least two are\nallocated by an affine minimizer and tasks in singleton groups by a\ntask-independent mechanism. This characterization is about all truthful\nmechanisms, including those with unbounded approximation ratio.\n  A direct consequence of this approach is that the approximation ratio of\nmechanisms for two players is 2, even for two tasks. In fact, it follows that\nfor two players, VCG is the unique algorithm with optimal approximation 2.\n  This characterization provides some support that any decisive truthful\nmechanism (for 3 or more players) partitions the tasks into groups some of\nwhich are allocated by affine minimizers, while the rest are allocated by a\nthreshold mechanism (in which a task is allocated to a player when it is below\na threshold value which depends only on the values of the other players). We\nalso show here that the class of threshold mechanisms is identical to the class\nof additive mechanisms.", 
    "link": "http://arxiv.org/pdf/0807.3427v1", 
    "arxiv-id": "0807.3427v1"
},{
    "category": "cs.GT", 
    "author": "Martin Hoefer", 
    "title": "Concurrent Imitation Dynamics in Congestion Games", 
    "publish": "2008-08-15T02:45:30Z", 
    "summary": "Imitating successful behavior is a natural and frequently applied approach to\ntrust in when facing scenarios for which we have little or no experience upon\nwhich we can base our decision. In this paper, we consider such behavior in\natomic congestion games. We propose to study concurrent imitation dynamics that\nemerge when each player samples another player and possibly imitates this\nagents' strategy if the anticipated latency gain is sufficiently large. Our\nmain focus is on convergence properties. Using a potential function argument,\nwe show that our dynamics converge in a monotonic fashion to stable states. In\nsuch a state none of the players can improve its latency by imitating somebody\nelse. As our main result, we show rapid convergence to approximate equilibria.\nAt an approximate equilibrium only a small fraction of agents sustains a\nlatency significantly above or below average. In particular, imitation dynamics\nbehave like fully polynomial time approximation schemes (FPTAS). Fixing all\nother parameters, the convergence time depends only in a logarithmic fashion on\nthe number of agents. Since imitation processes are not innovative they cannot\ndiscover unused strategies. Furthermore, strategies may become extinct with\nnon-zero probability. For the case of singleton games, we show that the\nprobability of this event occurring is negligible. Additionally, we prove that\nthe social cost of a stable state reached by our dynamics is not much worse\nthan an optimal state in singleton congestion games with linear latency\nfunction. Finally, we discuss how the protocol can be extended such that, in\nthe long run, dynamics converge to a Nash equilibrium.", 
    "link": "http://arxiv.org/pdf/0808.2081v2", 
    "arxiv-id": "0808.2081v2"
},{
    "category": "cs.GT", 
    "author": "Christos H. Papadimitriou", 
    "title": "Discretized Multinomial Distributions and Nash Equilibria in Anonymous   Games", 
    "publish": "2008-08-20T19:12:40Z", 
    "summary": "We show that there is a polynomial-time approximation scheme for computing\nNash equilibria in anonymous games with any fixed number of strategies (a very\nbroad and important class of games), extending the two-strategy result of\nDaskalakis and Papadimitriou 2007. The approximation guarantee follows from a\nprobabilistic result of more general interest: The distribution of the sum of n\nindependent unit vectors with values ranging over {e1, e2, ...,ek}, where ei is\nthe unit vector along dimension i of the k-dimensional Euclidean space, can be\napproximated by the distribution of the sum of another set of independent unit\nvectors whose probabilities of obtaining each value are multiples of 1/z for\nsome integer z, and so that the variational distance of the two distributions\nis at most eps, where eps is bounded by an inverse polynomial in z and a\nfunction of k, but with no dependence on n. Our probabilistic result specifies\nthe construction of a surprisingly sparse eps-cover -- under the total\nvariation distance -- of the set of distributions of sums of independent unit\nvectors, which is of interest on its own right.", 
    "link": "http://arxiv.org/pdf/0808.2801v1", 
    "arxiv-id": "0808.2801v1"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "Complexity of comparison of influence of players in simple games", 
    "publish": "2008-09-02T21:20:27Z", 
    "summary": "Coalitional voting games appear in different forms in multi-agent systems,\nsocial choice and threshold logic. In this paper, the complexity of comparison\nof influence between players in coalitional voting games is characterized. The\npossible representations of simple games considered are simple games\nrepresented by winning coalitions, minimal winning coalitions, weighted voting\ngame or a multiple weighted voting game. The influence of players is gauged\nfrom the viewpoint of basic player types, desirability relations and classical\npower indices such as Shapley-Shubik index, Banzhaf index, Holler index,\nDeegan-Packel index and Chow parameters. Among other results, it is shown that\nfor a simple game represented by minimal winning coalitions, although it is\neasy to verify whether a player has zero or one voting power, computing the\nBanzhaf value of the player is #P-complete. Moreover, it is proved that\nmultiple weighted voting games are the only representations for which it is\nNP-hard to verify whether the game is linear or not. For a simple game with a\nset W^m of minimal winning coalitions and n players, a O(n.|W^m|+(n^2)log(n))\nalgorithm is presented which returns `no' if the game is non-linear and returns\nthe strict desirability ordering otherwise. The complexity of transforming\nsimple games into compact representations is also examined.", 
    "link": "http://arxiv.org/pdf/0809.0519v1", 
    "arxiv-id": "0809.0519v1"
},{
    "category": "cs.GT", 
    "author": "Bruno Gaujal", 
    "title": "A Distributed Algorithm for Fair and Efficient User-Network Association   in Multi-Technology Wireless Networks", 
    "publish": "2008-09-18T07:47:31Z", 
    "summary": "Recent mobile equipment (as well as the norm IEEE 802.21) now offers the\npossibility for users to switch from one technology to another (vertical\nhandover). This allows flexibility in resource assignments and, consequently,\nincreases the potential throughput allocated to each user. In this paper, we\ndesign a fully distributed algorithm based on trial and error mechanisms that\nexploits the benefits of vertical handover by finding fair and efficient\nassignment schemes. On the one hand, mobiles gradually update the fraction of\ndata packets they send to each network based on the rewards they receive from\nthe stations. On the other hand, network stations send rewards to each mobile\nthat represent the impact each mobile has on the cell throughput. This reward\nfunction is closely related to the concept of marginal cost in the pricing\nliterature. Both the station and the mobile algorithms are simple enough to be\nimplemented in current standard equipment. Based on tools from evolutionary\ngames, potential games and replicator dynamics, we analytically show the\nconvergence of the algorithm to solutions that are efficient and fair in terms\nof throughput. Moreover, we show that after convergence, each user is connected\nto a single network cell which avoids costly repeated vertical handovers.\nSeveral simple heuristics based on this algorithm are proposed to achieve fast\nconvergence. Indeed, for implementation purposes, the number of iterations\nshould remain in the order of a few tens. We also compare, for different loads,\nthe quality of their solutions.", 
    "link": "http://arxiv.org/pdf/0809.3091v2", 
    "arxiv-id": "0809.3091v2"
},{
    "category": "cs.GT", 
    "author": "Vishwanath Raman", 
    "title": "Algorithms for Game Metrics", 
    "publish": "2008-09-25T06:32:48Z", 
    "summary": "Simulation and bisimulation metrics for stochastic systems provide a\nquantitative generalization of the classical simulation and bisimulation\nrelations. These metrics capture the similarity of states with respect to\nquantitative specifications written in the quantitative {\\mu}-calculus and\nrelated probabilistic logics. We first show that the metrics provide a bound\nfor the difference in long-run average and discounted average behavior across\nstates, indicating that the metrics can be used both in system verification,\nand in performance evaluation. For turn-based games and MDPs, we provide a\npolynomial-time algorithm for the computation of the one-step metric distance\nbetween states. The algorithm is based on linear programming; it improves on\nthe previous known exponential-time algorithm based on a reduction to the\ntheory of reals. We then present PSPACE algorithms for both the decision\nproblem and the problem of approximating the metric distance between two\nstates, matching the best known algorithms for Markov chains. For the\nbisimulation kernel of the metric our algorithm works in time O(n^4) for both\nturn-based games and MDPs; improving the previously best known O(n^9\\cdot\nlog(n)) time algorithm for MDPs. For a concurrent game G, we show that\ncomputing the exact distance between states is at least as hard as computing\nthe value of concurrent reachability games and the square-root-sum problem in\ncomputational geometry. We show that checking whether the metric distance is\nbounded by a rational r, can be done via a reduction to the theory of real\nclosed fields, involving a formula with three quantifier alternations, yielding\nO(|G|^O(|G|^5)) time complexity, improving the previously known reduction,\nwhich yielded O(|G|^O(|G|^7)) time complexity. These algorithms can be iterated\nto approximate the metrics using binary search.", 
    "link": "http://arxiv.org/pdf/0809.4326v4", 
    "arxiv-id": "0809.4326v4"
},{
    "category": "cs.GT", 
    "author": "Orestis A. Telelis", 
    "title": "On Pure and (approximate) Strong Equilibria of Facility Location Games", 
    "publish": "2008-09-28T19:26:39Z", 
    "summary": "We study social cost losses in Facility Location games, where $n$ selfish\nagents install facilities over a network and connect to them, so as to forward\ntheir local demand (expressed by a non-negative weight per agent). Agents using\nthe same facility share fairly its installation cost, but every agent pays\nindividually a (weighted) connection cost to the chosen location. We study the\nPrice of Stability (PoS) of pure Nash equilibria and the Price of Anarchy of\nstrong equilibria (SPoA), that generalize pure equilibria by being resilient to\ncoalitional deviations. A special case of recently studied network design\ngames, Facility Location merits separate study as a classic model with numerous\napplications and individual characteristics: our analysis for unweighted agents\non metric networks reveals constant upper and lower bounds for the PoS, while\nan $O(\\ln n)$ upper bound implied by previous work is tight for non-metric\nnetworks. Strong equilibria do not always exist, even for the unweighted metric\ncase. We show that $e$-approximate strong equilibria exist ($e=2.718...$). The\nSPoA is generally upper bounded by $O(\\ln W)$ ($W$ is the sum of agents'\nweights), which becomes tight $\\Theta(\\ln n)$ for unweighted agents. For the\nunweighted metric case we prove a constant upper bound. We point out several\nchallenging open questions that arise.", 
    "link": "http://arxiv.org/pdf/0809.4792v3", 
    "arxiv-id": "0809.4792v3"
},{
    "category": "cs.GT", 
    "author": "Arantza Est\u00e9vez-Fern\u00e1ndez", 
    "title": "Sequential pivotal mechanisms for public project problems", 
    "publish": "2008-10-08T08:42:31Z", 
    "summary": "It is well-known that for several natural decision problems no budget\nbalanced Groves mechanisms exist. This has motivated recent research on\ndesigning variants of feasible Groves mechanisms (termed as `redistribution of\nVCG (Vickrey-Clarke-Groves) payments') that generate reduced deficit. With this\nin mind, we study sequential mechanisms and consider optimal strategies that\ncould reduce the deficit resulting under the simultaneous mechanism. We show\nthat such strategies exist for the sequential pivotal mechanism of the\nwell-known public project problem. We also exhibit an optimal strategy with the\nproperty that a maximal social welfare is generated when each player follows\nit. Finally, we show that these strategies can be achieved by an implementation\nin Nash equilibrium.", 
    "link": "http://arxiv.org/pdf/0810.1383v2", 
    "arxiv-id": "0810.1383v2"
},{
    "category": "cs.GT", 
    "author": "Nicolas Wagner", 
    "title": "Dynamic assignment: there is an equilibrium !", 
    "publish": "2008-10-14T16:37:24Z", 
    "summary": "Given a network with a continuum of users at some origins, suppose that the\nusers wish to reach specific destinations, but that they are not indifferent to\nthe time needed to reach their destination. They may have several possibilities\n(of routes or deparure time), but their choices modify the travel times on the\nnetwork. Hence, each user faces the following problem: given a pattern of\ntravel times for the different possible routes that reach the destination, find\na shortest path. The situation in a context of perfect information is a\nso-called Nash equilibrium, and the question whether there is such an\nequilibrium and of finding it if it exists is the so-called equilibrium\nassignment problem. It arises for various kind of networks, such as computers,\ncommunication or transportation network. When each user occupies permanently\nthe whole route from the origin to its destination, we call it the static\nassignment problem, which has been extensively studied with pioneers works by\nWardrop or Beckmann. A less studied, but more realistic, and maybe more\ndifficult, problem is when the time needed to reach an arc is taken into\naccount. We speak then of a dynamic assignment problem. Several models have\nbeen proposed. For some of them, the existence of an equilibrium has been\nproved, but always under some technical assumptions or in a very special case\n(a network with one arc for the case when the users may chose their departure\ntime). The present paper proposes a compact model, with minimal and natural\nassumptions. For this model, we prove that there is always an equilibrium. To\nour knowledge, this imply all previous results about existence of an\nequilibrium for the dynamic assignment problem.", 
    "link": "http://arxiv.org/pdf/0810.2486v1", 
    "arxiv-id": "0810.2486v1"
},{
    "category": "cs.GT", 
    "author": "Evangelos Markakis", 
    "title": "Welfare Undominated Groves Mechanisms", 
    "publish": "2008-10-16T08:25:11Z", 
    "summary": "A common objective in mechanism design is to choose the outcome (for example,\nallocation of resources) that maximizes the sum of the agents' valuations,\nwithout introducing incentives for agents to misreport their preferences. The\nclass of Groves mechanisms achieves this; however, these mechanisms require the\nagents to make payments, thereby reducing the agents' total welfare.\n  In this paper we introduce a measure for comparing two mechanisms with\nrespect to the final welfare they generate. This measure induces a partial\norder on mechanisms and we study the question of finding minimal elements with\nrespect to this partial order. In particular, we say a non-deficit Groves\nmechanism is welfare undominated if there exists no other non-deficit Groves\nmechanism that always has a smaller or equal sum of payments. We focus on two\ndomains: (i) auctions with multiple identical units and unit-demand bidders,\nand (ii) mechanisms for public project problems. In the first domain we\nanalytically characterize all welfare undominated Groves mechanisms that are\nanonymous and have linear payment functions, by showing that the family of\noptimal-in-expectation linear redistribution mechanisms, which were introduced\nin [6] and include the Bailey-Cavallo mechanism [1,2], coincides with the\nfamily of welfare undominated Groves mechanisms that are anonymous and linear\nin the setting we study. In the second domain we show that the classic VCG\n(Clarke) mechanism is welfare undominated for the class of public project\nproblems with equal participation costs, but is not undominated for a more\ngeneral class.", 
    "link": "http://arxiv.org/pdf/0810.2865v1", 
    "arxiv-id": "0810.2865v1"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "Iterated Regret Minimization: A More Realistic Solution Concept", 
    "publish": "2008-10-16T20:49:34Z", 
    "summary": "For some well-known games, such as the Traveler's Dilemma or the Centipede\nGame, traditional game-theoretic solution concepts--and most notably Nash\nequilibrium--predict outcomes that are not consistent with empirical\nobservations. In this paper, we introduce a new solution concept, iterated\nregret minimization, which exhibits the same qualitative behavior as that\nobserved in experiments in many games of interest, including Traveler's\nDilemma, the Centipede Game, Nash bargaining, and Bertrand competition. As the\nname suggests, iterated regret minimization involves the iterated deletion of\nstrategies that do not minimize regret.", 
    "link": "http://arxiv.org/pdf/0810.3023v1", 
    "arxiv-id": "0810.3023v1"
},{
    "category": "cs.GT", 
    "author": "Vangelis Markakis", 
    "title": "Optimal Strategies in Sequential Bidding", 
    "publish": "2008-10-17T15:53:02Z", 
    "summary": "We are interested in mechanisms that maximize social welfare. In [1] this\nproblem was studied for multi-unit auctions with unit demand bidders and for\nthe public project problem, and in each case social welfare undominated\nmechanisms in the class of feasible and incentive compatible mechanisms were\nidentified. One way to improve upon these optimality results is by allowing the\nplayers to move sequentially. With this in mind, we study here sequential\nversions of two feasible Groves mechanisms used for single item auctions: the\nVickrey auction and the Bailey-Cavallo mechanism. Because of the absence of\ndominant strategies in this sequential setting, we focus on a weaker concept of\nan optimal strategy. For each mechanism we introduce natural optimal strategies\nand observe that in each mechanism these strategies exhibit different\nbehaviour. However, we then show that among all optimal strategies, the one we\nintroduce for each mechanism maximizes the social welfare when each player\nfollows it. The resulting social welfare can be larger than the one obtained in\nthe simultaneous setting. Finally, we show that, when interpreting both\nmechanisms as simultaneous ones, the vectors of the proposed strategies form a\nPareto optimal Nash equilibrium in the class of optimal strategies.", 
    "link": "http://arxiv.org/pdf/0810.3182v1", 
    "arxiv-id": "0810.3182v1"
},{
    "category": "cs.GT", 
    "author": "Ren\u00e9 Vestergaard", 
    "title": "Conversion/Preference Games", 
    "publish": "2008-11-03T08:12:20Z", 
    "summary": "We introduce the concept of Conversion/Preference Games, or CP games for\nshort. CP games generalize the standard notion of strategic games. First we\nexemplify the use of CP games. Second we formally introduce and define the\nCP-games formalism. Then we sketch two `real-life' applications, namely a\nconnection between CP games and gene regulation networks, and the use of CP\ngames to formalize implied information in Chinese Wall security. We end with a\nstudy of a particular fixed-point construction over CP games and of the\nresulting existence of equilibria in possibly infinite games.", 
    "link": "http://arxiv.org/pdf/0811.0071v1", 
    "arxiv-id": "0811.0071v1"
},{
    "category": "cs.GT", 
    "author": "Marco Faella", 
    "title": "Best-Effort Strategies for Losing States", 
    "publish": "2008-11-11T13:36:49Z", 
    "summary": "We consider games played on finite graphs, whose goal is to obtain a trace\nbelonging to a given set of winning traces. We focus on those states from which\nPlayer 1 cannot force a win. We explore and compare several criteria for\nestablishing what is the preferable behavior of Player 1 from those states.\n  Along the way, we prove several results of theoretical and practical\ninterest, such as a characterization of admissible strategies, which also\nprovides a simple algorithm for computing such strategies for various common\ngoals, and the equivalence between the existence of positional winning\nstrategies and the existence of positional subgame perfect strategies.", 
    "link": "http://arxiv.org/pdf/0811.1664v1", 
    "arxiv-id": "0811.1664v1"
},{
    "category": "cs.GT", 
    "author": "Hugo Gimbert", 
    "title": "Determinacy and Decidability of Reachability Games with Partial   Observation on Both Sides", 
    "publish": "2008-11-24T21:10:00Z", 
    "summary": "We prove two determinacy and decidability results about two-players\nstochastic reachability games with partial observation on both sides and\nfinitely many states, signals and actions.", 
    "link": "http://arxiv.org/pdf/0811.3975v1", 
    "arxiv-id": "0811.3975v1"
},{
    "category": "cs.GT", 
    "author": "Florian Horn", 
    "title": "Optimal Strategies in Perfect-Information Stochastic Games with Tail   Winning Conditions", 
    "publish": "2008-11-24T21:12:42Z", 
    "summary": "We prove that optimal strategies exist in every perfect-information\nstochastic game with finitely many states and actions and a tail winning\ncondition.", 
    "link": "http://arxiv.org/pdf/0811.3978v2", 
    "arxiv-id": "0811.3978v2"
},{
    "category": "cs.GT", 
    "author": "Amin Saberi", 
    "title": "Convergence to Equilibrium in Local Interaction Games and Ising Models", 
    "publish": "2008-12-01T02:16:04Z", 
    "summary": "Coordination games describe social or economic interactions in which the\nadoption of a common strategy has a higher payoff. They are classically used to\nmodel the spread of conventions, behaviors, and technologies in societies. Here\nwe consider a two-strategies coordination game played asynchronously between\nthe nodes of a network. Agents behave according to a noisy best-response\ndynamics.\n  It is known that noise removes the degeneracy among equilibria: In the long\nrun, the ``risk-dominant'' behavior spreads throughout the network. Here we\nconsider the problem of computing the typical time scale for the spread of this\nbehavior. In particular, we study its dependence on the network structure and\nderive a dichotomy between highly-connected, non-local graphs that show slow\nconvergence, and poorly connected, low dimensional graphs that show fast\nconvergence.", 
    "link": "http://arxiv.org/pdf/0812.0198v1", 
    "arxiv-id": "0812.0198v1"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "On the computational complexity of solving stochastic mean-payoff games", 
    "publish": "2008-12-02T12:28:58Z", 
    "summary": "We consider some well-known families of two-player, zero-sum, perfect\ninformation games that can be viewed as special cases of Shapley's stochastic\ngames. We show that the following tasks are polynomial time equivalent:\n  - Solving simple stochastic games.\n  - Solving stochastic mean-payoff games with rewards and probabilities given\nin unary. - Solving stochastic mean-payoff games with rewards and probabilities\ngiven in binary.", 
    "link": "http://arxiv.org/pdf/0812.0486v1", 
    "arxiv-id": "0812.0486v1"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "Trembling hand perfection is NP-hard", 
    "publish": "2008-12-02T12:42:06Z", 
    "summary": "It is NP-hard to decide if a given pure-strategy Nash equilibrium of a given\nthree-player game in strategic form with integer payoffs is trembling hand\nperfect.", 
    "link": "http://arxiv.org/pdf/0812.0492v1", 
    "arxiv-id": "0812.0492v1"
},{
    "category": "cs.GT", 
    "author": "Feng Tian", 
    "title": "A Relaying Incentive Scheme in Multihop Cellular Networks Based on   Coalitional Game with Externalities", 
    "publish": "2008-12-02T14:28:35Z", 
    "summary": "Cooperative multihop communication can greatly increase network throughput,\nyet packet forwarding for other nodes involves opportunity and energy cost for\nrelays. Thus one of the pre-requisite problems in the successful implementation\nof multihop transmission is how to foster cooperation among selfish nodes.\nExisting researches mainly adopt monetary stimulating. In this manuscript, we\npropose instead a simple and self-enforcing forwarding incentive scheme free of\nindirect monetary remunerating for asymmetric (uplink multihop, downlink\nsingle-hop) cellar network based on coalitional game theory, which comprises\ndouble compensation, namely, Inter- BEA, global stimulating policy allotting\nresources among relaying coalitions according to group size, and Intra-BEA,\nlocal compensating and allocating rule within coalitions. Firstly, given the\nglobal allotting policy, we introduce a fair allocation estimating approach\nwhich includes remunerating for relaying cost using Myerson value for partition\nfunction game, to enlighten the design of local allocating rules. Secondly,\ngiven the inter- and intra-BEA relay fostering approach, we check stability of\ncoalition structures in terms of internal and external stability as well as\ninductive core. Theoretic analysis and numerical simulation show that our\nmeasure can provide communication opportunities for outer ring nodes and\nenlarge system coverage, while at the same time provide enough motivation with\nrespect to resource allocation and energy saving for nodes in inner and middle\nring to relay for own profits.", 
    "link": "http://arxiv.org/pdf/0812.0515v2", 
    "arxiv-id": "0812.0515v2"
},{
    "category": "cs.GT", 
    "author": "Feng Tian", 
    "title": "Dynamic spectrum sharing game by lease", 
    "publish": "2008-12-03T01:12:23Z", 
    "summary": "We propose and analyze a dynamic implementation of the property-rights model\nof cognitive radio. A primary link has the possibility to lease the owned\nspectrum to a MAC network of secondary nodes, in exchange for cooperation in\nthe form of distributed space-time coding (DSTC). The cooperation and\ncompetition between the primary and secondary network are cast in the framework\nof sequential game. On one hand, the primary link attempts to maximize its\nquality of service in terms of signal-to-interference-plus-noise ratio (SINR);\non the other hand, nodes in the secondary network compete for transmission\nwithin the leased time-slot following a power control mechanism. We consider\nboth a baseline model with complete information and a more practical version\nwith incomplete information, using the backward induction approach for the\nformer and providing approximate algorithm for the latter. Analysis and\nnumerical results show that our models and algorithms provide a promising\nframework for fair and effective spectrum sharing, both between primary and\nsecondary networks and among secondary nodes.", 
    "link": "http://arxiv.org/pdf/0812.0629v2", 
    "arxiv-id": "0812.0629v2"
},{
    "category": "cs.GT", 
    "author": "Zhen Yang", 
    "title": "Analysis of Group Multiuser Detection Based on Coalitional Game", 
    "publish": "2008-12-03T02:16:45Z", 
    "summary": "The issue of group-blind multiuser detection in MAC channel among wireless\nnodes in the environment of multiple networks coexisting and sharing spectrum\nis addressed under the Framework of coalitional game. We investigate the\nperformance and stability of multiple access channel (MAC) with linear\ndecorrelating multiuser detection under varying SNR, channel gains and\ncoalitional structures, in which both single BS and multiple BSs cases were\nconsidered. The main results and conclusion are as follows: (1) the grand\ncoalition is payoff maximizing under loose SNR; (2) it is in conformity with\ngroup and coalitional rationality forming coalition among nodes that have\ncomparative channel gains.", 
    "link": "http://arxiv.org/pdf/0812.0635v1", 
    "arxiv-id": "0812.0635v1"
},{
    "category": "cs.GT", 
    "author": "Martin Drechsler", 
    "title": "EcoTRADE - a multi player network game of a tradable permit market for   biodiversity credits", 
    "publish": "2008-12-04T15:43:16Z", 
    "summary": "EcoTRADE is a multi player network game of a virtual biodiversity credit\nmarket. Each player controls the land use of a certain amount of parcels on a\nvirtual landscape. The biodiversity credits of a particular parcel depend on\nneighboring parcels, which may be owned by other players. The game can be used\nto study the strategies of players in experiments or classroom games and also\nas a communication tool for stakeholders participating in credit markets that\ninclude spatially interdependent credits.", 
    "link": "http://arxiv.org/pdf/0812.0956v2", 
    "arxiv-id": "0812.0956v2"
},{
    "category": "cs.GT", 
    "author": "Constantinos Daskalakis", 
    "title": "An Efficient PTAS for Two-Strategy Anonymous Games", 
    "publish": "2008-12-12T00:43:07Z", 
    "summary": "We present a novel polynomial time approximation scheme for two-strategy\nanonymous games, in which the players' utility functions, although potentially\ndifferent, do not differentiate among the identities of the other players. Our\nalgorithm computes an $eps$-approximate Nash equilibrium of an $n$-player\n2-strategy anonymous game in time $poly(n) (1/eps)^{O(1/eps^2)}$, which\nsignificantly improves upon the running time $n^{O(1/eps^2)}$ required by the\nalgorithm of Daskalakis & Papadimitriou, 2007. The improved running time is\nbased on a new structural understanding of approximate Nash equilibria: We show\nthat, for any $eps$, there exists an $eps$-approximate Nash equilibrium in\nwhich either only $O(1/eps^3)$ players randomize, or all players who randomize\nuse the same mixed strategy. To show this result we employ tools from the\nliterature on Stein's Method.", 
    "link": "http://arxiv.org/pdf/0812.2277v1", 
    "arxiv-id": "0812.2277v1"
},{
    "category": "cs.GT", 
    "author": "Jian Li", 
    "title": "An $O({\\log n\\over \\log\\log n})$ Upper Bound on the Price of Stability   for Undirected Shapley Network Design Games", 
    "publish": "2008-12-13T17:33:29Z", 
    "summary": "In this paper, we consider the Shapley network design game on undirected\nnetworks. In this game, we have an edge weighted undirected network $G(V,E)$\nand $n$ selfish players where player $i$ wants to choose a path from source\nvertex $s_i$ to destination vertex $t_i$. The cost of each edge is equally\nsplit among players who pass it. The price of stability is defined as the ratio\nof the cost of the best Nash equilibrium to that of the optimal solution. We\npresent an $O(\\log n/\\log\\log n)$ upper bound on price of stability for the\nsingle sink case, i.e, $t_i=t$ for all $i$.", 
    "link": "http://arxiv.org/pdf/0812.2567v1", 
    "arxiv-id": "0812.2567v1"
},{
    "category": "cs.GT", 
    "author": "Vicky Papadopoulou", 
    "title": "How Many Attackers Can Selfish Defenders Catch?", 
    "publish": "2008-12-22T14:48:24Z", 
    "summary": "In a distributed system with {\\it attacks} and {\\it defenses,} both {\\it\nattackers} and {\\it defenders} are self-interested entities. We assume a {\\it\nreward-sharing} scheme among {\\it interdependent} defenders; each defender\nwishes to (locally) maximize her own total {\\it fair share} to the attackers\nextinguished due to her involvement (and possibly due to those of others). What\nis the {\\em maximum} amount of protection achievable by a number of such\ndefenders against a number of attackers while the system is in a {\\it Nash\nequilibrium}? As a measure of system protection, we adopt the {\\it\nDefense-Ratio} \\cite{MPPS05a}, which provides the expected (inverse) proportion\nof attackers caught by the defenders. In a {\\it Defense-Optimal} Nash\nequilibrium, the Defense-Ratio is optimized.\n  We discover that the possibility of optimizing the Defense-Ratio (in a Nash\nequilibrium) depends in a subtle way on how the number of defenders compares to\ntwo natural graph-theoretic thresholds we identify. In this vein, we obtain,\nthrough a combinatorial analysis of Nash equilibria, a collection of trade-off\nresults:\n  - When the number of defenders is either sufficiently small or sufficiently\nlarge, there are cases where the Defense-Ratio can be optimized. The\noptimization problem is computationally tractable for a large number of\ndefenders; the problem becomes ${\\cal NP}$-complete for a small number of\ndefenders and the intractability is inherited from a previously unconsidered\ncombinatorial problem in {\\em Fractional Graph Theory}.\n  - Perhaps paradoxically, there is a middle range of values for the number of\ndefenders where optimizing the Defense-Ratio is never possible.", 
    "link": "http://arxiv.org/pdf/0812.4206v1", 
    "arxiv-id": "0812.4206v1"
},{
    "category": "cs.GT", 
    "author": "Asuman Ozdaglar", 
    "title": "Correlated Equilibria in Continuous Games: Characterization and   Computation", 
    "publish": "2008-12-22T20:28:01Z", 
    "summary": "We present several new characterizations of correlated equilibria in games\nwith continuous utility functions. These have the advantage of being more\ncomputationally and analytically tractable than the standard definition in\nterms of departure functions. We use these characterizations to construct\neffective algorithms for approximating a single correlated equilibrium or the\nentire set of correlated equilibria of a game with polynomial utility\nfunctions.", 
    "link": "http://arxiv.org/pdf/0812.4279v2", 
    "arxiv-id": "0812.4279v2"
},{
    "category": "cs.GT", 
    "author": "Yadati Narahari", 
    "title": "On Optimal Linear Redistribution of VCG Payments in Assignment of   Heterogeneous Objects", 
    "publish": "2008-12-28T05:08:08Z", 
    "summary": "There are p heterogeneous objects to be assigned to n competing agents (n >\np) each with unit demand. It is required to design a Groves mechanism for this\nassignment problem satisfying weak budget balance, individual rationality, and\nminimizing the budget imbalance. This calls for designing an appropriate rebate\nfunction. Our main result is an impossibility theorem which rules out linear\nrebate functions with non-zero efficiency in heterogeneous object assignment.\nMotivated by this theorem, we explore two approaches to get around this\nimpossibility. In the first approach, we show that linear rebate functions with\nnon-zero are possible when the valuations for the objects are correlated. In\nthe second approach, we show that rebate functions with non-zero efficiency are\npossible if linearity is relaxed.", 
    "link": "http://arxiv.org/pdf/0812.4792v1", 
    "arxiv-id": "0812.4792v1"
},{
    "category": "cs.GT", 
    "author": "Y Narahari", 
    "title": "An Optimal Multi-Unit Combinatorial Procurement Auction with Single   Minded Bidders", 
    "publish": "2009-02-03T15:05:26Z", 
    "summary": "The current art in optimal combinatorial auctions is limited to handling the\ncase of single units of multiple items, with each bidder bidding on exactly one\nbundle (single minded bidders). This paper extends the current art by proposing\nan optimal auction for procuring multiple units of multiple items when the\nbidders are single minded. The auction minimizes the cost of procurement while\nsatisfying Bayesian incentive compatibility and interim individual rationality.\nUnder appropriate regularity conditions, this optimal auction also satisfies\ndominant strategy incentive compatibility.", 
    "link": "http://arxiv.org/pdf/0902.0524v3", 
    "arxiv-id": "0902.0524v3"
},{
    "category": "cs.GT", 
    "author": "Joerg Rothe", 
    "title": "Degrees of Guaranteed Envy-Freeness in Finite Bounded Cake-Cutting   Protocols", 
    "publish": "2009-02-03T21:21:23Z", 
    "summary": "Cake-cutting protocols aim at dividing a ``cake'' (i.e., a divisible\nresource) and assigning the resulting portions to several players in a way that\neach of the players feels to have received a ``fair'' amount of the cake. An\nimportant notion of fairness is envy-freeness: No player wishes to switch the\nportion of the cake received with another player's portion. Despite intense\nefforts in the past, it is still an open question whether there is a\n\\emph{finite bounded} envy-free cake-cutting protocol for an arbitrary number\nof players, and even for four players. We introduce the notion of degree of\nguaranteed envy-freeness (DGEF) as a measure of how good a cake-cutting\nprotocol can approximate the ideal of envy-freeness while keeping the protocol\nfinite bounded (trading being disregarded). We propose a new finite bounded\nproportional protocol for any number n \\geq 3 of players, and show that this\nprotocol has a DGEF of 1 + \\lceil (n^2)/2 \\rceil. This is the currently best\nDGEF among known finite bounded cake-cutting protocols for an arbitrary number\nof players. We will make the case that improving the DGEF even further is a\ntough challenge, and determine, for comparison, the DGEF of selected known\nfinite bounded cake-cutting protocols.", 
    "link": "http://arxiv.org/pdf/0902.0620v5", 
    "arxiv-id": "0902.0620v5"
},{
    "category": "cs.GT", 
    "author": "Morteza Zadimoghaddam", 
    "title": "The Price of Anarchy in Cooperative Network Creation Games", 
    "publish": "2009-02-09T10:31:34Z", 
    "summary": "In general, the games are played on a host graph, where each node is a\nselfish independent agent (player) and each edge has a fixed link creation cost\n\\alpha. Together the agents create a network (a subgraph of the host graph)\nwhile selfishly minimizing the link creation costs plus the sum of the\ndistances to all other players (usage cost). In this paper, we pursue two\nimportant facets of the network creation game. First, we study extensively a\nnatural version of the game, called the cooperative model, where nodes can\ncollaborate and share the cost of creating any edge in the host graph. We prove\nthe first nontrivial bounds in this model, establishing that the price of\nanarchy is polylogarithmic in n for all values of &#945; in complete host\ngraphs. This bound is the first result of this type for any version of the\nnetwork creation game; most previous general upper bounds are polynomial in n.\nInterestingly, we also show that equilibrium graphs have polylogarithmic\ndiameter for the most natural range of \\alpha (at most n polylg n). Second, we\nstudy the impact of the natural assumption that the host graph is a general\ngraph, not necessarily complete. This model is a simple example of nonuniform\ncreation costs among the edges (effectively allowing weights of \\alpha and\n\\infty). We prove the first assemblage of upper and lower bounds for this\ncontext, stablishing nontrivial tight bounds for many ranges of \\alpha, for\nboth the unilateral and cooperative versions of network creation. In\nparticular, we establish polynomial lower bounds for both versions and many\nranges of \\alpha, even for this simple nonuniform cost model, which sharply\ncontrasts the conjectured constant bounds for these games in complete (uniform)\ngraphs.", 
    "link": "http://arxiv.org/pdf/0902.1400v1", 
    "arxiv-id": "0902.1400v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Dynamic Conjectures in Random Access Networks Using Bio-inspired   Learning", 
    "publish": "2009-03-01T20:42:05Z", 
    "summary": "This paper considers a conjecture-based distributed learning approach that\nenables autonomous nodes to independently optimize their transmission\nprobabilities in random access networks. We model the interaction among\nmultiple self-interested nodes as a game. It is well-known that the Nash\nequilibria in this game result in zero throughput for all the nodes if they\ntake myopic best-response, thereby leading to a network collapse. This paper\nenables nodes to behave as intelligent entities which can proactively gather\ninformation, form internal conjectures on how their competitors would react to\ntheir actions, and update their beliefs according to their local observations.\nIn this way, nodes are capable to autonomously \"learn\" the behavior of their\ncompetitors, optimize their own actions, and eventually cultivate reciprocity\nin the random access network. To characterize the steady-state outcome, the\nconjectural equilibrium is introduced. Inspired by the biological phenomena of\n\"derivative action\" and \"gradient dynamics\", two distributed conjecture-based\naction update mechanisms are proposed to stabilize the random access network.\nThe sufficient conditions that guarantee the proposed conjecture-based learning\nalgorithms to converge are derived. Moreover, it is shown that all the\nachievable operating points in the throughput region are essentially stable\nconjectural equilibria corresponding to different conjectures. We investigate\nhow the conjectural equilibrium can be selected in heterogeneous networks and\nhow the proposed methods can be extended to ad-hoc networks. Simulations verify\nthat the system performance significantly outperforms existing protocols, such\nas IEEE 802.11 DCF protocol and the PMAC protocol, in terms of throughput,\nfairness, convergence, and stability.", 
    "link": "http://arxiv.org/pdf/0903.0094v2", 
    "arxiv-id": "0903.0094v2"
},{
    "category": "cs.GT", 
    "author": "Beihang He", 
    "title": "Villager's dilemma", 
    "publish": "2009-03-01T07:32:21Z", 
    "summary": "With deeper study of the Game Theory, some conditions of Prisoner's Dilemma\nis no longer suitable of games in real life. So we try to develop a new\nmodel-Villager's Dilemma which has more realistic conditions to stimulate the\nprocess of game. It is emphasize that Prisoner's Dilemma is an exception which\nis lack of universality and the importance of rules in the game. And it puts\nforward that to let the rule maker take part in the game and specifies game\nplayers can stop the game as they like. This essay describes the basic model,\nthe villager's dilemma (VD) and put some extended use of it, and points out the\nimportance of rules and the effect it has on the result of the game. It briefly\ndescribes the disadvantage of Prisoner's Dilemma and advantage Villager's\nDilemma has. It summarizes the premise and scope of application of Villager's\nDilemma, and provides theory foundation for making rules for game and forecast\nof the future of the game.", 
    "link": "http://arxiv.org/pdf/0903.0126v1", 
    "arxiv-id": "0903.0126v1"
},{
    "category": "cs.GT", 
    "author": "A. Sayedi", 
    "title": "Multi-unit Auctions with Budget Constraints", 
    "publish": "2009-03-08T20:17:40Z", 
    "summary": "Motivated by sponsored search auctions, we study multi-unit auctions with\nbudget constraints. In the mechanism we propose, Sort-Cut, understating budgets\nor values is weakly dominated. Since Sort-Cut's revenue is increasing in\nbudgets and values, all kinds of equilibrium deviations from true valuations\nturn out to be beneficial to the auctioneer. We show that the revenue of\nSort-Cut can be an order of magnitude greater than that of the natural Market\nClearing Price mechanism, and we discuss the efficiency properties of its\nex-post Nash equilibrium.", 
    "link": "http://arxiv.org/pdf/0903.1450v2", 
    "arxiv-id": "0903.1450v2"
},{
    "category": "cs.GT", 
    "author": "Joseph Y. Halpern", 
    "title": "Manipulating Scrip Systems: Sybils and Collusion", 
    "publish": "2009-03-12T21:37:29Z", 
    "summary": "Game-theoretic analyses of distributed and peer-to-peer systems typically use\nthe Nash equilibrium solution concept, but this explicitly excludes the\npossibility of strategic behavior involving more than one agent. We examine the\neffects of two types of strategic behavior involving more than one agent,\nsybils and collusion, in the context of scrip systems where agents provide each\nother with service in exchange for scrip. Sybils make an agent more likely to\nbe chosen to provide service, which generally makes it harder for agents\nwithout sybils to earn money and decreases social welfare. Surprisingly, in\ncertain circumstances it is possible for sybils to make all agents better off.\nWhile collusion is generally bad, in the context of scrip systems it actually\ntends to make all agents better off, not merely those who collude. These\nresults also provide insight into the effects of allowing agents to advertise\nand loan money. While many extensions of Nash equilibrium have been proposed\nthat address collusion and other issues relevant to distributed and\npeer-to-peer systems, our results show that none of them adequately address the\nissues raised by sybils and collusion in scrip systems.", 
    "link": "http://arxiv.org/pdf/0903.2278v1", 
    "arxiv-id": "0903.2278v1"
},{
    "category": "cs.GT", 
    "author": "M. Debbah", 
    "title": "Introducing Hierarchy in Energy Games", 
    "publish": "2009-03-17T13:53:23Z", 
    "summary": "In this work we introduce hierarchy in wireless networks that can be modeled\nby a decentralized multiple access channel and for which energy-efficiency is\nthe main performance index. In these networks users are free to choose their\npower control strategy to selfishly maximize their energy-efficiency.\nSpecifically, we introduce hierarchy in two different ways: 1. Assuming\nsingle-user decoding at the receiver, we investigate a Stackelberg formulation\nof the game where one user is the leader whereas the other users are assumed to\nbe able to react to the leader's decisions; 2. Assuming neither leader nor\nfollowers among the users, we introduce hierarchy by assuming successive\ninterference cancellation at the receiver. It is shown that introducing a\ncertain degree of hierarchy in non-cooperative power control games not only\nimproves the individual energy efficiency of all the users but can also be a\nway of insuring the existence of a non-saturated equilibrium and reaching a\ndesired trade-off between the global network performance at the equilibrium and\nthe requested amount of signaling. In this respect, the way of measuring the\nglobal performance of an energy-efficient network is shown to be a critical\nissue.", 
    "link": "http://arxiv.org/pdf/0903.2966v1", 
    "arxiv-id": "0903.2966v1"
},{
    "category": "cs.GT", 
    "author": "Xiaoguang Yang", 
    "title": "Complementary cooperation, minimal winning coalitions, and power indices", 
    "publish": "2009-04-14T07:53:07Z", 
    "summary": "We introduce a new simple game, which is referred to as the complementary\nweighted multiple majority game (C-WMMG for short). C-WMMG models a basic\ncooperation rule, the complementary cooperation rule, and can be taken as a\nsister model of the famous weighted majority game (WMG for short). In this\npaper, we concentrate on the two dimensional C-WMMG. An interesting property of\nthis case is that there are at most $n+1$ minimal winning coalitions (MWC for\nshort), and they can be enumerated in time $O(n\\log n)$, where $n$ is the\nnumber of players. This property guarantees that the two dimensional C-WMMG is\nmore handleable than WMG. In particular, we prove that the main power indices,\ni.e. the Shapley-Shubik index, the Penrose-Banzhaf index, the Holler-Packel\nindex, and the Deegan-Packel index, are all polynomially computable. To make a\ncomparison with WMG, we know that it may have exponentially many MWCs, and none\nof the four power indices is polynomially computable (unless P=NP). Still for\nthe two dimensional case, we show that local monotonicity holds for all of the\nfour power indices. In WMG, this property is possessed by the Shapley-Shubik\nindex and the Penrose-Banzhaf index, but not by the Holler-Packel index or the\nDeegan-Packel index. Since our model fits very well the cooperation and\ncompetition in team sports, we hope that it can be potentially applied in\nmeasuring the values of players in team sports, say help people give more\nobjective ranking of NBA players and select MVPs, and consequently bring new\ninsights into contest theory and the more general field of sports economics. It\nmay also provide some interesting enlightenments into the design of\nnon-additive voting mechanisms. Last but not least, the threshold version of\nC-WMMG is a generalization of WMG, and natural variants of it are closely\nrelated with the famous airport game and the stable marriage/roommates problem.", 
    "link": "http://arxiv.org/pdf/0904.2060v3", 
    "arxiv-id": "0904.2060v3"
},{
    "category": "cs.GT", 
    "author": "Xiaoguang Yang", 
    "title": "Selfish Bin Covering", 
    "publish": "2009-04-14T07:17:01Z", 
    "summary": "In this paper, we address the selfish bin covering problem, which is greatly\nrelated both to the bin covering problem, and to the weighted majority game.\nWhat we mainly concern is how much the lack of coordination harms the social\nwelfare. Besides the standard PoA and PoS, which are based on Nash equilibrium,\nwe also take into account the strong Nash equilibrium, and several other new\nequilibria. For each equilibrium, the corresponding PoA and PoS are given, and\nthe problems of computing an arbitrary equilibrium, as well as approximating\nthe best one, are also considered.", 
    "link": "http://arxiv.org/pdf/0904.2061v2", 
    "arxiv-id": "0904.2061v2"
},{
    "category": "cs.GT", 
    "author": "David H. Wolpert Gregory Benford", 
    "title": "What does Newcomb's paradox teach us?", 
    "publish": "2009-04-16T16:50:22Z", 
    "summary": "In Newcomb's paradox you choose to receive either the contents of a\nparticular closed box, or the contents of both that closed box and another one.\nBefore you choose though, an antagonist uses a prediction algorithm to deduce\nyour choice, and fills the two boxes based on that deduction. Newcomb's paradox\nis that game theory's expected utility and dominance principles appear to\nprovide conflicting recommendations for what you should choose. A recent\nextension of game theory provides a powerful tool for resolving paradoxes\nconcerning human choice, which formulates such paradoxes in terms of Bayes\nnets. Here we apply this to ol to Newcomb's scenario. We show that the\nconflicting recommendations in Newcomb's scenario use different Bayes nets to\nrelate your choice and the algorithm's prediction. These two Bayes nets are\nincompatible. This resolves the paradox: the reason there appears to be two\nconflicting recommendations is that the specification of the underlying Bayes\nnet is open to two, conflicting interpretations. We then show that the accuracy\nof the prediction algorithm in Newcomb's paradox, the focus of much previous\nwork, is irrelevant. We similarly show that the utility functions of you and\nthe antagonist are irrelevant. We end by showing that Newcomb's paradox is\ntime-reversal invariant; both the paradox and its resolution are unchanged if\nthe algorithm makes its `prediction' \\emph{after} you make your choice rather\nthan before.", 
    "link": "http://arxiv.org/pdf/0904.2540v3", 
    "arxiv-id": "0904.2540v3"
},{
    "category": "cs.GT", 
    "author": "Heidi Gebauer", 
    "title": "Disproof of the Neighborhood Conjecture with Implications to SAT", 
    "publish": "2009-04-16T17:04:21Z", 
    "summary": "We study a Maker/Breaker game described by Beck. As a result we disprove a\nconjecture of Beck on positional games, establish a connection between this\ngame and SAT and construct an unsatisfiable k-CNF formula with few occurrences\nper variable, thereby improving a previous result by Hoory and Szeider and\nshowing that the bound obtained from the Lovasz Local Lemma is tight up to a\nconstant factor. The Maker/Breaker game we study is as follows. Maker and\nBreaker take turns in choosing vertices from a given n-uniform hypergraph F,\nwith Maker going first. Maker's goal is to completely occupy a hyperedge and\nBreaker tries to avoid this. Beck conjectures that if the maximum neighborhood\nsize of F is at most 2^(n-1) then Breaker has a winning strategy. We disprove\nthis conjecture by establishing an n-uniform hypergraph with maximum\nneighborhood size 3*2^(n - 3) where Maker has a winning strategy. Moreover, we\nshow how to construct an n-uniform hypergraph with maximum degree (2^(n-1))/n\nwhere maker has a winning strategy. Finally, we establish a connection between\nSAT and the Maker/Breaker game we study. We can use this connection to derive\nnew results in SAT. Kratochvil, Savicky and Tuza showed that for every k >= 3\nthere is an integer f(k) such that every (k,f(k))-formula is satisfiable, but\n(k,f(k) + 1)-SAT is already NP-complete (it is not known whether f(k) is\ncomputable). Kratochvil, Savicky and Tuza also gave the best known lower bound\nf(k) = Omega(2^k/k), which is a consequence of the Lovasz Local Lemma. We prove\nthat, in fact, f(k) = Theta(2^k/k), improving upon the best known upper bound\nO((log k) * 2^k/k) by Hoory and Szeider.", 
    "link": "http://arxiv.org/pdf/0904.2541v3", 
    "arxiv-id": "0904.2541v3"
},{
    "category": "cs.GT", 
    "author": "Sanjeev Khanna", 
    "title": "Dynamic and Non-Uniform Pricing Strategies for Revenue Maximization", 
    "publish": "2009-05-19T22:15:12Z", 
    "summary": "We consider the Item Pricing problem for revenue maximization in the limited\nsupply setting, where a single seller with $n$ items caters to $m$ buyers with\nunknown subadditive valuation functions who arrive in a sequence. The seller\nsets the prices on individual items. Each buyer buys a subset of yet unsold\nitems that maximizes her utility. Our goal is to design pricing strategies that\nguarantee an expected revenue that is within a small factor $\\alpha$ of the\nmaximum possible social welfare -- an upper bound on the maximum revenue that\ncan be generated. Most earlier work has focused on the unlimited supply\nsetting, where selling items to some buyer does not affect their availability\nto the future buyers. Balcan et. al. (EC 2008) studied the limited supply\nsetting, giving a randomized strategy that assigns a single price to all items\n(uniform strategy), and never changes it (static strategy), that gives an\n$2^{O(\\sqrt{\\log n \\log \\log n})}$-approximation, and moreover, no static\nuniform pricing strategy can give better than $2^{\\Omega(\\log^{1/4} n)}$-\napproximation. We improve this lower bound to $2^{\\Omega(sqrt{\\log n})}$.\n  We consider dynamic uniform strategies, which can change the price upon the\narrival of each buyer but the price on all unsold items is the same at all\ntimes, and static non-uniform strategies, which can assign different prices to\ndifferent items but can never change it after setting it initially. We design\nsuch pricing strategies that give a poly-logarithmic approximation to maximum\nrevenue. Thus in the limited supply setting, our results highlight a strong\nseparation between the power of dynamic and non-uniform pricing versus static\nuniform pricing. To our knowledge, this is the first non-trivial analysis of\ndynamic and non-uniform pricing schemes for revenue maximization.", 
    "link": "http://arxiv.org/pdf/0905.3191v1", 
    "arxiv-id": "0905.3191v1"
},{
    "category": "cs.GT", 
    "author": "Mike Paterson", 
    "title": "False name manipulations in weighted voting games: splitting, merging   and annexation", 
    "publish": "2009-05-20T16:28:58Z", 
    "summary": "An important aspect of mechanism design in social choice protocols and\nmultiagent systems is to discourage insincere and manipulative behaviour. We\nexamine the computational complexity of false-name manipulation in weighted\nvoting games which are an important class of coalitional voting games. Weighted\nvoting games have received increased interest in the multiagent community due\nto their compact representation and ability to model coalitional formation\nscenarios. Bachrach and Elkind in their AAMAS 2008 paper examined divide and\nconquer false-name manipulation in weighted voting games from the point of view\nof Shapley-Shubik index. We analyse the corresponding case of the Banzhaf index\nand check how much the Banzhaf index of a player increases or decreases if it\nsplits up into sub-players. A pseudo-polynomial algorithm to find the optimal\nsplit is also provided. Bachrach and Elkind also mentioned manipulation via\nmerging as an open problem. In the paper, we examine the cases where a player\nannexes other players or merges with them to increase their Banzhaf index or\nShapley-Shubik index payoff. We characterize the computational complexity of\nsuch manipulations and provide limits to the manipulation. The annexation\nnon-monotonicity paradox is also discovered in the case of the Banzhaf index.\nThe results give insight into coalition formation and manipulation.", 
    "link": "http://arxiv.org/pdf/0905.3348v1", 
    "arxiv-id": "0905.3348v1"
},{
    "category": "cs.GT", 
    "author": "Dusko Pavlovic", 
    "title": "A semantical approach to equilibria and rationality", 
    "publish": "2009-05-21T19:36:11Z", 
    "summary": "Game theoretic equilibria are mathematical expressions of rationality.\nRational agents are used to model not only humans and their software\nrepresentatives, but also organisms, populations, species and genes,\ninteracting with each other and with the environment. Rational behaviors are\nachieved not only through conscious reasoning, but also through spontaneous\nstabilization at equilibrium points.\n  Formal theories of rationality are usually guided by informal intuitions,\nwhich are acquired by observing some concrete economic, biological, or network\nprocesses. Treating such processes as instances of computation, we reconstruct\nand refine some basic notions of equilibrium and rationality from the some\nbasic structures of computation.\n  It is, of course, well known that equilibria arise as fixed points; the point\nis that semantics of computation of fixed points seems to be providing novel\nmethods, algebraic and coalgebraic, for reasoning about them.", 
    "link": "http://arxiv.org/pdf/0905.3548v1", 
    "arxiv-id": "0905.3548v1"
},{
    "category": "cs.GT", 
    "author": "Rustam Tagiew", 
    "title": "Towards Barter Double Auction as Model for Bilateral Social Cooperations", 
    "publish": "2009-05-22T15:39:19Z", 
    "summary": "The idea of this paper is an advanced game concept. This concept is expected\nto model non-monetary bilateral cooperations between self-interested agents.\nSuch non-monetary cases are social cooperations like allocation of high level\njobs or sexual relationships among humans. In a barter double auction, there is\na big amount of agents. Every agent has a vector of parameters which specifies\nhis demand and a vector which specifies his offer. Two agents can achieve a\ncommitment through barter exchange. The subjective satisfaction level (a number\nbetween 0% and 100%) of an agent is as high as small is the distance between\nhis demand and the accepted offer. This paper introduces some facets of this\ncomplex game concept.", 
    "link": "http://arxiv.org/pdf/0905.3709v1", 
    "arxiv-id": "0905.3709v1"
},{
    "category": "cs.GT", 
    "author": "Mir Mehdi Seyyed Esfahani", 
    "title": "Inventory competition in a multi channel distribution system: The Nash   and Stackelberg game", 
    "publish": "2009-05-31T12:25:12Z", 
    "summary": "This paper investigates inventory management in a multi channel distribution\nsystem consisting of one manufacturer and an arbitrary number of retailers that\nface stochastic demand. Existence of the pure Nash equilibrium is proved and\nparameter restriction which implies uniqueness of it is derived. Also the\nStackelberg game where the manufacturer plays a roll as a leader is discussed.\nUnder specified parameter restrictions which guarantee profitability,\nsufficient condition for uniqueness of Stackelberg equilibrium is obtained. In\naddition comparison with simultaneous move game is made. The result shows that\nwhen whole prices are equal to production cost, manufacturer carries more\ninventory than simultaneous move game. Keywords: Inventory management,\nSubstitution, Nash equilibrium, Stackelberg equilibrium.", 
    "link": "http://arxiv.org/pdf/0906.0151v1", 
    "arxiv-id": "0906.0151v1"
},{
    "category": "cs.GT", 
    "author": "E. Altman", 
    "title": "Methodologies for Analyzing Equilibria in Wireless Games", 
    "publish": "2009-06-02T11:20:34Z", 
    "summary": "Under certain assumptions in terms of information and models, equilibria\ncorrespond to possible stable outcomes in conflicting or cooperative scenarios\nwhere rational entities interact. For wireless engineers, it is of paramount\nimportance to be able to predict and even ensure such states at which the\nnetwork will effectively operate. In this article, we provide non-exhaustive\nmethodologies for characterizing equilibria in wireless games in terms of\nexistence, uniqueness, selection, and efficiency.", 
    "link": "http://arxiv.org/pdf/0906.0447v1", 
    "arxiv-id": "0906.0447v1"
},{
    "category": "cs.GT", 
    "author": "Aranyak Mehta", 
    "title": "Efficiency of (Revenue-)Optimal Mechanisms", 
    "publish": "2009-06-04T23:21:40Z", 
    "summary": "We compare the expected efficiency of revenue maximizing (or {\\em optimal})\nmechanisms with that of efficiency maximizing ones. We show that the efficiency\nof the revenue maximizing mechanism for selling a single item with k +\nlog_{e/(e-1)} k + 1 bidders is at least as much as the efficiency of the\nefficiency maximizing mechanism with k bidders, when bidder valuations are\ndrawn i.i.d. from a Monotone Hazard Rate distribution. Surprisingly, we also\nshow that this bound is tight within a small additive constant of 5.7. In other\nwords, Theta(log k) extra bidders suffice for the revenue maximizing mechanism\nto match the efficiency of the efficiency maximizing mechanism, while o(log k)\ndo not. This is in contrast to the result of Bulow and Klemperer comparing the\nrevenue of the two mechanisms, where only one extra bidder suffices. More\nprecisely, they show that the revenue of the efficiency maximizing mechanism\nwith k+1 bidders is no less than the revenue of the revenue maximizing\nmechanism with k bidders.\n  We extend our result for the case of selling t identical items and show that\n2.2 log k + t Theta(log log k) extra bidders suffice for the revenue maximizing\nmechanism to match the efficiency of the efficiency maximizing mechanism.\n  In order to prove our results, we do a classification of Monotone Hazard Rate\n(MHR) distributions and identify a family of MHR distributions, such that for\neach class in our classification, there is a member of this family that is\npointwise lower than every distribution in that class. This lets us prove\ninteresting structural theorems about distributions with Monotone Hazard Rate.", 
    "link": "http://arxiv.org/pdf/0906.1019v1", 
    "arxiv-id": "0906.1019v1"
},{
    "category": "cs.GT", 
    "author": "Xavier Koegler", 
    "title": "Playing With Population Protocols", 
    "publish": "2009-06-17T17:16:01Z", 
    "summary": "Population protocols have been introduced as a model of sensor networks\nconsisting of very limited mobile agents with no control over their own\nmovement: A collection of anonymous agents, modeled by finite automata,\ninteract in pairs according to some rules.\n  Predicates on the initial configurations that can be computed by such\nprotocols have been characterized under several hypotheses.\n  We discuss here whether and when the rules of interactions between agents can\nbe seen as a game from game theory. We do so by discussing several basic\nprotocols.", 
    "link": "http://arxiv.org/pdf/0906.3256v1", 
    "arxiv-id": "0906.3256v1"
},{
    "category": "cs.GT", 
    "author": "Amin Saberi", 
    "title": "On the Complexity of Envy-Free Cake Cutting", 
    "publish": "2009-07-08T05:28:07Z", 
    "summary": "We study the envy-free cake-cutting problem for $d+1$ players with $d$ cuts,\nfor both the oracle function model and the polynomial time function model. For\nthe former, we derive a $\\theta(({1\\over\\epsilon})^{d-1})$ time matching bound\nfor the query complexity of $d+1$ player cake cutting with Lipschitz utilities\nfor any $d> 1$. When the utility functions are given by a polynomial time\nalgorithm, we prove the problem to be PPAD-complete.\n  For measurable utility functions, we find a fully polynomial-time algorithm\nfor finding an approximate envy-free allocation of a cake among three people\nusing two cuts.", 
    "link": "http://arxiv.org/pdf/0907.1334v1", 
    "arxiv-id": "0907.1334v1"
},{
    "category": "cs.GT", 
    "author": "Arno Pauly", 
    "title": "How discontinuous is Computing Nash Equilibria?", 
    "publish": "2009-07-09T18:45:25Z", 
    "summary": "We investigate the degree of discontinuity of several solution concepts from\nnon-cooperative game theory. While the consideration of Nash equilibria forms\nthe core of our work, also pure and correlated equilibria are dealt with.\nFormally, we restrict the treatment to two player games, but results and proofs\nextend to the n-player case. As a side result, the degree of discontinuity of\nsolving systems of linear inequalities is settled.", 
    "link": "http://arxiv.org/pdf/0907.1482v1", 
    "arxiv-id": "0907.1482v1"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "Amplified Hardness of Approximation for VCG-Based Mechanisms", 
    "publish": "2009-07-13T16:57:24Z", 
    "summary": "If a two-player social welfare maximization problem does not admit a PTAS, we\nprove that any maximal-in-range truthful mechanism that runs in polynomial time\ncannot achieve an approximation factor better than 1/2. Moreover, for the\nk-player version of the same problem, the hardness of approximation improves to\n1/k under the same two-player hardness assumption. (We note that 1/k is\nachievable by a trivial deterministic maximal-in-range mechanism.) This\nhardness result encompasses not only deterministic maximal-in-range mechanisms,\nbut also all universally-truthful randomized maximal in range algorithms, as\nwell as a class of strictly more powerful truthful-in-expectation randomized\nmechanisms recently introduced by Dobzinski and Dughmi. Our result applies to\nany class of valuation functions that satisfies some minimal closure\nproperties. These properties are satisfied by the valuation functions in all\nwell-studied APX-hard social welfare maximization problems, such as coverage,\nsubmodular, and subadditive valuations.\n  We also prove a stronger result for universally-truthful maximal-in-range\nmechanisms. Namely, even for the class of budgeted additive valuations, which\nadmits an FPTAS, no such mechanism can achieve an approximation factor better\nthan 1/k in polynomial time.", 
    "link": "http://arxiv.org/pdf/0907.1948v2", 
    "arxiv-id": "0907.1948v2"
},{
    "category": "cs.GT", 
    "author": "Matthew C. Clarke", 
    "title": "On the Chances of Completing the Game of \"Perpetual Motion\"", 
    "publish": "2009-07-11T10:19:11Z", 
    "summary": "This brief paper describes the single-player card game called \"Perpetual\nMotion\" and reports on a computational analysis of the game's outcome. The\nanalysis follows a Monte Carlo methodology based on a sample of 10,000 randomly\ngenerated games. The key result is that 54.55% +/- 0.89% of games can be\ncompleted (by a patient player!) but that the remaining 45.45% result in\nnon-terminating cycles. The lengths of these non-terminating cycles leave some\noutstanding questions.", 
    "link": "http://arxiv.org/pdf/0907.1955v1", 
    "arxiv-id": "0907.1955v1"
},{
    "category": "cs.GT", 
    "author": "Balasubramanian Sivan", 
    "title": "Sequential Posted Pricing and Multi-parameter Mechanism Design", 
    "publish": "2009-07-14T19:51:10Z", 
    "summary": "We consider the classical mathematical economics problem of {\\em Bayesian\noptimal mechanism design} where a principal aims to optimize expected revenue\nwhen allocating resources to self-interested agents with preferences drawn from\na known distribution. In single-parameter settings (i.e., where each agent's\npreference is given by a single private value for being served and zero for not\nbeing served) this problem is solved [Myerson '81]. Unfortunately, these single\nparameter optimal mechanisms are impractical and rarely employed [Ausubel and\nMilgrom '06], and furthermore the underlying economic theory fails to\ngeneralize to the important, relevant, and unsolved multi-dimensional setting\n(i.e., where each agent's preference is given by multiple values for each of\nthe multiple services available) [Manelli and Vincent '07]. In contrast to the\ntheory of optimal mechanisms we develop a theory of sequential posted price\nmechanisms, where agents in sequence are offered take-it-or-leave-it prices.\nThese mechanisms are approximately optimal in single-dimensional settings, and\navoid many of the properties that make optimal mechanisms impractical.\nFurthermore, these mechanisms generalize naturally to give the first known\napproximations to the elusive optimal multi-dimensional mechanism design\nproblem. In particular, we solve multi-dimensional multi-unit auction problems\nand generalizations to matroid feasibility constraints. The constant\napproximations we obtain range from 1.5 to 8. For all but one case, our posted\nprice sequences can be computed in polynomial time.", 
    "link": "http://arxiv.org/pdf/0907.2435v2", 
    "arxiv-id": "0907.2435v2"
},{
    "category": "cs.GT", 
    "author": "Annamaria Kovacs", 
    "title": "A deterministic truthful PTAS for scheduling related machines", 
    "publish": "2009-07-17T13:13:07Z", 
    "summary": "Scheduling on related machines ($Q||C_{\\max}$) is one of the most important\nproblems in the field of Algorithmic Mechanism Design. Each machine is\ncontrolled by a selfish agent and her valuation can be expressed via a single\nparameter, her {\\em speed}. In contrast to other similar problems, Archer and\nTardos \\cite{AT01} showed that an algorithm that minimizes the makespan can be\ntruthfully implemented, although in exponential time. On the other hand, if we\nleave out the game-theoretic issues, the complexity of the problem has been\ncompletely settled -- the problem is strongly NP-hard, while there exists a\nPTAS \\cite{HS88,ES04}.\n  This problem is the most well studied in single-parameter algorithmic\nmechanism design. It gives an excellent ground to explore the boundary between\ntruthfulness and efficient computation. Since the work of Archer and Tardos,\nquite a lot of deterministic and randomized mechanisms have been suggested.\nRecently, a breakthrough result \\cite{DDDR08} showed that a randomized truthful\nPTAS exists. On the other hand, for the deterministic case, the best known\napproximation factor is 2.8 \\cite{Kov05,Kov07}.\n  It has been a major open question whether there exists a deterministic\ntruthful PTAS, or whether truthfulness has an essential, negative impact on the\ncomputational complexity of the problem. In this paper we give a definitive\nanswer to this important question by providing a truthful {\\em deterministic}\nPTAS.", 
    "link": "http://arxiv.org/pdf/0907.3068v1", 
    "arxiv-id": "0907.3068v1"
},{
    "category": "cs.GT", 
    "author": "Shahar Dobzinski", 
    "title": "A Note on the Power of Truthful Approximation Mechanisms", 
    "publish": "2009-07-30T09:18:31Z", 
    "summary": "We study the power of polynomial-time truthful mechanisms comparing to\npolynomial time (non-truthful) algorithms. We show that there is a setting in\nwhich deterministic polynomial-time truthful mechanisms cannot guarantee a\nbounded approximation ratio, but a non-truthful FPTAS exists. We also show that\nin the same setting there is a universally truthful mechanism that provides an\napproximation ratio of 2. This shows that the cost of truthfulness is\nunbounded. The proofs are almost standard in the field and follow from known\nresults.", 
    "link": "http://arxiv.org/pdf/0907.5219v2", 
    "arxiv-id": "0907.5219v2"
},{
    "category": "cs.GT", 
    "author": "Pierre Lescanne", 
    "title": "Feasibility/Desirability Games for Normal Form Games, Choice Models and   Evolutionary Games", 
    "publish": "2009-07-31T04:44:57Z", 
    "summary": "An abstraction of normal form games is proposed, called\nFeasibility/Desirability Games (or FD Games in short). FD Games can be seen\nfrom three points of view: as a new presentation of games in which Nash\nequilibria can be found, as choice models in microeconomics or as a model of\nevolution in games.", 
    "link": "http://arxiv.org/pdf/0907.5469v1", 
    "arxiv-id": "0907.5469v1"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "Randomized Online Algorithms for the Buyback Problem", 
    "publish": "2009-08-01T04:21:22Z", 
    "summary": "In the matroid buyback problem, an algorithm observes a sequence of bids and\nmust decide whether to accept each bid at the moment it arrives, subject to a\nmatroid constraint on the set of accepted bids. Decisions to reject bids are\nirrevocable, whereas decisions to accept bids may be canceled at a cost which\nis a fixed fraction of the bid value. We present a new randomized algorithm for\nthis problem, and we prove matching upper and lower bounds to establish that\nthe competitive ratio of this algorithm, against an oblivious adversary, is the\nbest possible. We also observe that when the adversary is adaptive, no\nrandomized algorithm can improve the competitive ratio of the optimal\ndeterministic algorithm. Thus, our work completely resolves the question of\nwhat competitive ratios can be achieved by randomized algorithms for the\nmatroid buyback problem.", 
    "link": "http://arxiv.org/pdf/0908.0043v1", 
    "arxiv-id": "0908.0043v1"
},{
    "category": "cs.GT", 
    "author": "F. Brasiliero", 
    "title": "Analytical Study of Adversarial Strategies in Cluster-based Overlays", 
    "publish": "2009-08-04T07:17:57Z", 
    "summary": "Scheideler has shown that peer-to-peer overlays networks can only survive\nByzantine attacks if malicious nodes are not able to predict what is going to\nbe the topology of the network for a given sequence of join and leave\noperations. In this paper we investigate adversarial strategies by following\nspecific games. Our analysis demonstrates first that an adversary can very\nquickly subvert DHT-based overlays by simply never triggering leave operations.\nWe then show that when all nodes (honest and malicious ones) are imposed on a\nlimited lifetime, the system eventually reaches a stationary regime where the\nratio of polluted clusters is bounded, independently from the initial amount of\ncorruption in the system.", 
    "link": "http://arxiv.org/pdf/0908.0398v1", 
    "arxiv-id": "0908.0398v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Linearly Coupled Communication Games", 
    "publish": "2009-08-12T04:56:18Z", 
    "summary": "This paper discusses a special type of multi-user communication scenario, in\nwhich users' utilities are linearly impacted by their competitors' actions.\nFirst, we explicitly characterize the Nash equilibrium and Pareto boundary of\nthe achievable utility region. Second, the price of anarchy incurred by the\nnon-collaborative Nash strategy is quantified. Third, to improve the\nperformance in the non-cooperative scenarios, we investigate the properties of\nan alternative solution concept named conjectural equilibrium, in which\nindividual users compensate for their lack of information by forming internal\nbeliefs about their competitors. The global convergence of the best response\nand Jacobi update dynamics that achieve various conjectural equilibria are\nanalyzed. It is shown that the Pareto boundaries of the investigated linearly\ncoupled games can be sustained as stable conjectural equilibria if the belief\nfunctions are properly initialized. The investigated models apply to a variety\nof realistic applications encountered in the multiple access design, including\nwireless random access and flow control.", 
    "link": "http://arxiv.org/pdf/0908.1613v1", 
    "arxiv-id": "0908.1613v1"
},{
    "category": "cs.GT", 
    "author": "M. Debbah", 
    "title": "On the Base Station Selection and Base Station Sharing in   Self-Configuring Networks", 
    "publish": "2009-08-12T10:18:16Z", 
    "summary": "We model the interaction of several radio devices aiming to obtain wireless\nconnectivity by using a set of base stations (BS) as a non-cooperative game.\nEach radio device aims to maximize its own spectral efficiency (SE) in two\ndifferent scenarios: First, we let each player to use a unique BS (BS\nselection) and second, we let them to simultaneously use several BSs (BS\nSharing). In both cases, we show that the resulting game is an exact potential\ngame. We found that the BS selection game posses multiple Nash equilibria (NE)\nwhile the BS sharing game posses a unique one. We provide fully decentralized\nalgorithms which always converge to a NE in both games. We analyze the price of\nanarchy and the price of stability for the case of BS selection. Finally, we\nobserved that depending on the number of transmitters, the BS selection\ntechnique might provide a better global performance (network spectral\nefficiency) than BS sharing, which suggests the existence of a Braess type\nparadox.", 
    "link": "http://arxiv.org/pdf/0908.1667v1", 
    "arxiv-id": "0908.1667v1"
},{
    "category": "cs.GT", 
    "author": "Allan Borodin", 
    "title": "Price of Anarchy for Greedy Auctions", 
    "publish": "2009-09-04T13:39:25Z", 
    "summary": "We consider auctions in which greedy algorithms, paired with first-price or\ncritical-price payment rules, are used to resolve multi-parameter combinatorial\nallocation problems. We study the price of anarchy for social welfare in such\nauctions. We show for a variety of equilibrium concepts, including Bayes-Nash\nequilibrium and correlated equilibrium, the resulting price of anarchy bound is\nclose to the approximation factor of the underlying greedy algorithm.", 
    "link": "http://arxiv.org/pdf/0909.0892v2", 
    "arxiv-id": "0909.0892v2"
},{
    "category": "cs.GT", 
    "author": "Svetlana Olonetsky", 
    "title": "Envy-Free Makespan Approximation", 
    "publish": "2009-09-06T09:19:59Z", 
    "summary": "We study envy-free mechanisms for scheduling tasks on unrelated machines\n(agents) that approximately minimize the makespan. For indivisible tasks, we\nput forward an envy-free poly-time mechanism that approximates the minimal\nmakespan to within a factor of $O(\\log m)$, where $m$ is the number of\nmachines. We also show a lower bound of $\\Omega(\\log m / \\log\\log m)$. This\nimproves the recent result of Hartline {\\sl et al.} \\cite{Ahuva:2008} who give\nan upper bound of $(m+1)/2$, and a lower bound of $2-1/m$. For divisible tasks,\nwe show that there always exists an envy-free poly-time mechanism with optimal\nmakespan.", 
    "link": "http://arxiv.org/pdf/0909.1072v1", 
    "arxiv-id": "0909.1072v1"
},{
    "category": "cs.GT", 
    "author": "Amiram Wingarten", 
    "title": "Envy, Multi Envy, and Revenue Maximization", 
    "publish": "2009-09-24T22:30:39Z", 
    "summary": "We study the envy free pricing problem faced by a seller who wishes to\nmaximize revenue by setting prices for bundles of items. If there is an\nunlimited supply of items and agents are single minded then we show that\nfinding the revenue maximizing envy free allocation/pricing can be solved in\npolynomial time by reducing it to an instance of weighted independent set on a\nperfect graph.\n  We define an allocation/pricing as \\textit{multi envy free} if no agent\nwishes to replace her allocation with the union of the allocations of some set\nof other agents and her price with the sum of their prices. We show that it is\n\\textit{coNP}-hard to decide if a given allocation/pricing is multi envy free.\nWe also show that revenue maximization multi envy free allocation/pricing is\n\\textit{APX} hard.\n  Furthermore, we give efficient algorithms and hardness results for various\nvariants of the highway problem.", 
    "link": "http://arxiv.org/pdf/0909.4569v1", 
    "arxiv-id": "0909.4569v1"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "Bayesian Algorithmic Mechanism Design", 
    "publish": "2009-09-25T18:00:59Z", 
    "summary": "The principal problem in algorithmic mechanism design is in merging the\nincentive constraints imposed by selfish behavior with the algorithmic\nconstraints imposed by computational intractability. This field is motivated by\nthe observation that the preeminent approach for designing incentive compatible\nmechanisms, namely that of Vickrey, Clarke, and Groves; and the central\napproach for circumventing computational obstacles, that of approximation\nalgorithms, are fundamentally incompatible: natural applications of the VCG\napproach to an approximation algorithm fails to yield an incentive compatible\nmechanism. We consider relaxing the desideratum of (ex post) incentive\ncompatibility (IC) to Bayesian incentive compatibility (BIC), where\ntruthtelling is a Bayes-Nash equilibrium (the standard notion of incentive\ncompatibility in economics). For welfare maximization in single-parameter agent\nsettings, we give a general black-box reduction that turns any approximation\nalgorithm into a Bayesian incentive compatible mechanism with essentially the\nsame approximation factor.", 
    "link": "http://arxiv.org/pdf/0909.4756v2", 
    "arxiv-id": "0909.4756v2"
},{
    "category": "cs.GT", 
    "author": "Uri Nadav", 
    "title": "Quasi-Proportional Mechanisms: Prior-free Revenue Maximization", 
    "publish": "2009-09-29T15:33:27Z", 
    "summary": "Inspired by Internet ad auction applications, we study the problem of\nallocating a single item via an auction when bidders place very different\nvalues on the item. We formulate this as the problem of prior-free auction and\nfocus on designing a simple mechanism that always allocates the item. Rather\nthan designing sophisticated pricing methods like prior literature, we design\nbetter allocation methods. In particular, we propose quasi-proportional\nallocation methods in which the probability that an item is allocated to a\nbidder depends (quasi-proportionally) on the bids.\n  We prove that corresponding games for both all-pay and winners-pay\nquasi-proportional mechanisms admit pure Nash equilibria and this equilibrium\nis unique. We also give an algorithm to compute this equilibrium in polynomial\ntime. Further, we show that the revenue of the auctioneer is promisingly high\ncompared to the ultimate, i.e., the highest value of any of the bidders, and\nshow bounds on the revenue of equilibria both analytically, as well as using\nexperiments for specific quasi-proportional functions. This is the first known\nrevenue analysis for these natural mechanisms (including the special case of\nproportional mechanism which is common in network resource allocation\nproblems).", 
    "link": "http://arxiv.org/pdf/0909.5365v1", 
    "arxiv-id": "0909.5365v1"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "Beyond Equilibria: Mechanisms for Repeated Combinatorial Auctions", 
    "publish": "2009-09-30T17:47:17Z", 
    "summary": "We study the design of mechanisms in combinatorial auction domains. We focus\non settings where the auction is repeated, motivated by auctions for licenses\nor advertising space. We consider models of agent behaviour in which they\neither apply common learning techniques to minimize the regret of their bidding\nstrategies, or apply short-sighted best-response strategies. We ask: when can a\nblack-box approximation algorithm for the base auction problem be converted\ninto a mechanism that approximately preserves the original algorithm's\napproximation factor on average over many iterations? We present a general\nreduction for a broad class of algorithms when agents minimize external regret.\nWe also present a new mechanism for the combinatorial auction problem that\nattains an $O(\\sqrt{m})$ approximation on average when agents apply\nbest-response dynamics.", 
    "link": "http://arxiv.org/pdf/0909.5677v1", 
    "arxiv-id": "0909.5677v1"
},{
    "category": "cs.GT", 
    "author": "Ye Du", 
    "title": "Ranking via Arrow-Debreu Equilibrium", 
    "publish": "2009-10-03T05:39:01Z", 
    "summary": "In this paper, we establish a connection between ranking theory and general\nequilibrium theory. First of all, we show that the ranking vector of PageRank\nor Invariant method is precisely the equilibrium of a special Cobb-Douglas\nmarket. This gives a natural economic interpretation for the PageRank or\nInvariant method. Furthermore, we propose a new ranking method, the CES\nranking, which is minimally fair, strictly monotone and invariant to reference\nintensity, but not uniform or weakly additive.", 
    "link": "http://arxiv.org/pdf/0910.0513v1", 
    "arxiv-id": "0910.0513v1"
},{
    "category": "cs.GT", 
    "author": "Sergei Vassilvitskii", 
    "title": "Social Networks and Stable Matchings in the Job Market", 
    "publish": "2009-10-06T03:04:52Z", 
    "summary": "For most people, social contacts play an integral part in finding a new job.\nAs observed by Granovetter's seminal study, the proportion of jobs obtained\nthrough social contacts is usually large compared to those obtained through\npostings or agencies. At the same time, job markets are a natural example of\ntwo-sided matching markets. An important solution concept in such markets is\nthat of stable matchings, and the use of the celebrated Gale-Shapley algorithm\nto compute them. So far, the literature has evolved separately, either focusing\non the implications of information flowing through a social network, or on\ndeveloping a mathematical theory of job markets through the use of two-sided\nmatching techniques.\n  In this paper we provide a model of the job market that brings both aspects\nof job markets together. To model the social scientists' observations, we\nassume that workers learn only about positions in firms through social\ncontacts. Given that information structure, we study both static properties of\nwhat we call locally stable matchings (i.e., stable matchings subject to\ninformational constraints given by a social network) and dynamic properties\nthrough a reinterpretation of Gale-Shapley's algorithm as myopic best response\ndynamics.\n  We prove that, in general, the set of locally stable matching strictly\ncontains that of stable matchings and it is in fact NP-complete to determine if\nthey are identical. We also show that the lattice structure of stable matchings\nis in general absent. Finally, we focus on myopic best response dynamics\ninspired by the Gale-Shapley algorithm. We study the efficiency loss due to the\ninformational constraints, providing both lower and upper bounds.", 
    "link": "http://arxiv.org/pdf/0910.0916v1", 
    "arxiv-id": "0910.0916v1"
},{
    "category": "cs.GT", 
    "author": "Sanjib Kumar Das", 
    "title": "A real world network pricing game with less severe Braess' Paradox", 
    "publish": "2009-10-12T09:34:27Z", 
    "summary": "Internet and graphs are very much related. The graphical structure of\ninternet has been studied extensively to provide efficient solutions to routing\nand other problems. But most of these studies assume a central authority which\ncontrols and manages the internet. In the recent years game theoretic models\nhave been proposed which do not require a central authority and the users are\nassumed to be routing their flows selfishly. The existence of Nash Equilibria,\ncongestion and the amount of inefficiency caused by this selfish routing is a\nmajor concern in this field. A type of paradox in the selfish routing networks,\nBraess' Paradox, first discovered by Braess, is a major contributor to\ninefficiency. Several pricing mechanisms have also been provided which give a\ngame theoretical model between users(consumers) and ISPs ({Internet Service\nProviders} or sellers) for the internet.\n  We propose a novel pricing mechanism, based on real world Internet network\narchitecture, which reduces the severity of Braess' Paradox in selfish routing\ngame theoretic networks. It's a pricing mechanism between combinatorial users\nand ISPs. We prove that Nash equilibria exists in this network and provide\nbounds on inefficiency . We use graphical properties of internet to prove our\nresult. Several interesting extensions and future work have also been\ndiscussed.", 
    "link": "http://arxiv.org/pdf/0910.2113v1", 
    "arxiv-id": "0910.2113v1"
},{
    "category": "cs.GT", 
    "author": "Ashish Sangwan", 
    "title": "The Effect of Malice on the Social Optimum in Linear Load Balancing   Games", 
    "publish": "2009-10-14T15:59:39Z", 
    "summary": "In this note we consider the following problem to study the effect of\nmalicious players on the social optimum in load balancing games: Consider two\nplayers SOC and MAL controlling (1-f) and f fraction of the flow in a load\nbalancing game. SOC tries to minimize the total cost faced by her players while\nMAL tries to maximize the same.\n  If the latencies are linear, we show that this 2-player zero-sum game has a\npure strategy Nash equilibrium. Moreover, we show that one of the optimal\nstrategies for MAL is to play selfishly: let the f fraction of the flow be sent\nas when the flow was controlled by infinitesimal players playing selfishly and\nreaching a Nash equilibrium. This shows that a malicious player cannot cause\nmore harm in this game than a set of selfish agents.\n  We also introduce the notion of Cost of Malice - the ratio of the cost faced\nby SOC at equilibrium to (1-f)OPT, where OPT is the social optimum minimizing\nthe cost of all the players. In linear load balancing games we bound the cost\nof malice by (1+f/2).", 
    "link": "http://arxiv.org/pdf/0910.2655v2", 
    "arxiv-id": "0910.2655v2"
},{
    "category": "cs.GT", 
    "author": "Merouane Debbah", 
    "title": "Continuum Equilibria and Global Optimization for Routing in Dense Static   Ad Hoc Networks", 
    "publish": "2009-10-28T16:47:51Z", 
    "summary": "We consider massively dense ad hoc networks and study their continuum limits\nas the node density increases and as the graph providing the available routes\nbecomes a continuous area with location and congestion dependent costs. We\nstudy both the global optimal solution as well as the non-cooperative routing\nproblem among a large population of users where each user seeks a path from its\norigin to its destination so as to minimize its individual cost. Finally, we\nseek for a (continuum version of the) Wardrop equilibrium. We first show how to\nderive meaningful cost models as a function of the scaling properties of the\ncapacity of the network and of the density of nodes. We present various\nsolution methodologies for the problem: (1) the viscosity solution of the\nHamilton-Jacobi-Bellman equation, for the global optimization problem, (2) a\nmethod based on Green's Theorem for the least cost problem of an individual,\nand (3) a solution of the Wardrop equilibrium problem using a transformation\ninto an equivalent global optimization problem.", 
    "link": "http://arxiv.org/pdf/0910.5426v2", 
    "arxiv-id": "0910.5426v2"
},{
    "category": "cs.GT", 
    "author": "Giuseppa Alfano", 
    "title": "Magnetworks: how mobility impacts the design of Mobile Networks", 
    "publish": "2009-10-29T14:02:45Z", 
    "summary": "In this paper we study the optimal placement and optimal number of active\nrelay nodes through the traffic density in mobile sensor ad-hoc networks. We\nconsider a setting in which a set of mobile sensor sources is creating data and\na set of mobile sensor destinations receiving that data. We make the assumption\nthat the network is massively dense, i.e., there are so many sources,\ndestinations, and relay nodes, that it is best to describe the network in terms\nof macroscopic parameters, such as their spatial density, rather than in terms\nof microscopic parameters, such as their individual placements.\n  We focus on a particular physical layer model that is characterized by the\nfollowing assumptions: i) the nodes must only transport the data from the\nsources to the destinations, and do not need to sense the data at the sources,\nor deliver them at the destinations once the data arrive at their physical\nlocations, and ii) the nodes have limited bandwidth available to them, but they\nuse it optimally to locally achieve the network capacity.\n  In this setting, the optimal distribution of nodes induces a traffic density\nthat resembles the electric displacement that will be created if we substitute\nthe sources and destinations with positive and negative charges respectively.\nThe analogy between the two settings is very tight and have a direct\ninterpretation in wireless sensor networks.", 
    "link": "http://arxiv.org/pdf/0910.5643v1", 
    "arxiv-id": "0910.5643v1"
},{
    "category": "cs.GT", 
    "author": "Merouane Debbah", 
    "title": "Spatial games and global optimization for mobile association problems", 
    "publish": "2009-11-02T08:54:56Z", 
    "summary": "The basic optimal transportation problem consists in finding the most\neffective way of moving masses from one location to another, while minimizing\nthe transportation cost. Such concept has been found to be useful to understand\nvarious mathematical, economical, and control theory phenomena, such as\nWitsenhausen's counterexam-ple in stochastic control theory, principal-agent\nproblem in microeco- nomic theory, location and planning problems, etc. In this\nwork, we focus on mobile association problems: the determina-tion of the cells\ncorresponding to each base station, i.e., the locations at which intelligent\nmobile terminals prefer to connect to a given base station rather than to\nothers. This work combines game theory and optimal transport theory to\ncharacterize the solution based on fluid approximations. We characterize the\noptimal solution from both the global network and the mobile user points of\nview.", 
    "link": "http://arxiv.org/pdf/0911.0257v2", 
    "arxiv-id": "0911.0257v2"
},{
    "category": "cs.GT", 
    "author": "Ingmar Weber", 
    "title": "On the Pricing of Recommendations and Recommending Strategically", 
    "publish": "2009-11-09T10:21:42Z", 
    "summary": "If you recommend a product to me and I buy it, how much should you be paid by\nthe seller? And if your sole interest is to maximize the amount paid to you by\nthe seller for a sequence of recommendations, how should you recommend\noptimally if I become more inclined to ignore you with each irrelevant\nrecommendation you make? Finding an answer to these questions is a key\nchallenge in all forms of marketing that rely on and explore social ties;\nranging from personal recommendations to viral marketing.\n  In the first part of this paper, we show that there can be no pricing\nmechanism that is \"truthful\" with respect to the seller, and we use solution\nconcepts from coalitional game theory, namely the Core, the Shapley Value, and\nthe Nash Bargaining Solution, to derive provably \"fair\" prices for settings\nwith one or multiple recommenders. We then investigate pricing mechanisms for\nthe setting where recommenders have different \"purchase arguments\". Here we\nshow that it might be beneficial for the recommenders to withhold some of their\narguments, unless anonymity-proof solution concepts, such as the\nanonymity-proof Shapley value, are used.\n  In the second part of this paper, we analyze the setting where the\nrecommendee loses trust in the recommender for each irrelevant recommendation.\nHere we prove that even if the recommendee regains her initial trust on each\nsuccessful recommendation, the expected total profit the recommender can make\nover an infinite period is bounded. This can only be overcome when the\nrecommendee also incrementally regains trust during periods without any\nrecommendation. Here, we see an interesting connection to \"banner blindness\",\nsuggesting that showing fewer ads can lead to a higher long-term profit.", 
    "link": "http://arxiv.org/pdf/0911.1619v1", 
    "arxiv-id": "0911.1619v1"
},{
    "category": "cs.GT", 
    "author": "Andrea Montanari", 
    "title": "A Natural Dynamics for Bargaining on Exchange Networks", 
    "publish": "2009-11-10T00:37:35Z", 
    "summary": "Bargaining networks model the behavior of a set of players that need to reach\npairwise agreements for making profits. Nash bargaining solutions are special\noutcomes of such games that are both stable and balanced. Kleinberg and Tardos\nproved a sharp algorithmic characterization of such outcomes, but left open the\nproblem of how the actual bargaining process converges to them. A partial\nanswer was provided by Azar et al. who proposed a distributed algorithm for\nconstructing Nash bargaining solutions, but without polynomial bounds on its\nconvergence rate. In this paper, we introduce a simple and natural model for\nthis process, and study its convergence rate to Nash bargaining solutions. At\neach time step, each player proposes a deal to each of her neighbors. The\nproposal consists of a share of the potential profit in case of agreement. The\nshare is chosen to be balanced in Nash's sense as far as this is feasible (with\nrespect to the current best alternatives for both players). We prove that,\nwhenever the Nash bargaining solution is unique (and satisfies a positive gap\ncondition) this dynamics converges to it in polynomial time. Our analysis is\nbased on an approximate decoupling phenomenon between the dynamics on different\nsubstructures of the network. This approach may be of general interest for the\nanalysis of local algorithms on networks.", 
    "link": "http://arxiv.org/pdf/0911.1767v2", 
    "arxiv-id": "0911.1767v2"
},{
    "category": "cs.GT", 
    "author": "Costas Busch", 
    "title": "The Impact of Exponential Utility Costs in Bottleneck Routing Games", 
    "publish": "2009-11-21T01:10:39Z", 
    "summary": "We study bottleneck routing games where the social cost is determined by the\nworst congestion on any edge in the network. Bottleneck games have been studied\nin the literature by having the player's utility costs to be determined by the\nworst congested edge in their paths. However, the Nash equilibria of such games\nare inefficient since the price of anarchy can be very high with respect to the\nparameters of the game. In order to obtain smaller price of anarchy we explore\n{\\em exponential bottleneck games} where the utility costs of the players are\nexponential functions on the congestion of the edges in their paths. We find\nthat exponential bottleneck games are very efficient giving a poly-log bound on\nthe price of anarchy: O(log L log |E|), where L is the largest path length in\nthe players strategy sets and E is the set of edges in the graph.", 
    "link": "http://arxiv.org/pdf/0911.4150v1", 
    "arxiv-id": "0911.4150v1"
},{
    "category": "cs.GT", 
    "author": "Perrinel Matthieu", 
    "title": "On the Rationality of Escalation", 
    "publish": "2009-12-09T13:52:49Z", 
    "summary": "Escalation is a typical feature of infinite games. Therefore tools conceived\nfor studying infinite mathematical structures, namely those deriving from\ncoinduction are essential. Here we use coinduction, or backward coinduction (to\nshow its connection with the same concept for finite games) to study carefully\nand formally the infinite games especially those called dollar auctions, which\nare considered as the paradigm of escalation. Unlike what is commonly admitted,\nwe show that, provided one assumes that the other agent will always stop,\nbidding is rational, because it results in a subgame perfect equilibrium. We\nshow that this is not the only rational strategy profile (the only subgame\nperfect equilibrium). Indeed if an agent stops and will stop at every step, we\nclaim that he is rational as well, if one admits that his opponent will never\nstop, because this corresponds to a subgame perfect equilibrium. Amazingly, in\nthe infinite dollar auction game, the behavior in which both agents stop at\neach step is not a Nash equilibrium, hence is not a subgame perfect\nequilibrium, hence is not rational.", 
    "link": "http://arxiv.org/pdf/0912.1746v2", 
    "arxiv-id": "0912.1746v2"
},{
    "category": "cs.GT", 
    "author": "Ingmar Weber", 
    "title": "Sponsored Search, Market Equilibria, and the Hungarian Method", 
    "publish": "2009-12-10T08:18:10Z", 
    "summary": "Matching markets play a prominent role in economic theory. A prime example of\nsuch a market is the sponsored search market. Here, as in other markets of that\nkind, market equilibria correspond to feasible, envy free, and bidder optimal\noutcomes. For settings without budgets such an outcome always exists and can be\ncomputed in polynomial-time by the so-called Hungarian Method. Moreover, every\nmechanism that computes such an outcome is incentive compatible. We show that\nthe Hungarian Method can be modified so that it finds a feasible, envy free,\nand bidder optimal outcome for settings with budgets. We also show that in\nsettings with budgets no mechanism that computes such an outcome can be\nincentive compatible for all inputs. For inputs in general position, however,\nthe presented mechanism---as any other mechanism that computes such an outcome\nfor settings with budgets---is incentive compatible.", 
    "link": "http://arxiv.org/pdf/0912.1934v6", 
    "arxiv-id": "0912.1934v6"
},{
    "category": "cs.GT", 
    "author": "Fedor Petrov", 
    "title": "Frugal Mechanism Design via Spectral Techniques", 
    "publish": "2009-12-17T15:44:58Z", 
    "summary": "We study the design of truthful mechanisms for set systems, i.e., scenarios\nwhere a customer needs to hire a team of agents to perform a complex task. In\nthis setting, frugality [Archer&Tardos'02] provides a measure to evaluate the\n\"cost of truthfulness\", that is, the overpayment of a truthful mechanism\nrelative to the \"fair\" payment. We propose a uniform scheme for designing\nfrugal truthful mechanisms for general set systems. Our scheme is based on\nscaling the agents' bids using the eigenvector of a matrix that encodes the\ninterdependencies between the agents. We demonstrate that the r-out-of-k-system\nmechanism and the \\sqrt-mechanism for buying a path in a graph [Karlin et.\nal'05] can be viewed as instantiations of our scheme. We then apply our scheme\nto two other classes of set systems, namely, vertex cover systems and k-path\nsystems, in which a customer needs to purchase k edge-disjoint source-sink\npaths. For both settings, we bound the frugality of our mechanism in terms of\nthe largest eigenvalue of the respective interdependency matrix. We show that\nour mechanism is optimal for a large subclass of vertex cover systems\nsatisfying a simple local sparsity condition. For k-path systems, while our\nmechanism is within a factor of k + 1 from optimal, we show that it is, in\nfact, optimal, when one uses a modified definition of frugality proposed in\n[Elkind et al.'07]. Our lower bound argument combines spectral techniques and\nYoung's inequality, and is applicable to all set systems. As both r-out-of-k\nsystems and single path systems can be viewed as special cases of k-path\nsystems, our result improves the lower bounds of [Karlin et al.'05] and answers\nseveral open questions proposed in that paper.", 
    "link": "http://arxiv.org/pdf/0912.3403v2", 
    "arxiv-id": "0912.3403v2"
},{
    "category": "cs.GT", 
    "author": "Jean Walrand", 
    "title": "Optimism in Games with Non-Probabilistic Uncertainty", 
    "publish": "2009-12-19T11:22:40Z", 
    "summary": "The paper studies one-shot two-player games with non-Bayesian uncertainty.\nThe players have an attitude that ranges from optimism to pessimism in the face\nof uncertainty. Given the attitudes, each player forms a belief about the set\nof possible strategies of the other player. If these beliefs are consistent,\none says that they form an uncertainty equilibrium. One then considers a\ntwo-phase game where the players first choose their attitude and then play the\nresulting game. The paper illustrates these notions with a number of games\nwhere the approach provides a new insight into the plausible strategies of the\nplayers.", 
    "link": "http://arxiv.org/pdf/0912.3886v3", 
    "arxiv-id": "0912.3886v3"
},{
    "category": "cs.GT", 
    "author": "Alderete Maria Veronica", 
    "title": "E-commerce between a large firm and a SME supplier: a screening model", 
    "publish": "2009-12-19T18:34:37Z", 
    "summary": "This paper derives a model of screening contracts in the presence of positive\nnetwork effects when building an electronic commerce network (e-commerce)\nbetween a large firm and a small and medium sized enterprise (SME) supplier\nbased on Compte (2008). Compte (2008) main insight is that when several\npotential candidates compete for the task, the principal will in general\nimprove the performance of his firm by inducing the member candidates to assess\ntheir competence before signing the contract (through an appropriate choice of\ncontracts). The large firm (principal) must choose between different SME\nsuppliers (agents) to build a business to business e-commerce network. In the\npresence of positive network externalities, we show that social surplus\nincreases.", 
    "link": "http://arxiv.org/pdf/0912.3920v1", 
    "arxiv-id": "0912.3920v1"
},{
    "category": "cs.GT", 
    "author": "Arpita Ghosh", 
    "title": "Truthful Assignment without Money", 
    "publish": "2010-01-04T04:53:13Z", 
    "summary": "We study the design of truthful mechanisms that do not use payments for the\ngeneralized assignment problem (GAP) and its variants. An instance of the GAP\nconsists of a bipartite graph with jobs on one side and machines on the other.\nMachines have capacities and edges have values and sizes; the goal is to\nconstruct a welfare maximizing feasible assignment. In our model of private\nvaluations, motivated by impossibility results, the value and sizes on all\njob-machine pairs are public information; however, whether an edge exists or\nnot in the bipartite graph is a job's private information.\n  We study several variants of the GAP starting with matching. For the\nunweighted version, we give an optimal strategyproof mechanism; for maximum\nweight bipartite matching, however, we show give a 2-approximate strategyproof\nmechanism and show by a matching lowerbound that this is optimal. Next we study\nknapsack-like problems, which are APX-hard. For these problems, we develop a\ngeneral LP-based technique that extends the ideas of Lavi and Swamy to reduce\ndesigning a truthful mechanism without money to designing such a mechanism for\nthe fractional version of the problem, at a loss of a factor equal to the\nintegrality gap in the approximation ratio. We use this technique to obtain\nstrategyproof mechanisms with constant approximation ratios for these problems.\nWe then design an O(log n)-approximate strategyproof mechanism for the GAP by\nreducing, with logarithmic loss in the approximation, to our solution for the\nvalue-invariant GAP. Our technique may be of independent interest for designing\ntruthful mechanisms without money for other LP-based problems.", 
    "link": "http://arxiv.org/pdf/1001.0436v5", 
    "arxiv-id": "1001.0436v5"
},{
    "category": "cs.GT", 
    "author": "Georgios Zervas", 
    "title": "Information Asymmetries in Pay-Per-Bid Auctions: How Swoopo Makes Bank", 
    "publish": "2010-01-05T16:31:06Z", 
    "summary": "Innovative auction methods can be exploited to increase profits, with\nShubik's famous \"dollar auction\" perhaps being the most widely known example.\nRecently, some mainstream e-commerce web sites have apparently achieved the\nsame end on a much broader scale, by using \"pay-per-bid\" auctions to sell\nitems, from video games to bars of gold. In these auctions, bidders incur a\ncost for placing each bid in addition to (or sometimes in lieu of) the winner's\nfinal purchase cost. Thus even when a winner's purchase cost is a small\nfraction of the item's intrinsic value, the auctioneer can still profit\nhandsomely from the bid fees. Our work provides novel analyses for these\nauctions, based on both modeling and datasets derived from auctions at\nSwoopo.com, the leading pay-per-bid auction site. While previous modeling work\npredicts profit-free equilibria, we analyze the impact of information asymmetry\nbroadly, as well as Swoopo features such as bidpacks and the Swoop It Now\noption specifically, to quantify the effects of imperfect information in these\nauctions. We find that even small asymmetries across players (cheaper bids,\nbetter estimates of other players' intent, different valuations of items,\ncommitted players willing to play \"chicken\") can increase the auction duration\nwell beyond that predicted by previous work and thus skew the auctioneer's\nprofit disproportionately. Finally, we discuss our findings in the context of a\ndataset of thousands of live auctions we observed on Swoopo, which enables us\nalso to examine behavioral factors, such as the power of aggressive bidding.\nUltimately, our findings show that even with fully rational players, if players\noverlook or are unaware any of these factors, the result is outsized profits\nfor pay-per-bid auctioneers.", 
    "link": "http://arxiv.org/pdf/1001.0592v3", 
    "arxiv-id": "1001.0592v3"
},{
    "category": "cs.GT", 
    "author": "Y. Narahari", 
    "title": "Multi-Armed Bandit Mechanisms for Multi-Slot Sponsored Search Auctions", 
    "publish": "2010-01-09T10:01:32Z", 
    "summary": "In pay-per click sponsored search auctions which are currently extensively\nused by search engines, the auction for a keyword involves a certain number of\nadvertisers (say k) competing for available slots (say m) to display their ads.\nThis auction is typically conducted for a number of rounds (say T). There are\nclick probabilities mu_ij associated with each agent-slot pairs. The goal of\nthe search engine is to maximize social welfare of the advertisers, that is,\nthe sum of values of the advertisers. The search engine does not know the true\nvalues advertisers have for a click to their respective ads and also does not\nknow the click probabilities mu_ij s. A key problem for the search engine\ntherefore is to learn these click probabilities during the T rounds of the\nauction and also to ensure that the auction mechanism is truthful. Mechanisms\nfor addressing such learning and incentives issues have recently been\nintroduced and are aptly referred to as multi-armed-bandit (MAB) mechanisms.\nWhen m = 1, characterizations for truthful MAB mechanisms are available in the\nliterature and it has been shown that the regret for such mechanisms will be\nO(T^{2/3}). In this paper, we seek to derive a characterization in the\nrealistic but non-trivial general case when m > 1 and obtain several\ninteresting results.", 
    "link": "http://arxiv.org/pdf/1001.1414v2", 
    "arxiv-id": "1001.1414v2"
},{
    "category": "cs.GT", 
    "author": "Angelina Vidali", 
    "title": "A complete characterization of group-strategyproof mechanisms of   cost-sharing", 
    "publish": "2010-01-12T15:23:43Z", 
    "summary": "We study the problem of designing group-strategyproof cost-sharing\nmechanisms. The players report their bids for getting serviced and the\nmechanism decides which players are going to be serviced and how much each one\nof them is going to pay. We determine three conditions: \\emph{Fence\nMonotonicity}, \\emph{Stability} of the allocation and \\emph{Validity} of the\ntie-breaking rule that are necessary and sufficient for\ngroup-strategyproofness, regardless of the cost function. Fence Monotonicity\nputs restrictions only on the payments of the mechanism and stability only on\nthe allocation. Consequently Fence Monotonicity characterizes\ngroup-strategyproof cost-sharing schemes. Finally, we use our results to prove\nthat there exist families of cost functions, where any group-strategyproof\nmechanism has unbounded approximation ratio.", 
    "link": "http://arxiv.org/pdf/1001.1901v1", 
    "arxiv-id": "1001.1901v1"
},{
    "category": "cs.GT", 
    "author": "Hamid Nazerzadeh", 
    "title": "An Optimal Dynamic Mechanism for Multi-Armed Bandit Processes", 
    "publish": "2010-01-26T06:32:42Z", 
    "summary": "We consider the problem of revenue-optimal dynamic mechanism design in\nsettings where agents' types evolve over time as a function of their (both\npublic and private) experience with items that are auctioned repeatedly over an\ninfinite horizon. A central question here is understanding what natural\nrestrictions on the environment permit the design of optimal mechanisms (note\nthat even in the simpler static setting, optimal mechanisms are characterized\nonly under certain restrictions). We provide a {\\em structural\ncharacterization} of a natural \"separable: multi-armed bandit environment\n(where the evolution and incentive structure of the a-priori type is decoupled\nfrom the subsequent experience in a precise sense) where dynamic optimal\nmechanism design is possible. Here, we present the Virtual Index Mechanism, an\noptimal dynamic mechanism, which maximizes the (long term) {\\em virtual\nsurplus} using the classical Gittins algorithm. The mechanism optimally\nbalances exploration and exploitation, taking incentives into account.", 
    "link": "http://arxiv.org/pdf/1001.4598v2", 
    "arxiv-id": "1001.4598v2"
},{
    "category": "cs.GT", 
    "author": "Edith Elkind", 
    "title": "Equilibria of Plurality Voting with Abstentions", 
    "publish": "2010-01-27T13:31:06Z", 
    "summary": "In the traditional voting manipulation literature, it is assumed that a group\nof manipulators jointly misrepresent their preferences to get a certain\ncandidate elected, while the remaining voters are truthful. In this paper, we\ndepart from this assumption, and consider the setting where all voters are\nstrategic. In this case, the election can be viewed as a game, and the election\noutcomes correspond to Nash equilibria of this game. We use this framework to\nanalyze two variants of Plurality voting, namely, simultaneous voting, where\nall voters submit their ballots at the same time, and sequential voting, where\nthe voters express their preferences one by one. For simultaneous voting, we\ncharacterize the preference profiles that admit a pure Nash equilibrium, but\nshow that it is computationally hard to check if a given profile fits our\ncriterion. For sequential voting, we provide a complete analysis of the setting\nwith two candidates, and show that for three or more candidates the equilibria\nof sequential voting may behave in a counterintuitive manner.", 
    "link": "http://arxiv.org/pdf/1001.4939v1", 
    "arxiv-id": "1001.4939v1"
},{
    "category": "cs.GT", 
    "author": "Pablo A. Parrilo", 
    "title": "Structure of Extreme Correlated Equilibria: a Zero-Sum Example and its   Implications", 
    "publish": "2010-01-30T00:32:18Z", 
    "summary": "We exhibit the rich structure of the set of correlated equilibria by\nanalyzing the simplest of polynomial games: the mixed extension of matching\npennies. We show that while the correlated equilibrium set is convex and\ncompact, the structure of its extreme points can be quite complicated. In\nfinite games the ratio of extreme correlated to extreme Nash equilibria can be\ngreater than exponential in the size of the strategy spaces. In polynomial\ngames there can exist extreme correlated equilibria which are not finitely\nsupported; we construct a large family of examples using techniques from\nergodic theory. We show that in general the set of correlated equilibrium\ndistributions of a polynomial game cannot be described by conditions on\nfinitely many moments (means, covariances, etc.), in marked contrast to the set\nof Nash equilibria which is always expressible in terms of finitely many\nmoments.", 
    "link": "http://arxiv.org/pdf/1002.0035v2", 
    "arxiv-id": "1002.0035v2"
},{
    "category": "cs.GT", 
    "author": "Jean-Fran\u00e7ois Raskin", 
    "title": "Iterated Regret Minimization in Game Graphs", 
    "publish": "2010-02-07T14:34:58Z", 
    "summary": "Iterated regret minimization has been introduced recently by J.Y. Halpern and\nR. Pass in classical strategic games. For many games of interest, this new\nsolution concept provides solutions that are judged more reasonable than\nsolutions offered by traditional game concepts -- such as Nash equilibrium --.\nAlthough computing iterated regret on explicit matrix game is conceptually and\ncomputationally easy, nothing is known about computing the iterated regret on\ngames whose matrices are defined implicitly using game tree, game DAG or, more\ngenerally game graphs. In this paper, we investigate iterated regret\nminimization for infinite duration two-player quantitative non-zero sum games\nplayed on graphs.\n  We consider reachability objectives that are not necessarily antagonist.\nEdges are weighted by integers -- one for each player --, and the payoffs are\ndefined by the sum of the weights along the paths. Depending on the class of\ngraphs, we give either polynomial or pseudo-polynomial time algorithms to\ncompute a strategy that minimizes the regret for a fixed player. We finally\ngive algorithms to compute the strategies of the two players that minimize the\niterated regret for trees, and for graphs with strictly positive weights only.", 
    "link": "http://arxiv.org/pdf/1002.1456v3", 
    "arxiv-id": "1002.1456v3"
},{
    "category": "cs.GT", 
    "author": "Brahim Chaib-draa", 
    "title": "An Approximate Subgame-Perfect Equilibrium Computation Technique for   Repeated Games", 
    "publish": "2010-02-08T21:16:51Z", 
    "summary": "This paper presents a technique for approximating, up to any precision, the\nset of subgame-perfect equilibria (SPE) in discounted repeated games. The\nprocess starts with a single hypercube approximation of the set of SPE. Then\nthe initial hypercube is gradually partitioned on to a set of smaller adjacent\nhypercubes, while those hypercubes that cannot contain any point belonging to\nthe set of SPE are simultaneously withdrawn.\n  Whether a given hypercube can contain an equilibrium point is verified by an\nappropriate mathematical program. Three different formulations of the algorithm\nfor both approximately computing the set of SPE payoffs and extracting players'\nstrategies are then proposed: the first two that do not assume the presence of\nan external coordination between players, and the third one that assumes a\ncertain level of coordination during game play for convexifying the set of\ncontinuation payoffs after any repeated game history.\n  A special attention is paid to the question of extracting players' strategies\nand their representability in form of finite automata, an important feature for\nartificial agent systems.", 
    "link": "http://arxiv.org/pdf/1002.1718v1", 
    "arxiv-id": "1002.1718v1"
},{
    "category": "cs.GT", 
    "author": "Yaron Singer", 
    "title": "Budget Feasible Mechanisms", 
    "publish": "2010-02-11T13:27:41Z", 
    "summary": "We study a novel class of mechanism design problems in which the outcomes are\nconstrained by the payments. This basic class of mechanism design problems\ncaptures many common economic situations, and yet it has not been studied, to\nour knowledge, in the past. We focus on the case of procurement auctions in\nwhich sellers have private costs, and the auctioneer aims to maximize a utility\nfunction on subsets of items, under the constraint that the sum of the payments\nprovided by the mechanism does not exceed a given budget. Standard mechanism\ndesign ideas such as the VCG mechanism and its variants are not applicable\nhere. We show that, for general functions, the budget constraint can render\nmechanisms arbitrarily bad in terms of the utility of the buyer. However, our\nmain result shows that for the important class of submodular functions, a\nbounded approximation ratio is achievable. Better approximation results are\nobtained for subclasses of the submodular functions. We explore the space of\nbudget feasible mechanisms in other domains and give a characterization under\nmore restricted conditions.", 
    "link": "http://arxiv.org/pdf/1002.2334v2", 
    "arxiv-id": "1002.2334v2"
},{
    "category": "cs.GT", 
    "author": "Qiqi Yan", 
    "title": "Robust Mechanisms for Risk-Averse Sellers", 
    "publish": "2010-02-12T06:31:35Z", 
    "summary": "The existing literature on optimal auctions focuses on optimizing the\nexpected revenue of the seller, and is appropriate for risk-neutral sellers. In\nthis paper, we identify good mechanisms for risk-averse sellers. As is standard\nin the economics literature, we model the risk-aversion of a seller by endowing\nthe seller with a monotone concave utility function. We then seek robust\nmechanisms that are approximately optimal for all sellers, no matter what their\nlevels of risk-aversion are. We have two main results for multi-unit auctions\nwith unit-demand bidders whose valuations are drawn i.i.d. from a regular\ndistribution. First, we identify a posted-price mechanism called the Hedge\nmechanism, which gives a universal constant factor approximation; we also show\nfor the unlimited supply case that this mechanism is in a sense the best\npossible. Second, we show that the VCG mechanism gives a universal constant\nfactor approximation when the number of bidders is even only a small multiple\nof the number of items. Along the way we point out that Myerson's\ncharacterization of the optimal mechanisms fails to extend to\nutility-maximization for risk-averse sellers, and establish interesting\nproperties of regular distributions and monotone hazard rate distributions.", 
    "link": "http://arxiv.org/pdf/1002.2477v2", 
    "arxiv-id": "1002.2477v2"
},{
    "category": "cs.GT", 
    "author": "Antonin Kucera", 
    "title": "Reachability Games on Extended Vector Addition Systems with States", 
    "publish": "2010-02-12T14:08:20Z", 
    "summary": "We consider two-player turn-based games with zero-reachability and\nzero-safety objectives generated by extended vector addition systems with\nstates. Although the problem of deciding the winner in such games is\nundecidable in general, we identify several decidable and even tractable\nsubcases of this problem obtained by restricting the number of counters and/or\nthe sets of target configurations.", 
    "link": "http://arxiv.org/pdf/1002.2557v1", 
    "arxiv-id": "1002.2557v1"
},{
    "category": "cs.GT", 
    "author": "Balasubramanian Sivan", 
    "title": "The power of randomness in Bayesian optimal mechanism design", 
    "publish": "2010-02-20T14:16:59Z", 
    "summary": "We investigate the power of randomness in the context of a fundamental\nBayesian optimal mechanism design problem--a single seller aims to maximize\nexpected revenue by allocating multiple kinds of resources to \"unit-demand\"\nagents with preferences drawn from a known distribution. When the agents'\npreferences are single-dimensional Myerson's seminal work [Myerson '81] shows\nthat randomness offers no benefit--the optimal mechanism is always\ndeterministic. In the multi-dimensional case, where each agent's preferences\nare given by different values for each of the available services, Briest et al.\n[Briest, Chawla, Kleinberg, and Weinberg '10] recently showed that the gap\nbetween the expected revenue obtained by an optimal randomized mechanism and an\noptimal deterministic mechanism can be unbounded even when a single agent is\noffered only 4 services. However, this large gap is attained through unnatural\ninstances where values of the agent for different services are correlated in a\nspecific way. We show that when the agent's values involve no correlation or a\nspecific kind of positive correlation, the benefit of randomness is only a\nsmall constant factor (4 and 8 respectively). Our model of positively\ncorrelated values (that we call additive values) is a natural model for\nunit-demand agents and items that are substitutes. Our results extend to\nmultiple agent settings as well.", 
    "link": "http://arxiv.org/pdf/1002.3893v2", 
    "arxiv-id": "1002.3893v2"
},{
    "category": "cs.GT", 
    "author": "Haoyang Wu", 
    "title": "Signaling games with pattern recognition", 
    "publish": "2010-02-23T11:09:16Z", 
    "summary": "The classical model of signaling games assumes that the receiver exactly know\nthe type space (private information) of the sender and be able to discriminate\neach type of the sender distinctly. However, the justification of this\nassumption is questionable. It is more reasonable to let the receiver recognize\nthe pattern of the sender. In this paper, we investigate what happens if the\nassumption is relaxed. A framework of signaling games with pattern recognition\nand an example are given.", 
    "link": "http://arxiv.org/pdf/1002.4298v1", 
    "arxiv-id": "1002.4298v1"
},{
    "category": "cs.GT", 
    "author": "Milind Sohoni", 
    "title": "Nash equilibria in Fisher market", 
    "publish": "2010-02-25T17:16:39Z", 
    "summary": "Much work has been done on the computation of market equilibria. However due\nto strategic play by buyers, it is not clear whether these are actually\nobserved in the market. Motivated by the observation that a buyer may derive a\nbetter payoff by feigning a different utility function and thereby manipulating\nthe Fisher market equilibrium, we formulate the {\\em Fisher market game} in\nwhich buyers strategize by posing different utility functions. We show that\nexistence of a {\\em conflict-free allocation} is a necessary condition for the\nNash equilibria (NE) and also sufficient for the symmetric NE in this game.\nThere are many NE with very different payoffs, and the Fisher equilibrium\npayoff is captured at a symmetric NE. We provide a complete polyhedral\ncharacterization of all the NE for the two-buyer market game. Surprisingly, all\nthe NE of this game turn out to be symmetric and the corresponding payoffs\nconstitute a piecewise linear concave curve. We also study the correlated\nequilibria of this game and show that third-party mediation does not help to\nachieve a better payoff than NE payoffs.", 
    "link": "http://arxiv.org/pdf/1002.4832v3", 
    "arxiv-id": "1002.4832v3"
},{
    "category": "cs.GT", 
    "author": "Jan Obdr\u017e\u00e1lek", 
    "title": "Qualitative Reachability in Stochastic BPA Games", 
    "publish": "2010-02-27T17:42:19Z", 
    "summary": "We consider a class of infinite-state stochastic games generated by stateless\npushdown automata (or, equivalently, 1-exit recursive state machines), where\nthe winning objective is specified by a regular set of target configurations\nand a qualitative probability constraint `>0' or `=1'. The goal of one player\nis to maximize the probability of reaching the target set so that the\nconstraint is satisfied, while the other player aims at the opposite. We show\nthat the winner in such games can be determined in PTIME for the `>0'\nconstraint, and both in NP and coNP for the `=1' constraint. Further, we prove\nthat the winning regions for both players are regular, and we design algorithms\nwhich compute the associated finite-state automata. Finally, we show that\nwinning strategies can be synthesized effectively.", 
    "link": "http://arxiv.org/pdf/1003.0118v1", 
    "arxiv-id": "1003.0118v1"
},{
    "category": "cs.GT", 
    "author": "Carla Selmi", 
    "title": "Strategical languages of infinite words", 
    "publish": "2010-03-02T19:47:21Z", 
    "summary": "We deal in this paper with strategical languages of infinite words, that is\nthose generated by a nondeterministic strategy in the sense of game theory. We\nfirst show the existence of a minimal strategy for such languages, for which we\ngive an explicit expression. Then we characterize the family of strategical\nlanguages as that of closed ones, in the topological space of infinite words.\nFinally, we give a definition of a Nash equilibrium for such languages, that we\nillustrate with a famous example.", 
    "link": "http://arxiv.org/pdf/1003.0662v1", 
    "arxiv-id": "1003.0662v1"
},{
    "category": "cs.GT", 
    "author": "Arunava Sen", 
    "title": "Roberts' Theorem with Neutrality: A Social Welfare Ordering Approach", 
    "publish": "2010-03-08T04:39:45Z", 
    "summary": "We consider dominant strategy implementation in private values settings, when\nagents have multi-dimensional types, the set of alternatives is finite,\nmonetary transfers are allowed, and agents have quasi-linear utilities. We show\nthat any implementable and neutral social choice function must be a weighted\nwelfare maximizer if the type space of every agent is an $m$-dimensional open\ninterval, where $m$ is the number of alternatives. When the type space of every\nagent is unrestricted, Roberts' theorem with neutrality \\cite{Roberts79}\nbecomes a corollary to our result. Our proof technique uses a {\\em social\nwelfare ordering} approach, commonly used in aggregation literature in social\nchoice theory. We also prove the general (affine maximizer) version of Roberts'\ntheorem for unrestricted type spaces of agents using this approach.", 
    "link": "http://arxiv.org/pdf/1003.1550v1", 
    "arxiv-id": "1003.1550v1"
},{
    "category": "cs.GT", 
    "author": "Mohammad Reza Pakravan", 
    "title": "A New Framework for Cognitive Medium Access Control: POSG Approach", 
    "publish": "2010-03-14T20:43:51Z", 
    "summary": "In this paper, we propose a new analytical framework to solve medium access\nproblem for secondary users (SUs) in cognitive radio networks. Partially\nObservable Stochastic Games (POSG) and Decentralized Markov Decision Process\n(Dec-POMDP) are two multi-agent Markovian decision processes which are used to\npresent a solution. A primary network with two SUs is considered as an example\nto demonstrate our proposed framework. Two different scenarios are assumed. In\nthe first scenario, SUs compete to acquire the licensed channel which is\nmodeled using POSG framework. In the second one, SUs cooperate to access\nchannel for which the solution is based on Dec-POMDP. Besides, the dominant\nstrategy for both of the above mentioned scenarios is presented for a three\nslot horizon length.", 
    "link": "http://arxiv.org/pdf/1003.2813v2", 
    "arxiv-id": "1003.2813v2"
},{
    "category": "cs.GT", 
    "author": "John Fearnley", 
    "title": "Non-oblivious Strategy Improvement", 
    "publish": "2010-03-15T17:33:45Z", 
    "summary": "We study strategy improvement algorithms for mean-payoff and parity games. We\ndescribe a structural property of these games, and we show that these\nstructures can affect the behaviour of strategy improvement. We show how\nawareness of these structures can be used to accelerate strategy improvement\nalgorithms. We call our algorithms non-oblivious because they remember\nproperties of the game that they have discovered in previous iterations. We\nshow that non-oblivious strategy improvement algorithms perform well on\nexamples that are known to be hard for oblivious strategy improvement. Hence,\nwe argue that previous strategy improvement algorithms fail because they ignore\nthe structural properties of the game that they are solving.", 
    "link": "http://arxiv.org/pdf/1003.2976v1", 
    "arxiv-id": "1003.2976v1"
},{
    "category": "cs.GT", 
    "author": "Burkhard C. Schipper", 
    "title": "Pure Saddle Points and Symmetric Relative Payoff Games", 
    "publish": "2010-03-22T20:44:50Z", 
    "summary": "It is well known that the rock-paper-scissors game has no pure saddle point.\nWe show that this holds more generally: A symmetric two-player zero-sum game\nhas a pure saddle point if and only if it is not a generalized\nrock-paper-scissors game. Moreover, we show that every finite symmetric\nquasiconcave two-player zero-sum game has a pure saddle point. Further\nsufficient conditions for existence are provided. We apply our theory to a rich\ncollection of examples by noting that the class of symmetric two-player\nzero-sum games coincides with the class of relative payoff games associated\nwith symmetric two-player games. This allows us to derive results on the\nexistence of a finite population evolutionary stable strategies.", 
    "link": "http://arxiv.org/pdf/1003.4277v1", 
    "arxiv-id": "1003.4277v1"
},{
    "category": "cs.GT", 
    "author": "Costas Busch", 
    "title": "Bottleneck Routing Games with Low Price of Anarchy", 
    "publish": "2010-03-22T23:31:55Z", 
    "summary": "We study {\\em bottleneck routing games} where the social cost is determined\nby the worst congestion on any edge in the network. In the literature,\nbottleneck games assume player utility costs determined by the worst congested\nedge in their paths. However, the Nash equilibria of such games are inefficient\nsince the price of anarchy can be very high and proportional to the size of the\nnetwork. In order to obtain smaller price of anarchy we introduce {\\em\nexponential bottleneck games} where the utility costs of the players are\nexponential functions of their congestions. We find that exponential bottleneck\ngames are very efficient and give a poly-log bound on the price of anarchy:\n$O(\\log L \\cdot \\log |E|)$, where $L$ is the largest path length in the\nplayers' strategy sets and $E$ is the set of edges in the graph. By adjusting\nthe exponential utility costs with a logarithm we obtain games whose player\ncosts are almost identical to those in regular bottleneck games, and at the\nsame time have the good price of anarchy of exponential games.", 
    "link": "http://arxiv.org/pdf/1003.4307v1", 
    "arxiv-id": "1003.4307v1"
},{
    "category": "cs.GT", 
    "author": "Svetlana Olonetsky", 
    "title": "Truth and Envy in Capacitated Allocation Games", 
    "publish": "2010-03-27T22:07:05Z", 
    "summary": "We study auctions with additive valuations where agents have a limit on the\nnumber of goods they may receive. We refer to such valuations as {\\em\ncapacitated} and seek mechanisms that maximize social welfare and are\nsimultaneously incentive compatible, envy-free, individually rational, and have\nno positive transfers. If capacities are infinite, then sequentially repeating\nthe 2nd price Vickrey auction meets these requirements. In 1983, Leonard showed\nthat for unit capacities, VCG with Clarke Pivot payments is also envy free. For\ncapacities that are all unit or all infinite, the mechanism produces a\nWalrasian pricing (subject to capacity constraints). Here, we consider general\ncapacities. For homogeneous capacities (all capacities equal) we show that VCG\nwith Clarke Pivot payments is envy free (VCG with Clarke Pivot payments is\nalways incentive compatible, individually rational, and has no positive\ntransfers). Contrariwise, there is no incentive compatible Walrasian pricing.\nFor heterogeneous capacities, we show that there is no mechanism with all 4\nproperties, but at least in some cases, one can achieve both incentive\ncompatibility and envy freeness.", 
    "link": "http://arxiv.org/pdf/1003.5326v2", 
    "arxiv-id": "1003.5326v2"
},{
    "category": "cs.GT", 
    "author": "Svetlana Olonetsky", 
    "title": "On the Interplay between Incentive Compatibility and Envy Freeness", 
    "publish": "2010-03-27T22:18:28Z", 
    "summary": "We study mechanisms for an allocation of goods among agents, where agents\nhave no incentive to lie about their true values (incentive compatible) and for\nwhich no agent will seek to exchange outcomes with another (envy-free).\nMechanisms satisfying each requirement separately have been studied\nextensively, but there are few results on mechanisms achieving both. We are\ninterested in those allocations for which there exist payments such that the\nresulting mechanism is simultaneously incentive compatible and envy-free.\nCyclic monotonicity is a characterization of incentive compatible allocations,\nlocal efficiency is a characterization for envy-free allocations. We combine\nthe above to give a characterization for allocations which are both incentive\ncompatible and envy free. We show that even for allocations that allow payments\nleading to incentive compatible mechanisms, and other payments leading to envy\nfree mechanisms, there may not exist any payments for which the mechanism is\nsimultaneously incentive compatible and envy-free. The characterization that we\ngive lets us compute the set of Pareto-optimal mechanisms that trade off envy\nfreeness for incentive compatibility.", 
    "link": "http://arxiv.org/pdf/1003.5328v1", 
    "arxiv-id": "1003.5328v1"
},{
    "category": "cs.GT", 
    "author": "Omer Tamuz", 
    "title": "Truthful Fair Division", 
    "publish": "2010-03-29T09:45:02Z", 
    "summary": "We address the problem of fair division, or cake cutting, with the goal of\nfinding truthful mechanisms. In the case of a general measure space (\"cake\")\nand non-atomic, additive individual preference measures - or utilities - we\nshow that there exists a truthful \"mechanism\" which ensures that each of the k\nplayers gets at least 1/k of the cake. This mechanism also minimizes risk for\ntruthful players. Furthermore, in the case where there exist at least two\ndifferent measures we present a different truthful mechanism which ensures that\neach of the players gets more than 1/k of the cake.\n  We then turn our attention to partitions of indivisible goods with bounded\nutilities and a large number of goods. Here we provide similar mechanisms, but\nwith slightly weaker guarantees. These guarantees converge to those obtained in\nthe non-atomic case as the number of goods goes to infinity.", 
    "link": "http://arxiv.org/pdf/1003.5480v2", 
    "arxiv-id": "1003.5480v2"
},{
    "category": "cs.GT", 
    "author": "Kaushik Kumar Majumdar", 
    "title": "Indian policeman's dilemma: A game theoretic model", 
    "publish": "2010-04-06T19:12:10Z", 
    "summary": "This paper focuses on a one person game called Indian policeman's dilemma\n(IPD). It represents the internal conflict between emotion and profession of a\ntypical Indian police officer. We have 'split' the game to be played\nindependently by different personality modules of the same player. Each module\nthen appears as an independent individual player of the game. None of the\nplayers knows the exact payoff values of any of the others. Only greater than\nor less than type of inequalities among the payoff values across the players\nare to be inferred probabilistically. There are two Nash equilibrium (NE)\npoints in this game signifying two completely opposing behavior by the\npoliceman involved. With the help of the probabilistic inequalities probable\npropensities of the different behaviors have been determined. The model\nunderscores the need for new surveys and data generation. A design of one such\nsurvey to measure professionalism of the police personnel has been outlined.", 
    "link": "http://arxiv.org/pdf/1004.0933v2", 
    "arxiv-id": "1004.0933v2"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Multi-Unit Auctions: Beyond Roberts", 
    "publish": "2010-04-09T02:22:26Z", 
    "summary": "We exhibit incentive compatible multi-unit auctions that are not affine\nmaximizers (i.e., are not of the VCG family) and yet approximate the social\nwelfare to within a factor of $1+\\epsilon$. For the case of two-item two-bidder\nauctions we show that these auctions, termed Triage auctions, are the only\nscalable ones that give an approximation factor better than 2. \"Scalable\" means\nthat the allocation does not depend on the units in which the valuations are\nmeasured. We deduce from this that any scalable computationally-efficient\nincentive-compatible auction for $m$ items and $n \\ge 2$ bidders cannot\napproximate the social welfare to within a factor better than 2. This is in\ncontrast to arbitrarily good approximations that can be reached under\ncomputational constraints alone, and in contrast to the fact that the optimal\nsocial welfare can be obtained under incentive constraints alone.", 
    "link": "http://arxiv.org/pdf/1004.1449v2", 
    "arxiv-id": "1004.1449v2"
},{
    "category": "cs.GT", 
    "author": "Jinsong Tan", 
    "title": "The Networked Common Goods Game", 
    "publish": "2010-04-09T15:37:38Z", 
    "summary": "We introduce a new class of games called the networked common goods game\n(NCGG), which generalizes the well-known common goods game. We focus on a\nfairly general subclass of the game where each agent's utility functions are\nthe same across all goods the agent is entitled to and satisfy certain natural\nproperties (diminishing return and smoothness). We give a comprehensive set of\ntechnical results listed as follows.\n  * We show the optimization problem faced by a single agent can be solved\nefficiently in this subclass. The discrete version of the problem is however\nNP-hard but admits an fully polynomial time approximation scheme (FPTAS).\n  * We show uniqueness results of pure strategy Nash equilibrium of NCGG, and\nthat the equilibrium is fully characterized by the structure of the network and\nindependent of the choices and combinations of agent utility functions.\n  * We show NCGG is a potential game, and give an implementation of best/better\nresponse Nash dynamics that lead to fast convergence to an\n$\\epsilon$-approximate pure strategy Nash equilibrium.\n  * Lastly, we show the price of anarchy of NCGG can be as large as\n$\\Omega(n^{1-\\epsilon})$ (for any $\\epsilon>0$), which means selfish behavior\nin NCGG can lead to extremely inefficient social outcomes.", 
    "link": "http://arxiv.org/pdf/1004.1578v1", 
    "arxiv-id": "1004.1578v1"
},{
    "category": "cs.GT", 
    "author": "Hamid Mahini", 
    "title": "The cooperative game theory foundations of network bargaining games", 
    "publish": "2010-04-25T01:50:25Z", 
    "summary": "We study bargaining games between suppliers and manufacturers in a network\ncontext. Agents wish to enter into contracts in order to generate surplus which\nthen must be divided among the participants. Potential contracts and their\nsurplus are represented by weighted edges in our bipartite network. Each agent\nin the market is additionally limited by a capacity representing the number of\ncontracts which he or she may undertake. When all agents are limited to just\none contract each, prior research applied natural generalizations of the Nash\nbargaining solution to the networked setting, defined the new solution concepts\nof stable and balanced, and characterized the resulting bargaining outcomes. We\nsimplify and generalize these results to a setting in which participants in\nonly one side of the market are limited to one contract each. The heart of our\nresults uses a linear-programming formulation to establish a novel connection\nbetween well-studied cooperative game theory concepts (such as core and\nprekernel) and the solution concepts of stable and balanced defined for the\nbargaining games. This immediately implies one can take advantage of the\nresults and algorithms in cooperative game theory to reproduce results such as\nthose of Azar et al. [1] and Kleinberg and Tardos [29] and also generalize them\nto our setting. The cooperative-game-theoretic connection also inspires us to\nrefine our solution space using standard solution concepts from that literature\nsuch as nucleolus and lexicographic kernel. The nucleolus is particularly\nattractive as it is unique, always exists, and is supported by experimental\ndata in the network bargaining literature. Guided by algorithms from\ncooperative game theory, we show how to compute the nucleolus by pruning and\niteratively solving a natural linear-programming formulation.", 
    "link": "http://arxiv.org/pdf/1004.4317v1", 
    "arxiv-id": "1004.4317v1"
},{
    "category": "cs.GT", 
    "author": "Krzysztof R. Apt", 
    "title": "Direct Proofs of Order Independence", 
    "publish": "2010-04-27T07:17:50Z", 
    "summary": "We establish a generic result concerning order independence of a dominance\nrelation on finite games. It allows us to draw conclusions about order\nindependence of various dominance relations in a direct and simple way.", 
    "link": "http://arxiv.org/pdf/1004.4727v2", 
    "arxiv-id": "1004.4727v2"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Structural Solutions For Additively Coupled Sum Constrained Games", 
    "publish": "2010-05-06T03:03:22Z", 
    "summary": "We propose and analyze a broad family of games played by resource-constrained\nplayers, which are characterized by the following central features: 1) each\nuser has a multi-dimensional action space, subject to a single sum resource\nconstraint; 2) each user's utility in a particular dimension depends on an\nadditive coupling between the user's action in the same dimension and the\nactions of the other users; and 3) each user's total utility is the sum of the\nutilities obtained in each dimension. Familiar examples of such multi-user\nenvironments in communication systems include power control over\nfrequency-selective Gaussian interference channels and flow control in Jackson\nnetworks. In settings where users cannot exchange messages in real-time, we\nstudy how users can adjust their actions based on their local observations. We\nderive sufficient conditions under which a unique Nash equilibrium exists and\nthe best-response algorithm converges globally and linearly to the Nash\nequilibrium. In settings where users can exchange messages in real-time, we\nfocus on user choices that optimize the overall utility. We provide the\nconvergence conditions of two distributed action update mechanisms, gradient\nplay and Jacobi update.", 
    "link": "http://arxiv.org/pdf/1005.0880v1", 
    "arxiv-id": "1005.0880v1"
},{
    "category": "cs.GT", 
    "author": "Bruce Hajek", 
    "title": "Revenue Optimal Auction for Single-Minded Buyers", 
    "publish": "2010-05-06T19:14:59Z", 
    "summary": "We study the problem of characterizing revenue optimal auctions for\nsingle-minded buyers. Each buyer is interested only in a specific bundle of\nitems and has a value for the same. Both his bundle and its value are his\nprivate information. The bundles that buyers are interested in and their\ncorresponding values are assumed to be realized from known probability\ndistributions independent across the buyers. We identify revenue optimal\nauctions with a simple structure, if the conditional distribution of any\nbuyer's valuation is nondecreasing, in the hazard rates ordering of probability\ndistributions, as a function of the bundle the buyer is interested in. The\nrevenue optimal auction is given by the solution of a maximum weight\nindependent set problem. We provide a novel graphical construction of the\nweights and highlight important properties of the resulting auction.", 
    "link": "http://arxiv.org/pdf/1005.1059v2", 
    "arxiv-id": "1005.1059v2"
},{
    "category": "cs.GT", 
    "author": "Bruce Hajek", 
    "title": "Efficiency Loss in Revenue Optimal Auctions", 
    "publish": "2010-05-07T02:30:27Z", 
    "summary": "We study efficiency loss in Bayesian revenue optimal auctions. We quantify\nthis as the worst case ratio of loss in the realized social welfare to the\nsocial welfare that can be realized by an efficient auction. Our focus is on\nauctions with single-parameter buyers and where buyers' valuation sets are\nfinite. For binary valued single-parameter buyers with independent (not\nnecessarily identically distributed) private valuations, we show that the worst\ncase efficiency loss ratio (ELR) is no worse than it is with only one buyer;\nmoreover, it is at most 1/2. Moving beyond the case of binary valuations but\nrestricting to single item auctions, where buyers' private valuations are\nindependent and identically distributed, we obtain bounds on the worst case ELR\nas a function of number of buyers, cardinality of buyers' valuation set, and\nratio of maximum to minimum possible values that buyers can have for the item.", 
    "link": "http://arxiv.org/pdf/1005.1121v2", 
    "arxiv-id": "1005.1121v2"
},{
    "category": "cs.GT", 
    "author": "Marc Harper", 
    "title": "A Population-centric Approach to the Beauty Contest Game", 
    "publish": "2010-05-07T23:33:32Z", 
    "summary": "An population-centric analysis for a version of the p-beauty contest game is\ngiven for the two-player, finite population, and infinite population cases.\nWinning strategies are characterized in terms of iterative thinking relative to\nthe population. To win the game one needs to iterate more times than the\nambient population, but not too many more times depending on the population\nsize and the value of p.", 
    "link": "http://arxiv.org/pdf/1005.1311v2", 
    "arxiv-id": "1005.1311v2"
},{
    "category": "cs.GT", 
    "author": "Zhiyi Huang", 
    "title": "Bayesian Incentive Compatibility via Fractional Assignments", 
    "publish": "2010-05-24T02:17:38Z", 
    "summary": "Very recently, Hartline and Lucier studied single-parameter mechanism design\nproblems in the Bayesian setting. They proposed a black-box reduction that\nconverted Bayesian approximation algorithms into Bayesian-Incentive-Compatible\n(BIC) mechanisms while preserving social welfare. It remains a major open\nquestion if one can find similar reduction in the more important\nmulti-parameter setting. In this paper, we give positive answer to this\nquestion when the prior distribution has finite and small support. We propose a\nblack-box reduction for designing BIC multi-parameter mechanisms. The reduction\nconverts any algorithm into an eps-BIC mechanism with only marginal loss in\nsocial welfare. As a result, for combinatorial auctions with sub-additive\nagents we get an eps-BIC mechanism that achieves constant approximation.", 
    "link": "http://arxiv.org/pdf/1005.4244v4", 
    "arxiv-id": "1005.4244v4"
},{
    "category": "cs.GT", 
    "author": "Hans Georg Seedig", 
    "title": "Optimal Partitions in Additively Separable Hedonic Games", 
    "publish": "2010-05-25T11:38:41Z", 
    "summary": "We conduct a computational analysis of fair and optimal partitions in\nadditively separable hedonic games. We show that, for strict preferences, a\nPareto optimal partition can be found in polynomial time while verifying\nwhether a given partition is Pareto optimal is coNP-complete, even when\npreferences are symmetric and strict. Moreover, computing a partition with\nmaximum egalitarian or utilitarian social welfare or one which is both Pareto\noptimal and individually rational is NP-hard. We also prove that checking\nwhether there exists a partition which is both Pareto optimal and envy-free is\n$\\Sigma_{2}^{p}$-complete. Even though an envy-free partition and a Nash stable\npartition are both guaranteed to exist for symmetric preferences, checking\nwhether there exists a partition which is both envy-free and Nash stable is\nNP-complete.", 
    "link": "http://arxiv.org/pdf/1005.4540v3", 
    "arxiv-id": "1005.4540v3"
},{
    "category": "cs.GT", 
    "author": "Uri Zwick", 
    "title": "Strategy iteration is strongly polynomial for 2-player turn-based   stochastic games with a constant discount factor", 
    "publish": "2010-08-03T12:11:27Z", 
    "summary": "Ye showed recently that the simplex method with Dantzig pivoting rule, as\nwell as Howard's policy iteration algorithm, solve discounted Markov decision\nprocesses (MDPs), with a constant discount factor, in strongly polynomial time.\nMore precisely, Ye showed that both algorithms terminate after at most\n$O(\\frac{mn}{1-\\gamma}\\log(\\frac{n}{1-\\gamma}))$ iterations, where $n$ is the\nnumber of states, $m$ is the total number of actions in the MDP, and\n$0<\\gamma<1$ is the discount factor. We improve Ye's analysis in two respects.\nFirst, we improve the bound given by Ye and show that Howard's policy iteration\nalgorithm actually terminates after at most\n$O(\\frac{m}{1-\\gamma}\\log(\\frac{n}{1-\\gamma}))$ iterations. Second, and more\nimportantly, we show that the same bound applies to the number of iterations\nperformed by the strategy iteration (or strategy improvement) algorithm, a\ngeneralization of Howard's policy iteration algorithm used for solving 2-player\nturn-based stochastic games with discounted zero-sum rewards. This provides the\nfirst strongly polynomial algorithm for solving these games, resolving a long\nstanding open problem.", 
    "link": "http://arxiv.org/pdf/1008.0530v1", 
    "arxiv-id": "1008.0530v1"
},{
    "category": "cs.GT", 
    "author": "Zeeshan Ahmed", 
    "title": "Statistical Trading Using Target Oriented Trading Agent", 
    "publish": "2010-08-07T11:29:41Z", 
    "summary": "In this article we briefly present our contributions toward Trading Agent\nCompetition (TAC); an international forum for promotion of research into the\ntrading agent problems. Moreover, we present some strategies proposed and used\nin the development of our TAC Agent and resultant brief information after its\nparticipation in a real time trading environment. In the end we conclude with\nneeded improvements and future recommendations.", 
    "link": "http://arxiv.org/pdf/1008.1324v1", 
    "arxiv-id": "1008.1324v1"
},{
    "category": "cs.GT", 
    "author": "Qiqi Yan", 
    "title": "Mechanism Design via Correlation Gap", 
    "publish": "2010-08-11T07:20:53Z", 
    "summary": "For revenue and welfare maximization in single-dimensional Bayesian settings,\nChawla et al. (STOC10) recently showed that sequential posted-price mechanisms\n(SPMs), though simple in form, can perform surprisingly well compared to the\noptimal mechanisms. In this paper, we give a theoretical explanation of this\nfact, based on a connection to the notion of correlation gap.\n  Loosely speaking, for auction environments with matroid constraints, we can\nrelate the performance of a mechanism to the expectation of a monotone\nsubmodular function over a random set. This random set corresponds to the\nwinner set for the optimal mechanism, which is highly correlated, and\ncorresponds to certain demand set for SPMs, which is independent. The notion of\ncorrelation gap of Agrawal et al.\\ (SODA10) quantifies how much we {}\"lose\" in\nthe expectation of the function by ignoring correlation in the random set, and\nhence bounds our loss in using certain SPM instead of the optimal mechanism.\nFurthermore, the correlation gap of a monotone and submodular function is known\nto be small, and it follows that certain SPM can approximate the optimal\nmechanism by a good constant factor.\n  Exploiting this connection, we give tight analysis of a greedy-based SPM of\nChawla et al.\\ for several environments. In particular, we show that it gives\nan $e/(e-1)$-approximation for matroid environments, gives asymptotically a\n$1/(1-1/\\sqrt{2\\pi k})$-approximation for the important sub-case of $k$-unit\nauctions, and gives a $(p+1)$-approximation for environments with\n$p$-independent set system constraints.", 
    "link": "http://arxiv.org/pdf/1008.1843v2", 
    "arxiv-id": "1008.1843v2"
},{
    "category": "cs.GT", 
    "author": "Vy Duong", 
    "title": "A Game Theoretical Approach to Modeling Full-Duplex Information   Dissemination", 
    "publish": "2010-08-12T18:28:21Z", 
    "summary": "One major function of social networks (e.g., massive online social networks)\nis the dissemination of information such as scientific knowledge, news, and\nrumors. Information can be propagated by the users of the network via natural\nconnections in written, oral or electronic form. The information passing from a\nsender to a receiver intrinsically involves both of them considering their\nself-perceived knowledge, reputation, and popularity, which further determine\ntheir decisions of whether or not to forward the information and whether or not\nto provide feedback. To understand such human aspects of the information\ndissemination, we propose a game theoretical model of the two-way full duplex\ninformation forwarding and feedback mechanisms in a social network that take\ninto account the personalities of the communicating actors (including their\nperceived knowledgeability, reputation, and desire for popularity) and the\nglobal characteristics of the network. The model demonstrates how the emergence\nof social networks can be explained in terms of maximizing game theoretical\nutility.", 
    "link": "http://arxiv.org/pdf/1008.2181v1", 
    "arxiv-id": "1008.2181v1"
},{
    "category": "cs.GT", 
    "author": "Haoyang Wu", 
    "title": "A note on revelation principle from an energy perspective", 
    "publish": "2010-08-19T12:23:58Z", 
    "summary": "The revelation principle has been known in the economics society for decades.\nIn this paper, I will investigate it from an energy perspective, i.e.,\nconsidering the energy consumed by agents and the designer in participating a\nmechanism. The main result is that when the strategies of agents are actions\nrather than messages, an additional energy condition should be added to make\nthe revelation principle hold in the real world.", 
    "link": "http://arxiv.org/pdf/1008.3287v9", 
    "arxiv-id": "1008.3287v9"
},{
    "category": "cs.GT", 
    "author": "Tamer Basar", 
    "title": "Dynamic Interference Minimization Routing Game for On-Demand Cognitive   Pilot Channel", 
    "publish": "2010-08-28T05:18:46Z", 
    "summary": "In this paper, we introduce a distributed dynamic routing algorithm for\nsecondary users (SUs) to minimize their interference with the primary users\n(PUs) in multi-hop cognitive radio (CR) networks. We use the medial axis with a\nrelaxation factor as a reference path which is contingent on the states of the\nPUs. Along the axis, we construct a hierarchical structure for multiple sources\nto reach cognitive pilot channel (CPC) base stations. We use a temporal and\nspatial dynamic non-cooperative game to model the interactions among SUs as\nwell as their influences from PUs in the multi-hop structure of the network. A\nmulti-stage fictitious play learning is used for distributed routing in\nmulti-hop CR networks. We obtain a set of mixed (behavioral) Nash equilibrium\nstrategies of the dynamic game in closed form by backward induction. The\nproposed algorithm minimizes the overall interference and the average packet\ndelay along the routing path from SU nodes to CPC base stations in an optimal\nand distributed manner", 
    "link": "http://arxiv.org/pdf/1008.5340v1", 
    "arxiv-id": "1008.5340v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "User Subscription, Revenue Maximization, and Competition in   Communications Markets", 
    "publish": "2010-08-31T17:07:34Z", 
    "summary": "An updated version of this paper (but with a different title) can be found at\narXiv:1204.4262", 
    "link": "http://arxiv.org/pdf/1008.5367v2", 
    "arxiv-id": "1008.5367v2"
},{
    "category": "cs.GT", 
    "author": "Chutima Boonthum", 
    "title": "MiBoard: Metacognitive Training Through Gaming in iSTART", 
    "publish": "2010-09-12T00:20:13Z", 
    "summary": "MiBoard (Multiplayer Interactive Board Game) is an online, turn-based board\ngame, which is a supplement of the iSTART (Interactive Strategy Training for\nActive Reading and Thinking) application. MiBoard is developed to test the\nhypothesis that integrating game characteristics (point rewards, game-like\ninteraction, and peer feedback) into the iSTART trainer will significantly\nimprove its effectiveness on students' learning. It was shown by M. Rowe that a\nphysical board game did in fact enhance students' performance. MiBoard is a\ncomputer-based version of Rowe's board game that eliminates constraints on\nlocality while retaining the crucial practice components that were the game's\nobjective. MiBoard gives incentives for participation and provides a more\nenjoyable and social practice environment compared to the online individual\npractice component of the original trainer.", 
    "link": "http://arxiv.org/pdf/1009.2204v1", 
    "arxiv-id": "1009.2204v1"
},{
    "category": "cs.GT", 
    "author": "Danielle S. McNamara", 
    "title": "MiBoard: iSTART Metacognitive Training through Gaming", 
    "publish": "2010-09-12T00:28:11Z", 
    "summary": "MiBoard (Multiplayer Interactive Board Game) is an online, turn-based board\ngame, which is a supplement of the iSTART (Interactive Strategy Training for\nActive Reading and Thinking) application. MiBoard is developed to test the\nhypothesis that integrating game characteristics (point rewards, game-like\ninteraction, and peer feedback) into the iSTART trainer will significantly\nimprove its effectiveness on students' learning. It was shown by M. Rowe that a\nphysical board game did in fact enhance students' performance. MiBoard is a\ncomputer-based version of Rowe's board game that eliminates constraints on\nlocality while retaining the crucial practice components that were the game's\nobjective. MiBoard gives incentives for participation and provides a more\nenjoyable and social practice environment compared to the online individual\npractice component of the original trainer", 
    "link": "http://arxiv.org/pdf/1009.2205v1", 
    "arxiv-id": "1009.2205v1"
},{
    "category": "cs.GT", 
    "author": "Danielle S. McNamara", 
    "title": "MiBoard: A Digital Game from a Physical World", 
    "publish": "2010-09-12T00:35:50Z", 
    "summary": "Increasing user engagement is constant challenge for Intelligent Tutoring\nSystems researchers. A current trend in the ITS field is to increase engagement\nof proven learning systems by integrating them within games, or adding in game\nlike components. Incorporating proven learning methods within a game based\nenvironment is expected to add to the overall experience without detracting\nfrom the original goals, however, the current study demonstrates two important\nissues with regard to ITS design. First, effective designs from the physical\nworld do not always translate into the digital world. Second, games do not\nnecessarily improve engagement, and in some cases, they may have the opposite\neffect. The current study discusses the development and a brief assessment of\nMiBoard a multiplayer collaborative online board game designed to closely\nemulate a previously developed physical board game, iSTART: The Board Game.", 
    "link": "http://arxiv.org/pdf/1009.2207v1", 
    "arxiv-id": "1009.2207v1"
},{
    "category": "cs.GT", 
    "author": "Danielle S. McNamara", 
    "title": "Gamed-based iSTART Practice: From MiBoard to Self-Explanation Showdown", 
    "publish": "2010-09-12T00:37:34Z", 
    "summary": "MiBoard (Multiplayer Interactive Board Game) is an online, turnbased board\ngame that was developed to assess the integration of game characteristics\n(point rewards, game-like interaction, and peer feedback) and how that might\naffect student engagement and learning efficacy. This online board game was\ndesigned to fit within the Extended Practice module of iSTART (Interactive\nStrategy Training for Active Reading and Thinking). Unfortunately, preliminary\nresearch shows that MiBoard actually reduces engagement and does not benefit\nthe quality of student self-explanations when compared to the original Extended\nPractice module. Consequently the MiBoard framework has been revamped to create\nSelf-Explanation Showdown, a faster-paced, less analytically oriented game that\nadds competition to the creation of self-explanations. Students are evaluated\non the quality of their self-explanations using the same assessment algorithms\nfrom iSTART Extended Practice module (this includes both word-based and\nLSA-based assessments). The technical issues involved in development of MiBoard\nand Self- Explanation Showdown are described. The lessons learned from the\nMiBoard experience are also discussed in this paper.", 
    "link": "http://arxiv.org/pdf/1009.2208v1", 
    "arxiv-id": "1009.2208v1"
},{
    "category": "cs.GT", 
    "author": "Li Zhang", 
    "title": "Understanding Fashion Cycles as a Social Choice", 
    "publish": "2010-09-14T10:32:44Z", 
    "summary": "We present a formal model for studying fashion trends, in terms of three\nparameters of fashionable items: (1) their innate utility; (2) individual\nboredom associated with repeated usage of an item; and (3) social influences\nassociated with the preferences from other people. While there are several\nworks that emphasize the effect of social influence in understanding fashion\ntrends, in this paper we show how boredom plays a strong role in both\nindividual and social choices. We show how boredom can be used to explain the\ncyclic choices in several scenarios such as an individual who has to pick a\nrestaurant to visit every day, or a society that has to repeatedly `vote' on a\nsingle fashion style from a collection. We formally show that a society that\nvotes for a single fashion style can be viewed as a single individual cycling\nthrough different choices.\n  In our model, the utility of an item gets discounted by the amount of boredom\nthat has accumulated over the past; this boredom increases with every use of\nthe item and decays exponentially when not used. We address the problem of\noptimally choosing items for usage, so as to maximize over-all satisfaction,\ni.e., composite utility, over a period of time. First we show that the simple\ngreedy heuristic of always choosing the item with the maximum current composite\nutility can be arbitrarily worse than the optimal. Second, we prove that even\nwith just a single individual, determining the optimal strategy for choosing\nitems is NP-hard. Third, we show that a simple modification to the greedy\nalgorithm that simply doubles the boredom of each item is a provably close\napproximation to the optimal strategy. Finally, we present an experimental\nstudy over real-world data collected from query logs to compare our algorithms.", 
    "link": "http://arxiv.org/pdf/1009.2617v1", 
    "arxiv-id": "1009.2617v1"
},{
    "category": "cs.GT", 
    "author": "Florin Constantin", 
    "title": "Sequential item pricing for unlimited supply", 
    "publish": "2010-09-23T13:13:15Z", 
    "summary": "We investigate the extent to which price updates can increase the revenue of\na seller with little prior information on demand. We study prior-free revenue\nmaximization for a seller with unlimited supply of n item types facing m myopic\nbuyers present for k < log n days. For the static (k = 1) case, Balcan et al.\n[2] show that one random item price (the same on each item) yields revenue\nwithin a \\Theta(log m + log n) factor of optimum and this factor is tight. We\ndefine the hereditary maximizers property of buyer valuations (satisfied by any\nmulti-unit or gross substitutes valuation) that is sufficient for a significant\nimprovement of the approximation factor in the dynamic (k > 1) setting. Our\nmain result is a non-increasing, randomized, schedule of k equal item prices\nwith expected revenue within a O((log m + log n) / k) factor of optimum for\nprivate valuations with hereditary maximizers. This factor is almost tight: we\nshow that any pricing scheme over k days has a revenue approximation factor of\nat least (log m + log n) / (3k). We obtain analogous matching lower and upper\nbounds of \\Theta((log n) / k) if all valuations have the same maximum. We\nexpect our upper bound technique to be of broader interest; for example, it can\nsignificantly improve the result of Akhlaghpour et al. [1]. We also initiate\nthe study of revenue maximization given allocative externalities (i.e.\ninfluences) between buyers with combinatorial valuations. We provide a rather\ngeneral model of positive influence of others' ownership of items on a buyer's\nvaluation. For affine, submodular externalities and valuations with hereditary\nmaximizers we present an influence-and-exploit (Hartline et al. [13]) marketing\nstrategy based on our algorithm for private valuations. This strategy preserves\nour approximation factor, despite an affine increase (due to externalities) in\nthe optimum revenue.", 
    "link": "http://arxiv.org/pdf/1009.4606v2", 
    "arxiv-id": "1009.4606v2"
},{
    "category": "cs.GT", 
    "author": "Kousha Etessami", 
    "title": "One-Counter Stochastic Games", 
    "publish": "2010-09-28T17:28:41Z", 
    "summary": "We study the computational complexity of basic decision problems for\none-counter simple stochastic games (OC-SSGs), under various objectives.\nOC-SSGs are 2-player turn-based stochastic games played on the transition graph\nof classic one-counter automata. We study primarily the termination objective,\nwhere the goal of one player is to maximize the probability of reaching counter\nvalue 0, while the other player wishes to avoid this. Partly motivated by the\ngoal of understanding termination objectives, we also study certain \"limit\" and\n\"long run average\" reward objectives that are closely related to some\nwell-studied objectives for stochastic games with rewards. Examples of problems\nwe address include: does player 1 have a strategy to ensure that the counter\neventually hits 0, i.e., terminates, almost surely, regardless of what player 2\ndoes? Or that the liminf (or limsup) counter value equals infinity with a\ndesired probability? Or that the long run average reward is >0 with desired\nprobability? We show that the qualitative termination problem for OC-SSGs is in\nNP intersection coNP, and is in P-time for 1-player OC-SSGs, or equivalently\nfor one-counter Markov Decision Processes (OC-MDPs). Moreover, we show that\nquantitative limit problems for OC-SSGs are in NP intersection coNP, and are in\nP-time for 1-player OC-MDPs. Both qualitative limit problems and qualitative\ntermination problems for OC-SSGs are already at least as hard as Condon's\nquantitative decision problem for finite-state SSGs.", 
    "link": "http://arxiv.org/pdf/1009.5636v1", 
    "arxiv-id": "1009.5636v1"
},{
    "category": "cs.GT", 
    "author": "Haoyang Wu", 
    "title": "A non-cooperative Pareto-efficient solution to a one-shot Prisoner's   Dilemma", 
    "publish": "2010-10-01T01:48:09Z", 
    "summary": "The Prisoner's Dilemma is a simple model that captures the essential\ncontradiction between individual rationality and global rationality. Although\nthe one-shot Prisoner's Dilemma is usually viewed simple, in this paper we will\ncategorize it into five different types. For the type-4 Prisoner's Dilemma\ngame, we will propose a self-enforcing algorithmic model to help\nnon-cooperative agents obtain Pareto-efficient payoffs. The algorithmic model\nis based on an algorithm using complex numbers and can work in macro\napplications.", 
    "link": "http://arxiv.org/pdf/1010.0047v5", 
    "arxiv-id": "1010.0047v5"
},{
    "category": "cs.GT", 
    "author": "Shang-Guan H. Wu", 
    "title": "A note on hierarchies and bureaucracies", 
    "publish": "2010-10-05T02:09:41Z", 
    "summary": "In this note, we argue that there is a bug in [Tirole, J., \"Hierarchies and\nbureaucracies: On the role of collusion in organizations,\" {\\em Journal of Law,\nEconomics and Organization}, vol.2, 181-214, 1986].", 
    "link": "http://arxiv.org/pdf/1010.0750v1", 
    "arxiv-id": "1010.0750v1"
},{
    "category": "cs.GT", 
    "author": "Lei Ying", 
    "title": "A Strategy-Proof and Non-monetary Admission Control Mechanism for   Wireless Access Networks", 
    "publish": "2010-10-13T17:41:07Z", 
    "summary": "We study admission control mechanisms for wireless access networks where (i)\neach user has a minimum service requirement, (ii) the capacity of the access\nnetwork is limited, and (iii) the access point is not allowed to use monetary\nmechanisms to guarantee that users do not lie when disclosing their minimum\nservice requirements. To guarantee truthfulness, we use auction theory to\ndesign a mechanism where users compete to be admitted into the network. We\npropose admission control mechanisms under which the access point intelligently\nallocates resources based on the announced minimum service requirements to\nensure that users have no incentive to lie and the capacity constraint is\nfulfilled. We also prove the properties that any feasible mechanism should\nhave.", 
    "link": "http://arxiv.org/pdf/1010.2713v3", 
    "arxiv-id": "1010.2713v3"
},{
    "category": "cs.GT", 
    "author": "Elliot Anshelevich", 
    "title": "A Stackelberg Strategy for Routing Flow over Time", 
    "publish": "2010-10-14T21:44:35Z", 
    "summary": "Routing games are used to to understand the impact of individual users'\ndecisions on network efficiency. Most prior work on routing games uses a\nsimplified model of network flow where all flow exists simultaneously, and\nusers care about either their maximum delay or their total delay. Both of these\nmeasures are surrogates for measuring how long it takes to get all of a user's\ntraffic through the network. We attempt a more direct study of how competition\naffects network efficiency by examining routing games in a flow over time\nmodel. We give an efficiently computable Stackelberg strategy for this model\nand show that the competitive equilibrium under this strategy is no worse than\na small constant times the optimal, for two natural measures of optimality.", 
    "link": "http://arxiv.org/pdf/1010.3034v1", 
    "arxiv-id": "1010.3034v1"
},{
    "category": "cs.GT", 
    "author": "Milind Sohoni", 
    "title": "Rank-1 Bi-matrix Games: A Homeomorphism and a Polynomial Time Algorithm", 
    "publish": "2010-10-15T07:24:24Z", 
    "summary": "Given a rank-1 bimatrix game (A,B), i.e., where rank(A+B)=1, we construct a\nsuitable linear subspace of the rank-1 game space and show that this subspace\nis homeomorphic to its Nash equilibrium correspondence. Using this\nhomeomorphism, we give the first polynomial time algorithm for computing an\nexact Nash equilibrium of a rank-1 bimatrix game. This settles an open question\nposed in Kannan and Theobald (SODA 2007) and Theobald (2007). In addition, we\ngive a novel algorithm to enumerate all the Nash equilibria of a rank-1 game\nand show that a similar technique may also be applied for finding a Nash\nequilibrium of any bimatrix game. This technique also proves the existence,\noddness and the index theorem of Nash equilibria in a bimatrix game. Further,\nwe extend the rank-1 homeomorphism result to a fixed rank game space, and give\na fixed point formulation on $[0,1]^k$ for solving a rank-k game. The\nhomeomorphism and the fixed point formulation are piece-wise linear and\nconsiderably simpler than the classical constructions.", 
    "link": "http://arxiv.org/pdf/1010.3083v2", 
    "arxiv-id": "1010.3083v2"
},{
    "category": "cs.GT", 
    "author": "Mohammad Reza Pakravan", 
    "title": "QoS-Aware Joint Policies in Cognitive Radio Networks", 
    "publish": "2010-10-14T14:19:43Z", 
    "summary": "One of the most challenging problems in Opportunistic Spectrum Access (OSA)\nis to design channel sensing-based protocol in multi secondary users (SUs)\nnetwork. Quality of Service (QoS) requirements for SUs have significant\nimplications on this protocol design. In this paper, we propose a new method to\nfind joint policies for SUs which not only guarantees QoS requirements but also\nmaximizes network throughput. We use Decentralized Partially Observable Markov\nDecision Process (Dec-POMDP) to formulate interactions between SUs. Meanwhile,\na tractable approach for Dec-POMDP is utilized to extract sub-optimum joint\npolicies for large horizons. Among these policies, the joint policy which\nguarantees QoS requirements is selected as the joint sensing strategy for SUs.\nTo show the efficiency of the proposed method, we consider two SUs trying to\naccess two-channel primary users (PUs) network modeled by discrete Markov\nchains. Simulations demonstrate three interesting findings: 1- Optimum joint\npolicies for large horizons can be obtained using the proposed method. 2- There\nexists a joint policy for the assumed QoS constraints. 3- Our method\noutperforms other related works in terms of network throughput.", 
    "link": "http://arxiv.org/pdf/1010.3197v1", 
    "arxiv-id": "1010.3197v1"
},{
    "category": "cs.GT", 
    "author": "Vijay V. Vazirani", 
    "title": "Non-Separable, Quasiconcave Utilities are Easy -- in a Perfect Price   Discrimination Market Model", 
    "publish": "2010-10-20T19:13:15Z", 
    "summary": "Recent results, establishing evidence of intractability for such restrictive\nutility functions as additively separable, piecewise-linear and concave, under\nboth Fisher and Arrow-Debreu market models, have prompted the question of\nwhether we have failed to capture some essential elements of real markets,\nwhich seem to do a good job of finding prices that maintain parity between\nsupply and demand.\n  The main point of this paper is to show that even non-separable, quasiconcave\nutility functions can be handled efficiently in a suitably chosen, though\nnatural, realistic and useful, market model; our model allows for perfect price\ndiscrimination. Our model supports unique equilibrium prices and, for the\nrestriction to concave utilities, satisfies both welfare theorems.", 
    "link": "http://arxiv.org/pdf/1010.4281v1", 
    "arxiv-id": "1010.4281v1"
},{
    "category": "cs.GT", 
    "author": "Bryan Bruns", 
    "title": "Navigating the Topology of 2x2 Games: An Introductory Note on Payoff   Families, Normalization, and Natural Order", 
    "publish": "2010-10-22T14:36:44Z", 
    "summary": "The Robinson-Goforth topology of swaps in adjoining payoffs elegantly\narranges 2x2 ordinal games in accordance with important properties including\nsymmetry, number of dominant strategies and Nash Equilibria, and alignment of\ninterests. Adding payoff families based on Nash Equilibria illustrates an\nadditional aspect of this order and aids visualization of the topology. Making\nties through half-swaps not only creates simpler games within the topology,\nbut, in reverse, breaking ties shows the evolution of preferences, yielding a\nnatural ordering for the topology of 2x2 games with ties. An ordinal game not\nonly represents an equivalence class of games with real values, but also a\ndiscrete equivalent of the normalized version of those games. The topology\nprovides coordinates which could be used to identify related games in a\nsemantic web ontology and facilitate comparative analysis of agent-based\nsimulations and other research in game theory, as well as charting\nrelationships and potential moves between games as a tool for institutional\nanalysis and design.", 
    "link": "http://arxiv.org/pdf/1010.4727v1", 
    "arxiv-id": "1010.4727v1"
},{
    "category": "cs.GT", 
    "author": "Athanasios Vasilakos", 
    "title": "Polynomial Bottleneck Congestion Games with Optimal Price of Anarchy", 
    "publish": "2010-10-22T20:44:09Z", 
    "summary": "We study {\\em bottleneck congestion games} where the social cost is\ndetermined by the worst congestion of any resource. These games directly relate\nto network routing problems and also job-shop scheduling problems. In typical\nbottleneck congestion games, the utility costs of the players are determined by\nthe worst congested resources that they use. However, the resulting Nash\nequilibria are inefficient, since the price of anarchy is proportional on the\nnumber of resources which can be high. Here we show that we can get smaller\nprice of anarchy with the bottleneck social cost metric. We introduce the {\\em\npolynomial bottleneck games} where the utility costs of the players are\npolynomial functions of the congestion of the resources that they use. In\nparticular, the delay function for any resource $r$ is $C_{r}^\\M$, where $C_r$\nis the congestion measured as the number of players that use $r$, and $\\M \\geq\n1$ is an integer constant that defines the degree of the polynomial. The\nutility cost of a player is the sum of the individual delays of the resources\nthat it uses. The social cost of the game remains the same, namely, it is the\nworst bottleneck resource congestion: $\\max_{r} C_r$. We show that polynomial\nbottleneck games are very efficient and give price of anarchy\n$O(|R|^{1/(\\M+1)})$, where $R$ is the set of resources. This price of anarchy\nis tight, since we demonstrate a game with price of anarchy\n$\\Omega(|R|^{1/(\\M+1)})$, for any $\\M \\geq 1$. We obtain our tight bounds by\nusing two proof techniques: {\\em transformation}, which we use to convert\narbitrary games to simpler games, and {\\em expansion}, which we use to bound\nthe price of anarchy in a simpler game.", 
    "link": "http://arxiv.org/pdf/1010.4812v1", 
    "arxiv-id": "1010.4812v1"
},{
    "category": "cs.GT", 
    "author": "Dmitry Shiryaev", 
    "title": "Dynamics of Profit-Sharing Games", 
    "publish": "2010-10-25T10:37:00Z", 
    "summary": "An important task in the analysis of multiagent systems is to understand how\ngroups of selfish players can form coalitions, i.e., work together in teams. In\nthis paper, we study the dynamics of coalition formation under bounded\nrationality. We consider settings where each team's profit is given by a convex\nfunction, and propose three profit-sharing schemes, each of which is based on\nthe concept of marginal utility. The agents are assumed to be myopic, i.e.,\nthey keep changing teams as long as they can increase their payoff by doing so.\nWe study the properties (such as closeness to Nash equilibrium or total profit)\nof the states that result after a polynomial number of such moves, and prove\nbounds on the price of anarchy and the price of stability of the corresponding\ngames.", 
    "link": "http://arxiv.org/pdf/1010.5081v2", 
    "arxiv-id": "1010.5081v2"
},{
    "category": "cs.GT", 
    "author": "Redjan F. Shabani", 
    "title": "The nature of individual choice: a formalism for utility function based   on set theory", 
    "publish": "2010-10-26T17:48:25Z", 
    "summary": "In the theory of social choice the research is focused around the projection\nof individual preference orders to the social preference order. Also, the\njustification of the preference order formalism begins with the concept of\nutility i.e. an alternative is preferred to another one if the utility over the\nfirst is higher then the utility over the second. In this paper is proposed an\nideal model of measuring utilities by considering individuals and alternatives\nno more as atomic concepts but as being composed by other entities. Furthermore\nis proposed a formal definition of evaluation processes based on utilities.", 
    "link": "http://arxiv.org/pdf/1010.5471v1", 
    "arxiv-id": "1010.5471v1"
},{
    "category": "cs.GT", 
    "author": "Juergen Jost", 
    "title": "Hysteresis effects of changing parameters of noncooperative games", 
    "publish": "2010-10-27T17:31:57Z", 
    "summary": "We adapt the method used by Jaynes to derive the equilibria of statistical\nphysics to instead derive equilibria of bounded rational game theory. We\nanalyze the dependence of these equilibria on the parameters of the underlying\ngame, focusing on hysteresis effects. In particular, we show that by gradually\nimposing individual-specific tax rates on the players of the game, and then\ngradually removing those taxes, the players move from a poor equilibrium to one\nthat is better for all of them.", 
    "link": "http://arxiv.org/pdf/1010.5749v1", 
    "arxiv-id": "1010.5749v1"
},{
    "category": "cs.GT", 
    "author": "Dah Ming Chiu", 
    "title": "Reciprocating Preferences Stablize Matching: College Admissions   Revisited", 
    "publish": "2010-11-04T12:26:57Z", 
    "summary": "In considering the college admissions problem, almost fifty years ago, Gale\nand Shapley came up with a simple abstraction based on preferences of students\nand colleges. They introduced the concept of stability and optimality; and\nproposed the deferred acceptance (DA) algorithm that is proven to lead to a\nstable and optimal solution. This algorithm is simple and computationally\nefficient. Furthermore, in subsequent studies it is shown that the DA algorithm\nis also strategy-proof, which means, when the algorithm is played out as a\nmechanism for matching two sides (e.g. colleges and students), the parties\n(colleges or students) have no incentives to act other than according to their\ntrue preferences. Yet, in practical college admission systems, the DA algorithm\nis often not adopted. Instead, an algorithm known as the Boston Mechanism (BM)\nor its variants are widely adopted. In BM, colleges accept students without\ndeferral (considering other colleges' decisions), which is exactly the opposite\nof Gale-Shapley's DA algorithm. To explain and rationalize this reality, we\nintroduce the notion of reciprocating preference to capture the influence of a\nstudent's interest on a college's decision. This model is inspired by the\nactual mechanism used to match students to universities in Hong Kong. The\nnotion of reciprocating preference defines a class of matching algorithms,\nallowing different degrees of reciprocating preferences by the students and\ncolleges. DA and BM are but two extreme cases (with zero and a hundred percent\nreciprocation) of this set. This model extends the notion of stability and\noptimality as well. As in Gale-Shapley's original paper, we discuss how the\nanalogy can be carried over to the stable marriage problem, thus demonstrating\nthe model's general applicability.", 
    "link": "http://arxiv.org/pdf/1011.1135v5", 
    "arxiv-id": "1011.1135v5"
},{
    "category": "cs.GT", 
    "author": "George Pierrakos", 
    "title": "Optimal Deterministic Auctions with Correlated Priors", 
    "publish": "2010-11-04T21:57:59Z", 
    "summary": "We revisit the problem of designing the profit-maximizing single-item\nauction, solved by Myerson in his seminal paper for the case in which bidder\nvaluations are independently distributed. We focus on general joint\ndistributions, seeking the optimal deterministic incentive compatible auction.\nWe give a geometric characterization of the optimal auction, resulting in a\nduality theorem and an efficient algorithm for finding the optimal\ndeterministic auction in the two-bidder case and an NP-completeness result for\nthree or more bidders.", 
    "link": "http://arxiv.org/pdf/1011.1279v2", 
    "arxiv-id": "1011.1279v2"
},{
    "category": "cs.GT", 
    "author": "Shahar Dobzinski", 
    "title": "An Impossibility Result for Truthful Combinatorial Auctions with   Submodular Valuations", 
    "publish": "2010-11-08T15:42:56Z", 
    "summary": "We show that every universally truthful randomized mechanism for\ncombinatorial auctions with submodular valuations that provides $m^{\\frac 1 2\n-\\epsilon}$ approximation to the social welfare and uses value queries only\nmust use exponentially many value queries, where $m$ is the number of items. In\ncontrast, ignoring incentives there exist constant ratio approximation\nalgorithms for this problem. Our approach is based on a novel \\emph{direct\nhardness} approach and completely skips the notoriously hard characterization\nstep. The characterization step was the main obstacle for proving impossibility\nresults in algorithmic mechanism design so far.\n  We demonstrate two additional applications of our new technique: (1) an\nimpossibility result for universally-truthful polynomial time flexible\ncombinatorial public projects and (2) an impossibility result for\ntruthful-in-expectation mechanisms for exact combinatorial public projects. The\nlatter is the first result that bounds the power of polynomial-time truthful in\nexpectation mechanisms in any setting.", 
    "link": "http://arxiv.org/pdf/1011.1830v1", 
    "arxiv-id": "1011.1830v1"
},{
    "category": "cs.GT", 
    "author": "Jennifer Wortman Vaughan", 
    "title": "An Optimization-Based Framework for Automated Market-Making", 
    "publish": "2010-11-08T22:58:37Z", 
    "summary": "Building on ideas from online convex optimization, we propose a general\nframework for the design of efficient securities markets over very large\noutcome spaces. The challenge here is computational. In a complete market, in\nwhich one security is offered for each outcome, the market institution can not\nefficiently keep track of the transaction history or calculate security prices\nwhen the outcome space is large. The natural solution is to restrict the space\nof securities to be much smaller than the outcome space in such a way that\nsecurities can be priced efficiently. Recent research has focused on searching\nfor spaces of securities that can be priced efficiently by existing mechanisms\ndesigned for complete markets. While there have been some successes, much of\nthis research has led to hardness results. In this paper, we take a drastically\ndifferent approach. We start with an arbitrary space of securities with bounded\npayoff, and establish a framework to design markets tailored to this space. We\nprove that any market satisfying a set of intuitive conditions must price\nsecurities via a convex potential function and that the space of reachable\nprices must be precisely the convex hull of the security payoffs. We then show\nhow the convex potential function can be defined in terms of an optimization\nover the convex hull of the security payoffs. The optimal solution to the\noptimization problem gives the security prices. Using this framework, we\nprovide an efficient market for predicting the landing location of an object on\na sphere. In addition, we show that we can relax our \"no-arbitrage\" condition\nto design a new efficient market maker for pair betting, which is known to be\n#P-hard to price using existing mechanisms. This relaxation also allows the\nmarket maker to charge transaction fees so that the depth of the market can be\ndynamically increased as the number of trades increases.", 
    "link": "http://arxiv.org/pdf/1011.1941v1", 
    "arxiv-id": "1011.1941v1"
},{
    "category": "cs.GT", 
    "author": "Avinatan Hassidim", 
    "title": "Matching with Couples Revisited", 
    "publish": "2010-11-09T15:52:21Z", 
    "summary": "It is well known that a stable matching in a many-to-one matching market with\ncouples need not exist. We introduce a new matching algorithm for such markets\nand show that for a general class of large random markets the algorithm will\nfind a stable matching with high probability. In particular we allow the number\nof couples to grow at a near-linear rate. Furthermore, truth-telling is an\napproximated equilibrium in the game induced by the new matching algorithm. Our\nresults are tight: for markets in which the number of couples grows at a linear\nrate, we show that with constant probability no stable matching exists.", 
    "link": "http://arxiv.org/pdf/1011.2121v2", 
    "arxiv-id": "1011.2121v2"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "Optimal Auctions with Correlated Bidders are Easy", 
    "publish": "2010-11-10T15:53:56Z", 
    "summary": "We consider the problem of designing a revenue-maximizing auction for a\nsingle item, when the values of the bidders are drawn from a correlated\ndistribution. We observe that there exists an algorithm that finds the optimal\nrandomized mechanism that runs in time polynomial in the size of the support.\nWe leverage this result to show that in the oracle model introduced by Ronen\nand Saberi [FOCS'02], there exists a polynomial time truthful in expectation\nmechanism that provides a $(\\frac 3 2+\\epsilon)$-approximation to the revenue\nachievable by an optimal truthful-in-expectation mechanism, and a polynomial\ntime deterministic truthful mechanism that guarantees $\\frac 5 3$ approximation\nto the revenue achievable by an optimal deterministic truthful mechanism.\n  We show that the $\\frac 5 3$-approximation mechanism provides the same\napproximation ratio also with respect to the optimal truthful-in-expectation\nmechanism. This shows that the performance gap between truthful-in-expectation\nand deterministic mechanisms is relatively small. En route, we solve an open\nquestion of Mehta and Vazirani [EC'04].\n  Finally, we extend some of our results to the multi-item case, and show how\nto compute the optimal truthful-in-expectation mechanisms for bidders with more\ncomplex valuations.", 
    "link": "http://arxiv.org/pdf/1011.2413v1", 
    "arxiv-id": "1011.2413v1"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "Truthfulness via Proxies", 
    "publish": "2010-11-14T16:19:27Z", 
    "summary": "This short note exhibits a truthful-in-expectation $O(\\frac {\\log m} {\\log\n\\log m})$-approximation mechanism for combinatorial auctions with subadditive\nbidders that uses polynomial communication.", 
    "link": "http://arxiv.org/pdf/1011.3232v2", 
    "arxiv-id": "1011.3232v2"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Improved Social Welfare Bounds for GSP at Equilibrium", 
    "publish": "2010-11-14T23:53:27Z", 
    "summary": "The Generalized Second Price auction is the primary method by which sponsered\nsearch advertisements are sold. We study the performance of this auction under\nvarious equilibrium concepts. In particular, we demonstrate that the Bayesian\nPrice of Anarchy is at most $2(1-1/e)^{-1} \\approx 3.16$, significantly\nimproving upon previously known bounds.\n  Our techniques are intuitively straightforward and extend in a number of\nways. For one, our result extends to a bound on the performance of GSP at\ncoarse correlated equilibria, which captures (for example) a repeated-auction\nsetting in which agents apply regret-minimizing bidding strategies. In\naddition, our analysis is robust against the presence of byzantine agents who\ncannot be assumed to participate rationally.\n  Additionally, we present tight bounds for the social welfare obtained at pure\nNE for the special case of an auction for 3 slots, and discuss potential\nmethods for extending this analysis to an arbitrary number of slots.", 
    "link": "http://arxiv.org/pdf/1011.3268v1", 
    "arxiv-id": "1011.3268v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Technology Choices and Pricing Policies in Public and Private Wireless   Networks", 
    "publish": "2010-11-16T04:15:37Z", 
    "summary": "This paper studies the provision of a wireless network by a monopolistic\nprovider who may be either benevolent (seeking to maximize social welfare) or\nselfish (seeking to maximize provider profit). The paper addresses questions\nthat do not seem to have been studied before in the engineering literature on\nwireless networks: Under what circumstances is it feasible for a provider,\neither benevolent or selfish, to operate a network in such a way as to cover\ncosts? How is the optimal behavior of a benevolent provider different from the\noptimal behavior of a selfish provider, and how does this difference affect\nsocial welfare? And, most importantly, how does the medium access control (MAC)\ntechnology influence the answers to these questions? To address these\nquestions, we build a general model, and provide analysis and simulations for\nsimplified but typical scenarios; the focus in these scenarios is on the\ncontrast between the outcomes obtained under carrier-sensing multiple access\n(CSMA) and outcomes obtained under time-division multiple access (TDMA).\nSimulation results demonstrate that differences in MAC technology can have a\nsignificant effect on social welfare, on provider profit, and even on the\n(financial) feasibility of a wireless network.", 
    "link": "http://arxiv.org/pdf/1011.3580v3", 
    "arxiv-id": "1011.3580v3"
},{
    "category": "cs.GT", 
    "author": "Jianwei Huang", 
    "title": "Spectrum Sharing as Spatial Congestion Games", 
    "publish": "2010-11-24T14:47:47Z", 
    "summary": "In this paper, we present and analyze the properties of a new class of games\n- the spatial congestion game (SCG), which is a generalization of the classical\ncongestion game (CG). In a classical congestion game, multiple users share the\nsame set of resources and a user's payoff for using any resource is a function\nof the total number of users sharing it. As a potential game, this game enjoys\nsome very appealing properties, including the existence of a pure strategy Nash\nequilibrium (NE) and that every improvement path is finite and leads to such a\nNE (also called the finite improvement property or FIP). While it's tempting to\nuse this model to study spectrum sharing, it does not capture the spatial reuse\nfeature of wireless communication, where resources (interpreted as channels)\nmay be reused without increasing congestion provided that users are located far\naway from each other. This motivates us to study an extended form of the\ncongestion game where a user's payoff for using a resource is a function of the\nnumber of its interfering users sharing it. This naturally results in a spatial\ncongestion game (SCG), where users are placed over a network (or a conflict\ngraph). We study fundamental properties of a spatial congestion game; in\nparticular, we seek to answer under what conditions this game possesses the\nfinite improvement property or a Nash equilibrium. We also discuss the\nimplications of these results when applied to wireless spectrum sharing.", 
    "link": "http://arxiv.org/pdf/1011.5384v1", 
    "arxiv-id": "1011.5384v1"
},{
    "category": "cs.GT", 
    "author": "Gabriel Y. Weintraub", 
    "title": "Equilibria of Dynamic Games with Many Players: Existence, Approximation,   and Market Structure", 
    "publish": "2010-11-25T00:28:19Z", 
    "summary": "In this paper we study stochastic dynamic games with many players; these are\na fundamental model for a wide range of economic applications. The standard\nsolution concept for such games is Markov perfect equilibrium (MPE), but it is\nwell known that MPE computation becomes intractable as the number of players\nincreases. We instead consider the notion of stationary equilibrium (SE), where\nplayers optimize assuming the empirical distribution of others' states remains\nconstant at its long run average. We make two main contributions. First, we\nprovide a rigorous justification for using SE. In particular, we provide a\nparsimonious collection of exogenous conditions over model primitives that\nguarantee existence of SE, and ensure that an appropriate approximation\nproperty to MPE holds, in a general model with possibly unbounded state spaces.\nSecond, we draw a significant connection between the validity of SE, and market\nstructure: under the same conditions that imply SE exist and approximates MPE\nwell, the market becomes fragmented in the limit of many firms. To illustrate\nthis connection, we study in detail a series of dynamic oligopoly examples.\nThese examples show that our conditions enforce a form of \"decreasing returns\nto larger states\"; this yields fragmented industries in the limit. By contrast,\nviolation of these conditions suggests \"increasing returns to larger states\"\nand potential market concentration. In that sense, our work uses a fully\ndynamic framework to also contribute to a longstanding issue in industrial\norganization: understanding the determinants of market structure in different\nindustries.", 
    "link": "http://arxiv.org/pdf/1011.5537v5", 
    "arxiv-id": "1011.5537v5"
},{
    "category": "cs.GT", 
    "author": "Ramesh Johari", 
    "title": "Mean Field Equilibrium in Dynamic Games with Complementarities", 
    "publish": "2010-11-25T19:31:47Z", 
    "summary": "We study a class of stochastic dynamic games that exhibit strategic\ncomplementarities between players; formally, in the games we consider, the\npayoff of a player has increasing differences between her own state and the\nempirical distribution of the states of other players. Such games can be used\nto model a diverse set of applications, including network security models,\nrecommender systems, and dynamic search in markets. Stochastic games are\ngenerally difficult to analyze, and these difficulties are only exacerbated\nwhen the number of players is large (as might be the case in the preceding\nexamples).\n  We consider an approximation methodology called mean field equilibrium to\nstudy these games. In such an equilibrium, each player reacts to only the long\nrun average state of other players. We find necessary conditions for the\nexistence of a mean field equilibrium in such games. Furthermore, as a simple\nconsequence of this existence theorem, we obtain several natural monotonicity\nproperties. We show that there exist a \"largest\" and a \"smallest\" equilibrium\namong all those where the equilibrium strategy used by a player is\nnondecreasing, and we also show that players converge to each of these\nequilibria via natural myopic learning dynamics; as we argue, these dynamics\nare more reasonable than the standard best response dynamics. We also provide\nsensitivity results, where we quantify how the equilibria of such games move in\nresponse to changes in parameters of the game (e.g., the introduction of\nincentives to players).", 
    "link": "http://arxiv.org/pdf/1011.5677v1", 
    "arxiv-id": "1011.5677v1"
},{
    "category": "cs.GT", 
    "author": "Balasubramanian Sivan", 
    "title": "Single-Call Mechanisms", 
    "publish": "2010-11-29T06:01:10Z", 
    "summary": "Truthfulness is fragile and demanding. It is oftentimes computationally\nharder than solving the original problem. Even worse, truthfulness can be\nutterly destroyed by small uncertainties in a mechanism's outcome. One obstacle\nis that truthful payments depend on outcomes other than the one realized, such\nas the lengths of non-shortest-paths in a shortest-path auction. Single-call\nmechanisms are a powerful tool that circumvents this obstacle --- they\nimplicitly charge truthful payments, guaranteeing truthfulness in expectation\nusing only the outcome realized by the mechanism. The cost of such truthfulness\nis a trade-off between the expected quality of the outcome and the risk of\nlarge payments.\n  We largely settle when and to what extent single-call mechanisms are\npossible. The first single-call construction was discovered by Babaioff,\nKleinberg, and Slivkins [BKS10] in single-parameter domains. They give a\ntransformation that turns any monotone, single-parameter allocation rule into a\ntruthful-in-expectation single-call mechanism. Our first result is a natural\ncomplement to [BKS10]: we give a new transformation that produces a single-call\nVCG mechanism from any allocation rule for which VCG payments are truthful.\nSecond, in both the single-parameter and VCG settings, we precisely\ncharacterize the possible transformations, showing that that a wide variety of\ntransformations are possible but that all take a very simple form. Finally, we\nstudy the inherent trade-off between the expected quality of the outcome and\nthe risk of large payments. We show that our construction and that of [BKS10]\nsimultaneously optimize a variety of metrics in their respective domains.\n  As an example, we analyze pay-per-click advertising auctions, where the\ntruthfulness of the standard VCG-based auction is easily broken when the\nauctioneer's estimated click-through-rates are imprecise.", 
    "link": "http://arxiv.org/pdf/1011.6134v3", 
    "arxiv-id": "1011.6134v3"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Designing Incentive Schemes Based on Intervention: The Case of Perfect   Monitoring", 
    "publish": "2010-12-08T02:18:20Z", 
    "summary": "This paper studies a class of incentive schemes based on intervention, where\nthere exists an intervention device that is able to monitor the actions of\nusers and to take an action that affects the payoffs of users. We consider the\ncase of perfect monitoring, where the intervention device can immediately\nobserve the actions of users without errors. We also assume that there exist\nactions of the intervention device that are most and least preferred by all the\nusers and the intervention device, regardless of the actions of users. We\nderive analytical results about the outcomes achievable with intervention, and\nillustrate our results with an example based on the Cournot model.", 
    "link": "http://arxiv.org/pdf/1012.1673v1", 
    "arxiv-id": "1012.1673v1"
},{
    "category": "cs.GT", 
    "author": "Max Klimm", 
    "title": "Congestion Games with Variable Demands", 
    "publish": "2010-12-09T08:27:20Z", 
    "summary": "We initiate the study of congestion games with variable demands where the\n(variable) demand has to be assigned to exactly one subset of resources. The\nplayers' incentives to use higher demands are stimulated by non-decreasing and\nconcave utility functions. The payoff for a player is defined as the difference\nbetween the utility of the demand and the associated cost on the used\nresources. Although this class of non-cooperative games captures many elements\nof real-world applications, it has not been studied in this generality, to our\nknowledge, in the past. We study the fundamental problem of the existence of\npure Nash equilibria (PNE for short) in congestion games with variable demands.\nWe call a set of cost functions C consistent if every congestion game with\nvariable demands and cost functions in C possesses a PNE. We say that C is FIP\nconsistent if every such game possesses the alpha-Finite Improvement Property\nfor every alpha>0. Our main results are structural characterizations of\nconsistency and FIP consistency for twice continuously differentiable cost\nfunctions. Specifically, we show 1. C is consistent if and only if C contains\neither only affine functions or only homogeneously exponential functions (c(x)\n= a exp(p x)). 2. C is FIP consistent if and only if C contains only affine\nfunctions. Our results provide a complete characterization of consistency of\ncost functions revealing structural differences to congestion games with fixed\ndemands (weighted congestion games), where in the latter even inhomogeneously\nexponential functions are FIP consistent. Finally, we study consistency and FIP\nconsistency of cost functions in a slightly different class of games, where\nevery player experiences the same cost on a resource (uniform cost model). We\ngive a characterization of consistency and FIP consistency showing that only\nhomogeneously exponential functions are consistent.", 
    "link": "http://arxiv.org/pdf/1012.1938v2", 
    "arxiv-id": "1012.1938v2"
},{
    "category": "cs.GT", 
    "author": "Ashish Rastogi", 
    "title": "Discrete Price Updates Yield Fast Convergence in Ongoing Markets with   Finite Warehouses", 
    "publish": "2010-12-09T21:10:53Z", 
    "summary": "This paper shows that in suitable markets, even with out-of-equilibrium trade\nallowed, a simple price update rule leads to rapid convergence toward the\nequilibrium. In particular, this paper considers a Fisher market repeated over\nan unbounded number of time steps, with the addition of finite sized warehouses\nto enable non-equilibrium trade. The main result is that suitable tatonnement\nstyle price updates lead to convergence in a significant subset of markets\nsatisfying the Weak Gross Substitutes property. Throughout this process the\nwarehouse are always able to store or meet demand imbalances (the needed\ncapacity depends on the initial imbalances). Finally, our price update rule is\nrobust in a variety of regards: 1. The updates for each good depend only on\ninformation about that good (its current price, its excess demand since its\nlast update) and occur asynchronously from updates to other prices. 2. The\nprocess is resilient to error in the excess demand data. 3. Likewise, the\nprocess is resilient to discreteness, i.e. a limit to divisibility, both of\ngoods and money.", 
    "link": "http://arxiv.org/pdf/1012.2124v1", 
    "arxiv-id": "1012.2124v1"
},{
    "category": "cs.GT", 
    "author": "Tansu Alpcan", 
    "title": "Incentive Games and Mechanisms for Risk Management", 
    "publish": "2010-12-15T11:14:33Z", 
    "summary": "Incentives play an important role in (security and IT) risk management of a\nlarge-scale organization with multiple autonomous divisions. This paper\npresents an incentive mechanism design framework for risk management based on a\ngame-theoretic approach. The risk manager acts as a mechanism designer\nproviding rules and incentive factors such as assistance or subsidies to\ndivisions or units, which are modeled as selfish players of a strategic\n(noncooperative) game. Based on this model, incentive mechanisms with various\nobjectives are developed that satisfy efficiency, preference-compatibility, and\nstrategy-proofness criteria. In addition, iterative and distributed algorithms\nare presented, which can be implemented under information limitations such as\nthe risk manager not knowing the individual units' preferences. An example\nscenario illustrates the framework and results numerically. The incentive\nmechanism design approach presented is useful for not only deriving guidelines\nbut also developing computer-assistance systems for large-scale risk\nmanagement.", 
    "link": "http://arxiv.org/pdf/1012.3282v1", 
    "arxiv-id": "1012.3282v1"
},{
    "category": "cs.GT", 
    "author": "J\u00e9r\u00f4me Monnot", 
    "title": "Minimum regulation of uncoordinated matchings", 
    "publish": "2010-12-17T14:34:02Z", 
    "summary": "Due to the lack of coordination, it is unlikely that the selfish players of a\nstrategic game reach a socially good state. A possible way to cope with\nselfishness is to compute a desired outcome (if it is tractable) and impose it.\nHowever this answer is often inappropriate because compelling an agent can be\ncostly, unpopular or just hard to implement. Since both situations (no\ncoordination and full coordination) show opposite advantages and drawbacks, it\nis natural to study possible tradeoffs. In this paper we study a strategic game\nwhere the nodes of a simple graph G are independent agents who try to form\npairs: e.g. jobs and applicants, tennis players for a match, etc. In many\ninstances of the game, a Nash equilibrium significantly deviates from a social\noptimum. We analyze a scenario where we fix the strategy of some players; the\nother players are free to make their choice. The goal is to compel a minimum\nnumber of players and guarantee that any possible equilibrium of the modified\ngame is a social optimum, i.e. created pairs must form a maximum matching of G.\nWe mainly show that this intriguing problem is NP-hard and propose an\napproximation algorithm with a constant ratio.", 
    "link": "http://arxiv.org/pdf/1012.3889v1", 
    "arxiv-id": "1012.3889v1"
},{
    "category": "cs.GT", 
    "author": "Jonathan A. Zvesper", 
    "title": "Public Announcements in Strategic Games with Arbitrary Strategy Sets", 
    "publish": "2010-12-23T10:44:45Z", 
    "summary": "In [Van Benthem 2007] the concept of a public announcement is used to study\nthe effect of the iterated elimination of strictly dominated strategies. We\noffer a simple generalisation of this approach to cover arbitrary strategic\ngames and many optimality notions. We distinguish between announcements of\noptimality and announcements of rationality.", 
    "link": "http://arxiv.org/pdf/1012.5173v1", 
    "arxiv-id": "1012.5173v1"
},{
    "category": "cs.GT", 
    "author": "Krzysztof R. Apt", 
    "title": "A Primer on Strategic Games", 
    "publish": "2011-02-01T16:22:14Z", 
    "summary": "This is a short introduction to the subject of strategic games. We focus on\nthe concepts of best response, Nash equilibrium, strict and weak dominance, and\nmixed strategies, and study the relation between these concepts in the context\nof the iterated elimination of strategies. Also, we discuss some variants of\nthe original definition of a strategic game. Finally, we introduce the basics\nof mechanism design and use pre-Bayesian games to explain it.", 
    "link": "http://arxiv.org/pdf/1102.0203v1", 
    "arxiv-id": "1102.0203v1"
},{
    "category": "cs.GT", 
    "author": "Mukund Sundararajan", 
    "title": "Axiomatic Attribution for Multilinear Functions", 
    "publish": "2011-02-04T18:24:26Z", 
    "summary": "We study the attribution problem, that is, the problem of attributing a\nchange in the value of a characteristic function to its independent variables.\nWe make three contributions. First, we propose a formalization of the problem\nbased on a standard cost sharing model. Second, we show that there is a unique\nattribution method that satisfies Dummy, Additivity, Conditional Nonnegativity,\nAffine Scale Invariance, and Anonymity for all characteristic functions that\nare the sum of a multilinear function and an additive function. We term this\nthe Aumann-Shapley-Shubik method. Conversely, we show that such a uniqueness\nresult does not hold for characteristic functions outside this class. Third, we\nstudy multilinear characteristic functions in detail; we describe a\ncomputationally efficient implementation of the Aumann-Shapley-Shubik method\nand discuss practical applications to pay-per-click advertising and portfolio\nanalysis.", 
    "link": "http://arxiv.org/pdf/1102.0989v2", 
    "arxiv-id": "1102.0989v2"
},{
    "category": "cs.GT", 
    "author": "David Auger", 
    "title": "Multiple Tree for Partially Observable Monte-Carlo Tree Search", 
    "publish": "2011-02-08T11:57:42Z", 
    "summary": "We propose an algorithm for computing approximate Nash equilibria of\npartially observable games using Monte-Carlo tree search based on recent bandit\nmethods. We obtain experimental results for the game of phantom tic-tac-toe,\nshowing that strong strategies can be efficiently computed by our algorithm.", 
    "link": "http://arxiv.org/pdf/1102.1580v1", 
    "arxiv-id": "1102.1580v1"
},{
    "category": "cs.GT", 
    "author": "Michael J. Collins", 
    "title": "Cost Sharing in the Aspnes Inoculation Model", 
    "publish": "2011-02-10T20:57:02Z", 
    "summary": "We consider the use of cost sharing in the Aspnes model of network\ninoculation, showing that this can improve the cost of the optimal equilibrium\nby a factor of $O(\\sqrt{n})$ in a network of $n$ nodes.", 
    "link": "http://arxiv.org/pdf/1102.2224v1", 
    "arxiv-id": "1102.2224v1"
},{
    "category": "cs.GT", 
    "author": "Gerhard J. Woeginger", 
    "title": "An Algorithmic Analysis of the Honey-Bee Game", 
    "publish": "2011-02-15T10:22:18Z", 
    "summary": "The Honey-Bee game is a two-player board game that is played on a connected\nhexagonal colored grid or (in a generalized setting) on a connected graph with\ncolored nodes. In a single move, a player calls a color and thereby conquers\nall the nodes of that color that are adjacent to his own current territory.\nBoth players want to conquer the majority of the nodes. We show that winning\nthe game is PSPACE-hard in general, NP-hard on series-parallel graphs, but easy\non outerplanar graphs.\n  In the solitaire version, the goal of the single player is to conquer the\nentire graph with the minimum number of moves. The solitaire version is NP-hard\non trees and split graphs, but can be solved in polynomial time on\nco-comparability graphs.", 
    "link": "http://arxiv.org/pdf/1102.3025v1", 
    "arxiv-id": "1102.3025v1"
},{
    "category": "cs.GT", 
    "author": "Steven R. Williams", 
    "title": "Auctions with a Profit Sharing Contract", 
    "publish": "2011-02-15T22:06:29Z", 
    "summary": "We study the problem of selling a resource through an auction mechanism. The\nwinning buyer in turn develops this resource to generate profit. Two forms of\npayment are considered: charging the winning buyer a one-time payment, or an\ninitial payment plus a profit sharing contract (PSC). We consider a symmetric\ninterdependent values model with risk averse or risk neutral buyers and a risk\nneutral seller. For the second price auction and the English auction, we show\nthat the seller's expected total revenue from the auction where he also takes a\nfraction of the positive profit is higher than the expected revenue from the\nauction with only a one-time payment. Moreover, the seller can generate an even\nhigher expected total revenue if, in addition to taking a fraction of the\npositive profit, he also takes the same fraction of any loss incurred from\ndeveloping the resource. Moving beyond simple PSCs, we show that the auction\nwith a PSC from a very general class generates higher expected total revenue\nthan the auction with only a one-time payment. Finally, we show that suitable\nPSCs provide higher expected total revenue than a one-time payment even when\nthe incentives of the winning buyer to develop the resource must be addressed\nby the seller.", 
    "link": "http://arxiv.org/pdf/1102.3195v5", 
    "arxiv-id": "1102.3195v5"
},{
    "category": "cs.GT", 
    "author": "David C. Parkes", 
    "title": "Simplicity-Expressiveness Tradeoffs in Mechanism Design", 
    "publish": "2011-02-17T16:58:09Z", 
    "summary": "A fundamental result in mechanism design theory, the so-called revelation\nprinciple, asserts that for many questions concerning the existence of\nmechanisms with a given outcome one can restrict attention to truthful direct\nrevelation-mechanisms. In practice, however, many mechanism use a restricted\nmessage space. This motivates the study of the tradeoffs involved in choosing\nsimplified mechanisms, which can sometimes bring benefits in precluding bad or\npromoting good equilibria, and other times impose costs on welfare and revenue.\nWe study the simplicity-expressiveness tradeoff in two representative settings,\nsponsored search auctions and combinatorial auctions, each being a canonical\nexample for complete information and incomplete information analysis,\nrespectively. We observe that the amount of information available to the agents\nplays an important role for the tradeoff between simplicity and expressiveness.", 
    "link": "http://arxiv.org/pdf/1102.3632v1", 
    "arxiv-id": "1102.3632v1"
},{
    "category": "cs.GT", 
    "author": "Velumailum Mohanaraj", 
    "title": "The Iterated Prisoner's Dilemma on a Cycle", 
    "publish": "2011-02-18T12:39:05Z", 
    "summary": "Pavlov, a well-known strategy in game theory, has been shown to have some\nadvantages in the Iterated Prisoner's Dilemma (IPD) game. However, this\nstrategy can be exploited by inveterate defectors. We modify this strategy to\nmitigate the exploitation. We call the resulting strategy Rational Pavlov. This\nhas a parameter p which measures the \"degree of forgiveness\" of the players. We\nstudy the evolution of cooperation in the IPD game, when n players are arranged\nin a cycle, and all play this strategy. We examine the effect of varying p on\nthe convergence rate and prove that the convergence rate is fast, O(n log n)\ntime, for high values of p. We also prove that the convergence rate is\nexponentially slow in n for small enough p. Our analysis leaves a gap in the\nrange of p, but simulations suggest that there is, in fact, a sharp phase\ntransition.", 
    "link": "http://arxiv.org/pdf/1102.3822v1", 
    "arxiv-id": "1102.3822v1"
},{
    "category": "cs.GT", 
    "author": "Velumailum Mohanaraj", 
    "title": "On the Imitation Strategy for Games on Graphs", 
    "publish": "2011-02-18T17:50:10Z", 
    "summary": "In evolutionary game theory, repeated two-player games are used to study\nstrategy evolution in a population under natural selection. As the evolution\ngreatly depends on the interaction structure, there has been growing interests\nin studying the games on graphs. In this setting, players occupy the vertices\nof a graph and play the game only with their immediate neighbours. Various\nevolutionary dynamics have been studied in this setting for different games.\nDue to the complexity of the analysis, however, most of the work in this area\nis experimental. This paper aims to contribute to a more complete\nunderstanding, by providing rigorous analysis. We study the imitation dynamics\non two classes of graph: cycles and complete graphs. We focus on three well\nknown social dilemmas, namely the Prisoner's Dilemma, the Stag Hunt and the\nSnowdrift Game. We also consider, for completeness, the so-called Harmony Game.\nOur analysis shows that, on the cycle, all four games converge fast, either to\ntotal cooperation or total defection. On the complete graph, all but the\nSnowdrift game converge fast, either to cooperation or defection. The Snowdrift\ngame reaches a metastable state fast, where cooperators and defectors coexist.\nIt will converge to cooperation or defection only after spending time in this\nstate which is exponential in the size, n, of the graph. In exceptional cases,\nit will remain in this state indefinitely. Our theoretical results are\nsupported by experimental investigations.", 
    "link": "http://arxiv.org/pdf/1102.3879v1", 
    "arxiv-id": "1102.3879v1"
},{
    "category": "cs.GT", 
    "author": "Michael Holtmann", 
    "title": "Memory Reduction via Delayed Simulation", 
    "publish": "2011-02-21T02:30:46Z", 
    "summary": "We address a central (and classical) issue in the theory of infinite games:\nthe reduction of the memory size that is needed to implement winning strategies\nin regular infinite games (i.e., controllers that ensure correct behavior\nagainst actions of the environment, when the specification is a regular\nomega-language). We propose an approach which attacks this problem before the\nconstruction of a strategy, by first reducing the game graph that is obtained\nfrom the specification. For the cases of specifications represented by\n\"request-response\"-requirements and general \"fairness\" conditions, we show that\nan exponential gain in the size of memory is possible.", 
    "link": "http://arxiv.org/pdf/1102.4120v1", 
    "arxiv-id": "1102.4120v1"
},{
    "category": "cs.GT", 
    "author": "Vianney Perchet", 
    "title": "Approachability of Convex Sets in Games with Partial Monitoring", 
    "publish": "2011-02-22T09:47:42Z", 
    "summary": "We provide a necessary and sufficient condition under which a convex set is\napproachable in a game with partial monitoring, i.e.\\ where players do not\nobserve their opponents' moves but receive random signals. This condition is an\nextension of Blackwell's Criterion in the full monitoring framework, where\nplayers observe at least their payoffs. When our condition is fulfilled, we\nconstruct explicitly an approachability strategy, derived from a strategy\nsatisfying some internal consistency property in an auxiliary game. We also\nprovide an example of a convex set, that is neither (weakly)-approachable nor\n(weakly)-excludable, a situation that cannot occur in the full monitoring case.\nWe finally apply our result to describe an $\\epsilon$-optimal strategy of the\nuninformed player in a zero-sum repeated game with incomplete information on\none side.", 
    "link": "http://arxiv.org/pdf/1102.4439v1", 
    "arxiv-id": "1102.4439v1"
},{
    "category": "cs.GT", 
    "author": "Carmine Ventre", 
    "title": "On the Approximation Performance of Fictitious Play in Finite Games", 
    "publish": "2011-03-05T10:37:48Z", 
    "summary": "We study the performance of Fictitious Play, when used as a heuristic for\nfinding an approximate Nash equilibrium of a 2-player game. We exhibit a class\nof 2-player games having payoffs in the range [0,1] that show that Fictitious\nPlay fails to find a solution having an additive approximation guarantee\nsignificantly better than 1/2. Our construction shows that for n times n games,\nin the worst case both players may perpetually have mixed strategies whose\npayoffs fall short of the best response by an additive quantity 1/2 -\nO(1/n^(1-delta)) for arbitrarily small delta. We also show an essentially\nmatching upper bound of 1/2 - O(1/n).", 
    "link": "http://arxiv.org/pdf/1103.1040v2", 
    "arxiv-id": "1103.1040v2"
},{
    "category": "cs.GT", 
    "author": "V\u00e1clav Bro\u017eek", 
    "title": "Optimal Strategies in Infinite-state Stochastic Reachability Games", 
    "publish": "2011-03-05T16:29:49Z", 
    "summary": "We consider perfect-information reachability stochastic games for 2 players\non infinite graphs. We identify a subclass of such games, and prove two\ninteresting properties of it: first, Player Max always has optimal strategies\nin games from this subclass, and second, these games are strongly determined.\nThe subclass is defined by the property that the set of all values can only\nhave one accumulation point -- 0. Our results nicely mirror recent results for\nfinitely-branching games, where, on the contrary, Player Min always has optimal\nstrategies. However, our proof methods are substantially different, because the\nroles of the players are not symmetric. We also do not restrict the branching\nof the games. Finally, we apply our results in the context of recently studied\nOne-Counter stochastic games.", 
    "link": "http://arxiv.org/pdf/1103.1065v3", 
    "arxiv-id": "1103.1065v3"
},{
    "category": "cs.GT", 
    "author": "Lacra Pavel", 
    "title": "Enabling Differentiated Services Using Generalized Power Control Model   in Optical Networks", 
    "publish": "2011-03-13T03:10:36Z", 
    "summary": "This paper considers a generalized framework to study OSNR optimization-based\nend-to-end link level power control problems in optical networks. We combine\nfavorable features of game-theoretical approach and central cost approach to\nallow different service groups within the network. We develop solutions\nconcepts for both cases of empty and nonempty feasible sets. In addition, we\nderive and prove the convergence of a distributed iterative algorithm for\ndifferent classes of users. In the end, we use numerical examples to illustrate\nthe novel framework.", 
    "link": "http://arxiv.org/pdf/1103.2490v1", 
    "arxiv-id": "1103.2490v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Mechanism design with uncertain inputs (to err is human, to forgive   divine)", 
    "publish": "2011-03-13T14:13:22Z", 
    "summary": "We consider a task of scheduling with a common deadline on a single machine.\nEvery player reports to a scheduler the length of his job and the scheduler\nneeds to finish as many jobs as possible by the deadline. For this simple\nproblem, there is a truthful mechanism that achieves maximum welfare in\ndominant strategies. The new aspect of our work is that in our setting players\nare uncertain about their own job lengths, and hence are incapable of providing\ntruthful reports (in the strict sense of the word). For a probabilistic model\nfor uncertainty our main results are as follows.\n  1) Even with relatively little uncertainty, no mechanism can guarantee a\nconstant fraction of the maximum welfare.\n  2) To remedy this situation, we introduce a new measure of economic\nefficiency, based on a notion of a {\\em fair share} of a player, and design\nmechanisms that are $\\Omega(1)$-fair. In addition to its intrinsic appeal, our\nnotion of fairness implies good approximation of maximum welfare in several\ncases of interest.\n  3) In our mechanisms the machine is sometimes left idle even though there are\njobs that want to use it. We show that this unfavorable aspect is unavoidable,\nunless one gives up other favorable aspects (e.g., give up\n$\\Omega(1)$-fairness).\n  We also consider a qualitative approach to uncertainty as an alternative to\nthe probabilistic quantitative model. In the qualitative approach we break away\nfrom solution concepts such as dominant strategies (they are no longer well\ndefined), and instead suggest an axiomatic approach, which amounts to listing\ndesirable properties for mechanisms. We provide a mechanism that satisfies\nthese properties.", 
    "link": "http://arxiv.org/pdf/1103.2520v1", 
    "arxiv-id": "1103.2520v1"
},{
    "category": "cs.GT", 
    "author": "Troels Bjerre S\u00f8rensen", 
    "title": "Path coalitional games", 
    "publish": "2011-03-16T22:26:15Z", 
    "summary": "We present a general framework to model strategic aspects and stable and fair\nresource allocations in networks via variants and generalizations of path\ncoalitional games. In these games, a coalition of edges or vertices is\nsuccessful if it can enable an s-t path. We present polynomial-time algorithms\nto compute and verify least core payoffs of cost-based generalizations of path\ncoalitional games and their duals, thereby settling a number of open problems.\nThe least core payoffs of path coalitional games are completely characterized\nand a polynomial-time algorithm for computing the nucleolus of edge path\ncoalitional games on undirected series-parallel graphs is presented.", 
    "link": "http://arxiv.org/pdf/1103.3310v2", 
    "arxiv-id": "1103.3310v2"
},{
    "category": "cs.GT", 
    "author": "Tat-Ming Lok", 
    "title": "Learning Equilibrium Play for Stochastic Parallel Gaussian Interference   Channels", 
    "publish": "2011-03-19T14:24:13Z", 
    "summary": "Distributed power control for parallel Gaussian interference channels\nrecently draws great interests. However, all existing works only studied this\nproblem under deterministic communication channels and required certain perfect\ninformation to carry out their proposed algorithms. In this paper, we study\nthis problem for stochastic parallel Gaussian interference channels. In\nparticular, we take into account the randomness of the communication\nenvironment and the estimation errors of the desired information, and thus\nformulate a stochastic noncooperative power control game. We then propose a\nstochastic distributed learning algorithm SDLA-I to help communication pairs\nlearn the Nash equilibrium. A careful convergence analysis on SDLA-I is\nprovided based on stochastic approximation theory and projected dynamic systems\napproach. We further propose another learning algorithm SDLA-II by including a\nsimple iterate averaging idea into SDLA-I to improve algorithmic convergence\nperformance. Numerical results are also presented to demonstrate the\nperformance of our algorithms and theoretical results.", 
    "link": "http://arxiv.org/pdf/1103.3782v1", 
    "arxiv-id": "1103.3782v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Non-Price Equilibria in Markets of Discrete Goods", 
    "publish": "2011-03-21T10:00:56Z", 
    "summary": "We study markets of indivisible items in which price-based (Walrasian)\nequilibria often do not exist due to the discrete non-convex setting. Instead\nwe consider Nash equilibria of the market viewed as a game, where players bid\nfor items, and where the highest bidder on an item wins it and pays his bid. We\nfirst observe that pure Nash-equilibria of this game excatly correspond to\nprice-based equilibiria (and thus need not exist), but that mixed-Nash\nequilibria always do exist, and we analyze their structure in several simple\ncases where no price-based equilibrium exists. We also undertake an analysis of\nthe welfare properties of these equilibria showing that while pure equilibria\nare always perfectly efficient (\"first welfare theorem\"), mixed equilibria need\nnot be, and we provide upper and lower bounds on their amount of inefficiency.", 
    "link": "http://arxiv.org/pdf/1103.3950v1", 
    "arxiv-id": "1103.3950v1"
},{
    "category": "cs.GT", 
    "author": "Xiaotie Deng", 
    "title": "On Nash Dynamics of Matching Market Equilibria", 
    "publish": "2011-03-22T03:15:31Z", 
    "summary": "In this paper, we study the Nash dynamics of strategic interplays of n buyers\nin a matching market setup by a seller, the market maker. Taking the standard\nmarket equilibrium approach, upon receiving submitted bid vectors from the\nbuyers, the market maker will decide on a price vector to clear the market in\nsuch a way that each buyer is allocated an item for which he desires the most\n(a.k.a., a market equilibrium solution). While such equilibrium outcomes are\nnot unique, the market maker chooses one (maxeq) that optimizes its own\nobjective --- revenue maximization. The buyers in turn change bids to their\nbest interests in order to obtain higher utilities in the next round's market\nequilibrium solution.\n  This is an (n+1)-person game where buyers place strategic bids to gain the\nmost from the market maker's equilibrium mechanism. The incentives of buyers in\ndeciding their bids and the market maker's choice of using the maxeq mechanism\ncreate a wave of Nash dynamics involved in the market. We characterize Nash\nequilibria in the dynamics in terms of the relationship between maxeq and mineq\n(i.e., minimum revenue equilibrium), and develop convergence results for Nash\ndynamics from the maxeq policy to a mineq solution, resulting an outcome\nequivalent to the truthful VCG mechanism.\n  Our results imply revenue equivalence between maxeq and mineq, and address\nthe question that why short-term revenue maximization is a poor long run\nstrategy, in a deterministic and dynamic setting.", 
    "link": "http://arxiv.org/pdf/1103.4196v1", 
    "arxiv-id": "1103.4196v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Robust Additively Coupled Games", 
    "publish": "2011-03-24T20:19:18Z", 
    "summary": "We study the robust Nash equilibrium (RNE) for a class of games in\ncommunications systems and networks where the impact of users on each other is\nan additive function of their strategies. Each user measures this impact, which\nmay be corrupted by uncertainty in feedback delays, estimation errors,\nmovements of users, etc. To study the outcome of the game in which such\nuncertainties are encountered, we utilize the worst-case robust optimization\ntheory. The existence and uniqueness conditions of RNE are derived using\nfinite-dimensions variational inequalities. To describe the effect of\nuncertainty on the performance of the system, we use two criteria measured at\nthe RNE and at the equilibrium of the game without uncertainty. The first is\nthe difference between the respective social utility of users and, the second\nis the differences between the strategies of users at their respective\nequilibria. These differences are obtained for the case of a unique NE and\nmultiple NEs. To reach the RNE, we propose a distributed algorithm based on the\nproximal response map and derive the conditions for its convergence.\nSimulations of the power control game in interference channels, and Jackson\nnetworks validate our analysis.", 
    "link": "http://arxiv.org/pdf/1103.4868v3", 
    "arxiv-id": "1103.4868v3"
},{
    "category": "cs.GT", 
    "author": "Vissarion Fisikopoulos", 
    "title": "Study of the effect of cost policies in the convergence of selfish   strategies in Pure Nash Equilibria in Congestion Games", 
    "publish": "2011-03-25T19:57:07Z", 
    "summary": "In this work we study of competitive situations among users of a set of\nglobal resources. More precisely we study the effect of cost policies used by\nthese resources in the convergence time to a pure Nash equilibrium. The work is\ndivided in two parts. In the theoretical part we prove lower and upper bounds\non the convergence time for various cost policies. We then implement all the\nmodels we study and provide some experimental results. These results follows\nthe theoretical with one exception which is the most interesting among the\nexperiments. In the case of coalitional users the theoretical upper bound is\npseudo-polynomial to the number of users but the experimental results shows\nthat the convergence time is polynomial.", 
    "link": "http://arxiv.org/pdf/1103.5071v1", 
    "arxiv-id": "1103.5071v1"
},{
    "category": "cs.GT", 
    "author": "David H. Wolpert", 
    "title": "Game theoretic modeling of pilot behavior during mid-air encounters", 
    "publish": "2011-03-26T21:52:52Z", 
    "summary": "We show how to combine Bayes nets and game theory to predict the behavior of\nhybrid systems involving both humans and automated components. We call this\nnovel framework \"Semi Network-Form Games,\" and illustrate it by predicting\naircraft pilot behavior in potential near mid-air collisions. At present, at\nthe beginning of such potential collisions, a collision avoidance system in the\naircraft cockpit advises the pilots what to do to avoid the collision. However\nstudies of mid-air encounters have found wide variability in pilot responses to\navoidance system advisories. In particular, pilots rarely perfectly execute the\nrecommended maneuvers, despite the fact that the collision avoidance system's\neffectiveness relies on their doing so. Rather pilots decide their actions\nbased on all information available to them (advisory, instrument readings,\nvisual observations). We show how to build this aspect into a semi network-form\ngame model of the encounter and then present computational simulations of the\nresultant model.", 
    "link": "http://arxiv.org/pdf/1103.5169v2", 
    "arxiv-id": "1103.5169v2"
},{
    "category": "cs.GT", 
    "author": "J. Andrew Bagnell", 
    "title": "Computational Rationalization: The Inverse Equilibrium Problem", 
    "publish": "2011-03-27T22:13:15Z", 
    "summary": "Modeling the purposeful behavior of imperfect agents from a small number of\nobservations is a challenging task. When restricted to the single-agent\ndecision-theoretic setting, inverse optimal control techniques assume that\nobserved behavior is an approximately optimal solution to an unknown decision\nproblem. These techniques learn a utility function that explains the example\nbehavior and can then be used to accurately predict or imitate future behavior\nin similar observed or unobserved situations.\n  In this work, we consider similar tasks in competitive and cooperative\nmulti-agent domains. Here, unlike single-agent settings, a player cannot\nmyopically maximize its reward --- it must speculate on how the other agents\nmay act to influence the game's outcome. Employing the game-theoretic notion of\nregret and the principle of maximum entropy, we introduce a technique for\npredicting and generalizing behavior, as well as recovering a reward function\nin these domains.", 
    "link": "http://arxiv.org/pdf/1103.5254v3", 
    "arxiv-id": "1103.5254v3"
},{
    "category": "cs.GT", 
    "author": "Azarakhsh Malekian", 
    "title": "Bayesian Mechanism Design for Budget-Constrained Agents", 
    "publish": "2011-03-31T19:46:25Z", 
    "summary": "We study Bayesian mechanism design problems in settings where agents have\nbudgets. Specifically, an agent's utility for an outcome is given by his value\nfor the outcome minus any payment he makes to the mechanism, as long as the\npayment is below his budget, and is negative infinity otherwise. This\ndiscontinuity in the utility function presents a significant challenge in the\ndesign of good mechanisms, and classical \"unconstrained\" mechanisms fail to\nwork in settings with budgets. The goal of this paper is to develop general\nreductions from budget-constrained Bayesian MD to unconstrained Bayesian MD\nwith small loss in performance. We consider this question in the context of the\ntwo most well-studied objectives in mechanism design---social welfare and\nrevenue---and present constant factor approximations in a number of settings.\nSome of our results extend to settings where budgets are private and agents\nneed to be incentivized to reveal them truthfully.", 
    "link": "http://arxiv.org/pdf/1103.6280v1", 
    "arxiv-id": "1103.6280v1"
},{
    "category": "cs.GT", 
    "author": "Maria D. Di Benedetto", 
    "title": "Hide-and-Seek with Directional Sensing", 
    "publish": "2011-04-07T08:26:36Z", 
    "summary": "We consider a game played between a hider, who hides a static object in one\nof several possible positions in a bounded planar region, and a searcher, who\nwishes to reach the object by querying sensors placed in the plane. The\nsearcher is a mobile agent, and whenever it physically visits a sensor, the\nsensor returns a random direction, corresponding to a half-plane in which the\nhidden object is located. We first present a novel search heuristic and\ncharacterize bounds on the expected distance covered before reaching the\nobject. Next, we model this game as a large-dimensional zero-sum dynamic game\nand we apply a recently introduced randomized sampling technique that provides\na probabilistic level of security to the hider. We observe that, when the\nrandomized sampling approach is only allowed to select a very small number of\nsamples, the cost of the heuristic is comparable to the security level provided\nby the randomized procedure. However, as we allow the number of samples to\nincrease, the randomized procedure provides a higher probabilistic security\nlevel.", 
    "link": "http://arxiv.org/pdf/1104.1268v1", 
    "arxiv-id": "1104.1268v1"
},{
    "category": "cs.GT", 
    "author": "Laurent Doyen", 
    "title": "Energy and Mean-Payoff Parity Markov Decision Processes", 
    "publish": "2011-04-14T20:07:20Z", 
    "summary": "We consider Markov Decision Processes (MDPs) with mean-payoff parity and\nenergy parity objectives. In system design, the parity objective is used to\nencode \\omega-regular specifications, and the mean-payoff and energy objectives\ncan be used to model quantitative resource constraints. The energy condition\nrequires that the resource level never drops below 0, and the mean-payoff\ncondition requires that the limit-average value of the resource consumption is\nwithin a threshold. While these two (energy and mean-payoff) classical\nconditions are equivalent for two-player games, we show that they differ for\nMDPs. We show that the problem of deciding whether a state is almost-sure\nwinning (i.e., winning with probability 1) in energy parity MDPs is in NP \\cap\ncoNP, while for mean-payoff parity MDPs, the problem is solvable in polynomial\ntime, improving a recent PSPACE bound.", 
    "link": "http://arxiv.org/pdf/1104.2909v1", 
    "arxiv-id": "1104.2909v1"
},{
    "category": "cs.GT", 
    "author": "Sanjeev Khanna", 
    "title": "Social Welfare in One-sided Matching Markets without Money", 
    "publish": "2011-04-15T03:47:44Z", 
    "summary": "We study social welfare in one-sided matching markets where the goal is to\nefficiently allocate n items to n agents that each have a complete, private\npreference list and a unit demand over the items. Our focus is on allocation\nmechanisms that do not involve any monetary payments. We consider two natural\nmeasures of social welfare: the ordinal welfare factor which measures the\nnumber of agents that are at least as happy as in some unknown, arbitrary\nbenchmark allocation, and the linear welfare factor which assumes an agent's\nutility linearly decreases down his preference lists, and measures the total\nutility to that achieved by an optimal allocation. We analyze two matching\nmechanisms which have been extensively studied by economists. The first\nmechanism is the random serial dictatorship (RSD) where agents are ordered in\naccordance with a randomly chosen permutation, and are successively allocated\ntheir best choice among the unallocated items. The second mechanism is the\nprobabilistic serial (PS) mechanism of Bogomolnaia and Moulin [8], which\ncomputes a fractional allocation that can be expressed as a convex combination\nof integral allocations. The welfare factor of a mechanism is the infimum over\nall instances. For RSD, we show that the ordinal welfare factor is\nasymptotically 1/2, while the linear welfare factor lies in the interval [.526,\n2/3]. For PS, we show that the ordinal welfare factor is also 1/2 while the\nlinear welfare factor is roughly 2/3. To our knowledge, these results are the\nfirst non-trivial performance guarantees for these natural mechanisms.", 
    "link": "http://arxiv.org/pdf/1104.2964v1", 
    "arxiv-id": "1104.2964v1"
},{
    "category": "cs.GT", 
    "author": "Rohit Singh", 
    "title": "On Memoryless Quantitative Objectives", 
    "publish": "2011-04-16T08:41:36Z", 
    "summary": "In two-player games on graph, the players construct an infinite path through\nthe game graph and get a reward computed by a payoff function over infinite\npaths. Over weighted graphs, the typical and most studied payoff functions\ncompute the limit-average or the discounted sum of the rewards along the path.\nBeside their simple definition, these two payoff functions enjoy the property\nthat memoryless optimal strategies always exist.\n  In an attempt to construct other simple payoff functions, we define a class\nof payoff functions which compute an (infinite) weighted average of the\nrewards. This new class contains both the limit-average and discounted sum\nfunctions, and we show that they are the only members of this class which\ninduce memoryless optimal strategies, showing that there is essentially no\nother simple payoff functions.", 
    "link": "http://arxiv.org/pdf/1104.3211v1", 
    "arxiv-id": "1104.3211v1"
},{
    "category": "cs.GT", 
    "author": "Nisarg Shah", 
    "title": "Symbolic Algorithms for Qualitative Analysis of Markov Decision   Processes with B\u00fcchi Objectives", 
    "publish": "2011-04-17T20:47:42Z", 
    "summary": "We consider Markov decision processes (MDPs) with \\omega-regular\nspecifications given as parity objectives. We consider the problem of computing\nthe set of almost-sure winning states from where the objective can be ensured\nwith probability 1. The algorithms for the computation of the almost-sure\nwinning set for parity objectives iteratively use the solutions for the\nalmost-sure winning set for B\\\"uchi objectives (a special case of parity\nobjectives). Our contributions are as follows: First, we present the first\nsubquadratic symbolic algorithm to compute the almost-sure winning set for MDPs\nwith B\\\"uchi objectives; our algorithm takes O(n \\sqrt{m}) symbolic steps as\ncompared to the previous known algorithm that takes O(n^2) symbolic steps,\nwhere $n$ is the number of states and $m$ is the number of edges of the MDP. In\npractice MDPs have constant out-degree, and then our symbolic algorithm takes\nO(n \\sqrt{n}) symbolic steps, as compared to the previous known $O(n^2)$\nsymbolic steps algorithm. Second, we present a new algorithm, namely win-lose\nalgorithm, with the following two properties: (a) the algorithm iteratively\ncomputes subsets of the almost-sure winning set and its complement, as compared\nto all previous algorithms that discover the almost-sure winning set upon\ntermination; and (b) requires O(n \\sqrt{K}) symbolic steps, where K is the\nmaximal number of edges of strongly connected components (scc's) of the MDP.\nThe win-lose algorithm requires symbolic computation of scc's. Third, we\nimprove the algorithm for symbolic scc computation; the previous known\nalgorithm takes linear symbolic steps, and our new algorithm improves the\nconstants associated with the linear number of steps. In the worst case the\nprevious known algorithm takes 5n symbolic steps, whereas our new algorithm\ntakes 4n symbolic steps.", 
    "link": "http://arxiv.org/pdf/1104.3348v2", 
    "arxiv-id": "1104.3348v2"
},{
    "category": "cs.GT", 
    "author": "Anton\u00edn Ku\u010dera", 
    "title": "Markov Decision Processes with Multiple Long-run Average Objectives", 
    "publish": "2011-04-18T14:12:46Z", 
    "summary": "We study Markov decision processes (MDPs) with multiple limit-average (or\nmean-payoff) functions. We consider two different objectives, namely,\nexpectation and satisfaction objectives. Given an MDP with k limit-average\nfunctions, in the expectation objective the goal is to maximize the expected\nlimit-average value, and in the satisfaction objective the goal is to maximize\nthe probability of runs such that the limit-average value stays above a given\nvector. We show that under the expectation objective, in contrast to the case\nof one limit-average function, both randomization and memory are necessary for\nstrategies even for epsilon-approximation, and that finite-memory randomized\nstrategies are sufficient for achieving Pareto optimal values. Under the\nsatisfaction objective, in contrast to the case of one limit-average function,\ninfinite memory is necessary for strategies achieving a specific value (i.e.\nrandomized finite-memory strategies are not sufficient), whereas memoryless\nrandomized strategies are sufficient for epsilon-approximation, for all\nepsilon>0. We further prove that the decision problems for both expectation and\nsatisfaction objectives can be solved in polynomial time and the trade-off\ncurve (Pareto curve) can be epsilon-approximated in time polynomial in the size\nof the MDP and 1/epsilon, and exponential in the number of limit-average\nfunctions, for all epsilon>0. Our analysis also reveals flaws in previous work\nfor MDPs with multiple mean-payoff functions under the expectation objective,\ncorrects the flaws, and allows us to obtain improved results.", 
    "link": "http://arxiv.org/pdf/1104.3489v3", 
    "arxiv-id": "1104.3489v3"
},{
    "category": "cs.GT", 
    "author": "Shuguang Cui", 
    "title": "Noncooperative Games for Autonomous Consumer Load Balancing over Smart   Grid", 
    "publish": "2011-04-19T16:56:45Z", 
    "summary": "Traditionally, most consumers of electricity pay for their consumptions\naccording to a fixed rate. With the advancement of Smart Grid technologies,\nlarge-scale implementation of variable-rate metering becomes more practical. As\na result, consumers will be able to control their electricity consumption in an\nautomated fashion, where one possible scheme is to have each individual\nmaximize its own utility as a noncooperative game. In this paper,\nnoncooperative games are formulated among the electricity consumers in Smart\nGrid with two real-time pricing schemes, where the Nash equilibrium operation\npoints are investigated for their uniqueness and load balancing properties. The\nfirst pricing scheme charges a price according to the average cost of\nelectricity borne by the retailer and the second one charges according to a\ntime-variant increasing-block price, where for each scheme, a zero-revenue\nmodel and a constant-rate revenue model are considered. In addition, the\nrelationship between the studied games and certain competitive routing games\nfrom the computer networking community, known as atomic flow games, is\nestablished, for which it is shown that the proposed noncooperative game\nformulation falls under the class of atomic splittable flow games. The Nash\nequilibrium is shown to exist for four different combined cases corresponding\nto the two pricing schemes and the two revenue models, and is unique for three\nof the cases under certain conditions. It is further shown that both pricing\nschemes lead to similar electricity loading patterns when consumers are only\ninterested in minimizing the electricity costs without any other profit\nconsiderations. Finally, the conditions under which the increasing-block\npricing scheme is preferred over the average-cost based pricing scheme are\ndiscussed.", 
    "link": "http://arxiv.org/pdf/1104.3802v3", 
    "arxiv-id": "1104.3802v3"
},{
    "category": "cs.GT", 
    "author": "Anton\u00edn Ku\u010dera", 
    "title": "Approximating the Termination Value of One-Counter MDPs and Stochastic   Games", 
    "publish": "2011-04-26T17:42:51Z", 
    "summary": "One-counter MDPs (OC-MDPs) and one-counter simple stochastic games (OC-SSGs)\nare 1-player, and 2-player turn-based zero-sum, stochastic games played on the\ntransition graph of classic one-counter automata (equivalently, pushdown\nautomata with a 1-letter stack alphabet). A key objective for the analysis and\nverification of these games is the termination objective, where the players aim\nto maximize (minimize, respectively) the probability of hitting counter value\n0, starting at a given control state and given counter value. Recently, we\nstudied qualitative decision problems (\"is the optimal termination value = 1?\")\nfor OC-MDPs (and OC-SSGs) and showed them to be decidable in P-time (in NP and\ncoNP, respectively). However, quantitative decision and approximation problems\n(\"is the optimal termination value ? p\", or \"approximate the termination value\nwithin epsilon\") are far more challenging. This is so in part because optimal\nstrategies may not exist, and because even when they do exist they can have a\nhighly non-trivial structure. It thus remained open even whether any of these\nquantitative termination problems are computable. In this paper we show that\nall quantitative approximation problems for the termination value for OC-MDPs\nand OC-SSGs are computable. Specifically, given a OC-SSG, and given epsilon >\n0, we can compute a value v that approximates the value of the OC-SSG\ntermination game within additive error epsilon, and furthermore we can compute\nepsilon-optimal strategies for both players in the game. A key ingredient in\nour proofs is a subtle martingale, derived from solving certain LPs that we can\nassociate with a maximizing OC-MDP. An application of Azuma's inequality on\nthese martingales yields a computable bound for the \"wealth\" at which a \"rich\nperson's strategy\" becomes epsilon-optimal for OC-MDPs.", 
    "link": "http://arxiv.org/pdf/1104.4978v2", 
    "arxiv-id": "1104.4978v2"
},{
    "category": "cs.GT", 
    "author": "Rustam Tagiew", 
    "title": "If more than Analytical Modeling is Needed to Predict Real Agents'   Strategic Interaction", 
    "publish": "2011-05-03T11:43:36Z", 
    "summary": "This paper presents the research on the interdisciplinary research\ninfrastructure for understanding human reasoning in game-theoretic terms.\nStrategic reasoning is considered to impact human decision making in social,\neconomical and competitive interactions. The provided introduction explains and\nconnects concepts from AI, game theory and psychology. First result is a\nconcept of interdisciplinary game description language as a part of the focused\ninterdisciplinary research infrastructure. The need of this domain-specific\nlanguage is motivated and is aimed to accelerate the current developments. As\nsecond result, the paper provides a summary of ongoing research and its\nsignificance.", 
    "link": "http://arxiv.org/pdf/1105.0558v1", 
    "arxiv-id": "1105.0558v1"
},{
    "category": "cs.GT", 
    "author": "Evangelia Pyrga", 
    "title": "Individual-based stability in hedonic games depending on the best or   worst players", 
    "publish": "2011-05-09T23:51:47Z", 
    "summary": "We consider coalition formation games in which each player has preferences\nover the other players and his preferences over coalitions are based on the\nbest player ($\\mathcal{B}$-/B-hedonic games) or the worst player\n($\\mathcal{W}$/W-hedonic games) in the coalition. We show that for\n$\\mathcal{B}$-hedonic games, an individually stable partition is guaranteed to\nexist and can be computed efficiently. Similarly, there exists a\npolynomial-time algorithm which returns a Nash stable partition (if one exists)\nfor $\\mathcal{B}$-hedonic games with strict preferences. Both $\\mathcal{W}$-\nand W-hedonic games are equivalent if individual rationality is assumed. It is\nalso shown that for B- or $\\mathcal{W}$-hedonic games, checking whether a Nash\nstable partition or an individually stable partition exists is NP-complete even\nin some cases for strict preferences. We identify a key source of\nintractability in compact coalition formation games in which preferences over\nplayers are extended to preferences over coalitions.", 
    "link": "http://arxiv.org/pdf/1105.1824v2", 
    "arxiv-id": "1105.1824v2"
},{
    "category": "cs.GT", 
    "author": "Oskar Skibski", 
    "title": "Steady Marginality: A Uniform Approach to Shapley Value for Games with   Externalities", 
    "publish": "2011-05-11T15:48:21Z", 
    "summary": "The Shapley value is one of the most important solution concepts in\ncooperative game theory. In coalitional games without externalities, it allows\nto compute a unique payoff division that meets certain desirable fairness\naxioms. However, in many realistic applications where externalities are\npresent, Shapley's axioms fail to indicate such a unique division.\nConsequently, there are many extensions of Shapley value to the environment\nwith externalities proposed in the literature built upon additional axioms. Two\nimportant such extensions are \"externality-free\" value by Pham Do and Norde and\nvalue that \"absorbed all externalities\" by McQuillin. They are good reference\npoints in a space of potential payoff divisions for coalitional games with\nexternalities as they limit the space at two opposite extremes. In a recent,\nimportant publication, De Clippel and Serrano presented a marginality-based\naxiomatization of the value by Pham Do Norde. In this paper, we propose a dual\napproach to marginality which allows us to derive the value of McQuillin. Thus,\nwe close the picture outlined by De Clippel and Serrano.", 
    "link": "http://arxiv.org/pdf/1105.2225v1", 
    "arxiv-id": "1105.2225v1"
},{
    "category": "cs.GT", 
    "author": "Guido Schaefer", 
    "title": "Selfishness Level of Strategic Games", 
    "publish": "2011-05-12T11:38:21Z", 
    "summary": "We introduce a new measure of the discrepancy in strategic games between the\nsocial welfare in a Nash equilibrium and in a social optimum, that we call\nselfishness level. It is the smallest fraction of the social welfare that needs\nto be offered to each player to achieve that a social optimum is realized in a\npure Nash equilibrium. The selfishness level is unrelated to the price of\nstability and the price of anarchy and is invariant under positive linear\ntransformations of the payoff functions. Also, it naturally applies to other\nsolution concepts and other forms of games.\n  We study the selfishness level of several well-known strategic games. This\nallows us to quantify the implicit tension within a game between players'\nindividual interests and the impact of their decisions on the society as a\nwhole. Our analyses reveal that the selfishness level often provides a deeper\nunderstanding of the characteristics of the underlying game that influence the\nplayers' willingness to cooperate.\n  In particular, the selfishness level of finite ordinal potential games is\nfinite, while that of weakly acyclic games can be infinite. We derive explicit\nbounds on the selfishness level of fair cost sharing games and linear\ncongestion games, which depend on specific parameters of the underlying game\nbut are independent of the number of players. Further, we show that the\nselfishness level of the $n$-players Prisoner's Dilemma is $c/(b(n-1)-c)$,\nwhere $b$ and $c$ are the benefit and cost for cooperation, respectively, that\nof the $n$-players public goods game is $(1-\\frac{c}{n})/(c-1)$, where $c$ is\nthe public good multiplier, and that of the Traveler's Dilemma game is\n$\\frac{1}{2}(b-1)$, where $b$ is the bonus. Finally, the selfishness level of\nCournot competition (an example of an infinite ordinal potential game, Tragedy\nof the Commons, and Bertrand competition is infinite.", 
    "link": "http://arxiv.org/pdf/1105.2432v7", 
    "arxiv-id": "1105.2432v7"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Stability Scores: Measuring Coalitional Stability", 
    "publish": "2011-05-30T13:16:15Z", 
    "summary": "We introduce a measure for the level of stability against coalitional\ndeviations, called \\emph{stability scores}, which generalizes widely used\nnotions of stability in non-cooperative games. We use the proposed measure to\ncompare various Nash equilibria in congestion games, and to quantify the effect\nof game parameters on coalitional stability. For our main results, we apply\nstability scores to analyze and compare the Generalized Second Price (GSP) and\nVickrey-Clarke-Groves (VCG) ad auctions. We show that while a central result of\nthe ad auctions literature is that the GSP and VCG auctions implement the same\noutcome in one of the equilibria of GSP, the GSP outcome is far more stable.\nFinally, a modified version of VCG is introduced, which is group\nstrategy-proof, and thereby achieves the highest possible stability score.", 
    "link": "http://arxiv.org/pdf/1105.5983v2", 
    "arxiv-id": "1105.5983v2"
},{
    "category": "cs.GT", 
    "author": "Oliver Friedmann", 
    "title": "An Exponential Lower Bound for the Latest Deterministic Strategy   Iteration Algorithms", 
    "publish": "2011-06-03T23:39:24Z", 
    "summary": "This paper presents a new exponential lower bound for the two most popular\ndeterministic variants of the strategy improvement algorithms for solving\nparity, mean payoff, discounted payoff and simple stochastic games. The first\nvariant improves every node in each step maximizing the current valuation\nlocally, whereas the second variant computes the globally optimal improvement\nin each step. We outline families of games on which both variants require\nexponentially many strategy iterations.", 
    "link": "http://arxiv.org/pdf/1106.0778v2", 
    "arxiv-id": "1106.0778v2"
},{
    "category": "cs.GT", 
    "author": "Saeed Alaei", 
    "title": "Bayesian Combinatorial Auctions: Expanding Single Buyer Mechanisms to   Many Buyers", 
    "publish": "2011-06-06T05:38:00Z", 
    "summary": "For Bayesian combinatorial auctions, we present a general framework for\napproximately reducing the mechanism design problem for multiple buyers to\nsingle buyer sub-problems. Our framework can be applied to any setting which\nroughly satisfies the following assumptions: (i) buyers' types must be\ndistributed independently (not necessarily identically), (ii) objective\nfunction must be linearly separable over the buyers, and (iii) except for the\nsupply constraints, there should be no other inter-buyer constraints. Our\nframework is general in the sense that it makes no explicit assumption about\nbuyers' valuations, type distributions, and single buyer constraints (e.g.,\nbudget, incentive compatibility, etc).\n  We present two generic multi buyer mechanisms which use single buyer\nmechanisms as black boxes; if an $\\alpha$-approximate single buyer mechanism\ncan be constructed for each buyer, and if no buyer requires more than\n$\\frac{1}{k}$ of all units of each item, then our generic multi buyer\nmechanisms are $\\gamma_k\\alpha$-approximation of the optimal multi buyer\nmechanism, where $\\gamma_k$ is a constant which is at least\n$1-\\frac{1}{\\sqrt{k+3}}$. Observe that $\\gamma_k$ is at least 1/2 (for $k=1$)\nand approaches 1 as $k \\to \\infty$. As a byproduct of our construction, we\npresent a generalization of prophet inequalities. Furthermore, as applications\nof our framework, we present multi buyer mechanisms with improved approximation\nfactor for several settings from the literature.", 
    "link": "http://arxiv.org/pdf/1106.0961v4", 
    "arxiv-id": "1106.0961v4"
},{
    "category": "cs.GT", 
    "author": "Nathana\u00ebl Fijalkow", 
    "title": "A reduction from parity games to simple stochastic games", 
    "publish": "2011-06-07T01:06:10Z", 
    "summary": "Games on graphs provide a natural model for reactive non-terminating systems.\nIn such games, the interaction of two players on an arena results in an\ninfinite path that describes a run of the system. Different settings are used\nto model various open systems in computer science, as for instance turn-based\nor concurrent moves, and deterministic or stochastic transitions. In this\npaper, we are interested in turn-based games, and specifically in deterministic\nparity games and stochastic reachability games (also known as simple stochastic\ngames). We present a simple, direct and efficient reduction from deterministic\nparity games to simple stochastic games: it yields an arena whose size is\nlinear up to a logarithmic factor in size of the original arena.", 
    "link": "http://arxiv.org/pdf/1106.1232v1", 
    "arxiv-id": "1106.1232v1"
},{
    "category": "cs.GT", 
    "author": "Laura Bozzelli", 
    "title": "Opacity Issues in Games with Imperfect Information", 
    "publish": "2011-06-07T01:06:17Z", 
    "summary": "We study in depth the class of games with opacity condition, which are\ntwo-player games with imperfect information in which one of the players only\nhas imperfect information, and where the winning condition relies on the\ninformation he has along the play. Those games are relevant for security\naspects of computing systems: a play is opaque whenever the player who has\nimperfect information never \"knows\" for sure that the current position is one\nof the distinguished \"secret\" positions. We study the problems of deciding the\nexistence of a winning strategy for each player, and we call them the\nopacity-violate problem and the opacity-guarantee problem. Focusing on the\nplayer with perfect information is new in the field of games with\nimperfect-information because when considering classical winning conditions it\namounts to solving the underlying perfect-information game. We establish the\nEXPTIME-completeness of both above-mentioned problems, showing that our winning\ncondition brings a gap of complexity for the player with perfect information,\nand we exhibit the relevant opacity-verify problem, which noticeably\ngeneralizes approaches considered in the literature for opacity analysis in\ndiscrete-event systems. In the case of blindfold games, this problem relates to\nthe two initial ones, yielding the determinacy of blindfold games with opacity\ncondition and the PSPACE-completeness of the three problems.", 
    "link": "http://arxiv.org/pdf/1106.1233v1", 
    "arxiv-id": "1106.1233v1"
},{
    "category": "cs.GT", 
    "author": "M\u00e9rouane Debbah", 
    "title": "On the Nash Equilibria in Decentralized Parallel Interference Channels", 
    "publish": "2011-06-14T09:38:51Z", 
    "summary": "In this paper, the 2-dimensional decentralized parallel interference channel\n(IC) with 2 transmitter-receiver pairs is modelled as a non-cooperative static\ngame. Each transmitter is assumed to be a fully rational entity with complete\ninformation on the game, aiming to maximize its own individual spectral\nefficiency by tuning its own power allocation (PA) vector. Two scenarios are\nanalysed. First, we consider that transmitters can split their transmit power\nbetween both dimensions (PA game). Second, we consider that each transmitter is\nlimited to use only one dimension (channel selection CS game). In the first\nscenario, the game might have either one or three NE in pure strategies (PS).\nHowever, two or infinitely many NE in PS might also be observed with zero\nprobability. In the second scenario, there always exists either one or two NE\nin PS. We show that in both games there always exists a non-zero probability of\nobserving more than one NE. More interestingly, using Monte-Carlo simulations,\nwe show that the highest and lowest network spectral efficiency at any of the\nNE in the CS game are always higher than the ones in the PA.", 
    "link": "http://arxiv.org/pdf/1106.2650v1", 
    "arxiv-id": "1106.2650v1"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "I Don't Want to Think About it Now:Decision Theory With Costly   Computation", 
    "publish": "2011-06-14T09:52:38Z", 
    "summary": "Computation plays a major role in decision making. Even if an agent is\nwilling to ascribe a probability to all states and a utility to all outcomes,\nand maximize expected utility, doing so might present serious computational\nproblems. Moreover, computing the outcome of a given act might be difficult. In\na companion paper we develop a framework for game theory with costly\ncomputation, where the objects of choice are Turing machines. Here we apply\nthat framework to decision theory. We show how well-known phenomena like\nfirst-impression-matters biases (i.e., people tend to put more weight on\nevidence they hear early on), belief polarization (two people with different\nprior beliefs, hearing the same evidence, can end up with diametrically opposed\nconclusions), and the status quo bias (people are much more likely to stick\nwith what they already have) can be easily captured in that framework. Finally,\nwe use the framework to define some new notions: value of computational\ninformation (a computational variant of value of information) and and\ncomputational value of conversation.", 
    "link": "http://arxiv.org/pdf/1106.2657v1", 
    "arxiv-id": "1106.2657v1"
},{
    "category": "cs.GT", 
    "author": "Valerio Capraro", 
    "title": "Solution of Wald's game using loadings and allowed strategies", 
    "publish": "2011-06-18T19:04:32Z", 
    "summary": "We propose a new interpretation of the strange phenomena that some authors\nhave observed about the Wald game. This interpretation is possible thanks to\nthe new language of \\emph{loadings} that Morrison and the author have\nintroduced in a previous work. Using the theory of loadings and allowed\nstrategies, we are also able to prove that Wald's game admits a \\emph{natural}\nsolution and, as one can expect, the game turns out to be fair for this\nsolution. As a technical tool, we introduce the notion of \\emph{embedding a\ngame into another game} that could be of interest from a theoretical point of\nview. \\emph{En passant} we find a very easy example of a game which is loadable\nin infinitely many different ways.", 
    "link": "http://arxiv.org/pdf/1106.3679v2", 
    "arxiv-id": "1106.3679v2"
},{
    "category": "cs.GT", 
    "author": "Ahmad R. Sharafat", 
    "title": "Opportunistic Power Control for Multi-Carrier Interference Channels", 
    "publish": "2011-06-26T15:44:45Z", 
    "summary": "We propose a new method for opportunistic power control in multi-carrier\ninterference channels for delay-tolerant data services. In doing so, we utilize\na game theoretic framework with novel constraints, where each user tries to\nmaximize its utility in a distributed and opportunistic manner, while\nsatisfying the game's constraints by adapting its transmit power to its\nchannel. In this scheme, users transmit with more power on good sub-channels\nand do the opposite on bad sub-channels. In this way, in addition to the\nallocated power on each sub-channel, the total power of all users also depends\non channel conditions. Since each user's power level depends on power levels of\nother users, the game belongs to the \\emph{generalized} Nash equilibrium (GNE)\nproblems, which in general, is hard to analyze. We show that the proposed game\nhas a GNE, and derive the sufficient conditions for its uniqueness. Besides, we\npropose a new pricing scheme for maximizing each user's throughput in an\nopportunistic manner under its total power constraint; and provide the\nsufficient conditions for the algorithm's convergence and its GNE's uniqueness.\nSimulations confirm that our proposed scheme yields a higher throughput for\neach user and/or has a significantly improved efficiency as compared to other\nexisting opportunistic methods.", 
    "link": "http://arxiv.org/pdf/1106.5230v1", 
    "arxiv-id": "1106.5230v1"
},{
    "category": "cs.GT", 
    "author": "Ahmad R. Sharafat", 
    "title": "Efficient and Distributed SINR-based Joint Resource Allocation and Base   Station Assignment in Wireless CDMA Networks", 
    "publish": "2011-06-27T08:17:40Z", 
    "summary": "We formulate the resource allocation problem for the uplink of code division\nmultiple access (CDMA) networks using a game theoretic framework, propose an\nefficient and distributed algorithm for a joint rate and power allocation, and\nshow that the proposed algorithm converges to the unique Nash equilibrium (NE)\nof the game. Our choice for the utility function enables each user to adapt its\ntransmit power and throughput to its channel. Due to users' selfish behavior,\nthe output of the game (its NE) may not be a desirable one. To avoid such\ncases, we use pricing to control each user's behavior, and analytically show\nthat similar to the no-pricing case, our pricing-based algorithm converges to\nthe unique NE of the game, at which, each user achieves its target\nsignal-to-interference-plus-noise ratio (SINR). We also extend our distributed\nresource allocation scheme to multi-cell environments for base station\nassignment. Simulation results confirm that our algorithm is computationally\nefficient and its signalling overhead is low. In particular, we will show that\nin addition to its ability to attain the required QoS of users, our scheme\nachieves better fairness in allocating resources and can significantly reduce\ntransmit power as compared to existing schemes.", 
    "link": "http://arxiv.org/pdf/1106.5326v1", 
    "arxiv-id": "1106.5326v1"
},{
    "category": "cs.GT", 
    "author": "N. Nisan", 
    "title": "Concurrent Auctions Across The Supply Chain", 
    "publish": "2011-06-30T20:34:24Z", 
    "summary": "With the recent technological feasibility of electronic commerce over the\nInternet, much attention has been given to the design of electronic markets for\nvarious types of electronically-tradable goods. Such markets, however, will\nnormally need to function in some relationship with markets for other related\ngoods, usually those downstream or upstream in the supply chain. Thus, for\nexample, an electronic market for rubber tires for trucks will likely need to\nbe strongly influenced by the rubber market as well as by the truck market. In\nthis paper we design protocols for exchange of information between a sequence\nof markets along a single supply chain. These protocols allow each of these\nmarkets to function separately, while the information exchanged ensures\nefficient global behavior across the supply chain. Each market that forms a\nlink in the supply chain operates as a double auction, where the bids on one\nside of the double auction come from bidders in the corresponding segment of\nthe industry, and the bids on the other side are synthetically generated by the\nprotocol to express the combined information from all other links in the chain.\nThe double auctions in each of the markets can be of several types, and we\nstudy several variants of incentive compatible double auctions, comparing them\nin terms of their efficiency and of the market revenue.", 
    "link": "http://arxiv.org/pdf/1107.0028v1", 
    "arxiv-id": "1107.0028v1"
},{
    "category": "cs.GT", 
    "author": "H. Reiju Mihara", 
    "title": "The second-price auction solves King Solomon's dilemma", 
    "publish": "2011-07-03T07:19:56Z", 
    "summary": "The planner wants to give k identical, indivisible objects to the top k\nvaluation agents at zero costs. Each agent knows her own valuation of the\nobject and whether it is among the top k. Modify the (k+1)st-price sealed-bid\nauction by introducing a small participation fee and the option not to\nparticipate in it. This simple mechanism implements the desired outcome in\niteratively undominated strategies. Moreover, no pair of agents can profitably\ndeviate from the equilibrium by coordinating their strategies or bribing each\nother.", 
    "link": "http://arxiv.org/pdf/1107.0433v1", 
    "arxiv-id": "1107.0433v1"
},{
    "category": "cs.GT", 
    "author": "Ioannis Caragiannis", 
    "title": "Efficient coordination mechanisms for unrelated machine scheduling", 
    "publish": "2011-07-09T20:13:28Z", 
    "summary": "We present new coordination mechanisms for scheduling selfish jobs on $m$\nunrelated machines. A coordination mechanism aims to mitigate the impact of\nselfishness of jobs on the efficiency of schedules by defining a local\nscheduling policy on each machine. The scheduling policies induce a game among\nthe jobs and each job prefers to be scheduled on a machine so that its\ncompletion time is minimum given the assignments of the other jobs. We consider\nthe maximum completion time among all jobs as the measure of the efficiency of\nschedules. The approximation ratio of a coordination mechanism quantifies the\nefficiency of pure Nash equilibria (price of anarchy) of the induced game.\n  Our mechanisms are deterministic, local, and preemptive. Our first\ncoordination mechanism has approximation ratio $\\Theta(\\log m)$ and guarantees\nthat the induced game has pure Nash equilibria. This result improves a bound of\n$O(\\log^2 m)$ due to Azar, Jain, and Mirrokni and uses a global ordering of the\njobs according to their distinct IDs. Our second mechanism handles anonymous\njobs and has approximation ratio $O(\\frac{\\log m}{\\log \\log m})$ although the\ngame induced is not a potential game and, hence, the existence of pure Nash\nequilibria is not guaranteed by potential function arguments. However, it\nprovides evidence that the known lower bounds for non-preemptive coordination\nmechanisms could be beaten using preemptive scheduling policies. Our third\ncoordination mechanism also handles anonymous jobs and has a nice\ncost-revealing potential function. We use this potential function in order to\nprove the existence of equilibria and to upper-bound the price of anarchy of\nthe induced game by $O(\\log^2m)$. Our third coordination mechanism is the first\nthat handles anonymous jobs and simultaneously guarantees that the induced game\nis a potential game and has bounded price of anarchy.", 
    "link": "http://arxiv.org/pdf/1107.1814v1", 
    "arxiv-id": "1107.1814v1"
},{
    "category": "cs.GT", 
    "author": "Krishnendu Chatterjee", 
    "title": "Robustness of Structurally Equivalent Concurrent Parity Games", 
    "publish": "2011-07-11T12:23:17Z", 
    "summary": "We consider two-player stochastic games played on a finite state space for an\ninfinite number of rounds. The games are concurrent: in each round, the two\nplayers (player 1 and player 2) choose their moves independently and\nsimultaneously; the current state and the two moves determine a probability\ndistribution over the successor states. We also consider the important special\ncase of turn-based stochastic games where players make moves in turns, rather\nthan concurrently. We study concurrent games with \\omega-regular winning\nconditions specified as parity objectives. The value for player 1 for a parity\nobjective is the maximal probability with which the player can guarantee the\nsatisfaction of the objective against all strategies of the opponent. We study\nthe problem of continuity and robustness of the value function in concurrent\nand turn-based stochastic parity gameswith respect to imprecision in the\ntransition probabilities. We present quantitative bounds on the difference of\nthe value function (in terms of the imprecision of the transition\nprobabilities) and show the value continuity for structurally equivalent\nconcurrent games (two games are structurally equivalent if the support of the\ntransition function is same and the probabilities differ). We also show\nrobustness of optimal strategies for structurally equivalent turn-based\nstochastic parity games. Finally we show that the value continuity property\nbreaks without the structurally equivalent assumption (even for Markov chains)\nand show that our quantitative bound is asymptotically optimal. Hence our\nresults are tight (the assumption is both necessary and sufficient) and optimal\n(our quantitative bound is asymptotically optimal).", 
    "link": "http://arxiv.org/pdf/1107.2009v2", 
    "arxiv-id": "1107.2009v2"
},{
    "category": "cs.GT", 
    "author": "Pritam Roy", 
    "title": "Magnifying Lens Abstraction for Stochastic Games with Discounted and   Long-run Average Objectives", 
    "publish": "2011-07-11T20:19:26Z", 
    "summary": "Turn-based stochastic games and its important subclass Markov decision\nprocesses (MDPs) provide models for systems with both probabilistic and\nnondeterministic behaviors. We consider turn-based stochastic games with two\nclassical quantitative objectives: discounted-sum and long-run average\nobjectives. The game models and the quantitative objectives are widely used in\nprobabilistic verification, planning, optimal inventory control, network\nprotocol and performance analysis. Games and MDPs that model realistic systems\noften have very large state spaces, and probabilistic abstraction techniques\nare necessary to handle the state-space explosion. The commonly used\nfull-abstraction techniques do not yield space-savings for systems that have\nmany states with similar value, but does not necessarily have similar\ntransition structure. A semi-abstraction technique, namely Magnifying-lens\nabstractions (MLA), that clusters states based on value only, disregarding\ndifferences in their transition relation was proposed for qualitative\nobjectives (reachability and safety objectives). In this paper we extend the\nMLA technique to solve stochastic games with discounted-sum and long-run\naverage objectives. We present the MLA technique based abstraction-refinement\nalgorithm for stochastic games and MDPs with discounted-sum objectives. For\nlong-run average objectives, our solution works for all MDPs and a sub-class of\nstochastic games where every state has the same value.", 
    "link": "http://arxiv.org/pdf/1107.2132v1", 
    "arxiv-id": "1107.2132v1"
},{
    "category": "cs.GT", 
    "author": "Laurent Doyen", 
    "title": "Partial-Observation Stochastic Games: How to Win when Belief Fails", 
    "publish": "2011-07-11T20:46:07Z", 
    "summary": "In two-player finite-state stochastic games of partial observation on graphs,\nin every state of the graph, the players simultaneously choose an action, and\ntheir joint actions determine a probability distribution over the successor\nstates. We consider reachability objectives where player 1 tries to ensure a\ntarget state to be visited almost-surely or positively. On the basis of\ninformation, the game can be one-sided with either (a)player 1 or (b)player 2\nhaving partial observation, or two-sided with both players having partial\nobservation. On the basis of randomization (a)players may not be allowed to use\nrandomization (pure strategies), or (b)may choose a probability distribution\nover actions but the actual random choice is not visible (actions invisible),\nor (c)may use full randomization. Our results for pure strategies are as\nfollows: (1)For one-sided games with player 2 perfect observation we show that\nbelief-based strategies are not sufficient, and present an exponential upper\nbound on memory both for almost-sure and positive winning strategies; we show\nthat the problem of deciding the existence of almost-sure and positive winning\nstrategies for player 1 is EXPTIME-complete and present symbolic algorithms\nthat avoid the explicit exponential construction. (2)For one-sided games with\nplayer 1 perfect observation we show that non-elementary memory is both\nnecessary and sufficient for both almost-sure and positive winning strategies.\n(3)We show that for the two-sided case finite memory strategies are sufficient\nfor both positive and almost-sure winning. We establish the equivalence of the\nalmost-sure winning problem for pure strategies with randomized strategies with\nactions invisible. Our equivalence result exhibit serious flaws in previous\nresults in the literature: we show a non-elementary memory lower bound for\nalmost-sure winning whereas an exponential upper bound was claimed.", 
    "link": "http://arxiv.org/pdf/1107.2141v1", 
    "arxiv-id": "1107.2141v1"
},{
    "category": "cs.GT", 
    "author": "Krishnendu Chatterjee", 
    "title": "Bounded Rationality in Concurrent Parity Games", 
    "publish": "2011-07-11T21:03:13Z", 
    "summary": "We consider 2-player games played on a finite state space for infinite\nrounds. The games are concurrent: in each round, the two players choose their\nmoves simultaneously; the current state and the moves determine the successor.\nWe consider omega-regular winning conditions given as parity objectives. We\nconsider the qualitative analysis problems: the computation of the almost-sure\nand limit-sure winning set of states, where player 1 can ensure to win with\nprobability 1 and with probability arbitrarily close to 1, respectively. In\ngeneral the almost-sure and limit-sure winning strategies require both\ninfinite-memory and infinite-precision. We study the bounded-rationality\nproblem for qualitative analysis of concurrent parity games, where the strategy\nset player 1 is restricted to bounded-resource strategies. In terms of\nprecision, strategies can be deterministic, uniform, finite-precision or\ninfinite-precision; and in terms of memory, strategies can be memoryless,\nfinite-memory or infinite-memory. We present a precise and complete\ncharacterization of the qualitative winning sets for all combinations of\nclasses of strategies. In particular, we show that uniform memoryless\nstrategies are as powerful as finite-precision infinite-memory strategies, and\ninfinite-precision memoryless strategies are as powerful as infinite-precision\nfinite-memory strategies. We show that the winning sets can be computed in\nO(n^{2d+3}) time, where n is the size of the game and 2d is the number of\npriorities, and our algorithms are symbolic. The membership problem of whether\na state belongs to a winning set can be decided in NP cap coNP. While this\ncomplexity is the same as for the simpler class of turn-based games, where in\neach state only one of the players has a choice of moves, our algorithms, that\nare obtained by characterization of the winning sets as mu-calculus formulas,\nare considerably more involved.", 
    "link": "http://arxiv.org/pdf/1107.2146v4", 
    "arxiv-id": "1107.2146v4"
},{
    "category": "cs.GT", 
    "author": "Alexander Skopalik", 
    "title": "Approximate Pure Nash Equilibria in Weighted Congestion Games:   Existence, Efficient Computation, and Structure", 
    "publish": "2011-07-12T11:21:16Z", 
    "summary": "We consider structural and algorithmic questions related to the Nash dynamics\nof weighted congestion games. In weighted congestion games with linear latency\nfunctions, the existence of (pure Nash) equilibria is guaranteed by potential\nfunction arguments. Unfortunately, this proof of existence is inefficient and\ncomputing equilibria is such games is a {\\sf PLS}-hard problem. The situation\ngets worse when superlinear latency functions come into play; in this case, the\nNash dynamics of the game may contain cycles and equilibria may not even exist.\nGiven these obstacles, we consider approximate equilibria as alternative\nsolution concepts. Do such equilibria exist? And if so, can we compute them\nefficiently?\n  We provide positive answers to both questions for weighted congestion games\nwith polynomial latency functions by exploiting an \"approximation\" of such\ngames by a new class of potential games that we call $\\Psi$-games. This allows\nus to show that these games have $d!$-approximate equilibria, where $d$ is the\nmaximum degree of the latency functions. Our main technical contribution is an\nefficient algorithm for computing O(1)-approximate equilibria when $d$ is a\nconstant. For games with linear latency functions, the approximation guarantee\nis $\\frac{3+\\sqrt{5}}{2}+O(\\gamma)$ for arbitrarily small $\\gamma>0$; for\nlatency functions with maximum degree $d\\geq 2$, it is $d^{2d+o(d)}$. The\nrunning time is polynomial in the number of bits in the representation of the\ngame and $1/\\gamma$. As a byproduct of our techniques, we also show the\nfollowing structural statement for weighted congestion games with polynomial\nlatency functions of maximum degree $d\\geq 2$: polynomially-long sequences of\nbest-response moves from any initial state to a $d^{O(d^2)}$-approximate\nequilibrium exist and can be efficiently identified in such games as long as\n$d$ is constant.", 
    "link": "http://arxiv.org/pdf/1107.2248v2", 
    "arxiv-id": "1107.2248v2"
},{
    "category": "cs.GT", 
    "author": "Zhenghui Wang", 
    "title": "Lower Bound for Envy-Free and Truthful Makespan Approximation on Related   Machines", 
    "publish": "2011-07-14T21:45:00Z", 
    "summary": "We study problems of scheduling jobs on related machines so as to minimize\nthe makespan in the setting where machines are strategic agents. In this\nproblem, each job $j$ has a length $l_{j}$ and each machine $i$ has a private\nspeed $t_{i}$. The running time of job $j$ on machine $i$ is $t_{i}l_{j}$. We\nseek a mechanism that obtains speed bids of machines and then assign jobs and\npayments to machines so that the machines have incentive to report true speeds\nand the allocation and payments are also envy-free. We show that\n  1. A deterministic envy-free, truthful, individually rational, and anonymous\nmechanism cannot approximate the makespan strictly better than $2-1/m$, where\n$m$ is the number of machines. This result contrasts with prior work giving a\ndeterministic PTAS for envy-free anonymous assignment and a distinct\ndeterministic PTAS for truthful anonymous mechanism.\n  2. For two machines of different speeds, the unique deterministic scalable\nallocation of any envy-free, truthful, individually rational, and anonymous\nmechanism is to allocate all jobs to the quickest machine. This allocation is\nthe same as that of the VCG mechanism, yielding a 2-approximation to the\nminimum makespan.\n  3. No payments can make any of the prior published monotone and locally\nefficient allocations that yield better than an $m$-approximation for $\\qcmax$\n\\cite{aas, at,ck10, dddr, kovacs} a truthful, envy-free, individually rational,\nand anonymous mechanism.", 
    "link": "http://arxiv.org/pdf/1107.2957v1", 
    "arxiv-id": "1107.2957v1"
},{
    "category": "cs.GT", 
    "author": "Pinyan Lu", 
    "title": "Budget Feasible Mechanism Design via Random Sampling", 
    "publish": "2011-07-15T06:16:48Z", 
    "summary": "Budget feasible mechanism considers algorithmic mechanism design questions\nwhere there is a budget constraint on the total payment of the mechanism. An\nimportant question in the field is that under which valuation domains there\nexist budget feasible mechanisms that admit `small' approximations (compared to\na socially optimal solution). Singer \\cite{PS10} showed that additive and\nsubmodular functions admit a constant approximation mechanism. Recently,\nDobzinski, Papadimitriou, and Singer \\cite{DPS11} gave an $O(\\log^2n)$\napproximation mechanism for subadditive functions and remarked that: \"A\nfundamental question is whether, regardless of computational constraints, a\nconstant-factor budget feasible mechanism exists for subadditive function.\"\n  In this paper, we give the first attempt to this question. We give a\npolynomial time $O(\\frac{\\log n}{\\log\\log n})$ sub-logarithmic approximation\nratio mechanism for subadditive functions, improving the best known ratio\n$O(\\log^2 n)$. Further, we connect budget feasible mechanism design to the\nconcept of approximate core in cooperative game theory, and show that there is\na mechanism for subadditive functions whose approximation is, via a\ncharacterization of the integrality gap of a linear program, linear to the\nlargest value to which an approximate core exists. Our result implies in\nparticular that the class of XOS functions, which is a superclass of submodular\nfunctions, admits a constant approximation mechanism. We believe that our work\ncould be a solid step towards solving the above fundamental problem eventually,\nand possibly, with an affirmative answer.", 
    "link": "http://arxiv.org/pdf/1107.2994v2", 
    "arxiv-id": "1107.2994v2"
},{
    "category": "cs.GT", 
    "author": "Giorgos Stamatopoulos", 
    "title": "Cooperative oligopoly games: a probabilistic approach", 
    "publish": "2011-07-16T04:49:44Z", 
    "summary": "We analyze the core of a cooperative Cournot game. We assume that when\ncontemplating a deviation, the members of a coalition assign positive\nprobability over all possible coalition structures that the non-members can\nform. We show that when the number of firms in the market is sufficiently large\nthen the core of the underlying cooperative game is non-empty. Moreover, we\nshow that the core of our game is a subset of the \\gamma - core.", 
    "link": "http://arxiv.org/pdf/1107.3197v1", 
    "arxiv-id": "1107.3197v1"
},{
    "category": "cs.GT", 
    "author": "Giorgos Stamatopoulos", 
    "title": "Strategic delegation in a sequential model with multiple stages", 
    "publish": "2011-07-16T04:59:12Z", 
    "summary": "We analyze strategic delegation in a Stackelberg model with an arbitrary\nnumber, n, of firms. We show that the n-1 last movers delegate their production\ndecisions to managers whereas the first mover does not. Equilibrium incentive\nrates are increasing in the order with which managers select quantities.\nLetting u_i^* denote the equilibrium payoff of the firm whose manager moves in\nthe i-th place, we show that u_n^*>u_{n-1}^*>...>u_2^*>u_1^*. We also compare\nthe delegation outcome of our game with that of a Cournot oligopoly and show\nthat the late (early) moving firms choose higher (lower) incentive rates than\nthe Cournot firms.", 
    "link": "http://arxiv.org/pdf/1107.3198v2", 
    "arxiv-id": "1107.3198v2"
},{
    "category": "cs.GT", 
    "author": "Piotr Frackiewicz", 
    "title": "Quantum information approach to normal representation of extensive games", 
    "publish": "2011-07-16T18:42:17Z", 
    "summary": "We modify the concept of quantum strategic game to make it useful for\nextensive form games. We prove that our modification allows to consider the\nnormal representation of any finite extensive game using the fundamental\nconcepts of quantum information. The Selten's Horse game and the general form\nof two-stage extensive game with perfect information are studied to illustrate\na potential application of our idea. In both examples we use\nEisert-Wilkens-Lewenstein approach as well as Marinatto-Weber approach to\nquantization of games.", 
    "link": "http://arxiv.org/pdf/1107.3245v2", 
    "arxiv-id": "1107.3245v2"
},{
    "category": "cs.GT", 
    "author": "Michel Kieffer", 
    "title": "A Stochastic Game Formulation of Energy-Efficient Power Control:   Equilibrium Utilities and Practical Strategies", 
    "publish": "2011-07-21T12:49:18Z", 
    "summary": "Frequency non-selective time-selective multiple access channels in which\ntransmitters can freely choose their power control policy are considered. The\nindividual objective of the transmitters is to maximize their averaged\nenergy-efficiency. For this purpose, a transmitter has to choose a power\ncontrol policy that is, a sequence of power levels adapted to the channel\nvariations. This problem can be formulated as a stochastic game with\ndiscounting for which there exists a theorem characterizing all the equilibrium\nutilities (equilibrium utility region). As in its general formulation, this\ntheorem relies on global channel state information (CSI), it is shown that some\npoints of the utility region can be reached with individual CSI. Interestingly,\ntime-sharing based solutions, which are usually considered for centralized\npolicies, appear to be part of the equilibrium solutions. This analysis is\nillustrated by numerical results providing further insights to the problem\nunder investigation.", 
    "link": "http://arxiv.org/pdf/1107.4258v1", 
    "arxiv-id": "1107.4258v1"
},{
    "category": "cs.GT", 
    "author": "Pablo A. Parrilo", 
    "title": "Dynamics in Near-Potential Games", 
    "publish": "2011-07-21T21:45:02Z", 
    "summary": "Except for special classes of games, there is no systematic framework for\nanalyzing the dynamical properties of multi-agent strategic interactions.\nPotential games are one such special but restrictive class of games that allow\nfor tractable dynamic analysis. Intuitively, games that are \"close\" to a\npotential game should share similar properties. In this paper, we formalize and\ndevelop this idea by quantifying to what extent the dynamic features of\npotential games extend to \"near-potential\" games. We study convergence of three\ncommonly studied classes of adaptive dynamics: discrete-time better/best\nresponse, logit response, and discrete-time fictitious play dynamics. For\nbetter/best response dynamics, we focus on the evolution of the sequence of\npure strategy profiles and show that this sequence converges to a (pure)\napproximate equilibrium set, whose size is a function of the \"distance\" from a\nclose potential game. We then study logit response dynamics and provide a\ncharacterization of the stationary distribution of this update rule in terms of\nthe distance of the game from a close potential game and the corresponding\npotential function. We further show that the stochastically stable strategy\nprofiles are pure approximate equilibria. Finally, we turn attention to\nfictitious play, and establish that the sequence of empirical frequencies of\nplayer actions converges to a neighborhood of (mixed) equilibria of the game,\nwhere the size of the neighborhood increases with distance of the game to a\npotential game. Thus, our results suggest that games that are close to a\npotential game inherit the dynamical properties of potential games. Since a\nclose potential game to a given game can be found by solving a convex\noptimization problem, our approach also provides a systematic framework for\nstudying convergence behavior of adaptive learning dynamics in arbitrary finite\nstrategic form games.", 
    "link": "http://arxiv.org/pdf/1107.4386v1", 
    "arxiv-id": "1107.4386v1"
},{
    "category": "cs.GT", 
    "author": "Giuseppe Persiano", 
    "title": "Metastability of Logit Dynamics for Coordination Games", 
    "publish": "2011-07-22T15:00:42Z", 
    "summary": "Logit Dynamics [Blume, Games and Economic Behavior, 1993] are randomized best\nresponse dynamics for strategic games: at every time step a player is selected\nuniformly at random and she chooses a new strategy according to a probability\ndistribution biased toward strategies promising higher payoffs. This process\ndefines an ergodic Markov chain, over the set of strategy profiles of the game,\nwhose unique stationary distribution is the long-term equilibrium concept for\nthe game. However, when the mixing time of the chain is large (e.g.,\nexponential in the number of players), the stationary distribution loses its\nappeal as equilibrium concept, and the transient phase of the Markov chain\nbecomes important. In several cases it happens that on a time-scale shorter\nthan mixing time the chain is \"metastable\", i.e. it stays close to some small\nset of the state space, while in a time-scale multiple of the mixing time it\njumps from one metastable configuration to another.\n  In this paper we give a quantitative definition of \"metastable probability\ndistributions\" for a Markov chain and we study the metastability of the logit\ndynamics for some classes of coordination games. We first consider a pure\nn-player coordination game that highlights the distinctive features of our\nmetastability notion based on distributions. Then, we study no-risk-dominant\ncoordination games on the clique (which is equivalent to the well-known Glauber\ndynamics for the Curie-Weiss model) and coordination games on a ring (both the\nrisk-dominant and no-risk-dominant case).", 
    "link": "http://arxiv.org/pdf/1107.4537v3", 
    "arxiv-id": "1107.4537v3"
},{
    "category": "cs.GT", 
    "author": "Jay Sethuraman", 
    "title": "Groupstrategyproofness of the Egalitarian Mechanism for Constrained   Rationing Problems", 
    "publish": "2011-07-22T16:30:24Z", 
    "summary": "The key contribution of the paper is a comprehensive study of the egalitarian\nmechanism with respect to manipulation by a coalition of agents. Our main\nresult is that the egalitarian mechanism is, in fact, peak group strategyproof\n: no coalition of agents can (weakly) benefit from jointly misreporting their\npeaks. Furthermore, we show that the egalitarian mechanism cannot be\nmanipulated by any coalition of suppliers (or any coalition of demanders) in\nthe model where both the suppliers and demanders are agents. Our proofs shed\nlight on the structure of the two models and simpify some of the earlier proofs\nof strategyproofness in the earlier papers. An implication of our results is\nthat the well known algorithm of Megiddo to compute a lexicographically optimal\nflow in a network is group strategyproof with respect to the source capacities\n(or sink capacities).", 
    "link": "http://arxiv.org/pdf/1107.4566v1", 
    "arxiv-id": "1107.4566v1"
},{
    "category": "cs.GT", 
    "author": "Sanjeev Khanna", 
    "title": "Mechanism Design and Risk Aversion", 
    "publish": "2011-07-24T04:38:20Z", 
    "summary": "We develop efficient algorithms to construct utility maximizing mechanisms in\nthe presence of risk averse players (buyers and sellers) in Bayesian settings.\nWe model risk aversion by a concave utility function, and players play\nstrategically to maximize their expected utility. Bayesian mechanism design has\nusually focused on maximizing expected revenue in a {\\em risk neutral}\nenvironment, and no succinct characterization of expected utility maximizing\nmechanisms is known even for single-parameter multi-unit auctions.\n  We first consider the problem of designing optimal DSIC mechanism for a risk\naverse seller in the case of multi-unit auctions, and we give a poly-time\ncomputable SPM that is $(1-1/e-\\eps)$-approximation to the expected utility of\nthe seller in an optimal DSIC mechanism. Our result is based on a novel\napplication of a correlation gap bound, along with {\\em splitting} and {\\em\nmerging} of random variables to redistribute probability mass across buyers.\nThis allows us to reduce our problem to that of checking feasibility of a small\nnumber of distinct configurations, each of which corresponds to a covering LP.\nA feasible solution to the LP gives us the distribution on prices for each\nbuyer to use in a randomized SPM.\n  We next consider the setting when buyers as well as the seller are risk\naverse, and the objective is to maximize the seller's expected utility. We\ndesign a truthful-in-expectation mechanism whose utility is a $(1-1/e\n-\\eps)^3$-approximation to the optimal BIC mechanism under two mild\nassumptions. Our mechanism consists of multiple rounds that processes each\nbuyer in a round with small probability. Lastly, we consider the problem of\nrevenue maximization for a risk neutral seller in presence of risk averse\nbuyers, and give a poly-time algorithm to design an optimal mechanism for the\nseller.", 
    "link": "http://arxiv.org/pdf/1107.4722v3", 
    "arxiv-id": "1107.4722v3"
},{
    "category": "cs.GT", 
    "author": "Pinyan Lu", 
    "title": "Competitive Auctions for Markets with Positive Externalities", 
    "publish": "2011-07-26T14:29:39Z", 
    "summary": "In digital goods auctions, there is an auctioneer who sells an item with\nunlimited supply to a set of potential buyers, and the objective is to design\ntruthful auction to maximize the total profit of the auctioneer. Motivated from\nan observation that the values of buyers for the item could be interconnected\nthrough social networks, we study digital goods auctions with positive\nexternalities among the buyers. This defines a multi-parameter auction design\nproblem where the private valuation of every buyer is a function of other\nwinning buyers. The main contribution of this paper is a truthful competitive\nmechanism for subadditive valuations. Our competitive result is with respect to\na new solution benchmark $\\mathcal{F}^{(3)}$; on the other hand, we show a\nsurprising impossibility result if comparing to the benchmark\n$\\mathcal{F}^{(2)}$, where the latter has been used quite successfully in\ndigital goods auctions without extenalities \\cite{Goldberg2006}. Our results\nfrom $\\mathcal{F}^{(2)}$ to $\\mathcal{F}^{(3)}$ could be considered as the loss\nof optimal profit at the cost of externalities.", 
    "link": "http://arxiv.org/pdf/1107.5221v1", 
    "arxiv-id": "1107.5221v1"
},{
    "category": "cs.GT", 
    "author": "John Musacchio", 
    "title": "Unilateral Altruism in Network Routing Games with Atomic Players", 
    "publish": "2011-08-05T00:32:57Z", 
    "summary": "We study a routing game in which one of the players unilaterally acts\naltruistically by taking into consideration the latency cost of other players\nas well as his own. By not playing selfishly, a player can not only improve the\nother players' equilibrium utility but also improve his own equilibrium\nutility. To quantify the effect, we define a metric called the Value of\nUnilateral Altruism (VoU) to be the ratio of the equilibrium utility of the\naltruistic user to the equilibrium utility he would have received in Nash\nequilibrium if he were selfish. We show by example that the VoU, in a game with\nnonlinear latency functions and atomic players, can be arbitrarily large. Since\nthe Nash equilibrium social welfare of this example is arbitrarily far from\nsocial optimum, this example also has a Price of Anarchy (PoA) that is\nunbounded. The example is driven by there being a small number of players since\nthe same example with non-atomic players yields a Nash equilibrium that is\nfully efficient.", 
    "link": "http://arxiv.org/pdf/1108.1233v2", 
    "arxiv-id": "1108.1233v2"
},{
    "category": "cs.GT", 
    "author": "Subhash Suri", 
    "title": "k-Capture in Multiagent Pursuit Evasion, or the Lion and the Hyenas", 
    "publish": "2011-08-07T18:14:40Z", 
    "summary": "We consider the following generalization of the classical pursuit-evasion\nproblem, which we call k-capture. A group of n pursuers (hyenas) wish to\ncapture an evader (lion) who is free to move in an m-dimensional Euclidean\nspace, the pursuers and the evader can move with the same maximum speed, and at\nleast k pursuers must simultaneously reach the evader's location to capture it.\nIf fewer than k pursuers reach the evader, then those pursuers get destroyed by\nthe evader. Under what conditions can the evader be k-captured? We study this\nproblem in the discrete time, continuous space model and prove that k-capture\nis possible if and only there exists a time when the evader lies in the\ninterior of the pursuers' k-Hull. When the pursuit occurs inside a compact,\nconvex subset of the Euclidean space, we show through an easy constructive\nstrategy that k-capture is always possible.", 
    "link": "http://arxiv.org/pdf/1108.1561v1", 
    "arxiv-id": "1108.1561v1"
},{
    "category": "cs.GT", 
    "author": "Yoav Wilf", 
    "title": "Randomized Strategyproof Mechanisms for Facility Location and the   Mini-Sum-of-Squares Objective", 
    "publish": "2011-08-08T17:47:11Z", 
    "summary": "We consider the problem of locating a public facility on a line, where a set\nof $n$ strategic agents report their \\emph{locations} and a mechanism\ndetermines, either deterministically or randomly, the location of the facility.\nGame theoretic perspectives of the facility location problem advanced in two\nmain directions. The first direction is concerned with the characterization of\n\\emph{strategyproof} (SP) mechanisms; i.e., mechanisms that induce truthful\nreporting as a dominant strategy; and the second direction quantifies how well\nvarious objective functions can be approximated when restricted to SP\nmechanisms. The current paper provides contributions in both directions. First,\nwe construct a parameterized randomized SP mechanism, and show that all of the\npreviously proposed deterministic and randomized SP mechanisms for the current\nsettings can be formalized as special cases of this mechanism. Second, we give\ntight results for the approximation ratio of SP mechanisms with respect to the\nobjective of minimizing the sum of squares of distances to the agents\n(\\emph{miniSOS}). Holzman \\cite{Holzman1990} provided an axiomatic foundation\nfor this function, showing that it is the unique function that satisfies\nunanimity, continuity and invariance. We devise a randomized mechanism that\ngives a 1.5-approximation for the miniSOS function, and show that no other\nrandomized SP mechanism can provide a better approximation. This mechanism\nchooses the average location with probability 1/2 and a \\emph{random dictator}\nwith probability 1/2. For deterministic mechanisms, we show that the median\nmechanism provides a 2-approximation, and this is tight. Together, our study\nprovides fundamental understanding of the miniSOS objective function and makes\na step toward the characterization of randomized SP facility location\nmechanisms.", 
    "link": "http://arxiv.org/pdf/1108.1762v4", 
    "arxiv-id": "1108.1762v4"
},{
    "category": "cs.GT", 
    "author": "Michael Schapira", 
    "title": "On the Structure of Weakly Acyclic Games", 
    "publish": "2011-08-10T04:09:43Z", 
    "summary": "The class of weakly acyclic games, which includes potential games and\ndominance-solvable games, captures many practical application domains. In a\nweakly acyclic game, from any starting state, there is a sequence of\nbetter-response moves that leads to a pure Nash equilibrium; informally, these\nare games in which natural distributed dynamics, such as better-response\ndynamics, cannot enter inescapable oscillations. We establish a novel link\nbetween such games and the existence of pure Nash equilibria in subgames.\nSpecifically, we show that the existence of a unique pure Nash equilibrium in\nevery subgame implies the weak acyclicity of a game. In contrast, the possible\nexistence of multiple pure Nash equilibria in every subgame is insufficient for\nweak acyclicity in general; here, we also systematically identify the special\ncases (in terms of the number of players and strategies) for which this is\nsufficient to guarantee weak acyclicity.", 
    "link": "http://arxiv.org/pdf/1108.2092v1", 
    "arxiv-id": "1108.2092v1"
},{
    "category": "cs.GT", 
    "author": "Eva Tardos", 
    "title": "Sequential Auctions and Externalities", 
    "publish": "2011-08-11T16:29:38Z", 
    "summary": "In many settings agents participate in multiple different auctions that are\nnot necessarily implemented simultaneously. Future opportunities affect\nstrategic considerations of the players in each auction, introducing\nexternalities. Motivated by this consideration, we study a setting of a market\nof buyers and sellers, where each seller holds one item, bidders have\ncombinatorial valuations and sellers hold item auctions sequentially.\n  Our results are qualitatively different from those of simultaneous auctions,\nproving that simultaneity is a crucial aspect of previous work. We prove that\nif sellers hold sequential first price auctions then for unit-demand bidders\n(matching market) every subgame perfect equilibrium achieves at least half of\nthe optimal social welfare, while for submodular bidders or when second price\nauctions are used, the social welfare can be arbitrarily worse than the\noptimal. We also show that a first price sequential auction for buying or\nselling a base of a matroid is always efficient, and implements the VCG\noutcome.\n  An important tool in our analysis is studying first and second price auctions\nwith externalities (bidders have valuations for each possible winner outcome),\nwhich can be of independent interest. We show that a Pure Nash Equilibrium\nalways exists in a first price auction with externalities.", 
    "link": "http://arxiv.org/pdf/1108.2452v2", 
    "arxiv-id": "1108.2452v2"
},{
    "category": "cs.GT", 
    "author": "Preetjot Singh", 
    "title": "Manipulation Can Be Hard in Tractable Voting Systems Even for   Constant-Sized Coalitions", 
    "publish": "2011-08-22T21:02:46Z", 
    "summary": "Voting theory has become increasingly integrated with computational social\nchoice and multiagent systems. Computational complexity has been extensively\nused as a shield against manipulation of voting systems, however for several\nvoting schemes this complexity may cause calculating the winner to be\ncomputationally difficult. Of the many voting systems that have been studied\nwith regard to election manipulation, a few have been found to have an\nunweighted coalitional manipulation problem that is NP-hard for a constant\nnumber of manipulators despite having a winner problem that is in P. We survey\nthis interesting class of voting systems and the work that has analyzed their\ncomplexity.", 
    "link": "http://arxiv.org/pdf/1108.4439v1", 
    "arxiv-id": "1108.4439v1"
},{
    "category": "cs.GT", 
    "author": "Jason D. Hartline", 
    "title": "Mechanism Design via Consensus Estimates, Cross Checking, and Profit   Extraction", 
    "publish": "2011-08-24T03:27:52Z", 
    "summary": "There is only one technique for prior-free optimal mechanism design that\ngeneralizes beyond the structurally benevolent setting of digital goods. This\ntechnique uses random sampling to estimate the distribution of agent values and\nthen employs the Bayesian optimal mechanism for this estimated distribution on\nthe remaining players. Though quite general, even for digital goods, this\nrandom sampling auction has a complicated analysis and is known to be\nsuboptimal. To overcome these issues we generalize the consensus technique from\nGoldberg and Hartline (2003) to structurally rich environments that include,\ne.g., single-minded combinatorial auctions.", 
    "link": "http://arxiv.org/pdf/1108.4744v1", 
    "arxiv-id": "1108.4744v1"
},{
    "category": "cs.GT", 
    "author": "William Zame", 
    "title": "Designing Practical Distributed Exchange for Online Communities", 
    "publish": "2011-08-30T08:24:48Z", 
    "summary": "In many online systems, individuals provide services for each other; the\nrecipient of the service obtains a benefit but the provider of the service\nincurs a cost. If benefit exceeds cost, provision of the service increases\nsocial welfare and should therefore be encouraged -- but the individuals\nproviding the service gain no (immediate) benefit from providing the service\nand hence have an incentive to withhold service. Hence there is scope for\ndesigning a system that improves welfare by encouraging exchange. To operate\nsuccessfully within the confines of the online environment, such a system\nshould be distributed, practicable, and consistent with individual incentives.\nThis paper proposes and analyzes a simple such system that relies on the\nexchange of {\\em tokens}; the emphasis is on the design of a protocol (number\nof tokens and suggested strategies). We provide estimates for the efficiency of\nsuch protocols and show that choosing the right protocol will lead to almost\nfull efficiency if agents are sufficiently patient. However, choosing the wrong\nprotocols may lead to an enormous loss of efficiency.", 
    "link": "http://arxiv.org/pdf/1108.5871v2", 
    "arxiv-id": "1108.5871v2"
},{
    "category": "cs.GT", 
    "author": "Guido Schaefer", 
    "title": "Multi-Unit Auction with Diminishing Marginal Valuations and Capacities", 
    "publish": "2011-08-30T18:35:58Z", 
    "summary": "This paper has been withdrawn by the author.", 
    "link": "http://arxiv.org/pdf/1108.6033v3", 
    "arxiv-id": "1108.6033v3"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "On the Impossibility of Black-Box Transformations in Mechanism Design", 
    "publish": "2011-09-09T17:03:16Z", 
    "summary": "We consider the problem of converting an arbitrary approximation algorithm\nfor a single-parameter optimization problem into a computationally efficient\ntruthful mechanism. We ask for reductions that are black-box, meaning that they\nrequire only oracle access to the given algorithm and in particular do not\nrequire explicit knowledge of the problem constraints. Such a reduction is\nknown to be possible, for example, for the social welfare objective when the\ngoal is to achieve Bayesian truthfulness and preserve social welfare in\nexpectation. We show that a black-box reduction for the social welfare\nobjective is not possible if the resulting mechanism is required to be truthful\nin expectation and to preserve the worst-case approximation ratio of the\nalgorithm to within a subpolynomial factor. Further, we prove that for other\nobjectives such as makespan, no black-box reduction is possible even if we only\nrequire Bayesian truthfulness and an average-case performance guarantee.", 
    "link": "http://arxiv.org/pdf/1109.2067v1", 
    "arxiv-id": "1109.2067v1"
},{
    "category": "cs.GT", 
    "author": "F. Scarcello", 
    "title": "Pure Nash Equilibria: Hard and Easy Games", 
    "publish": "2011-09-09T20:42:30Z", 
    "summary": "We investigate complexity issues related to pure Nash equilibria of strategic\ngames. We show that, even in very restrictive settings, determining whether a\ngame has a pure Nash Equilibrium is NP-hard, while deciding whether a game has\na strong Nash equilibrium is SigmaP2-complete. We then study practically\nrelevant restrictions that lower the complexity. In particular, we are\ninterested in quantitative and qualitative restrictions of the way each players\npayoff depends on moves of other players. We say that a game has small\nneighborhood if the utility function for each player depends only on (the\nactions of) a logarithmically small number of other players. The dependency\nstructure of a game G can be expressed by a graph DG(G) or by a hypergraph\nH(G). By relating Nash equilibrium problems to constraint satisfaction problems\n(CSPs), we show that if G has small neighborhood and if H(G) has bounded\nhypertree width (or if DG(G) has bounded treewidth), then finding pure Nash and\nPareto equilibria is feasible in polynomial time. If the game is graphical,\nthen these problems are LOGCFL-complete and thus in the class NC2 of highly\nparallelizable problems.", 
    "link": "http://arxiv.org/pdf/1109.2152v1", 
    "arxiv-id": "1109.2152v1"
},{
    "category": "cs.GT", 
    "author": "Piotr Frackiewicz", 
    "title": "Quantum information approach to the ultimatum game", 
    "publish": "2011-09-09T22:23:49Z", 
    "summary": "The paper is devoted to quantization of extensive games with the use of both\nthe Marinatto-Weber and the Eisert-Wilkens-Lewenstein concept of quantum game.\nWe revise the current conception of quantum ultimatum game and we show why the\nproposal is unacceptable. To support our comment, we present the new idea of\nthe quantum ultimatum game. Our scheme also makes a point of departure for a\nprotocol to quantize extensive games.", 
    "link": "http://arxiv.org/pdf/1109.2169v1", 
    "arxiv-id": "1109.2169v1"
},{
    "category": "cs.GT", 
    "author": "Jinwoo Shin", 
    "title": "Near Optimality in Covering and Packing Games by Exposing Global   Information", 
    "publish": "2011-09-16T13:08:34Z", 
    "summary": "Covering and packing problems can be modeled as games to encapsulate\ninteresting social and engineering settings. These games have a high Price of\nAnarchy in their natural formulation. However, existing research applicable to\nspecific instances of these games has only been able to prove fast convergence\nto arbitrary equilibria. This paper studies general classes of covering and\npacking games with learning dynamics models that incorporate a central\nauthority who broadcasts weak, socially beneficial signals to agents that\notherwise only use local information in their decision-making. Rather than\nillustrating convergence to an arbitrary equilibrium that may have very high\nsocial cost, we show that these systems quickly achieve near-optimal\nperformance.\n  In particular, we show that in the public service advertising model, reaching\na small constant fraction of the agents is enough to bring the system to a\nstate within a log n factor of optimal in a broad class of set cover and set\npacking games or a constant factor of optimal in the special cases of vertex\ncover and maximum independent set, circumventing social inefficiency of bad\nlocal equilibria that could arise without a central authority. We extend these\nresults to the learn-then-decide model, in which agents use any of a broad\nclass of learning algorithms to decide in a given round whether to behave\naccording to locally optimal behavior or the behavior prescribed by the\nbroadcast signal. The new techniques we use for analyzing these games could be\nof broader interest for analyzing more general classic optimization problems in\na distributed fashion.", 
    "link": "http://arxiv.org/pdf/1109.3606v1", 
    "arxiv-id": "1109.3606v1"
},{
    "category": "cs.GT", 
    "author": "Kevin Leyton-Brown", 
    "title": "A General Framework for Computing Optimal Correlated Equilibria in   Compact Games", 
    "publish": "2011-09-28T00:08:45Z", 
    "summary": "We analyze the problem of computing a correlated equilibrium that optimizes\nsome objective (e.g., social welfare). Papadimitriou and Roughgarden [2008]\ngave a sufficient condition for the tractability of this problem; however, this\ncondition only applies to a subset of existing representations. We propose a\ndifferent algorithmic approach for the optimal CE problem that applies to all\ncompact representations, and give a sufficient condition that generalizes that\nof Papadimitriou and Roughgarden. In particular, we reduce the optimal CE\nproblem to the deviation-adjusted social welfare problem, a combinatorial\noptimization problem closely related to the optimal social welfare problem.\nThis framework allows us to identify new classes of games for which the optimal\nCE problem is tractable; we show that graphical polymatrix games on tree graphs\nare one example. We also study the problem of computing the optimal coarse\ncorrelated equilibrium, a solution concept closely related to CE. Using a\nsimilar approach we derive a sufficient condition for this problem, and use it\nto prove that the problem is tractable for singleton congestion games.", 
    "link": "http://arxiv.org/pdf/1109.6064v1", 
    "arxiv-id": "1109.6064v1"
},{
    "category": "cs.GT", 
    "author": "Ramesh Johari", 
    "title": "Heavy Traffic Approximation of Equilibria in Resource Sharing Games", 
    "publish": "2011-09-28T11:09:04Z", 
    "summary": "We consider a model of priced resource sharing that combines both queueing\nbehavior and strategic behavior. We study a priority service model where a\nsingle server allocates its capacity to agents in proportion to their payment\nto the system, and users from different classes act to minimize the sum of\ntheir cost for processing delay and payment. As the exact processing time of\nthis system is hard to compute, we introduce the notion of heavy traffic\nequilibrium as an approximation of the Nash equilibrium, derived by considering\nthe asymptotic regime where the system load approaches capacity. We discuss\nefficiency and revenue, and in particular provide a bound for the price of\nanarchy of the heavy traffic equilibrium.", 
    "link": "http://arxiv.org/pdf/1109.6166v3", 
    "arxiv-id": "1109.6166v3"
},{
    "category": "cs.GT", 
    "author": "Ruta Mehta", 
    "title": "Bilinear Games: Polynomial Time Algorithms for Rank Based Subclasses", 
    "publish": "2011-09-28T12:15:42Z", 
    "summary": "Motivated by the sequence form formulation of Koller et al. (GEB'96), this\npaper defines {\\em bilinear games}, and proposes efficient algorithms for its\nrank based subclasses. Bilinear games are two-player non-cooperative\nsingle-shot games with compact polytopal strategy sets and two payoff matrices\n(A,B) such that when (x,y) is the played strategy profile, the payoffs of the\nplayers are xAy and xBy respectively. We show that bilinear games are very\ngeneral and capture many interesting classes of games like bimatrix games, two\nplayer Bayesian games, polymatrix games, two-player extensive form games with\nperfect recall etc. as special cases, and hence are hard to solve in general.\n  Existence of a (symmetric) Nash equilibrium for (symmetric) bilinear games\nfollow directly from the known results. For a given bilinear game, we define\nits {\\em Best Response Polytopes} (BRPs) and characterize the set of Nash\nequilibria as {\\em fully-labeled} pairs in the BRPs. We consider a rank based\nhierarchy of bilinear games, where rank of a game (A,B) is defined as\nrank(A+B). In this paper, we give polynomial time algorithms to compute Nash\nequilibrium for special classes of bilinear games:\n  (i) Rank-1 games (i.e., rank(A+B)=1). (ii) FPTAS for constant rank games\n(i.e., rank(A+B) is constant). (iii) When rank(A) or rank(B) is constant. This\nimproves the results by Lipton et al. (EC'03) and Kannan et al. (ET'09), for\nbimatrix games with low rank matrices.", 
    "link": "http://arxiv.org/pdf/1109.6182v1", 
    "arxiv-id": "1109.6182v1"
},{
    "category": "cs.GT", 
    "author": "A. Ronen", 
    "title": "Computationally Feasible VCG Mechanisms", 
    "publish": "2011-09-30T20:55:24Z", 
    "summary": "A major achievement of mechanism design theory is a general method for the\nconstruction of truthful mechanisms called VCG (Vickrey, Clarke, Groves). When\napplying this method to complex problems such as combinatorial auctions, a\ndifficulty arises: VCG mechanisms are required to compute optimal outcomes and\nare, therefore, computationally infeasible. However, if the optimal outcome is\nreplaced by the results of a sub-optimal algorithm, the resulting mechanism\n(termed VCG-based) is no longer necessarily truthful. The first part of this\npaper studies this phenomenon in depth and shows that it is near universal.\nSpecifically, we prove that essentially all reasonable approximations or\nheuristics for combinatorial auctions as well as a wide class of cost\nminimization problems yield non-truthful VCG-based mechanisms. We generalize\nthese results for affine maximizers.\n  The second part of this paper proposes a general method for circumventing the\nabove problem. We introduce a modification of VCG-based mechanisms in which the\nagents are given a chance to improve the output of the underlying algorithm.\nWhen the agents behave truthfully, the welfare obtained by the mechanism is at\nleast as good as the one obtained by the algorithms output. We provide a strong\nrationale for truth-telling behavior. Our method satisfies individual\nrationality as well.", 
    "link": "http://arxiv.org/pdf/1110.0025v1", 
    "arxiv-id": "1110.0025v1"
},{
    "category": "cs.GT", 
    "author": "Carmine Ventre", 
    "title": "Using Lotteries to Approximate the Optimal Revenue", 
    "publish": "2011-10-10T09:58:16Z", 
    "summary": "There has been much recent work on the revenue-raising properties of truthful\nmechanisms for selling goods to selfish bidders. Typically the revenue of a\nmechanism is compared against a benchmark (such as, the maximum revenue\nobtainable by an omniscient seller selling at a fixed price to at least two\ncustomers), with a view to understanding how much lower the mechanism's revenue\nis than the benchmark, in the worst case.\n  We study this issue in the context of {\\em lotteries}, where the seller may\nsell a probability of winning an item. We are interested in two general issues.\nFirstly, we aim at using the true optimum revenue as benchmark for our\nauctions. Secondly, we study the extent to which the expressive power resulting\nfrom lotteries, helps to improve the worst-case ratio. We study this in the\nwell-known context of {\\em digital goods}, where the production cost is zero.\nWe show that in this scenario, collusion-resistant lotteries (these are\nlotteries for which no coalition of bidders exchanging side payments has an\nadvantage in lying) are as powerful as truthful ones.", 
    "link": "http://arxiv.org/pdf/1110.1980v2", 
    "arxiv-id": "1110.1980v2"
},{
    "category": "cs.GT", 
    "author": "Arkadii Slinko", 
    "title": "Clone Structures in Voters' Preferences", 
    "publish": "2011-10-18T11:18:28Z", 
    "summary": "In elections, a set of candidates ranked consecutively (though possibly in\ndifferent order) by all voters is called a clone set, and its members are\ncalled clones. A clone structure is a family of all clone sets of a given\nelection. In this paper we study properties of clone structures. In particular,\nwe give an axiomatic characterization of clone structures, show their\nhierarchical structure, and analyze clone structures in single-peaked and\nsingle-crossing elections. We give a polynomial-time algorithm that finds a\nminimal collection of clones that need to be collapsed for an election to\nbecome single-peaked, and we show that this problem is NP-hard for\nsingle-crossing elections.", 
    "link": "http://arxiv.org/pdf/1110.3939v1", 
    "arxiv-id": "1110.3939v1"
},{
    "category": "cs.GT", 
    "author": "Subhash Suri", 
    "title": "Capturing an Evader in Polygonal Environments: A Complete Information   Game", 
    "publish": "2011-10-21T16:41:47Z", 
    "summary": "Suppose an unpredictable evader is free to move around in a polygonal\nenvironment of arbitrary complexity that is under full camera surveillance. How\nmany pursuers, each with the same maximum speed as the evader, are necessary\nand sufficient to guarantee a successful capture of the evader? The pursuers\nalways know the evader's current position through the camera network, but need\nto physically reach the evader to capture it. We allow the evader the knowledge\nof the current positions of all the pursuers as well---this accords with the\nstandard worst-case analysis model, but also models a practical situation where\nthe evader has \"hacked\" into the surveillance system.\n  Our main result is to prove that three pursuers are always sufficient and\nsometimes necessary to capture the evader. The bound is independent of the\nnumber of vertices or holes in the polygonal environment. The result should be\ncontrasted with the incomplete information pursuit-evasion where at least\n{\\Omega}(\\surd h + log n) pursuers are required just for detecting the evader\nin an environment with n vertices and h holes.", 
    "link": "http://arxiv.org/pdf/1110.4838v1", 
    "arxiv-id": "1110.4838v1"
},{
    "category": "cs.GT", 
    "author": "Ankit Sharma", 
    "title": "Welfare and Profit Maximization with Production Costs", 
    "publish": "2011-10-22T19:28:11Z", 
    "summary": "Combinatorial Auctions are a central problem in Algorithmic Mechanism Design:\npricing and allocating goods to buyers with complex preferences in order to\nmaximize some desired objective (e.g., social welfare, revenue, or profit). The\nproblem has been well-studied in the case of limited supply (one copy of each\nitem), and in the case of digital goods (the seller can produce additional\ncopies at no cost). Yet in the case of resources---oil, labor, computing\ncycles, etc.---neither of these abstractions is just right: additional supplies\nof these resources can be found, but at increasing difficulty (marginal cost)\nas resources are depleted.\n  In this work, we initiate the study of the algorithmic mechanism design\nproblem of combinatorial pricing under increasing marginal cost. The goal is to\nsell these goods to buyers with unknown and arbitrary combinatorial valuation\nfunctions to maximize either the social welfare, or the seller's profit;\nspecifically we focus on the setting of \\emph{posted item prices} with buyers\narriving online. We give algorithms that achieve {\\em constant factor}\napproximations for a class of natural cost functions---linear, low-degree\npolynomial, logarithmic---and that give logarithmic approximations for more\ngeneral increasing marginal cost functions (along with a necessary additive\nloss). We show that these bounds are essentially best possible for these\nsettings.", 
    "link": "http://arxiv.org/pdf/1110.4992v1", 
    "arxiv-id": "1110.4992v1"
},{
    "category": "cs.GT", 
    "author": "Vittorio Bil\u00f2", 
    "title": "A Unifying Tool for Bounding the Quality of Non-Cooperative Solutions in   Weighted Congestion Games", 
    "publish": "2011-10-25T08:40:32Z", 
    "summary": "We present a general technique, based on a primal-dual formulation, for\nanalyzing the quality of self-emerging solutions in weighted congestion games.\nWith respect to traditional combinatorial approaches, the primal-dual schema\nhas at least three advantages: first, it provides an analytic tool which can\nalways be used to prove tight upper bounds for all the cases in which we are\nable to characterize exactly the polyhedron of the solutions under analysis;\nsecondly, in each such a case the complementary slackness conditions give us an\nhint on how to construct matching lower bounding instances; thirdly, proofs\nbecome simpler and easy to check. For the sake of exposition, we first apply\nour technique to the problems of bounding the prices of anarchy and stability\nof exact and approximate pure Nash equilibria, as well as the approximation\nratio of the solutions achieved after a one-round walk starting from the empty\nstrategy profile, in the case of affine latency functions and we show how all\nthe known upper bounds for these measures (and some of their generalizations)\ncan be easily reobtained under a unified approach. Then, we use the technique\nto attack the more challenging setting of polynomial latency functions. In\nparticular, we obtain the first known upper bounds on the price of stability of\npure Nash equilibria and on the approximation ratio of the solutions achieved\nafter a one-round walk starting from the empty strategy profile for unweighted\nplayers in the cases of quadratic and cubic latency functions. We believe that\nour technique, thanks to its versatility, may prove to be a powerful tool also\nin several other applications.", 
    "link": "http://arxiv.org/pdf/1110.5439v1", 
    "arxiv-id": "1110.5439v1"
},{
    "category": "cs.GT", 
    "author": "Roman Rabinovich", 
    "title": "Graph Searching, Parity Games and Imperfect Information", 
    "publish": "2011-10-25T16:52:23Z", 
    "summary": "We investigate the interrelation between graph searching games and games with\nimperfect information. As key consequence we obtain that parity games with\nbounded imperfect information can be solved in PTIME on graphs of bounded\nDAG-width which generalizes several results for parity games on graphs of\nbounded complexity. We use a new concept of graph searching where several cops\ntry to catch multiple robbers instead of just a single robber. The main\ntechnical result is that the number of cops needed to catch r robbers\nmonotonously is at most r times the DAG-width of the graph. We also explore\naspects of this new concept as a refinement of directed path-width which\naccentuates its connection to the concept of imperfect information.", 
    "link": "http://arxiv.org/pdf/1110.5575v1", 
    "arxiv-id": "1110.5575v1"
},{
    "category": "cs.GT", 
    "author": "C. R. Shelton", 
    "title": "A Continuation Method for Nash Equilibria in Structured Games", 
    "publish": "2011-09-29T18:51:28Z", 
    "summary": "Structured game representations have recently attracted interest as models\nfor multi-agent artificial intelligence scenarios, with rational behavior most\ncommonly characterized by Nash equilibria. This paper presents efficient, exact\nalgorithms for computing Nash equilibria in structured game representations,\nincluding both graphical games and multi-agent influence diagrams (MAIDs). The\nalgorithms are derived from a continuation method for normal-form and\nextensive-form games due to Govindan and Wilson; they follow a trajectory\nthrough a space of perturbed games and their equilibria, exploiting game\nstructure through fast computation of the Jacobian of the payoff function. They\nare theoretically guaranteed to find at least one equilibrium of the game, and\nmay find more. Our approach provides the first efficient algorithm for\ncomputing exact equilibria in graphical games with arbitrary topology, and the\nfirst algorithm to exploit fine-grained structural properties of MAIDs.\nExperimental results are presented demonstrating the effectiveness of the\nalgorithms and comparing them to predecessors. The running time of the\ngraphical game algorithm is similar to, and often better than, the running time\nof previous approximate algorithms. The algorithm for MAIDs can effectively\nsolve games that are much larger than those solvable by previous methods.", 
    "link": "http://arxiv.org/pdf/1110.5886v1", 
    "arxiv-id": "1110.5886v1"
},{
    "category": "cs.GT", 
    "author": "Michael Kearns", 
    "title": "Competitive Contagion in Networks", 
    "publish": "2011-10-28T15:42:23Z", 
    "summary": "We develop a game-theoretic framework for the study of competition between\nfirms who have budgets to \"seed\" the initial adoption of their products by\nconsumers located in a social network. The payoffs to the firms are the\neventual number of adoptions of their product through a competitive stochastic\ndiffusion process in the network. This framework yields a rich class of\ncompetitive strategies, which depend in subtle ways on the stochastic dynamics\nof adoption, the relative budgets of the players, and the underlying structure\nof the social network.\n  We identify a general property of the adoption dynamics --- namely,\ndecreasing returns to local adoption --- for which the inefficiency of resource\nuse at equilibrium (the Price of Anarchy) is uniformly bounded above, across\nall networks. We also show that if this property is violated the Price of\nAnarchy can be unbounded, thus yielding sharp threshold behavior for a broad\nclass of dynamics.\n  We also introduce a new notion, the Budget Multiplier, that measures the\nextent that imbalances in player budgets can be amplified at equilibrium. We\nagain identify a general property of the adoption dynamics --- namely,\nproportional local adoption between competitors --- for which the (pure\nstrategy) Budget Multiplier is uniformly bounded above, across all networks. We\nshow that a violation of this property can lead to unbounded Budget Multiplier,\nagain yielding sharp threshold behavior for a broad class of dynamics.", 
    "link": "http://arxiv.org/pdf/1110.6372v3", 
    "arxiv-id": "1110.6372v3"
},{
    "category": "cs.GT", 
    "author": "Elena Kleiman", 
    "title": "Packing, Scheduling and Covering Problems in a Game-Theoretic   Perspective", 
    "publish": "2011-10-28T17:29:22Z", 
    "summary": "Many packing, scheduling and covering problems that were previously\nconsidered by computer science literature in the context of various\ntransportation and production problems, appear also suitable for describing and\nmodeling various fundamental aspects in networks optimization such as routing,\nresource allocation, congestion control, etc. Various combinatorial problems\nwere already studied from the game theoretic standpoint, and we attempt to\ncomplement to this body of research.\n  Specifically, we consider the bin packing problem both in the classic and\nparametric versions, the job scheduling problem and the machine covering\nproblem in various machine models. We suggest new interpretations of such\nproblems in the context of modern networks and study these problems from a game\ntheoretic perspective by modeling them as games, and then concerning various\ngame theoretic concepts in these games by combining tools from game theory and\nthe traditional combinatorial optimization. In the framework of this research\nwe introduce and study models that were not considered before, and also improve\nupon previously known results.", 
    "link": "http://arxiv.org/pdf/1110.6407v1", 
    "arxiv-id": "1110.6407v1"
},{
    "category": "cs.GT", 
    "author": "D. C. Parkes", 
    "title": "Chain: A Dynamic Double Auction Framework for Matching Patient Agents", 
    "publish": "2011-10-31T21:50:57Z", 
    "summary": "In this paper we present and evaluate a general framework for the design of\ntruthful auctions for matching agents in a dynamic, two-sided market. A single\ncommodity, such as a resource or a task, is bought and sold by multiple buyers\nand sellers that arrive and depart over time. Our algorithm, Chain, provides\nthe first framework that allows a truthful dynamic double auction (DA) to be\nconstructed from a truthful, single-period (i.e. static) double-auction rule.\nThe pricing and matching method of the Chain construction is unique amongst\ndynamic-auction rules that adopt the same building block. We examine\nexperimentally the allocative efficiency of Chain when instantiated on various\nsingle-period rules, including the canonical McAfee double-auction rule. For a\nbaseline we also consider non-truthful double auctions populated with\nzero-intelligence plus\"-style learning agents. Chain-based auctions perform\nwell in comparison with other schemes, especially as arrival intensity falls\nand agent valuations become more volatile.", 
    "link": "http://arxiv.org/pdf/1111.0046v1", 
    "arxiv-id": "1111.0046v1"
},{
    "category": "cs.GT", 
    "author": "M\u00e9rouane Debbah", 
    "title": "Spectrum Leasing as an Incentive towards Uplink Macrocell and Femtocell   Cooperation", 
    "publish": "2011-11-02T13:54:08Z", 
    "summary": "The concept of femtocell access points underlaying existing communication\ninfrastructure has recently emerged as a key technology that can significantly\nimprove the coverage and performance of next-generation wireless networks. In\nthis paper, we propose a framework for macrocell-femtocell cooperation under a\nclosed access policy, in which a femtocell user may act as a relay for\nmacrocell users. In return, each cooperative macrocell user grants the\nfemtocell user a fraction of its superframe. We formulate a coalitional game\nwith macrocell and femtocell users being the players, which can take individual\nand distributed decisions on whether to cooperate or not, while maximizing a\nutility function that captures the cooperative gains, in terms of throughput\nand delay.We show that the network can selforganize into a partition composed\nof disjoint coalitions which constitutes the recursive core of the game\nrepresenting a key solution concept for coalition formation games in partition\nform. Simulation results show that the proposed coalition formation algorithm\nyields significant gains in terms of average rate per macrocell user, reaching\nup to 239%, relative to the non-cooperative case. Moreover, the proposed\napproach shows an improvement in terms of femtocell users' rate of up to 21%\nwhen compared to the traditional closed access policy.", 
    "link": "http://arxiv.org/pdf/1111.0503v1", 
    "arxiv-id": "1111.0503v1"
},{
    "category": "cs.GT", 
    "author": "Morteza Saghafian", 
    "title": "On a Bounded Budget Network Creation Game", 
    "publish": "2011-11-02T16:11:07Z", 
    "summary": "We consider a network creation game in which each player (vertex) has a fixed\nbudget to establish links to other players. In our model, each link has unit\nprice and each agent tries to minimize its cost, which is either its local\ndiameter or its total distance to other players in the (undirected) underlying\ngraph of the created network. Two versions of the game are studied: in the MAX\nversion, the cost incurred to a vertex is the maximum distance between the\nvertex and other vertices, and in the SUM version, the cost incurred to a\nvertex is the sum of distances between the vertex and other vertices. We prove\nthat in both versions pure Nash equilibria exist, but the problem of finding\nthe best response of a vertex is NP-hard. We take the social cost of the\ncreated network to be its diameter, and next we study the maximum possible\ndiameter of an equilibrium graph with n vertices in various cases. When the sum\nof players' budgets is n-1, the equilibrium graphs are always trees, and we\nprove that their maximum diameter is Theta(n) and Theta(log n) in MAX and SUM\nversions, respectively. When each vertex has unit budget (i.e. can establish\nlink to just one vertex), the diameter of any equilibrium graph in either\nversion is Theta(1). We give examples of equilibrium graphs in the MAX version,\nsuch that all vertices have positive budgets and yet the diameter is\nOmega(sqrt(log n)). This interesting (and perhaps counter-intuitive) result\nshows that increasing the budgets may increase the diameter of equilibrium\ngraphs and hence deteriorate the network structure. Then we prove that every\nequilibrium graph in the SUM version has diameter 2^O(sqrt(log n)). Finally, we\nshow that if the budget of each player is at least k, then every equilibrium\ngraph in the SUM version is k-connected or has diameter smaller than 4.", 
    "link": "http://arxiv.org/pdf/1111.0554v2", 
    "arxiv-id": "1111.0554v2"
},{
    "category": "cs.GT", 
    "author": "Steven R. Williams", 
    "title": "On Bidding with Securities: Risk Aversion and Positive Dependence", 
    "publish": "2011-11-06T21:46:07Z", 
    "summary": "DeMarzo et al. (2005) consider auctions in which bids are selected from a\ncompletely ordered family of securities whose values are tied to the resource\nbeing auctioned. The paper defines a notion of relative steepness of families\nof securities and shows that a steeper family provides greater expected revenue\nto the seller. Two assumptions are: the buyers are risk-neutral; the random\nvariables through which values and signals of the buyers are realized are\naffiliated. We show that this revenue ranking holds for the second price\nauction in the case of risk-aversion. However, it does not hold if affiliation\nis relaxed to a less restrictive form of positive dependence, namely first\norder stochastic dominance (FOSD). We define the relative strong steepness of\nfamilies of securities and show that it provides a necessary and sufficient\ncondition for comparing two families in the FOSD case. All results extend to\nthe English auction.", 
    "link": "http://arxiv.org/pdf/1111.1453v5", 
    "arxiv-id": "1111.1453v5"
},{
    "category": "cs.GT", 
    "author": "Aviv Zohar", 
    "title": "On Bitcoin and Red Balloons", 
    "publish": "2011-11-10T22:07:26Z", 
    "summary": "Many large decentralized systems rely on information propagation to ensure\ntheir proper function. We examine a common scenario in which only participants\nthat are aware of the information can compete for some reward, and thus\ninformed participants have an incentive not to propagate information to others.\nOne recent example in which such tension arises is the 2009 DARPA Network\nChallenge (finding red balloons). We focus on another prominent example:\nBitcoin, a decentralized electronic currency system.\n  Bitcoin represents a radical new approach to monetary systems. It has been\ngetting a large amount of public attention over the last year, both in policy\ndiscussions and in the popular press. Its cryptographic fundamentals have\nlargely held up even as its usage has become increasingly widespread. We find,\nhowever, that it exhibits a fundamental problem of a different nature, based on\nhow its incentives are structured. We propose a modification to the protocol\nthat can eliminate this problem.\n  Bitcoin relies on a peer-to-peer network to track transactions that are\nperformed with the currency. For this purpose, every transaction a node learns\nabout should be transmitted to its neighbors in the network. The current\nimplemented protocol provides an incentive to nodes to not broadcast\ntransactions they are aware of. Our solution is to augment the protocol with a\nscheme that rewards information propagation. Since clones are easy to create in\nthe Bitcoin system, an important feature of our scheme is Sybil-proofness.\n  We show that our proposed scheme succeeds in setting the correct incentives,\nthat it is Sybil-proof, and that it requires only a small payment overhead, all\nthis is achieved with iterated elimination of dominated strategies. We\ncomplement this result by showing that there are no reward schemes in which\ninformation propagation and no self-cloning is a dominant strategy.", 
    "link": "http://arxiv.org/pdf/1111.2626v2", 
    "arxiv-id": "1111.2626v2"
},{
    "category": "cs.GT", 
    "author": "Arunesh Sinha", 
    "title": "Adaptive Regret Minimization in Bounded-Memory Games", 
    "publish": "2011-11-11T23:49:24Z", 
    "summary": "Online learning algorithms that minimize regret provide strong guarantees in\nsituations that involve repeatedly making decisions in an uncertain\nenvironment, e.g. a driver deciding what route to drive to work every day.\nWhile regret minimization has been extensively studied in repeated games, we\nstudy regret minimization for a richer class of games called bounded memory\ngames. In each round of a two-player bounded memory-m game, both players\nsimultaneously play an action, observe an outcome and receive a reward. The\nreward may depend on the last m outcomes as well as the actions of the players\nin the current round. The standard notion of regret for repeated games is no\nlonger suitable because actions and rewards can depend on the history of play.\nTo account for this generality, we introduce the notion of k-adaptive regret,\nwhich compares the reward obtained by playing actions prescribed by the\nalgorithm against a hypothetical k-adaptive adversary with the reward obtained\nby the best expert in hindsight against the same adversary. Roughly, a\nhypothetical k-adaptive adversary adapts her strategy to the defender's actions\nexactly as the real adversary would within each window of k rounds. Our\ndefinition is parametrized by a set of experts, which can include both fixed\nand adaptive defender strategies.\n  We investigate the inherent complexity of and design algorithms for adaptive\nregret minimization in bounded memory games of perfect and imperfect\ninformation. We prove a hardness result showing that, with imperfect\ninformation, any k-adaptive regret minimizing algorithm (with fixed strategies\nas experts) must be inefficient unless NP=RP even when playing against an\noblivious adversary. In contrast, for bounded memory games of perfect and\nimperfect information we present approximate 0-adaptive regret minimization\nalgorithms against an oblivious adversary running in time n^{O(1)}.", 
    "link": "http://arxiv.org/pdf/1111.2888v5", 
    "arxiv-id": "1111.2888v5"
},{
    "category": "cs.GT", 
    "author": "Balasubramanian Sivan", 
    "title": "Optimal Crowdsourcing Contests", 
    "publish": "2011-11-12T02:38:16Z", 
    "summary": "We study the design and approximation of optimal crowdsourcing contests.\nCrowdsourcing contests can be modeled as all-pay auctions because entrants must\nexert effort up-front to enter. Unlike all-pay auctions where a usual design\nobjective would be to maximize revenue, in crowdsourcing contests, the\nprincipal only benefits from the submission with the highest quality. We give a\ntheory for optimal crowdsourcing contests that mirrors the theory of optimal\nauction design: the optimal crowdsourcing contest is a virtual valuation\noptimizer (the virtual valuation function depends on the distribution of\ncontestant skills and the number of contestants). We also compare crowdsourcing\ncontests with more conventional means of procurement. In this comparison,\ncrowdsourcing contests are relatively disadvantaged because the effort of\nlosing contestants is wasted. Nonetheless, we show that crowdsourcing contests\nare 2-approximations to conventional methods for a large family of \"regular\"\ndistributions, and 4-approximations, otherwise.", 
    "link": "http://arxiv.org/pdf/1111.2893v1", 
    "arxiv-id": "1111.2893v1"
},{
    "category": "cs.GT", 
    "author": "Rann Smorodinsky", 
    "title": "Privacy-Aware Mechanism Design", 
    "publish": "2011-11-14T20:32:33Z", 
    "summary": "In traditional mechanism design, agents only care about the utility they\nderive from the outcome of the mechanism. We look at a richer model where\nagents also assign non-negative dis-utility to the information about their\nprivate types leaked by the outcome of the mechanism.\n  We present a new model for privacy-aware mechanism design, where we only\nassume an upper bound on the agents' loss due to leakage, as opposed to\nprevious work where a full characterization of the loss was required.\n  In this model, under a mild assumption on the distribution of how agents\nvalue their privacy, we show a generic construction of privacy-aware mechanisms\nand demonstrate its applicability to electronic polling and pricing of a\ndigital good.", 
    "link": "http://arxiv.org/pdf/1111.3350v2", 
    "arxiv-id": "1111.3350v2"
},{
    "category": "cs.GT", 
    "author": "Rann Smorodinsky", 
    "title": "Equilibrium and Potential in Coalitional Congestion Games", 
    "publish": "2011-11-16T20:09:13Z", 
    "summary": "The model of congestion games is widely used to analyze games related to\ntraffic and communication. A central property of these games is that they are\npotential games and hence posses a pure Nash equilibrium. In reality it is\noften the case that some players cooperatively decide on their joint action in\norder to maximize the coalition's total utility. This is by modeled by\nCoalitional Congestion Games. Typical settings include truck drivers who work\nfor the same shipping company, or routers that belong to the same ISP. The\nformation of coalitions will typically imply that the resulting coalitional\ncongestion game will no longer posses a pure Nash equilibrium. In this paper we\nprovide conditions under which such games are potential games and posses a pure\nNash equilibrium.", 
    "link": "http://arxiv.org/pdf/1111.3933v1", 
    "arxiv-id": "1111.3933v1"
},{
    "category": "cs.GT", 
    "author": "Adam O. Kalinich", 
    "title": "Flipping the Winner of a Poset Game", 
    "publish": "2011-11-21T14:03:42Z", 
    "summary": "Partially-ordered set games, also called poset games, are a class of\ntwo-player combinatorial games. The playing field consists of a set of\nelements, some of which are greater than other elements. Two players take turns\nremoving an element and all elements greater than it, and whoever takes the\nlast element wins. Examples of poset games include Nim and Chomp. We\ninvestigate the complexity of computing which player of a poset game has a\nwinning strategy. We give an inductive procedure that modifies poset games to\nchange the nim- value which informally captures the winning strategies in the\ngame. For a generic poset game G, we describe an efficient method for\nconstructing a game not G such that the first player has a winning strategy if\nand only if the second player has a winning strategy on G. This solves the\nlong-standing problem of whether this construction can be done efficiently.\nThis construction also allows us to reduce the class of Boolean formulas to\nposet games, establishing a lower bound on the complexity of poset games.", 
    "link": "http://arxiv.org/pdf/1111.4872v1", 
    "arxiv-id": "1111.4872v1"
},{
    "category": "cs.GT", 
    "author": "Salil Vadhan", 
    "title": "Truthful Mechanisms for Agents that Value Privacy", 
    "publish": "2011-11-23T12:12:32Z", 
    "summary": "Recent work has constructed economic mechanisms that are both truthful and\ndifferentially private. In these mechanisms, privacy is treated separately from\nthe truthfulness; it is not incorporated in players' utility functions (and\ndoing so has been shown to lead to non-truthfulness in some cases). In this\nwork, we propose a new, general way of modelling privacy in players' utility\nfunctions. Specifically, we only assume that if an outcome $o$ has the property\nthat any report of player $i$ would have led to $o$ with approximately the same\nprobability, then $o$ has small privacy cost to player $i$. We give three\nmechanisms that are truthful with respect to our modelling of privacy: for an\nelection between two candidates, for a discrete version of the facility\nlocation problem, and for a general social choice problem with discrete\nutilities (via a VCG-like mechanism). As the number $n$ of players increases,\nthe social welfare achieved by our mechanisms approaches optimal (as a fraction\nof $n$).", 
    "link": "http://arxiv.org/pdf/1111.5472v2", 
    "arxiv-id": "1111.5472v2"
},{
    "category": "cs.GT", 
    "author": "Rann Smorodinsky", 
    "title": "Greediness and Equilibrium in Congestion Games", 
    "publish": "2011-11-26T12:23:36Z", 
    "summary": "Rosenthal (1973) introduced the class of congestion games and proved that\nthey always possess a Nash equilibrium in pure strategies. Fotakis et al.\n(2005) introduce the notion of a greedy strategy tuple, where players\nsequentially and irrevocably choose a strategy that is a best response to the\nchoice of strategies by former players. Whereas the former solution concept is\ndriven by strong assumptions on the rationality of the players and the common\nknowledge thereof, the latter assumes very little rationality on the players'\nbehavior. From Fotakis \\cite{fotakis10} it follows that for Tree Representable\ncongestion Games greedy behavior leads to a NE. In this paper we obtain\nnecessary and sufficient conditions for the equivalence of these two solution\nconcepts. Such equivalence enhances the viability of these concepts as\nrealistic outcomes of the environment. The conditions for such equivalence to\nemerge for monotone symmetric games is that the strategy set has a tree-form,\nor equivalently is a `extension-parallel graph'.", 
    "link": "http://arxiv.org/pdf/1111.6156v2", 
    "arxiv-id": "1111.6156v2"
},{
    "category": "cs.GT", 
    "author": "Giovanni Viglietta", 
    "title": "Hardness of Mastermind", 
    "publish": "2011-11-29T18:30:12Z", 
    "summary": "Mastermind is a popular board game released in 1971, where a codemaker\nchooses a secret pattern of colored pegs, and a codebreaker has to guess it in\nseveral trials. After each attempt, the codebreaker gets a response from the\ncodemaker containing some information on the number of correctly guessed pegs.\nThe search space is thus reduced at each turn, and the game continues until the\ncodebreaker is able to find the correct code, or runs out of trials.\n  In this paper we study several variations of #MSP, the problem of computing\nthe size of the search space resulting from a given (possibly fictitious)\nsequence of guesses and responses. Our main contribution is a proof of the\n#P-completeness of #MSP under parsimonious reductions, which settles an open\nproblem posed by Stuckman and Zhang in 2005, concerning the complexity of\ndeciding if the secret code is uniquely determined by the previous guesses and\nresponses. Similarly, #MSP stays #P-complete under Turing reductions even with\nthe promise that the search space has at least k elements, for any constant k.\n(In a regular game of Mastermind, k=1.)\n  All our hardness results hold even in the most restrictive setting, in which\nthere are only two available peg colors, and also if the codemaker's responses\ncontain less information, for instance like in the so-called single-count\n(black peg) Mastermind variation.", 
    "link": "http://arxiv.org/pdf/1111.6922v2", 
    "arxiv-id": "1111.6922v2"
},{
    "category": "cs.GT", 
    "author": "Pierre Lescanne", 
    "title": "Les crashs sont rationnels", 
    "publish": "2011-11-30T20:27:28Z", 
    "summary": "As we show by using notions of equilibrium in infinite sequential games,\ncrashes or financial escalations are rational for economic or environmental\nagents, who have a vision of an infinite world. This contradicts a picture of a\nself-regulating, wise and pacific economic world. In other words, in this\ncontext, equilibrium is not synonymous of stability. We try to draw, from this\nstatement, methodological consequences and new ways of thinking, especially in\neconomic game theory. Among those new paths, coinduction is the basis of our\nreasoning in infinite games.", 
    "link": "http://arxiv.org/pdf/1111.7299v5", 
    "arxiv-id": "1111.7299v5"
},{
    "category": "cs.GT", 
    "author": "Sven Schewe", 
    "title": "Time and Parallelizability Results for Parity Games with Bounded Tree   and DAG Width", 
    "publish": "2011-12-01T16:05:26Z", 
    "summary": "Parity games are a much researched class of games in NP intersect CoNP that\nare not known to be in P. Consequently, researchers have considered specialised\nalgorithms for the case where certain graph parameters are small. In this\npaper, we study parity games on graphs with bounded treewidth, and graphs with\nbounded DAG width. We show that parity games with bounded DAG width can be\nsolved in O(n^(k+3) k^(k + 2) (d + 1)^(3k + 2)) time, where n, k, and d are the\nsize, treewidth, and number of priorities in the parity game. This is an\nimprovement over the previous best algorithm, given by Berwanger et al., which\nruns in n^O(k^2) time. We also show that, if a tree decomposition is provided,\nthen parity games with bounded treewidth can be solved in O(n k^(k + 5) (d +\n1)^(3k + 5)) time. This improves over previous best algorithm, given by\nObdrzalek, which runs in O(n d^(2(k+1)^2)) time. Our techniques can also be\nadapted to show that the problem of solving parity games with bounded treewidth\nlies in the complexity class NC^2, which is the class of problems that can be\nefficiently parallelized. This is in stark contrast to the general parity game\nproblem, which is known to be P-hard, and thus unlikely to be contained in NC.", 
    "link": "http://arxiv.org/pdf/1112.0221v6", 
    "arxiv-id": "1112.0221v6"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Knightian Auctions", 
    "publish": "2011-12-06T02:53:14Z", 
    "summary": "We study single-good auctions in a setting where each player knows his own\nvaluation only within a constant multiplicative factor \\delta{} in (0,1), and\nthe mechanism designer knows \\delta. The classical notions of implementation in\ndominant strategies and implementation in undominated strategies are naturally\nextended to this setting, but their power is vastly different.\n  On the negative side, we prove that no dominant-strategy mechanism can\nguarantee social welfare that is significantly better than that achievable by\nassigning the good to a random player.\n  On the positive side, we provide tight upper and lower bounds for the\nfraction of the maximum social welfare achievable in undominated strategies,\nwhether deterministically or probabilistically.", 
    "link": "http://arxiv.org/pdf/1112.1147v1", 
    "arxiv-id": "1112.1147v1"
},{
    "category": "cs.GT", 
    "author": "Pierre Lescanne", 
    "title": "Rationality and Escalation in Infinite Extensive Games", 
    "publish": "2011-12-06T07:58:34Z", 
    "summary": "The aim of this of this paper is to study infinite games and to prove\nformally some properties in this framework. As a consequence we show that the\nbehavior (the madness) of people which leads to speculative crashes or\nescalation can be fully rational. Indeed it proceeds from the statement that\nresources are infinite. The reasoning is based on the concept of coinduction\nconceived by computer scientists to model infinite computations and used by\neconomic agents unknowingly. When used consciously, this concept is not as\nsimple as induction and we could paraphrase Newton: \"Modeling the madness of\npeople is more difficult than modeling the motion of planets\".", 
    "link": "http://arxiv.org/pdf/1112.1185v3", 
    "arxiv-id": "1112.1185v3"
},{
    "category": "cs.GT", 
    "author": "M\u00e9rouane Debbah", 
    "title": "Equilibria of Channel Selection Games in Parallel Multiple Access   Channel", 
    "publish": "2011-12-08T17:47:08Z", 
    "summary": "In this paper, we study the decentralized parallel multiple access channel\n(MAC) when transmitters selfishly maximize their individual spectral efficiency\nby selecting a single channel to transmit. More specifically, we investigate\nthe set of Nash equilibria (NE) of decentralized networks comprising several\ntransmitters communicating with a single receiver that implements single user\ndecoding. This scenario is modeled as a one-shot game where the players (the\ntransmitters) have discrete action sets (the channels). We show that the\ncorresponding game has always at least one NE in pure strategies, but,\ndepending on certain parameters, the game might possess several NE. We provide\nan upper bound for the maximum number of NE as a function of the number of\ntransmitters and available channels. The main contribution of this paper is a\nmathematical proof of the existence of a Braess-type paradox. In particular, it\nis shown that under the assumption of a fully loaded network, when transmitters\nare allowed to use all the available channels, the corresponding sum spectral\nefficiency achieved at the NE is lower or equal than the sum spectral\nefficiency achieved when transmitters can use only one channel. A formal proof\nof this observation is provided in the case of small networks. For general\nscenarios, we provide numerical examples that show that the same effect holds\nas long as the network is kept fully loaded. We conclude the paper by\nconsidering the case of successive interference cancellation at the receiver.\nIn this context, we show that the power allocation vectors at the NE are\ncapacity maximizers. Finally, simulations are presented to verify our\ntheoretical results.", 
    "link": "http://arxiv.org/pdf/1112.1895v1", 
    "arxiv-id": "1112.1895v1"
},{
    "category": "cs.GT", 
    "author": "Guido Schaefer", 
    "title": "The Robust Price of Anarchy of Altruistic Games", 
    "publish": "2011-12-15T21:51:12Z", 
    "summary": "We study the inefficiency of equilibria for various classes of games when\nplayers are (partially) altruistic. We model altruistic behavior by assuming\nthat player i's perceived cost is a convex combination of 1-\\alpha_i times his\ndirect cost and \\alpha_i times the social cost. Tuning the parameters \\alpha_i\nallows smooth interpolation between purely selfish and purely altruistic\nbehavior. Within this framework, we study altruistic extensions of linear\ncongestion games, fair cost-sharing games and valid utility games.\n  We derive (tight) bounds on the price of anarchy of these games for several\nsolution concepts. Thereto, we suitably adapt the smoothness notion introduced\nby Roughgarden and show that it captures the essential properties to determine\nthe robust price of anarchy of these games. Our bounds show that for congestion\ngames and cost-sharing games, the worst-case robust price of anarchy increases\nwith increasing altruism, while for valid utility games, it remains constant\nand is not affected by altruism. However, the increase in the price of anarchy\nis not a universal phenomenon: for symmetric singleton linear congestion games,\nwe derive a bound on the pure price of anarchy that decreases as the level of\naltruism increases. Since the bound is also strictly lower than the robust\nprice of anarchy, it exhibits a natural example in which Nash equilibria are\nmore efficient than more permissive notions of equilibrium.", 
    "link": "http://arxiv.org/pdf/1112.3680v2", 
    "arxiv-id": "1112.3680v2"
},{
    "category": "cs.GT", 
    "author": "S. Matthew Weinberg", 
    "title": "On Optimal Multi-Dimensional Mechanism Design", 
    "publish": "2011-12-17T01:42:24Z", 
    "summary": "We efficiently solve the optimal multi-dimensional mechanism design problem\nfor independent bidders with arbitrary demand constraints when either the\nnumber of bidders is a constant or the number of items is a constant. In the\nfirst setting, we need that each bidder's values for the items are sampled from\na possibly correlated, item-symmetric distribution, allowing different\ndistributions for each bidder. In the second setting, we allow the values of\neach bidder for the items to be arbitrarily correlated, but assume that the\ndistribution of bidder types is bidder-symmetric.\n  For all eps>0, we obtain an additive eps-approximation, when the value\ndistributions are bounded, or a multiplicative (1-eps)-approximation when the\nvalue distributions are unbounded, but satisfy the Monotone Hazard Rate\ncondition, covering a widely studied class of distributions in Economics. Our\nruntime is polynomial in max{#items,#bidders}, and not the size of the support\nof the joint distribution of all bidders' values for all items, which is\ntypically exponential in both the number of items and the number of bidders.\nOur mechanisms are randomized, explicitly price bundles, and can sometimes\naccommodate budget constraints.\n  Our results are enabled by establishing several new tools and structural\nproperties of Bayesian mechanisms. We provide a symmetrization technique\nturning any truthful mechanism into one that has the same revenue and respects\nall symmetries in the underlying value distributions. We also prove that\nitem-symmetric mechanisms satisfy a natural monotonicity property which, unlike\ncyclic-monotonicity, can be harnessed algorithmically. Finally, we provide a\ntechnique that turns any given eps-BIC mechanism (i.e. one where incentive\nconstraints are violated by eps) into a truly-BIC mechanism at the cost of\nO(sqrt{eps}) revenue. We expect our tools to be used beyond the settings we\nconsider here.", 
    "link": "http://arxiv.org/pdf/1112.4006v1", 
    "arxiv-id": "1112.4006v1"
},{
    "category": "cs.GT", 
    "author": "Guido Proietti", 
    "title": "Bounded-Distance Network Creation Games", 
    "publish": "2011-12-19T08:30:51Z", 
    "summary": "A network creation game simulates a decentralized and non-cooperative\nbuilding of a communication network. Informally, there are $n$ players sitting\non the network nodes, which attempt to establish a reciprocal communication by\nactivating, incurring a certain cost, any of their incident links. The goal of\neach player is to have all the other nodes as close as possible in the\nresulting network, while buying as few links as possible. According to this\nintuition, any model of the game must then appropriately address a balance\nbetween these two conflicting objectives. Motivated by the fact that a player\nmight have a strong requirement about its centrality in the network, in this\npaper we introduce a new setting in which if a player maintains its (either\nmaximum or average) distance to the other nodes within a given associated\nbound, then its cost is simply equal to the number of activated edges,\notherwise its cost is unbounded. We study the problem of understanding the\nstructure of associated pure Nash equilibria of the resulting games, that we\ncall MaxBD and SumBD, respectively. For both games, we show that computing the\nbest response of a player is an NP-hard problem. Next, we show that when\ndistance bounds associated with players are non-uniform, then equilibria can be\narbitrarily bad. On the other hand, for MaxBD, we show that when nodes have a\nuniform bound $R$ on the maximum distance, then the Price of Anarchy (PoA) is\nlower and upper bounded by 2 and $O(n^{\\frac{1}{\\lfloor\\log_3 R\\rfloor+1}})$\nfor $R \\geq 3$, while for the interesting case R=2, we are able to prove that\nthe PoA is $\\Omega(\\sqrt{n})$ and $O(\\sqrt{n \\log n})$. For the uniform SumBD\nwe obtain similar (asymptotically) results, and moreover we show that the PoA\nbecomes constant as soon as the bound on the average distance is\n$n^{\\omega(\\frac{1}{\\sqrt{\\log n}})}$.", 
    "link": "http://arxiv.org/pdf/1112.4264v1", 
    "arxiv-id": "1112.4264v1"
},{
    "category": "cs.GT", 
    "author": "S. Matthew Weinberg", 
    "title": "An Algorithmic Characterization of Multi-Dimensional Mechanisms", 
    "publish": "2011-12-20T05:03:40Z", 
    "summary": "We obtain a characterization of feasible, Bayesian, multi-item multi-bidder\nauctions with independent, additive bidders as distributions over hierarchical\nmechanisms. Combined with cyclic-monotonicity our results provide a complete\ncharacterization of feasible, Bayesian Incentive Compatible (BIC) auctions for\nthis setting.\n  Our characterization is enabled by a novel, constructive proof of Border's\ntheorem, and a new generalization of this theorem to independent (but not\nnecessarily iid) bidders. For one item and independent bidders, we show that\nany feasible reduced form auction can be implemented as a distribution over\nhierarchical mechanisms. We also give a polytime algorithm for determining\nfeasibility of a reduced form, or finding a separation hyperplane from feasible\nreduced forms. Finally, we provide polytime algorithms to find and exactly\nsample from a distribution over hierarchical mechanisms consistent with a given\nfeasible reduced form.\n  Our results generalize to multi-item reduced forms for independent, additive\nbidders. For multiple items, additive bidders with hard demand constraints, and\narbitrary value correlation across items or bidders, we give a proper\ngeneralization of Border's theorem, and characterize feasible reduced forms as\nmulticommodity flows in related multicommodity flow instances. We show that our\ngeneralization holds for a broader class of feasibility constraints, including\nintersections of any two matroids.\n  As a corollary we obtain revenue-optimal, BIC mechanisms in multi-item\nmulti-bidder settings, when each bidder has arbitrarily correlated values over\nthe items and additive valuations over bundles, and bidders are independent.\nTheir runtime is polynomial in the total number of bidder types (instead of\ntype profiles), and is improved to poly(#items, #bidders) using recent\nstructural results on optimal BIC auctions in item-symmetric settings.", 
    "link": "http://arxiv.org/pdf/1112.4572v1", 
    "arxiv-id": "1112.4572v1"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "Solving simple stochastic games with few coin toss positions", 
    "publish": "2011-12-22T09:29:05Z", 
    "summary": "Gimbert and Horn gave an algorithm for solving simple stochastic games with\nrunning time O(r! n) where n is the number of positions of the simple\nstochastic game and r is the number of its coin toss positions. Chatterjee et\nal. pointed out that a variant of strategy iteration can be implemented to\nsolve this problem in time 4^r r^{O(1)} n^{O(1)}. In this paper, we show that\nan algorithm combining value iteration with retrograde analysis achieves a time\nbound of O(r 2^r (r log r + n)), thus improving both time bounds. While the\nalgorithm is simple, the analysis leading to this time bound is involved, using\ntechniques of extremal combinatorics to identify worst case instances for the\nalgorithm.", 
    "link": "http://arxiv.org/pdf/1112.5255v3", 
    "arxiv-id": "1112.5255v3"
},{
    "category": "cs.GT", 
    "author": "Martin Starnberger", 
    "title": "On Multiple Round Sponsored Search Auctions with Budgets", 
    "publish": "2011-12-29T18:14:33Z", 
    "summary": "In a sponsored search auction the advertisement slots on a search result page\nare generally ordered by click-through rate. Bidders have a valuation, which is\nusually assumed to be linear in the click-through rate, a budget constraint,\nand receive at most one slot per search result page (round). We study\nmulti-round sponsored search auctions, where the different rounds are linked\nthrough the budget constraints of the bidders and the valuation of a bidder for\nall rounds is the sum of the valuations for the individual rounds. All\nmechanisms published so far either study one-round sponsored search auctions or\nthe setting where every round has only one slot and all slots have the same\nclick-through rate, which is identical to a multi-item auction.\n  This paper contains the following three results: (1) We give the first\nmechanism for the multi-round sponsored search problem where different slots\nhave different click-through rates. Our mechanism is incentive compatible in\nexpectation, individually rational in expectation, Pareto optimal in\nexpectation, and also ex-post Pareto optimal for each realized outcome. (2)\nAdditionally we study the combinatorial setting, where each bidder is only\ninterested in a subset of the rounds. We give a deterministic, incentive\ncompatible, individually rational, and Pareto optimal mechanism for the setting\nwhere all slots have the same click-through rate. (3) We present an\nimpossibility result for auctions where bidders have diminishing marginal\nvaluations. Specifically, we show that even for the multi-unit (one slot per\nround) setting there is no incentive compatible, individually rational, and\nPareto optimal mechanism for private diminishing marginal valuations and public\nbudgets.", 
    "link": "http://arxiv.org/pdf/1112.6361v1", 
    "arxiv-id": "1112.6361v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Polyhedral Clinching Auctions and the Adwords Polytope", 
    "publish": "2012-01-02T01:05:34Z", 
    "summary": "A central issue in applying auction theory in practice is the problem of\ndealing with budget-constrained agents. A desirable goal in practice is to\ndesign incentive compatible, individually rational, and Pareto optimal auctions\nwhile respecting the budget constraints. Achieving this goal is particularly\nchallenging in the presence of nontrivial combinatorial constraints over the\nset of feasible allocations.\n  Toward this goal and motivated by AdWords auctions, we present an auction for\n{\\em polymatroidal} environments satisfying the above properties. Our auction\nemploys a novel clinching technique with a clean geometric description and only\nneeds an oracle access to the submodular function defining the polymatroid. As\na result, this auction not only simplifies and generalizes all previous\nresults, it applies to several new applications including AdWords Auctions,\nbandwidth markets, and video on demand. In particular, our characterization of\nthe AdWords auction as polymatroidal constraints might be of independent\ninterest. This allows us to design the first mechanism for Ad Auctions taking\ninto account simultaneously budgets, multiple keywords and multiple slots.\n  We show that it is impossible to extend this result to generic polyhedral\nconstraints. This also implies an impossibility result for multi-unit auctions\nwith decreasing marginal utilities in the presence of budget constraints.", 
    "link": "http://arxiv.org/pdf/1201.0404v3", 
    "arxiv-id": "1201.0404v3"
},{
    "category": "cs.GT", 
    "author": "Varun R Embar", 
    "title": "Pattern Clustering using Cooperative Game Theory", 
    "publish": "2012-01-02T12:56:30Z", 
    "summary": "In this paper, we approach the classical problem of clustering using solution\nconcepts from cooperative game theory such as Nucleolus and Shapley value. We\nformulate the problem of clustering as a characteristic form game and develop a\nnovel algorithm DRAC (Density-Restricted Agglomerative Clustering) for\nclustering. With extensive experimentation on standard data sets, we compare\nthe performance of DRAC with that of well known algorithms. We show an\ninteresting result that four prominent solution concepts, Nucleolus, Shapley\nvalue, Gately point and \\tau-value coincide for the defined characteristic form\ngame. This vindicates the choice of the characteristic function of the\nclustering game and also provides strong intuitive foundation for our approach.", 
    "link": "http://arxiv.org/pdf/1201.0461v1", 
    "arxiv-id": "1201.0461v1"
},{
    "category": "cs.GT", 
    "author": "Youngmi Jin", 
    "title": "Stochastic Loss Aversion for Random Medium Access", 
    "publish": "2012-01-09T14:24:37Z", 
    "summary": "We consider a slotted-ALOHA LAN with loss-averse, noncooperative greedy\nusers. To avoid non-Pareto equilibria, particularly deadlock, we assume\nprobabilistic loss-averse behavior. This behavior is modeled as a modulated\nwhite noise term, in addition to the greedy term, creating a diffusion process\nmodeling the game. We observe that when player's modulate with their\nthroughput, a more efficient exploration of play-space results, and so finding\na Pareto equilibrium is more likely over a given interval of time.", 
    "link": "http://arxiv.org/pdf/1201.1776v2", 
    "arxiv-id": "1201.1776v2"
},{
    "category": "cs.GT", 
    "author": "Thomas A. Henzinger", 
    "title": "Strategy Improvement for Concurrent Reachability and Safety Games", 
    "publish": "2012-01-13T13:38:21Z", 
    "summary": "We consider concurrent games played on graphs. At every round of a game, each\nplayer simultaneously and independently selects a move; the moves jointly\ndetermine the transition to a successor state. Two basic objectives are the\nsafety objective to stay forever in a given set of states, and its dual, the\nreachability objective to reach a given set of states. First, we present a\nsimple proof of the fact that in concurrent reachability games, for all\n$\\epsilon>0$, memoryless $\\epsilon$-optimal strategies exist. A memoryless\nstrategy is independent of the history of plays, and an $\\epsilon$-optimal\nstrategy achieves the objective with probability within $\\epsilon$ of the value\nof the game. In contrast to previous proofs of this fact, our proof is more\nelementary and more combinatorial. Second, we present a strategy-improvement\n(a.k.a.\\ policy-iteration) algorithm for concurrent games with reachability\nobjectives. We then present a strategy-improvement algorithm for concurrent\ngames with safety objectives. Our algorithms yield sequences of player-1\nstrategies which ensure probabilities of winning that converge monotonically to\nthe value of the game. Our result is significant because the\nstrategy-improvement algorithm for safety games provides, for the first time, a\nway to approximate the value of a concurrent safety game from below. Previous\nmethods could approximate the values of these games only from one direction,\nand as no rates of convergence are known, they did not provide a practical way\nto solve these games.", 
    "link": "http://arxiv.org/pdf/1201.2834v3", 
    "arxiv-id": "1201.2834v3"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Social Norm Design for Information Exchange Systems with Limited   Observations", 
    "publish": "2012-01-13T19:12:39Z", 
    "summary": "Information exchange systems differ in many ways, but all share a common\nvulnerability to selfish behavior and free-riding. In this paper, we build\nincentives schemes based on social norms. Social norms prescribe a social\nstrategy for the users in the system to follow and deploy reputation schemes to\nreward or penalize users depending on their behaviors. Because users in these\nsystems often have only limited capability to observe the global system\ninformation, e.g. the reputation distribution of the users participating in the\nsystem, their beliefs about the reputation distribution are heterogeneous and\nbiased. Such belief heterogeneity causes a positive fraction of users to not\nfollow the social strategy. In such practical scenarios, the standard\nequilibrium analysis deployed in the economics literature is no longer directly\napplicable and hence, the system design needs to consider these differences. To\ninvestigate how the system designs need to change when the participating users\nhave only limited observations, we focus on a simple social norm with binary\nreputation labels but allow adjusting the punishment severity through\nrandomization. First, we model the belief heterogeneity using a suitable\nBayesian belief function. Next, we formalize the users' optimal decision\nproblems and derive in which scenarios they follow the prescribed social\nstrategy. With this result, we then study the system dynamics and formally\ndefine equilibrium in the sense that the system is stable when users\nstrategically optimize their decisions. By rigorously studying two specific\ncases where users' belief distribution is constant or is linearly influenced by\nthe true reputation distribution, we prove that the optimal reputation update\nrule is to choose the mildest possible punishment. This result is further\nconfirmed for higher order beliefs in simulations.", 
    "link": "http://arxiv.org/pdf/1201.2918v2", 
    "arxiv-id": "1201.2918v2"
},{
    "category": "cs.GT", 
    "author": "Florian Brandl", 
    "title": "Existence of Stability in Hedonic Coalition Formation Games", 
    "publish": "2012-01-23T16:15:22Z", 
    "summary": "In this paper, we examine \\emph{hedonic coalition formation games} in which\neach player's preferences over partitions of players depend only on the members\nof his coalition. We present three main results in which restrictions on the\npreferences of the players guarantee the existence of stable partitions for\nvarious notions of stability. The preference restrictions pertain to \\emph{top\nresponsiveness} and \\emph{bottom responsiveness} which model optimistic and\npessimistic behavior of players respectively. The existence results apply to\nnatural subclasses of \\emph{additive separable hedonic games} and \\emph{hedonic\ngames with \\B-preferences}. It is also shown that our existence results cannot\nbe strengthened to the case of stronger known stability concepts.", 
    "link": "http://arxiv.org/pdf/1201.4754v1", 
    "arxiv-id": "1201.4754v1"
},{
    "category": "cs.GT", 
    "author": "Peter Key", 
    "title": "Fixed and Market Pricing for Cloud Services", 
    "publish": "2012-01-26T19:59:45Z", 
    "summary": "We study a model of congestible resources, where pricing and scheduling are\nintertwined. Motivated by the problem of pricing cloud instances, we model a\ncloud computing service as linked $GI/GI/\\cdot$ queuing systems where the\nprovider chooses to offer a fixed pricing service, a dynamic market based\nservice, or a hybrid of both, where jobs can be preempted in the market-based\nservice. Users (jobs), who are heterogeneous in both the value they place on\nservice and their cost for waiting, then choose between the services offered.\nCombining insights from auction theory with queuing theory we are able to\ncharacterize user equilibrium behavior, and show its insensitivity to the\nprecise market design mechanism used. We then provide theoretical and\nsimulation based evidence suggesting that a fixed price typically, though not\nalways, generates a higher expected revenue than the hybrid system for the\nprovider.", 
    "link": "http://arxiv.org/pdf/1201.5621v2", 
    "arxiv-id": "1201.5621v2"
},{
    "category": "cs.GT", 
    "author": "\u00c9va Tardos", 
    "title": "Bounding the inefficiency of outcomes in generalized second price   auctions", 
    "publish": "2012-01-31T03:36:26Z", 
    "summary": "The Generalized Second Price (GSP) auction is the primary auction used for\nmonetizing the use of the Internet. It is well-known that truthtelling is not a\ndominant strategy in this auction and that inefficient equilibria can arise. In\nthis paper we study the space of equilibria in GSP, and quantify the efficiency\nloss that can arise in equilibria under a wide range of sources of uncertainty,\nas well as in the full information setting. The traditional Bayesian game\nmodels uncertainty in the valuations (types) of the participants. The\nGeneralized Second Price (GSP) auction gives rise to a further form of\nuncertainty: the selection of quality factors resulting in uncertainty about\nthe behavior of the underlying ad allocation algorithm. The bounds we obtain\napply to both forms of uncertainty, and are robust in the sense that they apply\nunder various perturbations of the solution concept, extending to models with\ninformation asymmetries and bounded rationality in the form of learning\nstrategies.\n  We present a constant bound (2.927) on the factor of the efficiency loss\n(\\emph{price of anarchy}) of the corresponding game for the Bayesian model of\npartial information about other participants and about ad quality factors. For\nthe full information setting, we prove a surprisingly low upper bound of 1.282\non the price of anarchy over pure Nash equilibria, nearly matching a lower\nbound of 1.259 for the case of three advertisers. Further, we do not require\nthat the system reaches equilibrium, and give similarly low bounds also on the\nquality degradation for any no-regret learning outcome. Our conclusion is that\nthe number of advertisers in the auction has almost no impact on the price of\nanarchy, and that the efficiency of GSP is very robust with respect to the\nbelief and rationality assumptions imposed on the participants.", 
    "link": "http://arxiv.org/pdf/1201.6429v2", 
    "arxiv-id": "1201.6429v2"
},{
    "category": "cs.GT", 
    "author": "Laurent Bartholdi", 
    "title": "The Game of Pure Strategy is solved!", 
    "publish": "2012-02-03T13:19:43Z", 
    "summary": "We solve the classical \"Game of Pure Strategy\" using linear programming. We\nnotice an intricate even-odd behavior in the results of our computations, that\nseems to encourage odd or maximal bids.", 
    "link": "http://arxiv.org/pdf/1202.0695v1", 
    "arxiv-id": "1202.0695v1"
},{
    "category": "cs.GT", 
    "author": "Omer Tamuz", 
    "title": "Bundling Customers: How to Exploit Trust Among Customers to Maximize   Seller Profit", 
    "publish": "2012-02-05T15:22:26Z", 
    "summary": "We consider an auction of identical digital goods to customers whose\nvaluations are drawn independently from known distributions. Myerson's classic\nresult identifies the truthful mechanism that maximizes the seller's expected\nprofit.\n  Under the assumption that in small groups customers can learn each others'\nvaluations, we show how Myerson's result can be improved to yield a higher\npayoff to the seller using a mechanism that offers groups of customers to buy\nbundles of items.", 
    "link": "http://arxiv.org/pdf/1202.0969v2", 
    "arxiv-id": "1202.0969v2"
},{
    "category": "cs.GT", 
    "author": "Or Sheffet", 
    "title": "Send Mixed Signals -- Earn More, Work Less", 
    "publish": "2012-02-07T18:13:15Z", 
    "summary": "Emek et al. presented a model of probabilistic single-item second price\nauctions where an auctioneer who is informed about the type of an item for\nsale, broadcasts a signal about this type to uninformed bidders. They proved\nthat finding the optimal (for the purpose of generating revenue) {\\em pure}\nsignaling scheme is strongly NP-hard. In contrast, we prove that finding the\noptimal {\\em mixed} signaling scheme can be done in polynomial time using\nlinear programming. For the proof, we show that the problem is strongly related\nto a problem of optimally bundling divisible goods for auctioning. We also\nprove that a mixed signaling scheme can in some cases generate twice as much\nrevenue as the best pure signaling scheme and we prove a generally applicable\nlower bound on the revenue generated by the best mixed signaling scheme.", 
    "link": "http://arxiv.org/pdf/1202.1483v1", 
    "arxiv-id": "1202.1483v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Signaling Schemes for Revenue Maximization", 
    "publish": "2012-02-08T03:48:31Z", 
    "summary": "Signaling is an important topic in the study of asymmetric information in\neconomic settings. In particular, the transparency of information available to\na seller in an auction setting is a question of major interest. We introduce\nthe study of signaling when conducting a second price auction of a\nprobabilistic good whose actual instantiation is known to the auctioneer but\nnot to the bidders. This framework can be used to model impressions selling in\ndisplay advertising. We study the problem of computing a signaling scheme that\nmaximizes the auctioneer's revenue in a Bayesian setting. While the general\ncase is proved to be computationally hard, several cases of interest are shown\nto be polynomially solvable. In addition, we establish a tight bound on the\nminimum number of signals required to implement an optimal signaling scheme and\nshow that at least half of the maximum social welfare can be preserved within\nsuch a scheme.", 
    "link": "http://arxiv.org/pdf/1202.1590v2", 
    "arxiv-id": "1202.1590v2"
},{
    "category": "cs.GT", 
    "author": "Rahul Sami", 
    "title": "Multi-outcome and Multidimensional Market Scoring Rules", 
    "publish": "2012-02-08T14:40:03Z", 
    "summary": "Hanson's market scoring rules allow us to design a prediction market that\nstill gives useful information even if we have an illiquid market with a\nlimited number of budget-constrained agents. Each agent can \"move\" the current\nprice of a market towards their prediction.\n  While this movement still occurs in multi-outcome or multidimensional markets\nwe show that no market-scoring rule, under reasonable conditions, always moves\nthe price directly towards beliefs of the agents. We present a modified version\nof a market scoring rule for budget-limited traders, and show that it does have\nthe property that, from any starting position, optimal trade by a\nbudget-limited trader will result in the market being moved towards the\ntrader's true belief. This mechanism also retains several attractive strategic\nproperties of the market scoring rule.", 
    "link": "http://arxiv.org/pdf/1202.1712v1", 
    "arxiv-id": "1202.1712v1"
},{
    "category": "cs.GT", 
    "author": "Jan Vondrak", 
    "title": "The Computational Complexity of Truthfulness in Combinatorial Auctions", 
    "publish": "2012-02-13T17:05:34Z", 
    "summary": "One of the fundamental questions of Algorithmic Mechanism Design is whether\nthere exists an inherent clash between truthfulness and computational\ntractability: in particular, whether polynomial-time truthful mechanisms for\ncombinatorial auctions are provably weaker in terms of approximation ratio than\nnon-truthful ones. This question was very recently answered for universally\ntruthful mechanisms for combinatorial auctions \\cite{D11}, and even for\ntruthful-in-expectation mechanisms \\cite{DughmiV11}. However, both of these\nresults are based on information-theoretic arguments for valuations given by a\nvalue oracle, and leave open the possibility of polynomial-time truthful\nmechanisms for succinctly described classes of valuations.\n  This paper is the first to prove {\\em computational hardness} results for\ntruthful mechanisms for combinatorial auctions with succinctly described\nvaluations. We prove that there is a class of succinctly represented submodular\nvaluations for which no deterministic truthful mechanism provides an\n$m^{1/2-\\epsilon}$-approximation for a constant $\\epsilon>0$, unless $NP=RP$\n($m$ denotes the number of items). Furthermore, we prove that even\ntruthful-in-expectation mechanisms cannot approximate combinatorial auctions\nwith certain succinctly described submodular valuations better than within\n$n^\\gamma$, where $n$ is the number of bidders and $\\gamma>0$ some absolute\nconstant, unless $NP \\subseteq P/poly$. In addition, we prove computational\nhardness results for two related problems.", 
    "link": "http://arxiv.org/pdf/1202.2789v1", 
    "arxiv-id": "1202.2789v1"
},{
    "category": "cs.GT", 
    "author": "Evangelia Pyrga", 
    "title": "Improving the Price of Anarchy for Selfish Routing via Coordination   Mechanisms", 
    "publish": "2012-02-13T21:41:11Z", 
    "summary": "We reconsider the well-studied Selfish Routing game with affine latency\nfunctions. The Price of Anarchy for this class of games takes maximum value\n4/3; this maximum is attained already for a simple network of two parallel\nlinks, known as Pigou's network. We improve upon the value 4/3 by means of\nCoordination Mechanisms.\n  We increase the latency functions of the edges in the network, i.e., if\n$\\ell_e(x)$ is the latency function of an edge $e$, we replace it by\n$\\hat{\\ell}_e(x)$ with $\\ell_e(x) \\le \\hat{\\ell}_e(x)$ for all $x$. Then an\nadversary fixes a demand rate as input. The engineered Price of Anarchy of the\nmechanism is defined as the worst-case ratio of the Nash social cost in the\nmodified network over the optimal social cost in the original network.\nFormally, if $\\CM(r)$ denotes the cost of the worst Nash flow in the modified\nnetwork for rate $r$ and $\\Copt(r)$ denotes the cost of the optimal flow in the\noriginal network for the same rate then [\\ePoA = \\max_{r \\ge 0}\n\\frac{\\CM(r)}{\\Copt(r)}.]\n  We first exhibit a simple coordination mechanism that achieves for any\nnetwork of parallel links an engineered Price of Anarchy strictly less than\n4/3. For the case of two parallel links our basic mechanism gives 5/4 = 1.25.\nThen, for the case of two parallel links, we describe an optimal mechanism; its\nengineered Price of Anarchy lies between 1.191 and 1.192.", 
    "link": "http://arxiv.org/pdf/1202.2877v2", 
    "arxiv-id": "1202.2877v2"
},{
    "category": "cs.GT", 
    "author": "Patrick Hummel", 
    "title": "Implementing Optimal Outcomes in Social Computing: A Game-Theoretic   Approach", 
    "publish": "2012-02-16T00:28:12Z", 
    "summary": "In many social computing applications such as online Q&A forums, the best\ncontribution for each task receives some high reward, while all remaining\ncontributions receive an identical, lower reward irrespective of their actual\nqualities. Suppose a mechanism designer (site owner) wishes to optimize an\nobjective that is some function of the number and qualities of received\ncontributions. When potential contributors are strategic agents, who decide\nwhether to contribute or not to selfishly maximize their own utilities, is such\na \"best contribution\" mechanism, M_B, adequate to implement an outcome that is\noptimal for the mechanism designer?\n  We first show that in settings where a contribution's value is determined\nprimarily by an agent's expertise, and agents only strategically choose whether\nto contribute or not, contests can implement optimal outcomes: for any\nreasonable objective, the rewards for the best and remaining contributions in\nM_B can always be chosen so that the outcome in the unique symmetric\nequilibrium of M_B maximizes the mechanism designer's utility. We also show how\nthe mechanism designer can learn these optimal rewards when she does not know\nthe parameters of the agents' utilities, as might be the case in practice. We\nnext consider settings where a contribution's value depends on both the\ncontributor's expertise as well as her effort, and agents endogenously choose\nhow much effort to exert in addition to deciding whether to contribute. Here,\nwe show that optimal outcomes can never be implemented by contests if the\nsystem can rank the qualities of contributions perfectly. However, if there is\nnoise in the contributions' rankings, then the mechanism designer can again\ninduce agents to follow strategies that maximize his utility. Thus imperfect\nrankings can actually help achieve implementability of optimal outcomes when\neffort is endogenous and influences quality.", 
    "link": "http://arxiv.org/pdf/1202.3480v1", 
    "arxiv-id": "1202.3480v1"
},{
    "category": "cs.GT", 
    "author": "Giorgos Stamatopoulos", 
    "title": "Cooperative oligopoly games with boundedly rational firms", 
    "publish": "2012-02-17T11:44:18Z", 
    "summary": "We analyze cooperative Cournot games with boundedly rational firms. Due to\ncogni- tive constraints, the members of a coalition cannot accurately predict\nthe coalitional structure of the non-members. Thus, they compute their value\nusing simple heuris- tics. In particular, they assign various non-equilibrium\nprobability distributions over the outsiders' set of partitions. We construct\nthe characteristic function of a coalition in such an environment and we\nanalyze the core of the corresponding games. We show that the core is non-empty\nprovided the number of firms in the market is sufficiently large. Moreover, we\nshow that if two distributions over the set of partitions are related via\nfirst-order dominance, then the core of the game under the dominated\ndistribution is a subset of the core under the dominant distribution.", 
    "link": "http://arxiv.org/pdf/1202.3885v2", 
    "arxiv-id": "1202.3885v2"
},{
    "category": "cs.GT", 
    "author": "Elias Tsigaridas", 
    "title": "Exact Algorithms for Solving Stochastic Games", 
    "publish": "2012-02-17T12:37:42Z", 
    "summary": "Shapley's discounted stochastic games, Everett's recursive games and\nGillette's undiscounted stochastic games are classical models of game theory\ndescribing two-player zero-sum games of potentially infinite duration. We\ndescribe algorithms for exactly solving these games.", 
    "link": "http://arxiv.org/pdf/1202.3898v1", 
    "arxiv-id": "1202.3898v1"
},{
    "category": "cs.GT", 
    "author": "Rupak Majumdar", 
    "title": "Equivalence of Games with Probabilistic Uncertainty and   Partial-observation Games", 
    "publish": "2012-02-19T10:00:59Z", 
    "summary": "We introduce games with probabilistic uncertainty, a natural model for\ncontroller synthesis in which the controller observes the state of the system\nthrough imprecise sensors that provide correct information about the current\nstate with a fixed probability. That is, in each step, the sensors return an\nobserved state, and given the observed state, there is a probability\ndistribution (due to the estimation error) over the actual current state. The\ncontroller must base its decision on the observed state (rather than the actual\ncurrent state, which it does not know). On the other hand, we assume that the\nenvironment can perfectly observe the current state. We show that our model can\nbe reduced in polynomial time to standard partial-observation stochastic games,\nand vice-versa. As a consequence we establish the precise decidability frontier\nfor the new class of games, and for most of the decidable problems establish\noptimal complexity results.", 
    "link": "http://arxiv.org/pdf/1202.4140v2", 
    "arxiv-id": "1202.4140v2"
},{
    "category": "cs.GT", 
    "author": "Paraskevas V. Lekeas", 
    "title": "Should I quit using my resource? Modeling Resource Usage through Game   Theory", 
    "publish": "2012-02-20T12:42:32Z", 
    "summary": "Existing web infrastructures have supported the publication of a tremendous\namount of resources, and over the past few years Data Resource Usage is an\neveryday task for millions of users all over the world. In this work we model\nResource Usage as a Cooperative Cournot Game in which a resource user and the\nvarious resource services are engaged. We give quantified answers as to when it\nis of interest for the user to stop using part of a resource and to switch to a\ndifferent one. Moreover, we do the same from the perspective of a resource's\nprovider.", 
    "link": "http://arxiv.org/pdf/1202.4304v2", 
    "arxiv-id": "1202.4304v2"
},{
    "category": "cs.GT", 
    "author": "Preston McAfee", 
    "title": "Crowdsourcing with Endogenous Entry", 
    "publish": "2012-02-22T18:15:49Z", 
    "summary": "We investigate the design of mechanisms to incentivize high quality in\ncrowdsourcing environments with strategic agents, when entry is an endogenous,\nstrategic choice. Modeling endogenous entry in crowdsourcing is important\nbecause there is a nonzero cost to making a contribution of any quality which\ncan be avoided by not participating, and indeed many sites based on\ncrowdsourced content do not have adequate participation. We use a mechanism\nwith monotone, rank-based, rewards in a model where agents strategically make\nparticipation and quality choices to capture a wide variety of crowdsourcing\nenvironments, ranging from conventional crowdsourcing contests to crowdsourced\ncontent as in online Q&A forums.\n  We first explicitly construct the unique mixed-strategy equilibrium for such\nmonotone rank-order mechanisms, and use these participation probabilities and\nquality distribution to address the design of incentives for two kinds of\nrewards that arise in crowdsourcing. We first show that for attention rewards\nas in crowdsourced content, the entire equilibrium distribution improves when\nthe rewards for every rank but the last are as high as possible. In particular,\nwhen producing the lowest quality content has low cost, the optimal mechanism\ndisplays all but the worst contribution. We next investigate settings where\nthere is a total reward that can be arbitrarily distributed amongst all\nparticipants, as in crowdsourcing contests. Unlike with exogenous entry, here\nthe expected number of participants can be increased by subsidizing entry,\nwhich could potentially improve the expected quality of the best contribution.\nHowever, we show that free entry is dominated by taxing entry- making all\nentrants pay a small fee, which is rebated to the winner along with whatever\nrewards were already assigned, can improve the quality of the best contribution\nover a winner-take-all contest with no taxes.", 
    "link": "http://arxiv.org/pdf/1202.4997v1", 
    "arxiv-id": "1202.4997v1"
},{
    "category": "cs.GT", 
    "author": "Lasse Kliemann", 
    "title": "The Price of Anarchy for Network Formation in an Adversary Model", 
    "publish": "2012-02-22T20:21:02Z", 
    "summary": "We study network formation with n players and link cost \\alpha > 0. After the\nnetwork is built, an adversary randomly deletes one link according to a certain\nprobability distribution. Cost for player v incorporates the expected number of\nplayers to which v will become disconnected. We show existence of equilibria\nand a price of stability of 1+o(1) under moderate assumptions on the adversary\nand n \\geq 9.\n  As the main result, we prove bounds on the price of anarchy for two special\nadversaries: one removes a link chosen uniformly at random, while the other\nremoves a link that causes a maximum number of player pairs to be separated.\nFor unilateral link formation we show a bound of O(1) on the price of anarchy\nfor both adversaries, the constant being bounded by 10+o(1) and 8+o(1),\nrespectively. For bilateral link formation we show O(1+\\sqrt{n/\\alpha}) for one\nadversary (if \\alpha > 1/2), and \\Theta(n) for the other (if \\alpha > 2\nconsidered constant and n \\geq 9). The latter is the worst that can happen for\nany adversary in this model (if \\alpha = \\Omega(1)). This points out\nsubstantial differences between unilateral and bilateral link formation.", 
    "link": "http://arxiv.org/pdf/1202.5025v1", 
    "arxiv-id": "1202.5025v1"
},{
    "category": "cs.GT", 
    "author": "Egor Ianovski", 
    "title": "Cake Cutting Mechanisms", 
    "publish": "2012-03-01T06:48:21Z", 
    "summary": "We examine the history of cake cutting mechanisms and discuss the efficiency\nof their allocations. In the case of piecewise uniform preferences, we define a\ngame that in the presence of strategic agents has equilibria that are not\ndominated by the allocations of any mechanism. We identify that the equilibria\nof this game coincide with the allocations of an existing cake cutting\nmechanism.", 
    "link": "http://arxiv.org/pdf/1203.0100v2", 
    "arxiv-id": "1203.0100v2"
},{
    "category": "cs.GT", 
    "author": "Louise Young", 
    "title": "The Evolution of Cooperation in Business", 
    "publish": "2012-03-06T06:41:07Z", 
    "summary": "The development of cooperative relations within and between firms plays an\nimportant role in the successful implementation of business strategy. How to\nproduce such relations is less well understood. We build on work in relational\ncontract theory and the evolution of cooperation to examine the conditions\nunder which group based incentives outperform individual based incentives and\nhow they produce more cooperative behavior. Group interactions are modeled as\niterated games in which individuals learn optimal strategies under individual\nand group based reward mechanisms. The space of possible games is examined and\nit is found that, when individual and group interests are not aligned, group\nevaluation and reward systems lead to higher group performance and,\ncounter-intuitively, higher individual performance. Such groups include\nindividuals who, quite differently to free-riders, sacrifice their own\nperformance for the good of the group. We discuss the implications of these\nresults for the design of incentive systems.", 
    "link": "http://arxiv.org/pdf/1203.1107v1", 
    "arxiv-id": "1203.1107v1"
},{
    "category": "cs.GT", 
    "author": "Vincent Conitzer", 
    "title": "Undominated Groves Mechanisms", 
    "publish": "2012-03-08T14:20:07Z", 
    "summary": "The family of Groves mechanisms, which includes the well-known VCG mechanism\n(also known as the Clarke mechanism), is a family of efficient and\nstrategy-proof mechanisms. Unfortunately, the Groves mechanisms are generally\nnot budget balanced. That is, under such mechanisms, payments may flow into or\nout of the system of the agents, resulting in deficits or reduced utilities for\nthe agents. We consider the following problem: within the family of Groves\nmechanisms, we want to identify mechanisms that give the agents the highest\nutilities, under the constraint that these mechanisms must never incur\ndeficits.\n  We adopt a prior-free approach. We introduce two general measures for\ncomparing mechanisms in prior-free settings. We say that a non-deficit Groves\nmechanism $M$ {\\em individually dominates} another non-deficit Groves mechanism\n$M'$ if for every type profile, every agent's utility under $M$ is no less than\nthat under $M'$, and this holds with strict inequality for at least one type\nprofile and one agent. We say that a non-deficit Groves mechanism $M$ {\\em\ncollectively dominates} another non-deficit Groves mechanism $M'$ if for every\ntype profile, the agents' total utility under $M$ is no less than that under\n$M'$, and this holds with strict inequality for at least one type profile. The\nabove definitions induce two partial orders on non-deficit Groves mechanisms.\nWe study the maximal elements corresponding to these two partial orders, which\nwe call the {\\em individually undominated} mechanisms and the {\\em collectively\nundominated} mechanisms, respectively.", 
    "link": "http://arxiv.org/pdf/1203.1809v2", 
    "arxiv-id": "1203.1809v2"
},{
    "category": "cs.GT", 
    "author": "Marco Scarsini", 
    "title": "On the Core of Dynamic Cooperative Games", 
    "publish": "2012-03-13T15:11:35Z", 
    "summary": "We consider dynamic cooperative games, where the worth of coalitions varies\nover time according to the history of allocations. When defining the core of a\ndynamic game, we allow the possibility for coalitions to deviate at any time\nand thereby to give rise to a new environment. A coalition that considers a\ndeviation needs to take the consequences into account because from the\ndeviation point on, the game is no longer played with the original set of\nplayers. The deviating coalition becomes the new grand coalition which, in\nturn, induces a new dynamic game. The stage games of the new dynamical game\ndepend on all previous allocation including those that have materialized from\nthe deviating time on.\n  We define three types of core solutions: fair core, stable core and credible\ncore. We characterize the first two in case where the instantaneous game\ndepends on the last allocation (rather than on the whole history of\nallocations) and the third in the general case. The analysis and the results\nresembles to a great extent the theory of non-cooperative dynamic games.", 
    "link": "http://arxiv.org/pdf/1203.2832v1", 
    "arxiv-id": "1203.2832v1"
},{
    "category": "cs.GT", 
    "author": "Pinyan Lu", 
    "title": "Budget Feasible Mechanism Design: From Prior-Free to Bayesian", 
    "publish": "2012-03-20T14:52:32Z", 
    "summary": "Budget feasible mechanism design studies procurement combinatorial auctions\nwhere the sellers have private costs to produce items, and the\nbuyer(auctioneer) aims to maximize a social valuation function on subsets of\nitems, under the budget constraint on the total payment. One of the most\nimportant questions in the field is \"which valuation domains admit truthful\nbudget feasible mechanisms with `small' approximations (compared to the social\noptimum)?\" Singer showed that additive and submodular functions have such\nconstant approximations. Recently, Dobzinski, Papadimitriou, and Singer gave an\nO(log^2 n)-approximation mechanism for subadditive functions; they also\nremarked that: \"A fundamental question is whether, regardless of computational\nconstraints, a constant-factor budget feasible mechanism exists for subadditive\nfunctions.\"\n  We address this question from two viewpoints: prior-free worst case analysis\nand Bayesian analysis. For the prior-free framework, we use an LP that\ndescribes the fractional cover of the valuation function; it is also connected\nto the concept of approximate core in cooperative game theory. We provide an\nO(I)-approximation mechanism for subadditive functions, via the worst case\nintegrality gap I of LP. This implies an O(log n)-approximation for subadditive\nvaluations, O(1)-approximation for XOS valuations, and for valuations with a\nconstant I. XOS valuations are an important class of functions that lie between\nsubmodular and subadditive classes. We give another polynomial time O(log\nn/loglog n) sub-logarithmic approximation mechanism for subadditive valuations.\n  For the Bayesian framework, we provide a constant approximation mechanism for\nall subadditive functions, using the above prior-free mechanism for XOS\nvaluations as a subroutine. Our mechanism allows correlations in the\ndistribution of private information and is universally truthful.", 
    "link": "http://arxiv.org/pdf/1203.4455v1", 
    "arxiv-id": "1203.4455v1"
},{
    "category": "cs.GT", 
    "author": "Azarakhsh Malekian", 
    "title": "Bayesian Optimal Auctions via Multi- to Single-agent Reduction", 
    "publish": "2012-03-22T19:59:22Z", 
    "summary": "We study an abstract optimal auction problem for a single good or service.\nThis problem includes environments where agents have budgets, risk preferences,\nor multi-dimensional preferences over several possible configurations of the\ngood (furthermore, it allows an agent's budget and risk preference to be known\nonly privately to the agent). These are the main challenge areas for auction\ntheory. A single-agent problem is to optimize a given objective subject to a\nconstraint on the maximum probability with which each type is allocated,\na.k.a., an allocation rule. Our approach is a reduction from multi-agent\nmechanism design problem to collection of single-agent problems. We focus on\nmaximizing revenue, but our results can be applied to other objectives (e.g.,\nwelfare).\n  An optimal multi-agent mechanism can be computed by a linear/convex program\non interim allocation rules by simultaneously optimizing several single-agent\nmechanisms subject to joint feasibility of the allocation rules. For\nsingle-unit auctions, Border \\citeyearpar{B91} showed that the space of all\njointly feasible interim allocation rules for $n$ agents is a\n$\\NumTypes$-dimensional convex polytope which can be specified by $2^\\NumTypes$\nlinear constraints, where $\\NumTypes$ is the total number of all agents' types.\nConsequently, efficiently solving the mechanism design problem requires a\nseparation oracle for the feasibility conditions and also an algorithm for\nex-post implementation of the interim allocation rules. We show that the\npolytope of jointly feasible interim allocation rules is the projection of a\nhigher dimensional polytope which can be specified by only $O(\\NumTypes^2)$\nlinear constraints. Furthermore, our proof shows that finding a preimage of the\ninterim allocation rules in the higher dimensional polytope immediately gives\nan ex-post implementation.", 
    "link": "http://arxiv.org/pdf/1203.5099v1", 
    "arxiv-id": "1203.5099v1"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Bayesian Games and the Smoothness Framework", 
    "publish": "2012-03-23T02:24:35Z", 
    "summary": "We consider a general class of Bayesian Games where each players utility\ndepends on his type (possibly multidimensional) and on the strategy profile and\nwhere players' types are distributed independently. We show that if their full\ninformation version for any fixed instance of the type profile is a smooth game\nthen the Price of Anarchy bound implied by the smoothness property, carries\nover to the Bayes-Nash Price of Anarchy. We show how some proofs from the\nliterature (item bidding auctions, greedy auctions) can be cast as smoothness\nproofs or be simplified using smoothness. For first price item bidding with\nfractionally subadditive bidders we actually manage to improve by much the\nexisting result \\cite{Hassidim2011a} from 4 to $\\frac{e}{e-1}\\approx 1.58$.\nThis also shows a very interesting separation between first and second price\nitem bidding since second price item bidding has PoA at least 2 even under\ncomplete information. For a larger class of Bayesian Games where the strategy\nspace of a player also changes with his type we are able to show that a\nslightly stronger definition of smoothness also implies a Bayes-Nash PoA bound.\nWe show how weighted congestion games actually satisfy this stronger definition\nof smoothness. This allows us to show that the inefficiency bounds of weighted\ncongestion games known in the literature carry over to incomplete versions\nwhere the weights of the players are private information. We also show how an\nincomplete version of a natural class of monotone valid utility games, called\neffort market games are universally $(1,1)$-smooth. Hence, we show that\nincomplete versions of effort market games where the abilities of the players\nand their budgets are private information has Bayes-Nash PoA at most 2.", 
    "link": "http://arxiv.org/pdf/1203.5155v1", 
    "arxiv-id": "1203.5155v1"
},{
    "category": "cs.GT", 
    "author": "David Kempe", 
    "title": "Bayesian Auctions with Friends and Foes", 
    "publish": "2012-03-27T12:03:18Z", 
    "summary": "We study auctions whose bidders are embedded in a social or economic network.\nAs a result, even bidders who do not win the auction themselves might derive\nutility from the auction, namely, when a friend wins. On the other hand, when\nan enemy or competitor wins, a bidder might derive negative utility. Such spite\nand altruism will alter the bidding strategies. A simple and natural model for\nbidders' utilities in these settings posits that the utility of a losing bidder\ni as a result of bidder j winning is a constant (positive or negative) fraction\nof bidder j's utility.", 
    "link": "http://arxiv.org/pdf/1203.5945v3", 
    "arxiv-id": "1203.5945v3"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "An Analysis of One-Dimensional Schelling Segregation", 
    "publish": "2012-03-28T19:30:51Z", 
    "summary": "We analyze the Schelling model of segregation in which a society of n\nindividuals live in a ring. Each individual is one of two races and is only\nsatisfied with his location so long as at least half his 2w nearest neighbors\nare of the same race as him. In the dynamics, randomly-chosen unhappy\nindividuals successively swap locations. We consider the average size of\nmonochromatic neighborhoods in the final stable state. Our analysis is the\nfirst rigorous analysis of the Schelling dynamics. We note that, in contrast to\nprior approximate analyses, the final state is nearly integrated: the average\nsize of monochromatic neighborhoods is independent of n and polynomial in w.", 
    "link": "http://arxiv.org/pdf/1203.6346v2", 
    "arxiv-id": "1203.6346v2"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Doubleclick Ad Exchange Auction", 
    "publish": "2012-04-02T20:56:53Z", 
    "summary": "Display advertisements on the web are sold via ad exchanges that use real\ntime auction. We describe the challenges of designing a suitable auction, and\npresent a simple auction called the Optional Second Price (OSP) auction that is\ncurrently used in Doubleclick Ad Exchange.", 
    "link": "http://arxiv.org/pdf/1204.0535v1", 
    "arxiv-id": "1204.0535v1"
},{
    "category": "cs.GT", 
    "author": "Troels Bjerre S\u00f8rensen", 
    "title": "Approximate Well-supported Nash Equilibria below Two-thirds", 
    "publish": "2012-04-03T15:17:39Z", 
    "summary": "In an epsilon-Nash equilibrium, a player can gain at most epsilon by changing\nhis behaviour. Recent work has addressed the question of how best to compute\nepsilon-Nash equilibria, and for what values of epsilon a polynomial-time\nalgorithm exists. An epsilon-well-supported Nash equilibrium (epsilon-WSNE) has\nthe additional requirement that any strategy that is used with non-zero\nprobability by a player must have payoff at most epsilon less than the best\nresponse. A recent algorithm of Kontogiannis and Spirakis shows how to compute\na 2/3-WSNE in polynomial time, for bimatrix games. Here we introduce a new\ntechnique that leads to an improvement to the worst-case approximation\nguarantee.", 
    "link": "http://arxiv.org/pdf/1204.0707v2", 
    "arxiv-id": "1204.0707v2"
},{
    "category": "cs.GT", 
    "author": "Sampath Kannan", 
    "title": "The Exponential Mechanism for Social Welfare: Private, Truthful, and   Nearly Optimal", 
    "publish": "2012-04-05T15:22:18Z", 
    "summary": "In this paper we show that for any mechanism design problem with the\nobjective of maximizing social welfare, the exponential mechanism can be\nimplemented as a truthful mechanism while still preserving differential\nprivacy. Our instantiation of the exponential mechanism can be interpreted as a\ngeneralization of the VCG mechanism in the sense that the VCG mechanism is the\nextreme case when the privacy parameter goes to infinity. To our knowledge,\nthis is the first general tool for designing mechanisms that are both truthful\nand differentially private.", 
    "link": "http://arxiv.org/pdf/1204.1255v2", 
    "arxiv-id": "1204.1255v2"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "Stable marriage and roommate problems with individual-based stability", 
    "publish": "2012-04-07T12:53:44Z", 
    "summary": "Research regarding the stable marriage and roommate problem has a long and\ndistinguished history in mathematics, computer science and economics. Stability\nin this context is predominantly core stability or one of its variants in which\neach deviation is by a group of players. There has been little focus in\nmatching theory on stability concepts such as Nash stability and individual\nstability in which the deviation is by a single player. Such stability concepts\nare suitable especially when trust for the other party is limited, complex\ncoordination is not feasible, or when only unmatched agents can be approached.\nFurthermore, weaker stability notions such as individual stability may in\nprinciple circumvent the negative existence and computational complexity\nresults in matching theory. We characterize the computational complexity of\nchecking the existence and computing individual-based stable matchings for the\nmarriage and roommate settings. One of our key computational results for the\nstable marriage setting also carries over to different classes of hedonic games\nfor which individual-based stability has already been of much interest.", 
    "link": "http://arxiv.org/pdf/1204.1628v2", 
    "arxiv-id": "1204.1628v2"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Approximate Revenue Maximization with Multiple Items", 
    "publish": "2012-04-09T10:08:10Z", 
    "summary": "Myerson's classic result provides a full description of how a seller can\nmaximize revenue when selling a single item. We address the question of revenue\nmaximization in the simplest possible multi-item setting: two items and a\nsingle buyer who has independently distributed values for the items, and an\nadditive valuation. In general, the revenue achievable from selling two\nindependent items may be strictly higher than the sum of the revenues\nobtainable by selling each of them separately. In fact, the structure of\noptimal (i.e., revenue-maximizing) mechanisms for two items even in this simple\nsetting is not understood.\n  In this paper we obtain approximate revenue optimization results using two\nsimple auctions: that of selling the items separately, and that of selling them\nas a single bundle. Our main results (which are of a \"direct sum\" variety, and\napply to any distributions) are as follows. Selling the items separately\nguarantees at least half the revenue of the optimal auction; for identically\ndistributed items, this becomes at least 73% of the optimal revenue. For the\ncase of k>2 items, we show that selling separately guarantees at least a\nc/log^2(k) fraction of the optimal revenue; for identically distributed items,\nthe bundling auction yields at least a c/log(k) fraction of the optimal\nrevenue.", 
    "link": "http://arxiv.org/pdf/1204.1846v2", 
    "arxiv-id": "1204.1846v2"
},{
    "category": "cs.GT", 
    "author": "Joseph Y. Halpern", 
    "title": "An Equilibrium Analysis of Scrip Systems", 
    "publish": "2012-04-13T10:25:12Z", 
    "summary": "A game-theoretic model of scrip (artificial currency) systems is analyzed. It\nis shown that relative entropy can be used to characterize the distribution of\nagent wealth when all agents use threshold strategies---that is, they volunteer\nto do work iff they have below a threshold amount of money. Monotonicity of\nagents' best-reply functions is used to show that scrip systems have pure\nstrategy equilibria where all agents use threshold strategies. An algorithm is\ngiven that can compute such an equilibrium and the resulting distribution of\nwealth.", 
    "link": "http://arxiv.org/pdf/1204.2942v2", 
    "arxiv-id": "1204.2942v2"
},{
    "category": "cs.GT", 
    "author": "Yu-Han Lyu", 
    "title": "Approximately Optimal Auctions for Selling Privacy when Costs are   Correlated with Data", 
    "publish": "2012-04-18T10:09:54Z", 
    "summary": "We consider a scenario in which a database stores sensitive data of users and\nan analyst wants to estimate statistics of the data. The users may suffer a\ncost when their data are used in which case they should be compensated. The\nanalyst wishes to get an accurate estimate, while the users want to maximize\ntheir utility. We want to design a mechanism that can estimate statistics\naccurately without compromising users' privacy.\n  Since users' costs and sensitive data may be correlated, it is important to\nprotect the privacy of both data and cost. We model this correlation by\nassuming that a user's unknown sensitive data determines a distribution from a\nset of publicly known distributions and a user's cost is drawn from that\ndistribution. We propose a stronger model of privacy preserving mechanism where\nusers are compensated whenever they reveal information about their data to the\nmechanism. In this model, we design a Bayesian incentive compatible and privacy\npreserving mechanism that guarantees accuracy and protects the privacy of both\ncost and data.", 
    "link": "http://arxiv.org/pdf/1204.4031v1", 
    "arxiv-id": "1204.4031v1"
},{
    "category": "cs.GT", 
    "author": "Manu Harju", 
    "title": "On probabilities of Risk type board game combats", 
    "publish": "2012-04-18T13:23:07Z", 
    "summary": "Risk is a well-known turn based board game where the primary objective is\nnothing less than the world domination. Gameplay is based on battles between\narmies located in adjacent territories on the map of Earth. The combat's\noutcome is decided by rolling dice, and therefore a probabilistic approach can\nbe taken. Although several results are derived, the conclusions suggest that\nthe gameplay is highly depending on luck.", 
    "link": "http://arxiv.org/pdf/1204.4082v1", 
    "arxiv-id": "1204.4082v1"
},{
    "category": "cs.GT", 
    "author": "Britta Peis", 
    "title": "Resource Buying Games", 
    "publish": "2012-04-18T15:47:25Z", 
    "summary": "In resource buying games a set of players jointly buys a subset of a finite\nresource set E (e.g., machines, edges, or nodes in a digraph). The cost of a\nresource e depends on the number (or load) of players using e, and has to be\npaid completely by the players before it becomes available. Each player i needs\nat least one set of a predefined family S_i in 2^E to be available. Thus,\nresource buying games can be seen as a variant of congestion games in which the\nload-dependent costs of the resources can be shared arbitrarily among the\nplayers. A strategy of player i in resource buying games is a tuple consisting\nof one of i's desired configurations S_i together with a payment vector p_i in\nR^E_+ indicating how much i is willing to contribute towards the purchase of\nthe chosen resources. In this paper, we study the existence and computational\ncomplexity of pure Nash equilibria (PNE, for short) of resource buying games.\nIn contrast to classical congestion games for which equilibria are guaranteed\nto exist, the existence of equilibria in resource buying games strongly depends\non the underlying structure of the S_i's and the behavior of the cost\nfunctions. We show that for marginally non-increasing cost functions, matroids\nare exactly the right structure to consider, and that resource buying games\nwith marginally non-decreasing cost functions always admit a PNE.", 
    "link": "http://arxiv.org/pdf/1204.4111v1", 
    "arxiv-id": "1204.4111v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Entry and Spectrum Sharing Scheme Selection in Femtocell Markets", 
    "publish": "2012-04-19T06:54:59Z", 
    "summary": "Focusing on a femtocell communications market, we study the entrant network\nservice provider's (NSP's) long-term decision: whether to enter the market and\nwhich spectrum sharing technology to select to maximize its profit. This\nlong-term decision is closely related to the entrant's pricing strategy and the\nusers' aggregate demand, which we model as medium-term and short-term\ndecisions, respectively. We consider two markets, one with no incumbent and the\nother with one incumbent. For both markets, we show the existence and\nuniqueness of an equilibrium point in the user subscription dynamics, and\nprovide a sufficient condition for the convergence of the dynamics. For the\nmarket with no incumbent, we derive upper and lower bounds on the optimal price\nand market share that maximize the entrant's revenue, based on which the\nentrant selects an available technology to maximize its long-term profit. For\nthe market with one incumbent, we model competition between the two NSPs as a\nnon-cooperative game, in which the incumbent and the entrant choose their\nmarket shares independently, and provide a sufficient condition that guarantees\nthe existence of at least one pure Nash equilibrium. Finally, we formalize the\nproblem of entry and spectrum sharing scheme selection for the entrant and\nprovide numerical results to complement our analysis.", 
    "link": "http://arxiv.org/pdf/1204.4262v1", 
    "arxiv-id": "1204.4262v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Fair Allocation Without Trade", 
    "publish": "2012-04-19T08:42:14Z", 
    "summary": "We consider the age-old problem of allocating items among different agents in\na way that is efficient and fair. Two papers, by Dolev et al. and Ghodsi et\nal., have recently studied this problem in the context of computer systems.\nBoth papers had similar models for agent preferences, but advocated different\nnotions of fairness. We formalize both fairness notions in economic terms,\nextending them to apply to a larger family of utilities. Noting that in\nsettings with such utilities efficiency is easily achieved in multiple ways, we\nstudy notions of fairness as criteria for choosing between different efficient\nallocations. Our technical results are algorithms for finding fair allocations\ncorresponding to two fairness notions: Regarding the notion suggested by Ghodsi\net al., we present a polynomial-time algorithm that computes an allocation for\na general class of fairness notions, in which their notion is included. For the\nother, suggested by Dolev et al., we show that a competitive market equilibrium\nachieves the desired notion of fairness, thereby obtaining a polynomial-time\nalgorithm that computes such a fair allocation and solving the main open\nproblem raised by Dolev et al.", 
    "link": "http://arxiv.org/pdf/1204.4286v1", 
    "arxiv-id": "1204.4286v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Optimal Mechanisms for Selling Information", 
    "publish": "2012-04-25T00:26:04Z", 
    "summary": "The buying and selling of information is taking place at a scale\nunprecedented in the history of commerce, thanks to the formation of online\nmarketplaces for user data. Data providing agencies sell user information to\nadvertisers to allow them to match ads to viewers more effectively. In this\npaper we study the design of optimal mechanisms for a monopolistic data\nprovider to sell information to a buyer, in a model where both parties have\n(possibly correlated) private signals about a state of the world, and the buyer\nuses information learned from the seller, along with his own signal, to choose\nan action (e.g., displaying an ad) whose payoff depends on the state of the\nworld.\n  We provide sufficient conditions under which there is a simple one-round\nprotocol (i.e. a protocol where the buyer and seller each sends a single\nmessage, and there is a single money transfer) achieving optimal revenue. In\nthese cases we present a polynomial-time algorithm that computes the optimal\nmechanism. Intriguingly, we show that multiple rounds of partial information\ndisclosure (interleaved by payment to the seller) are sometimes necessary to\nachieve optimal revenue if the buyer is allowed to abort his interaction with\nthe seller prematurely. We also prove some negative results about the inability\nof simple mechanisms for selling information to approximate more complicated\nones in the worst case.", 
    "link": "http://arxiv.org/pdf/1204.5519v1", 
    "arxiv-id": "1204.5519v1"
},{
    "category": "cs.GT", 
    "author": "Omer Tamuz", 
    "title": "A lower bound on seller revenue in single buyer monopoly auctions", 
    "publish": "2012-04-25T03:09:58Z", 
    "summary": "We consider a monopoly seller who optimally auctions a single object to a\nsingle potential buyer, with a known distribution of valuations. We show that a\ntight lower bound on the seller's expected revenue is $1/e$ times the geometric\nexpectation of the buyer's valuation, and that this bound is uniquely achieved\nfor the equal revenue distribution. We show also that when the valuation's\nexpectation and geometric expectation are close, then the seller's expected\nrevenue is close to the expected valuation.", 
    "link": "http://arxiv.org/pdf/1204.5551v2", 
    "arxiv-id": "1204.5551v2"
},{
    "category": "cs.GT", 
    "author": "Yevgeniy Vorobeychik", 
    "title": "Simulation-Based Game Theoretic Analysis of Keyword Auctions with   Low-Dimensional Bidding Strategies", 
    "publish": "2012-05-09T18:39:36Z", 
    "summary": "We perform a simulation-based analysis of keyword auctions modeled as\none-shot games of incomplete information to study a series of mechanism design\nquestions. Our first question addresses the degree to which incentive\ncompatibility fails in generalized second-price (GSP) auctions. Our results\nsuggest that sincere bidding in GSP auctions is a strikingly poor strategy and\na poor predictor of equilibrium outcomes. We next show that the rank-by-revenue\nmechanism is welfare optimal, corroborating past results. Finally, we analyze\nprofit as a function of auction mechanism under a series of alternative\nsettings. Our conclusions coincide with those of Lahaie and Pennock [2007] when\nvalues and quality scores are strongly positively correlated: in such a case,\nrank-by-bid rules are clearly superior. We diverge, however, in showing that\nauctions that put little weight on quality scores almost universally dominate\nthe pure rank-by-revenue scheme.", 
    "link": "http://arxiv.org/pdf/1205.2607v1", 
    "arxiv-id": "1205.2607v1"
},{
    "category": "cs.GT", 
    "author": "David C. Parkes", 
    "title": "Quantifying the Strategyproofness of Mechanisms via Metrics on Payoff   Distributions", 
    "publish": "2012-05-09T17:12:19Z", 
    "summary": "Strategyproof mechanisms provide robust equilibrium with minimal assumptions\nabout knowledge and rationality but can be unachievable in combination with\nother desirable properties such as budget-balance, stability against deviations\nby coalitions, and computational tractability. In the search for\nmaximally-strategyproof mechanisms that simultaneously satisfy other desirable\nproperties, we introduce a new metric to quantify the strategyproofness of a\nmechanism, based on comparing the payoff distribution, given truthful reports,\nagainst that of a strategyproof \"reference\" mechanism that solves a problem\nrelaxation. Focusing on combinatorial exchanges, we demonstrate that the metric\nis informative about the eventual equilibrium, where simple regretbased metrics\nare not, and can be used for online selection of an effective mechanism.", 
    "link": "http://arxiv.org/pdf/1205.2630v1", 
    "arxiv-id": "1205.2630v1"
},{
    "category": "cs.GT", 
    "author": "Geoffrey Gordon", 
    "title": "A Sampling-Based Approach to Computing Equilibria in Succinct   Extensive-Form Games", 
    "publish": "2012-05-09T15:11:43Z", 
    "summary": "A central task of artificial intelligence is the design of artificial agents\nthat act towards specified goals in partially observed environments. Since such\nenvironments frequently include interaction over time with other agents with\ntheir own goals, reasoning about such interaction relies on sequential\ngame-theoretic models such as extensive-form games or some of their succinct\nrepresentations such as multi-agent influence diagrams. The current algorithms\nfor calculating equilibria either work with inefficient representations,\npossibly doubly exponential inthe number of time steps, or place strong\nassumptions on the game structure. In this paper,we propose a sampling-based\napproach, which calculates extensive-form correlated equilibria with small\nrepresentations without placing such strong assumptions. Thus, it is practical\nin situations where the previous approaches would fail. In addition, our\nalgorithm allows control over characteristics of the target equilibrium, e.g.,\nwe can ask for an equilibrium with high social welfare. Our approach is based\non a multiplicativeweight update algorithm analogous to AdaBoost, and Markov\nchain Monte Carlo sampling. We prove convergence guarantees and explore the\nutility of our approach on several moderately sized multi-player games.", 
    "link": "http://arxiv.org/pdf/1205.2649v1", 
    "arxiv-id": "1205.2649v1"
},{
    "category": "cs.GT", 
    "author": "Vincent Conitzer", 
    "title": "Prediction Markets, Mechanism Design, and Cooperative Game Theory", 
    "publish": "2012-05-09T14:59:00Z", 
    "summary": "Prediction markets are designed to elicit information from multiple agents in\norder to predict (obtain probabilities for) future events. A good prediction\nmarket incentivizes agents to reveal their information truthfully; such\nincentive compatibility considerations are commonly studied in mechanism\ndesign. While this relation between prediction markets and mechanism design is\nwell understood at a high level, the models used in prediction markets tend to\nbe somewhat different from those used in mechanism design. This paper considers\na model for prediction markets that fits more straightforwardly into the\nmechanism design framework. We consider a number of mechanisms within this\nmodel, all based on proper scoring rules. We discuss basic properties of these\nmechanisms, such as incentive compatibility. We also draw connections between\nsome of these mechanisms and cooperative game theory. Finally, we speculate how\none might build a practical prediction market based on some of these ideas.", 
    "link": "http://arxiv.org/pdf/1205.2654v1", 
    "arxiv-id": "1205.2654v1"
},{
    "category": "cs.GT", 
    "author": "S. Muthukrishnan", 
    "title": "Analyses of Cardinal Auctions", 
    "publish": "2012-05-12T01:14:29Z", 
    "summary": "We study cardinal auctions for selling multiple copies of a good, in which\nbidders specify not only their bid or how much they are ready to pay for the\ngood, but also a cardinality constraint on the number of copies that will be\nsold via the auction. We perform first known Price of Anarchy type analyses\nwith detailed comparison of the classical Vickrey-Clarke-Groves (VCG) auction\nand one based on minimum pay property (MPP) which is similar to Generalized\nSecond Price auction commonly used in sponsored search. Without cardinality\nconstraints, MPP has the same efficiency (total value to bidders) and at least\nas much revenue (total income to the auctioneer) as VCG; this also holds for\ncertain other generalizations of MPP (e.g., prefix constrained auctions, as we\nshow here). In contrast, our main results are that, with cardinality\nconstraints, (a) equilibrium efficiency of MPP is 1/2 of that of VCG and this\nfactor is tight, and (b) in equilibrium MPP may collect as little as 1/2 the\nrevenue of VCG. These aspects arise because in presence of cardinality\nconstraints, more strategies are available to bidders in MPP, including bidding\nabove their value, and this makes analyses nontrivial.", 
    "link": "http://arxiv.org/pdf/1205.2740v1", 
    "arxiv-id": "1205.2740v1"
},{
    "category": "cs.GT", 
    "author": "Yaron Singer", 
    "title": "Efficiency-Revenue Trade-offs in Auctions", 
    "publish": "2012-05-14T16:12:59Z", 
    "summary": "When agents with independent priors bid for a single item, Myerson's optimal\nauction maximizes expected revenue, whereas Vickrey's second-price auction\noptimizes social welfare. We address the natural question of trade-offs between\nthe two criteria, that is, auctions that optimize, say, revenue under the\nconstraint that the welfare is above a given level. If one allows for\nrandomized mechanisms, it is easy to see that there are polynomial-time\nmechanisms that achieve any point in the trade-off (the Pareto curve) between\nrevenue and welfare. We investigate whether one can achieve the same guarantees\nusing deterministic mechanisms. We provide a negative answer to this question\nby showing that this is a (weakly) NP-hard problem. On the positive side, we\nprovide polynomial-time deterministic mechanisms that approximate with\narbitrary precision any point of the trade-off between these two fundamental\nobjectives for the case of two bidders, even when the valuations are correlated\narbitrarily. The major problem left open by our work is whether there is such\nan algorithm for three or more bidders with independent valuation\ndistributions.", 
    "link": "http://arxiv.org/pdf/1205.3077v1", 
    "arxiv-id": "1205.3077v1"
},{
    "category": "cs.GT", 
    "author": "Avinatan Hassidim", 
    "title": "Computing Socially-Efficient Cake Divisions", 
    "publish": "2012-05-17T17:01:39Z", 
    "summary": "We consider a setting in which a single divisible good (\"cake\") needs to be\ndivided between n players, each with a possibly different valuation function\nover pieces of the cake. For this setting, we address the problem of finding\ndivisions that maximize the social welfare, focusing on divisions where each\nplayer needs to get one contiguous piece of the cake. We show that for both the\nutilitarian and the egalitarian social welfare functions it is NP-hard to find\nthe optimal division. For the utilitarian welfare, we provide a constant factor\napproximation algorithm, and prove that no FPTAS is possible unless P=NP. For\negalitarian welfare, we prove that it is NP-hard to approximate the optimum to\nany factor smaller than 2. For the case where the number of players is small,\nwe provide an FPT (fixed parameter tractable) FPTAS for both the utilitarian\nand the egalitarian welfare objectives.", 
    "link": "http://arxiv.org/pdf/1205.3982v1", 
    "arxiv-id": "1205.3982v1"
},{
    "category": "cs.GT", 
    "author": "Tim Roughgarden", 
    "title": "Combinatorial Auctions with Restricted Complements", 
    "publish": "2012-05-18T07:58:59Z", 
    "summary": "Complements between goods - where one good takes on added value in the\npresence of another - have been a thorn in the side of algorithmic mechanism\ndesigners. On the one hand, complements are common in the standard motivating\napplications for combinatorial auctions, like spectrum license auctions. On the\nother, welfare maximization in the presence of complements is notoriously\ndifficult, and this intractability has stymied theoretical progress in the\narea. For example, there are no known positive results for combinatorial\nauctions in which bidder valuations are multi-parameter and\nnon-complement-free, other than the relatively weak results known for general\nvaluations.\n  To make inroads on the problem of combinatorial auction design in the\npresence of complements, we propose a model for valuations with complements\nthat is parameterized by the \"size\" of the complements. A valuation in our\nmodel is represented succinctly by a weighted hypergraph, where the size of the\nhyper-edges corresponds to degree of complementarity. Our model permits a\nvariety of computationally efficient queries, and non-trivial\nwelfare-maximization algorithms and mechanisms.\n  We design the following polynomial-time approximation algorithms and truthful\nmechanisms for welfare maximization with bidders with hypergraph valuations.\n  1- For bidders whose valuations correspond to subgraphs of a known graph that\nis planar (or more generally, excludes a fixed minor), we give a truthful and\n(1+epsilon)-approximate mechanism.\n  2- We give a polynomial-time, r-approximation algorithm for welfare\nmaximization with hypergraph-r valuations. Our algorithm randomly rounds a\ncompact linear programming relaxation of the problem.\n  3- We design a different approximation algorithm and use it to give a\npolynomial-time, truthful-in-expectation mechanism that has an approximation\nfactor of O(log^r m).", 
    "link": "http://arxiv.org/pdf/1205.4104v1", 
    "arxiv-id": "1205.4104v1"
},{
    "category": "cs.GT", 
    "author": "Julie De Pril", 
    "title": "On Equilibria in Quantitative Games with Reachability/Safety Objectives", 
    "publish": "2012-05-22T12:08:37Z", 
    "summary": "In this paper, we study turn-based quantitative multiplayer non zero-sum\ngames played on finite graphs with both reachability and safety objectives. In\nthis framework a player with a reachability objective aims at reaching his own\ngoal as soon as possible, whereas a player with a safety objective aims at\navoiding his bad set or, if impossible, delaying its visit as long as possible.\nWe prove the existence of Nash equilibria with finite memory in quantitative\nmultiplayer reachability/safety games. Moreover, we prove the existence of\nfinite-memory secure equilibria for quantitative two-player reachability games.", 
    "link": "http://arxiv.org/pdf/1205.4889v1", 
    "arxiv-id": "1205.4889v1"
},{
    "category": "cs.GT", 
    "author": "Georgios Sakellariou", 
    "title": "Multi-games and a double game extension of the Prisoner's Dilemma", 
    "publish": "2012-05-22T16:38:44Z", 
    "summary": "We propose a new class of games, called Multi-Games (MG), in which a given\nnumber of players play a fixed number of basic games simultaneously. In each\nround of the MG, each player will have a specific set of weights, one for each\nbasic game, which add up to one and represent the fraction of the player's\ninvestment in each basic game. The total payoff for each player is then the\nconvex combination, with the corresponding weights, of the payoffs it obtains\nin the basic games. The basic games in a MG can be regarded as different\nenvironments for the players. When the players' weights for the different games\nin MG are private information or types with given conditional probability\ndistributions, we obtain a particular class of Bayesian games. We show that for\nthe class of so-called completely pure regular Double Game (DG) with finite\nsets of types, the Nash equilibria (NE) of the basic games can be used to\ncompute a Bayesian Nash equilibrium of the DG in linear time with respect to\nthe number of types of the players. We study a DG for the Prisoner's Dilemma\n(PD) by extending the PD with a second so-called Social Game (SG), generalising\nthe notion of altruistic extension of a game in which players have different\naltruistic levels (or social coefficients). We study two different examples of\nBayesian games in this context in which the social coefficients have a finite\nset of values and each player only knows the probability distribution of the\nopponent's social coefficient. In the first case we have a completely pure\nregular DG for which we deduce a Bayesian NE. Finally, we use the second\nexample to compare various strategies in a round-robin tournament of the DG for\nPD, in which the players can change their social coefficients incrementally\nfrom one round to the next.", 
    "link": "http://arxiv.org/pdf/1205.4973v3", 
    "arxiv-id": "1205.4973v3"
},{
    "category": "cs.GT", 
    "author": "Sergey Kuniavsky", 
    "title": "Consumer Search with Chain Stores", 
    "publish": "2012-05-27T16:02:41Z", 
    "summary": "The paper explores a consumer search setting where the sellers have\nasymmetries. The model is an extension of the popular Stahl Model, which is\nwidely used in the literature. The extension introduces sellers with\nheterogeneous stores number, reflecting the typical market structure. The\nmarket consists of several sellers heterogeneous in size consumers, some of\nwhich face a cost when sequentially searching. The paper shows that no\nsymmetric model exist in the extension and asymmetric NE of the Stahl model are\nfound for comparison. Additional results suggest that smallest sellers will be\nthe ones offering lowest prices, in line with several real world examples\nprovided in the paper. However, profits remain in most cases fixed per store,\nmaking a larger firm more profitable, yet with lower sold quantity. The\nfindings suggest that on some level price dispersion will still exist, together\nwith some level of price stickiness, both observed in reality.", 
    "link": "http://arxiv.org/pdf/1205.5982v1", 
    "arxiv-id": "1205.5982v1"
},{
    "category": "cs.GT", 
    "author": "Sunil Simon", 
    "title": "A Classification of Weakly Acyclic Games", 
    "publish": "2012-06-01T09:37:50Z", 
    "summary": "Weakly acyclic games form a natural generalization of the class of games that\nhave the finite improvement property (FIP). In such games one stipulates that\nfrom any initial joint strategy some finite improvement path exists. We\nclassify weakly acyclic games using the concept of a scheduler introduced in\narXiv:1202.2209. We also show that finite games that can be solved by the\niterated elimination of never best response strategies are weakly acyclic.\nFinally, we explain how the schedulers allow us to improve the bounds on\nfinding a Nash equilibrium in a weakly acyclic game.", 
    "link": "http://arxiv.org/pdf/1206.0130v5", 
    "arxiv-id": "1206.0130v5"
},{
    "category": "cs.GT", 
    "author": "Daan Wilmer", 
    "title": "Evaluation and Improvement of Laruelle-Widgr\u00e9n Inverse Banzhaf   Approximation", 
    "publish": "2012-06-06T08:32:15Z", 
    "summary": "The goal of this paper is to critically evaluate a heuristic algorithm for\nthe Inverse Banzhaf Index problem by Laruelle and Widgr\\'en. Few qualitative\nresults are known about the approximation quality of the heuristics for this\nproblem. The intuition behind the operation of this approximation algorithm is\nanalysed and evaluated. We found that the algorithm can not handle general\ninputs well, and often fails to improve inputs. It is also shown to diverge\nafter only tens of iterations. We present three alternative extensions of the\nalgorithm that do not alter the complexity but can result in up to a factor 6.5\nimprovement in solution quality.", 
    "link": "http://arxiv.org/pdf/1206.1145v1", 
    "arxiv-id": "1206.1145v1"
},{
    "category": "cs.GT", 
    "author": "Haoyang Wu", 
    "title": "Traditional sufficient conditions for Nash implementation may fail on   Internet", 
    "publish": "2012-06-06T11:32:31Z", 
    "summary": "The Maskin's theorem is a fundamental work in the theory of mechanism design.\nIn this paper, we propose that if agents report messages to the designer\nthrough channels (e.g., Internet), agents can construct a self-enforcing\nagreement such that any Pareto-inefficient social choice rule satisfying\nmonotonicity and no-veto will not be Nash implementable when an additional\ncondition is satisfied. The key points are: 1) The agreement is unobservable to\nthe designer, and the designer cannot prevent the agents from constructing such\nagreement; 2) The agents act non-cooperatively, and the Maskin mechanism remain\nunchanged from the designer's perspective.", 
    "link": "http://arxiv.org/pdf/1206.1188v1", 
    "arxiv-id": "1206.1188v1"
},{
    "category": "cs.GT", 
    "author": "Andrew Lohr", 
    "title": "Tight Lower Bounds for Unequal Division", 
    "publish": "2012-06-07T16:54:19Z", 
    "summary": "Alice and Bob want to cut a cake; however, in contrast to the usual problems\nof fair division, they want to cut it unfairly. More precisely, they want to\ncut it in ratio $(a:b)$. (We can assume gcd(a,b)=1.) Let f(a,b) be the number\nof cuts will this take (assuming both act in their own self interest). It is\nknown that f(a,b) \\le \\ceil{lg(a+b)}. We show that (1) for all a,b, f(a,b) \\ge\nlg(lg(a+b)) + (2) for an infinite number of (a,b), f(a,b) \\le 1+lg(lg(a+b).", 
    "link": "http://arxiv.org/pdf/1206.1553v1", 
    "arxiv-id": "1206.1553v1"
},{
    "category": "cs.GT", 
    "author": "Bryan Bruns", 
    "title": "Escaping Prisoner's Dilemmas: From Discord to Harmony in the Landscape   of 2x2 Games", 
    "publish": "2012-06-08T21:27:24Z", 
    "summary": "Changes in payoffs can transform Prisoner's Dilemma and other social dilemmas\ninto harmonious win-win games. Using the Robinson-Goforth topology of 2x2\ngames, this paper analyzes how payoff swaps turn Prisoner's Dilemma into other\ngames, compares Prisoner's Dilemmas with other families of games, traces paths\nthat affect the difficulty of transforming Prisoner's Dilemma and other social\ndilemmas into win-win games, and shows how ties connect simpler and more\ncomplex games. Charts illustrate the relationships between the 144 strict\nordinal 2x2 games, the 38 symmetric 2x2 ordinal games with and without ties,\nand the complete set of 1,413 2x2 ordinal games. Payoffs from the symmetric\nordinal 2x2 games combine to form asymmetric games, generating coordinates for\na simple labeling scheme to uniquely identify and locate all asymmetric ordinal\n2x2 games. The expanded topology elegantly maps relationships between 2x2 games\nwith and without ties, enables a systematic understanding of the potential for\ntransformations in social dilemmas and other strategic interactions, offers a\ntool for institutional analysis and design, and locates a variety of\ninteresting games for further research.", 
    "link": "http://arxiv.org/pdf/1206.1880v1", 
    "arxiv-id": "1206.1880v1"
},{
    "category": "cs.GT", 
    "author": "Preetjot Singh", 
    "title": "Manipulation and Control Complexity of Schulze Voting", 
    "publish": "2012-06-11T06:58:50Z", 
    "summary": "Schulze voting is a recently introduced voting system enjoying unusual\npopularity and a high degree of real-world use, with users including the\nWikimedia foundation, several branches of the Pirate Party, and MTV. It is a\nCondorcet voting system that determines the winners of an election using\ninformation about paths in a graph representation of the election. We resolve\nthe complexity of many electoral control cases for Schulze voting. We find that\nit falls short of the best known voting systems in terms of control resistance,\ndemonstrating vulnerabilities of concern to some prospective users of the\nsystem.", 
    "link": "http://arxiv.org/pdf/1206.2111v4", 
    "arxiv-id": "1206.2111v4"
},{
    "category": "cs.GT", 
    "author": "Yuval Peres", 
    "title": "Mechanisms for Risk Averse Agents, Without Loss", 
    "publish": "2012-06-13T22:34:26Z", 
    "summary": "Auctions in which agents' payoffs are random variables have received\nincreased attention in recent years. In particular, recent work in algorithmic\nmechanism design has produced mechanisms employing internal randomization,\npartly in response to limitations on deterministic mechanisms imposed by\ncomputational complexity. For many of these mechanisms, which are often\nreferred to as truthful-in-expectation, incentive compatibility is contingent\non the assumption that agents are risk-neutral. These mechanisms have been\ncriticized on the grounds that this assumption is too strong, because \"real\"\nagents are typically risk averse, and moreover their precise attitude towards\nrisk is typically unknown a-priori. In response, researchers in algorithmic\nmechanism design have sought the design of universally-truthful mechanisms ---\nmechanisms for which incentive-compatibility makes no assumptions regarding\nagents' attitudes towards risk.\n  We show that any truthful-in-expectation mechanism can be generically\ntransformed into a mechanism that is incentive compatible even when agents are\nrisk averse, without modifying the mechanism's allocation rule. The transformed\nmechanism does not require reporting of agents' risk profiles. Equivalently,\nour result can be stated as follows: Every (randomized) allocation rule that is\nimplementable in dominant strategies when players are risk neutral is also\nimplementable when players are endowed with an arbitrary and unknown concave\nutility function for money.", 
    "link": "http://arxiv.org/pdf/1206.2957v1", 
    "arxiv-id": "1206.2957v1"
},{
    "category": "cs.GT", 
    "author": "Michael L. Littman", 
    "title": "A Polynomial-time Nash Equilibrium Algorithm for Repeated Stochastic   Games", 
    "publish": "2012-06-13T15:41:52Z", 
    "summary": "We present a polynomial-time algorithm that always finds an (approximate)\nNash equilibrium for repeated two-player stochastic games. The algorithm\nexploits the folk theorem to derive a strategy profile that forms an\nequilibrium by buttressing mutually beneficial behavior with threats, where\npossible. One component of our algorithm efficiently searches for an\napproximation of the egalitarian point, the fairest pareto-efficient solution.\nThe paper concludes by applying the algorithm to a set of grid games to\nillustrate typical solutions the algorithm finds. These solutions compare very\nfavorably to those found by competing algorithms, resulting in strategies with\nhigher social welfare, as well as guaranteed computational efficiency.", 
    "link": "http://arxiv.org/pdf/1206.3277v1", 
    "arxiv-id": "1206.3277v1"
},{
    "category": "cs.GT", 
    "author": "Jason Hartline", 
    "title": "The Simple Economics of Approximately Optimal Auctions", 
    "publish": "2012-06-15T18:47:07Z", 
    "summary": "The intuition that profit is optimized by maximizing marginal revenue is a\nguiding principle in microeconomics. In the classical auction theory for agents\nwith linear utility and single-dimensional preferences, Bulow and Roberts\n(1989) show that the optimal auction of Myerson (1981) is in fact optimizing\nmarginal revenue. In particular Myerson's virtual values are exactly the\nderivative of an appropriate revenue curve.\n  This paper considers mechanism design in environments where the agents have\nmulti-dimensional and non-linear preferences. Understanding good auctions for\nthese environments is considered to be the main challenge in Bayesian optimal\nmechanism design. In these environments maximizing marginal revenue may not be\noptimal and there is sometimes no direct way to implement the marginal revenue\nmaximization. Our contributions are three fold: we characterize the settings\nfor which marginal revenue maximization is optimal (by identifying an important\ncondition that we call revenue linearity), we give simple procedures for\nimplementing marginal revenue maximization in general, and we show that\nmarginal revenue maximization is approximately optimal. Our approximation\nfactor smoothly degrades in a term that quantifies how far the environment is\nfrom ideal (where marginal revenue maximization is optimal). Because the\nmarginal revenue mechanism is optimal for single-dimensional agents, our\ngeneralization immediately approximately extends many results for\nsingle-dimensional agents.\n  One of the biggest open questions in Bayesian algorithmic mechanism design is\ndeveloping methodologies that are not brute-force in the size of the agent type\nspace. Our methods identify a subproblem that, e.g., for unit-demand agents\nwith values drawn from product distributions, enables approximation mechanisms\nthat are polynomial in the dimension.", 
    "link": "http://arxiv.org/pdf/1206.3541v3", 
    "arxiv-id": "1206.3541v3"
},{
    "category": "cs.GT", 
    "author": "Eva Tardos", 
    "title": "Bayesian Sequential Auctions", 
    "publish": "2012-06-21T03:37:33Z", 
    "summary": "In many natural settings agents participate in multiple different auctions\nthat are not simultaneous. In such auctions, future opportunities affect\nstrategic considerations of the players. The goal of this paper is to develop a\nquantitative understanding of outcomes of such sequential auctions. In earlier\nwork (Paes Leme et al. 2012) we initiated the study of the price of anarchy in\nsequential auctions. We considered sequential first price auctions in the full\ninformation model, where players are aware of all future opportunities, as well\nas the valuation of all players. In this paper, we study efficiency in\nsequential auctions in the Bayesian environment, relaxing the informational\nassumption on the players. We focus on two environments, both studied in the\nfull information model in Paes Leme et al. 2012, matching markets and matroid\nauctions. In the full information environment, a sequential first price cut\nauction for matroid settings is efficient. In Bayesian environments this is no\nlonger the case, as we show using a simple example with three players. Our main\nresult is a bound of $1+\\frac{e}{e-1}\\approx 2.58$ on the price of anarchy in\nboth matroid auctions and single-value matching markets (even with correlated\ntypes) and a bound of $2\\frac{e}{e-1}\\approx 3.16$ for general matching markets\nwith independent types. To bound the price of anarchy we need to consider\npossible deviations at an equilibrium. In a sequential Bayesian environment the\neffect of deviations is more complex than in one-shot games; early bids allow\nothers to infer information about the player's value. We create effective\ndeviations despite the presence of this difficulty by introducing a bluffing\ntechnique of independent interest.", 
    "link": "http://arxiv.org/pdf/1206.4771v1", 
    "arxiv-id": "1206.4771v1"
},{
    "category": "cs.GT", 
    "author": "Jason D. Hartline", 
    "title": "The Biased Sampling Profit Extraction Auction", 
    "publish": "2012-06-21T17:58:31Z", 
    "summary": "We give an auction for downward-closed environments that generalizes the\nrandom sampling profit extraction auction for digital goods of Fiat et al.\n(2002). The mechanism divides the agents in to a market and a sample using a\nbiased coin and attempts to extract the optimal revenue from the sample from\nthe market. The latter step is done with the downward-closed profit extractor\nof Ha and Hartline (2012). The auction is a 11-approximation to the envyfree\nbenchmark in downward-closed permutation environments. This is an improvement\non the previously best known results of 12.5 for matroid and 30.4 for\ndownward-closed permutation environments that are due to Devanur et al. (2012)\nand Ha and Hartline (2012), respectively.", 
    "link": "http://arxiv.org/pdf/1206.4955v1", 
    "arxiv-id": "1206.4955v1"
},{
    "category": "cs.GT", 
    "author": "Thomas Pradeau", 
    "title": "The uniqueness property for networks with several origin-destination   pairs", 
    "publish": "2012-06-22T11:49:27Z", 
    "summary": "We consider congestion games on networks with nonatomic users and\nuser-specific costs. We are interested in the uniqueness property defined by\nMilchtaich [Milchtaich, I. 2005. Topological conditions for uniqueness of\nequilibrium in networks. Math. Oper. Res. 30 225-244] as the uniqueness of\nequilibrium flows for all assignments of strictly increasing cost functions. He\nsettled the case with two-terminal networks. As a corollary of his result, it\nis possible to prove that some other networks have the uniqueness property as\nwell by adding common fictitious origin and destination.\n  In the present work, we find a necessary condition for networks with several\norigin-destination pairs to have the uniqueness property in terms of excluded\nminors or subgraphs. As a key result, we characterize completely bidirectional\nrings for which the uniqueness property holds: it holds precisely for nine\nnetworks and those obtained from them by elementary operations. For other\nbidirectional rings, we exhibit affine cost functions yielding to two distinct\nequilibrium flows. Related results are also proven. For instance, we\ncharacterize networks having the uniqueness property for any choice of\norigin-destination pairs.", 
    "link": "http://arxiv.org/pdf/1206.5120v4", 
    "arxiv-id": "1206.5120v4"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Robust Learning Equilibrium", 
    "publish": "2012-06-27T15:41:34Z", 
    "summary": "We introduce robust learning equilibrium. The idea of learning equilibrium is\nthat learning algorithms in multi-agent systems should themselves be in\nequilibrium rather than only lead to equilibrium. That is, learning equilibrium\nis immune to strategic deviations: Every agent is better off using its\nprescribed learning algorithm, if all other agents follow their algorithms,\nregardless of the unknown state of the environment. However, a learning\nequilibrium may not be immune to non strategic mistakes. For example, if for a\ncertain period of time there is a failure in the monitoring devices (e.g., the\ncorrect input does not reach the agents), then it may not be in equilibrium to\nfollow the algorithm after the devices are corrected. A robust learning\nequilibrium is immune also to such non-strategic mistakes. The existence of\n(robust) learning equilibrium is especially challenging when the monitoring\ndevices are 'weak'. That is, the information available to each agent at each\nstage is limited. We initiate a study of robust learning equilibrium with\ngeneral monitoring structure and apply it to the context of auctions. We prove\nthe existence of robust learning equilibrium in repeated first-price auctions,\nand discuss its properties.", 
    "link": "http://arxiv.org/pdf/1206.6826v1", 
    "arxiv-id": "1206.6826v1"
},{
    "category": "cs.GT", 
    "author": "Martin Zinkevich", 
    "title": "An Efficient Optimal-Equilibrium Algorithm for Two-player Game Trees", 
    "publish": "2012-06-27T16:25:57Z", 
    "summary": "Two-player complete-information game trees are perhaps the simplest possible\nsetting for studying general-sum games and the computational problem of finding\nequilibria. These games admit a simple bottom-up algorithm for finding subgame\nperfect Nash equilibria efficiently. However, such an algorithm can fail to\nidentify optimal equilibria, such as those that maximize social welfare. The\nreason is that, counterintuitively, probabilistic action choices are sometimes\nneeded to achieve maximum payoffs. We provide a novel polynomial-time algorithm\nfor this problem that explicitly reasons about stochastic decisions and\ndemonstrate its use in an example card game.", 
    "link": "http://arxiv.org/pdf/1206.6855v1", 
    "arxiv-id": "1206.6855v1"
},{
    "category": "cs.GT", 
    "author": "John Musacchio", 
    "title": "A Game-Theoretical Approach for Finding Optimal Strategies in an   Intruder Classification Game", 
    "publish": "2012-07-03T16:43:07Z", 
    "summary": "We consider a game in which a strategic defender classifies an intruder as\nspy or spammer. The classification is based on the number of file server and\nmail server attacks observed during a fixed window. The spammer naively attacks\n(with a known distribution) his main target: the mail server. The spy\nstrategically selects the number of attacks on his main target: the file\nserver. The defender strategically selects his classification policy: a\nthreshold on the number of file server attacks. We model the interaction of the\ntwo players (spy and defender) as a nonzero-sum game: The defender needs to\nbalance missed detections and false alarms in his objective function, while the\nspy has a tradeoff between attacking the file server more aggressively and\nincreasing the chances of getting caught. We give a characterization of the\nNash equilibria in mixed strategies, and demonstrate how the Nash equilibria\ncan be computed in polynomial time. Our characterization gives interesting and\nnon-intuitive insights on the players' strategies at equilibrium: The defender\nuniformly randomizes between a set of thresholds that includes very large\nvalues. The strategy of the spy is a truncated version of the spammer's\ndistribution. We present numerical simulations that validate and illustrate our\ntheoretical results.", 
    "link": "http://arxiv.org/pdf/1207.0745v1", 
    "arxiv-id": "1207.0745v1"
},{
    "category": "cs.GT", 
    "author": "Christos Tzamos", 
    "title": "On the Power of Deterministic Mechanisms for Facility Location Games", 
    "publish": "2012-07-04T10:06:36Z", 
    "summary": "We consider K-Facility Location games, where n strategic agents report their\nlocations in a metric space, and a mechanism maps them to K facilities. Our\nmain result is an elegant characterization of deterministic strategyproof\nmechanisms with a bounded approximation ratio for 2-Facility Location on the\nline. In particular, we show that for instances with n \\geq 5 agents, any such\nmechanism either admits a unique dictator, or always places the facilities at\nthe leftmost and the rightmost location of the instance. As a corollary, we\nobtain that the best approximation ratio achievable by deterministic\nstrategyproof mechanisms for the problem of locating 2 facilities on the line\nto minimize the total connection cost is precisely n-2. Another rather\nsurprising consequence is that the Two-Extremes mechanism of (Procaccia and\nTennenholtz, EC 2009) is the only deterministic anonymous strategyproof\nmechanism with a bounded approximation ratio for 2-Facility Location on the\nline.\n  The proof of the characterization employs several new ideas and technical\ntools, which provide new insights into the behavior of deterministic\nstrategyproof mechanisms for K-Facility Location games, and may be of\nindependent interest. Employing one of these tools, we show that for every K\n\\geq 3, there do not exist any deterministic anonymous strategyproof mechanisms\nwith a bounded approximation ratio for K-Facility Location on the line, even\nfor simple instances with K+1 agents. Moreover, building on the\ncharacterization for the line, we show that there do not exist any\ndeterministic strategyproof mechanisms with a bounded approximation ratio for\n2-Facility Location on more general metric spaces, which is true even for\nsimple instances with 3 agents located in a star.", 
    "link": "http://arxiv.org/pdf/1207.0935v1", 
    "arxiv-id": "1207.0935v1"
},{
    "category": "cs.GT", 
    "author": "David C. Parkes", 
    "title": "Models for Truthful Online Double Auctions", 
    "publish": "2012-07-04T16:02:21Z", 
    "summary": "Online double auctions (DAs) model a dynamic two-sided matching problem with\nprivate information and self-interest, and are relevant for dynamic resource\nand task allocation problems. We present a general method to design truthful\nDAs, such that no agent can benefit from misreporting its arrival time,\nduration, or value. The family of DAs is parameterized by a pricing rule, and\nincludes a generalization of McAfee's truthful DA to this dynamic setting. We\npresent an empirical study, in which we study the allocative-surplus and agent\nsurplus for a number of different DAs. Our results illustrate that dynamic\npricing rules are important to provide good market efficiency for markets with\nhigh volatility or low volume.", 
    "link": "http://arxiv.org/pdf/1207.1360v1", 
    "arxiv-id": "1207.1360v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "On the Value of Correlation", 
    "publish": "2012-07-04T16:02:46Z", 
    "summary": "Correlated equilibrium (Aumann, 1974) generalizes Nash equilibrium to allow\ncorrelation devices. Aumann showed an example of a game, and of a correlated\nequilibrium in this game, in which the agents' surplus (expected sum of payo s)\nis greater than their surplus in all mixed-strategy equilibria. Following the\nidea initiated by the price of anarchy literature (Koutsoupias & Papadimitriou,\n1999;Papadimitriou, 2001) this suggests the study of two major measures for the\nvalue of correlation in a game with non-negative payoffs: 1. The ratio between\nthe maximal surplus obtained in a correlated equilibrium to the maximal surplus\nobtained in a mixed-strategy equilibrium. We refer to this ratio as the\nmediation value. 2. The ratio between the maximal surplus to the maximal\nsurplus obtained in a correlated equilibrium. We refer to this ratio as the\nenforcement value. In this work we initiate the study of the mediation and\nenforcement values, providing several general results on the value of\ncorrelation as captured by these concepts. We also present a set of results for\nthe more specialized case of congestion games (Rosenthal,1973), a class of\ngames that received a lot of attention in the recent literature.", 
    "link": "http://arxiv.org/pdf/1207.1362v1", 
    "arxiv-id": "1207.1362v1"
},{
    "category": "cs.GT", 
    "author": "Francesco Scarcello", 
    "title": "Bounding the Uncertainty of Graphical Games: The Complexity of Simple   Requirements, Pareto and Strong Nash Equilibria", 
    "publish": "2012-07-04T16:12:21Z", 
    "summary": "We investigate the complexity of bounding the uncertainty of graphical games,\nand we provide new insight into the intrinsic difficulty of computing Nash\nequilibria. In particular, we show that, if one adds very simple and natural\nadditional requirements to a graphical game, the existence of Nash equilibria\nis no longer guaranteed, and computing an equilibrium is an intractable\nproblem. Moreover, if stronger equilibrium conditions are required for the\ngame, we get hardness results for the second level of the polynomial hierarchy.\nOur results offer a clear picture of the complexity of mixed Nash equilibria in\ngraphical games, and answer some open research questions posed by Conitzer and\nSandholm (2003).", 
    "link": "http://arxiv.org/pdf/1207.1383v1", 
    "arxiv-id": "1207.1383v1"
},{
    "category": "cs.GT", 
    "author": "Jeffrey K. MacKie-Mason", 
    "title": "Self-Confirming Price Prediction for Bidding in Simultaneous Ascending   Auctions", 
    "publish": "2012-07-04T16:19:04Z", 
    "summary": "Simultaneous ascending auctions present agents with the exposure problem:\nbidding to acquire a bundle risks the possibility of obtaining an undesired\nsubset of the goods. Auction theory provides little guidance for dealing with\nthis problem. We present a new family of decisiontheoretic bidding strategies\nthat use probabilistic predictions of final prices. We focus on selfconfirming\nprice distribution predictions, which by definition turn out to be correct when\nall agents bid decision-theoretically based on them. Bidding based on these is\nprovably not optimal in general, but our experimental evidence indicates the\nstrategy can be quite effective compared to other known methods.", 
    "link": "http://arxiv.org/pdf/1207.1400v1", 
    "arxiv-id": "1207.1400v1"
},{
    "category": "cs.GT", 
    "author": "Amy Greenwald", 
    "title": "An Algorithm for Computing Stochastically Stable Distributions with   Applications to Multiagent Learning in Repeated Games", 
    "publish": "2012-07-04T16:28:54Z", 
    "summary": "One of the proposed solutions to the equilibrium selection problem for agents\nlearning in repeated games is obtained via the notion of stochastic stability.\nLearning algorithms are perturbed so that the Markov chain underlying the\nlearning dynamics is necessarily irreducible and yields a unique stable\ndistribution. The stochastically stable distribution is the limit of these\nstable distributions as the perturbation rate tends to zero. We present the\nfirst exact algorithm for computing the stochastically stable distribution of a\nMarkov chain. We use our algorithm to predict the long-term dynamics of simple\nlearning algorithms in sample repeated games.", 
    "link": "http://arxiv.org/pdf/1207.1424v1", 
    "arxiv-id": "1207.1424v1"
},{
    "category": "cs.GT", 
    "author": "Nicholas R. Jennings", 
    "title": "Matching Games with Additive Externalities", 
    "publish": "2012-07-16T14:00:50Z", 
    "summary": "Two-sided matchings are an important theoretical tool used to model markets\nand social interactions. In many real life problems the utility of an agent is\ninfluenced not only by their own choices, but also by the choices that other\nagents make. Such an influence is called an externality. Whereas fully\nexpressive representations of externalities in matchings require exponential\nspace, in this paper we propose a compact model of externalities, in which the\ninfluence of a match on each agent is computed additively. In this framework,\nwe analyze many-to-many and one-to-one matchings under neutral, optimistic, and\npessimistic behaviour, and provide both computational hardness results and\npolynomial-time algorithms for computing stable outcomes.", 
    "link": "http://arxiv.org/pdf/1207.3682v1", 
    "arxiv-id": "1207.3682v1"
},{
    "category": "cs.GT", 
    "author": "Justin Boyan", 
    "title": "Bidding under Uncertainty: Theory and Experiments", 
    "publish": "2012-07-11T14:40:38Z", 
    "summary": "This paper describes a study of agent bidding strategies, assuming\ncombinatorial valuations for complementary and substitutable goods, in three\nauction environments: sequential auctions, simultaneous auctions, and the\nTrading Agent Competition (TAC) Classic hotel auction design, a hybrid of\nsequential and simultaneous auctions. The problem of bidding in sequential\nauctions is formulated as an MDP, and it is argued that expected marginal\nutility bidding is the optimal bidding policy. The problem of bidding in\nsimultaneous auctions is formulated as a stochastic program, and it is shown by\nexample that marginal utility bidding is not an optimal bidding policy, even in\ndeterministic settings. Two alternative methods of approximating a solution to\nthis stochastic program are presented: the first method, which relies on\nexpected values, is optimal in deterministic environments; the second method,\nwhich samples the nondeterministic environment, is asymptotically optimal as\nthe number of samples tends to infinity. Finally, experiments with these\nvarious bidding policies are described in the TAC Classic setting.", 
    "link": "http://arxiv.org/pdf/1207.4108v1", 
    "arxiv-id": "1207.4108v1"
},{
    "category": "cs.GT", 
    "author": "Kevin Leyton-Brown", 
    "title": "Computing Nash Equilibria of Action-Graph Games", 
    "publish": "2012-07-11T14:47:40Z", 
    "summary": "Action-graph games (AGGs) are a fully expressive game representation which\ncan compactly express both strict and context-specific independence between\nplayers' utility functions. Actions are represented as nodes in a graph G, and\nthe payoff to an agent who chose the action s depends only on the numbers of\nother agents who chose actions connected to s. We present algorithms for\ncomputing both symmetric and arbitrary equilibria of AGGs using a continuation\nmethod. We analyze the worst-case cost of computing the Jacobian of the payoff\nfunction, the exponential-time bottleneck step, and in all cases achieve\nexponential speedup. When the indegree of G is bounded by a constant and the\ngame is symmetric, the Jacobian can be computed in polynomial time.", 
    "link": "http://arxiv.org/pdf/1207.4128v1", 
    "arxiv-id": "1207.4128v1"
},{
    "category": "cs.GT", 
    "author": "Craig Boutilier", 
    "title": "Regret Minimizing Equilibria and Mechanisms for Games with Strict Type   Uncertainty", 
    "publish": "2012-07-11T14:55:55Z", 
    "summary": "Mechanism design has found considerable application to the construction of\nagent-interaction protocols. In the standard setting, the type (e.g., utility\nfunction) of an agent is not known by other agents, nor is it known by the\nmechanism designer. When this uncertainty is quantified probabilistically, a\nmechanism induces a game of incomplete information among the agents. However,\nin many settings, uncertainty over utility functions cannot easily be\nquantified. We consider the problem of incomplete information games in which\ntype uncertainty is strict or unquantified. We propose the use of minimax\nregret as a decision criterion in such games, a robust approach for dealing\nwith type uncertainty. We define minimax-regret equilibria and prove that these\nexist in mixed strategies for finite games. We also consider the problem of\nmechanism design in this framework by adopting minimax regret as an\noptimization criterion for the designer itself, and study automated\noptimization of such mechanisms.", 
    "link": "http://arxiv.org/pdf/1207.4147v1", 
    "arxiv-id": "1207.4147v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Reputation Systems: An Axiomatic Approach", 
    "publish": "2012-07-11T15:03:16Z", 
    "summary": "Reasoning about agent preferences on a set of alternatives, and the\naggregation of such preferences into some social ranking is a fundamental issue\nin reasoning about uncertainty and multi-agent systems. When the set of agents\nand the set of alternatives coincide, we get the so-called reputation systems\nsetting. Famous types of reputation systems include page ranking in the context\nof search engines and traders ranking in the context of e-commerce. In this\npaper we present the first axiomatic study of reputation systems. We present\nthree basic postulates that the desired/aggregated social ranking should\nsatisfy and prove an impossibility theorem showing that no appropriate social\nranking, satisfying all requirements, exists. Then we show that by relaxing any\nof these requirements an appropriate social ranking can be found. We first\nstudy reputation systems with (only) positive feedbacks. This setting refers to\nsystems where agents' votes are interpreted as indications for the importance\nof other agents, as is the case in page ranking. Following this, we discuss the\ncase of negative feedbacks, a most common situation in e-commerce settings,\nwhere traders may complain about the behavior of others. Finally, we discuss\nthe case where both positive and negative feedbacks are available.", 
    "link": "http://arxiv.org/pdf/1207.4163v1", 
    "arxiv-id": "1207.4163v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Sequential Information Elicitation in Multi-Agent Systems", 
    "publish": "2012-07-11T15:04:29Z", 
    "summary": "We introduce the study of sequential information elicitation in strategic\nmulti-agent systems. In an information elicitation setup a center attempts to\ncompute the value of a function based on private information (a-k-a secrets)\naccessible to a set of agents. We consider the classical multi-party\ncomputation setup where each agent is interested in knowing the result of the\nfunction. However, in our setting each agent is strategic,and since acquiring\ninformation is costly, an agent may be tempted not spending the efforts of\nobtaining the information, free-riding on other agents' computations. A\nmechanism which elicits agents' secrets and performs the desired computation\ndefines a game. A mechanism is 'appropriate' if there exists an equilibrium in\nwhich it is able to elicit (sufficiently many) agents' secrets and perform the\ncomputation, for all possible secret vectors.We characterize a general\nefficient procedure for determining an appropriate mechanism, if such mechanism\nexists. Moreover, we also address the existence problem, providing a polynomial\nalgorithm for verifying the existence of an appropriate mechanism.", 
    "link": "http://arxiv.org/pdf/1207.4165v1", 
    "arxiv-id": "1207.4165v1"
},{
    "category": "cs.GT", 
    "author": "Michael P. Wellman", 
    "title": "Computing Best-Response Strategies in Infinite Games of Incomplete   Information", 
    "publish": "2012-07-11T15:06:33Z", 
    "summary": "We describe an algorithm for computing best response strategies in a class of\ntwo-player infinite games of incomplete information, defined by payoffs\npiecewise linear in agents' types and actions, conditional on linear\ncomparisons of agents' actions. We show that this class includes many\nwell-known games including a variety of auctions and a novel allocation game.\nIn some cases, the best-response algorithm can be iterated to compute\nBayes-Nash equilibria. We demonstrate the efficiency of our approach on\nexisting and new games.", 
    "link": "http://arxiv.org/pdf/1207.4171v1", 
    "arxiv-id": "1207.4171v1"
},{
    "category": "cs.GT", 
    "author": "Athanasios V. Vasilakos", 
    "title": "Joint Rate Adaptation and Medium Access in Wireless LANs: a   Non-cooperative Game Theoretic Perspective", 
    "publish": "2012-07-18T04:04:35Z", 
    "summary": "Wireless local area networks (WLANs) based on IEEE 802.11 standards are\nbecoming ubiquitous today and typically support multiple data rates. In such\nmulti-rate WLANs, distributed medium access and rate adaptation are two key\nelements to achieve efficient radio resource utilization, especially in\nnon-cooperative environments. In this paper, we present an analytical study on\nthe non-cooperative multi-rate WLANs composed of selfish users jointly\nadjusting their data rate and contention window size at the medium access level\nto maximize their own throughput, irrespective of the impact of their selfish\nbehaviors on overall system performance. Specifically, we develop an adapted\nTit-For-Tat (TFT) strategy to guide the system to an efficient equilibrium in\nnon-cooperative environments. We model the interactions among selfish users\nunder the adapted TFT framework as a non-cooperative joint medium access and\nrate adaptation game. A systematic analysis is conducted on the structural\nproperties of the game to provide insights on the interaction between rate\nadaptation and 802.11 medium access control in a competitive setting. We show\nthat the game has multiple equilibria, which, after the equilibrium refinement\nprocess that we develop, reduce to a unique efficient equilibrium. We further\ndevelop a distributed algorithm to achieve this equilibrium and demonstrate\nthat the equilibrium achieves the performance very close to the system optimum\nin a social perspective.", 
    "link": "http://arxiv.org/pdf/1207.4258v1", 
    "arxiv-id": "1207.4258v1"
},{
    "category": "cs.GT", 
    "author": "Paul G. Spirakis", 
    "title": "On the Hardness of Network Design for Bottleneck Routing Games", 
    "publish": "2012-07-22T10:22:09Z", 
    "summary": "In routing games, the network performance at equilibrium can be significantly\nimproved if we remove some edges from the network. This counterintuitive fact,\nwidely known as Braess's paradox, gives rise to the (selfish) network design\nproblem, where we seek to recognize routing games suffering from the paradox,\nand to improve the equilibrium performance by edge removal. In this work, we\ninvestigate the computational complexity and the approximability of the network\ndesign problem for non-atomic bottleneck routing games, where the individual\ncost of each player is the bottleneck cost of her path, and the social cost is\nthe bottleneck cost of the network. We first show that bottleneck routing games\ndo not suffer from Braess's paradox either if the network is series-parallel,\nor if we consider only subpath-optimal Nash flows. On the negative side, we\nprove that even for games with strictly increasing linear latencies, it is\nNP-hard not only to recognize instances suffering from the paradox, but also to\ndistinguish between instances for which the Price of Anarchy (PoA) can decrease\nto 1 and instances for which the PoA is as large as \\Omega(n^{0.121}) and\ncannot improve by edge removal. Thus, the network design problem for such games\nis NP-hard to approximate within a factor of O(n^{0.121-\\eps}), for any\nconstant \\eps > 0. On the positive side, we show how to compute an almost\noptimal subnetwork w.r.t. the bottleneck cost of its worst Nash flow, when the\nworst Nash flow in the best subnetwork routes a non-negligible amount of flow\non all used edges. The running time is determined by the total number of paths,\nand is quasipolynomial when the number of paths is quasipolynomial.", 
    "link": "http://arxiv.org/pdf/1207.5212v1", 
    "arxiv-id": "1207.5212v1"
},{
    "category": "cs.GT", 
    "author": "Alexander Setzer", 
    "title": "Basic Network Creation Games with Communication Interests", 
    "publish": "2012-07-23T15:01:11Z", 
    "summary": "Network creation games model the creation and usage costs of networks formed\nby a set of selfish peers. Each peer has the ability to change the network in a\nlimited way, e.g., by creating or deleting incident links. In doing so, a peer\ncan reduce its individual communication cost. Typically, these costs are\nmodeled by the maximum or average distance in the network. We introduce a\ngeneralized version of the basic network creation game (BNCG). In the BNCG (by\nAlon et al., SPAA 2010), each peer may replace one of its incident links by a\nlink to an arbitrary peer. This is done in a selfish way in order to minimize\neither the maximum or average distance to all other peers. That is, each peer\nworks towards a network structure that allows himself to communicate\nefficiently with all other peers. However, participants of large networks are\nseldom interested in all peers. Rather, they want to communicate efficiently\nonly with a small subset of peers. Our model incorporates these (communication)\ninterests explicitly. In the MAX-version, each node tries to minimize its\nmaximum distance to nodes it is interested in.\n  Given peers with interests and a communication network forming a tree, we\nprove several results on the structure and quality of equilibria in our model.\nFor the MAX-version, we give an upper worst case bound of O(\\sqrt{n}) for the\nprivate costs in an equilibrium of n peers. Moreover, we give an equilibrium\nfor a circular interest graph where a node has private cost \\Omega(\\sqrt{n}),\nshowing that our bound is tight. This example can be extended such that we get\na tight bound of \\Theta(\\sqrt{n}) for the price of anarchy. For the case of\ngeneral communication networks we show the price of anarchy to be \\Theta(n).\nAdditionally, we prove an interesting connection between a maximum independent\nset in the interest graph and the private costs of the peers.", 
    "link": "http://arxiv.org/pdf/1207.5419v1", 
    "arxiv-id": "1207.5419v1"
},{
    "category": "cs.GT", 
    "author": "Jean Walrand", 
    "title": "Incentive Mechanisms based on Minority Game in Heterogeneous DTNs", 
    "publish": "2012-07-29T09:48:24Z", 
    "summary": "In this paper we design an incentive mechanism for heterogeneous Delay\nTolerant Networks (DTNs). The proposed mechanism tackles a core problem of such\nsystems: how to induce coordination of DTN relays in order to achieve a target\nperformance figure, e.g., delivery probability or end-to-end delay, under a\ngiven constraint in term of network resources, e.g., number of active nodes or\nenergy consumption. Also, we account for the realistic case when the cost for\ntaking part in the forwarding process varies with the devices' technology or\nthe users' habits. Finally, the scheme is truly applicable to DTNs since it\nworks with no need for end-to-end connectivity.\n  In this context, we first introduce the basic coordination mechanism\nleveraging the notion of a Minority Game. In this game, relays compete to be in\nthe population minority and their utility is defined in combination with a\nrewarding mechanism. The rewards in turn configure as a control by which the\nnetwork operator controls the desired operating point for the DTN. To this aim,\nwe provide a full characterization of the equilibria of the game in the case of\nheterogeneous DTNs. Finally, a learning algorithm based on stochastic\napproximations provably drives the system to the equilibrium solution without\nrequiring perfect state information at relay nodes or at the source node and\nwithout using end-to-end communications to implement the rewarding scheme. We\nprovide extensive numerical results to validate the proposed scheme.", 
    "link": "http://arxiv.org/pdf/1207.6760v4", 
    "arxiv-id": "1207.6760v4"
},{
    "category": "cs.GT", 
    "author": "Eva Tardos", 
    "title": "Composable and Efficient Mechanisms", 
    "publish": "2012-11-06T17:47:16Z", 
    "summary": "We initiate the study of efficient mechanism design with guaranteed good\nproperties even when players participate in multiple different mechanisms\nsimultaneously or sequentially. We define the class of smooth mechanisms,\nrelated to smooth games defined by Roughgarden, that can be thought of as\nmechanisms that generate approximately market clearing prices. We show that\nsmooth mechanisms result in high quality outcome in equilibrium both in the\nfull information setting and in the Bayesian setting with uncertainty about\nparticipants, as well as in learning outcomes. Our main result is to show that\nsuch mechanisms compose well: smoothness locally at each mechanism implies\nefficiency globally.\n  For mechanisms where good performance requires that bidders do not bid above\ntheir value, we identify the notion of a weakly smooth mechanism. Weakly smooth\nmechanisms, such as the Vickrey auction, are approximately efficient under the\nno-overbidding assumption. Similar to smooth mechanisms, weakly smooth\nmechanisms behave well in composition, and have high quality outcome in\nequilibrium (assuming no overbidding) both in the full information setting and\nin the Bayesian setting, as well as in learning outcomes.\n  In most of the paper we assume participants have quasi-linear valuations. We\nalso extend some of our results to settings where participants have budget\nconstraints.", 
    "link": "http://arxiv.org/pdf/1211.1325v1", 
    "arxiv-id": "1211.1325v1"
},{
    "category": "cs.GT", 
    "author": "Kamesh Munagala", 
    "title": "Optimal Auctions via the Multiplicative Weight Method", 
    "publish": "2012-11-07T21:45:50Z", 
    "summary": "We show that the multiplicative weight update method provides a simple recipe\nfor designing and analyzing optimal Bayesian Incentive Compatible (BIC)\nauctions, and reduces the time complexity of the problem to pseudo-polynomial\nin parameters that depend on single agent instead of depending on the size of\nthe joint type space. We use this framework to design computationally efficient\noptimal auctions that satisfy ex-post Individual Rationality in the presence of\nconstraints such as (hard, private) budgets and envy-freeness. We also design\noptimal auctions when buyers and a seller's utility functions are non-linear.\nScenarios with such functions include (a) auctions with \"quitting rights\", (b)\ncost to borrow money beyond budget, (c) a seller's and buyers' risk aversion.\nFinally, we show how our framework also yields optimal auctions for variety of\nauction settings considered in Cai et al, Alaei et al, albeit with\npseudo-polynomial running times.", 
    "link": "http://arxiv.org/pdf/1211.1699v3", 
    "arxiv-id": "1211.1699v3"
},{
    "category": "cs.GT", 
    "author": "Christos Tzamos", 
    "title": "The Complexity of Optimal Mechanism Design", 
    "publish": "2012-11-07T21:56:16Z", 
    "summary": "Myerson's seminal work provides a computationally efficient revenue-optimal\nauction for selling one item to multiple bidders. Generalizing this work to\nselling multiple items at once has been a central question in economics and\nalgorithmic game theory, but its complexity has remained poorly understood. We\nanswer this question by showing that a revenue-optimal auction in multi-item\nsettings cannot be found and implemented computationally efficiently, unless\nZPP contains P^#P. This is true even for a single additive bidder whose values\nfor the items are independently distributed on two rational numbers with\nrational probabilities. Our result is very general: we show that it is hard to\ncompute any encoding of an optimal auction of any format (direct or indirect,\ntruthful or non-truthful) that can be implemented in expected polynomial time.\nIn particular, under well-believed complexity-theoretic assumptions,\nrevenue-optimization in very simple multi-item settings can only be tractably\napproximated.\n  We note that our hardness result applies to randomized mechanisms in a very\nsimple setting, and is not an artifact of introducing combinatorial structure\nto the problem by allowing correlation among item values, introducing\ncombinatorial valuations, or requiring the mechanism to be deterministic (whose\nstructure is readily combinatorial). Our proof is enabled by a\nflow-interpretation of the solutions of an exponential-size linear program for\nrevenue maximization with an additional supermodularity constraint.", 
    "link": "http://arxiv.org/pdf/1211.1703v2", 
    "arxiv-id": "1211.1703v2"
},{
    "category": "cs.GT", 
    "author": "Orestis Telelis", 
    "title": "On the Inefficiency of the Uniform Price Auction", 
    "publish": "2012-11-08T14:18:01Z", 
    "summary": "We present our results on Uniform Price Auctions, one of the standard\nsealed-bid multi-unit auction formats, for selling multiple identical units of\na single good to multi-demand bidders. Contrary to the truthful and\neconomically efficient multi-unit Vickrey auction, the Uniform Price Auction\nencourages strategic bidding and is socially inefficient in general. The\nuniform pricing rule is, however, widely popular by its appeal to the natural\nanticipation, that identical items should be identically priced. In this work\nwe study equilibria of the Uniform Price Auction for bidders with (symmetric)\nsubmodular valuation functions, over the number of units that they win. We\ninvestigate pure Nash equilibria of the auction in undominated strategies; we\nproduce a characterization of these equilibria that allows us to prove that a\nfraction 1-1/e of the optimum social welfare is always recovered in undominated\npure Nash equilibrium -- and this bound is essentially tight. Subsequently, we\nstudy the auction under the incomplete information setting and prove a bound of\n4-2/k on the economic inefficiency of (mixed) Bayes Nash equilibria that are\nsupported by undominated strategies.", 
    "link": "http://arxiv.org/pdf/1211.1860v4", 
    "arxiv-id": "1211.1860v4"
},{
    "category": "cs.GT", 
    "author": "Bingli Jiao", 
    "title": "Dynamic Popular Content Distribution in Vehicular Networks using   Coalition Formation Games", 
    "publish": "2012-11-09T09:11:56Z", 
    "summary": "Driven by both safety concerns and commercial interests, vehicular ad hoc\nnetworks (VANETs) have recently received considerable attentions. In this\npaper, we address popular content distribution (PCD) in VANETs, in which one\nlarge popular file is downloaded from a stationary roadside unit (RSU), by a\ngroup of on-board units (OBUs) driving through an area of interest (AoI) along\na highway. Due to high speeds of vehicles and deep fadings of\nvehicle-to-roadside (V2R) channels, some of the vehicles may not finish\ndownloading the entire file but only possess several pieces of it. To\nsuccessfully send a full copy to each OBU, we propose a cooperative approach\nbased on the coalition formation games, in which OBUs exchange their possessed\npieces by broadcasting to and receiving from their neighbors. Simulation\nresults show that our proposed approach presents a considerable performance\nimprovement relative to the non-cooperative approach, in which the OBUs\nbroadcast randomly selected pieces to their neighbors as along as the spectrum\nis detected to be unoccupied.", 
    "link": "http://arxiv.org/pdf/1211.2081v1", 
    "arxiv-id": "1211.2081v1"
},{
    "category": "cs.GT", 
    "author": "Mat\u00fa\u0161 Mihal\u00e1k", 
    "title": "Improving the H_k-Bound on the Price of Stability in Undirected Shapley   Network Design Games", 
    "publish": "2012-11-09T10:05:53Z", 
    "summary": "In this paper we show that the price of stability of Shapley network design\ngames on undirected graphs with k players is at most (k^3(k+1)/2-k^2) /\n(1+k^3(k+1)/2-k^2) H_k = (1 - \\Theta(1/k^4)) H_k, where H_k denotes the k-th\nharmonic number. This improves on the known upper bound of H_k, which is also\nvalid for directed graphs but for these, in contrast, is tight. Hence, we give\nthe first non-trivial upper bound on the price of stability for undirected\nShapley network design games that is valid for an arbitrary number of players.\nOur bound is proved by analyzing the price of stability restricted to Nash\nequilibria that minimize the potential function of the game. We also present a\ngame with k=3 players in which such a restricted price of stability is 1.634.\nThis shows that the analysis of Bil\\`o and Bove (Journal of Interconnection\nNetworks, Volume 12, 2011) is tight. In addition, we give an example for three\nplayers that improves the lower bound on the (unrestricted) price of stability\nto 1.571.", 
    "link": "http://arxiv.org/pdf/1211.2090v2", 
    "arxiv-id": "1211.2090v2"
},{
    "category": "cs.GT", 
    "author": "Ashish Rastogi", 
    "title": "Tatonnement in Ongoing Markets of Complementary Goods", 
    "publish": "2012-11-10T00:24:54Z", 
    "summary": "This paper continues the study, initiated by Cole and Fleischer, of the\nbehavior of a tatonnement price update rule in Ongoing Fisher Markets. The\nprior work showed fast convergence toward an equilibrium when the goods\nsatisfied the weak gross substitutes property and had bounded demand and income\nelasticities.\n  The current work shows that fast convergence also occurs for the following\ntypes of markets:\n  - All pairs of goods are complements to each other, and - the demand and\nincome elasticities are suitably bounded.\n  In particular, these conditions hold when all buyers in the market are\nequipped with CES utilities, where all the parameters $\\rho$, one per buyer,\nsatisfy $-1 < \\rho \\le 0$.\n  In addition, we extend the above result to markets in which a mixture of\ncomplements and substitutes occur. This includes characterizing a class of\nnested CES utilities for which fast convergence holds.\n  An interesting technical contribution, which may be of independent interest,\nis an amortized analysis for handling asynchronous events in settings in which\nthere are a mix of continuous changes and discrete events.", 
    "link": "http://arxiv.org/pdf/1211.2268v1", 
    "arxiv-id": "1211.2268v1"
},{
    "category": "cs.GT", 
    "author": "Bernhard von Stengel", 
    "title": "Rank-1 Games With Exponentially Many Nash Equilibria", 
    "publish": "2012-11-11T11:55:27Z", 
    "summary": "The rank of a bimatrix game (A,B) is the rank of the matrix A+B. We give a\nconstruction of rank-1 games with exponentially many equilibria, which answers\nan open problem by Kannan and Theobald (2010).", 
    "link": "http://arxiv.org/pdf/1211.2405v1", 
    "arxiv-id": "1211.2405v1"
},{
    "category": "cs.GT", 
    "author": "Ian A. Kash", 
    "title": "General Truthfulness Characterizations Via Convex Analysis", 
    "publish": "2012-11-13T16:31:30Z", 
    "summary": "We present a model of truthful elicitation which generalizes and extends\nmechanisms, scoring rules, and a number of related settings that do not quite\nqualify as one or the other. Our main result is a characterization theorem,\nyielding characterizations for all of these settings, including a new\ncharacterization of scoring rules for non-convex sets of distributions. We\ngeneralize this model to eliciting some property of the agent's private\ninformation, and provide the first general characterization for this setting.\nWe also show how this yields a new proof of a result in mechanism design due to\nSaks and Yu.", 
    "link": "http://arxiv.org/pdf/1211.3043v3", 
    "arxiv-id": "1211.3043v3"
},{
    "category": "cs.GT", 
    "author": "Rann Smorodinsky", 
    "title": "Ex-Post Equilibrium and VCG Mechanisms", 
    "publish": "2012-11-14T12:52:16Z", 
    "summary": "Consider an abstract social choice setting with incomplete information, where\nthe number of alternatives is large. Albeit natural, implementing VCG\nmechanisms may not be feasible due to the prohibitive communication\nconstraints. However, if players restrict attention to a subset of the\nalternatives, feasibility may be recovered.\n  This paper characterizes the class of subsets which induce an ex-post\nequilibrium in the original game. It turns out that a crucial condition for\nsuch subsets to exist is the existence of a type-independent optimal social\nalternative, for each player. We further analyze the welfare implications of\nthese restrictions.\n  This work follows work by Holzman, Kfir-Dahav, Monderer and Tennenholtz\n(2004) and Holzman and Monderer (2004) where similar analysis is done for\ncombinatorial auctions.", 
    "link": "http://arxiv.org/pdf/1211.3293v1", 
    "arxiv-id": "1211.3293v1"
},{
    "category": "cs.GT", 
    "author": "Sophie Pinchinat", 
    "title": "Uniform Strategies", 
    "publish": "2012-12-03T20:24:48Z", 
    "summary": "We consider turn-based game arenas for which we investigate uniformity\nproperties of strategies. These properties involve bundles of plays, that arise\nfrom some semantical motive. Typically, we can represent constraints on allowed\nstrategies, such as being observation-based. We propose a formal language to\nspecify uniformity properties and demonstrate its relevance by rephrasing\nvarious known problems from the literature. Note that the ability to correlate\ndifferent plays cannot be achieved by any branching-time logic if not equipped\nwith an additional modality, so-called R in this contribution. We also study an\nautomated procedure to synthesize strategies subject to a uniformity property,\nwhich strictly extends existing results based on, say standard temporal logics.\nWe exhibit a generic solution for the synthesis problem provided the bundles of\nplays rely on any binary relation definable by a finite state transducer. This\nsolution yields a non-elementary procedure.", 
    "link": "http://arxiv.org/pdf/1212.0526v1", 
    "arxiv-id": "1212.0526v1"
},{
    "category": "cs.GT", 
    "author": "Behrouz Touri", 
    "title": "A Novel Distance-Based Approach to Constrained Rank Aggregation", 
    "publish": "2012-12-06T21:06:21Z", 
    "summary": "We consider a classical problem in choice theory -- vote aggregation -- using\nnovel distance measures between permutations that arise in several practical\napplications. The distance measures are derived through an axiomatic approach,\ntaking into account various issues arising in voting with side constraints. The\nside constraints of interest include non-uniform relevance of the top and the\nbottom of rankings (or equivalently, eliminating negative outliers in votes)\nand similarities between candidates (or equivalently, introducing diversity in\nthe voting process). The proposed distance functions may be seen as weighted\nversions of the Kendall $\\tau$ distance and weighted versions of the Cayley\ndistance. In addition to proposing the distance measures and providing the\ntheoretical underpinnings for their applications, we also consider algorithmic\naspects associated with distance-based aggregation processes. We focus on two\nmethods. One method is based on approximating weighted distance measures by a\ngeneralized version of Spearman's footrule distance, and it has provable\nconstant approximation guarantees. The second class of algorithms is based on a\nnon-uniform Markov chain method inspired by PageRank, for which currently only\nheuristic guarantees are known. We illustrate the performance of the proposed\nalgorithms for a number of distance measures for which the optimal solution may\nbe easily computed.", 
    "link": "http://arxiv.org/pdf/1212.1471v1", 
    "arxiv-id": "1212.1471v1"
},{
    "category": "cs.GT", 
    "author": "William E. Walsh", 
    "title": "Cooperative Negotiation in Autonomic Systems using Incremental Utility   Elicitation", 
    "publish": "2012-10-19T15:04:08Z", 
    "summary": "Decentralized resource allocation is a key problem for large-scale autonomic\n(or self-managing) computing systems. Motivated by a data center scenario, we\nexplore efficient techniques for resolving resource conflicts via cooperative\nnegotiation. Rather than computing in advance the functional dependence of each\nelement's utility upon the amount of resource it receives, which could be\nprohibitively expensive, each element's utility is elicited incrementally. Such\nincremental utility elicitation strategies require the evaluation of only a\nsmall set of sampled utility function points, yet they find near-optimal\nallocations with respect to a minimax regret criterion. We describe preliminary\ncomputational experiments that illustrate the benefit of our approach.", 
    "link": "http://arxiv.org/pdf/1212.2443v1", 
    "arxiv-id": "1212.2443v1"
},{
    "category": "cs.GT", 
    "author": "Tim Roughgarden", 
    "title": "Near-Optimal Multi-Unit Auctions with Ordered Bidders", 
    "publish": "2012-12-12T14:14:40Z", 
    "summary": "We construct prior-free auctions with constant-factor approximation\nguarantees with ordered bidders, in both unlimited and limited supply settings.\nWe compare the expected revenue of our auctions on a bid vector to the monotone\nprice benchmark, the maximum revenue that can be obtained from a bid vector\nusing supply-respecting prices that are nonincreasing in the bidder ordering\nand bounded above by the second-highest bid. As a consequence, our auctions are\nsimultaneously near-optimal in a wide range of Bayesian multi-unit\nenvironments.", 
    "link": "http://arxiv.org/pdf/1212.2825v1", 
    "arxiv-id": "1212.2825v1"
},{
    "category": "cs.GT", 
    "author": "Qiqi Yan", 
    "title": "Envy Freedom and Prior-free Mechanism Design", 
    "publish": "2012-12-16T00:06:41Z", 
    "summary": "We consider the provision of an abstract service to single-dimensional\nagents. Our model includes position auctions, single-minded combinatorial\nauctions, and constrained matching markets. When the agents' values are drawn\nfrom a distribution, the Bayesian optimal mechanism is given by Myerson (1981)\nas a virtual-surplus optimizer. We develop a framework for prior-free mechanism\ndesign and analysis. A good mechanism in our framework approximates the optimal\nmechanism for the distribution if there is a distribution; moreover, when there\nis no distribution this mechanism still performs well.\n  We define and characterize optimal envy-free outcomes in symmetric\nsingle-dimensional environments. Our characterization mirrors Myerson's theory.\nFurthermore, unlike in mechanism design where there is no point-wise optimal\nmechanism, there is always a point-wise optimal envy-free outcome.\n  Envy-free outcomes and incentive-compatible mechanisms are similar in\nstructure and performance. We therefore use the optimal envy-free revenue as a\nbenchmark for measuring the performance of a prior-free mechanism. A good\nmechanism is one that approximates the envy free benchmark on any profile of\nagent values. We show that good mechanisms exist, and in particular, a natural\ngeneralization of the random sampling auction of Goldberg et al. (2001) is a\nconstant approximation.", 
    "link": "http://arxiv.org/pdf/1212.3741v1", 
    "arxiv-id": "1212.3741v1"
},{
    "category": "cs.GT", 
    "author": "Jason D. Hartline", 
    "title": "Prior-free Auctions for Budgeted Agents", 
    "publish": "2012-12-23T06:36:49Z", 
    "summary": "We consider prior-free auctions for revenue and welfare maximization when\nagents have a common budget. The abstract environments we consider are ones\nwhere there is a downward-closed and symmetric feasibility constraint on the\nprobabilities of service of the agents. These environments include position\nauctions where slots with decreasing click-through rates are auctioned to\nadvertisers. We generalize and characterize the envy-free benchmark from\nHartline and Yan (2011) to settings with budgets and characterize the optimal\nenvy-free outcomes for both welfare and revenue. We give prior-free mechanisms\nthat approximate these benchmarks. A building block in our mechanism is a\nclinching auction for position auction environments. This auction is a\ngeneralization of the multi-unit clinching auction of Dobzinski et al. (2008)\nand a special case of the polyhedral clinching auction of Goel et al. (2012).\nFor welfare maximization, we show that this clinching auction is a good\napproximation to the envy-free optimal welfare for position auction\nenvironments. For profit maximization, we generalize the random sampling profit\nextraction auction from Fiat et al. (2002) for digital goods to give a\n10.0-approximation to the envy-free optimal revenue in symmetric,\ndownward-closed environments. The profit maximization question is of interest\neven without budgets and our mechanism is a 7.5-approximation which improving\non the 30.4 bound of Ha and Hartline (2012).", 
    "link": "http://arxiv.org/pdf/1212.5766v1", 
    "arxiv-id": "1212.5766v1"
},{
    "category": "cs.GT", 
    "author": "Arno Pauly", 
    "title": "Efficient Decomposition of Bimatrix Games", 
    "publish": "2012-12-27T11:57:24Z", 
    "summary": "Exploiting the algebraic structure of the set of bimatrix games, a\ndivide-and-conquer algorithm for finding Nash equilibria is proposed. The\nalgorithm is fixed-parameter tractable with the size of the largest irreducible\ncomponent of a game as parameter. An implementation of the algorithm is shown\nto yield a significant performance increase on inputs with small parameters.", 
    "link": "http://arxiv.org/pdf/1212.6355v1", 
    "arxiv-id": "1212.6355v1"
},{
    "category": "cs.GT", 
    "author": "Oscar C. V\u00e1squez", 
    "title": "Energy in computing systems with speed scaling: optimization and   mechanisms design", 
    "publish": "2012-12-27T14:11:28Z", 
    "summary": "We study a simple scheduling game for the speed scaling model. Players want\ntheir job to complete early, which however generates a big energy consumption.\nWe address the game from the mechanism design side, and by charging the energy\nusage to the players we seek for a good compromize between quality of service\nand energy usage.", 
    "link": "http://arxiv.org/pdf/1212.6375v1", 
    "arxiv-id": "1212.6375v1"
},{
    "category": "cs.GT", 
    "author": "Yaron Velner", 
    "title": "The Complexity of Infinitely Repeated Alternating Move Games", 
    "publish": "2012-12-29T14:14:34Z", 
    "summary": "We consider infinite duration alternating move games. These games were\npreviously studied by Roth, Balcan, Kalai and Mansour. They presented an FPTAS\nfor computing an approximated equilibrium, and conjectured that there is a\npolynomial algorithm for finding an exact equilibrium. We extend their study in\ntwo directions: (1) We show that finding an exact equilibrium, even for\ntwo-player zero-sum games, is polynomial time equivalent to finding a winning\nstrategy for a (two-player) mean-payoff game on graphs. The existence of a\npolynomial algorithm for the latter is a long standing open question in\ncomputer science. Our hardness result for two-player games suggests that\ntwo-player alternating move games are harder to solve than two-player\nsimultaneous move games, while the work of Roth et al., suggests that for\n$k\\geq 3$, $k$-player games are easier to analyze in the alternating move\nsetting. (2) We show that optimal equilibriums (with respect to the social\nwelfare metric) can be obtained by pure strategies, and we present an FPTAS for\ncomputing a pure approximated equilibrium that is $\\delta$-optimal with respect\nto the social welfare metric. This result extends the previous work by\npresenting an FPTAS that finds a much more desirable approximated equilibrium.\nWe also show that if there is a polynomial algorithm for mean-payoff games on\ngraphs, then there is a polynomial algorithm that computes an optimal exact\nequilibrium, and hence, (two-player) mean-payoff games on graphs are\ninter-reducible with $k$-player alternating move games, for any $k\\geq 2$.", 
    "link": "http://arxiv.org/pdf/1212.6632v2", 
    "arxiv-id": "1212.6632v2"
},{
    "category": "cs.GT", 
    "author": "Arkadii Slinko", 
    "title": "Nonconvergent Electoral Equilibria under Scoring Rules: Beyond Plurality", 
    "publish": "2013-01-02T01:06:26Z", 
    "summary": "We use Hotelling's spatial model of competition to investigate the\nposition-taking behaviour of political candidates under a class of electoral\nsystems known as scoring rules. In a scoring rule election, voters rank all the\ncandidates running for office, following which the candidates are assigned\npoints according to a vector of nonincreasing scores. Convergent Nash\nequilibria in which all candidates adopt the same policy were characterised by\nCox (1987). Here, we investigate nonconvergent equilibria, where candidates\nadopt divergent policies. We identify a number of classes of scoring rules\nexhibiting a range of different equilibrium properties. For some of these,\nnonconvergent equilibria do not exist. For others, nonconvergent equilibria in\nwhich candidates cluster at positions spread across the issue space are\nobserved. In particular, we prove that the class of convex rules does not have\nNash equilibria (convergent or nonconvergent) with the exception of some\nderivatives of Borda rule. Finally, we examine the special cases of four-,\nfive- and six- candidate elections. In the former two cases, we provide a\ncomplete characterisation of nonconvergent equilibria.", 
    "link": "http://arxiv.org/pdf/1301.0152v1", 
    "arxiv-id": "1301.0152v1"
},{
    "category": "cs.GT", 
    "author": "Darrell Hoy", 
    "title": "Prior-independent Auctions for Risk-averse Agents", 
    "publish": "2013-01-03T09:23:38Z", 
    "summary": "We study simple and approximately optimal auctions for agents with a\nparticular form of risk-averse preferences. We show that, for symmetric agents,\nthe optimal revenue (given a prior distribution over the agent preferences) can\nbe approximated by the first-price auction (which is prior independent), and,\nfor asymmetric agents, the optimal revenue can be approximated by an auction\nwith simple form. These results are based on two technical methods. The first\nis for upper-bounding the revenue from a risk-averse agent. The second gives a\npayment identity for mechanisms with pay-your-bid semantics.", 
    "link": "http://arxiv.org/pdf/1301.0401v1", 
    "arxiv-id": "1301.0401v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Mechanism Design with Execution Uncertainty", 
    "publish": "2012-12-12T15:58:02Z", 
    "summary": "We introduce the notion of fault tolerant mechanism design, which extends the\nstandard game theoretic framework of mechanism design to allow for uncertainty\nabout execution. Specifically, we define the problem of task allocation in\nwhich the private information of the agents is not only their costs to attempt\nthe tasks, but also their probabilities of failure. For several different\ninstances of this setting we present technical results, including positive ones\nin the form of mechanisms that are incentive compatible, individually rational\nand efficient, and negative ones in the form of impossibility theorems.", 
    "link": "http://arxiv.org/pdf/1301.0595v1", 
    "arxiv-id": "1301.0595v1"
},{
    "category": "cs.GT", 
    "author": "Ilan Newman", 
    "title": "Ascending auctions and Walrasian equilibrium", 
    "publish": "2013-01-07T11:15:56Z", 
    "summary": "We present a family of submodular valuation classes that generalizes gross\nsubstitute. We show that Walrasian equilibrium always exist for one class in\nthis family, and there is a natural ascending auction which finds it. We prove\nsome new structural properties on gross-substitute auctions which, in turn,\nshow that the known ascending auctions for this class (Gul-Stacchetti and\nAusbel) are, in fact, identical. We generalize these two auctions, and provide\na simple proof that they terminate in a Walrasian equilibrium.", 
    "link": "http://arxiv.org/pdf/1301.1153v3", 
    "arxiv-id": "1301.1153v3"
},{
    "category": "cs.GT", 
    "author": "Shaun White", 
    "title": "Is it ever safe to vote strategically?", 
    "publish": "2013-01-08T06:05:29Z", 
    "summary": "There are many situations in which mis-coordinated strategic voting can leave\nstrategic voters worse off than they would have been had they not tried to\nstrategize. We analyse the simplest of such scenarios, in which the set of\nstrategic voters all have the same sincere preferences and all cast the same\nstrategic vote, while all other voters vote sincerely. Most mis-coordinations\nin this framework can be classified as instances of either strategic\novershooting (too many voted strategically) or strategic undershooting (too\nfew). If mis-coordination can result in strategic voters ending up worse off\nthan they would have been had they all just voted sincerely, we call the\nrelevant strategic vote unsafe. We show that under every onto and\nnon-dictatorial social choice rule there exist circumstances where a voter has\nan incentive to cast a safe strategic vote. We extend the Gibbard-Satterthwaite\nTheorem by proving that every onto and non-dictatorial social choice rule can\nbe individually manipulated by a voter casting a safe strategic vote.", 
    "link": "http://arxiv.org/pdf/1301.1420v1", 
    "arxiv-id": "1301.1420v1"
},{
    "category": "cs.GT", 
    "author": "Toramatsu Shintani", 
    "title": "A Dynamic Programming Model for Determining Bidding Strategies in   Sequential Auctions: Quasi-linear Utility and Budget Constraints", 
    "publish": "2013-01-10T16:24:02Z", 
    "summary": "In this paper, we develop a new method for finding an optimal biddingstrategy\nin sequential auctions, using a dynamic programming technique. Theexisting\nmethod assumes that the utility of a user is represented in anadditive form.\nThus, the remaining endowment of money must be explicitlyrepresented in each\nstate, and the calculation of the optimal biddingstrategy becomes\ntime-consuming when the initial endowment of money mbecomes large.In this\npaper, we develop a new problem formalization that avoids\nexplicitlyrepresenting the remaining endowment, by assuming the utility of a\nuser canbe represented in a quasi-linear form, and representing the payment as\nastate-transition cost. Experimental evaluations show that we can obtainmore\nthan an m-fold speed-up in the computation time. Furthermore, we havedeveloped\na method for obtaining a semi-optimal bidding strategy underbudget constraints,\nand have experimentally confirmed the efficacy of thismethod.", 
    "link": "http://arxiv.org/pdf/1301.2276v1", 
    "arxiv-id": "1301.2276v1"
},{
    "category": "cs.GT", 
    "author": "Nathana\u00ebl Fijalkow", 
    "title": "Infinite-state games with finitary conditions", 
    "publish": "2013-01-12T07:54:15Z", 
    "summary": "We study two-player zero-sum games over infinite-state graphs with\nboundedness conditions. Our first contribution is about the strategy\ncomplexity, i.e the memory required for winning strategies: we prove that over\ngeneral infinite-state graphs, memoryless strategies are sufficient for\nfinitary B\\\"uchi games, and finite-memory suffices for finitary parity games.\nWe then study pushdown boundedness games, with two contributions. First we\nprove a collapse result for pushdown omega B games, implying the decidability\nof solving these games. Second we consider pushdown games with finitary parity\nalong with stack boundedness conditions, and show that solving these games is\nEXPTIME-complete.", 
    "link": "http://arxiv.org/pdf/1301.2661v2", 
    "arxiv-id": "1301.2661v2"
},{
    "category": "cs.GT", 
    "author": "Vianney Perchet", 
    "title": "Nash equilibria with partial monitoring; Computation and Lemke-Howson   algorithm", 
    "publish": "2013-01-12T07:55:05Z", 
    "summary": "In two player bi-matrix games with partial monitoring, actions played are not\nobserved, only some messages are received. Those games satisfy a crucial\nproperty of usual bi-matrix games: there are only a finite number of required\n(mixed) best replies. This is very helpful while investigating sets of Nash\nequilibria: for instance, in some cases, it allows to relate it to the set of\nequilibria of some auxiliary game with full monitoring. In the general case,\nthe Lemke-Howson algorithm is extended and, under some genericity assumption,\nits output are Nash equilibria of the original game. As a by product, we obtain\nan oddness property on their number.", 
    "link": "http://arxiv.org/pdf/1301.2662v1", 
    "arxiv-id": "1301.2662v1"
},{
    "category": "cs.GT", 
    "author": "Vianney Perchet", 
    "title": "Approachability, Regret and Calibration; implications and equivalences", 
    "publish": "2013-01-12T07:56:02Z", 
    "summary": "Blackwell approachability, regret minimization and calibration are three\ncriteria evaluating a strategy (or an algorithm) in different sequential\ndecision problems, or repeated games between a player and Nature. Although they\nhave at first sight nothing in common, links between have been discovered: both\nconsistent and calibrated strategies can be constructed by following, in some\nauxiliary game, an approachability strategy. We gathered famous or recent\nresults and provide new ones in order to develop and generalize Blackwell's\nelegant theory. The final goal is to show how it can be used as a basic\npowerful tool to exhibit a new class of intuitive algorithms, based on simple\ngeometric properties. In order to be complete, we also prove that\napproachability can be seen as a byproduct of the very existence of consistent\nor calibrated strategies.", 
    "link": "http://arxiv.org/pdf/1301.2663v1", 
    "arxiv-id": "1301.2663v1"
},{
    "category": "cs.GT", 
    "author": "Yishay Mansour", 
    "title": "Nash Convergence of Gradient Dynamics in Iterated General-Sum Games", 
    "publish": "2013-01-16T15:52:37Z", 
    "summary": "Multi-agent games are becoming an increasing prevalent formalism for the\nstudy of electronic commerce and auctions. The speed at which transactions can\ntake place and the growing complexity of electronic marketplaces makes the\nstudy of computationally simple agents an appealing direction. In this work, we\nanalyze the behavior of agents that incrementally adapt their strategy through\ngradient ascent on expected payoff, in the simple setting of two-player,\ntwo-action, iterated general-sum games, and present a surprising result. We\nshow that either the agents will converge to Nash equilibrium, or if the\nstrategies themselves do not converge, then their average payoffs will\nnevertheless converge to the payoffs of a Nash equilibrium.", 
    "link": "http://arxiv.org/pdf/1301.3892v1", 
    "arxiv-id": "1301.3892v1"
},{
    "category": "cs.GT", 
    "author": "Manish Purohit", 
    "title": "Improved algorithms and analysis for the laminar matroid secretary   problem", 
    "publish": "2013-01-21T18:51:55Z", 
    "summary": "In a matroid secretary problem, one is presented with a sequence of objects\nof various weights in a random order, and must choose irrevocably to accept or\nreject each item. There is a further constraint that the set of items selected\nmust form an independent set of an associated matroid. Constant-competitive\nalgorithms (algorithms whose expected solution weight is within a constant\nfactor of the optimal) are known for many types of matroid secretary problems.\nWe examine the laminar matroid and show an algorithm achieving provably 0.053\ncompetitive ratio.", 
    "link": "http://arxiv.org/pdf/1301.4958v1", 
    "arxiv-id": "1301.4958v1"
},{
    "category": "cs.GT", 
    "author": "Arpita Ghosh", 
    "title": "Crowdsourced Judgement Elicitation with Endogenous Proficiency", 
    "publish": "2013-03-04T19:10:12Z", 
    "summary": "Crowdsourcing is now widely used to replace judgement by an expert authority\nwith an aggregate evaluation from a number of non-experts, in applications\nranging from rating and categorizing online content to evaluation of student\nassignments in massively open online courses via peer grading. A key issue in\nthese settings, where direct monitoring is infeasible, is incentivizing agents\nin the `crowd' to put in effort to make good evaluations, as well as to\ntruthfully report their evaluations. This leads to a new family of information\nelicitation problems with unobservable ground truth, where an agent's\nproficiency- the probability with which she correctly evaluates the underlying\nground truth- is endogenously determined by her strategic choice of how much\neffort to put into the task.\n  Our main contribution is a simple, new, mechanism for binary information\nelicitation for multiple tasks when agents have endogenous proficiencies, with\nthe following properties: (i) Exerting maximum effort followed by truthful\nreporting of observations is a Nash equilibrium. (ii) This is the equilibrium\nwith maximum payoff to all agents, even when agents have different maximum\nproficiencies, can use mixed strategies, and can choose a different strategy\nfor each of their tasks. Our information elicitation mechanism requires only\nminimal bounds on the priors, asks agents to only report their own evaluations,\nand does not require any conditions on a diverging number of agent reports per\ntask to achieve its incentive properties. The main idea behind our mechanism is\nto use the presence of multiple tasks and ratings to identify and penalize\nlow-effort agreement: the mechanism rewards agents for agreeing with a\n`reference' rater on a task but also penalizes for blind agreement by\nsubtracting out a statistic term designed so that agents obtain reward only\nwhen they put effort into their observations.", 
    "link": "http://arxiv.org/pdf/1303.0799v1", 
    "arxiv-id": "1303.0799v1"
},{
    "category": "cs.GT", 
    "author": "Bruno Salcedo", 
    "title": "Implementation without commitment in moral hazard environments", 
    "publish": "2013-03-05T03:09:06Z", 
    "summary": "Interdependent-choice equilibrium is defined as an extension of correlated\nequilibrium in which the mediator is able to choose the timing of her signals,\nand observe the actions taken by the players. The set of interdependent-choice\nequilibria is a nonempty, closed and convex polytope. It characterizes all the\noutcomes that can be implemented in single shot interactions without\nrepetition, side payments, binding contracts or any other form of delegation.", 
    "link": "http://arxiv.org/pdf/1303.0916v2", 
    "arxiv-id": "1303.0916v2"
},{
    "category": "cs.GT", 
    "author": "Raissa M. D'Souza", 
    "title": "Inequality and Network Formation Games", 
    "publish": "2013-03-06T19:40:30Z", 
    "summary": "This paper addresses the matter of inequality in network formation games. We\nemploy a quantity that we are calling the Nash Inequality Ratio (NIR), defined\nas the maximal ratio between the highest and lowest costs incurred to\nindividual agents in a Nash equilibrium strategy, to characterize the extent to\nwhich inequality is possible in equilibrium. We give tight upper bounds on the\nNIR for the network formation games of Fabrikant et al. (PODC '03) and Ehsani\net al. (SPAA '11). With respect to the relationship between equality and social\nefficiency, we show that, contrary to common expectations, efficiency does not\nnecessarily come at the expense of increased inequality.", 
    "link": "http://arxiv.org/pdf/1303.1434v2", 
    "arxiv-id": "1303.1434v2"
},{
    "category": "cs.GT", 
    "author": "Orestis Telelis", 
    "title": "On the Inefficiency of Standard Multi-Unit Auctions", 
    "publish": "2013-03-07T10:51:14Z", 
    "summary": "We study two standard multi-unit auction formats for allocating multiple\nunits of a single good to multi-demand bidders. The first one is the\nDiscriminatory Auction, which charges every winner his winning bids. The second\nis the Uniform Price Auction, which determines a uniform price to be paid per\nunit. Variants of both formats find applications ranging from the allocation of\nstate bonds to investors, to online sales over the internet, facilitated by\npopular online brokers. For these formats, we consider two bidding interfaces:\n(i) standard bidding, which is most prevalent in the scientific literature, and\n(ii) uniform bidding, which is more popular in practice. In this work, we\nevaluate the economic inefficiency of both multi-unit auction formats for both\nbidding interfaces, by means of upper and lower bounds on the Price of Anarchy\nfor pure Nash equilibria and mixed Bayes-Nash equilibria. Our developments\nimprove significantly upon bounds that have been obtained recently in\n[Markakis, Telelis, ToCS 2014] and [Syrgkanis, Tardos, STOC 2013] for\nsubmodular valuation functions. Moreover, we consider for the first time\nbidders with subadditive valuation functions for these auction formats. Our\nresults signify that these auctions are nearly efficient, which provides\nfurther justification for their use in practice.", 
    "link": "http://arxiv.org/pdf/1303.1646v3", 
    "arxiv-id": "1303.1646v3"
},{
    "category": "cs.GT", 
    "author": "Emmanouil Pountourakis", 
    "title": "Socially stable matchings in the Hospitals / Residents problem", 
    "publish": "2013-03-08T16:18:55Z", 
    "summary": "In the Hospitals/Residents (HR) problem, agents are partitioned into\nhospitals and residents. Each agent wishes to be matched to an agent in the\nother set and has a strict preference over these potential matches. A matching\nis stable if there are no blocking pairs, i.e., no pair of agents that prefer\neach other to their assigned matches. Such a situation is undesirable as it\ncould lead to a deviation in which the blocking pair form a private arrangement\noutside the matching. This however assumes that the blocking pair have social\nties or communication channels to facilitate the deviation. Relaxing the\nstability definition to take account of the potential lack of social ties\nbetween agents can yield larger stable matchings.\n  In this paper, we define the Hospitals/Residents problem under Social\nStability (HRSS) which takes into account social ties between agents by\nintroducing a social network graph to the HR problem. Edges in the social\nnetwork graph correspond to resident-hospital pairs in the HR instance that\nknow one another. Pairs that do not have corresponding edges in the social\nnetwork graph can belong to a matching M but they can never block M. Relative\nto a relaxed stability definition for HRSS, called social stability, we show\nthat socially stable matchings can have different sizes and the problem of\nfinding a maximum socially stable matching is NP-hard, though approximable\nwithin 3/2. Furthermore we give polynomial time algorithms for three special\ncases of the problem.", 
    "link": "http://arxiv.org/pdf/1303.2041v3", 
    "arxiv-id": "1303.2041v3"
},{
    "category": "cs.GT", 
    "author": "Sven Seuken", 
    "title": "Hybrid Mechanisms: Trading off Strategyproofness and Efficiency of   Random Assignment Mechanisms", 
    "publish": "2013-03-11T15:56:58Z", 
    "summary": "Severe impossibility results restrict the design of strategyproof random\nassignment mechanisms, and trade-offs are necessary when aiming for more\ndemanding efficiency requirements, such as ordinal or rank efficiency. We\nintroduce hybrid mechanisms, which are convex combinations of two component\nmechanisms. We give a set of conditions under which such hybrids facilitate a\nnon-degenerate trade-off between strategyproofness (in terms of partial\nstrategyproofness) and efficiency (in terms of dominance). This set of\nconditions is tight in the sense that trade-offs may become degenerate if any\nof the conditions are dropped. Moreover, we give an algorithm for the mechanism\ndesigner's problem of determining a maximal mixing factor. Finally, we prove\nthat our construction can be applied to mix Random Serial Dictatorship with\nProbabilistic Serial, as well as with the adaptive Boston mechanism, and we\nillustrate the efficiency gains numerically.", 
    "link": "http://arxiv.org/pdf/1303.2558v5", 
    "arxiv-id": "1303.2558v5"
},{
    "category": "cs.GT", 
    "author": "Eitan Altman", 
    "title": "Network Non-Neutrality through Preferential Signaling", 
    "publish": "2013-03-18T10:24:07Z", 
    "summary": "One of the central issues in the debate on network neutrality has been\nwhether one should allow or prevent preferential treatment by an internet\nservice provider (ISP) of traffic according to its origin. This raised the\nquestion of whether to allow an ISP to have exclusive agreement with a content\nprovider (CP). In this paper we consider discrimination in the opposite\ndirection. We study the impact that a CP can have on the benefits of several\ncompeting ISPs by sharing private information concerning the demand for its\ncontent. More precisely, we consider ISPs that compete over access to one\ncommon CP. Each ISP selects the price that it charges its subscribers for\naccessing the content. The CP is assumed to have private information about\ndemand for its content, and in particular, about the inverse demand function\ncorresponding to the content. The competing ISPs are assumed to have knowledge\non only the statistical distribution of these functions. We derive in this\npaper models for studying the impact that the CP can have on the utilities of\nthe ISPs by favoring one of them by exclusively revealing its private\ninformation. We also consider the case where CP can charge ISPs for providing\nsuch information. We propose two mechanisms based on {\\em weighted proportional\nfairness} for payment between ISPs and CP. Finally, we compare the social\nutility resulting from these mechanisms with the optimal social utility by\nintroducing a performance metric termed as {\\em price of partial bargaining}", 
    "link": "http://arxiv.org/pdf/1303.4199v1", 
    "arxiv-id": "1303.4199v1"
},{
    "category": "cs.GT", 
    "author": "Aravind Srinivasan", 
    "title": "On Random Sampling Auctions for Digital Goods", 
    "publish": "2013-03-18T21:52:31Z", 
    "summary": "In the context of auctions for digital goods, an interesting random sampling\nauction has been proposed by Goldberg, Hartline, and Wright [2001]. This\nauction has been analyzed by Feige, Flaxman, Hartline, and Kleinberg [2005],\nwho have shown that it is 15-competitive in the worst case {which is\nsubstantially better than the previously proven constant bounds but still far\nfrom the conjectured competitive ratio of 4. In this paper, we prove that the\naforementioned random sampling auction is indeed 4-competitive for a large\nclass of instances where the number of bids above (or equal to) the optimal\nsale price is at least 6. We also show that it is 4:68-competitive for the\nsmall class of remaining instances thus leaving a negligible gap between the\nlower and upper bound. We employ a mix of probabilistic techniques and dynamic\nprogramming to compute these bounds.", 
    "link": "http://arxiv.org/pdf/1303.4438v1", 
    "arxiv-id": "1303.4438v1"
},{
    "category": "cs.GT", 
    "author": "Michael Bowling", 
    "title": "Solving Imperfect Information Games Using Decomposition", 
    "publish": "2013-03-18T22:00:22Z", 
    "summary": "Decomposition, i.e. independently analyzing possible subgames, has proven to\nbe an essential principle for effective decision-making in perfect information\ngames. However, in imperfect information games, decomposition has proven to be\nproblematic. To date, all proposed techniques for decomposition in imperfect\ninformation games have abandoned theoretical guarantees. This work presents the\nfirst technique for decomposing an imperfect information game into subgames\nthat can be solved independently, while retaining optimality guarantees on the\nfull-game solution. We can use this technique to construct theoretically\njustified algorithms that make better use of information available at run-time,\novercome memory or disk limitations at run-time, or make a time/space trade-off\nto overcome memory or disk limitations while solving a game. In particular, we\npresent an algorithm for subgame solving which guarantees performance in the\nwhole game, in contrast to existing methods which may have unbounded error. In\naddition, we present an offline game solving algorithm, CFR-D, which can\nproduce a Nash equilibrium for a game that is larger than available storage.", 
    "link": "http://arxiv.org/pdf/1303.4441v4", 
    "arxiv-id": "1303.4441v4"
},{
    "category": "cs.GT", 
    "author": "Wenyi Zhang", 
    "title": "Competition Between Wireless Service Providers: Pricing, Equilibrium and   Efficiency", 
    "publish": "2013-04-03T09:54:01Z", 
    "summary": "As the communication network is in transition towards a commercial one\ncontrolled by service providers (SP), the present paper considers a pricing\ngame in a communication market covered by several wireless access points\nsharing the same spectrum and analyzes two business models: monopoly (APs\ncontrolled by one SP) and oligopoly (APs controlled by different SPs). We use a\nStackelberg game to model the problem: SPs are the leader(s) and end users are\nthe followers. We prove, under certain conditions, the existence and uniqueness\nof Nash equilibrium for both models and derive their expressions. In order to\ncompare the impact of different business models on social welfare and SPs'\nprofits, we define two metrics: PoCS (price of competition on social welfare)\nand PoCP (price of competition on profits). For symmetric cross-AP\ninterferences, the tight lower bound of PoCS is 3/4, and that of PoCP is 1.", 
    "link": "http://arxiv.org/pdf/1304.0892v1", 
    "arxiv-id": "1304.0892v1"
},{
    "category": "cs.GT", 
    "author": "H. Vincent Poor", 
    "title": "Prioritizing Consumers in Smart Grid: Energy Management Using Game   Theory", 
    "publish": "2013-03-04T23:41:10Z", 
    "summary": "This paper explores an idea of demand-supply balance for smart grids in which\nconsumers are expected to play a significant role. The main objective is to\nmotivate the consumer, by maximizing their benefit both as a seller and a\nbuyer, to trade their surplus energy with the grid so as to balance the demand\nat the peak hour. To that end, a Stackelberg game is proposed to capture the\ninteractions between the grid and consumers, and it is shown analytically that\noptimal energy trading parameters that maximize customers utilities are\nobtained at the solution of the game. A novel distributed algorithm is proposed\nto reach the optimal solution of the game, and numerical examples are used to\nassess the properties and effectiveness of the proposed approach.", 
    "link": "http://arxiv.org/pdf/1304.0992v1", 
    "arxiv-id": "1304.0992v1"
},{
    "category": "cs.GT", 
    "author": "Tuomas Sandholm", 
    "title": "On the complexity of strong Nash equilibrium: Hard-to-solve instances   and smoothed complexity", 
    "publish": "2013-04-04T12:45:09Z", 
    "summary": "The computational characterization of game-theoretic solution concepts is a\ncentral topic in artificial intelligence, with the aim of developing\ncomputationally efficient tools for finding optimal ways to behave in strategic\ninteractions. The central solution concept in game theory is Nash equilibrium\n(NE). However, it fails to capture the possibility that agents can form\ncoalitions (even in the 2-agent case). Strong Nash equilibrium (SNE) refines NE\nto this setting. It is known that finding an SNE is NP-complete when the number\nof agents is constant. This hardness is solely due to the existence of\nmixed-strategy SNEs, given that the problem of enumerating all pure-strategy\nSNEs is trivially in P. Our central result is that, in order for a game to have\nat least one non-pure-strategy SNE, the agents' payoffs restricted to the\nagents' supports must, in the case of 2 agents, lie on the same line, and, in\nthe case of n agents, lie on an (n - 1)-dimensional hyperplane. Leveraging this\nresult, we provide two contributions. First, we develop worst-case instances\nfor support-enumeration algorithms. These instances have only one SNE and the\nsupport size can be chosen to be of any size-in particular, arbitrarily large.\nSecond, we prove that, unlike NE, finding an SNE is in smoothed polynomial\ntime: generic game instances (i.e., all instances except knife-edge cases) have\nonly pure-strategy SNEs.", 
    "link": "http://arxiv.org/pdf/1304.1351v1", 
    "arxiv-id": "1304.1351v1"
},{
    "category": "cs.GT", 
    "author": "Marcello Restelli", 
    "title": "Efficient evolutionary dynamics with extensive-form games", 
    "publish": "2013-04-04T18:16:57Z", 
    "summary": "Evolutionary game theory combines game theory and dynamical systems and is\ncustomarily adopted to describe evolutionary dynamics in multi-agent systems.\nIn particular, it has been proven to be a successful tool to describe\nmulti-agent learning dynamics. To the best of our knowledge, we provide in this\npaper the first replicator dynamics applicable to the sequence form of an\nextensive-form game, allowing an exponential reduction of time and space w.r.t.\nthe currently adopted replicator dynamics for normal form. Furthermore, our\nreplicator dynamics is realization equivalent to the standard replicator\ndynamics for normal form. We prove our results for both discrete-time and\ncontinuous-time cases. Finally, we extend standard tools to study the stability\nof a strategy profile to our replicator dynamics.", 
    "link": "http://arxiv.org/pdf/1304.1456v1", 
    "arxiv-id": "1304.1456v1"
},{
    "category": "cs.GT", 
    "author": "Mathieu Sassolas", 
    "title": "The Complexity of Admissibility in Omega-Regular Games", 
    "publish": "2013-04-05T11:23:42Z", 
    "summary": "Iterated admissibility is a well-known and important concept in classical\ngame theory, e.g. to determine rational behaviors in multi-player matrix games.\nAs recently shown by Berwanger, this concept can be soundly extended to\ninfinite games played on graphs with omega-regular objectives. In this paper,\nwe study the algorithmic properties of this concept for such games. We settle\nthe exact complexity of natural decision problems on the set of strategies that\nsurvive iterated elimination of dominated strategies. As a byproduct of our\nconstruction, we obtain automata which recognize all the possible outcomes of\nsuch strategies.", 
    "link": "http://arxiv.org/pdf/1304.1682v3", 
    "arxiv-id": "1304.1682v3"
},{
    "category": "cs.GT", 
    "author": "Rasmus Ibsen-Jensen", 
    "title": "The complexity of interior point methods for solving discounted   turn-based stochastic games", 
    "publish": "2013-04-06T13:13:14Z", 
    "summary": "We study the problem of solving discounted, two player, turn based,\nstochastic games (2TBSGs). Jurdzinski and Savani showed that 2TBSGs with\ndeterministic transitions can be reduced to solving $P$-matrix linear\ncomplementarity problems (LCPs). We show that the same reduction works for\ngeneral 2TBSGs. This implies that a number of interior point methods for\nsolving $P$-matrix LCPs can be used to solve 2TBSGs. We consider two such\nalgorithms. First, we consider the unified interior point method of Kojima,\nMegiddo, Noma, and Yoshise, which runs in time $O((1+\\kappa)n^{3.5}L)$, where\n$\\kappa$ is a parameter that depends on the $n \\times n$ matrix $M$ defining\nthe LCP, and $L$ is the number of bits in the representation of $M$. Second, we\nconsider the interior point potential reduction algorithm of Kojima, Megiddo,\nand Ye, which runs in time $O(\\frac{-\\delta}{\\theta}n^4\\log \\epsilon^{-1})$,\nwhere $\\delta$ and $\\theta$ are parameters that depend on $M$, and $\\epsilon$\ndescribes the quality of the solution. For 2TBSGs with $n$ states and discount\nfactor $\\gamma$ we prove that in the worst case $\\kappa =\n\\Theta(n/(1-\\gamma)^2)$, $-\\delta = \\Theta(\\sqrt{n}/(1-\\gamma))$, and $1/\\theta\n= \\Theta(n/(1-\\gamma)^2)$. The lower bounds for $\\kappa$, $-\\delta$, and\n$1/\\theta$ are obtained using the same family of deterministic games.", 
    "link": "http://arxiv.org/pdf/1304.1888v2", 
    "arxiv-id": "1304.1888v2"
},{
    "category": "cs.GT", 
    "author": "Paolo Turrini", 
    "title": "Two-player preplay negotiation games with conditional offers", 
    "publish": "2013-04-08T10:45:51Z", 
    "summary": "We consider an extension of strategic normal form games with a phase before\nthe actual play of the game, where players can make binding offers for transfer\nof utilities to other players after the play of the game, contingent on the\nrecipient playing the strategy indicated in the offer. Such offers transform\nthe payoff matrix of the original game but preserve its non-cooperative nature.\nThe type of offers we focus on here are conditional on a suggested 'matching\noffer' of the same kind made in return by the receiver. Players can exchange a\nseries of such offers, thus engaging in a bargaining process before a strategic\nnormal form game is played.\n  In this paper we study and analyze solution concepts for two-player normal\nform games with such preplay negotiation phase, under several assumptions for\nthe bargaining power of the players, such as the possibility of withdrawing\npreviously made offers and opting out from the negotiation process, as well as\nthe value of time for the players in such negotiations. We obtain results\ndescribing the possible solutions of such bargaining games and analyze the\ndegrees of efficiency and fairness that can be achieved in such negotiation\nprocess.", 
    "link": "http://arxiv.org/pdf/1304.2161v2", 
    "arxiv-id": "1304.2161v2"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "Combinatorial Walrasian Equilibrium", 
    "publish": "2013-04-08T15:49:19Z", 
    "summary": "We study a combinatorial market design problem, where a collection of\nindivisible objects is to be priced and sold to potential buyers subject to\nequilibrium constraints.The classic solution concept for such problems is\nWalrasian Equilibrium (WE), which provides a simple and transparent pricing\nstructure that achieves optimal social welfare. The main weakness of the WE\nnotion is that it exists only in very restrictive cases. To overcome this\nlimitation, we introduce the notion of a Combinatorial Walrasian equilibium\n(CWE), a natural relaxation of WE. The difference between a CWE and a\n(non-combinatorial) WE is that the seller can package the items into\nindivisible bundles prior to sale, and the market does not necessarily clear.\n  We show that every valuation profile admits a CWE that obtains at least half\nof the optimal (unconstrained) social welfare. Moreover, we devise a poly-time\nalgorithm that, given an arbitrary allocation X, computes a CWE that achieves\nat least half of the welfare of X. Thus, the economic problem of finding a CWE\nwith high social welfare reduces to the algorithmic problem of social-welfare\napproximation. In addition, we show that every valuation profile admits a CWE\nthat extracts a logarithmic fraction of the optimal welfare as revenue.\nFinally, these results are complemented by strong lower bounds when the seller\nis restricted to using item prices only, which motivates the use of bundles.\nThe strength of our results derives partly from their generality - our results\nhold for arbitrary valuations that may exhibit complex combinations of\nsubstitutes and complements.", 
    "link": "http://arxiv.org/pdf/1304.2244v1", 
    "arxiv-id": "1304.2244v1"
},{
    "category": "cs.GT", 
    "author": "Seong-Lyun Kim", 
    "title": "Game-theoretic Understanding of Price Dynamics in Mobile Communication   Services", 
    "publish": "2013-04-14T03:36:34Z", 
    "summary": "In the mobile communication services, users wish to subscribe to high quality\nservice with a low price level, which leads to competition between mobile\nnetwork operators (MNOs). The MNOs compete with each other by service prices\nafter deciding the extent of investment to improve quality of service (QoS).\nUnfortunately, the theoretic backgrounds of price dynamics are not known to us,\nand as a result, effective network planning and regulative actions are hard to\nmake in the competitive market. To explain this competition more detail, we\nformulate and solve an optimization problem applying the two-stage Cournot and\nBertrand competition model. Consequently, we derive a price dynamics that the\nMNOs increase and decrease their service prices periodically, which completely\nexplains the subsidy dynamics in the real world. Moving forward, to avoid this\ninstability and inefficiency, we suggest a simple regulation rule which leads\nto a Pareto-optimal equilibrium point. Moreover, we suggest regulator's optimal\nactions corresponding to user welfare and the regulator's revenue.", 
    "link": "http://arxiv.org/pdf/1304.3875v3", 
    "arxiv-id": "1304.3875v3"
},{
    "category": "cs.GT", 
    "author": "Jiong Guo", 
    "title": "Complexity of Control Behaviors in k-Peaked Elections for a Variant of   Approval Voting", 
    "publish": "2013-04-16T14:41:44Z", 
    "summary": "Single-peaked elections have been attracting much attention recently. It\nturned out that many NP-hard voting problems become polynomial-time solvable\nwhen restricted to single-peaked elections. A natural generalization of the\nsingle-peaked elections is the k-peaked elections, where at most k peaks are\nallowed in each vote in the election. In this paper, we mainly aim at\nestablishing a complexity dichotomy of controlling behaviors of a variant of\nthe sincere-strategy preference-based approval voting in k-peaked elections for\ndifferent values of k. It turns out that most NP-hardness results in the\ngeneral case also hold in k-peaked elections, even for k=2,3. On the other\nhand, we derive polynomial-time algorithms for certain sincere-strategy\npreference-based approval voting control problems for k=2. In addition, we also\nstudy the sincere-strategy preference-based approval control problems from the\nviewpoint of parameterized complexity and prove some FPT and W-hardness\nresults.", 
    "link": "http://arxiv.org/pdf/1304.4471v3", 
    "arxiv-id": "1304.4471v3"
},{
    "category": "cs.GT", 
    "author": "Sanjiv Kapoor", 
    "title": "Auction Algorithm for Production Models", 
    "publish": "2013-04-16T20:47:36Z", 
    "summary": "We show an auction-based algorithm to compute market equilibrium prices in a\nproduction model, where consumers purchase items under separable nonlinear\nutility concave functions which satisfy W.G.S(Weak Gross Substitutes);\nproducers produce items with multiple linear production constraints. Our\nalgorithm differs from previous approaches in that the prices are allowed to\nboth increase and decrease to handle changes in the production. This provides a\nt^atonnement style algorithm which converges and provides a PTAS. The algorithm\ncan also be extended to arbitrary convex production regions and the\nArrow-Debreu model. The convergence is dependent on the behavior of the\nmarginal utility of the concave function.", 
    "link": "http://arxiv.org/pdf/1304.4618v1", 
    "arxiv-id": "1304.4618v1"
},{
    "category": "cs.GT", 
    "author": "Tom Wexler", 
    "title": "Assignment Games with Conflicts: Price of Total Anarchy and Convergence   Results via Semi-Smoothness", 
    "publish": "2013-04-18T14:32:12Z", 
    "summary": "We study assignment games in which jobs select machines, and in which certain\npairs of jobs may conflict, which is to say they may incur an additional cost\nwhen they are both assigned to the same machine, beyond that associated with\nthe increase in load. Questions regarding such interactions apply beyond\nallocating jobs to machines: when people in a social network choose to align\nthemselves with a group or party, they typically do so based upon not only the\ninherent quality of that group, but also who amongst their friends (or enemies)\nchoose that group as well. We show how semi-smoothness, a recently introduced\ngeneralization of smoothness, is necessary to find tight or near-tight bounds\non the price of total anarchy, and thus on the quality of correlated and Nash\nequilibria, for several natural job-assignment games with interacting jobs. For\nmost cases, our bounds on the price of total anarchy are either exactly 2 or\napproach 2. We also prove new convergence results implied by semi-smoothness\nfor our games. Finally we consider coalitional deviations, and prove results\nabout the existence and quality of Strong equilibrium.", 
    "link": "http://arxiv.org/pdf/1304.5149v2", 
    "arxiv-id": "1304.5149v2"
},{
    "category": "cs.GT", 
    "author": "Mark H. M. Winands", 
    "title": "Monte Carlo *-Minimax Search", 
    "publish": "2013-04-22T19:00:13Z", 
    "summary": "This paper introduces Monte Carlo *-Minimax Search (MCMS), a Monte Carlo\nsearch algorithm for turned-based, stochastic, two-player, zero-sum games of\nperfect information. The algorithm is designed for the class of of densely\nstochastic games; that is, games where one would rarely expect to sample the\nsame successor state multiple times at any particular chance node. Our approach\ncombines sparse sampling techniques from MDP planning with classic pruning\ntechniques developed for adversarial expectimax planning. We compare and\ncontrast our algorithm to the traditional *-Minimax approaches, as well as MCTS\nenhanced with the Double Progressive Widening, on four games: Pig, EinStein\nW\\\"urfelt Nicht!, Can't Stop, and Ra. Our results show that MCMS can be\ncompetitive with enhanced MCTS variants in some domains, while consistently\noutperforming the equivalent classic approaches given the same amount of\nthinking time.", 
    "link": "http://arxiv.org/pdf/1304.6057v1", 
    "arxiv-id": "1304.6057v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "The Menu-Size Complexity of Auctions", 
    "publish": "2013-04-22T22:02:01Z", 
    "summary": "We consider the menu size of auctions as a measure of auction complexity and\nstudy how it affects revenue. Our setting has a single revenue-maximizing\nseller selling two or more heterogeneous items to a single buyer whose private\nvalues for the items are drawn from a (possibly correlated) known distribution,\nand whose valuation is additive over the items. We show that the revenue may\nincrease arbitrarily with menu size and that a bounded menu size can not ensure\nany positive fraction of the optimal revenue. The menu size turns out to \"nail\ndown\" the revenue properties of deterministic auctions: their menu size may be\nat most exponential in the number of items and indeed their revenue may be\nlarger than that achievable by the simplest types of auctions by a factor that\nis exponential in the number of items but no larger. Our model is related to a\npreviously studied \"unit-demand\" model and our results also answer an open\nproblem in that model.", 
    "link": "http://arxiv.org/pdf/1304.6116v1", 
    "arxiv-id": "1304.6116v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Bertrand Networks", 
    "publish": "2013-04-25T05:49:29Z", 
    "summary": "We study scenarios where multiple sellers of a homogeneous good compete on\nprices, where each seller can only sell to some subset of the buyers.\nCrucially, sellers cannot price-discriminate between buyers. We model the\nstructure of the competition by a graph (or hyper-graph), with nodes\nrepresenting the sellers and edges representing populations of buyers. We study\nequilibria in the game between the sellers, prove that they always exist, and\npresent various structural, quantitative, and computational results about them.\nWe also analyze the equilibria completely for a few cases. Many questions are\nleft open.", 
    "link": "http://arxiv.org/pdf/1304.6806v2", 
    "arxiv-id": "1304.6806v2"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Efficiency Guarantees in Auctions with Budgets", 
    "publish": "2013-04-26T01:29:04Z", 
    "summary": "In settings where players have a limited access to liquidity, represented in\nthe form of budget constraints, efficiency maximization has proven to be a\nchallenging goal. In particular, the social welfare cannot be approximated by a\nbetter factor then the number of players. Therefore, the literature has mainly\nresorted to Pareto-efficiency as a way to achieve efficiency in such settings.\nWhile successful in some important scenarios, in many settings it is known that\neither exactly one incentive-compatible auction that always outputs a\nPareto-efficient solution, or that no truthful mechanism can always guarantee a\nPareto-efficient outcome. Traditionally, impossibility results can be avoided\nby considering approximations. However, Pareto-efficiency is a binary property\n(is either satisfied or not), which does not allow for approximations.\n  In this paper we propose a new notion of efficiency, called \\emph{liquid\nwelfare}. This is the maximum amount of revenue an omniscient seller would be\nable to extract from a certain instance. We explain the intuition behind this\nobjective function and show that it can be 2-approximated by two different\nauctions. Moreover, we show that no truthful algorithm can guarantee an\napproximation factor better than 4/3 with respect to the liquid welfare, and\nprovide a truthful auction that attains this bound in a special case.\n  Importantly, the liquid welfare benchmark also overcomes impossibilities for\nsome settings. While it is impossible to design Pareto-efficient auctions for\nmulti-unit auctions where players have decreasing marginal values, we give a\ndeterministic $O(\\log n)$-approximation for the liquid welfare in this setting.", 
    "link": "http://arxiv.org/pdf/1304.7048v1", 
    "arxiv-id": "1304.7048v1"
},{
    "category": "cs.GT", 
    "author": "Peter Key", 
    "title": "Ranking and Tradeoffs in Sponsored Search Auctions", 
    "publish": "2013-04-29T12:29:30Z", 
    "summary": "In a sponsored search auction, decisions about how to rank ads impose\ntradeoffs between objectives such as revenue and welfare. In this paper, we\nexamine how these tradeoffs should be made. We begin by arguing that the most\nnatural solution concept to evaluate these tradeoffs is the lowest symmetric\nNash equilibrium (SNE). As part of this argument, we generalise the well known\nconnection between the lowest SNE and the VCG outcome. We then propose a new\nranking algorithm, loosely based on the revenue-optimal auction, that uses a\nreserve price to order the ads (not just to filter them) and give conditions\nunder which it raises more revenue than simply applying that reserve price.\nFinally, we conduct extensive simulations examining the tradeoffs enabled by\ndifferent ranking algorithms and show that our proposed algorithm enables\nsuperior operating points by a variety of metrics.", 
    "link": "http://arxiv.org/pdf/1304.7642v1", 
    "arxiv-id": "1304.7642v1"
},{
    "category": "cs.GT", 
    "author": "Christopher A. Wilkens", 
    "title": "A Dynamic Axiomatic Approach to First-Price Auctions", 
    "publish": "2013-04-29T17:31:27Z", 
    "summary": "The first-price auction is popular in practice for its simplicity and\ntransparency. Moreover, its potential virtues grow in complex settings where\nincentive compatible auctions may generate little or no revenue. Unfortunately,\nthe first-price auction is poorly understood in theory because equilibrium is\nnot {\\em a priori} a credible predictor of bidder behavior.\n  We take a dynamic approach to studying first-price auctions: rather than\nbasing performance guarantees solely on static equilibria, we study the\nrepeated setting and show that robust performance guarantees may be derived\nfrom simple axioms of bidder behavior. For example, as long as a loser raises\nher bid quickly, a standard first-price auction will generate at least as much\nrevenue as a second-price auction. We generalize this dynamic technique to\ncomplex pay-your-bid auction settings and show that progressively stronger\nassumptions about bidder behavior imply progressively stronger guarantees about\nthe auction's performance.\n  Along the way, we find that the auctioneer's choice of bidding language is\ncritical when generalizing beyond the single-item setting, and we propose a\nspecific construction called the {\\em utility-target auction} that performs\nwell. The utility-target auction includes a bidder's final utility as an\nadditional parameter, identifying the single dimension along which she wishes\nto compete. This auction is closely related to profit-target bidding in\nfirst-price and ascending proxy package auctions and gives strong revenue\nguarantees for a variety of complex auction environments. Of particular\ninterest, the guaranteed existence of a pure-strategy equilibrium in the\nutility-target auction shows how Overture might have eliminated the cyclic\nbehavior in their generalized first-price sponsored search auction if bidders\ncould have placed more sophisticated bids.", 
    "link": "http://arxiv.org/pdf/1304.7718v1", 
    "arxiv-id": "1304.7718v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Pricing Public Goods for Private Sale", 
    "publish": "2013-05-01T05:14:41Z", 
    "summary": "We consider the pricing problem faced by a seller who assigns a price to a\ngood that confers its benefits not only to its buyers, but also to other\nindividuals around them. For example, a snow-blower is potentially useful not\nonly to the household that buys it, but also to others on the same street.\nGiven that the seller is constrained to selling such a (locally) public good\nvia individual private sales, how should he set his prices given the\ndistribution of values held by the agents?\n  We study this problem as a two-stage game. In the first stage, the seller\nchooses and announces a price for the product. In the second stage, the agents\n(each having a private value for the good) decide simultaneously whether or not\nthey will buy the product. In the resulting game, which can exhibit a\nmultiplicity of equilibria, agents must strategize about whether they will\nthemselves purchase the good to receive its benefits.\n  In the case of a fully public good (where all agents benefit whenever any\nagent purchases), we describe a pricing mechanism that is approximately\nrevenue-optimal (up to a constant factor) when values are drawn from a regular\ndistribution. We then study settings in which the good is only \"locally\"\npublic: agents are arranged in a network and share benefits only with their\nneighbors. We describe a pricing method that approximately maximizes revenue,\nin the worst case over equilibria of agent behavior, for any $d$-regular\nnetwork. Finally, we show that approximately optimal prices can be found for\ngeneral networks in the special case that private values are drawn from a\nuniform distribution. We also discuss some barriers to extending these results\nto general networks and regular distributions.", 
    "link": "http://arxiv.org/pdf/1305.0085v1", 
    "arxiv-id": "1305.0085v1"
},{
    "category": "cs.GT", 
    "author": "Yang Yuan", 
    "title": "On the Ratio of Revenue to Welfare in Single-Parameter Mechanism Design", 
    "publish": "2013-05-02T18:54:15Z", 
    "summary": "What fraction of the potential social surplus in an environment can be\nextracted by a revenue-maximizing monopolist? We investigate this problem in\nBayesian single-parameter environments with independent private values. The\nprecise answer to the question obviously depends on the particulars of the\nenvironment: the feasibility constraint and the distributions from which the\nbidders' private values are sampled. Rather than solving the problem in\nparticular special cases, our work aims to provide universal lower bounds on\nthe revenue-to-welfare ratio that hold under the most general hypotheses that\nallow for non-trivial such bounds.\n  Our results can be summarized as follows. For general feasibility\nconstraints, the revenue-to-welfare ratio is at least a constant times the\ninverse-square-root of the number of agents, and this is tight up to constant\nfactors. For downward-closed feasibility constraints, the revenue-to-welfare\nratio is bounded below by a constant. Both results require the bidders'\ndistributions to satisfy hypotheses somewhat stronger than regularity; we show\nthat the latter result cannot avoid this requirement.", 
    "link": "http://arxiv.org/pdf/1305.0534v1", 
    "arxiv-id": "1305.0534v1"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Cost-Recovering Bayesian Algorithmic Mechanism Design", 
    "publish": "2013-05-02T23:51:41Z", 
    "summary": "We study the design of Bayesian incentive compatible mechanisms in single\nparameter domains, for the objective of optimizing social efficiency as\nmeasured by social cost. In the problems we consider, a group of participants\ncompete to receive service from a mechanism that can provide such services at a\ncost. The mechanism wishes to choose which agents to serve in order to maximize\nsocial efficiency, but is not willing to suffer an expected loss: the agents'\npayments should cover the cost of service in expectation.\n  We develop a general method for converting arbitrary approximation algorithms\nfor the underlying optimization problem into Bayesian incentive compatible\nmechanisms that are cost-recovering in expectation. In particular, we give\npolynomial time black-box reductions from the mechanism design problem to the\nproblem of designing a social cost minimization algorithm without incentive\nconstraints. Our reduction increases the expected social cost of the given\nalgorithm by a factor of O(log(min{n, h})), where n is the number of agents and\nh is the ratio between the highest and lowest nonzero valuations in the\nsupport. We also provide a lower bound illustrating that this inflation of the\nsocial cost is essential: no BIC cost-recovering mechanism can achieve an\napproximation factor better than \\Omega(log(n)) or \\Omega(log(h)) in general.\n  Our techniques extend to show that a certain class of truthful algorithms can\nbe made cost-recovering in the non-Bayesian setting, in such a way that the\napproximation factor degrades by at most O(log(min{n, h})). This is an\nimprovement over previously-known constructions with inflation factor O(log n).", 
    "link": "http://arxiv.org/pdf/1305.0598v1", 
    "arxiv-id": "1305.0598v1"
},{
    "category": "cs.GT", 
    "author": "Geoffroy Ville", 
    "title": "An Optimal Mastermind (4,7) Strategy and More Results in the Expected   Case", 
    "publish": "2013-05-05T13:23:56Z", 
    "summary": "This paper presents an optimal strategy for solving the 4 peg-7 color\nMastermind MM(4,7) in the expected case (4.676) along with optimal strategies\nor upper bounds for other values. The program developed is using a depth-first\nbranch and bound algorithm relying on tight upper bound, dynamic lower bound\nevaluation and guess equivalence to prune symmetric tree branches.", 
    "link": "http://arxiv.org/pdf/1305.1010v1", 
    "arxiv-id": "1305.1010v1"
},{
    "category": "cs.GT", 
    "author": "Thomas Kesselheim", 
    "title": "Universally Truthful Secondary Spectrum Auctions", 
    "publish": "2013-05-10T14:33:04Z", 
    "summary": "We present algorithms for implementing local spectrum redistribution in\nwireless networks using a mechanism design approach. For example, in single-hop\nrequest scheduling, secondary users are modeled as rational agents that have\nprivate utility when getting assigned a channel for successful transmission. We\npresent a rather simple algorithmic technique that allows to turn existing and\nfuture approximation algorithms and heuristics into truthful mechanisms for a\nlarge variety of networking problems. In contrast to previous work, our\napproach works for virtually all known interference models in the literature,\nincluding the physical model of interference based on SINR. It allows to\naddress single-hop and multi-hop scheduling, routing, and even more general\nassignment and allocation problems. Our mechanisms are randomized and represent\nthe first universally-truthful mechanisms for these problems with rigorous\nworst-case guarantees on the solution quality. In this way, our mechanisms can\nbe used to obtain guaranteed solution quality even with risk-averse or\nrisk-seeking bidders, for which existing approaches fail.", 
    "link": "http://arxiv.org/pdf/1305.2350v1", 
    "arxiv-id": "1305.2350v1"
},{
    "category": "cs.GT", 
    "author": "Yakov Babichenko", 
    "title": "Small Support Equilibria in Large Games", 
    "publish": "2013-05-10T20:31:55Z", 
    "summary": "In this note we provide a new proof for the results of Lipton et al. on the\nexistence of an approximate Nash equilibrium with logarithmic support size.\nBesides its simplicity, the new proof leads to the following contributions:\n  1. For n-player games, we improve the bound on the size of the support of an\napproximate Nash equilibrium.\n  2. We generalize the result of Daskalakis and Papadimitriou on small\nprobability games from the two-player case to the general n-player case.\n  3. We provide a logarithmic bound on the size of the support of an\napproximate Nash equilibrium in the case of graphical games.", 
    "link": "http://arxiv.org/pdf/1305.2432v2", 
    "arxiv-id": "1305.2432v2"
},{
    "category": "cs.GT", 
    "author": "Chun Ye", 
    "title": "Approximately Optimal Mechanisms for Strategyproof Facility Location:   Minimizing $L_p$ Norm of Costs", 
    "publish": "2013-05-10T21:47:17Z", 
    "summary": "We consider the problem of locating a single facility on the real line. This\nfacility serves a set of agents, each of whom is located on the line, and\nincurs a cost equal to his distance from the facility. An agent's location is\nprivate information that is known only to him. Agents report their location to\na central planner who decides where to locate the facility. The planner's\nobjective is to minimize a \"social\" cost function that depends on the\nagent-costs. However, agents might not report truthfully; to address this\nissue, the planner must restrict himself to {\\em strategyproof} mechanisms, in\nwhich truthful reporting is a dominant strategy for each agent. A mechanism\nthat simply chooses the optimal solution is generally not strategyproof, and so\nthe planner aspires to use a mechanism that effectively {\\em approximates} his\nobjective function. In our paper, we study the problem described above with the\nsocial cost function being the $L_p$ norm of the vector of agent-costs. We show\nthat the median mechanism (which is known to be strategyproof) provides a\n$2^{1-\\frac{1}{p}}$ approximation ratio, and that is the optimal approximation\nratio among all deterministic strategyproof mechanisms. For randomized\nmechanisms, we present two results. First, we present a negative result: we\nshow that for integer $\\infty>p>2$, no mechanism---from a rather large class of\nrandomized mechanisms--- has an approximation ratio better than that of the\nmedian mechanism. This is in contrast to the case of $p=2$ and $p=\\infty$ where\na randomized mechanism provably helps improve the worst case approximation\nratio. Second, for the case of 2 agents, we show that a mechanism called LRM,\nfirst designed by Procaccia and Tennenholtz for the special case of\n$L_{\\infty}$, provides the optimal approximation ratio among all randomized\nmechanisms.", 
    "link": "http://arxiv.org/pdf/1305.2446v2", 
    "arxiv-id": "1305.2446v2"
},{
    "category": "cs.GT", 
    "author": "Vijay V. Vazirani", 
    "title": "An Incentive Compatible, Efficient Market for Air Traffic Flow   Management", 
    "publish": "2013-05-14T18:33:12Z", 
    "summary": "We present a market-based approach to the Air Traffic Flow Management (ATFM)\nproblem. The goods in our market are delays and buyers are airline companies;\nthe latter pay money to the FAA to buy away the desired amount of delay on a\nper flight basis. We give a notion of equilibrium for this market and an LP\nwhose solution gives an equilibrium allocation of flights to landing slots as\nwell as equilibrium prices for the landing slots. Via a reduction to matching,\nwe show that this equilibrium can be computed combinatorially in strongly\npolynomial time. Moreover, there is a special set of equilibrium prices, which\ncan be computed easily, that is identical to the VCG solution, and therefore\nthe market is incentive compatible in dominant strategy.", 
    "link": "http://arxiv.org/pdf/1305.3241v2", 
    "arxiv-id": "1305.3241v2"
},{
    "category": "cs.GT", 
    "author": "Christos Tzamos", 
    "title": "Strategy-Proof Facility Location for Concave Cost Functions", 
    "publish": "2013-05-15T01:22:15Z", 
    "summary": "We consider k-Facility Location games, where n strategic agents report their\nlocations on the real line, and a mechanism maps them to k facilities. Each\nagent seeks to minimize his connection cost, given by a nonnegative increasing\nfunction of his distance to the nearest facility. Departing from previous work,\nthat mostly considers the identity cost function, we are interested in\nmechanisms without payments that are (group) strategyproof for any given cost\nfunction, and achieve a good approximation ratio for the social cost and/or the\nmaximum cost of the agents.\n  We present a randomized mechanism, called Equal Cost, which is group\nstrategyproof and achieves a bounded approximation ratio for all k and n, for\nany given concave cost function. The approximation ratio is at most 2 for Max\nCost and at most n for Social Cost. To the best of our knowledge, this is the\nfirst mechanism with a bounded approximation ratio for instances with k > 2\nfacilities and any number of agents. Our result implies an interesting\nseparation between deterministic mechanisms, whose approximation ratio for Max\nCost jumps from 2 to unbounded when k increases from 2 to 3, and randomized\nmechanisms, whose approximation ratio remains at most 2 for all k. On the\nnegative side, we exclude the possibility of a mechanism with the properties of\nEqual Cost for strictly convex cost functions. We also present a randomized\nmechanism, called Pick the Loser, which applies to instances with k facilities\nand n = k+1 agents, and for any given concave cost function, is strongly group\nstrategyproof and achieves an approximation ratio of 2 for Social Cost.", 
    "link": "http://arxiv.org/pdf/1305.3333v1", 
    "arxiv-id": "1305.3333v1"
},{
    "category": "cs.GT", 
    "author": "Adam Wierman", 
    "title": "The Empirical Implications of Rank in Bimatrix Games", 
    "publish": "2013-05-15T01:50:49Z", 
    "summary": "We study the structural complexity of bimatrix games, formalized via rank,\nfrom an empirical perspective. We consider a setting where we have data on\nplayer behavior in diverse strategic situations, but where we do not observe\nthe relevant payoff functions. We prove that high complexity (high rank) has\nempirical consequences when arbitrary data is considered. Additionally, we\nprove that, in more restrictive classes of data (termed laminar), any\nobservation is rationalizable using a low-rank game: specifically a zero-sum\ngame. Hence complexity as a structural property of a game is not always\ntestable. Finally, we prove a general result connecting the structure of the\nfeasible data sets with the highest rank that may be needed to rationalize a\nset of observations.", 
    "link": "http://arxiv.org/pdf/1305.3336v1", 
    "arxiv-id": "1305.3336v1"
},{
    "category": "cs.GT", 
    "author": "Saswati Sarkar", 
    "title": "Quality Sensitive Price Competition in Spectrum Oligopoly", 
    "publish": "2013-05-15T03:42:45Z", 
    "summary": "We investigate a spectrum oligopoly where primary users allow secondary\naccess in lieu of financial remuneration. Transmission qualities of the\nlicensed bands fluctuate randomly. Each primary needs to select the price of\nits channel with the knowledge of its own channel state but not that of its\ncompetitors. Secondaries choose among the channels available on sale based on\ntheir states and prices. We formulate the price selection as a non-cooperative\ngame and prove that a symmetric Nash equilibrium (NE) strategy profile exists\nuniquely. We explicitly compute this strategy profile and analytically and\nnumerically evaluate its efficiency. Our structural results provide certain key\ninsights about the unique symmetric NE.", 
    "link": "http://arxiv.org/pdf/1305.3351v2", 
    "arxiv-id": "1305.3351v2"
},{
    "category": "cs.GT", 
    "author": "Sunil Simon", 
    "title": "Social Network Games with Obligatory Product Selection", 
    "publish": "2013-05-22T08:44:10Z", 
    "summary": "Recently, Apt and Markakis introduced a model for product adoption in social\nnetworks with multiple products, where the agents, influenced by their\nneighbours, can adopt one out of several alternatives (products). To analyze\nthese networks we introduce social network games in which product adoption is\nobligatory.\n  We show that when the underlying graph is a simple cycle, there is a\npolynomial time algorithm allowing us to determine whether the game has a Nash\nequilibrium. In contrast, in the arbitrary case this problem is NP-complete. We\nalso show that the problem of determining whether the game is weakly acyclic is\nco-NP hard.\n  Using these games we analyze various types of paradoxes that can arise in the\nconsidered networks. One of them corresponds to the well-known Braess paradox\nin congestion games. In particular, we show that social networks exist with the\nproperty that by adding an additional product to a specific node, the choices\nof the nodes will unavoidably evolve in such a way that everybody is strictly\nworse off.", 
    "link": "http://arxiv.org/pdf/1305.5050v3", 
    "arxiv-id": "1305.5050v3"
},{
    "category": "cs.GT", 
    "author": "Y. Narahari", 
    "title": "Asymptotic Collusion-Proofness of Voting Rules: The Case of Large Number   of Candidates", 
    "publish": "2013-05-22T08:58:24Z", 
    "summary": "Classical results in voting theory show that strategic manipulation by voters\nis inevitable if a voting rule simultaneously satisfy certain desirable\nproperties. Motivated by this, we study the relevant question of how often a\nvoting rule is manipulable. It is well known that elections with a large number\nof voters are rarely manipulable under impartial culture (IC) assumption.\nHowever, the manipulability of voting rules when the number of candidates is\nlarge has hardly been addressed in the literature and our paper focuses on this\nproblem. First, we propose two properties (1) asymptotic strategy-proofness and\n(2) asymptotic collusion-proofness, with respect to new voters, which makes the\ntwo notions more relevant from the perspective of computational problem of\nmanipulation. In addition to IC, we explore a new culture of society where all\nscore vectors of the candidates are equally likely. This new notion has its\nmotivation in computational social choice and we call it impartial scores\nculture (ISC) assumption. We study asymptotic strategy-proofness and asymptotic\ncollusion-proofness for plurality, veto, $k$-approval, and Borda voting rules\nunder IC as well as ISC assumptions. Specifically, we prove bounds for the\nfraction of manipulable profiles when the number of candidates is large. Our\nresults show that the size of the coalition and the tie-breaking rule play a\ncrucial role in determining whether or not a voting rule satisfies the above\ntwo properties.", 
    "link": "http://arxiv.org/pdf/1305.5053v2", 
    "arxiv-id": "1305.5053v2"
},{
    "category": "cs.GT", 
    "author": "Kate Larson", 
    "title": "A Truth Serum for Sharing Rewards", 
    "publish": "2013-05-22T15:30:35Z", 
    "summary": "We study a problem where a group of agents has to decide how a joint reward\nshould be shared among them. We focus on settings where the share that each\nagent receives depends on the subjective opinions of its peers concerning that\nagent's contribution to the group. To this end, we introduce a mechanism to\nelicit and aggregate subjective opinions as well as for determining agents'\nshares. The intuition behind the proposed mechanism is that each agent who\nbelieves that the others are telling the truth has its expected share maximized\nto the extent that it is well-evaluated by its peers and that it is truthfully\nreporting its opinions. Under the assumptions that agents are Bayesian\ndecision-makers and that the underlying population is sufficiently large, we\nshow that our mechanism is incentive-compatible, budget-balanced, and\ntractable. We also present strategies to make this mechanism individually\nrational and fair.", 
    "link": "http://arxiv.org/pdf/1305.5170v1", 
    "arxiv-id": "1305.5170v1"
},{
    "category": "cs.GT", 
    "author": "Tie-Yan Liu", 
    "title": "Pure Price of Anarchy for Generalized Second Price Auction", 
    "publish": "2013-05-23T12:57:26Z", 
    "summary": "The Generalized Second Price auction (GSP) has been widely used by search\nengines to sell ad slots. Previous studies have shown that the pure Price Of\nAnarchy (POA) of GSP is 1.25 when there are two ad slots and 1.259 when three\nad slots. For the cases with more than three ad slots, however, only some\nuntight upper bounds of the pure POA were obtained. In this work, we improve\nprevious results in two aspects: (1) We prove that the pure POA for GSP is\n1.259 when there are four ad slots, and (2) We show that the pure POA for GSP\nwith more than four ad slots is also 1.259 given the bidders are ranked\naccording to a particular permutation.", 
    "link": "http://arxiv.org/pdf/1305.5404v1", 
    "arxiv-id": "1305.5404v1"
},{
    "category": "cs.GT", 
    "author": "Carlos Gamez", 
    "title": "A game-theoretic analysis of baccara chemin de fer", 
    "publish": "2013-05-23T15:47:16Z", 
    "summary": "Assuming that cards are dealt with replacement from a single deck and that\neach of Player and Banker sees the total of his own two-card hand but not its\ncomposition, baccara is a 2 x 2^88 matrix game, which was solved by Kemeny and\nSnell in 1957. Assuming that cards are dealt without replacement from a d-deck\nshoe and that Banker sees the composition of his own two-card hand while Player\nsees only his own total, baccara is a 2 x 2^484 matrix game, which was solved\nby Downton and Lockwood in 1975 for d=1,2,...,8. Assuming that cards are dealt\nwithout replacement from a d-deck shoe and that each of Player and Banker sees\nthe composition of his own two-card hand, baccara is a 2^5 x 2^484 matrix game,\nwhich is solved herein for every positive integer d.", 
    "link": "http://arxiv.org/pdf/1305.5468v1", 
    "arxiv-id": "1305.5468v1"
},{
    "category": "cs.GT", 
    "author": "K. J. Ray Liu", 
    "title": "On Cost-Effective Incentive Mechanisms in Microtask Crowdsourcing", 
    "publish": "2013-05-29T06:46:43Z", 
    "summary": "While microtask crowdsourcing provides a new way to solve large volumes of\nsmall tasks at a much lower price compared with traditional in-house solutions,\nit suffers from quality problems due to the lack of incentives. On the other\nhand, providing incentives for microtask crowdsourcing is challenging since\nverifying the quality of submitted solutions is so expensive that will negate\nthe advantage of microtask crowdsourcing. We study cost-effective incentive\nmechanisms for microtask crowdsourcing in this paper. In particular, we\nconsider a model with strategic workers, where the primary objective of a\nworker is to maximize his own utility. Based on this model, we analyze two\nbasic mechanisms widely adopted in existing microtask crowdsourcing\napplications and show that, to obtain high quality solutions from workers,\ntheir costs are constrained by some lower bounds. We then propose a\ncost-effective mechanism that employs quality-aware worker training as a tool\nto stimulate workers to provide high quality solutions. We prove theoretically\nthat the proposed mechanism, when properly designed, can obtain high quality\nsolutions with an arbitrarily low cost. Beyond its theoretical guarantees, we\nfurther demonstrate the effectiveness of our proposed mechanisms through a set\nof behavioral experiments.", 
    "link": "http://arxiv.org/pdf/1305.6705v1", 
    "arxiv-id": "1305.6705v1"
},{
    "category": "cs.GT", 
    "author": "Mingyan Liu", 
    "title": "Perceptions and Truth: A Mechanism Design Approach to Crowd-Sourcing   Reputation", 
    "publish": "2013-06-02T05:40:10Z", 
    "summary": "We consider a distributed multi-user system where individual entities possess\nobservations or perceptions of one another, while the truth is only known to\nthemselves, and they might have an interest in withholding or distorting the\ntruth. We ask the question whether it is possible for the system as a whole to\narrive at the correct perceptions or assessment of all users, referred to as\ntheir reputation, by encouraging or incentivizing the users to participate in a\ncollective effort without violating private information and self-interest. Two\nspecific applications, online shopping and network reputation, are provided to\nmotivate our study and interpret the results. In this paper we investigate this\nproblem using a mechanism design theoretic approach. We introduce a number of\nutility models representing users' strategic behavior, each consisting of one\nor both of a truth element and an image element, reflecting the user's desire\nto obtain an accurate view of the other and an inflated image of itself. For\neach model, we either design a mechanism that achieves the optimal performance\n(solution to the corresponding centralized problem), or present individually\nrational sub-optimal solutions. In the latter case, we demonstrate that even\nwhen the centralized solution is not achievable, by using a simple\npunish-reward mechanism, not only a user has the incentive to participate and\nprovide information, but also that this information can improve the system\nperformance.", 
    "link": "http://arxiv.org/pdf/1306.0173v1", 
    "arxiv-id": "1306.0173v1"
},{
    "category": "cs.GT", 
    "author": "Kate Larson", 
    "title": "Sharing a Reward Based on Peer Evaluations", 
    "publish": "2013-06-03T14:22:00Z", 
    "summary": "We study a problem where a group of agents has to decide how some fixed value\nshould be shared among them. We are interested in settings where the share that\neach agent receives is based on how that agent is evaluated by other members of\nthe group, where highly regarded agents receive a greater share compared to\nagents that are not well regarded. We introduce two mechanisms for determining\nagents' shares: the peer-evaluation mechanism, where each agent gives a direct\nevaluation for every other member of the group, and the peer-prediction\nmechanism, where each agent is asked to report how they believe group members\nwill evaluate a particular agent. The sharing is based on the provided\ninformation. While both mechanisms are individually rational, the first\nmechanism is strategy-proof and budget-balanced, but it can be collusion-prone.\nFurther, the second mechanism is collusion-resistant and incentive-compatible.", 
    "link": "http://arxiv.org/pdf/1306.0428v1", 
    "arxiv-id": "1306.0428v1"
},{
    "category": "cs.GT", 
    "author": "Kevin Leyton-Brown", 
    "title": "Predicting Human Behavior in Unrepeated, Simultaneous-Move Games", 
    "publish": "2013-06-04T20:13:20Z", 
    "summary": "It is common to assume that agents will adopt Nash equilibrium strategies;\nhowever, experimental studies have demonstrated that Nash equilibrium is often\na poor description of human players' behavior in unrepeated normal-form games.\nIn this paper, we analyze five widely studied models (Quantal Response\nEquilibrium, Level-$k$, Cognitive Hierarchy, QLk, and Noisy Introspection) that\naim to describe actual, rather than idealized, human behavior in such games. We\nperformed what we believe is the most comprehensive meta-analysis of these\nmodels, leveraging ten different data sets from the literature recording human\nplay of two-player games. We began by evaluating the models' generalization or\npredictive performance, asking how well a model fits unseen test data after\nhaving had its parameters calibrated based on separate training data.\nSurprisingly, we found that what we dub the QLk model of Stahl & Wilson (1994)\nconsistently achieved the best performance. Motivated by this finding, we\ndescribe methods for analyzing the posterior distributions over a model's\nparameters. We found that QLk's parameters were being set to values that were\nnot consistent with their intended economic interpretations. We thus explored\nvariations of QLk, ultimately identifying a new model family that has fewer\nparameters, gives rise to more parsimonious parameter values, and achieves\nbetter predictive performance.", 
    "link": "http://arxiv.org/pdf/1306.0918v3", 
    "arxiv-id": "1306.0918v3"
},{
    "category": "cs.GT", 
    "author": "P. G. Spirakis", 
    "title": "On the Structure of Equilibria in Basic Network Formation", 
    "publish": "2013-06-07T09:57:29Z", 
    "summary": "We study network connection games where the nodes of a network perform edge\nswaps in order to improve their communication costs. For the model proposed by\nAlon et al. (2010), in which the selfish cost of a node is the sum of all\nshortest path distances to the other nodes, we use the probabilistic method to\nprovide a new, structural characterization of equilibrium graphs. We show how\nto use this characterization in order to prove upper bounds on the diameter of\nequilibrium graphs in terms of the size of the largest $k$-vicinity (defined as\nthe the set of vertices within distance $k$ from a vertex), for any $k \\geq 1$\nand in terms of the number of edges, thus settling positively a conjecture of\nAlon et al. in the cases of graphs of large $k$-vicinity size (including graphs\nof large maximum degree) and of graphs which are dense enough.\n  Next, we present a new swap-based network creation game, in which selfish\ncosts depend on the immediate neighborhood of each node; in particular, the\nprofit of a node is defined as the sum of the degrees of its neighbors. We\nprove that, in contrast to the previous model, this network creation game\nadmits an exact potential, and also that any equilibrium graph contains an\ninduced star. The existence of the potential function is exploited in order to\nshow that an equilibrium can be reached in expected polynomial time even in the\ncase where nodes can only acquire limited knowledge concerning non-neighboring\nnodes.", 
    "link": "http://arxiv.org/pdf/1306.1677v1", 
    "arxiv-id": "1306.1677v1"
},{
    "category": "cs.GT", 
    "author": "Marcin Peczarski", 
    "title": "The Worst Case Number of Questions in Generalized AB Game with and   without White-peg Answers", 
    "publish": "2013-06-07T13:07:18Z", 
    "summary": "The AB game is a two-player game, where the codemaker has to choose a secret\ncode and the codebreaker has to guess it in as few questions as possible. It is\na variant of the famous Mastermind game, with the only difference that all pegs\nin both, the secret and the questions must have distinct colors. In this work,\nwe consider the Generalized AB game, where for given arbitrary numbers $p$, $c$\nwith $p \\le c$ the secret code consists of $p$ pegs each having one of $c$\ncolors and the answer consists only of a number of black and white pegs. There\nthe number of black pegs equals the number of pegs matching in the\ncorresponding question and the secret in position and color, and the number of\nwhite pegs equals the additional number of pegs matching in the corresponding\nquestion and the secret only in color. We consider also a variant of the\nGeneralized AB game, where the information of white pegs is omitted. This\nvariant is called Generalized Black-peg AB game. Let $\\ab(p,c)$ and $\\abb(p,c)$\nbe the worst case number of questions for Generalized AB game and Generalized\nBlack-peg AB game, respectively. Combining a computer program with theoretical\nconsiderations, we confirm known exact values of $\\ab(2,c)$ and $\\ab(3,c)$ and\nprove tight bounds for $\\ab(4,c)$. Furthermore, we present exact values for\n$\\abb(2,c)$ and $\\abb(3,c)$ and tight bounds for $\\abb(4,c)$.", 
    "link": "http://arxiv.org/pdf/1306.1713v1", 
    "arxiv-id": "1306.1713v1"
},{
    "category": "cs.GT", 
    "author": "Siddharth Barman", 
    "title": "Query Complexity of Correlated Equilibrium", 
    "publish": "2013-06-11T07:10:10Z", 
    "summary": "We study lower bounds on the query complexity of determining correlated\nequilibrium. In particular, we consider a query model in which an n-player game\nis specified via a black box that returns players' utilities at pure action\nprofiles. In this model we establish that in order to compute a correlated\nequilibrium any deterministic algorithm must query the black box an exponential\n(in n) number of times.", 
    "link": "http://arxiv.org/pdf/1306.2437v2", 
    "arxiv-id": "1306.2437v2"
},{
    "category": "cs.GT", 
    "author": "George Kesidis", 
    "title": "Behavior in a Shared Resource Game with Cooperative, Greedy, and   Vigilante Players", 
    "publish": "2013-06-13T14:50:42Z", 
    "summary": "We study a problem of trust in a distributed system in which a common\nresource is shared by multiple parties. In such naturally information-limited\nsettings, parties abide by a behavioral protocol that leads to fair sharing of\nthe resource. However, greedy players may defect from a cooperative protocol\nand achieve a greater than fair share of resources, often without significant\nadverse consequences to themselves. In this paper, we study the role of a few\nvigilante players who also defect from a cooperative resource-sharing protocol\nbut only in response to perceived greedy behavior. For a simple model of\nengagement, we demonstrate surprisingly complex dynamics among greedy and\nvigilante players. We show that the best response function for the\ngreedy-player under our formulation has a jump discontinuity, which leads to\nconditions under which there is no Nash equilibrium. To study this property, we\nformulate an exact representation for the greedy player best response function\nin the case when there is one greedy player, one vigilante player and $N-2$\ncooperative players. We use this formulation to show conditions under which a\nNash equilibrium exists. We also illustrate that in the case when there is no\nNash equilibrium, then the discrete dynamic system generated from fictitious\nplay will not converge, but will oscillate indefinitely as a result of the jump\ndiscontinuity. The case of multiple vigilante and greedy players is studied\nnumerically. Finally, we explore the relationship between fictitious play and\nthe better response dynamics (gradient descent) and illustrate that this\ndynamical system can have a fixed point even when the discrete dynamical system\narising from fictitious play does not.", 
    "link": "http://arxiv.org/pdf/1306.3127v3", 
    "arxiv-id": "1306.3127v3"
},{
    "category": "cs.GT", 
    "author": "Luis F. Zuluaga", 
    "title": "Copula-based Randomized Mechanisms for Truthful Scheduling on Two   Unrelated Machines", 
    "publish": "2013-06-17T15:52:53Z", 
    "summary": "We design a Copula-based generic randomized truthful mechanism for scheduling\non two unrelated machines with approximation ratio within $[1.5852, 1.58606]$,\noffering an improved upper bound for the two-machine case. Moreover, we provide\nan upper bound 1.5067711 for the two-machine two-task case, which is almost\ntight in view of the lower bound of 1.506 for the scale-free truthful\nmechanisms [4]. Of independent interest is the explicit incorporation of the\nconcept of Copula in the design and analysis of the proposed approximation\nalgorithm. We hope that techniques like this one will also prove useful in\nsolving other problems in the future.", 
    "link": "http://arxiv.org/pdf/1306.3909v1", 
    "arxiv-id": "1306.3909v1"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Vickrey Auctions for Irregular Distributions", 
    "publish": "2013-06-17T21:19:08Z", 
    "summary": "The classic result of Bulow and Klemperer \\cite{BK96} says that in a\nsingle-item auction recruiting one more bidder and running the Vickrey auction\nachieves a higher revenue than the optimal auction's revenue on the original\nset of bidders, when values are drawn i.i.d. from a regular distribution. We\ngive a version of Bulow and Klemperer's result in settings where bidders'\nvalues are drawn from non-i.i.d. irregular distributions. We do this by\nmodeling irregular distributions as some convex combination of regular\ndistributions. The regular distributions that constitute the irregular\ndistribution correspond to different population groups in the bidder\npopulation. Drawing a bidder from this collection of population groups is\nequivalent to drawing from some convex combination of these regular\ndistributions. We show that recruiting one extra bidder from each underlying\npopulation group and running the Vickrey auction gives at least half of the\noptimal auction's revenue on the original set of bidders.", 
    "link": "http://arxiv.org/pdf/1306.4022v2", 
    "arxiv-id": "1306.4022v2"
},{
    "category": "cs.GT", 
    "author": "Alex Rogers", 
    "title": "Bounding the Estimation Error of Sampling-based Shapley Value   Approximation", 
    "publish": "2013-06-18T16:51:53Z", 
    "summary": "The Shapley value is arguably the most central normative solution concept in\ncooperative game theory. It specifies a unique way in which the reward from\ncooperation can be \"fairly\" divided among players. While it has a wide range of\nreal world applications, its use is in many cases hampered by the hardness of\nits computation. A number of researchers have tackled this problem by (i)\nfocusing on classes of games where the Shapley value can be computed\nefficiently, or (ii) proposing representation formalisms that facilitate such\nefficient computation, or (iii) approximating the Shapley value in certain\nclasses of games. For the classical \\textit{characteristic function}\nrepresentation, the only attempt to approximate the Shapley value for the\ngeneral class of games is due to Castro \\textit{et al.} \\cite{castro}. While\nthis algorithm provides a bound on the approximation error, this bound is\n\\textit{asymptotic}, meaning that it only holds when the number of samples\nincreases to infinity. On the other hand, when a finite number of samples is\ndrawn, an unquantifiable error is introduced, meaning that the bound no longer\nholds. With this in mind, we provide non-asymptotic bounds on the estimation\nerror for two cases: where (i) the \\textit{variance}, and (ii) the\n\\textit{range}, of the players' marginal contributions is known. Furthermore,\nfor the second case, we show that when the range is significantly large\nrelative to the Shapley value, the bound can be improved (from $O(\\frac{r}{m})$\nto $O(\\sqrt{\\frac{r}{m}})$). Finally, we propose, and demonstrate the\neffectiveness of using stratified sampling for improving the bounds further.", 
    "link": "http://arxiv.org/pdf/1306.4265v2", 
    "arxiv-id": "1306.4265v2"
},{
    "category": "cs.GT", 
    "author": "Jochen Koenemann", 
    "title": "Network bargaining with general capacities", 
    "publish": "2013-06-18T19:28:24Z", 
    "summary": "We study balanced solutions for network bargaining games with general\ncapacities, where agents can participate in a fixed but arbitrary number of\ncontracts. We provide the first polynomial time algorithm for computing\nbalanced solutions for these games. In addition, we prove that an instance has\na balanced solution if and only if it has a stable one. Our methods use a new\nidea of reducing an instance with general capacities to a network bargaining\ngame with unit capacities defined on an auxiliary graph. This represents a\ndeparture from previous approaches, which rely on computing an allocation in\nthe intersection of the core and prekernel of a corresponding cooperative game,\nand then proving that the solution corresponding to this allocation is\nbalanced. In fact, we show that such cooperative game methods do not extend to\ngeneral capacity games, since contrary to the case of unit capacities, there\nexist allocations in the intersection of the core and prekernel with no\ncorresponding balanced solution. Finally, we identify two sufficient conditions\nunder which the set of balanced solutions corresponds to the intersection of\nthe core and prekernel, thereby extending the class of games for which this\nresult was previously known.", 
    "link": "http://arxiv.org/pdf/1306.4302v1", 
    "arxiv-id": "1306.4302v1"
},{
    "category": "cs.GT", 
    "author": "Perouz Taslakian", 
    "title": "Cannibal Animal Games: a new variant of Tic-Tac-Toe", 
    "publish": "2013-06-20T14:14:04Z", 
    "summary": "This paper presents a new partial two-player game, called the \\emph{cannibal\nanimal game}, which is a variant of Tic-Tac-Toe. The game is played on the\ninfinite grid, where in each round a player chooses and occupies free cells.\nThe first player Alice can occupy a cell in each turn and wins if she occupies\na set of cells, the union of a subset of which is a translated, reflected\nand/or rotated copy of a previously agreed upon polyomino $P$ (called an\n\\emph{animal}). The objective of the second player Bob is to prevent Alice from\ncreating her animal by occupying in each round a translated, reflected and/or\nrotated copy of $P$. An animal is a \\emph{cannibal} if Bob has a winning\nstrategy, and a \\emph{non-cannibal} otherwise. This paper presents some new\ntools, such as the \\emph{bounding strategy} and the \\emph{punching lemma}, to\nclassify animals into cannibals or non-cannibals. We also show that the\n\\emph{pairing strategy} works for this problem.", 
    "link": "http://arxiv.org/pdf/1306.4884v1", 
    "arxiv-id": "1306.4884v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Equilibrium in Labor Markets with Few Firms", 
    "publish": "2013-06-25T06:45:44Z", 
    "summary": "We study competition between firms in labor markets, following a\ncombinatorial model suggested by Kelso and Crawford [1982]. In this model, each\nfirm is trying to recruit workers by offering a higher salary than its\ncompetitors, and its production function defines the utility generated from any\nactual set of recruited workers. We define two natural classes of production\nfunctions for firms, where the first one is based on additive capacities\n(weights), and the second on the influence of workers in a social network. We\nthen analyze the existence of pure subgame perfect equilibrium (PSPE) in the\nlabor market and its properties. While neither class holds the gross\nsubstitutes condition, we show that in both classes the existence of PSPE is\nguaranteed under certain restrictions, and in particular when there are only\ntwo competing firms. As a corollary, there exists a Walrasian equilibrium in a\ncorresponding combinatorial auction, where bidders' valuation functions belong\nto these classes.\n  While a PSPE may not exist when there are more than two firms, we perform an\nempirical study of equilibrium outcomes for the case of weight-based games with\nthree firms, which extend our analytical results. We then show that stability\ncan in some cases be extended to coalitional stability, and study the\ndistribution of profit between firms and their workers in weight-based games.", 
    "link": "http://arxiv.org/pdf/1306.5855v1", 
    "arxiv-id": "1306.5855v1"
},{
    "category": "cs.GT", 
    "author": "Krzysztof Le\u015bniak", 
    "title": "Playing cooperatively with possibly treacherous partner", 
    "publish": "2013-06-26T15:50:34Z", 
    "summary": "We investigate an alternative concept of Nash equilibrium, m-equilibrium,\nwhich slightly resembles Harsanyi-Selten risk dominant equilibrium although it\nis a different notion. M-equilibria provide nontrivial solutions of normal form\ngames as shown by comparison of the Prisoner's Dilemma with the Traveler's\nDilemma. They are also resistant on the deep iterated elimination of dominated\nstrategies.", 
    "link": "http://arxiv.org/pdf/1306.6278v1", 
    "arxiv-id": "1306.6278v1"
},{
    "category": "cs.GT", 
    "author": "Yakov Babichenko", 
    "title": "Query Complexity of Approximate Nash Equilibria", 
    "publish": "2013-06-28T00:56:13Z", 
    "summary": "We study the query complexity of approximate notions of Nash equilibrium in\ngames with a large number of players $n$. Our main result states that for\n$n$-player binary-action games and for constant $\\varepsilon$, the query\ncomplexity of an $\\varepsilon$-well-supported Nash equilibrium is exponential\nin $n$. One of the consequences of this result is an exponential lower bound on\nthe rate of convergence of adaptive dynamics to approxiamte Nash equilibrium.", 
    "link": "http://arxiv.org/pdf/1306.6686v3", 
    "arxiv-id": "1306.6686v3"
},{
    "category": "cs.GT", 
    "author": "Bart de Keijzer", 
    "title": "Shapley Meets Shapley", 
    "publish": "2013-07-01T11:07:12Z", 
    "summary": "This paper concerns the analysis of the Shapley value in matching games.\nMatching games constitute a fundamental class of cooperative games which help\nunderstand and model auctions and assignments. In a matching game, the value of\na coalition of vertices is the weight of the maximum size matching in the\nsubgraph induced by the coalition. The Shapley value is one of the most\nimportant solution concepts in cooperative game theory.\n  After establishing some general insights, we show that the Shapley value of\nmatching games can be computed in polynomial time for some special cases:\ngraphs with maximum degree two, and graphs that have a small modular\ndecomposition into cliques or cocliques (complete k-partite graphs are a\nnotable special case of this). The latter result extends to various other\nwell-known classes of graph-based cooperative games.\n  We continue by showing that computing the Shapley value of unweighted\nmatching games is #P-complete in general. Finally, a fully polynomial-time\nrandomized approximation scheme (FPRAS) is presented. This FPRAS can be\nconsidered the best positive result conceivable, in view of the #P-completeness\nresult.", 
    "link": "http://arxiv.org/pdf/1307.0332v1", 
    "arxiv-id": "1307.0332v1"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "Truthful approximations to range voting", 
    "publish": "2013-07-06T09:22:25Z", 
    "summary": "We consider the fundamental mechanism design problem of approximate social\nwelfare maximization under general cardinal preferences on a finite number of\nalternatives and without money. The well-known range voting scheme can be\nthought of as a non-truthful mechanism for exact social welfare maximization in\nthis setting. With m being the number of alternatives, we exhibit a randomized\ntruthful-in-expectation ordinal mechanism implementing an outcome whose\nexpected social welfare is at least an Omega(m^{-3/4}) fraction of the social\nwelfare of the socially optimal alternative. On the other hand, we show that\nfor sufficiently many agents and any truthful-in-expectation ordinal mechanism,\nthere is a valuation profile where the mechanism achieves at most an\nO(m^{-{2/3}) fraction of the optimal social welfare in expectation. We get\ntighter bounds for the natural special case of m = 3, and in that case\nfurthermore obtain separation results concerning the approximation ratios\nachievable by natural restricted classes of truthful-in-expectation mechanisms.\nIn particular, we show that for m = 3 and a sufficiently large number of\nagents, the best mechanism that is ordinal as well as mixed-unilateral has an\napproximation ratio between 0.610 and 0.611, the best ordinal mechanism has an\napproximation ratio between 0.616 and 0.641, while the best mixed-unilateral\nmechanism has an approximation ratio bigger than 0.660. In particular, the best\nmixed-unilateral non-ordinal (i.e., cardinal) mechanism strictly outperforms\nall ordinal ones, even the non-mixed-unilateral ordinal ones.", 
    "link": "http://arxiv.org/pdf/1307.1766v2", 
    "arxiv-id": "1307.1766v2"
},{
    "category": "cs.GT", 
    "author": "J. Jost", 
    "title": "Periodic Strategies a New Solution Concept-Algorithm for non-trivial   Strategic Form Games", 
    "publish": "2013-07-08T11:06:16Z", 
    "summary": "We introduce a new solution concept for selecting optimal strategies in\nstrategic form games which we call periodic strategies and the solution concept\nperiodicity. As we will explicitly demonstrate, the periodicity solution\nconcept has implications for non-trivial realistic games, which renders this\nsolution concept very valuable. The most striking application of periodicity is\nthat in mixed strategy strategic form games, we were able to find solutions\nthat result to values for the utility function of each player, that are equal\nto the Nash equilibrium ones, with the difference that in the Nash strategies\nplaying, the payoffs strongly depend on what the opponent plays, while in the\nperiodic strategies case, the payoffs of each player are completely robust\nagainst what the opponent plays. We formally define and study periodic\nstrategies in two player perfect information strategic form games, with pure\nstrategies and generalize the results to include multiplayer games with perfect\ninformation. We prove that every non-trivial finite game has at least one\nperiodic strategy, with non-trivial meaning a game with non-degenerate payoffs.\nIn principle the algorithm we provide, holds true for every non-trivial game,\nbecause in degenerate games, inconsistencies can occur. In addition, we also\naddress the incomplete information games in the context of Bayesian games, in\nwhich case generalizations of Bernheim's rationalizability offers us the\npossibility to embed the periodicity concept in the Bayesian games framework.\nApplying the algorithm of periodic strategies in the case where mixed\nstrategies are used, we find some very interesting outcomes with useful\nquantitative features for some classes of games.", 
    "link": "http://arxiv.org/pdf/1307.2035v3", 
    "arxiv-id": "1307.2035v3"
},{
    "category": "cs.GT", 
    "author": "Sven Schewe", 
    "title": "The benefit of law-making power", 
    "publish": "2013-07-08T11:55:23Z", 
    "summary": "We study optimal equilibria in multi-player games. An equilibrium is optimal\nfor a player, if her payoff is maximal. A tempting approach to solving this\nproblem is to seek optimal Nash equilibria, the standard form of equilibria\nwhere no player has an incentive to deviate from her strategy. We argue that a\nplayer with the power to define an equilibrium is in a position, where she\nshould not be interested in the symmetry of a Nash equilibrium, and ignore the\nquestion of whether or not her outcome can be improved if the other strategies\nare fixed. That is, she would only have to make sure that the other players\nhave no incentive to deviate. This defines a greater class of equilibria, which\nmay have better (and cannot have worse) optimal equilibria for the designated\npowerful player. We apply this strategy to concurrent bimatrix games and to\nturn based multi-player mean-payoff games. For the latter, we show that such\npolitical equilibria as well as Nash equilibria always exist, and provide\nsimple examples where the political equilibrium is superior. We show that\nconstructing political and Nash equilibria are NP-complete problems. We also\nshow that, for a fixed number of players, the hardest part is to solve the\nunderlying two-player mean-payoff games: using an MPG oracle, the problem is\nsolvable in polynomial time. It is therefore in UP and CoUP, and can be solved\nin pseudo polynomial and expected subexponential time.", 
    "link": "http://arxiv.org/pdf/1307.2051v1", 
    "arxiv-id": "1307.2051v1"
},{
    "category": "cs.GT", 
    "author": "Ariel D. Procaccia", 
    "title": "An Algorithmic Framework for Strategic Fair Division", 
    "publish": "2013-07-08T19:58:15Z", 
    "summary": "We study the paradigmatic fair division problem of allocating a divisible\ngood among agents with heterogeneous preferences, commonly known as cake\ncutting. Classical cake cutting protocols are susceptible to manipulation. Do\ntheir strategic outcomes still guarantee fairness?\n  To address this question we adopt a novel algorithmic approach, by designing\na concrete computational framework for fair division---the class of Generalized\nCut and Choose (GCC) protocols}---and reasoning about the game-theoretic\nproperties of algorithms that operate in this model. The class of GCC protocols\nincludes the most important discrete cake cutting protocols, and turns out to\nbe compatible with the study of fair division among strategic agents. In\nparticular, GCC protocols are guaranteed to have approximate subgame perfect\nNash equilibria, or even exact equilibria if the protocol's tie-breaking rule\nis flexible. We further observe that the (approximate) equilibria of\nproportional GCC protocols---which guarantee each of the $n$ agents a\n$1/n$-fraction of the cake---must be (approximately) proportional. Finally, we\ndesign a protocol in this framework with the property that its Nash equilibrium\nallocations coincide with the set of (contiguous) envy-free allocations.", 
    "link": "http://arxiv.org/pdf/1307.2225v2", 
    "arxiv-id": "1307.2225v2"
},{
    "category": "cs.GT", 
    "author": "Milan Vojnovic", 
    "title": "Strong Price of Anarchy and Coalitional Dynamics", 
    "publish": "2013-07-09T18:29:52Z", 
    "summary": "We introduce a framework for studying the effect of cooperation on the\nquality of outcomes in utility games. Our framework is a coalitional analog of\nthe smoothness framework of non-cooperative games. Coalitional smoothness\nimplies bounds on the strong price of anarchy, the loss of quality of\ncoalitionally stable outcomes, as well as bounds on coalitional versions of\ncoarse correlated equilibria and sink equilibria, which we define as\nout-of-equilibrium myopic behavior as determined by a natural coalitional\nversion of best-response dynamics.\n  Our coalitional smoothness framework captures existing results bounding the\nstrong price of anarchy of network design games. We show that in any monotone\nutility-maximization game, if each player's utility is at least his marginal\ncontribution to the welfare, then the strong price of anarchy is at most 2.\nThis captures a broad class of games, including games with a very high price of\nanarchy. Additionally, we show that in potential games the strong price of\nanarchy is close to the price of stability, the quality of the best Nash\nequilibrium.", 
    "link": "http://arxiv.org/pdf/1307.2537v1", 
    "arxiv-id": "1307.2537v1"
},{
    "category": "cs.GT", 
    "author": "Pablo A. Parrilo", 
    "title": "Exchangeable Equilibria, Part I: Symmetric Bimatrix Games", 
    "publish": "2013-07-12T21:33:05Z", 
    "summary": "We introduce the notion of exchangeable equilibria of a symmetric bimatrix\ngame, defined as those correlated equilibria in which players' strategy choices\nare conditionally independently and identically distributed given some hidden\nvariable. We give several game-theoretic interpretations and a version of the\n\"revelation principle\". Geometrically, the set of exchangeable equilibria is\nconvex and lies between the symmetric Nash equilibria and the symmetric\ncorrelated equilibria. Exchangeable equilibria can achieve higher expected\nutility than symmetric Nash equilibria.", 
    "link": "http://arxiv.org/pdf/1307.3586v3", 
    "arxiv-id": "1307.3586v3"
},{
    "category": "cs.GT", 
    "author": "Ariel Orda", 
    "title": "Network Formation Games with Heterogeneous Players and the Internet   Structure", 
    "publish": "2013-07-15T21:03:50Z", 
    "summary": "We study the structure and evolution of the Internet's Autonomous System (AS)\ninterconnection topology as a game with heterogeneous players. In this network\nformation game, the utility of a player depends on the network structure, e.g.,\nthe distances between nodes and the cost of links. We analyze static properties\nof the game, such as the prices of anarchy and stability and provide explicit\nresults concerning the generated topologies. Furthermore, we discuss dynamic\naspects, demonstrating linear convergence rate and showing that only a\nrestricted subset of equilibria is feasible under realistic dynamics. We also\nconsider the case where utility (or monetary) transfers are allowed between the\nplayers.", 
    "link": "http://arxiv.org/pdf/1307.4102v4", 
    "arxiv-id": "1307.4102v4"
},{
    "category": "cs.GT", 
    "author": "Valerio Capraro", 
    "title": "A Model of Human Cooperation in Social Dilemmas", 
    "publish": "2013-07-16T09:57:13Z", 
    "summary": "Social dilemmas are situations in which collective interests are at odds with\nprivate interests: pollution, depletion of natural resources, and intergroup\nconflicts, are at their core social dilemmas.\n  Because of their multidisciplinarity and their importance, social dilemmas\nhave been studied by economists, biologists, psychologists, sociologists, and\npolitical scientists. These studies typically explain tendency to cooperation\nby dividing people in proself and prosocial types, or appealing to forms of\nexternal control or, in iterated social dilemmas, to long-term strategies.\n  But recent experiments have shown that cooperation is possible even in\none-shot social dilemmas without forms of external control and the rate of\ncooperation typically depends on the payoffs. This makes impossible a\npredictive division between proself and prosocial people and proves that people\nhave attitude to cooperation by nature.\n  The key innovation of this article is in fact to postulate that humans have\nattitude to cooperation by nature and consequently they do not act a priori as\nsingle agents, as assumed by standard economic models, but they forecast how a\nsocial dilemma would evolve if they formed coalitions and then they act\naccording to their most optimistic forecast. Formalizing this idea we propose\nthe first predictive model of human cooperation able to organize a number of\ndifferent experimental findings that are not explained by the standard model.\nWe show also that the model makes satisfactorily accurate quantitative\npredictions of population average behavior in one-shot social dilemmas.", 
    "link": "http://arxiv.org/pdf/1307.4228v2", 
    "arxiv-id": "1307.4228v2"
},{
    "category": "cs.GT", 
    "author": "Ron Peretz", 
    "title": "Approximate Nash Equilibria via Sampling", 
    "publish": "2013-07-18T13:23:47Z", 
    "summary": "We prove that in a normal form n-player game with m actions for each player,\nthere exists an approximate Nash equilibrium where each player randomizes\nuniformly among a set of O(log(m) + log(n)) pure strategies. This result\ninduces an $N^{\\log \\log N}$ algorithm for computing an approximate Nash\nequilibrium in games where the number of actions is polynomial in the number of\nplayers (m=poly(n)), where $N=nm^n$ is the size of the game (the input size).\n  In addition, we establish an inverse connection between the entropy of Nash\nequilibria in the game, and the time it takes to find such an approximate Nash\nequilibrium using the random sampling algorithm.", 
    "link": "http://arxiv.org/pdf/1307.4934v1", 
    "arxiv-id": "1307.4934v1"
},{
    "category": "cs.GT", 
    "author": "David C. Parkes", 
    "title": "Expressiveness and Robustness of First-Price Position Auctions", 
    "publish": "2013-07-19T13:59:10Z", 
    "summary": "Since economic mechanisms are often applied to very different instances of\nthe same problem, it is desirable to identify mechanisms that work well in a\nwide range of circumstances. We pursue this goal for a position auction setting\nand specifically seek mechanisms that guarantee good outcomes under both\ncomplete and incomplete information. A variant of the generalized first-price\nmechanism with multi-dimensional bids turns out to be the only standard\nmechanism able to achieve this goal, even when types are one-dimensional. The\nfact that expressiveness beyond the type space is both necessary and sufficient\nfor this kind of robustness provides an interesting counterpoint to previous\nwork on position auctions that has highlighted the benefits of simplicity. From\na technical perspective our results are interesting because they establish\nequilibrium existence for a multi-dimensional bid space, where standard\ntechniques break down. The structure of the equilibrium bids moreover provides\nan intuitive explanation for why first-price payments may be able to support\nequilibria in a wider range of circumstances than second-price payments.", 
    "link": "http://arxiv.org/pdf/1307.5216v1", 
    "arxiv-id": "1307.5216v1"
},{
    "category": "cs.GT", 
    "author": "Kalyanmoy Deb", 
    "title": "Finding Optimal Strategies in a Multi-Period Multi-Leader-Follower   Stackelberg Game Using an Evolutionary Algorithm", 
    "publish": "2013-07-23T21:15:06Z", 
    "summary": "Stackelberg games are a classic example of bilevel optimization problems,\nwhich are often encountered in game theory and economics. These are complex\nproblems with a hierarchical structure, where one optimization task is nested\nwithin the other. Despite a number of studies on handling bilevel optimization\nproblems, these problems still remain a challenging territory, and existing\nmethodologies are able to handle only simple problems with few variables under\nassumptions of continuity and differentiability. In this paper, we consider a\nspecial case of a multi-period multi-leader-follower Stackelberg competition\nmodel with non-linear cost and demand functions and discrete production\nvariables. The model has potential applications, for instance in aircraft\nmanufacturing industry, which is an oligopoly where a few giant firms enjoy a\ntremendous commitment power over the other smaller players. We solve cases with\ndifferent number of leaders and followers, and show how the entrance or exit of\na player affects the profits of the other players. In the presence of various\nmodel complexities, we use a computationally intensive nested evolutionary\nstrategy to find an optimal solution for the model. The strategy is evaluated\non a test-suite of bilevel problems, and it has been shown that the method is\nsuccessful in handling difficult bilevel problems.", 
    "link": "http://arxiv.org/pdf/1307.6246v1", 
    "arxiv-id": "1307.6246v1"
},{
    "category": "cs.GT", 
    "author": "Kalyanmoy Deb", 
    "title": "Multi-objective Stackelberg Game Between a Regulating Authority and a   Mining Company: A Case Study in Environmental Economics", 
    "publish": "2013-07-23T21:34:11Z", 
    "summary": "Bilevel programming problems are often found in practice. In this paper, we\nhandle one such bilevel application problem from the domain of environmental\neconomics. The problem is a Stakelberg game with multiple objectives at the\nupper level, and a single objective at the lower level. The leader in this case\nis the regulating authority, and it tries to maximize its total tax revenue\nover multiple periods while trying to minimize the environmental damages caused\nby a mining company. The follower is the mining company whose sole objective is\nto maximize its total profit over multiple periods under the limitations set by\nthe leader. The solution to the model contains the optimal taxation and\nextraction decisions to be made by the players in each of the time periods. We\nconstruct a simplistic model for the Stackelberg game and provide an analytical\nsolution to the problem. Thereafter, the model is extended to incorporate\nrealism and is solved using a bilevel evolutionary algorithm capable of\nhandling multiple objectives.", 
    "link": "http://arxiv.org/pdf/1307.6250v1", 
    "arxiv-id": "1307.6250v1"
},{
    "category": "cs.GT", 
    "author": "Frederic Prost", 
    "title": "Gardner's Minichess Variant is solved", 
    "publish": "2013-07-26T18:11:38Z", 
    "summary": "A 5x5 board is the smallest board on which one can set up all kind of chess\npieces as a start position. We consider Gardner's minichess variant in which\nall pieces are set as in a standard chessboard (from Rook to King). This game\nhas roughly 9x10^{18} legal positions and is comparable in this respect with\ncheckers. We weakly solve this game, that is we prove its game-theoretic value\nand give a strategy to draw against best play for White and Black sides. Our\napproach requires surprisingly small computing power. We give a human readable\nproof. The way the result is obtained is generic and could be generalized to\nbigger chess settings or to other games.", 
    "link": "http://arxiv.org/pdf/1307.7118v1", 
    "arxiv-id": "1307.7118v1"
},{
    "category": "cs.GT", 
    "author": "Jared Saia", 
    "title": "The Power of Mediation in an Extended El Farol Game", 
    "publish": "2013-07-26T18:40:47Z", 
    "summary": "A mediator implements a correlated equilibrium when it proposes a strategy to\neach player confidentially such that the mediator's proposal is the best\ninterest for every player to follow. In this paper, we present a mediator that\nimplements the best correlated equilibrium for an extended El Farol game with\nsymmetric players. The extended El Farol game we consider incorporates both\nnegative and positive network effects.\n  We study the degree to which this type of mediator can decrease the overall\nsocial cost. In particular, we give an exact characterization of Mediation\nValue (MV) and Enforcement Value (EV) for this game. MV is the ratio of the\nminimum social cost over all Nash equilibria to the minimum social cost over\nall mediators, and EV is the ratio of the minimum social cost over all\nmediators to the optimal social cost. This sort of exact characterization is\nuncommon for games with both kinds of network effects. An interesting outcome\nof our results is that both the MV and EV values can be unbounded for our game.", 
    "link": "http://arxiv.org/pdf/1307.7122v2", 
    "arxiv-id": "1307.7122v2"
},{
    "category": "cs.GT", 
    "author": "Lena Schend", 
    "title": "Complexity of Manipulation, Bribery, and Campaign Management in Bucklin   and Fallback Voting", 
    "publish": "2013-07-28T00:24:35Z", 
    "summary": "A central theme in computational social choice is to study the extent to\nwhich voting systems computationally resist manipulative attacks seeking to\ninfluence the outcome of elections, such as manipulation (i.e., strategic\nvoting), control, and bribery. Bucklin and fallback voting are among the voting\nsystems with the broadest resistance (i.e., NP-hardness) to control attacks.\nHowever, only little is known about their behavior regarding manipulation and\nbribery attacks. We comprehensively investigate the computational resistance of\nBucklin and fallback voting for many of the common manipulation and bribery\nscenarios; we also complement our discussion by considering several campaign\nmanagement problems for Bucklin and fallback.", 
    "link": "http://arxiv.org/pdf/1307.7322v1", 
    "arxiv-id": "1307.7322v1"
},{
    "category": "cs.GT", 
    "author": "Yannai A. Gonczarowski", 
    "title": "Manipulation of Stable Matchings using Minimal Blacklists", 
    "publish": "2013-07-29T06:45:49Z", 
    "summary": "Gale and Sotomayor (1985) have shown that in the Gale-Shapley matching\nalgorithm (1962), the proposed-to side W (referred to as women there) can\nstrategically force the W-optimal stable matching as the M-optimal one by\ntruncating their preference lists, each woman possibly blacklisting all but one\nman. As Gusfield and Irving have already noted in 1989, no results are known\nregarding achieving this feat by means other than such preference-list\ntruncation, i.e. by also permuting preference lists.\n  We answer Gusfield and Irving's open question by providing tight upper bounds\non the amount of blacklists and their combined size, that are required by the\nwomen to force a given matching as the M-optimal stable matching, or, more\ngenerally, as the unique stable matching. Our results show that the coalition\nof all women can strategically force any matching as the unique stable\nmatching, using preference lists in which at most half of the women have\nnonempty blacklists, and in which the average blacklist size is less than 1.\nThis allows the women to manipulate the market in a manner that is far more\ninconspicuous, in a sense, than previously realized. When there are less women\nthan men, we show that in the absence of blacklists for men, the women can\nforce any matching as the unique stable matching without blacklisting anyone,\nwhile when there are more women than men, each to-be-unmatched woman may have\nto blacklist as many as all men. Together, these results shed light on the\nquestion of how much, if at all, do given preferences for one side a priori\nimpose limitations on the set of stable matchings under various conditions. All\nof the results in this paper are constructive, providing efficient algorithms\nfor calculating the desired strategies.", 
    "link": "http://arxiv.org/pdf/1307.7477v4", 
    "arxiv-id": "1307.7477v4"
},{
    "category": "cs.GT", 
    "author": "Merav Parter", 
    "title": "Braess's Paradox in Wireless Networks: The Danger of Improved Technology", 
    "publish": "2013-08-01T12:39:34Z", 
    "summary": "When comparing new wireless technologies, it is common to consider the effect\nthat they have on the capacity of the network (defined as the maximum number of\nsimultaneously satisfiable links). For example, it has been shown that giving\nreceivers the ability to do interference cancellation, or allowing transmitters\nto use power control, never decreases the capacity and can in certain cases\nincrease it by $\\Omega(\\log (\\Delta \\cdot P_{\\max}))$, where $\\Delta$ is the\nratio of the longest link length to the smallest transmitter-receiver distance\nand $P_{\\max}$ is the maximum transmission power. But there is no reason to\nexpect the optimal capacity to be realized in practice, particularly since\nmaximizing the capacity is known to be NP-hard. In reality, we would expect\nlinks to behave as self-interested agents, and thus when introducing a new\ntechnology it makes more sense to compare the values reached at game-theoretic\nequilibria than the optimum values.\n  In this paper we initiate this line of work by comparing various notions of\nequilibria (particularly Nash equilibria and no-regret behavior) when using a\nsupposedly \"better\" technology. We show a version of Braess's Paradox for all\nof them: in certain networks, upgrading technology can actually make the\nequilibria \\emph{worse}, despite an increase in the capacity. We construct\ninstances where this decrease is a constant factor for power control,\ninterference cancellation, and improvements in the SINR threshold ($\\beta$),\nand is $\\Omega(\\log \\Delta)$ when power control is combined with interference\ncancellation. However, we show that these examples are basically tight: the\ndecrease is at most O(1) for power control, interference cancellation, and\nimproved $\\beta$, and is at most $O(\\log \\Delta)$ when power control is\ncombined with interference cancellation.", 
    "link": "http://arxiv.org/pdf/1308.0173v2", 
    "arxiv-id": "1308.0173v2"
},{
    "category": "cs.GT", 
    "author": "Milan Vojnovic", 
    "title": "Incentives and Efficiency in Uncertain Collaborative Environments", 
    "publish": "2013-08-05T14:20:24Z", 
    "summary": "We consider collaborative systems where users make contributions across\nmultiple available projects and are rewarded for their contributions in\nindividual projects according to a local sharing of the value produced. This\nserves as a model of online social computing systems such as online Q&A forums\nand of credit sharing in scientific co-authorship settings. We show that the\nmaximum feasible produced value can be well approximated by simple local\nsharing rules where users are approximately rewarded in proportion to their\nmarginal contributions and that this holds even under incomplete information\nabout the player's abilities and effort constraints. For natural instances we\nshow almost 95% optimality at equilibrium. When players incur a cost for their\neffort, we identify a threshold phenomenon: the efficiency is a constant\nfraction of the optimal when the cost is strictly convex and decreases with the\nnumber of players if the cost is linear.", 
    "link": "http://arxiv.org/pdf/1308.0990v1", 
    "arxiv-id": "1308.0990v1"
},{
    "category": "cs.GT", 
    "author": "Jinshan Zhang", 
    "title": "Pricing Ad Slots with Consecutive Multi-unit Demand", 
    "publish": "2013-08-06T19:22:07Z", 
    "summary": "We consider the optimal pricing problem for a model of the rich media\nadvertisement market, as well as other related applications. In this market,\nthere are multiple buyers (advertisers), and items (slots) that are arranged in\na line such as a banner on a website. Each buyer desires a particular number of\n{\\em consecutive} slots and has a per-unit-quality value $v_i$ (dependent on\nthe ad only) while each slot $j$ has a quality $q_j$ (dependent on the position\nonly such as click-through rate in position auctions). Hence, the valuation of\nthe buyer $i$ for item $j$ is $v_iq_j$. We want to decide the allocations and\nthe prices in order to maximize the total revenue of the market maker.\n  A key difference from the traditional position auction is the advertiser's\nrequirement of a fixed number of consecutive slots. Consecutive slots may be\nneeded for a large size rich media ad. We study three major pricing mechanisms,\nthe Bayesian pricing model, the maximum revenue market equilibrium model and an\nenvy-free solution model. Under the Bayesian model, we design a polynomial time\ncomputable truthful mechanism which is optimum in revenue. For the market\nequilibrium paradigm, we find a polynomial time algorithm to obtain the maximum\nrevenue market equilibrium solution. In envy-free settings, an optimal solution\nis presented when the buyers have the same demand for the number of consecutive\nslots. We conduct a simulation that compares the revenues from the above\nschemes and gives convincing results.", 
    "link": "http://arxiv.org/pdf/1308.1382v1", 
    "arxiv-id": "1308.1382v1"
},{
    "category": "cs.GT", 
    "author": "Lasse Kliemann", 
    "title": "The Price of Anarchy in Bilateral Network Formation in an Adversary   Model", 
    "publish": "2013-08-08T12:56:10Z", 
    "summary": "We study network formation with the bilateral link formation rule (Jackson\nand Wolinsky 1996) with $n$ players and link cost $\\alpha>0$. After the network\nis built, an adversary randomly destroys one link according to a certain\nprobability distribution. Cost for player $v$ incorporates the expected number\nof players to which $v$ will become disconnected. This model was previously\nstudied for unilateral link formation (K. 2011).\n  We prove existence of pairwise Nash equilibria under moderate assumptions on\nthe adversary and $n\\geq 9$. As the main result, we prove bounds on the price\nof anarchy for two special adversaries: one destroys a link chosen uniformly at\nrandom, while the other destroys a link that causes a maximum number of player\npairs to be separated. We prove bounds tight up to constants, namely $O(1)$ for\none adversary (if $\\alpha>1/2$), and $\\Theta(n)$ for the other (if $\\alpha>2$\nconsidered constant and $n \\geq 9$). The latter is the worst that can happen\nfor any adversary in this model (if $\\alpha=\\Omega(1)$).", 
    "link": "http://arxiv.org/pdf/1308.1832v1", 
    "arxiv-id": "1308.1832v1"
},{
    "category": "cs.GT", 
    "author": "Guido Sch\u00e4fer", 
    "title": "Bounding the Inefficiency of Altruism Through Social Contribution Games", 
    "publish": "2013-08-12T09:13:07Z", 
    "summary": "We introduce a new class of games, called social contribution games (SCGs),\nwhere each player's individual cost is equal to the cost he induces on society\nbecause of his presence. Our results reveal that SCGs constitute useful\nabstractions of altruistic games when it comes to the analysis of the robust\nprice of anarchy. We first show that SCGs are altruism-independently smooth,\ni.e., the robust price of anarchy of these games remains the same under\narbitrary altruistic extensions. We then devise a general reduction technique\nthat enables us to reduce the problem of establishing smoothness for an\naltruistic extension of a base game to a corresponding SCG. Our reduction\napplies whenever the base game relates to a canonical SCG by satisfying a\nsimple social contribution boundedness property. As it turns out, several\nwell-known games satisfy this property and are thus amenable to our reduction\ntechnique. Examples include min-sum scheduling games, congestion games, second\nprice auctions and valid utility games. Using our technique, we derive mostly\ntight bounds on the robust price of anarchy of their altruistic extensions. For\nthe majority of the mentioned game classes, the results extend to the more\ndifferentiated friendship setting. As we show, our reduction technique covers\nthis model if the base game satisfies three additional natural properties.", 
    "link": "http://arxiv.org/pdf/1308.2497v1", 
    "arxiv-id": "1308.2497v1"
},{
    "category": "cs.GT", 
    "author": "Vittorio Bil\u00f2", 
    "title": "On Linear Congestion Games with Altruistic Social Context", 
    "publish": "2013-08-15T07:47:55Z", 
    "summary": "We study the issues of existence and inefficiency of pure Nash equilibria in\nlinear congestion games with altruistic social context, in the spirit of the\nmodel recently proposed by de Keijzer {\\em et al.} \\cite{DSAB13}. In such a\nframework, given a real matrix $\\Gamma=(\\gamma_{ij})$ specifying a particular\nsocial context, each player $i$ aims at optimizing a linear combination of the\npayoffs of all the players in the game, where, for each player $j$, the\nmultiplicative coefficient is given by the value $\\gamma_{ij}$. We give a broad\ncharacterization of the social contexts for which pure Nash equilibria are\nalways guaranteed to exist and provide tight or almost tight bounds on their\nprices of anarchy and stability. In some of the considered cases, our\nachievements either improve or extend results previously known in the\nliterature.", 
    "link": "http://arxiv.org/pdf/1308.3329v1", 
    "arxiv-id": "1308.3329v1"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "Game Theory with Translucent Players", 
    "publish": "2013-08-17T12:29:53Z", 
    "summary": "A traditional assumption in game theory is that players are opaque to one\nanother---if a player changes strategies, then this change in strategies does\nnot affect the choice of other players' strategies. In many situations this is\nan unrealistic assumption. We develop a framework for reasoning about games\nwhere the players may be translucent to one another; in particular, a player\nmay believe that if she were to change strategies, then the other player would\nalso change strategies. Translucent players may achieve significantly more\nefficient outcomes than opaque ones.\n  Our main result is a characterization of strategies consistent with\nappropriate analogues of common belief of rationality. Common Counterfactual\nBelief of Rationality (CCBR) holds if (1) everyone is rational, (2) everyone\ncounterfactually believes that everyone else is rational (i.e., all players i\nbelieve that everyone else would still be rational even if $i$ were to switch\nstrategies), (3) everyone counterfactually believes that everyone else is\nrational, and counterfactually believes that everyone else is rational, and so\non. CCBR characterizes the set of strategies surviving iterated removal of\nminimax dominated strategies, where a strategy s for player i is minimax\ndominated by s' if the worst-case payoff for i using s' is better than the best\npossible payoff using s.", 
    "link": "http://arxiv.org/pdf/1308.3778v1", 
    "arxiv-id": "1308.3778v1"
},{
    "category": "cs.GT", 
    "author": "Paul Spirakis", 
    "title": "The Price of Anarchy is Unbounded for Congestion Games with   Superpolynomial Latency Costs", 
    "publish": "2013-08-19T19:14:14Z", 
    "summary": "We consider non-cooperative unsplittable congestion games where players share\nresources, and each player's strategy is pure and consists of a subset of the\nresources on which it applies a fixed weight. Such games represent unsplittable\nrouting flow games and also job allocation games. The congestion of a resource\nis the sum of the weights of the players that use it and the player's cost\nfunction is the sum of the utilities of the resources on its strategy. The\nsocial cost is the total weighted sum of the player's costs. The quality of\nNash equilibria is determined by the price of anarchy ($PoA$) which expresses\nhow much worse is the social outcome in the worst equilibrium versus the\noptimal coordinated solution. In the literature the predominant work has only\nbeen on games with polynomial utility costs, where it has been proven that the\nprice of anarchy is bounded by the degree of the polynomial. However, no\nresults exist on general bounds for non-polynomial utility functions.\n  Here, we consider general versions of these games in which the utility of\neach resource is an arbitrary non-decreasing function of the congestion. In\nparticular, we consider a large family of superpolynomial utility functions\nwhich are asymptotically larger than any polynomial. We demonstrate that for\nevery such function there exist games for which the price of anarchy is\nunbounded and increasing with the number of players (even if they have\ninfinitesimal weights) while network resources remain fixed. We give tight\nlower and upper bounds which show this dependence on the number of players.\nFurthermore we provide an exact characterization of the $PoA$ of all congestion\ngames whose utility costs are bounded above by a polynomial function.\nHeretofore such results existed only for games with polynomial cost functions.", 
    "link": "http://arxiv.org/pdf/1308.4101v1", 
    "arxiv-id": "1308.4101v1"
},{
    "category": "cs.GT", 
    "author": "Vijay V. Vazirani", 
    "title": "On Computability of Equilibria in Markets with Production", 
    "publish": "2013-08-24T01:20:22Z", 
    "summary": "Although production is an integral part of the Arrow-Debreu market model,\nmost of the work in theoretical computer science has so far concentrated on\nmarkets without production, i.e., the exchange economy. This paper takes a\nsignificant step towards understanding computational aspects of markets with\nproduction.\n  We first define the notion of separable, piecewise-linear concave (SPLC)\nproduction by analogy with SPLC utility functions. We then obtain a linear\ncomplementarity problem (LCP) formulation that captures exactly the set of\nequilibria for Arrow-Debreu markets with SPLC utilities and SPLC production,\nand we give a complementary pivot algorithm for finding an equilibrium. This\nsettles a question asked by Eaves in 1975 of extending his complementary pivot\nalgorithm to markets with production.\n  Since this is a path-following algorithm, we obtain a proof of membership of\nthis problem in PPAD, using Todd, 1976. We also obtain an elementary proof of\nexistence of equilibrium (i.e., without using a fixed point theorem),\nrationality, and oddness of the number of equilibria. We further give a proof\nof PPAD-hardness for this problem and also for its restriction to markets with\nlinear utilities and SPLC production. Experiments show that our algorithm runs\nfast on randomly chosen examples, and unlike previous approaches, it does not\nsuffer from issues of numerical instability. Additionally, it is strongly\npolynomial when the number of goods or the number of agents and firms is\nconstant. This extends the result of Devanur and Kannan (2008) to markets with\nproduction.\n  Finally, we show that an LCP-based approach cannot be extended to PLC\n(non-separable) production, by constructing an example which has only\nirrational equilibria.", 
    "link": "http://arxiv.org/pdf/1308.5272v2", 
    "arxiv-id": "1308.5272v2"
},{
    "category": "cs.GT", 
    "author": "Ron Peretz", 
    "title": "Small-Support Approximate Correlated Equilibria", 
    "publish": "2013-08-28T01:39:05Z", 
    "summary": "We prove the existence of approximate correlated equilibrium of support size\npolylogarithmic in the number of players and the number of actions per player.\nIn particular, using the probabilistic method, we show that there exists a\nmultiset of polylogarithmic size such that the uniform distribution over this\nmultiset forms an approximate correlated equilibrium. Along similar lines, we\nestablish the existence of approximate coarse correlated equilibrium with\nlogarithmic support.\n  We complement these results by considering the computational complexity of\ndetermining small-support approximate equilibria. We show that random sampling\ncan be used to efficiently determine an approximate coarse correlated\nequilibrium with logarithmic support. But, such a tight result does not hold\nfor correlated equilibrium, i.e., sampling might generate an approximate\ncorrelated equilibrium of support size \\Omega(m) where m is the number of\nactions per player. Finally, we show that finding an exact correlated\nequilibrium with smallest possible support is NP-hard under Cook reductions,\neven in the case of two-player zero-sum games.", 
    "link": "http://arxiv.org/pdf/1308.6025v1", 
    "arxiv-id": "1308.6025v1"
},{
    "category": "cs.GT", 
    "author": "Michael Wooldridge", 
    "title": "The Shapley Axiomatization for Values in Partition Function Games", 
    "publish": "2013-08-28T19:16:05Z", 
    "summary": "One of the long-debated issues in coalitional game theory is how to extend\nthe Shapley value to games with externalities (partition-function games). When\nexternalities are present, not only can a player's marginal contribution - a\ncentral notion to the Shapley value - be defined in a variety of ways, but it\nis also not obvious which axiomatization should be used. Consequently, a number\nof authors extended the Shapley value using complex and often unintuitive\naxiomatizations. Furthermore, no algorithm to approximate any extension of the\nShapley value to partition-function games has been proposed to date. Given this\nbackground, we prove in this paper that, for any well-defined measure of\nmarginal contribution, Shapley's original four axioms imply a unique value for\ngames with externalities. As an consequence of this general theorem, we show\nthat values proposed by Macho-Stadler et al., McQuillin and Bolger can be\nderived from Shapley's axioms. Building upon our analysis of marginal\ncontribution, we develop a general algorithm to approximate extensions of the\nShapley value to games with externalities using a Monte Carlo simulation\ntechnique.", 
    "link": "http://arxiv.org/pdf/1308.6255v1", 
    "arxiv-id": "1308.6255v1"
},{
    "category": "cs.GT", 
    "author": "Laurent Perrussel", 
    "title": "Decomposing Truthful and Competitive Online Double Auctions", 
    "publish": "2013-11-01T14:45:54Z", 
    "summary": "In this paper, we study online double auctions, where multiple sellers and\nmultiple buyers arrive and depart dynamically to exchange one commodity. We\nshow that there is no deterministic online double auction that is truthful and\ncompetitive for maximising social welfare in an adversarial model. However,\ngiven the prior information that sellers are patient and the demand is not more\nthan the supply, a deterministic and truthful greedy mechanism is actually\n2-competitive, i.e. it guarantees that the social welfare of its allocation is\nat least half of the optimal one achievable offline. Moreover, if the number of\nincoming buyers is predictable, we demonstrate that an online double auction\ncan be reduced to an online one-sided auction, and the truthfulness and\ncompetitiveness of the reduced online double auction follow that of the online\none-sided auction. Notably, by using the reduction, we find a truthful\nmechanism that is almost 1-competitive, when buyers arrive randomly. Finally,\nwe argue that these mechanisms also have a promising applicability in more\ngeneral settings without assuming that sellers are patient, by decomposing a\nmarket into multiple sub-markets.", 
    "link": "http://arxiv.org/pdf/1311.0198v1", 
    "arxiv-id": "1311.0198v1"
},{
    "category": "cs.GT", 
    "author": "Edward W. Piotrowski", 
    "title": "When \"I cut, you choose\" method implies intransitivity", 
    "publish": "2013-10-31T18:43:03Z", 
    "summary": "There is a common belief that humans and many animals follow transitive\ninference (choosing A over C on the basis of knowing that A is better than B\nand B is better than C). Transitivity seems to be the essence of rational\nchoice. We present a theoretical model of a repeated game in which the players\nmake a choice between three goods (e.g. food). The rules of the game refer to\nthe simple procedure of fair division among two players, known as the \"I cut,\nyou choose\" mechanism which has been widely discussed in the literature. In\nthis game one of the players has to make intransitive choices in order to\nachieve the optimal result (for him/her and his/her co-player). The point is\nthat an intransitive choice can be rational. Previously, an increase in the\nsignificance of intransitive strategies was achieved by referring to models of\nquantum games. We show that \\textit{relevant intransitive strategies} also\nappear in the classic description of decision algorithms.", 
    "link": "http://arxiv.org/pdf/1311.0803v3", 
    "arxiv-id": "1311.0803v3"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Bidding Games and Efficient Allocations", 
    "publish": "2013-11-04T22:03:16Z", 
    "summary": "Bidding games are extensive form games, where in each turn players bid in\norder to determine who will play next. Zero-sum bidding games (also known as\nRichman games) have been extensively studied, focusing on the fraction of the\ninitial budget that can guaranty the victory of each player [Lazarus et al.'99,\nDevelin and Payne'10].\n  We extend the theory of bidding games to general-sum two player games,\nshowing the existence of pure subgame-perfect Nash equilibria (PSPE), and\nstudying their properties.\n  We show that if the underlying game has the form of a binary tree (only two\nactions available to the players in each node), then there exists a natural\nPSPE with the following highly desirable properties: (a) players' utility is\nweakly monotone in their budget; (b) a Pareto-efficient outcome is reached for\nany initial budget; and (c) for any Pareto-efficient outcome there is an\ninitial budget s.t. this outcome is attained. In particular, we can assign the\nbudget so as to implement the outcome with maximum social welfare, maximum\nEgalitarian welfare, etc.\n  We show implications of this result for combinatorial bargaining. In\nparticular, we show that the PSPE above is fair, in the sense that a player\nwith a fraction of X% of the total budget prefers her allocation to X% of the\npossible allocations.\n  In addition, we discuss the computational challenges of bidding games, and\nprovide a polynomial-time algorithm to compute the PSPE.", 
    "link": "http://arxiv.org/pdf/1311.0913v4", 
    "arxiv-id": "1311.0913v4"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "On the Efficiency of the Walrasian Mechanism", 
    "publish": "2013-11-04T23:21:11Z", 
    "summary": "Central results in economics guarantee the existence of efficient equilibria\nfor various classes of markets. An underlying assumption in early work is that\nagents are price-takers, i.e., agents honestly report their true demand in\nresponse to prices. A line of research in economics, initiated by Hurwicz\n(1972), is devoted to understanding how such markets perform when agents are\nstrategic about their demands. This is captured by the \\emph{Walrasian\nMechanism} that proceeds by collecting reported demands, finding clearing\nprices in the \\emph{reported} market via an ascending price t\\^{a}tonnement\nprocedure, and returns the resulting allocation. Similar mechanisms are used,\nfor example, in the daily opening of the New York Stock Exchange and the call\nmarket for copper and gold in London.\n  In practice, it is commonly observed that agents in such markets reduce their\ndemand leading to behaviors resembling bargaining and to inefficient outcomes.\nWe ask how inefficient the equilibria can be. Our main result is that the\nwelfare of every pure Nash equilibrium of the Walrasian mechanism is at least\none quarter of the optimal welfare, when players have gross substitute\nvaluations and do not overbid. Previous analysis of the Walrasian mechanism\nhave resorted to large market assumptions to show convergence to efficiency in\nthe limit. Our result shows that approximate efficiency is guaranteed\nregardless of the size of the market.", 
    "link": "http://arxiv.org/pdf/1311.0924v1", 
    "arxiv-id": "1311.0924v1"
},{
    "category": "cs.GT", 
    "author": "Carmine Ventre", 
    "title": "Decentralized Dynamics for Finite Opinion Games", 
    "publish": "2013-11-07T08:57:37Z", 
    "summary": "Game theory studies situations in which strategic players can modify the\nstate of a given system, due to the absence of a central authority. Solution\nconcepts, such as Nash equilibrium, are defined to predict the outcome of such\nsituations. In multi-player settings, it has been pointed out that to be\nrealistic, a solution concept should be obtainable via processes that are\ndecentralized and reasonably simple. Accordingly we look at the computation of\nsolution concepts by means of decentralized dynamics. These are algorithms in\nwhich players move in turns to improve their own utility and the hope is that\nthe system reaches an \"equilibrium\" quickly.\n  We study these dynamics for the class of opinion games, recently introduced\nby Bindel et al. [Bindel et al., FOCS2011]. These are games, important in\neconomics and sociology, that model the formation of an opinion in a social\nnetwork. We study best-response dynamics and show upper and lower bounds on the\nconvergence to Nash equilibria. We also study a noisy version of best-response\ndynamics, called logit dynamics, and prove a host of results about its\nconvergence rate as the noise in the system varies. To get these results, we\nuse a variety of techniques developed to bound the mixing time of Markov\nchains, including coupling, spectral characterizations and bottleneck ratio.", 
    "link": "http://arxiv.org/pdf/1311.1610v1", 
    "arxiv-id": "1311.1610v1"
},{
    "category": "cs.GT", 
    "author": "Adam Wierman", 
    "title": "On the Existence of Low-Rank Explanations for Mixed Strategy Behavior", 
    "publish": "2013-11-12T01:58:09Z", 
    "summary": "Nash equilibrium is used as a model to explain the observed behavior of\nplayers in strategic settings. For example, in many empirical applications we\nobserve player behavior, and the problem is to determine if there exist payoffs\nfor the players for which the equilibrium corresponds to observed player\nbehavior. Computational complexity of Nash equilibria is an important\nconsideration in this framework. If the instance of the model that explains\nobserved player behavior requires players to have solved a computationally hard\nproblem, then the explanation provided is questionable. In this paper we\nprovide conditions under which Nash equilibrium is a reasonable explanation for\nstrategic behavior, i.e., conditions under which observed behavior of players\ncan be explained by games in which Nash equilibria are easy to compute. We\nidentify three structural conditions and show that if the data set of observed\nbehavior satisfies any of these conditions, then it is consistent with payoff\nmatrices for which the observed Nash equilibria could have been computed\nefficiently. Our conditions admit large and structurally complex data sets of\nobserved behavior, showing that even with complexity considerations, Nash\nequilibrium is often a reasonable model.", 
    "link": "http://arxiv.org/pdf/1311.2655v2", 
    "arxiv-id": "1311.2655v2"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Draft Auctions", 
    "publish": "2013-11-12T15:59:15Z", 
    "summary": "We introduce draft auctions, which is a sequential auction format where at\neach iteration players bid for the right to buy items at a fixed price. We show\nthat draft auctions offer an exponential improvement in social welfare at\nequilibrium over sequential item auctions where predetermined items are\nauctioned at each time step. Specifically, we show that for any subadditive\nvaluation the social welfare at equilibrium is an $O(\\log^2(m))$-approximation\nto the optimal social welfare, where $m$ is the number of items. We also\nprovide tighter approximation results for several subclasses. Our welfare\nguarantees hold for Bayes-Nash equilibria and for no-regret learning outcomes,\nvia the smooth-mechanism framework. Of independent interest, our techniques\nshow that in a combinatorial auction setting, efficiency guarantees of a\nmechanism via smoothness for a very restricted class of cardinality valuations,\nextend with a small degradation, to subadditive valuations, the largest\ncomplement-free class of valuations. Variants of draft auctions have been used\nin practice and have been experimentally shown to outperform other auctions.\nOur results provide a theoretical justification.", 
    "link": "http://arxiv.org/pdf/1311.2820v1", 
    "arxiv-id": "1311.2820v1"
},{
    "category": "cs.GT", 
    "author": "Paolo Turrini", 
    "title": "Endogenous games with goals: side-payments among goal-directed   artificial agents", 
    "publish": "2013-11-13T11:31:39Z", 
    "summary": "Artificial agents are typically oriented to the realization of an externally\nassigned task and try to optimize over secondary aspects of plan execution such\ntime lapse or power consumption, technically displaying a quasi-dichotomous\npreference relation. Boolean games have been developed as a paradigm for\nmodelling societies of agents with this type of preference. In boolean games\nagents exercise control over propositional variables and strive to achieve a\ngoal formula whose realization might require the opponents' cooperation.\nRecently, a theory of incentive engineering for such games has been devised,\nwhere an external authority steers the outcome of the game towards certain\ndesirable properties consistent with players' goals, by imposing a taxation\nmechanism on the players that makes the outcomes that do not comply with those\nproperties less appealing to them. The present contribution stems from a\ncomplementary perspective and studies, instead, how games with\nquasi-dichotomous preferences can be transformed from inside, rather than from\noutside, by endowing players with the possibility of sacrificing a part of\ntheir payoff received at a certain outcome in order to convince other players\nto play a certain strategy. Concretely we explore the properties of endogenous\ngames with goals, obtained coupling strategic games with goals, a\ngeneralization of boolean games, with the machinery of endogenous games coming\nfrom game theory. We analyze equilibria in those structures, showing the\npreconditions needed for desirable outcomes to be achieved without external\nintervention. What our results show is that endogenous games with goals display\nspecific irreducible features - with respect to what already known for\nendogenous games - which makes them worth studying in their own sake.", 
    "link": "http://arxiv.org/pdf/1311.3088v2", 
    "arxiv-id": "1311.3088v2"
},{
    "category": "cs.GT", 
    "author": "Jean-Fran\u00e7ois Raskin", 
    "title": "Doomsday Equilibria for Omega-Regular Games", 
    "publish": "2013-11-13T18:18:51Z", 
    "summary": "Two-player games on graphs provide the theoretical frame- work for many\nimportant problems such as reactive synthesis. While the traditional study of\ntwo-player zero-sum games has been extended to multi-player games with several\nnotions of equilibria, they are decidable only for perfect-information games,\nwhereas several applications require imperfect-information games. In this paper\nwe propose a new notion of equilibria, called doomsday equilibria, which is a\nstrategy profile such that all players satisfy their own objective, and if any\ncoalition of players deviates and violates even one of the players objective,\nthen the objective of every player is violated. We present algorithms and\ncomplexity results for deciding the existence of doomsday equilibria for\nvarious classes of omega-regular objectives, both for imperfect-information\ngames, and for perfect-information games. We provide optimal complexity bounds\nfor imperfect-information games, and in most cases for perfect-information\ngames.", 
    "link": "http://arxiv.org/pdf/1311.3238v1", 
    "arxiv-id": "1311.3238v1"
},{
    "category": "cs.GT", 
    "author": "Shai Vardi", 
    "title": "Local computation mechanism design", 
    "publish": "2013-11-15T18:21:56Z", 
    "summary": "We introduce the notion of Local Computation Mechanism Design - designing\ngame theoretic mechanisms which run in polylogarithmic time and space. Local\ncomputation mechanisms reply to each query in polylogarithmic time and space,\nand the replies to different queries are consistent with the same global\nfeasible solution. In addition, the computation of the payments is also done in\npolylogarithmic time and space. Furthermore, the mechanisms need to maintain\nincentive compatibility with respect to the allocation and payments.\n  We present local computation mechanisms for a variety of classical\ngame-theoretical problems: 1. stable matching, 2. job scheduling, 3.\ncombinatorial auctions for unit-demand and k-minded bidders, and 4. the housing\nallocation problem.\n  For stable matching, some of our techniques may have general implications.\nSpecifically, we show that when the men's preference lists are bounded, we can\nachieve an arbitrarily good approximation to the stable matching within a fixed\nnumber of iterations of the Gale-Shapley algorithm.", 
    "link": "http://arxiv.org/pdf/1311.3939v2", 
    "arxiv-id": "1311.3939v2"
},{
    "category": "cs.GT", 
    "author": "Samira Samadi", 
    "title": "Submodular Welfare Maximization", 
    "publish": "2013-11-21T22:35:21Z", 
    "summary": "An overview of different variants of the submodular welfare maximization\nproblem in combinatorial auctions. In particular, I studied the existing\nalgorithmic and game theoretic results for submodular welfare maximization\nproblem and its applications in other areas such as social networks.", 
    "link": "http://arxiv.org/pdf/1311.5603v1", 
    "arxiv-id": "1311.5603v1"
},{
    "category": "cs.GT", 
    "author": "Stefan Napel", 
    "title": "The Prediction value", 
    "publish": "2013-11-22T12:05:28Z", 
    "summary": "We introduce the prediction value (PV) as a measure of players' informational\nimportance in probabilistic TU games. The latter combine a standard TU game and\na probability distribution over the set of coalitions. Player $i$'s prediction\nvalue equals the difference between the conditional expectations of $v(S)$ when\n$i$ cooperates or not. We characterize the prediction value as a special member\nof the class of (extended) values which satisfy anonymity, linearity and a\nconsistency property. Every $n$-player binomial semivalue coincides with the PV\nfor a particular family of probability distributions over coalitions. The PV\ncan thus be regarded as a power index in specific cases. Conversely, some\nsemivalues -- including the Banzhaf but not the Shapley value -- can be\ninterpreted in terms of informational importance.", 
    "link": "http://arxiv.org/pdf/1311.5728v1", 
    "arxiv-id": "1311.5728v1"
},{
    "category": "cs.GT", 
    "author": "Andy Lewis-Pye", 
    "title": "Tipping Points in Schelling Segregation", 
    "publish": "2013-11-23T00:00:50Z", 
    "summary": "One of the earliest agent-based economical models, Schelling's spacial\nproximity model illustrated how global segregation can emerge, often unwanted,\nfrom the actions of agents of two races acting in accordance with their\nindividual local preferences. Here a 1-dimensional unperturbed variant of the\nmodel is studied, which is additionally open in the sense that agents may enter\nand exit the model. Following the authors' previous work in [1] and that of\nBrandt, Immorlica, Kamath, and Kleinberg in [2], rigorous results are\nestablished, whose statements are asymptotic in both the model and\nneighbourhood sizes.\n  The current model's openness allows one race or the other to take over almost\neverywhere in a measure-theoretic sense. Tipping points are identified between\nthe two regions of takeover and the region of staticity, in terms of the\nparameters of the model. In a significant generalization from previous work,\nthe parameters comprise the initial proportions of the two races, along with\nindependent values of the tolerance for each race.", 
    "link": "http://arxiv.org/pdf/1311.5934v3", 
    "arxiv-id": "1311.5934v3"
},{
    "category": "cs.GT", 
    "author": "Pingzhong Tang", 
    "title": "Optimal mechanisms with simple menus", 
    "publish": "2013-11-23T07:03:32Z", 
    "summary": "We consider optimal mechanism design for the case with one buyer and two\nitems. The buyer's valuations towards the two items are independent and\nadditive. In this setting, optimal mechanism is unknown for general valuation\ndistributions. We obtain two categories of structural results that shed light\non the optimal mechanisms.\n  The first category of results state that, under certain mild condition, the\noptimal mechanism has a monotone menu. In other words, in the menu that\nrepresents the optimal mechanism, as payment increases, the allocation\nprobabilities for both items increase simultaneously. Applying this theorem, we\nderive a version of revenue monotonicity theorem that states stochastically\nsuperior distributions yield more revenue. Moreover, our theorem subsumes a\nprevious result regarding sufficient conditions under which bundling is\noptimal. The second category of results state that, under certain conditions,\nthe optimal mechanisms have few menu items. Our first result in this category\nsays, for certain distributions, the optimal menu contains at most 4 items. The\ncondition admits power (including uniform) density functions. Based on a\nsimilar proof of this result, we are able to obtain a wide class of\ndistributions where bundling is optimal. Our second result in this category\nworks for a weaker condition, under which the optimal menu contains at most 6\nitems. This condition includes exponential density functions. Our last result\nin this category works for unit-demand setting. It states that, for uniform\ndistributions, the optimal menu contains at most 5 items. All these results are\nin sharp contrast to Hart and Nisan's recent result that finite-sized menu\ncannot guarantee any positive fraction of optimal revenue for correlated\nvaluation distributions.", 
    "link": "http://arxiv.org/pdf/1311.5966v2", 
    "arxiv-id": "1311.5966v2"
},{
    "category": "cs.GT", 
    "author": "Jiajun Sun", 
    "title": "Privacy-Preserving Verifiable Incentive Mechanism for Crowdsourcing   Market Applications", 
    "publish": "2013-11-25T08:35:37Z", 
    "summary": "Recently, a novel class of incentive mechanisms is proposed to attract\nextensive users to truthfully participate in crowd sensing applications with a\ngiven budget constraint. The class mechanisms also bring good service quality\nfor the requesters in crowd sensing applications. Although it is so important,\nthere still exists many verification and privacy challenges, including users'\nbids and subtask information privacy and identification privacy, winners' set\nprivacy of the platform, and the security of the payment outcomes. In this\npaper, we present a privacy-preserving verifiable incentive mechanism for crowd\nsensing applications with the budget constraint, not only to explore how to\nprotect the privacies of users and the platform, but also to make the\nverifiable payment correct between the platform and users for crowd sensing\napplications. Results indicate that our privacy-preserving verifiable incentive\nmechanism achieves the same results as the generic one without privacy\npreservation.", 
    "link": "http://arxiv.org/pdf/1311.6230v7", 
    "arxiv-id": "1311.6230v7"
},{
    "category": "cs.GT", 
    "author": "Tie-Yan Liu", 
    "title": "$K$-anonymous Signaling Scheme", 
    "publish": "2013-11-26T12:20:24Z", 
    "summary": "We incorporate signaling scheme into Ad Auction setting, to achieve better\nwelfare and revenue while protect users' privacy. We propose a new\n\\emph{$K$-anonymous signaling scheme setting}, prove the hardness of the\ncorresponding welfare/revenue maximization problem, and finally propose the\nalgorithms to approximate the optimal revenue or welfare.", 
    "link": "http://arxiv.org/pdf/1311.6638v2", 
    "arxiv-id": "1311.6638v2"
},{
    "category": "cs.GT", 
    "author": "Romain Brenguier", 
    "title": "Robust Equilibria in Concurrent Games", 
    "publish": "2013-11-29T20:15:41Z", 
    "summary": "We study the problem of finding robust equilibria in multiplayer concurrent\ngames with mean payoff objectives. A $(k,t)$-robust equilibrium is a strategy\nprofile such that no coalition of size $k$ can improve the payoff of one its\nmember by deviating, and no coalition of size $t$ can decrease the payoff of\nother players. We are interested in pure equilibria, that is, solutions that\ncan be implemented using non-randomized strategies. We suggest a general\ntransformation from multiplayer games to two-player games such that pure\nequilibria in the first game correspond to winning strategies in the second\none. We then devise from this transformation, an algorithm which computes\nequilibria in mean-payoff games. Robust equilibria in mean-payoff games reduce\nto winning strategies in multidimensional mean-payoff games for some threshold\nsatisfying some constraints. We then show that the existence of such equilibria\ncan be decided in polynomial space, and that the decision problem is\nPSPACE-complete.", 
    "link": "http://arxiv.org/pdf/1311.7683v7", 
    "arxiv-id": "1311.7683v7"
},{
    "category": "cs.GT", 
    "author": "Sergey Kuniavsky", 
    "title": "Minimum Price in Search Model", 
    "publish": "2014-02-03T16:04:19Z", 
    "summary": "This paper investigates the effects of a low bound price. To do so, a popular\nand empirically proven model (Stahl (89') \\cite{Stahl89}) is used. The model is\nextended to include an exogenously given bound on prices sellers can offer,\nexcluding prices below such bound. The finding are rather surprising - when the\nbound is set sufficiently high expected price offered (EPO) by sellers drops\nsignificantly. The result seem to be robust in the parameters of the model, and\ndriven by the information provided to consumers by such legislation step: when\nthe limitation is set at sufficiently high levels all consumers anticipate the\nbound price, and searchers reject any price above it. As a result sellers offer\nthe bound price as a pure strategy.", 
    "link": "http://arxiv.org/pdf/1402.0410v1", 
    "arxiv-id": "1402.0410v1"
},{
    "category": "cs.GT", 
    "author": "Nicholas R. Jennings", 
    "title": "Efficient Computation of the Shapley Value for Game-Theoretic Network   Centrality", 
    "publish": "2014-02-04T01:36:18Z", 
    "summary": "The Shapley value---probably the most important normative payoff division\nscheme in coalitional games---has recently been advocated as a useful measure\nof centrality in networks. However, although this approach has a variety of\nreal-world applications (including social and organisational networks,\nbiological networks and communication networks), its computational properties\nhave not been widely studied. To date, the only practicable approach to compute\nShapley value-based centrality has been via Monte Carlo simulations which are\ncomputationally expensive and not guaranteed to give an exact answer. Against\nthis background, this paper presents the first study of the computational\naspects of the Shapley value for network centralities. Specifically, we develop\nexact analytical formulae for Shapley value-based centrality in both weighted\nand unweighted networks and develop efficient (polynomial time) and exact\nalgorithms based on them. We empirically evaluate these algorithms on two\nreal-life examples (an infrastructure network representing the topology of the\nWestern States Power Grid and a collaboration network from the field of\nastrophysics) and demonstrate that they deliver significant speedups over the\nMonte Carlo approach. For instance, in the case of unweighted networks our\nalgorithms are able to return the exact solution about 1600 times faster than\nthe Monte Carlo approximation, even if we allow for a generous 10% error margin\nfor the latter method.", 
    "link": "http://arxiv.org/pdf/1402.0567v1", 
    "arxiv-id": "1402.0567v1"
},{
    "category": "cs.GT", 
    "author": "Jeffrey S. Rosenschein", 
    "title": "Sharing Rewards in Cooperative Connectivity Games", 
    "publish": "2014-02-04T01:38:31Z", 
    "summary": "We consider how selfish agents are likely to share revenues derived from\nmaintaining connectivity between important network servers. We model a network\nwhere a failure of one node may disrupt communication between other nodes as a\ncooperative game called the vertex Connectivity Game (CG). In this game, each\nagent owns a vertex, and controls all the edges going to and from that vertex.\nA coalition of agents wins if it fully connects a certain subset of vertices in\nthe graph, called the primary vertices. Power indices measure an agents ability\nto affect the outcome of the game. We show that in our domain, such indices can\nbe used to both determine the fair share of the revenues an agent is entitled\nto, and identify significant possible points of failure affecting the\nreliability of communication in the network. We show that in general graphs,\ncalculating the Shapley and Banzhaf power indices is #P-complete, but suggest a\npolynomial algorithm for calculating them in trees. We also investigate finding\nstable payoff divisions of the revenues in CGs, captured by the game theoretic\nsolution of the core, and its relaxations, the epsilon-core and least core. We\nshow a polynomial algorithm for computing the core of a CG, but show that\ntesting whether an imputation is in the epsilon-core is coNP-complete. Finally,\nwe show that for trees, it is possible to test for epsilon-core imputations in\npolynomial time.", 
    "link": "http://arxiv.org/pdf/1402.0572v1", 
    "arxiv-id": "1402.0572v1"
},{
    "category": "cs.GT", 
    "author": "Sascha Kurz", 
    "title": "The inverse problem for power distributions in committees", 
    "publish": "2014-02-05T09:33:10Z", 
    "summary": "Several power indices have been introduced in the literature in order to\nmeasure the influence of individual committee members on the aggregated\ndecision. Here we ask the inverse question and aim to design voting rules for a\ncommittee such that a given desired power distribution is met as closely as\npossible. We present an exact algorithm for a large class of different power\nindices based on integer linear programming. With respect to negative\napproximation results we generalize the approach of Alon and Edelman who\nstudied power distributions for the Banzhaf index, where most of the power is\nconcentrated on few coordinates. It turned out that each Banzhaf vector of an\nn-member committee that is near to such a desired power distribution, has to be\nalso near to the Banzhaf vector of a k-member committee. We show that such\nAlon-Edelman type results are possible for other power indices like e.g. the\nPublic Good index or the Coleman index to prevent actions, while they are\nprincipally impossible for e.g. the Johnston index.", 
    "link": "http://arxiv.org/pdf/1402.0988v1", 
    "arxiv-id": "1402.0988v1"
},{
    "category": "cs.GT", 
    "author": "Anwitaman Datta", 
    "title": "Cooperation and Competition when Bidding for Complex Projects:   Centralized and Decentralized Perspectives", 
    "publish": "2014-02-12T20:52:12Z", 
    "summary": "To successfully complete a complex project, be it a construction of an\nairport or of a backbone IT system, agents (companies or individuals) must form\na team having required competences and resources. A team can be formed either\nby the project issuer based on individual agents' offers (centralized\nformation); or by the agents themselves (decentralized formation) bidding for a\nproject as a consortium---in that case many feasible teams compete for the\ncontract. We investigate rational strategies of the agents (what salary should\nthey ask? with whom should they team up?). We propose concepts to characterize\nthe stability of the winning teams and study their computational complexity.", 
    "link": "http://arxiv.org/pdf/1402.2970v3", 
    "arxiv-id": "1402.2970v3"
},{
    "category": "cs.GT", 
    "author": "Ruta Mehta", 
    "title": "Constant Rank Bimatrix Games are PPAD-hard", 
    "publish": "2014-02-14T02:32:42Z", 
    "summary": "The rank of a bimatrix game (A,B) is defined as rank(A+B). Computing a Nash\nequilibrium (NE) of a rank-$0$, i.e., zero-sum game is equivalent to linear\nprogramming (von Neumann'28, Dantzig'51). In 2005, Kannan and Theobald gave an\nFPTAS for constant rank games, and asked if there exists a polynomial time\nalgorithm to compute an exact NE. Adsul et al. (2011) answered this question\naffirmatively for rank-$1$ games, leaving rank-2 and beyond unresolved.\n  In this paper we show that NE computation in games with rank $\\ge 3$, is\nPPAD-hard, settling a decade long open problem. Interestingly, this is the\nfirst instance that a problem with an FPTAS turns out to be PPAD-hard. Our\nreduction bypasses graphical games and game gadgets, and provides a simpler\nproof of PPAD-hardness for NE computation in bimatrix games. In addition, we\nget:\n  * An equivalence between 2D-Linear-FIXP and PPAD, improving a result by\nEtessami and Yannakakis (2007) on equivalence between Linear-FIXP and PPAD.\n  * NE computation in a bimatrix game with convex set of Nash equilibria is as\nhard as solving a simple stochastic game.\n  * Computing a symmetric NE of a symmetric bimatrix game with rank $\\ge 6$ is\nPPAD-hard.\n  * Computing a (1/poly(n))-approximate fixed-point of a (Linear-FIXP)\npiecewise-linear function is PPAD-hard.\n  The status of rank-$2$ games remains unresolved.", 
    "link": "http://arxiv.org/pdf/1402.3350v2", 
    "arxiv-id": "1402.3350v2"
},{
    "category": "cs.GT", 
    "author": "Alexandros A. Voudouris", 
    "title": "Welfare guarantees for proportional allocations", 
    "publish": "2014-02-14T12:21:14Z", 
    "summary": "According to the proportional allocation mechanism from the network\noptimization literature, users compete for a divisible resource -- such as\nbandwidth -- by submitting bids. The mechanism allocates to each user a\nfraction of the resource that is proportional to her bid and collects an amount\nequal to her bid as payment. Since users act as utility-maximizers, this\nnaturally defines a proportional allocation game. Recently, Syrgkanis and\nTardos (STOC 2013) quantified the inefficiency of equilibria in this game with\nrespect to the social welfare and presented a lower bound of 26.8% on the price\nof anarchy over coarse-correlated and Bayes-Nash equilibria in the full and\nincomplete information settings, respectively. In this paper, we improve this\nbound to 50% over both equilibrium concepts. Our analysis is simpler and,\nfurthermore, we argue that it cannot be improved by arguments that do not take\nthe equilibrium structure into account. We also extend it to settings with\nbudget constraints where we show the first constant bound (between 36% and 50%)\non the price of anarchy of the corresponding game with respect to an effective\nwelfare benchmark that takes budgets into account.", 
    "link": "http://arxiv.org/pdf/1402.3447v1", 
    "arxiv-id": "1402.3447v1"
},{
    "category": "cs.GT", 
    "author": "Adam Smith", 
    "title": "Privacy-Preserving Public Information for Sequential Games", 
    "publish": "2014-02-18T21:03:28Z", 
    "summary": "In settings with incomplete information, players can find it difficult to\ncoordinate to find states with good social welfare. For example, in financial\nsettings, if a collection of financial firms have limited information about\neach other's strategies, some large number of them may choose the same\nhigh-risk investment in hopes of high returns. While this might be acceptable\nin some cases, the economy can be hurt badly if many firms make investments in\nthe same risky market segment and it fails. One reason why many firms might end\nup choosing the same segment is that they do not have information about other\nfirms' investments (imperfect information may lead to `bad' game states).\nDirectly reporting all players' investments, however, raises confidentiality\nconcerns for both individuals and institutions.\n  In this paper, we explore whether information about the game-state can be\npublicly announced in a manner that maintains the privacy of the actions of the\nplayers, and still suffices to deter players from reaching bad game-states. We\nshow that in many games of interest, it is possible for players to avoid these\nbad states with the help of privacy-preserving, publicly-announced information.\nWe model behavior of players in this imperfect information setting in two ways\n-- greedy and undominated strategic behaviours, and we prove guarantees on\nsocial welfare that certain kinds of privacy-preserving information can help\nattain. Furthermore, we design a counter with improved privacy guarantees under\ncontinual observation.", 
    "link": "http://arxiv.org/pdf/1402.4488v2", 
    "arxiv-id": "1402.4488v2"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Sampling and Representation Complexity of Revenue Maximization", 
    "publish": "2014-02-19T00:31:32Z", 
    "summary": "We consider (approximate) revenue maximization in auctions where the\ndistribution on input valuations is given via \"black box\" access to samples\nfrom the distribution. We observe that the number of samples required -- the\nsample complexity -- is tightly related to the representation complexity of an\napproximately revenue-maximizing auction. Our main results are upper bounds and\nan exponential lower bound on these complexities.", 
    "link": "http://arxiv.org/pdf/1402.4535v2", 
    "arxiv-id": "1402.4535v2"
},{
    "category": "cs.GT", 
    "author": "Girish Varma", 
    "title": "Playing games in an uncertain world", 
    "publish": "2014-02-19T07:30:13Z", 
    "summary": "Traditional game theory assumes that the players in the game are aware of the\nrules of the game. However, in practice, often the players are unaware or have\nonly partial knowledge about the game they are playing. They may also have\nknowledge that other players have only partial knowledge of the game they are\nplaying, which they can try to exploit. We present a novel mathematical\nformulation of such games. We make use of Kripke semantics, which are a way to\nkeep track of what different players know and do not know about the world. We\npropose a notion of equilibrium for such games, and show that equilibrium\nalways exists.", 
    "link": "http://arxiv.org/pdf/1402.4570v1", 
    "arxiv-id": "1402.4570v1"
},{
    "category": "cs.GT", 
    "author": "Yakov Babichenko", 
    "title": "Axiomatic Approach to Solutions of Games", 
    "publish": "2014-02-20T22:56:02Z", 
    "summary": "We consider solutions of normal form games that are invariant under strategic\nequivalence. We consider additional properties that can be expected (or be\ndesired) from a solution of a game, and we observe the following:\n  - Even the weakest notion of individual rationality restricts the set of\nsolutions to be equilibria. This observation holds for all types of solutions:\nin pure-strategies, in mixed strategies, and in correlated strategies where the\ncorresponding notions of equilibria are pure-Nash, Nash and coarse-correlated.\n  An action profile is (strict) simultaneous maximizer if it simultaneously\nglobally (strictly) maximizes the payoffs of all players.\n  - If we require that a simultaneous maximizer (if it exists) will be a\nsolution, then the solution contains the set of pure Nash equilibria.\n  - There is no solution for which a strict simultaneous maximizer (if it\nexists) is the unique solution.", 
    "link": "http://arxiv.org/pdf/1402.5165v1", 
    "arxiv-id": "1402.5165v1"
},{
    "category": "cs.GT", 
    "author": "Jian-Jun Shu", 
    "title": "On generalized Tian Ji's horse racing strategy", 
    "publish": "2014-02-21T17:01:23Z", 
    "summary": "Tian Ji's horse racing strategy, a famous Chinese legend, constitutes a\npromising concept to be applied to important issues in today's competitive\nenvironment; this strategy is elaborated on and analyzed by examining the\ngeneral case. The mathematical formulation concerning the calculation of\nwinning, drawing or losing combinations and probabilities is presented to\nillustrate the interesting insights on how ancient philosophies could promote\nthinking in business competitiveness, in particular, the wisdom behind\nsacrificing the part for the benefit of the whole or sacrificing the short-term\nobjectives in order to gain the long-term goal.", 
    "link": "http://arxiv.org/pdf/1402.5351v2", 
    "arxiv-id": "1402.5351v2"
},{
    "category": "cs.GT", 
    "author": "Xuegong Deng", 
    "title": "A Solution to Bargaining Problem on Divisible Goods", 
    "publish": "2014-03-02T05:00:20Z", 
    "summary": "Two-person bargaining problem is considered as to allocate a number of goods\nbetween two players. This paper suggests that any non-trivial division of goods\ncause a non-zero change on the solution of bargaining. So, a axiom of sharing\ndivision is presented, as an alternative axiom to Nash axiom of independence of\nirrelevant alternatives and Kalai-Smorodinsky axiom of monotonicity. This\nsolution is targeted at the partialities of Nash and Kalai-Smorodinsky solution\non some specific issues, but not to say it is better than others.", 
    "link": "http://arxiv.org/pdf/1403.0162v1", 
    "arxiv-id": "1403.0162v1"
},{
    "category": "cs.GT", 
    "author": "Juli\u00e1n Mestre", 
    "title": "Parametrized Algorithms for Random Serial Dictatorship", 
    "publish": "2014-03-04T23:25:44Z", 
    "summary": "Voting and assignment are two of the most fundamental settings in social\nchoice theory. For both settings, random serial dictatorship (RSD) is a\nwell-known rule that satisfies anonymity, ex post efficiency, and\nstrategyproofness. Recently, it was shown that computing the resulting\nprobabilities is #P-complete both in the voting and assignment setting. In this\npaper, we study RSD from a parametrized complexity perspective. More\nspecifically, we present efficient algorithms to compute the RSD probabilities\nunder the condition that the number of agent types, alternatives, or objects is\nbounded.", 
    "link": "http://arxiv.org/pdf/1403.0974v3", 
    "arxiv-id": "1403.0974v3"
},{
    "category": "cs.GT", 
    "author": "Jie Zhang", 
    "title": "Social welfare in one-sided matchings: Random priority and beyond", 
    "publish": "2014-03-06T17:44:08Z", 
    "summary": "We study the problem of approximate social welfare maximization (without\nmoney) in one-sided matching problems when agents have unrestricted cardinal\npreferences over a finite set of items. Random priority is a very well-known\ntruthful-in-expectation mechanism for the problem. We prove that the\napproximation ratio of random priority is Theta(n^{-1/2}) while no\ntruthful-in-expectation mechanism can achieve an approximation ratio better\nthan O(n^{-1/2}), where n is the number of agents and items. Furthermore, we\nprove that the approximation ratio of all ordinal (not necessarily\ntruthful-in-expectation) mechanisms is upper bounded by O(n^{-1/2}), indicating\nthat random priority is asymptotically the best truthful-in-expectation\nmechanism and the best ordinal mechanism for the problem.", 
    "link": "http://arxiv.org/pdf/1403.1508v2", 
    "arxiv-id": "1403.1508v2"
},{
    "category": "cs.GT", 
    "author": "Tie-Yan Liu", 
    "title": "Online Mechanism Design for Cloud Computing", 
    "publish": "2014-03-07T23:17:15Z", 
    "summary": "In this work, we study the problem of online mechanism design for resources\nallocation and pricing in cloud computing (RAPCC). We show that in general the\nallocation problems in RAPCC are NP-hard, and therefore we focus on designing\ndominant-strategy incentive compatible (DSIC) mechanisms with good competitive\nratios compared to the offline optimal allocation (with the prior knowledge\nabout the future jobs). We propose two kinds of DSIC online mechanisms. The\nfirst mechanism, which is based on a greedy allocation rule and leverages a\npriority function for allocation, is very fast and has a tight competitive\nbound. We discuss several priority functions including exponential and linear\npriority functions, and show that the former one has a better competitive\nratio. The second mechanism, which is based on a dynamic program for\nallocation, also has a tight competitive ratio and performs better than the\nfirst one when the maximum demand of cloud customers is close to the capacity\nof the cloud provider.", 
    "link": "http://arxiv.org/pdf/1403.1896v1", 
    "arxiv-id": "1403.1896v1"
},{
    "category": "cs.GT", 
    "author": "Yong Deng", 
    "title": "Generalized prisoner's dilemma", 
    "publish": "2014-03-14T14:54:49Z", 
    "summary": "Prisoner's dilemma has been heavily studied. In classical model, each player\nchooses to either \"Cooperate\" or \"Defect\". In this paper, we generalize the\nprisoner's dilemma with a new alternative which is neither defect or\ncooperation. The classical model is the special case under the condition that\nthe third state is not taken into consideration.", 
    "link": "http://arxiv.org/pdf/1403.3595v1", 
    "arxiv-id": "1403.3595v1"
},{
    "category": "cs.GT", 
    "author": "Bernhard von Stengel", 
    "title": "Game Theory Explorer - Software for the Applied Game Theorist", 
    "publish": "2014-03-16T22:28:32Z", 
    "summary": "This paper presents the \"Game Theory Explorer\" software tool to create and\nanalyze games as models of strategic interaction. A game in extensive or\nstrategic form is created and nicely displayed with a graphical user interface\nin a web browser. State-of-the-art algorithms then compute all Nash equilibria\nof the game after a mouseclick. In tutorial fashion, we present how the program\nis used, and the ideas behind its main algorithms. We report on experiences\nwith the architecture of the software and its development as an open-source\nproject.", 
    "link": "http://arxiv.org/pdf/1403.3969v1", 
    "arxiv-id": "1403.3969v1"
},{
    "category": "cs.GT", 
    "author": "Qi-Wen Wang", 
    "title": "Beyond Parrondo's paradox", 
    "publish": "2014-03-21T14:10:46Z", 
    "summary": "The Parrondo's paradox is a counterintuitive phenomenon where\nindividually-losing strategies can be combined in producing a winning\nexpectation. In this paper, the issues surrounding the Parrondo's paradox are\ninvestigated. The focus is lying on testifying whether the same paradoxical\neffect can be reproduced by using a simple capital dependent game. The\nparadoxical effect generated by the Parrondo's paradox can be explained by\nplacing all the parameters in one probability space. Based on this framework,\nit is able to generate other possible paradoxical effects by manipulating the\nparameters in the probability space.", 
    "link": "http://arxiv.org/pdf/1403.5468v1", 
    "arxiv-id": "1403.5468v1"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Bridging Utility Maximization and Regret Minimization", 
    "publish": "2014-03-25T15:40:41Z", 
    "summary": "We relate the strategy sets that a player ends up with after refining his own\nstrategies according to two very different models of rationality: namely,\nutility maximization and regret minimization.", 
    "link": "http://arxiv.org/pdf/1403.6394v1", 
    "arxiv-id": "1403.6394v1"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Knightian Robustness from Regret Minimization", 
    "publish": "2014-03-25T16:26:13Z", 
    "summary": "We consider auctions in which the players have very limited knowledge about\ntheir own valuations. Specifically, the only information that a Knightian\nplayer $i$ has about the profile of true valuations, $\\theta^*$, consists of a\nset of distributions, from one of which $\\theta_i^*$ has been drawn.\n  We analyze the social-welfare performance of the VCG mechanism, for\nunrestricted combinatorial auctions, when Knightian players that either (a)\nchoose a regret-minimizing strategy, or (b) resort to regret minimization only\nto refine further their own sets of undominated strategies, if needed. We prove\nthat this performance is very good.", 
    "link": "http://arxiv.org/pdf/1403.6409v2", 
    "arxiv-id": "1403.6409v2"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Knightian Analysis of the VCG Mechanism in Unrestricted Combinatorial   Auctions", 
    "publish": "2014-03-25T16:27:47Z", 
    "summary": "We consider auctions in which the players have very limited knowledge about\ntheir own valuations. Specifically, the only information that a Knightian\nplayer $i$ has about the profile of true valuations, $\\theta^*$, consists of a\nset of distributions, from one of which $\\theta_i^*$ has been drawn.\n  The VCG mechanism guarantees very high social welfare both in single- and\nmulti-good auctions, so long as Knightian players do not select strategies that\nare dominated. With such Knightian players, however, we prove that the VCG\nmechanism guarantees very poor social welfare in unrestricted combinatorial\nauctions.", 
    "link": "http://arxiv.org/pdf/1403.6410v1", 
    "arxiv-id": "1403.6410v1"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Knightian Robustness of Single-Parameter Domains", 
    "publish": "2014-03-25T16:28:42Z", 
    "summary": "We consider players that have very limited knowledge about their own\nvaluations. Specifically, the only information that a Knightian player $i$ has\nabout the profile of true valuations, $\\theta^*$, consists of a set of\ndistributions, from one of which $\\theta_i^*$ has been drawn.\n  We prove a ``robustness'' theorem for Knightian players in single-parameter\ndomains: every mechanism that is weakly dominant-strategy truthful for\nclassical players continues to be well-behaved for Knightian players that\nchoose undominated strategies.", 
    "link": "http://arxiv.org/pdf/1403.6411v1", 
    "arxiv-id": "1403.6411v1"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Knightian Analysis of the Vickrey Mechanism", 
    "publish": "2014-03-25T16:32:19Z", 
    "summary": "We analyze the Vickrey mechanism for auctions of multiple identical goods\nwhen the players have both Knightian uncertainty over their own valuations and\nincomplete preferences. In this model, the Vickrey mechanism is no longer\ndominant-strategy, and we prove that all dominant-strategy mechanisms are\ninadequate. However, we also prove that, in undominated strategies, the social\nwelfare produced by the Vickrey mechanism in the worst case is not only very\ngood, but also essentially optimal.", 
    "link": "http://arxiv.org/pdf/1403.6413v3", 
    "arxiv-id": "1403.6413v3"
},{
    "category": "cs.GT", 
    "author": "Ram Rajagopal", 
    "title": "Compensating Demand Response Participants Via Their Shapley Values", 
    "publish": "2014-03-26T15:31:48Z", 
    "summary": "Designing fair compensation mechanisms for demand response (DR) is\nchallenging. This paper models the problem in a game theoretic setting and\ndesigns a payment distribution mechanism based on the Shapley Value. As exact\ncomputation of the Shapley Value is in general intractable, we propose\nestimating it using a reinforcement learning algorithm that approximates\noptimal stratified sampling. We apply this algorithm to two DR programs that\nutilize the Shapley Value for payments and quantify the accuracy of the\nresulting estimates.", 
    "link": "http://arxiv.org/pdf/1403.6713v1", 
    "arxiv-id": "1403.6713v1"
},{
    "category": "cs.GT", 
    "author": "Adam Wierman", 
    "title": "The Role of a Market Maker in Networked Cournot Competition", 
    "publish": "2014-03-28T06:42:17Z", 
    "summary": "We study the role of a market maker (or market operator) in a transmission\nconstrained electricity market. We model the market as a one-shot networked\nCournot competition where generators supply quantity bids and load serving\nentities provide downward sloping inverse demand functions. This mimics the\noperation of a spot market in a deregulated market structure. In this paper, we\nfocus on possible mechanisms employed by the market maker to balance demand and\nsupply. In particular, we consider three candidate objective functions that the\nmarket maker optimizes - social welfare, residual social welfare, and consumer\nsurplus. We characterize the existence of Generalized Nash Equilibrium (GNE) in\nthis setting and demonstrate that market outcomes at equilibrium can be very\ndifferent under the candidate objective functions.", 
    "link": "http://arxiv.org/pdf/1403.7286v1", 
    "arxiv-id": "1403.7286v1"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "A Mirage of Market Allocation", 
    "publish": "2014-03-28T20:29:56Z", 
    "summary": "Can noncooperative behaviour of merchants lead to a market split that prima\nfacie seems anticompetitive? We introduce a model in which service providers,\nwith ISPs being the main example, aim at optimizing the number of customers\nusing their services, while customers aim at choosing service providers with\nlow customer load (high bandwidth per subscriber, for ISPs). Each service\nprovider chooses between a variety of levels of service (latencies, for ISPs),\nand as long as it does not lose customers, aims at minimizing its level of\nservice; the minimum level of service required to satisfy a customer varies\nacross customers. We consider a two-stage competition: in the first stage,\nservice providers select their levels of service; in the second stage,\ncustomers choose between service providers. In the two-stage game, we show that\nthe competition among service providers possesses a unique Nash equilibrium,\nwhich is moreover super-strong; we also show that sequential better-response\ndynamics of service providers reach this equilibrium, with best-response\ndynamics doing so surprisingly fast. If service providers choose their levels\nof service according to this equilibrium, then the unique Nash equilibrium\namong customers in the second phase is a split of the market between the\nservice providers, based on the customers' minimum acceptable quality of\nservice; moreover, each service provider's chosen level of service is the\nlowest acceptable by the entirety of its market slice, seemingly making no\nattempt to attract other customers. Our results show that this prima facie\nmarket allocation (collusive split of the market) arises as the unique and\nhighly robust outcome of noncooperative, even myopic, service-provider\nbehaviour. These results are applicable to a wide variety of scenarios, from\nexplaining phenomena observable in food markets, to shedding a surprising light\non aspects of location theory.", 
    "link": "http://arxiv.org/pdf/1403.7536v2", 
    "arxiv-id": "1403.7536v2"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "A Hydraulic Approach to Equilibria of Resource Selection Games", 
    "publish": "2014-03-29T08:36:25Z", 
    "summary": "Drawing intuition from a (physical) hydraulic system, we present a novel\nframework, constructively showing the existence of a strong Nash equilibrium in\nresource selection games (i.e., asymmetric singleton congestion games) with\nnonatomic players, the coincidence of strong equilibria and Nash equilibria in\nsuch games, and the uniqueness of the cost of each given resource across all\nNash equilibria. Our proofs allow for explicit calculation of Nash equilibrium\nand for explicit and direct calculation of the resulting (unique) costs of\nresources, and do not hinge on any fixed-point theorem, on the Minimax theorem\nor any equivalent result, on linear programming, or on the existence of a\npotential (though our analysis does provide powerful insights into the\npotential, via a natural concrete physical interpretation). A generalization of\nresource selection games, called resource selection games with I.D.-dependent\nweighting, is defined, and the results are extended to this family, showing the\nexistence of strong equilibria, and showing that while resource costs are no\nlonger unique across Nash equilibria in games of this family, they are\nnonetheless unique across all strong Nash equilibria, drawing a novel\nfundamental connection between group deviation and I.D.-congestion. A natural\napplication of the resulting machinery to a large class of\nconstraint-satisfaction problems is also described.", 
    "link": "http://arxiv.org/pdf/1403.7605v7", 
    "arxiv-id": "1403.7605v7"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "Testing Top Monotonicity", 
    "publish": "2014-03-29T11:51:07Z", 
    "summary": "Top monotonicity is a relaxation of various well-known domain restrictions\nsuch as single-peaked and single-crossing for which negative impossibility\nresults are circumvented and for which the median-voter theorem still holds. We\nexamine the problem of testing top monotonicity and present a characterization\nof top monotonicity with respect to non-betweenness constraints. We then extend\nthe definition of top monotonicity to partial orders and show that testing top\nmonotonicity of partial orders is NP-complete.", 
    "link": "http://arxiv.org/pdf/1403.7625v5", 
    "arxiv-id": "1403.7625v5"
},{
    "category": "cs.GT", 
    "author": "Saswati Sarkar", 
    "title": "Uncertain Price Competition in a Duopoly with Heterogeneous Availability", 
    "publish": "2014-03-29T23:51:05Z", 
    "summary": "We study the price competition in a duopoly with an arbitrary number of\nbuyers. Each seller can offer multiple units of a commodity depending on the\navailability of the commodity which is random and may be different for\ndifferent sellers. Sellers seek to select a price that will be attractive to\nthe buyers and also fetch adequate profits. The selection will in general\ndepend on the number of units available with the seller and also that of its\ncompetitor - the seller may only know the statistics of the latter. The setting\ncaptures a secondary spectrum access network, a non-neutral Internet, or a\nmicrogrid network in which unused spectrum bands, resources of ISPs, and excess\npower units constitute the respective commodities of sale. We analyze this\nprice competition as a game, and identify a set of necessary and sufficient\nproperties for the Nash Equilibrium (NE). The properties reveal that sellers\nrandomize their price using probability distributions whose support sets are\nmutually disjoint and in decreasing order of the number of availability. We\nprove the uniqueness of a symmetric NE in a symmetric market, and explicitly\ncompute the price distribution in the symmetric NE.", 
    "link": "http://arxiv.org/pdf/1403.7681v3", 
    "arxiv-id": "1403.7681v3"
},{
    "category": "cs.GT", 
    "author": "Amir Leshem", 
    "title": "On the allocation of multiple divisible assets to players with different   utilities", 
    "publish": "2014-03-30T06:46:31Z", 
    "summary": "When there is a dispute between players on how to divide multiple divisible\nassets, how should it be resolved? In this paper we introduce a multi-asset\ngame model that enables cooperation between multiple agents who bargain on\nsharing K assets, when each player has a different value for each asset. It\nthus extends the sequential discrete Raiffa solution and the Talmud rule\nsolution to multi-asset cases. keyword: resource allocation, game theory,\nRaiffa Bargaining Solution, Aumann Bankruptcy, non-transferable commodities", 
    "link": "http://arxiv.org/pdf/1403.7707v2", 
    "arxiv-id": "1403.7707v2"
},{
    "category": "cs.GT", 
    "author": "D. Dumitrescu", 
    "title": "Computing Strong Nash Equilibria for Multiplayer Games", 
    "publish": "2014-05-01T06:59:20Z", 
    "summary": "An heuristic approach to compute strong Nash (Aumann) equilibria is\npresented. The method is based on differential evolution and three variants of\na generative relation for strong Nash equilibria characterization. Numerical\nexperiments performed on the minimum effort game for up to 150 players\nillustrate the efficiency of the approach. The advantages and disadvantages of\neach variant is discussed in terms of precision and running time.", 
    "link": "http://arxiv.org/pdf/1405.0108v2", 
    "arxiv-id": "1405.0108v2"
},{
    "category": "cs.GT", 
    "author": "D. Dumitrescu", 
    "title": "Characterization and Detection of epsilon-Berge Zhukovskii Equilibria", 
    "publish": "2014-05-02T07:32:15Z", 
    "summary": "Berge equilibrium in the sense of Zhukovskii (Berge-Zhukovskii) is an\nalternate solution concept in non-cooperative game theory that formalizes\ncooperation in a noncooperative setting. In this paper the\nepsilon-Berge-Zhukovskii equilibrium is introduced and characterized by using a\ngenerative relation. A computational method for detecting\nepsilon-Berge-Zhukovskii equilibrium based on evolutionary multiobjective\noptimization algorithms is presented. Numerical examples are used to illustrate\nthe results obtained.", 
    "link": "http://arxiv.org/pdf/1405.0355v1", 
    "arxiv-id": "1405.0355v1"
},{
    "category": "cs.GT", 
    "author": "Aviad Rubinstein", 
    "title": "Computational Complexity of Approximate Nash Equilibrium in Large Games", 
    "publish": "2014-05-02T22:05:26Z", 
    "summary": "We prove that finding an epsilon-Nash equilibrium in a succinctly\nrepresentable game with many players is PPAD-hard for constant epsilon. Our\nproof uses succinct games, i.e. games whose payoff function is represented by a\ncircuit. Our techniques build on a recent query complexity lower bound by\nBabichenko.", 
    "link": "http://arxiv.org/pdf/1405.0524v3", 
    "arxiv-id": "1405.0524v3"
},{
    "category": "cs.GT", 
    "author": "Sascha Kurz", 
    "title": "The average representation - a cornucopia of power indices?", 
    "publish": "2014-05-05T08:47:45Z", 
    "summary": "For the classical power indices there is a disproportion between power and\nrelative weights, in general. We introduce two new indices, based on weighted\nrepresentations, which are proportional to suitable relative weights and which\nalso share several important properties of the classical power indices.\nImposing further restrictions on the set of representations may lead to a whole\nfamily of such indices.", 
    "link": "http://arxiv.org/pdf/1405.0825v1", 
    "arxiv-id": "1405.0825v1"
},{
    "category": "cs.GT", 
    "author": "Matthias Weber", 
    "title": "Mostly Sunny: A Forecast of Tomorrow's Power Index Research", 
    "publish": "2014-05-07T05:50:13Z", 
    "summary": "Power index research has been a very active field in the last decades. Will\nthis continue or are all the important questions solved? We argue that there\nare still many opportunities to conduct useful research with and on power\nindices. Positive and normative questions keep calling for theoretical and\nempirical attention. Technical and technological improvements are likely to\nboost applicability.", 
    "link": "http://arxiv.org/pdf/1405.1510v1", 
    "arxiv-id": "1405.1510v1"
},{
    "category": "cs.GT", 
    "author": "Koos Vrieze", 
    "title": "Existence of Secure Equilibrium in Multi-Player Games with Perfect   Information", 
    "publish": "2014-05-07T14:26:21Z", 
    "summary": "Secure equilibrium is a refinement of Nash equilibrium, which provides some\nsecurity to the players against deviations when a player changes his strategy\nto another best response strategy. The concept of secure equilibrium is\nspecifically developed for assume-guarantee synthesis and has already been\napplied in this context. Yet, not much is known about its existence in games\nwith more than two players. In this paper, we establish the existence of secure\nequilibrium in two classes of multi-player perfect information turn-based\ngames: (1) in games with possibly probabilistic transitions, having countable\nstate and finite action spaces and bounded and continuous payoff functions, and\n(2) in games with only deterministic transitions, having arbitrary state and\naction spaces and Borel payoff functions with a finite range (in particular,\nqualitative Borel payoff functions). We show that these results apply to\nseveral types of games studied in the literature.", 
    "link": "http://arxiv.org/pdf/1405.1615v1", 
    "arxiv-id": "1405.1615v1"
},{
    "category": "cs.GT", 
    "author": "Anshul Sawant", 
    "title": "Network Cournot Competition", 
    "publish": "2014-05-08T03:08:17Z", 
    "summary": "Cournot competition is a fundamental economic model that represents firms\ncompeting in a single market of a homogeneous good. Each firm tries to maximize\nits utility---a function of the production cost as well as market price of the\nproduct---by deciding on the amount of production. In today's dynamic and\ndiverse economy, many firms often compete in more than one market\nsimultaneously, i.e., each market might be shared among a subset of these\nfirms. In this situation, a bipartite graph models the access restriction where\nfirms are on one side, markets are on the other side, and edges demonstrate\nwhether a firm has access to a market or not. We call this game \\emph{Network\nCournot Competition} (NCC). In this paper, we propose algorithms for finding\npure Nash equilibria of NCC games in different situations. First, we carefully\ndesign a potential function for NCC, when the price functions for markets are\nlinear functions of the production in that market. However, for nonlinear price\nfunctions, this approach is not feasible. We model the problem as a nonlinear\ncomplementarity problem in this case, and design a polynomial-time algorithm\nthat finds an equilibrium of the game for strongly convex cost functions and\nstrongly monotone revenue functions. We also explore the class of price\nfunctions that ensures strong monotonicity of the revenue function, and show it\nconsists of a broad class of functions. Moreover, we discuss the uniqueness of\nequilibria in both of these cases which means our algorithms find the unique\nequilibria of the games. Last but not least, when the cost of production in one\nmarket is independent from the cost of production in other markets for all\nfirms, the problem can be separated into several independent classical\n\\emph{Cournot Oligopoly} problems. We give the first combinatorial algorithm\nfor this widely studied problem.", 
    "link": "http://arxiv.org/pdf/1405.1794v2", 
    "arxiv-id": "1405.1794v2"
},{
    "category": "cs.GT", 
    "author": "Afshin Nikzad", 
    "title": "Mechanism Design for Crowdsourcing: An Optimal 1-1/e Competitive   Budget-Feasible Mechanism for Large Markets", 
    "publish": "2014-05-10T16:55:57Z", 
    "summary": "In this paper we consider a mechanism design problem in the context of\nlarge-scale crowdsourcing markets such as Amazon's Mechanical Turk,\nClickWorker, CrowdFlower. In these markets, there is a requester who wants to\nhire workers to accomplish some tasks. Each worker is assumed to give some\nutility to the requester. Moreover each worker has a minimum cost that he wants\nto get paid for getting hired. This minimum cost is assumed to be private\ninformation of the workers. The question then is - if the requester has a\nlimited budget, how to design a direct revelation mechanism that picks the\nright set of workers to hire in order to maximize the requester's utility.\n  We note that although the previous work has studied this problem, a crucial\ndifference in which we deviate from earlier work is the notion of large-scale\nmarkets that we introduce in our model. Without the large market assumption, it\nis known that no mechanism can achieve an approximation factor better than\n0.414 and 0.5 for deterministic and randomized mechanisms respectively (while\nthe best known deterministic and randomized mechanisms achieve an approximation\nratio of 0.292 and 0.33 respectively). In this paper, we design a\nbudget-feasible mechanism for large markets that achieves an approximation\nfactor of 1-1/e (i.e. almost 0.63). Our mechanism can be seen as a\ngeneralization of an alternate way to look at the proportional share mechanism\nwhich is used in all the previous works so far on this problem. Interestingly,\nwe also show that our mechanism is optimal by showing that no truthful\nmechanism can achieve a factor better than 1-1/e; thus, fully resolving this\nsetting. Finally we consider the more general case of submodular utility\nfunctions and give new and improved mechanisms for the case when the markets\nare large.", 
    "link": "http://arxiv.org/pdf/1405.2452v3", 
    "arxiv-id": "1405.2452v3"
},{
    "category": "cs.GT", 
    "author": "Francesco Trov\u00f2", 
    "title": "Truthful Learning Mechanisms for Multi-Slot Sponsored Search Auctions   with Externalities", 
    "publish": "2014-05-11T01:11:57Z", 
    "summary": "Sponsored search auctions constitute one of the most successful applications\nof microeconomic mechanisms. In mechanism design, auctions are usually designed\nto incentivize advertisers to bid their truthful valuations and to assure both\nthe advertisers and the auctioneer a non-negative utility. Nonetheless, in\nsponsored search auctions, the click-through-rates (CTRs) of the advertisers\nare often unknown to the auctioneer and thus standard truthful mechanisms\ncannot be directly applied and must be paired with an effective learning\nalgorithm for the estimation of the CTRs. This introduces the critical problem\nof designing a learning mechanism able to estimate the CTRs at the same time as\nimplementing a truthful mechanism with a revenue loss as small as possible\ncompared to an optimal mechanism designed with the true CTRs. Previous work\nshowed that, when dominant-strategy truthfulness is adopted, in single-slot\nauctions the problem can be solved using suitable exploration-exploitation\nmechanisms able to achieve a per-step regret (over the auctioneer's revenue) of\norder $O(T^{-1/3})$ (where T is the number of times the auction is repeated).\nIt is also known that, when truthfulness in expectation is adopted, a per-step\nregret (over the social welfare) of order $O(T^{-1/2})$ can be obtained. In\nthis paper we extend the results known in the literature to the case of\nmulti-slot auctions. In this case, a model of the user is needed to\ncharacterize how the advertisers' valuations change over the slots. We adopt\nthe cascade model that is the most famous model in the literature for sponsored\nsearch auctions. We prove a number of novel upper bounds and lower bounds both\non the auctioneer's revenue loss and social welfare w.r.t. to the VCG auction\nand we report numerical simulations investigating the accuracy of the bounds in\npredicting the dependency of the regret on the auction parameters.", 
    "link": "http://arxiv.org/pdf/1405.2484v1", 
    "arxiv-id": "1405.2484v1"
},{
    "category": "cs.GT", 
    "author": "Tsai-Ching Lu", 
    "title": "Algorithm Instance Games", 
    "publish": "2014-05-13T20:13:54Z", 
    "summary": "This paper introduces algorithm instance games (AIGs) as a conceptual\nclassification applying to games in which outcomes are resolved from joint\nstrategies algorithmically. For such games, a fundamental question asks: How do\nthe details of the algorithm's description influence agents' strategic\nbehavior?\n  We analyze two versions of an AIG based on the set-cover optimization\nproblem. In these games, joint strategies correspond to instances of the\nset-cover problem, with each subset (of a given universe of elements)\nrepresenting the strategy of a single agent. Outcomes are covers computed from\nthe joint strategies by a set-cover algorithm. In one variant of this game,\noutcomes are computed by a deterministic greedy algorithm, and the other\nvariant utilizes a non-deterministic form of the greedy algorithm. We\ncharacterize Nash equilibrium strategies for both versions of the game, finding\nthat agents' strategies can vary considerably between the two settings. In\nparticular, we find that the version of the game based on the deterministic\nalgorithm only admits Nash equilibrium in which agents choose strategies (i.e.,\nsubsets) containing at most one element, with no two agents picking the same\nelement. On the other hand, in the version of the game based on the\nnon-deterministic algorithm, Nash equilibrium strategies can include agents\nwith zero, one, or every element, and the same element can appear in the\nstrategies of multiple agents.", 
    "link": "http://arxiv.org/pdf/1405.3296v1", 
    "arxiv-id": "1405.3296v1"
},{
    "category": "cs.GT", 
    "author": "Aviad Rubinstein", 
    "title": "Inapproximability of Nash Equilibrium", 
    "publish": "2014-05-13T22:41:04Z", 
    "summary": "We prove that finding an $\\epsilon$-approximate Nash equilibrium is\nPPAD-complete for constant $\\epsilon$ and a particularly simple class of games:\npolymatrix, degree 3 graphical games, in which each player has only two\nactions.\n  As corollaries, we also prove similar inapproximability results for Bayesian\nNash equilibrium in a two-player incomplete information game with a constant\nnumber of actions, for relative $\\epsilon$-Well Supported Nash Equilibrium in a\ntwo-player game, for market equilibrium in a non-monotone market, for the\ngeneralized circuit problem defined by Chen, Deng, and Teng [CDT'09], and for\napproximate competitive equilibrium from equal incomes with indivisible goods.", 
    "link": "http://arxiv.org/pdf/1405.3322v5", 
    "arxiv-id": "1405.3322v5"
},{
    "category": "cs.GT", 
    "author": "Jean-Marie Gorce", 
    "title": "On the Nash Stability in the Hedonic Coalition Formation Games", 
    "publish": "2014-05-14T04:54:08Z", 
    "summary": "This paper studies the Nash stability in hedonic coalition formation games.\nWe address the following issue: for a general problem formulation, is there any\nutility allocation method ensuring a Nash-stable partition? We propose the\ndefinition of the Nash-stable core and we analyze the conditions for having a\nnon-empty Nash-stable core. More precisely, we prove that using relaxed\nefficiency in utility sharing allows to ensure a non empty Nash-stable core.\nThen, a decentralized algorithm called Nash stability establisher is proposed\nfor finding the Nash stability in a game whenever at least one exists. The\nproblem of finding the Nash stability is formulated as a non-cooperative game.\nIn the proposed approach, during each round, each player determines its\nstrategy in its turn according to a random round-robin scheduler. We prove that\nthe algorithm converges to an equilibrium if it exists, which is the indicator\nof the Nash stability.", 
    "link": "http://arxiv.org/pdf/1405.3360v1", 
    "arxiv-id": "1405.3360v1"
},{
    "category": "cs.GT", 
    "author": "Fabi\u00e1n Riquelme", 
    "title": "Satisfaction in societies with opinion leaders and mediators: properties   and an axiomatization", 
    "publish": "2014-05-14T11:41:52Z", 
    "summary": "In this paper we propose the opinion leader-follower through mediators\nsystems (OLFM systems) a multiple-action collective choice model for societies.\nIn those societies three kind of actors are considered: opinion leaders that\ncan exert certain influence over the decision of other actors, followers that\ncan be convinced to modify their original decisions, and independent actors\nthat neither are influenced nor can influence; mediators are actors that both\nare influenced and influence other actors. This is a generalization of the\nopinion leader-follower systems (OLF systems) proposed by van den Brink R, et\nal. (2011).\n  The satisfaction score is defined on the set of actors. For each actor it\nmeasures the number of society initial decisions in which the final collective\ndecision coincides with the one that the actor initially selected. We\ngeneralize in OLFM systems some properties that the satisfaction score meets\nfor OLF systems. By using these properties, we provide an axiomatization of the\nsatisfaction score for the case in which followers maintain their own initial\ndecisions unless all their opinion leaders share an opposite inclination. This\nnew axiomatization generalizes the one given by van den Brink R, et al. (2012)\nfor OLF systems under the same restrictions.", 
    "link": "http://arxiv.org/pdf/1405.3460v1", 
    "arxiv-id": "1405.3460v1"
},{
    "category": "cs.GT", 
    "author": "Y. Narahari", 
    "title": "Kernelization Complexity of Possible Winner and Coalitional Manipulation   Problems in Voting", 
    "publish": "2014-05-15T14:39:11Z", 
    "summary": "In the Possible Winner problem in computational social choice theory, we are\ngiven a set of partial preferences and the question is whether a distinguished\ncandidate could be made winner by extending the partial preferences to linear\npreferences. Previous work has provided, for many common voting rules, fixed\nparameter tractable algorithms for the Possible Winner problem, with number of\ncandidates as the parameter. However, the corresponding kernelization question\nis still open and in fact, has been mentioned as a key research challenge. In\nthis paper, we settle this open question for many common voting rules.\n  We show that the Possible Winner problem for maximin, Copeland, Bucklin,\nranked pairs, and a class of scoring rules that include the Borda voting rule\ndo not admit a polynomial kernel with the number of candidates as the\nparameter. We show however that the Coalitional Manipulation problem which is\nan important special case of the Possible Winner problem does admit a\npolynomial kernel for maximin, Copeland, ranked pairs, and a class of scoring\nrules that includes the Borda voting rule, when the number of manipulators is\npolynomial in the number of candidates. A significant conclusion of our work is\nthat the Possible Winner problem is harder than the Coalitional Manipulation\nproblem since the Coalitional Manipulation problem admits a polynomial kernel\nwhereas the Possible Winner problem does not admit a polynomial kernel.", 
    "link": "http://arxiv.org/pdf/1405.3865v2", 
    "arxiv-id": "1405.3865v2"
},{
    "category": "cs.GT", 
    "author": "Jun Wang", 
    "title": "A dynamic pricing model for unifying programmatic guarantee and   real-time bidding in display advertising", 
    "publish": "2014-05-20T19:01:27Z", 
    "summary": "There are two major ways of selling impressions in display advertising. They\nare either sold in spot through auction mechanisms or in advance via guaranteed\ncontracts. The former has achieved a significant automation via real-time\nbidding (RTB); however, the latter is still mainly done over the counter\nthrough direct sales. This paper proposes a mathematical model that allocates\nand prices the future impressions between real-time auctions and guaranteed\ncontracts. Under conventional economic assumptions, our model shows that the\ntwo ways can be seamless combined programmatically and the publisher's revenue\ncan be maximized via price discrimination and optimal allocation. We consider\nadvertisers are risk-averse, and they would be willing to purchase guaranteed\nimpressions if the total costs are less than their private values. We also\nconsider that an advertiser's purchase behavior can be affected by both the\nguaranteed price and the time interval between the purchase time and the\nimpression delivery date. Our solution suggests an optimal percentage of future\nimpressions to sell in advance and provides an explicit formula to calculate at\nwhat prices to sell. We find that the optimal guaranteed prices are dynamic and\nare non-decreasing over time. We evaluate our method with RTB datasets and find\nthat the model adopts different strategies in allocation and pricing according\nto the level of competition. From the experiments we find that, in a less\ncompetitive market, lower prices of the guaranteed contracts will encourage the\npurchase in advance and the revenue gain is mainly contributed by the increased\ncompetition in future RTB. In a highly competitive market, advertisers are more\nwilling to purchase the guaranteed contracts and thus higher prices are\nexpected. The revenue gain is largely contributed by the guaranteed selling.", 
    "link": "http://arxiv.org/pdf/1405.5189v3", 
    "arxiv-id": "1405.5189v3"
},{
    "category": "cs.GT", 
    "author": "Yan Zhang", 
    "title": "An Ordinal Bargaining Solution with Fixed-Point Property", 
    "publish": "2014-01-15T05:19:50Z", 
    "summary": "Shapleys impossibility result indicates that the two-person bargaining\nproblem has no non-trivial ordinal solution with the traditional game-theoretic\nbargaining model. Although the result is no longer true for bargaining problems\nwith more than two agents, none of the well known bargaining solutions are\nordinal. Searching for meaningful ordinal solutions, especially for the\nbilateral bargaining problem, has been a challenging issue in bargaining theory\nfor more than three decades. This paper proposes a logic-based ordinal solution\nto the bilateral bargaining problem. We argue that if a bargaining problem is\nmodeled in terms of the logical relation of players physical negotiation items,\na meaningful bargaining solution can be constructed based on the ordinal\nstructure of bargainers preferences. We represent bargainers demands in\npropositional logic and bargainers preferences over their demands in total\npreorder. We show that the solution satisfies most desirable logical\nproperties, such as individual rationality (logical version), consistency,\ncollective rationality as well as a few typical game-theoretic properties, such\nas weak Pareto optimality and contraction invariance. In addition, if all\nplayers demand sets are logically closed, the solution satisfies a fixed-point\ncondition, which says that the outcome of a negotiation is the result of mutual\nbelief revision. Finally, we define various decision problems in relation to\nour bargaining model and study their computational complexity.", 
    "link": "http://arxiv.org/pdf/1405.5201v1", 
    "arxiv-id": "1405.5201v1"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "Voting with Coarse Beliefs", 
    "publish": "2014-05-22T17:05:38Z", 
    "summary": "The classic Gibbard-Satterthwaite theorem says that every strategy-proof\nvoting rule with at least three possible candidates must be dictatorial.\nSimilar impossibility results hold even if we consider a weaker notion of\nstrategy-proofness where voters believe that the other voters' preferences are\ni.i.d.~(independent and identically distributed). In this paper, we take a\nbounded-rationality approach to this problem and consider a setting where\nvoters have \"coarse\" beliefs (a notion that has gained popularity in the\nbehavioral economics literature). In particular, we construct good voting rules\nthat satisfy a notion of strategy-proofness with respect to coarse\ni.i.d.~beliefs, thus circumventing the above impossibility results.", 
    "link": "http://arxiv.org/pdf/1405.5827v2", 
    "arxiv-id": "1405.5827v2"
},{
    "category": "cs.GT", 
    "author": "S. Matthew Weinberg", 
    "title": "Bayesian Truthful Mechanisms for Job Scheduling from Bi-criterion   Approximation Algorithms", 
    "publish": "2014-05-23T00:42:09Z", 
    "summary": "We provide polynomial-time approximately optimal Bayesian mechanisms for\nmakespan minimization on unrelated machines as well as for max-min fair\nallocations of indivisible goods, with approximation factors of $2$ and\n$\\min\\{m-k+1, \\tilde{O}(\\sqrt{k})\\}$ respectively, matching the approximation\nratios of best known polynomial-time \\emph{algorithms} (for max-min fairness,\nthe latter claim is true for certain ratios of the number of goods $m$ to\npeople $k$). Our mechanisms are obtained by establishing a polynomial-time\napproximation-sensitive reduction from the problem of designing approximately\noptimal {\\em mechanisms} for some arbitrary objective ${\\cal O}$ to that of\ndesigning bi-criterion approximation {\\em algorithms} for the same objective\n${\\cal O}$ plus a linear allocation cost term. Our reduction is itself enabled\nby extending the celebrated \"equivalence of separation and\noptimization\"[GLSS81,KP80] to also accommodate bi-criterion approximations.\nMoreover, to apply the reduction to the specific problems of makespan and\nmax-min fairness we develop polynomial-time bi-criterion approximation\nalgorithms for makespan minimization with costs and max-min fairness with\ncosts, adapting the algorithms of [ST93], [BD05] and [AS07] to the type of\nbi-criterion approximation that is required by the reduction.", 
    "link": "http://arxiv.org/pdf/1405.5940v1", 
    "arxiv-id": "1405.5940v1"
},{
    "category": "cs.GT", 
    "author": "S. Matthew Weinberg", 
    "title": "A Simple and Approximately Optimal Mechanism for an Additive Buyer", 
    "publish": "2014-05-23T18:05:53Z", 
    "summary": "We consider a monopolist seller with $n$ heterogeneous items, facing a single\nbuyer. The buyer has a value for each item drawn independently according to\n(non-identical) distributions, and his value for a set of items is additive.\nThe seller aims to maximize his revenue. It is known that an optimal mechanism\nin this setting may be quite complex, requiring randomization [HR12] and menus\nof infinite size [DDT13]. Hart and Nisan [HN12] have initiated a study of two\nvery simple pricing schemes for this setting: item pricing, in which each item\nis priced at its monopoly reserve; and bundle pricing, in which the entire set\nof items is priced and sold as one bundle. Hart and Nisan [HN12] have shown\nthat neither scheme can guarantee more than a vanishingly small fraction of the\noptimal revenue. In sharp contrast, we show that for any distributions, the\nbetter of item and bundle pricing is a constant-factor approximation to the\noptimal revenue. We further discuss extensions to multiple buyers and to\nvaluations that are correlated across items.", 
    "link": "http://arxiv.org/pdf/1405.6146v2", 
    "arxiv-id": "1405.6146v2"
},{
    "category": "cs.GT", 
    "author": "Yoav Shoham", 
    "title": "Stable Invitations", 
    "publish": "2014-05-30T00:33:55Z", 
    "summary": "We consider the situation in which an organizer is trying to convene an\nevent, and needs to choose a subset of agents to be invited. Agents have\npreferences over how many attendees should be at the event and possibly also\nwho the attendees should be. This induces a stability requirement: All invited\nagents should prefer attending to not attending, and all the other agents\nshould not regret being not invited. The organizer's objective is to find the\ninvitation of maximum size subject to the stability requirement. We investigate\nthe computational complexity of finding the maximum stable invitation when all\nagents are truthful, as well as the mechanism design problem when agents may\nstrategically misreport their preferences.", 
    "link": "http://arxiv.org/pdf/1405.7751v1", 
    "arxiv-id": "1405.7751v1"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "Optimal Auctions for Correlated Buyers with Sampling", 
    "publish": "2014-06-06T02:22:37Z", 
    "summary": "Cr\\'emer and McLean [1985] showed that, when buyers' valuations are drawn\nfrom a correlated distribution, an auction with full knowledge on the\ndistribution can extract the full social surplus. We study whether this\nphenomenon persists when the auctioneer has only incomplete knowledge of the\ndistribution, represented by a finite family of candidate distributions, and\nhas sample access to the real distribution. We show that the naive approach\nwhich uses samples to distinguish candidate distributions may fail, whereas an\nextended version of the Cr\\'emer-McLean auction simultaneously extracts full\nsocial surplus under each candidate distribution. With an algebraic argument,\nwe give a tight bound on the number of samples needed by this auction, which is\nthe difference between the number of candidate distributions and the dimension\nof the linear space they span.", 
    "link": "http://arxiv.org/pdf/1406.1571v1", 
    "arxiv-id": "1406.1571v1"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "Behavioral Mechanism Design: Optimal Contests for Simple Agents", 
    "publish": "2014-06-06T19:58:35Z", 
    "summary": "Incentives are more likely to elicit desired outcomes when they are designed\nbased on accurate models of agents' strategic behavior. A growing literature,\nhowever, suggests that people do not quite behave like standard economic agents\nin a variety of environments, both online and offline. What consequences might\nsuch differences have for the optimal design of mechanisms in these\nenvironments? In this paper, we explore this question in the context of optimal\ncontest design for simple agents---agents who strategically reason about\nwhether or not to participate in a system, but not about the input they provide\nto it. Specifically, consider a contest where $n$ potential contestants with\ntypes $(q_i,c_i)$ each choose between participating and producing a submission\nof quality $q_i$ at cost $c_i$, versus not participating at all, to maximize\ntheir utilities. How should a principal distribute a total prize $V$ amongst\nthe $n$ ranks to maximize some increasing function of the qualities of elicited\nsubmissions in a contest with such simple agents?\n  We first solve the optimal contest design problem for settings with\nhomogenous participation costs $c_i = c$. Here, the optimal contest is always a\nsimple contest, awarding equal prizes to the top $j^*$ contestants for a\nsuitable choice of $j^*$. (In comparable models with strategic effort choices,\nthe optimal contest is either a winner-take-all contest or awards possibly\nunequal prizes, depending on the curvature of agents' effort cost functions.)\nWe next address the general case with heterogeneous costs where agents' types\nare inherently two-dimensional, significantly complicating equilibrium\nanalysis. Our main result here is that the winner-take-all contest is a\n3-approximation of the optimal contest when the principal's objective is to\nmaximize the quality of the best elicited contribution.", 
    "link": "http://arxiv.org/pdf/1406.1790v1", 
    "arxiv-id": "1406.1790v1"
},{
    "category": "cs.GT", 
    "author": "Andrew Chi-Chih Yao", 
    "title": "An n-to-1 Bidder Reduction for Multi-item Auctions and its Applications", 
    "publish": "2014-06-12T16:03:45Z", 
    "summary": "In this paper, we introduce a novel approach for reducing the $k$-item\n$n$-bidder auction with additive valuation to $k$-item $1$-bidder auctions.\nThis approach, called the \\emph{Best-Guess} reduction, can be applied to\naddress several central questions in optimal revenue auction theory such as the\npower of randomization, and Bayesian versus dominant-strategy implementations.\nFirst, when the items have independent valuation distributions, we present a\ndeterministic mechanism called {\\it Deterministic Best-Guess} that yields at\nleast a constant fraction of the optimal revenue by any randomized mechanism.\nSecond, if all the $nk$ valuation random variables are independent, the optimal\nrevenue achievable in {\\it dominant strategy incentive compatibility} (DSIC) is\nshown to be at least a constant fraction of that achievable in {\\it Bayesian\nincentive compatibility} (BIC). Third, when all the $nk$ values are identically\ndistributed according to a common one-dimensional distribution $F$, the optimal\nrevenue is shown to be expressible in the closed form $\\Theta(k(r+\\int_0^{mr}\n(1-F(x)^n) \\ud x))$ where $r= sup_{x\\geq 0} \\, x(1 - F(x)^n)$ and $m=\\lceil\nk/n\\rceil$; this revenue is achievable by a simple mechanism called\n\\emph{2nd-Price Bundling}. All our results apply to arbitrary distributions,\nregular or irregular.", 
    "link": "http://arxiv.org/pdf/1406.3278v3", 
    "arxiv-id": "1406.3278v3"
},{
    "category": "cs.GT", 
    "author": "Sven Seuken", 
    "title": "Trade-offs in School Choice: Comparing Deferred Acceptance, the Naive   and the Adaptive Boston Mechanism", 
    "publish": "2014-06-12T19:08:57Z", 
    "summary": "We compare the three most common school choice mechanisms: the Deferred\nAcceptance mechanism (DA), the classic naive Boston mechanism (NBM), and a\nvariant of the Boston mechanism where students automatically skip exhausted\nschools, which we call the adaptive Boston mechanism (ABM). When priorities are\nrandom we show that the three mechanisms form two hierarchies, one in terms of\nincentives and the other in terms of student welfare. Regarding incentives:\nwhile DA is strategyproof, we show that ABM satisfies the intermediate partial\nstrategyproof concept but NBM does not. Regarding student welfare the hierarchy\nis exactly inverted: we first show that, given truthful preference information,\nNBM rank dominates DA whenever they are comparable; and via limit arguments and\nsimulations we show that ABM yields intermediate student welfare between NBM\nand DA. Second, we perform computational experiments with preference data from\nthe high school match in Mexico City. We find that student welfare (in terms of\nrank transitions) is highest under NBM, intermediate under ABM, and lowest\nunder DA. Our results show that a decision between these three common\nmechanisms involves an implicit trade-off between incentives and student\nwelfare.", 
    "link": "http://arxiv.org/pdf/1406.3327v2", 
    "arxiv-id": "1406.3327v2"
},{
    "category": "cs.GT", 
    "author": "Paraskevas V. Lekeas", 
    "title": "An Evolutionary Approach to Coalition Formation", 
    "publish": "2014-06-13T00:41:08Z", 
    "summary": "In Cooperative Games with Externalities when the members of a set S \\subset N\nof agents wish to deviate they need to calculate their worth. This worth\ndepends on what the non-members (outsiders) N \\setminus S will do, which in\nturn depends on which coalition structure the outsiders will form. Since this\ncoalition formation problem is NP-hard, various approaches have been adopted.\nIn this paper using an evolutionary game theoretic approach we provide a set of\nequations that can help agents in S reason about the coalition structures the\noutsiders may form in terms of minimum distances on an n-s dimensional space,\nwhere n=|N|, s=|S|.", 
    "link": "http://arxiv.org/pdf/1406.3395v1", 
    "arxiv-id": "1406.3395v1"
},{
    "category": "cs.GT", 
    "author": "Simone Montemezzani", 
    "title": "An $H_{n/2}$ Upper Bound on the Price of Stability of Undirected Network   Design Games", 
    "publish": "2014-06-13T18:00:18Z", 
    "summary": "In the network design game with $n$ players, every player chooses a path in\nan edge-weighted graph to connect her pair of terminals, sharing costs of the\nedges on her path with all other players fairly. We study the price of\nstability of the game, i.e., the ratio of the social costs of a best Nash\nequilibrium (with respect to the social cost) and of an optimal play. It has\nbeen shown that the price of stability of any network design game is at most\n$H_n$, the $n$-th harmonic number. This bound is tight for directed graphs. For\nundirected graphs, the situation is dramatically different, and tight bounds\nare not known. It has only recently been shown that the price of stability is\nat most $H_n \\left(1-\\frac{1}{\\Theta(n^4)} \\right)$, while the worst-case known\nexample has price of stability around 2.25. In this paper we improve the upper\nbound considerably by showing that the price of stability is at most $H_{n/2} +\n\\epsilon$ for any $\\epsilon$ starting from some suitable $n \\geq n(\\epsilon)$.", 
    "link": "http://arxiv.org/pdf/1406.3597v1", 
    "arxiv-id": "1406.3597v1"
},{
    "category": "cs.GT", 
    "author": "Lili Dworkin", 
    "title": "A Computational Study of Feasible Repackings in the FCC Incentive   Auctions", 
    "publish": "2014-06-18T18:54:00Z", 
    "summary": "We report the results of a computational study of repacking in the FCC\nIncentive Auctions. Our interest lies in the structure and constraints of the\nsolution space of feasible repackings. Our analyses are \"mechanism-free\", in\nthe sense that they identify constraints that must hold regardless of the\nreverse auction mechanism chosen or the prices offered for broadcaster\nclearing. We examine topics such as the amount of spectrum that can be cleared\nnationwide, the geographic distribution of broadcaster clearings required to\nreach a clearing target, and the likelihood of reaching clearing targets under\nvarious models for broadcaster participation. Our study uses FCC interference\ndata and a satisfiability-checking approach, and elucidates both the\nunavoidable mathematical constraints on solutions imposed by interference, as\nwell as additional constraints imposed by assumptions on the participation\ndecisions of broadcasters.", 
    "link": "http://arxiv.org/pdf/1406.4837v1", 
    "arxiv-id": "1406.4837v1"
},{
    "category": "cs.GT", 
    "author": "Maria J. Serna", 
    "title": "Optimizing the Social Cost of Congestion Games by Imposing Variable   Delays", 
    "publish": "2014-06-19T19:05:40Z", 
    "summary": "We describe a new coordination mechanism for non-atomic congestion games that\nleads to a (selfish) social cost which is arbitrarily close to the non-selfish\noptimal. This mechanism does not incur any additional extra cost, like tolls,\nwhich are usually differentiated from the social cost as expressed in terms of\ndelays only.", 
    "link": "http://arxiv.org/pdf/1406.5153v1", 
    "arxiv-id": "1406.5153v1"
},{
    "category": "cs.GT", 
    "author": "Sascha Kurz", 
    "title": "The price of fairness for a small number of indivisible items", 
    "publish": "2014-06-22T13:01:32Z", 
    "summary": "Incorporating fairness criteria in optimization problems comes at a certain\ncost, which is measured by the so-called price of fairness. Here we consider\nthe allocation of indivisible goods. For envy-freeness as fairness criterion it\nis known from literature that the price of fairness can increase linearly in\nterms of the number of agents. For the constructive lower bound a quadratic\nnumber of items was used. In practice this might be inadequately large. So we\nintroduce the price of fairness in terms of both the number of agents and\nitems, i.e., key parameters which generally may be considered as common and\navailable knowledge. It turned out that the price of fairness increases\nsublinear if the number of items is not too much larger than the number of\nagents. For the special case of coincide of both counts exact asymptotics could\nbe determined. Additionally an efficient integer programming formulation is\ngiven.", 
    "link": "http://arxiv.org/pdf/1406.5722v1", 
    "arxiv-id": "1406.5722v1"
},{
    "category": "cs.GT", 
    "author": "Eran Shmaya", 
    "title": "Rental harmony with roommates", 
    "publish": "2014-06-25T19:14:50Z", 
    "summary": "We prove existence of envy-free allocations in markets with heterogenous\nindivisible goods and money, when a given quantity is supplied from each of the\ngoods and agents have unit demands. We depart from most of the previous\nliterature by allowing agents' preferences over the goods to depend on the\nentire vector of prices. Our proof uses Shapley's K-K-M-S theorem and Hall's\nmarriage lemma. We then show how our theorem may be applied in two related\nproblems: Existence of envy-free allocations in a version of the cake-cutting\nproblem, and existence of equilibrium in an exchange economy with indivisible\ngoods and money.", 
    "link": "http://arxiv.org/pdf/1406.6672v1", 
    "arxiv-id": "1406.6672v1"
},{
    "category": "cs.GT", 
    "author": "Brandon Goldfedder", 
    "title": "Trade-based Asset Model using Dynamic Junction Tree for Combinatorial   Prediction Markets", 
    "publish": "2014-06-30T02:43:28Z", 
    "summary": "Prediction markets have demonstrated their value for aggregating collective\nexpertise. Combinatorial prediction markets allow forecasts not only on base\nevents, but also on conditional and/or Boolean combinations of events. We\ndescribe a trade-based combinatorial prediction market asset management system,\ncalled Dynamic Asset Cluster (DAC), that improves both time and space\nefficiency over the method of, which maintains parallel junction trees for\nassets and probabilities. The basic data structure is the asset block, which\ncompactly represents a set of trades made by a user. A user's asset model\nconsists of a set of asset blocks representing the user's entire trade history.\nA junction tree is created dynamically from the asset blocks to compute a\nuser's minimum and expected assets.", 
    "link": "http://arxiv.org/pdf/1406.7583v1", 
    "arxiv-id": "1406.7583v1"
},{
    "category": "cs.GT", 
    "author": "Didier Sornette", 
    "title": "Using Prediction Markets to Incentivize and Measure Collective Knowledge   Production", 
    "publish": "2014-06-30T14:11:50Z", 
    "summary": "We present a mechanism design, coupling an online collaboration software and\na prediction market, which allows tracking down the very roots of individual\nincentives, actions and how these behaviors influence collective intelligence\nin terms of knowledge production as a public good. We show that the incentive\nmechanism efficiently engages users without further governance structure, and\ndoesn't crowd out intrinsic motivation. Furthermore, it enables a powerful and\nrobust creative destruction process, which helps quickly filter out irrelevant\nknowledge. While still at an early stage, this mechanism design can not only\nbring insights for knowledge production organization design, but also has the\npotential to illuminate the fundamental mechanisms underlying the emergence of\ncollective intelligence.", 
    "link": "http://arxiv.org/pdf/1406.7746v1", 
    "arxiv-id": "1406.7746v1"
},{
    "category": "cs.GT", 
    "author": "Evangelos Markakis", 
    "title": "Cooperative Games with Overlapping Coalitions: Charting the Tractability   Frontier", 
    "publish": "2014-07-01T22:30:45Z", 
    "summary": "In many multiagent scenarios, agents distribute resources, such as time or\nenergy, among several tasks. Having completed their tasks and generated\nprofits, task payoffs must be divided among the agents in some reasonable\nmanner. Cooperative games with overlapping coalitions (OCF games) are a recent\nframework proposed by Chalkiadakis et al. (2010), generalizing classic\ncooperative games to the case where agents may belong to more than one\ncoalition. Having formed overlapping coalitions and divided profits, some\nagents may feel dissatisfied with their share of the profits, and would like to\ndeviate from the given outcome. However, deviation in OCF games is a\ncomplicated matter: agents may decide to withdraw only some of their weight\nfrom some of the coalitions they belong to; that is, even after deviation, it\nis possible that agents will still be involved in tasks with non-deviators.\nThis means that the desirability of a deviation, and the stability of formed\ncoalitions, is to a great extent determined by the reaction of non-deviators.\nIn this work, we explore algorithmic aspects of OCF games, focusing on the core\nin OCF games. We study the problem of deciding if the core of an OCF game is\nnot empty, and whether a core payoff division can be found in polynomial time;\nmoreover, we identify conditions that ensure that the problem admits polynomial\ntime algorithms. Finally, we introduce and study a natural class of OCF games,\nLinear Bottleneck Games. Interestingly, we show that such games always have a\nnon-empty core, even assuming a highly lenient reaction to deviations.", 
    "link": "http://arxiv.org/pdf/1407.0420v3", 
    "arxiv-id": "1407.0420v3"
},{
    "category": "cs.GT", 
    "author": "Guido Proietti", 
    "title": "The Max-Distance Network Creation Game on General Host Graphs", 
    "publish": "2014-07-02T16:48:53Z", 
    "summary": "In this paper we study a generalization of the classic \\emph{network creation\ngame} in the scenario in which the $n$ players sit on a given arbitrary\n\\emph{host graph}, which constrains the set of edges a player can activate at a\ncost of $\\alpha \\geq 0$ each. This finds its motivations in the physical\nlimitations one can have in constructing links in practice, and it has been\nstudied in the past only when the routing cost component of a player is given\nby the sum of distances to all the other nodes. Here, we focus on another\npopular routing cost, namely that which takes into account for each player its\n\\emph{maximum} distance to any other player. For this version of the game, we\nfirst analyze some of its computational and dynamic aspects, and then we\naddress the problem of understanding the structure of associated pure Nash\nequilibria. In this respect, we show that the corresponding price of anarchy\n(PoA) is fairly bad, even for several basic classes of host graphs. More\nprecisely, we first exhibit a lower bound of $\\Omega (\\sqrt{ n / (1+\\alpha)})$\nfor any $\\alpha = o(n)$. Notice that this implies a counter-intuitive lower\nbound of $\\Omega(\\sqrt{n})$ for very small values of $\\alpha$ (i.e., edges can\nbe activated almost for free). Then, we show that when the host graph is\nrestricted to be either $k$-regular (for any constant $k \\geq 3$), or a\n2-dimensional grid, the PoA is still $\\Omega(1+\\min\\{\\alpha,\n\\frac{n}{\\alpha}\\})$, which is proven to be tight for\n$\\alpha=\\Omega(\\sqrt{n})$. On the positive side, if $\\alpha \\geq n$, we show\nthe PoA is $O(1)$. Finally, in the case in which the host graph is very sparse\n(i.e., $|E(H)|=n-1+k$, with $k=O(1)$), we prove that the PoA is $O(1)$, for any\n$\\alpha$.", 
    "link": "http://arxiv.org/pdf/1407.0643v1", 
    "arxiv-id": "1407.0643v1"
},{
    "category": "cs.GT", 
    "author": "Jochen K\u00f6nemann", 
    "title": "Stable marriage with general preferences", 
    "publish": "2014-07-07T20:01:24Z", 
    "summary": "We propose a generalization of the classical stable marriage problem. In our\nmodel, the preferences on one side of the partition are given in terms of\narbitrary binary relations, which need not be transitive nor acyclic. This\ngeneralization is practically well-motivated, and as we show, encompasses the\nwell studied hard variant of stable marriage where preferences are allowed to\nhave ties and to be incomplete. As a result, we prove that deciding the\nexistence of a stable matching in our model is NP-complete. Complementing this\nnegative result we present a polynomial-time algorithm for the above decision\nproblem in a significant class of instances where the preferences are\nasymmetric. We also present a linear programming formulation whose feasibility\nfully characterizes the existence of stable matchings in this special case.\nFinally, we use our model to study a long standing open problem regarding the\nexistence of cyclic 3D stable matchings. In particular, we prove that the\nproblem of deciding whether a fixed 2D perfect matching can be extended to a 3D\nstable matching is NP-complete, showing this way that a natural attempt to\nresolve the existence (or not) of 3D stable matchings is bound to fail.", 
    "link": "http://arxiv.org/pdf/1407.1853v2", 
    "arxiv-id": "1407.1853v2"
},{
    "category": "cs.GT", 
    "author": "Jay Sethuraman", 
    "title": "The size of the core in assignment markets", 
    "publish": "2014-07-09T18:09:02Z", 
    "summary": "Assignment markets involve matching with transfers, as in labor markets and\nhousing markets. We consider a two-sided assignment market with agent types and\nstochastic structure similar to models used in empirical studies, and\ncharacterize the size of the core in such markets. Each agent has a randomly\ndrawn productivity with respect to each type of agent on the other side. The\nvalue generated from a match between a pair of agents is the sum of the two\nproductivity terms, each of which depends only on the type but not the identity\nof one of the agents, and a third deterministic term driven by the pair of\ntypes. We allow the number of agents to grow, keeping the number of agent types\nfixed. Let $n$ be the number of agents and $K$ be the number of types on the\nside of the market with more types. We find, under reasonable assumptions, that\nthe relative variation in utility per agent over core outcomes is bounded as\n$O^*(1/n^{1/K})$, where polylogarithmic factors have been suppressed. Further,\nwe show that this bound is tight in worst case. We also provide a tighter bound\nunder more restrictive assumptions. Our results provide partial justification\nfor the typical assumption of a unique core outcome in empirical studies.", 
    "link": "http://arxiv.org/pdf/1407.2576v1", 
    "arxiv-id": "1407.2576v1"
},{
    "category": "cs.GT", 
    "author": "Zhiwei Steven Wu", 
    "title": "Approximately Stable, School Optimal, and Student-Truthful Many-to-One   Matchings (via Differential Privacy)", 
    "publish": "2014-07-09T21:18:21Z", 
    "summary": "We present a mechanism for computing asymptotically stable school optimal\nmatchings, while guaranteeing that it is an asymptotic dominant strategy for\nevery student to report their true preferences to the mechanism. Our main tool\nin this endeavor is differential privacy: we give an algorithm that coordinates\na stable matching using differentially private signals, which lead to our\ntruthfulness guarantee. This is the first setting in which it is known how to\nachieve nontrivial truthfulness guarantees for students when computing school\noptimal matchings, assuming worst- case preferences (for schools and students)\nin large markets.", 
    "link": "http://arxiv.org/pdf/1407.2640v2", 
    "arxiv-id": "1407.2640v2"
},{
    "category": "cs.GT", 
    "author": "Aaron Roth", 
    "title": "Private Pareto Optimal Exchange", 
    "publish": "2014-07-09T21:29:20Z", 
    "summary": "We consider the problem of implementing an individually rational,\nasymptotically Pareto optimal allocation in a barter-exchange economy where\nagents are endowed with goods and have preferences over the goods of others,\nbut may not use money as a medium of exchange. Because one of the most\nimportant instantiations of such economies is kidney exchange -- where the\n\"input\"to the problem consists of sensitive patient medical records -- we ask\nto what extent such exchanges can be carried out while providing formal privacy\nguarantees to the participants. We show that individually rational allocations\ncannot achieve any non-trivial approximation to Pareto optimality if carried\nout under the constraint of differential privacy -- or even the relaxation of\n\\emph{joint} differential privacy, under which it is known that asymptotically\noptimal allocations can be computed in two-sided markets, where there is a\ndistinction between buyers and sellers and we are concerned only with privacy\nof the buyers~\\citep{Matching}. We therefore consider a further relaxation that\nwe call \\emph{marginal} differential privacy -- which promises, informally,\nthat the privacy of every agent $i$ is protected from every other agent $j \\neq\ni$ so long as $j$ does not collude or share allocation information with other\nagents. We show that, under marginal differential privacy, it is possible to\ncompute an individually rational and asymptotically Pareto optimal allocation\nin such exchange economies.", 
    "link": "http://arxiv.org/pdf/1407.2641v2", 
    "arxiv-id": "1407.2641v2"
},{
    "category": "cs.GT", 
    "author": "Jamie Morgenstern", 
    "title": "Learning Valuation Distributions from Partial Observation", 
    "publish": "2014-07-10T16:35:09Z", 
    "summary": "Auction theory traditionally assumes that bidders' valuation distributions\nare known to the auctioneer, such as in the celebrated, revenue-optimal Myerson\nauction. However, this theory does not describe how the auctioneer comes to\npossess this information. Recently, Cole and Roughgarden [2014] showed that an\napproximation based on a finite sample of independent draws from each bidder's\ndistribution is sufficient to produce a near-optimal auction. In this work, we\nconsider the problem of learning bidders' valuation distributions from much\nweaker forms of observations. Specifically, we consider a setting where there\nis a repeated, sealed-bid auction with $n$ bidders, but all we observe for each\nround is who won, but not how much they bid or paid. We can also participate\n(i.e., submit a bid) ourselves, and observe when we win. From this information,\nour goal is to (approximately) recover the inherently recoverable part of the\nunderlying bid distributions. We also consider extensions where different\nsubsets of bidders participate in each round, and where bidders' valuations\nhave a common-value component added to their independent private values.", 
    "link": "http://arxiv.org/pdf/1407.2855v1", 
    "arxiv-id": "1407.2855v1"
},{
    "category": "cs.GT", 
    "author": "Junghwan Shin", 
    "title": "Price of Anarchy with Heterogeneous Latency Functions", 
    "publish": "2014-07-11T00:28:34Z", 
    "summary": "In this paper we consider the price of anarchy (PoA) in multi-commodity flows\nwhere the latency or delay function on an edge has a heterogeneous dependency\non the flow commodities, i.e. when the delay on each link is dependent on the\nflow of individual commodities, rather than on the aggregate flow. An\napplication of this study is the performance analysis of a network with\ndifferentiated traffic that may arise when traffic is prioritized according to\nsome type classification. This study has implications in the debate on\nnet-neutrality. We provide price of anarchy bounds for networks with $k$ (types\nof) commodities where each link is associated with heterogeneous polynomial\ndelays, i.e. commodity $i$ on edge $e$ faces delay specified by\n$g_{i1}(e)f^{\\theta}_1(e) + g_{i2}(e)f^{\\theta}_2(e) + \\ldots +\ng_{ik}(e)f^{\\theta}_k(e) + c_i(e), $ where $f_i(e)$ is the flow of the $i$th\ncommodity through edge $e$, $\\theta \\in {\\cal N}$, $g_{i1}(e), g_{i2}(e),\n\\ldots, g_{ik}(e)$ and $c_i(e)$ are nonnegative constants. We consider both\natomic and non-atomic flows.\n  For networks with decomposable delay functions where the delay induced by a\nparticular commodity is the same, i.e. delays on edge $e$ are defined by\n$a_1(e)f_1^\\theta(e) + a_2(e)f_2^\\theta(e) + \\ldots + c(e)$ where $\\forall j ,\n\\forall e: g_{1j}(e) = g_{2j}(e) = \\ldots = a_j(e)$, we show an improved bound\non the price of anarchy.\n  Further, we show bounds on the price of anarchy for uniform latency functions\nwhere each edge of the network has the same delay function.", 
    "link": "http://arxiv.org/pdf/1407.2991v2", 
    "arxiv-id": "1407.2991v2"
},{
    "category": "cs.GT", 
    "author": "Marcin Jurdzi\u0144ski", 
    "title": "Approximate well-supported Nash equilibria in symmetric bimatrix games", 
    "publish": "2014-07-11T01:44:49Z", 
    "summary": "The $\\varepsilon$-well-supported Nash equilibrium is a strong notion of\napproximation of a Nash equilibrium, where no player has an incentive greater\nthan $\\varepsilon$ to deviate from any of the pure strategies that she uses in\nher mixed strategy. The smallest constant $\\varepsilon$ currently known for\nwhich there is a polynomial-time algorithm that computes an\n$\\varepsilon$-well-supported Nash equilibrium in bimatrix games is slightly\nbelow $2/3$. In this paper we study this problem for symmetric bimatrix games\nand we provide a polynomial-time algorithm that gives a\n$(1/2+\\delta)$-well-supported Nash equilibrium, for an arbitrarily small\npositive constant $\\delta$.", 
    "link": "http://arxiv.org/pdf/1407.3004v1", 
    "arxiv-id": "1407.3004v1"
},{
    "category": "cs.GT", 
    "author": "Alexander Skopalik", 
    "title": "Budget-restricted utility games with ordered strategic decisions", 
    "publish": "2014-07-11T12:05:12Z", 
    "summary": "We introduce the concept of budget games. Players choose a set of tasks and\neach task has a certain demand on every resource in the game. Each resource has\na budget. If the budget is not enough to satisfy the sum of all demands, it has\nto be shared between the tasks. We study strategic budget games, where the\nbudget is shared proportionally. We also consider a variant in which the order\nof the strategic decisions influences the distribution of the budgets. The\ncomplexity of the optimal solution as well as existence, complexity and quality\nof equilibria are analyzed. Finally, we show that the time an ordered budget\ngame needs to convergence towards an equilibrium may be exponential.", 
    "link": "http://arxiv.org/pdf/1407.3123v1", 
    "arxiv-id": "1407.3123v1"
},{
    "category": "cs.GT", 
    "author": "Sergei Vassilvitskii", 
    "title": "Value of Targeting", 
    "publish": "2014-07-12T03:12:49Z", 
    "summary": "We undertake a formal study of the value of targeting data to an advertiser.\nAs expected, this value is increasing in the utility difference between\nrealizations of the targeting data and the accuracy of the data, and depends on\nthe distribution of competing bids. However, this value may vary\nnon-monotonically with an advertiser's budget. Similarly, modeling the values\nas either private or correlated, or allowing other advertisers to also make use\nof the data, leads to unpredictable changes in the value of data. We address\nquestions related to multiple data sources, show that utility of additional\ndata may be non-monotonic, and provide tradeoffs between the quality and the\nprice of data sources. In a game-theoretic setting, we show that advertisers\nmay be worse off than if the data had not been available at all. We also ask\nwhether a publisher can infer the value an advertiser would place on targeting\ndata from the advertiser's bidding behavior and illustrate that this is\nimpossible.", 
    "link": "http://arxiv.org/pdf/1407.3338v1", 
    "arxiv-id": "1407.3338v1"
},{
    "category": "cs.GT", 
    "author": "Nati Linial", 
    "title": "Market Share Indicates Quality", 
    "publish": "2014-07-14T13:27:03Z", 
    "summary": "Market share and quality, or customer satisfaction, go together. Yet\ninferring one from the other appears difficult. Indeed, such an inference would\nneed detailed information about customer behavior, and might be clouded by\nmodes of behavior such as herding (following popularity) or elitism, where\ncustomers avoid popular products. We investigate a fixed-price model where\ncustomers are informed about their history with products and about market share\ndata. We find that it is in fact correct to make a Bayesian inference that the\nproduct with the higher market share has the better quality under few and\nunrestrictive assumptions on customer behavior.", 
    "link": "http://arxiv.org/pdf/1407.3641v1", 
    "arxiv-id": "1407.3641v1"
},{
    "category": "cs.GT", 
    "author": "Qiang Zhang", 
    "title": "Efficiency of Truthful and Symmetric Mechanisms in One-sided Matching", 
    "publish": "2014-07-15T12:24:47Z", 
    "summary": "We study the efficiency (in terms of social welfare) of truthful and\nsymmetric mechanisms in one-sided matching problems with {\\em dichotomous\npreferences} and {\\em normalized von Neumann-Morgenstern preferences}. We are\nparticularly interested in the well-known {\\em Random Serial Dictatorship}\nmechanism. For dichotomous preferences, we first show that truthful, symmetric\nand optimal mechanisms exist if intractable mechanisms are allowed. We then\nprovide a connection to online bipartite matching. Using this connection, it is\npossible to design truthful, symmetric and tractable mechanisms that extract\n0.69 of the maximum social welfare, which works under assumption that agents\nare not adversarial. Without this assumption, we show that Random Serial\nDictatorship always returns an assignment in which the expected social welfare\nis at least a third of the maximum social welfare. For normalized von\nNeumann-Morgenstern preferences, we show that Random Serial Dictatorship always\nreturns an assignment in which the expected social welfare is at least\n$\\frac{1}{e}\\frac{\\nu(\\opt)^2}{n}$, where $\\nu(\\opt)$ is the maximum social\nwelfare and $n$ is the number of both agents and items. On the hardness side,\nwe show that no truthful mechanism can achieve a social welfare better than\n$\\frac{\\nu(\\opt)^2}{n}$.", 
    "link": "http://arxiv.org/pdf/1407.3957v2", 
    "arxiv-id": "1407.3957v2"
},{
    "category": "cs.GT", 
    "author": "Benjamin Monmege", 
    "title": "To Reach or not to Reach? Efficient Algorithms for Total-Payoff Games", 
    "publish": "2014-07-18T15:13:13Z", 
    "summary": "Quantitative games are two-player zero-sum games played on directed weighted\ngraphs. Total-payoff games (that can be seen as a refinement of the\nwell-studied mean-payoff games) are the variant where the payoff of a play is\ncomputed as the sum of the weights. Our aim is to describe the first\npseudo-polynomial time algorithm for total-payoff games in the presence of\narbitrary weights. It consists of a non-trivial application of the value\niteration paradigm. Indeed, it requires to study, as a milestone, a refinement\nof these games, called min-cost reachability games, where we add a reachability\nobjective to one of the players. For these games, we give an efficient value\niteration algorithm to compute the values and optimal strategies (when they\nexist), that runs in pseudo-polynomial time. We also propose heuristics\nallowing one to possibly speed up the computations in both cases.", 
    "link": "http://arxiv.org/pdf/1407.5030v4", 
    "arxiv-id": "1407.5030v4"
},{
    "category": "cs.GT", 
    "author": "Oskari Tammelin", 
    "title": "Solving Large Imperfect Information Games Using CFR+", 
    "publish": "2014-07-18T15:41:28Z", 
    "summary": "Counterfactual Regret Minimization and variants (e.g. Public Chance Sampling\nCFR and Pure CFR) have been known as the best approaches for creating\napproximate Nash equilibrium solutions for imperfect information games such as\npoker. This paper introduces CFR$^+$, a new algorithm that typically\noutperforms the previously known algorithms by an order of magnitude or more in\nterms of computation time while also potentially requiring less memory.", 
    "link": "http://arxiv.org/pdf/1407.5042v1", 
    "arxiv-id": "1407.5042v1"
},{
    "category": "cs.GT", 
    "author": "Aviad Rubinstein", 
    "title": "On the Complexity of Dynamic Mechanism Design", 
    "publish": "2014-07-21T04:54:44Z", 
    "summary": "We introduce a dynamic mechanism design problem in which the designer wants\nto offer for sale an item to an agent, and another item to the same agent at\nsome point in the future. The agent's joint distribution of valuations for the\ntwo items is known, and the agent knows the valuation for the current item (but\nnot for the one in the future). The designer seeks to maximize expected\nrevenue, and the auction must be deterministic, truthful, and ex post\nindividually rational. The optimum mechanism involves a protocol whereby the\nseller elicits the buyer's current valuation, and based on the bid makes two\ntake-it-or-leave-it offers, one for now and one for the future. We show that\nfinding the optimum deterministic mechanism in this situation - arguably the\nsimplest meaningful dynamic mechanism design problem imaginable - is NP-hard.\nWe also prove several positive results, among them a polynomial linear\nprogramming-based algorithm for the optimum randomized auction (even for many\nbidders and periods), and we show strong separations in revenue between\nnon-adaptive, adaptive, and randomized auctions, even when the valuations in\nthe two periods are uncorrelated. Finally, for the same problem in an\nenvironment in which contracts cannot be enforced, and thus perfection of\nequilibrium is necessary, we show that the optimum randomized mechanism\nrequires multiple rounds of cheap talk-like interactions.", 
    "link": "http://arxiv.org/pdf/1407.5373v2", 
    "arxiv-id": "1407.5373v2"
},{
    "category": "cs.GT", 
    "author": "Slawomir Stanczak", 
    "title": "Joint Channel Selection and Power Control in Infrastructureless Wireless   Networks: A Multi-Player Multi-Armed Bandit Framework", 
    "publish": "2014-07-21T10:25:08Z", 
    "summary": "This paper deals with the problem of efficient resource allocation in dynamic\ninfrastructureless wireless networks. Assuming a reactive interference-limited\nscenario, each transmitter is allowed to select one frequency channel (from a\ncommon pool) together with a power level at each transmission trial; hence, for\nall transmitters, not only the fading gain, but also the number of interfering\ntransmissions and their transmit powers are varying over time. Due to the\nabsence of a central controller and time-varying network characteristics, it is\nhighly inefficient for transmitters to acquire global channel and network\nknowledge. Therefore a reasonable assumption is that transmitters have no\nknowledge of fading gains, interference, and network topology. Each\ntransmitting node selfishly aims at maximizing its average reward (or\nminimizing its average cost), which is a function of the action of that\nspecific transmitter as well as those of all other transmitters. This scenario\nis modeled as a multi-player multi-armed adversarial bandit game, in which\nmultiple players receive an a priori unknown reward with an arbitrarily\ntime-varying distribution by sequentially pulling an arm, selected from a known\nand finite set of arms. Since players do not know the arm with the highest\naverage reward in advance, they attempt to minimize their so-called regret,\ndetermined by the set of players' actions, while attempting to achieve\nequilibrium in some sense. To this end, we design in this paper two joint power\nlevel and channel selection strategies. We prove that the gap between the\naverage reward achieved by our approaches and that based on the best fixed\nstrategy converges to zero asymptotically. Moreover, the empirical joint\nfrequencies of the game converge to the set of correlated equilibria. We\nfurther characterize this set for two special cases of our designed game.", 
    "link": "http://arxiv.org/pdf/1407.5447v1", 
    "arxiv-id": "1407.5447v1"
},{
    "category": "cs.GT", 
    "author": "Ye Du", 
    "title": "The Discrete Sell or Hold Problem with Constraints on Asset Values", 
    "publish": "2014-07-23T08:27:24Z", 
    "summary": "The discrete sell or hold problem (DSHP), which is introduced in \\cite{H12},\nis studied under the constraint that each asset can only take a constant number\nof different values. We show that if each asset can take only two values, the\nproblem becomes polynomial-time solvable. However, even if each asset can take\nthree different values, DSHP is still NP-hard. An approximation algorithm is\nalso given under this setting.", 
    "link": "http://arxiv.org/pdf/1407.6131v1", 
    "arxiv-id": "1407.6131v1"
},{
    "category": "cs.GT", 
    "author": "Piotr Frackiewicz", 
    "title": "Quantum signaling game", 
    "publish": "2014-07-24T23:06:11Z", 
    "summary": "We present a quantum approach to a signaling game; a special kind of\nextensive games of incomplete information. Our model is based on quantum\nschemes for games in strategic form where players perform unitary operators on\ntheir own qubits of some fixed initial state and the payoff function is given\nby a measurement on the resulting final state. We show that the quantum game\ninduced by our scheme coincides with a signaling game as a special case and\noutputs nonclassical results in general. As an example, we consider a quantum\nextension of the signaling game in which the chance move is a three-parameter\nunitary operator whereas the players' actions are equivalent to classical ones.\nIn this case, we study the game in terms of Nash equilibria and refine the pure\nNash equilibria adapting to the quantum game the notion of a weak perfect\nBayesian equilibrium.", 
    "link": "http://arxiv.org/pdf/1407.6757v1", 
    "arxiv-id": "1407.6757v1"
},{
    "category": "cs.GT", 
    "author": "Sanmay Das", 
    "title": "On Manipulation in Prediction Markets When Participants Influence   Outcomes Directly", 
    "publish": "2014-07-01T04:12:31Z", 
    "summary": "Prediction markets are often used as mechanisms to aggregate information\nabout a future event, for example, whether a candidate will win an election.\nThe event is typically assumed to be exogenous. In reality, participants may\ninfluence the outcome, and therefore (1) running the prediction market could\nchange the incentives of participants in the process that creates the outcome\n(for example, agents may want to change their vote in an election), and (2)\nsimple results such as the myopic incentive compatibility of proper scoring\nrules no longer hold in the prediction market itself. We introduce a model of\ngames of this kind, where agents first trade in a prediction market and then\ntake an action that influences the market outcome. Our two-stage two-player\nmodel, despite its simplicity, captures two aspects of real-world prediction\nmarkets: (1) agents may directly influence the outcome, (2) some of the agents\ninstrumental in deciding the outcome may not take part in the prediction\nmarket. We show that this game has two different types of perfect Bayesian\nequilibria, which we term LPP and HPP, depending on the values of the belief\nparameters: in the LPP domain, equilibrium prices reveal expected market\noutcomes conditional on the participants' private information, whereas HPP\nequilibria are collusive -- participants effectively coordinate in an\nuninformative and untruthful way.", 
    "link": "http://arxiv.org/pdf/1407.7015v1", 
    "arxiv-id": "1407.7015v1"
},{
    "category": "cs.GT", 
    "author": "Chenxia Wu", 
    "title": "Price of Anarchy of Innovation Diffusion in Social Networks", 
    "publish": "2014-07-28T04:40:45Z", 
    "summary": "There have been great efforts in studying the cascading behavior in social\nnetworks such as the innovation diffusion, etc. Game theoretically, in a social\nnetwork where individuals choose from two strategies: A (the innovation) and B\n(the status quo) and get payoff from their neighbors for coordination, it has\nlong been known that the Price of Anarchy (PoA) of this game is not 1, since\nthe Nash equilibrium (NE) where all players take B (B Nash) is inferior to the\none all players taking A (A Nash). However, no quantitative analysis has been\nperformed to give an accurate upper bound of PoA in this game.\n  In this paper, we adopt a widely used networked coordination game setting [3]\nto study how bad a Nash equilibrium can be and give a tight upper bound of the\nPoA of such games. We show that there is an NE that is slightly worse than the\nB Nash. On the other hand, the PoA is bounded and the worst NE cannot be much\nworse than the B Nash. In addition, we discuss how the PoA upper bound would\nchange when compatibility between A and B is introduced, and show an intuitive\nresult that the upper bound strictly decreases as the compatibility is\nincreased.", 
    "link": "http://arxiv.org/pdf/1407.7319v1", 
    "arxiv-id": "1407.7319v1"
},{
    "category": "cs.GT", 
    "author": "Jean Walrand", 
    "title": "Monotonic Preference Aggregation Mechanisms for Purchasing a Shareable   Resource", 
    "publish": "2014-07-28T22:57:18Z", 
    "summary": "Situations where a group of agents come together to jointly buy a resource\nthat they individually cannot afford to buy are commonly observed in markets.\nFor example in the US market for radio spectrum, a recent proposal invited\nsmall firms who would benefit from gaining additional access to spectrum to\njointly submit bids for blocks of spectrum with the idea that its utilization\ncould be shared. In such a scenario, the problem is to design a mechanism that\ntruthfully elicits and aggregates the privately held preferences of these\nagents, and enables them to act as a single decision-making body in order to\nparticipate in the market. In this paper, we design a class of mechanisms\ncalled monotonic aggregation mechanisms that achieves this under a specific\nsetting. We assume that the resource is being sold in a sealed-bid second-price\nauction that solicits bids for the entire resource. Our mechanism truthfully\nelicits utility functions from the buyers, prescribes a joint bid, and\nprescribes a division of the payment and the resource in the event that they\nwin the resource in the auction. This mechanism further satisfies a popular\nnotion of collusion-resistance known as coalition-strategyproofness. We give\ntwo explicit examples of this generic class for the case where the utility\nfunctions of the buyers are non-decreasing and concave.", 
    "link": "http://arxiv.org/pdf/1407.7594v3", 
    "arxiv-id": "1407.7594v3"
},{
    "category": "cs.GT", 
    "author": "Tao Xiao", 
    "title": "Improved Efficiency Guarantees in Auctions with Budgets", 
    "publish": "2014-07-31T09:18:39Z", 
    "summary": "We study the efficiency guarantees in the simple auction environment where\nthe auctioneer has one unit of divisible good to be distributed among a number\nof budget constrained agents. With budget constraints, the social welfare\ncannot be approximated by a better factor than the number of agents by any\ntruthful mechanism. Thus, we follow a recent work by Dobzinski and Leme (ICALP\n2014) to approximate the liquid welfare, which is the welfare of the agents\neach capped by her/his own budget. We design a new truthful auction with an\napproximation ratio of $\\frac{\\sqrt{5}+1}{2} \\approx 1.618$, improving the best\nprevious ratio of $2$ when the budgets for agents are public knowledge and\ntheir valuation is linear (additive). In private budget setting, we propose the\nfirst constant approximation auction with approximation ratio of $34$.\nMoreover, this auction works for any valuation function. Previously, only\n$O(\\log n)$ approximation was known for linear and decreasing marginal\n(concave) valuations, and $O(\\log^2 n)$ approximation was known for\nsub-additive valuations.", 
    "link": "http://arxiv.org/pdf/1407.8325v3", 
    "arxiv-id": "1407.8325v3"
},{
    "category": "cs.GT", 
    "author": "Yves Smeers", 
    "title": "Equilibria on a Game with Discrete Variables", 
    "publish": "2014-07-31T12:52:33Z", 
    "summary": "Equilibrium in Economics has been seldom addressed in a situation where some\nvariables are discrete. This work introduces a problem related to lot-sizing\nwith several players, and analyses some strategies which are likely to be found\nin real world games. An illustration with a simple example is presented, with\nconcerns about the difficulty of the problem and computation possibilities.", 
    "link": "http://arxiv.org/pdf/1407.8394v2", 
    "arxiv-id": "1407.8394v2"
},{
    "category": "cs.GT", 
    "author": "Adrian Vetta", 
    "title": "A Near-Optimal Mechanism for Impartial Selection", 
    "publish": "2014-07-31T19:02:27Z", 
    "summary": "We examine strategy-proof elections to select a winner amongst a set of\nagents, each of whom cares only about winning. This impartial selection problem\nwas introduced independently by Holzman and Moulin and Alon et al. Fisher and\nKlimm showed that the permutation mechanism is impartial and $1/2$-optimal,\nthat is, it selects an agent who gains, in expectation, at least half the\nnumber of votes of most popular agent. Furthermore, they showed the mechanism\nis $7/12$-optimal if agents cannot abstain in the election. We show that a\nbetter guarantee is possible, provided the most popular agent receives at least\na large enough, but constant, number of votes. Specifically, we prove that, for\nany $\\epsilon>0$, there is a constant $N_{\\epsilon}$ (independent of the number\n$n$ of voters) such that, if the maximum number of votes of the most popular\nagent is at least $N_{\\epsilon}$ then the permutation mechanism is\n$(\\frac{3}{4}-\\epsilon)$-optimal. This result is tight.\n  Furthermore, in our main result, we prove that near-optimal impartial\nmechanisms exist. In particular, there is an impartial mechanism that is\n$(1-\\epsilon)$-optimal, for any $\\epsilon>0$, provided that the maximum number\nof votes of the most popular agent is at least a constant $M_{\\epsilon}$.", 
    "link": "http://arxiv.org/pdf/1407.8535v1", 
    "arxiv-id": "1407.8535v1"
},{
    "category": "cs.GT", 
    "author": "Rann Smorodinsky", 
    "title": "Perception Games and Privacy", 
    "publish": "2014-09-04T16:53:26Z", 
    "summary": "Players (people, firms, states, etc.) have privacy concerns that may affect\ntheir choice of actions in strategic settings. We use a variant of signaling\ngames to model this effect and study its relation to pooling behavior,\nmisrepresentation of information, and inefficiency. We discuss these issues and\nshow that common intuitions may lead to inaccurate conclusions about the\nimplications of privacy concerns.", 
    "link": "http://arxiv.org/pdf/1409.1487v3", 
    "arxiv-id": "1409.1487v3"
},{
    "category": "cs.GT", 
    "author": "Robert D. Kleinberg", 
    "title": "Simple and Near-Optimal Mechanisms For Market Intermediation", 
    "publish": "2014-09-09T05:10:46Z", 
    "summary": "A prevalent market structure in the Internet economy consists of buyers and\nsellers connected by a platform (such as Amazon or eBay) that acts as an\nintermediary and keeps a share of the revenue of each transaction. While the\noptimal mechanism that maximizes the intermediary's profit in such a setting\nmay be quite complicated, the mechanisms observed in reality are generally much\nsimpler, e.g., applying an affine function to the price of the transaction as\nthe intermediary's fee. Loertscher and Niedermayer [2007] initiated the study\nof such fee-setting mechanisms in two-sided markets, and we continue this\ninvestigation by addressing the question of when an affine fee schedule is\napproximately optimal for worst-case seller distribution. On one hand our work\nsupplies non-trivial sufficient conditions on the buyer side (i.e. linearity of\nmarginal revenue function, or MHR property of value and value minus cost\ndistributions) under which an affine fee schedule can obtain a constant\nfraction of the intermediary's optimal profit for all seller distributions. On\nthe other hand we complement our result by showing that proper affine\nfee-setting mechanisms (e.g. those used in eBay and Amazon selling plans) are\nunable to extract a constant fraction of optimal profit in the worst-case\nseller distribution. As subsidiary results we also show there exists a constant\ngap between maximum surplus and maximum revenue under the aforementioned\nconditions. Most of the mechanisms that we propose are also prior-independent\nwith respect to the seller, which signifies the practical implications of our\nresult.", 
    "link": "http://arxiv.org/pdf/1409.2597v1", 
    "arxiv-id": "1409.2597v1"
},{
    "category": "cs.GT", 
    "author": "Paul Spirakis", 
    "title": "Computing Approximate Nash Equilibria in Polymatrix Games", 
    "publish": "2014-09-12T14:04:29Z", 
    "summary": "In an $\\epsilon$-Nash equilibrium, a player can gain at most $\\epsilon$ by\nunilaterally changing his behaviour. For two-player (bimatrix) games with\npayoffs in $[0,1]$, the best-known$\\epsilon$ achievable in polynomial time is\n0.3393. In general, for $n$-player games an $\\epsilon$-Nash equilibrium can be\ncomputed in polynomial time for an $\\epsilon$ that is an increasing function of\n$n$ but does not depend on the number of strategies of the players. For\nthree-player and four-player games the corresponding values of $\\epsilon$ are\n0.6022 and 0.7153, respectively. Polymatrix games are a restriction of general\n$n$-player games where a player's payoff is the sum of payoffs from a number of\nbimatrix games. There exists a very small but constant $\\epsilon$ such that\ncomputing an $\\epsilon$-Nash equilibrium of a polymatrix game is \\PPAD-hard.\nOur main result is that a $(0.5+\\delta)$-Nash equilibrium of an $n$-player\npolymatrix game can be computed in time polynomial in the input size and\n$\\frac{1}{\\delta}$. Inspired by the algorithm of Tsaknakis and Spirakis, our\nalgorithm uses gradient descent on the maximum regret of the players. We also\nshow that this algorithm can be applied to efficiently find a\n$(0.5+\\delta)$-Nash equilibrium in a two-player Bayesian game.", 
    "link": "http://arxiv.org/pdf/1409.3741v2", 
    "arxiv-id": "1409.3741v2"
},{
    "category": "cs.GT", 
    "author": "Jiajun Sun", 
    "title": "An Incentive Mechanism for Periodical Mobile Crowdsensing from a   Frugality Perspective", 
    "publish": "2014-09-14T04:00:07Z", 
    "summary": "Mobile crowdsensing (MCS) has been intensively explored recently due to its\nflexible and pervasive sensing ability. Although many incentive mechanisms have\nbeen built to attract extensive user participation, Most of these mechanisms\nfocus only on independent task scenarios, where the sensing tasks are\nindependent of each other. On the contrary, we focus on a periodical task\nscenario, where each user participates in the same type of sensing tasks\nperiodically. In this paper, we consider the long-term user participation\nincentive in a general periodical MCS system from a frugality payment\nperspective. We explore the issue under both semi-online (the intra-period\ninteractive process is synchronous while the inter-period interactive process\nis sequential and asynchronous during each period) and online user arrival\nmodels (the previous two interactive processes are sequential and\nasynchronous). In particular, we first propose a semi-online frugal incentive\nmechanism by introducing a Lyapunov method. Moreover, we also extend it to an\nonline frugal incentive mechanism, which satisfies the constant frugality.\nBesides, the two mechanisms can also satisfy computational efficiency,\nasymptotical optimality, individual rationality and truthfulness. Through\nextensive simulations, we evaluate the performance and validate the theoretical\nproperties of our online mechanisms.", 
    "link": "http://arxiv.org/pdf/1409.4010v6", 
    "arxiv-id": "1409.4010v6"
},{
    "category": "cs.GT", 
    "author": "Piotr Skowron", 
    "title": "Equilibria of Plurality Voting: Lazy and Truth-biased Voters", 
    "publish": "2014-09-15T01:44:38Z", 
    "summary": "We present a systematic study of Plurality elections with strategic voters\nwho, in addition to having preferences over election winners, have secondary\npreferences, which govern their behavior when their vote cannot affect the\nelection outcome. Specifically, we study two models that have been recently\nconsidered in the literature: lazy voters, who prefer to abstain when they are\nnot pivotal, and truth-biased voters, who prefer to vote truthfully when they\nare not pivotal. We extend prior work by investigating the behavior of both\nlazy and truth-biased voters under different tie-breaking rules (lexicographic\nrule, random voter rule, random candidate rule). Two of these six combinations\nof secondary preferences and a tie-breaking rule have been studied in prior\nwork. In order to understand the impact of different secondary preferences and\ntie-breaking rules on the election outcomes, we study the remaining four\ncombinations. We characterize pure Nash equilibria (PNE) of the resulting\nstrategic games and study the complexity of related computational problems. Our\nresults extend to settings where some of the voters may be non-strategic.", 
    "link": "http://arxiv.org/pdf/1409.4132v1", 
    "arxiv-id": "1409.4132v1"
},{
    "category": "cs.GT", 
    "author": "Christos Tzamos", 
    "title": "Strong Duality for a Multiple-Good Monopolist", 
    "publish": "2014-09-15T03:54:55Z", 
    "summary": "We provide a duality-based framework for revenue maximization in a\nmultiple-good monopoly. Our framework shows that every optimal mechanism has a\ncertificate of optimality, taking the form of an optimal transportation map\nbetween measures. Using our framework, we prove that grand-bundling mechanisms\nare optimal if and only if two stochastic dominance conditions hold between\nspecific measures induced by the buyer's type distribution. This result\nstrengthens several results in the literature, where only sufficient conditions\nfor grand-bundling optimality have been provided. As a corollary of our tight\ncharacterization of grand-bundling optimality, we show that the optimal\nmechanism for $n$ independent uniform items each supported on $[c,c+1]$ is a\ngrand-bundling mechanism, as long as $c$ is sufficiently large, extending\nPavlov's result for 2 items [Pavlov11]. In contrast, our characterization also\nimplies that, for all $c$ and for all sufficiently large $n$, the optimal\nmechanism for $n$ independent uniform items supported on $[c,c+1]$ is not a\ngrand bundling mechanism. The necessary and sufficient condition for grand\nbundling optimality is a special case of our more general characterization\nresult that provides necessary and sufficient conditions for the optimality of\nan arbitrary mechanism (with a finite menu size) for an arbitrary type\ndistribution.", 
    "link": "http://arxiv.org/pdf/1409.4150v2", 
    "arxiv-id": "1409.4150v2"
},{
    "category": "cs.GT", 
    "author": "Lisa Wagner", 
    "title": "Matching Dynamics with Constraints", 
    "publish": "2014-09-15T15:56:26Z", 
    "summary": "We study uncoordinated matching markets with additional local constraints\nthat capture, e.g., restricted information, visibility, or externalities in\nmarkets. Each agent is a node in a fixed matching network and strives to be\nmatched to another agent. Each agent has a complete preference list over all\nother agents it can be matched with. However, depending on the constraints and\nthe current state of the game, not all possible partners are available for\nmatching at all times. For correlated preferences, we propose and study a\ngeneral class of hedonic coalition formation games that we call coalition\nformation games with constraints. This class includes and extends many recently\nstudied variants of stable matching, such as locally stable matching, socially\nstable matching, or friendship matching. Perhaps surprisingly, we show that all\nthese variants are encompassed in a class of \"consistent\" instances that always\nallow a polynomial improvement sequence to a stable state. In addition, we show\nthat for consistent instances there always exists a polynomial sequence to\nevery reachable state. Our characterization is tight in the sense that we\nprovide exponential lower bounds when each of the requirements for consistency\nis violated. We also analyze matching with uncorrelated preferences, where we\nobtain a larger variety of results. While socially stable matching always\nallows a polynomial sequence to a stable state, for other classes different\nadditional assumptions are sufficient to guarantee the same results. For the\nproblem of reaching a given stable state, we show NP-hardness in almost all\nconsidered classes of matching games.", 
    "link": "http://arxiv.org/pdf/1409.4304v1", 
    "arxiv-id": "1409.4304v1"
},{
    "category": "cs.GT", 
    "author": "R. Preston McAfee", 
    "title": "Position Auctions with Externalities and Brand Effects", 
    "publish": "2014-09-16T16:28:38Z", 
    "summary": "This paper presents models for predicted click-through rates in position\nauctions that take into account two possibilities that are not normally\nconsidered---that the identities of ads shown in other positions may affect the\nprobability that an ad in a particular position receives a click\n(externalities) and that some ads may be less adversely affected by being shown\nin a lower position than others (brand effects). We present a general axiomatic\nmethodology for how click probabilities are affected by the qualities of the\nads in the other positions, and illustrate that using these axioms will\nincrease revenue as long as higher quality ads tend to be ranked ahead of lower\nquality ads. We also present appropriate algorithms for selecting the optimal\nallocation of ads when predicted click-through rates are governed by either the\nmodels of externalities or brand effects that we consider. Finally, we analyze\nthe performance of a greedy algorithm of ranking the ads by their expected\ncost-per-1000-impressions bids when the true click-through rates are governed\nby our model of predicted click-through rates with brand effects and illustrate\nthat such an algorithm will potentially cost as much as half of the total\npossible social welfare.", 
    "link": "http://arxiv.org/pdf/1409.4687v1", 
    "arxiv-id": "1409.4687v1"
},{
    "category": "cs.GT", 
    "author": "Udi Weinsberg", 
    "title": "The Shapley Value in Knapsack Budgeted Games", 
    "publish": "2014-09-18T06:03:03Z", 
    "summary": "We propose the study of computing the Shapley value for a new class of\ncooperative games that we call budgeted games, and investigate in particular\nknapsack budgeted games, a version modeled after the classical knapsack\nproblem. In these games, the \"value\" of a set $S$ of agents is determined only\nby a critical subset $T\\subseteq S$ of the agents and not the entirety of $S$\ndue to a budget constraint that limits how large $T$ can be. We show that the\nShapley value can be computed in time faster than by the na\\\"ive exponential\ntime algorithm when there are sufficiently many agents, and also provide an\nalgorithm that approximates the Shapley value within an additive error. For a\nrelated budgeted game associated with a greedy heuristic, we show that the\nShapley value can be computed in pseudo-polynomial time. Furthermore, we\ngeneralize our proof techniques and propose what we term algorithmic\nrepresentation framework that captures a broad class of cooperative games with\nthe property of efficient computation of the Shapley value. The main idea is\nthat the problem of determining the efficient computation can be reduced to\nthat of finding an alternative representation of the games and an associated\nalgorithm for computing the underlying value function with small time and space\ncomplexities in the representation size.", 
    "link": "http://arxiv.org/pdf/1409.5200v1", 
    "arxiv-id": "1409.5200v1"
},{
    "category": "cs.GT", 
    "author": "Rasmus Ibsen-Jensen", 
    "title": "Qualitative Analysis of Concurrent Mean-payoff Games", 
    "publish": "2014-09-18T14:12:13Z", 
    "summary": "We consider concurrent games played by two-players on a finite-state graph,\nwhere in every round the players simultaneously choose a move, and the current\nstate along with the joint moves determine the successor state. We study a\nfundamental objective, namely, mean-payoff objective, where a reward is\nassociated to each transition, and the goal of player 1 is to maximize the\nlong-run average of the rewards, and the objective of player 2 is strictly the\nopposite. The path constraint for player 1 could be qualitative, i.e., the\nmean-payoff is the maximal reward, or arbitrarily close to it; or quantitative,\ni.e., a given threshold between the minimal and maximal reward. We consider the\ncomputation of the almost-sure (resp. positive) winning sets, where player 1\ncan ensure that the path constraint is satisfied with probability 1 (resp.\npositive probability). Our main results for qualitative path constraints are as\nfollows: (1) we establish qualitative determinacy results that show that for\nevery state either player 1 has a strategy to ensure almost-sure (resp.\npositive) winning against all player-2 strategies, or player 2 has a spoiling\nstrategy to falsify almost-sure (resp. positive) winning against all player-1\nstrategies; (2) we present optimal strategy complexity results that precisely\ncharacterize the classes of strategies required for almost-sure and positive\nwinning for both players; and (3) we present quadratic time algorithms to\ncompute the almost-sure and the positive winning sets, matching the best known\nbound of algorithms for much simpler problems (such as reachability\nobjectives). For quantitative constraints we show that a polynomial time\nsolution for the almost-sure or the positive winning set would imply a solution\nto a long-standing open problem (the value problem for turn-based deterministic\nmean-payoff games) that is not known to be solvable in polynomial time.", 
    "link": "http://arxiv.org/pdf/1409.5306v1", 
    "arxiv-id": "1409.5306v1"
},{
    "category": "cs.GT", 
    "author": "Friedhelm Meyer auf der Heide", 
    "title": "Quality of Service in Network Creation Games", 
    "publish": "2014-09-18T16:33:45Z", 
    "summary": "Network creation games model the creation and usage costs of networks formed\nby n selfish nodes. Each node v can buy a set of edges, each for a fixed price\n\\alpha > 0. Its goal is to minimize its private costs, i.e., the sum (SUM-game,\nFabrikant et al., PODC 2003) or maximum (MAX-game, Demaine et al., PODC 2007)\nof distances from $v$ to all other nodes plus the prices of the bought edges.\nThe above papers show the existence of Nash equilibria as well as upper and\nlower bounds for the prices of anarchy and stability. In several subsequent\npapers, these bounds were improved for a wide range of prices \\alpha. In this\npaper, we extend these models by incorporating quality-of-service aspects: Each\nedge cannot only be bought at a fixed quality (edge length one) for a fixed\nprice \\alpha. Instead, we assume that quality levels (i.e., edge lengths) are\nvarying in a fixed interval [\\beta,B], 0 < \\beta <= B. A node now cannot only\nchoose which edge to buy, but can also choose its quality x, for the price\np(x), for a given price function p. For both games and all price functions, we\nshow that Nash equilibria exist and that the price of stability is either\nconstant or depends only on the interval size of available edge lengths. Our\nmain results are bounds for the price of anarchy. In case of the SUM-game, we\nshow that they are tight if price functions decrease sufficiently fast.", 
    "link": "http://arxiv.org/pdf/1409.5366v1", 
    "arxiv-id": "1409.5366v1"
},{
    "category": "cs.GT", 
    "author": "Alexander Skopalik", 
    "title": "Multilevel Network Games", 
    "publish": "2014-09-18T17:34:55Z", 
    "summary": "We consider a multilevel network game, where nodes can improve their\ncommunication costs by connecting to a high-speed network. The $n$ nodes are\nconnected by a static network and each node can decide individually to become a\ngateway to the high-speed network. The goal of a node $v$ is to minimize its\nprivate costs, i.e., the sum (SUM-game) or maximum (MAX-game) of communication\ndistances from $v$ to all other nodes plus a fixed price $\\alpha > 0$ if it\ndecides to be a gateway. Between gateways the communication distance is $0$,\nand gateways also improve other nodes' distances by behaving as shortcuts. For\nthe SUM-game, we show that for $\\alpha \\leq n-1$, the price of anarchy is\n$\\Theta(n/\\sqrt{\\alpha})$ and in this range equilibria always exist. In range\n$\\alpha \\in (n-1,n(n-1))$ the price of anarchy is $\\Theta(\\sqrt{\\alpha})$, and\nfor $\\alpha \\geq n(n-1)$ it is constant. For the MAX-game, we show that the\nprice of anarchy is either $\\Theta(1 + n/\\sqrt{\\alpha})$, for $\\alpha\\geq 1$,\nor else $1$. Given a graph with girth of at least $4\\alpha$, equilibria always\nexist. Concerning the dynamics, both the SUM-game and the MAX-game are not\npotential games. For the SUM-game, we even show that it is not weakly acyclic.", 
    "link": "http://arxiv.org/pdf/1409.5383v1", 
    "arxiv-id": "1409.5383v1"
},{
    "category": "cs.GT", 
    "author": "Jialin Zhang", 
    "title": "Computing the Least-core and Nucleolus for Threshold Cardinality   Matching Games", 
    "publish": "2014-09-21T14:19:11Z", 
    "summary": "Cooperative games provide a framework for fair and stable profit allocation\nin multi-agent systems. \\emph{Core}, \\emph{least-core} and \\emph{nucleolus} are\nsuch solution concepts that characterize stability of cooperation. In this\npaper, we study the algorithmic issues on the least-core and nucleolus of\nthreshold cardinality matching games (TCMG). A TCMG is defined on a graph\n$G=(V,E)$ and a threshold $T$, in which the player set is $V$ and the profit of\na coalition $S\\subseteq V$ is 1 if the size of a maximum matching in $G[S]$\nmeets or exceeds $T$, and 0 otherwise. We first show that for a TCMG, the\nproblems of computing least-core value, finding and verifying least-core payoff\nare all polynomial time solvable. We also provide a general characterization of\nthe least core for a large class of TCMG. Next, based on Gallai-Edmonds\nDecomposition in matching theory, we give a concise formulation of the\nnucleolus for a typical case of TCMG which the threshold $T$ equals $1$. When\nthe threshold $T$ is relevant to the input size, we prove that the nucleolus\ncan be obtained in polynomial time in bipartite graphs and graphs with a\nperfect matching.", 
    "link": "http://arxiv.org/pdf/1409.5987v1", 
    "arxiv-id": "1409.5987v1"
},{
    "category": "cs.GT", 
    "author": "Chun Ye", 
    "title": "Structure and complexity of ex post efficient random assignments", 
    "publish": "2014-09-22T03:39:59Z", 
    "summary": "In the random assignment problem, objects are randomly assigned to agents\nkeeping in view the agents' preferences over objects. A random assignment\nspecifies the probability of an agent getting an object. We examine the\nstructural and computational aspects of ex post efficiency of random\nassignments. We first show that whereas an ex post efficient assignment can be\ncomputed easily, checking whether a given random assignment is ex post\nefficient is NP-complete. Hence implementing a given random assignment via\ndeterministic Pareto optimal assignments is NP-hard. We then formalize another\nconcept of efficiency called robust ex post efficiency that is weaker than\nstochastic dominance efficiency but stronger than ex post efficiency. We\npresent a characterization of robust ex post efficiency and show that it can be\ntested in polynomial time if there are a constant number of agent types. It is\nshown that the well-known random serial dictatorship rule is not robust ex post\nefficient. Finally, we show that whereas robust ex post efficiency depends\nsolely on which entries of the assignment matrix are zero/non-zero, ex post\nefficiency of an assignment depends on the actual values.", 
    "link": "http://arxiv.org/pdf/1409.6076v1", 
    "arxiv-id": "1409.6076v1"
},{
    "category": "cs.GT", 
    "author": "Jean-Pierre Dupuy", 
    "title": "Perfect Prediction Equilibrium", 
    "publish": "2014-09-22T13:40:24Z", 
    "summary": "In the framework of finite games in extensive form with perfect information\nand strict preferences, this paper introduces a new equilibrium concept: the\nPerfect Prediction Equilibrium (PPE).\n  In the Nash paradigm, rational players consider that the opponent's strategy\nis fixed while maximizing their payoff. The PPE, on the other hand, models the\nbehavior of agents with an alternate form of rationality that involves a\nStackelberg competition with the past.\n  Agents with this form of rationality integrate in their reasoning that they\nhave such accurate logical and predictive skills, that the world is fully\ntransparent: all players share the same knowledge and know as much as an\nomniscient external observer. In particular, there is common knowledge of the\nsolution of the game including the reached outcome and the thought process\nleading to it. The PPE is stable given each player's knowledge of its actual\noutcome and uses no assumptions at unreached nodes.\n  This paper gives the general definition and construction of the PPE as a\nfixpoint problem, proves its existence, uniqueness and Pareto optimality, and\npresents two algorithms to compute it. Finally, the PPE is put in perspective\nwith existing literature (Newcomb's Problem, Superrationality, Nash\nEquilibrium, Subgame Perfect Equilibrium, Backward Induction Paradox, Forward\nInduction).", 
    "link": "http://arxiv.org/pdf/1409.6172v2", 
    "arxiv-id": "1409.6172v2"
},{
    "category": "cs.GT", 
    "author": "Stephane Le Roux", 
    "title": "On terminating improvement in two-player games", 
    "publish": "2014-09-23T11:16:53Z", 
    "summary": "A real-valued game has the finite improvement property (FIP), if starting\nfrom an arbitrary strategy profile and letting the players change strategies to\nincrease their individual payoffs in a sequential but non-deterministic order\nalways reaches a Nash equilibrium. E.g., potential games have the FIP. Many of\nthem have the FIP by chance nonetheless, since modifying even a single payoff\nmay ruin the property. This article characterises (in quadratic time) the class\nof the finite games where FIP not only holds but is also preserved when\nmodifying all the occurrences of an arbitrary payoff. The characterisation\nrelies on a pattern-matching sufficient condition for games (finite or\ninfinite) to enjoy the FIP, and is followed by an inductive description of this\nclass.\n  A real-valued game is weakly acyclic if the improvement described above can\nreach a Nash equilibrium. This article characterises the finite such games\nusing Markov chains and almost sure convergence to equilibrium. It also gives\nan inductive description of the two-player such games.", 
    "link": "http://arxiv.org/pdf/1409.6489v2", 
    "arxiv-id": "1409.6489v2"
},{
    "category": "cs.GT", 
    "author": "Rasmus Ibsen-Jensen", 
    "title": "The Value 1 Problem Under Finite-memory Strategies for Concurrent   Mean-payoff Games", 
    "publish": "2014-09-23T18:37:00Z", 
    "summary": "We consider concurrent mean-payoff games, a very well-studied class of\ntwo-player (player 1 vs player 2) zero-sum games on finite-state graphs where\nevery transition is assigned a reward between 0 and 1, and the payoff function\nis the long-run average of the rewards. The value is the maximal expected\npayoff that player 1 can guarantee against all strategies of player 2. We\nconsider the computation of the set of states with value 1 under finite-memory\nstrategies for player 1, and our main results for the problem are as follows:\n(1) we present a polynomial-time algorithm; (2) we show that whenever there is\na finite-memory strategy, there is a stationary strategy that does not need\nmemory at all; and (3) we present an optimal bound (which is double\nexponential) on the patience of stationary strategies (where patience of a\ndistribution is the inverse of the smallest positive probability and represents\na complexity measure of a stationary strategy).", 
    "link": "http://arxiv.org/pdf/1409.6690v2", 
    "arxiv-id": "1409.6690v2"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "A Generalization of the AL method for Fair Allocation of Indivisible   Objects", 
    "publish": "2014-09-23T22:16:46Z", 
    "summary": "We consider the assignment problem in which agents express ordinal\npreferences over $m$ objects and the objects are allocated to the agents based\non the preferences. In a recent paper, Brams, Kilgour, and Klamler (2014)\npresented the AL method to compute an envy-free assignment for two agents. The\nAL method crucially depends on the assumption that agents have strict\npreferences over objects. We generalize the AL method to the case where agents\nmay express indifferences and prove the axiomatic properties satisfied by the\nalgorithm. As a result of the generalization, we also get a $O(m)$ speedup on\nprevious algorithms to check whether a complete envy-free assignment exists or\nnot. Finally, we show that unless P=NP, there can be no polynomial-time\nextension of GAL to the case of arbitrary number of agents.", 
    "link": "http://arxiv.org/pdf/1409.6765v3", 
    "arxiv-id": "1409.6765v3"
},{
    "category": "cs.GT", 
    "author": "Yiannis Giannakopoulos", 
    "title": "A Note on Selling Optimally Two Uniformly Distributed Goods", 
    "publish": "2014-09-24T12:33:41Z", 
    "summary": "We provide a new, much simplified and straightforward proof to a result of\nPavlov [2011] regarding the revenue maximizing mechanism for selling two goods\nwith uniformly i.i.d. valuations over intervals $[c,c+1]$, to an additive\nbuyer. This is done by explicitly defining optimal dual solutions to a relaxed\nversion of the problem, where the convexity requirement for the bidder's\nutility has been dropped. Their optimality comes directly from their structure,\nthrough the use of exact complementarity. For $c=0$ and $c\\geq 0.092$ it turns\nout that the corresponding optimal primal solution is a feasible selling\nmechanism, thus the initial relaxation comes without a loss, and revenue\nmaximality follows. However, for $0<c<0.092$ that's not the case, providing the\nfirst clear example where relaxing convexity provably does not come for free,\neven in a two-item regularly i.i.d. setting.", 
    "link": "http://arxiv.org/pdf/1409.6925v4", 
    "arxiv-id": "1409.6925v4"
},{
    "category": "cs.GT", 
    "author": "Eitan Altman", 
    "title": "Altruism in groups: an evolutionary games approach", 
    "publish": "2014-09-25T15:19:47Z", 
    "summary": "We revisit in this paper the relation between evolution of species and the\nmathematical tool of evolutionary games, which has been used to model and\npredict it. We indicate known shortcoming of this model that restricts the\ncapacity of evolutionary games to model groups of individuals that share a\ncommon gene or a common fitness function. In this paper we provide a new\nconcept to remedy this shortcoming in the standard evolutionary games in order\nto cover this kind of behavior. Further, we explore the relationship between\nthis new concept and Nash equilibrium or ESS. We indicate through the study of\nsome example in the biology as Hawk and Dove game, Stag Hunt Game and Prisoner\nDilemma, that when taking into account a utility that is common to a group of\nindividuals, the equilibrium structure may change dramatically. We also study\nthe multiple access control in slotted Aloha based wireless networks. We\nanalyze the impact of the altruism behavior on the performance at the\nequilibrium.", 
    "link": "http://arxiv.org/pdf/1409.7288v2", 
    "arxiv-id": "1409.7288v2"
},{
    "category": "cs.GT", 
    "author": "Jing Chen", 
    "title": "Truthful Multi-unit Procurements with Budgets", 
    "publish": "2014-09-26T14:58:42Z", 
    "summary": "We study procurement games where each seller supplies multiple units of his\nitem, with a cost per unit known only to him. The buyer can purchase any number\nof units from each seller, values different combinations of the items\ndifferently, and has a budget for his total payment.\n  For a special class of procurement games, the {\\em bounded knapsack} problem,\nwe show that no universally truthful budget-feasible mechanism can approximate\nthe optimal value of the buyer within $\\ln n$, where $n$ is the total number of\nunits of all items available. We then construct a polynomial-time mechanism\nthat gives a $4(1+\\ln n)$-approximation for procurement games with {\\em concave\nadditive valuations}, which include bounded knapsack as a special case. Our\nmechanism is thus optimal up to a constant factor. Moreover, for the bounded\nknapsack problem, given the well-known FPTAS, our results imply there is a\nprovable gap between the optimization domain and the mechanism design domain.\n  Finally, for procurement games with {\\em sub-additive valuations}, we\nconstruct a universally truthful budget-feasible mechanism that gives an\n$O(\\frac{\\log^2 n}{\\log \\log n})$-approximation in polynomial time with a\ndemand oracle.", 
    "link": "http://arxiv.org/pdf/1409.7595v1", 
    "arxiv-id": "1409.7595v1"
},{
    "category": "cs.GT", 
    "author": "Adrian Vetta", 
    "title": "The effect of a finite time horizon in the durable good monopoly problem   with atomic consumers", 
    "publish": "2014-09-29T01:48:41Z", 
    "summary": "A durable good is a long-lasting good that can be consumed repeatedly over\ntime, and a duropolist is a monopolist in the market of a durable good. In\n1972, Ronald Coase conjectured that a duropolist who lacks commitment power\ncannot sell the good above the competitive price if the time between periods\napproaches zero. Coase's counterintuitive conjecture was later proven by Gul et\nal. (1986) under an infinite time horizon model with non-atomic consumers.\nRemarkably, the situation changes dramatically for atomic consumers and an\ninfinite time horizon. Bagnoli et al. (1989) showed the existence of a\nsubgame-perfect Nash equilibrium where the duropolist extracts all the consumer\nsurplus. Observe that, in these cases, duropoly profits are either arbitrarily\nsmaller or arbitrarily larger than the corresponding static monopoly profits --\nthe profit a monopolist for an equivalent consumable good could generate. In\nthis paper we show that the result of Bagnoli et al. (1989) is in fact driven\nby the infinite time horizon. Indeed, we prove that for finite time horizons\nand atomic agents, in any equilibrium satisfying the standard skimming\nproperty, duropoly profits are at most an additive factor more than static\nmonopoly profits. In particular, duropoly profits are always at least static\nmonopoly profits but never exceed twice the static monopoly profits.\n  Finally we show that, for atomic consumers, equilibria may exist that do not\nsatisfy the skimming property. For two time periods, we prove that amongst all\nequilibria that maximize duropoly profits, at least one of them satisfies the\nskimming property. We conjecture that this is true for any number of time\nperiod.", 
    "link": "http://arxiv.org/pdf/1409.7979v3", 
    "arxiv-id": "1409.7979v3"
},{
    "category": "cs.GT", 
    "author": "N. Stier-Moses", 
    "title": "The Burden of Risk Aversion in Mean-Risk Selfish Routing", 
    "publish": "2014-11-01T03:29:59Z", 
    "summary": "Considering congestion games with uncertain delays, we compute the\ninefficiency introduced in network routing by risk-averse agents. At\nequilibrium, agents may select paths that do not minimize the expected latency\nso as to obtain lower variability. A social planner, who is likely to be more\nrisk neutral than agents because it operates at a longer time-scale, quantifies\nsocial cost with the total expected delay along routes. From that perspective,\nagents may make suboptimal decisions that degrade long-term quality. We define\nthe {\\em price of risk aversion} (PRA) as the worst-case ratio of the social\ncost at a risk-averse Wardrop equilibrium to that where agents are\nrisk-neutral. For networks with general delay functions and a single\nsource-sink pair, we show that the PRA depends linearly on the agents' risk\ntolerance and on the degree of variability present in the network. In contrast\nto the {\\em price of anarchy}, in general the PRA increases when the network\ngets larger but it does not depend on the shape of the delay functions. To get\nthis result we rely on a combinatorial proof that employs alternating paths\nthat are reminiscent of those used in max-flow algorithms. For {\\em\nseries-parallel} (SP) graphs, the PRA becomes independent of the network\ntopology and its size. As a result of independent interest, we prove that for\nSP networks with deterministic delays, Wardrop equilibria {\\em maximize} the\nshortest-path objective among all feasible flows.", 
    "link": "http://arxiv.org/pdf/1411.0059v2", 
    "arxiv-id": "1411.0059v2"
},{
    "category": "cs.GT", 
    "author": "Eric Bax", 
    "title": "Incorporating Hidden Costs of Annoying Ads in Display Auctions", 
    "publish": "2014-11-03T21:38:55Z", 
    "summary": "Media publisher platforms often face an effectiveness-nuisance tradeoff: more\nannoying ads can be more effective for some advertisers because of their\nability to attract attention, but after attracting viewers' attention, their\nnuisance to viewers can decrease engagement with the platform over time. With\nthe rise of mobile technology and ad blockers, many platforms are becoming\nincreasingly concerned about how to improve monetization through digital ads\nwhile improving viewer experience.\n  We study an online ad auction mechanism that incorporates a charge for ad\nimpact on user experience as a criterion for ad selection and pricing. Like a\nPigovian tax, the charge causes advertisers to internalize the hidden cost of\nforegone future platform revenue due to ad impact on user experience. Over\ntime, the mechanism provides an incentive for advertisers to develop ads that\nare effective while offering viewers a more pleasant experience. We show that\nadopting the mechanism can simultaneously benefit the publisher, advertisers,\nand viewers, even in the short term.\n  Incorporating a charge for ad impact can increase expected advertiser profits\nif enough advertisers compete. A stronger effectiveness-nuisance tradeoff,\nmeaning that ad effectiveness is more strongly associated with negative impact\non user experience, increases the amount of competition required for the\nmechanism to benefit advertisers. The findings suggest that the mechanism can\nbenefit the marketplace for ad slots that consistently attract many\nadvertisers.", 
    "link": "http://arxiv.org/pdf/1411.0710v2", 
    "arxiv-id": "1411.0710v2"
},{
    "category": "cs.GT", 
    "author": "Paul Christiano", 
    "title": "Provably Manipulation-Resistant Reputation Systems", 
    "publish": "2014-11-05T01:28:47Z", 
    "summary": "We consider a community of users who must make periodic decisions about\nwhether to interact with one another. We propose a protocol which allows honest\nusers to reliably interact with each other, while limiting the damage done by\neach malicious or incompetent user. The worst-case cost per user is sublinear\nin the average number of interactions per user and is independent of the number\nof users. Our guarantee holds simultaneously for every group of honest users.\nFor example, multiple groups of users with incompatible tastes or preferences\ncan coexist.\n  As a motivating example, we consider a game where players have periodic\nopportunities to do one another favors but minimal ability to determine when a\nfavor was done. In this setting, our protocol achieves nearly optimal\ncollective welfare while remaining resistant to exploitation.\n  Our results also apply to a collaborative filtering setting where users must\nmake periodic decisions about whether to interact with resources such as movies\nor restaurants. In this setting, we guarantee that any set of honest users\nachieves a payoff nearly as good as if they had identified the optimal set of\nitems in advance and then chosen to interact only with resources from that set.", 
    "link": "http://arxiv.org/pdf/1411.1127v1", 
    "arxiv-id": "1411.1127v1"
},{
    "category": "cs.GT", 
    "author": "Laia Saumell", 
    "title": "Choosing by means of approval-preferential voting. The path-revised   approval choice", 
    "publish": "2014-11-03T23:55:05Z", 
    "summary": "We consider the problem of making a collective choice by means of\napproval-preferential voting. The existing proposals are briefly overviewed so\nas to point out several issues that leave to be desired. In particular, and\nfollowing Condorcet's last views on elections, we pay a special attention to\nmaking sure that a good option is chosen rather than aiming for the best option\nbut not being so sure about it. We show that this goal is fulfilled in a\nwell-defined sense by a method that we introduced in a previous paper and whose\nstudy is deepened here. This procedure, that we call path-revised approval\nchoice, is based on interpreting the approval and paired-comparison scores as\ndegrees of collective belief, revising them in the light of the existing\nimplications by means of the so-called Theophrastus rule, and deciding about\nevery option on the basis of the balance of revised degrees of belief for and\nagainst its approval. The computations rely on the path scores, which are used\nalso in a method that was introduced by Markus Schulze in the spirit of looking\nfor the best option. Besides dealing with the confidence in the respective\nresults of both methods, we also establish several other properties of them,\nincluding a property of upper semicontinuity of the choice set with respect to\nthe profile and a property of Pareto consistency (in a certain weak sense).", 
    "link": "http://arxiv.org/pdf/1411.1367v2", 
    "arxiv-id": "1411.1367v2"
},{
    "category": "cs.GT", 
    "author": "Christopher A. Wilkens", 
    "title": "The Value of Knowing Your Enemy", 
    "publish": "2014-11-05T19:51:50Z", 
    "summary": "Many auction settings implicitly or explicitly require that bidders are\ntreated equally ex-ante. This may be because discrimination is philosophically\nor legally impermissible, or because it is practically difficult to implement\nor impossible to enforce. We study so-called {\\em anonymous} auctions to\nunderstand the revenue tradeoffs and to develop simple anonymous auctions that\nare approximately optimal.\n  We consider digital goods settings and show that the optimal anonymous,\ndominant strategy incentive compatible auction has an intuitive structure ---\nimagine that bidders are randomly permuted before the auction, then infer a\nposterior belief about bidder i's valuation from the values of other bidders\nand set a posted price that maximizes revenue given this posterior.\n  We prove that no anonymous mechanism can guarantee an approximation better\nthan O(n) to the optimal revenue in the worst case (or O(log n) for regular\ndistributions) and that even posted price mechanisms match those guarantees.\nUnderstanding that the real power of anonymous mechanisms comes when the\nauctioneer can infer the bidder identities accurately, we show a tight O(k)\napproximation guarantee when each bidder can be confused with at most k \"higher\ntypes\". Moreover, we introduce a simple mechanism based on n target prices that\nis asymptotically optimal and build on this mechanism to extend our results to\nm-unit auctions and sponsored search.", 
    "link": "http://arxiv.org/pdf/1411.1379v1", 
    "arxiv-id": "1411.1379v1"
},{
    "category": "cs.GT", 
    "author": "Balasubramanian Sivan", 
    "title": "How to sell an app: pay-per-play or buy-it-now?", 
    "publish": "2014-11-05T19:53:42Z", 
    "summary": "We consider pricing in settings where a consumer discovers his value for a\ngood only as he uses it, and the value evolves with each use. We explore simple\nand natural pricing strategies for a seller in this setting, under the\nassumption that the seller knows the distribution from which the consumer's\ninitial value is drawn, as well as the stochastic process that governs the\nevolution of the value with each use.\n  We consider the differences between up-front or \"buy-it-now\" pricing (BIN),\nand \"pay-per-play\" (PPP) pricing, where the consumer is charged per use. Our\nresults show that PPP pricing can be a very effective mechanism for price\ndiscrimination, and thereby can increase seller revenue. But it can also be\nadvantageous to the buyers, as a way of mitigating risk. Indeed, this\nmitigation of risk can yield a larger pool of buyers. We also show that the\npractice of offering free trials is largely beneficial.\n  We consider two different stochastic processes for how the buyer's value\nevolves: In the first, the key random variable is how long the consumer remains\ninterested in the product. In the second process, the consumer's value evolves\naccording to a random walk or Brownian motion with reflection at 1, and\nabsorption at 0.", 
    "link": "http://arxiv.org/pdf/1411.1381v1", 
    "arxiv-id": "1411.1381v1"
},{
    "category": "cs.GT", 
    "author": "Balasubramanian Sivan", 
    "title": "Price Competition, Fluctuations, and Welfare Guarantees", 
    "publish": "2014-11-07T21:16:06Z", 
    "summary": "In various markets where sellers compete in price, price oscillations are\nobserved rather than convergence to equilibrium. Such fluctuations have been\nempirically observed in the retail market for gasoline, in airline pricing and\nin the online sale of consumer goods. Motivated by this, we study a model of\nprice competition in which an equilibrium rarely exists. We seek to analyze the\nwelfare, despite the nonexistence of an equilibrium, and present welfare\nguarantees as a function of the market power of the sellers.\n  We first study best response dynamics in markets with sellers that provide a\nhomogeneous good, and show that except for a modest number of initial rounds,\nthe welfare is guaranteed to be high. We consider two variations: in the first\nthe sellers have full information about the valuation of the buyer. Here we\nshow that if there are $n$ items available across all sellers and $n_{\\max}$ is\nthe maximum number of items controlled by any given seller, the ratio of the\noptimal welfare to the achieved welfare will be at most\n$\\log(\\frac{n}{n-n_{\\max}+1})+1$. As the market power of the largest seller\ndiminishes, the welfare becomes closer to optimal. In the second variation we\nconsider an extended model where sellers have uncertainty about the buyer's\nvaluation. Here we similarly show that the welfare improves as the market power\nof the largest seller decreases, yet with a worse ratio of\n$\\frac{n}{n-n_{\\max}+1}$. The exponential gap in welfare between the two\nvariations quantifies the value of accurately learning the buyer valuation.\n  Finally, we show that extending our results to heterogeneous goods in general\nis not possible. Even for the simple class of $k$-additive valuations, there\nexists a setting where the welfare approximates the optimal welfare within any\nnon-zero factor only for $O(1/s)$ fraction of the time, where $s$ is the number\nof sellers.", 
    "link": "http://arxiv.org/pdf/1411.2036v2", 
    "arxiv-id": "1411.2036v2"
},{
    "category": "cs.GT", 
    "author": "Pinyan Lu", 
    "title": "Competitive analysis via benchmark decomposition", 
    "publish": "2014-11-08T04:30:45Z", 
    "summary": "We propose a uniform approach for the design and analysis of prior-free\ncompetitive auctions and online auctions. Our philosophy is to view the\nbenchmark function as a variable parameter of the model and study a broad class\nof functions instead of a individual target benchmark. We consider a multitude\nof well-studied auction settings, and improve upon a few previous results.\n  (1) Multi-unit auctions. Given a $\\beta$-competitive unlimited supply\nauction, the best previously known multi-unit auction is $2\\beta$-competitive.\nWe design a $(1+\\beta)$-competitive auction reducing the ratio from $4.84$ to\n$3.24$. These results carry over to matroid and position auctions.\n  (2) General downward-closed environments. We design a $6.5$-competitive\nauction improving upon the ratio of $7.5$. Our auction is noticeably simpler\nthan the previous best one.\n  (3) Unlimited supply online auctions. Our analysis yields an auction with a\ncompetitive ratio of $4.12$, which significantly narrows the margin of\n$[4,4.84]$ previously known for this problem.\n  A particularly important tool in our analysis is a simple decomposition\nlemma, which allows us to bound the competitive ratio against a sum of\nbenchmark functions. We use this lemma in a \"divide and conquer\" fashion by\ndividing the target benchmark into the sum of simpler functions.", 
    "link": "http://arxiv.org/pdf/1411.2079v1", 
    "arxiv-id": "1411.2079v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Incentive Design in Peer Review: Rating and Repeated Endogenous Matching", 
    "publish": "2014-11-08T17:10:44Z", 
    "summary": "Peer review (e.g., grading assignments in Massive Open Online Courses\n(MOOCs), academic paper review) is an effective and scalable method to evaluate\nthe products (e.g., assignments, papers) of a large number of agents when the\nnumber of dedicated reviewing experts (e.g., teaching assistants, editors) is\nlimited. Peer review poses two key challenges: 1) identifying the reviewers'\nintrinsic capabilities (i.e., adverse selection) and 2) incentivizing the\nreviewers to exert high effort (i.e., moral hazard). Some works in mechanism\ndesign address pure adverse selection using one-shot matching rules, and pure\nmoral hazard was addressed in repeated games with exogenously given and fixed\nmatching rules. However, in peer review systems exhibiting both adverse\nselection and moral hazard, one-shot or exogenous matching rules do not link\nagents' current behavior with future matches and future payoffs, and as we\nprove, will induce myopic behavior (i.e., exerting the lowest effort) resulting\nin the lowest review quality.\n  In this paper, we propose for the first time a solution that simultaneously\nsolves adverse selection and moral hazard. Our solution exploits the repeated\ninteractions of agents, utilizes ratings to summarize agents' past review\nquality, and designs matching rules that endogenously depend on agents'\nratings. Our proposed matching rules are easy to implement and require no\nknowledge about agents' private information (e.g., their benefit and cost\nfunctions). Yet, they are effective in guiding the system to an equilibrium\nwhere the agents are incentivized to exert high effort and receive ratings that\nprecisely reflect their review quality. Using several illustrative examples, we\nquantify the significant performance gains obtained by our proposed mechanism\nas compared to existing one-shot or exogenous matching rules.", 
    "link": "http://arxiv.org/pdf/1411.2139v1", 
    "arxiv-id": "1411.2139v1"
},{
    "category": "cs.GT", 
    "author": "Sunoo Park", 
    "title": "Cryptographically Blinded Games: Leveraging Players' Limitations for   Equilibria and Profit", 
    "publish": "2014-11-13T21:32:51Z", 
    "summary": "In this work we apply methods from cryptography to enable any number of\nmutually distrusting players to implement broad classes of mediated equilibria\nof strategic games without the need for trusted mediation.\n  Our implementation makes use of a (standard) pre-play \"cheap talk\" phase, in\nwhich players engage in free and non-binding communication prior to playing in\nthe original game. In our cheap talk phase, the players execute a secure\nmulti-party computation protocol to sample an action profile from an\nequilibrium of a \"cryptographically blinded\" version of the original game, in\nwhich actions are encrypted. The essence of our approach is to exploit the\npower of encryption to selectively restrict the information available to\nplayers about sampled action profiles, such that these desirable equilibria can\nbe stably achieved. In contrast to previous applications of cryptography to\ngame theory, this work is the first to employ the paradigm of using encryption\nto allow players to benefit from hiding information \\emph{from themselves},\nrather than from others; and we stress that rational players would\n\\emph{choose} to hide the information from themselves.", 
    "link": "http://arxiv.org/pdf/1411.3747v1", 
    "arxiv-id": "1411.3747v1"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "Combinatorial Auctions via Posted Prices", 
    "publish": "2014-11-18T17:17:57Z", 
    "summary": "We study anonymous posted price mechanisms for combinatorial auctions in a\nBayesian framework. In a posted price mechanism, item prices are posted, then\nthe consumers approach the seller sequentially in an arbitrary order, each\npurchasing her favorite bundle from among the unsold items at the posted\nprices. These mechanisms are simple, transparent and trivially dominant\nstrategy incentive compatible (DSIC).\n  We show that when agent preferences are fractionally subadditive (which\nincludes all submodular functions), there always exist prices that, in\nexpectation, obtain at least half of the optimal welfare. Our result is\nconstructive: given black-box access to a combinatorial auction algorithm A,\nsample access to the prior distribution, and appropriate query access to the\nsampled valuations, one can compute, in polytime, prices that guarantee at\nleast half of the expected welfare of A. As a corollary, we obtain the first\npolytime (in n and m) constant-factor DSIC mechanism for Bayesian submodular\ncombinatorial auctions, given access to demand query oracles. Our results also\nextend to valuations with complements, where the approximation factor degrades\nlinearly with the level of complementarity.", 
    "link": "http://arxiv.org/pdf/1411.4916v1", 
    "arxiv-id": "1411.4916v1"
},{
    "category": "cs.GT", 
    "author": "David Parkes", 
    "title": "Congestion Games with Distance-Based Strict Uncertainty", 
    "publish": "2014-11-18T18:04:58Z", 
    "summary": "We put forward a new model of congestion games where agents have uncertainty\nover the routes used by other agents. We take a non-probabilistic approach,\nassuming that each agent knows that the number of agents using an edge is\nwithin a certain range. Given this uncertainty, we model agents who either\nminimize their worst-case cost (WCC) or their worst-case regret (WCR), and\nstudy implications on equilibrium existence, convergence through adaptive play,\nand efficiency. Under the WCC behavior the game reduces to a modified\ncongestion game, and welfare improves when agents have moderate uncertainty.\nUnder WCR behavior the game is not, in general, a congestion game, but we show\nconvergence and efficiency bounds for a simple class of games.", 
    "link": "http://arxiv.org/pdf/1411.4943v1", 
    "arxiv-id": "1411.4943v1"
},{
    "category": "cs.GT", 
    "author": "Ofir Geri", 
    "title": "Do Capacity Constraints Constrain Coalitions?", 
    "publish": "2014-11-20T22:27:27Z", 
    "summary": "We study strong equilibria in symmetric capacitated cost-sharing games. In\nthese games, a graph with designated source $s$ and sink $t$ is given, and each\nedge is associated with some cost. Each agent chooses strategically an $s$-$t$\npath, knowing that the cost of each edge is shared equally between all agents\nusing it. Two variants of cost-sharing games have been previously studied: (i)\ngames where coalitions can form, and (ii) games where edges are associated with\ncapacities; both variants are inspired by real-life scenarios. In this work we\ncombine these variants and analyze strong equilibria (profiles where no\ncoalition can deviate) in capacitated games. This combination gives rise to new\nphenomena that do not occur in the previous variants. Our contribution is\ntwo-fold. First, we provide a topological characterization of networks that\nalways admit a strong equilibrium. Second, we establish tight bounds on the\nefficiency loss that may be incurred due to strategic behavior, as quantified\nby the strong price of anarchy (and stability) measures. Interestingly, our\nresults are qualitatively different than those obtained in the analysis of each\nvariant alone, and the combination of coalitions and capacities entails the\nintroduction of more refined topology classes than previously studied.", 
    "link": "http://arxiv.org/pdf/1411.5712v3", 
    "arxiv-id": "1411.5712v3"
},{
    "category": "cs.GT", 
    "author": "Anup Basil Mathew", 
    "title": "Infinite games with finite knowledge gaps", 
    "publish": "2014-11-21T10:45:02Z", 
    "summary": "Infinite games where several players seek to coordinate under imperfect\ninformation are deemed to be undecidable, unless the information is\nhierarchically ordered among the players.\n  We identify a class of games for which joint winning strategies can be\nconstructed effectively without restricting the direction of information flow.\nInstead, our condition requires that the players attain common knowledge about\nthe actual state of the game over and over again along every play.\n  We show that it is decidable whether a given game satisfies the condition,\nand prove tight complexity bounds for the strategy synthesis problem under\n$\\omega$-regular winning conditions given by parity automata.", 
    "link": "http://arxiv.org/pdf/1411.5820v2", 
    "arxiv-id": "1411.5820v2"
},{
    "category": "cs.GT", 
    "author": "Edward Lui", 
    "title": "Bayesian Mechanism Design with Efficiency, Privacy, and Approximate   Truthfulness", 
    "publish": "2014-11-22T17:36:26Z", 
    "summary": "Recently, there has been a number of papers relating mechanism design and\nprivacy (e.g., see \\cite{MT07,Xia11,CCKMV11,NST12,NOS12,HK12}). All of these\npapers consider a worst-case setting where there is no probabilistic\ninformation about the players' types. In this paper, we investigate mechanism\ndesign and privacy in the \\emph{Bayesian} setting, where the players' types are\ndrawn from some common distribution. We adapt the notion of \\emph{differential\nprivacy} to the Bayesian mechanism design setting, obtaining \\emph{Bayesian\ndifferential privacy}. We also define a robust notion of approximate\ntruthfulness for Bayesian mechanisms, which we call \\emph{persistent\napproximate truthfulness}. We give several classes of mechanisms (e.g., social\nwelfare mechanisms and histogram mechanisms) that achieve both Bayesian\ndifferential privacy and persistent approximate truthfulness. These classes of\nmechanisms can achieve optimal (economic) efficiency, and do not use any\npayments. We also demonstrate that by considering the above mechanisms in a\nmodified mechanism design model, the above mechanisms can achieve actual\ntruthfulness.", 
    "link": "http://arxiv.org/pdf/1411.6148v1", 
    "arxiv-id": "1411.6148v1"
},{
    "category": "cs.GT", 
    "author": "Y. Narahari", 
    "title": "Profit Maximizing Prior-free Multi-unit Procurement Auctions with   Capacitated Sellers", 
    "publish": "2015-04-04T16:48:13Z", 
    "summary": "In this paper, we derive bounds for profit maximizing prior-free procurement\nauctions where a buyer wishes to procure multiple units of a homogeneous item\nfrom n sellers who are strategic about their per unit valuation. The buyer\nearns the profit by reselling these units in an external consumer market. The\npaper looks at three scenarios of increasing complexity. First, we look at unit\ncapacity sellers where per unit valuation is private information of each seller\nand the revenue curve is concave. For this setting, we define two benchmarks.\nWe show that no randomized prior free auction can be constant competitive\nagainst any of these two benchmarks. However, for a lightly constrained\nbenchmark we design a prior-free auction PEPA (Profit Extracting Procurement\nAuction) which is 4-competitive and we show this bound is tight. Second, we\nstudy a setting where the sellers have non-unit capacities that are common\nknowledge and derive similar results. In particular, we propose a prior free\nauction PEPAC (Profit Extracting Procurement Auction with Capacity) which is\ntruthful for any concave revenue curve. Third, we obtain results in the\ninherently harder bi-dimensional case where per unit valuation as well as\ncapacities are private information of the sellers. We show that PEPAC is\ntruthful and constant competitive for the specific case of linear revenue\ncurves. We believe that this paper represents the first set of results on\nsingle dimensional and bi-dimensional profit maximizing prior-free multi-unit\nprocurement auctions.", 
    "link": "http://arxiv.org/pdf/1504.01020v1", 
    "arxiv-id": "1504.01020v1"
},{
    "category": "cs.GT", 
    "author": "Jean-Fran\u00e7ois Raskin", 
    "title": "Weak Subgame Perfect Equilibria and their Application to Quantitative   Reachability", 
    "publish": "2015-04-07T11:40:31Z", 
    "summary": "We study $n$-player turn-based games played on a finite directed graph. For\neach play, the players have to pay a cost that they want to minimize. Instead\nof the well-known notion of Nash equilibrium (NE), we focus on the notion of\nsubgame perfect equilibrium (SPE), a refinement of NE well-suited in the\nframework of games played on graphs. We also study natural variants of SPE,\nnamed weak (resp. very weak) SPE, where players who deviate cannot use the full\nclass of strategies but only a subclass with a finite number of (resp. a\nunique) deviation step(s).\n  Our results are threefold. Firstly, we characterize in the form of a Folk\ntheorem the set of all plays that are the outcome of a weak SPE. Secondly, for\nthe class of quantitative reachability games, we prove the existence of a\nfinite-memory SPE and provide an algorithm for computing it (only existence was\nknown with no information regarding the memory). Moreover, we show that the\nexistence of a constrained SPE, i.e. an SPE such that each player pays a cost\nless than a given constant, can be decided. The proofs rely on our Folk theorem\nfor weak SPEs (which coincide with SPEs in the case of quantitative\nreachability games) and on the decidability of MSO logic on infinite words.\nFinally with similar techniques, we provide a second general class of games for\nwhich the existence of a (constrained) weak SPE is decidable.", 
    "link": "http://arxiv.org/pdf/1504.01557v2", 
    "arxiv-id": "1504.01557v2"
},{
    "category": "cs.GT", 
    "author": "Omri Weinstein", 
    "title": "Welfare Maximization with Limited Interaction", 
    "publish": "2015-04-07T23:25:16Z", 
    "summary": "We continue the study of welfare maximization in unit-demand (matching)\nmarkets, in a distributed information model where agent's valuations are\nunknown to the central planner, and therefore communication is required to\ndetermine an efficient allocation. Dobzinski, Nisan and Oren (STOC'14) showed\nthat if the market size is $n$, then $r$ rounds of interaction (with\nlogarithmic bandwidth) suffice to obtain an $n^{1/(r+1)}$-approximation to the\noptimal social welfare. In particular, this implies that such markets converge\nto a stable state (constant approximation) in time logarithmic in the market\nsize.\n  We obtain the first multi-round lower bound for this setup. We show that even\nif the allowable per-round bandwidth of each agent is $n^{\\epsilon(r)}$, the\napproximation ratio of any $r$-round (randomized) protocol is no better than\n$\\Omega(n^{1/5^{r+1}})$, implying an $\\Omega(\\log \\log n)$ lower bound on the\nrate of convergence of the market to equilibrium.\n  Our construction and technique may be of interest to round-communication\ntradeoffs in the more general setting of combinatorial auctions, for which the\nonly known lower bound is for simultaneous ($r=1$) protocols [DNO14].", 
    "link": "http://arxiv.org/pdf/1504.01780v1", 
    "arxiv-id": "1504.01780v1"
},{
    "category": "cs.GT", 
    "author": "Leandros Tassiulas", 
    "title": "Exchange of Services in Networks: Competition, Cooperation, and Fairness", 
    "publish": "2015-04-08T17:51:41Z", 
    "summary": "Exchange of services and resources in, or over, networks is attracting\nnowadays renewed interest. However, despite the broad applicability and the\nextensive study of such models, e.g., in the context of P2P networks, many\nfundamental questions regarding their properties and efficiency remain\nunanswered. We consider such a service exchange model and analyze the users'\ninteractions under three different approaches. First, we study a centrally\ndesigned service allocation policy that yields the fair total service each user\nshould receive based on the service it others to the others. Accordingly, we\nconsider a competitive market where each user determines selfishly its\nallocation policy so as to maximize the service it receives in return, and a\ncoalitional game model where users are allowed to coordinate their policies. We\nprove that there is a unique equilibrium exchange allocation for both game\ntheoretic formulations, which also coincides with the central fair service\nallocation. Furthermore, we characterize its properties in terms of the\ncoalitions that emerge and the equilibrium allocations, and analyze its\ndependency on the underlying network graph. That servicing policy is the\nnatural reference point to the various mechanisms that are currently proposed\nto incentivize user participation and improve the efficiency of such networked\nservice (or, resource) exchange markets.", 
    "link": "http://arxiv.org/pdf/1504.02052v1", 
    "arxiv-id": "1504.02052v1"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "Stronger Impossibility Results for Strategy-Proof Voting with i.i.d.   Beliefs", 
    "publish": "2015-04-09T22:57:26Z", 
    "summary": "The classic Gibbard-Satterthwaite theorem says that every strategy-proof\nvoting rule with at least three possible candidates must be dictatorial. In\n\\cite{McL11}, McLennan showed that a similar impossibility result holds even if\nwe consider a weaker notion of strategy-proofness where voters believe that the\nother voters' preferences are i.i.d.~(independent and identically distributed):\nIf an anonymous voting rule (with at least three candidates) is strategy-proof\nw.r.t.~all i.i.d.~beliefs and is also Pareto efficient, then the voting rule\nmust be a random dictatorship. In this paper, we strengthen McLennan's result\nby relaxing Pareto efficiency to $\\epsilon$-Pareto efficiency where Pareto\nefficiency can be violated with probability $\\epsilon$, and we further relax\n$\\epsilon$-Pareto efficiency to a very weak notion of efficiency which we call\n$\\epsilon$-super-weak unanimity. We then show the following: If an anonymous\nvoting rule (with at least three candidates) is strategy-proof w.r.t.~all\ni.i.d.~beliefs and also satisfies $\\epsilon$-super-weak unanimity, then the\nvoting rule must be $O(\\epsilon)$-close to random dictatorship.", 
    "link": "http://arxiv.org/pdf/1504.02514v1", 
    "arxiv-id": "1504.02514v1"
},{
    "category": "cs.GT", 
    "author": "Jiyang Xie", 
    "title": "Discrete All-Pay Bidding Games", 
    "publish": "2015-04-03T03:13:01Z", 
    "summary": "In an all-pay auction, only one bidder wins but all bidders must pay the\nauctioneer. All-pay bidding games arise from attaching a similar bidding\nstructure to traditional combinatorial games to determine which player moves\nnext. In contrast to the established theory of single-pay bidding games,\noptimal play involves choosing bids from some probability distribution that\nwill guarantee a minimum probability of winning. In this manner, all-pay\nbidding games wed the underlying concepts of economic and combinatorial games.\nWe present several results on the structures of optimal strategies in these\ngames. We then give a fast algorithm for computing such strategies for a large\nclass of all-pay bidding games. The methods presented provide a framework for\nfurther development of the theory of all-pay bidding games.", 
    "link": "http://arxiv.org/pdf/1504.02799v2", 
    "arxiv-id": "1504.02799v2"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "The (Non)-Existence of Stable Mechanisms in Incomplete Information   Environments", 
    "publish": "2015-04-13T17:01:58Z", 
    "summary": "We consider two-sided matching markets, and study the incentives of agents to\ncircumvent a centralized clearing house by signing binding contracts with one\nanother. It is well-known that if the clearing house implements a stable match\nand preferences are known, then no group of agents can profitably deviate in\nthis manner.\n  We ask whether this property holds even when agents have incomplete\ninformation about their own preferences or the preferences of others. We find\nthat it does not. In particular, when agents are uncertain about the\npreferences of others, every mechanism is susceptible to deviations by groups\nof agents. When, in addition, agents are uncertain about their own preferences,\nevery mechanism is susceptible to deviations in which a single pair of agents\nagrees in advance to match to each other.", 
    "link": "http://arxiv.org/pdf/1504.03257v1", 
    "arxiv-id": "1504.03257v1"
},{
    "category": "cs.GT", 
    "author": "\u00d3scar C. V\u00e1squez", 
    "title": "Mechanism design for aggregating energy consumption and quality of   service in speed scaling scheduling", 
    "publish": "2015-04-14T15:30:50Z", 
    "summary": "We consider a strategic game, where players submit jobs to a machine that\nexecutes all jobs in a way that minimizes energy while respecting the given\neadlines. The energy consumption is then charged to the players in some way.\nEach player wants to minimize the sum of that charge and of their job's\ndeadline ultiplied by a priority weight. Two charging schemes are studied, the\nproportional cost share which does not always admit pure Nash equilibria, and\nthe arginal cost share, which does always admit pure Nash equilibria, at the\nprice of overcharging by a constant factor.", 
    "link": "http://arxiv.org/pdf/1504.03586v1", 
    "arxiv-id": "1504.03586v1"
},{
    "category": "cs.GT", 
    "author": "Adi Vardi", 
    "title": "Truthful Secretaries with Budgets", 
    "publish": "2015-04-14T16:55:08Z", 
    "summary": "We study online auction settings in which agents arrive and depart\ndynamically in a random (secretary) order, and each agent's private type\nconsists of the agent's arrival and departure times, value and budget. We\nconsider multi-unit auctions with additive agents for the allocation of both\ndivisible and indivisible items. For both settings, we devise truthful\nmechanisms that give a constant approximation with respect to the auctioneer's\nrevenue, under a large market assumption. For divisible items, we devise in\naddition a truthful mechanism that gives a constant approximation with respect\nto the liquid welfare --- a natural efficiency measure for budgeted settings\nintroduced by Dobzinski and Paes Leme [ICALP'14]. Our techniques provide\nhigh-level principles for transforming offline truthful mechanisms into online\nones, with or without budget constraints. To the best of our knowledge, this is\nthe first work that addresses the non-trivial challenge of combining online\nsettings with budgeted agents.", 
    "link": "http://arxiv.org/pdf/1504.03625v1", 
    "arxiv-id": "1504.03625v1"
},{
    "category": "cs.GT", 
    "author": "Simon D. Lentner", 
    "title": "Nash Equilibria And Partition Functions Of Games With Many Dependent   Players", 
    "publish": "2015-04-15T16:54:29Z", 
    "summary": "We discuss and solve a model for a game with many players, where a subset of\ntruely deciding players is embedded into a hierarchy of dependent agents.\n  These interdependencies modify the game matrix and the Nash equilibria for\nthe deciding players. In a concrete example, we recognize the partition\nfunction of the Ising model and for high dependency we observe a phase\ntransition to a new Nash equilibrium, which is the Pareto-efficient outcome.\n  An example we have in mind is the game theory for major shareholders in a\nstock market, where intermediate companies decide according to a majority vote\nof their owners and compete for the final profit. In our model, these\ninterdependency eventually forces cooperation.", 
    "link": "http://arxiv.org/pdf/1504.03965v1", 
    "arxiv-id": "1504.03965v1"
},{
    "category": "cs.GT", 
    "author": "Achilleas Anastasopoulos", 
    "title": "Mechanism Design for Fair Allocation", 
    "publish": "2015-04-22T06:54:47Z", 
    "summary": "Mechanism design for a social utility being the sum of agents' utilities\n(SoU) is a well-studied problem. There are, however, a number of problems of\ntheoretical and practical interest where a designer may have a different\nobjective than maximization of the SoU. One motivation for this is the desire\nfor more equitable allocation of resources among agents. A second, more subtle,\nmotivation is the fact that a fairer allocation indirectly implies less\nvariation in taxes which can be desirable in a situation where (implicit)\nindividual agent budgetary constraints make payment of large taxes unrealistic.\nIn this paper we study a family of social utilities that provide fair\nallocation (with SoU being subsumed as an extreme case) and derive conditions\nunder which Bayesian and Dominant strategy implementation is possible.\nFurthermore, it is shown how a simple modification of the above mechanism can\nguarantee full Bayesian implementation. Through a numerical example it is shown\nthat the proposed method can result in significant gains both in allocation\nfairness and tax reduction.", 
    "link": "http://arxiv.org/pdf/1504.05670v5", 
    "arxiv-id": "1504.05670v5"
},{
    "category": "cs.GT", 
    "author": "Katrina Ligett", 
    "title": "Finding Any Nontrivial Coarse Correlated Equilibrium Is Hard", 
    "publish": "2015-04-23T19:54:51Z", 
    "summary": "One of the most appealing aspects of the (coarse) correlated equilibrium\nconcept is that natural dynamics quickly arrive at approximations of such\nequilibria, even in games with many players. In addition, there exist\npolynomial-time algorithms that compute exact (coarse) correlated equilibria.\nIn light of these results, a natural question is how good are the (coarse)\ncorrelated equilibria that can arise from any efficient algorithm or dynamics.\n  In this paper we address this question, and establish strong negative\nresults. In particular, we show that in multiplayer games that have a succinct\nrepresentation, it is NP-hard to compute any coarse correlated equilibrium (or\napproximate coarse correlated equilibrium) with welfare strictly better than\nthe worst possible. The focus on succinct games ensures that the underlying\ncomplexity question is interesting; many multiplayer games of interest are in\nfact succinct. Our results imply that, while one can efficiently compute a\ncoarse correlated equilibrium, one cannot provide any nontrivial welfare\nguarantee for the resulting equilibrium, unless P=NP. We show that analogous\nhardness results hold for correlated equilibria, and persist under the\negalitarian objective or Pareto optimality.\n  To complement the hardness results, we develop an algorithmic framework that\nidentifies settings in which we can efficiently compute an approximate\ncorrelated equilibrium with near-optimal welfare. We use this framework to\ndevelop an efficient algorithm for computing an approximate correlated\nequilibrium with near-optimal welfare in aggregative games.", 
    "link": "http://arxiv.org/pdf/1504.06314v1", 
    "arxiv-id": "1504.06314v1"
},{
    "category": "cs.GT", 
    "author": "Gabriel Renault", 
    "title": "Quantitative Games under Failures", 
    "publish": "2015-04-25T17:20:54Z", 
    "summary": "We study a generalisation of sabotage games, a model of dynamic network games\nintroduced by van Benthem. The original definition of the game is inherently\nfinite and therefore does not allow one to model infinite processes. We propose\nan extension of the sabotage games in which the first player (Runner) traverses\nan arena with dynamic weights determined by the second player (Saboteur). In\nour model of quantitative sabotage games, Saboteur is now given a budget that\nhe can distribute amongst the edges of the graph, whilst Runner attempts to\nminimise the quantity of budget witnessed while completing his task. We show\nthat, on the one hand, for most of the classical cost functions considered in\nthe literature, the problem of determining if Runner has a strategy to ensure a\ncost below some threshold is EXPTIME-complete. On the other hand, if the budget\nof Saboteur is fixed a priori, then the problem is in PTIME for most cost\nfunctions. Finally, we show that restricting the dynamics of the game also\nleads to better complexity.", 
    "link": "http://arxiv.org/pdf/1504.06744v2", 
    "arxiv-id": "1504.06744v2"
},{
    "category": "cs.GT", 
    "author": "Shalabh Bhatnagar", 
    "title": "A bi-convex optimization problem to compute Nash equilibrium in n-player   games and an algorithm", 
    "publish": "2015-04-26T14:24:14Z", 
    "summary": "In this paper we present optimization problems with biconvex objective\nfunction and linear constraints such that the set of global minima of the\noptimization problems is the same as the set of Nash equilibria of a n-player\ngeneral-sum normal form game. We further show that the objective function is an\ninvex function and consider a projected gradient descent algorithm. We prove\nthat the projected gradient descent scheme converges to a partial optimum of\nthe objective function. We also present simulation results on certain test\ncases showing convergence to a Nash equilibrium strategy.", 
    "link": "http://arxiv.org/pdf/1504.06828v1", 
    "arxiv-id": "1504.06828v1"
},{
    "category": "cs.GT", 
    "author": "Adam Wierman", 
    "title": "Greening Multi-Tenant Data Center Demand Response", 
    "publish": "2015-04-27T23:52:10Z", 
    "summary": "Data centers have emerged as promising resources for demand response,\nparticularly for emergency demand response (EDR), which saves the power grid\nfrom incurring blackouts during emergency situations. However, currently, data\ncenters typically participate in EDR by turning on backup (diesel) generators,\nwhich is both expensive and environmentally unfriendly. In this paper, we focus\non \"greening\" demand response in multi-tenant data centers, i.e., colocation\ndata centers, by designing a pricing mechanism through which the data center\noperator can efficiently extract load reductions from tenants during emergency\nperiods to fulfill energy reduction requirement for EDR. In particular, we\npropose a pricing mechanism for both mandatory and voluntary EDR programs,\nColoEDR, that is based on parameterized supply function bidding and provides\nprovably near-optimal efficiency guarantees, both when tenants are price-taking\nand when they are price-anticipating. In addition to analytic results, we\nextend the literature on supply function mechanism design, and evaluate ColoEDR\nusing trace-based simulation studies. These validate the efficiency analysis\nand conclude that the pricing mechanism is both beneficial to the environment\nand to the data center operator (by decreasing the need for backup diesel\ngeneration), while also aiding tenants (by providing payments for load\nreductions).", 
    "link": "http://arxiv.org/pdf/1504.07308v1", 
    "arxiv-id": "1504.07308v1"
},{
    "category": "cs.GT", 
    "author": "Jiandong Zhu", 
    "title": "On Potential Equations of Finite Games", 
    "publish": "2015-04-28T04:41:31Z", 
    "summary": "In this paper, some new criteria for detecting whether a finite game is\npotential are proposed by solving potential equations. The verification\nequations with the minimal number for checking a potential game are obtained\nfor the first time. Some connections between the potential equations and the\nexisting characterizations of potential games are established. It is revealed\nthat a finite game is potential if and only if its every bi-matrix sub-game is\npotential.", 
    "link": "http://arxiv.org/pdf/1504.07342v1", 
    "arxiv-id": "1504.07342v1"
},{
    "category": "cs.GT", 
    "author": "Guido Sch\u00e4fer", 
    "title": "Efficient Equilibria in Polymatrix Coordination Games", 
    "publish": "2015-04-28T15:03:30Z", 
    "summary": "We consider polymatrix coordination games with individual preferences where\nevery player corresponds to a node in a graph who plays with each neighbor a\nseparate bimatrix game with non-negative symmetric payoffs. In this paper, we\nstudy $\\alpha$-approximate $k$-equilibria of these games, i.e., outcomes where\nno group of at most $k$ players can deviate such that each member increases his\npayoff by at least a factor $\\alpha$. We prove that for $\\alpha \\ge 2$ these\ngames have the finite coalitional improvement property (and thus\n$\\alpha$-approximate $k$-equilibria exist), while for $\\alpha < 2$ this\nproperty does not hold. Further, we derive an almost tight bound of\n$2\\alpha(n-1)/(k-1)$ on the price of anarchy, where $n$ is the number of\nplayers; in particular, it scales from unbounded for pure Nash equilibria ($k =\n1)$ to $2\\alpha$ for strong equilibria ($k = n$). We also settle the complexity\nof several problems related to the verification and existence of these\nequilibria. Finally, we investigate natural means to reduce the inefficiency of\nNash equilibria. Most promisingly, we show that by fixing the strategies of $k$\nplayers the price of anarchy can be reduced to $n/k$ (and this bound is tight).", 
    "link": "http://arxiv.org/pdf/1504.07518v1", 
    "arxiv-id": "1504.07518v1"
},{
    "category": "cs.GT", 
    "author": "James Li", 
    "title": "Revenue-Maximizing Mechanism Design for Quasi-Proportional Auctions", 
    "publish": "2015-04-30T18:38:22Z", 
    "summary": "In quasi-proportional auctions, each bidder receives a fraction of the\nallocation equal to the weight of their bid divided by the sum of weights of\nall bids, where each bid's weight is determined by a weight function. We study\nthe relationship between the weight function, bidders' private values, number\nof bidders, and the seller's revenue in equilibrium. It has been shown that if\none bidder has a much higher private value than the others, then a nearly flat\nweight function maximizes revenue. Essentially, threatening the bidder who has\nthe highest valuation with having to share the allocation maximizes the\nrevenue. We show that as bidder private values approach parity, steeper weight\nfunctions maximize revenue by making the quasi-proportional auction more like a\nwinner-take-all auction. We also show that steeper weight functions maximize\nrevenue as the number of bidders increases. For flatter weight functions, there\nis known to be a unique pure-strategy Nash equilibrium. We show that a\npure-strategy Nash equilibrium also exists for steeper weight functions, and we\ngive lower bounds for bids at an equilibrium. For a special case that includes\nthe two-bidder auction, we show that the pure-strategy Nash equilibrium is\nunique, and we show how to compute the revenue at equilibrium. We also show\nthat selecting a weight function based on private value ratios and number of\nbidders is necessary for a quasi-proportional auction to produce more revenue\nthan a second-price auction.", 
    "link": "http://arxiv.org/pdf/1504.08333v2", 
    "arxiv-id": "1504.08333v2"
},{
    "category": "cs.GT", 
    "author": "Oliver Friedmann", 
    "title": "A Super-Polynomial Lower Bound for the Parity Game Strategy Improvement   Algorithm as We Know it", 
    "publish": "2009-01-18T19:55:17Z", 
    "summary": "This paper presents a new lower bound for the discrete strategy improvement\nalgorithm for solving parity games due to Voege and Jurdziski. First, we\ninformally show which structures are difficult to solve for the algorithm.\nSecond, we outline a family of games of quadratic size on which the algorithm\nrequires exponentially many strategy iterations, answering in the negative the\nlong-standing question whether this algorithm runs in polynomial time.\nAdditionally we note that the same family of games can be used to prove a\nsimilar result w.r.t. the strategy improvement variant by Schewe.", 
    "link": "http://arxiv.org/pdf/0901.2731v1", 
    "arxiv-id": "0901.2731v1"
},{
    "category": "cs.GT", 
    "author": "Dah Ming Chiu", 
    "title": "Mathematical Modeling of Competition in Sponsored Search Market", 
    "publish": "2010-06-05T05:01:36Z", 
    "summary": "Sponsored search mechanisms have drawn much attention from both academic\ncommunity and industry in recent years since the seminal papers of [13] and\n[14]. However, most of the existing literature concentrates on the mechanism\ndesign and analysis within the scope of only one search engine in the market.\nIn this paper we propose a mathematical framework for modeling the interaction\nof publishers, advertisers and end users in a competitive market. We first\nconsider the monopoly market model and provide optimal solutions for both ex\nante and ex post cases, which represents the long-term and short-term revenues\nof search engines respectively. We then analyze the strategic behaviors of end\nusers and advertisers under duopoly and prove the existence of equilibrium for\nboth search engines to co-exist from ex-post perspective. To show the more\ngeneral ex ante results, we carry out extensive simulations under different\nparameter settings. Our analysis and observation in this work can provide\nuseful insight in regulating the sponsored search market and protecting the\ninterests of advertisers and end users.", 
    "link": "http://arxiv.org/pdf/1006.1019v2", 
    "arxiv-id": "1006.1019v2"
},{
    "category": "cs.GT", 
    "author": "Wies\u0142aw Zielonka", 
    "title": "Blackwell-Optimal Strategies in Priority Mean-Payoff Games", 
    "publish": "2010-06-08T00:42:24Z", 
    "summary": "We examine perfect information stochastic mean-payoff games - a class of\ngames containing as special sub-classes the usual mean-payoff games and parity\ngames. We show that deterministic memoryless strategies that are optimal for\ndiscounted games with state-dependent discount factors close to 1 are optimal\nfor priority mean-payoff games establishing a strong link between these two\nclasses.", 
    "link": "http://arxiv.org/pdf/1006.1402v1", 
    "arxiv-id": "1006.1402v1"
},{
    "category": "cs.GT", 
    "author": "Florian Horn", 
    "title": "How do we remember the past in randomised strategies?", 
    "publish": "2010-06-08T00:42:33Z", 
    "summary": "Graph games of infinite length are a natural model for open reactive\nprocesses: one player represents the controller, trying to ensure a given\nspecification, and the other represents a hostile environment. The evolution of\nthe system depends on the decisions of both players, supplemented by chance.\n  In this work, we focus on the notion of randomised strategy. More\nspecifically, we show that three natural definitions may lead to very different\nresults: in the most general cases, an almost-surely winning situation may\nbecome almost-surely losing if the player is only allowed to use a weaker\nnotion of strategy. In more reasonable settings, translations exist, but they\nrequire infinite memory, even in simple cases. Finally, some traditional\nproblems becomes undecidable for the strongest type of strategies.", 
    "link": "http://arxiv.org/pdf/1006.1404v1", 
    "arxiv-id": "1006.1404v1"
},{
    "category": "cs.GT", 
    "author": "Wladimir Fridman", 
    "title": "Formats of Winning Strategies for Six Types of Pushdown Games", 
    "publish": "2010-06-08T00:45:03Z", 
    "summary": "The solution of parity games over pushdown graphs (Walukiewicz '96) was the\nfirst step towards an effective theory of infinite-state games. It was shown\nthat winning strategies for pushdown games can be implemented again as pushdown\nautomata. We continue this study and investigate the connection between game\npresentations and winning strategies in altogether six cases of game arenas,\namong them realtime pushdown systems, visibly pushdown systems, and counter\nsystems. In four cases we show by a uniform proof method that we obtain\nstrategies implementable by the same type of pushdown machine as given in the\ngame arena. We prove that for the two remaining cases this correspondence\nfails. In the conclusion we address the question of an abstract criterion that\nexplains the results.", 
    "link": "http://arxiv.org/pdf/1006.1415v1", 
    "arxiv-id": "1006.1415v1"
},{
    "category": "cs.GT", 
    "author": "Ariel D. Procaccia", 
    "title": "Mix and Match", 
    "publish": "2010-06-09T19:26:00Z", 
    "summary": "Consider a matching problem on a graph where disjoint sets of vertices are\nprivately owned by self-interested agents. An edge between a pair of vertices\nindicates compatibility and allows the vertices to match. We seek a mechanism\nto maximize the number of matches despite self-interest, with agents that each\nwant to maximize the number of their own vertices that match. Each agent can\nchoose to hide some of its vertices, and then privately match the hidden\nvertices with any of its own vertices that go unmatched by the mechanism. A\nprominent application of this model is to kidney exchange, where agents\ncorrespond to hospitals and vertices to donor-patient pairs. Here hospitals may\ngame an exchange by holding back pairs and harm social welfare. In this paper\nwe seek to design mechanisms that are strategyproof, in the sense that agents\ncannot benefit from hiding vertices, and approximately maximize efficiency,\ni.e., produce a matching that is close in cardinality to the maximum\ncardinality matching. Our main result is the design and analysis of the\neponymous Mix-and-Match mechanism; we show that this randomized mechanism is\nstrategyproof and provides a 2-approximation. Lower bounds establish that the\nmechanism is near optimal.", 
    "link": "http://arxiv.org/pdf/1006.1881v1", 
    "arxiv-id": "1006.1881v1"
},{
    "category": "cs.GT", 
    "author": "Thomas Moscibroda", 
    "title": "Optimal whitespace synchronization strategies", 
    "publish": "2010-06-16T22:23:17Z", 
    "summary": "The whitespace-discovery problem describes two parties, Alice and Bob, trying\nto establish a communication channel over one of a given large segment of\nwhitespace channels. Subsets of the channels are occupied in each of the local\nenvironments surrounding Alice and Bob, as well as in the global environment\nbetween them (Eve). In the absence of a common clock for the two parties, the\ngoal is to devise time-invariant (stationary) strategies minimizing the\nsynchronization time. This emerged from recent applications in discovery of\nwireless devices.\n  We model the problem as follows. There are $N$ channels, each of which is\nopen (unoccupied) with probability $p_1,p_2,q$ independently for Alice, Bob and\nEve respectively. Further assume that $N \\gg 1/(p_1 p_2 q)$ to allow for\nsufficiently many open channels. Both Alice and Bob can detect which channels\nare locally open and every time-slot each of them chooses one such channel for\nan attempted sync. One aims for strategies that, with high probability over the\nenvironments, guarantee a shortest possible expected sync time depending only\non the $p_i$'s and $q$.\n  Here we provide a stationary strategy for Alice and Bob with a guaranteed\nexpected sync time of $O(1 / (p_1 p_2 q^2))$ given that each party also has\nknowledge of $p_1,p_2,q$. When the parties are oblivious of these\nprobabilities, analogous strategies incur a cost of a poly-log factor, i.e.\\\n$\\tilde{O}(1 / (p_1 p_2 q^2))$. Furthermore, this performance guarantee is\nessentially optimal as we show that any stationary strategies of Alice and Bob\nhave an expected sync time of at least $\\Omega(1/(p_1 p_2 q^2))$.", 
    "link": "http://arxiv.org/pdf/1006.3334v1", 
    "arxiv-id": "1006.3334v1"
},{
    "category": "cs.GT", 
    "author": "Azarakhsh Malekian", 
    "title": "Competitive Equilibria in Two Sided Matching Markets with   Non-transferable Utilities", 
    "publish": "2010-06-24T06:45:27Z", 
    "summary": "We consider two sided matching markets consisting of agents with\nnon-transferable utilities; agents from the opposite sides form matching pairs\n(e.g., buyers-sellers) and negotiate the terms of their math which may include\na monetary transfer. Competitive equilibria are the elements of the core of\nthis game.\n  We present the first combinatorial characterization of competitive equilibria\nthat relates the utility of each agent at equilibrium to the equilibrium\nutilities of other agents in a strictly smaller market excluding that agent;\nthus automatically providing a constructive proof of existence of competitive\nequilibria in such markets.\n  Our characterization also yields a group strategyproof mechanism for\nallocating indivisible goods to unit demand buyers with non-quasilinear\nutilities that highly resembles the Vickrey Clarke Groves (VCG) mechanism. As a\ndirect application of this, we present a group strategyproof welfare maximizing\nmechanism for Ad-Auctions without requiring the usual assumption that search\nengine and advertisers have consistent estimates of the clickthrough rates.", 
    "link": "http://arxiv.org/pdf/1006.4696v4", 
    "arxiv-id": "1006.4696v4"
},{
    "category": "cs.GT", 
    "author": "Krzysztof R. Apt", 
    "title": "Proof-theoretic Analysis of Rationality for Strategic Games with   Arbitrary Strategy Sets", 
    "publish": "2010-06-25T08:00:13Z", 
    "summary": "In the context of strategic games, we provide an axiomatic proof of the\nstatement Common knowledge of rationality implies that the players will choose\nonly strategies that survive the iterated elimination of strictly dominated\nstrategies. Rationality here means playing only strategies one believes to be\nbest responses. This involves looking at two formal languages. One is\nfirst-order, and is used to formalise optimality conditions, like avoiding\nstrictly dominated strategies, or playing a best response. The other is a modal\nfixpoint language with expressions for optimality, rationality and belief.\nFixpoints are used to form expressions for common belief and for iterated\nelimination of non-optimal strategies.", 
    "link": "http://arxiv.org/pdf/1006.4926v1", 
    "arxiv-id": "1006.4926v1"
},{
    "category": "cs.GT", 
    "author": "Honggang Zhang", 
    "title": "A Game Theoretical Approach to Modeling Information Dissemination in   Social Networks", 
    "publish": "2010-06-29T02:24:49Z", 
    "summary": "One major function of social networks (e.g., massive online social networks)\nis the dissemination of information such as scientific knowledge, news, and\nrumors. Information can be propagated by the users of the network via natural\nconnections in written, oral or electronic form. The information passing from a\nsender to a receiver intrinsically involves both of them considering their\nself-perceived knowledge, reputation, and popularity, which further determine\ntheir decisions of whether or not to forward the information and whether or not\nto provide feedback. To understand such human aspects of the information\ndissemination, we propose a game theoretical model of the information\nforwarding and feedback mechanisms in a social network that take into account\nthe personalities of the sender and the receiver (including their perceived\nknowledgeability, reputation, and desire for popularity) and the global\ncharacteristics of the network.", 
    "link": "http://arxiv.org/pdf/1006.5493v1", 
    "arxiv-id": "1006.5493v1"
},{
    "category": "cs.GT", 
    "author": "Zeyuan Allen Zhu", 
    "title": "Optimal Pricing in Social Networks with Incomplete Information", 
    "publish": "2010-07-09T02:55:21Z", 
    "summary": "In revenue maximization of selling a digital product in a social network, the\nutility of an agent is often considered to have two parts: a private valuation,\nand linearly additive influences from other agents. We study the incomplete\ninformation case where agents know a common distribution about others' private\nvaluations, and make decisions simultaneously. The \"rational behavior\" of\nagents in this case is captured by the well-known Bayesian Nash equilibrium.\n  Two challenging questions arise: how to compute an equilibrium and how to\noptimize a pricing strategy accordingly to maximize the revenue assuming agents\nfollow the equilibrium? In this paper, we mainly focus on the natural model\nwhere the private valuation of each agent is sampled from a uniform\ndistribution, which turns out to be already challenging.\n  Our main result is a polynomial-time algorithm that can exactly compute the\nequilibrium and the optimal price, when pairwise influences are non-negative.\nIf negative influences are allowed, computing any equilibrium even\napproximately is PPAD-hard. Our algorithm can also be used to design an FPTAS\nfor optimizing discriminative price profile.", 
    "link": "http://arxiv.org/pdf/1007.1501v2", 
    "arxiv-id": "1007.1501v2"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "The complexity of solving reachability games using value and strategy   iteration", 
    "publish": "2010-07-12T00:59:26Z", 
    "summary": "Two standard algorithms for approximately solving two-player zero-sum\nconcurrent reachability games are value iteration and strategy iteration. We\nprove upper and lower bounds of 2^(m^(Theta(N))) on the worst case number of\niterations needed by both of these algorithms for providing non-trivial\napproximations to the value of a game with N non-terminal positions and m\nactions for each player in each position. In particular, both algorithms have\ndoubly-exponential complexity. Even when the game given as input has only one\nnon-terminal position, we prove an exponential lower bound on the worst case\nnumber of iterations needed to provide non-trivial approximations.", 
    "link": "http://arxiv.org/pdf/1007.1812v3", 
    "arxiv-id": "1007.1812v3"
},{
    "category": "cs.GT", 
    "author": "Ravi Sundaram", 
    "title": "Capacitated Caching Games", 
    "publish": "2010-07-16T04:16:39Z", 
    "summary": "Motivated by P2P networks and content delivery applications, we study\nCapacitated Selfish Replication (CSR) games, which involve nodes on a network\nmaking strategic choices regarding the content to replicate in their caches.\nSelfish Replication games were introduced in [Chun et al, PODC2004}, who\nanalyzed the uncapacitated case leaving the capacitated version as an open\ndirection.\n  In this work, we study pure Nash equilibria of CSR games with an emphasis on\nhierarchical networks. Our main result is an exact polynomial-time algorithm\nfor finding a Nash Equilibrium in any hierarchical network using a new\ntechnique which we term \"fictional players\". We show that this technique\nextends to a general framework of natural preference orders, orders that are\nentirely arbitrary except for two natural constraints - \"Nearer is better\" and\n\"Independence of irrelevant alternatives\".\n  Using our axiomatic framework, we next study CSR games on arbitrary networks\nand delineate the boundary between intractability and effective computability\nin terms of the network structure, object preferences, and the total number of\nobjects. We also show the existence of equilibria for general undirected\nnetworks when either object preferences are binary or there are two objects.\nFor general CSR games, however, we show that it is NP-hard to determine whether\nequilibria exist. We also show that the existence of equilibria in strongly\nconnected networks with two objects and binary object preferences can be\ndetermined in polynomial time via a reduction to the well-studied even-cycle\nproblem. Finally, we introduce a fractional version of CSR games (F-SCR) with\napplication to content distribution using erasure codes. We show that while\nevery F-CSR game instance possesses an equilibrium, finding an equilibrium in\nan F-CSR game is PPAD-complete.", 
    "link": "http://arxiv.org/pdf/1007.2694v3", 
    "arxiv-id": "1007.2694v3"
},{
    "category": "cs.GT", 
    "author": "Yasha Savelyev", 
    "title": "Time symmetric Go", 
    "publish": "2010-07-19T23:51:22Z", 
    "summary": "In this note we describe a time symmetric version of the classical game Go.\nTime symmetry means that players move simultaneously without knowledge of the\nother player's move. In particular the classical Komi rule is removed, as well\nas the Ko rule. This is a perfect information game, (up to the fact that the\nother playe r's move is not not known on the given turn) to resolve the natural\nissues that can occur with simultaneity we use ideas inspired by quantum\nmechanics, but instead of a dice roll there is a certain deterministic\n``quantum state'' reduction. This requires introduction of 2 new rules.", 
    "link": "http://arxiv.org/pdf/1007.3310v2", 
    "arxiv-id": "1007.3310v2"
},{
    "category": "cs.GT", 
    "author": "Lei Wang", 
    "title": "Single Parameter Combinatorial Auctions with Partially Public Valuations", 
    "publish": "2010-07-20T23:53:55Z", 
    "summary": "We consider the problem of designing truthful auctions, when the bidders'\nvaluations have a public and a private component. In particular, we consider\ncombinatorial auctions where the valuation of an agent $i$ for a set $S$ of\nitems can be expressed as $v_if(S)$, where $v_i$ is a private single parameter\nof the agent, and the function $f$ is publicly known. Our motivation behind\nstudying this problem is two-fold: (a) Such valuation functions arise naturally\nin the case of ad-slots in broadcast media such as Television and Radio. For an\nad shown in a set $S$ of ad-slots, $f(S)$ is, say, the number of {\\em unique}\nviewers reached by the ad, and $v_i$ is the valuation per-unique-viewer. (b)\nFrom a theoretical point of view, this factorization of the valuation function\nsimplifies the bidding language, and renders the combinatorial auction more\namenable to better approximation factors. We present a general technique, based\non maximal-in-range mechanisms, that converts any $\\alpha$-approximation\nnon-truthful algorithm ($\\alpha \\leq 1$) for this problem into\n$\\Omega(\\frac{\\alpha}{\\log{n}})$ and $\\Omega(\\alpha)$-approximate truthful\nmechanisms which run in polynomial time and quasi-polynomial time,\nrespectively.", 
    "link": "http://arxiv.org/pdf/1007.3539v1", 
    "arxiv-id": "1007.3539v1"
},{
    "category": "cs.GT", 
    "author": "Pinyan Lu", 
    "title": "On the Approximability of Budget Feasible Mechanisms", 
    "publish": "2010-07-22T05:26:07Z", 
    "summary": "Budget feasible mechanisms, recently initiated by Singer (FOCS 2010), extend\nalgorithmic mechanism design problems to a realistic setting with a budget\nconstraint. We consider the problem of designing truthful budget feasible\nmechanisms for general submodular functions: we give a randomized mechanism\nwith approximation ratio $7.91$ (improving the previous best-known result 112),\nand a deterministic mechanism with approximation ratio $8.34$. Further we study\nthe knapsack problem, which is special submodular function, give a $2+\\sqrt{2}$\napproximation deterministic mechanism (improving the previous best-known result\n6), and a 3 approximation randomized mechanism. We provide a similar result for\nan extended knapsack problem with heterogeneous items, where items are divided\ninto groups and one can pick at most one item from each group.\n  Finally we show a lower bound of approximation ratio of $1+\\sqrt{2}$ for\ndeterministic mechanisms and 2 for randomized mechanisms for knapsack, as well\nas the general submodular functions. Our lower bounds are unconditional, which\ndo not rely on any computational or complexity assumptions.", 
    "link": "http://arxiv.org/pdf/1007.3801v1", 
    "arxiv-id": "1007.3801v1"
},{
    "category": "cs.GT", 
    "author": "Inbal Talgam-Cohen", 
    "title": "A Direct Reduction from k-Player to 2-Player Approximate Nash   Equilibrium", 
    "publish": "2010-07-22T13:58:04Z", 
    "summary": "We present a direct reduction from k-player games to 2-player games that\npreserves approximate Nash equilibrium. Previously, the computational\nequivalence of computing approximate Nash equilibrium in k-player and 2-player\ngames was established via an indirect reduction. This included a sequence of\nworks defining the complexity class PPAD, identifying complete problems for\nthis class, showing that computing approximate Nash equilibrium for k-player\ngames is in PPAD, and reducing a PPAD-complete problem to computing approximate\nNash equilibrium for 2-player games. Our direct reduction makes no use of the\nconcept of PPAD, thus eliminating some of the difficulties involved in\nfollowing the known indirect reduction.", 
    "link": "http://arxiv.org/pdf/1007.3886v1", 
    "arxiv-id": "1007.3886v1"
},{
    "category": "cs.GT", 
    "author": "Vijay Vazirani", 
    "title": "Equilibrium Pricing of Semantically Substitutable Digital Goods", 
    "publish": "2010-07-26T22:54:30Z", 
    "summary": "The problem of arriving at a principled method of pricing goods and services\nwas very satisfactorily solved for conventional goods; however, this solution\nis not applicable to digital goods. This paper studies pricing of a special\nclass of digital goods, which we call {\\em semantically substitutable digital\ngoods}. After taking into consideration idiosyncrasies of goods in this class,\nwe define a market model for it, together with a notion of equilibrium. We\nprove existence of equilibrium prices for our market model using Kakutani's\nfixed point theorem.\n  The far reaching significance of a competitive equilibrium is made explicit\nin the Fundamental Theorems of Welfare Economics. There are basic reasons due\nto which these theorems are not applicable to digital goods. This naturally\nleads to the question of whether the allocations of conventional goods are\nrendered inefficient or \"socially unfair\" in the mixed economy we have\nproposed. We prove that that is not the case and that in this sense, the\nintended goal of Welfare Economics is still achieved in the mixed economy.", 
    "link": "http://arxiv.org/pdf/1007.4586v4", 
    "arxiv-id": "1007.4586v4"
},{
    "category": "cs.GT", 
    "author": "\u013dubo\u0161 Steskal", 
    "title": "Braess's Paradox for Flows Over Time", 
    "publish": "2010-07-28T03:11:56Z", 
    "summary": "We study the properties of Braess's paradox in the context of the model of\ncongestion games with flow over time introduced by Koch and Skutella. We\ncompare them to the well known properties of Braess's paradox for Wardrop's\nmodel of games with static flows. We show that there are networks which do not\nadmit Braess's paradox in Wardrop's model, but which admit it in the model with\nflow over time. Moreover, there is a topology that admits a much more severe\nBraess's ratio for this model. Further, despite its symmetry for games with\nstatic flow, we show that Braess's paradox is not symmetric for flows over\ntime. We illustrate that there are network topologies which exhibit Braess's\nparadox, but for which the transpose does not. Finally, we conjecture a\nnecessary and sufficient condition of existence of Braess's paradox in a\nnetwork, and prove the condition of existence of the paradox either in the\nnetwork or in its transpose.", 
    "link": "http://arxiv.org/pdf/1007.4864v1", 
    "arxiv-id": "1007.4864v1"
},{
    "category": "cs.GT", 
    "author": "Roger Wattenhofer", 
    "title": "On the Windfall and Price of Friendship: Inoculation Strategies on   Social Networks", 
    "publish": "2011-01-09T14:07:19Z", 
    "summary": "This article investigates selfish behavior in games where players are\nembedded in a social context. A framework is presented which allows us to\nmeasure the Windfall of Friendship, i.e., how much players benefit (compared to\npurely selfish environments) if they care about the welfare of their friends in\nthe social network graph. As a case study, a virus inoculation game is\nexamined. We analyze the corresponding Nash equilibria and show that the\nWindfall of Friendship can never be negative. However, we find that if the\nvaluation of a friend is independent of the total number of friends, the social\nwelfare may not increase monotonically with the extent to which players care\nfor each other; intriguingly, in the corresponding scenario where the relative\nimportance of a friend declines, the Windfall is monotonic again. This article\nalso studies convergence of best-response sequences. It turns out that in\nsocial networks, convergence times are typically higher and hence constitute a\nprice of friendship. While such phenomena may be known on an anecdotal level,\nour framework allows us to quantify these effects analytically. Our formal\ninsights on the worst case equilibria are complemented by simulations shedding\nlight onto the structure of other equilibria.", 
    "link": "http://arxiv.org/pdf/1101.1633v2", 
    "arxiv-id": "1101.1633v2"
},{
    "category": "cs.GT", 
    "author": "Christos Zaroliagis", 
    "title": "Robust Line Planning in case of Multiple Pools and Disruptions", 
    "publish": "2011-01-14T11:04:13Z", 
    "summary": "We consider the line planning problem in public transportation, under a\nrobustness perspective. We present a mechanism for robust line planning in the\ncase of multiple line pools, when the line operators have a different utility\nfunction per pool. We conduct an experimental study of our mechanism on both\nsynthetic and real-world data that shows fast convergence to the optimum. We\nalso explore a wide range of scenarios, varying from an arbitrary initial state\n(to be solved) to small disruptions in a previously optimal solution (to be\nrecovered). Our experiments with the latter scenario show that our mechanism\ncan be used as an online recovery scheme causing the system to re-converge to\nits optimum extremely fast.", 
    "link": "http://arxiv.org/pdf/1101.2770v1", 
    "arxiv-id": "1101.2770v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "The Theory of Intervention Games for Resource Sharing in Wireless   Communications", 
    "publish": "2011-01-16T07:13:53Z", 
    "summary": "This paper develops a game-theoretic framework for the design and analysis of\na new class of incentive schemes called intervention schemes. We formulate\nintervention games, propose a solution concept of intervention equilibrium, and\nprove its existence in a finite intervention game. We apply our framework to\nresource sharing scenarios in wireless communications, whose non-cooperative\noutcomes without intervention yield suboptimal performance. We derive\nanalytical results and analyze illustrative examples in the cases of imperfect\nand perfect monitoring. In the case of imperfect monitoring, intervention\nschemes can improve the suboptimal performance of non-cooperative equilibrium\nwhen the intervention device has a sufficiently accurate monitoring technology,\nalthough it may not be possible to achieve the best feasible performance. In\nthe case of perfect monitoring, the best feasible performance can be obtained\nwith an intervention scheme when the intervention device has a sufficiently\nstrong intervention capability.", 
    "link": "http://arxiv.org/pdf/1101.3052v2", 
    "arxiv-id": "1101.3052v2"
},{
    "category": "cs.GT", 
    "author": "Edmund M. Yeh", 
    "title": "The Impact of Incomplete Information on Games in Parallel Relay Networks", 
    "publish": "2011-01-21T01:44:09Z", 
    "summary": "We consider the impact of incomplete information on incentives for node\ncooperation in parallel relay networks with one source node, one destination\nnode, and multiple relay nodes. All nodes are selfish and strategic, interested\nin maximizing their own profit instead of the social welfare. We consider the\npractical situation where the channel state on any given relay path is not\nobservable to the source or to the other relays. We examine different\nbargaining relationships between the source and the relays, and propose a\nframework for analyzing the efficiency loss induced by incomplete information.\nWe analyze the source of the efficiency loss, and quantify the amount of\ninefficiency which results.", 
    "link": "http://arxiv.org/pdf/1101.4063v1", 
    "arxiv-id": "1101.4063v1"
},{
    "category": "cs.GT", 
    "author": "Yair Dombb", 
    "title": "Throw One's Cake --- and Have It Too", 
    "publish": "2011-01-23T19:28:02Z", 
    "summary": "We consider the problem of fairly dividing a heterogeneous cake between a\nnumber of players with different tastes. In this setting, it is known that\nfairness requirements may result in a suboptimal division from the social\nwelfare standpoint. Here, we show that in some cases, discarding some of the\ncake and fairly dividing only the remainder may be socially preferable to any\nfair division of the entire cake. We study this phenomenon, providing\nasymptotically-tight bounds on the social improvement achievable by such\ndiscarding.", 
    "link": "http://arxiv.org/pdf/1101.4401v3", 
    "arxiv-id": "1101.4401v3"
},{
    "category": "cs.GT", 
    "author": "Gabriel Istrate", 
    "title": "A Parametric Worst-Case Approach to Fairness in TU-Cooperative Games", 
    "publish": "2012-08-01T17:17:10Z", 
    "summary": "We propose a parametric family of measures of fairness in allocations of\nTU-cooperative games. Their definition is based on generalized Renyi Entropy,\nis related to the Cowell-Kuga generalized entropy indices in welfare economics,\nand aims to parallel the spirit of the notion of price of anarchy in the case\nof convex TU-cooperative games.\n  Since computing these indices is NP-complete in general, we first upper bound\nthe performance of a \"reverse greedy\" algorithm for approximately computing\nworst-case fairness. The result provides a general additive error guarantee in\nterms of two (problem dependent) packing constants. We then particularize this\nresult to the class of induced subset games. For such games computing\nworst-case fairness is NP-complete, and the additive guarantee constant can be\nexplicitly computed. We compare this result to the performance of an alternate\nalgorithm based on \"biased orientations\".", 
    "link": "http://arxiv.org/pdf/1208.0283v1", 
    "arxiv-id": "1208.0283v1"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "Equilibria of Chinese Auctions", 
    "publish": "2012-08-01T17:40:07Z", 
    "summary": "Chinese auctions are a combination between a raffle and an auction and are\nheld in practice at charity events or festivals. In a Chinese auction, multiple\nplayers compete for several items by buying tickets, which can be used to win\nthe items. In front of each item there is a basket, and the players can bid by\nplacing tickets in the basket(s) corresponding to the item(s) they are trying\nto win. After all the players have placed their tickets, a ticket is drawn at\nrandom from each basket and the item is given to the owner of the winning\nticket. While a player is never guaranteed to win an item, they can improve\ntheir chances of getting it by increasing the number of tickets for that item.\n  In this paper we investigate the existence of pure Nash equilibria in both\nthe continuous and discrete settings. When the players have continuous budgets,\nwe show that a pure Nash equilibrium may not exist for asymmetric games when\nsome valuations are zero. In that case we prove that the auctioneer can\nstabilize the game by placing his own ticket in each basket. On the other hand,\nwhen all the valuations are strictly positive, a pure Nash equilibrium is\nguaranteed to exist, and the equilibrium strategies are symmetric when both\nvaluations and budgets are symmetric. We also study Chinese auctions with\ndiscrete budgets, for which we give both existence results and counterexamples.\nWhile the literature on rent-seeking contests traditionally focuses on\ncontinuous costly tickets, the discrete variant is very natural and more\nclosely models the version of the auction held in practice.", 
    "link": "http://arxiv.org/pdf/1208.0296v2", 
    "arxiv-id": "1208.0296v2"
},{
    "category": "cs.GT", 
    "author": "Georgios Zervas", 
    "title": "An Economic Analysis of User-Privacy Options in Ad-Supported Services", 
    "publish": "2012-08-02T02:23:40Z", 
    "summary": "We analyze the value to e-commerce website operators of offering privacy\noptions to users, e.g., of allowing users to opt out of ad targeting. In\nparticular, we assume that site operators have some control over the cost that\na privacy option imposes on users and ask when it is to their advantage to make\nsuch costs low. We consider both the case of a single site and the case of\nmultiple sites that compete both for users who value privacy highly and for\nusers who value it less. One of our main results in the case of a single site\nis that, under normally distributed utilities, if a privacy-sensitive user is\nworth at least $\\sqrt{2} - 1$ times as much to advertisers as a\nprivacy-insensitive user, the site operator should strive to make the cost of a\nprivacy option as low as possible. In the case of multiple sites, we show how a\nPrisoner's-Dilemma situation can arise: In the equilibrium in which both sites\nare obliged to offer a privacy option at minimal cost, both sites obtain lower\nrevenue than they would if they colluded and neither offered a privacy option.", 
    "link": "http://arxiv.org/pdf/1208.0383v1", 
    "arxiv-id": "1208.0383v1"
},{
    "category": "cs.GT", 
    "author": "Demosthenis Teneketzis", 
    "title": "Local public good provisioning in networks: A Nash implementation   mechanism", 
    "publish": "2012-08-02T05:14:04Z", 
    "summary": "In this paper we study resource allocation in decentralized information local\npublic good networks. A network is a local public good network if each user's\nactions directly affect the utility of an arbitrary subset of network users. We\nconsider networks where each user knows only that part of the network that\neither affects or is affected by it. Furthermore, each user's utility and\naction space are its private information, and each user is a self utility\nmaximizer. This network model is motivated by several applications including\nwireless communications and online advertising. For this network model we\nformulate a decentralized resource allocation problem and develop a\ndecentralized resource allocation mechanism (game form) that possesses the\nfollowing properties: (i) All Nash equilibria of the game induced by the\nmechanism result in allocations that are optimal solutions of the corresponding\ncentralized resource allocation problem (Nash implementation). (ii) All users\nvoluntarily participate in the allocation process specified by the mechanism\n(individual rationality). (iii) The mechanism results in budget balance at all\nNash equilibria and off equilibrium.", 
    "link": "http://arxiv.org/pdf/1208.0400v1", 
    "arxiv-id": "1208.0400v1"
},{
    "category": "cs.GT", 
    "author": "Petr Novotn\u00fd", 
    "title": "Determinacy in Stochastic Games with Unbounded Payoff Functions", 
    "publish": "2012-08-08T10:58:00Z", 
    "summary": "We consider infinite-state turn-based stochastic games of two players, Box\nand Diamond, who aim at maximizing and minimizing the expected total reward\naccumulated along a run, respectively. Since the total accumulated reward is\nunbounded, the determinacy of such games cannot be deduced directly from\nMartin's determinacy result for Blackwell games. Nevertheless, we show that\nthese games are determined both for unrestricted (i.e., history-dependent and\nrandomized) strategies and deterministic strategies, and the equilibrium value\nis the same. Further, we show that these games are generally not determined for\nmemoryless strategies. Then, we consider a subclass of\nDiamond-finitely-branching games and show that they are determined for all of\nthe considered strategy types, where the equilibrium value is always the same.\nWe also examine the existence and type of (epsilon-)optimal strategies for both\nplayers.", 
    "link": "http://arxiv.org/pdf/1208.1639v1", 
    "arxiv-id": "1208.1639v1"
},{
    "category": "cs.GT", 
    "author": "Paolo Turrini", 
    "title": "Non-cooperative games with preplay negotiations", 
    "publish": "2012-08-08T17:31:33Z", 
    "summary": "We consider an extension of strategic normal form games with a phase of\nnegotiations before the actual play of the game, where players can make binding\noffers for transfer of utilities to other players after the play of the game,\nin order to provide additional incentives for each other to play designated\nstrategies. Such offers are conditional on the recipients playing the specified\nstrategies and they effect transformations of the payoff matrix of the game by\naccordingly transferring payoffs between players. We introduce and analyze\nsolution concepts for 2-player normal form games with such preplay offers under\nvarious assumptions for the preplay negotiation phase and obtain results for\nexistence of efficient negotiation strategies of the players. Then we extend\nthe framework to coalitional preplay offers in N-player games, as well as to\nextensive form games with inter-play offers for side payments.", 
    "link": "http://arxiv.org/pdf/1208.1718v4", 
    "arxiv-id": "1208.1718v4"
},{
    "category": "cs.GT", 
    "author": "Valentin Goranko", 
    "title": "Transformations of normal form games by preplay offers for payments   among players", 
    "publish": "2012-08-08T21:58:11Z", 
    "summary": "We consider transformations of normal form games by binding preplay offers of\nplayers for payments of utility to other players conditional on them playing\ndesignated in the offers strategies. The game-theoretic effect of such preplay\noffers is transformation of the payoff matrix of the game by transferring\npayoffs between players. Here we analyze and completely characterize the\npossible transformations of the payoff matrix of a normal form game by sets of\npreplay offers.", 
    "link": "http://arxiv.org/pdf/1208.1758v1", 
    "arxiv-id": "1208.1758v1"
},{
    "category": "cs.GT", 
    "author": "Zhihui Qin", 
    "title": "A New Algorithm for the Subtraction Games", 
    "publish": "2012-08-19T13:12:06Z", 
    "summary": "Subtraction games is a class of combinatorial games. It was solved since the\nSprague-Grundy Theory was put forward. This paper described a new algorithm for\nsubtraction games. The new algorithm can find win or lost positions in\nsubtraction games. In addition, it is much simpler than Sprague-Grundy Theory\nin one pile of the games.", 
    "link": "http://arxiv.org/pdf/1208.3832v2", 
    "arxiv-id": "1208.3832v2"
},{
    "category": "cs.GT", 
    "author": "Angelina Vidali", 
    "title": "Approaching Utopia: Strong Truthfulness and Externality-Resistant   Mechanisms", 
    "publish": "2012-08-20T08:36:56Z", 
    "summary": "We introduce and study strongly truthful mechanisms and their applications.\nWe use strongly truthful mechanisms as a tool for implementation in undominated\nstrategies for several problems,including the design of externality resistant\nauctions and a variant of multi-dimensional scheduling.", 
    "link": "http://arxiv.org/pdf/1208.3939v1", 
    "arxiv-id": "1208.3939v1"
},{
    "category": "cs.GT", 
    "author": "H. A. A. El-Saka", 
    "title": "On Dynamical Cournot Game on a Graph", 
    "publish": "2012-07-13T05:40:46Z", 
    "summary": "Cournot dynamical game is studied on a graph. The stability of the system is\nstudied. Prisoner's dilemma game is used to model natural gas transmission.", 
    "link": "http://arxiv.org/pdf/1208.4528v1", 
    "arxiv-id": "1208.4528v1"
},{
    "category": "cs.GT", 
    "author": "Daniela Rus", 
    "title": "Road Pricing for Spreading Peak Travel: Modeling and Design", 
    "publish": "2012-07-16T09:35:31Z", 
    "summary": "A case study of the Singapore road network provides empirical evidence that\nroad pricing can significantly affect commuter trip timing behaviors. In this\npaper, we propose a model of trip timing decisions that reasonably matches the\nobserved commuters' behaviors. Our model explicitly captures the difference in\nindividuals' sensitivity to price, travel time and early or late arrival at\ndestination. New pricing schemes are suggested to better spread peak travel and\nreduce traffic congestion. Simulation results based on the proposed model are\nprovided in comparison with the real data for the Singapore case study.", 
    "link": "http://arxiv.org/pdf/1208.4589v1", 
    "arxiv-id": "1208.4589v1"
},{
    "category": "cs.GT", 
    "author": "Guanglei He", 
    "title": "The Period of the subtraction games", 
    "publish": "2012-08-30T10:58:53Z", 
    "summary": "Subtraction games is a class of impartial combinatorial games, They with\nfinite subtraction sets are known to have periodic nim-sequences. So people try\nto find the regular of the games. But for specific of Sprague-Grundy Theory, it\nis too difficult to find, they obtained some conclusions just by simple\nobserving. This paper used PTFN algorithm to analyze the period of the\nSubtraction games. It is more suitable than Sprague-Grundy Theory, and this\npaper obtained four conclusions by PTFN algorithm . This algorithm provide a\nnew direction to study the subtraction games' period.", 
    "link": "http://arxiv.org/pdf/1208.6134v1", 
    "arxiv-id": "1208.6134v1"
},{
    "category": "cs.GT", 
    "author": "Vincent Conitzer", 
    "title": "False-name-proofness with Bid Withdrawal", 
    "publish": "2012-08-31T14:05:53Z", 
    "summary": "We study a more powerful variant of false-name manipulation in Internet\nauctions: an agent can submit multiple false-name bids, but then, once the\nallocation and payments have been decided, withdraw some of her false-name\nidentities (have some of her false-name identities refuse to pay). While these\nwithdrawn identities will not obtain the items they won, their initial presence\nmay have been beneficial to the agent's other identities. We define a mechanism\nto be false-name-proof with withdrawal (FNPW) if the aforementioned\nmanipulation is never beneficial. FNPW is a stronger condition than\nfalse-name-proofness (FNP).", 
    "link": "http://arxiv.org/pdf/1208.6501v2", 
    "arxiv-id": "1208.6501v2"
},{
    "category": "cs.GT", 
    "author": "Christopher A. Wilkens", 
    "title": "Coopetitive Ad Auctions", 
    "publish": "2012-09-04T23:54:49Z", 
    "summary": "A single advertisement often benefits many parties, for example, an ad for a\nSamsung laptop benefits Microsoft. We study this phenomenon in search\nadvertising auctions and show that standard solutions, including the status quo\nignorance of mutual benefit and a benefit-aware Vickrey-Clarke-Groves\nmechanism, perform poorly. In contrast, we show that an appropriate first-price\nauction has nice equilibria in a single-slot ad auction --- all equilibria that\nsatisfy a natural cooperative envy-freeness condition select the\nwelfare-maximizing ad and satisfy an intuitive lower-bound on revenue.", 
    "link": "http://arxiv.org/pdf/1209.0832v1", 
    "arxiv-id": "1209.0832v1"
},{
    "category": "cs.GT", 
    "author": "Sergey Kuniavsky", 
    "title": "Mechanisms and Behavior Prediction", 
    "publish": "2012-09-05T15:26:41Z", 
    "summary": "This article discusses the possibility of predicting human behavior in a\nmechanism. Such a mechanism will have certain properties, which are defined and\ndiscussed here. Here it is shown that, unfortunately, certain property\ncombinations are not possible. The impossibility result implies that either the\nsuch mechanism will not be finite or it would never be fully known. In both\ncases such a mechanism is inapplicable to fully predict human behavior.", 
    "link": "http://arxiv.org/pdf/1209.1013v2", 
    "arxiv-id": "1209.1013v2"
},{
    "category": "cs.GT", 
    "author": "David Malec", 
    "title": "Sequential Auctions of Identical Items with Budget-Constrained Bidders", 
    "publish": "2012-09-08T09:09:44Z", 
    "summary": "In this paper, we study sequential auctions with two budget constrained\nbidders and any number of identical items. All prior results on such auctions\nconsider only two items. We construct a canonical outcome of the auction that\nis the only natural equilibrium and is unique under a refinement of subgame\nperfect equilibria. We show certain interesting properties of this equilibrium;\nfor instance, we show that the prices decrease as the auction progresses. This\nphenomenon has been observed in many experiments and previous theoretic work\nattributed it to features such as uncertainty in the supply or risk averse\nbidders. We show that such features are not needed for this phenomenon and that\nit arises purely from the most essential features: budget constraints and the\nsequential nature of the auction. A little surprisingly we also show that in\nthis equilibrium one agent wins all his items in the beginning and then the\nother agent wins the rest. The major difficulty in analyzing such sequential\nauctions has been in understanding how the selling prices of the first few\nrounds affect the utilities of the agents in the later rounds. We tackle this\ndifficulty by identifying certain key properties of the auction and the proof\nis via a joint induction on all of them.", 
    "link": "http://arxiv.org/pdf/1209.1698v1", 
    "arxiv-id": "1209.1698v1"
},{
    "category": "cs.GT", 
    "author": "Bruce Hajek", 
    "title": "On the Incentive to Deviate in Core Selecting Combinatorial Auctions", 
    "publish": "2012-09-10T20:04:32Z", 
    "summary": "Recent spectrum auctions in the United Kingdom, and some proposals for future\nauctions of spectrum in the United States, are based on preliminary price\ndiscovery rounds, followed by calculation of final prices for the winning\nbuyers. For example, the prices could be the projection of Vikrey prices onto\nthe core of reported prices. The use of Vikrey prices should lead to more\nstraightforward bidding, but the projection reverses some of the incentive for\nbidders to report truthfully. Still, we conjecture that the price paid by a\nwinning buyer increases no faster than the bid, as in a first price auction. It\nwould be rather disturbing if the conjecture is false. The conjecture is\nestablished for a buyer interacting with disjoint groups of other buyers in a\nstar network setting. It is also shown that for any core-selecting payment rule\nand any integer w greater than or equal to two, there is a market setting with\nw winning buyers such that the price paid by some winning buyer increases at\nleast (1-1/w) times as fast as the price bid.", 
    "link": "http://arxiv.org/pdf/1209.2131v1", 
    "arxiv-id": "1209.2131v1"
},{
    "category": "cs.GT", 
    "author": "Jean-Francois Raskin", 
    "title": "The Complexity of Multi-Mean-Payoff and Multi-Energy Games", 
    "publish": "2012-09-14T15:55:24Z", 
    "summary": "In mean-payoff games, the objective of the protagonist is to ensure that the\nlimit average of an infinite sequence of numeric weights is nonnegative. In\nenergy games, the objective is to ensure that the running sum of weights is\nalways nonnegative. Multi-mean-payoff and multi-energy games replace individual\nweights by tuples, and the limit average (resp. running sum) of each coordinate\nmust be (resp. remain) nonnegative. These games have applications in the\nsynthesis of resource-bounded processes with multiple resources.\n  We prove the finite-memory determinacy of multi-energy games and show the\ninter-reducibility of multimean-payoff and multi-energy games for finite-memory\nstrategies. We also improve the computational complexity for solving both\nclasses of games with finite-memory strategies: while the previously best known\nupper bound was EXPSPACE, and no lower bound was known, we give an optimal\ncoNP-complete bound. For memoryless strategies, we show that the problem of\ndeciding the existence of a winning strategy for the protagonist is\nNP-complete. Finally we present the first solution of multi-meanpayoff games\nwith infinite-memory strategies. We show that multi-mean-payoff games with\nmean-payoff-sup objectives can be decided in NP and coNP, whereas\nmulti-mean-payoff games with mean-payoff-inf objectives are coNP-complete.", 
    "link": "http://arxiv.org/pdf/1209.3234v1", 
    "arxiv-id": "1209.3234v1"
},{
    "category": "cs.GT", 
    "author": "Francesco Scarcello", 
    "title": "Mechanisms for Fair Allocation Problems: No-Punishment Payment Rules in   Fully Verifiable Settings", 
    "publish": "2012-09-15T16:34:54Z", 
    "summary": "Mechanism design is addressed in the context of fair allocations of\nindivisible goods with monetary compensation. Motivated by a real-world social\nchoice problem, mechanisms with verification are considered in a setting where\n(i) agents' declarations on allocated goods can be fully verified before\npayments are performed, and where (ii) verification is not used to punish\nagents whose declarations resulted in incorrect ones. Within this setting, a\nmechanism is designed that is shown to be truthful, efficient, and\nbudget-balanced, and where agents' utilities are fairly determined by the\nShapley value of suitable coalitional games. The proposed mechanism is however\nshown to be #P-complete. Thus, to deal with applications with many agents\ninvolved, two polynomial-time randomized variants are also proposed: one that\nis still truthful and efficient, and which is approximately budget-balanced\nwith high probability, and another one that is truthful in expectation, while\nstill budget-balanced and efficient.", 
    "link": "http://arxiv.org/pdf/1209.3418v1", 
    "arxiv-id": "1209.3418v1"
},{
    "category": "cs.GT", 
    "author": "Rasmus Ibsen-Jensen", 
    "title": "Strategy complexity of finite-horizon Markov decision processes and   simple stochastic games", 
    "publish": "2012-09-17T10:28:56Z", 
    "summary": "Markov decision processes (MDPs) and simple stochastic games (SSGs) provide a\nrich mathematical framework to study many important problems related to\nprobabilistic systems. MDPs and SSGs with finite-horizon objectives, where the\ngoal is to maximize the probability to reach a target state in a given finite\ntime, is a classical and well-studied problem. In this work we consider the\nstrategy complexity of finite-horizon MDPs and SSGs. We show that for all\n$\\epsilon>0$, the natural class of counter-based strategies require at most\n$\\log \\log (\\frac{1}{\\epsilon}) + n+1$ memory states, and memory of size\n$\\Omega(\\log \\log (\\frac{1}{\\epsilon}) + n)$ is required. Thus our bounds are\nasymptotically optimal. We then study the periodic property of optimal\nstrategies, and show a sub-exponential lower bound on the period for optimal\nstrategies.", 
    "link": "http://arxiv.org/pdf/1209.3617v1", 
    "arxiv-id": "1209.3617v1"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "Simultaneous Auctions are (almost) Efficient", 
    "publish": "2012-09-21T05:21:42Z", 
    "summary": "Simultaneous item auctions are simple procedures for allocating items to\nbidders with potentially complex preferences over different item sets. In a\nsimultaneous auction, every bidder submits bids on all items simultaneously.\nThe allocation and prices are then resolved for each item separately, based\nsolely on the bids submitted on that item. Such procedures occur in practice\n(e.g. eBay) but are not truthful. We study the efficiency of Bayesian Nash\nequilibrium (BNE) outcomes of simultaneous first- and second-price auctions\nwhen bidders have complement-free (a.k.a. subadditive) valuations. We show that\nthe expected social welfare of any BNE is at least 1/2 of the optimal social\nwelfare in the case of first-price auctions, and at least 1/4 in the case of\nsecond-price auctions. These results improve upon the previously-known\nlogarithmic bounds, which were established by [Hassidim, Kaplan, Mansour and\nNisan '11] for first-price auctions and by [Bhawalkar and Roughgarden '11] for\nsecond-price auctions.", 
    "link": "http://arxiv.org/pdf/1209.4703v1", 
    "arxiv-id": "1209.4703v1"
},{
    "category": "cs.GT", 
    "author": "Christopher A. Wilkens", 
    "title": "eBay's Market Intermediation Problem", 
    "publish": "2012-09-24T18:01:36Z", 
    "summary": "We study the optimal mechanism design problem faced by a market intermediary\nwho makes revenue by connecting buyers and sellers. We first show that the\noptimal intermediation protocol has substantial structure: it is the solution\nto an algorithmic pricing problem in which seller's costs are replaced with\nvirtual costs, and the sellers' payments need only depend on the buyer's\nbehavior and not the buyer's actual valuation function.\n  Since the underlying algorithmic pricing problem may be difficult to solve\noptimally, we study specific models of buyer behavior and give mechanisms with\nprovable approximation guarantees. We show that offering only the single most\nprofitable item for sale guarantees an $\\Omega(\\frac1{\\log n})$ fraction of the\noptimal revenue when item value distributions are independent and have monotone\nhazard rates. We also give constant factor approximations when the buyer\nconsiders all items at once, $k$ items at once, or items in sequence.", 
    "link": "http://arxiv.org/pdf/1209.5348v2", 
    "arxiv-id": "1209.5348v2"
},{
    "category": "cs.GT", 
    "author": "Martin Starnberger", 
    "title": "Auctions with Heterogeneous Items and Budget Limits", 
    "publish": "2012-09-28T08:21:13Z", 
    "summary": "We study individual rational, Pareto optimal, and incentive compatible\nmechanisms for auctions with heterogeneous items and budget limits. For\nmulti-dimensional valuations we show that there can be no deterministic\nmechanism with these properties for divisible items. We use this to show that\nthere can also be no randomized mechanism that achieves this for either\ndivisible or indivisible items. For single-dimensional valuations we show that\nthere can be no deterministic mechanism with these properties for indivisible\nitems, but that there is a randomized mechanism that achieves this for either\ndivisible or indivisible items. The impossibility results hold for public\nbudgets, while the mechanism allows private budgets, which is in both cases the\nharder variant to show. While all positive results are polynomial-time\nalgorithms, all negative results hold independent of complexity considerations.", 
    "link": "http://arxiv.org/pdf/1209.6448v1", 
    "arxiv-id": "1209.6448v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Incentive Compatible Two Player Cake Cutting", 
    "publish": "2012-09-29T22:08:51Z", 
    "summary": "We characterize methods of dividing a cake between two bidders in a way that\nis incentive-compatible and Pareto-efficient. In our cake cutting model, each\nbidder desires a subset of the cake (with a uniform value over this subset),\nand is allocated some subset. Our characterization proceeds via reducing to a\nsimple one-dimensional version of the problem, and yields, for example, a tight\nbound on the social welfare achievable.", 
    "link": "http://arxiv.org/pdf/1210.0155v1", 
    "arxiv-id": "1210.0155v1"
},{
    "category": "cs.GT", 
    "author": "Jinshan Zhang", 
    "title": "On Revenue Maximization with Sharp Multi-Unit Demands", 
    "publish": "2012-09-30T14:02:31Z", 
    "summary": "We consider markets consisting of a set of indivisible items, and buyers that\nhave {\\em sharp} multi-unit demand. This means that each buyer $i$ wants a\nspecific number $d_i$ of items; a bundle of size less than $d_i$ has no value,\nwhile a bundle of size greater than $d_i$ is worth no more than the most valued\n$d_i$ items (valuations being additive). We consider the objective of setting\nprices and allocations in order to maximize the total revenue of the market\nmaker. The pricing problem with sharp multi-unit demand buyers has a number of\nproperties that the unit-demand model does not possess, and is an important\nquestion in algorithmic pricing. We consider the problem of computing a revenue\nmaximizing solution for two solution concepts: competitive equilibrium and\nenvy-free pricing.\n  For unrestricted valuations, these problems are NP-complete; we focus on a\nrealistic special case of \"correlated values\" where each buyer $i$ has a\nvaluation $v_i\\qual_j$ for item $j$, where $v_i$ and $\\qual_j$ are positive\nquantities associated with buyer $i$ and item $j$ respectively. We present a\npolynomial time algorithm to solve the revenue-maximizing competitive\nequilibrium problem. For envy-free pricing, if the demand of each buyer is\nbounded by a constant, a revenue maximizing solution can be found efficiently;\nthe general demand case is shown to be NP-hard.", 
    "link": "http://arxiv.org/pdf/1210.0203v5", 
    "arxiv-id": "1210.0203v5"
},{
    "category": "cs.GT", 
    "author": "Carola Winzen", 
    "title": "The Price of Anarchy for Selfish Ring Routing is Two", 
    "publish": "2012-09-30T19:07:13Z", 
    "summary": "We analyze the network congestion game with atomic players, asymmetric\nstrategies, and the maximum latency among all players as social cost. This\nimportant social cost function is much less understood than the average\nlatency. We show that the price of anarchy is at most two, when the network is\na ring and the link latencies are linear. Our bound is tight. This is the first\nsharp bound for the maximum latency objective.", 
    "link": "http://arxiv.org/pdf/1210.0230v1", 
    "arxiv-id": "1210.0230v1"
},{
    "category": "cs.GT", 
    "author": "Omer Tamuz", 
    "title": "Lower Bounds on Revenue of Approximately Optimal Auctions", 
    "publish": "2012-10-01T02:14:33Z", 
    "summary": "We obtain revenue guarantees for the simple pricing mechanism of a single\nposted price, in terms of a natural parameter of the distribution of buyers'\nvaluations. Our revenue guarantee applies to the single item n buyers setting,\nwith values drawn from an arbitrary joint distribution. Specifically, we show\nthat a single price drawn from the distribution of the maximum valuation Vmax =\nmax {V_1, V_2, ...,V_n} achieves a revenue of at least a 1/e fraction of the\ngeometric expecation of Vmax. This generic bound is a measure of how revenue\nimproves/degrades as a function of the concentration/spread of Vmax.\n  We further show that in absence of buyers' valuation distributions,\nrecruiting an additional set of identical bidders will yield a similar\nguarantee on revenue. Finally, our bound also gives a measure of the extent to\nwhich one can simultaneously approximate welfare and revenue in terms of the\nconcentration/spread of Vmax.", 
    "link": "http://arxiv.org/pdf/1210.0275v1", 
    "arxiv-id": "1210.0275v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Clinching Auctions with Online Supply", 
    "publish": "2012-10-04T14:16:55Z", 
    "summary": "Auctions for perishable goods such as internet ad inventory need to make\nreal-time allocation and pricing decisions as the supply of the good arrives in\nan online manner, without knowing the entire supply in advance. These\nallocation and pricing decisions get complicated when buyers have some global\nconstraints. In this work, we consider a multi-unit model where buyers have\nglobal {\\em budget} constraints, and the supply arrives in an online manner.\nOur main contribution is to show that for this setting there is an\nindividually-rational, incentive-compatible and Pareto-optimal auction that\nallocates these units and calculates prices on the fly, without knowledge of\nthe total supply. We do so by showing that the Adaptive Clinching Auction\nsatisfies a {\\em supply-monotonicity} property.\n  We also analyze and discuss, using examples, how the insights gained by the\nallocation and payment rule can be applied to design better ad allocation\nheuristics in practice. Finally, while our main technical result concerns\nmulti-unit supply, we propose a formal model of online supply that captures\nscenarios beyond multi-unit supply and has applications to sponsored search. We\nconjecture that our results for multi-unit auctions can be extended to these\nmore general models.", 
    "link": "http://arxiv.org/pdf/1210.1456v1", 
    "arxiv-id": "1210.1456v1"
},{
    "category": "cs.GT", 
    "author": "Qing Zhao", 
    "title": "Distributed Flow Scheduling in an Unknown Environment", 
    "publish": "2012-10-05T11:08:24Z", 
    "summary": "Flow scheduling tends to be one of the oldest and most stubborn problems in\nnetworking. It becomes more crucial in the next generation network, due to fast\nchanging link states and tremendous cost to explore the global structure. In\nsuch situation, distributed algorithms often dominate. In this paper, we design\na distributed virtual game to solve the flow scheduling problem and then\ngeneralize it to situations of unknown environment, where online learning\nschemes are utilized. In the virtual game, we use incentives to stimulate\nselfish users to reach a Nash Equilibrium Point which is valid based on the\nanalysis of the `Price of Anarchy'. In the unknown-environment generalization,\nour ultimate goal is the minimization of cost in the long run. In order to\nachieve balance between exploration of routing cost and exploitation based on\nlimited information, we model this problem based on Multi-armed Bandit Scenario\nand combined newly proposed DSEE with the virtual game design. Armed with these\npowerful tools, we find a totally distributed algorithm to ensure the\nlogarithmic growing of regret with time, which is optimum in classic\nMulti-armed Bandit Problem. Theoretical proof and simulation results both\naffirm this claim. To our knowledge, this is the first research to combine\nmulti-armed bandit with distributed flow scheduling.", 
    "link": "http://arxiv.org/pdf/1210.1708v2", 
    "arxiv-id": "1210.1708v2"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "The AND-OR game: Equilibrium Characterization (Working Paper)", 
    "publish": "2012-10-05T13:36:17Z", 
    "summary": "We consider a simple simultaneous first price auction for multiple items in a\ncomplete information setting. Our goal is to completely characterize the mixed\nequilibria in this setting, for a simple, yet highly interesting, {\\tt\nAND}-{\\tt OR} game, where one agent is single minded and the other is unit\ndemand.", 
    "link": "http://arxiv.org/pdf/1210.1757v1", 
    "arxiv-id": "1210.1757v1"
},{
    "category": "cs.GT", 
    "author": "Martin Zimmermann", 
    "title": "Playing Pushdown Parity Games in a Hurry", 
    "publish": "2012-10-09T00:54:43Z", 
    "summary": "We continue the investigation of finite-duration variants of\ninfinite-duration games by extending known results for games played on finite\ngraphs to those played on infinite ones. In particular, we establish an\nequivalence between pushdown parity games and a finite-duration variant. This\nallows us to determine the winner of a pushdown parity game by solving a\nreachability game on a finite tree.", 
    "link": "http://arxiv.org/pdf/1210.2458v1", 
    "arxiv-id": "1210.2458v1"
},{
    "category": "cs.GT", 
    "author": "Zhiyi Huang", 
    "title": "Simple and Nearly Optimal Multi-Item Auctions", 
    "publish": "2012-10-12T16:12:25Z", 
    "summary": "We provide a Polynomial Time Approximation Scheme (PTAS) for the Bayesian\noptimal multi-item multi-bidder auction problem under two conditions. First,\nbidders are independent, have additive valuations and are from the same\npopulation. Second, every bidder's value distributions of items are independent\nbut not necessarily identical monotone hazard rate (MHR) distributions. For\nnon-i.i.d. bidders, we also provide a PTAS when the number of bidders is small.\nPrior to our work, even for a single bidder, only constant factor\napproximations are known.\n  Another appealing feature of our mechanism is the simple allocation rule.\nIndeed, the mechanism we use is either the second-price auction with reserve\nprice on every item individually, or VCG allocation with a few outlying items\nthat requires additional treatments. It is surprising that such simple\nallocation rules suffice to obtain nearly optimal revenue.", 
    "link": "http://arxiv.org/pdf/1210.3560v2", 
    "arxiv-id": "1210.3560v2"
},{
    "category": "cs.GT", 
    "author": "Viktor Winschel", 
    "title": "Coalgebraic Analysis of Subgame-perfect Equilibria in Infinite Games   without Discounting", 
    "publish": "2012-10-16T19:32:51Z", 
    "summary": "We present a novel coalgebraic formulation of infinite extensive games. We\ndefine both the game trees and the strategy profiles by possibly infinite\nsystems of corecursive equations. Certain strategy profiles are proved to be\nsubgame perfect equilibria using a novel proof principle of predicate\ncoinduction. We characterize all subgame perfect equilibria for the dollar\nauction game. The economically interesting feature is that in order to prove\nthese results we do not need to rely on continuity assumptions on the payoffs\nwhich amount to discounting the future. In particular, we prove a form of\none-deviation principle without any such assumptions. This suggests that\ncoalgebra supports a more adequate treatment of infinite-horizon models in game\ntheory and economics.", 
    "link": "http://arxiv.org/pdf/1210.4537v3", 
    "arxiv-id": "1210.4537v3"
},{
    "category": "cs.GT", 
    "author": "Anton Schwaighofer", 
    "title": "Budget Optimization for Sponsored Search: Censored Learning in MDPs", 
    "publish": "2012-10-16T17:34:55Z", 
    "summary": "We consider the budget optimization problem faced by an advertiser\nparticipating in repeated sponsored search auctions, seeking to maximize the\nnumber of clicks attained under that budget. We cast the budget optimization\nproblem as a Markov Decision Process (MDP) with censored observations, and\npropose a learning algorithm based on the wellknown Kaplan-Meier or\nproduct-limit estimator. We validate the performance of this algorithm by\ncomparing it to several others on a large set of search auction data from\nMicrosoft adCenter, demonstrating fast convergence to optimal performance.", 
    "link": "http://arxiv.org/pdf/1210.4847v1", 
    "arxiv-id": "1210.4847v1"
},{
    "category": "cs.GT", 
    "author": "Tuomas Sandholm", 
    "title": "Combining local search techniques and path following for bimatrix games", 
    "publish": "2012-10-16T17:38:03Z", 
    "summary": "Computing a Nash equilibrium (NE) is a central task in computer science. An\nNE is a particularly appropriate solution concept for two-agent settings\nbecause coalitional deviations are not an issue. However, even in this case,\nfinding an NE is PPAD-complete. In this paper, we combine path following\nalgorithms with local search techniques to design new algorithms for finding\nexact and approximate NEs. We show that our algorithms largely outperform the\nstate of the art and that almost all the known benchmark game classes are\neasily solvable or approximable (except for the GAMUT CovariantGameRand class).", 
    "link": "http://arxiv.org/pdf/1210.4858v1", 
    "arxiv-id": "1210.4858v1"
},{
    "category": "cs.GT", 
    "author": "Craig Boutilier", 
    "title": "Bayesian Vote Manipulation: Optimal Strategies and Impact on Welfare", 
    "publish": "2012-10-16T17:47:55Z", 
    "summary": "Most analyses of manipulation of voting schemes have adopted two assumptions\nthat greatly diminish their practical import. First, it is usually assumed that\nthe manipulators have full knowledge of the votes of the nonmanipulating\nagents. Second, analysis tends to focus on the probability of manipulation\nrather than its impact on the social choice objective (e.g., social welfare).\nWe relax both of these assumptions by analyzing optimal Bayesian manipulation\nstrategies when the manipulators have only partial probabilistic information\nabout nonmanipulator votes, and assessing the expected loss in social welfare\n(in the broad sense of the term). We present a general optimization framework\nfor the derivation of optimal manipulation strategies given arbitrary voting\nrules and distributions over preferences. We theoretically and empirically\nanalyze the optimal manipulability of some popular voting rules using\ndistributions and real data sets that go well beyond the common, but\nunrealistic, impartial culture assumption. We also shed light on the stark\ndifference between the loss in social welfare and the probability of\nmanipulation by showing that even when manipulation is likely, impact to social\nwelfare is slight (and often negligible).", 
    "link": "http://arxiv.org/pdf/1210.4895v1", 
    "arxiv-id": "1210.4895v1"
},{
    "category": "cs.GT", 
    "author": "Amy Greenwald", 
    "title": "Self-Confirming Price Prediction Strategies for Simultaneous One-Shot   Auctions", 
    "publish": "2012-10-16T17:56:19Z", 
    "summary": "Bidding in simultaneous auctions is challenging because an agent's value for\na good in one auction may depend on the uncertain outcome of other auctions:\nthe so-called exposure problem. Given the gap in understanding of general\nsimultaneous auction games, previous works have tackled this problem with\nheuristic strategies that employ probabilistic price predictions. We define a\nconcept of self-confirming prices, and show that within an independent private\nvalue model, Bayes-Nash equilibrium can be fully characterized as a profile of\noptimal price prediction strategies with self-confirming predictions. We\nexhibit practical procedures to compute approximately optimal bids given a\nprobabilistic price prediction, and near self-confirming price predictions\ngiven a price-prediction strategy. An extensive empirical game-theoretic\nanalysis demonstrates that self-confirming price prediction strategies are\neffective in simultaneous auction games with both complementary and\nsubstitutable preference structures.", 
    "link": "http://arxiv.org/pdf/1210.4915v1", 
    "arxiv-id": "1210.4915v1"
},{
    "category": "cs.GT", 
    "author": "Matthijs Ruijgrok", 
    "title": "A single-item continuous double auction game", 
    "publish": "2012-10-19T21:25:39Z", 
    "summary": "A double auction game with an infinite number of buyers and sellers is\nintroduced. All sellers posses one unit of a good, all buyers desire to buy one\nunit. Each seller and each buyer has a private valuation of the good. The\ndistribution of the valuations define supply and demand functions. One unit of\nthe good is auctioned. At successive, discrete time instances, a player is\nrandomly selected to make a bid (buyer) or an ask (seller). When the maximum of\nthe bids becomes larger than the minimum of the asks, a transaction occurs and\nthe auction is closed. The players have to choose the value of their bid or ask\nbefore the auction starts and use this value when they are selected. Assuming\nthat the supply and demand functions are known, expected profits as functions\nof the strategies are derived, as well as expected transaction prices. It is\nshown that for linear supply and demand functions, there exists at most one\nBayesian Nash equilibrium. Competitive behaviour is not an equilibrium of the\ngame. For linear supply and demand functions, the sum of the expected profit of\nthe sellers and the buyers is the same for the Bayesian Nash equilibrium and\nthe market where players behave competitively. Connections are made with the\nZI-C traders model and the $k$-double auction.", 
    "link": "http://arxiv.org/pdf/1210.5541v1", 
    "arxiv-id": "1210.5541v1"
},{
    "category": "cs.GT", 
    "author": "Amjed Shareef", 
    "title": "Short Report on: Possible directions to Auctions with Cryptographic   pre-play", 
    "publish": "2012-10-24T08:05:30Z", 
    "summary": "In auction theory, cryptography has been used to achieve anonymity of the\nparticipants, security and privacy of the bids, secure computation and to\nsimulate mediator (auctioneer). Auction theory focuses on revenue and\nCryptography focuses on security and privacy. Involving Cryptography at base\nlevel, to enhance revenue gives entirely new perspective and insight to Auction\ntheory, thereby achieving the core goals of auction theory. In this report, we\ntry to investigate an interesting field of study in Auction Theory using\nCryptographic primitives.", 
    "link": "http://arxiv.org/pdf/1210.6450v1", 
    "arxiv-id": "1210.6450v1"
},{
    "category": "cs.GT", 
    "author": "Balakrishnan Narayanaswamy", 
    "title": "Improving Productive Output in Influencer-Influencee Networks", 
    "publish": "2013-02-13T10:40:01Z", 
    "summary": "In any organization, a primary goal of the designer is to maximize the net\nproductive output. Every organization has a network (either hierarchical or\nother) that is used to divide the tasks. It is observed that the individuals in\nthese networks trade off between their productive and managing efforts to do\nthese tasks and the trade-off is caused by their positions and share of rewards\nin the network. Efforts of the agents here are substitutable, e.g., the\nincrease in the productive effort by an individual in effect reduces the same\nof some other individual in the network, who now puts their efforts into\nmanagement. The management effort of an agent improves the productivity of\ncertain other agents in the network. In this paper, we provide a detailed\nanalysis of the Nash equilibrium efforts of the individuals connected over a\nnetwork and a design recipe of the reward sharing scheme that maximizes the net\nproductive output. Our results show that under the strategic behavior of the\nagents, it may not always be possible to achieve the optimal output and we\nprovide bounds on the achievability in such scenarios.", 
    "link": "http://arxiv.org/pdf/1302.3045v3", 
    "arxiv-id": "1302.3045v3"
},{
    "category": "cs.GT", 
    "author": "Rahul Savani", 
    "title": "Learning Equilibria of Games via Payoff Queries", 
    "publish": "2013-02-13T14:29:13Z", 
    "summary": "A recent body of experimental literature has studied empirical\ngame-theoretical analysis, in which we have partial knowledge of a game,\nconsisting of observations of a subset of the pure-strategy profiles and their\nassociated payoffs to players. The aim is to find an exact or approximate Nash\nequilibrium of the game, based on these observations. It is usually assumed\nthat the strategy profiles may be chosen in an on-line manner by the algorithm.\nWe study a corresponding computational learning model, and the query complexity\nof learning equilibria for various classes of games. We give basic results for\nbimatrix and graphical games. Our focus is on symmetric network congestion\ngames. For directed acyclic networks, we can learn the cost functions (and\nhence compute an equilibrium) while querying just a small fraction of\npure-strategy profiles. For the special case of parallel links, we have the\nstronger result that an equilibrium can be identified while only learning a\nsmall fraction of the cost values.", 
    "link": "http://arxiv.org/pdf/1302.3116v4", 
    "arxiv-id": "1302.3116v4"
},{
    "category": "cs.GT", 
    "author": "Emmanouil Pountourakis", 
    "title": "Socially Stable Matchings", 
    "publish": "2013-02-14T04:37:06Z", 
    "summary": "In two-sided matching markets, the agents are partitioned into two sets. Each\nagent wishes to be matched to an agent in the other set and has a strict\npreference over these potential matches. A matching is stable if there are no\nblocking pairs, i.e., no pair of agents that prefer each other to their\nassigned matches. In this paper we study a variant of stable matching motivated\nby the fact that, in most centralized markets, many agents do not have direct\ncommunication with each other. Hence even if some blocking pairs exist, the\nagents involved in those pairs may not be able to coordinate a deviation. We\nmodel communication channels with a bipartite graph between the two sets of\nagents which we call the social graph, and we study socially stable matchings.\nA matching is socially stable if there are no blocking pairs that are connected\nby an edge in the social graph. Socially stable matchings vary in size and so\nwe look for a maximum socially stable matching. We prove that this problem is\nNP-hard and, assuming the unique games conjecture, hard to approximate within a\nfactor of 3/2-{\\epsilon}, for any constant {\\epsilon}>0. We complement the\nhardness results with a 3/2-approximation algorithm.", 
    "link": "http://arxiv.org/pdf/1302.3309v2", 
    "arxiv-id": "1302.3309v2"
},{
    "category": "cs.GT", 
    "author": "Arnoud Pastink", 
    "title": "On the Communication Complexity of Approximate Nash Equilibria", 
    "publish": "2013-02-15T16:17:46Z", 
    "summary": "We study the problem of computing approximate Nash equilibria of bimatrix\ngames, in a setting where players initially know their own payoffs but not the\npayoffs of the other player. In order for a solution of reasonable quality to\nbe found, some amount of communication needs to take place between the players.\nWe are interested in algorithms where the communication is substantially less\nthan the contents of a payoff matrix, for example logarithmic in the size of\nthe matrix. When the communication is polylogarithmic in the number of\nstrategies n, we show how to obtain epsilon-approximate Nash equilibria for\nepsilon approximately 0.438, and for well-supported approximate equilibria we\nobtain epsilon approximately 0.732. For one-way communication we show that\nepsilon=1/2 is achievable, but no constant improvement over 1/2 is possible,\neven with unlimited one-way communication. For well-supported equilibria, no\nvalue of epsilon less than 1 is achievable with one-way communication. When the\nplayers do not communicate at all, epsilon-Nash equilibria can be obtained for\nepsilon=3/4, and we also give a lower bound of slightly more than 1/2 on the\nlowest constant epsilon achievable.", 
    "link": "http://arxiv.org/pdf/1302.3793v1", 
    "arxiv-id": "1302.3793v1"
},{
    "category": "cs.GT", 
    "author": "Andy Lewis-Pye", 
    "title": "Digital morphogenesis via Schelling segregation", 
    "publish": "2013-02-16T23:58:55Z", 
    "summary": "Schelling's model of segregation looks to explain the way in which particles\nor agents of two types may come to arrange themselves spatially into\nconfigurations consisting of large homogeneous clusters, i.e.\\ connected\nregions consisting of only one type. As one of the earliest agent based models\nstudied by economists and perhaps the most famous model of self-organising\nbehaviour, it also has direct links to areas at the interface between computer\nscience and statistical mechanics, such as the Ising model and the study of\ncontagion and cascading phenomena in networks.\n  While the model has been extensively studied it has largely resisted rigorous\nanalysis, prior results from the literature generally pertaining to variants of\nthe model which are tweaked so as to be amenable to standard techniques from\nstatistical mechanics or stochastic evolutionary game theory. In \\cite{BK},\nBrandt, Immorlica, Kamath and Kleinberg provided the first rigorous analysis of\nthe unperturbed model, for a specific set of input parameters. Here we provide\na rigorous analysis of the model's behaviour much more generally and establish\nsome surprising forms of threshold behaviour, notably the existence of\nsituations where an \\emph{increased} level of intolerance for neighbouring\nagents of opposite type leads almost certainly to \\emph{decreased} segregation.", 
    "link": "http://arxiv.org/pdf/1302.4014v6", 
    "arxiv-id": "1302.4014v6"
},{
    "category": "cs.GT", 
    "author": "Aleksandrs Slivkins", 
    "title": "Multi-parameter Mechanisms with Implicit Payment Computation", 
    "publish": "2013-02-18T00:25:29Z", 
    "summary": "In this paper we show that payment computation essentially does not present\nany obstacle in designing truthful mechanisms, even for multi-parameter\ndomains, and even when we can only call the allocation rule once. We present a\ngeneral reduction that takes any allocation rule which satisfies \"cyclic\nmonotonicity\" (a known necessary and sufficient condition for truthfulness) and\nconverts it to a truthful mechanism using a single call to the allocation rule,\nwith arbitrarily small loss to the expected social welfare.\n  A prominent example for a multi-parameter setting in which an allocation rule\ncan only be called once arises in sponsored search auctions. These are\nmulti-parameter domains when each advertiser has multiple possible ads he may\ndisplay, each with a different value per click. Moreover, the mechanism\ntypically does not have complete knowledge of the click-realization or the\nclick-through rates (CTRs); it can only call the allocation rule a single time\nand observe the click information for ads that were presented. % are not known.\nOn the negative side, we show that an allocation that is truthful for any\nrealization essentially cannot depend on the bids, and hence cannot do better\nthan random selection for one agent. We then consider a relaxed requirement of\ntruthfulness, only in expectation over the CTRs. Even for that relaxed version,\nmaking any progress is challenging as standard techniques for construction of\ntruthful mechanisms (as using VCG or an MIDR allocation rule) cannot be used in\nthis setting. We design an allocation rule with non-trivial performance and\ndirectly prove it is cyclic-monotone, and thus it can be used to create a\ntruthful mechanism using our general reduction.", 
    "link": "http://arxiv.org/pdf/1302.4138v2", 
    "arxiv-id": "1302.4138v2"
},{
    "category": "cs.GT", 
    "author": "Argyrios Deligkas", 
    "title": "Revenue Maximization via Hiding Item Attributes", 
    "publish": "2013-02-21T16:48:25Z", 
    "summary": "We study probabilistic single-item second-price auctions where the item is\ncharacterized by a set of attributes. The auctioneer knows the actual\ninstantiation of all the attributes, but he may choose to reveal only a subset\nof these attributes to the bidders. Our model is an abstraction of the\nfollowing Ad auction scenario. The website (auctioneer) knows the demographic\ninformation of its impressions, and this information is in terms of a list of\nattributes (e.g., age, gender, country of location). The website may hide\ncertain attributes from its advertisers (bidders) in order to create thicker\nmarket, which may lead to higher revenue. We study how to hide attributes in an\noptimal way. We show that it is NP-hard to solve for the optimal attribute\nhiding scheme. We then derive a polynomial-time solvable upper bound on the\noptimal revenue. Finally, we propose two heuristic-based attribute hiding\nschemes. Experiments show that revenue achieved by these schemes is close to\nthe upper bound.", 
    "link": "http://arxiv.org/pdf/1302.5332v1", 
    "arxiv-id": "1302.5332v1"
},{
    "category": "cs.GT", 
    "author": "S. Muthukrishnan", 
    "title": "Budget Feasible Mechanisms for Experimental Design", 
    "publish": "2013-02-22T22:12:11Z", 
    "summary": "In the classical experimental design setting, an experimenter E has access to\na population of $n$ potential experiment subjects $i\\in \\{1,...,n\\}$, each\nassociated with a vector of features $x_i\\in R^d$. Conducting an experiment\nwith subject $i$ reveals an unknown value $y_i\\in R$ to E. E typically assumes\nsome hypothetical relationship between $x_i$'s and $y_i$'s, e.g., $y_i \\approx\n\\beta x_i$, and estimates $\\beta$ from experiments, e.g., through linear\nregression. As a proxy for various practical constraints, E may select only a\nsubset of subjects on which to conduct the experiment.\n  We initiate the study of budgeted mechanisms for experimental design. In this\nsetting, E has a budget $B$. Each subject $i$ declares an associated cost $c_i\n>0$ to be part of the experiment, and must be paid at least her cost. In\nparticular, the Experimental Design Problem (EDP) is to find a set $S$ of\nsubjects for the experiment that maximizes $V(S) = \\log\\det(I_d+\\sum_{i\\in\nS}x_i\\T{x_i})$ under the constraint $\\sum_{i\\in S}c_i\\leq B$; our objective\nfunction corresponds to the information gain in parameter $\\beta$ that is\nlearned through linear regression methods, and is related to the so-called\n$D$-optimality criterion. Further, the subjects are strategic and may lie about\ntheir costs.\n  We present a deterministic, polynomial time, budget feasible mechanism\nscheme, that is approximately truthful and yields a constant factor\napproximation to EDP. In particular, for any small $\\delta > 0$ and $\\epsilon >\n0$, we can construct a (12.98, $\\epsilon$)-approximate mechanism that is\n$\\delta$-truthful and runs in polynomial time in both $n$ and\n$\\log\\log\\frac{B}{\\epsilon\\delta}$. We also establish that no truthful,\nbudget-feasible algorithms is possible within a factor 2 approximation, and\nshow how to generalize our approach to a wide class of learning problems,\nbeyond linear regression.", 
    "link": "http://arxiv.org/pdf/1302.5724v4", 
    "arxiv-id": "1302.5724v4"
},{
    "category": "cs.GT", 
    "author": "Inbal Talgam-Cohen", 
    "title": "Refine Predictions Ad Infinitum?", 
    "publish": "2013-02-27T09:06:23Z", 
    "summary": "We study how standard auction objectives in sponsored search markets change\nwith refinements in the prediction of the relevance (click-through rates) of\nads. We study mechanisms that optimize for a convex combination of efficiency\nand revenue. We show that the objective function of such a mechanism can only\nimprove with refined (improved) relevance predictions, i.e., the search engine\nhas no disincentive to perform these refinements. More interestingly, we show\nthat under assumptions, refinements to relevance predictions can only improve\nthe efficiency of any such mechanism. Our main technical contribution is to\nstudy how relevance refinements affect the similarity between ranking by\nvirtual-value (revenue ranking) and ranking by value (efficiency ranking).\nFinally, we discuss implications of our results to the literature on signaling.", 
    "link": "http://arxiv.org/pdf/1302.6700v1", 
    "arxiv-id": "1302.6700v1"
},{
    "category": "cs.GT", 
    "author": "Edward A. Billard", 
    "title": "Learning in Multi-level Stochastic games with Delayed Information", 
    "publish": "2013-02-27T14:14:20Z", 
    "summary": "Distributed decision-makers are modeled as players in a game with two levels.\nHigh level decisions concern the game environment and determine the willingness\nof the players to form a coalition (or group). Low level decisions involve the\nactions to be implemented within the chosen environment. Coalition and action\nstrategies are determined by probability distributions, which are updated using\nlearning automata schemes. The payoffs are also probabilistic and there is\nuncertainty in the state vector since information is delayed. The goal is to\nreach equilibrium in both levels of decision making; the results show the\nconditions for instability, based on the age of information.", 
    "link": "http://arxiv.org/pdf/1302.6790v1", 
    "arxiv-id": "1302.6790v1"
},{
    "category": "cs.GT", 
    "author": "Michael Johanson", 
    "title": "Measuring the Size of Large No-Limit Poker Games", 
    "publish": "2013-02-27T21:20:49Z", 
    "summary": "In the field of computational game theory, games are often compared in terms\nof their size. This can be measured in several ways, including the number of\nunique game states, the number of decision points, and the total number of\nlegal actions over all decision points. These numbers are either known or\nestimated for a wide range of classic games such as chess and checkers. In the\nstochastic and imperfect information game of poker, these sizes are easily\ncomputed in \"limit\" games which restrict the players' available actions, but\nuntil now had only been estimated for the more complicated \"no-limit\" variants.\nIn this paper, we describe a simple algorithm for quickly computing the size of\ntwo-player no-limit poker games, provide an implementation of this algorithm,\nand present for the first time precise counts of the number of game states,\ninformation sets, actions and terminal nodes in the no-limit poker games played\nin the Annual Computer Poker Competition.", 
    "link": "http://arxiv.org/pdf/1302.7008v2", 
    "arxiv-id": "1302.7008v2"
},{
    "category": "cs.GT", 
    "author": "Zhigang Cao", 
    "title": "Coalitional Game Theoretic Approach for Cooperative Transmission in   Vehicular Networks", 
    "publish": "2013-02-28T13:57:25Z", 
    "summary": "Cooperative transmission in vehicular networks is studied by using\ncoalitional game and pricing in this paper. There are several vehicles and\nroadside units (RSUs) in the networks. Each vehicle has a desire to transmit\nwith a certain probability, which represents its data burtiness. The RSUs can\nenhance the vehicles' transmissions by cooperatively relaying the vehicles'\ndata. We consider two kinds of cooperations: cooperation among the vehicles and\ncooperation between the vehicle and RSU. First, vehicles cooperate to avoid\ninterfering transmissions by scheduling the transmissions of the vehicles in\neach coalition. Second, a RSU can join some coalition to cooperate the\ntransmissions of the vehicles in that coalition. Moreover, due to the mobility\nof the vehicles, we introduce the notion of encounter between the vehicle and\nRSU to indicate the availability of the relay in space. To stimulate the RSU's\ncooperative relaying for the vehicles, the pricing mechanism is applied. A\nnon-transferable utility (NTU) game is developed to analyze the behaviors of\nthe vehicles and RSUs. The stability of the formulated game is studied.\nFinally, we present and discuss the numerical results for the 2-vehicle and\n2-RSU scenario, and the numerical results verify the theoretical analysis.", 
    "link": "http://arxiv.org/pdf/1302.7195v1", 
    "arxiv-id": "1302.7195v1"
},{
    "category": "cs.GT", 
    "author": "William Zame", 
    "title": "Designing Efficient Resource Sharing For Impatient Players Using Limited   Monitoring", 
    "publish": "2013-09-01T20:37:05Z", 
    "summary": "The problem of efficient sharing of a resource is nearly ubiquitous. Except\nfor pure public goods, each agent's use creates a negative externality; often\nthe negative externality is so strong that efficient sharing is impossible in\nthe short run. We show that, paradoxically, the impossibility of efficient\nsharing in the short run enhances the possibility of efficient sharing in the\nlong run, even if outcomes depend stochastically on actions, monitoring is\nlimited and users are not patient. We base our analysis on the familiar\nframework of repeated games with imperfect public monitoring, but we extend the\nframework to view the monitoring structure as chosen by a designer who balances\nthe benefits and costs of more accurate observations and reports. Our\nconclusions are much stronger than in the usual folk theorems: we do not\nrequire a rich signal structure or patient users and provide an explicit online\nconstruction of equilibrium strategies.", 
    "link": "http://arxiv.org/pdf/1309.0262v1", 
    "arxiv-id": "1309.0262v1"
},{
    "category": "cs.GT", 
    "author": "Yang Liu", 
    "title": "Towards a Unified Belief Structure in Games with indeterminate   probabilities", 
    "publish": "2013-09-06T17:00:31Z", 
    "summary": "This paper provides an analysis of different formal representations of\nbeliefs in epistemic game theory. The aim is to attempt a synthesis of\ndifferent structures of beliefs in the presence of indeterminate probabilities.\nSpecial attention is also paid to the decision-theoretic principle known as the\nthesis of no subjective probability for self-action. Conditions in cope with\nthis principle are given which underlie the interrelationships between\ndifferent models of beliefs, and it is shown that under these conditions\ndifferent doxastic structures can be coherently unified.", 
    "link": "http://arxiv.org/pdf/1309.1700v1", 
    "arxiv-id": "1309.1700v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Information Sharing in Networks of Strategic Agents", 
    "publish": "2013-09-07T03:57:42Z", 
    "summary": "To ensure that social networks (e.g. opinion consensus, cooperative\nestimation, distributed learning and adaptation etc.) proliferate and\nefficiently operate, the participating agents need to collaborate with each\nother by repeatedly sharing information. However, sharing information is often\ncostly for the agents while resulting in no direct immediate benefit for them.\nHence, lacking incentives to collaborate, strategic agents who aim to maximize\ntheir own individual utilities will withhold rather than share information,\nleading to inefficient operation or even collapse of networks. In this paper,\nwe develop a systematic framework for designing distributed rating protocols\naimed at incentivizing the strategic agents to collaborate with each other by\nsharing information. The proposed incentive protocols exploit the ongoing\nnature of the agents' interactions to assign ratings and through them,\ndetermine future rewards and punishments: agents that have behaved as directed\nenjoy high ratings -- and hence greater future access to the information of\nothers; agents that have not behaved as directed enjoy low ratings -- and hence\nless future access to the information of others. Unlike existing rating\nprotocols, the proposed protocol operates in a distributed manner, online, and\ntakes into consideration the underlying interconnectivity of agents as well as\ntheir heterogeneity. We prove that in many deployment scenarios the price of\nanarchy (PoA) obtained by adopting the proposed rating protocols is one. In\nsettings in which the PoA is larger than one, we show that the proposed rating\nprotocol still significantly outperforms existing incentive mechanisms such as\nTit-for-Tat. Importantly, the proposed rating protocols can also operate\nefficiently in deployment scenarios where the strategic agents interact over\ntime-varying network topologies where new agents join the network over time.", 
    "link": "http://arxiv.org/pdf/1309.1815v2", 
    "arxiv-id": "1309.1815v2"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Limits of Efficiency in Sequential Auctions", 
    "publish": "2013-09-10T14:39:58Z", 
    "summary": "We study the efficiency of sequential first-price item auctions at (subgame\nperfect) equilibrium. This auction format has recently attracted much\nattention, with previous work establishing positive results for unit-demand\nvaluations and negative results for submodular valuations. This leaves a large\ngap in our understanding between these valuation classes. In this work we\nresolve this gap on the negative side. In particular, we show that even in the\nvery restricted case in which each bidder has either an additive valuation or a\nunit-demand valuation, there exist instances in which the inefficiency at\nequilibrium grows linearly with the minimum of the number of items and the\nnumber of bidders. Moreover, these inefficient equilibria persist even under\niterated elimination of weakly dominated strategies. Our main result implies\nlinear inefficiency for many natural settings, including auctions with gross\nsubstitute valuations, capacitated valuations, budget-additive valuations, and\nadditive valuations with hard budget constraints on the payments. Another\nimplication is that the inefficiency in sequential auctions is driven by the\nmaximum number of items contained in any player's optimal set, and this is\ntight. For capacitated valuations, our results imply a lower bound that equals\nthe maximum capacity of any bidder, which is tight following the upper-bound\ntechnique established by Paes Leme et al. \\cite{PaesLeme2012}.", 
    "link": "http://arxiv.org/pdf/1309.2529v1", 
    "arxiv-id": "1309.2529v1"
},{
    "category": "cs.GT", 
    "author": "Arno Pauly", 
    "title": "A semi-potential for finite and infinite sequential games", 
    "publish": "2013-09-11T12:00:49Z", 
    "summary": "We consider a dynamical approach to sequential games. By restricting the\nconvertibility relation over strategy profiles, we obtain a semi-potential (in\nthe sense of Kukushkin), and we show that in finite games the corresponding\nrestriction of better-response dynamics will converge to a Nash equilibrium in\nquadratic time. Convergence happens on a per-player basis, and even in the\npresence of players with cyclic preferences, the players with acyclic\npreferences will stabilize. Thus, we obtain a candidate notion for rationality\nin the presence of irrational agents. Moreover, the restriction of\nconvertibility can be justified by a conservative updating of beliefs about the\nother players strategies.\n  For infinite sequential games we can retain convergence to a Nash equilibrium\n(in some sense), if the preferences are given by continuous payoff functions;\nor obtain a transfinite convergence if the outcome sets of the game are\n$\\Delta^0_2$-sets.", 
    "link": "http://arxiv.org/pdf/1309.2798v3", 
    "arxiv-id": "1309.2798v3"
},{
    "category": "cs.GT", 
    "author": "K. J. Ray Liu", 
    "title": "Indian Buffet Game with Negative Network Externality and Non-Bayesian   Social Learning", 
    "publish": "2013-09-11T19:27:47Z", 
    "summary": "How users in a dynamic system perform learning and make decision become more\nand more important in numerous research fields. Although there are some works\nin the social learning literatures regarding how to construct belief on an\nuncertain system state, few study has been conducted on incorporating social\nlearning with decision making. Moreover, users may have multiple concurrent\ndecisions on different objects/resources and their decisions usually negatively\ninfluence each other's utility, which makes the problem even more challenging.\nIn this paper, we propose an Indian Buffet Game to study how users in a dynamic\nsystem learn the uncertain system state and make multiple concurrent decisions\nby not only considering the current myopic utility, but also taking into\naccount the influence of subsequent users' decisions. We analyze the proposed\nIndian Buffet Game under two different scenarios: customers request multiple\ndishes without budget constraint and with budget constraint. For both cases, we\ndesign recursive best response algorithms to find the subgame perfect Nash\nequilibrium for customers and characterize special properties of the Nash\nequilibrium profile under homogeneous setting. Moreover, we introduce a\nnon-Bayesian social learning algorithm for customers to learn the system state,\nand theoretically prove its convergence. Finally, we conduct simulations to\nvalidate the effectiveness and efficiency of the proposed algorithms.", 
    "link": "http://arxiv.org/pdf/1309.2922v1", 
    "arxiv-id": "1309.2922v1"
},{
    "category": "cs.GT", 
    "author": "Piotr Beling", 
    "title": "A Complexity of double dummy bridge", 
    "publish": "2013-09-23T19:54:06Z", 
    "summary": "This paper presents an analysis of complexity of double dummy bridge. Values\nof both, a state-space (search-space) complexity and a game tree complexity\nhave been estimated.\n  -----\n  Oszacowanie z{\\l}o\\.zono\\'sci problemu rozgrywki w otwarte karty w bryd\\.zu\n  Artyku{\\l} zawiera analiz{\\ke} z{\\l}o\\.zono\\'sci problemu rozgrywki w otwarte\nkarty w bryd\\.zu, przy u\\.zyciu miar zaproponowanych przez Louisa Victora\nAllisa. Oszacowane s{\\ka} w nim z{\\l}o\\.zono\\'sci przestrzeni stan\\'ow i drzewa\nwspomnianej gry.", 
    "link": "http://arxiv.org/pdf/1309.5946v1", 
    "arxiv-id": "1309.5946v1"
},{
    "category": "cs.GT", 
    "author": "Maria Serna", 
    "title": "On the Stability of Generalized Second Price Auctions with Budgets", 
    "publish": "2013-09-25T12:05:12Z", 
    "summary": "The Generalized Second Price (GSP) auction used typically to model sponsored\nsearch auctions does not include the notion of budget constraints, which is\npresent in practice. Motivated by this, we introduce the different variants of\nGSP auctions that take budgets into account in natural ways. We examine their\nstability by focusing on the existence of Nash equilibria and envy-free\nassignments. We highlight the differences between these mechanisms and find\nthat only some of them exhibit both notions of stability. This shows the\nimportance of carefully picking the right mechanism to ensure stable outcomes\nin the presence of budgets", 
    "link": "http://arxiv.org/pdf/1309.6474v2", 
    "arxiv-id": "1309.6474v2"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Pay or Play", 
    "publish": "2013-09-26T12:47:02Z", 
    "summary": "We introduce the class of pay or play games, which captures scenarios in\nwhich each decision maker is faced with a choice between two actions: one with\na fixed payoff and an- other with a payoff dependent on others' selected\nactions. This is, arguably, the simplest setting that models selection among\ncertain and uncertain outcomes in a multi-agent system. We study the properties\nof equilibria in such games from both a game-theoretic perspective and a\ncomputational perspective. Our main positive result establishes the existence\nof a semi-strong equilibrium in every such game. We show that although simple,\npay of play games contain a large variety of well-studied environments, e.g.,\nvaccination games. We discuss the interesting implications of our results for\nthese environments.", 
    "link": "http://arxiv.org/pdf/1309.6854v1", 
    "arxiv-id": "1309.6854v1"
},{
    "category": "cs.GT", 
    "author": "Adrian Vetta", 
    "title": "Polylogarithmic Supports are required for Approximate Well-Supported   Nash Equilibria below 2/3", 
    "publish": "2013-09-27T15:01:32Z", 
    "summary": "In an epsilon-approximate Nash equilibrium, a player can gain at most epsilon\nin expectation by unilateral deviation. An epsilon well-supported approximate\nNash equilibrium has the stronger requirement that every pure strategy used\nwith positive probability must have payoff within epsilon of the best response\npayoff. Daskalakis, Mehta and Papadimitriou conjectured that every win-lose\nbimatrix game has a 2/3-well-supported Nash equilibrium that uses supports of\ncardinality at most three. Indeed, they showed that such an equilibrium will\nexist subject to the correctness of a graph-theoretic conjecture. Regardless of\nthe correctness of this conjecture, we show that the barrier of a 2/3 payoff\nguarantee cannot be broken with constant size supports; we construct win-lose\ngames that require supports of cardinality at least Omega((log n)^(1/3)) in any\nepsilon-well supported equilibrium with epsilon < 2/3. The key tool in showing\nthe validity of the construction is a proof of a bipartite digraph variant of\nthe well-known Caccetta-Haggkvist conjecture. A probabilistic argument shows\nthat there exist epsilon-well-supported equilibria with supports of cardinality\nO(log n/(epsilon^2)), for any epsilon> 0; thus, the polylogarithmic cardinality\nbound presented cannot be greatly improved. We also show that for any delta >\n0, there exist win-lose games for which no pair of strategies with support\nsizes at most two is a (1-delta)-well-supported Nash equilibrium. In contrast,\nevery bimatrix game with payoffs in [0,1] has a 1/2-approximate Nash\nequilibrium where the supports of the players have cardinality at most two.", 
    "link": "http://arxiv.org/pdf/1309.7258v2", 
    "arxiv-id": "1309.7258v2"
},{
    "category": "cs.GT", 
    "author": "Rafael C. S. Schouery", 
    "title": "The Unit-Demand Envy-Free Pricing Problem", 
    "publish": "2013-09-30T20:13:42Z", 
    "summary": "We consider the unit-demand envy-free pricing problem, which is a unit-demand\nauction where each bidder receives an item that maximizes his utility, and the\ngoal is to maximize the auctioneer's profit. This problem is NP-hard and\nunlikely to be in APX. We present four new MIP formulations for it and\nexperimentally compare them to a previous one due to Shioda, Tun\\c{c}el, and\nMyklebust. We describe three models to generate different random instances for\ngeneral unit-demand auctions, that we designed for the computational\nexperiments. Each model has a nice economic interpretation. Aiming\napproximation results, we consider the variant of the problem where the item\nprices are restricted to be chosen from a geometric series, and prove that an\noptimal solution for this variant has value that is a fraction (depending on\nthe series used) of the optimal value of the original problem. So this variant\nis also unlikely to be in APX.", 
    "link": "http://arxiv.org/pdf/1310.0038v1", 
    "arxiv-id": "1310.0038v1"
},{
    "category": "cs.GT", 
    "author": "Carmine Ventre", 
    "title": "Combinatorial Auctions without Money", 
    "publish": "2013-10-01T08:14:23Z", 
    "summary": "Algorithmic Mechanism Design attempts to marry computation and incentives,\nmainly by leveraging monetary transfers between designer and selfish agents\ninvolved. This is principally because in absence of money, very little can be\ndone to enforce truthfulness. However, in certain applications, money is\nunavailable, morally unacceptable or might simply be at odds with the objective\nof the mechanism. For example, in Combinatorial Auctions (CAs), the\nparadigmatic problem of the area, we aim at solutions of maximum social welfare\nbut still charge the society to ensure truthfulness. Additionally, truthfulness\nof CAs is poorly understood already in the case in which bidders happen to be\ninterested in only two different sets of goods.\n  We focus on the design of incentive-compatible CAs without money in the\ngeneral setting of $k$-minded bidders. We trade monetary transfers with the\nobservation that the mechanism can detect certain lies of the bidders: i.e., we\nstudy truthful CAs with verification and without money. We prove a\ncharacterization of truthful mechanisms, which makes an interesting parallel\nwith the well-understood case of CAs with money for single-minded bidders. We\nthen give a host of upper bounds on the approximation ratio obtained by either\ndeterministic or randomized truthful mechanisms when the sets and valuations\nare private knowledge of the bidders. (Most of these mechanisms run in\npolynomial time and return solutions with (nearly) best possible approximation\nguarantees.) We complement these positive results with a number of lower bounds\n(some of which are essentially tight) that hold in the easier case of public\nsets. We thus provide an almost complete picture of truthfully approximating\nCAs in this general setting with multi-dimensional bidders.", 
    "link": "http://arxiv.org/pdf/1310.0177v1", 
    "arxiv-id": "1310.0177v1"
},{
    "category": "cs.GT", 
    "author": "Bo Waggoner", 
    "title": "Designing Markets for Daily Deals", 
    "publish": "2013-10-02T02:25:32Z", 
    "summary": "Daily deals platforms such as Amazon Local, Google Offers, GroupOn, and\nLivingSocial have provided a new channel for merchants to directly market to\nconsumers. In order to maximize consumer acquisition and retention, these\nplatforms would like to offer deals that give good value to users. Currently,\nselecting such deals is done manually; however, the large number of submarkets\nand localities necessitates an automatic approach to selecting good deals and\ndetermining merchant payments.\n  We approach this challenge as a market design problem. We postulate that\nmerchants already have a good idea of the attractiveness of their deal to\nconsumers as well as the amount they are willing to pay to offer their deal.\nThe goal is to design an auction that maximizes a combination of the revenue of\nthe auctioneer (platform), welfare of the bidders (merchants), and the positive\nexternality on a third party (the consumer), despite the asymmetry of\ninformation about this consumer benefit. We design auctions that truthfully\nelicit this information from the merchants and maximize the social welfare\nobjective, and we characterize the consumer welfare functions for which this\nobjective is truthfully implementable. We generalize this characterization to a\nvery broad mechanism-design setting and give examples of other applications.", 
    "link": "http://arxiv.org/pdf/1310.0548v1", 
    "arxiv-id": "1310.0548v1"
},{
    "category": "cs.GT", 
    "author": "Gregory B. Sorkin", 
    "title": "VCG Auction Mechanism Cost Expectations and Variances", 
    "publish": "2013-10-07T13:26:45Z", 
    "summary": "We consider Vickrey-Clarke-Groves (VCG) auctions for a very general\ncombinatorial structure, in an average-case setting where item costs are\nindependent, identically distributed uniform random variables. We prove that\nthe expected VCG cost is at least double the expected nominal cost, and exactly\ndouble when the desired structure is a basis of a bridgeless matroid. In the\nmatroid case we further show that, conditioned upon the VCG cost, the\nexpectation of the nominal cost is exactly half the VCG cost, and we show\nseveral results on variances and covariances among the nominal cost, the VCG\ncost, and related quantities. As an application, we find the asymptotic\nvariance of the VCG cost of the minimum spanning tree in a complete graph with\nrandom edge costs.", 
    "link": "http://arxiv.org/pdf/1310.1777v1", 
    "arxiv-id": "1310.1777v1"
},{
    "category": "cs.GT", 
    "author": "Tamer Ba\u015far", 
    "title": "A Game-Theoretic Approach to Energy Trading in the Smart Grid", 
    "publish": "2013-10-07T15:14:41Z", 
    "summary": "Electric storage units constitute a key element in the emerging smart grid\nsystem. In this paper, the interactions and energy trading decisions of a\nnumber of geographically distributed storage units are studied using a novel\nframework based on game theory. In particular, a noncooperative game is\nformulated between storage units, such as PHEVs, or an array of batteries that\nare trading their stored energy. Here, each storage unit's owner can decide on\nthe maximum amount of energy to sell in a local market so as to maximize a\nutility that reflects the tradeoff between the revenues from energy trading and\nthe accompanying costs. Then in this energy exchange market between the storage\nunits and the smart grid elements, the price at which energy is traded is\ndetermined via an auction mechanism. The game is shown to admit at least one\nNash equilibrium and a novel proposed algorithm that is guaranteed to reach\nsuch an equilibrium point is proposed. Simulation results show that the\nproposed approach yields significant performance improvements, in terms of the\naverage utility per storage unit, reaching up to 130.2% compared to a\nconventional greedy approach.", 
    "link": "http://arxiv.org/pdf/1310.1814v1", 
    "arxiv-id": "1310.1814v1"
},{
    "category": "cs.GT", 
    "author": "Mihaela van der Schaar", 
    "title": "Socially-Optimal Design of Service Exchange Platforms with Imperfect   Monitoring", 
    "publish": "2013-10-09T01:47:09Z", 
    "summary": "In service exchange platforms, anonymous users exchange services with each\nother: clients request services and are matched to servers who provide\nservices. Because providing good-quality services requires effort, in any\nsingle interaction a server will have no incentive to exert effort and will\nshirk. We show that if current servers will later become clients and want\ngood-quality services, shirking can be eliminated by rating protocols, which\nmaintain ratings for each user, prescribe behavior in each client-server\ninteraction, and update ratings based on whether observed/reported behavior\nconforms with prescribed behavior. The rating protocols proposed are the first\nto achieve social optimum even when observation/reporting is imperfect (quality\nis incorrectly assessed/reported or reports are lost). The proposed protocols\nare remarkably simple, requiring only binary ratings and three possible\nprescribed behaviors. Key to the efficacy of the proposed protocols is that\nthey are nonstationary, and tailor prescriptions to both current and past\nrating distributions.", 
    "link": "http://arxiv.org/pdf/1310.2323v1", 
    "arxiv-id": "1310.2323v1"
},{
    "category": "cs.GT", 
    "author": "Michael J. Neely", 
    "title": "A Lyapunov Optimization Approach to Repeated Stochastic Games", 
    "publish": "2013-10-09T22:46:37Z", 
    "summary": "This paper considers a time-varying game with $N$ players. Every time slot,\nplayers observe their own random events and then take a control action. The\nevents and control actions affect the individual utilities earned by each\nplayer. The goal is to maximize a concave function of time average utilities\nsubject to equilibrium constraints. Specifically, participating players are\nprovided access to a common source of randomness from which they can optimally\ncorrelate their decisions. The equilibrium constraints incentivize\nparticipation by ensuring that players cannot earn more utility if they choose\nnot to participate. This form of equilibrium is similar to the notions of Nash\nequilibrium and correlated equilibrium, but is simpler to attain. A Lyapunov\nmethod is developed that solves the problem in an online \\emph{max-weight}\nfashion by selecting actions based on a set of time-varying weights. The\nalgorithm does not require knowledge of the event probabilities and has\npolynomial convergence time. A similar method can be used to compute a standard\ncorrelated equilibrium, albeit with increased complexity.", 
    "link": "http://arxiv.org/pdf/1310.2648v3", 
    "arxiv-id": "1310.2648v3"
},{
    "category": "cs.GT", 
    "author": "Mahsa Shirmohammadi", 
    "title": "Limit Synchronization in Markov Decision Processes", 
    "publish": "2013-10-10T16:30:45Z", 
    "summary": "Markov decision processes (MDP) are finite-state systems with both strategic\nand probabilistic choices. After fixing a strategy, an MDP produces a sequence\nof probability distributions over states. The sequence is eventually\nsynchronizing if the probability mass accumulates in a single state, possibly\nin the limit. Precisely, for 0 <= p <= 1 the sequence is p-synchronizing if a\nprobability distribution in the sequence assigns probability at least p to some\nstate, and we distinguish three synchronization modes: (i) sure winning if\nthere exists a strategy that produces a 1-synchronizing sequence; (ii)\nalmost-sure winning if there exists a strategy that produces a sequence that\nis, for all epsilon > 0, a (1-epsilon)-synchronizing sequence; (iii) limit-sure\nwinning if for all epsilon > 0, there exists a strategy that produces a\n(1-epsilon)-synchronizing sequence.\n  We consider the problem of deciding whether an MDP is sure, almost-sure,\nlimit-sure winning, and we establish the decidability and optimal complexity\nfor all modes, as well as the memory requirements for winning strategies. Our\nmain contributions are as follows: (a) for each winning modes we present\ncharacterizations that give a PSPACE complexity for the decision problems, and\nwe establish matching PSPACE lower bounds; (b) we show that for sure winning\nstrategies, exponential memory is sufficient and may be necessary, and that in\ngeneral infinite memory is necessary for almost-sure winning, and unbounded\nmemory is necessary for limit-sure winning; (c) along with our results, we\nestablish new complexity results for alternating finite automata over a\none-letter alphabet.", 
    "link": "http://arxiv.org/pdf/1310.2935v2", 
    "arxiv-id": "1310.2935v2"
},{
    "category": "cs.GT", 
    "author": "Martin Starnberger", 
    "title": "Valuation Compressions in VCG-Based Combinatorial Auctions", 
    "publish": "2013-10-11T14:58:51Z", 
    "summary": "The focus of classic mechanism design has been on truthful direct-revelation\nmechanisms. In the context of combinatorial auctions the truthful\ndirect-revelation mechanism that maximizes social welfare is the VCG mechanism.\nFor many valuation spaces computing the allocation and payments of the VCG\nmechanism, however, is a computationally hard problem. We thus study the\nperformance of the VCG mechanism when bidders are forced to choose bids from a\nsubspace of the valuation space for which the VCG outcome can be computed\nefficiently. We prove improved upper bounds on the welfare loss for\nrestrictions to additive bids and upper and lower bounds for restrictions to\nnon-additive bids. These bounds show that the welfare loss increases in\nexpressiveness. All our bounds apply to equilibrium concepts that can be\ncomputed in polynomial time as well as to learning outcomes.", 
    "link": "http://arxiv.org/pdf/1310.3153v1", 
    "arxiv-id": "1310.3153v1"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "User Satisfaction in Competitive Sponsored Search", 
    "publish": "2013-10-15T16:07:54Z", 
    "summary": "We present a model of competition between web search algorithms, and study\nthe impact of such competition on user welfare. In our model, search providers\ncompete for customers by strategically selecting which search results to\ndisplay in response to user queries. Customers, in turn, have private\npreferences over search results and will tend to use search engines that are\nmore likely to display pages satisfying their demands.\n  Our main question is whether competition between search engines increases the\noverall welfare of the users (i.e., the likelihood that a user finds a page of\ninterest). When search engines derive utility only from customers to whom they\nshow relevant results, we show that they differentiate their results, and every\nequilibrium of the resulting game achieves at least half of the welfare that\ncould be obtained by a social planner. This bound also applies whenever the\nlikelihood of selecting a given engine is a convex function of the probability\nthat a user's demand will be satisfied, which includes natural Markovian models\nof user behavior.\n  On the other hand, when search engines derive utility from all customers\n(independent of search result relevance) and the customer demand functions are\nnot convex, there are instances in which the (unique) equilibrium involves no\ndifferentiation between engines and a high degree of randomness in search\nresults. This can degrade social welfare by a factor of the square root of N\nrelative to the social optimum, where N is the number of webpages. These bad\nequilibria persist even when search engines can extract only small (but\nnon-zero) expected revenue from dissatisfied users, and much higher revenue\nfrom satisfied ones.", 
    "link": "http://arxiv.org/pdf/1310.4098v1", 
    "arxiv-id": "1310.4098v1"
},{
    "category": "cs.GT", 
    "author": "M. Sadegh Talebi", 
    "title": "Uncoupled Learning Rules for Seeking Equilibria in Repeated Plays: An   Overview", 
    "publish": "2013-10-21T18:04:24Z", 
    "summary": "In this note, we consider repeated play of a finite game using learning rules\nwhose period-by-period behavior probabilities or empirical distributions\nconverge to some notion of equilibria of the stage game. Our primary focus is\non uncoupled and completely uncoupled learning rules. While the former relies\non players being aware of only their own payoff functions and able to monitor\nthe action taken by the others, the latter assumes that players only know their\nown past realized payoffs. We highlight the border between possible and\nimpossible results using these rules. We also overview several uncoupled and\ncompletely uncoupled learning rules, most of which leverage notions of regret\nas the solution concept to seek payoff-improving action profiles.", 
    "link": "http://arxiv.org/pdf/1310.5660v1", 
    "arxiv-id": "1310.5660v1"
},{
    "category": "cs.GT", 
    "author": "Joerg Rothe", 
    "title": "The Complexity of Online Manipulation of Sequential Elections", 
    "publish": "2013-10-23T22:46:39Z", 
    "summary": "Most work on manipulation assumes that all preferences are known to the\nmanipulators. However, in many settings elections are open and sequential, and\nmanipulators may know the already cast votes but may not know the future votes.\nWe introduce a framework, in which manipulators can see the past votes but not\nthe future ones, to model online coalitional manipulation of sequential\nelections, and we show that in this setting manipulation can be extremely\ncomplex even for election systems with simple winner problems. Yet we also show\nthat for some of the most important election systems such manipulation is\nsimple in certain settings. This suggests that when using sequential voting,\none should pay great attention to the details of the setting in choosing one's\nvoting rule.\n  Among the highlights of our classifications are: We show that, depending on\nthe size of the manipulative coalition, the online manipulation problem can be\ncomplete for each level of the polynomial hierarchy or even for PSPACE. We\nobtain the most dramatic contrast to date between the nonunique-winner and\nunique-winner models: Online weighted manipulation for plurality is in P in the\nnonunique-winner model, yet is coNP-hard (constructive case) and NP-hard\n(destructive case) in the unique-winner model. And we obtain what to the best\nof our knowledge are the first PNP[1]-completeness and PNP-completeness results\nin the field of computational social choice, in particular proving such\ncompleteness for, respectively, the complexity of 3-candidate and 4-candidate\n(and unlimited-candidate) online weighted coalition manipulation of veto\nelections.", 
    "link": "http://arxiv.org/pdf/1310.6997v1", 
    "arxiv-id": "1310.6997v1"
},{
    "category": "cs.GT", 
    "author": "Chun-Ta Kung", 
    "title": "Optimizing scanning strategies: Selecting scanning bandwidth in   adversarial RF environments", 
    "publish": "2013-10-27T20:27:43Z", 
    "summary": "In this paper we investigate the problem of designing a spectrum scanning\nstrategy to detect an intelligent Invader who wants to utilize spectrum\nundetected for his/her unapproved purposes. To deal with this problem we apply\ngame-theoretical tools. We model the situation as a game between a Scanner and\nan Invader where the Invader faces a dilemma: the more bandwidth the Invader\nattempts to use leads to a larger payoff if he is not detected, but at the same\ntime also increases the probability of being detected and thus fined.\nSimilarly, the Scanner faces a dilemma: the wider the bandwidth scanned, the\nhigher the probability of detecting the Invader, but at the expense of\nincreasing the cost of building the scanning system. The equilibrium strategies\nare found explicitly and reveal interesting properties. In particular, we have\nfound a discontinuous dependence of the equilibrium strategies on the network\nparameters, fine and the type of the Invader's award. This discontinuity on\nfine means that the network provider has to take into account a human factor\nsince some threshold values of fine could be very sensible for the Invader,\nwhile in other situations simply increasing the fine has minimal deterrence\nimpact. Also we show how different reward types for the Invader (e.g. motivated\nby using different type of application, say, video-streaming or downloading\nfiles) can be incorporated into scanning strategy to increase its efficiency.", 
    "link": "http://arxiv.org/pdf/1310.7247v1", 
    "arxiv-id": "1310.7247v1"
},{
    "category": "cs.GT", 
    "author": "Rahul Savani", 
    "title": "Finding Approximate Nash Equilibria of Bimatrix Games via Payoff Queries", 
    "publish": "2013-10-28T13:57:40Z", 
    "summary": "We study the deterministic and randomized query complexity of finding\napproximate equilibria in bimatrix games. We show that the deterministic query\ncomplexity of finding an $\\epsilon$-Nash equilibrium when $\\epsilon <\n\\frac{1}{2}$ is $\\Omega(k^2)$, even in zero-one constant-sum games. In\ncombination with previous results \\cite{FGGS13}, this provides a complete\ncharacterization of the deterministic query complexity of approximate Nash\nequilibria. We also study randomized querying algorithms. We give a randomized\nalgorithm for finding a $(\\frac{3 - \\sqrt{5}}{2} + \\epsilon)$-Nash equilibrium\nusing $O(\\frac{k \\cdot \\log k}{\\epsilon^2})$ payoff queries, which shows that\nthe $\\frac{1}{2}$ barrier for deterministic algorithms can be broken by\nrandomization. For well-supported Nash equilibria (WSNE), we first give a\nrandomized algorithm for finding an $\\epsilon$-WSNE of a zero-sum bimatrix game\nusing $O(\\frac{k \\cdot \\log k}{\\epsilon^4})$ payoff queries, and we then use\nthis to obtain a randomized algorithm for finding a $(\\frac{2}{3} +\n\\epsilon)$-WSNE in a general bimatrix game using $O(\\frac{k \\cdot \\log\nk}{\\epsilon^4})$ payoff queries. Finally, we initiate the study of lower bounds\nagainst randomized algorithms in the context of bimatrix games, by showing that\nrandomized algorithms require $\\Omega(k^2)$ payoff queries in order to find a\n$\\frac{1}{6k}$-Nash equilibrium, even in zero-one constant-sum games. In\nparticular, this rules out query-efficient randomized algorithms for finding\nexact Nash equilibria.", 
    "link": "http://arxiv.org/pdf/1310.7419v2", 
    "arxiv-id": "1310.7419v2"
},{
    "category": "cs.GT", 
    "author": "Jiajun Sun", 
    "title": "How Much Should I Pay for Privacy Concerns in Truthful Online Crowd   Sensing?", 
    "publish": "2013-10-28T15:11:55Z", 
    "summary": "Crowd sensing is a new paradigm which leverages the pervasive smartphones to\nefficiently collect sensing data, enabling numerous novel applications. To\nachieve good service quality for a crowd sensing application, incentive\nmechanisms are indispensable to attract more user participation. Most of\nexisting mechanisms only apply for the offline scenario, where the system has\nfull information about the users' sensing profiles, i.e., a set of locations or\nmobility as well as the type of smartphones used, and their true costs. On the\ncontrary, we focus on a more real scenario where users with their own privacy\nconcerns arrive one by one online in a random order. We model the problem as a\nprivacy-respecting online auction in which users are willing to negotiate\naccess to certain private information and submit their sensing profiles\nsatisfying privacy concerns to the platform (the provider of crowd sensing\napplications) over time, and the platform aims to the total total value of the\nservices provided by selected users under a budget constraint. We then design\ntwo online mechanisms for a budgeted crowd sensing application, satisfying the\ncomputational efficiency, individual rationality, budget feasibility,\ntruthfulness, consumer sovereignty, constant competitiveness and privacy\nconcerns. Through extensive simulations, we evaluate the performance and\nvalidate the theoretical properties of our online mechanisms.", 
    "link": "http://arxiv.org/pdf/1310.7452v5", 
    "arxiv-id": "1310.7452v5"
},{
    "category": "cs.GT", 
    "author": "Ron Peretz", 
    "title": "Empirical Distribution of Equilibrium Play and Its Testing Application", 
    "publish": "2013-10-29T00:57:02Z", 
    "summary": "We show that in any $n$-player $m$-action normal-form game, we can obtain an\napproximate equilibrium by sampling any mixed-action equilibrium a small number\nof times. We study three types of equilibria: Nash, correlated and coarse\ncorrelated. For each one of them we obtain upper and lower bounds on the number\nof samples required for the empirical distribution over the sampled action\nprofiles to form an approximate equilibrium with probability close to one.\n  These bounds imply that using a small number of samples we can test whether\nor not players are playing according to an approximate equilibrium, even in\ngames where $n$ and $m$ are large. In addition, our results substantially\nimprove previously known upper bounds on the support size of approximate\nequilibria in games with many players. In particular, for all the three types\nof equilibria we show the existence of approximate equilibrium with support\nsize polylogarithmic in $n$ and $m$, whereas the previously best-known upper\nbounds were polynomial in $n$.", 
    "link": "http://arxiv.org/pdf/1310.7654v2", 
    "arxiv-id": "1310.7654v2"
},{
    "category": "cs.GT", 
    "author": "Branislav Bo\u0161ansk\u00fd", 
    "title": "Convergence of Monte Carlo Tree Search in Simultaneous Move Games", 
    "publish": "2013-10-31T17:41:51Z", 
    "summary": "We study Monte Carlo tree search (MCTS) in zero-sum extensive-form games with\nperfect information and simultaneous moves. We present a general template of\nMCTS algorithms for these games, which can be instantiated by various selection\nmethods. We formally prove that if a selection method is $\\epsilon$-Hannan\nconsistent in a matrix game and satisfies additional requirements on\nexploration, then the MCTS algorithm eventually converges to an approximate\nNash equilibrium (NE) of the extensive-form game. We empirically evaluate this\nclaim using regret matching and Exp3 as the selection methods on randomly\ngenerated games and empirically selected worst case games. We confirm the\nformal result and show that additional MCTS variants also converge to\napproximate NE on the evaluated games.", 
    "link": "http://arxiv.org/pdf/1310.8613v2", 
    "arxiv-id": "1310.8613v2"
},{
    "category": "cs.GT", 
    "author": "Max Klimm", 
    "title": "Optimal Impartial Selection", 
    "publish": "2013-10-31T18:38:29Z", 
    "summary": "We study the problem of selecting a member of a set of agents based on\nimpartial nominations by agents from that set. The problem was studied\npreviously by Alon et al. and Holzman and Moulin and has important applications\nin situations where representatives are selected from within a group or where\npublishing or funding decisions are made based on a process of peer review. Our\nmain result concerns a randomized mechanism that in expectation awards the\nprize to an agent with at least half the maximum number of nominations. Subject\nto impartiality, this is best possible.", 
    "link": "http://arxiv.org/pdf/1310.8631v1", 
    "arxiv-id": "1310.8631v1"
},{
    "category": "cs.GT", 
    "author": "Chaitanya Swamy", 
    "title": "Approximation Algorithms for Non-Single-minded Profit-Maximization   Problems with Limited Supply", 
    "publish": "2013-11-30T18:41:54Z", 
    "summary": "We consider {\\em profit-maximization} problems for {\\em combinatorial\nauctions} with {\\em non-single minded valuation functions} and {\\em limited\nsupply}.\n  We obtain fairly general results that relate the approximability of the\nprofit-maximization problem to that of the corresponding {\\em\nsocial-welfare-maximization} (SWM) problem, which is the problem of finding an\nallocation $(S_1,\\ldots,S_n)$ satisfying the capacity constraints that has\nmaximum total value $\\sum_j v_j(S_j)$. For {\\em subadditive valuations} (and\nhence {\\em submodular, XOS valuations}), we obtain a solution with profit\n$\\OPT_\\swm/O(\\log c_{\\max})$, where $\\OPT_\\swm$ is the optimum social welfare\nand $c_{\\max}$ is the maximum item-supply; thus, this yields an $O(\\log\nc_{\\max})$-approximation for the profit-maximization problem. Furthermore,\ngiven {\\em any} class of valuation functions, if the SWM problem for this\nvaluation class has an LP-relaxation (of a certain form) and an algorithm\n\"verifying\" an {\\em integrality gap} of $\\al$ for this LP, then we obtain a\nsolution with profit $\\OPT_\\swm/O(\\al\\log c_{\\max})$, thus obtaining an\n$O(\\al\\log c_{\\max})$-approximation.\n  For the special case, when the tree is a path, we also obtain an incomparable\n$O(\\log m)$-approximation (via a different approach) for subadditive\nvaluations, and arbitrary valuations with unlimited supply. Our approach for\nthe latter problem also gives an $\\frac{e}{e-1}$-approximation algorithm for\nthe multi-product pricing problem in the Max-Buy model, with limited supply,\nimproving on the previously known approximation factor of 2.", 
    "link": "http://arxiv.org/pdf/1312.0137v1", 
    "arxiv-id": "1312.0137v1"
},{
    "category": "cs.GT", 
    "author": "Lior Seeman", 
    "title": "The Truth Behind the Myth of the Folk Theorem", 
    "publish": "2013-12-04T03:52:24Z", 
    "summary": "We study the problem of computing an $\\epsilon$-Nash equilibrium in repeated\ngames. Earlier work by Borgs et al. [2010] suggests that this problem is\nintractable. We show that if we make a slight change to their model---modeling\nthe players as polynomial-time Turing machines that maintain state ---and make\nsome standard cryptographic hardness assumptions (the existence of public-key\nencryption), the problem can actually be solved in polynomial time. Our\nalgorithm works not only for games with a finite number of players, but also\nfor constant-degree graphical games.\n  As Nash equilibrium is a weak solution concept for extensive form games, we\nadditionally define and study an appropriate notion of a subgame-perfect\nequilibrium for computationally bounded players, and show how to efficiently\nfind such an equilibrium in repeated games (again, making standard\ncryptographic hardness assumptions).", 
    "link": "http://arxiv.org/pdf/1312.1017v3", 
    "arxiv-id": "1312.1017v3"
},{
    "category": "cs.GT", 
    "author": "Sampath Kannan", 
    "title": "Optimal Provision-After-Wait in Healthcare", 
    "publish": "2013-12-06T18:41:26Z", 
    "summary": "We investigate computational and mechanism design aspects of scarce resource\nallocation, where the primary rationing mechanism is through waiting times.\nSpecifically we consider allocating medical treatments to a population of\npatients. Each patient needs exactly one treatment, and can choose from $k$\nhospitals. Hospitals have different costs, which are fully paid by a third\nparty ---the \"payer\". The payer has a fixed budget $B$, and each hospital will\nhave its own waiting time. At equilibrium, each patient will choose his most\npreferred hospital given his intrinsic preferences and the waiting times. The\npayer thus computes the waiting times so that at equilibrium the budget\nconstraint is satisfied and the social welfare is maximized.\n  We first show that the optimization problem is NP-hard, yet if the budget can\nbe relaxed to $(1+\\epsilon)B$ for an arbitrarily small $\\epsilon$, then the\noptimum under budget $B$ can be approximated efficiently. Next, we study the\nendogenous emergence of waiting time from the dynamics between hospitals and\npatients, and show that there is no need for the payer to explicitly enforce\nthe optimal waiting times. Under certain conditions, all he need is to enforce\nthe amount of money he wants to pay to each hospital. The dynamics will always\nconverge to the desired waiting times in finite time.\n  We then go beyond equilibrium solutions and investigate the optimization\nproblem over a much larger class of mechanisms containing the equilibrium ones\nas special cases. With two hospitals, we show that under a natural assumption\non the patients' preference profiles, optimal welfare is in fact attained by\nthe randomized assignment mechanism, which allocates patients to hospitals at\nrandom subject to the budget constraint, but avoids waiting times.\n  Finally, we discuss potential policy implications of our results, as well as\nfollow-up directions and open problems.", 
    "link": "http://arxiv.org/pdf/1312.1955v1", 
    "arxiv-id": "1312.1955v1"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Social Status and Badge Design", 
    "publish": "2013-12-09T03:18:18Z", 
    "summary": "Many websites rely on user-generated content to provide value to consumers.\nThese websites typically incentivize participation by awarding users badges\nbased on their contributions. While these badges typically have no explicit\nvalue, they act as symbols of social status within a community. In this paper,\nwe consider the design of badge mechanisms for the objective of maximizing the\ntotal contributions made to a website. Users exert costly effort to make\ncontributions and, in return, are awarded with badges. A badge is only valued\nto the extent that it signals social status and thus badge valuations are\ndetermined endogenously by the number of users who earn each badge. The goal of\nthis paper is to study the design of optimal and approximately badge mechanisms\nunder these status valuations. We characterize badge mechanisms by whether they\nuse a coarse partitioning scheme, i.e. awarding the same badge to many users,\nor use a fine partitioning scheme, i.e. awarding a unique badge to most users.\nWe find that the optimal mechanism uses both fine partitioning and coarse\npartitioning. When status valuations exhibit a decreasing marginal value\nproperty, we prove that coarse partitioning is a necessary feature of any\napproximately optimal mechanism. Conversely, when status valuations exhibit an\nincreasing marginal value property, we prove that fine partitioning is\nnecessary for approximate optimality.", 
    "link": "http://arxiv.org/pdf/1312.2299v2", 
    "arxiv-id": "1312.2299v2"
},{
    "category": "cs.GT", 
    "author": "Bo Tang", 
    "title": "Tight Bounds for the Price of Anarchy of Simultaneous First Price   Auctions", 
    "publish": "2013-12-09T10:30:46Z", 
    "summary": "We study the Price of Anarchy of simultaneous first-price auctions for buyers\nwith submodular and subadditive valuations. The current best upper bounds for\nthe Bayesian Price of Anarchy of these auctions are e/(e-1) [Syrgkanis and\nTardos 2013] and 2 [Feldman et al. 2013], respectively. We provide matching\nlower bounds for both cases even for the case of full information and for mixed\nNash equilibria via an explicit construction.\n  We present an alternative proof of the upper bound of e/(e-1) for first-price\nauctions with fractionally subadditive valuations which reveals the worst-case\nprice distribution, that is used as a building block for the matching lower\nbound construction.\n  We generalize our results to a general class of item bidding auctions that we\ncall bid-dependent auctions (including first-price auctions and all-pay\nauctions) where the winner is always the highest bidder and each bidder's\npayment depends only on his own bid.\n  Finally, we apply our techniques to discriminatory price multi-unit auctions.\nWe complement the results of [de Keijzer et al. 2013] for the case of\nsubadditive valuations, by providing a matching lower bound of 2. For the case\nof submodular valuations, we provide a lower bound of 1.109. For the same class\nof valuations, we were able to reproduce the upper bound of e/(e-1) using our\nnon-smooth approach.", 
    "link": "http://arxiv.org/pdf/1312.2371v3", 
    "arxiv-id": "1312.2371v3"
},{
    "category": "cs.GT", 
    "author": "James B. Orlin", 
    "title": "On the power of randomization in network interdiction", 
    "publish": "2013-12-12T13:38:00Z", 
    "summary": "Network interdiction can be viewed as a game between two players, an\n\"interdictor\" and a \"flow player\". The flow player wishes to send as much\nmaterial as possible through a network, while the interdictor attempts to\nminimize the amount of transported material by removing a certain number of\narcs, say $\\Gamma$ arcs. We introduce the randomized network interdiction\nproblem that allows the interdictor to use randomness to select arcs to be\nremoved. We model the problem in two different ways: arc-based and path-based\nformulations, depending on whether flows are defined on arcs or paths,\nrespectively. We present insights into the modeling power, complexity, and\napproximability of both formulations. In particular, we prove that\n$Z_{\\text{NI}}/Z_{\\text{RNI}}\\leq \\Gamma+1$,\n$Z_{\\text{NI}}/Z_{\\text{RNI}}^{\\text{Path}}\\leq \\Gamma+1$,\n$Z_{\\text{RNI}}/Z_{\\text{RNI}}^{\\text{Path}}\\leq \\Gamma$, where\n$Z_{\\text{NI}}$, $Z_{\\text{RNI}}$, and $Z_{\\text{RNI}}^{\\text{Path}}$ are the\noptimal values of the network interdiction problem and its randomized versions\nin arc-based and path-based formulations, respectively. We also show that these\nbounds are tight. We show that it is NP-hard to compute the values\n$Z_{\\text{RNI}}$ and $Z_{\\text{RNI}}^{\\text{Path}}$ for a general $\\Gamma$, but\nthey are computable in polynomial time when $\\Gamma=1$. Further, we provide a\n$(\\Gamma+1)$-approximation for $Z_{\\text{NI}}$, a $\\Gamma$-approximation for\n$Z_{\\text{RNI}}$, and a $\\big(1+\\lfloor \\Gamma/2\\rfloor \\cdot \\lceil\n\\Gamma/2\\rceil/(\\Gamma+1)\\big)$-approximation for\n$Z_{\\text{RNI}}^{\\text{Path}}$.", 
    "link": "http://arxiv.org/pdf/1312.3478v1", 
    "arxiv-id": "1312.3478v1"
},{
    "category": "cs.GT", 
    "author": "Luke Ong", 
    "title": "EGuaranteeNash for Boolean Games is NEXP-Hard", 
    "publish": "2013-12-15T06:36:40Z", 
    "summary": "Boolean games are an expressive and natural formalism through which to\ninvestigate problems of strategic interaction in multiagent systems. Although\nthey have been widely studied, almost all previous work on Nash equilibria in\nBoolean games has focused on the restricted setting of pure strategies. This is\na shortcoming as finite games are guaranteed to have at least one equilibrium\nin mixed strategies, but many simple games fail to have pure strategy\nequilibria at all. We address this by showing that a natural decision problem\nabout mixed equilibria: determining whether a Boolean game has a mixed strategy\nequilibrium that guarantees every player a given payoff, is NEXP-hard.\nAccordingly, the $\\epsilon$ variety of the problem is NEXP-complete. The proof\ncan be adapted to show coNEXP-hardness of a similar question: whether all Nash\nequilibria of a Boolean game guarantee every player at least the given payoff.", 
    "link": "http://arxiv.org/pdf/1312.4114v1", 
    "arxiv-id": "1312.4114v1"
},{
    "category": "cs.GT", 
    "author": "Lior Seeman", 
    "title": "I'd Rather Stay Stupid: The Advantage of Having Low Utility", 
    "publish": "2013-12-15T20:21:52Z", 
    "summary": "Motivated by cost of computation in game theory, we explore how changing the\nutilities of players (changing their complexity costs) affects the outcome of a\ngame. We show that even if we improve a player's utility in every action\nprofile, his payoff in equilibrium might be lower than in the equilibrium\nbefore the change. We provide some conditions on games that are sufficient to\nensure this does not occur. We then show how this counter-intuitive phenomenon\ncan explain real life phenomena such as free riding, and why this might cause\npeople to give signals indicating that they are not as good as they really are.", 
    "link": "http://arxiv.org/pdf/1312.4187v1", 
    "arxiv-id": "1312.4187v1"
},{
    "category": "cs.GT", 
    "author": "Sascha Kurz", 
    "title": "Measuring voting power in convex policy spaces", 
    "publish": "2013-12-20T13:37:15Z", 
    "summary": "Classical power index analysis considers the individual's ability to\ninfluence the aggregated group decision by changing its own vote, where all\ndecisions and votes are assumed to be binary. In many practical applications we\nhave more options than either \"yes\" or \"no\". Here we generalize three important\npower indices to continuous convex policy spaces. This allows the analysis of a\ncollection of economic problems like e.g. tax rates or spending that otherwise\nwould not be covered in binary models.", 
    "link": "http://arxiv.org/pdf/1312.5936v1", 
    "arxiv-id": "1312.5936v1"
},{
    "category": "cs.GT", 
    "author": "Aviad Rubinstein", 
    "title": "The Complexity of Fairness through Equilibrium", 
    "publish": "2013-12-21T13:09:10Z", 
    "summary": "Competitive equilibrium with equal incomes (CEEI) is a well known fair\nallocation mechanism; however, for indivisible resources a CEEI may not exist.\nIt was shown in [Budish '11] that in the case of indivisible resources there is\nalways an allocation, called A-CEEI, that is approximately fair, approximately\ntruthful, and approximately efficient, for some favorable approximation\nparameters. This approximation is used in practice to assign students to\nclasses. In this paper we show that finding the A-CEEI allocation guaranteed to\nexist by Budish's theorem is PPAD-complete. We further show that finding an\napproximate equilibrium with better approximation guarantees is even harder:\nNP-complete.", 
    "link": "http://arxiv.org/pdf/1312.6249v3", 
    "arxiv-id": "1312.6249v3"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "A note on the undercut procedure", 
    "publish": "2013-12-23T00:09:06Z", 
    "summary": "The undercut procedure was presented by Brams et al. [2] as a procedure for\nidentifying an envy-free allocation when agents have preferences over sets of\nobjects. They assumed that agents have strict preferences over objects and\ntheir preferences are extended over to sets of objects via the responsive set\nextension. We point out some shortcomings of the undercut procedure. We then\nsimplify the undercut procedure of Brams et al. [2] and show that it works\nunder a more general condition where agents may express indifference between\nobjects and they may not necessarily have responsive preferences over sets of\nobjects. Finally, we show that the procedure works even if agents have unequal\nclaims.", 
    "link": "http://arxiv.org/pdf/1312.6444v2", 
    "arxiv-id": "1312.6444v2"
},{
    "category": "cs.GT", 
    "author": "Toshimitsu Ushio", 
    "title": "Game Theoretic Approach to the Stabilization of Heterogeneous Multiagent   Systems Using Subsidy", 
    "publish": "2013-12-25T03:51:04Z", 
    "summary": "We consider a multiagent system consisting of selfish and heterogeneous\nagents. Its behavior is modeled by multipopulation replicator dynamics, where\npayoff functions of populations are different from each other. In general,\nthere exist several equilibrium points in the replicator dynamics. In order to\nstabilize a desirable equilibrium point, we introduce a controller called a\ngovernment which controls the behaviors of agents by offering them subsidies.\nIn previous work, it is assumed that the government determines the subsidies\nbased on the populations the agents belong to. In general, however, the\ngovernment cannot identify the members of each population. In this paper, we\nassume that the government observes the action of each agent and determines the\nsubsidies based on the observed action profile. Then, we model the controlled\nbehaviors of the agents using replicator dynamics with feedback. We derive a\nstabilization condition of the target equilibrium point in the replicator\ndynamics.", 
    "link": "http://arxiv.org/pdf/1312.6916v1", 
    "arxiv-id": "1312.6916v1"
},{
    "category": "cs.GT", 
    "author": "Juergen Jost", 
    "title": "Value of information in noncooperative games", 
    "publish": "2013-12-27T21:39:30Z", 
    "summary": "In some games, additional information hurts a player, e.g., in games with\nfirst-mover advantage, the second-mover is hurt by seeing the first-mover's\nmove. What properties of a game determine whether it has such negative \"value\nof information\" for a particular player? Can a game have negative value of\ninformation for all players? To answer such questions, we generalize the\ndefinition of marginal utility of a good to define the marginal utility of a\nparameter vector specifying a game. So rather than analyze the global structure\nof the relationship between a game's parameter vector and player behavior, as\nin previous work, we focus on the local structure of that relationship. This\nallows us to prove that generically, every game can have negative marginal\nvalue of information, unless one imposes a priori constraints on allowed\nchanges to the game's parameter vector. We demonstrate these and related\nresults numerically, and discuss their implications.", 
    "link": "http://arxiv.org/pdf/1401.0001v3", 
    "arxiv-id": "1401.0001v3"
},{
    "category": "cs.GT", 
    "author": "Adam Wierman", 
    "title": "The Empirical Implications of Privacy-Aware Choice", 
    "publish": "2014-01-01T21:17:22Z", 
    "summary": "This paper initiates the study of the testable implications of choice data in\nsettings where agents have privacy preferences. We adapt the standard\nconceptualization of consumer choice theory to a situation where the consumer\nis aware of, and has preferences over, the information revealed by her choices.\nThe main message of the paper is that little can be inferred about consumers'\npreferences once we introduce the possibility that the consumer has concerns\nabout privacy. This holds even when consumers' privacy preferences are assumed\nto be monotonic and separable. This motivates the consideration of stronger\nassumptions and, to that end, we introduce an additive model for privacy\npreferences that does have testable implications.", 
    "link": "http://arxiv.org/pdf/1401.0336v1", 
    "arxiv-id": "1401.0336v1"
},{
    "category": "cs.GT", 
    "author": "Pinyan Lu", 
    "title": "Optimal Competitive Auctions", 
    "publish": "2014-01-05T09:59:07Z", 
    "summary": "We study the design of truthful auctions for selling identical items in\nunlimited supply (e.g., digital goods) to n unit demand buyers. This classic\nproblem stands out from profit-maximizing auction design literature as it\nrequires no probabilistic assumptions on buyers' valuations and employs the\nframework of competitive analysis. Our objective is to optimize the worst-case\nperformance of an auction, measured by the ratio between a given benchmark and\nrevenue generated by the auction.\n  We establish a sufficient and necessary condition that characterizes\ncompetitive ratios for all monotone benchmarks. The characterization identifies\nthe worst-case distribution of instances and reveals intrinsic relations\nbetween competitive ratios and benchmarks in the competitive analysis. With the\ncharacterization at hand, we show optimal competitive auctions for two natural\nbenchmarks.\n  The most well-studied benchmark $\\mathcal{F}^{(2)}(\\cdot)$ measures the\nenvy-free optimal revenue where at least two buyers win. Goldberg et al. [13]\nshowed a sequence of lower bounds on the competitive ratio for each number of\nbuyers n. They conjectured that all these bounds are tight. We show that\noptimal competitive auctions match these bounds. Thus, we confirm the\nconjecture and settle a central open problem in the design of digital goods\nauctions. As one more application we examine another economically meaningful\nbenchmark, which measures the optimal revenue across all limited-supply Vickrey\nauctions. We identify the optimal competitive ratios to be\n$(\\frac{n}{n-1})^{n-1}-1$ for each number of buyers n, that is $e-1$ as $n$\napproaches infinity.", 
    "link": "http://arxiv.org/pdf/1401.0880v1", 
    "arxiv-id": "1401.0880v1"
},{
    "category": "cs.GT", 
    "author": "Eitan Altman", 
    "title": "Multilevel Pricing Schemes in a Deregulated Wireless Network Market", 
    "publish": "2014-01-07T19:08:01Z", 
    "summary": "Typically the cost of a product, a good or a service has many components.\nThose components come from different complex steps in the supply chain of the\nproduct from sourcing to distribution. This economic point of view also takes\nplace in the determination of goods and services in wireless networks. Indeed,\nbefore transmitting customer data, a network operator has to lease some\nfrequency range from a spectrum owner and also has to establish agreements with\nelectricity suppliers. The goal of this paper is to compare two pricing\nschemes, namely a power-based and a flat rate, and give a possible explanation\nwhy flat rate pricing schemes are more common than power based pricing ones in\na deregulated wireless market. We suggest a hierarchical game-theoretical model\nof a three level supply chain: the end users, the service provider and the\nspectrum owner. The end users intend to transmit data on a wireless network.\nThe amount of traffic sent by the end users depends on the available frequency\nbandwidth as well as the price they have to pay for their transmission. A\nnatural question arises for the service provider: how to design an efficient\npricing scheme in order to maximize his profit. Moreover he has to take into\naccount the lease charge he has to pay to the spectrum owner and how many\nfrequency bandwidth to rent. The spectrum owner itself also looks for\nmaximizing its profit and has to determine the lease price to the service\nprovider. The equilibrium at each level of our supply chain model are\nestablished and several properties are investigated. In particular, in the case\nof a power-based pricing scheme, the service provider and the spectrum owner\ntend to share the gross provider profit. Whereas, considering the flat rate\npricing scheme, if the end users are going to exploit the network intensively,\nthen the tariffs of the suppliers (spectrum owner and service provider)\nexplode.", 
    "link": "http://arxiv.org/pdf/1401.1479v1", 
    "arxiv-id": "1401.1479v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Price Competition in Online Combinatorial Markets", 
    "publish": "2014-01-08T01:59:03Z", 
    "summary": "We consider a single buyer with a combinatorial preference that would like to\npurchase related products and services from different vendors, where each\nvendor supplies exactly one product. We study the general case where subsets of\nproducts can be substitutes as well as complementary and analyze the game that\nis induced on the vendors, where a vendor's strategy is the price that he asks\nfor his product. This model generalizes both Bertrand competition (where\nvendors are perfect substitutes) and Nash bargaining (where they are perfect\ncomplements), and captures a wide variety of scenarios that can appear in\ncomplex crowd sourcing or in automatic pricing of related products.\n  We study the equilibria of such games and show that a pure efficient\nequilibrium always exists. In the case of submodular buyer preferences we fully\ncharacterize the set of pure Nash equilibria, essentially showing uniqueness.\nFor the even more restricted \"substitutes\" buyer preferences we also prove\nuniqueness over {\\em mixed} equilibria. Finally we begin the exploration of\nnatural generalizations of our setting such as when services have costs, when\nthere are multiple buyers or uncertainty about the the buyer's valuation, and\nwhen a single vendor supplies multiple products.", 
    "link": "http://arxiv.org/pdf/1401.1559v1", 
    "arxiv-id": "1401.1559v1"
},{
    "category": "cs.GT", 
    "author": "Xuegong Deng", 
    "title": "The security deposit for finitely repeated Prisoner's dilemma", 
    "publish": "2014-01-08T03:50:39Z", 
    "summary": "Under the assumption of complete rationality, Nash equilibrium is the only\nreasonable strategy (set) of the finitely repeated prisoner's dilemma. In fact,\nsome strategies only slightly deviate from the so-called rationality, and the\ncorresponding payoff may much better than that of Nash equilibrium. This\narticle points out, even under the rational assumptions, the players have\nreason to seek a mutually beneficial agreement (Pareto dominated compare to\nNash equilibrium) and a weak and optional constraints, so that the agreement\ncan be successfully implemented. If the constraint does not harm the interests\nof the participants, or the adversely affects of the constraint are negligible,\nthen the finitely repeated prisoner's dilemma becomes a bargaining problem\nissues on the strategy sequences and the problem to seek the constraints. The\nquantification of the constraints, the so-called security deposit in this\npaper, is nearly a concept of distance from an agreement (a strategy set) to\nthe complete rationality.", 
    "link": "http://arxiv.org/pdf/1401.1573v1", 
    "arxiv-id": "1401.1573v1"
},{
    "category": "cs.GT", 
    "author": "Achilleas Anastasopoulos", 
    "title": "Generalized Proportional Allocation Mechanism Design for Unicast Service   on the Internet", 
    "publish": "2014-01-08T17:39:21Z", 
    "summary": "In this report we construct two mechanisms that fully implement social\nwelfare maximising allocation in Nash equilibria for the case of a single\ninfinitely divisible good subject to multiple inequality constraints. The first\nmechanism achieves weak budget balance, while the second is an extension of the\nfirst, and achieves strong budget balance. One important application of this\nmechanism is unicast service on the Internet where a network operator wishes to\nallocate rates among strategic users in such a way that maximise overall user\nsatisfaction while respecting capacity constraints on every link in the\nnetwork. The emphasis of this work is on full implementation, which means that\nall Nash equilibria of the induced game result in the optimal allocations of\nthe centralized allocation problem.", 
    "link": "http://arxiv.org/pdf/1401.1760v3", 
    "arxiv-id": "1401.1760v3"
},{
    "category": "cs.GT", 
    "author": "Brendan Lucier", 
    "title": "Clearing Markets via Bundles", 
    "publish": "2014-01-13T03:53:04Z", 
    "summary": "We study algorithms for combinatorial market design problems, where a set of\nheterogeneous and indivisible objects are priced and sold to potential buyers\nsubject to equilibrium constraints. Extending the CWE notion introduced by\nFeldman et al. [STOC 2013], we introduce the concept of a Market-Clearing\nCombinatorial Walrasian Equilibium (MC-CWE) as a natural relaxation of the\nclassical Walrasian equilibrium (WE) solution concept. The only difference\nbetween a MC-CWE and a WE is the ability for the seller to bundle the items\nprior to sale. This innocuous and natural bundling operation imposes a plethora\nof algorithmic and economic challenges and opportunities. Unlike WE, which is\nguaranteed to exist only for (gross) substitutes valuations, a MC-CWE always\nexists. The main algorithmic challenge, therefore, is to design computationally\nefficient mechanisms that generate MC-CWE outcomes that approximately maximize\nsocial welfare. For a variety of valuation classes encompassing substitutes and\ncomplements (including super-additive, single-minded and budget-additive\nvaluations), we design polynomial-time MC-CWE mechanisms that provide tight\nwelfare approximation results.", 
    "link": "http://arxiv.org/pdf/1401.2702v2", 
    "arxiv-id": "1401.2702v2"
},{
    "category": "cs.GT", 
    "author": "Nicholas Robert Jennings", 
    "title": "Optimal Strategies for Simultaneous Vickrey Auctions with Perfect   Substitutes", 
    "publish": "2014-01-15T04:50:20Z", 
    "summary": "We derive optimal strategies for a bidding agent that participates in\nmultiple, simultaneous second-price auctions with perfect substitutes. We prove\nthat, if everyone else bids locally in a single auction, the global bidder\nshould always place non-zero bids in all available auctions, provided there are\nno budget constraints. With a budget, however, the optimal strategy is to bid\nlocally if this budget is equal or less than the valuation. Furthermore, for a\nwide range of valuation distributions, we prove that the problem of finding the\noptimal bids reduces to two dimensions if all auctions are identical. Finally,\nwe address markets with both sequential and simultaneous auctions,\nnon-identical auctions, and the allocative efficiency of the market.", 
    "link": "http://arxiv.org/pdf/1401.3433v1", 
    "arxiv-id": "1401.3433v1"
},{
    "category": "cs.GT", 
    "author": "Vincent Conitzer", 
    "title": "Eliciting Single-Peaked Preferences Using Comparison Queries", 
    "publish": "2014-01-15T05:10:11Z", 
    "summary": "Voting is a general method for aggregating the preferences of multiple\nagents. Each agent ranks all the possible alternatives, and based on this, an\naggregate ranking of the alternatives (or at least a winning alternative) is\nproduced. However, when there are many alternatives, it is impractical to\nsimply ask agents to report their complete preferences. Rather, the agents\npreferences, or at least the relevant parts thereof, need to be elicited. This\nis done by asking the agents a (hopefully small) number of simple queries about\ntheir preferences, such as comparison queries, which ask an agent to compare\ntwo of the alternatives. Prior work on preference elicitation in voting has\nfocused on the case of unrestricted preferences. It has been shown that in this\nsetting, it is sometimes necessary to ask each agent (almost) as many queries\nas would be required to determine an arbitrary ranking of the alternatives. In\ncontrast, in this paper, we focus on single-peaked preferences. We show that\nsuch preferences can be elicited using only a linear number of comparison\nqueries, if either the order with respect to which preferences are\nsingle-peaked is known, or at least one other agents complete preferences are\nknown. We show that using a sublinear number of queries does not suffice. We\nalso consider the case of cardinally single-peaked preferences. For this case,\nwe show that if the alternatives cardinal positions are known, then an agents\npreferences can be elicited using only a logarithmic number of queries;\nhowever, we also show that if the cardinal positions are not known, then a\nsublinear number of queries does not suffice. We present experimental results\nfor all elicitation algorithms. We also consider the problem of only eliciting\nenough information to determine the aggregate ranking, and show that even for\nthis more modest objective, a sublinear number of queries per agent does not\nsuffice for known ordinal or unknown cardinal positions. Finally, we discuss\nwhether and how these techniques can be applied when preferences are almost\nsingle-peaked.", 
    "link": "http://arxiv.org/pdf/1401.3449v1", 
    "arxiv-id": "1401.3449v1"
},{
    "category": "cs.GT", 
    "author": "Boi Faltings", 
    "title": "Mechanisms for Making Crowds Truthful", 
    "publish": "2014-01-15T05:11:17Z", 
    "summary": "We consider schemes for obtaining truthful reports on a common but hidden\nsignal from large groups of rational, self-interested agents. One example are\nonline feedback mechanisms, where users provide observations about the quality\nof a product or service so that other users can have an accurate idea of what\nquality they can expect. However, (i) providing such feedback is costly, and\n(ii) there are many motivations for providing incorrect feedback.\n  Both problems can be addressed by reward schemes which (i) cover the cost of\nobtaining and reporting feedback, and (ii) maximize the expected reward of a\nrational agent who reports truthfully. We address the design of such\nincentive-compatible rewards for feedback generated in environments with pure\nadverse selection. Here, the correlation between the true knowledge of an agent\nand her beliefs regarding the likelihoods of reports of other agents can be\nexploited to make honest reporting a Nash equilibrium.\n  In this paper we extend existing methods for designing incentive-compatible\nrewards by also considering collusion. We analyze different scenarios, where,\nfor example, some or all of the agents collude. For each scenario we\ninvestigate whether a collusion-resistant, incentive-compatible reward scheme\nexists, and use automated mechanism design to specify an algorithm for deriving\nan efficient reward mechanism.", 
    "link": "http://arxiv.org/pdf/1401.3451v1", 
    "arxiv-id": "1401.3451v1"
},{
    "category": "cs.GT", 
    "author": "Nicholas Robert Jennings", 
    "title": "Trust-Based Mechanisms for Robust and Efficient Task Allocation in the   Presence of Execution Uncertainty", 
    "publish": "2014-01-15T05:29:44Z", 
    "summary": "Vickrey-Clarke-Groves (VCG) mechanisms are often used to allocate tasks to\nselfish and rational agents. VCG mechanisms are incentive compatible, direct\nmechanisms that are efficient (i.e., maximise social utility) and individually\nrational (i.e., agents prefer to join rather than opt out). However, an\nimportant assumption of these mechanisms is that the agents will \"always\"\nsuccessfully complete their allocated tasks. Clearly, this assumption is\nunrealistic in many real-world applications, where agents can, and often do,\nfail in their endeavours. Moreover, whether an agent is deemed to have failed\nmay be perceived differently by different agents. Such subjective perceptions\nabout an agents probability of succeeding at a given task are often captured\nand reasoned about using the notion of \"trust\". Given this background, in this\npaper we investigate the design of novel mechanisms that take into account the\ntrust between agents when allocating tasks.\n  Specifically, we develop a new class of mechanisms, called \"trust-based\nmechanisms\", that can take into account multiple subjective measures of the\nprobability of an agent succeeding at a given task and produce allocations that\nmaximise social utility, whilst ensuring that no agent obtains a negative\nutility. We then show that such mechanisms pose a challenging new combinatorial\noptimisation problem (that is NP-complete), devise a novel representation for\nsolving the problem, and develop an effective integer programming solution\n(that can solve instances with about 2x10^5 possible allocations in 40\nseconds).", 
    "link": "http://arxiv.org/pdf/1401.3473v1", 
    "arxiv-id": "1401.3473v1"
},{
    "category": "cs.GT", 
    "author": "Tami Tamir", 
    "title": "Approximate Strong Equilibrium in Job Scheduling Games", 
    "publish": "2014-01-15T05:42:16Z", 
    "summary": "A Nash Equilibrium (NE) is a strategy profile resilient to unilateral\ndeviations, and is predominantly used in the analysis of multiagent systems. A\ndownside of NE is that it is not necessarily stable against deviations by\ncoalitions. Yet, as we show in this paper, in some cases, NE does exhibit\nstability against coalitional deviations, in that the benefits from a joint\ndeviation are bounded. In this sense, NE approximates strong equilibrium.\n  Coalition formation is a key issue in multiagent systems. We provide a\nframework for quantifying the stability and the performance of various\nassignment policies and solution concepts in the face of coalitional\ndeviations. Within this framework we evaluate a given configuration according\nto three measures: (i) IR_min: the maximal number alpha, such that there exists\na coalition in which the minimal improvement ratio among the coalition members\nis alpha, (ii) IR_max: the maximal number alpha, such that there exists a\ncoalition in which the maximal improvement ratio among the coalition members is\nalpha, and (iii) DR_max: the maximal possible damage ratio of an agent outside\nthe coalition.\n  We analyze these measures in job scheduling games on identical machines. In\nparticular, we provide upper and lower bounds for the above three measures for\nboth NE and the well-known assignment rule Longest Processing Time (LPT).\n  Our results indicate that LPT performs better than a general NE. However, LPT\nis not the best possible approximation. In particular, we present a polynomial\ntime approximation scheme (PTAS) for the makespan minimization problem which\nprovides a schedule with IR_min of 1+epsilon for any given epsilon. With\nrespect to computational complexity, we show that given an NE on m >= 3\nidentical machines or m >= 2 unrelated machines, it is NP-hard to determine\nwhether a given coalition can deviate such that every member decreases its\ncost.", 
    "link": "http://arxiv.org/pdf/1401.3494v1", 
    "arxiv-id": "1401.3494v1"
},{
    "category": "cs.GT", 
    "author": "Sven Seuken", 
    "title": "Partial Strategyproofness: Relaxing Strategyproofness for the Random   Assignment Problem", 
    "publish": "2014-01-15T17:08:44Z", 
    "summary": "We present partial strategyproofness, a new, relaxed notion of\nstrategyproofness for studying the incentive properties of non-strategyproof\nassignment mechanisms that involve some form of randomness. Informally, a\nmechanism is partially strategyproof if it makes truthful reporting a dominant\nstrategy for those agents whose preference intensities differ sufficiently\nbetween any two objects. A single numerical parameter, the degree of\nstrategyproofness, controls the extent to which these intensities must differ.\nWe demonstrate that partial strategyproofness is a natural and useful\nrelaxation of strategyproofness: It is axiomatically motivated, it allows a\nmeaningful parametric and algorithmic comparison of mechanisms by their\nincentive properties, and it provides new insights across a wide range of\npopular mechanisms.", 
    "link": "http://arxiv.org/pdf/1401.3675v4", 
    "arxiv-id": "1401.3675v4"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Mechanisms for Multi-Unit Auctions", 
    "publish": "2014-01-16T04:50:35Z", 
    "summary": "We present an incentive-compatible polynomial-time approximation scheme for\nmulti-unit auctions with general k-minded player valuations. The mechanism\nfully optimizes over an appropriately chosen sub-range of possible allocations\nand then uses VCG payments over this sub-range. We show that obtaining a fully\npolynomial-time incentive-compatible approximation scheme, at least using VCG\npayments, is NP-hard. For the case of valuations given by black boxes, we give\na polynomial-time incentive-compatible 2-approximation mechanism and show that\nno better is possible, at least using VCG payments.", 
    "link": "http://arxiv.org/pdf/1401.3834v1", 
    "arxiv-id": "1401.3834v1"
},{
    "category": "cs.GT", 
    "author": "Noam Nisan", 
    "title": "Mixed Strategies in Combinatorial Agency", 
    "publish": "2014-01-16T04:51:30Z", 
    "summary": "In many multiagent domains a set of agents exert effort towards a joint\noutcome, yet the individual effort levels cannot be easily observed. A typical\nexample for such a scenario is routing in communication networks, where the\nsender can only observe whether the packet reached its destination, but often\nhas no information about the actions of the intermediate routers, which\ninfluences the final outcome. We study a setting where a principal needs to\nmotivate a team of agents whose combination of hidden efforts stochastically\ndetermines an outcome. In a companion paper we devise and study a basic\ncombinatorial agency model for this setting, where the principal is restricted\nto inducing a pure Nash equilibrium. Here we study various implications of this\nrestriction. First, we show that, in contrast to the case of observable\nefforts, inducing a mixed-strategies equilibrium may be beneficial for the\nprincipal. Second, we present a sufficient condition for technologies for which\nno gain can be generated. Third, we bound the principals gain for various\nfamilies of technologies. Finally, we study the robustness of mixed equilibria\nto coalitional deviations and the computational hardness of the optimal mixed\nequilibria.", 
    "link": "http://arxiv.org/pdf/1401.3837v1", 
    "arxiv-id": "1401.3837v1"
},{
    "category": "cs.GT", 
    "author": "Francesco Scarcello", 
    "title": "Non-Transferable Utility Coalitional Games via Mixed-Integer Linear   Constraints", 
    "publish": "2014-01-16T04:59:32Z", 
    "summary": "Coalitional games serve the purpose of modeling payoff distribution problems\nin scenarios where agents can collaborate by forming coalitions in order to\nobtain higher worths than by acting in isolation. In the classical Transferable\nUtility (TU) setting, coalition worths can be freely distributed amongst\nagents. However, in several application scenarios, this is not the case and the\nNon-Transferable Utility setting (NTU) must be considered, where additional\napplication-oriented constraints are imposed on the possible worth\ndistributions. In this paper, an approach to define NTU games is proposed which\nis based on describing allowed distributions via a set of mixed-integer linear\nconstraints applied to an underlying TU game. It is shown that such games allow\nnon-transferable conditions on worth distributions to be specified in a natural\nand succinct way. The properties and the relationships among the most prominent\nsolution concepts for NTU games that hold when they are applied on\n(mixed-integer) constrained games are investigated. Finally, a thorough\nanalysis is carried out to assess the impact of issuing constraints on the\ncomputational complexity of some of these solution concepts.", 
    "link": "http://arxiv.org/pdf/1401.3852v1", 
    "arxiv-id": "1401.3852v1"
},{
    "category": "cs.GT", 
    "author": "Nicholas Robert Jennings", 
    "title": "Cooperative Games with Overlapping Coalitions", 
    "publish": "2014-01-16T05:01:33Z", 
    "summary": "In the usual models of cooperative game theory, the outcome of a coalition\nformation process is either the grand coalition or a coalition structure that\nconsists of disjoint coalitions. However, in many domains where coalitions are\nassociated with tasks, an agent may be involved in executing more than one\ntask, and thus may distribute his resources among several coalitions. To tackle\nsuch scenarios, we introduce a model for cooperative games with overlapping\ncoalitions--or overlapping coalition formation (OCF) games. We then explore the\nissue of stability in this setting. In particular, we introduce a notion of the\ncore, which generalizes the corresponding notion in the traditional\n(non-overlapping) scenario. Then, under some quite general conditions, we\ncharacterize the elements of the core, and show that any element of the core\nmaximizes the social welfare. We also introduce a concept of balancedness for\noverlapping coalitional games, and use it to characterize coalition structures\nthat can be extended to elements of the core. Finally, we generalize the notion\nof convexity to our setting, and show that under some natural assumptions\nconvex games have a non-empty core. Moreover, we introduce two alternative\nnotions of stability in OCF that allow a wider range of deviations, and explore\nthe relationships among the corresponding definitions of the core, as well as\nthe classic (non-overlapping) core and the Aubin core. We illustrate the\ngeneral properties of the three cores, and also study them from a computational\nperspective, thus obtaining additional insights into their fundamental\nstructure.", 
    "link": "http://arxiv.org/pdf/1401.3856v1", 
    "arxiv-id": "1401.3856v1"
},{
    "category": "cs.GT", 
    "author": "Yadati Narahari", 
    "title": "Redistribution Mechanisms for Assignment of Heterogeneous Objects", 
    "publish": "2014-01-16T05:13:45Z", 
    "summary": "There are p heterogeneous objects to be assigned to n competing agents (n >\np) each with unit demand. It is required to design a Groves mechanism for this\nassignment problem satisfying weak budget balance, individual rationality, and\nminimizing the budget imbalance. This calls for designing an appropriate rebate\nfunction. When the objects are identical, this problem has been solved which we\nrefer as WCO mechanism. We measure the performance of such mechanisms by the\nredistribution index. We first prove an impossibility theorem which rules out\nlinear rebate functions with non-zero redistribution index in heterogeneous\nobject assignment. Motivated by this theorem, we explore two approaches to get\naround this impossibility. In the first approach, we show that linear rebate\nfunctions with non-zero redistribution index are possible when the valuations\nfor the objects have a certain type of relationship and we design a mechanism\nwith linear rebate function that is worst case optimal. In the second approach,\nwe show that rebate functions with non-zero efficiency are possible if\nlinearity is relaxed. We extend the rebate functions of the WCO mechanism to\nheterogeneous objects assignment and conjecture them to be worst case optimal.", 
    "link": "http://arxiv.org/pdf/1401.3884v1", 
    "arxiv-id": "1401.3884v1"
},{
    "category": "cs.GT", 
    "author": "Milind Tambe", 
    "title": "Stackelberg vs. Nash in Security Games: An Extended Investigation of   Interchangeability, Equivalence, and Uniqueness", 
    "publish": "2014-01-16T05:15:53Z", 
    "summary": "There has been significant recent interest in game-theoretic approaches to\nsecurity, with much of the recent research focused on utilizing the\nleader-follower Stackelberg game model. Among the major applications are the\nARMOR program deployed at LAX Airport and the IRIS program in use by the US\nFederal Air Marshals (FAMS). The foundational assumption for using Stackelberg\ngames is that security forces (leaders), acting first, commit to a randomized\nstrategy; while their adversaries (followers) choose their best response after\nsurveillance of this randomized strategy. Yet, in many situations, a leader may\nface uncertainty about the follower's surveillance capability. Previous work\nfails to address how a leader should compute her strategy given such\nuncertainty. We provide five contributions in the context of a general class of\nsecurity games. First, we show that the Nash equilibria in security games are\ninterchangeable, thus alleviating the equilibrium selection problem. Second,\nunder a natural restriction on security games, any Stackelberg strategy is also\na Nash equilibrium strategy; and furthermore, the solution is unique in a class\nof security games of which ARMOR is a key exemplar. Third, when faced with a\nfollower that can attack multiple targets, many of these properties no longer\nhold. Fourth, we show experimentally that in most (but not all) games where the\nrestriction does not hold, the Stackelberg strategy is still a Nash equilibrium\nstrategy, but this is no longer true when the attacker can attack multiple\ntargets. Finally, as a possible direction for future research, we propose an\nextensive-form game model that makes the defender's uncertainty about the\nattacker's ability to observe explicit.", 
    "link": "http://arxiv.org/pdf/1401.3888v1", 
    "arxiv-id": "1401.3888v1"
},{
    "category": "cs.GT", 
    "author": "David Xiao", 
    "title": "Redrawing the Boundaries on Purchasing Data from Privacy-Sensitive   Individuals", 
    "publish": "2014-01-16T17:02:17Z", 
    "summary": "We prove new positive and negative results concerning the existence of\ntruthful and individually rational mechanisms for purchasing private data from\nindividuals with unbounded and sensitive privacy preferences. We strengthen the\nimpossibility results of Ghosh and Roth (EC 2011) by extending it to a much\nwider class of privacy valuations. In particular, these include privacy\nvaluations that are based on ({\\epsilon}, {\\delta})-differentially private\nmechanisms for non-zero {\\delta}, ones where the privacy costs are measured in\na per-database manner (rather than taking the worst case), and ones that do not\ndepend on the payments made to players (which might not be observable to an\nadversary). To bypass this impossibility result, we study a natural special\nsetting where individuals have mono- tonic privacy valuations, which captures\ncommon contexts where certain values for private data are expected to lead to\nhigher valuations for privacy (e.g. having a particular disease). We give new\nmech- anisms that are individually rational for all players with monotonic\nprivacy valuations, truthful for all players whose privacy valuations are not\ntoo large, and accurate if there are not too many players with too-large\nprivacy valuations. We also prove matching lower bounds showing that in some\nrespects our mechanism cannot be improved significantly.", 
    "link": "http://arxiv.org/pdf/1401.4092v1", 
    "arxiv-id": "1401.4092v1"
},{
    "category": "cs.GT", 
    "author": "Federico Echenique", 
    "title": "Testing for separability is hard", 
    "publish": "2014-01-18T00:31:09Z", 
    "summary": "This paper shows that it is computationally hard to decide (or test) if a\nconsumption data set is consistent with separable preferences.", 
    "link": "http://arxiv.org/pdf/1401.4499v1", 
    "arxiv-id": "1401.4499v1"
},{
    "category": "cs.GT", 
    "author": "Marc Lanctot", 
    "title": "Computing Approximate Nash Equilibria and Robust Best-Responses Using   Sampling", 
    "publish": "2014-01-18T21:03:42Z", 
    "summary": "This article discusses two contributions to decision-making in complex\npartially observable stochastic games. First, we apply two state-of-the-art\nsearch techniques that use Monte-Carlo sampling to the task of approximating a\nNash-Equilibrium (NE) in such games, namely Monte-Carlo Tree Search (MCTS) and\nMonte-Carlo Counterfactual Regret Minimization (MCCFR). MCTS has been proven to\napproximate a NE in perfect-information games. We show that the algorithm\nquickly finds a reasonably strong strategy (but not a NE) in a complex\nimperfect information game, i.e. Poker. MCCFR on the other hand has theoretical\nNE convergence guarantees in such a game. We apply MCCFR for the first time in\nPoker. Based on our experiments, we may conclude that MCTS is a valid approach\nif one wants to learn reasonably strong strategies fast, whereas MCCFR is the\nbetter choice if the quality of the strategy is most important. Our second\ncontribution relates to the observation that a NE is not a best response\nagainst players that are not playing a NE. We present Monte-Carlo Restricted\nNash Response (MCRNR), a sample-based algorithm for the computation of\nrestricted Nash strategies. These are robust best-response strategies that (1)\nexploit non-NE opponents more than playing a NE and (2) are not (overly)\nexploitable by other strategies. We combine the advantages of two\nstate-of-the-art algorithms, i.e. MCCFR and Restricted Nash Response (RNR).\nMCRNR samples only relevant parts of the game tree. We show that MCRNR learns\nquicker than standard RNR in smaller games. Also we show in Poker that MCRNR\nlearns robust best-response strategies fast, and that these strategies exploit\nopponents more than playing a NE does.", 
    "link": "http://arxiv.org/pdf/1401.4591v1", 
    "arxiv-id": "1401.4591v1"
},{
    "category": "cs.GT", 
    "author": "Tuen-Wai Ng", 
    "title": "A Three-Dimensional Voting System in Hong Kong", 
    "publish": "2014-01-20T05:58:50Z", 
    "summary": "The voting system in the Legislative Council of Hong Kong (Legco) is\nsometimes unicameral and sometimes bicameral, depending on whether the bill is\nproposed by the Hong Kong government. Therefore, although without any\nrepresentative within Legco, the Hong Kong government has certain degree of\nlegislative power --- as if there is a virtual representative of the Hong Kong\ngovernment within the Legco. By introducing such a virtual representative of\nthe Hong Kong government, we show that Legco is a three-dimensional voting\nsystem. We also calculate two power indices of the Hong Kong government through\nthis virtual representative and consider the $C$-dimension and the\n$W$-dimension of Legco. Finally, some implications of this Legco model to the\ncurrent constitutional reform in Hong Kong will be given.", 
    "link": "http://arxiv.org/pdf/1401.4795v1", 
    "arxiv-id": "1401.4795v1"
},{
    "category": "cs.GT", 
    "author": "Jean Walrand", 
    "title": "Motivating Smartphone Collaboration in Data Acquisition and Distributed   Computing", 
    "publish": "2014-01-26T09:04:15Z", 
    "summary": "This paper analyzes and compares different incentive mechanisms for a master\nto motivate the collaboration of smartphone users on both data acquisition and\ndistributed computing applications. To collect massive sensitive data from\nusers, we propose a reward-based collaboration mechanism, where the master\nannounces a total reward to be shared among collaborators, and the\ncollaboration is successful if there are enough users wanting to collaborate.\nWe show that if the master knows the users' collaboration costs, then he can\nchoose to involve only users with the lowest costs. However, without knowing\nusers' private information, then he needs to offer a larger total reward to\nattract enough collaborators. Users will benefit from knowing their costs\nbefore the data acquisition. Perhaps surprisingly, the master may benefit as\nthe variance of users' cost distribution increases.\n  To utilize smartphones' computation resources to solve complex computing\nproblems, we study how the master can design an optimal contract by specifying\ndifferent task-reward combinations for different user types. Under complete\ninformation, we show that the master involves a user type as long as the\nmaster's preference characteristic outweighs that type's unit cost. All\ncollaborators achieve a zero payoff in this case. If the master does not know\nusers' private cost information, however, he will conservatively target at a\nsmaller group of users with small costs, and has to give most benefits to the\ncollaborators.", 
    "link": "http://arxiv.org/pdf/1401.6455v1", 
    "arxiv-id": "1401.6455v1"
},{
    "category": "cs.GT", 
    "author": "Edon Kelmendi", 
    "title": "Two-Player Perfect-Information Shift-Invariant Submixing Stochastic   Games Are Half-Positional", 
    "publish": "2014-01-25T19:55:41Z", 
    "summary": "We consider zero-sum stochastic games with perfect information and finitely\nmany states and actions. The payoff is computed by a payoff function which\nassociates to each infinite sequence of states and actions a real number. We\nprove that if the the payoff function is both shift-invariant and submixing,\nthen the game is half-positional, i.e. the first player has an optimal strategy\nwhich is both deterministic and stationary. This result relies on the existence\nof $\\epsilon$-subgame-perfect equilibria in shift-invariant games, a second\ncontribution of the paper.", 
    "link": "http://arxiv.org/pdf/1401.6575v2", 
    "arxiv-id": "1401.6575v2"
},{
    "category": "cs.GT", 
    "author": "Gala Yadgar", 
    "title": "Convergence of T\u00e2tonnement in Fisher Markets", 
    "publish": "2014-01-26T10:55:54Z", 
    "summary": "Analyzing simple and natural price-adjustment processes that converge to a\nmarket equilibrium is a fundamental question in economics. Such an analysis may\nhave implications in economic theory, computational economics, and distributed\nsystems. T\\^atonnement, proposed by Walras in 1874, is a process by which\nprices go up in response to excess demand, and down in response to excess\nsupply. This paper analyzes the convergence of a time-discrete t\\^atonnement\nprocess, a problem that recently attracted considerable attention of computer\nscientists. We prove that the simple t\\^atonnement process that we consider\nconverges (efficiently) to equilibrium prices and allocation in markets with\nnested CES-Leontief utilities, generalizing some of the previous convergence\nproofs for more restricted types of utility functions.", 
    "link": "http://arxiv.org/pdf/1401.6637v3", 
    "arxiv-id": "1401.6637v3"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "Random assignment with multi-unit demands", 
    "publish": "2014-01-29T23:19:54Z", 
    "summary": "We consider the multi-unit random assignment problem in which agents express\npreferences over objects and objects are allocated to agents randomly based on\nthe preferences. The most well-established preference relation to compare\nrandom allocations of objects is stochastic dominance (SD) which also leads to\ncorresponding notions of envy-freeness, efficiency, and weak strategyproofness.\nWe show that there exists no rule that is anonymous, neutral, efficient and\nweak strategyproof. For single-unit random assignment, we show that there\nexists no rule that is anonymous, neutral, efficient and weak\ngroup-strategyproof. We then study a generalization of the PS (probabilistic\nserial) rule called multi-unit-eating PS and prove that multi-unit-eating PS\nsatisfies envy-freeness, weak strategyproofness, and unanimity.", 
    "link": "http://arxiv.org/pdf/1401.7700v3", 
    "arxiv-id": "1401.7700v3"
},{
    "category": "cs.GT", 
    "author": "Ryszard Kowalczyk", 
    "title": "Truthful Market-based Trading of Cloud Resources with Reservation Price", 
    "publish": "2014-01-31T02:07:15Z", 
    "summary": "With the rapidly growing demand for the cloud services, a need for efficient\nmethods to trade computing resources increases. Commonly used fixed-price model\nis not always the best approach for trading cloud resources, because of its\ninflexible and static nature. Dynamic trading systems, which make use of market\nmechanisms, show promise for more efficient resource allocation and pricing in\nthe cloud. However, most of the existing mechanisms ignore the seller's costs\nof providing the resources. In order to address it, we propose a single-sided\nmarket mechanism for trading virtual machine instances in the cloud, where the\ncloud provider can express the reservation prices for traded cloud services. We\ninvestigate the theoretical properties of the proposed mechanism and prove that\nit is truthful, i.e. the buyers do not have an incentive to lie about their\ntrue valuation of the resources. We perform extensive experiments in order to\ninvestigate the impact of the reserve price on the market outcome. Our\nexperiments show that the proposed mechanism yields near optimal allocations\nand has a low execution time.", 
    "link": "http://arxiv.org/pdf/1401.8038v1", 
    "arxiv-id": "1401.8038v1"
},{
    "category": "cs.GT", 
    "author": "David Rosales", 
    "title": "Cooperative Product Games", 
    "publish": "2014-01-31T11:54:49Z", 
    "summary": "I introduce cooperative product games (CPGs), a cooperative game where every\nplayer has a weight, and the value of a coalition is the product of the weights\nof the players in the coalition. I only look at games where the weights are at\nleast $2$.\n  I show that no player in such a game can be a dummy. I show that the game is\nconvex, and therefore always has a non-empty core. I provide a simple method\nfor finding a payoff vector in the core.", 
    "link": "http://arxiv.org/pdf/1401.8144v1", 
    "arxiv-id": "1401.8144v1"
},{
    "category": "cs.GT", 
    "author": "Gerhard Woeginger", 
    "title": "Group Activity Selection Problem", 
    "publish": "2014-01-31T12:27:39Z", 
    "summary": "We consider a setting where one has to organize one or several group\nactivities for a set of agents. Each agent will participate in at most one\nactivity, and her preferences over activities depend on the number of\nparticipants in the activity. The goal is to assign agents to activities based\non their preferences. We put forward a general model for this setting, which is\na natural generalization of anonymous hedonic games. We then focus on a special\ncase of our model, where agents' preferences are binary, i.e., each agent\nclassifies all pairs of the form \"(activity, group size)\" into ones that are\nacceptable and ones that are not. We formulate several solution concepts for\nthis scenario, and study them from the computational point of view, providing\nhardness results for the general case as well as efficient algorithms for\nsettings where agents' preferences satisfy certain natural constraints.", 
    "link": "http://arxiv.org/pdf/1401.8151v1", 
    "arxiv-id": "1401.8151v1"
},{
    "category": "cs.GT", 
    "author": "Nicholas R Jennings", 
    "title": "Towards a Fair Allocation of Rewards in Multi-Level Marketing", 
    "publish": "2014-04-02T13:24:33Z", 
    "summary": "An increasing number of businesses and organisations rely on existing users\nfor finding new users or spreading a message. One of the widely used\n\"refer-a-friend\" mechanisms offers an equal reward to both the referrer and the\ninvitee. This mechanism provides incentives for direct referrals and is fair to\nthe invitee. On the other hand, multi-level marketing and recent social\nmobilisation experiments focus on mechanisms that incentivise both direct and\nindirect referrals. Such mechanisms share the reward for inviting a new member\namong the ancestors, usually in geometrically decreasing shares. A new member\nreceives nothing at the time of joining. We study fairness in multi-level\nmarketing mechanisms. We show how characteristic function games can be used to\nmodel referral marketing, show how the canonical fairness concept of the\nShapley value can be applied to this setting, and establish the complexity of\nfinding the Shapley value in each class, and provide a comparison of the\nShapley value-based mechanism to existing referral mechanisms.", 
    "link": "http://arxiv.org/pdf/1404.0542v1", 
    "arxiv-id": "1404.0542v1"
},{
    "category": "cs.GT", 
    "author": "Jason Hartline", 
    "title": "Multi-dimensional Virtual Values and Second-degree Price Discrimination", 
    "publish": "2014-04-04T19:02:42Z", 
    "summary": "We consider a multi-dimensional screening problem of selling a product with\nmultiple quality levels and design virtual value functions to derive conditions\nthat imply optimality of only selling highest quality. A challenge of designing\nvirtual values for multi-dimensional agents is that a mechanism that pointwise\noptimizes virtual values resulting from a general application of integration by\nparts is not incentive compatible, and no general methodology is known for\nselecting the right paths for integration by parts. We resolve this issue by\nfirst uniquely solving for paths that satisfy certain necessary conditions that\nthe pointwise optimality of the mechanism imposes on virtual values, and then\nidentifying distributions that ensure the resulting virtual surplus is indeed\npointwise optimized by the mechanism. Our method of solving for virtual values\nis general, and as a second application we use it to derive conditions of\noptimality for selling only the grand bundle of items to an agent with additive\npreferences.", 
    "link": "http://arxiv.org/pdf/1404.1341v4", 
    "arxiv-id": "1404.1341v4"
},{
    "category": "cs.GT", 
    "author": "Robert Kleinberg", 
    "title": "On the Complexity of Computing an Equilibrium in Combinatorial Auctions", 
    "publish": "2014-04-08T08:39:24Z", 
    "summary": "We study combinatorial auctions where each item is sold separately but\nsimultaneously via a second price auction. We ask whether it is possible to\nefficiently compute in this game a pure Nash equilibrium with social welfare\nclose to the optimal one.\n  We show that when the valuations of the bidders are submodular, in many\ninteresting settings (e.g., constant number of bidders, budget additive\nbidders) computing an equilibrium with good welfare is essentially as easy as\ncomputing, completely ignoring incentives issues, an allocation with good\nwelfare. On the other hand, for subadditive valuations, we show that computing\nan equilibrium requires exponential communication. Finally, for XOS (a.k.a.\nfractionally subadditive) valuations, we show that if there exists an efficient\nalgorithm that finds an equilibrium, it must use techniques that are very\ndifferent from our current ones.", 
    "link": "http://arxiv.org/pdf/1404.2041v2", 
    "arxiv-id": "1404.2041v2"
},{
    "category": "cs.GT", 
    "author": "Elias Koutsoupias", 
    "title": "Duality and Optimality of Auctions for Uniform Distributions", 
    "publish": "2014-04-08T23:10:39Z", 
    "summary": "We develop a general duality-theory framework for revenue maximization in\nadditive Bayesian auctions. The framework extends linear programming duality\nand complementarity to constraints with partial derivatives. The dual system\nreveals the geometric nature of the problem and highlights its connection with\nthe theory of bipartite graph matchings. We demonstrate the power of the\nframework by applying it to a multiple-good monopoly setting where the buyer\nhas uniformly distributed valuations for the items, the canonical long-standing\nopen problem in the area. We propose a deterministic selling mechanism called\nStraight-Jacket Auction (SJA) which we prove to be exactly optimal for up to 6\nitems, and conjecture its optimality for any number of goods. The duality\nframework is used not only for proving optimality, but perhaps more\nimportantly, for deriving the optimal mechanism itself; as a result, SJA is\ndefined by natural geometric constraints.", 
    "link": "http://arxiv.org/pdf/1404.2329v3", 
    "arxiv-id": "1404.2329v3"
},{
    "category": "cs.GT", 
    "author": "Liang Liu", 
    "title": "Frugal Online Incentive Mechanisms for Crowdsourcing Tasks Truthfully", 
    "publish": "2014-04-09T09:05:46Z", 
    "summary": "Mobile Crowd Sensing (MCS) is a new paradigm which takes advantage of\npervasive smartphones to efficiently collect data, enabling numerous novel\napplications. To achieve good service quality for a MCS application, incentive\nmechanisms are necessary to attract more user participation. Most of existing\nmechanisms apply only for the offline scenario where all users' information are\nknown a priori. On the contrary, we focus on a more realistic scenario where\nusers arrive one by one online in a random order. Based on the online auction\nmodel, we investigate the problem that users submit their private profiles to\nthe crowdsourcer when they arrive, and the crowdsourcer aims at selecting a\nsubset of users before a specified deadline for minimizing the total payment\nwhile a specific number of tasks can be completed.We design three online\nmechanisms, Homo-OMZ, Hetero-OMZ and Hetero-OMG, all of which can satisfy the\ncomputational efficiency, individual rationality, cost-truthfulness, and\nconsumer sovereignty. The Homo-OMZ mechanism is applicable to the homogeneous\nuser model and can satisfy the social efficiency but not constant frugality.\nThe Hetero-OMZ and Hetero-OMG mechanisms are applicable to both the homogeneous\nand heterogeneous user models, and can satisfy the constant frugality. Besides,\nthe Hetero-OMG mechanism can also satisfy the time-truthfulness. Through\nextensive simulations, we evaluate the performance and validate the theoretical\nproperties of our online mechanisms.", 
    "link": "http://arxiv.org/pdf/1404.2399v1", 
    "arxiv-id": "1404.2399v1"
},{
    "category": "cs.GT", 
    "author": "Saswati Sarkar", 
    "title": "Quality Sensitive Price Competition in Spectrum Oligopoly:Part 1", 
    "publish": "2014-04-06T04:14:03Z", 
    "summary": "We investigate a spectrum oligopoly market where primaries lease their\nchannels to secondaries in lieu of financial remuneration. Transmission quality\nof a channel evolves randomly. Each primary has to select the price it would\nquote without knowing the transmission qualities of its competitors' channels.\nEach secondary buys a channel depending on the price and the transmission\nquality a channel offers. We formulate the price selection problem as a non\nco-operative game with primaries as players. In the one-shot game, we show that\nthere exists a unique symmetric Nash Equilibrium(NE) strategy profile and\nexplicitly compute it. Our analysis reveals that under the NE strategy profile\na primary prices its channel to render high quality channel more preferable to\nthe secondary; this negates the popular belief that prices ought to be selected\nto render channels equally preferable to the secondary regardless of their\nqualities. We show the loss of revenue in the asymptotic limit due to the non\nco-operation of primaries. In the repeated version of the game, we characterize\na subgame perfect NE where a primary can attain a payoff arbitrarily close to\nthe payoff it would obtain when primaries co-operate.", 
    "link": "http://arxiv.org/pdf/1404.2514v4", 
    "arxiv-id": "1404.2514v4"
},{
    "category": "cs.GT", 
    "author": "Jian Li", 
    "title": "The Multi-shop Ski Rental Problem", 
    "publish": "2014-04-10T02:14:53Z", 
    "summary": "We consider the {\\em multi-shop ski rental} problem. This problem generalizes\nthe classic ski rental problem to a multi-shop setting, in which each shop has\ndifferent prices for renting and purchasing a pair of skis, and a\n\\emph{consumer} has to make decisions on when and where to buy. We are\ninterested in the {\\em optimal online (competitive-ratio minimizing) mixed\nstrategy} from the consumer's perspective. For our problem in its basic form,\nwe obtain exciting closed-form solutions and a linear time algorithm for\ncomputing them. We further demonstrate the generality of our approach by\ninvestigating three extensions of our basic problem, namely ones that consider\ncosts incurred by entering a shop or switching to another shop. Our solutions\nto these problems suggest that the consumer must assign positive probability in\n\\emph{exactly one} shop at any buying time. Our results apply to many\nreal-world applications, ranging from cost management in \\texttt{IaaS} cloud to\nscheduling in distributed computing.", 
    "link": "http://arxiv.org/pdf/1404.2671v1", 
    "arxiv-id": "1404.2671v1"
},{
    "category": "cs.GT", 
    "author": "Yiannis Giannakopoulos", 
    "title": "Bounding the Optimal Revenue of Selling Multiple Goods", 
    "publish": "2014-04-10T14:46:38Z", 
    "summary": "Using duality theory techniques we derive simple, closed-form formulas for\nbounding the optimal revenue of a monopolist selling many heterogeneous goods,\nin the case where the buyer's valuations for the items come i.i.d. from a\nuniform distribution and in the case where they follow independent (but not\nnecessarily identical) exponential distributions. We apply this in order to get\nin both these settings specific performance guarantees, as functions of the\nnumber of items $m$, for the simple deterministic selling mechanisms studied by\nHart and Nisan [EC 2012], namely the one that sells the items separately and\nthe one that offers them all in a single bundle.\n  We also propose and study the performance of a natural randomized mechanism\nfor exponential valuations, called Proportional. As an interesting corollary,\nfor the special case where the exponential distributions are also identical, we\ncan derive that offering the goods in a single full bundle is the optimal\nselling mechanism for any number of items. To our knowledge, this is the first\nresult of its kind: finding a revenue-maximizing auction in an additive setting\nwith arbitrarily many goods.", 
    "link": "http://arxiv.org/pdf/1404.2832v6", 
    "arxiv-id": "1404.2832v6"
},{
    "category": "cs.GT", 
    "author": "Omri Weinstein", 
    "title": "Distributed Signaling Games", 
    "publish": "2014-04-10T16:06:56Z", 
    "summary": "A recurring theme in recent computer science literature is that proper design\nof signaling schemes is a crucial aspect of effective mechanisms aiming to\noptimize social welfare or revenue. One of the research endeavors of this line\nof work is understanding the algorithmic and computational complexity of\ndesigning efficient signaling schemes. In reality, however, information is\ntypically not held by a central authority, but is distributed among multiple\nsources (third-party \"mediators\"), a fact that dramatically changes the\nstrategic and combinatorial nature of the signaling problem, making it a game\nbetween information providers, as opposed to a traditional mechanism design\nproblem.\n  In this paper we introduce {\\em distributed signaling games}, while using\ndisplay advertising as a canonical example for introducing this foundational\nframework. A distributed signaling game may be a pure coordination game (i.e.,\na distributed optimization task), or a non-cooperative game. In the context of\npure coordination games, we show a wide gap between the computational\ncomplexity of the centralized and distributed signaling problems. On the other\nhand, we show that if the information structure of each mediator is assumed to\nbe \"local\", then there is an efficient algorithm that finds a near-optimal\n($5$-approximation) distributed signaling scheme.\n  In the context of non-cooperative games, the outcome generated by the\nmediators' signals may have different value to each (due to the auctioneer's\ndesire to align the incentives of the mediators with his own by relative\ncompensations). We design a mechanism for this problem via a novel application\nof Shapley's value, and show that it possesses some interesting properties, in\nparticular, it always admits a pure Nash equilibrium, and it never decreases\nthe revenue of the auctioneer.", 
    "link": "http://arxiv.org/pdf/1404.2861v2", 
    "arxiv-id": "1404.2861v2"
},{
    "category": "cs.GT", 
    "author": "Michael Wooldridge", 
    "title": "A Measure of Synergy in Coalitions", 
    "publish": "2014-04-10T21:25:02Z", 
    "summary": "When the performance of a team of agents exceeds our expectations or fall\nshort of them, we often explain this by saying that there was some synergy in\nthe team---either positive (the team exceeded our expectations) or negative\n(they fell short). Our aim in this article is to develop a formal and\nprincipled way of measuring synergies, both positive and negative. Using\ncharacteristic function cooperative games as our underlying model, we present a\nformal measure of synergy, based on the idea that a synergy is exhibited when\nthe performance of a team deviates from the norm. We then show that our synergy\nvalue is the only possible such measure that satisfies certain intuitive\nproperties. We then investigate some alternative characterisations of this\nmeasure.", 
    "link": "http://arxiv.org/pdf/1404.2954v1", 
    "arxiv-id": "1404.2954v1"
},{
    "category": "cs.GT", 
    "author": "Liwei Wang", 
    "title": "Generalized Second Price Auction with Probabilistic Broad Match", 
    "publish": "2014-04-15T07:02:46Z", 
    "summary": "Generalized Second Price (GSP) auctions are widely used by search engines\ntoday to sell their ad slots. Most search engines have supported broad match\nbetween queries and bid keywords when executing GSP auctions, however, it has\nbeen revealed that GSP auction with the standard broad-match mechanism they are\ncurrently using (denoted as SBM-GSP) has several theoretical drawbacks (e.g.,\nits theoretical properties are known only for the single-slot case and\nfull-information setting, and even in this simple setting, the corresponding\nworst-case social welfare can be rather bad). To address this issue, we propose\na novel broad-match mechanism, which we call the Probabilistic Broad-Match\n(PBM) mechanism. Different from SBM that puts together the ads bidding on all\nthe keywords matched to a given query for the GSP auction, the GSP with PBM\n(denoted as PBM-GSP) randomly samples a keyword according to a predefined\nprobability distribution and only runs the GSP auction for the ads bidding on\nthis sampled keyword. We perform a comprehensive study on the theoretical\nproperties of the PBM-GSP. Specifically, we study its social welfare in the\nworst equilibrium, in both full-information and Bayesian settings. The results\nshow that PBM-GSP can generate larger welfare than SBM-GSP under mild\nconditions. Furthermore, we also study the revenue guarantee for PBM-GSP in\nBayesian setting. To the best of our knowledge, this is the first work on\nbroad-match mechanisms for GSP that goes beyond the single-slot case and the\nfull-information setting.", 
    "link": "http://arxiv.org/pdf/1404.3828v1", 
    "arxiv-id": "1404.3828v1"
},{
    "category": "cs.GT", 
    "author": "Enrico H. Gerding", 
    "title": "Mechanism Design for Mobile Geo-Location Advertising", 
    "publish": "2014-04-15T22:59:53Z", 
    "summary": "Mobile geo-location advertising, where mobile ads are targeted based on a\nuser's location, has been identified as a key growth factor for the mobile\nmarket. As with online advertising, a crucial ingredient for their success is\nthe development of effective economic mechanisms. An important difference is\nthat mobile ads are shown sequentially over time and information about the user\ncan be learned based on their movements. Furthermore, ads need to be shown\nselectively to prevent ad fatigue. To this end, we introduce, for the first\ntime, a user model and suitable economic mechanisms which take these factors\ninto account. Specifically, we design two truthful mechanisms which produce an\nadvertisement plan based on the user's movements. One mechanism is allocatively\nefficient, but requires exponential compute time in the worst case. The other\nrequires polynomial time, but is not allocatively efficient. Finally, we\nexperimentally evaluate the tradeoff between compute time and efficiency of our\nmechanisms.", 
    "link": "http://arxiv.org/pdf/1404.4106v1", 
    "arxiv-id": "1404.4106v1"
},{
    "category": "cs.GT", 
    "author": "Jeffrey S. Rosenschein", 
    "title": "A Local-Dominance Theory of Voting Equilibria", 
    "publish": "2014-04-18T04:40:28Z", 
    "summary": "It is well known that no reasonable voting rule is strategyproof. Moreover,\nthe common Plurality rule is particularly prone to strategic behavior of the\nvoters and empirical studies show that people often vote strategically in\npractice. Multiple game-theoretic models have been proposed to better\nunderstand and predict such behavior and the outcomes it induces. However,\nthese models often make unrealistic assumptions regarding voters' behavior and\nthe information on which they base their vote.\n  We suggest a new model for strategic voting that takes into account voters'\nbounded rationality, as well as their limited access to reliable information.\nWe introduce a simple behavioral heuristic based on \\emph{local dominance},\nwhere each voter considers a set of possible world states without assigning\nprobabilities to them. This set is constructed based on prospective candidates'\nscores (e.g., available from an inaccurate poll). In a \\emph{voting\nequilibrium}, all voters vote for candidates not dominated within the set of\npossible states.\n  We prove that these voting equilibria exist in the Plurality rule for a broad\nclass of local dominance relations (that is, different ways to decide which\nstates are possible). Furthermore, we show that in an iterative setting where\nvoters may repeatedly change their vote, local dominance-based dynamics quickly\nconverge to an equilibrium if voters start from the truthful state. Weaker\nconvergence guarantees in more general settings are also provided.\n  Using extensive simulations of strategic voting on generated and real\npreference profiles, we show that convergence is fast and robust, that emerging\nequilibria are consistent across various starting conditions, and that they\nreplicate widely known patterns of human voting behavior such as Duverger's\nlaw. Further, strategic voting generally improves the quality of the winner\ncompared to truthful voting.", 
    "link": "http://arxiv.org/pdf/1404.4688v2", 
    "arxiv-id": "1404.4688v2"
},{
    "category": "cs.GT", 
    "author": "Shreyas Sekar", 
    "title": "Approximate Equilibrium and Incentivizing Social Coordination", 
    "publish": "2014-04-18T08:28:09Z", 
    "summary": "We study techniques to incentivize self-interested agents to form socially\ndesirable solutions in scenarios where they benefit from mutual coordination.\nTowards this end, we consider coordination games where agents have different\nintrinsic preferences but they stand to gain if others choose the same strategy\nas them. For non-trivial versions of our game, stable solutions like Nash\nEquilibrium may not exist, or may be socially inefficient even when they do\nexist. This motivates us to focus on designing efficient algorithms to compute\n(almost) stable solutions like Approximate Equilibrium that can be realized if\nagents are provided some additional incentives. Our results apply in many\nsettings like adoption of new products, project selection, and group formation,\nwhere a central authority can direct agents towards a strategy but agents may\ndefect if they have better alternatives. We show that for any given instance,\nwe can either compute a high quality approximate equilibrium or a near-optimal\nsolution that can be stabilized by providing small payments to some players. We\nthen generalize our model to encompass situations where player relationships\nmay exhibit complementarities and present an algorithm to compute an\nApproximate Equilibrium whose stability factor is linear in the degree of\ncomplementarity. Our results imply that a little influence is necessary in\norder to ensure that selfish players coordinate and form socially efficient\nsolutions.", 
    "link": "http://arxiv.org/pdf/1404.4718v1", 
    "arxiv-id": "1404.4718v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Clinching Auctions Beyond Hard Budget Constraints", 
    "publish": "2014-04-20T01:21:39Z", 
    "summary": "Constraints on agent's ability to pay play a major role in auction design for\nany setting where the magnitude of financial transactions is sufficiently\nlarge. Those constraints have been traditionally modeled in mechanism design as\n\\emph{hard budget}, i.e., mechanism is not allowed to charge agents more than a\ncertain amount. Yet, real auction systems (such as Google AdWords) allow more\nsophisticated constraints on agents' ability to pay, such as \\emph{average\nbudgets}. In this work, we investigate the design of Pareto optimal and\nincentive compatible auctions for agents with \\emph{constrained quasi-linear\nutilities}, which captures more realistic models of liquidity constraints that\nthe agents may have. Our result applies to a very general class of allocation\nconstraints known as polymatroidal environments, encompassing many settings of\ninterest such as multi-unit auctions, matching markets, video-on-demand and\nadvertisement systems.\n  Our design is based Ausubel's \\emph{clinching framework}. Incentive\ncompatibility and feasibility with respect to ability-to-pay constraints are\ndirect consequences of the clinching framework. Pareto-optimality, on the other\nhand, is considerably more challenging, since the no-trade condition that\ncharacterizes it depends not only on whether agents have their budgets\nexhausted or not, but also on prices {at} which the goods are allocated. In\norder to get a handle on those prices, we introduce novel concepts of dropping\nprices and saturation. These concepts lead to our main structural result which\nis a characterization of the tight sets in the clinching auction outcome and\nits relation to dropping prices.", 
    "link": "http://arxiv.org/pdf/1404.5000v1", 
    "arxiv-id": "1404.5000v1"
},{
    "category": "cs.GT", 
    "author": "David Kurokawa", 
    "title": "Optimising Trade-offs Among Stakeholders in Ad Auctions", 
    "publish": "2014-04-21T07:06:22Z", 
    "summary": "We examine trade-offs among stakeholders in ad auctions. Our metrics are the\nrevenue for the utility of the auctioneer, the number of clicks for the utility\nof the users and the welfare for the utility of the advertisers. We show how to\noptimize linear combinations of the stakeholder utilities, showing that these\ncan be tackled through a GSP auction with a per-click reserve price. We then\nexamine constrained optimization of stakeholder utilities.\n  We use simulations and analysis of real-world sponsored search auction data\nto demonstrate the feasible trade-offs, examining the effect of changing the\nallowed number of ads on the utilities of the stakeholders. We investigate both\nshort term effects, when the players do not have the time to modify their\nbehavior, and long term equilibrium conditions.\n  Finally, we examine a combinatorially richer constrained optimization\nproblem, where there are several possible allowed configurations (templates) of\nad formats. This model captures richer ad formats, which allow using the\navailable screen real estate in various ways. We show that two natural\ngeneralizations of the GSP auction rules to this domain are poorly behaved,\nresulting in not having a symmetric Nash equilibrium or having one with poor\nwelfare. We also provide positive results for restricted cases.", 
    "link": "http://arxiv.org/pdf/1404.5127v1", 
    "arxiv-id": "1404.5127v1"
},{
    "category": "cs.GT", 
    "author": "Tie-Yan Liu", 
    "title": "Incentivizing High-quality Content from Heterogeneous Users: On the   Existence of Nash Equilibrium", 
    "publish": "2014-04-21T10:08:57Z", 
    "summary": "We study the existence of pure Nash equilibrium (PNE) for the mechanisms used\nin Internet services (e.g., online reviews and question-answer websites) to\nincentivize users to generate high-quality content. Most existing work assumes\nthat users are homogeneous and have the same ability. However, real-world users\nare heterogeneous and their abilities can be very different from each other due\nto their diverse background, culture, and profession. In this work, we consider\nheterogeneous users with the following framework: (1) the users are\nheterogeneous and each of them has a private type indicating the best quality\nof the content she can generate; (2) there is a fixed amount of reward to\nallocate to the participated users. Under this framework, we study the\nexistence of pure Nash equilibrium of several mechanisms composed by different\nallocation rules, action spaces, and information settings. We prove the\nexistence of PNE for some mechanisms and the non-existence of PNE for some\nmechanisms. We also discuss how to find a PNE for those mechanisms with PNE\neither through a constructive way or a search algorithm.", 
    "link": "http://arxiv.org/pdf/1404.5155v1", 
    "arxiv-id": "1404.5155v1"
},{
    "category": "cs.GT", 
    "author": "Jinshan Zhang", 
    "title": "Size versus truthfulness in the House Allocation problem", 
    "publish": "2014-04-21T17:08:42Z", 
    "summary": "We study the House Allocation problem (also known as the Assignment problem),\ni.e., the problem of allocating a set of objects among a set of agents, where\neach agent has ordinal preferences (possibly involving ties) over a subset of\nthe objects. We focus on truthful mechanisms without monetary transfers for\nfinding large Pareto optimal matchings. It is straightforward to show that no\ndeterministic truthful mechanism can approximate a maximum cardinality Pareto\noptimal matching with ratio better than 2. We thus consider randomized\nmechanisms. We give a natural and explicit extension of the classical Random\nSerial Dictatorship Mechanism (RSDM) specifically for the House Allocation\nproblem where preference lists can include ties. We thus obtain a universally\ntruthful randomized mechanism for finding a Pareto optimal matching and show\nthat it achieves an approximation ratio of $\\frac{e}{e-1}$. The same bound\nholds even when agents have priorities (weights) and our goal is to find a\nmaximum weight (as opposed to maximum cardinality) Pareto optimal matching. On\nthe other hand we give a lower bound of $\\frac{18}{13}$ on the approximation\nratio of any universally truthful Pareto optimal mechanism in settings with\nstrict preferences. In the case that the mechanism must additionally be\nnon-bossy, an improved lower bound of $\\frac{e}{e-1}$ holds. This lower bound\nis tight given that RSDM for strict preference lists is non-bossy. We moreover\ninterpret our problem in terms of the classical secretary problem and prove\nthat our mechanism provides the best randomized strategy of the administrator\nwho interviews the applicants.", 
    "link": "http://arxiv.org/pdf/1404.5245v3", 
    "arxiv-id": "1404.5245v3"
},{
    "category": "cs.GT", 
    "author": "Demosthenis Teneketzis", 
    "title": "Electricity Pooling Markets with Strategic Producers Possessing   Asymmetric Information II: Inelastic Demand", 
    "publish": "2014-04-21T17:29:57Z", 
    "summary": "In the restructured electricity industry, electricity pooling markets are an\noligopoly with strategic producers possessing private information (private\nproduction cost function). We focus on pooling markets where aggregate demand\nis represented by a non-strategic agent.\n  Inelasticity of demand is a main difficulty in electricity markets which can\npotentially result in market failure and high prices. We consider demand to be\ninelastic.\n  We propose a market mechanism that has the following features. (F1) It is\nindividually rational. (F2) It is budget balanced. (F3) It is price efficient,\nthat is, at equilibrium the price of electricity is equal to the marginal cost\nof production. (F4) The energy production profile corresponding to every\nnon-zero Nash equilibrium of the game induced by the mechanism is a solution of\nthe corresponding centralized problem where the objective is the maximization\nof the sum of the producers' and consumers' utilities.\n  We identify some open problems associated with our approach to electricity\npooling markets.", 
    "link": "http://arxiv.org/pdf/1404.5539v2", 
    "arxiv-id": "1404.5539v2"
},{
    "category": "cs.GT", 
    "author": "Rasmus Ibsen-Jensen", 
    "title": "The Complexity of Ergodic Mean-payoff Games", 
    "publish": "2014-04-23T08:12:19Z", 
    "summary": "We study two-player (zero-sum) concurrent mean-payoff games played on a\nfinite-state graph. We focus on the important sub-class of ergodic games where\nall states are visited infinitely often with probability 1. The algorithmic\nstudy of ergodic games was initiated in a seminal work of Hoffman and Karp in\n1966, but all basic complexity questions have remained unresolved. Our main\nresults for ergodic games are as follows: We establish (1) an optimal\nexponential bound on the patience of stationary strategies (where patience of a\ndistribution is the inverse of the smallest positive probability and represents\na complexity measure of a stationary strategy); (2) the approximation problem\nlie in FNP; (3) the approximation problem is at least as hard as the decision\nproblem for simple stochastic games (for which NP intersection coNP is the\nlong-standing best known bound). We present a variant of the strategy-iteration\nalgorithm by Hoffman and Karp; show that both our algorithm and the classical\nvalue-iteration algorithm can approximate the value in exponential time; and\nidentify a subclass where the value-iteration algorithm is a FPTAS. We also\nshow that the exact value can be expressed in the existential theory of the\nreals, and establish square-root sum hardness for a related class of games.", 
    "link": "http://arxiv.org/pdf/1404.5734v1", 
    "arxiv-id": "1404.5734v1"
},{
    "category": "cs.GT", 
    "author": "Ashutosh Trivedi", 
    "title": "Adding Negative Prices to Priced Timed Games", 
    "publish": "2014-04-23T17:08:23Z", 
    "summary": "Priced timed games (PTGs) are two-player zero-sum games played on the\ninfinite graph of configurations of priced timed automata where two players\ntake turns to choose transitions in order to optimize cost to reach target\nstates. Bouyer et al. and Alur, Bernadsky, and Madhusudan independently\nproposed algorithms to solve PTGs with nonnegative prices under certain\ndivergence restriction over prices. Brihaye, Bruyere, and Raskin later provided\na justification for such a restriction by showing the undecidability of the\noptimal strategy synthesis problem in the absence of this divergence\nrestriction. This problem for PTGs with one clock has long been conjectured to\nbe in polynomial time, however the current best known algorithm, by Hansen,\nIbsen-Jensen, and Miltersen, is exponential. We extend this picture by studying\nPTGs with both negative and positive prices. We refine the undecidability\nresults for optimal strategy synthesis problem, and show undecidability for\nseveral variants of optimal reachability cost objectives including reachability\ncost, time-bounded reachability cost, and repeated reachability cost\nobjectives. We also identify a subclass with bi-valued price-rates and give a\npseudo-polynomial (polynomial when prices are nonnegative) algorithm to\npartially answer the conjecture on the complexity of one-clock PTGs.", 
    "link": "http://arxiv.org/pdf/1404.5894v5", 
    "arxiv-id": "1404.5894v5"
},{
    "category": "cs.GT", 
    "author": "Sam Taggart", 
    "title": "Price of Anarchy for Auction Revenue", 
    "publish": "2014-04-23T19:57:35Z", 
    "summary": "This paper develops tools for welfare and revenue analyses of Bayes-Nash\nequilibria in asymmetric auctions with single-dimensional agents. We employ\nthese tools to derive price of anarchy results for social welfare and revenue.\nOur approach separates the standard smoothness framework into two distinct\nparts, isolating the analysis common to any auction from the analysis specific\nto a given auction. The first part relates a bidder's contribution to welfare\nin equilibrium to their contribution to welfare in the optimal auction using\nthe price the bidder faces for additional allocation. Intuitively, either an\nagent's utility and hence contribution to welfare is high, or the price she has\nto pay for additional allocation is high relative to her value. We call this\ncondition value covering; it holds in every Bayes-Nash equilibrium of any\nauction. The second part, revenue covering, relates the prices bidders face for\nadditional allocation to the revenue of the auction, using an auction's rules\nand feasibility constraints. Combining the two parts gives approximation\nresults to the optimal welfare, and, under the right conditions, the optimal\nrevenue. In mechanisms with reserve prices, our welfare results show\napproximation with respect to the optimal mechanism with the same reserves.\n  As a center-piece result, we analyze the single-item first-price auction with\nindividual monopoly reserves. When each distribution satisfies a regularity\ncondition the auction's revenue is at least a $2e/(e-1) \\approx 3.16$\napproximation to the revenue of the optimal auction. We also give bounds for\nmatroid auctions with first-price or all-pay semantics, and the generalized\nfirst-price position auction. Finally, we give an extension theorem for\nsimultaneous composition, i.e., when multiple auctions are run simultaneously,\nwith single-valued, unit-demand agents.", 
    "link": "http://arxiv.org/pdf/1404.5943v4", 
    "arxiv-id": "1404.5943v4"
},{
    "category": "cs.GT", 
    "author": "Denis Nekipelov", 
    "title": "Mechanism Design for Data Science", 
    "publish": "2014-04-23T20:27:58Z", 
    "summary": "Good economic mechanisms depend on the preferences of participants in the\nmechanism. For example, the revenue-optimal auction for selling an item is\nparameterized by a reserve price, and the appropriate reserve price depends on\nhow much the bidders are willing to pay. A mechanism designer can potentially\nlearn about the participants' preferences by observing historical data from the\nmechanism; the designer could then update the mechanism in response to learned\npreferences to improve its performance. The challenge of such an approach is\nthat the data corresponds to the actions of the participants and not their\npreferences. Preferences can potentially be inferred from actions but the\ndegree of inference possible depends on the mechanism. In the optimal auction\nexample, it is impossible to learn anything about preferences of bidders who\nare not willing to pay the reserve price. These bidders will not cast bids in\nthe auction and, from historical bid data, the auctioneer could never learn\nthat lowering the reserve price would give a higher revenue (even if it would).\nTo address this impossibility, the auctioneer could sacrifice revenue\noptimality in the initial auction to obtain better inference properties so that\nthe auction's parameters can be adapted to changing preferences in the future.\nThis paper develops the theory for optimal mechanism design subject to good\ninferability.", 
    "link": "http://arxiv.org/pdf/1404.5971v2", 
    "arxiv-id": "1404.5971v2"
},{
    "category": "cs.GT", 
    "author": "Assaf Romm", 
    "title": "An Approximate \"Law of One Price\" in Random Assignment Games", 
    "publish": "2014-04-24T12:26:04Z", 
    "summary": "Assignment games represent a tractable yet versatile model of two-sided\nmarkets with transfers. We study the likely properties of the core of randomly\ngenerated assignment games. If the joint productivities of every firm and\nworker are i.i.d bounded random variables, then with high probability all\nworkers are paid roughly equal wages, and all firms make similar profits. This\nimplies that core allocations vary significantly in balanced markets, but that\nthere is core convergence in even slightly unbalanced markets. For the\nbenchmark case of uniform distribution, we provide a tight bound for the\nworkers' share of the surplus under the firm-optimal core allocation. We\npresent simulation results suggesting that the phenomena analyzed appear even\nin medium-sized markets. Finally, we briefly discuss the effects of unbounded\ndistributions and the ways in which they may affect wage dispersion.", 
    "link": "http://arxiv.org/pdf/1404.6103v1", 
    "arxiv-id": "1404.6103v1"
},{
    "category": "cs.GT", 
    "author": "Shahar Dobzinski", 
    "title": "Reallocation Mechanisms", 
    "publish": "2014-04-27T16:43:54Z", 
    "summary": "We consider reallocation problems in settings where the initial endowment of\neach agent consists of a subset of the resources. The private information of\nthe players is their value for every possible subset of the resources. The goal\nis to redistribute resources among agents to maximize efficiency. Monetary\ntransfers are allowed, but participation is voluntary.\n  We develop incentive-compatible, individually-rational and budget balanced\nmechanisms for several classic settings, including bilateral trade, partnership\ndissolving, Arrow-Debreu markets, and combinatorial exchanges. All our\nmechanisms (except one) provide a constant approximation to the optimal\nefficiency in these settings, even in ones where the preferences of the agents\nare complex multi-parameter functions.", 
    "link": "http://arxiv.org/pdf/1404.6786v1", 
    "arxiv-id": "1404.6786v1"
},{
    "category": "cs.GT", 
    "author": "Slawomir Stanczak", 
    "title": "Channel Selection for Network-assisted D2D Communication via No-Regret   Bandit Learning with Calibrated Forecasting", 
    "publish": "2014-04-28T17:12:02Z", 
    "summary": "We consider the distributed channel selection problem in the context of\ndevice-to-device (D2D) communication as an underlay to a cellular network.\nUnderlaid D2D users communicate directly by utilizing the cellular spectrum but\ntheir decisions are not governed by any centralized controller. Selfish D2D\nusers that compete for access to the resources construct a distributed system,\nwhere the transmission performance depends on channel availability and quality.\nThis information, however, is difficult to acquire. Moreover, the adverse\neffects of D2D users on cellular transmissions should be minimized. In order to\novercome these limitations, we propose a network-assisted distributed channel\nselection approach in which D2D users are only allowed to use vacant cellular\nchannels. This scenario is modeled as a multi-player multi-armed bandit game\nwith side information, for which a distributed algorithmic solution is\nproposed. The solution is a combination of no-regret learning and calibrated\nforecasting, and can be applied to a broad class of multi-player stochastic\nlearning problems, in addition to the formulated channel selection problem.\nAnalytically, it is established that this approach not only yields vanishing\nregret (in comparison to the global optimal solution), but also guarantees that\nthe empirical joint frequencies of the game converge to the set of correlated\nequilibria.", 
    "link": "http://arxiv.org/pdf/1404.7061v1", 
    "arxiv-id": "1404.7061v1"
},{
    "category": "cs.GT", 
    "author": "Gal Oshri", 
    "title": "Contracting Experts With Unknown Cost Structures", 
    "publish": "2014-04-29T05:33:27Z", 
    "summary": "We investigate the problem of a principal looking to contract an expert to\nprovide a probability forecast for a categorical event. We assume all experts\nhave a common public prior on the event's probability, but can form more\naccurate opinions by engaging in research. Various experts' research costs are\nunknown to the principal. We present a truthful and efficient mechanism for the\nprincipal's problem of contracting an expert. This results in the principal\ncontracting the best expert to do the work, and the principal's expected\nutility is equivalent to having the second best expert in-house. Our mechanism\nconnects scoring rules with auctions, a connection that is useful when\nobtaining new information requires costly research.", 
    "link": "http://arxiv.org/pdf/1404.7239v1", 
    "arxiv-id": "1404.7239v1"
},{
    "category": "cs.GT", 
    "author": "Ahuva Mualem", 
    "title": "Monotonicity, Revenue Equivalence and Budgets", 
    "publish": "2014-04-30T16:28:08Z", 
    "summary": "We study multidimensional mechanism design in a common scenario where players\nhave private information about their willingness to pay and their ability to\npay. We provide a complete characterization of dominant-strategy\nincentive-compatible direct mechanisms where over-reporting the budget is not\npossible. In several settings, reporting larger budgets can be made suboptimal\nwith a small randomized modification to the payments. We then derive a closely\nrelated partial characterization for the general case where players can\narbitrarily misreport their private budgets. Immediate applications of these\nresults include simple characterizations for mechanisms with publicly-known\nbudgets and for mechanisms without monetary transfers.\n  The celebrated revenue equivalence theorem states that the seller\"s revenue\nfor a broad class of standard auction formats and settings will be the same in\nequilibrium. Our main application is a revenue equivalence theorem for\nfinancially constrained bidders.", 
    "link": "http://arxiv.org/pdf/1404.7784v1", 
    "arxiv-id": "1404.7784v1"
},{
    "category": "cs.GT", 
    "author": "Yoram Bachrach", 
    "title": "Power Distribution in Randomized Weighted Voting: the Effects of the   Quota", 
    "publish": "2014-08-03T00:15:02Z", 
    "summary": "We study the Shapley value in weighted voting games. The Shapley value has\nbeen used as an index for measuring the power of individual agents in\ndecision-making bodies and political organizations, where decisions are made by\na majority vote process. We characterize the impact of changing the quota\n(i.e., the minimum number of seats in the parliament that are required to form\na coalition) on the Shapley values of the agents. Contrary to previous studies,\nwhich assumed that the agent weights (corresponding to the size of a caucus or\na political party) are fixed, we analyze new domains in which the weights are\nstochastically generated, modelling, for example, elections processes.\n  We examine a natural weight generation process: the Balls and Bins model,\nwith uniform as well as exponentially decaying probabilities. We also analyze\nweights that admit a super-increasing sequence, answering several open\nquestions pertaining to the Shapley values in such games.", 
    "link": "http://arxiv.org/pdf/1408.0442v1", 
    "arxiv-id": "1408.0442v1"
},{
    "category": "cs.GT", 
    "author": "Tuomas Sandholm", 
    "title": "Complexity of Mechanism Design", 
    "publish": "2014-08-07T06:26:34Z", 
    "summary": "The aggregation of conflicting preferences is a central problem in multiagent\nsystems. The key difficulty is that the agents may report their preferences\ninsincerely. Mechanism design is the art of designing the rules of the game so\nthat the agents are motivated to report their preferences truthfully and a\n(socially) desirable outcome is chosen. We propose an approach where a\nmechanism is automatically created for the preference aggregation setting at\nhand. This has several advantages, but the downside is that the mechanism\ndesign optimization problem needs to be solved anew each time. Focusing on\nsettings where side payments are not possible, we show that the mechanism\ndesign problem is NP-complete for deterministic mechanisms. This holds both for\ndominant-strategy implementation and for Bayes-Nash implementation. We then\nshow that if we allow randomized mechanisms, the mechanism design problem\nbecomes tractable. In other words, the coordinator can tackle the computational\ncomplexity introduced by its uncertainty about the agents preferences BY making\nthe agents face additional uncertainty.This comes at no loss, AND IN SOME cases\nat a gain, IN the(social) objective.", 
    "link": "http://arxiv.org/pdf/1408.1486v1", 
    "arxiv-id": "1408.1486v1"
},{
    "category": "cs.GT", 
    "author": "Jeremy Hoon", 
    "title": "Truthful Prioritization Schemes for Spectrum Sharing", 
    "publish": "2014-08-07T06:38:25Z", 
    "summary": "We design a protocol for dynamic prioritization of data on shared routers\nsuch as untethered 3G/4G devices. The mechanism prioritizes bandwidth in favor\nof users with the highest value, and is incentive compatible, so that users can\nsimply report their true values for network access. A revenue pooling mechanism\nalso aligns incentives for sellers, so that they will choose to use\nprioritization methods that retain the incentive properties on the buy-side. In\nthis way, the design allows for an open architecture. In addition to revenue\npooling, the technical contribution is to identify a class of stochastic demand\nmodels and a prioritization scheme that provides allocation monotonicity.\nSimulation results confirm efficiency gains from dynamic prioritization\nrelative to prior methods, as well as the effectiveness of revenue pooling.", 
    "link": "http://arxiv.org/pdf/1408.1492v1", 
    "arxiv-id": "1408.1492v1"
},{
    "category": "cs.GT", 
    "author": "Martin Bichler", 
    "title": "Fast Convex Decomposition for Truthful Social Welfare Approximation", 
    "publish": "2014-08-12T11:08:29Z", 
    "summary": "Approximating the optimal social welfare while preserving truthfulness is a\nwell studied problem in algorithmic mechanism design. Assuming that the social\nwelfare of a given mechanism design problem can be optimized by an integer\nprogram whose integrality gap is at most $\\alpha$, Lavi and Swamy~\\cite{Lavi11}\npropose a general approach to designing a randomized $\\alpha$-approximation\nmechanism which is truthful in expectation. Their method is based on\ndecomposing an optimal solution for the relaxed linear program into a convex\ncombination of integer solutions. Unfortunately, Lavi and Swamy's decomposition\ntechnique relies heavily on the ellipsoid method, which is notorious for its\npoor practical performance. To overcome this problem, we present an alternative\ndecomposition technique which yields an $\\alpha(1 + \\epsilon)$ approximation\nand only requires a quadratic number of calls to an integrality gap verifier.", 
    "link": "http://arxiv.org/pdf/1408.2690v1", 
    "arxiv-id": "1408.2690v1"
},{
    "category": "cs.GT", 
    "author": "Zhu Han", 
    "title": "Coalitional Graph Games for Popular Content Distribution in Cognitive   Radio VANETs", 
    "publish": "2014-08-14T02:12:06Z", 
    "summary": "Popular content distribution is one of the key services provided by vehicular\nad hoc networks (VANETs), in which a popular file is broadcasted by roadside\nunits (RSUs) to the on-board units (OBUs) driving through a particular area.\nDue to fast speed and deep fading, some file packets might be lost during the\nvehicle-to-roadside broadcasting stage. In this paper, we propose a\npeer-to-peer (P2P) approach to allow the OBUs to exchange data and complement\nthe missing packets. Specifically, we introduce a coalitional graph game to\nmodel the cooperation among OBUs and propose a coalition formation algorithm to\nimplement the P2P approach. Moreover, cognitive radio is utilized for\nvehicle-to-vehicle transmissions so that the P2P approach does not require\nadditional bandwidth. Simulation results show that the proposed approach\nperforms better in various conditions, relative to the non-cooperative\napproach, in which the OBUs share no information and simply response to any\ndata request from other OBUs.", 
    "link": "http://arxiv.org/pdf/1408.3181v1", 
    "arxiv-id": "1408.3181v1"
},{
    "category": "cs.GT", 
    "author": "Scott Deeann Chen", 
    "title": "A Crude Analysis of Twitch Plays Pokemon", 
    "publish": "2014-08-21T09:10:24Z", 
    "summary": "We model and study the game mechanisms and human behavior of the anarchy mode\nin Twitch Plays Pokemon with a pure-jump continuous-time Markov process. We\ncomputed the winning probability and expected game time for $1$ player and $N$\nplayers and identified when collaboration helps. A numerical plug-in example is\nalso provided.", 
    "link": "http://arxiv.org/pdf/1408.4925v1", 
    "arxiv-id": "1408.4925v1"
},{
    "category": "cs.GT", 
    "author": "Nicanor Quijano", 
    "title": "Incentives-Based Mechanism for Efficient Demand Response Programs", 
    "publish": "2014-08-22T17:31:02Z", 
    "summary": "In this work we investigate the inefficiency of the electricity system with\nstrategic agents. Specifically, we prove that without a proper control the\ntotal demand of an inefficient system is at most twice the total demand of the\noptimal outcome. We propose an incentives scheme that promotes optimal outcomes\nin the inefficient electricity market. The economic incentives can be seen as\nan indirect revelation mechanism that allocates resources using a\none-dimensional message space per resource to be allocated. The mechanism does\nnot request private information from users and is valid for any concave\ncustomer's valuation function. We propose a distributed implementation of the\nmechanism using population games and evaluate the performance of four popular\ndynamics methods in terms of the cost to implement the mechanism. We find that\nthe achievement of efficiency in strategic environments might be achieved at a\ncost, which is dependent on both the users' preferences and the dynamic\nevolution of the system. Some simulation results illustrate the ideas presented\nthroughout the paper.", 
    "link": "http://arxiv.org/pdf/1408.5366v3", 
    "arxiv-id": "1408.5366v3"
},{
    "category": "cs.GT", 
    "author": "Frank Neumann", 
    "title": "Solving Hard Control Problems in Voting Systems via Integer Programming", 
    "publish": "2014-08-26T02:51:50Z", 
    "summary": "Voting problems are central in the area of social choice. In this article, we\ninvestigate various voting systems and types of control of elections. We\npresent integer linear programming (ILP) formulations for a wide range of\nNP-hard control problems. Our ILP formulations are flexible in the sense that\nthey can work with an arbitrary number of candidates and voters. Using the\noff-the-shelf solver Cplex, we show that our approaches can manipulate\nelections with a large number of voters and candidates efficiently.", 
    "link": "http://arxiv.org/pdf/1408.5987v2", 
    "arxiv-id": "1408.5987v2"
},{
    "category": "cs.GT", 
    "author": "Aditya Parameswaran", 
    "title": "Finish Them!: Pricing Algorithms for Human Computation", 
    "publish": "2014-08-27T02:01:48Z", 
    "summary": "Given a batch of human computation tasks, a commonly ignored aspect is how\nthe price (i.e., the reward paid to human workers) of these tasks must be set\nor varied in order to meet latency or cost constraints. Often, the price is set\nup-front and not modified, leading to either a much higher monetary cost than\nneeded (if the price is set too high), or to a much larger latency than\nexpected (if the price is set too low). Leveraging a pricing model from prior\nwork, we develop algorithms to optimally set and then vary price over time in\norder to meet a (a) user-specified deadline while minimizing total monetary\ncost (b) user-specified monetary budget constraint while minimizing total\nelapsed time. We leverage techniques from decision theory (specifically, Markov\nDecision Processes) for both these problems, and demonstrate that our\ntechniques lead to upto 30\\% reduction in cost over schemes proposed in prior\nwork. Furthermore, we develop techniques to speed-up the computation, enabling\nusers to leverage the price setting algorithms on-the-fly.", 
    "link": "http://arxiv.org/pdf/1408.6292v1", 
    "arxiv-id": "1408.6292v1"
},{
    "category": "cs.GT", 
    "author": "Jamie Morgenstern", 
    "title": "Learning What's going on: reconstructing preferences and priorities from   opaque transactions", 
    "publish": "2014-08-27T21:37:51Z", 
    "summary": "We consider a setting where $n$ buyers, with combinatorial preferences over\n$m$ items, and a seller, running a priority-based allocation mechanism,\nrepeatedly interact. Our goal, from observing limited information about the\nresults of these interactions, is to reconstruct both the preferences of the\nbuyers and the mechanism of the seller. More specifically, we consider an\nonline setting where at each stage, a subset of the buyers arrive and are\nallocated items, according to some unknown priority that the seller has among\nthe buyers. Our learning algorithm observes only which buyers arrive and the\nallocation produced (or some function of the allocation, such as just which\nbuyers received positive utility and which did not), and its goal is to predict\nthe outcome for future subsets of buyers. For this task, the learning algorithm\nneeds to reconstruct both the priority among the buyers and the preferences of\neach buyer. We derive mistake bound algorithms for additive, unit-demand and\nsingle minded buyers. We also consider the case where buyers' utilities for a\nfixed bundle can change between stages due to different (observed) prices. Our\nalgorithms are efficient both in computation time and in the maximum number of\nmistakes (both polynomial in the number of buyers and items).", 
    "link": "http://arxiv.org/pdf/1408.6575v1", 
    "arxiv-id": "1408.6575v1"
},{
    "category": "cs.GT", 
    "author": "Anna Scaglione", 
    "title": "Generation bidding game with flexible demand", 
    "publish": "2014-08-28T11:35:11Z", 
    "summary": "For a simple model of price-responsive demand, we consider a deregulated\nelectricity marketplace wherein the grid (ISO, retailer-distributor) accepts\nbids per-unit supply from generators (simplified herein neither to consider\nstart-up/ramp-up expenses nor day-ahead or shorter-term load following) which\nare then averaged (by supply allocations via an economic dispatch) to a common\n\"clearing\" price borne by customers (irrespective of variations in\ntransmission/distribution or generation prices), i.e., the ISO does not\ncompensate generators based on their marginal costs. Rather, the ISO provides\nsufficient information for generators to sensibly adjust their bids.\nNotwithstanding our idealizations, the dispatch dynamics are complex. For a\nsimple benchmark power system, we find a price-symmetric Nash equilibrium\nthrough numerical experiments.", 
    "link": "http://arxiv.org/pdf/1408.6689v1", 
    "arxiv-id": "1408.6689v1"
},{
    "category": "cs.GT", 
    "author": "Iain McBride", 
    "title": "Integer programming methods for special college admissions problems", 
    "publish": "2014-08-28T22:56:48Z", 
    "summary": "We develop Integer Programming (IP) solutions for some special college\nadmission problems arising from the Hungarian higher education admission\nscheme. We focus on four special features, namely the solution concept of\nstable score-limits, the presence of lower and common quotas, and paired\napplications. We note that each of the latter three special feature makes the\ncollege admissions problem NP-hard to solve. Currently, a heuristic based on\nthe Gale-Shapley algorithm is being used in the application. The IP methods\nthat we propose are not only interesting theoretically, but may also serve as\nan alternative solution concept for this practical application, and also for\nother ones.", 
    "link": "http://arxiv.org/pdf/1408.6878v2", 
    "arxiv-id": "1408.6878v2"
},{
    "category": "cs.GT", 
    "author": "Ian A. Kash", 
    "title": "Elicitation for Aggregation", 
    "publish": "2014-10-01T20:11:04Z", 
    "summary": "We study the problem of eliciting and aggregating probabilistic information\nfrom multiple agents. In order to successfully aggregate the predictions of\nagents, the principal needs to elicit some notion of confidence from agents,\ncapturing how much experience or knowledge led to their predictions. To\nformalize this, we consider a principal who wishes to elicit predictions about\na random variable from a group of Bayesian agents, each of whom have privately\nobserved some independent samples of the random variable, and hopes to\naggregate the predictions as if she had directly observed the samples of all\nagents. Leveraging techniques from Bayesian statistics, we represent confidence\nas the number of samples an agent has observed, which is quantified by a\nhyperparameter from a conjugate family of prior distributions. This then allows\nus to show that if the principal has access to a few samples, she can achieve\nher aggregation goal by eliciting predictions from agents using proper scoring\nrules. In particular, if she has access to one sample, she can successfully\naggregate the agents' predictions if and only if every posterior predictive\ndistribution corresponds to a unique value of the hyperparameter. Furthermore,\nthis uniqueness holds for many common distributions of interest. When this\nuniqueness property does not hold, we construct a novel and intuitive mechanism\nwhere a principal with two samples can elicit and optimally aggregate the\nagents' predictions.", 
    "link": "http://arxiv.org/pdf/1410.0375v1", 
    "arxiv-id": "1410.0375v1"
},{
    "category": "cs.GT", 
    "author": "Shreyas Sekar", 
    "title": "Price Competition in Networked Markets: How do monopolies impact social   welfare?", 
    "publish": "2014-10-05T05:00:41Z", 
    "summary": "We study the efficiency of allocations in large markets with a network\nstructure where every seller owns an edge in a graph and every buyer desires a\npath connecting some nodes. While it is known that stable allocations in such\nsettings can be very inefficient, the exact properties of equilibria in markets\nwith multiple sellers are not fully understood even in single-source\nsingle-sink networks. In this work, we show that for a large class of natural\nbuyer demand functions, we are guaranteed the existence of an equilibrium with\nseveral desirable properties. The crucial insight that we gain into the\nequilibrium structure allows us to obtain tight bounds on efficiency in terms\nof the various parameters governing the market, especially the number of\nmonopolies M. All of our efficiency results extend to markets without the\nnetwork structure.\n  While it is known that monopolies can cause large inefficiencies in general,\nour main results for single-source single-sink networks indicate that for\nseveral natural demand functions the efficiency only drops linearly with M. For\nexample, for concave demand we prove that the efficiency loss is at most a\nfactor 1+M/2 from the optimum, for demand with monotone hazard rate it is at\nmost 1+M, and for polynomial demand the efficiency decreases logarithmically\nwith M. In contrast to previous work that showed that monopolies may adversely\naffect welfare, our main contribution is showing that monopolies may not be as\n`evil' as they are made out to be; the loss in efficiency is bounded in many\nnatural markets. Finally, we consider more general, multiple-source networks\nand show that in the absence of monopolies, mild assumptions on the network\ntopology guarantee an equilibrium that maximizes social welfare.", 
    "link": "http://arxiv.org/pdf/1410.1113v3", 
    "arxiv-id": "1410.1113v3"
},{
    "category": "cs.GT", 
    "author": "Salil Vadhan", 
    "title": "Privacy Games", 
    "publish": "2014-10-07T21:31:59Z", 
    "summary": "The problem of analyzing the effect of privacy concerns on the behavior of\nselfish utility-maximizing agents has received much attention lately. Privacy\nconcerns are often modeled by altering the utility functions of agents to\nconsider also their privacy loss. Such privacy aware agents prefer to take a\nrandomized strategy even in very simple games in which non-privacy aware agents\nplay pure strategies. In some cases, the behavior of privacy aware agents\nfollows the framework of Randomized Response, a well-known mechanism that\npreserves differential privacy.\n  Our work is aimed at better understanding the behavior of agents in settings\nwhere their privacy concerns are explicitly given. We consider a toy setting\nwhere agent A, in an attempt to discover the secret type of agent B, offers B a\ngift that one type of B agent likes and the other type dislikes. As opposed to\nprevious works, B's incentive to keep her type a secret isn't the result of\n\"hardwiring\" B's utility function to consider privacy, but rather takes the\nform of a payment between B and A. We investigate three different types of\npayment functions and analyze B's behavior in each of the resulting games. As\nwe show, under some payments, B's behavior is very different than the behavior\nof agents with hardwired privacy concerns and might even be deterministic.\nUnder a different payment we show that B's BNE strategy does fall into the\nframework of Randomized Response.", 
    "link": "http://arxiv.org/pdf/1410.1920v1", 
    "arxiv-id": "1410.1920v1"
},{
    "category": "cs.GT", 
    "author": "Arkadii Slinko", 
    "title": "The single-crossing property on a tree", 
    "publish": "2014-10-08T20:44:06Z", 
    "summary": "We generalize the classical single-crossing property to single-crossing\nproperty on trees and obtain new ways to construct Condorcet domains which are\nsets of linear orders which possess the property that every profile composed\nfrom those orders have transitive majority relation. We prove that for any tree\nthere exist profiles that are single-crossing on that tree; moreover, that tree\nis minimal in this respect for at least one such profile. Finally, we provide a\npolynomial-time algorithm to recognize whether or not a given profile is\nsingle-crossing with respect to some tree. We also show that finding winners\nfor Chamberlin-Courant rule is polynomial for profiles that are single-crossing\non trees.", 
    "link": "http://arxiv.org/pdf/1410.2272v1", 
    "arxiv-id": "1410.2272v1"
},{
    "category": "cs.GT", 
    "author": "Shanghua Teng", 
    "title": "Signaling in Quasipolynomial time", 
    "publish": "2014-10-11T23:26:10Z", 
    "summary": "Strategic interactions often take place in an environment rife with\nuncertainty. As a result, the equilibrium of a game is intimately related to\nthe information available to its players. The \\emph{signaling problem}\nabstracts the task faced by an informed \"market maker\", who must choose how to\nreveal information in order to effect a desirable equilibrium.\n  In this paper, we consider two fundamental signaling problems: one for\nabstract normal form games, and the other for single item auctions. For the\nformer, we consider an abstract class of objective functions which includes the\nsocial welfare and weighted combinations of players' utilities, and for the\nlatter we restrict our attention to the social welfare objective and to\nsignaling schemes which are constrained in the number of signals used. For both\nproblems, we design approximation algorithms for the signaling problem which\nrun in quasi-polynomial time under various conditions, extending and\ncomplementing the results of various recent works on the topic.\n  Underlying each of our results is a \"meshing scheme\" which effectively\novercomes the \"curse of dimensionality\" and discretizes the space of\n\"essentially different\" posterior beliefs -- in the sense of inducing\n\"essentially different\" equilibria. This is combined with an algorithm for\noptimally assembling a signaling scheme as a convex combination of such\nbeliefs. For the normal form game setting, the meshing scheme leads to a convex\npartition of the space of posterior beliefs and this assembly procedure is\nreduced to a linear program, and in the auction setting the assembly procedure\nis reduced to submodular function maximization.", 
    "link": "http://arxiv.org/pdf/1410.3033v1", 
    "arxiv-id": "1410.3033v1"
},{
    "category": "cs.GT", 
    "author": "Christopher A. Wilkens", 
    "title": "GSP with General Independent Click-Through-Rates", 
    "publish": "2014-10-12T04:50:44Z", 
    "summary": "The popular generalized second price (GSP) auction for sponsored search is\nbuilt upon a separable model of click-through-rates that decomposes the\nlikelihood of a click into the product of a \"slot effect\" and an \"advertiser\neffect\" --- if the first slot is twice as good as the second for some bidder,\nthen it is twice as good for everyone. Though appealing in its simplicity, this\nmodel is quite suspect in practice. A wide variety of factors including\nexternalities and budgets have been studied that can and do cause it to be\nviolated. In this paper we adopt a view of GSP as an iterated second price\nauction (see, e.g., Milgrom 2010) and study how the most basic violation of\nseparability --- position dependent, arbitrary public click-through-rates that\ndo not decompose --- affects results from the foundational analysis of GSP\n(Varian 2007, Edelman et al. 2007). For the two-slot setting we prove that for\narbitrary click-through-rates, for arbitrary bidder values, an efficient\npure-strategy equilibrium always exists; however, without separability there\nalways exist values such that the VCG outcome and payments cannot be realized\nby any bids, in equilibrium or otherwise. The separability assumption is\ntherefore necessary in the two-slot case to match the payments of VCG but not\nfor efficiency. We moreover show that without separability, generic existence\nof efficient equilibria is sensitive to the choice of tie-breaking rule, and\nwhen there are more than two slots, no (bid-independent) tie-breaking rule\nyields the positive result. In light of this we suggest alternative mechanisms\nthat trade the simplicity of GSP for better equilibrium properties when there\nare three or more slots.", 
    "link": "http://arxiv.org/pdf/1410.3048v1", 
    "arxiv-id": "1410.3048v1"
},{
    "category": "cs.GT", 
    "author": "Dominik Wojtczak", 
    "title": "Making the Best of Limited Memory in Multi-Player Discounted Sum Games", 
    "publish": "2014-10-15T18:20:42Z", 
    "summary": "In this paper, we establish the existence of optimal bounded memory strategy\nprofiles in multi-player discounted sum games. We introduce a non-deterministic\napproach to compute optimal strategy profiles with bounded memory. Our approach\ncan be used to obtain optimal rewards in a setting where a powerful player\nselects the strategies of all players for Nash and leader equilibria, where in\nleader equilibria the Nash condition is waived for the strategy of this\npowerful player. The resulting strategy profiles are optimal for this player\namong all strategy profiles that respect the given memory bound, and the\nrelated decision problem is NP-complete. We also provide simple examples, which\nshow that having more memory will improve the optimal strategy profile, and\nthat sufficient memory to obtain optimal strategy profiles cannot be inferred\nfrom the structure of the game.", 
    "link": "http://arxiv.org/pdf/1410.4154v3", 
    "arxiv-id": "1410.4154v3"
},{
    "category": "cs.GT", 
    "author": "Monique Becker", 
    "title": "Coalition Formation Algorithm of Prosumers in a Smart Grid Environment", 
    "publish": "2014-10-31T15:32:12Z", 
    "summary": "In a smart grid environment, we study coalition formation of prosumers that\naim at entering the energy market. It is paramount for the grid operation that\nthe energy producers are able to sustain the grid demand in terms of stability\nand minimum production requirement. We design an algorithm that seeks to form\ncoalitions that will meet both of these requirements: a minimum energy level\nfor the coalitions and a steady production level which leads to finding\nuncorrelated sources of energy to form a coalition. We propose an algorithm\nthat uses graph tools such as correlation graphs or clique percolation to form\ncoalitions that meet such complex constraints. We validate the algorithm\nagainst a random procedure and show that, it not only performs better in term\nof social welfare for the power grid, but also that it is more robust against\nunforeseen production variations due to changing weather conditions for\ninstance.", 
    "link": "http://arxiv.org/pdf/1410.8776v1", 
    "arxiv-id": "1410.8776v1"
},{
    "category": "cs.GT", 
    "author": "Ariel D. Procaccia", 
    "title": "Verifiably Truthful Mechanisms", 
    "publish": "2014-11-29T00:51:23Z", 
    "summary": "It is typically expected that if a mechanism is truthful, then the agents\nwould, indeed, truthfully report their private information. But why would an\nagent believe that the mechanism is truthful? We wish to design truthful\nmechanisms, whose truthfulness can be verified efficiently (in the\ncomputational sense). Our approach involves three steps: (i) specifying the\nstructure of mechanisms, (ii) constructing a verification algorithm, and (iii)\nmeasuring the quality of verifiably truthful mechanisms. We demonstrate this\napproach using a case study: approximate mechanism design without money for\nfacility location.", 
    "link": "http://arxiv.org/pdf/1412.0056v1", 
    "arxiv-id": "1412.0056v1"
},{
    "category": "cs.GT", 
    "author": "Bernhard von Stengel", 
    "title": "Recursive Inspection Games", 
    "publish": "2014-11-29T17:45:21Z", 
    "summary": "We consider a sequential inspection game where an inspector uses a limited\nnumber of inspections over a larger number of time periods to detect a\nviolation (an illegal act) of an inspectee. Compared with earlier models, we\nallow varying rewards to the inspectee for successful violations. As one\npossible example, the most valuable reward may be the completion of a sequence\nof thefts of nuclear material needed to build a nuclear bomb. The inspectee can\nobserve the inspector, but the inspector can only determine if a violation\nhappens during a stage where he inspects, which terminates the game; otherwise\nthe game continues. Under reasonable assumptions for the payoffs, the\ninspector's strategy is independent of the number of successful violations.\nThis allows to apply a recursive description of the game, even though this\nnormally assumes fully informed players after each stage. The resulting\nrecursive equation in three variables for the equilibrium payoff of the game,\nwhich generalizes several other known equations of this kind, is solved\nexplicitly in terms of sums of binomial coefficients. We also extend this\napproach to non-zero-sum games and, similar to Maschler (1966), \"inspector\nleadership\" where the inspector commits to (the same) randomized inspection\nschedule, but the inspectee acts legally (rather than mixes as in the\nsimultaneous game) as long as inspections remain.", 
    "link": "http://arxiv.org/pdf/1412.0129v2", 
    "arxiv-id": "1412.0129v2"
},{
    "category": "cs.GT", 
    "author": "Vittorio Bil\u00f2", 
    "title": "On the Robustness of the Approximate Price of Anarchy in Generalized   Congestion Games", 
    "publish": "2014-12-02T10:30:27Z", 
    "summary": "One of the main results shown through Roughgarden's notions of smooth games\nand robust price of anarchy is that, for any sum-bounded utilitarian social\nfunction, the worst-case price of anarchy of coarse correlated equilibria\ncoincides with that of pure Nash equilibria in the class of weighted congestion\ngames with non-negative and non-decreasing latency functions and that such a\nvalue can always be derived through the, so called, smoothness argument. We\nsignificantly extend this result by proving that, for a variety of (even\nnon-sum-bounded) utilitarian and egalitarian social functions and for a broad\ngeneralization of the class of weighted congestion games with non-negative (and\npossibly decreasing) latency functions, the worst-case price of anarchy of\n$\\epsilon$-approximate coarse correlated equilibria still coincides with that\nof $\\epsilon$-approximate pure Nash equilibria, for any $\\epsilon\\geq 0$. As a\nbyproduct of our proof, it also follows that such a value can always be\ndetermined by making use of the primal-dual method we introduced in a previous\nwork. It is important to note that our scenario of investigation is beyond the\nscope of application of the robust price of anarchy (for as it is currently\ndefined), so that our result seems unlikely to be alternatively proved via the\nsmoothness framework.", 
    "link": "http://arxiv.org/pdf/1412.0845v1", 
    "arxiv-id": "1412.0845v1"
},{
    "category": "cs.GT", 
    "author": "Sigal Oren", 
    "title": "Dynamic Models of Reputation and Competition in Job-Market Matching", 
    "publish": "2014-12-05T16:55:24Z", 
    "summary": "A fundamental decision faced by a firm hiring employees - and a familiar one\nto anyone who has dealt with the academic job market, for example - is deciding\nwhat caliber of candidates to pursue. Should the firm try to increase its\nreputation by making offers to higher-quality candidates, despite the risk that\nthe candidates might reject the offers and leave the firm empty-handed? Or\nshould it concentrate on weaker candidates who are more likely to accept the\noffer? The question acquires an added level of complexity once we take into\naccount the effect one hiring cycle has on the next: hiring better employees in\nthe current cycle increases the firm's reputation, which in turn increases its\nattractiveness for higher-quality candidates in the next hiring cycle. These\nconsiderations introduce an interesting temporal dynamic aspect to the rich\nline of research on matching models for job markets, in which long-range\nplanning and evolving reputational effects enter into the strategic decisions\nmade by competing firms.\n  We develop a model based on two competing firms to try capturing as cleanly\nas possible the elements that we believe constitute the strategic tension at\nthe core of the problem: the trade-off between short-term recruiting success\nand long-range reputation-building; the inefficiency that results from\nunderemployment of people who are not ranked highest; and the influence of\nearlier accidental outcomes on long-term reputations.\n  Our model exhibits all these phenomena in a stylized setting, governed by a\nparameter q that captures the difference in strength between the two top\ncandidates in each hiring cycle. We show that when q is relatively low the\nefficiency of the job market is improved by long-range reputational effects,\nbut when q is relatively high, taking future reputations into account can\nsometimes reduce the efficiency.", 
    "link": "http://arxiv.org/pdf/1412.2062v1", 
    "arxiv-id": "1412.2062v1"
},{
    "category": "cs.GT", 
    "author": "Nimrod Talmon", 
    "title": "Multi-Player Diffusion Games on Graph Classes", 
    "publish": "2014-12-08T12:50:17Z", 
    "summary": "We study competitive diffusion games on graphs introduced by Alon et al. [1]\nto model the spread of influence in social networks. Extending results of\nRoshanbin [8] for two players, we investigate the existence of pure Nash\nequilibria for at least three players on different classes of graphs including\npaths, cycles, grid graphs and hypercubes; as a main contribution, we answer an\nopen question proving that there is no Nash equilibrium for three players on (m\nx n) grids with min(m, n) >= 5. Further, extending results of Etesami and Basar\n[3] for two players, we prove the existence of pure Nash equilibria for four\nplayers on every d-dimensional hypercube.", 
    "link": "http://arxiv.org/pdf/1412.2544v2", 
    "arxiv-id": "1412.2544v2"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "Algorithmic Rationality: Game Theory with Costly Computation", 
    "publish": "2014-12-09T15:24:42Z", 
    "summary": "We develop a general game-theoretic framework for reasoning about strategic\nagents performing possibly costly computation. In this framework, many\ntraditional game-theoretic results (such as the existence of a Nash\nequilibrium) no longer hold. Nevertheless, we can use the framework to provide\npsychologically appealing explanations of observed behavior in well-studied\ngames (such as finitely repeated prisoner's dilemma and rock-paper-scissors).\nFurthermore, we provide natural conditions on games sufficient to guarantee\nthat equilibria exist.", 
    "link": "http://arxiv.org/pdf/1412.2993v1", 
    "arxiv-id": "1412.2993v1"
},{
    "category": "cs.GT", 
    "author": "Saeed Seddighin", 
    "title": "Revenue Maximization for Selling Multiple Correlated Items", 
    "publish": "2014-12-10T02:52:57Z", 
    "summary": "We study the problem of selling $n$ items to a single buyer with an additive\nvaluation function. We consider the valuation of the items to be correlated,\ni.e., desirabilities of the buyer for the items are not drawn independently.\nIdeally, the goal is to design a mechanism to maximize the revenue. However, it\nhas been shown that a revenue optimal mechanism might be very complicated and\nas a result inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that achieves a constant fraction of the optimal\nrevenue. Babaioff et al. propose a simple mechanism that achieves a constant\nfraction of the optimal revenue for independent setting with a single additive\nbuyer. However, they leave the following problem as an open question: \"Is there\na simple, approximately optimal mechanism for a single additive buyer whose\nvalue for $n$ items is sampled from a common base-value distribution?\"\n  Babaioff et al. show a constant approximation factor of the optimal revenue\ncan be achieved by either selling the items separately or as a whole bundle in\nthe independent setting. We show a similar result for the correlated setting\nwhen the desirabilities of the buyer are drawn from a common base-value\ndistribution. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we propose a modified version of this lemma\nwhich is applicable to the correlated settings as well. Although we apply this\ntechnique to show the proposed mechanism can guarantee a constant fraction of\nthe optimal revenue in a very weak correlation, this method alone can not\ndirectly show the efficiency of the mechanism in stronger correlations.", 
    "link": "http://arxiv.org/pdf/1412.3187v2", 
    "arxiv-id": "1412.3187v2"
},{
    "category": "cs.GT", 
    "author": "Jay Sethuraman", 
    "title": "Strategyproof Mechanisms for One-Dimensional Hybrid and Obnoxious   Facility Location", 
    "publish": "2014-12-10T19:08:55Z", 
    "summary": "We consider a strategic variant of the facility location problem. We would\nlike to locate a facility on a closed interval. There are n agents located on\nthat interval, divided into two types: type 1 agents, who wish for the facility\nto be as far from them as possible, and type 2 agents, who wish for the\nfacility to be as close to them as possible. Our goal is to maximize a form of\naggregated social benefit: maxisum- the sum of the agents' utilities, or the\negalitarian objective- the minimal agent utility. The strategic aspect of the\nproblem is that the agents' locations are not known to us, but rather reported\nto us by the agents- an agent might misreport his location in an attempt to\nmove the facility away from or towards to his true location. We therefore\nrequire the facility-locating mechanism to be strategyproof, namely that\nreporting truthfully is a dominant strategy for each agent. As simply\nmaximizing the social benefit is generally not strategyproof, our goal is to\ndesign strategyproof mechanisms with good approximation ratios.\n  For the maxisum objective, in the deterministic setting, we provide a\nbest-possible 3- approximate strategyproof mechanism; in the randomized\nsetting, we provide a 23/13- approximate strategyproof mechanism and a lower\nbound of \\frac{2}{\\sqrt{3}}. For the egalitarian objective, we provide a lower\nbound of 3/2 in the randomized setting, and show that no bounded approximation\nratio is attainable in the deterministic setting. To obtain our deterministic\nlower bounds, we characterize all deterministic strategyproof mechanisms when\nall agents are of type 1. Finally, we consider a generalized model that allows\nan agent to control more than one location, and provide best-possible 3- and\n3/2- approximate strategyproof mechanisms for maxisum, in the deterministic and\nrandomized settings respectively, when only type 1 agents are present.", 
    "link": "http://arxiv.org/pdf/1412.3414v2", 
    "arxiv-id": "1412.3414v2"
},{
    "category": "cs.GT", 
    "author": "Warut Suksompong", 
    "title": "An Ordinal Minimax Theorem", 
    "publish": "2014-12-13T06:54:17Z", 
    "summary": "In the early 1950s Lloyd Shapley proposed an ordinal and set-valued solution\nconcept for zero-sum games called \\emph{weak saddle}. We show that all weak\nsaddles of a given zero-sum game are interchangeable and equivalent. As a\nconsequence, every such game possesses a unique set-based value.", 
    "link": "http://arxiv.org/pdf/1412.4198v5", 
    "arxiv-id": "1412.4198v5"
},{
    "category": "cs.GT", 
    "author": "Daniel Schmand", 
    "title": "Sharing Non-Anonymous Costs of Multiple Resources Optimally", 
    "publish": "2014-12-15T04:17:41Z", 
    "summary": "In cost sharing games, the existence and efficiency of pure Nash equilibria\nfundamentally depends on the method that is used to share the resources' costs.\nWe consider a general class of resource allocation problems in which a set of\nresources is used by a heterogeneous set of selfish users. The cost of a\nresource is a (non-decreasing) function of the set of its users. Under the\nassumption that the costs of the resources are shared by uniform cost sharing\nprotocols, i.e., protocols that use only local information of the resource's\ncost structure and its users to determine the cost shares, we exactly quantify\nthe inefficiency of the resulting pure Nash equilibria. Specifically, we show\ntight bounds on prices of stability and anarchy for games with only submodular\nand only supermodular cost functions, respectively, and an asymptotically tight\nbound for games with arbitrary set-functions. While all our upper bounds are\nattained for the well-known Shapley cost sharing protocol, our lower bounds\nhold for arbitrary uniform cost sharing protocols and are even valid for games\nwith anonymous costs, i.e., games in which the cost of each resource only\ndepends on the cardinality of the set of its users.", 
    "link": "http://arxiv.org/pdf/1412.4456v2", 
    "arxiv-id": "1412.4456v2"
},{
    "category": "cs.GT", 
    "author": "Qinxuan Pan", 
    "title": "A Counter-Example to Karlin's Strong Conjecture for Fictitious Play", 
    "publish": "2014-12-16T00:24:25Z", 
    "summary": "Fictitious play is a natural dynamic for equilibrium play in zero-sum games,\nproposed by [Brown 1949], and shown to converge by [Robinson 1951]. Samuel\nKarlin conjectured in 1959 that fictitious play converges at rate\n$O(1/\\sqrt{t})$ with the number of steps $t$. We disprove this conjecture\nshowing that, when the payoff matrix of the row player is the $n \\times n$\nidentity matrix, fictitious play may converge with rate as slow as\n$\\Omega(t^{-1/n})$.", 
    "link": "http://arxiv.org/pdf/1412.4840v2", 
    "arxiv-id": "1412.4840v2"
},{
    "category": "cs.GT", 
    "author": "Anthi Orfanou", 
    "title": "On the Complexity of Nash Equilibria in Anonymous Games", 
    "publish": "2014-12-17T23:54:25Z", 
    "summary": "We show that the problem of finding an {\\epsilon}-approximate Nash\nequilibrium in an anonymous game with seven pure strategies is complete in\nPPAD, when the approximation parameter {\\epsilon} is exponentially small in the\nnumber of players.", 
    "link": "http://arxiv.org/pdf/1412.5681v1", 
    "arxiv-id": "1412.5681v1"
},{
    "category": "cs.GT", 
    "author": "Chun Ye", 
    "title": "A Note on the Assignment Problem with Uniform Preferences", 
    "publish": "2014-10-16T12:38:25Z", 
    "summary": "Motivated by a problem of scheduling unit-length jobs with weak preferences\nover time-slots, the random assignment problem (also called the house\nallocation problem) is considered on a uniform preference domain. For the\nsubdomain in which preferences are strict except possibly for the class of\nunacceptable objects, Bogomolnaia and Moulin characterized the probabilistic\nserial mechanism as the only mechanism satisfying equal treatment of equals,\nstrategyproofness, and ordinal efficiency. The main result in this paper is\nthat the natural extension of the probabilistic serial mechanism to the domain\nof weak, but uniform, preferences fails strategyproofness, but so does every\nother mechanism that is ordinally efficient and treats equals equally. If\nenvy-free assignments are required, then any (probabilistic or deterministic)\nmechanism that guarantees an ex post efficient outcome must fail even a weak\nform of strategyproofness.", 
    "link": "http://arxiv.org/pdf/1412.6078v1", 
    "arxiv-id": "1412.6078v1"
},{
    "category": "cs.GT", 
    "author": "Rafael Pass", 
    "title": "Sequential Equilibrium in Computational Games", 
    "publish": "2014-12-19T14:53:21Z", 
    "summary": "We examine sequential equilibrium in the context of computational games,\nwhere agents are charged for computation. In such games, an agent can\nrationally choose to forget, so issues of imperfect recall arise. In this\nsetting, we consider two notions of sequential equilibrium. One is an ex ante\nnotion, where a player chooses his strategy before the game starts and is\ncommitted to it, but chooses it in such a way that it remains optimal even off\nthe equilibrium path. The second is an interim notion, where a player can\nreconsider at each information set whether he is doing the \"right\" thing, and\nif not, can change his strategy. The two notions agree in games of perfect\nrecall, but not in games of imperfect recall. Although the interim notion seems\nmore appealing, \\fullv{Halpern and Pass [2011] argue that there are some deep\nconceptual problems with it in standard games of imperfect recall. We show that\nthe conceptual problems largely disappear in the computational setting.\nMoreover, in this setting, under natural assumptions, the two notions coincide.", 
    "link": "http://arxiv.org/pdf/1412.6361v1", 
    "arxiv-id": "1412.6361v1"
},{
    "category": "cs.GT", 
    "author": "Stefano Turchetta", 
    "title": "Query Complexity of Approximate Equilibria in Anonymous Games", 
    "publish": "2014-12-19T17:45:12Z", 
    "summary": "We study the computation of equilibria of anonymous games, via algorithms\nthat may proceed via a sequence of adaptive queries to the game's payoff\nfunction, assumed to be unknown initially. The general topic we consider is\n\\emph{query complexity}, that is, how many queries are necessary or sufficient\nto compute an exact or approximate Nash equilibrium.\n  We show that exact equilibria cannot be found via query-efficient algorithms.\nWe also give an example of a 2-strategy, 3-player anonymous game that does not\nhave any exact Nash equilibrium in rational numbers. However, more positive\nquery-complexity bounds are attainable if either further symmetries of the\nutility functions are assumed or we focus on approximate equilibria. We\ninvestigate four sub-classes of anonymous games previously considered by\n\\cite{bfh09, dp14}.\n  Our main result is a new randomized query-efficient algorithm that finds a\n$O(n^{-1/4})$-approximate Nash equilibrium querying $\\tilde{O}(n^{3/2})$\npayoffs and runs in time $\\tilde{O}(n^{3/2})$. This improves on the running\ntime of pre-existing algorithms for approximate equilibria of anonymous games,\nand is the first one to obtain an inverse polynomial approximation in\npoly-time. We also show how this can be utilized as an efficient\npolynomial-time approximation scheme (PTAS). Furthermore, we prove that\n$\\Omega(n \\log{n})$ payoffs must be queried in order to find any\n$\\epsilon$-well-supported Nash equilibrium, even by randomized algorithms.", 
    "link": "http://arxiv.org/pdf/1412.6455v3", 
    "arxiv-id": "1412.6455v3"
},{
    "category": "cs.GT", 
    "author": "Joseph Y. Halpern", 
    "title": "Cooperative Equilibrium: A solution predicting cooperative play", 
    "publish": "2014-12-21T04:36:42Z", 
    "summary": "Nash equilibrium (NE) assumes that players always make a best response.\nHowever, this is not always true; sometimes people cooperate even it is not a\nbest response to do so. For example, in the Prisoner's Dilemma, people often\ncooperate. Are there rules underlying cooperative behavior? In an effort to\nanswer this question, we propose a new equilibrium concept: perfect cooperative\nequilibrium (PCE), and two related variants: max-PCE and cooperative\nequilibrium. PCE may help explain players' behavior in games where cooperation\nis observed in practice. A player's payoff in a PCE is at least as high as in\nany NE. However, a PCE does not always exist. We thus consider {\\alpha}-PCE,\nwhere {\\alpha} takes into account the degree of cooperation; a PCE is a 0-PCE.\nEvery game has a Pareto-optimal max-PCE (M-PCE); that is, an {\\alpha}-PCE for a\nmaximum {\\alpha}. We show that M-PCE does well at predicting behavior in quite\na few games of interest. We also consider cooperative equilibrium (CE), another\ngeneralization of PCE that takes punishment into account. Interestingly, all\nPareto-optimal M-PCE are CE. We prove that, in 2-player games, a PCE (if it\nexists), a M-PCE, and a CE can all be found in polynomial time using bilinear\nprogramming. This is a contrast to Nash equilibrium, which is PPAD complete\neven in 2-player games [Chen, Deng, and Teng 2009]. We compare M-PCE to the\ncoco value [Kalai and Kalai 2009], another solution concept that tries to\ncapture cooperation, both axiomatically and in terms of an algebraic\ncharacterization, and show that the two are closely related, despite their very\ndifferent definitions.", 
    "link": "http://arxiv.org/pdf/1412.6722v1", 
    "arxiv-id": "1412.6722v1"
},{
    "category": "cs.GT", 
    "author": "Ilya Pollak", 
    "title": "Secondary Spectrum Auctions for Markets with Communication Constraints", 
    "publish": "2014-12-23T04:35:23Z", 
    "summary": "Auctions have been proposed as a way to provide economic incentives for\nprimary users to dynamically allocate unused spectrum to other users in need of\nit. Previously proposed schemes do not take into account the fact that the\npower constraints of users might prevent them from transmitting their bid\nprices to the auctioneer with high precision and that transmitted bid prices\nmust travel through a noisy channel. These schemes also have very high\noverheads which cannot be accommodated in wireless standards. We propose\nauction schemes where a central clearing authority auctions spectrum to users\nwho bid for it, while taking into account quantization of prices, overheads in\nbid revelation, and noise in the channel explicitly. Our schemes are closely\nrelated to channel output feedback problems and, specifically, to the technique\nof posterior matching. We consider several scenarios where the objective of the\nclearing authority is to award spectrum to the bidders who value spectrum the\nmost. We prove theoretically that this objective is asymptotically attained by\nour scheme when the bidders are non-strategic with constant bids. We propose\nseparate schemes to make strategic users reveal their private values\ntruthfully, to auction multiple sub-channels among strategic users, and to\ntrack slowly time-varying bid prices. Our simulations illustrate the optimality\nof our schemes for constant bid prices, and also demonstrate the effectiveness\nof our tracking algorithm for slowly time-varying bids.", 
    "link": "http://arxiv.org/pdf/1412.7250v1", 
    "arxiv-id": "1412.7250v1"
},{
    "category": "cs.GT", 
    "author": "Edith Elkind", 
    "title": "Campaign Management under Approval-Driven Voting Rules", 
    "publish": "2015-01-02T11:34:58Z", 
    "summary": "Approval-like voting rules, such as Sincere-Strategy Preference-Based\nApproval voting (SP-AV), the Bucklin rule (an adaptive variant of $k$-Approval\nvoting), and the Fallback rule (an adaptive variant of SP-AV) have many\ndesirable properties: for example, they are easy to understand and encourage\nthe candidates to choose electoral platforms that have a broad appeal. In this\npaper, we investigate both classic and parameterized computational complexity\nof electoral campaign management under such rules. We focus on two methods that\ncan be used to promote a given candidate: asking voters to move this candidate\nupwards in their preference order or asking them to change the number of\ncandidates they approve of. We show that finding an optimal campaign management\nstrategy of the first type is easy for both Bucklin and Fallback. In contrast,\nthe second method is computationally hard even if the degree to which we need\nto affect the votes is small. Nevertheless, we identify a large class of\nscenarios that admit fixed-parameter tractable algorithms.", 
    "link": "http://arxiv.org/pdf/1501.00387v1", 
    "arxiv-id": "1501.00387v1"
},{
    "category": "cs.GT", 
    "author": "Yanfeng Ouyang", 
    "title": "Parking Space Management via Dynamic Performance-Based Pricing", 
    "publish": "2015-01-04T05:35:11Z", 
    "summary": "In congested urban areas, it remains a pressing challenge to reduce\nunnecessary vehicle circling for parking while at the same time maximize\nparking space utilization. In observance of new information technologies that\nhave become readily accessible to drivers and parking agencies, we develop a\ndynamic non-cooperative bi-level model (i.e. Stackelberg leader-follower game)\nto set parking prices in real-time for effective parking access and space\nutilization. The model is expected to fit into an integrated parking pricing\nand management system, where parking reservations and transactions are\nfacilitated by sensing and informatics infrastructures, that ensures the\navailability of convenient spaces at equilibrium market prices. It is shown\nwith numerical examples that the proposed dynamic parking pricing model has the\npotential to virtually eliminate vehicle circling for parking, which results in\nsignificant reduction in adverse socioeconomic externalities such as traffic\ncongestion and emissions.", 
    "link": "http://arxiv.org/pdf/1501.00638v1", 
    "arxiv-id": "1501.00638v1"
},{
    "category": "cs.GT", 
    "author": "Yevgeniy Vorobeychik", 
    "title": "Mechanism Design for Team Formation", 
    "publish": "2015-01-04T20:09:14Z", 
    "summary": "Team formation is a core problem in AI. Remarkably, little prior work has\naddressed the problem of mechanism design for team formation, accounting for\nthe need to elicit agents' preferences over potential teammates. Coalition\nformation in the related hedonic games has received much attention, but only\nfrom the perspective of coalition stability, with little emphasis on the\nmechanism design objectives of true preference elicitation, social welfare, and\nequity. We present the first formal mechanism design framework for team\nformation, building on recent combinatorial matching market design literature.\nWe exhibit four mechanisms for this problem, two novel, two simple extensions\nof known mechanisms from other domains. Two of these (one new, one known) have\ndesirable theoretical properties. However, we use extensive experiments to show\nour second novel mechanism, despite having no theoretical guarantees,\nempirically achieves good incentive compatibility, welfare, and fairness.", 
    "link": "http://arxiv.org/pdf/1501.00715v1", 
    "arxiv-id": "1501.00715v1"
},{
    "category": "cs.GT", 
    "author": "Bernhard von Stengel", 
    "title": "Unit Vector Games", 
    "publish": "2015-01-09T19:43:04Z", 
    "summary": "McLennan and Tourky (2010) showed that \"imitation games\" provide a new view\nof the computation of Nash equilibria of bimatrix games with the Lemke-Howson\nalgorithm. In an imitation game, the payoff matrix of one of the players is the\nidentity matrix. We study the more general \"unit vector games\", which are\nalready known, where the payoff matrix of one player is composed of unit\nvectors. Our main application is a simplification of the construction by Savani\nand von Stengel (2006) of bimatrix games where two basic equilibrium-finding\nalgorithms take exponentially many steps: the Lemke-Howson algorithm, and\nsupport enumeration.", 
    "link": "http://arxiv.org/pdf/1501.02243v3", 
    "arxiv-id": "1501.02243v3"
},{
    "category": "cs.GT", 
    "author": "Jianwei Huang", 
    "title": "HySIM: A Hybrid Spectrum and Information Market for TV White Space   Networks", 
    "publish": "2015-01-11T18:13:05Z", 
    "summary": "We propose a hybrid spectrum and information market for a database-assisted\nTV white space network, where the geo-location database serves as both a\nspectrum market platform and an information market platform. We study the\ninter- actions among the database operator, the spectrum licensee, and\nunlicensed users systematically, using a three-layer hierarchical model. In\nLayer I, the database and the licensee negotiate the commission fee that the\nlicensee pays for using the spectrum market platform. In Layer II, the database\nand the licensee compete for selling information or channels to unlicensed\nusers. In Layer III, unlicensed users determine whether they should buy the\nexclusive usage right of licensed channels from the licensee, or the\ninformation regarding unlicensed channels from the database. Analyzing such a\nthree-layer model is challenging due to the co-existence of both positive and\nnegative network externalities in the information market. We characterize how\nthe network externalities affect the equilibrium behaviours of all parties\ninvolved. Our numerical results show that the proposed hybrid market can\nimprove the network profit up to 87%, compared with a pure information market.\nMeanwhile, the achieved network profit is very close to the coordinated\nbenchmark solution (the gap is less than 4% in our simulation).", 
    "link": "http://arxiv.org/pdf/1501.02478v2", 
    "arxiv-id": "1501.02478v2"
},{
    "category": "cs.GT", 
    "author": "Haozhen Situ", 
    "title": "Evolutionary Stable Strategies in Games with Fuzzy Payoffs", 
    "publish": "2015-01-18T04:42:17Z", 
    "summary": "Evolutionarily stable strategy (ESS) is a key concept in evolutionary game\ntheory. ESS provides an evolutionary stability criterion for biological, social\nand economical behaviors. In this paper, we develop a new approach to evaluate\nESS in symmetric two player games with fuzzy payoffs. Particularly, every\nstrategy is assigned a fuzzy membership that describes to what degree it is an\nESS in presence of uncertainty. The fuzzy set of ESS characterize the nature of\nESS. The proposed approach avoids loss of any information that happens by the\ndefuzzification method in games and handles uncertainty of payoffs through all\nsteps of finding an ESS. We use the satisfaction function to compare fuzzy\npayoffs, and adopts the fuzzy decision rule to obtain the membership function\nof the fuzzy set of ESS. The theorem shows the relation between fuzzy ESS and\nfuzzy Nash quilibrium. The numerical results illustrate the proposed method is\nan appropriate generalization of ESS to fuzzy payoff games.", 
    "link": "http://arxiv.org/pdf/1501.04265v2", 
    "arxiv-id": "1501.04265v2"
},{
    "category": "cs.GT", 
    "author": "Moshe Tennenholtz", 
    "title": "Mechanism Design with Strategic Mediators", 
    "publish": "2015-01-19T11:32:43Z", 
    "summary": "We consider the problem of designing mechanisms that interact with strategic\nagents through strategic intermediaries (or mediators), and investigate the\ncost to society due to the mediators' strategic behavior. Selfish agents with\nprivate information are each associated with exactly one strategic mediator,\nand can interact with the mechanism exclusively through that mediator. Each\nmediator aims to optimize the combined utility of his agents, while the\nmechanism aims to optimize the combined utility of all agents. We focus on the\nproblem of facility location on a metric induced by a publicly known tree. With\nnon-strategic mediators, there is a dominant strategy mechanism that is\noptimal. We show that when both agents and mediators act strategically, there\nis no dominant strategy mechanism that achieves any approximation. We, thus,\nslightly relax the incentive constraints, and define the notion of a two-sided\nincentive compatible mechanism. We show that the $3$-competitive deterministic\nmechanism suggested by Procaccia and Tennenholtz (2013) and Dekel et al. (2010)\nfor lines extends naturally to trees, and is still $3$-competitive as well as\ntwo-sided incentive compatible. This is essentially the best possible. We then\nshow that by allowing randomization one can construct a $2$-competitive\nrandomized mechanism that is two-sided incentive compatible, and this is also\nessentially tight. This result also closes a gap left in the work of Procaccia\nand Tennenholtz (2013) and Lu et al. (2009) for the simpler problem of\ndesigning strategy-proof mechanisms for weighted agents with no mediators on a\nline, while extending to the more general model of trees. We also investigate a\nfurther generalization of the above setting where there are multiple levels of\nmediators.", 
    "link": "http://arxiv.org/pdf/1501.04457v1", 
    "arxiv-id": "1501.04457v1"
},{
    "category": "cs.GT", 
    "author": "Thomas Varghese", 
    "title": "Symmetric Strategy Improvement", 
    "publish": "2015-01-26T17:09:18Z", 
    "summary": "Symmetry is inherent in the definition of most of the two-player zero-sum\ngames, including parity, mean-payoff, and discounted-payoff games. It is\ntherefore quite surprising that no symmetric analysis techniques for these\ngames exist. We develop a novel symmetric strategy improvement algorithm where,\nin each iteration, the strategies of both players are improved simultaneously.\nWe show that symmetric strategy improvement defies Friedmann's traps, which\nshook the belief in the potential of classic strategy improvement to be\npolynomial.", 
    "link": "http://arxiv.org/pdf/1501.06484v1", 
    "arxiv-id": "1501.06484v1"
},{
    "category": "cs.GT", 
    "author": "Haris Aziz", 
    "title": "Competitive Equilibrium with Equal Incomes for Allocation of Indivisible   Objects", 
    "publish": "2015-01-27T00:12:30Z", 
    "summary": "In AAMAS 2014, Bouveret and Lemaitre (2014) presented a hierarchy of fairness\nconcepts for allocation of indivisible objects. Among them CEEI (Competitive\nEquilibrium with Equal Incomes) was the strongest. In this note, we settle the\ncomplexity of computing a discrete CEEI assignment by showing it is strongly\nNP-hard. We then highlight a fairness notion (CEEI-FRAC) that is even stronger\nthan CEEI for discrete assignments, is always Pareto optimal, and can be\nverified in polynomial time. We also show that computing a CEEI-FRAC discrete\nassignment is strongly NP-hard in general but polynomial-time computable if the\nutilities are zero or one.", 
    "link": "http://arxiv.org/pdf/1501.06627v2", 
    "arxiv-id": "1501.06627v2"
},{
    "category": "cs.GT", 
    "author": "Sunil Simon", 
    "title": "Coordination Games on Graphs", 
    "publish": "2015-01-29T09:23:24Z", 
    "summary": "We introduce natural strategic games on graphs, which capture the idea of\ncoordination in a local setting. We study the existence of equilibria that are\nresilient to coalitional deviations of unbounded and bounded size (i.e., strong\nequilibria and k-equilibria respectively). We show that pure Nash equilibria\nand 2-equilibria exist, and give an example in which no 3-equilibrium exists.\nMoreover, we prove that strong equilibria exist for various special cases.\n  We also study the price of anarchy (PoA) and price of stability (PoS) for\nthese solution concepts. We show that the PoS for strong equilibria is 1 in\nalmost all of the special cases for which we have proven strong equilibria to\nexist. The PoA for pure Nash equilbria turns out to be unbounded, even when we\nfix the graph on which the coordination game is to be played. For the PoA for\nk-equilibria, we show that the price of anarchy is between 2(n-1)/(k-1) - 1 and\n2(n-1)/(k-1). The latter upper bound is tight for $k=n$ (i.e., strong\nequilibria).\n  Finally, we consider the problems of computing strong equilibria and of\ndetermining whether a joint strategy is a k-equilibrium or strong equilibrium.\nWe prove that, given a coordination game, a joint strategy s, and a number k as\ninput, it is co-NP complete to determine whether s is a k-equilibrium. On the\npositive side, we give polynomial time algorithms to compute strong equilibria\nfor various special cases.", 
    "link": "http://arxiv.org/pdf/1501.07388v3", 
    "arxiv-id": "1501.07388v3"
},{
    "category": "cs.GT", 
    "author": "S. Matthew Weinberg", 
    "title": "Simple Mechanisms for a Combinatorial Buyer and Applications to Revenue   Monotonicity", 
    "publish": "2015-01-30T00:12:55Z", 
    "summary": "We study the revenue maximization problem of a seller with n heterogeneous\nitems for sale to a single buyer whose valuation function for sets of items is\nunknown and drawn from some distribution D. We show that if D is a distribution\nover subadditive valuations with independent items, then the better of pricing\neach item separately or pricing only the grand bundle achieves a\nconstant-factor approximation to the revenue of the optimal mechanism. This\nincludes buyers who are k-demand, additive up to a matroid constraint, or\nadditive up to constraints of any downwards-closed set system (and whose values\nfor the individual items are sampled independently), as well as buyers who are\nfractionally subadditive with item multipliers drawn independently. Our proof\nmakes use of the core-tail decomposition framework developed in prior work\nshowing similar results for the significantly simpler class of additive buyers\n[LY13, BILW14].\n  In the second part of the paper, we develop a connection between\napproximately optimal simple mechanisms and approximate revenue monotonicity\nwith respect to buyers' valuations. Revenue non-monotonicity is the phenomenon\nthat sometimes strictly increasing buyers' values for every set can strictly\ndecrease the revenue of the optimal mechanism [HR12]. Using our main result, we\nderive a bound on how bad this degradation can be (and dub such a bound a proof\nof approximate revenue monotonicity); we further show that better bounds on\napproximate monotonicity imply a better analysis of our simple mechanisms.", 
    "link": "http://arxiv.org/pdf/1501.07637v1", 
    "arxiv-id": "1501.07637v1"
},{
    "category": "cs.GT", 
    "author": "Yishay Mansour", 
    "title": "Optimistic-Conservative Bidding in Sequential Auctions", 
    "publish": "2015-01-30T07:35:28Z", 
    "summary": "In this work we consider selling items using a sequential first price auction\nmechanism. We generalize the assumption of conservative bidding to extensive\nform games (henceforth optimistic conservative bidding), and show that for both\nlinear and unit demand valuations, the only pure subgame perfect equilibrium\nwhere buyers are bidding in an optimistic conservative manner is the minimal\nWalrasian equilibrium.\n  In addition, we show examples where without the requirement of conservative\nbidding, subgame perfect equilibria can admit a variety of unlikely\npredictions, including high price of anarchy and low revenue in markets\ncomposed of additive bidders, equilibria which elicit all the surplus as\nrevenue, and more. We also show that the order in which the items are sold can\ninfluence the outcome.", 
    "link": "http://arxiv.org/pdf/1501.07687v1", 
    "arxiv-id": "1501.07687v1"
},{
    "category": "cs.GT", 
    "author": "Tim Roughgarden", 
    "title": "The Sample Complexity of Revenue Maximization", 
    "publish": "2015-02-03T19:10:54Z", 
    "summary": "In the design and analysis of revenue-maximizing auctions, auction\nperformance is typically measured with respect to a prior distribution over\ninputs. The most obvious source for such a distribution is past data. The goal\nis to understand how much data is necessary and sufficient to guarantee\nnear-optimal expected revenue.\n  Our basic model is a single-item auction in which bidders' valuations are\ndrawn independently from unknown and non-identical distributions. The seller is\ngiven $m$ samples from each of these distributions \"for free\" and chooses an\nauction to run on a fresh sample. How large does m need to be, as a function of\nthe number k of bidders and eps > 0, so that a (1 - eps)-approximation of the\noptimal revenue is achievable?\n  We prove that, under standard tail conditions on the underlying\ndistributions, m = poly(k, 1/eps) samples are necessary and sufficient. Our\nlower bound stands in contrast to many recent results on simple and\nprior-independent auctions and fundamentally involves the interplay between\nbidder competition, non-identical distributions, and a very close (but still\nconstant) approximation of the optimal revenue. It effectively shows that the\nonly way to achieve a sufficiently good constant approximation of the optimal\nrevenue is through a detailed understanding of bidders' valuation\ndistributions. Our upper bound is constructive and applies in particular to a\nvariant of the empirical Myerson auction, the natural auction that runs the\nrevenue-maximizing auction with respect to the empirical distributions of the\nsamples.\n  Our sample complexity lower bound depends on the set of allowable\ndistributions, and to capture this we introduce alpha-strongly regular\ndistributions, which interpolate between the well-studied classes of regular\n(alpha = 0) and MHR (alpha = 1) distributions. We give evidence that this\ndefinition is of independent interest.", 
    "link": "http://arxiv.org/pdf/1502.00963v2", 
    "arxiv-id": "1502.00963v2"
},{
    "category": "cs.GT", 
    "author": "Harris V. Georgiou", 
    "title": "Collective decision efficiency and optimal voting mechanisms: A   comprehensive overview for multi-classifier models", 
    "publish": "2015-02-07T22:48:52Z", 
    "summary": "A new game-theoretic approach for combining multiple classifiers is proposed.\nA short introduction in Game Theory and coalitions illustrate the way any\ncollective decision scheme can be viewed as a competitive game of coalitions\nthat are formed naturally when players state their preferences. The winning\nconditions and the voting power of each player are studied under the scope of\nvoting power indices, as well and the collective competence of the group.\nCoalitions and power indices are presented in relation to the Condorcet\ncriterion of optimality in voting systems, and weighted Borda count models are\nasserted as a way to implement them in practice. A special case of coalition\ngames, the weighted majority games (WMG) are presented as a restricted\nrealization in dichotomy choice situations. As a result, the weighted majority\nrules (WMR), an extended version of the simple majority rules, are asserted as\nthe theoretically optimal and complete solution to this type of coalition\ngaming. Subsequently, a generalized version of WMRs is suggested as the means\nto design a voting system that is optimal in the sense of both the correct\nclassification criterion and the Condorcet efficiency criterion. In the scope\nof Pattern Recognition, a generalized risk-based approach is proposed as the\nframework upon which any classifier combination scheme can be applied. A new\nfully adaptive version of WMRs is proposed as a statistically invariant way of\nadjusting the design process of the optimal WMR to the arbitrary\nnon-symmetrical properties of the underlying feature space. SVM theory is\nassociated with properties and conclusions that emerge from the game-theoretic\napproach of the classification in general, while the theoretical and practical\nimplications of employing SVM experts in WMR combination schemes are briefly\ndiscussed. Finally, a summary of the most important issues for further research\nis presented.", 
    "link": "http://arxiv.org/pdf/1502.02191v1", 
    "arxiv-id": "1502.02191v1"
},{
    "category": "cs.GT", 
    "author": "Agust\u00edn Santos", 
    "title": "A Mechanism for Fair Distribution of Resources without Payments", 
    "publish": "2015-02-11T15:35:32Z", 
    "summary": "We design a mechanism for Fair and Efficient Distribution of Resources\n(FEDoR) in the presence of strategic agents. We consider a multiple-instances,\nBayesian setting, where in each round the preference of an agent over the set\nof resources is a private information. We assume that in each of r rounds n\nagents are competing for k non-identical indivisible goods, (n > k). In each\nround the strategic agents declare how much they value receiving any of the\ngoods in the specific round. The agent declaring the highest valuation receives\nthe good with the highest value, the agent with the second highest valuation\nreceives the second highest valued good, etc. Hence we assume a decision\nfunction that assigns goods to agents based on their valuations. The novelty of\nthe mechanism is that no payment scheme is required to achieve truthfulness in\na setting with rational/strategic agents. The FEDoR mechanism takes advantage\nof the repeated nature of the framework, and through a statistical test is able\nto punish the misreporting agents and be fair, truthful, and socially\nefficient. FEDoR is fair in the sense that, in expectation over the course of\nthe rounds, all agents will receive the same good the same amount of times.\nFEDoR is an eligible candidate for applications that require fair distribution\nof resources over time. For example, equal share of bandwidth for nodes through\nthe same point of access. But further on, FEDoR can be applied in less trivial\nsettings like sponsored search, where payment is necessary and can be given in\nthe form of a flat participation fee. To this extent we perform a comparison\nwith traditional mechanisms applied to sponsored search, presenting the\nadvantage of FEDoR.", 
    "link": "http://arxiv.org/pdf/1502.03337v2", 
    "arxiv-id": "1502.03337v2"
},{
    "category": "cs.GT", 
    "author": "Vincent Conitzer", 
    "title": "Timeability of Extensive-Form Games", 
    "publish": "2015-02-11T20:34:01Z", 
    "summary": "Extensive-form games constitute the standard representation scheme for games\nwith a temporal component. But do all extensive-form games correspond to\nprotocols that we can implement in the real world? We often rule out games with\nimperfect recall, which prescribe that an agent forget something that she knew\nbefore. In this paper, we show that even some games with perfect recall can be\nproblematic to implement. Specifically, we show that if the agents have a sense\nof time passing (say, access to a clock), then some extensive-form games can no\nlonger be implemented; no matter how we attempt to time the game, some\ninformation will leak to the agents that they are not supposed to have. We say\nsuch a game is not exactly timeable. We provide easy-to-check necessary and\nsufficient conditions for a game to be exactly timeable. Most of the technical\ndepth of the paper concerns how to approximately time games, which we show can\nalways be done, though it may require large amounts of time. Specifically, we\nshow that for some games the time required to approximately implement the game\ngrows as a power tower of height proportional to the number of players and with\na parameter that measures the precision of the approximation at the top of the\npower tower. In practice, that makes the games untimeable. Besides the\nconceptual contribution to game theory, we believe our methodology can have\napplications to preventing information leakage in security protocols.", 
    "link": "http://arxiv.org/pdf/1502.03430v1", 
    "arxiv-id": "1502.03430v1"
},{
    "category": "cs.GT", 
    "author": "Jinshan Zhang", 
    "title": "Social Welfare in One-Sided Matching Mechanisms", 
    "publish": "2015-02-12T22:24:24Z", 
    "summary": "We study the Price of Anarchy of mechanisms for the well-known problem of\none-sided matching, or house allocation, with respect to the social welfare\nobjective. We consider both ordinal mechanisms, where agents submit preference\nlists over the items, and cardinal mechanisms, where agents may submit\nnumerical values for the items being allocated. We present a general lower\nbound of $\\Omega(\\sqrt{n})$ on the Price of Anarchy, which applies to all\nmechanisms. We show that two well-known mechanisms, Probabilistic Serial, and\nRandom Priority, achieve a matching upper bound. We extend our lower bound to\nthe Price of Stability of a large class of mechanisms that satisfy a common\nproportionality property, and show stronger bounds on the Price of Anarchy of\nall deterministic mechanisms.", 
    "link": "http://arxiv.org/pdf/1502.03849v2", 
    "arxiv-id": "1502.03849v2"
},{
    "category": "cs.GT", 
    "author": "Zhiwei Steven Wu", 
    "title": "Inducing Approximately Optimal Flow Using Truthful Mediators", 
    "publish": "2015-02-13T15:01:15Z", 
    "summary": "We revisit a classic coordination problem from the perspective of mechanism\ndesign: how can we coordinate a social welfare maximizing flow in a network\ncongestion game with selfish players? The classical approach, which computes\ntolls as a function of known demands, fails when the demands are unknown to the\nmechanism designer, and naively eliciting them does not necessarily yield a\ntruthful mechanism. Instead, we introduce a weak mediator that can provide\nsuggested routes to players and set tolls as a function of reported demands.\nHowever, players can choose to ignore or misreport their type to this mediator.\nUsing techniques from differential privacy, we show how to design a weak\nmediator such that it is an asymptotic ex-post Nash equilibrium for all players\nto truthfully report their types to the mediator and faithfully follow its\nsuggestion, and that when they do, they end up playing a nearly optimal flow.\nNotably, our solution works in settings of incomplete information even in the\nabsence of a prior distribution on player types. Along the way, we develop new\ntechniques for privately solving convex programs which may be of independent\ninterest.", 
    "link": "http://arxiv.org/pdf/1502.04019v2", 
    "arxiv-id": "1502.04019v2"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Bayesian Incentive-Compatible Bandit Exploration", 
    "publish": "2015-02-13T23:16:22Z", 
    "summary": "Individual decision-makers consume information revealed by the previous\ndecision makers, and produce information that may help in future decisions.\nThis phenomenon is common in a wide range of scenarios in the Internet economy,\nas well as in other domains such as medical decisions. Each decision-maker\nwould individually prefer to \"exploit\": select an action with the highest\nexpected reward given her current information. At the same time, each\ndecision-maker would prefer previous decision-makers to \"explore\", producing\ninformation about the rewards of various actions. A social planner, by means of\ncarefully designed information disclosure, can incentivize the agents to\nbalance the exploration and exploitation so as to maximize social welfare.\n  We formulate this problem as a multi-armed bandit problem (and various\ngeneralizations thereof) under incentive-compatibility constraints induced by\nthe agents' Bayesian priors. We design an incentive-compatible bandit algorithm\nfor the social planner whose regret is asymptotically optimal among all bandit\nalgorithms (incentive-compatible or not). Further, we provide a black-box\nreduction from an arbitrary multi-arm bandit algorithm to an\nincentive-compatible one, with only a constant multiplicative increase in\nregret. This reduction works for very general bandit setting that incorporate\ncontexts and arbitrary auxiliary feedback.", 
    "link": "http://arxiv.org/pdf/1502.04147v3", 
    "arxiv-id": "1502.04147v3"
},{
    "category": "cs.GT", 
    "author": "Wade Trappe", 
    "title": "Optimal Scanning Bandwidth Strategy Incorporating Uncertainty about   Adversary's Characteristics", 
    "publish": "2015-02-16T19:33:21Z", 
    "summary": "In this paper we investigate the problem of designing a spectrum scanning\nstrategy to detect an intelligent Invader who wants to utilize spectrum\nundetected for his/her unapproved purposes. To deal with this problem we model\nthe situation as two games, between a Scanner and an Invader, and solve them\nsequentially. The first game is formulated to design the optimal (in maxmin\nsense) scanning algorithm, while the second one allows one to find the optimal\nvalues of the parameters for the algorithm depending on parameters of the\nnetwork. These games provide solutions for two dilemmas that the rivals face.\nThe Invader's dilemma consists of the following: the more bandwidth the Invader\nattempts to use leads to a larger payoff if he is not detected, but at the same\ntime also increases the probability of being detected and thus fined.\nSimilarly, the Scanner faces a dilemma: the wider the bandwidth scanned, the\nhigher the probability of detecting the Invader, but at the expense of\nincreasing the cost of building the scanning system. The equilibrium strategies\nare found explicitly and reveal interesting properties. In particular, we have\nfound a discontinuous dependence of the equilibrium strategies on the network\nparameters, fine and the type of the Invader's award. This discontinuity of the\nfine means that the network provider has to take into account a human/social\nfactor since some threshold values of fine could be very sensible for the\nInvader, while in other situations simply increasing the fine has minimal\ndeterrence impact. Also we show how incomplete information about the Invader's\ntechnical characteristics and reward (e.g. motivated by using different type of\napplication, say, video-streaming or downloading files) can be incorporated\ninto scanning strategy to increase its efficiency.", 
    "link": "http://arxiv.org/pdf/1502.04676v2", 
    "arxiv-id": "1502.04676v2"
},{
    "category": "cs.GT", 
    "author": "Toby Walsh", 
    "title": "Equilibria Under the Probabilistic Serial Rule", 
    "publish": "2015-02-17T13:26:38Z", 
    "summary": "The probabilistic serial (PS) rule is a prominent randomized rule for\nassigning indivisible goods to agents. Although it is well known for its good\nfairness and welfare properties, it is not strategyproof. In view of this, we\naddress several fundamental questions regarding equilibria under PS. Firstly,\nwe show that Nash deviations under the PS rule can cycle. Despite the\npossibilities of cycles, we prove that a pure Nash equilibrium is guaranteed to\nexist under the PS rule. We then show that verifying whether a given profile is\na pure Nash equilibrium is coNP-complete, and computing a pure Nash equilibrium\nis NP-hard. For two agents, we present a linear-time algorithm to compute a\npure Nash equilibrium which yields the same assignment as the truthful profile.\nFinally, we conduct experiments to evaluate the quality of the equilibria that\nexist under the PS rule, finding that the vast majority of pure Nash equilibria\nyield social welfare that is at least that of the truthful profile.", 
    "link": "http://arxiv.org/pdf/1502.04888v2", 
    "arxiv-id": "1502.04888v2"
},{
    "category": "cs.GT", 
    "author": "Rahul Savani", 
    "title": "An Empirical Study of Finding Approximate Equilibria in Bimatrix Games", 
    "publish": "2015-02-17T17:57:24Z", 
    "summary": "While there have been a number of studies about the efficacy of methods to\nfind exact Nash equilibria in bimatrix games, there has been little empirical\nwork on finding approximate Nash equilibria. Here we provide such a study that\ncompares a number of approximation methods and exact methods. In particular, we\nexplore the trade-off between the quality of approximate equilibrium and the\nrequired running time to find one. We found that the existing library GAMUT,\nwhich has been the de facto standard that has been used to test exact methods,\nis insufficient as a test bed for approximation methods since many of its games\nhave pure equilibria or other easy-to-find good approximate equilibria. We\nextend the breadth and depth of our study by including new interesting families\nof bimatrix games, and studying bimatrix games upto size $2000 \\times 2000$.\nFinally, we provide new close-to-worst-case examples for the best-performing\nalgorithms for finding approximate Nash equilibria.", 
    "link": "http://arxiv.org/pdf/1502.04980v3", 
    "arxiv-id": "1502.04980v3"
},{
    "category": "cs.GT", 
    "author": "Qiang Zhang", 
    "title": "Facility location with double-peaked preference", 
    "publish": "2015-02-19T12:26:46Z", 
    "summary": "We study the problem of locating a single facility on a real line based on\nthe reports of self-interested agents, when agents have double-peaked\npreferences, with the peaks being on opposite sides of their locations. We\nobserve that double-peaked preferences capture real-life scenarios and thus\ncomplement the well-studied notion of single-peaked preferences. We mainly\nfocus on the case where peaks are equidistant from the agents' locations and\ndiscuss how our results extend to more general settings. We show that most of\nthe results for single-peaked preferences do not directly apply to this\nsetting; this makes the problem essentially more challenging. As our main\ncontribution, we present a simple truthful-in-expectation mechanism that\nachieves an approximation ratio of 1+b/c for both the social and the maximum\ncost, where b is the distance of the agent from the peak and c is the minimum\ncost of an agent. For the latter case, we provide a 3/2 lower bound on the\napproximation ratio of any truthful-in-expectation mechanism. We also study\ndeterministic mechanisms under some natural conditions, proving lower bounds\nand approximation guarantees. We prove that among a large class of reasonable\nmechanisms, there is no deterministic mechanism that outperforms our\ntruthful-in-expectation mechanism.", 
    "link": "http://arxiv.org/pdf/1502.05548v1", 
    "arxiv-id": "1502.05548v1"
},{
    "category": "cs.GT", 
    "author": "Sven Seuken", 
    "title": "The Pareto Frontier for Random Mechanisms", 
    "publish": "2015-02-20T14:30:37Z", 
    "summary": "We study the trade-offs between strategyproofness and other desiderata, such\nas efficiency or fairness, that often arise in the design of random ordinal\nmechanisms. We use approximate strategyproofness to define manipulability, a\nmeasure to quantify the incentive properties of non-strategyproof mechanisms,\nand we introduce the deficit, a measure to quantify the performance of\nmechanisms with respect to another desideratum. When this desideratum is\nincompatible with strategyproofness, mechanisms that trade off manipulability\nand deficit optimally form the Pareto frontier. Our main contribution is a\nstructural characterization of this Pareto frontier, and we present algorithms\nthat exploit this structure to compute it. To illustrate its shape, we apply\nour results for two different desiderata, namely Plurality and Veto scoring, in\nsettings with 3 alternatives and up to 18 agents.", 
    "link": "http://arxiv.org/pdf/1502.05883v3", 
    "arxiv-id": "1502.05883v3"
},{
    "category": "cs.GT", 
    "author": "Jana Karina von Wedel", 
    "title": "On the Susceptibility of the Deferred Acceptance Algorithm", 
    "publish": "2015-02-23T05:33:01Z", 
    "summary": "The Deferred Acceptance Algorithm (DAA) is the most widely accepted and used\nalgorithm to match students, workers, or residents to colleges, firms or\nhospitals respectively. In this paper, we consider for the first time, the\ncomplexity of manipulating DAA by agents such as colleges that have capacity\nmore than one. For such agents, truncation is not an exhaustive strategy. We\npresent efficient algorithms to compute a manipulation for the colleges when\nthe colleges are proposing or being proposed to. We then conduct detailed\nexperiments on the frequency of manipulable instances in order to get better\ninsight into strategic aspects of two-sided matching markets. Our results bear\nsomewhat negative news: assuming that agents have information other agents'\npreference, they not only often have an incentive to misreport but there exist\nefficient algorithms to find such a misreport.", 
    "link": "http://arxiv.org/pdf/1502.06318v1", 
    "arxiv-id": "1502.06318v1"
},{
    "category": "cs.GT", 
    "author": "Y. Narahari", 
    "title": "An Optimal Bidimensional Multi-Armed Bandit Auction for Multi-unit   Procurement", 
    "publish": "2015-02-24T20:15:00Z", 
    "summary": "We study the problem of a buyer (aka auctioneer) who gains stochastic rewards\nby procuring multiple units of a service or item from a pool of heterogeneous\nstrategic agents. The reward obtained for a single unit from an allocated agent\ndepends on the inherent quality of the agent; the agent's quality is fixed but\nunknown. Each agent can only supply a limited number of units (capacity of the\nagent). The costs incurred per unit and capacities are private information of\nthe agents. The auctioneer is required to elicit costs as well as capacities\n(making the mechanism design bidimensional) and further, learn the qualities of\nthe agents as well, with a view to maximize her utility. Motivated by this, we\ndesign a bidimensional multi-armed bandit procurement auction that seeks to\nmaximize the expected utility of the auctioneer subject to incentive\ncompatibility and individual rationality while simultaneously learning the\nunknown qualities of the agents. We first assume that the qualities are known\nand propose an optimal, truthful mechanism 2D-OPT for the auctioneer to elicit\ncosts and capacities. Next, in order to learn the qualities of the agents in\naddition, we provide sufficient conditions for a learning algorithm to be\nBayesian incentive compatible and individually rational. We finally design a\nnovel learning mechanism, 2D-UCB that is stochastic Bayesian incentive\ncompatible and individually rational.", 
    "link": "http://arxiv.org/pdf/1502.06934v2", 
    "arxiv-id": "1502.06934v2"
},{
    "category": "cs.GT", 
    "author": "Pingzhong Tang", 
    "title": "Optimal commitments in auctions with incomplete information", 
    "publish": "2015-02-26T04:48:15Z", 
    "summary": "We are interested in the problem of optimal commitments in rank-and-bid based\nauctions, a general class of auctions that include first price and all-pay\nauctions as special cases. Our main contribution is a novel approach to solve\nfor optimal commitment in this class of auctions, for any continuous type\ndistributions. Applying our approach, we are able to solve optimal commitments\nfor first-price and all-pay auctions in closed-form for fairly general\ndistribution settings. The optimal commitments functions in these auctions\nreveal two surprisingly opposite insights: in the optimal commitment, the\nleader bids passively when he has a low type. We interpret this as a credible\nway to alleviate competition and to collude. In sharp contrast, when his type\nis high enough, the leader sometimes would go so far as to bid above his own\nvalue. We interpret this as a credible way to threat. Combing both insights, we\nshow via concrete examples that the leader is indeed willing to do so to secure\nmore utility when his type is in the middle. Our main approach consists of a\nseries of nontrivial innovations. In particular we put forward a concept called\nequal-bid function that connects both players' strategies, as well as a concept\ncalled equal-utility curve that smooths any leader strategy into a continuous\nand differentiable strategy. We believe these techniques and insights are\ngeneral and can be applied to similar problems.", 
    "link": "http://arxiv.org/pdf/1502.07431v1", 
    "arxiv-id": "1502.07431v1"
},{
    "category": "cs.GT", 
    "author": "Jamie Payton", 
    "title": "Incentive Mechanisms for Participatory Sensing: Survey and Research   Challenges", 
    "publish": "2015-02-26T19:25:26Z", 
    "summary": "Participatory sensing is a powerful paradigm which takes advantage of\nsmartphones to collect and analyze data beyond the scale of what was previously\npossible. Given that participatory sensing systems rely completely on the\nusers' willingness to submit up-to-date and accurate information, it is\nparamount to effectively incentivize users' active and reliable participation.\nIn this paper, we survey existing literature on incentive mechanisms for\nparticipatory sensing systems. In particular, we present a taxonomy of existing\nincentive mechanisms for participatory sensing systems, which are subsequently\ndiscussed in depth by comparing and contrasting different approaches. Finally,\nwe discuss an agenda of open research challenges in incentivizing users in\nparticipatory sensing.", 
    "link": "http://arxiv.org/pdf/1502.07687v3", 
    "arxiv-id": "1502.07687v3"
},{
    "category": "cs.GT", 
    "author": "Pingzhong Tang", 
    "title": "Coalition manipulations of the Gale-Shapley algorithm", 
    "publish": "2015-02-27T06:37:06Z", 
    "summary": "It is well-known that the Gale-Shapley algorithm is not truthful for all\nagents. Previous studies in this category focus on manipulations using\nincomplete preference lists by a single woman and by the set of all women.\nLittle is known about manipulations by a subset of women or other types of\nmanipulations, such as permutation of complete preference lists.\n  In this paper, we consider manipulations by any subset of women with\narbitrary preferences. For the setting where agents can report incomplete\npreference lists, we show that a strong Nash equilibrium of the induced\nmanipulation game always exists and the equilibrium outcome is unique and\nPareto-dominant. In addition, the set of matchings achievable by manipulations\nhas a Lattice structure.\n  For the setting where agents can only report complete preference lists, we\ngive answers to Gusfield and Irving's open question on what matchings can be\nachieved in the induced manipulation games. We first give a counter-example to\nshow that a unique Pareto-dominant outcome may not exist. Then we present a\npolynomial-time algorithm to find a Pareto-optimal strategy profile. In fact,\nwe give an algorithmic characterization of such profiles: a strategy profile is\nPareto-optimal if and only if it is the outcome of our algorithm. We also show\nthat Pareto-optimality is equivalent to strong Nash equilibrium outcomes. These\nresults are enabled by applying a structure called rotation and a careful\nanalysis of the so-called suitor graph. We also introduce several new concepts,\nsuch as maximal rotation and principle set, and develop a series of original\ntechniques which may be of independent interest in this domain.\n  Even though all these results may show the vulnerabilities of the\nGale-Shapley algorithm, we prove a hardness result in the end: it is\nNP-complete to find a manipulation that induces a matching strictly better off\nfor all manipulators.", 
    "link": "http://arxiv.org/pdf/1502.07823v2", 
    "arxiv-id": "1502.07823v2"
},{
    "category": "cs.GT", 
    "author": "Shreyas Sekar", 
    "title": "Envy-Free Pricing in Large Markets: Approximating Revenue and Welfare", 
    "publish": "2015-03-01T19:43:04Z", 
    "summary": "We study the classic setting of envy-free pricing, in which a single seller\nchooses prices for its many items, with the goal of maximizing revenue once the\nitems are allocated. Despite the large body of work addressing such settings,\nmost versions of this problem have resisted good approximation factors for\nmaximizing revenue; this is true even for the classic unit-demand case. In this\npaper we study envy-free pricing with unit-demand buyers, but unlike previous\nwork we focus on large markets: ones in which the demand of each buyer is\ninfinitesimally small compared to the size of the overall market. We assume\nthat the buyer valuations for the items they desire have a nice (although\nreasonable) structure, i.e., that the aggregate buyer demand has a monotone\nhazard rate and that the values of every buyer type come from the same support.\n  For such large markets, our main contribution is a 1.88 approximation\nalgorithm for maximizing revenue, showing that good pricing schemes can be\ncomputed when the number of buyers is large. We also give a (e,2)-bicriteria\nalgorithm that simultaneously approximates both maximum revenue and welfare,\nthus showing that it is possible to obtain both good revenue and welfare at the\nsame time. We further generalize our results by relaxing some of our\nassumptions, and quantify the necessary tradeoffs between revenue and welfare\nin our setting. Our results are the first known approximations for large\nmarkets, and crucially rely on new lower bounds which we prove for the\nrevenue-maximizing prices.", 
    "link": "http://arxiv.org/pdf/1503.00340v1", 
    "arxiv-id": "1503.00340v1"
},{
    "category": "cs.GT", 
    "author": "Amin Saberi", 
    "title": "Approximation Algorithms for Computing Maximin Share Allocations", 
    "publish": "2015-03-03T13:37:53Z", 
    "summary": "We study the problem of computing maximin share guarantees, a recently\nintroduced fairness notion. Given a set of $n$ agents and a set of goods, the\nmaximin share of a single agent is the best that she can guarantee to herself,\nif she would be allowed to partition the goods in any way she prefers, into $n$\nbundles, and then receive her least desirable bundle. The objective then in our\nproblem is to find a partition, so that each agent is guaranteed her maximin\nshare. In settings with indivisible goods, such allocations are not guaranteed\nto exist, so we resort to approximation algorithms. Our main result is a\n$2/3$-approximation, that runs in polynomial time for any number of agents.\nThis improves upon the algorithm of Procaccia and Wang, which also produces a\n$2/3$-approximation but runs in polynomial time only for a constant number of\nagents. To achieve this, we redesign certain parts of their algorithm.\nFurthermore, motivated by the apparent difficulty, both theoretically and\nexperimentally, in finding lower bounds on the existence of approximate\nsolutions, we undertake a probabilistic analysis. We prove that in randomly\ngenerated instances, with high probability there exists a maximin share\nallocation. This can be seen as a justification of the experimental evidence\nreported in relevant works.\n  Finally, we provide further positive results for two special cases that arise\nfrom previous works. The first one is the intriguing case of $3$ agents, for\nwhich it is already known that exact maximin share allocations do not always\nexist (contrary to the case of $2$ agents). We provide a $7/8$-approximation\nalgorithm, improving the previously known result of $3/4$. The second case is\nwhen all item values belong to $\\{0, 1, 2\\}$, extending the $\\{0, 1\\}$ setting\nstudied in Bouveret and Lema\\^itre. We obtain an exact algorithm for any number\nof agents in this case.", 
    "link": "http://arxiv.org/pdf/1503.00941v2", 
    "arxiv-id": "1503.00941v2"
},{
    "category": "cs.GT", 
    "author": "Christos Tzamos", 
    "title": "Mechanism Design via Optimal Transport", 
    "publish": "2015-03-06T14:01:51Z", 
    "summary": "Optimal mechanisms have been provided in quite general multi-item settings,\nas long as each bidder's type distribution is given explicitly by listing every\ntype in the support along with its associated probability. In the implicit\nsetting, e.g. when the bidders have additive valuations with independent and/or\ncontinuous values for the items, these results do not apply, and it was\nrecently shown that exact revenue optimization is intractable, even when there\nis only one bidder. Even for item distributions with special structure, optimal\nmechanisms have been surprisingly rare and the problem is challenging even in\nthe two-item case. In this paper, we provide a framework for designing optimal\nmechanisms using optimal transport theory and duality theory. We instantiate\nour framework to obtain conditions under which only pricing the grand bundle is\noptimal in multi-item settings (complementing the work of [Manelli and Vincent\n2006], as well as to characterize optimal two-item mechanisms. We use our\nresults to derive closed-form descriptions of the optimal mechanism in several\ntwo-item settings, exhibiting also a setting where a continuum of lotteries is\nnecessary for revenue optimization but a closed-form representation of the\nmechanism can still be found efficiently using our framework.", 
    "link": "http://arxiv.org/pdf/1503.01958v1", 
    "arxiv-id": "1503.01958v1"
},{
    "category": "cs.GT", 
    "author": "Stefano Leonardi", 
    "title": "Sequential Posted Price Mechanisms with Correlated Valuations", 
    "publish": "2015-03-07T19:02:16Z", 
    "summary": "We study the revenue performance of sequential posted price mechanisms and\nsome natural extensions, for a general setting where the valuations of the\nbuyers are drawn from a correlated distribution. Sequential posted price\nmechanisms are conceptually simple mechanisms that work by proposing a\ntake-it-or-leave-it offer to each buyer. We apply sequential posted price\nmechanisms to single-parameter multi-unit settings in which each buyer demands\nonly one item and the mechanism can assign the service to at most k of the\nbuyers. For standard sequential posted price mechanisms, we prove that with the\nvaluation distribution having finite support, no sequential posted price\nmechanism can extract a constant fraction of the optimal expected revenue, even\nwith unlimited supply. We extend this result to the the case of a continuous\nvaluation distribution when various standard assumptions hold simultaneously.\nIn fact, it turns out that the best fraction of the optimal revenue that is\nextractable by a sequential posted price mechanism is proportional to ratio of\nthe highest and lowest possible valuation. We prove that for two simple\ngeneralizations of these mechanisms, a better revenue performance can be\nachieved: if the sequential posted price mechanism has for each buyer the\noption of either proposing an offer or asking the buyer for its valuation, then\na Omega(1/max{1,d}) fraction of the optimal revenue can be extracted, where d\ndenotes the degree of dependence of the valuations, ranging from complete\nindependence (d=0) to arbitrary dependence (d=n-1). Moreover, when we\ngeneralize the sequential posted price mechanisms further, such that the\nmechanism has the ability to make a take-it-or-leave-it offer to the i-th buyer\nthat depends on the valuations of all buyers except i's, we prove that a\nconstant fraction (2-sqrt{e})/4~0.088 of the optimal revenue can be always be\nextracted.", 
    "link": "http://arxiv.org/pdf/1503.02200v3", 
    "arxiv-id": "1503.02200v3"
},{
    "category": "cs.GT", 
    "author": "Achilleas Anastasopoulos", 
    "title": "A General Mechanism Design Methodology for Social Utility Maximization   with Linear Constraints", 
    "publish": "2015-03-08T02:52:37Z", 
    "summary": "Social utility maximization refers to the process of allocating resources in\nsuch a way that the sum of agents' utilities is maximized under the system\nconstraints. Such allocation arises in several problems in the general area of\ncommunications, including unicast (and multicast multi-rate) service on the\nInternet, as well as in applications with (local) public goods, such as power\nallocation in wireless networks, spectrum allocation, etc. Mechanisms that\nimplement such allocations in Nash equilibrium have also been studied but\neither they do not possess full implementation property, or are given in a\ncase-by-case fashion, thus obscuring fundamental understanding of these\nproblems.\n  In this paper we propose a unified methodology for creating mechanisms that\nfully implement, in Nash equilibria, social utility maximizing functions\narising in various contexts where the constraints are convex. The construction\nof the mechanism is done in a systematic way by considering the dual\noptimization problem. In addition to the required properties of efficiency and\nindividual rationality that such mechanisms ought to satisfy, three additional\ndesign goals are the focus of this paper: a) the size of the message space\nscaling linearly with the number of agents (even if agents' types are entire\nvaluation functions), b) allocation being feasible on and off equilibrium, and\nc) strong budget balance at equilibrium and also off equilibrium whenever\ndemand is feasible.", 
    "link": "http://arxiv.org/pdf/1503.02240v1", 
    "arxiv-id": "1503.02240v1"
},{
    "category": "cs.GT", 
    "author": "Christos Tzamos", 
    "title": "Optimal Pricing is Hard", 
    "publish": "2015-03-09T15:18:15Z", 
    "summary": "We show that computing the revenue-optimal deterministic auction in\nunit-demand single-buyer Bayesian settings, i.e. the optimal item-pricing, is\ncomputationally hard even in single-item settings where the buyer's value\ndistribution is a sum of independently distributed attributes, or multi-item\nsettings where the buyer's values for the items are independent. We also show\nthat it is intractable to optimally price the grand bundle of multiple items\nfor an additive bidder whose values for the items are independent. These\ndifficulties stem from implicit definitions of a value distribution. We provide\nthree instances of how different properties of implicit distributions can lead\nto intractability: the first is a #P-hardness proof, while the remaining two\nare reductions from the SQRT-SUM problem of Garey, Graham, and Johnson. While\nsimple pricing schemes can oftentimes approximate the best scheme in revenue,\nthey can have drastically different underlying structure. We argue therefore\nthat either the specification of the input distribution must be highly\nrestricted in format, or it is necessary for the goal to be mere approximation\nto the optimal scheme's revenue instead of computing properties of the scheme\nitself.", 
    "link": "http://arxiv.org/pdf/1503.02516v1", 
    "arxiv-id": "1503.02516v1"
},{
    "category": "cs.GT", 
    "author": "Oana Ciobotaru", 
    "title": "Co-Utility: Self-Enforcing Protocols without Coordination Mechanisms", 
    "publish": "2015-03-09T17:18:55Z", 
    "summary": "Performing some task among a set of agents requires the use of some protocol\nthat regulates the interactions between them. If those agents are rational,\nthey may try to subvert the protocol for their own benefit, in an attempt to\nreach an outcome that provides greater utility. We revisit the traditional\nnotion of self-enforcing protocols implemented using existing game-theoretic\nsolution concepts, we describe its shortcomings in real-world applications, and\nwe propose a new notion of self-enforcing protocols, namely co-utile protocols.\nThe latter represent a solution concept that can be implemented without a\ncoordination mechanism in situations when traditional self-enforcing protocols\nneed a coordination mechanism. Co-utile protocols are preferable in\ndecentralized systems of rational agents because of their efficiency and\nfairness. We illustrate the application of co-utile protocols to information\ntechnology, specifically to preserving the privacy of query profiles of\ndatabase/search engine users.", 
    "link": "http://arxiv.org/pdf/1503.02563v1", 
    "arxiv-id": "1503.02563v1"
},{
    "category": "cs.GT", 
    "author": "Le Xie", 
    "title": "Mean Field Games in Nudge Systems for Societal Networks", 
    "publish": "2015-03-10T15:20:34Z", 
    "summary": "We consider the general problem of resource sharing in societal networks,\nconsisting of interconnected communication, transportation, energy and other\nnetworks important to the functioning of society. Participants in such network\nneed to take decisions daily, both on the quantity of resources to use as well\nas the periods of usage. With this in mind, we discuss the problem of\nincentivizing users to behave in such a way that society as a whole benefits.\nIn order to perceive societal level impact, such incentives may take the form\nof rewarding users with lottery tickets based on good behavior, and\nperiodically conducting a lottery to translate these tickets into real rewards.\nWe will pose the user decision problem as a mean field game (MFG), and the\nincentives question as one of trying to select a good mean field equilibrium\n(MFE). In such a framework, each agent (a participant in the societal network)\ntakes a decision based on an assumed distribution of actions of his/her\ncompetitors, and the incentives provided by the social planner. The system is\nsaid to be at MFE if the agent's action is a sample drawn from the assumed\ndistribution. We will show the existence of such an MFE under different\nsettings, and also illustrate how to choose an attractive equilibrium using as\nan example demand-response in energy networks.", 
    "link": "http://arxiv.org/pdf/1503.02951v3", 
    "arxiv-id": "1503.02951v3"
},{
    "category": "cs.GT", 
    "author": "Dusko Pavlovic", 
    "title": "Testing randomness by Matching Pennies", 
    "publish": "2015-03-11T05:58:06Z", 
    "summary": "In the game of Matching Pennies, Alice and Bob each hold a penny, and at\nevery tick of the clock they simultaneously display the head or the tail sides\nof their coins. If they both display the same side, then Alice wins Bob's\npenny; if they display different sides, then Bob wins Alice's penny. To avoid\ngiving the opponent a chance to win, both players seem to have nothing else to\ndo but to randomly play heads and tails with equal frequencies. However, while\nnot losing in this game is easy, not missing an opportunity to win is not.\nRandomizing your own moves can be made easy. Recognizing when the opponent's\nmoves are not random can be arbitrarily hard.\n  The notion of randomness is central in game theory, but it is usually taken\nfor granted. The notion of outsmarting is not central in game theory, but it is\ncentral in the practice of gaming. We pursue the idea that these two notions\ncan be usefully viewed as two sides of the same coin.", 
    "link": "http://arxiv.org/pdf/1503.03185v1", 
    "arxiv-id": "1503.03185v1"
},{
    "category": "cs.GT", 
    "author": "Alkmini Sgouritsa", 
    "title": "Designing Networks with Good Equilibria under Uncertainty", 
    "publish": "2015-03-11T15:56:12Z", 
    "summary": "We consider the problem of designing network cost-sharing protocols with good\nequilibria under uncertainty. The underlying game is a multicast game in a\nrooted undirected graph with nonnegative edge costs. A set of k terminal\nvertices or players need to establish connectivity with the root. The social\noptimum is the Minimum Steiner Tree. We are interested in situations where the\ndesigner has incomplete information about the input. We propose two different\nmodels, the adversarial and the stochastic. In both models, the designer has\nprior knowledge of the underlying metric but the requested subset of the\nplayers is not known and is activated either in an adversarial manner\n(adversarial model) or is drawn from a known probability distribution\n(stochastic model).\n  In the adversarial model, the designer's goal is to choose a single,\nuniversal protocol that has low Price of Anarchy (PoA) for all possible\nrequested subsets of players. The main question we address is: to what extent\ncan prior knowledge of the underlying metric help in the design? We first\ndemonstrate that there exist graphs (outerplanar) where knowledge of the\nunderlying metric can dramatically improve the performance of good network\ndesign. Then, in our main technical result, we show that there exist graph\nmetrics, for which knowing the underlying metric does not help and any\nuniversal protocol has PoA of $\\Omega(\\log k)$, which is tight. We attack this\nproblem by developing new techniques that employ powerful tools from extremal\ncombinatorics, and more specifically Ramsey Theory in high dimensional\nhypercubes.\n  Then we switch to the stochastic model, where each player is independently\nactivated. We show that there exists a randomized ordered protocol that\nachieves constant PoA. By using standard derandomization techniques, we produce\na deterministic ordered protocol with constant PoA.", 
    "link": "http://arxiv.org/pdf/1503.03392v2", 
    "arxiv-id": "1503.03392v2"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Price of Stability in Games of Incomplete Information", 
    "publish": "2015-03-12T14:27:27Z", 
    "summary": "We address the question of whether price of stability results (existence of\nequilibria with low social cost) are robust to incomplete information. We show\nthat this is the case in potential games, if the underlying algorithmic social\ncost minimization problem admits a constant factor approximation algorithm via\nstrict cost-sharing schemes. Roughly, if the existence of an\n$\\alpha$-approximate equilibrium in the complete information setting was proven\nvia the potential method, then there also exists a $\\alpha\\cdot\n\\beta$-approximate Bayes-Nash equilibrium in the incomplete information\nsetting, where $\\beta$ is the approximation factor of the strict-cost sharing\nscheme algorithm. We apply our approach to Bayesian versions of the archetypal,\nin the price of stability analysis, network design models and show the\nexistence of $O(\\log(n))$-approximate Bayes-Nash equilibria in several games\nwhose complete information counterparts have been well-studied, such as\nundirected network design games, multi-cast games and covering games.", 
    "link": "http://arxiv.org/pdf/1503.03739v1", 
    "arxiv-id": "1503.03739v1"
},{
    "category": "cs.GT", 
    "author": "Xiaoming Sun", 
    "title": "The Least-core and Nucleolus of Path Cooperative Games", 
    "publish": "2015-03-16T09:11:01Z", 
    "summary": "Cooperative games provide an appropriate framework for fair and stable profit\ndistribution in multiagent systems. In this paper, we study the algorithmic\nissues on path cooperative games that arise from the situations where some\ncommodity flows through a network. In these games, a coalition of edges or\nvertices is successful if it enables a path from the source to the sink in the\nnetwork, and lose otherwise. Based on dual theory of linear programming and the\nrelationship with flow games, we provide the characterizations on the CS-core,\nleast-core and nucleolus of path cooperative games. Furthermore, we show that\nthe least-core and nucleolus are polynomially solvable for path cooperative\ngames defined on both directed and undirected network.", 
    "link": "http://arxiv.org/pdf/1503.04575v1", 
    "arxiv-id": "1503.04575v1"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "The Price of Anarchy in Large Games", 
    "publish": "2015-03-16T18:05:47Z", 
    "summary": "Game-theoretic models relevant for computer science applications usually\nfeature a large number of players. The goal of this paper is to develop an\nanalytical framework for bounding the price of anarchy in such models. We\ndemonstrate the wide applicability of our framework through instantiations for\nseveral well-studied models, including simultaneous single-item auctions,\ngreedy combinatorial auctions, and routing games. In all cases, we identify\nconditions under which the POA of large games is much better than that of\nworst-case instances. Our results also give new senses in which simple auctions\ncan perform almost as well as optimal ones in realistic settings.", 
    "link": "http://arxiv.org/pdf/1503.04755v2", 
    "arxiv-id": "1503.04755v2"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Greedy Algorithms make Efficient Mechanisms", 
    "publish": "2015-03-18T22:58:50Z", 
    "summary": "We study mechanisms that use greedy allocation rules and pay-your-bid pricing\nto allocate resources subject to a matroid constraint. We show that all such\nmechanisms obtain a constant fraction of the optimal welfare at any equilibrium\nof bidder behavior, via a smoothness argument. This unifies numerous recent\nresults on the price of anarchy of simple auctions. Our results extend to\npolymatroid and matching constraints, and we discuss extensions to more general\nmatroid intersections.", 
    "link": "http://arxiv.org/pdf/1503.05608v1", 
    "arxiv-id": "1503.05608v1"
},{
    "category": "cs.GT", 
    "author": "Jennifer Wortman Vaughan", 
    "title": "Incentivizing High Quality Crowdwork", 
    "publish": "2015-03-19T19:19:08Z", 
    "summary": "We study the causal effects of financial incentives on the quality of\ncrowdwork. We focus on performance-based payments (PBPs), bonus payments\nawarded to workers for producing high quality work. We design and run\nrandomized behavioral experiments on the popular crowdsourcing platform Amazon\nMechanical Turk with the goal of understanding when, where, and why PBPs help,\nidentifying properties of the payment, payment structure, and the task itself\nthat make them most effective. We provide examples of tasks for which PBPs do\nimprove quality. For such tasks, the effectiveness of PBPs is not too sensitive\nto the threshold for quality required to receive the bonus, while the magnitude\nof the bonus must be large enough to make the reward salient. We also present\nexamples of tasks for which PBPs do not improve quality. Our results suggest\nthat for PBPs to improve quality, the task must be effort-responsive: the task\nmust allow workers to produce higher quality work by exerting more effort. We\nalso give a simple method to determine if a task is effort-responsive a priori.\nFurthermore, our experiments suggest that all payments on Mechanical Turk are,\nto some degree, implicitly performance-based in that workers believe their work\nmay be rejected if their performance is sufficiently poor. Finally, we propose\na new model of worker behavior that extends the standard principal-agent model\nfrom economics to include a worker's subjective beliefs about his likelihood of\nbeing paid, and show that the predictions of this model are in line with our\nexperimental findings. This model may be useful as a foundation for theoretical\nstudies of incentives in crowdsourcing markets.", 
    "link": "http://arxiv.org/pdf/1503.05897v1", 
    "arxiv-id": "1503.05897v1"
},{
    "category": "cs.GT", 
    "author": "Eckart Bindewald", 
    "title": "Achieving Multiple Goals via Voluntary Efforts and Motivation Asymmetry", 
    "publish": "2015-03-15T14:41:36Z", 
    "summary": "The achievement of common goals through voluntary efforts of members of a\ngroup can be challenged by the high temptation of individual defection. Here,\ntwo-person one-goal assurance games are generalized to N-person, M-goal\nachievement games in which group members can have different motivations with\nrespect to the achievement of the different goals. The theoretical performance\nof groups faced with the challenge of multiple simultaneous goals is analyzed\nmathematically and computationally. For two-goal scenarios one finds that\n\"polarized\" as well as \"biased\" groups perform well in the presence of\ndefectors. A special case, called individual purpose games (N-person, N-goal\nachievements games where there is a one-to-one mapping between actors and goals\nfor which they have a high achievement motivation) is analyzed in more detail\nin form of the \"importance of being different theorem\". It is shown that in\nsome individual purpose games, groups of size N can successfully accomplish N\ngoals, such that each group member is highly motivated towards the achievement\nof one unique goal. The game-theoretic results suggest that multiple goals as\nwell as differences in motivations can, in some cases, correspond to highly\neffective groups.", 
    "link": "http://arxiv.org/pdf/1503.05908v1", 
    "arxiv-id": "1503.05908v1"
},{
    "category": "cs.GT", 
    "author": "Haifeng Xu", 
    "title": "Algorithmic Bayesian Persuasion", 
    "publish": "2015-03-20T04:35:44Z", 
    "summary": "Persuasion, defined as the act of exploiting an informational advantage in\norder to effect the decisions of others, is ubiquitous. Indeed, persuasive\ncommunication has been estimated to account for almost a third of all economic\nactivity in the US. This paper examines persuasion through a computational\nlens, focusing on what is perhaps the most basic and fundamental model in this\nspace: the celebrated Bayesian persuasion model of Kamenica and Gentzkow. Here\nthere are two players, a sender and a receiver. The receiver must take one of a\nnumber of actions with a-priori unknown payoff, and the sender has access to\nadditional information regarding the payoffs. The sender can commit to\nrevealing a noisy signal regarding the realization of the payoffs of various\nactions, and would like to do so as to maximize her own payoff assuming a\nperfectly rational receiver.\n  We examine the sender's optimization task in three of the most natural input\nmodels for this problem, and essentially pin down its computational complexity\nin each. When the payoff distributions of the different actions are i.i.d. and\ngiven explicitly, we exhibit a polynomial-time (exact) algorithm, and a\n\"simple\" $(1-1/e)$-approximation algorithm. Our optimal scheme for the i.i.d.\nsetting involves an analogy to auction theory, and makes use of Border's\ncharacterization of the space of reduced-forms for single-item auctions. When\naction payoffs are independent but non-identical with marginal distributions\ngiven explicitly, we show that it is #P-hard to compute the optimal expected\nsender utility. Finally, we consider a general (possibly correlated) joint\ndistribution of action payoffs presented by a black box sampling oracle, and\nexhibit a fully polynomial-time approximation scheme (FPTAS) with a bi-criteria\nguarantee. We show that this result is the best possible in the black-box model\nfor information-theoretic reasons.", 
    "link": "http://arxiv.org/pdf/1503.05988v3", 
    "arxiv-id": "1503.05988v3"
},{
    "category": "cs.GT", 
    "author": "M. Serna", 
    "title": "On the Complexity of Exchanging", 
    "publish": "2015-03-20T12:28:44Z", 
    "summary": "We analyze the computational complexity of the problem of deciding whether,\nfor a given simple game, there exists the possibility of rearranging the\nparticipants in a set of $j$ given losing coalitions into a set of $j$ winning\ncoalitions. We also look at the problem of turning winning coalitions into\nlosing coalitions. We analyze the problem when the simple game is represented\nby a list of wining, losing, minimal winning or maximal loosing coalitions.", 
    "link": "http://arxiv.org/pdf/1503.06052v2", 
    "arxiv-id": "1503.06052v2"
},{
    "category": "cs.GT", 
    "author": "Benjamin Lubin", 
    "title": "Games and Meta-Games: Pricing Rules for Combinatorial Mechanisms", 
    "publish": "2015-03-20T22:44:19Z", 
    "summary": "In settings where full incentive-compatibility is not available, such as\ncore-constraint combinatorial auctions and budget-balanced combinatorial\nexchanges, we may wish to design mechanisms that are as incentive-compatible as\npossible. This paper offers a new characterization of approximate\nincentive-compatibility by casting the pricing problem as a meta-game between\nthe center and the participating agents. Through a suitable set of\nsimplifications, we describe the equilibrium of this game as a variational\nproblem. We use this to characterize the space of optimal prices, enabling\nclosed-form solutions in restricted cases, and numerically-determined prices in\nthe general case. We offer theory motivating this approach, and numerical\nexperiments showing its application.", 
    "link": "http://arxiv.org/pdf/1503.06244v1", 
    "arxiv-id": "1503.06244v1"
},{
    "category": "cs.GT", 
    "author": "S\u00f8ren Kristoffer Stiil Frederiksen", 
    "title": "The Adjusted Winner Procedure: Characterizations and Equilibria", 
    "publish": "2015-03-23T14:47:47Z", 
    "summary": "The Adjusted Winner procedure is an important fair division mechanism\nproposed by Brams and Taylor for allocating goods between two parties. It has\nbeen used in practice for divorce settlements and analyzing political disputes.\nAssuming truthful declaration of the valuations, it computes an allocation that\nis envy-free, equitable and Pareto optimal.\n  We show that Adjusted Winner admits several elegant characterizations, which\nfurther shed light on the outcomes reached with strategic agents. We find that\nthe procedure may not admit pure Nash equilibria in either the discrete or\ncontinuous variants, but is guaranteed to have $\\epsilon$-Nash equilibria for\neach $\\epsilon$ > 0. Moreover, under informed tie-breaking, exact pure Nash\nequilibria always exist, are Pareto optimal, and their social welfare is at\nleast 3/4 of the optimal.", 
    "link": "http://arxiv.org/pdf/1503.06665v3", 
    "arxiv-id": "1503.06665v3"
},{
    "category": "cs.GT", 
    "author": "Kameshwar Poolla", 
    "title": "Price and capacity competition in balancing markets with energy storage", 
    "publish": "2015-03-23T21:54:17Z", 
    "summary": "Energy storage can absorb variability from the rising number of wind and\nsolar power producers. Storage is different from the conventional generators\nthat have traditionally balanced supply and demand on fast time scales due to\nits hard energy capacity constraints, dynamic coupling, and low marginal costs.\nThese differences are leading system operators to propose new mechanisms for\nenabling storage to participate in reserve and real-time energy markets. The\npersistence of market power and gaming in electricity markets suggests that\nthese changes will expose new vulnerabilities.\n  We develop a new model of strategic behavior among storages in energy\nbalancing markets. Our model is a two-stage game that generalizes a classic\nmodel of capacity followed by Bertrand-Edgeworth price competition by\nexplicitly modeling storage dynamics and uncertainty in the pricing stage. By\napplying the model to balancing markets with storage, we are able to compare\ncapacity and energy-based pricing schemes, and to analyze the dynamic effects\nof the market horizon and energy losses due to leakage. Our first key finding\nis that capacity pricing leads to higher prices and higher capacity\ncommitments, and that energy pricing leads to lower, randomized prices and\nlower capacity commitments. Second, we find that a longer market horizon and\nhigher physical efficiencies lead to lower prices by inducing the storage to\ncompete to have their states of charge cycled more frequently.", 
    "link": "http://arxiv.org/pdf/1503.06851v2", 
    "arxiv-id": "1503.06851v2"
},{
    "category": "cs.GT", 
    "author": "Peter Bro Miltersen", 
    "title": "Characterization and Computation of Equilibria for Indivisible Goods", 
    "publish": "2015-03-23T21:57:58Z", 
    "summary": "We consider the problem of allocating indivisible goods in a way that is\nfair, using one of the leading market mechanisms in economics: the competitive\nequilibrium from equal incomes. Focusing on two major classes of valuations,\nnamely perfect substitutes and perfect complements, we establish the\ncomputational properties of algorithms operating in this framework. For the\nclass of valuations with perfect complements, our algorithm yields a\nsurprisingly succinct characterization of instances that admit a competitive\nequilibrium from equal incomes.", 
    "link": "http://arxiv.org/pdf/1503.06855v2", 
    "arxiv-id": "1503.06855v2"
},{
    "category": "cs.GT", 
    "author": "Mingyan Liu", 
    "title": "A Tale of Two Mechanisms: Incentivizing Investments in Security Games", 
    "publish": "2015-03-25T13:53:39Z", 
    "summary": "In a system of interdependent users, the security of an entity is affected\nnot only by that user's investment in security measures, but also by the\npositive externality of the security decisions of (some of) the other users.\nThe provision of security in such system is therefore modeled as a public good\nprovision problem, and is referred to as a security game. In this paper, we\ncompare two well-known incentive mechanisms in this context for incentivizing\noptimal security investments among users, namely the Pivotal and the\nExternality mechanisms. The taxes in a Pivotal mechanism are designed to ensure\nusers' voluntary participation, while those in an Externality mechanism are\ndevised to maintain a balanced budget. We first show the more general result\nthat, due to the non-excludable nature of security, no mechanism can\nincentivize the socially optimal investment profile, while at the same time\nensuring voluntary participation and maintaining a balanced budget for all\ninstances of security games. To further illustrate, we apply the Pivotal and\nExternality mechanisms to the special case of weighted total effort\ninterdependence models, and identify some of the effects of varying\ninterdependency between users on the budget deficit in the Pivotal mechanism,\nas well as on the participation incentives in the Externality mechanism.", 
    "link": "http://arxiv.org/pdf/1503.07377v1", 
    "arxiv-id": "1503.07377v1"
},{
    "category": "cs.GT", 
    "author": "Yair Zick", 
    "title": "Influence in Classification via Cooperative Game Theory", 
    "publish": "2015-04-30T21:22:36Z", 
    "summary": "A dataset has been classified by some unknown classifier into two types of\npoints. What were the most important factors in determining the classification\noutcome? In this work, we employ an axiomatic approach in order to uniquely\ncharacterize an influence measure: a function that, given a set of classified\npoints, outputs a value for each feature corresponding to its influence in\ndetermining the classification outcome. We show that our influence measure\ntakes on an intuitive form when the unknown classifier is linear. Finally, we\nemploy our influence measure in order to analyze the effects of user profiling\non Google's online display advertising.", 
    "link": "http://arxiv.org/pdf/1505.00036v1", 
    "arxiv-id": "1505.00036v1"
},{
    "category": "cs.GT", 
    "author": "Yair Zick", 
    "title": "Learning Cooperative Games", 
    "publish": "2015-04-30T21:36:55Z", 
    "summary": "This paper explores a PAC (probably approximately correct) learning model in\ncooperative games. Specifically, we are given $m$ random samples of coalitions\nand their values, taken from some unknown cooperative game; can we predict the\nvalues of unseen coalitions? We study the PAC learnability of several\nwell-known classes of cooperative games, such as network flow games, threshold\ntask games, and induced subgraph games. We also establish a novel connection\nbetween PAC learnability and core stability: for games that are efficiently\nlearnable, it is possible to find payoff divisions that are likely to be stable\nusing a polynomial number of samples.", 
    "link": "http://arxiv.org/pdf/1505.00039v2", 
    "arxiv-id": "1505.00039v2"
},{
    "category": "cs.GT", 
    "author": "Martin Lackner", 
    "title": "Structure in Dichotomous Preferences", 
    "publish": "2015-05-02T13:23:21Z", 
    "summary": "Many hard computational social choice problems are known to become tractable\nwhen voters' preferences belong to a restricted domain, such as those of\nsingle-peaked or single-crossing preferences. However, to date, all algorithmic\nresults of this type have been obtained for the setting where each voter's\npreference list is a total order of candidates. The goal of this paper is to\nextend this line of research to the setting where voters' preferences are\ndichotomous, i.e., each voter approves a subset of candidates and disapproves\nthe remaining candidates. We propose several analogues of the notions of\nsingle-peaked and single-crossing preferences for dichotomous profiles and\ninvestigate the relationships among them. We then demonstrate that for some of\nthese notions the respective restricted domains admit efficient algorithms for\ncomputationally hard approval-based multi-winner rules.", 
    "link": "http://arxiv.org/pdf/1505.00341v2", 
    "arxiv-id": "1505.00341v2"
},{
    "category": "cs.GT", 
    "author": "Eva Tardos", 
    "title": "Learning and Efficiency in Games with Dynamic Population", 
    "publish": "2015-05-03T03:47:12Z", 
    "summary": "We study the quality of outcomes in repeated games when the population of\nplayers is dynamically changing and participants use learning algorithms to\nadapt to the changing environment. Game theory classically considers Nash\nequilibria of one-shot games, while in practice many games are players\nrepeatedly, and in such games players often use algorithmic tools to learn to\nplay in the given environment. Learning in repeated games has only been studied\nwhen the population playing the game is stable over time.\n  We analyze efficiency of repeated games in dynamically changing environments,\nmotivated by application domains such as packet routing and Internet\nad-auctions. We prove that, in many classes of games, if players choose their\nstrategies in a way that guarantees low adaptive regret, then high social\nwelfare is ensured, even under very frequent changes. This result extends\nprevious work, which showed high welfare for learning outcomes in stable\nenvironments. A main technical tool for our analysis is the existence of a\nsolution to the welfare maximization problem that is both close to optimal and\nrelatively stable over time. Such a solution serves as a benchmark in the\nefficiency analysis of learning outcomes. We show that such stable and\nnear-optimal solutions exist for many problems, even in cases when the exact\noptimal solution can be very unstable. We develop direct techniques to show the\nexistence of a stable solution in some classes of games. Further, we show that\na sufficient condition for the existence of stable solutions is the existence\nof a differentially private algorithm for the welfare maximization problem. We\ndemonstrate our techniques by focusing on three classes of games as examples:\nsimultaneous item auctions, bandwidth allocation mechanisms and congestion\ngames.", 
    "link": "http://arxiv.org/pdf/1505.00391v3", 
    "arxiv-id": "1505.00391v3"
},{
    "category": "cs.GT", 
    "author": "Vasilis Syrgkanis", 
    "title": "Robust Data-Driven Guarantees in Auctions", 
    "publish": "2015-05-03T15:02:29Z", 
    "summary": "Analysis of welfare in auctions comes traditionally via one of two\napproaches: precise but fragile inference of the exact details of a setting\nfrom data or robust but coarse theoretical price of anarchy bounds that hold in\nany setting. As markets get more and more dynamic and bidders become more and\nmore sophisticated, the weaknesses of each approach are magnified.\n  In this paper, we provide tools for analyzing and estimating the empirical\nprice of anarchy of an auction. The empirical price of anarchy is the worst\ncase efficiency loss of any auction that could have produced the data, relative\nto the optimal.\n  Our techniques are based on inferring simple properties of auctions:\nprimarily the expected revenue and the expected payments and allocation\nprobabilities from possible bids. These quantities alone allow us to\nempirically estimate the revenue covering parameter of an auction which allows\nus to re-purpose the theoretical machinery of \\citet{HHT14} for empirical\npurposes. Moreover, we show that under general conditions the revenue covering\nparameter estimated from the data approaches the true parameter with the error\ndecreasing at the rate proportional to the square root of the number of\nauctions and at most polynomially in the number of agents.\n  Finally, we apply our techniques to a selection of advertising auctions on\nMicrosoft's Bing and find empirical results that are a significant improvement\nover the theoretical worst-case bounds.", 
    "link": "http://arxiv.org/pdf/1505.00437v5", 
    "arxiv-id": "1505.00437v5"
},{
    "category": "cs.GT", 
    "author": "Adrian Vetta", 
    "title": "The Combinatorial World (of Auctions) According to GARP", 
    "publish": "2015-05-04T01:32:29Z", 
    "summary": "Revealed preference techniques are used to test whether a data set is\ncompatible with rational behaviour. They are also incorporated as constraints\nin mechanism design to encourage truthful behaviour in applications such as\ncombinatorial auctions. In the auction setting, we present an efficient\ncombinatorial algorithm to find a virtual valuation function with the optimal\n(additive) rationality guarantee. Moreover, we show that there exists such a\nvaluation function that both is individually rational and is minimum (that is,\nit is component-wise dominated by any other individually rational, virtual\nvaluation function that approximately fits the data). Similarly, given upper\nbound constraints on the valuation function, we show how to fit the maximum\nvirtual valuation function with the optimal additive rationality guarantee. In\npractice, revealed preference bidding constraints are very demanding. We\nexplain how approximate rationality can be used to create relaxed revealed\npreference constraints in an auction. We then show how combinatorial methods\ncan be used to implement these relaxed constraints. Worst/best-case welfare\nguarantees that result from the use of such mechanisms can be quantified via\nthe minimum/maximum virtual valuation function.", 
    "link": "http://arxiv.org/pdf/1505.00508v2", 
    "arxiv-id": "1505.00508v2"
},{
    "category": "cs.GT", 
    "author": "Eva Tardos", 
    "title": "Econometrics for Learning Agents", 
    "publish": "2015-05-04T17:28:47Z", 
    "summary": "The main goal of this paper is to develop a theory of inference of player\nvaluations from observed data in the generalized second price auction without\nrelying on the Nash equilibrium assumption. Existing work in Economics on\ninferring agent values from data relies on the assumption that all participant\nstrategies are best responses of the observed play of other players, i.e. they\nconstitute a Nash equilibrium. In this paper, we show how to perform inference\nrelying on a weaker assumption instead: assuming that players are using some\nform of no-regret learning. Learning outcomes emerged in recent years as an\nattractive alternative to Nash equilibrium in analyzing game outcomes, modeling\nplayers who haven't reached a stable equilibrium, but rather use algorithmic\nlearning, aiming to learn the best way to play from previous observations. In\nthis paper we show how to infer values of players who use algorithmic learning\nstrategies. Such inference is an important first step before we move to testing\nany learning theoretic behavioral model on auction data. We apply our\ntechniques to a dataset from Microsoft's sponsored search ad auction system.", 
    "link": "http://arxiv.org/pdf/1505.00720v1", 
    "arxiv-id": "1505.00720v1"
},{
    "category": "cs.GT", 
    "author": "Nicholas R. Jennings", 
    "title": "Incentive Design for Ridesharing with Uncertainty", 
    "publish": "2015-05-07T08:14:25Z", 
    "summary": "We consider a ridesharing problem where there is uncertainty about the\ncompletion of trips from both drivers and riders. Specifically, we study\nridesharing mechanisms that aim to incentivize commuters to reveal their\nvaluation for trips and their probability of undertaking their trips. Due to\nthe interdependence created by the uncertainty on commuters' valuations, we\nshow that the Groves mechanisms are not ex-post truthful even if there is only\none commuter whose valuation depends on the other commuters' uncertainty of\nundertaking their trips. To circumvent this impossibility, we propose an\nex-post truthful mechanism, the best incentive we can design without\nsacrificing social welfare in this setting. Our mechanism pays a commuter if\nshe undertakes her trip, otherwise she is penalized for not undertaking her\ntrip. Furthermore, we identify a sufficient and necessary condition under which\nour mechanism is ex-post truthful.", 
    "link": "http://arxiv.org/pdf/1505.01617v1", 
    "arxiv-id": "1505.01617v1"
},{
    "category": "cs.GT", 
    "author": "Steven Bankes", 
    "title": "Non-spatial Probabilistic Condorcet Election Methodology", 
    "publish": "2015-05-11T07:37:25Z", 
    "summary": "There is a class of models for pol/mil/econ bargaining and conflict that is\nloosely based on the Median Voter Theorem which has been used with great\nsuccess for about 30 years. However, there are fundamental mathematical\nlimitations to these models. They apply to issues which can be represented on a\nsingle one-dimensional continuum. They represent fundamental group decision\nprocess by a deterministic Condorcet Election: deterministic voting by all\nactors, and deterministic outcomes of each vote. This work provides a\nmethodology for addressing a broader class of problems. The first extension is\nto continuous issue sets where the consequences of policies are not\nwell-described by a distance measure or utility is not monotonic in distance.\nThe second fundamental extension is to inherently discrete issue sets. Because\nthe options cannot easily be mapped into a multidimensional space so that the\nutility depends on distance, we refer to it as a non-spatial issue set. The\nthird, but most fundamental, extension is to represent the negotiating process\nas a probabilistic Condorcet election (PCE). The actors' generalized voting is\ndeterministic, but the outcomes of the votes is probabilistic. The PCE provides\nthe flexibility to make the first two extensions possible; this flexibility\ncomes at the cost of less precise predictions and more complex validation. The\nmethodology has been implemented in two proof-of-concept prototypes which\naddress the subset selection problem of forming a parliament, and strategy\noptimization for one-dimensional issues.", 
    "link": "http://arxiv.org/pdf/1505.02509v1", 
    "arxiv-id": "1505.02509v1"
},{
    "category": "cs.GT", 
    "author": "Patrick H. D. O'Callaghan", 
    "title": "Minimal conditions for parametric continuity of a utility representation", 
    "publish": "2015-05-12T01:23:33Z", 
    "summary": "Dependence on the parameter is continuous when perturbations of the parameter\npreserves strict preference for one alternative over another. We characterise\nthis property via a utility function over alternatives that depends\ncontinuously on the parameter. The class of parameter spaces where such a\nrepresentation is guaranteed to exist is also identified. When the parameter is\nthe type or belief of a player, these results have implications for Bayesian\nand psychological games. When alternatives are discrete, the representation is\njointly continuous and an extension of Berge's theorem of the maximum yields a\ncontinuous value function. We apply this result to generalise a standard\nconsumer choice problem where parameters are price-wealth vectors. When the\nparameter space is lexicographically ordered, a novel application to\nreference-dependent preferences is possible.", 
    "link": "http://arxiv.org/pdf/1505.02847v1", 
    "arxiv-id": "1505.02847v1"
},{
    "category": "cs.GT", 
    "author": "Maria Serna", 
    "title": "Stars and Celebrities: A Network Creation Game", 
    "publish": "2015-05-14T13:34:31Z", 
    "summary": "Celebrity games, a new model of network creation games is introduced. The\nspecific features of this model are that players have different celebrity\nweights and that a critical distance is taken into consideration. The aim of\nany player is to be close (at distance less than critical) to the others,\nmainly to those with high celebrity weights. The cost of each player depends on\nthe cost of establishing direct links to other players and on the sum of the\nweights of those players at a distance greater than the critical distance. We\nshow that celebrity games always have pure Nash equilibria and we characterize\nthe family of subgames having connected Nash equilibria, the so called star\ncelebrity games. We provide exact bounds for the PoA of celebrity games.\n  The PoA can be tightened when restricted to particular classes of Nash\nequilibria graphs, in particular for trees.", 
    "link": "http://arxiv.org/pdf/1505.03718v3", 
    "arxiv-id": "1505.03718v3"
},{
    "category": "cs.GT", 
    "author": "Chaitanya Swamy", 
    "title": "Computing Optimal Tolls in Routing Games without Knowing the Latency   Functions", 
    "publish": "2015-05-19T07:45:44Z", 
    "summary": "We consider the following question: in a nonatomic routing game, can the\ntolls that induce the minimum latency flow be computed without knowing the\nlatency functions? Since the latency functions are unknown, we assume we are\ngiven an oracle that has access to the underlying routing game. A query to the\noracle consists of tolls on edges, and the response is the resulting\nequilibrium flow. We show that in this model, it is impossible to obtain\noptimal tolls. However, if we augment the oracle so that it returns the total\nlatency of the equilibrium flow induced by the tolls in addition to the flow\nitself, then the required tolls can be computed with a polynomial number of\nqueries.", 
    "link": "http://arxiv.org/pdf/1505.04897v1", 
    "arxiv-id": "1505.04897v1"
},{
    "category": "cs.GT", 
    "author": "Michael McInerney", 
    "title": "Integer Valued Betting strategies and Turing Degrees", 
    "publish": "2015-05-20T09:35:27Z", 
    "summary": "Betting strategies are often expressed formally as martingales. A martingale\nis called integer-valued if each bet must be an integer value. Integer-valued\nstrategies correspond to the fact that in most betting situations, there is a\nminimum amount that a player can bet. According to a well known paradigm,\nalgorithmic randomness can be founded on the notion of betting strategies. A\nreal X is called integer-valued random if no effective integer-valued\nmartingale succeeds on X. It turns out that this notion of randomness has\ninteresting interactions with genericity and the computably enumerable degrees.\nWe investigate the computational power of the integer-valued random reals in\nterms of standard notions from computability theory.", 
    "link": "http://arxiv.org/pdf/1505.05298v1", 
    "arxiv-id": "1505.05298v1"
},{
    "category": "cs.GT", 
    "author": "Michael Franke", 
    "title": "Smart Transformations: The Evolution of Choice Principles", 
    "publish": "2015-04-30T14:59:02Z", 
    "summary": "Evolutionary game theory classically investigates which behavioral patterns\nare evolutionarily successful in a single game. More recently, a number of\ncontributions have studied the evolution of preferences instead: which\nsubjective conceptualizations of a game's payoffs give rise to evolutionarily\nsuccessful behavior in a single game. Here, we want to extend this existing\napproach even further by asking: which general patterns of subjective\nconceptualizations of payoff functions are evolutionarily successful across a\nclass of games. In other words, we will look at evolutionary competition of\npayoff transformations in \"meta-games\", obtained from averaging over payoffs of\nsingle games. Focusing for a start on the class of 2x2 symmetric games, we show\nthat regret minimization can outperform payoff maximization if agents resort to\na security strategy in case of radical uncertainty.", 
    "link": "http://arxiv.org/pdf/1505.07054v1", 
    "arxiv-id": "1505.07054v1"
},{
    "category": "cs.GT", 
    "author": "Pierre Lescanne", 
    "title": "Intelligent escalation and the principle of relativity", 
    "publish": "2015-05-27T07:45:20Z", 
    "summary": "Escalation is the fact that in a game (for instance in an auction), the\nagents play forever. The $0,1$-game is an extremely simple infinite game with\nintelligent agents in which escalation arises. It shows at the light of\nresearch on cognitive psychology the difference between intelligence\n(algorithmic mind) and rationality (algorithmic and reflective mind) in\ndecision processes. It also shows that depending on the point of view (inside\nor outside) the rationality of the agent may change which is proposed to be\ncalled the principle of relativity.", 
    "link": "http://arxiv.org/pdf/1505.07212v1", 
    "arxiv-id": "1505.07212v1"
},{
    "category": "cs.GT", 
    "author": "Renato Paes Leme", 
    "title": "Core-competitive Auctions", 
    "publish": "2015-05-29T03:10:08Z", 
    "summary": "One of the major drawbacks of the celebrated VCG auction is its low (or zero)\nrevenue even when the agents have high value for the goods and a {\\em\ncompetitive} outcome could have generated a significant revenue. A competitive\noutcome is one for which it is impossible for the seller and a subset of buyers\nto `block' the auction by defecting and negotiating an outcome with higher\npayoffs for themselves. This corresponds to the well-known concept of {\\em\ncore} in cooperative game theory.\n  In particular, VCG revenue is known to be not competitive when the goods\nbeing sold have complementarities. A bottleneck here is an impossibility result\nshowing that there is no auction that simultaneously achieves competitive\nprices (a core outcome) and incentive-compatibility.\n  In this paper we try to overcome the above impossibility result by asking the\nfollowing natural question: is it possible to design an incentive-compatible\nauction whose revenue is comparable (even if less) to a competitive outcome?\nTowards this, we define a notion of {\\em core-competitive} auctions. We say\nthat an incentive-compatible auction is $\\alpha$-core-competitive if its\nrevenue is at least $1/\\alpha$ fraction of the minimum revenue of a\ncore-outcome. We study the Text-and-Image setting. In this setting, there is an\nad slot which can be filled with either a single image ad or $k$ text ads. We\ndesign an $O(\\ln \\ln k)$ core-competitive randomized auction and an\n$O(\\sqrt{\\ln(k)})$ competitive deterministic auction for the Text-and-Image\nsetting. We also show that both factors are tight.", 
    "link": "http://arxiv.org/pdf/1505.07911v2", 
    "arxiv-id": "1505.07911v2"
},{
    "category": "cs.GT", 
    "author": "David Smith", 
    "title": "The Application of Non-Cooperative Stackelberg Game Theory in Behavioral   Science: Social Optimality with any Number of Players", 
    "publish": "2015-04-29T14:17:29Z", 
    "summary": "Here we present a ground-breaking new postulate for game theory. The first\npart of this postulate contains the axiomatic observation that all games are\ncreated by a designer, whether they are: e.g., (dynamic/static) or\n(stationary/non-stationary) or (sequential/one-shot) non-cooperative games, and\nimportantly, whether or not they are intended to represent a non-cooperative\nStackelberg game, they can be mapped to a Stackelberg game. I.e., the game\ndesigner is the leader who is totally rational and honest, and the followers\nare mapped to the players of the designed game. If now the game designer, or\n\"the leader\" in the Stackelberg context, adopts a pure strategy, we postulate\nthe following second part following from axiomatic observation of ultimate game\nleadership, where empirical insight leads to the second part of this postulate.\nImportantly, implementing a non-cooperative Stackelberg game, with a very\nhonest and rational leader results in social optimality for all players\n(followers), assuming pure strategy across all followers and leader, and that\nthe leader is totally rational, honest, and is able to achieve a minimum amount\nof competency in leading this game, with any finite number of iterations of\nleading this finite game.", 
    "link": "http://arxiv.org/pdf/1506.00012v1", 
    "arxiv-id": "1506.00012v1"
},{
    "category": "cs.GT", 
    "author": "Massimo Franceschetti", 
    "title": "Group buying with bundle discounts: computing efficient, stable and fair   solutions", 
    "publish": "2015-06-01T21:36:34Z", 
    "summary": "We model a market in which nonstrategic vendors sell items of different types\nand offer bundles at discounted prices triggered by demand volumes. Each buyer\nacts strategically in order to maximize her utility, given by the difference\nbetween product valuation and price paid. Buyers report their valuations in\nterms of reserve prices on sets of items, and might be willing to pay prices\ndifferent than the market price in order to subsidize other buyers and to\ntrigger discounts. The resulting price discrimination can be interpreted as a\nredistribution of the total discount. We consider a notion of stability that\nlooks at unilateral deviations, and show that efficient allocations - the ones\nmaximizing the social welfare - can be stabilized by prices that enjoy\ndesirable properties of rationality and fairness. These dictate that buyers pay\nhigher prices only to subsidize others who contribute to the activation of the\ndesired discounts, and that they pay premiums over the discounted price\nproportionally to their surplus - the difference between their current utility\nand the utility of their best alternative. Therefore, the resulting price\ndiscrimination appears to be desirable to buyers. Building on this existence\nresult, and letting N, M and c be the numbers of buyers, vendors and product\ntypes, we propose a O(N^2+NM^c) algorithm that, given an efficient allocation,\ncomputes prices that are rational and fair and that stabilize the market. The\nalgorithm first determines the redistribution of the discount between groups of\nbuyers with an equal product choice, and then computes single buyers' prices.\nOur results show that if a desirable form of price discrimination is\nimplemented then social efficiency and stability can coexists in a market\npresenting subtle externalities, and computing individual prices from market\nprices is tractable.", 
    "link": "http://arxiv.org/pdf/1506.00682v5", 
    "arxiv-id": "1506.00682v5"
},{
    "category": "cs.GT", 
    "author": "Philipp Zahn", 
    "title": "Higher-Order Game Theory", 
    "publish": "2015-06-02T19:39:53Z", 
    "summary": "In applied game theory the motivation of players is a key element. It is\nencoded in the payoffs of the game form and often based on utility functions.\nBut there are cases were formal descriptions in the form of a utility function\ndo not exist. In this paper we introduce a representation of games where\nplayers' goals are modeled based on so-called higher-order functions. Our\nrepresentation provides a general and powerful way to mathematically summarize\nplayers' intentions. In our framework utility functions as well as preference\nrelations are special cases to describe players' goals. We show that in\nhigher-order functions formal descriptions of players may still exist where\nutility functions do not using a classical example, a variant of Keynes' beauty\ncontest. We also show that equilibrium conditions based on Nash can be easily\nadapted to our framework. Lastly, this framework serves as a stepping stone to\npowerful tools from computer science that can be usefully applied to economic\ngame theory in the future such as computational and computability aspects.", 
    "link": "http://arxiv.org/pdf/1506.01002v2", 
    "arxiv-id": "1506.01002v2"
},{
    "category": "cs.GT", 
    "author": "Philipp Zahn", 
    "title": "Higher-Order Decision Theory", 
    "publish": "2015-06-02T19:40:46Z", 
    "summary": "Classical decision theory models behaviour in terms of utility maximisation\nwhere utilities represent rational preference relations over outcomes. However,\nempirical evidence and theoretical considerations suggest that we need to go\nbeyond this framework. We propose to represent goals by higher-order functions\nor operators that take other functions as arguments where the max and argmax\noperators are special cases. Our higher-order functions take a context function\nas their argument where a context represents a process from actions to\noutcomes. By that we can define goals being dependent on the actions and the\nprocess in addition to outcomes only. This formulation generalises outcome\nbased preferences to context-dependent goals. We show how to uniformly\nrepresent within our higher-order framework classical utility maximisation but\nalso various other extensions that have been debated in economics.", 
    "link": "http://arxiv.org/pdf/1506.01003v2", 
    "arxiv-id": "1506.01003v2"
},{
    "category": "cs.GT", 
    "author": "Pascal Lenzner", 
    "title": "Network Creation Games: Think Global - Act Local", 
    "publish": "2015-06-08T18:53:19Z", 
    "summary": "We investigate a non-cooperative game-theoretic model for the formation of\ncommunication networks by selfish agents. Each agent aims for a central\nposition at minimum cost for creating edges. In particular, the general model\n(Fabrikant et al., PODC'03) became popular for studying the structure of the\nInternet or social networks. Despite its significance, locality in this game\nwas first studied only recently (Bil\\`o et al., SPAA'14), where a worst case\nlocality model was presented, which came with a high efficiency loss in terms\nof quality of equilibria. Our main contribution is a new and more optimistic\nview on locality: agents are limited in their knowledge and actions to their\nlocal view ranges, but can probe different strategies and finally choose the\nbest. We study the influence of our locality notion on the hardness of\ncomputing best responses, convergence to equilibria, and quality of equilibria.\nMoreover, we compare the strength of local versus non-local strategy-changes.\nOur results address the gap between the original model and the worst case\nlocality variant. On the bright side, our efficiency results are in line with\nobservations from the original model, yet we have a non-constant lower bound on\nthe price of anarchy.", 
    "link": "http://arxiv.org/pdf/1506.02616v1", 
    "arxiv-id": "1506.02616v1"
}]