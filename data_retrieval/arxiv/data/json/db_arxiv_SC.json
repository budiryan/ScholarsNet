[{
    "category": "cs.SC", 
    "doi": "10.1088/0266-5611/30/3/035004", 
    "link": "http://arxiv.org/pdf/cs/0206032v1", 
    "title": "A correct proof of the heuristic GCD algorithm", 
    "arxiv-id": "cs/0206032v1", 
    "author": "Bernard Parisse", 
    "publish": "2002-06-21T06:49:37Z", 
    "summary": "In this note, we fill a gap in the proof of the heuristic GCD in the\nmultivariate case made by Char, Geddes and Gonnet (JSC 1989) and give some\nadditionnal information on this method."
},{
    "category": "cs.SC", 
    "doi": "10.1088/0266-5611/30/3/035004", 
    "link": "http://arxiv.org/pdf/cs/0207006v1", 
    "title": "Orthonormal RBF wavelet and ridgelet-like series and transforms for   high-dimensional problems", 
    "arxiv-id": "cs/0207006v1", 
    "author": "W. Chen", 
    "publish": "2002-07-03T15:34:39Z", 
    "summary": "This paper developed a systematic strategy establishing RBF on the wavelet\nanalysis, which includes continuous and discrete RBF orthonormal wavelet\ntransforms respectively in terms of singular fundamental solutions and\nnonsingular general solutions of differential operators. In particular, the\nharmonic Bessel RBF transforms were presented for high-dimensional data\nprocessing. It was also found that the kernel functions of convection-diffusion\noperator are feasible to construct some stable ridgelet-like RBF transforms. We\npresented time-space RBF transforms based on non-singular solution and\nfundamental solution of time-dependent differential operators. The present\nmethodology was further extended to analysis of some known RBFs such as the MQ,\nGaussian and pre-wavelet kernel RBFs."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0207034v1", 
    "title": "A Note on the DQ Analysis of Anisotropic Plates", 
    "arxiv-id": "cs/0207034v1", 
    "author": "Tingxiu Zhong", 
    "publish": "2002-07-09T20:04:28Z", 
    "summary": "Recently, Bert, Wang and Striz [1, 2] applied the differential quadrature\n(DQ) and harmonic differential quadrature (HDQ) methods to analyze static and\ndynamic behaviors of anisotropic plates. Their studies showed that the methods\nwere conceptually simple and computationally efficient in comparison to other\nnumerical techniques. Based on some recent work by the present author [3, 4],\nthe purpose of this note is to further simplify the formulation effort and\nimprove computing efficiency in applying the DQ and HDQ methods for these\ncases."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0208031v1", 
    "title": "Parameterized Type Definitions in Mathematica: Methods and Advantages", 
    "arxiv-id": "cs/0208031v1", 
    "author": "Alina Andreica", 
    "publish": "2002-08-20T13:19:42Z", 
    "summary": "The theme of symbolic computation in algebraic categories has become of\nutmost importance in the last decade since it enables the automatic modeling of\nmodern algebra theories. On this theoretical background, the present paper\nreveals the utility of the parameterized categorical approach by deriving a\nmultivariate polynomial category (over various coefficient domains), which is\nused by our Mathematica implementation of Buchberger's algorithms for\ndetermining the Groebner basis. These implementations are designed according to\ndomain and category parameterization principles underlining their advantages:\noperation protection, inheritance, generality, easy extendibility. In\nparticular, such an extension of Mathematica, a widely used symbolic\ncomputation system, with a new type system has a certain practical importance.\nThe approach we propose for Mathematica is inspired from D. Gruntz and M.\nMonagan's work in Gauss, for Maple."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0301029v1", 
    "title": "Size reduction and partial decoupling of systems of equations", 
    "arxiv-id": "cs/0301029v1", 
    "author": "Thomas Wolf", 
    "publish": "2003-01-28T06:16:25Z", 
    "summary": "A method is presented that reduces the number of terms of systems of linear\nequations (algebraic, ordinary and partial differential equations). As a\nbyproduct these systems have a tendency to become partially decoupled and are\nmore likely to be factorizable or integrable. A variation of this method is\napplicable to non-linear systems. Modifications to improve efficiency are given\nand examples are shown. This procedure can be used in connection with the\ncomputation of the radical of a differential ideal (differential Groebner\nbasis)."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0304003v2", 
    "title": "TCTL Inevitability Analysis of Dense-time Systems", 
    "arxiv-id": "cs/0304003v2", 
    "author": "Fang Yu", 
    "publish": "2003-04-01T07:28:29Z", 
    "summary": "Inevitability properties in branching temporal logics are of the syntax\nforall eventually \\phi, where \\phi is an arbitrary (timed) CTL formula. In the\nsense that \"good things will happen\", they are parallel to the \"liveness\"\nproperties in linear temporal logics. Such inevitability properties in\ndense-time logics can be analyzed with greatest fixpoint calculation. We\npresent algorithms to model-check inevitability properties both with and\nwithout requirement of non-Zeno computations. We discuss a technique for early\ndecision on greatest fixpoints in the temporal logics, and experiment with the\neffect of non-Zeno computations on the evaluation of greatest fixpoints. We\nalso discuss the TCTL subclass with only universal path quantifiers which\nallows for the safe abstraction analysis of inevitability properties. Finally,\nwe report our implementation and experiments to show the plausibility of our\nideas."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0304004v2", 
    "title": "Quasi-Optimal Arithmetic for Quaternion Polynomials", 
    "arxiv-id": "cs/0304004v2", 
    "author": "Martin Ziegler", 
    "publish": "2003-04-01T19:21:21Z", 
    "summary": "Fast algorithms for arithmetic on real or complex polynomials are well-known\nand have proven to be not only asymptotically efficient but also very\npractical. Based on Fast Fourier Transform (FFT), they for instance multiply\ntwo polynomials of degree up to N or multi-evaluate one at N points\nsimultaneously within quasi-linear time O(N.polylog N). An extension to (and in\nfact the mere definition of) polynomials over the skew-field H of quaternions\nis promising but still missing. The present work proposes three such\ndefinitions which in the commutative case coincide but for H turn out to\ndiffer, each one satisfying some desirable properties while lacking others. For\neach notion we devise algorithms for according arithmetic; these are\nquasi-optimal in that their running times match lower complexity bounds up to\npolylogarithmic factors."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0309008v1", 
    "title": "Digital Version of Green`s Theorem and its Application to The Coverage   Problem in Formal Verification", 
    "arxiv-id": "cs/0309008v1", 
    "author": "Emil Saucan", 
    "publish": "2003-09-07T05:13:44Z", 
    "summary": "We present a novel scheme to the coverage problem, introducing a quantitative\nway to estimate the interaction between a block and its enviroment.This is\nachieved by setting a discrete version of Green`s theorem, specially adapted\nfor Model Checking based verification of integrated circuits.This method is\nbest suited for the coverage problem since it enables one to quantify the\nincompleteness or, on the other hand, the redundancy of a set of rules,\ndescribing the model under verification.Moreover this can be done continuously\nthroughout the verification process, thus enabling the user to pinpoint the\nstages at which incompleteness/redundancy occurs. Although the method is\npresented locally on a small hardware example, we additionally show its\npossibility to provide precise coverage estimation also for large scale\nsystems. We compare this method to others by checking it on the same\ntest-cases."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0404008v2", 
    "title": "Efficient dot product over word-size finite fields", 
    "arxiv-id": "cs/0404008v2", 
    "author": "Jean-Guillaume Dumas", 
    "publish": "2004-04-05T07:24:15Z", 
    "summary": "We want to achieve efficiency for the exact computation of the dot product of\ntwo vectors over word-size finite fields. We therefore compare the practical\nbehaviors of a wide range of implementation techniques using different\nrepresentations. The techniques used include oating point representations,\ndiscrete logarithms, tabulations, Montgomery reduction, delayed modulus."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0405060v1", 
    "title": "An unexpected application of minimization theory to module   decompositions", 
    "arxiv-id": "cs/0405060v1", 
    "author": "Eric Laugerotte", 
    "publish": "2004-05-17T18:44:59Z", 
    "summary": "The aim of this work is to show how we can decompose a module (if\ndecomposable) into an indecomposable module with the help of the minimization\nprocess."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0406002v1", 
    "title": "A novel approach to symbolic algebra", 
    "arxiv-id": "cs/0406002v1", 
    "author": "Thomas Fischbacher", 
    "publish": "2004-06-02T12:13:55Z", 
    "summary": "A prototype for an extensible interactive graphical term manipulation system\nis presented that combines pattern matching and nondeterministic evaluation to\nprovide a convenient framework for doing tedious algebraic manipulations that\nso far had to be done manually in a semi-automatic fashion."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0409048v1", 
    "title": "FORM Matters: Fast Symbolic Computation under UNIX", 
    "arxiv-id": "cs/0409048v1", 
    "author": "Michael M. Tung", 
    "publish": "2004-09-27T17:25:34Z", 
    "summary": "We give a brief introduction to FORM, a symbolic programming language for\nmassive batch operations, designed by J.A.M. Vermaseren. In particular, we\nstress various methods to efficiently use FORM under the UNIX operating system.\nSeveral scripts and examples are given, and suggestions on how to use the vim\neditor as development platform."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0411063v1", 
    "title": "From Tensor Equations to Numerical Code -- Computer Algebra Tools for   Numerical Relativity", 
    "arxiv-id": "cs/0411063v1", 
    "author": "Sascha Husa", 
    "publish": "2004-11-17T14:30:18Z", 
    "summary": "In this paper we present our recent work in developing a computer-algebra\ntool for systems of partial differential equations (PDEs), termed \"Kranc\". Our\nwork is motivated by the problem of finding solutions of the Einstein equations\nthrough numerical simulations. Kranc consists of Mathematica based\ncomputer-algebra packages, that facilitate the task of dealing with symbolic\ntensorial calculations and realize the conversion of systems of partial\ndifferential evolution equations into parallelized C or Fortran code."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0412005v1", 
    "title": "Jordan Normal and Rational Normal Form Algorithms", 
    "arxiv-id": "cs/0412005v1", 
    "author": "Morgane Vaughan", 
    "publish": "2004-12-02T09:39:30Z", 
    "summary": "In this paper, we present a determinist Jordan normal form algorithms based\non the Fadeev formula: \\[(\\lambda \\cdot I-A) \\cdot B(\\lambda)=P(\\lambda) \\cdot\nI\\] where $B(\\lambda)$ is $(\\lambda \\cdot I-A)$'s comatrix and $P(\\lambda)$ is\n$A$'s characteristic polynomial. This rational Jordan normal form algorithm\ndiffers from usual algorithms since it is not based on the Frobenius/Smith\nnormal form but rather on the idea already remarked in Gantmacher that the\nnon-zero column vectors of $B(\\lambda_0)$ are eigenvectors of $A$ associated to\n$\\lambda_0$ for any root $\\lambda_0$ of the characteristical polynomial. The\ncomplexity of the algorithm is $O(n^4)$ field operations if we know the\nfactorization of the characteristic polynomial (or $O(n^5 \\ln(n))$ operations\nfor a matrix of integers of fixed size). This algorithm has been implemented\nusing the Maple and Giac/Xcas computer algebra systems."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0501074v2", 
    "title": "Efficient Computation of the Characteristic Polynomial", 
    "arxiv-id": "cs/0501074v2", 
    "author": "Zhendong Wan", 
    "publish": "2005-01-25T13:16:16Z", 
    "summary": "This article deals with the computation of the characteristic polynomial of\ndense matrices over small finite fields and over the integers. We first present\ntwo algorithms for the finite fields: one is based on Krylov iterates and\nGaussian elimination. We compare it to an improvement of the second algorithm\nof Keller-Gehrig. Then we show that a generalization of Keller-Gehrig's third\nalgorithm could improve both complexity and computational time. We use these\nresults as a basis for the computation of the characteristic polynomial of\ninteger matrices. We first use early termination and Chinese remaindering for\ndense matrices. Then a probabilistic approach, based on integer minimal\npolynomial and Hensel factorization, is particularly well suited to sparse\nand/or structured matrices."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0503073v2", 
    "title": "Tensor manipulation in GPL Maxima", 
    "arxiv-id": "cs/0503073v2", 
    "author": "Viktor Toth", 
    "publish": "2005-03-26T14:41:49Z", 
    "summary": "GPL Maxima is an open-source computer algebra system based on DOE-MACSYMA.\nGPL Maxima included two tensor manipulation packages from DOE-MACSYMA, but\nthese were in various states of disrepair. One of the two packages, CTENSOR,\nimplemented component-based tensor manipulation; the other, ITENSOR, treated\ntensor symbols as opaque, manipulating them based on their index properties.\nThe present paper describes the state in which these packages were found, the\nsteps that were needed to make the packages fully functional again, and the new\nfunctionality that was implemented to make them more versatile. A third\npackage, ATENSOR, was also implemented; fully compatible with the identically\nnamed package in the commercial version of MACSYMA, ATENSOR implements abstract\ntensor algebras."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsvi.1996.0895", 
    "link": "http://arxiv.org/pdf/cs/0510057v1", 
    "title": "Towards a diagrammatic modeling of the LinBox C++ linear algebra library", 
    "arxiv-id": "cs/0510057v1", 
    "author": "Dominique Duval", 
    "publish": "2005-10-20T15:07:18Z", 
    "summary": "We propose a new diagrammatic modeling language, DML. The paradigm used is\nthat of the category theory and in particular of the pushout tool. We show that\nmost of the object-oriented structures can be described with this tool and have\nmany examples in C++, ranging from virtual inheritance and polymorphism to\ntemplate genericity. With this powerful tool, we propose a quite simple\ndescription of the C++ LinBox library. This library has been designed for\nefficiency and genericity and therefore makes heavy usage of complex template\nand polymorphic mecanism. Be reverse engineering, we are able to describe in a\nsimple manner the complex structure of archetypes in LinBox."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0510093v1", 
    "title": "ParFORM: recent development", 
    "arxiv-id": "cs/0510093v1", 
    "author": "H. M. Staudenmaier", 
    "publish": "2005-10-31T14:19:41Z", 
    "summary": "We report on the status of our project of parallelization of the symbolic\nmanipulation program FORM. We have now parallel versions of FORM running on\nCluster- or SMP-architectures. These versions can be used to run arbitrary FORM\nprograms in parallel."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0511033v1", 
    "title": "Fast (Multi-)Evaluation of Linearly Recurrent Sequences: Improvements   and Applications", 
    "arxiv-id": "cs/0511033v1", 
    "author": "Martin Ziegler", 
    "publish": "2005-11-08T16:46:18Z", 
    "summary": "For a linearly recurrent vector sequence P[n+1] = A(n) * P[n], consider the\nproblem of calculating either the n-th term P[n] or L<=n arbitrary terms\nP[n_1],...,P[n_L], both for the case of constant coefficients A(n)=A and for a\nmatrix A(n) with entries polynomial in n. We improve and extend known\nalgorithms for this problem and present new applications for it. Specifically\nit turns out that for instance * any family (p_n) of classical orthogonal\npolynomials admits evaluation at given x within O(n^{1/2} log n) operations\nINDEPENDENT of the family (p_n) under consideration. * For any L indices\nn_1,...,n_L <= n, the values p_{n_i}(x) can be calculated simultaneously using\nO(n^{1/2} log n + L log(n/L)) arithmetic operations; again this running time\nbound holds uniformly. * Every hypergeometric (or, more generally, holonomic)\nfunction admits approximate evaluation up to absolute error e>0 within\nO((log(1/e)^{1/2} loglog(1/e)) -- as opposed to O(log(1/e)) -- arithmetic\nsteps. * Given m and a polynomial p of degree d over a field of characteristic\nzero, the coefficient of p^m to term X^n can be computed within O(d^2\nM(n^{1/2})) steps where M(n) denotes the cost of multiplying two degree-n\npolynomials. * The same time bound holds for the joint calculation of any\nL<=n^{1/2} desired coefficients of p^m to terms X^{n_i}, n_1,...,n_L <= n."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0511066v5", 
    "title": "An introspective algorithm for the integer determinant", 
    "arxiv-id": "cs/0511066v5", 
    "author": "Anna Urbanska", 
    "publish": "2005-11-17T14:53:41Z", 
    "summary": "We present an algorithm computing the determinant of an integer matrix A. The\nalgorithm is introspective in the sense that it uses several distinct\nalgorithms that run in a concurrent manner. During the course of the algorithm\npartial results coming from distinct methods can be combined. Then, depending\non the current running time of each method, the algorithm can emphasize a\nparticular variant. With the use of very fast modular routines for linear\nalgebra, our implementation is an order of magnitude faster than other existing\nimplementations. Moreover, we prove that the expected complexity of our\nalgorithm is only O(n^3 log^{2.5}(n ||A||)) bit operations in the dense case\nand O(Omega n^{1.5} log^2(n ||A||) + n^{2.5}log^3(n||A||)) in the sparse case,\nwhere ||A|| is the largest entry in absolute value of the matrix and Omega is\nthe cost of matrix-vector multiplication in the case of a sparse matrix."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0601133v3", 
    "title": "Dense Linear Algebra over Finite Fields: the FFLAS and FFPACK packages", 
    "arxiv-id": "cs/0601133v3", 
    "author": "Cl\u00e9ment Pernet", 
    "publish": "2006-01-31T09:54:41Z", 
    "summary": "In the past two decades, some major efforts have been made to reduce exact\n(e.g. integer, rational, polynomial) linear algebra problems to matrix\nmultiplication in order to provide algorithms with optimal asymptotic\ncomplexity. To provide efficient implementations of such algorithms one need to\nbe careful with the underlying arithmetic. It is well known that modular\ntechniques such as the Chinese remainder algorithm or the p-adic lifting allow\nvery good practical performance, especially when word size arithmetic are used.\nTherefore, finite field arithmetic becomes an important core for efficient\nexact linear algebra libraries. In this paper, we study high performance\nimplementations of basic linear algebra routines over word size prime fields:\nspecially the matrix multiplication; our goal being to provide an exact\nalternate to the numerical BLAS library. We show that this is made possible by\na carefull combination of numerical computations and asymptotically faster\nalgorithms. Our kernel has several symbolic linear algebra applications enabled\nby diverse matrix multiplication reductions: symbolic triangularization, system\nsolving, determinant and matrix inverse implementations are thus studied."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0602064v1", 
    "title": "Computing spectral sequences", 
    "arxiv-id": "cs/0602064v1", 
    "author": "F. Sergeraert", 
    "publish": "2006-02-17T12:29:57Z", 
    "summary": "In this paper, a set of programs enhancing the Kenzo system is presented.\nKenzo is a Common Lisp program designed for computing in Algebraic Topology, in\nparticular it allows the user to calculate homology and homotopy groups of\ncomplicated spaces. The new programs presented here entirely compute Serre and\nEilenberg-Moore spectral sequences, in particular the groups and differential\nmaps for arbitrary r. They also determine when the spectral sequence has\nconverged and describe the filtration of the target homology groups induced by\nthe spectral sequence."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0603082v1", 
    "title": "Solving Sparse Integer Linear Systems", 
    "arxiv-id": "cs/0603082v1", 
    "author": "Gilles Villard", 
    "publish": "2006-03-21T16:09:45Z", 
    "summary": "We propose a new algorithm to solve sparse linear systems of equations over\nthe integers. This algorithm is based on a $p$-adic lifting technique combined\nwith the use of block matrices with structured blocks. It achieves a sub-cubic\ncomplexity in terms of machine operations subject to a conjecture on the\neffectiveness of certain sparse projections. A LinBox-based implementation of\nthis algorithm is demonstrated, and emphasizes the practical benefits of this\nnew method over the previous state of the art."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0604060v1", 
    "title": "Polynomial Time Nondimensionalisation of Ordinary Differential Equations   via their Lie Point Symmetries", 
    "arxiv-id": "cs/0604060v1", 
    "author": "Alexandre Sedoglavic", 
    "publish": "2006-04-13T14:35:00Z", 
    "summary": "Lie group theory states that knowledge of a $m$-parameters solvable group of\nsymmetries of a system of ordinary differential equations allows to reduce by\n$m$ the number of equation. We apply this principle by finding dilatations and\ntranslations that are Lie point symmetries of considered ordinary differential\nsystem. By rewriting original problem in an invariant coordinates set for these\nsymmetries, one can reduce the involved number of parameters. This process is\nclassically call nondimensionalisation in dimensional analysis. We present an\nalgorithm based on this standpoint and show that its arithmetic complexity is\npolynomial in input's size."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0604101v1", 
    "title": "Fast computation of power series solutions of systems of differential   equations", 
    "arxiv-id": "cs/0604101v1", 
    "author": "Alexandre Sedoglavic", 
    "publish": "2006-04-25T15:25:35Z", 
    "summary": "We propose new algorithms for the computation of the first N terms of a\nvector (resp. a basis) of power series solutions of a linear system of\ndifferential equations at an ordinary point, using a number of arithmetic\noperations which is quasi-linear with respect to N. Similar results are also\ngiven in the non-linear case. This extends previous results obtained by Brent\nand Kung for scalar differential equations of order one and two."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.142", 
    "link": "http://arxiv.org/pdf/cs/0605021v1", 
    "title": "SAT Techniques for Lexicographic Path Orders", 
    "arxiv-id": "cs/0605021v1", 
    "author": "Harald Zankl", 
    "publish": "2006-05-05T19:11:22Z", 
    "summary": "This seminar report is concerned with expressing LPO-termination of term\nrewrite systems as a satisfiability problem in propositional logic. After\nrelevant algorithms are explained, experimental results are reported."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0605068v1", 
    "title": "Low Complexity Algorithms for Linear Recurrences", 
    "arxiv-id": "cs/0605068v1", 
    "author": "Thomas Cluzeau", 
    "publish": "2006-05-16T10:03:04Z", 
    "summary": "We consider two kinds of problems: the computation of polynomial and rational\nsolutions of linear recurrences with coefficients that are polynomials with\ninteger coefficients; indefinite and definite summation of sequences that are\nhypergeometric over the rational numbers. The algorithms for these tasks all\ninvolve as an intermediate quantity an integer $N$ (dispersion or root of an\nindicial polynomial) that is potentially exponential in the bit size of their\ninput. Previous algorithms have a bit complexity that is at least quadratic in\n$N$. We revisit them and propose variants that exploit the structure of\nsolutions and avoid expanding polynomials of degree $N$. We give two\nalgorithms: a probabilistic one that detects the existence or absence of\nnonzero polynomial and rational solutions in $O(\\sqrt{N}\\log^{2}N)$ bit\noperations; a deterministic one that computes a compact representation of the\nsolution in $O(N\\log^{3}N)$ bit operations. Similar speed-ups are obtained in\nindefinite and definite hypergeometric summation. We describe the results of an\nimplementation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0606031v1", 
    "title": "Complexity of Resolution of Parametric Systems of Polynomial Equations   and Inequations", 
    "arxiv-id": "cs/0606031v1", 
    "author": "Guillaume Moroz", 
    "publish": "2006-06-07T14:44:53Z", 
    "summary": "Consider a system of n polynomial equations and r polynomial inequations in n\nindeterminates of degree bounded by d with coefficients in a polynomial ring of\ns parameters with rational coefficients of bit-size at most $\\sigma$. From the\nreal viewpoint, solving such a system often means describing some\nsemi-algebraic sets in the parameter space over which the number of real\nsolutions of the considered parametric system is constant. Following the works\nof Lazard and Rouillier, this can be done by the computation of a discriminant\nvariety. In this report we focus on the case where for a generic specialization\nof the parameters the system of equations generates a radical zero-dimensional\nideal, which is usual in the applications. In this case, we provide a\ndeterministic method computing the minimal discriminant variety reducing the\nproblem to a problem of elimination. Moreover, we prove that the degree of the\ncomputed minimal discriminant variety is bounded by $D:=(n+r)d^{(n+1)}$ and\nthat the complexity of our method is $\\sigma^{\\mathcal{O}(1)}\nD^{\\mathcal{O}(n+s)}$ bit-operations on a deterministic Turing machine."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0610051v2", 
    "title": "Strong bi-homogeneous B\u00e9zout theorem and its use in effective real   algebraic geometry", 
    "arxiv-id": "cs/0610051v2", 
    "author": "Philippe Trebuchet", 
    "publish": "2006-10-10T15:02:07Z", 
    "summary": "Let f1, ..., fs be a polynomial family in Q[X1,..., Xn] (with s less than n)\nof degree bounded by D. Suppose that f1, ..., fs generates a radical ideal, and\ndefines a smooth algebraic variety V. Consider a projection P. We prove that\nthe degree of the critical locus of P restricted to V is bounded by\nD^s(D-1)^(n-s) times binomial of n and n-s. This result is obtained in two\nsteps. First the critical points of P restricted to V are characterized as\nprojections of the solutions of Lagrange's system for which a bi-homogeneous\nstructure is exhibited. Secondly we prove a bi-homogeneous B\\'ezout Theorem,\nwhich bounds the sum of the degrees of the equidimensional components of the\nradical of an ideal generated by a bi-homogeneous polynomial family. This\nresult is improved when f1,..., fs is a regular sequence. Moreover, we use\nLagrange's system to design an algorithm computing at least one point in each\nconnected component of a smooth real algebraic set. This algorithm generalizes,\nto the non equidimensional case, the one of Safey El Din and Schost. The\nevaluation of the output size of this algorithm gives new upper bounds on the\nfirst Betti number of a smooth real algebraic set. Finally, we estimate its\narithmetic complexity and prove that in the worst cases it is polynomial in n,\ns, D^s(D-1)^(n-s) and the binomial of n and n-s, and the complexity of\nevaluation of f1,..., fs."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0610136v4", 
    "title": "Bounds on the coefficients of the characteristic and minimal polynomials", 
    "arxiv-id": "cs/0610136v4", 
    "author": "Jean-Guillaume Dumas", 
    "publish": "2006-10-24T08:24:08Z", 
    "summary": "This note presents absolute bounds on the size of the coefficients of the\ncharacteristic and minimal polynomials depending on the size of the\ncoefficients of the associated matrix. Moreover, we present algorithms to\ncompute more precise input-dependant bounds on these coefficients. Such bounds\nare e.g. useful to perform deterministic chinese remaindering of the\ncharacteristic or minimal polynomial of an integer matrix."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0611041v1", 
    "title": "Groebner Bases Applied to Systems of Linear Difference Equations", 
    "arxiv-id": "cs/0611041v1", 
    "author": "V. P. Gerdt", 
    "publish": "2006-11-09T10:41:31Z", 
    "summary": "In this paper we consider systems of partial (multidimensional) linear\ndifference equations. Specifically, such systems arise in scientific computing\nunder discretization of linear partial differential equations and in\ncomputational high energy physics as recurrence relations for multiloop Feynman\nintegrals. The most universal algorithmic tool for investigation of linear\ndifference systems is based on their transformation into an equivalent Groebner\nbasis form. We present an algorithm for this transformation implemented in\nMaple. The algorithm and its implementation can be applied to automatic\ngeneration of difference schemes for linear partial differential equations and\nto reduction of Feynman integrals. Some illustrative examples are given."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0612094v1", 
    "title": "Reduction of Algebraic Parametric Systems by Rectification of their   Affine Expanded Lie Symmetries", 
    "arxiv-id": "cs/0612094v1", 
    "author": "Alexandre Sedoglavic", 
    "publish": "2006-12-19T14:58:15Z", 
    "summary": "Lie group theory states that knowledge of a $m$-parameters solvable group of\nsymmetries of a system of ordinary differential equations allows to reduce by\n$m$ the number of equations. We apply this principle by finding some\n\\emph{affine derivations} that induces \\emph{expanded} Lie point symmetries of\nconsidered system. By rewriting original problem in an invariant coordinates\nset for these symmetries, we \\emph{reduce} the number of involved parameters.\nWe present an algorithm based on this standpoint whose arithmetic complexity is\n\\emph{quasi-polynomial} in input's size."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0612119v2", 
    "title": "Symmetric Subresultants and Applications", 
    "arxiv-id": "cs/0612119v2", 
    "author": "Philippe Saux Picart", 
    "publish": "2006-12-22T08:20:11Z", 
    "summary": "Schur's transforms of a polynomial are used to count its roots in the unit\ndisk. These are generalized them by introducing the sequence of symmetric\nsub-resultants of two polynomials. Although they do have a determinantal\ndefinition, we show that they satisfy a structure theorem which allows us to\ncompute them with a type of Euclidean division. As a consequence, a fast\nalgorithm based on a dichotomic process and FFT is designed. We prove also that\nthese symmetric sub-resultants have a deep link with Toeplitz matrices.\nFinally, we propose a new algorithm of inversion for such matrices. It has the\nsame cost as those already known, however it is fraction-free and consequently\nwell adapted to computer algebra."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0701151v1", 
    "title": "Time- and Space-Efficient Evaluation of Some Hypergeometric Constants", 
    "arxiv-id": "cs/0701151v1", 
    "author": "Paul Zimmermann", 
    "publish": "2007-01-25T08:07:38Z", 
    "summary": "The currently best known algorithms for the numerical evaluation of\nhypergeometric constants such as $\\zeta(3)$ to $d$ decimal digits have time\ncomplexity $O(M(d) \\log^2 d)$ and space complexity of $O(d \\log d)$ or $O(d)$.\nFollowing work from Cheng, Gergel, Kim and Zima, we present a new algorithm\nwith the same asymptotic complexity, but more efficient in practice. Our\nimplementation of this algorithm improves slightly over existing programs for\nthe computation of $\\pi$, and we announce a new record of 2 billion digits for\n$\\zeta(3)$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0702065v2", 
    "title": "Towards a New ODE Solver Based on Cartan's Equivalence Method", 
    "arxiv-id": "cs/0702065v2", 
    "author": "M. Petitot", 
    "publish": "2007-02-10T16:54:12Z", 
    "summary": "The aim of the present paper is to propose an algorithm for a new ODE--solver\nwhich should improve the abilities of current solvers to handle second order\ndifferential equations. The paper provides also a theoretical result revealing\nthe relationship between the change of coordinates, that maps the generic\nequation to a given target equation, and the symmetry $\\D$-groupoid of this\ntarget."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/cs/0703026v3", 
    "title": "Formal proof for delayed finite field arithmetic using floating point   operators", 
    "arxiv-id": "cs/0703026v3", 
    "author": "Pascal Giorgi", 
    "publish": "2007-03-06T14:55:44Z", 
    "summary": "Formal proof checkers such as Coq are capable of validating proofs of\ncorrection of algorithms for finite field arithmetics but they require\nextensive training from potential users. The delayed solution of a triangular\nsystem over a finite field mixes operations on integers and operations on\nfloating point numbers. We focus in this report on verifying proof obligations\nthat state that no round off error occurred on any of the floating point\noperations. We use a tool named Gappa that can be learned in a matter of\nminutes to generate proofs related to floating point arithmetic and hide\ntechnicalities of formal proof checkers. We found that three facilities are\nmissing from existing tools. The first one is the ability to use in Gappa new\nlemmas that cannot be easily expressed as rewriting rules. We coined the second\none ``variable interchange'' as it would be required to validate loop\ninterchanges. The third facility handles massive loop unrolling and argument\ninstantiation by generating traces of execution for a large number of cases. We\nhope that these facilities may sometime in the future be integrated into\nmainstream code validation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/0706.0014v1", 
    "title": "Towards an exact adaptive algorithm for the determinant of a rational   matrix", 
    "arxiv-id": "0706.0014v1", 
    "author": "Anna Urbanska", 
    "publish": "2007-05-31T20:23:08Z", 
    "summary": "In this paper we propose several strategies for the exact computation of the\ndeterminant of a rational matrix. First, we use the Chinese Remaindering\nTheorem and the rational reconstruction to recover the rational determinant\nfrom its modular images. Then we show a preconditioning for the determinant\nwhich allows us to skip the rational reconstruction process and reconstruct an\ninteger result. We compare those approaches with matrix preconditioning which\nallow us to treat integer instead of rational matrices. This allows us to\nintroduce integer determinant algorithms to the rational determinant problem.\nIn particular, we discuss the applicability of the adaptive determinant\nalgorithm of [9] and compare it with the integer Chinese Remaindering scheme.\nWe present an analysis of the complexity of the strategies and evaluate their\nexperimental performance on numerous examples. This experience allows us to\ndevelop an adaptive strategy which would choose the best solution at the run\ntime, depending on matrix properties. All strategies have been implemented in\nLinBox linear algebra library."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/0710.0510v5", 
    "title": "Q-adic Transform revisited", 
    "arxiv-id": "0710.0510v5", 
    "author": "Jean-Guillaume Dumas", 
    "publish": "2007-10-02T12:02:07Z", 
    "summary": "We present an algorithm to perform a simultaneous modular reduction of\nseveral residues. This algorithm is applied fast modular polynomial\nmultiplication. The idea is to convert the $X$-adic representation of modular\npolynomials, with $X$ an indeterminate, to a $q$-adic representation where $q$\nis an integer larger than the field characteristic. With some control on the\ndifferent involved sizes it is then possible to perform some of the $q$-adic\narithmetic directly with machine integers or floating points. Depending also on\nthe number of performed numerical operations one can then convert back to the\n$q$-adic or $X$-adic representation and eventually mod out high residues. In\nthis note we present a new version of both conversions: more tabulations and a\nway to reduce the number of divisions involved in the process are presented.\nThe polynomial multiplication is then applied to arithmetic in small finite\nfield extensions."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/0801.1341v1", 
    "title": "Factorization in categories of systems of linear partial differential   equations", 
    "arxiv-id": "0801.1341v1", 
    "author": "S. P. Tsarev", 
    "publish": "2008-01-09T00:50:20Z", 
    "summary": "We start with elementary algebraic theory of factorization of linear ordinary\ndifferential equations developed in the period 1880-1930. After exposing these\nclassical results we sketch more sophisticated algorithmic approaches developed\nin the last 20 years.\n  The main part of this paper is devoted to modern generalizations of the\nnotion of factorization to the case of systems of linear partial differential\nequations and their relation with explicit solvability of nonlinear partial\ndifferential equations based on some constructions from the theory of abelian\ncategories."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1145768.1145781", 
    "link": "http://arxiv.org/pdf/0801.1676v2", 
    "title": "Analyzing the Topology Types arising in a Family of Algebraic Curves   Depending On Two Parameters", 
    "arxiv-id": "0801.1676v2", 
    "author": "Juan Gerardo Alcazar", 
    "publish": "2008-01-10T21:08:22Z", 
    "summary": "Given the implicit equation $F(x,y,t,s)$ of a family of algebraic plane\ncurves depending on the parameters $t,s$, we provide an algorithm for studying\nthe topology types arising in the family. For this purpose, the algorithm\ncomputes a finite partition of the parameter space so that the topology type of\nthe family stays invariant over each element of the partition. The ideas\ncontained in the paper can be seen as a generalization of the ideas in\n\\cite{JGRS}, where the problem is solved for families of algebraic curves\ndepending on one parameter, to the two-parameters case."
},{
    "category": "cs.SC", 
    "doi": "10.1063/1.2890843", 
    "link": "http://arxiv.org/pdf/0802.2201v2", 
    "title": "Reconstruction of eye movements during blinks", 
    "arxiv-id": "0802.2201v2", 
    "author": "J. Kurths", 
    "publish": "2008-02-15T13:37:27Z", 
    "summary": "In eye movement research in reading, the amount of data plays a crucial role\nfor the validation of results. A methodological problem for the analysis of the\neye movement in reading are blinks, when readers close their eyes. Blinking\nrate increases with increasing reading time, resulting in high data losses,\nespecially for older adults or reading impaired subjects. We present a method,\nbased on the symbolic sequence dynamics of the eye movements, that reconstructs\nthe horizontal position of the eyes while the reader blinks. The method makes\nuse of an observed fact that the movements of the eyes before closing or after\nopening contain information about the eyes movements during blinks. Test\nresults indicate that our reconstruction method is superior to methods that use\nsimpler interpolation approaches. In addition, analyses of the reconstructed\ndata show no significant deviation from the usual behavior observed in readers."
},{
    "category": "cs.SC", 
    "doi": "10.1063/1.2890843", 
    "link": "http://arxiv.org/pdf/0803.1975v1", 
    "title": "Compressed Modular Matrix Multiplication", 
    "arxiv-id": "0803.1975v1", 
    "author": "Bruno Salvy", 
    "publish": "2008-03-13T19:15:42Z", 
    "summary": "We propose to store several integers modulo a small prime into a single\nmachine word. Modular addition is performed by addition and possibly\nsubtraction of a word containing several times the modulo. Modular\nMultiplication is not directly accessible but modular dot product can be\nperformed by an integer multiplication by the reverse integer. Modular\nmultiplication by a word containing a single residue is a also possible.\nTherefore matrix multiplication can be performed on such a compressed storage.\nWe here give bounds on the sizes of primes and matrices for which such a\ncompression is possible. We also explicit the details of the required\ncompressed arithmetic routines."
},{
    "category": "cs.SC", 
    "doi": "10.1063/1.2890843", 
    "link": "http://arxiv.org/pdf/0803.3027v1", 
    "title": "Towards a Symbolic-Numeric Method to Compute Puiseux Series: The Modular   Part", 
    "arxiv-id": "0803.3027v1", 
    "author": "Marc Rybowicz", 
    "publish": "2008-03-20T16:23:40Z", 
    "summary": "We have designed a new symbolic-numeric strategy to compute efficiently and\naccurately floating point Puiseux series defined by a bivariate polynomial over\nan algebraic number field. In essence, computations modulo a well chosen prime\n$p$ are used to obtain the exact information required to guide floating point\ncomputations. In this paper, we detail the symbolic part of our algorithm:\nFirst of all, we study modular reduction of Puiseux series and give a good\nreduction criterion to ensure that the information required by the numerical\npart is preserved. To establish our results, we introduce a simple modification\nof classical Newton polygons, that we call \"generic Newton polygons\", which\nhappen to be very convenient. Then, we estimate the arithmetic complexity of\ncomputing Puiseux series over finite fields and improve known bounds. Finally,\nwe give bit-complexity bounds for deterministic and randomized versions of the\nsymbolic part. The details of the numerical part will be described in a\nforthcoming paper."
},{
    "category": "cs.SC", 
    "doi": "10.1063/1.2890843", 
    "link": "http://arxiv.org/pdf/0804.2181v1", 
    "title": "Products of Ordinary Differential Operators by Evaluation and   Interpolation", 
    "arxiv-id": "0804.2181v1", 
    "author": "Nicolas Le Roux", 
    "publish": "2008-04-14T13:37:14Z", 
    "summary": "It is known that multiplication of linear differential operators over ground\nfields of characteristic zero can be reduced to a constant number of matrix\nproducts. We give a new algorithm by evaluation and interpolation which is\nfaster than the previously-known one by a constant factor, and prove that in\ncharacteristic zero, multiplication of differential operators and of matrices\nare computationally equivalent problems. In positive characteristic, we show\nthat differential operators can be multiplied in nearly optimal time.\nTheoretical results are validated by intensive experiments."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1390768.1390806", 
    "link": "http://arxiv.org/pdf/0804.2337v1", 
    "title": "Power Series Composition and Change of Basis", 
    "arxiv-id": "0804.2337v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2008-04-15T09:43:27Z", 
    "summary": "Efficient algorithms are known for many operations on truncated power series\n(multiplication, powering, exponential, ...). Composition is a more complex\ntask. We isolate a large class of power series for which composition can be\nperformed efficiently. We deduce fast algorithms for converting polynomials\nbetween various bases, including Euler, Bernoulli, Fibonacci, and the\northogonal Laguerre, Hermite, Jacobi, Krawtchouk, Meixner and\nMeixner-Pollaczek."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.laa.2009.08.002", 
    "link": "http://arxiv.org/pdf/0804.2373v1", 
    "title": "Fast Conversion Algorithms for Orthogonal Polynomials", 
    "arxiv-id": "0804.2373v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2008-04-15T12:47:14Z", 
    "summary": "We discuss efficient conversion algorithms for orthogonal polynomials. We\ndescribe a known conversion algorithm from an arbitrary orthogonal basis to the\nmonomial basis, and deduce a new algorithm of the same complexity for the\nconverse operation."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.laa.2009.08.002", 
    "link": "http://arxiv.org/pdf/0809.2978v2", 
    "title": "A local construction of the Smith normal form of a matrix polynomial", 
    "arxiv-id": "0809.2978v2", 
    "author": "Jia Yu", 
    "publish": "2008-09-17T18:58:42Z", 
    "summary": "We present an algorithm for computing a Smith form with multipliers of a\nregular matrix polynomial over a field. This algorithm differs from previous\nones in that it computes a local Smith form for each irreducible factor in the\ndeterminant separately and then combines them into a global Smith form, whereas\nother algorithms apply a sequence of unimodular row and column operations to\nthe original matrix. The performance of the algorithm in exact arithmetic is\nreported for several test cases."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.laa.2009.08.002", 
    "link": "http://arxiv.org/pdf/0811.1061v2", 
    "title": "How to turn a scripting language into a domain specific language for   computer algebra", 
    "arxiv-id": "0811.1061v2", 
    "author": "Heinz Kredel", 
    "publish": "2008-11-06T23:07:36Z", 
    "summary": "We have developed two computer algebra systems, meditor [Jolly:2007] and JAS\n[Kredel:2006]. These CAS systems are available as Java libraries. For the\nuse-case of interactively entering and manipulating mathematical expressions,\nthere is a need of a scripting front-end for our libraries. Most other CAS\ninvent and implement their own scripting interface for this purpose. We,\nhowever, do not want to reinvent the wheel and propose to use a contemporary\nscripting language with access to Java code. In this paper we discuss the\nrequirements for a scripting language in computer algebra and check whether the\nlanguages Python, Ruby, Groovy and Scala meet these requirements. We conclude\nthat, with minor problems, any of these languages is suitable for our purpose."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0812.0067v1", 
    "title": "Stable normal forms for polynomial system solving", 
    "arxiv-id": "0812.0067v1", 
    "author": "Philippe Tr\u00e9buchet", 
    "publish": "2008-11-29T11:26:50Z", 
    "summary": "This paper describes and analyzes a method for computing border bases of a\nzero-dimensional ideal $I$. The criterion used in the computation involves\nspecific commutation polynomials and leads to an algorithm and an\nimplementation extending the one provided in [MT'05]. This general border basis\nalgorithm weakens the monomial ordering requirement for \\grob bases\ncomputations. It is up to date the most general setting for representing\nquotient algebras, embedding into a single formalism Gr\\\"obner bases, Macaulay\nbases and new representation that do not fit into the previous categories. With\nthis formalism we show how the syzygies of the border basis are generated by\ncommutation relations. We also show that our construction of normal form is\nstable under small perturbations of the ideal, if the number of solutions\nremains constant. This new feature for a symbolic algorithm has a huge impact\non the practical efficiency as it is illustrated by the experiments on\nclassical benchmark polynomial systems, at the end of the paper."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0812.0088v1", 
    "title": "Moment matrices, trace matrices and the radical of ideals", 
    "arxiv-id": "0812.0088v1", 
    "author": "Lajos Ronyai", 
    "publish": "2008-11-29T16:14:07Z", 
    "summary": "Let $f_1,...,f_s \\in \\mathbb{K}[x_1,...,x_m]$ be a system of polynomials\ngenerating a zero-dimensional ideal $\\I$, where $\\mathbb{K}$ is an arbitrary\nalgebraically closed field. Assume that the factor algebra\n$\\A=\\mathbb{K}[x_1,...,x_m]/\\I$ is Gorenstein and that we have a bound\n$\\delta>0$ such that a basis for $\\A$ can be computed from multiples of\n$f_1,...,f_s$ of degrees at most $\\delta$. We propose a method using Sylvester\nor Macaulay type resultant matrices of $f_1,...,f_s$ and $J$, where $J$ is a\npolynomial of degree $\\delta$ generalizing the Jacobian, to compute moment\nmatrices, and in particular matrices of traces for $\\A$. These matrices of\ntraces in turn allow us to compute a system of multiplication matrices\n$\\{M_{x_i}|i=1,...,m\\}$ of the radical $\\sqrt{\\I}$, following the approach in\nthe previous work by Janovitz-Freireich, R\\'{o}nyai and Sz\\'ant\\'o.\nAdditionally, we give bounds for $\\delta$ for the case when $\\I$ has finitely\nmany projective roots in $\\mathbb{P}^m_\\CC$."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0901.1848v2", 
    "title": "Detecting lacunary perfect powers and computing their roots", 
    "arxiv-id": "0901.1848v2", 
    "author": "Daniel S. Roche", 
    "publish": "2009-01-13T18:44:43Z", 
    "summary": "We consider solutions to the equation f = h^r for polynomials f and h and\ninteger r > 1. Given a polynomial f in the lacunary (also called sparse or\nsuper-sparse) representation, we first show how to determine if f can be\nwritten as h^r and, if so, to find such an r. This is a Monte Carlo randomized\nalgorithm whose cost is polynomial in the number of non-zero terms of f and in\nlog(deg f), i.e., polynomial in the size of the lacunary representation, and it\nworks over GF(q)[x] (for large characteristic) as well as Q[x]. We also give\ntwo deterministic algorithms to compute the perfect root h given f and r. The\nfirst is output-sensitive (based on the sparsity of h) and works only over\nQ[x]. A sparsity-sensitive Newton iteration forms the basis for the second\napproach to computing h, which is extremely efficient and works over both\nGF(q)[x] (for large characteristic) and Q[x], but depends on a number-theoretic\nconjecture. Work of Erdos, Schinzel, Zannier, and others suggests that both of\nthese algorithms are unconditionally polynomial-time in the lacunary size of\nthe input polynomial f. Finally, we demonstrate the efficiency of the\nrandomized detection algorithm and the latter perfect root computation\nalgorithm with an implementation in the C++ library NTL."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0901.3843v1", 
    "title": "Fast algorithms for differential equations in positive characteristic", 
    "arxiv-id": "0901.3843v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2009-01-24T16:23:34Z", 
    "summary": "We address complexity issues for linear differential equations in\ncharacteristic $p>0$: resolution and computation of the $p$-curvature. For\nthese tasks, our main focus is on algorithms whose complexity behaves well with\nrespect to $p$. We prove bounds linear in $p$ on the degree of polynomial\nsolutions and propose algorithms for testing the existence of polynomial\nsolutions in sublinear time $\\tilde{O}(p^{1/2})$, and for determining a whole\nbasis of the solution space in quasi-linear time $\\tilde{O}(p)$; the\n$\\tilde{O}$ notation indicates that we hide logarithmic factors. We show that\nfor equations of arbitrary order, the $p$-curvature can be computed in\nsubquadratic time $\\tilde{O}(p^{1.79})$, and that this can be improved to\n$O(\\log(p))$ for first order equations and to $\\tilde{O}(p)$ for classes of\nsecond order equations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0901.4747v2", 
    "title": "On finding multiplicities of characteristic polynomial factors of   black-box matrices", 
    "arxiv-id": "0901.4747v2", 
    "author": "B. David Saunders", 
    "publish": "2009-01-29T18:51:24Z", 
    "summary": "We present algorithms and heuristics to compute the characteristic polynomial\nof a matrix given its minimal polynomial. The matrix is represented as a\nblack-box, i.e., by a function to compute its matrix-vector product. The\nmethods apply to matrices either over the integers or over a large enough\nfinite field. Experiments show that these methods perform efficiently in\npractice. Combined in an adaptive strategy, these algorithms reach significant\nspeedups in practice for some integer matrices arising in an application from\ngraph theory."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0902.1612v1", 
    "title": "A baby steps/giant steps Monte Carlo algorithm for computing roadmaps in   smooth compact real hypersurfaces", 
    "arxiv-id": "0902.1612v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2009-02-10T09:20:30Z", 
    "summary": "We consider the problem of constructing roadmaps of real algebraic sets. The\nproblem was introduced by Canny to answer connectivity questions and solve\nmotion planning problems. Given $s$ polynomial equations with rational\ncoefficients, of degree $D$ in $n$ variables, Canny's algorithm has a Monte\nCarlo cost of $s^n\\log(s) D^{O(n^2)}$ operations in $\\mathbb{Q}$; a\ndeterministic version runs in time $s^n \\log(s) D^{O(n^4)}$. The next\nimprovement was due to Basu, Pollack and Roy, with an algorithm of\ndeterministic cost $s^{d+1} D^{O(n^2)}$ for the more general problem of\ncomputing roadmaps of semi-algebraic sets ($d \\le n$ is the dimension of an\nassociated object). We give a Monte Carlo algorithm of complexity\n$(nD)^{O(n^{1.5})}$ for the problem of computing a roadmap of a compact\nhypersurface $V$ of degree $D$ in $n$ variables; we also have to assume that\n$V$ has a finite number of singular points. Even under these extra assumptions,\nno previous algorithm featured a cost better than $D^{O(n^2)}$."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0902.3304v1", 
    "title": "A bound on the minimum of a real positive polynomial over the standard   simplex", 
    "arxiv-id": "0902.3304v1", 
    "author": "Marie-Francoise Roy", 
    "publish": "2009-02-19T15:52:58Z", 
    "summary": "We consider the problem of bounding away from 0 the minimum value m taken by\na polynomial P of Z[X_1,...,X_k] over the standard simplex, assuming that m>0.\nRecent algorithmic developments in real algebraic geometry enable us to obtain\na positive lower bound on m in terms of the dimension k, the degree d and the\nbitsize of the coefficients of P. The bound is explicit, and obtained without\nany extra assumption on P, in contrast with previous results reported in the\nliterature."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0903.3690v2", 
    "title": "Computations modulo regular chains", 
    "arxiv-id": "0903.3690v2", 
    "author": "Wei Pan", 
    "publish": "2009-03-21T20:43:02Z", 
    "summary": "The computation of triangular decompositions are based on two fundamental\noperations: polynomial GCDs modulo regular chains and regularity test modulo\nsaturated ideals. We propose new algorithms for these core operations relying\non modular methods and fast polynomial arithmetic. Our strategies take also\nadvantage of the context in which these operations are performed. We report on\nextensive experimentation, comparing our code to pre-existing Maple\nimplementations, as well as more optimized Magma functions. In most cases, our\nnew code outperforms the other packages by several orders of magnitude."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2008.09.004", 
    "link": "http://arxiv.org/pdf/0903.5221v1", 
    "title": "Computing Cylindrical Algebraic Decomposition via Triangular   Decomposition", 
    "arxiv-id": "0903.5221v1", 
    "author": "Lu Yang", 
    "publish": "2009-03-30T13:26:43Z", 
    "summary": "Cylindrical algebraic decomposition is one of the most important tools for\ncomputing with semi-algebraic sets, while triangular decomposition is among the\nmost important approaches for manipulating constructible sets. In this paper,\nfor an arbitrary finite set $F \\subset {\\R}[y_1, ..., y_n]$ we apply\ncomprehensive triangular decomposition in order to obtain an $F$-invariant\ncylindrical decomposition of the $n$-dimensional complex space, from which we\nextract an $F$-invariant cylindrical algebraic decomposition of the\n$n$-dimensional real space. We report on an implementation of this new approach\nfor constructing cylindrical algebraic decompositions."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.06.024", 
    "link": "http://arxiv.org/pdf/0904.2452v2", 
    "title": "Effective Bounds for P-Recursive Sequences", 
    "arxiv-id": "0904.2452v2", 
    "author": "Bruno Salvy", 
    "publish": "2009-04-16T09:39:09Z", 
    "summary": "We describe an algorithm that takes as input a complex sequence $(u_n)$ given\nby a linear recurrence relation with polynomial coefficients along with initial\nvalues, and outputs a simple explicit upper bound $(v_n)$ such that $|u_n| \\leq\nv_n$ for all $n$. Generically, the bound is tight, in the sense that its\nasymptotic behaviour matches that of $u_n$. We discuss applications to the\nevaluation of power series with guaranteed precision."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1576702.1576720", 
    "link": "http://arxiv.org/pdf/0904.2761v1", 
    "title": "A Non-Holonomic Systems Approach to Special Function Identities", 
    "arxiv-id": "0904.2761v1", 
    "author": "Bruno Salvy", 
    "publish": "2009-04-17T18:36:10Z", 
    "summary": "We extend Zeilberger's approach to special function identities to cases that\nare not holonomic. The method of creative telescoping is thus applied to\ndefinite sums or integrals involving Stirling or Bernoulli numbers, incomplete\nGamma function or polylogarithms, which are not covered by the holonomic\nframework. The basic idea is to take into account the dimension of appropriate\nideals in Ore algebras. This unifies several earlier extensions and provides\nalgorithms for summation and integration in classes that had not been\naccessible to computer algebra before."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1576702.1576720", 
    "link": "http://arxiv.org/pdf/0904.3827v1", 
    "title": "La R\u00e9solvante de Lagrange et ses Applications", 
    "arxiv-id": "0904.3827v1", 
    "author": "Annick Valibouze", 
    "publish": "2009-04-24T09:00:48Z", 
    "summary": "In this paper, the changes of representations of a group are used in order to\ndescribe its action as algebraic Galois group of an univariate polynomial on\nthe roots of factors of any Lagrange resolvent. By this way, the Galois group\nof resolvent factors are pre-determinated. In follows, different applications\nare exposed; in particular, some classical results of algebraic Galois theory."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1576702.1576720", 
    "link": "http://arxiv.org/pdf/0904.4030v3", 
    "title": "Successive Difference Substitution Based on Column Stochastic Matrix and   Mechanical Decision for Positive Semi-definite Forms", 
    "arxiv-id": "0904.4030v3", 
    "author": "Yong Yao", 
    "publish": "2009-04-27T04:54:11Z", 
    "summary": "The theory part of this paper is sketched as follows. Based on column\nstochastic average matrix $T_n$ selected as a basic substitution matrix, the\nmethod of advanced successive difference substitution is established. Then, a\nset of necessary and sufficient conditions for deciding positive semi-definite\nform on $\\R^n_+$ is derived from this method. And furthermore, it is proved\nthat the sequence of SDS sets of a positive definite form is positively\nterminating.\n  Worked out according to these results, the Maple program TSDS3 not only\nautomatically proves the polynomial inequalities, but also outputs counter\nexamples for the false. Sometimes TSDS3 does not halt, but it is very useful by\nexperimenting on so many examples."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1577190.1577207", 
    "link": "http://arxiv.org/pdf/0905.3993v2", 
    "title": "Continued Fraction Expansion of Real Roots of Polynomial Systems", 
    "arxiv-id": "0905.3993v2", 
    "author": "Elias P. P. Tsigaridas", 
    "publish": "2009-05-25T10:39:17Z", 
    "summary": "We present a new algorithm for isolating the real roots of a system of\nmultivariate polynomials, given in the monomial basis. It is inspired by\nexisting subdivision methods in the Bernstein basis; it can be seen as\ngeneralization of the univariate continued fraction algorithm or alternatively\nas a fully analog of Bernstein subdivision in the monomial basis. The\nrepresentation of the subdivided domains is done through homographies, which\nallows us to use only integer arithmetic and to treat efficiently unbounded\nregions. We use univariate bounding functions, projection and preconditionning\ntechniques to reduce the domain of search. The resulting boxes have optimized\nrational coordinates, corresponding to the first terms of the continued\nfraction expansion of the real roots. An extension of Vincent's theorem to\nmultivariate polynomials is proved and used for the termination of the\nalgorithm. New complexity bounds are provided for a simplified version of the\nalgorithm. Examples computed with a preliminary C++ implementation illustrate\nthe approach."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1577190.1577207", 
    "link": "http://arxiv.org/pdf/0906.2315v2", 
    "title": "Symbolic Script Programming for Java", 
    "arxiv-id": "0906.2315v2", 
    "author": "Heinz Kredel", 
    "publish": "2009-06-12T12:38:22Z", 
    "summary": "Computer algebra in Java is a promising field of development. It has not yet\nreached an industrial strength, in part because of a lack of good user\ninterfaces. Using a general purpose scripting language can bring a natural\nmathematical notation, akin to the one of specialized interfaces included in\nmost computer algebra systems. We present such an interface for Java computer\nalgebra libraries, using scripts available in the JSR 223 framework. We\nintroduce the concept of `symbolic programming' and show its usefulness by\nprototypes of symbolic polynomials and polynomial rings."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1576702.1576709", 
    "link": "http://arxiv.org/pdf/0906.2888v1", 
    "title": "Chebyshev Expansions for Solutions of Linear Differential Equations", 
    "arxiv-id": "0906.2888v1", 
    "author": "Bruno Salvy", 
    "publish": "2009-06-16T10:21:01Z", 
    "summary": "A Chebyshev expansion is a series in the basis of Chebyshev polynomials of\nthe first kind. When such a series solves a linear differential equation, its\ncoefficients satisfy a linear recurrence equation. We interpret this equation\nas the numerator of a fraction of linear recurrence operators. This\ninterpretation lets us give a simple view of previous algorithms, analyze their\ncomplexity, and design a faster one for large orders."
},{
    "category": "cs.SC", 
    "doi": "10.1142/S1793042110003691", 
    "link": "http://arxiv.org/pdf/0907.0291v3", 
    "title": "Generating functions of Chebyshev-like polynomials", 
    "arxiv-id": "0907.0291v3", 
    "author": "Khang Tran", 
    "publish": "2009-07-02T06:29:52Z", 
    "summary": "In this short note, we give simple proofs of several results and conjectures\nformulated by Stolarsky and Tran concerning generating functions of some\nfamilies of Chebyshev-like polynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1142/S1793042110003691", 
    "link": "http://arxiv.org/pdf/0907.2076v1", 
    "title": "The Piranha algebraic manipulator", 
    "arxiv-id": "0907.2076v1", 
    "author": "Francesco Biscani", 
    "publish": "2009-07-12T23:41:03Z", 
    "summary": "In this paper we present a specialised algebraic manipulation package devoted\nto Celestial Mechanics. The system, called Piranha, is built on top of a\ngeneric and extensible framework, which allows to treat efficiently and in a\nunified way the algebraic structures most commonly encountered in Celestial\nMechanics (such as multivariate polynomials and Poisson series). In this\ncontribution we explain the architecture of the software, with special focus on\nthe implementation of series arithmetics, show its current capabilities, and\npresent benchmarks indicating that Piranha is competitive, performance-wise,\nwith other specialised manipulators."
},{
    "category": "cs.SC", 
    "doi": "10.1142/S1793042110003691", 
    "link": "http://arxiv.org/pdf/0907.2300v2", 
    "title": "An Efficient Algorithm for Factoring Polynomials over Algebraic   Extension Field", 
    "arxiv-id": "0907.2300v2", 
    "author": "Dingkang Wang", 
    "publish": "2009-07-14T07:25:07Z", 
    "summary": "A new efficient algorithm is proposed for factoring polynomials over an\nalgebraic extension field. The extension field is defined by a polynomial ring\nmodulo a maximal ideal. If the maximal ideal is given by its Groebner basis, no\nextra Groebner basis computation is needed for factoring a polynomial over this\nextension field. Nothing more than linear algebraic technique is used to get a\npolynomial over the ground field by a generic linear map. Then this polynomial\nis factorized over the ground field. From these factors, the factorization of\nthe polynomial over the extension field is obtained. The new algorithm has been\nimplemented and computer experiments indicate that the new algorithm is very\nefficient, particularly in complicated examples."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/0910.4668v1", 
    "title": "Computing modular correspondences for abelian varieties", 
    "arxiv-id": "0910.4668v1", 
    "author": "Damien Robert", 
    "publish": "2009-10-24T17:34:54Z", 
    "summary": "The aim of this paper is to give a higher dimensional equivalent of the\nclassical modular polynomials $\\Phi_\\ell(X,Y)$. If $j$ is the $j$-invariant\nassociated to an elliptic curve $E_k$ over a field $k$ then the roots of\n$\\Phi_\\ell(j,X)$ correspond to the $j$-invariants of the curves which are\n$\\ell$-isogeneous to $E_k$. Denote by $X_0(N)$ the modular curve which\nparametrizes the set of elliptic curves together with a $N$-torsion subgroup.\nIt is possible to interpret $\\Phi_\\ell(X,Y)$ as an equation cutting out the\nimage of a certain modular correspondence $X_0(\\ell) \\to X_0(1) \\times X_0(1)$\nin the product $X_0(1) \\times X_0(1)$. Let $g$ be a positive integer and\n$\\overn \\in \\N^g$. We are interested in the moduli space that we denote by\n$\\Mn$ of abelian varieties of dimension $g$ over a field $k$ together with an\nample symmetric line bundle $\\pol$ and a symmetric theta structure of type\n$\\overn$. If $\\ell$ is a prime and let $\\overl=(\\ell, ..., \\ell)$, there exists\na modular correspondence $\\Mln \\to \\Mn \\times \\Mn$. We give a system of\nalgebraic equations defining the image of this modular correspondence."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/0912.1649v1", 
    "title": "Completeness of the WDS method in Checking Positivity of Integral Forms", 
    "arxiv-id": "0912.1649v1", 
    "author": "Junwei Shao", 
    "publish": "2009-12-09T02:29:22Z", 
    "summary": "Examples show that integral forms can be efficiently proved positive\nsemidefinite by the WDS method, but it was unknown that how many steps of\nsubstitutions are needed, or furthermore, which integral forms is this method\napplicable for. In this paper, we give upper bounds of step numbers of WDS\nrequired in proving that an integral form is positive definite, positive\nsemidefinite, or not positive semidefinite, thus deducing that the WDS method\nis complete."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/0912.4430v1", 
    "title": "Simplex Subdivisions and Nonnegativity Decision of Forms", 
    "arxiv-id": "0912.4430v1", 
    "author": "Song Xu", 
    "publish": "2009-12-22T15:50:22Z", 
    "summary": "This paper mainly studies nonnegativity decision of forms based on variable\nsubstitutions. Unlike existing research, the paper regards simplex subdivisions\nas new perspectives to study variable substitutions, gives some subdivisions of\nthe simplex T_n, introduces the concept of convergence of the subdivision\nsequence, and presents a sufficient and necessary condition for the convergent\nself-similar subdivision sequence. Then the relationships between subdivisions\nand their corresponding substitutions are established. Moreover, it is proven\nthat if the form F is indefinite on T_n and the sequence of the successive\nL-substitution sets is convergent, then the sequence of sets {SLS^(m)(F)} is\nnegatively terminating, and an algorithm for deciding indefinite forms with a\ncounter-example is obtained. Thus, various effective substitutions for deciding\npositive semi-definite forms and indefinite forms are gained, which are beyond\nthe weighted difference substitutions characterized by \"difference\"."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/1001.0304v1", 
    "title": "A Complete Method for Checking Hurwitz Stability of a Polytope of   Matrices", 
    "arxiv-id": "1001.0304v1", 
    "author": "Xiaorong Hou", 
    "publish": "2010-01-02T13:16:14Z", 
    "summary": "We present a novel method for checking the Hurwitz stability of a polytope of\nmatrices. First we prove that the polytope matrix is stable if and only if two\nhomogenous polynomials are positive on a simplex, then through a newly proposed\nmethod, i.e., the weighted difference substitution method, the latter can be\nchecked in finite steps. Examples show the efficiency of our method."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/1001.0649v1", 
    "title": "A complete algorithm to find exact minimal polynomial by approximations", 
    "arxiv-id": "1001.0649v1", 
    "author": "Jingzhong Zhang", 
    "publish": "2010-01-05T08:44:31Z", 
    "summary": "We present a complete algorithm for finding an exact minimal polynomial from\nits approximate value by using an improved parameterized integer relation\nconstruction method. Our result is superior to the existence of error\ncontrolling on obtaining an exact rational number from its approximation. The\nalgorithm is applicable for finding exact minimal polynomial of an algebraic\nnumber by its approximate root. This also enables us to provide an efficient\nmethod of converting the rational approximation representation to the minimal\npolynomial representation, and devise a simple algorithm to factor multivariate\npolynomials with rational coefficients.\n  Compared with the subsistent methods, our method combines advantage of high\nefficiency in numerical computation, and exact, stable results in symbolic\ncomputation. we also discuss some applications to some transcendental numbers\nby approximations. Moreover, the Digits of our algorithm is far less than the\nLLL-lattice basis reduction technique in theory. In this paper, we completely\nimplement how to obtain exact results by numerical approximate computations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/1001.4004v2", 
    "title": "Gr\u00f6bner Bases of Bihomogeneous Ideals generated by Polynomials of   Bidegree (1,1): Algorithms and Complexity", 
    "arxiv-id": "1001.4004v2", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2010-01-22T14:59:59Z", 
    "summary": "Solving multihomogeneous systems, as a wide range of structured algebraic\nsystems occurring frequently in practical problems, is of first importance.\nExperimentally, solving these systems with Gr\\\"obner bases algorithms seems to\nbe easier than solving homogeneous systems of the same degree. Nevertheless,\nthe reasons of this behaviour are not clear. In this paper, we focus on\nbilinear systems (i.e. bihomogeneous systems where all equations have bidegree\n(1,1)). Our goal is to provide a theoretical explanation of the aforementionned\nexperimental behaviour and to propose new techniques to speed up the Gr\\\"obner\nbasis computations by using the multihomogeneous structure of those systems.\nThe contributions are theoretical and practical. First, we adapt the classical\nF5 criterion to avoid reductions to zero which occur when the input is a set of\nbilinear polynomials. We also prove an explicit form of the Hilbert series of\nbihomogeneous ideals generated by generic bilinear polynomials and give a new\nupper bound on the degree of regularity of generic affine bilinear systems.\nThis leads to new complexity bounds for solving bilinear systems. We propose\nalso a variant of the F5 Algorithm dedicated to multihomogeneous systems which\nexploits a structural property of the Macaulay matrix which occurs on such\ninputs. Experimental results show that this variant requires less time and\nmemory than the classical homogeneous F5 Algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/1002.3077v2", 
    "title": "NumGfun: a Package for Numerical and Analytic Computation with D-finite   Functions", 
    "arxiv-id": "1002.3077v2", 
    "author": "Marc Mezzarobba", 
    "publish": "2010-02-16T13:07:30Z", 
    "summary": "This article describes the implementation in the software package NumGfun of\nclassical algorithms that operate on solutions of linear differential equations\nor recurrence relations with polynomial coefficients, including what seems to\nbe the first general implementation of the fast high-precision numerical\nevaluation algorithms of Chudnovsky & Chudnovsky. In some cases, our\ndescriptions contain improvements over existing algorithms. We also provide\nreferences to relevant ideas not currently used in NumGfun."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.031", 
    "link": "http://arxiv.org/pdf/1004.0084v4", 
    "title": "A New Proof for the Correctness of F5 (F5-Like) Algorithm", 
    "arxiv-id": "1004.0084v4", 
    "author": "Dingkang Wang", 
    "publish": "2010-04-01T08:51:30Z", 
    "summary": "The famous F5 algorithm for computing Gr\\\"obner basis was presented by\nFaug\\`ere in 2002 without complete proofs for its correctness. The current\nauthors have simplified the original F5 algorithm into an F5 algorithm in\nBuchberger's style (F5B algorithm), which is equivalent to original F5\nalgorithm and may deduce some F5-like versions. In this paper, the F5B\nalgorithm is briefly revisited and a new complete proof for the correctness of\nF5B algorithm is proposed. This new proof is not limited to homogeneous systems\nand does not depend on the strategy of selecting critical pairs (i.e. the\nstrategy deciding which critical pair is computed first) such that any strategy\ncould be utilized in F5B (F5) algorithm. From this new proof, we find that the\nspecial reduction procedure (F5-reduction) is the key of F5 algorithm, so\nmaintaining this special reduction, various variation algorithms become\navailable. A natural variation of F5 algorithm, which transforms original F5\nalgorithm to a non-incremental algorithm, is presented and proved in this paper\nas well. This natural variation has been implemented over the Boolean ring. The\ntwo revised criteria in this natural variation are also able to reject almost\nall unnecessary computations and few polynomials reduce to 0 in most examples."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1004.2090v2", 
    "title": "On Computing Groebner Basis in the Rings of Differential Operators", 
    "arxiv-id": "1004.2090v2", 
    "author": "Dingkang Wang", 
    "publish": "2010-04-13T01:59:38Z", 
    "summary": "Insa and Pauer presented a basic theory of Groebner basis for differential\noperators with coefficients in a commutative ring in 1998, and a criterion was\nproposed to determine if a set of differential operators is a Groebner basis.\nIn this paper, we will give a new criterion such that Insa and Pauer's\ncriterion could be concluded as a special case and one could compute the\nGroebner basis more efficiently by this new criterion."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1004.4548v1", 
    "title": "Multiplication of sparse Laurent polynomials and Poisson series on   modern hardware architectures", 
    "arxiv-id": "1004.4548v1", 
    "author": "Francesco Biscani", 
    "publish": "2010-04-26T15:14:27Z", 
    "summary": "In this paper we present two algorithms for the multiplication of sparse\nLaurent polynomials and Poisson series (the latter being algebraic structures\ncommonly arising in Celestial Mechanics from the application of perturbation\ntheories). Both algorithms first employ the Kronecker substitution technique to\nreduce multivariate multiplication to univariate multiplication, and then use\nthe schoolbook method to perform the univariate multiplication. The first\nalgorithm, suitable for moderately-sparse multiplication, uses the exponents of\nthe monomials resulting from the univariate multiplication as trivial hash\nvalues in a one dimensional lookup array of coefficients. The second algorithm,\nsuitable for highly-sparse multiplication, uses a cache-optimised hash table\nwhich stores the coefficient-exponent pairs resulting from the multiplication\nusing the exponents as keys. Both algorithms have been implemented with\nattention to modern computer hardware architectures. Particular care has been\ndevoted to the efficient exploitation of contemporary memory hierarchies\nthrough cache-blocking techniques and cache-friendly term ordering. The first\nalgorithm has been parallelised for shared-memory multicore architectures,\nwhereas the second algorithm is in the process of being parallelised. We\npresent benchmarks comparing our algorithms to the routines of other computer\nalgebra systems, both in sequential and parallel mode."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1004.5433v1", 
    "title": "Some Results on the Functional Decomposition of Polynomials", 
    "arxiv-id": "1004.5433v1", 
    "author": "Mark Giesbrecht", 
    "publish": "2010-04-30T01:31:51Z", 
    "summary": "If g and h are functions over some field, we can consider their composition f\n= g(h). The inverse problem is decomposition: given f, determine the ex-\nistence of such functions g and h. In this thesis we consider functional decom-\npositions of univariate and multivariate polynomials, and rational functions\nover a field F of characteristic p. In the polynomial case, \"wild\" behaviour\noccurs in both the mathematical and computational theory of the problem if p\ndivides the degree of g. We consider the wild case in some depth, and deal with\nthose polynomials whose decompositions are in some sense the \"wildest\": the\nadditive polynomials. We determine the maximum number of decompositions and\nshow some polynomial time algorithms for certain classes of polynomials with\nwild decompositions. For the rational function case we present a definition of\nthe problem, a normalised version of the problem to which the general problem\nreduces, and an exponential time solution to the normal problem."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1005.0600v1", 
    "title": "When can we decide that a P-finite sequence is positive?", 
    "arxiv-id": "1005.0600v1", 
    "author": "Veronika Pillwein", 
    "publish": "2010-05-04T18:24:19Z", 
    "summary": "We consider two algorithms which can be used for proving positivity of\nsequences that are defined by a linear recurrence equation with polynomial\ncoefficients (P-finite sequences). Both algorithms have in common that while\nthey do succeed on a great many examples, there is no guarantee for them to\nterminate, and they do in fact not terminate for every input. For some\nrestricted classes of P-finite recurrence equations of order up to three we\nprovide a priori criteria that assert the termination of the algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1005.0602v1", 
    "title": "Partial Denominator Bounds for Partial Linear Difference Equations", 
    "arxiv-id": "1005.0602v1", 
    "author": "Carsten Schneider", 
    "publish": "2010-05-04T18:29:08Z", 
    "summary": "We investigate which polynomials can possibly occur as factors in the\ndenominators of rational solutions of a given partial linear difference\nequation (PLDE). Two kinds of polynomials are to be distinguished, we call them\n/periodic/ and /aperiodic/. The main result is a generalization of a well-known\ndenominator bounding technique for univariate equations to PLDEs. This\ngeneralization is able to find all the aperiodic factors of the denominators\nfor a given PLDE."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1005.2001v2", 
    "title": "Random polynomials and expected complexity of bisection methods for real   solving", 
    "arxiv-id": "1005.2001v2", 
    "author": "Elias Tsigaridas", 
    "publish": "2010-05-12T06:52:48Z", 
    "summary": "Our probabilistic analysis sheds light to the following questions: Why do\nrandom polynomials seem to have few, and well separated real roots, on the\naverage? Why do exact algorithms for real root isolation may perform\ncomparatively well or even better than numerical ones? We exploit results by\nKac, and by Edelman and Kostlan in order to estimate the real root separation\nof degree $d$ polynomials with i.i.d.\\ coefficients that follow two zero-mean\nnormal distributions: for SO(2) polynomials, the $i$-th coefficient has\nvariance ${d \\choose i}$, whereas for Weyl polynomials its variance is\n${1/i!}$. By applying results from statistical physics, we obtain the expected\n(bit) complexity of \\func{sturm} solver, $\\sOB(r d^2 \\tau)$, where $r$ is the\nnumber of real roots and $\\tau$ the maximum coefficient bitsize. Our bounds are\ntwo orders of magnitude tighter than the record worst case ones. We also derive\nan output-sensitive bound in the worst case. The second part of the paper shows\nthat the expected number of real roots of a degree $d$ polynomial in the\nBernstein basis is $\\sqrt{2d}\\pm\\OO(1)$, when the coefficients are i.i.d.\\\nvariables with moderate standard deviation. Our paper concludes with\nexperimental results which corroborate our analysis."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1005.5610v2", 
    "title": "The DMM bound: multivariate (aggregate) separation bounds", 
    "arxiv-id": "1005.5610v2", 
    "author": "Elias Tsigaridas", 
    "publish": "2010-05-31T07:56:58Z", 
    "summary": "In this paper we derive aggregate separation bounds, named after\nDavenport-Mahler-Mignotte (\\dmm), on the isolated roots of polynomial systems,\nspecifically on the minimum distance between any two such roots. The bounds\nexploit the structure of the system and the height of the sparse (or toric)\nresultant by means of mixed volume, as well as recent advances on aggregate\nroot bounds for univariate polynomials, and are applicable to arbitrary\npositive dimensional systems. We improve upon Canny's gap theorem\n\\cite{c-crmp-87} by a factor of $\\OO(d^{n-1})$, where $d$ bounds the degree of\nthe polynomials, and $n$ is the number of variables. One application is to the\nbitsize of the eigenvalues and eigenvectors of an integer matrix, which also\nyields a new proof that the problem is polynomial. We also compare against\nrecent lower bounds on the absolute value of the root coordinates by Brownawell\nand Yap \\cite{by-issac-2009}, obtained under the hypothesis there is a\n0-dimensional projection. Our bounds are in general comparable, but exploit\nsparseness; they are also tighter when bounding the value of a positive\npolynomial over the simplex. For this problem, we also improve upon the bounds\nin \\cite{bsr-arxix-2009,jp-arxiv-2009}. Our analysis provides a precise\nasymptotic upper bound on the number of steps that subdivision-based algorithms\nperform in order to isolate all real roots of a polynomial system. This leads\nto the first complexity bound of Milne's algorithm \\cite{Miln92} in 2D."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1006.5299v2", 
    "title": "The F5 Algorithm in Buchberger's Style", 
    "arxiv-id": "1006.5299v2", 
    "author": "Dingkang Wang", 
    "publish": "2010-06-28T09:23:32Z", 
    "summary": "The famous F5 algorithm for computing \\gr basis was presented by Faug\\`ere in\n2002. The original version of F5 is given in programming codes, so it is a bit\ndifficult to understand. In this paper, the F5 algorithm is simplified as F5B\nin a Buchberger's style such that it is easy to understand and implement. In\norder to describe F5B, we introduce F5-reduction, which keeps the signature of\nlabeled polynomials unchanged after reduction. The equivalence between F5 and\nF5B is also shown. At last, some versions of the F5 algorithm are illustrated."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1008.3459v1", 
    "title": "Bit-size estimates for triangular sets in positive dimension", 
    "arxiv-id": "1008.3459v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2010-08-20T08:43:03Z", 
    "summary": "We give bit-size estimates for the coefficients appearing in triangular sets\ndescribing positive-dimensional algebraic sets defined over Q. These estimates\nare worst case upper bounds; they depend only on the degree and height of the\nunderlying algebraic sets. We illustrate the use of these results in the\ncontext of a modular algorithm. This extends results by the first and last\nauthor, which were confined to the case of dimension 0. Our strategy is to get\nback to dimension 0 by evaluation and inter- polation techniques. Even though\nthe main tool (height theory) remains the same, new difficulties arise to\ncontrol the growth of the coefficients during the interpolation process."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1010.1764v2", 
    "title": "Improved complexity bounds for real root isolation using Continued   Fractions", 
    "arxiv-id": "1010.1764v2", 
    "author": "Elias Tsigaridas", 
    "publish": "2010-10-08T18:54:07Z", 
    "summary": "We consider the problem of isolating the real roots of a square-free\npolynomial with integer coefficients using (variants of) the continued fraction\nalgorithm (CF). We introduce a novel way to compute a lower bound on the\npositive real roots of univariate polynomials. This allows us to derive a worst\ncase bound of $\\sOB(d^6 + d^4\\tau^2 + d^3\\tau^2)$ for isolating the real roots\nof a polynomial with integer coefficients using the classic variant of CF,\nwhere $d$ is the degree of the polynomial and $\\tau$ the maximum bitsize of its\ncoefficients. This improves the previous bound by Sharma \\cite{sharma-tcs-2008}\nby a factor of $d^3$ and matches the bound derived by Mehlhorn and Ray\n\\cite{mr-jsc-2009} for another variant of CF; it also matches the worst case\nbound of the subdivision-based solvers. We present a new variant of CF, we call\nit iCF, that isolates the real roots of a polynomial with integer coefficients\nin $\\sOB(d^5+d^4\\tau)$, thus improving the current known bound for the problem\nby a factor of $d$. If the polynomial has only real roots, then our bound\nbecomes $\\sOB(d^4+d^3\\tau+ d^2\\tau^2)$, thus matching the bound of the\nnumerical algorithms by Reif \\cite{r-focs-1993} and by Ben-Or and Tiwari\n\\cite{bt-joc-1990}. Actually the latter bound holds in a more general setting,\nthat is under the rather mild assumption that $\\Omega(d/\\lg^c{d})$, where\n$c\\geq 0$ is a constant, roots contribute to the sign variations of the\ncoefficient list of the polynomial. This is the only bound on exact algorithms\nthat matches the one of the numerical algorithms by Pan \\cite{Pan02jsc} and\nSch\\\"onhage \\cite{Sch82}. To our knowledge the presented bounds are the best\nknown for the problem of real root isolation for algorithms based on exact\ncomputations."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1010.2006v2", 
    "title": "Improved complexity bounds for real root isolation using Continued   Fractions", 
    "arxiv-id": "1010.2006v2", 
    "author": "Elias Tsigaridas", 
    "publish": "2010-10-11T06:02:43Z", 
    "summary": "We consider the problem of isolating the real roots of a square-free\npolynomial with integer coefficients using (variants of) the continued fraction\nalgorithm (CF). We introduce a novel way to compute a lower bound on the\npositive real roots of univariate polynomials. This allows us to derive a worst\ncase bound of $\\sOB(d^6 + d^4\\tau^2 + d^3\\tau^2)$ for isolating the real roots\nof a polynomial with integer coefficients using the classic variant\n\\cite{Akritas:implementation} of CF, where $d$ is the degree of the polynomial\nand $\\tau$ the maximum bitsize of its coefficients. This improves the previous\nbound of Sharma \\cite{sharma-tcs-2008} by a factor of $d^3$ and matches the\nbound derived by Mehlhorn and Ray \\cite{mr-jsc-2009} for another variant of CF;\nit also matches the worst case bound of the subdivision-based solvers."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1012.3442v1", 
    "title": "Th\u00e9orie de Galois effective : aide m\u00e9moire", 
    "arxiv-id": "1012.3442v1", 
    "author": "Annick Valibouze", 
    "publish": "2010-12-15T19:49:42Z", 
    "summary": "This paper collects many results on galoisian ideals and Galois theory."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1012.5353v1", 
    "title": "Computing Differential Equations for Integrals Associated to Smooth Fano   Polytopes", 
    "arxiv-id": "1012.5353v1", 
    "author": "Nobuki Takayama", 
    "publish": "2010-12-24T07:40:16Z", 
    "summary": "We give an approximate algorithm of computing holonomic systems of linear\ndifferential equations for definite integrals with parameters. We show that\nthis algorithm gives a correct answer in finite steps, but we have no general\nstopping condition. We apply the approximate method to find differential\nequations for integrals associated to smooth Fano polytopes. They are\ninterested in the study of K3 surfaces and the toric mirror symmetry. In this\nclass of integrals, we can apply Stienstra's rank formula to our algorithm,\nwhich gives a stopping condition of the approximate algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1101.2803v1", 
    "title": "A Refined Denominator Bounding Algorithm for Multivariate Linear   Difference Equations", 
    "arxiv-id": "1101.2803v1", 
    "author": "Carsten Schneider", 
    "publish": "2011-01-14T13:41:29Z", 
    "summary": "We continue to investigate which polynomials can possibly occur as factors in\nthe denominators of rational solutions of a given partial linear difference\nequation.\n  In an earlier article we had introduced the distinction between periodic and\naperiodic factors in the denominator, and we gave an algorithm for predicting\nthe aperiodic ones. Now we extend this technique towards the periodic case and\npresent a refined algorithm which also finds most of the periodic factors."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1101.3140v1", 
    "title": "Deflation and Certified Isolation of Singular Zeros of Polynomial   Systems", 
    "arxiv-id": "1101.3140v1", 
    "author": "Bernard Mourrain", 
    "publish": "2011-01-17T08:02:23Z", 
    "summary": "We develop a new symbolic-numeric algorithm for the certification of singular\nisolated points, using their associated local ring structure and certified\nnumerical computations. An improvement of an existing method to compute inverse\nsystems is presented, which avoids redundant computation and reduces the size\nof the intermediate linear systems to solve. We derive a one-step deflation\ntechnique, from the description of the multiplicity structure in terms of\ndifferentials. The deflated system can be used in Newton-based iterative\nschemes with quadratic convergence. Starting from a polynomial system and a\nsmall-enough neighborhood, we obtain a criterion for the existence and\nuniqueness of a singular root of a given multiplicity structure, applying a\nwell-chosen symbolic perturbation. Standard verification methods, based eg. on\ninterval arithmetic and a fixed point theorem, are employed to certify that\nthere exists a unique perturbed system with a singular root in the domain.\nApplications to topological degree computation and to the analysis of real\nbranches of an implicit curve illustrate the method."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1101.3382v2", 
    "title": "A Generalized Criterion for Signature Related Gr\u00f6bner Basis Algorithms", 
    "arxiv-id": "1101.3382v2", 
    "author": "Dingkang Wang", 
    "publish": "2011-01-18T04:13:04Z", 
    "summary": "A generalized criterion for signature related algorithms to compute Gr\\\"obner\nbasis is proposed in this paper. Signature related algorithms are a popular\nkind of algorithms for computing Gr\\\"obner basis, including the famous F5\nalgorithm, the extended F5 algorithm and the GVW algorithm. The main purpose of\ncurrent paper is to study in theory what kind of criteria is correct in\nsignature related algorithms and provide a generalized method to develop new\ncriteria. For this purpose, a generalized criterion is proposed. The\ngeneralized criterion only relies on a general partial order defined on a set\nof polynomials. When specializing the partial order to appropriate specific\norders, the generalized criterion can specialize to almost all existing\ncriteria of signature related algorithms. For {\\em admissible} partial orders,\na complete proof of the correctness of the algorithm based on this generalized\ncriterion is also presented. This proof has no extra requirements on the\ncomputing order of critical pairs, and is also valid for non-homogeneous\npolynomial systems. More importantly, the partial orders implied by existing\ncriteria are admissible. Besides, one can also check whether a new criterion is\ncorrect in signature related algorithms or even develop new criteria by using\nother admissible partial orders in the generalized criterion."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1101.3603v1", 
    "title": "Multiplicity Preserving Triangular Set Decomposition of Two Polynomials", 
    "arxiv-id": "1101.3603v1", 
    "author": "Xiao-Shan Gao", 
    "publish": "2011-01-19T02:59:37Z", 
    "summary": "In this paper, a multiplicity preserving triangular set decomposition\nalgorithm is proposed for a system of two polynomials. The algorithm decomposes\nthe variety defined by the polynomial system into unmixed components\nrepresented by triangular sets, which may have negative multiplicities. In the\nbivariate case, we give a complete algorithm to decompose the system into\nmultiplicity preserving triangular sets with positive multiplicities. We also\nanalyze the complexity of the algorithm in the bivariate case. We implement our\nalgorithm and show the effectiveness of the method with extensive experiments."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1102.1809v1", 
    "title": "Generalized companion matrix for approximate GCD", 
    "arxiv-id": "1102.1809v1", 
    "author": "Olivier Ruatta", 
    "publish": "2011-02-09T08:26:25Z", 
    "summary": "We study a variant of the univariate approximate GCD problem, where the\ncoefficients of one polynomial f(x)are known exactly, whereas the coefficients\nof the second polynomial g(x)may be perturbed. Our approach relies on the\nproperties of the matrix which describes the operator of multiplication by gin\nthe quotient ring C[x]=(f). In particular, the structure of the null space of\nthe multiplication matrix contains all the essential information about GCD(f;\ng). Moreover, the multiplication matrix exhibits a displacement structure that\nallows us to design a fast algorithm for approximate GCD computation with\nquadratic complexity w.r.t. polynomial degrees."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1102.4681v1", 
    "title": "Root Isolation of Zero-dimensional Polynomial Systems with Linear   Univariate Representation", 
    "arxiv-id": "1102.4681v1", 
    "author": "Leilei Guo", 
    "publish": "2011-02-23T08:12:18Z", 
    "summary": "In this paper, a linear univariate representation for the roots of a\nzero-dimensional polynomial equation system is presented, where the roots of\nthe equation system are represented as linear combinations of roots of several\nunivariate polynomial equations. The main advantage of this representation is\nthat the precision of the roots can be easily controlled. In fact, based on the\nlinear univariate representation, we can give the exact precisions needed for\nroots of the univariate equations in order to obtain the roots of the equation\nsystem to a given precision. As a consequence, a root isolation algorithm for a\nzero-dimensional polynomial equation system can be easily derived from its\nlinear univariate representation."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1105.4682v1", 
    "title": "A note on Solving Parametric Polynomial Systems", 
    "arxiv-id": "1105.4682v1", 
    "author": "Asieh Pourhaghani", 
    "publish": "2011-05-24T05:42:39Z", 
    "summary": "Lazard and Rouillier in [9], by introducing the concept of discriminant\nvariety, have described a new and efficient algorithm for solving parametric\npolynomial systems. In this paper we modify this algorithm, and we show that\nwith our improvements the output of our algorithm is always minimal and it does\nnot need to compute the radical of ideals."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1106.4918v1", 
    "title": "A Generalized Criterion for Signature-based Algorithms to Compute   Gr\u00f6bner Bases", 
    "arxiv-id": "1106.4918v1", 
    "author": "Dingkang Wang", 
    "publish": "2011-06-24T09:21:56Z", 
    "summary": "A generalized criterion for signature-based algorithms to compute Gr\\\"obner\nbases is proposed in this paper. This criterion is named by \"generalized\ncriterion\", because it can be specialized to almost all existing criteria for\nsignature-based algorithms which include the famous F5 algorithm, F5C, extended\nF5, G$^2$V and the GVW algorithm. The main purpose of current paper is to study\nin theory which kind of criteria is correct in signature-based algorithms and\nprovide a generalized method to develop new criteria. For this purpose, by\nstudying some key facts and observations of signature-based algorithms, a\ngeneralized criterion is proposed. The generalized criterion only relies on a\npartial order defined on a set of polynomials. When specializing the partial\norder to appropriate specific orders, the generalized criterion can specialize\nto almost all existing criteria of signature-based algorithms. For {\\em\nadmissible} partial orders, a proof is presented for the correctness of the\nalgorithm that is based on this generalized criterion. And the partial orders\nimplied by the criteria of F5 and GVW are also shown to be admissible. More\nimportantly, the generalized criterion provides an effective method to check\nwhether a new criterion is correct as well as to develop new criteria for\nsignature-based algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1107.3584v1", 
    "title": "On Consensus under Polynomial Protocols", 
    "arxiv-id": "1107.3584v1", 
    "author": "Debasish Ghose", 
    "publish": "2011-07-18T21:50:21Z", 
    "summary": "In this paper we explore the possibility of using computational algebraic\nmethods to analyze a class of consensus protocols. We state some necessary\nconditions for convergence under consensus protocols that are polynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1108.1301v1", 
    "title": "Solving Detachability Problem for the Polynomial Ring by Signature-based   Groebner Basis Algorithms", 
    "arxiv-id": "1108.1301v1", 
    "author": "Dingkang Wang", 
    "publish": "2011-08-05T11:09:40Z", 
    "summary": "Signature-based algorithms are a popular kind of algorithms for computing\nGroebner basis, including the famous F5 algorithm, F5C, extended F5, G2V and\nthe GVW algorithm. In this paper, an efficient method is proposed to solve the\ndetachability problem. The new method only uses the outputs of signature-based\nalgorithms, and no extra Groebner basis computations are needed. When a\nGroebner basis is obtained by signature-based algorithms, the detachability\nproblem can be settled in polynomial time."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1108.4508v2", 
    "title": "Trading Order for Degree in Creative Telescoping", 
    "arxiv-id": "1108.4508v2", 
    "author": "Manuel Kauers", 
    "publish": "2011-08-23T07:26:25Z", 
    "summary": "We analyze the differential equations produced by the method of creative\ntelescoping applied to a hyperexponential term in two variables. We show that\nequations of low order have high degree, and that higher order equations have\nlower degree. More precisely, we derive degree bounding formulas which allow to\nestimate the degree of the output equations from creative telescoping as a\nfunction of the order. As an application, we show how the knowledge of these\nformulas can be used to improve, at least in principle, the performance of\ncreative telescoping implementations, and we deduce bounds on the asymptotic\ncomplexity of creative telescoping for hyperexponential terms."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1108.4772v3", 
    "title": "A fast algorithm for reversion of power series", 
    "arxiv-id": "1108.4772v3", 
    "author": "Fredrik Johansson", 
    "publish": "2011-08-24T07:41:26Z", 
    "summary": "We give an algorithm for reversion of formal power series, based on an\nefficient way to implement the Lagrange inversion formula. Our algorithm\nrequires $O(n^{1/2}(M(n) + MM(n^{1/2})))$ operations where $M(n)$ and $MM(n)$\nare the costs of polynomial and matrix multiplication respectively. This\nmatches the asymptotic complexity of an algorithm of Brent and Kung, but we\nachieve a constant factor speedup whose magnitude depends on the polynomial and\nmatrix multiplication algorithms used. Benchmarks confirm that the algorithm\nperforms well in practice."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1110.3185v1", 
    "title": "Structure of lexicographic Groebner bases in three variables of ideals   of dimension zero", 
    "arxiv-id": "1110.3185v1", 
    "author": "X. Dahan", 
    "publish": "2011-10-14T12:17:11Z", 
    "summary": "We generalize the structural theorem of Lazard in 1985, from 2 variables to 3\nvariables. We use the Gianni-Kalkbrener result to do this, which implies some\nrestrictions inside which lies the case of a radical ideal."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1111.0732v1", 
    "title": "Generating Loop Invariants by Computing Vanishing Ideals of Sample   Points", 
    "arxiv-id": "1111.0732v1", 
    "author": "Zhenbing Zeng", 
    "publish": "2011-11-03T05:40:29Z", 
    "summary": "Loop invariants play a very important role in proving correctness of\nprograms. In this paper, we address the problem of generating invariants of\npolynomial loop programs. We present a new approach, for generating polynomial\nequation invariants of polynomial loop programs through computing vanishing\nideals of sample points. We apply rational function interpolation, based on\nearly termination technique, to generate invariants of loop programs with\nsymbolic initial values. Our approach avoids first-order quantifier elimination\nand cylindrical algebraic decomposition(CAD). An algorithm for generating\npolynomial invariants is proposed and some examples are given to illustrate the\nalgorithm. Furthermore, we demonstrate on a set of loop programs with symbolic\ninitial values that our algorithm can yield polynomial invariants with degrees\nhigh up to 15."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1112.4014v1", 
    "title": "Note on fast division algorithm for polynomials using Newton iteration", 
    "arxiv-id": "1112.4014v1", 
    "author": "Hanyue Cao", 
    "publish": "2011-12-17T03:14:52Z", 
    "summary": "The classical division algorithm for polynomials requires $O(n^2)$ operations\nfor inputs of size $n$. Using reversal technique and Newton iteration, it can\nbe improved to $O({M}(n))$, where ${M}$ is a multiplication time. But the\nmethod requires that the degree of the modulo, $x^l$, should be the power of 2.\nIf $l$ is not a power of 2 and $f(0)=1$, Gathen and Gerhard suggest to compute\nthe inverse,$f^{-1}$, modulo $x^{\\lceil l/2^r\\rceil}, x^{\\lceil\nl/2^{r-1}\\rceil},..., x^{\\lceil l/2\\rceil}, x^l$, separately. But they did not\nspecify the iterative step. In this note, we show that the original Newton\niteration formula can be directly used to compute $f^{-1}\\,{mod}\\,x^{l}$\nwithout any additional cost, when $l$ is not a power of 2."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1112.4411v2", 
    "title": "On the Complexity of the Generalized MinRank Problem", 
    "arxiv-id": "1112.4411v2", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2011-12-19T17:18:33Z", 
    "summary": "We study the complexity of solving the \\emph{generalized MinRank problem},\ni.e. computing the set of points where the evaluation of a polynomial matrix\nhas rank at most $r$. A natural algebraic representation of this problem gives\nrise to a \\emph{determinantal ideal}: the ideal generated by all minors of size\n$r+1$ of the matrix. We give new complexity bounds for solving this problem\nusing Gr\\\"obner bases algorithms under genericity assumptions on the input\nmatrix. In particular, these complexity bounds allow us to identify families of\ngeneralized MinRank problems for which the arithmetic complexity of the solving\nprocess is polynomial in the number of solutions. We also provide an algorithm\nto compute a rational parametrization of the variety of a 0-dimensional and\nradical system of bi-degree $(D,1)$. We show that its complexity can be bounded\nby using the complexity bounds for the generalized MinRank problem."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1112.4703v1", 
    "title": "Abstracting Path Conditions for Effective Symbolic Execution", 
    "arxiv-id": "1112.4703v1", 
    "author": "Marek Trt\u00edk", 
    "publish": "2011-12-20T14:36:01Z", 
    "summary": "We present an algorithm for tests generation tools based on symbolic\nexecution. The algorithm is supposed to help in situations, when a tool is\nrepeatedly failing to cover some code by tests. The algorithm then provides the\ntool a necessary condition strongly narrowing space of program paths, which\nmust be checked for reaching the uncovered code. We also discuss integration of\nthe algorithm into the tools and we provide experimental results showing a\npotential of the algorithm to be valuable in the tools, when properly\nimplemented there."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1201.1177v1", 
    "title": "Computational Tutorial on Gr\u00f6bner bases embedding Sage in LaTeX with   SageTEX", 
    "arxiv-id": "1201.1177v1", 
    "author": "Edinah K. Gnang", 
    "publish": "2012-01-05T14:32:00Z", 
    "summary": "Elementary tutorial on implementation aspects of Gr\\\"obner bases computation."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1201.1982v1", 
    "title": "Order-Degree Curves for Hypergeometric Creative Telescoping", 
    "arxiv-id": "1201.1982v1", 
    "author": "Manuel Kauers", 
    "publish": "2012-01-10T08:04:59Z", 
    "summary": "Creative telescoping applied to a bivariate proper hypergeometric term\nproduces linear recurrence operators with polynomial coefficients, called\ntelescopers. We provide bounds for the degrees of the polynomials appearing in\nthese operators. Our bounds are expressed as curves in the (r,d)-plane which\nassign to every order r a bound on the degree d of the telescopers. These\ncurves are hyperbolas, which reflect the phenomenon that higher order\ntelescopers tend to have lower degree, and vice versa."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11425-011-4176-y", 
    "link": "http://arxiv.org/pdf/1202.0179v1", 
    "title": "Critical Points and Gr\u00f6bner Bases: the Unmixed Case", 
    "arxiv-id": "1202.0179v1", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2012-02-01T14:42:59Z", 
    "summary": "We consider the problem of computing critical points of the restriction of a\npolynomial map to an algebraic variety. This is of first importance since the\nglobal minimum of such a map is reached at a critical point. Thus, these points\nappear naturally in non-convex polynomial optimization which occurs in a wide\nrange of scientific applications (control theory, chemistry, economics,...).\nCritical points also play a central role in recent algorithms of effective real\nalgebraic geometry. Experimentally, it has been observed that Gr\\\"obner basis\nalgorithms are efficient to compute such points. Therefore, recent software\nbased on the so-called Critical Point Method are built on Gr\\\"obner bases\nengines. Let $f_1,..., f_p$ be polynomials in $ \\Q[x_1,..., x_n]$ of degree\n$D$, $V\\subset\\C^n$ be their complex variety and $\\pi_1$ be the projection map\n$(x_1,.., x_n)\\mapsto x_1$. The critical points of the restriction of $\\pi_1$\nto $V$ are defined by the vanishing of $f_1,..., f_p$ and some maximal minors\nof the Jacobian matrix associated to $f_1,..., f_p$. Such a system is\nalgebraically structured: the ideal it generates is the sum of a determinantal\nideal and the ideal generated by $f_1,..., f_p$. We provide the first\ncomplexity estimates on the computation of Gr\\\"obner bases of such systems\ndefining critical points. We prove that under genericity assumptions on\n$f_1,..., f_p$, the complexity is polynomial in the generic number of critical\npoints, i.e. $D^p(D-1)^{n-p}{{n-1}\\choose{p-1}}$. More particularly, in the\nquadratic case D=2, the complexity of such a Gr\\\"obner basis computation is\npolynomial in the number of variables $n$ and exponential in $p$. We also give\nexperimental evidence supporting these theoretical results."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2442829.2442847", 
    "link": "http://arxiv.org/pdf/1205.0879v1", 
    "title": "Fast Computation of Common Left Multiples of Linear Ordinary   Differential Operators", 
    "arxiv-id": "1205.0879v1", 
    "author": "Bruno Salvy", 
    "publish": "2012-05-04T08:35:52Z", 
    "summary": "We study tight bounds and fast algorithms for LCLMs of several linear\ndifferential operators with polynomial coefficients. We analyze the arithmetic\ncomplexity of existing algorithms for LCLMs, as well as the size of their\noutputs. We propose a new algorithm that recasts the LCLM computation in a\nlinear algebra problem on a polynomial matrix. This algorithm yields sharp\nbounds on the coefficient degrees of the LCLM, improving by one order of\nmagnitude the best bounds obtained using previous algorithms. The complexity of\nthe new algorithm is almost optimal, in the sense that it nearly matches the\narithmetic size of the output."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2442829.2442847", 
    "link": "http://arxiv.org/pdf/1205.3414v1", 
    "title": "Power Series Solutions of Singular (q)-Differential Equations", 
    "arxiv-id": "1205.3414v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2012-05-15T15:27:15Z", 
    "summary": "We provide algorithms computing power series solutions of a large class of\ndifferential or $q$-differential equations or systems. Their number of\narithmetic operations grows linearly with the precision, up to logarithmic\nterms."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2442829.2442847", 
    "link": "http://arxiv.org/pdf/1206.2346v5", 
    "title": "Power Series Solution to Non-Linear Partial Differential equations of   Mathematical Physics", 
    "arxiv-id": "1206.2346v5", 
    "author": "J. J. Godina Nava", 
    "publish": "2012-06-11T00:58:53Z", 
    "summary": "Power Series Solution method has been used traditionally for to solve Linear\nDifferential Equations, in Ordinary and Partial form. But this method has been\nlimited to this kind of problems. We present the solution of problems of Non\nLinear Partial Differential equations of Physical Mathematical using power\nseries."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2442829.2442847", 
    "link": "http://arxiv.org/pdf/1208.6112v4", 
    "title": "Generic Regular Decompositions for Generic Zero-Dimensional Systems", 
    "arxiv-id": "1208.6112v4", 
    "author": "Bican Xia", 
    "publish": "2012-08-30T08:43:38Z", 
    "summary": "Two new concepts, generic regular decomposition and\nregular-decomposition-unstable (RDU) variety for generic zero-dimensional\nsystems, are introduced in this paper and an algorithm is proposed for\ncomputing a generic regular decomposition and the associated RDU variety of a\ngiven generic zero-dimensional system simultaneously. The solutions of the\ngiven system can be expressed by finitely many zero-dimensional regular chains\nif the parameter value is not on the RDU variety.\n  The so called weakly relatively simplicial decomposition plays a crucial role\nin the algorithm, which is based on the theories of subresultant chains.\nFurthermore, the algorithm can be naturally adopted to compute a non-redundant\nWu's decomposition and the decomposition is stable at any parameter value that\nis not on the RDU variety. The algorithm has been implemented with Maple 15 and\nexperimented with a number of benchmarks from the literature. Empirical results\nare also presented to show the good performance of the algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-32973-9_18", 
    "link": "http://arxiv.org/pdf/1209.5097v1", 
    "title": "A Note on the Space Complexity of Fast D-Finite Function Evaluation", 
    "arxiv-id": "1209.5097v1", 
    "author": "Marc Mezzarobba", 
    "publish": "2012-09-23T19:02:26Z", 
    "summary": "We state and analyze a generalization of the \"truncation trick\" suggested by\nGourdon and Sebah to improve the performance of power series evaluation by\nbinary splitting. It follows from our analysis that the values of D-finite\nfunctions (i.e., functions described as solutions of linear differential\nequations with polynomial coefficients) may be computed with error bounded by\n2^(-p) in time O(p*(lg p)^(3+o(1))) and space O(p). The standard fast algorithm\nfor this task, due to Chudnovsky and Chudnovsky, achieves the same time\ncomplexity bound but requires \\Theta(p*lg p) bits of memory."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-32973-9_18", 
    "link": "http://arxiv.org/pdf/1210.4960v3", 
    "title": "A new Truncated Fourier Transform algorithm", 
    "arxiv-id": "1210.4960v3", 
    "author": "Andrew Arnold", 
    "publish": "2012-10-17T21:16:30Z", 
    "summary": "Truncated Fourier Transforms (TFTs), first introduced by Van der Hoeven,\nrefer to a family of algorithms that attempt to smooth \"jumps\" in complexity\nexhibited by FFT algorithms. We present an in-place TFT whose time complexity,\nmeasured in terms of ring operations, is comparable to existing not-in-place\nTFT methods. We also describe a transformation that maps between two families\nof TFT algorithms that use different sets of evaluation points."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-32973-9_18", 
    "link": "http://arxiv.org/pdf/1210.5543v1", 
    "title": "An Incremental Algorithm for Computing Cylindrical Algebraic   Decompositions", 
    "arxiv-id": "1210.5543v1", 
    "author": "Marc Moreno Maza", 
    "publish": "2012-10-19T21:31:13Z", 
    "summary": "In this paper, we propose an incremental algorithm for computing cylindrical\nalgebraic decompositions. The algorithm consists of two parts: computing a\ncomplex cylindrical tree and refining this complex tree into a cylindrical tree\nin real space. The incrementality comes from the first part of the algorithm,\nwhere a complex cylindrical tree is constructed by refining a previous complex\ncylindrical tree with a polynomial constraint. We have implemented our\nalgorithm in Maple. The experimentation shows that the proposed algorithm\noutperforms existing ones for many examples taken from the literature."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-32973-9_18", 
    "link": "http://arxiv.org/pdf/1212.4731v2", 
    "title": "Multiple precision evaluation of the Airy Ai function with reduced   cancellation", 
    "arxiv-id": "1212.4731v2", 
    "author": "Marc Mezzarobba", 
    "publish": "2012-12-19T16:45:44Z", 
    "summary": "The series expansion at the origin of the Airy function Ai(x) is alternating\nand hence problematic to evaluate for x > 0 due to cancellation. Based on a\nmethod recently proposed by Gawronski, M\\\"uller, and Reinhard, we exhibit two\nfunctions F and G, both with nonnegative Taylor expansions at the origin, such\nthat Ai(x) = G(x)/F(x). The sums are now well-conditioned, but the Taylor\ncoefficients of G turn out to obey an ill-conditioned three-term recurrence. We\nuse the classical Miller algorithm to overcome this issue. We bound all errors\nand our implementation allows an arbitrary and certified accuracy, that can be\nused, e.g., for providing correct rounding in arbitrary precision."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1212.5417v1", 
    "title": "Program Verification in the presence of complex numbers, functions with   branch cuts etc", 
    "arxiv-id": "1212.5417v1", 
    "author": "David Wilson", 
    "publish": "2012-12-21T12:35:51Z", 
    "summary": "In considering the reliability of numerical programs, it is normal to \"limit\nour study to the semantics dealing with numerical precision\" (Martel, 2005). On\nthe other hand, there is a great deal of work on the reliability of programs\nthat essentially ignores the numerics. The thesis of this paper is that there\nis a class of problems that fall between these two, which could be described as\n\"does the low-level arithmetic implement the high-level mathematics\". Many of\nthese problems arise because mathematics, particularly the mathematics of the\ncomplex numbers, is more difficult than expected: for example the complex\nfunction log is not continuous, writing down a program to compute an inverse\nfunction is more complicated than just solving an equation, and many algebraic\nsimplification rules are not universally valid.\n  The good news is that these problems are theoretically capable of being\nsolved, and are practically close to being solved, but not yet solved, in\nseveral real-world examples. However, there is still a long way to go before\nimplementations match the theoretical possibilities."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1302.2169v1", 
    "title": "Representation, simplification and display of fractional powers of   rational numbers in computer algebra", 
    "arxiv-id": "1302.2169v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2013-02-08T22:41:08Z", 
    "summary": "Simplification of fractional powers of positive rational numbers and of sums,\nproducts and powers of such numbers is taught in beginning algebra. Such\nnumbers can often be expressed in many ways, as this article discusses in some\ndetail. Since they are such a restricted subset of algebraic numbers, it might\nseem that good simplification of them must already be implemented in all widely\nused computer algebra systems. However, the algorithm taught in beginning\nalgebra uses integer factorization, which can consume unacceptable time for the\nlarge numbers that often arise within computer algebra. Therefore some systems\napparently use various ad hoc techniques that can return an incorrect result\nbecause of not simplifying to 0 the difference between two equivalent such\nexpressions. Even systems that avoid this flaw often do not return the same\nresult for all equivalent such input forms, or return an unnecessarily bulky\nresult that does not have any other compensating useful property. This article\nidentifies some of these deficiencies, then describes the advantages and\ndisadvantages of various alternative forms and how to overcome the deficiencies\nwithout costly integer factorization."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1302.2224v1", 
    "title": "Computer-Aided Derivation of Multi-scale Models: A Rewriting Framework", 
    "arxiv-id": "1302.2224v1", 
    "author": "Michel Lenczner", 
    "publish": "2013-02-09T11:56:12Z", 
    "summary": "We introduce a framework for computer-aided derivation of multi-scale models.\nIt relies on a combination of an asymptotic method used in the field of partial\ndifferential equations with term rewriting techniques coming from computer\nscience.\n  In our approach, a multi-scale model derivation is characterized by the\nfeatures taken into account in the asymptotic analysis. Its formulation\nconsists in a derivation of a reference model associated to an elementary\nnominal model, and in a set of transformations to apply to this proof until it\ntakes into account the wanted features. In addition to the reference model\nproof, the framework includes first order rewriting principles designed for\nasymptotic model derivations, and second order rewriting principles dedicated\nto transformations of model derivations. We apply the method to generate a\nfamily of homogenized models for second order elliptic equations with periodic\ncoefficients that could be posed in multi-dimensional domains, with possibly\nmulti-domains and/or thin domains."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1302.4688v1", 
    "title": "An Algorithm for Computing the Limit Points of the Quasi-component of a   Regular Chain", 
    "arxiv-id": "1302.4688v1", 
    "author": "Marc Moreno Maza", 
    "publish": "2013-02-19T17:25:14Z", 
    "summary": "For a regular chain $R$, we propose an algorithm which computes the\n(non-trivial) limit points of the quasi-component of $R$, that is, the set\n$\\bar{W(R)} \\setminus W(R)$. Our procedure relies on Puiseux series expansions\nand does not require to compute a system of generators of the saturated ideal\nof $R$. We focus on the case where this saturated ideal has dimension one and\nwe discuss extensions of this work in higher dimensions. We provide\nexperimental results illustrating the benefits of our algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1302.6401v1", 
    "title": "An implementation of CAD in Maple utilising McCallum projection", 
    "arxiv-id": "1302.6401v1", 
    "author": "Matthew England", 
    "publish": "2013-02-26T11:33:33Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets. Originally introduced by Collins in the\n1970s for use in quantifier elimination it has since found numerous\napplications within algebraic geometry and beyond. Following from his original\nwork in 1988, McCallum presented an improved algorithm, CADW, which offered a\nhuge increase in the practical utility of CAD. In 2009 a team based at the\nUniversity of Western Ontario presented a new and quite separate algorithm for\nCAD, which was implemented and included in the computer algebra system Maple.\nAs part of a wider project at Bath investigating CAD and its applications,\nCollins and McCallum's CAD algorithms have been implemented in Maple. This\nreport details these implementations and compares them to Qepcad and the\nOntario algorithm.\n  The implementations were originally undertaken to facilitate research into\nthe connections between the algorithms. However, the ability of the code to\nguarantee order-invariant output has led to its use in new research on CADs\nwhich are minimal for certain problems. In addition, the implementation\ndescribed here is of interest as the only full implementation of CADW, (since\nQepcad does not currently make use of McCallum's delineating polynomials), and\nhence can solve problems not admissible to other CAD implementations."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1308.2371v1", 
    "title": "Signature-Based Gr\u00f6bner Basis Algorithms --- Extended MMM Algorithm   for computing Gr\u00f6bner bases", 
    "arxiv-id": "1308.2371v1", 
    "author": "Yao Sun", 
    "publish": "2013-08-11T07:35:14Z", 
    "summary": "Signature-based algorithms is a popular kind of algorithms for computing\nGr\\\"obner bases, and many related papers have been published recently. In this\npaper, no new signature-based algorithms and no new proofs are presented.\nInstead, a view of signature-based algorithms is given, that is,\nsignature-based algorithms can be regarded as an extended version of the famous\nMMM algorithm. By this view, this paper aims to give an easier way to\nunderstand signature-based Gr\\\"obner basis algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1308.5029v1", 
    "title": "Computing Equilibria of Semi-algebraic Economies Using Triangular   Decomposition and Real Solution Classification", 
    "arxiv-id": "1308.5029v1", 
    "author": "Dongming Wang", 
    "publish": "2013-08-23T02:24:00Z", 
    "summary": "In this paper, we are concerned with the problem of determining the existence\nof multiple equilibria in economic models. We propose a general and complete\napproach for identifying multiplicities of equilibria in semi-algebraic\neconomies, which may be expressed as semi-algebraic systems. The approach is\nbased on triangular decomposition and real solution classification, two\npowerful tools of algebraic computation. Its effectiveness is illustrated by\ntwo examples of application."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1309.2138v3", 
    "title": "On the Complexity of Computing Critical Points with Gr\u00f6bner Bases", 
    "arxiv-id": "1309.2138v3", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2013-09-09T12:49:18Z", 
    "summary": "Computing the critical points of a polynomial function $q\\in\\mathbb\nQ[X_1,\\ldots,X_n]$ restricted to the vanishing locus $V\\subset\\mathbb R^n$ of\npolynomials $f_1,\\ldots, f_p\\in\\mathbb Q[X_1,\\ldots, X_n]$ is of first\nimportance in several applications in optimization and in real algebraic\ngeometry. These points are solutions of a highly structured system of\nmultivariate polynomial equations involving maximal minors of a Jacobian\nmatrix. We investigate the complexity of solving this problem by using\nGr\\\"obner basis algorithms under genericity assumptions on the coefficients of\nthe input polynomials. The main results refine known complexity bounds (which\ndepend on the maximum $D=\\max(deg(f_1),\\ldots,deg(f_p),deg(q))$) to bounds\nwhich depend on the list of degrees $(deg(f_1),\\ldots,deg(f_p),deg(q))$: we\nprove that the Gr\\\"obner basis computation can be performed in\n$\\delta^{O(\\log(A)/\\log(G))}$ arithmetic operations in $\\mathbb Q$, where\n$\\delta$ is the algebraic degree of the ideal vanishing on the critical points,\nand $A$ and $G$ are the arithmetic and geometric average of a multiset\nconstructed from the sequence of degrees. As a by-product, we prove that\nsolving such generic optimization problems with Gr\\\"obner bases requires at\nmost $D^{O(n)}$ arithmetic operations in $\\mathbb Q$, which meets the best\nknown complexity bound for this problem. Finally, we illustrate these\ncomplexity results with experiments, giving evidence that these bounds are\nrelevant for applications."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1309.4044v2", 
    "title": "A probabilistic and deterministic modular algorithm for computing   Groebner basis over $\\Q$", 
    "arxiv-id": "1309.4044v2", 
    "author": "Bernard Parisse", 
    "publish": "2013-09-16T17:31:38Z", 
    "summary": "Modular algorithm are widely used in computer algebra systems (CAS), for\nexample to compute efficiently the gcd of multivariate polynomials. It is known\nto work to compute Groebner basis over $\\Q$, but it does not seem to be popular\namong CAS implementers. In this paper, I will show how to check a candidate\nGroebner basis (obtained by reconstruction of several Groebner basis modulo\ndistinct prime numbers) with a given error probability, that may be 0 if a\ncertified Groebner basis is desired. This algorithm is now the default\nalgorithm used by the Giac/Xcas computer algebra system with competitive\ntimings, thanks to a trick that can accelerate computing Groebner basis modulo\na prime once the computation has been done modulo another prime."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1309.6655v1", 
    "title": "Introduction to the Symbolic Integration System", 
    "arxiv-id": "1309.6655v1", 
    "author": "Weiguang Mao", 
    "publish": "2013-09-23T16:26:40Z", 
    "summary": "Symbolic integration is an important module of a typical Computer Algebra\nSystem. As for now, Mathematica, Matlab, Maple and Sage are all mainstream CAS.\nThey share the same framework for symbolic integration at some points. In this\nbook first we review the state of the art in the field of CAS. Then we focus on\ntypical frameworks of the current symbolic integration systems and summarize\nthe main mathematical theories behind these frameworks. Based on the\nopen-source computer algebra system maTHmU developed by our team in our\nuniversity, we propose a potential framework to improve the performance of the\ncurrent symbolic integration system."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1311.3720v2", 
    "title": "On the length of integers in telescopers for proper hypergeometric terms", 
    "arxiv-id": "1311.3720v2", 
    "author": "Lily Yen", 
    "publish": "2013-11-15T04:10:38Z", 
    "summary": "We show that the number of digits in the integers of a creative telescoping\nrelation of expected minimal order for a bivariate proper hypergeometric term\nhas essentially cubic growth with the problem size. For telescopers of higher\norder but lower degree we obtain a quintic bound. Experiments suggest that\nthese bounds are tight. As applications of our results, we give an improved\nbound on the maximal possible integer root of the leading coefficient of a\ntelescoper, and the first discussion of the bit complexity of creative\ntelescoping."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2012.68", 
    "link": "http://arxiv.org/pdf/1311.6897v1", 
    "title": "Analyzing Multiplicities of a Zero-dimensional Regular Set's Zeros Using   Pseudo Squarefree Decomposition", 
    "arxiv-id": "1311.6897v1", 
    "author": "Yao Sun", 
    "publish": "2013-11-27T08:42:29Z", 
    "summary": "In this paper, we are concerned with the problem of counting the\nmultiplicities of a zero-dimensional regular set's zeros. We generalize the\nsquarefree decomposition of univariate polynomials to the so-called pseudo\nsquarefree decomposition of multivariate polynomials, and then propose an\nalgorithm for decomposing a regular set into a finite number of simple sets.\nFrom the output of this algorithm, the multiplicities of zeros could be\ndirectly read out, and the real solution isolation with multiplicity can also\nbe easily produced. Experiments with a preliminary implementation show the\nefficiency of our method."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608641", 
    "link": "http://arxiv.org/pdf/1402.2409v3", 
    "title": "A Generalized Apagodu-Zeilberger Algorithm", 
    "arxiv-id": "1402.2409v3", 
    "author": "Christoph Koutschan", 
    "publish": "2014-02-11T09:35:59Z", 
    "summary": "The Apagodu-Zeilberger algorithm can be used for computing annihilating\noperators for definite sums over hypergeometric terms, or for definite\nintegrals over hyperexponential functions. In this paper, we propose a\ngeneralization of this algorithm which is applicable to arbitrary\n$\\partial$-finite functions. In analogy to the hypergeometric case, we\nintroduce the notion of proper $\\partial$-finite functions. We show that the\nalgorithm always succeeds for these functions, and we give a tight a priori\nbound for the order of the output operator."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608663", 
    "link": "http://arxiv.org/pdf/1402.7205v3", 
    "title": "Sparse Gr\u00f6bner Bases: the Unmixed Case", 
    "arxiv-id": "1402.7205v3", 
    "author": "Jules Svartz", 
    "publish": "2014-02-28T11:24:10Z", 
    "summary": "Toric (or sparse) elimination theory is a framework developped during the\nlast decades to exploit monomial structures in systems of Laurent polynomials.\nRoughly speaking, this amounts to computing in a \\emph{semigroup algebra},\n\\emph{i.e.} an algebra generated by a subset of Laurent monomials. In order to\nsolve symbolically sparse systems, we introduce \\emph{sparse Gr\\\"obner bases},\nan analog of classical Gr\\\"obner bases for semigroup algebras, and we propose\nsparse variants of the $F_5$ and FGLM algorithms to compute them. Our prototype\n\"proof-of-concept\" implementation shows large speed-ups (more than 100 for some\nexamples) compared to optimized (classical) Gr\\\"obner bases software. Moreover,\nin the case where the generating subset of monomials corresponds to the points\nwith integer coordinates in a normal lattice polytope $\\mathcal P\\subset\\mathbb\nR^n$ and under regularity assumptions, we prove complexity bounds which depend\non the combinatorial properties of $\\mathcal P$. These bounds yield new\nestimates on the complexity of solving $0$-dim systems where all polynomials\nshare the same Newton polytope (\\emph{unmixed case}). For instance, we\ngeneralize the bound $\\min(n_1,n_2)+1$ on the maximal degree in a Gr\\\"obner\nbasis of a $0$-dim. bilinear system with blocks of variables of sizes\n$(n_1,n_2)$ to the multilinear case: $\\sum n_i - \\max(n_i)+1$. We also propose\na variant of Fr\\\"oberg's conjecture which allows us to estimate the complexity\nof solving overdetermined sparse systems."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608663", 
    "link": "http://arxiv.org/pdf/1404.1428v2", 
    "title": "An Improvement over the GVW Algorithm for Inhomogeneous Polynomial   Systems", 
    "arxiv-id": "1404.1428v2", 
    "author": "Dingkang Wang", 
    "publish": "2014-04-05T03:49:32Z", 
    "summary": "The GVW algorithm is a signature-based algorithm for computing Gr\\\"obner\nbases. If the input system is not homogeneous, some J-pairs with higher\nsignatures but lower degrees are rejected by GVW's Syzygy Criterion, instead,\nGVW have to compute some J-pairs with lower signatures but higher degrees.\nConsequently, degrees of polynomials appearing during the computations may\nunnecessarily grow up higher and the computation become more expensive. In this\npaper, a variant of the GVW algorithm, called M-GVW, is proposed and mutant\npairs are introduced to overcome inconveniences brought by inhomogeneous input\npolynomials. Some techniques from linear algebra are used to improve the\nefficiency. Both GVW and M-GVW have been implemented in C++ and tested by many\nexamples from boolean polynomial rings. The timings show M-GVW usually performs\nmuch better than the original GVW algorithm when mutant pairs are found.\nBesides, M-GVW is also compared with intrinsic Gr\\\"obner bases functions on\nMaple, Singular and Magma. Due to the efficient routines from the M4RI library,\nthe experimental results show that M-GVW is very efficient."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608663", 
    "link": "http://arxiv.org/pdf/1404.2371v1", 
    "title": "The Secant-Newton Map is Optimal Among Contracting $n^{th}$ Degree Maps   for $n^{th}$ Root Computation", 
    "arxiv-id": "1404.2371v1", 
    "author": "Hoon Hong", 
    "publish": "2014-04-09T05:48:36Z", 
    "summary": "Consider the problem: given a real number $x$ and an error bound $\\epsilon$,\nfind an interval such that it contains the $\\sqrt[n]{x}$ and its width is less\nthan $\\epsilon$. One way to solve the problem is to start with an initial\ninterval and to repeatedly update it by applying an interval refinement map on\nit until it becomes narrow enough. In this paper, we prove that the well known\nSecant-Newton map is optimal among a certain family of natural generalizations."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608663", 
    "link": "http://arxiv.org/pdf/1404.4768v1", 
    "title": "Nearly Optimal Computations with Structured Matrices", 
    "arxiv-id": "1404.4768v1", 
    "author": "Elias Tsigaridas", 
    "publish": "2014-04-18T12:43:34Z", 
    "summary": "We estimate the Boolean complexity of multiplication of structured matrices\nby a vector and the solution of nonsingular linear systems of equations with\nthese matrices. We study four basic most popular classes, that is, Toeplitz,\nHankel, Cauchy and Van-der-monde matrices, for which the cited computational\nproblems are equivalent to the task of polynomial multiplication and division\nand polynomial and rational multipoint evaluation and interpolation. The\nBoolean cost estimates for the latter problems have been obtained by Kirrinnis\nin \\cite{kirrinnis-joc-1998}, except for rational interpolation, which we\nsupply now. All known Boolean cost estimates for these problems rely on using\nKronecker product. This implies the $d$-fold precision increase for the $d$-th\ndegree output, but we avoid such an increase by relying on distinct techniques\nbased on employing FFT. Furthermore we simplify the analysis and make it more\ntransparent by combining the representation of our tasks and algorithms in\nterms of both structured matrices and polynomials and rational functions. This\nalso enables further extensions of our estimates to cover Trummer's important\nproblem and computations with the popular classes of structured matrices that\ngeneralize the four cited basic matrix classes."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608663", 
    "link": "http://arxiv.org/pdf/1404.4775v1", 
    "title": "Accelerated Approximation of the Complex Roots of a Univariate   Polynomial (Extended Abstract)", 
    "arxiv-id": "1404.4775v1", 
    "author": "Elias Tsigaridas", 
    "publish": "2014-04-18T12:51:33Z", 
    "summary": "Highly efficient and even nearly optimal algorithms have been developed for\nthe classical problem of univariate polynomial root-finding (see, e.g.,\n\\cite{P95}, \\cite{P02}, \\cite{MNP13}, and the bibliography therein), but this\nis still an area of active research. By combining some powerful techniques\ndeveloped in this area we devise new nearly optimal algorithms, whose\nsubstantial merit is their simplicity, important for the implementation."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_5", 
    "link": "http://arxiv.org/pdf/1404.6371v1", 
    "title": "Problem formulation for truth-table invariant cylindrical algebraic   decomposition by incremental triangular decomposition", 
    "arxiv-id": "1404.6371v1", 
    "author": "David Wilson", 
    "publish": "2014-04-25T09:49:49Z", 
    "summary": "Cylindrical algebraic decompositions (CADs) are a key tool for solving\nproblems in real algebraic geometry and beyond. We recently presented a new CAD\nalgorithm combining two advances: truth-table invariance, making the CAD\ninvariant with respect to the truth of logical formulae rather than the signs\nof polynomials; and CAD construction by regular chains technology, where first\na complex decomposition is constructed by refining a tree incrementally by\nconstraint. We here consider how best to formulate problems for input to this\nalgorithm. We focus on a choice (not relevant for other CAD algorithms) about\nthe order in which constraints are presented. We develop new heuristics to help\nmake this choice and thus allow the best use of the algorithm in practice. We\nalso consider other choices of problem formulation for CAD, as discussed in\nCICM 2013, revisiting these in the context of the new algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_5", 
    "link": "http://arxiv.org/pdf/1406.0599v1", 
    "title": "Hierarchical Comprehensive Triangular Decomposition", 
    "arxiv-id": "1406.0599v1", 
    "author": "Bican Xia", 
    "publish": "2014-06-03T07:13:17Z", 
    "summary": "The concept of comprehensive triangular decomposition (CTD) was first\nintroduced by Chen et al. in their CASC'2007 paper and could be viewed as an\nanalogue of comprehensive Grobner systems for parametric polynomial systems.\nThe first complete algorithm for computing CTD was also proposed in that paper\nand implemented in the RegularChains library in Maple. Following our previous\nwork on generic regular decomposition for parametric polynomial systems, we\nintroduce in this paper a so-called hierarchical strategy for computing CTDs.\nRoughly speaking, for a given parametric system, the parametric space is\ndivided into several sub-spaces of different dimensions and we compute CTDs\nover those sub-spaces one by one. So, it is possible that, for some benchmarks,\nit is difficult to compute CTDs in reasonable time while this strategy can\nobtain some \"partial\" solutions over some parametric sub-spaces. The program\nbased on this strategy has been tested on a number of benchmarks from the\nliterature. Experimental results on these benchmarks with comparison to\nRegularChains are reported and may be valuable for developing more efficient\ntriangularization tools."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_5", 
    "link": "http://arxiv.org/pdf/1408.2776v2", 
    "title": "A Difference Ring Theory for Symbolic Summation", 
    "arxiv-id": "1408.2776v2", 
    "author": "Carsten Schneider", 
    "publish": "2014-08-12T16:54:37Z", 
    "summary": "A summation framework is developed that enhances Karr's difference field\napproach. It covers not only indefinite nested sums and products in terms of\ntranscendental extensions, but it can treat, e.g., nested products defined over\nroots of unity. The theory of the so-called $R\\Pi\\Sigma^*$-extensions is\nsupplemented by algorithms that support the construction of such difference\nrings automatically and that assist in the task to tackle symbolic summation\nproblems. Algorithms are presented that solve parameterized telescoping\nequations, and more generally parameterized first-order difference equations,\nin the given difference ring. As a consequence, one obtains algorithms for the\nsummation paradigms of telescoping and Zeilberger's creative telescoping. With\nthis difference ring theory one obtains a rigorous summation machinery that has\nbeen applied to numerous challenging problems coming, e.g., from combinatorics\nand particle physics."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_5", 
    "link": "http://arxiv.org/pdf/1408.3639v1", 
    "title": "Solving Polynomial Equations with Equation Constraints: the   Zero-dimensional Case", 
    "arxiv-id": "1408.3639v1", 
    "author": "Ye Liang", 
    "publish": "2014-08-15T20:03:21Z", 
    "summary": "A zero-dimensional polynomial ideal may have a lot of complex zeros. But\nsometimes, only some of them are needed. In this paper, for a zero-dimensional\nideal $I$, we study its complex zeros that locate in another variety\n$\\textbf{V}(J)$ where $J$ is an arbitrary ideal.\n  The main problem is that for a point in $\\textbf{V}(I) \\cap\n\\textbf{V}(J)=\\textbf{V}(I+J)$, its multiplicities w.r.t. $I$ and $I+J$ may be\ndifferent. Therefore, we cannot get the multiplicity of this point w.r.t. $I$\nby studying $I + J$. A straightforward way is that first compute the points of\n$\\textbf{V}(I + J)$, then study their multiplicities w.r.t. $I$. But the former\nstep is difficult to realize exactly.\n  In this paper, we propose a natural geometric explanation of the localization\nof a polynomial ring corresponding to a semigroup order. Then, based on this\nview, using the standard basis method and the border basis method, we introduce\na way to compute the complex zeros of $I$ in $\\textbf{V}(J)$ with their\nmultiplicities w.r.t. $I$. As an application, we compute the sum of Milnor\nnumbers of the singular points on a polynomial hypersurface and work out all\nthe singular points on the hypersurface with their Milnor numbers."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_5", 
    "link": "http://arxiv.org/pdf/1408.5879v2", 
    "title": "Computing the determinant of a matrix with polynomial entries by   approximation", 
    "arxiv-id": "1408.5879v2", 
    "author": "Yong Feng", 
    "publish": "2014-08-25T19:45:05Z", 
    "summary": "Computing the determinant of a matrix with the univariate and multivariate\npolynomial entries arises frequently in the scientific computing and\nengineering fields. In this paper, an effective algorithm is presented for\ncomputing the determinant of a matrix with polynomial entries using hybrid\nsymbolic and numerical computation. The algorithm relies on the Newton's\ninterpolation method with error control for solving Vandermonde systems. It is\nalso based on a novel approach for estimating the degree of variables, and the\ndegree homomorphism method for dimension reduction. Furthermore, the\nparallelization of the method arises naturally."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2014.15", 
    "link": "http://arxiv.org/pdf/1409.1781v1", 
    "title": "Using the distribution of cells by dimension in a cylindrical algebraic   decomposition", 
    "arxiv-id": "1409.1781v1", 
    "author": "James H. Davenport", 
    "publish": "2014-09-05T13:11:17Z", 
    "summary": "We investigate the distribution of cells by dimension in cylindrical\nalgebraic decompositions (CADs). We find that they follow a standard\ndistribution which seems largely independent of the underlying problem or CAD\nalgorithm used. Rather, the distribution is inherent to the cylindrical\nstructure and determined mostly by the number of variables.\n  This insight is then combined with an algorithm that produces only\nfull-dimensional cells to give an accurate method of predicting the number of\ncells in a complete CAD. Since constructing only full-dimensional cells is\nrelatively inexpensive (involving no costly algebraic number calculations) this\nleads to heuristics for helping with various questions of problem formulation\nfor CAD, such as choosing an optimal variable ordering. Our experiments\ndemonstrate that this approach can be highly effective."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2014.15", 
    "link": "http://arxiv.org/pdf/1409.5462v1", 
    "title": "Fast and deterministic computation of the determinant of a polynomial   matrix", 
    "arxiv-id": "1409.5462v1", 
    "author": "George Labahn", 
    "publish": "2014-09-18T20:55:37Z", 
    "summary": "Given a square, nonsingular matrix of univariate polynomials\n$\\mathbf{F}\\in\\mathbb{K}[x]^{n\\times n}$ over a field $\\mathbb{K}$, we give a\ndeterministic algorithm for finding the determinant of $\\mathbf{F}$. The\ncomplexity of the algorithm is $\\bigO \\left(n^{\\omega}s\\right)$ field\noperations where $s$ is the average column degree or the average row degree of\n$\\mathbf{F}$. Here $\\bigO$ notation is Big-$O$ with log factors omitted and\n$\\omega$ is the exponent of matrix multiplication."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2014.15", 
    "link": "http://arxiv.org/pdf/1409.7788v1", 
    "title": "On Ideal Lattices and Gr\u00f6bner Bases", 
    "arxiv-id": "1409.7788v1", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2014-09-27T10:01:19Z", 
    "summary": "In this paper, we draw a connection between ideal lattices and Gr\\\"{o}bner\nbases in the multivariate polynomial rings over integers. We study extension of\nideal lattices in $\\mathbb{Z}[x]/\\langle f \\rangle$ (Lyubashevsky \\&\nMicciancio, 2006) to ideal lattices in\n$\\mathbb{Z}[x_1,\\ldots,x_n]/\\mathfrak{a}$, the multivariate case, where $f$ is\na polynomial in $\\mathbb{Z}[X]$ and $\\mathfrak{a}$ is an ideal in\n$\\mathbb{Z}[x_1,\\ldots,x_n]$. Ideal lattices in univariate case are interpreted\nas generalizations of cyclic lattices. We introduce a notion of multivariate\ncyclic lattices and we show that multivariate ideal lattices are indeed a\ngeneralization of them. We show that the fact that existence of ideal lattice\nin univariate case if and only if $f$ is monic translates to short reduced\nGr\\\"obner basis (Francis \\& Dukkipati, 2014) of $\\mathfrak{a}$ is monic in\nmultivariate case. We, thereby, give a necessary and sufficient condition for\nresidue class polynomial rings over $\\mathbb{Z}$ to have ideal lattices. We\nalso characterize ideals in $\\mathbb{Z}[x_1,\\ldots,x_n]$ that give rise to full\nrank lattices."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2014.15", 
    "link": "http://arxiv.org/pdf/1501.00334v5", 
    "title": "Data-Discriminants of Likelihood Equations", 
    "arxiv-id": "1501.00334v5", 
    "author": "Xiaoxian Tang", 
    "publish": "2015-01-02T01:55:37Z", 
    "summary": "Maximum likelihood estimation (MLE) is a fundamental computational problem in\nstatistics. The problem is to maximize the likelihood function with respect to\ngiven data on a statistical model. An algebraic approach to this problem is to\nsolve a very structured parameterized polynomial system called likelihood\nequations. For general choices of data, the number of complex solutions to the\nlikelihood equations is finite and called the ML-degree of the model. The only\nsolutions to the likelihood equations that are statistically meaningful are the\nreal/positive solutions. However, the number of real/positive solutions is not\ncharacterized by the ML-degree. We use discriminants to classify data according\nto the number of real/positive solutions of the likelihood equations. We call\nthese discriminants data-discriminants (DD). We develop a probabilistic\nalgorithm for computing DDs. Experimental results show that, for the benchmarks\nwe have tried, the probabilistic algorithm is more efficient than the standard\nelimination algorithm. Based on the computational results, we discuss the real\nroot classification problem for the 3 by 3 symmetric matrix~model."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756678", 
    "link": "http://arxiv.org/pdf/1501.04466v2", 
    "title": "Improving the use of equational constraints in cylindrical algebraic   decomposition", 
    "arxiv-id": "1501.04466v2", 
    "author": "James H. Davenport", 
    "publish": "2015-01-19T12:10:21Z", 
    "summary": "When building a cylindrical algebraic decomposition (CAD) savings can be made\nin the presence of an equational constraint (EC): an equation logically implied\nby a formula.\n  The present paper is concerned with how to use multiple ECs, propagating\nthose in the input throughout the projection set. We improve on the approach of\nMcCallum in ISSAC 2001 by using the reduced projection theory to make savings\nin the lifting phase (both to the polynomials we lift with and the cells lifted\nover). We demonstrate the benefits with worked examples and a complexity\nanalysis."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756678", 
    "link": "http://arxiv.org/pdf/1501.04836v1", 
    "title": "Subtropical Real Root Finding", 
    "arxiv-id": "1501.04836v1", 
    "author": "Thomas Sturm", 
    "publish": "2015-01-20T15:01:11Z", 
    "summary": "We describe a new incomplete but terminating method for real root finding for\nlarge multivariate polynomials. We take an abstract view of the polynomial as\nthe set of exponent vectors associated with sign information on the\ncoefficients. Then we employ linear programming to heuristically find roots.\nThere is a specialized variant for roots with exclusively positive coordinates,\nwhich is of considerable interest for applications in chemistry and systems\nbiology. An implementation of our method combining the computer algebra system\nReduce with the linear programming solver Gurobi has been successfully applied\nto input data originating from established mathematical models used in these\nareas. We have solved several hundred problems with up to more than 800000\nmonomials in up to 10 variables with degrees up to 12. Our method has failed\ndue to its incompleteness in less than 8 percent of the cases."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1501.05239v2", 
    "title": "Computing the Rank Profile Matrix", 
    "arxiv-id": "1501.05239v2", 
    "author": "Ziad Sultan", 
    "publish": "2015-01-21T17:31:13Z", 
    "summary": "The row (resp. column) rank profile of a matrix describes the staircase shape\nof its row (resp. column) echelon form. In an ISSAC'13 paper, we proposed a\nrecursive Gaussian elimination that can compute simultaneously the row and\ncolumn rank profiles of a matrix as well as those of all of its leading\nsub-matrices, in the same time as state of the art Gaussian elimination\nalgorithms. Here we first study the conditions making a Gaus-sian elimination\nalgorithm reveal this information. Therefore, we propose the definition of a\nnew matrix invariant, the rank profile matrix, summarizing all information on\nthe row and column rank profiles of all the leading sub-matrices. We also\nexplore the conditions for a Gaussian elimination algorithm to compute all or\npart of this invariant, through the corresponding PLUQ decomposition. As a\nconsequence, we show that the classical iterative CUP decomposition algorithm\ncan actually be adapted to compute the rank profile matrix. Used, in a Crout\nvariant, as a base-case to our ISSAC'13 implementation, it delivers a\nsignificant improvement in efficiency. Second, the row (resp. column) echelon\nform of a matrix are usually computed via different dedicated triangular\ndecompositions. We show here that, from some PLUQ decompositions, it is\npossible to recover the row and column echelon forms of a matrix and of any of\nits leading sub-matrices thanks to an elementary post-processing algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1501.05385v8", 
    "title": "Numerically Safe Gaussian Elimination with No Pivoting", 
    "arxiv-id": "1501.05385v8", 
    "author": "Liang Zhao", 
    "publish": "2015-01-22T04:07:57Z", 
    "summary": "Gaussian elimination with no pivoting and block Gaussian elimination are\nattractive alternatives to the customary but communication intensive Gaussian\nelimination with partial pivoting (hereafter we use the acronyms GENP, BGE, and\nGEPP} provided that the computations proceed safely and numerically safely},\nthat is, run into neither division by 0 nor numerical problems. Empirically,\nsafety and numerical safety of GENP have been consistently observed in a number\nof papers where an input matrix was pre-processed with various structured\nmultipliers chosen ad hoc. Our present paper provides missing formal support\nfor this empirical observation and explains why it was elusive so far. Namely\nwe prove that GENP is numerically unsafe for a specific class of input matrices\nin spite of its pre-processing with some well-known and well-tested structured\nmultipliers, but we also prove that GENP and BGE are safe and numerically safe\nfor the average input matrix pre-processed with any nonsingular and\nwell-conditioned multiplier. This should embolden search for sparse and\nstructured multipliers, and we list and test some new classes of them. We also\nseek randomized pre-processing that universally (that is, for all input\nmatrices) supports (i) safe GENP and BGE with probability 1 and/or (ii)\nnumerically safe GENP and BGE with a probability close to 1.We achieve goal (i)\nwith a Gaussian structured multiplier and goal (ii) with a Gaussian\nunstructured multiplier and alternatively with Gaussian structured\naugmentation. We consistently confirm all these formal results with our tests\nof GENP for benchmark inputs. We have extended our approach to other\nfundamental matrix computations and keep working on further extensions."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1501.05390v2", 
    "title": "Real Polynomial Root-finding by Means of Matrix and Polynomial   Iterations", 
    "arxiv-id": "1501.05390v2", 
    "author": "Liang Zhao", 
    "publish": "2015-01-22T04:30:09Z", 
    "summary": "Univariate polynomial root-finding is a classical subject, still important\nfor modern computing. Frequently one seeks just the real roots of a polynomial\nwith real coefficients. They can be approximated at a low computational cost if\nthe polynomial has no nonreal roots, but for high degree polynomials, nonreal\nroots are typically much more numerous than the real ones. The challenge is\nknown for a long time, and the subject has been intensively studied.\nNevertheless, we produce some novel ideas and techniques and obtain dramatic\nacceleration of the known algorithms. In order to achieve our progress we\nexploit the correlation between the computations with matrices and polynomials,\nrandomized matrix computations, and complex plane geometry, extend the\ntechniques of the matrix sign iterations, and use the structure of the\ncompanion matrix of the input polynomial. The results of our extensive tests\nwith benchmark polynomials and random matrices are quite encouraging. In\nparticular in our tests the number of iterations required for convergence of\nour algorithms grew very slowly (if at all) as we increased the degree of the\nunivariate input polynomials and the dimension of the input matrices from 64 to\n1024."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1501.05392v3", 
    "title": "Accelerated Approximation of the Complex Roots and Factors of a   Univariate Polynomial", 
    "arxiv-id": "1501.05392v3", 
    "author": "Liang Zhao", 
    "publish": "2015-01-22T04:39:26Z", 
    "summary": "The algorithms of Pan (1995) and(2002) approximate the roots of a complex\nunivariate polynomial in nearly optimal arithmetic and Boolean time but require\nprecision of computing that exceeds the degree of the polynomial. This causes\nnumerical stability problems when the degree is large. We observe, however,\nthat such a difficulty disappears at the initial stage of the algorithms, and\nin our present paper we extend this stage to root-finding within a nearly\noptimal arithmetic and Boolean complexity bounds provided that some mild\ninitial isolation of the roots of the input polynomial has been ensured.\nFurthermore our algorithm is nearly optimal for the approximation of the roots\nisolated in a fixed disc, square or another region on the complex plane rather\nthan all complex roots of a polynomial. Moreover the algorithm can be applied\nto a polynomial given by a black box for its evaluation (even if its\ncoefficients are not known); it promises to be of practical value for\npolynomial root-finding and factorization, the latter task being of interest on\nits own right. We also provide a new support for a winding number algorithm,\nwhich enables extension of our progress to obtaining mild initial\napproximations to the roots. We conclude with summarizing our algorithms and\ntheir extension to the approximation of isolated multiple roots and root\nclusters."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1007.0143v1", 
    "title": "From matrix interpretations over the rationals to matrix interpretations   over the naturals", 
    "arxiv-id": "1007.0143v1", 
    "author": "Salvador Lucas", 
    "publish": "2010-07-01T12:06:00Z", 
    "summary": "Matrix interpretations generalize linear polynomial interpretations and have\nbeen proved useful in the implementation of tools for automatically proving\ntermination of Term Rewriting Systems. In view of the successful use of\nrational coefficients in polynomial interpretations, we have recently\ngeneralized traditional matrix interpretations (using natural numbers in the\nmatrix entries) to incorporate real numbers. However, existing results which\nformally prove that polynomials over the reals are more powerful than\npolynomials over the naturals for proving termination of rewrite systems failed\nto be extended to matrix interpretations. In this paper we get deeper into this\nproblem. We show that, under some conditions, it is possible to transform a\nmatrix interpretation over the rationals satisfying a set of symbolic\nconstraints into a matrix interpretation over the naturals (using bigger\nmatrices) which still satisfies the constraints."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1104.1362v3", 
    "title": "Root Refinement for Real Polynomials", 
    "arxiv-id": "1104.1362v3", 
    "author": "Michael Sagraloff", 
    "publish": "2011-04-07T15:46:11Z", 
    "summary": "We consider the problem of approximating all real roots of a square-free\npolynomial $f$. Given isolating intervals, our algorithm refines each of them\nto a width of $2^{-L}$ or less, that is, each of the roots is approximated to\n$L$ bits after the binary point. Our method provides a certified answer for\narbitrary real polynomials, only considering finite approximations of the\npolynomial coefficients and choosing a suitable working precision adaptively.\nIn this way, we get a correct algorithm that is simple to implement and\npractically efficient. Our algorithm uses the quadratic interval refinement\nmethod; we adapt that method to be able to cope with inaccuracies when\nevaluating $f$, without sacrificing its quadratic convergence behavior. We\nprove a bound on the bit complexity of our algorithm in terms of the degree of\nthe polynomial, the size and the separation of the roots, that is, parameters\nexclusively related to the geometric location of the roots. Our bound is near\noptimal and significantly improves previous work on integer polynomials.\nFurthermore, it essentially matches the best known theoretical bounds on root\napproximation which are obtained by very sophisticated algorithms. We also\ninvestigate the practical behavior of the algorithm and demonstrate how closely\nthe practical performance matches our asymptotic bounds."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756682", 
    "link": "http://arxiv.org/pdf/1104.1510v1", 
    "title": "A Worst-case Bound for Topology Computation of Algebraic Curves", 
    "arxiv-id": "1104.1510v1", 
    "author": "Michael Sagraloff", 
    "publish": "2011-04-08T07:56:51Z", 
    "summary": "Computing the topology of an algebraic plane curve $\\mathcal{C}$ means to\ncompute a combinatorial graph that is isotopic to $\\mathcal{C}$ and thus\nrepresents its topology in $\\mathbb{R}^2$. We prove that, for a polynomial of\ndegree $n$ with coefficients bounded by $2^\\rho$, the topology of the induced\ncurve can be computed with $\\tilde{O}(n^8(n+\\rho^2))$ bit operations\ndeterministically, and with $\\tilde{O}(n^8\\rho^2)$ bit operations with a\nrandomized algorithm in expectation. Our analysis improves previous best known\ncomplexity bounds by a factor of $n^2$. The improvement is based on new\ntechniques to compute and refine isolating intervals for the real roots of\npolynomials, and by the consequent amortized analysis of the critical fibers of\nthe algebraic curve."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1109.2809v2", 
    "title": "On Kahan's Rules for Determining Branch Cuts", 
    "arxiv-id": "1109.2809v2", 
    "author": "Bruno Salvy", 
    "publish": "2011-09-13T14:52:47Z", 
    "summary": "In computer algebra there are different ways of approaching the mathematical\nconcept of functions, one of which is by defining them as solutions of\ndifferential equations. We compare different such approaches and discuss the\noccurring problems. The main focus is on the question of determining possible\nbranch cuts. We explore the extent to which the treatment of branch cuts can be\nrendered (more) algorithmic, by adapting Kahan's rules to the differential\nequation setting."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1109.3656v3", 
    "title": "Computing the Hermite Form of a Matrix of Ore Polynomials", 
    "arxiv-id": "1109.3656v3", 
    "author": "Myung Sub Kim", 
    "publish": "2011-09-16T16:11:26Z", 
    "summary": "Let R=F[D;sigma,delta] be the ring of Ore polynomials over a field (or skew\nfield) F, where sigma is a automorphism of F and delta is a sigma-derivation.\nGiven a an m by n matrix A over R, we show how to compute the Hermite form H of\nA and a unimodular matrix U such that UA=H. The algorithm requires a polynomial\nnumber of operations in F in terms of both the dimensions m and n, and the\ndegree of the entries in A. When F=k(z) for some field k, it also requires time\npolynomial in the degree in z, and if k is the rational numbers Q, it requires\ntime polynomial in the bit length of the coefficients as well. Explicit\nanalyses are provided for the complexity, in particular for the important cases\nof differential and shift polynomials over Q(z). To accomplish our algorithm,\nwe apply the Dieudonne determinant and quasideterminant theory for Ore\npolynomial rings to get explicit bounds on the degrees and sizes of entries in\nH and U."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1109.4323v1", 
    "title": "On the complexity of computing with zero-dimensional triangular sets", 
    "arxiv-id": "1109.4323v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2011-09-20T15:34:04Z", 
    "summary": "We study the complexity of some fundamental operations for triangular sets in\ndimension zero. Using Las-Vegas algorithms, we prove that one can perform such\noperations as change of order, equiprojectable decomposition, or quasi-inverse\ncomputation with a cost that is essentially that of modular composition. Over\nan abstract field, this leads to a subquadratic cost (with respect to the\ndegree of the underlying algebraic set). Over a finite field, in a boolean RAM\nmodel, we obtain a quasi-linear running time using Kedlaya and Umans' algorithm\nfor modular composition. Conversely, we also show how to reduce the problem of\nmodular composition to change of order for triangular sets, so that all these\nproblems are essentially equivalent. Our algorithms are implemented in Maple;\nwe present some experimental results."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1204.3735v1", 
    "title": "Computational linear algebra over finite fields", 
    "arxiv-id": "1204.3735v1", 
    "author": "Cl\u00e9ment Pernet", 
    "publish": "2012-04-17T09:06:42Z", 
    "summary": "We present here algorithms for efficient computation of linear algebra\nproblems over finite fields."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1204.3773v1", 
    "title": "Matrix Formula of Differential Resultant for First Order Generic   Ordinary Differential Polynomials", 
    "arxiv-id": "1204.3773v1", 
    "author": "Xiao-Shan Gao", 
    "publish": "2012-04-17T12:10:03Z", 
    "summary": "In this paper, a matrix representation for the differential resultant of two\ngeneric ordinary differential polynomials $f_1$ and $f_2$ in the differential\nindeterminate $y$ with order one and arbitrary degree is given. That is, a\nnon-singular matrix is constructed such that its determinant contains the\ndifferential resultant as a factor. Furthermore, the algebraic sparse resultant\nof $f_1, f_2, \\delta f_1, \\delta f_2$ treated as polynomials in $y, y', y\"$ is\nshown to be a non-zero multiple of the differential resultant of $f_1, f_2$.\nAlthough very special, this seems to be the first matrix representation for a\nclass of nonlinear generic differential polynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1207.3019v3", 
    "title": "Real Root Isolation of Polynomial Equations Based on Hybrid Computation", 
    "arxiv-id": "1207.3019v3", 
    "author": "Bican Xia", 
    "publish": "2012-07-12T16:52:08Z", 
    "summary": "A new algorithm for real root isolation of polynomial equations based on\nhybrid computation is presented in this paper. Firstly, the approximate\n(complex) zeros of the given polynomial equations are obtained via homotopy\ncontinuation method. Then, for each approximate zero, an initial box relying on\nthe Kantorovich theorem is constructed, which contains the corresponding\naccurate zero. Finally, the Krawczyk interval iteration with interval\narithmetic is applied to the initial boxes so as to check whether or not the\ncorresponding approximate zeros are real and to obtain the real root isolation\nboxes. Meanwhile, an empirical construction of initial box is provided for\nhigher performance. Our experiments on many benchmarks show that the new hybrid\nmethod is more efficient, compared with the traditional symbolic approaches."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1207.3887v2", 
    "title": "On lexicographic Groebner bases of radical ideals in dimension zero:   interpolation and structure", 
    "arxiv-id": "1207.3887v2", 
    "author": "Xavier Dahan", 
    "publish": "2012-07-17T06:03:57Z", 
    "summary": "Due to the elimination property held by the lexicographic monomial order, the\ncorresponding Groebner bases display strong structural properties from which\nmeaningful informations can easily be extracted. We study these properties for\nradical ideals of (co)dimension zero. The proof presented relies on a\ncombinatorial decomposition of the finite set of points whereby iterated\nLagrange interpolation formulas permit to reconstruct a minimal Groebner basis.\nThis is the first fully explicit interpolation formula for polynomials forming\na lexicographic Groebner basis, from which the structure property can easily be\nread off. The inductive nature of the proof also yield as a byproduct a\ntriangular decomposition algorithm from the Groebner basis."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1301.0917v1", 
    "title": "Desingularization Explains Order-Degree Curves for Ore Operators", 
    "arxiv-id": "1301.0917v1", 
    "author": "Michael F. Singer", 
    "publish": "2013-01-05T16:45:53Z", 
    "summary": "Desingularization is the problem of finding a left multiple of a given Ore\noperator in which some factor of the leading coefficient of the original\noperator is removed. An order-degree curve for a given Ore operator is a curve\nin the $(r,d)$-plane such that for all points $(r,d)$ above this curve, there\nexists a left multiple of order $r$ and degree $d$ of the given operator. We\ngive a new proof of a desingularization result by Abramov and van Hoeij for the\nshift case, and show how desingularization implies order-degree curves which\nare extremely accurate in examples."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2011.51", 
    "link": "http://arxiv.org/pdf/1301.2486v1", 
    "title": "Finding Hyperexponential Solutions of Linear ODEs by Numerical   Evaluation", 
    "arxiv-id": "1301.2486v1", 
    "author": "Marc Mezzarobba", 
    "publish": "2013-01-11T13:00:24Z", 
    "summary": "We present a new algorithm for computing hyperexponential solutions of\nordinary linear differential equations with polynomial coefficients. The\nalgorithm relies on interpreting formal series solutions at the singular points\nas analytic functions and evaluating them numerically at some common ordinary\npoint. The numerical data is used to determine a small number of combinations\nof the formal series that may give rise to hyperexponential solutions."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465935", 
    "link": "http://arxiv.org/pdf/1301.4313v2", 
    "title": "Creative telescoping for rational functions using the Griffiths-Dwork   method", 
    "arxiv-id": "1301.4313v2", 
    "author": "Bruno Salvy", 
    "publish": "2013-01-18T07:40:01Z", 
    "summary": "Creative telescoping algorithms compute linear differential equations\nsatisfied by multiple integrals with parameters. We describe a precise and\nelementary algorithmic version of the Griffiths-Dwork method for the creative\ntelescoping of rational functions. This leads to bounds on the order and degree\nof the coefficients of the differential equation, and to the first complexity\nresult which is simply exponential in the number of variables. One of the\nimportant features of the algorithm is that it does not need to compute\ncertificates. The approach is vindicated by a prototype implementation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465935", 
    "link": "http://arxiv.org/pdf/1301.4870v2", 
    "title": "From Approximate Factorization to Root Isolation with Application to   Cylindrical Algebraic Decomposition", 
    "arxiv-id": "1301.4870v2", 
    "author": "Pengming Wang", 
    "publish": "2013-01-21T14:14:07Z", 
    "summary": "We present an algorithm for isolating the roots of an arbitrary complex\npolynomial $p$ that also works for polynomials with multiple roots provided\nthat the number $k$ of distinct roots is given as part of the input. It outputs\n$k$ pairwise disjoint disks each containing one of the distinct roots of $p$,\nand its multiplicity. The algorithm uses approximate factorization as a\nsubroutine.\n  In addition, we apply the new root isolation algorithm to a recent algorithm\nfor computing the topology of a real planar algebraic curve specified as the\nzero set of a bivariate integer polynomial and for isolating the real solutions\nof a bivariate polynomial system. For input polynomials of degree $n$ and\nbitsize $\\tau$, we improve the currently best running time from\n$\\tO(n^{9}\\tau+n^{8}\\tau^{2})$ (deterministic) to $\\tO(n^{6}+n^{5}\\tau)$\n(randomized) for topology computation and from $\\tO(n^{8}+n^{7}\\tau)$\n(deterministic) to $\\tO(n^{6}+n^{5}\\tau)$ (randomized) for solving bivariate\nsystems."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465935", 
    "link": "http://arxiv.org/pdf/1301.4983v1", 
    "title": "Closed form solutions of linear difference equations in terms of   symmetric products", 
    "arxiv-id": "1301.4983v1", 
    "author": "Yongjae Cha", 
    "publish": "2013-01-21T20:54:32Z", 
    "summary": "In this paper we show how to find a closed form solution for third order\ndifference operators in terms of solutions of second order operators. This work\nis an extension of previous results on finding closed form solutions of\nrecurrence equations and a counterpart to existing results on differential\nequations. As motivation and application for this work, we discuss the problem\nof proving positivity of sequences given merely in terms of their defining\nrecurrence relation. The main advantage of the present approach to earlier\nmethods attacking the same problem is that our algorithm provides\nhuman-readable and verifiable, i.e., certified proofs."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465935", 
    "link": "http://arxiv.org/pdf/1301.5045v1", 
    "title": "Complexity of Creative Telescoping for Bivariate Rational Functions", 
    "arxiv-id": "1301.5045v1", 
    "author": "Ziming Li", 
    "publish": "2013-01-22T00:26:00Z", 
    "summary": "The long-term goal initiated in this work is to obtain fast algorithms and\nimplementations for definite integration in Almkvist and Zeilberger's framework\nof (differential) creative telescoping. Our complexity-driven approach is to\nobtain tight degree bounds on the various expressions involved in the method.\nTo make the problem more tractable, we restrict to bivariate rational\nfunctions. By considering this constrained class of inputs, we are able to\nblend the general method of creative telescoping with the well-known Hermite\nreduction. We then use our new method to compute diagonals of rational power\nseries arising from combinatorics."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465935", 
    "link": "http://arxiv.org/pdf/1301.5414v2", 
    "title": "Complexity Estimates for Two Uncoupling Algorithms", 
    "arxiv-id": "1301.5414v2", 
    "author": "\u00c9lie De Panafieu", 
    "publish": "2013-01-23T07:18:35Z", 
    "summary": "Uncoupling algorithms transform a linear differential system of first order\ninto one or several scalar differential equations. We examine two approaches to\nuncoupling: the cyclic-vector method (CVM) and the\nDanilevski-Barkatou-Z\\\"urcher algorithm (DBZ). We give tight size bounds on the\nscalar equations produced by CVM, and design a fast variant of CVM whose\ncomplexity is quasi-optimal with respect to the output size. We exhibit a\nstrong structural link between CVM and DBZ enabling to show that, in the\ngeneric case, DBZ has polynomial complexity and that it produces a single\nequation, strongly related to the output of CVM. We prove that algorithm CVM is\nfaster than DBZ by almost two orders of magnitude, and provide experimental\nresults that validate the theoretical complexity analyses."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465935", 
    "link": "http://arxiv.org/pdf/1301.5612v3", 
    "title": "On the Complexity of Computing Gr\u00f6bner Bases for Quasi-homogeneous   Systems", 
    "arxiv-id": "1301.5612v3", 
    "author": "Thibaut Verron", 
    "publish": "2013-01-23T19:49:36Z", 
    "summary": "Let $\\K$ be a field and $(f_1, \\ldots, f_n)\\subset \\K[X_1, \\ldots, X_n]$ be a\nsequence of quasi-homogeneous polynomials of respective weighted degrees $(d_1,\n\\ldots, d_n)$ w.r.t a system of weights $(w_{1},\\dots,w_{n})$. Such systems are\nlikely to arise from a lot of applications, including physics or cryptography.\nWe design strategies for computing Gr\\\"obner bases for quasi-homogeneous\nsystems by adapting existing algorithms for homogeneous systems to the\nquasi-homogeneous case. Overall, under genericity assumptions, we show that for\na generic zero-dimensional quasi-homogeneous system, the complexity of the full\nstrategy is polynomial in the weighted B\\'ezout bound $\\prod_{i=1}^{n}d_{i} /\n\\prod_{i=1}^{n}w_{i}$. We provide some experimental results based on generic\nsystems as well as systems arising from a cryptography problem. They show that\ntaking advantage of the quasi-homogeneous structure of the systems allow us to\nsolve systems that were out of reach otherwise."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.ipl.2009.03.012", 
    "link": "http://arxiv.org/pdf/1301.5804v1", 
    "title": "A simple and fast algorithm for computing exponentials of power series", 
    "arxiv-id": "1301.5804v1", 
    "author": "Eric Schost", 
    "publish": "2013-01-24T14:49:29Z", 
    "summary": "As was initially shown by Brent, exponentials of truncated power series can\nbe computed using a constant number of polynomial multiplications. This note\ngives a relatively simple algorithm with a low constant factor."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2016.07.025", 
    "link": "http://arxiv.org/pdf/1304.1238v1", 
    "title": "Sparse FGLM algorithms", 
    "arxiv-id": "1304.1238v1", 
    "author": "Chenqi Mou", 
    "publish": "2013-04-04T03:50:03Z", 
    "summary": "Given a zero-dimensional ideal I in K[x1,...,xn] of degree D, the\ntransformation of the ordering of its Groebner basis from DRL to LEX is a key\nstep in polynomial system solving and turns out to be the bottleneck of the\nwhole solving process. Thus it is of crucial importance to design efficient\nalgorithms to perform the change of ordering.\n  The main contributions of this paper are several efficient methods for the\nchange of ordering which take advantage of the sparsity of multiplication\nmatrices in the classical FGLM algorithm. Combing all these methods, we propose\na deterministic top-level algorithm that automatically detects which method to\nuse depending on the input. As a by-product, we have a fast implementation that\nis able to handle ideals of degree over 40000. Such an implementation\noutperforms the Magma and Singular ones, as shown by our experiments.\n  First for the shape position case, two methods are designed based on the\nWiedemann algorithm: the first is probabilistic and its complexity to complete\nthe change of ordering is O(D(N1+nlog(D))), where N1 is the number of nonzero\nentries of a multiplication matrix; the other is deterministic and computes the\nLEX Groebner basis of the radical of I via Chinese Remainder Theorem. Then for\nthe general case, the designed method is characterized by the\nBerlekamp-Massey-Sakata algorithm from Coding Theory to handle the\nmulti-dimensional linearly recurring relations. Complexity analyses of all\nproposed methods are also provided.\n  Furthermore, for generic polynomial systems, we present an explicit formula\nfor the estimation of the sparsity of one main multiplication matrix, and prove\nits construction is free. With the asymptotic analysis of such sparsity, we are\nable to show for generic systems the complexity above becomes $O(\\sqrt{6/n \\pi}\nD^{2+(n-1)/n}})$."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2016.07.025", 
    "link": "http://arxiv.org/pdf/1304.1928v2", 
    "title": "A probabilistic algorithm to compute the real dimension of a   semi-algebraic set", 
    "arxiv-id": "1304.1928v2", 
    "author": "Elias Tsigaridas", 
    "publish": "2013-04-06T19:23:00Z", 
    "summary": "Let $\\RR$ be a real closed field (e.g. the field of real numbers) and\n$\\mathscr{S} \\subset \\RR^n$ be a semi-algebraic set defined as the set of\npoints in $\\RR^n$ satisfying a system of $s$ equalities and inequalities of\nmultivariate polynomials in $n$ variables, of degree at most $D$, with\ncoefficients in an ordered ring $\\ZZ$ contained in $\\RR$. We consider the\nproblem of computing the {\\em real dimension}, $d$, of $\\mathscr{S}$. The real\ndimension is the first topological invariant of interest; it measures the\nnumber of degrees of freedom available to move in the set. Thus, computing the\nreal dimension is one of the most important and fundamental problems in\ncomputational real algebraic geometry. The problem is ${\\rm\nNP}_{\\mathbb{R}}$-complete in the Blum-Shub-Smale model of computation. The\ncurrent algorithms (probabilistic or deterministic) for computing the real\ndimension have complexity $(s \\, D)^{O(d(n-d))}$, that becomes $(s \\,\nD)^{O(n^2)}$ in the worst-case. The existence of a probabilistic or\ndeterministic algorithm for computing the real dimension with single\nexponential complexity with a factor better than ${O(n^2)}$ in the exponent in\nthe worst-case, is a longstanding open problem. We provide a positive answer to\nthis problem by introducing a probabilistic algorithm for computing the real\ndimension of a semi-algebraic set with complexity $(s\\, D)^{O(n)}$."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_5", 
    "link": "http://arxiv.org/pdf/1304.3483v2", 
    "title": "Faster sparse interpolation of straight-line programs", 
    "arxiv-id": "1304.3483v2", 
    "author": "Daniel S. Roche", 
    "publish": "2013-04-11T20:43:48Z", 
    "summary": "We give a new probabilistic algorithm for interpolating a \"sparse\" polynomial\nf given by a straight-line program. Our algorithm constructs an approximation\nf* of f, such that their difference probably has at most half the number of\nterms of f, then recurses on their difference. Our approach builds on previous\nwork by Garg and Schost (2009), and Giesbrecht and Roche (2011), and is\nasymptotically more efficient in terms of the total cost of the probes required\nthan previous methods, in many cases."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_5", 
    "link": "http://arxiv.org/pdf/1304.4691v1", 
    "title": "Efficient Calculation of Determinants of Symbolic Matrices with Many   Variables", 
    "arxiv-id": "1304.4691v1", 
    "author": "Ziv Scully", 
    "publish": "2013-04-17T05:07:55Z", 
    "summary": "Efficient matrix determinant calculations have been studied since the 19th\ncentury. Computers expand the range of determinants that are practically\ncalculable to include matrices with symbolic entries. However, the fastest\ndeterminant algorithms for numerical matrices are often not the fastest for\nsymbolic matrices with many variables. We compare the performance of two\nalgorithms, fraction-free Gaussian elimination and minor expansion, on symbolic\nmatrices with many variables. We show that, under a simplified theoretical\nmodel, minor expansion is faster in most situations. We then propose\noptimizations for minor expansion and demonstrate their effectiveness with\nempirical data."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_5", 
    "link": "http://arxiv.org/pdf/1304.5214v2", 
    "title": "Intrinsic complexity estimates in polynomial optimization", 
    "arxiv-id": "1304.5214v2", 
    "author": "Mohab Safey El Din", 
    "publish": "2013-04-18T18:42:46Z", 
    "summary": "It is known that point searching in basic semialgebraic sets and the search\nfor globally minimal points in polynomial optimization tasks can be carried out\nusing $(s\\,d)^{O(n)}$ arithmetic operations, where $n$ and $s$ are the numbers\nof variables and constraints and $d$ is the maximal degree of the polynomials\ninvolved.\\spar \\noindent We associate to each of these problems an intrinsic\nsystem degree which becomes in worst case of order $(n\\,d)^{O(n)}$ and which\nmeasures the intrinsic complexity of the task under consideration.\\spar\n\\noindent We design non-uniformly deterministic or uniformly probabilistic\nalgorithms of intrinsic, quasi-polynomial complexity which solve these\nproblems."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_5", 
    "link": "http://arxiv.org/pdf/1304.6039v2", 
    "title": "Polynomial Systems Solving by Fast Linear Algebra", 
    "arxiv-id": "1304.6039v2", 
    "author": "Gu\u00e9na\u00ebl Renault", 
    "publish": "2013-04-22T18:11:51Z", 
    "summary": "Polynomial system solving is a classical problem in mathematics with a wide\nrange of applications. This makes its complexity a fundamental problem in\ncomputer science. Depending on the context, solving has different meanings. In\norder to stick to the most general case, we consider a representation of the\nsolutions from which one can easily recover the exact solutions or a certified\napproximation of them. Under generic assumption, such a representation is given\nby the lexicographical Gr\\\"obner basis of the system and consists of a set of\nunivariate polynomials. The best known algorithm for computing the\nlexicographical Gr\\\"obner basis is in $\\widetilde{O}(d^{3n})$ arithmetic\noperations where $n$ is the number of variables and $d$ is the maximal degree\nof the equations in the input system. The notation $\\widetilde{O}$ means that\nwe neglect polynomial factors in $n$. We show that this complexity can be\ndecreased to $\\widetilde{O}(d^{\\omega n})$ where $2 \\leq \\omega < 2.3727$ is\nthe exponent in the complexity of multiplying two dense matrices. Consequently,\nwhen the input polynomial system is either generic or reaches the B\\'ezout\nbound, the complexity of solving a polynomial system is decreased from\n$\\widetilde{O}(D^3)$ to $\\widetilde{O}(D^\\omega)$ where $D$ is the number of\nsolutions of the system. To achieve this result we propose new algorithms which\nrely on fast linear algebra. When the degree of the equations are bounded\nuniformly by a constant we propose a deterministic algorithm. In the unbounded\ncase we present a Las Vegas algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-39320-4_2", 
    "link": "http://arxiv.org/pdf/1304.7222v2", 
    "title": "Optimising Problem Formulation for Cylindrical Algebraic Decomposition", 
    "arxiv-id": "1304.7222v2", 
    "author": "David Wilson", 
    "publish": "2013-04-26T16:45:11Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is an important tool for the study\nof real algebraic geometry with many applications both within mathematics and\nelsewhere. It is known to have doubly exponential complexity in the number of\nvariables in the worst case, but the actual computation time can vary greatly.\nIt is possible to offer different formulations for a given problem leading to\ngreat differences in tractability. In this paper we suggest a new measure for\nCAD complexity which takes into account the real geometry of the problem. This\nleads to new heuristics for choosing: the variable ordering for a CAD problem,\na designated equational constraint, and formulations for truth-table invariant\nCADs (TTICADs). We then consider the possibility of using Groebner bases to\nprecondition TTICAD and when such formulations constitute the creation of a new\nproblem."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-39320-4_2", 
    "link": "http://arxiv.org/pdf/1304.7380v1", 
    "title": "A Symbolic Approach to Boundary Problems for Linear Partial Differential   Equations: Applications to the Completely Reducible Case of the Cauchy   Problem with Constant Coefficients", 
    "arxiv-id": "1304.7380v1", 
    "author": "Nalina Phisanbut", 
    "publish": "2013-04-27T15:54:48Z", 
    "summary": "We introduce a general algebraic setting for describing linear boundary\nproblems in a symbolic computation context, with emphasis on the case of\npartial differential equations. The general setting is then applied to the\nCauchy problem for completely reducible partial differential equations with\nconstant coefficients. While we concentrate on the theoretical features in this\npaper, the underlying operator ring is implemented and provides a sufficient\nbasis for all methods presented here."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2465506.2465516", 
    "link": "http://arxiv.org/pdf/1304.7603v1", 
    "title": "Cylindrical Algebraic Decompositions for Boolean Combinations", 
    "arxiv-id": "1304.7603v1", 
    "author": "David Wilson", 
    "publish": "2013-04-29T09:46:40Z", 
    "summary": "This article makes the key observation that when using cylindrical algebraic\ndecomposition (CAD) to solve a problem with respect to a set of polynomials, it\nis not always the signs of those polynomials that are of paramount importance\nbut rather the truth values of certain quantifier free formulae involving them.\nThis motivates our definition of a Truth Table Invariant CAD (TTICAD). We\ngeneralise the theory of equational constraints to design an algorithm which\nwill efficiently construct a TTICAD for a wide class of problems, producing\nstronger results than when using equational constraints alone. The algorithm is\nimplemented fully in Maple and we present promising results from\nexperimentation."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_3", 
    "link": "http://arxiv.org/pdf/1305.4818v2", 
    "title": "Computer-Assisted Proofs of Some Identities for Bessel Functions of   Fractional Order", 
    "arxiv-id": "1305.4818v2", 
    "author": "Burkhard Zimmermann", 
    "publish": "2013-05-21T13:53:11Z", 
    "summary": "We employ computer algebra algorithms to prove a collection of identities\ninvolving Bessel functions with half-integer orders and other special\nfunctions. These identities appear in the famous Handbook of Mathematical\nFunctions, as well as in its successor, the DLMF, but their proofs were lost.\nWe use generating functions and symbolic summation techniques to produce new\nproofs for them."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_3", 
    "link": "http://arxiv.org/pdf/1306.3062v1", 
    "title": "An implementation of CAD in Maple utilising problem formulation,   equational constraints and truth-table invariance", 
    "arxiv-id": "1306.3062v1", 
    "author": "Matthew England", 
    "publish": "2013-06-13T09:35:05Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets, with applications within algebraic\ngeometry and beyond. We recently reported on a new implementation of CAD in\nMaple which implemented the original algorithm of Collins and the subsequent\nimprovement to projection by McCallum. Our implementation was in contrast to\nMaple's in-built CAD command, based on a quite separate theory. Although\ninitially developed as an investigative tool to compare the algorithms, we\nfound and reported that our code offered functionality not currently available\nin any other existing implementations. One particularly important piece of\nfunctionality is the ability to produce order-invariant CADs. This has allowed\nus to extend the implementation to produce CADs invariant with respect to\neither equational constraints (ECCADs) or the truth-tables of sequences of\nformulae (TTICADs). This new functionality is contained in the second release\nof our code, along with commands to consider problem formulation which can be a\nmajor factor in the tractability of a CAD. In the report we describe the new\nfunctionality and some theoretical discoveries it prompted. We describe how the\nCADs produced using equational constraints are able to take advantage of not\njust improved projection but also improvements in the lifting phase. We also\npresent an extension to the original TTICAD algorithm which increases both the\napplicability of TTICAD and its relative benefit over other algorithms. The\ncode and an introductory Maple worksheet / pdf demonstrating the full\nfunctionality of the package are freely available online."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_3", 
    "link": "http://arxiv.org/pdf/1306.4059v1", 
    "title": "Deciding Nonnegativity of Polynomials by MAPLE", 
    "arxiv-id": "1306.4059v1", 
    "author": "Bican Xia", 
    "publish": "2013-06-18T02:23:15Z", 
    "summary": "There have been some effective tools for solving (constant/parametric)\nsemi-algebraic systems in Maple's library RegularChains since Maple 13. By\nusing the functions of the library, e.g., RealRootClassfication, one can prove\nand discover polynomial inequalities. This paper is more or less a user guide\non using RealRootClassfication to prove the nonnegativity of polynomials. We\nshow by examples how to use this powerful tool to prove a polynomial is\nnonnegative under some polynomial inequality and/or equation constraints. Some\ntricks for using the tool are also provided."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_3", 
    "link": "http://arxiv.org/pdf/1306.6749v1", 
    "title": "Software for Evaluating Relevance of Steps in Algebraic Transformations", 
    "arxiv-id": "1306.6749v1", 
    "author": "Rein Prank", 
    "publish": "2013-06-28T08:15:43Z", 
    "summary": "Students of our department solve algebraic exercises in mathematical logic in\na computerized environment. They construct transformations step by step and the\nprogram checks the syntax, equivalence of expressions and completion of the\ntask. With our current project, we add a program component for checking\nrelevance of the steps."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1307.4554v1", 
    "title": "Creative Telescoping for Holonomic Functions", 
    "arxiv-id": "1307.4554v1", 
    "author": "Christoph Koutschan", 
    "publish": "2013-07-17T09:48:39Z", 
    "summary": "The aim of this article is twofold: on the one hand it is intended to serve\nas a gentle introduction to the topic of creative telescoping, from a practical\npoint of view; for this purpose its application to several problems is\nexemplified. On the other hand, this chapter has the flavour of a survey\narticle: the developments in this area during the last two decades are sketched\nand a selection of references is compiled in order to highlight the impact of\ncreative telescoping in numerous contexts."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1307.5655v2", 
    "title": "Fast polynomial evaluation and composition", 
    "arxiv-id": "1307.5655v2", 
    "author": "Guillaume Moroz", 
    "publish": "2013-07-22T11:12:44Z", 
    "summary": "The library \\emph{fast\\_polynomial} for Sage compiles multivariate\npolynomials for subsequent fast evaluation. Several evaluation schemes are\nhandled, such as H\\\"orner, divide and conquer and new ones can be added easily.\nNotably, a new scheme is introduced that improves the classical divide and\nconquer scheme when the number of terms is not a pure power of two. Natively,\nthe library handles polynomials over gmp big integers, boost intervals, python\nnumeric types. And any type that supports addition and multiplication can\nextend the library thanks to the template design. Finally, the code is\nparallelized for the divide and conquer schemes, and memory allocation is\nlocalized and optimized for the different evaluation schemes. This extended\nabstract presents the concepts behind the \\emph{fast\\_polynomial} library. The\nsage package can be downloaded at\n\\url{http://trac.sagemath.org/sage_trac/ticket/13358}."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1307.7836v3", 
    "title": "A nearly optimal algorithm for deciding connectivity queries in smooth   and bounded real algebraic sets", 
    "arxiv-id": "1307.7836v3", 
    "author": "Eric Schost", 
    "publish": "2013-07-30T06:30:48Z", 
    "summary": "A roadmap for a semi-algebraic set $S$ is a curve which has a non-empty and\nconnected intersection with all connected components of $S$. Hence, this kind\nof object, introduced by Canny, can be used to answer connectivity queries\n(with applications, for instance, to motion planning) but has also become of\ncentral importance in effective real algebraic geometry, since it is used in\nhigher-level algorithms. In this paper, we provide a probabilistic algorithm\nwhich computes roadmaps for smooth and bounded real algebraic sets. Its output\nsize and running time are polynomial in $(nD)^{n\\log(d)}$, where $D$ is the\nmaximum of the degrees of the input polynomials, $d$ is the dimension of the\nset under consideration and $n$ is the number of variables. More precisely, the\nrunning time of the algorithm is essentially subquadratic in the output size.\nEven under our assumptions, it is the first roadmap algorithm with output size\nand running time polynomial in $(nD)^{n\\log(d)}$."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1307.7887v2", 
    "title": "Fast Algorithms for Refined Parameterized Telescoping in Difference   Fields", 
    "arxiv-id": "1307.7887v2", 
    "author": "Carsten Schneider", 
    "publish": "2013-07-30T09:38:54Z", 
    "summary": "Parameterized telescoping (including telescoping and creative telescoping)\nand refined versions of it play a central role in the research area of symbolic\nsummation. Karr introduced 1981 $\\Pi\\Sigma$-fields, a general class of\ndifference fields, that enables one to consider this problem for indefinite\nnested sums and products covering as special cases, e.g., the\n($q$--)hypergeometric case and their mixed versions. This survey article\npresents the available algorithms in the framework of $\\Pi\\Sigma$-extensions\nand elaborates new results concerning efficiency."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1310.0919v1", 
    "title": "On the Parameterized Complexity of Associative and Commutative   Unification", 
    "arxiv-id": "1310.0919v1", 
    "author": "Atsuhiro Takasu", 
    "publish": "2013-10-03T08:00:43Z", 
    "summary": "This paper studies the unification problem with associative, commutative, and\nassociative-commutative functions mainly from a viewpoint of the parameterized\ncomplexity on the number of variables. It is shown that both associative and\nassociative-commutative unification problems are $W[1]$-hard. A fixed-parameter\nalgorithm and a polynomial-time algorithm are presented for special cases of\ncommutative unification in which one input term is variable-free and the number\nof variables is bounded by a constant, respectively. Related results including\nthose on the string and tree edit distance problems with variables are shown\ntoo."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1310.3741v1", 
    "title": "Evaluating parametric holonomic sequences using rectangular splitting", 
    "arxiv-id": "1310.3741v1", 
    "author": "Fredrik Johansson", 
    "publish": "2013-10-14T16:34:06Z", 
    "summary": "We adapt the rectangular splitting technique of Paterson and Stockmeyer to\nthe problem of evaluating terms in holonomic sequences that depend on a\nparameter. This approach allows computing the $n$-th term in a recurrent\nsequence of suitable type using $O(n^{1/2})$ \"expensive\" operations at the cost\nof an increased number of \"cheap\" operations.\n  Rectangular splitting has little overhead and can perform better than either\nnaive evaluation or asymptotically faster algorithms for ranges of $n$\nencountered in applications. As an example, fast numerical evaluation of the\ngamma function is investigated. Our work generalizes two previous algorithms of\nSmith."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1312.0453v2", 
    "title": "Comprehensive Border Bases for Zero Dimensional Parametric Polynomial   Ideals", 
    "arxiv-id": "1312.0453v2", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2013-12-02T13:46:25Z", 
    "summary": "In this paper, we extend the idea of comprehensive Gr\\\"{o}bner bases given by\nWeispfenning (1992) to border bases for zero dimensional parametric polynomial\nideals. For this, we introduce a notion of comprehensive border bases and\nborder system, and prove their existence even in the cases where they do not\ncorrespond to any term order. We further present algorithms to compute\ncomprehensive border bases and border system. Finally, we study the relation\nbetween comprehensive Gr\\\"{o}bner bases and comprehensive border bases w.r.t. a\nterm order and give an algorithm to compute such comprehensive border bases\nfrom comprehensive Gr\\\"{o}bner bases."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1312.0462v1", 
    "title": "A Generic Position Based Method for Real Root Isolation of   Zero-Dimensional Polynomial Systems", 
    "arxiv-id": "1312.0462v1", 
    "author": "Kai Jin", 
    "publish": "2013-12-02T14:05:16Z", 
    "summary": "We improve the local generic position method for isolating the real roots of\na zero-dimensional bivariate polynomial system with two polynomials and extend\nthe method to general zero-dimensional polynomial systems. The method mainly\ninvolves resultant computation and real root isolation of univariate polynomial\nequations. The roots of the system have a linear univariate representation. The\ncomplexity of the method is $\\tilde{O}_B(N^{10})$ for the bivariate case, where\n$N=\\max(d,\\tau)$, $d$ resp., $\\tau$ is an upper bound on the degree, resp., the\nmaximal coefficient bitsize of the input polynomials. The algorithm is\ncertified with probability 1 in the multivariate case. The implementation shows\nthat the method is efficient, especially for bivariate polynomial systems."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1312.1655v2", 
    "title": "On the Complexity of the F5 Gr\u00f6bner basis Algorithm", 
    "arxiv-id": "1312.1655v2", 
    "author": "Bruno Salvy", 
    "publish": "2013-12-05T19:47:02Z", 
    "summary": "We study the complexity of Gr\\\"obner bases computation, in particular in the\ngeneric situation where the variables are in simultaneous Noether position with\nrespect to the system.\n  We give a bound on the number of polynomials of degree $d$ in a Gr\\\"obner\nbasis computed by Faug\\`ere's $F_5$ algorithm~(Fau02) in this generic case for\nthe grevlex ordering (which is also a bound on the number of polynomials for a\nreduced Gr\\\"obner basis, independently of the algorithm used). Next, we analyse\nmore precisely the structure of the polynomials in the Gr\\\"obner bases with\nsignatures that $F_5$ computes and use it to bound the complexity of the\nalgorithm.\n  Our estimates show that the version of~$F_5$ we analyse, which uses only\nstandard Gaussian elimination techniques, outperforms row reduction of the\nMacaulay matrix with the best known algorithms for moderate degrees, and even\nfor degrees up to the thousands if Strassen's multiplication is used. The\ndegree being fixed, the factor of improvement grows exponentially with the\nnumber of variables."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-1616-6_7", 
    "link": "http://arxiv.org/pdf/1312.1780v2", 
    "title": "Special Algorithm for Stability Analysis of Multistable Biological   Regulatory Systems", 
    "arxiv-id": "1312.1780v2", 
    "author": "Bican Xia", 
    "publish": "2013-12-06T06:23:36Z", 
    "summary": "We consider the problem of counting (stable) equilibriums of an important\nfamily of algebraic differential equations modeling multistable biological\nregulatory systems. The problem can be solved, in principle, using real\nquantifier elimination algorithms, in particular real root classification\nalgorithms. However, it is well known that they can handle only very small\ncases due to the enormous computing time requirements. In this paper, we\npresent a special algorithm which is much more efficient than the general\nmethods. Its efficiency comes from the exploitation of certain interesting\nstructures of the family of differential equations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.aam.2015.01.001", 
    "link": "http://arxiv.org/pdf/1312.5029v3", 
    "title": "Hrushovski's Algorithm for Computing the Galois Group of a Linear   Differential Equation", 
    "arxiv-id": "1312.5029v3", 
    "author": "Ruyong Feng", 
    "publish": "2013-12-18T03:03:18Z", 
    "summary": "We present a detailed and simplified version of Hrushovski's algorithm that\ndetermines the Galois group of a linear differential equation. There are three\nmajor ingredients in this algorithm. The first is to look for a degree bound\nfor proto-Galois groups, which enables one to compute one of them. The second\nis to determine the identity component of the Galois group that is the pullback\nof a torus to the proto-Galois group. The third is to recover the Galois group\nfrom its identity component and a finite Galois group."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.11.002", 
    "link": "http://arxiv.org/pdf/1401.0645v3", 
    "title": "Truth Table Invariant Cylindrical Algebraic Decomposition", 
    "arxiv-id": "1401.0645v3", 
    "author": "David Wilson", 
    "publish": "2014-01-03T13:23:05Z", 
    "summary": "When using cylindrical algebraic decomposition (CAD) to solve a problem with\nrespect to a set of polynomials, it is likely not the signs of those\npolynomials that are of paramount importance but rather the truth values of\ncertain quantifier free formulae involving them. This observation motivates our\narticle and definition of a Truth Table Invariant CAD (TTICAD).\n  In ISSAC 2013 the current authors presented an algorithm that can efficiently\nand directly construct a TTICAD for a list of formulae in which each has an\nequational constraint. This was achieved by generalising McCallum's theory of\nreduced projection operators. In this paper we present an extended version of\nour theory which can be applied to an arbitrary list of formulae, achieving\nsavings if at least one has an equational constraint. We also explain how the\ntheory of reduced projection operators can allow for further improvements to\nthe lifting phase of CAD algorithms, even in the context of a single equational\nconstraint.\n  The algorithm is implemented fully in Maple and we present both promising\nresults from experimentation and a complexity analysis showing the benefits of\nour contributions."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.11.002", 
    "link": "http://arxiv.org/pdf/1401.4567v2", 
    "title": "Essentially optimal interactive certificates in linear algebra", 
    "arxiv-id": "1401.4567v2", 
    "author": "Erich Kaltofen", 
    "publish": "2014-01-18T17:08:05Z", 
    "summary": "Certificates to a linear algebra computation are additional data structures\nfor each output, which can be used by a---possibly randomized---verification\nalgorithm that proves the correctness of each output. The certificates are\nessentially optimal if the time (and space) complexity of verification is\nessentially linear in the input size $N$, meaning $N$ times a factor\n$N^{o(1)}$, i.e., a factor $N^{\\eta(N)}$ with $\\lim_{N\\to \\infty} \\eta(N)$ $=$\n$0$. We give algorithms that compute essentially optimal certificates for the\npositive semidefiniteness, Frobenius form, characteristic and minimal\npolynomial of an $n\\times n$ dense integer matrix $A$. Our certificates can be\nverified in Monte-Carlo bit complexity $(n^2 \\lognormA)^{1+o(1)}$, where\n$\\lognormA$ is the bit size of the integer entries, solving an open problem in\n[Kaltofen, Nehring, Saunders, Proc.\\ ISSAC 2011] subject to computational\nhardness assumptions. Second, we give algorithms that compute certificates for\nthe rank of sparse or structured $n\\times n$ matrices over an abstract field,\nwhose Monte Carlo verification complexity is $2$ matrix-times-vector products\n$+$ $n^{1+o(1)}$ arithmetic operations in the field. For example, if the\n$n\\times n$ input matrix is sparse with $n^{1+o(1)}$ non-zero entries, our rank\ncertificate can be verified in $n^{1+o(1)}$ field operations. This extends also\nto integer matrices with only an extra $||A||^{1+o(1)}$ factor. All our\ncertificates are based on interactive verification protocols with the\ninteraction removed by a Fiat-Shamir identification heuristic. The validity of\nour verification procedure is subject to standard computational hardness\nassumptions from cryptography."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.11.002", 
    "link": "http://arxiv.org/pdf/1401.4744v2", 
    "title": "Sparse interpolation over finite fields via low-order roots of unity", 
    "arxiv-id": "1401.4744v2", 
    "author": "Daniel S. Roche", 
    "publish": "2014-01-19T21:51:32Z", 
    "summary": "We present a new Monte Carlo algorithm for the interpolation of a\nstraight-line program as a sparse polynomial $f$ over an arbitrary finite field\nof size $q$. We assume a priori bounds $D$ and $T$ are given on the degree and\nnumber of terms of $f$. The approach presented in this paper is a hybrid of the\ndiversified and recursive interpolation algorithms, the two previous fastest\nknown probabilistic methods for this problem. By making effective use of the\ninformation contained in the coefficients themselves, this new algorithm\nimproves on the bit complexity of previous methods by a \"soft-Oh\" factor of\n$T$, $\\log D$, or $\\log q$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1401.4953v2", 
    "title": "Constructing Fewer Open Cells by GCD Computation in CAD Projection", 
    "arxiv-id": "1401.4953v2", 
    "author": "Bican Xia", 
    "publish": "2014-01-20T15:55:33Z", 
    "summary": "A new projection operator based on cylindrical algebraic decomposition (CAD)\nis proposed. The new operator computes the intersection of projection factor\nsets produced by different CAD projection orders. In other words, it computes\nthe gcd of projection polynomials in the same variables produced by different\nCAD projection orders. We prove that the new operator still guarantees\nobtaining at least one sample point from every connected component of the\nhighest dimension, and therefore, can be used for testing semi-definiteness of\npolynomials. Although the complexity of the new method is still doubly\nexponential, in many cases, the new operator does produce smaller projection\nfactor sets and fewer open cells. Some examples of testing semi-definiteness of\npolynomials, which are difficult to be solved by existing tools, have been\nworked out efficiently by our program based on the new method."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1403.4026v1", 
    "title": "A Short Note on Zero-error Computation for Algebraic Numbers by IPSLQ", 
    "arxiv-id": "1403.4026v1", 
    "author": "Wenyuan Wu", 
    "publish": "2014-03-17T08:32:59Z", 
    "summary": "The PSLQ algorithm is one of the most popular algorithm for finding\nnontrivial integer relations for several real numbers. In the present work, we\npresent an incremental version of PSLQ. For some applications needing to call\nPSLQ many times, such as finding the minimal polynomial of an algebraic number\nwithout knowing the degree, the incremental PSLQ algorithm is more efficient\nthan PSLQ, both theoretically and practically."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1403.6487v1", 
    "title": "Model-based construction of Open Non-uniform Cylindrical Algebraic   Decompositions", 
    "arxiv-id": "1403.6487v1", 
    "author": "Christopher W. Brown", 
    "publish": "2014-03-24T02:10:31Z", 
    "summary": "In this paper we introduce the notion of an Open Non-uniform Cylindrical\nAlgebraic Decomposition (NuCAD), and present an efficient model-based algorithm\nfor constructing an Open NuCAD from an input formula. A NuCAD is a\ngeneralization of Cylindrical Algebraic Decomposition (CAD) as defined by\nCollins in his seminal work from the early 1970s, and as extended in concepts\nlike Hong's partial CAD. A NuCAD, like a CAD, is a decomposition of\nn-dimensional real space into cylindrical cells. But unlike a CAD, the cells in\na NuCAD need not be arranged cylindrically. It is in this sense that NuCADs are\nnot uniformly cylindrical. However, NuCADs--- like CADs --- carry a tree-like\nstructure that relates different cells. It is a very different tree but, as\nwith the CAD tree structure, it allows some operations to be performed\nefficiently, for example locating the containing cell for an arbitrary input\npoint."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1403.6719v1", 
    "title": "Procesamiento topo-geom\u00e9trico de im\u00e1genes neuronales", 
    "arxiv-id": "1403.6719v1", 
    "author": "Miguel Morales y Julio Rubio", 
    "publish": "2014-03-26T15:45:48Z", 
    "summary": "Fruit of the relationship of our research group with the team coordinated by\nthe biologist Miguel Morales (http://spineup.es), we have applied different\ntopo-geometric techniques for neuronal image processing. The images, captured\nwith a powerful confocal microscope, allow to study the evolution of synaptic\ndensity under the influence of various substances, with the aim of studying\nneurodegenerative diseases like Alzheimer.\n  In the paper we make a brief review of the techniques that appear in our\nbioinformatic problems, including the calculation of ordinary and persistent\nhomology (for which one can use the program Kenzo for symbolic computation in\nalgebraic topology ) and classical problems of digital topology as skeleton\nlocation and path tracking. We focus on some particular cases of recent\napplication, with which we will illustrate the previous techniques."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1405.3461v1", 
    "title": "Formulating problems for real algebraic geometry", 
    "arxiv-id": "1405.3461v1", 
    "author": "Matthew England", 
    "publish": "2014-05-14T11:43:13Z", 
    "summary": "We discuss issues of problem formulation for algorithms in real algebraic\ngeometry, focussing on quantifier elimination by cylindrical algebraic\ndecomposition. We recall how the variable ordering used can have a profound\neffect on both performance and output and summarise what may be done to assist\nwith this choice. We then survey other questions of problem formulation and\nalgorithm optimisation that have become pertinent following advances in CAD\ntheory, including both work that is already published and work that is\ncurrently underway. With implementations now in reach of real world\napplications and new theory meaning algorithms are far more sensitive to the\ninput, our thesis is that intelligently formulating problems for algorithms,\nand indeed choosing the correct algorithm variant for a problem, is key to\nimproving the practical use of both quantifier elimination and symbolic real\nalgebraic geometry in general."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1405.4596v3", 
    "title": "On the Efficiency of Solving Boolean Polynomial Systems with the   Characteristic Set Method", 
    "arxiv-id": "1405.4596v3", 
    "author": "Dongdai Lin", 
    "publish": "2014-05-19T04:23:42Z", 
    "summary": "An improved characteristic set algorithm for solving Boolean polynomial\nsystems is pro- posed. This algorithm is based on the idea of converting all\nthe polynomials into monic ones by zero decomposition, and using additions to\nobtain pseudo-remainders. Three important techniques are applied in the\nalgorithm. The first one is eliminating variables by new gener- ated linear\npolynomials. The second one is optimizing the strategy of choosing polynomial\nfor zero decomposition. The third one is to compute add-remainders to eliminate\nthe leading variable of new generated monic polynomials. By analyzing the depth\nof the zero decompo- sition tree, we present some complexity bounds of this\nalgorithm, which are lower than the complexity bounds of previous\ncharacteristic set algorithms. Extensive experimental results show that this\nnew algorithm is more efficient than previous characteristic set algorithms for\nsolving Boolean polynomial systems."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1405.4779v1", 
    "title": "Una metodolog\u00eda para realizar Diferenciaci\u00f3n Autom\u00e1tica Anidada", 
    "arxiv-id": "1405.4779v1", 
    "author": "Fernando Raul Rodriguez", 
    "publish": "2014-05-19T16:01:18Z", 
    "summary": "En este trabajo se presenta una propuesta para realizar Diferenciaci\\'on\nAutom\\'atica Anidada utilizando cualquier biblioteca de Diferenciaci\\'on\nAutom\\'atica que permita sobrecarga de operadores. Para calcular las derivadas\nanidadas en una misma evaluaci\\'on de la funci\\'on, la cual se asume que sea\nanal\\'itica, se trabaja con el modo forward utilizando una nueva estructura\nllamada SuperAdouble, que garantiza que se aplique correctamente la\nDiferenciaci\\'on Autom\\'atica y se calculen el valor y la derivada que se\nrequiera.\n  This paper proposes a framework to apply Nested Automatic Differentiation\nusing any library of Automatic Differentiation which allows operator\noverloading. To compute nested derivatives of a function while it is being\nevaluated, which is assumed to be analytic, a new structure called SuperAdouble\nis used in the forward mode. This new class guarantees the correct application\nof Automatic Differentiation to calculate the value and derivative of a\nfunction where is required."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608676", 
    "link": "http://arxiv.org/pdf/1405.4925v1", 
    "title": "Cylindrical Algebraic Decomposition Using Local Projections", 
    "arxiv-id": "1405.4925v1", 
    "author": "Adam Strzebonski", 
    "publish": "2014-05-20T00:49:15Z", 
    "summary": "We present an algorithm which computes a cylindrical algebraic decomposition\nof a semialgebraic set using projection sets computed for each cell separately.\nSuch local projection sets can be significantly smaller than the global\nprojection set used by the Cylindrical Algebraic Decomposition (CAD) algorithm.\nThis leads to reduction in the number of cells the algorithm needs to\nconstruct. We give an empirical comparison of our algorithm and the classical\nCAD algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608650", 
    "link": "http://arxiv.org/pdf/1405.5341v1", 
    "title": "A fast algorithm for computing the characteristic polynomial of the   p-curvature", 
    "arxiv-id": "1405.5341v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2014-05-21T09:05:33Z", 
    "summary": "We discuss theoretical and algorithmic questions related to the $p$-curvature\nof differential operators in characteristic $p$. Given such an operator $L$,\nand denoting by $\\Chi(L)$ the characteristic polynomial of its $p$-curvature,\nwe first prove a new, alternative, description of $\\Chi(L)$. This description\nturns out to be particularly well suited to the fast computation of $\\Chi(L)$\nwhen $p$ is large: based on it, we design a new algorithm for computing\n$\\Chi(L)$, whose cost with respect to $p$ is $\\softO(p^{0.5})$ operations in\nthe ground field. This is remarkable since, prior to this work, the fastest\nalgorithms for this task, and even for the subtask of deciding nilpotency of\nthe $p$-curvature, had merely slightly subquadratic complexity\n$\\softO(p^{1.79})$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608662", 
    "link": "http://arxiv.org/pdf/1405.5342v1", 
    "title": "Computing necessary integrability conditions for planar parametrized   homogeneous potentials", 
    "arxiv-id": "1405.5342v1", 
    "author": "Safey El Din Mohab", 
    "publish": "2014-05-21T09:07:15Z", 
    "summary": "Let $V\\in\\mathbb{Q}(i)(\\a_1,\\dots,\\a_n)(\\q_1,\\q_2)$ be a rationally\nparametrized planar homogeneous potential of homogeneity degree $k\\neq -2, 0,\n2$. We design an algorithm that computes polynomial \\emph{necessary} conditions\non the parameters $(\\a_1,\\dots,\\a_n)$ such that the dynamical system associated\nto the potential $V$ is integrable. These conditions originate from those of\nthe Morales-Ramis-Sim\\'o integrability criterion near all Darboux points. The\nimplementation of the algorithm allows to treat applications that were out of\nreach before, for instance concerning the non-integrability of polynomial\npotentials up to degree $9$. Another striking application is the first complete\nproof of the non-integrability of the \\emph{collinear three body problem}."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2608628.2608662", 
    "link": "http://arxiv.org/pdf/1405.5854v1", 
    "title": "Diferenciaci\u00f3n Autom\u00e1tica Anidada. Un enfoque algebraico", 
    "arxiv-id": "1405.5854v1", 
    "author": "Juan Luis Valerdi", 
    "publish": "2014-05-22T18:49:41Z", 
    "summary": "En este trabajo se presenta una propuesta para realizar Diferenciaci\\'on\nAutom\\'atica Anidada utilizando cualquier biblioteca de Diferenciaci\\'on\nAutom\\'atica que permita sobrecarga de operadores. Para calcular las derivadas\nanidadas en una misma evaluaci\\'on de la funci\\'on, la cual se asume que sea\nanal'itica, se trabaja con el modo forward utilizando una nueva estructura\nllamada SuperAdouble, que garantiza que se aplique correctamente la\ndiferenciaci\\'on autom\\'atica y se calculen el valor y la derivada que se\nrequiera. Tambi\\'en se presenta un enfoque algebraico de la Diferenciaci\\'on\nAutom\\'atica y en particular del espacio de los SuperAdoubles.\n  This paper proposes a framework to apply Nested Automatic Differentiation\nusing any library of Automatic Differentiation which allows operator\noverloading. To compute nested derivatives of a function while it is being\nevaluated, which is assumed to be analytic, a new structure called SuperAdouble\nis used in the forward mode. This new class guarantees the correct application\nof Automatic Differentiation to calculate the value and derivative of a\nfunction where is required. Also, an Automatic Differentiation algebraic point\nof view is presented with particular emphasis in Nested Automatic\nDifferentiation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2733693.2733706", 
    "link": "http://arxiv.org/pdf/1405.6082v1", 
    "title": "A comparison of three heuristics to choose the variable ordering for CAD", 
    "arxiv-id": "1405.6082v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2014-05-23T14:50:14Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is a key tool for problems in real\nalgebraic geometry and beyond. When using CAD there is often a choice over the\nvariable ordering to use, with some problems infeasible in one ordering but\nsimple in another. Here we discuss a recent experiment comparing three\nheuristics for making this choice on thousands of examples."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-662-44199-2_69", 
    "link": "http://arxiv.org/pdf/1405.6090v1", 
    "title": "Using the Regular Chains Library to build cylindrical algebraic   decompositions by projecting and lifting", 
    "arxiv-id": "1405.6090v1", 
    "author": "James H. Davenport", 
    "publish": "2014-05-23T15:05:37Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is an important tool, both for\nquantifier elimination over the reals and a range of other applications.\nTraditionally, a CAD is built through a process of projection and lifting to\nmove the problem within Euclidean spaces of changing dimension. Recently, an\nalternative approach which first decomposes complex space using triangular\ndecomposition before refining to real space has been introduced and implemented\nwithin the RegularChains Library of Maple. We here describe a freely available\npackage ProjectionCAD which utilises the routines within the RegularChains\nLibrary to build CADs by projection and lifting. We detail how the projection\nand lifting algorithms were modified to allow this, discuss the motivation and\nsurvey the functionality of the package."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-662-44199-2_68", 
    "link": "http://arxiv.org/pdf/1405.6094v1", 
    "title": "Choosing a variable ordering for truth-table invariant cylindrical   algebraic decomposition by incremental triangular decomposition", 
    "arxiv-id": "1405.6094v1", 
    "author": "David Wilson", 
    "publish": "2014-05-23T15:18:19Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is a key tool for solving problems\nin real algebraic geometry and beyond. In recent years a new approach has been\ndeveloped, where regular chains technology is used to first build a\ndecomposition in complex space. We consider the latest variant of this which\nbuilds the complex decomposition incrementally by polynomial and produces CADs\non whose cells a sequence of formulae are truth-invariant. Like all CAD\nalgorithms the user must provide a variable ordering which can have a profound\nimpact on the tractability of a problem. We evaluate existing heuristics to\nhelp with the choice for this algorithm, suggest improvements and then derive a\nnew heuristic more closely aligned with the mechanics of the new algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-662-44199-2_68", 
    "link": "http://arxiv.org/pdf/1410.0105v1", 
    "title": "A Monomial-Oriented GVW for Computing Gr\u00f6bner Bases", 
    "arxiv-id": "1410.0105v1", 
    "author": "Dongdai Lin", 
    "publish": "2014-10-01T04:16:01Z", 
    "summary": "The GVW algorithm, presented by Gao et al., is a signature-based algorithm\nfor computing Gr\\\"obner bases. In this paper, a variant of GVW is presented.\nThis new algorithm is called a monomial-oriented GVW algorithm or mo-GVW\nalgorithm for short. The mo-GVW algorithm presents a new frame of GVW and\nregards {\\em labeled monomials} instead of {\\em labeled polynomials} as basic\nelements of the algorithm. Being different from the original GVW algorithm, for\neach labeled monomial, the mo-GVW makes efforts to find the smallest signature\nthat can generate this monomial. The mo-GVW algorithm also avoids generating\nJ-pairs, and uses efficient methods of searching reducers and checking\ncriteria. Thus, the mo-GVW algorithm has a better performance during practical\nimplementations."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-662-44199-2_68", 
    "link": "http://arxiv.org/pdf/1411.6919v1", 
    "title": "A canonical form for the continuous piecewise polynomial functions", 
    "arxiv-id": "1411.6919v1", 
    "author": "Laureano Gonzalez-Vega", 
    "publish": "2014-11-25T16:57:51Z", 
    "summary": "We present in this paper a canonical form for the elements in the ring of\ncontinuous piecewise polynomial functions. This new representation is based on\nthe use of a particular class of functions\n$$\\{C_i(P):P\\in\\Q[x],i=0,\\ldots,\\deg(P)\\}$$ defined by $$C_i(P)(x)= \\left\\{\n\\begin{array}{cll}0 & \\mbox{ if } & x \\leq \\alpha \\\\ P(x) & \\mbox{ if } & x\n\\geq \\alpha \\end{array} \\right.$$ where $\\alpha$ is the $i$-th real root of the\npolynomial $P$. These functions will allow us to represent and manipulate\neasily every continuous piecewise polynomial function through the use of the\ncorresponding canonical form.\n  It will be also shown how to produce a \"rational\" representation of each\nfunction $C_{i}(P)$ allowing its evaluation by performing only operations in\n$\\Q$ and avoiding the use of any real algebraic number."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2014.12", 
    "link": "http://arxiv.org/pdf/1412.2782v2", 
    "title": "A streamlined difference ring theory: Indefinite nested sums, the   alternating sign and the parameterized telescoping problem", 
    "arxiv-id": "1412.2782v2", 
    "author": "Carsten Schneider", 
    "publish": "2014-12-08T21:35:44Z", 
    "summary": "We present an algebraic framework to represent indefinite nested sums over\nhypergeometric expressions in difference rings. In order to accomplish this\ntask, parts of Karr's difference field theory have been extended to a ring\ntheory in which also the alternating sign can be expressed. The underlying\nmachinery relies on algorithms that compute all solutions of a given\nparameterized telescoping equation. As a consequence, we can solve the\ntelescoping and creative telescoping problem in such difference rings."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2014.12", 
    "link": "http://arxiv.org/pdf/1412.4861v1", 
    "title": "A Successive Resultant Projection for Cylindrical Algebraic   Decomposition", 
    "arxiv-id": "1412.4861v1", 
    "author": "Lu Yang", 
    "publish": "2014-12-16T02:39:44Z", 
    "summary": "This note shows the equivalence of two projection operators which both can be\nused in cylindrical algebraic decomposition (CAD) . One is known as Brown's\nProjection (C. W. Brown (2001)); the other was proposed by Lu Yang in his\nearlier work (L.Yang and S.~H. Xia (2000)) that is sketched as follows: given a\npolynomial $f$ in $x_1,\\,x_2,\\,\\cdots$, by $f_1$ denote the resultant of $f$\nand its partial derivative with respect to $x_1$ (removing the multiple\nfactors), by $f_2$ denote the resultant of $f_1$ and its partial derivative\nwith respect to $x_2$, (removing the multiple factors), $\\cdots$, repeat this\nprocedure successively until the last resultant becomes a univariate\npolynomial. Making use of an identity, the equivalence of these two projection\noperators is evident."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.06.005", 
    "link": "http://arxiv.org/pdf/1412.5071v3", 
    "title": "Probabilistic analysis of Wiedemann's algorithm for minimal polynomial   computation", 
    "arxiv-id": "1412.5071v3", 
    "author": "B. David Saunders", 
    "publish": "2014-12-16T16:41:27Z", 
    "summary": "Blackbox algorithms for linear algebra problems start with projection of the\nsequence of powers of a matrix to a sequence of vectors (Lanczos), a sequence\nof scalars (Wiedemann) or a sequence of smaller matrices (block methods). Such\nalgorithms usually depend on the minimal polynomial of the resulting sequence\nbeing that of the given matrix. Here exact formulas are given for the\nprobability that this occurs. They are based on the generalized Jordan normal\nform (direct sum of companion matrices of the elementary divisors) of the\nmatrix. Sharp bounds follow from this for matrices of unknown elementary\ndivisors. The bounds are valid for all finite field sizes and show that a small\nblocking factor can give high probability of success for all cardinalities and\nmatrix dimensions."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.12.001", 
    "link": "http://arxiv.org/pdf/1412.7547v2", 
    "title": "On the complexity of computing Gr\u00f6bner bases for weighted homogeneous   systems", 
    "arxiv-id": "1412.7547v2", 
    "author": "Thibaut Verron", 
    "publish": "2014-12-23T21:15:05Z", 
    "summary": "Solving polynomial systems arising from applications is frequently made\neasier by the structure of the systems. Weighted homogeneity (or\nquasi-homogeneity) is one example of such a structure: given a system of\nweights $W=(w\\_{1},\\dots,w\\_{n})$, $W$-homogeneous polynomials are polynomials\nwhich are homogeneous w.r.t the weighted degree\n$\\deg\\_{W}(X\\_{1}^{\\alpha\\_{1}},\\dots,X\\_{n}^{\\alpha\\_{n}}) = \\sum\nw\\_{i}\\alpha\\_{i}$. Gr\\\"obner bases for weighted homogeneous systems can be\ncomputed by adapting existing algorithms for homogeneous systems to the\nweighted homogeneous case. We show that in this case, the complexity estimate\nfor Algorithm~\\F5 $\\left(\\binom{n+\\dmax-1}{\\dmax}^{\\omega}\\right)$ can be\ndivided by a factor $\\left(\\prod w\\_{i} \\right)^{\\omega}$. For zero-dimensional\nsystems, the complexity of Algorithm~\\FGLM $nD^{\\omega}$ (where $D$ is the\nnumber of solutions of the system) can be divided by the same factor\n$\\left(\\prod w\\_{i} \\right)^{\\omega}$. Under genericity assumptions, for\nzero-dimensional weighted homogeneous systems of $W$-degree\n$(d\\_{1},\\dots,d\\_{n})$, these complexity estimates are polynomial in the\nweighted B\\'ezout bound $\\prod\\_{i=1}^{n}d\\_{i} / \\prod\\_{i=1}^{n}w\\_{i}$.\nFurthermore, the maximum degree reached in a run of Algorithm \\F5 is bounded by\nthe weighted Macaulay bound $\\sum (d\\_{i}-w\\_{i}) + w\\_{n}$, and this bound is\nsharp if we can order the weights so that $w\\_{n}=1$. For overdetermined\nsemi-regular systems, estimates from the homogeneous case can be adapted to the\nweighted case. We provide some experimental results based on systems arising\nfrom a cryptography problem and from polynomial inversion problems. They show\nthat taking advantage of the weighted homogeneous structure yields substantial\nspeed-ups, and allows us to solve systems which were otherwise out of reach."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.12.001", 
    "link": "http://arxiv.org/pdf/1502.02473v1", 
    "title": "Real root finding for rank defects in linear Hankel matrices", 
    "arxiv-id": "1502.02473v1", 
    "author": "Mohab Safey El Din", 
    "publish": "2015-02-09T13:12:40Z", 
    "summary": "Let $H\\_0, ..., H\\_n$ be $m \\times m$ matrices with entries in $\\QQ$ and\nHankel structure, i.e. constant skew diagonals. We consider the linear Hankel\nmatrix $H(\\vecx)=H\\_0+\\X\\_1H\\_1+...+\\X\\_nH\\_n$ and the problem of computing\nsample points in each connected component of the real algebraic set defined by\nthe rank constraint ${\\sf rank}(H(\\vecx))\\leq r$, for a given integer $r \\leq\nm-1$. Computing sample points in real algebraic sets defined by rank defects in\nlinear matrices is a general problem that finds applications in many areas such\nas control theory, computational geometry, optimization, etc. Moreover, Hankel\nmatrices appear in many areas of engineering sciences. Also, since Hankel\nmatrices are symmetric, any algorithmic development for this problem can be\nseen as a first step towards a dedicated exact algorithm for solving\nsemi-definite programming problems, i.e. linear matrix inequalities. Under some\ngenericity assumptions on the input (such as smoothness of an incidence\nvariety), we design a probabilistic algorithm for tackling this problem. It is\nan adaptation of the so-called critical point method that takes advantage of\nthe special structure of the problem. Its complexity reflects this: it is\nessentially quadratic in specific degree bounds on an incidence variety. We\nreport on practical experiments and analyze how the algorithm takes advantage\nof this special structure. A first implementation outperforms existing\nimplementations for computing sample points in general real algebraic sets: it\ntackles examples that are out of reach of the state-of-the-art."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1502.06152v3", 
    "title": "On Sequences, Rational Functions and Decomposition", 
    "arxiv-id": "1502.06152v3", 
    "author": "Graham H. Norton", 
    "publish": "2015-02-21T23:29:58Z", 
    "summary": "Our overall goal is to unify and extend some results in the literature\nrelated to the approximation of generating functions of finite and infinite\nsequences over a field by rational functions. In our approach, numerators play\na significant role. We revisit a theorem of Niederreiter on (i) linear\ncomplexities and (ii) '$n^{th}$ minimal polynomials' of an infinite sequence,\nproved using partial quotients. We prove (i) and its converse from first\nprinciples and generalise (ii) to rational functions where the denominator need\nnot have minimal degree. We prove (ii) in two parts: firstly for geometric\nsequences and then for sequences with a jump in linear complexity. The basic\nidea is to decompose the denominator as a sum of polynomial multiples of two\npolynomials of minimal degree; there is a similar decomposition for the\nnumerators. The decomposition is unique when the denominator has degree at most\nthe length of the sequence. The proof also applies to rational functions\nrelated to finite sequences, generalising a result of Massey. We give a number\nof applications to rational functions associated to sequences."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1502.07220v2", 
    "title": "Groebner basis in Boolean rings is not polynomial-space", 
    "arxiv-id": "1502.07220v2", 
    "author": "Mark van Hoeij", 
    "publish": "2015-02-25T16:09:01Z", 
    "summary": "We give an example where the number of elements of a Groebner basis in a\nBoolean ring is not polynomially bounded in terms of the bitsize and degrees of\nthe input."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1503.02239v1", 
    "title": "On the Computation of the Galois Group of Linear Difference Equations", 
    "arxiv-id": "1503.02239v1", 
    "author": "Ruyong Feng", 
    "publish": "2015-03-08T02:20:14Z", 
    "summary": "We present an algorithm that determines the Galois group of linear difference\nequations with rational function coefficients."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1503.04380v1", 
    "title": "A Triangular Decomposition Algorithm for Differential Polynomial Systems   with Elementary Computation Complexity", 
    "arxiv-id": "1503.04380v1", 
    "author": "Xiao-Shan Gao", 
    "publish": "2015-03-15T03:20:14Z", 
    "summary": "In this paper, a new triangular decomposition algorithm is proposed for\nordinary differential polynomial systems, which has triple exponential\ncomputational complexity. The key idea is to eliminate one algebraic variable\nfrom a set of polynomials in one step using the theory of multivariate\nresultant. This seems to be the first differential triangular decomposition\nalgorithm with elementary computation complexity."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1503.06599v1", 
    "title": "An implementation of Sub-CAD in Maple", 
    "arxiv-id": "1503.06599v1", 
    "author": "David Wilson", 
    "publish": "2015-03-23T11:21:37Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is an important tool for the\ninvestigation of semi-algebraic sets, with applications in algebraic geometry\nand beyond. We have previously reported on an implementation of CAD in Maple\nwhich offers the original projection and lifting algorithm of Collins along\nwith subsequent improvements.\n  Here we report on new functionality: specifically the ability to build\ncylindrical algebraic sub-decompositions (sub-CADs) where only certain cells\nare returned. We have implemented algorithms to return cells of a prescribed\ndimensions or higher (layered {\\scad}s), and an algorithm to return only those\ncells on which given polynomials are zero (variety {\\scad}s). These offer\nsubstantial savings in output size and computation time.\n  The code described and an introductory Maple worksheet / pdf demonstrating\nthe full functionality of the package are freely available online at\nhttp://opus.bath.ac.uk/43911/."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1503.07342v1", 
    "title": "One-Step Stochastic Processes Simulation Software Package", 
    "arxiv-id": "1503.07342v1", 
    "author": "L. A. Sevastyanov", 
    "publish": "2015-03-25T11:34:51Z", 
    "summary": "Background. It is assumed that the introduction of stochastic in mathematical\nmodel makes it more adequate. But there is virtually no methods of coordinated\n(depended on structure of the system) stochastic introduction into\ndeterministic models. Authors have improved the method of stochastic models\nconstruction for the class of one-step processes and illustrated by models of\npopulation dynamics. Population dynamics was chosen for study because its\ndeterministic models were sufficiently well explored that allows to compare the\nresults with already known ones.\n  Purpose. To optimize the models creation as much as possible some routine\noperations should be automated. In this case, the process of drawing up the\nmodel equations can be algorithmized and implemented in the computer algebra\nsystem. Furthermore, on the basis of these results a set of programs for\nnumerical experiment can be obtained.\n  Method. The computer algebra system Axiom is used for analytical calculations\nimplementation. To perform the numerical experiment FORTRAN and Julia languages\nare used. The method Runge--Kutta method for stochastic differential equations\nis used as numerical method.\n  Results. The program compex for creating stochastic one-step processes models\nis constructed. Its application is illustrated by the predator-prey population\ndynamic system.\n  Conclusions. Computer algebra systems are very convenient for the purposes of\nrapid prototyping in mathematical models design and analysis."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1504.04977v1", 
    "title": "Index reduction of differential algebraic equations by differential   algebraic elimination", 
    "arxiv-id": "1504.04977v1", 
    "author": "Peter Fritzson", 
    "publish": "2015-04-20T09:02:05Z", 
    "summary": "High index differential algebraic equations (DAEs) are ordinary differential\nequations (ODEs) with constraints and arise frequently from many mathematical\nmodels of physical phenomenons and engineering fields. In this paper, we\ngeneralize the idea of differential elimination with Dixon resultant to\npolynomially nonlinear DAEs. We propose a new algorithm for index reduction of\nDAEs and establish the notion of differential algebraic elimination, which can\nprovide the differential algebraic resultant of the enlarged system of original\nequations. To make use of structure of DAEs, variable pencil technique is given\nto determine the termination of differentiation. Moreover, we also provide a\nheuristics method for removing the extraneous factors from differential\nalgebraic resultant. The experimentation shows that the proposed algorithm\noutperforms existing ones for many examples taken from the literature."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-015-0256-5", 
    "link": "http://arxiv.org/pdf/1506.02423v1", 
    "title": "An Elimination Method to Solve Interval Polynomial Systems", 
    "arxiv-id": "1506.02423v1", 
    "author": "Benyamin M. -Alizadeh", 
    "publish": "2015-06-08T09:51:35Z", 
    "summary": "There are several efficient methods to solve linear interval polynomial\nsystems in the context of interval computations, however, the general case of\ninterval polynomial systems is not yet covered as well. In this paper we\nintroduce a new elimination method to solve and analyse interval polynomial\nsystems, in general case. This method is based on computational algebraic\ngeometry concepts such as polynomial ideals and Groebner basis computation.\nSpecially, we use the comprehensive Groebner system concept to keep the\ndependencies between interval coefficients. At the end of paper, we will state\nsome applications of our method to evaluate its performance."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756674", 
    "link": "http://arxiv.org/pdf/1506.05645v1", 
    "title": "A Fast Algorithm for Computing the p-Curvature", 
    "arxiv-id": "1506.05645v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2015-06-18T12:14:55Z", 
    "summary": "We design an algorithm for computing the $p$-curvature of a differential\nsystem in positive characteristic $p$. For a system of dimension $r$ with\ncoefficients of degree at most $d$, its complexity is $\\softO (p d r^\\omega)$\noperations in the ground field (where $\\omega$ denotes the exponent of matrix\nmultiplication), whereas the size of the output is about $p d r^2$. Our\nalgorithm is then quasi-optimal assuming that matrix multiplication is\n(\\emph{i.e.} $\\omega = 2$). The main theoretical input we are using is the\nexistence of a well-suited ring of series with divided powers for which an\nanalogue of the Cauchy--Lipschitz Theorem holds."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756674", 
    "link": "http://arxiv.org/pdf/1507.03217v1", 
    "title": "An algorithm for computing Grobner basis and the complexity evaluation", 
    "arxiv-id": "1507.03217v1", 
    "author": "Chong-Il Byon", 
    "publish": "2015-07-12T11:12:42Z", 
    "summary": "In this paper, we suggest a new efficient algorithm in order to compute\nS-polynomial reduction rapidly in the known algorithm for computing Grobner\nbases, and compare the complexity with others."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756674", 
    "link": "http://arxiv.org/pdf/1507.03834v2", 
    "title": "Open Weak CAD and Its Applications", 
    "arxiv-id": "1507.03834v2", 
    "author": "Bican Xia", 
    "publish": "2015-07-14T13:08:14Z", 
    "summary": "The concept of open weak CAD is introduced. Every open CAD is an open weak\nCAD. On the contrary, an open weak CAD is not necessarily an open CAD. An\nalgorithm for computing open weak CADs is proposed. The key idea is to compute\nthe intersection of projection factor sets produced by different projection\norders. The resulting open weak CAD often has smaller number of sample points\nthan open CADs.\n  The algorithm can be used for computing sample points for all open connected\ncomponents of $ f\\ne 0$ for a given polynomial $f$. It can also be used for\nmany other applications, such as testing semi-definiteness of polynomials and\ncopositive problems. In fact, we solved several difficult semi-definiteness\nproblems efficiently by using the algorithm. Furthermore, applying the\nalgorithm to copositive problems, we find an explicit expression of the\npolynomials producing open weak CADs under some conditions, which significantly\nimproves the efficiency of solving copositive problems."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756660", 
    "link": "http://arxiv.org/pdf/1507.04203v1", 
    "title": "Formulas for Continued Fractions. An Automated Guess and Prove Approach", 
    "arxiv-id": "1507.04203v1", 
    "author": "Bruno Salvy", 
    "publish": "2015-07-15T13:12:23Z", 
    "summary": "We describe a simple method that produces automatically closed forms for the\ncoefficients of continued fractions expansions of a large number of special\nfunctions. The function is specified by a non-linear differential equation and\ninitial conditions. This is used to generate the first few coefficients and\nfrom there a conjectured formula. This formula is then proved automatically\nthanks to a linear recurrence satisfied by some remainder terms. Extensive\nexperiments show that this simple approach and its straightforward\ngeneralization to difference and $q$-difference equations capture a large part\nof the formulas in the literature on continued fractions."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756660", 
    "link": "http://arxiv.org/pdf/1508.06724v1", 
    "title": "Algebraic Local Cohomology with Parameters and Parametric Standard Bases   for Zero-Dimensional Ideals", 
    "arxiv-id": "1508.06724v1", 
    "author": "Shinichi Tajima", 
    "publish": "2015-08-27T05:31:14Z", 
    "summary": "A computation method of algebraic local cohomology with parameters,\nassociated with zero-dimensional ideal with parameter, is introduced. This\ncomputation method gives us in particular a decomposition of the parameter\nspace depending on the structure of algebraic local cohomology classes. This\ndecomposition informs us several properties of input ideals and the output of\nour algorithm completely describes the multiplicity structure of input ideals.\nAn efficient algorithm for computing a parametric standard basis of a given\nzero-dimensional ideal, with respect to an arbitrary local term order, is also\ndescribed as an application of the computation method. The algorithm can always\noutput \"reduced\" standard basis of a given zero-dimensional ideal, even if the\nzero-dimensional ideal has parameters."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756663", 
    "link": "http://arxiv.org/pdf/1510.04080v1", 
    "title": "Algebraic Diagonals and Walks", 
    "arxiv-id": "1510.04080v1", 
    "author": "Bruno Salvy", 
    "publish": "2015-10-14T13:20:38Z", 
    "summary": "The diagonal of a multivariate power series F is the univariate power series\nDiag(F) generated by the diagonal terms of F. Diagonals form an important class\nof power series; they occur frequently in number theory, theoretical physics\nand enumerative combinatorics. We study algorithmic questions related to\ndiagonals in the case where F is the Taylor expansion of a bivariate rational\nfunction. It is classical that in this case Diag(F) is an algebraic function.\nWe propose an algorithm that computes an annihilating polynomial for Diag(F).\nGenerically, it is its minimal polynomial and is obtained in time quasi-linear\nin its size. We show that this minimal polynomial has an exponential size with\nrespect to the degree of the input rational function. We then address the\nrelated problem of enumerating directed lattice walks. The insight given by our\nstudy leads to a new method for expanding the generating power series of\nbridges, excursions and meanders. We show that their first N terms can be\ncomputed in quasi-linear complexity in N, without first computing a very large\npolynomial equation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756663", 
    "link": "http://arxiv.org/pdf/1510.04526v1", 
    "title": "Algebraic Diagonals and Walks: Algorithms, Bounds, Complexity", 
    "arxiv-id": "1510.04526v1", 
    "author": "Bruno Salvy", 
    "publish": "2015-10-15T13:34:08Z", 
    "summary": "The diagonal of a multivariate power series F is the univariate power series\nDiag(F) generated by the diagonal terms of F. Diagonals form an important class\nof power series; they occur frequently in number theory, theoretical physics\nand enumerative combinatorics. We study algorithmic questions related to\ndiagonals in the case where F is the Taylor expansion of a bivariate rational\nfunction. It is classical that in this case Diag(F) is an algebraic function.\nWe propose an algorithm that computes an annihilating polynomial for Diag(F).\nWe give a precise bound on the size of this polynomial and show that\ngenerically, this polynomial is the minimal polynomial and that its size\nreaches the bound. The algorithm runs in time quasi-linear in this bound, which\ngrows exponentially with the degree of the input rational function. We then\naddress the related problem of enumerating directed lattice walks. The insight\ngiven by our study leads to a new method for expanding the generating power\nseries of bridges, excursions and meanders. We show that their first N terms\ncan be computed in quasi-linear complexity in N, without first computing a very\nlarge polynomial equation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756663", 
    "link": "http://arxiv.org/pdf/1511.00180v3", 
    "title": "Formal Solutions of Completely Integrable Pfaffian Systems With Normal   Crossings", 
    "arxiv-id": "1511.00180v3", 
    "author": "Suzy S. Maddah", 
    "publish": "2015-10-31T21:34:58Z", 
    "summary": "In this paper, we present an algorithm for computing a fundamental matrix of\nformal solutions of completely integrable Pfaffian systems with normal\ncrossings in several variables. This algorithm is a generalization of a method\ndeveloped for the bivariate case based on a combination of several reduction\ntechniques and is implemented in the computer algebra system Maple."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1511.01128v1", 
    "title": "Improved Polynomial Remainder Sequences for Ore Polynomials", 
    "arxiv-id": "1511.01128v1", 
    "author": "Maximilian Jaroschek", 
    "publish": "2015-11-03T21:47:11Z", 
    "summary": "Polynomial remainder sequences contain the intermediate results of the\nEuclidean algorithm when applied to (non-)commutative polynomials. The running\ntime of the algorithm is dependent on the size of the coefficients of the\nremainders. Different ways have been studied to make these as small as\npossible. The subresultant sequence of two polynomials is a polynomial\nremainder sequence in which the size of the coefficients is optimal in the\ngeneric case, but when taking the input from applications, the coefficients are\noften larger than necessary. We generalize two improvements of the subresultant\nsequence to Ore polynomials and derive a new bound for the minimal coefficient\nsize. Our approach also yields a new proof for the results in the commutative\ncase, providing a new point of view on the origin of the extraneous factors of\nthe coefficients."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1511.06436v1", 
    "title": "On the robust hardness of Gr\u00f6bner basis computation", 
    "arxiv-id": "1511.06436v1", 
    "author": "David Rolnick", 
    "publish": "2015-11-19T22:54:21Z", 
    "summary": "We introduce a new problem in the approximate computation of Gr\\\"{o}bner\nbases that allows the algorithm to ignore a constant fraction of the generators\n- of the algorithm's choice - then compute a Gr\\\"{o}bner basis for the\nremaining polynomial system. The set ignored is subject to one quite-natural\nstructural constraint. For lexicographic orders, when the discarded fraction is\nless than $(1/4-\\epsilon)$, for $\\epsilon>0$, we prove that this problem cannot\nbe solved in polynomial time, even when the original polynomial system has\nmaximum degree 3 and each polynomial contains at most 3 variables.\nQualitatively, even for sparse systems composed of low-degree polynomials, we\nshow that Gr\\\"{o}bner basis computation is robustly hard: even producing a\nGr\\\"{o}bner basis for a large subset of the generators is NP-hard."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1511.07922v8", 
    "title": "Contraction of Ore Ideals with Applications", 
    "arxiv-id": "1511.07922v8", 
    "author": "Yi Zhang", 
    "publish": "2015-11-25T00:15:50Z", 
    "summary": "Ore operators form a common algebraic abstraction of linear ordinary\ndifferential and recurrence equations. Given an Ore operator $L$ with\npolynomial coefficients in $x$, it generates a left ideal $I$ in the Ore\nalgebra over the field $\\mathbf{k}(x)$ of rational functions. We present an\nalgorithm for computing a basis of the contraction ideal of $I$ in the Ore\nalgebra over the ring $R[x]$ of polynomials, where $R$ may be either\n$\\mathbf{k}$ or a domain with $\\mathbf{k}$ as its fraction field. This\nalgorithm is based on recent work on desingularization for Ore operators by\nChen, Jaroschek, Kauers and Singer. Using a basis of the contraction ideal, we\ncompute a completely desingularized operator for $L$ whose leading coefficient\nnot only has minimal degree in $x$ but also has minimal content. Completely\ndesingularized operators have interesting applications such as certifying\ninteger sequences and checking special cases of a conjecture of Krattenthaler."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1512.03901v2", 
    "title": "A Probabilistic Algorithm for Computing Data-Discriminants of Likelihood   Equations", 
    "arxiv-id": "1512.03901v2", 
    "author": "Xiaoxian Tang", 
    "publish": "2015-12-12T10:48:58Z", 
    "summary": "An algebraic approach to the maximum likelihood estimation problem is to\nsolve a very structured parameterized polynomial system called likelihood\nequations that have finitely many complex (real or non-real) solutions. The\nonly solutions that are statistically meaningful are the real solutions with\npositive coordinates. In order to classify the parameters (data) according to\nthe number of real/positive solutions, we study how to efficiently compute the\ndiscriminants, say data-discriminants (DD), of the likelihood equations. We\ndevelop a probabilistic algorithm with three different strategies for computing\nDDs. Our implemented probabilistic algorithm based on Maple and FGb is more\nefficient than our previous version presented in ISSAC2015, and is also more\nefficient than the standard elimination for larger benchmarks. By applying\nRAGlib to a DD we compute, we give the real root classification of 3 by 3\nsymmetric matrix model."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1512.07766v1", 
    "title": "Computing Chebyshev knot diagrams", 
    "arxiv-id": "1512.07766v1", 
    "author": "C Tran", 
    "publish": "2015-12-24T09:23:25Z", 
    "summary": "A Chebyshev curve $\\cC(a,b,c,\\phi)$ has a parametrization of the form$\nx(t)=T\\_a(t)$; \\ $y(t)=T\\_b(t)$; $z(t)= T\\_c(t + \\phi)$, where $a,b,c$are\nintegers, $T\\_n(t)$ is the Chebyshev polynomialof degree $n$ and $\\phi \\in\n\\RR$. When $\\cC(a,b,c,\\phi)$ is nonsingular,it defines a polynomial knot. We\ndetermine all possible knot diagrams when $\\phi$ varies. Let $a,b,c$ be\nintegers, $a$ is odd, $(a,b)=1$, we show that one can list all possible knots\n$\\cC(a,b,c,\\phi)$ in$\\tcO(n^2)$ bit operations, with $n=abc$."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1601.01038v1", 
    "title": "A Modular Algorithm for Computing Polynomial GCDs over Number Fields   presented with Multiple Extensions", 
    "arxiv-id": "1601.01038v1", 
    "author": "Michael Monagan", 
    "publish": "2016-01-06T01:03:52Z", 
    "summary": "We consider the problem of computing the monic gcd of two polynomials over a\nnumber field L = Q(alpha_1,...,alpha_n). Langemyr and McCallum have already\nshown how Brown's modular GCD algorithm for polynomials over Q can be modified\nto work for Q(alpha) and subsequently, Langemyr extended the algorithm to L[x].\nEncarnacion also showed how to use rational number to make the algorithm for\nQ(alpha) output sensitive, that is, the number of primes used depends on the\nsize of the integers in the gcd and not on bounds based on the input\npolynomials.\n  Our first contribution is an extension of Encarnacion's modular GCD algorithm\nto the case n>1, which, like Encarnacion's algorithm, is is output sensitive.\n  Our second contribution is a proof that it is not necessary to test if p\ndivides the discriminant. This simplifies the algorithm; it is correct without\nthis test.\n  Our third contribution is a modification to the algorithm to treat the case\nof reducible extensions. Such cases arise when solving systems of polynomial\nequations.\n  Our fourth contribution is an implementation of the modular GCD algorithm in\nMaple and in Magma. Both implementations use a recursive dense polynomial data\nstructure for representing polynomials over number fields with multiple field\nextensions.\n  Our fifth contribution is a primitive fraction-free algorithm. This is the\nbest non-modular approach. We present timing comparisons of the Maple and Magma\nimplementations demonstrating various optimizations and comparing them with the\nmonic Euclidan algorithm and our primitive fraction-free algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1601.01274v1", 
    "title": "Encoding and Decoding Algorithms for Arbitrary Dimensional Hilbert Order", 
    "arxiv-id": "1601.01274v1", 
    "author": "Linbo Zhang", 
    "publish": "2016-01-06T18:53:04Z", 
    "summary": "Hilbert order is widely applied in many areas. However, most of the\nalgorithms are confined to low dimensional cases. In this paper, algorithms for\nencoding and decoding arbitrary dimensional Hilbert order are presented. Eight\nalgorithms are proposed. Four algorithms are based on arithmetic operations and\nthe other four algorithms are based on bit operations. For the algorithms\ncomplexities, four of them are linear and the other four are constant for given\ninputs. In the end of the paper, algorithms for two dimensional Hilbert order\nare presented to demonstrate the usage of the algorithms introduced."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1601.01798v1", 
    "title": "Fast Computation of the Rank Profile Matrix and the Generalized Bruhat   Decomposition", 
    "arxiv-id": "1601.01798v1", 
    "author": "Ziad Sultan", 
    "publish": "2016-01-08T09:04:59Z", 
    "summary": "The row (resp. column) rank profile of a matrix describes the stair-case\nshape of its row (resp. column) echelon form.We here propose a new matrix\ninvariant, the rank profile matrix, summarizing all information on the row\nandcolumn rank profiles of all the leading sub-matrices.We show that this\nnormal form exists and is unique over any ring, provided that the notion of\nMcCoy's rank is used, in the presence of zero divisors.We then explore the\nconditions for a Gaussian elimination algorithm to compute all or part of this\ninvariant,through the corresponding PLUQ decomposition. This enlarges the set\nof known Elimination variants that compute row or column rank profiles.As a\nconsequence a new Crout base case variant significantly improves the practical\nefficiency of previously known implementations over a finite field.With\nmatrices of very small rank, we also generalize the techniques ofStorjohann and\nYang to the computation of the rank profile matrix, achieving an\n$(r^\\omega+mn)^{1+o(1)}$ time complexity for an $m \\times n$ matrix of rank\n$r$, where $\\omega$ is the exponent of matrix multiplication. Finally, by give\nconnections to the Bruhat decomposition, and severalof its variants and\ngeneralizations. Thus, our algorithmicimprovements for the PLUQ factorization,\nand their implementations,directly apply to these decompositions.In particular,\nwe show how a PLUQ decomposition revealing the rankprofile matrix also reveals\nboth a row and a column echelon form ofthe input matrix or of any of its\nleading sub-matrices, by a simplepost-processing made of row and column\npermutations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.05.012", 
    "link": "http://arxiv.org/pdf/1601.02756v1", 
    "title": "Factorization of C-finite Sequences", 
    "arxiv-id": "1601.02756v1", 
    "author": "Doron Zeilberger", 
    "publish": "2016-01-12T07:45:00Z", 
    "summary": "We discuss how to decide whether a given C-finite sequence can be written\nnontrivially as a product of two other C-finite sequences."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930912", 
    "link": "http://arxiv.org/pdf/1602.00244v2", 
    "title": "On p-adic differential equations with separation of variables", 
    "arxiv-id": "1602.00244v2", 
    "author": "Tristan Vaccon", 
    "publish": "2016-01-31T13:26:48Z", 
    "summary": "Several algorithms in computer algebra involve the computation of a power\nseries solution of a given ordinary differential equation. Over finite fields,\nthe problem is often lifted in an approximate $p$-adic setting to be\nwell-posed. This raises precision concerns: how much precision do we need on\nthe input to compute the output accurately? In the case of ordinary\ndifferential equations with separation of variables, we make use of the recent\ntechnique of differential precision to obtain optimal bounds on the stability\nof the Newton iteration. The results apply, for example, to algorithms for\nmanipulating algebraic numbers over finite fields, for computing isogenies\nbetween elliptic curves or for deterministically finding roots of polynomials\nin finite fields. The new bounds lead to significant speedups in practice."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930912", 
    "link": "http://arxiv.org/pdf/1602.00424v1", 
    "title": "Reduction-Based Creative Telescoping for Algebraic Functions", 
    "arxiv-id": "1602.00424v1", 
    "author": "Christoph Koutschan", 
    "publish": "2016-02-01T08:19:40Z", 
    "summary": "Continuing a series of articles in the past few years on creative telescoping\nusing reductions, we develop a new algorithm to construct minimal telescopers\nfor algebraic functions. This algorithm is based on Trager's Hermite reduction\nand on polynomial reduction, which was originally designed for hyperexponential\nfunctions and extended to the algebraic case in this paper."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930928", 
    "link": "http://arxiv.org/pdf/1602.00651v2", 
    "title": "Fast Computation of Minimal Interpolation Bases in Popov Form for   Arbitrary Shifts", 
    "arxiv-id": "1602.00651v2", 
    "author": "Gilles Villard", 
    "publish": "2016-02-01T19:32:34Z", 
    "summary": "We compute minimal bases of solutions for a general interpolation problem,\nwhich encompasses Hermite-Pad\\'e approximation and constrained multivariate\ninterpolation, and has applications in coding theory and security.\n  This problem asks to find univariate polynomial relations between $m$ vectors\nof size $\\sigma$; these relations should have small degree with respect to an\ninput degree shift. For an arbitrary shift, we propose an algorithm for the\ncomputation of an interpolation basis in shifted Popov normal form with a cost\nof $\\mathcal{O}\\tilde{~}(m^{\\omega-1} \\sigma)$ field operations, where $\\omega$\nis the exponent of matrix multiplication and the notation\n$\\mathcal{O}\\tilde{~}(\\cdot)$ indicates that logarithmic terms are omitted.\n  Earlier works, in the case of Hermite-Pad\\'e approximation and in the general\ninterpolation case, compute non-normalized bases. Since for arbitrary shifts\nsuch bases may have size $\\Theta(m^2 \\sigma)$, the cost bound\n$\\mathcal{O}\\tilde{~}(m^{\\omega-1} \\sigma)$ was feasible only with restrictive\nassumptions on the shift that ensure small output sizes. The question of\nhandling arbitrary shifts with the same complexity bound was left open.\n  To obtain the target cost for any shift, we strengthen the properties of the\noutput bases, and of those obtained during the course of the algorithm: all the\nbases are computed in shifted Popov form, whose size is always $\\mathcal{O}(m\n\\sigma)$. Then, we design a divide-and-conquer scheme. We recursively reduce\nthe initial interpolation problem to sub-problems with more convenient shifts\nby first computing information on the degrees of the intermediate bases."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930936", 
    "link": "http://arxiv.org/pdf/1602.00710v2", 
    "title": "Fast Computation of Shifted Popov Forms of Polynomial Matrices via   Systems of Modular Polynomial Equations", 
    "arxiv-id": "1602.00710v2", 
    "author": "Vincent Neiger", 
    "publish": "2016-02-01T21:10:31Z", 
    "summary": "We give a Las Vegas algorithm which computes the shifted Popov form of an $m\n\\times m$ nonsingular polynomial matrix of degree $d$ in expected\n$\\widetilde{\\mathcal{O}}(m^\\omega d)$ field operations, where $\\omega$ is the\nexponent of matrix multiplication and $\\widetilde{\\mathcal{O}}(\\cdot)$\nindicates that logarithmic factors are omitted. This is the first algorithm in\n$\\widetilde{\\mathcal{O}}(m^\\omega d)$ for shifted row reduction with arbitrary\nshifts.\n  Using partial linearization, we reduce the problem to the case $d \\le \\lceil\n\\sigma/m \\rceil$ where $\\sigma$ is the generic determinant bound, with $\\sigma\n/ m$ bounded from above by both the average row degree and the average column\ndegree of the matrix. The cost above becomes $\\widetilde{\\mathcal{O}}(m^\\omega\n\\lceil \\sigma/m \\rceil)$, improving upon the cost of the fastest previously\nknown algorithm for row reduction, which is deterministic.\n  Our algorithm first builds a system of modular equations whose solution set\nis the row space of the input matrix, and then finds the basis in shifted Popov\nform of this set. We give a deterministic algorithm for this second step\nsupporting arbitrary moduli in $\\widetilde{\\mathcal{O}}(m^{\\omega-1} \\sigma)$\nfield operations, where $m$ is the number of unknowns and $\\sigma$ is the sum\nof the degrees of the moduli. This extends previous results with the same cost\nbound in the specific cases of order basis computation and M-Pad\\'e\napproximation, in which the moduli are products of known linear factors."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930936", 
    "link": "http://arxiv.org/pdf/1602.00810v1", 
    "title": "Linear Time Interactive Certificates for the Minimal Polynomial and the   Determinant of a Sparse Matrix", 
    "arxiv-id": "1602.00810v1", 
    "author": "Gilles Villard", 
    "publish": "2016-02-02T07:29:28Z", 
    "summary": "Certificates to a linear algebra computation are additional data structures\nfor each output, which can be used by a-possibly randomized- verification\nalgorithm that proves the correctness of each output. In this paper, we give an\nalgorithm that compute a certificate for the minimal polynomial of sparse or\nstructured n x n matrices over an abstract field, of sufficiently large\ncardinality, whose Monte Carlo verification complexity requires a single\nmatrix-vector multiplication and a linear number of extra field operations. We\nalso propose a novel preconditioner that ensures irreducibility of the\ncharacteristic polynomial of the preconditioned matrix. This preconditioner\ntakes linear time to be applied and uses only two random entries. We then\ncombine these two techniques to give algorithms that compute certificates for\nthe determinant, and thus for the characteristic polynomial, whose Monte Carlo\nverification complexity is therefore also linear."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930933", 
    "link": "http://arxiv.org/pdf/1602.00836v2", 
    "title": "Algorithms for Simultaneous Pad\u00e9 Approximations", 
    "arxiv-id": "1602.00836v2", 
    "author": "Arne Storjohann", 
    "publish": "2016-02-02T09:06:58Z", 
    "summary": "We describe how to solve simultaneous Pad\\'e approximations over a power\nseries ring $K[[x]]$ for a field $K$ using $O~(n^{\\omega - 1} d)$ operations in\n$K$, where $d$ is the sought precision and $n$ is the number of power series to\napproximate. We develop two algorithms using different approaches. Both\nalgorithms return a reduced sub-bases that generates the complete set of\nsolutions to the input approximations problem that satisfy the given degree\nconstraints. Our results are made possible by recent breakthroughs in fast\ncomputations of minimal approximant bases and Hermite Pad\\'e approximations."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1602.01246v2", 
    "title": "Computing with quasiseparable matrices", 
    "arxiv-id": "1602.01246v2", 
    "author": "Clement Pernet", 
    "publish": "2016-02-03T10:11:19Z", 
    "summary": "The class of quasiseparable matrices is defined by a pair of bounds, called\nthe quasiseparable orders, on the ranks of the maximal sub-matrices entirely\nlocated in their strictly lower and upper triangular parts. These arise\nnaturally in applications, as e.g. the inverse of band matrices, and are widely\nused for they admit structured representations allowing to compute with them in\ntime linear in the dimension and quadratic with the quasiseparable order. We\nshow, in this paper, the connection between the notion of quasisepa-rability\nand the rank profile matrix invariant, presented in [Dumas \\& al. ISSAC'15].\nThis allows us to propose an algorithm computing the quasiseparable orders (rL,\nrU) in time O(n^2 s^($\\omega$--2)) where s = max(rL, rU) and $\\omega$ the\nexponent of matrix multiplication. We then present two new structured\nrepresentations, a binary tree of PLUQ decompositions, and the Bruhat\ngenerator, using respectively O(ns log n/s) and O(ns) field elements instead of\nO(ns^2) for the previously known generators. We present algorithms computing\nthese representations in time O(n^2 s^($\\omega$--2)). These representations\nallow a matrix-vector product in time linear in the size of their\nrepresentation. Lastly we show how to multiply two such structured matrices in\ntime O(n^2 s^($\\omega$--2))."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1602.02049v1", 
    "title": "A fast, deterministic algorithm for computing a Hermite Normal Form of a   polynomial matrix", 
    "arxiv-id": "1602.02049v1", 
    "author": "Wei Zhou", 
    "publish": "2016-02-05T14:59:34Z", 
    "summary": "Given a square, nonsingular matrix of univariate polynomials $\\mathbf{F} \\in\n\\mathbb{K}[x]^{n \\times n}$ over a field $\\mathbb{K}$, we give a fast,\ndeterministic algorithm for finding the Hermite normal form of $\\mathbf{F}$\nwith complexity $O^{\\sim}\\left(n^{\\omega}d\\right)$ where $d$ is the degree of\n$\\mathbf{F}$. Here soft-$O$ notation is Big-$O$ with log factors removed and\n$\\omega$ is the exponent of matrix multiplication. The method relies of a fast\nalgorithm for determining the diagonal entries of its Hermite normal form,\nhaving as cost $O^{\\sim}\\left(n^{\\omega}s\\right)$ operations with $s$ the\naverage of the column degrees of $\\mathbf{F}$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1602.04300v3", 
    "title": "On Gr\u00f6bner Bases and Krull Dimension of Residue Class Rings of   Polynomial Rings over Integral Domains using Gr\u00f6bner Bases", 
    "arxiv-id": "1602.04300v3", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2016-02-13T08:11:02Z", 
    "summary": "Given an ideal $\\mathfrak{a}$ in $A[x_1, \\ldots, x_n]$, where $A$ is a\nNoetherian integral domain, we propose an approach to compute the Krull\ndimension of $A[x_1,\\ldots,x_n]/\\mathfrak{a}$, when the residue class\npolynomial ring is a free $A$-module. When $A$ is a field, the Krull dimension\nof $A[x_1,\\ldots,x_n]/\\mathfrak{a}$ has several equivalent algorithmic\ndefinitions by which it can be computed. But this is not true in the case of\narbitrary Noetherian rings. For a Noetherian integral domain, $A$ we introduce\nthe notion of combinatorial dimension of $A[x_1, \\ldots,x_n]/\\mathfrak{a}$ and\ngive a Gr\\\"obner basis method to compute it for residue class polynomial rings\nthat have a free $A$-module representation w.r.t. a lexicographic ordering. For\nsuch $A$-algebras, we derive a relation between Krull dimension and\ncombinatorial dimension of $A[x_1, \\ldots, x_n]/\\mathfrak{a}$. An immediate\napplication of this relation is that it gives a uniform method, the first of\nits kind, to compute the dimension of $A[x_1, \\ldots, x_n]/\\mathfrak{a}$\nwithout having to consider individual properties of the ideal. For $A$-algebras\nthat have a free $A$-module representation w.r.t. degree compatible monomial\norderings, we introduce the concepts of Hilbert function, Hilbert series and\nHilbert polynomials and show that Gr\\\"obner basis methods can be used to\ncompute these quantities. We then proceed to show that the combinatorial\ndimension of such $A$-algebras is equal to the degree of the Hilbert\npolynomial. This enables us to extend the relation between Krull dimension and\ncombinatorial dimension to $A$-algebras with a free $A$-module representation\nw.r.t. a degree compatible ordering as well."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1602.04562v2", 
    "title": "An Illustrated Introduction to the Truncated Fourier Transform", 
    "arxiv-id": "1602.04562v2", 
    "author": "Paul Vrbik", 
    "publish": "2016-02-15T05:24:41Z", 
    "summary": "The Truncated Fourier Transform (TFT) is a variation of the Discrete Fourier\nTransform (DFT/FFT) that allows for input vectors that do NOT have length $2^n$\nfor $n$ a positive integer. We present the univariate version of the TFT,\noriginally due to Joris van der Hoeven, heavily illustrating the presentation\nin order to make these methods accessible to a broader audience."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1602.06097v1", 
    "title": "GBLA -- Gr\u00f6bner Basis Linear Algebra Package", 
    "arxiv-id": "1602.06097v1", 
    "author": "Fayssal Martani", 
    "publish": "2016-02-19T10:07:00Z", 
    "summary": "This is a system paper about a new GPLv2 open source C library GBLA\nimplementing and improving the idea of Faug\\`ere and Lachartre (GB reduction).\nWe further exploit underlying structures in matrices generated during Gr\\\"obner\nbasis computations in algorithms like F4 or F5 taking advantage of block\npatterns by using a special data structure called multilines. Moreover, we\ndiscuss a new order of operations for the reduction process. In various\ndifferent experimental results we show that GBLA performs better than GB\nreduction or Magma in sequential computations (up to 40% faster) and scales\nmuch better than GB reduction for a higher number of cores: On 32 cores we\nreach a scaling of up to 26. GBLA is up to 7 times faster than GB reduction.\nFurther, we compare different parallel schedulers GBLA can be used with. We\nalso developed a new advanced storage format that exploits the fact that our\nmatrices are coming from Gr\\\"obner basis computations, shrinking storage by a\nfactor of up to 4. A huge database of our matrices is freely available with\nGBLA."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1603.01338v1", 
    "title": "Finding best possible constant for a polynomial inequality", 
    "arxiv-id": "1603.01338v1", 
    "author": "Ju Zhang", 
    "publish": "2016-03-04T03:23:49Z", 
    "summary": "Given a multi-variant polynomial inequality with a parameter, how to find the\nbest possible value of this parameter that satisfies the inequality? For\ninstance, find the greatest number $k$ that satisfies $ a^3+b^3+c^3+\nk(a^2b+b^2c+c^2a)-(k+1)(ab^2+bc^2+ca^2)\\geq 0 $ for all nonnegative real\nnumbers $ a,b,c $. Analogues problems often appeared in studies of inequalities\nand were dealt with by various methods. In this paper, a general algorithm is\nproposed for finding the required best possible constant. The algorithm can be\neasily implemented by computer algebra tools such as Maple."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1603.03565v1", 
    "title": "Matrix factoring by fraction-free reduction", 
    "arxiv-id": "1603.03565v1", 
    "author": "David J. Jeffrey", 
    "publish": "2016-03-11T08:46:30Z", 
    "summary": "We consider exact matrix decomposition by Gauss-Bareiss reduction. We\ninvestigate two aspects of the process: common row and column factors and the\ninfluence of pivoting strategies. We identify two types of common factors:\nsystematic and statistical. Systematic factors depend on the process, while\nstatistical factors depend on the specific data. We show that existing\nfraction-free QR (Gram-Schmidt) algorithms create a common factor in the last\ncolumn of Q. We relate the existence of row factors in LU decomposition to\nfactors appearing in the Smith normal form of the matrix. For statistical\nfactors, we identify mechanisms and give estimates of the frequency. Our\nconclusions are tested by experimental data. For pivoting strategies, we\ncompare the sizes of output factors obtained by different strategies. We also\ncomment on timing differences."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1603.04285v2", 
    "title": "Summation Theory II: Characterizations of   $\\boldsymbol{R\u03a0\u03a3^*}$-extensions and algorithmic aspects", 
    "arxiv-id": "1603.04285v2", 
    "author": "Carsten Schneider", 
    "publish": "2016-03-14T14:48:09Z", 
    "summary": "Recently, $R\\Pi\\Sigma^*$-extensions have been introduced which extend Karr's\n$\\Pi\\Sigma^*$-fields substantially: one can represent expressions not only in\nterms of transcendental sums and products, but one can work also with products\nover primitive roots of unity. Since one can solve the parameterized\ntelescoping problem in such rings, covering as special cases the summation\nparadigms of telescoping and creative telescoping, one obtains a rather\nflexible toolbox for symbolic summation. This article is the continuation of\nthis work. Inspired by Singer's Galois theory of difference equations we will\nwork out several alternative characterizations of $R\\Pi\\Sigma^*$-extensions:\nadjoining naively sums and products leads to an $R\\Pi\\Sigma^*$-extension iff\nthe obtained difference ring is simple iff the ring can be embedded into the\nring of sequences iff the ring can be given by the interlacing of\n$\\Pi\\Sigma^*$-extensions. From the viewpoint of applications this leads to a\nfully automatic machinery to represent indefinite nested sums and products in\nsuch $R\\Pi\\Sigma^*$-rings. In addition, we work out how the parameterized\ntelescoping paradigm can be used to prove algebraic independence of indefinite\nnested sums. Furthermore, one obtains an alternative reduction tactic to solve\nthe parameterized telescoping problem in basic $R\\Pi\\Sigma^*$-extensions\nexploiting the interlacing property."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930915", 
    "link": "http://arxiv.org/pdf/1603.08752v1", 
    "title": "Solution of Interpolation Problems via the Hankel Polynomial   Construction", 
    "arxiv-id": "1603.08752v1", 
    "author": "Ivan Baravy", 
    "publish": "2016-03-29T13:02:01Z", 
    "summary": "We treat the interpolation problem $ \\{f(x_j)=y_j\\}_{j=1}^N $ for polynomial\nand rational functions. Developing the approach by C.Jacobi, we represent the\ninterpolants by virtue of the Hankel polynomials generated by the sequences $\n\\{\\sum_{j=1}^N x_j^ky_j/W^{\\prime}(x_j) \\}_{k\\in \\mathbb N} $ and $\n\\{\\sum_{j=1}^N x_j^k/(y_jW^{\\prime}(x_j)) \\}_{k\\in \\mathbb N} $; here $\nW(x)=\\prod_{j=1}^N(x-x_j) $. The obtained results are applied for the error\ncorrection problem, i.e. the problem of reconstructing the polynomial from a\nredundant set of its values some of which are probably erroneous. The problem\nof evaluation of the resultant of polynomials $ p(x) $ and $ q(x) $ from the\nset of values $ \\{p(x_j)/q(x_j) \\}_{j=1}^N $ is also tackled within the\nframework of this approach."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00006-016-0682-x", 
    "link": "http://arxiv.org/pdf/1604.06967v1", 
    "title": "Sparse Representations of Clifford and Tensor algebras in Maxima", 
    "arxiv-id": "1604.06967v1", 
    "author": "Viktor T. Toth", 
    "publish": "2016-04-23T23:55:27Z", 
    "summary": "Clifford algebras have broad applications in science and engineering. The use\nof Clifford algebras can be further promoted in these fields by availability of\ncomputational tools that automate tedious routine calculations. We offer an\nextensive demonstration of the applications of Clifford algebras in\nelectromagnetism using the geometric algebra G3 = Cl(3,0) as a computational\nmodel in the Maxima computer algebra system. We compare the geometric\nalgebra-based approach with conventional symbolic tensor calculations supported\nby Maxima, based on the itensor package. The Clifford algebra functionality of\nMaxima is distributed as two new packages called clifford - for basic\nsimplification of Clifford products, outer products, scalar products and\ninverses; and cliffordan - for applications of geometric calculus."
},{
    "category": "cs.SC", 
    "doi": "10.1134/S0361768816020043", 
    "link": "http://arxiv.org/pdf/1605.00832v1", 
    "title": "Using Two Types of Computer Algebra Systems to Solve Maxwell Optics   Problems", 
    "arxiv-id": "1605.00832v1", 
    "author": "D. S. Kulyabov", 
    "publish": "2016-05-03T10:55:19Z", 
    "summary": "To synthesize Maxwell optics systems, the mathematical apparatus of tensor\nand vector analysis is generally employed. This mathematical apparatus implies\nexecuting a great number of simple stereotyped operations, which are adequately\nsupported by computer algebra systems. In this paper, we distinguish between\ntwo stages of working with a mathematical model: model development and model\nusage. Each of these stages implies its own computer algebra system. As a model\nproblem, we consider the problem of geometrization of Maxwell's equations. Two\ncomputer algebra systems---Cadabra and FORM---are selected for use at different\nstages of investigation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930916", 
    "link": "http://arxiv.org/pdf/1605.00887v1", 
    "title": "Determinantal sets, singularities and application to optimal control in   medical imagery", 
    "arxiv-id": "1605.00887v1", 
    "author": "Thibaut Verron", 
    "publish": "2016-05-03T13:05:59Z", 
    "summary": "Control theory has recently been involved in the field of nuclear magnetic\nresonance imagery. The goal is to control the magnetic field optimally in order\nto improve the contrast between two biological matters on the pictures.\nGeometric optimal control leads us here to analyze mero-morphic vector fields\ndepending upon physical parameters , and having their singularities defined by\na deter-minantal variety. The involved matrix has polynomial entries with\nrespect to both the state variables and the parameters. Taking into account the\nphysical constraints of the problem, one needs to classify, with respect to the\nparameters, the number of real singularities lying in some prescribed\nsemi-algebraic set. We develop a dedicated algorithm for real root\nclassification of the singularities of the rank defects of a polynomial matrix,\ncut with a given semi-algebraic set. The algorithm works under some genericity\nassumptions which are easy to check. These assumptions are not so restrictive\nand are satisfied in the aforementioned application. As more general strategies\nfor real root classification do, our algorithm needs to compute the critical\nloci of some maps, intersections with the boundary of the semi-algebraic\ndomain, etc. In order to compute these objects, the determinantal structure is\nexploited through a stratifi-cation by the rank of the polynomial matrix. This\nspeeds up the computations by a factor 100. Furthermore, our implementation is\nable to solve the application in medical imagery, which was out of reach of\nmore general algorithms for real root classification. For instance,\ncomputational results show that the contrast problem where one of the matters\nis water is partitioned into three distinct classes."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-45641-6_12", 
    "link": "http://arxiv.org/pdf/1605.02494v1", 
    "title": "The complexity of cylindrical algebraic decomposition with respect to   polynomial degree", 
    "arxiv-id": "1605.02494v1", 
    "author": "James H. Davenport", 
    "publish": "2016-05-09T09:46:37Z", 
    "summary": "Cylindrical algebraic decomposition (CAD) is an important tool for working\nwith polynomial systems, particularly quantifier elimination. However, it has\ncomplexity doubly exponential in the number of variables. The base algorithm\ncan be improved by adapting to take advantage of any equational constraints\n(ECs): equations logically implied by the input. Intuitively, we expect the\ndouble exponent in the complexity to decrease by one for each EC. In ISSAC 2015\nthe present authors proved this for the factor in the complexity bound\ndependent on the number of polynomials in the input. However, the other term,\nthat dependent on the degree of the input polynomials, remained unchanged.\n  In the present paper the authors investigate how CAD in the presence of ECs\ncould be further refined using the technology of Groebner Bases to move towards\nthe intuitive bound for polynomial degree."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-45641-6_12", 
    "link": "http://arxiv.org/pdf/1605.02518v1", 
    "title": "Critical Point Computations on Smooth Varieties: Degree and Complexity   bounds", 
    "arxiv-id": "1605.02518v1", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2016-05-09T10:53:12Z", 
    "summary": "Let V $\\subset$ C n be an equidimensional algebraic set and g be an n-variate\npolynomial with rational coefficients. Computing the critical points of the map\nthat evaluates g at the points of V is a cornerstone of several algorithms in\nreal algebraic geometry and optimization. Under the assumption that the\ncritical locus is finite and that the projective closure of V is smooth, we\nprovide sharp upper bounds on the degree of the critical locus which depend\nonly on deg(g) and the degrees of the generic polar varieties associated to V.\nHence, in some special cases where the degrees of the generic polar varieties\ndo not reach the worst-case bounds, this implies that the number of critical\npoints of the evaluation map of g is less than the currently known degree\nbounds. We show that, given a lifting fiber of V , a slight variant of an\nalgorithm due to Bank, Giusti, Heintz, Lecerf, Matera and Solern{\\'o} computes\nthese critical points in time which is quadratic in this bound up to\nlogarithmic factors, linear in the complexity of evaluating the input system\nand polynomial in the number of variables and the maximum degree of the input\npolynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-42432-3_20", 
    "link": "http://arxiv.org/pdf/1605.02912v1", 
    "title": "Need Polynomial Systems be Doubly-exponential?", 
    "arxiv-id": "1605.02912v1", 
    "author": "Matthew England", 
    "publish": "2016-05-10T09:54:16Z", 
    "summary": "Polynomial Systems, or at least their algorithms, have the reputation of\nbeing doubly-exponential in the number of variables [Mayr and Mayer, 1982],\n[Davenport and Heintz, 1988]. Nevertheless, the Bezout bound tells us that that\nnumber of zeros of a zero-dimensional system is singly-exponential in the\nnumber of variables. How should this contradiction be reconciled?\n  We first note that [Mayr and Ritscher, 2013] shows that the doubly\nexponential nature of Gr\\\"{o}bner bases is with respect to the dimension of the\nideal, not the number of variables. This inspires us to consider what can be\ndone for Cylindrical Algebraic Decomposition which produces a\ndoubly-exponential number of polynomials of doubly-exponential degree.\n  We review work from ISSAC 2015 which showed the number of polynomials could\nbe restricted to doubly-exponential in the (complex) dimension using McCallum's\ntheory of reduced projection in the presence of equational constraints. We then\ndiscuss preliminary results showing the same for the degree of those\npolynomials. The results are under primitivity assumptions whose importance we\nillustrate."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-42432-3_20", 
    "link": "http://arxiv.org/pdf/1605.04472v1", 
    "title": "Extended Hardness Results for Approximate Gr\u00f6bner Basis Computation", 
    "arxiv-id": "1605.04472v1", 
    "author": "Gwen Spencer", 
    "publish": "2016-05-14T21:44:01Z", 
    "summary": "Two models were recently proposed to explore the robust hardness of Gr\\\"obner\nbasis computation. Given a polynomial system, both models allow an algorithm to\nselectively ignore some of the polynomials: the algorithm is only responsible\nfor returning a Gr\\\"obner basis for the ideal generated by the remaining\npolynomials. For the $q$-Fractional Gr\\\"obner Basis Problem the algorithm is\nallowed to ignore a constant $(1-q)$-fraction of the polynomials (subject to\none natural structural constraint). Here we prove a new strongest-parameter\nresult: even if the algorithm is allowed to choose a $(3/10-\\epsilon)$-fraction\nof the polynomials to ignore, and need only compute a Gr\\\"obner basis with\nrespect to some lexicographic order for the remaining polynomials, this cannot\nbe accomplished in polynomial time (unless $P=NP$). This statement holds even\nif every polynomial has maximum degree 3. Next, we prove the first robust\nhardness result for polynomial systems of maximum degree 2: for the\n$q$-Fractional model a $(1/5-\\epsilon)$ fraction of the polynomials may be\nignored without losing provable NP-Hardness. Both theorems hold even if every\npolynomial contains at most three distinct variables. Finally, for the Strong\n$c$-partial Gr\\\"obner Basis Problem of De Loera et al. we give conditional\nresults that depend on famous (unresolved) conjectures of Khot and Dinur, et\nal."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930907", 
    "link": "http://arxiv.org/pdf/1605.05082v1", 
    "title": "Efficient Algorithms for Mixed Creative Telescoping", 
    "arxiv-id": "1605.05082v1", 
    "author": "Bruno Salvy", 
    "publish": "2016-05-17T09:56:40Z", 
    "summary": "Creative telescoping is a powerful computer algebra paradigm -initiated by\nDoron Zeilberger in the 90's- for dealing with definite integrals and sums with\nparameters. We address the mixed continuous-discrete case, and focus on the\nintegration of bivariate hypergeometric-hyperexponential terms. We design a new\ncreative telescoping algorithm operating on this class of inputs, based on a\nHermite-like reduction procedure. The new algorithm has two nice features: it\nis efficient and it delivers, for a suitable representation of the input, a\nminimal-order telescoper. Its analysis reveals tight bounds on the sizes of the\ntelescoper it produces."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930907", 
    "link": "http://arxiv.org/pdf/1605.05889v1", 
    "title": "Computing Small Certificates of Inconsistency of Quadratic Fewnomial   Systems", 
    "arxiv-id": "1605.05889v1", 
    "author": "Jules Svartz", 
    "publish": "2016-05-19T11:25:17Z", 
    "summary": "B{\\'e}zout 's theorem states that dense generic systems of n multivariate\nquadratic equations in n variables have 2 n solutions over algebraically closed\nfields. When only a small subset M of monomials appear in the equations\n(fewnomial systems), the number of solutions may decrease dramatically. We\nfocus in this work on subsets of quadratic monomials M such that generic\nsystems with support M do not admit any solution at all. For these systems,\nHilbert's Nullstellensatz ensures the existence of algebraic certificates of\ninconsistency. However, up to our knowledge all known bounds on the sizes of\nsuch certificates -including those which take into account the Newton polytopes\nof the polynomials- are exponential in n. Our main results show that if the\ninequality 2|M| -- 2n $\\le$ $\\sqrt$ 1 + 8{\\nu} -- 1 holds for a quadratic\nfewnomial system -- where {\\nu} is the matching number of a graph associated\nwith M, and |M| is the cardinality of M -- then there exists generically a\ncertificate of inconsistency of linear size (measured as the number of\ncoefficients in the ground field K). Moreover this certificate can be computed\nwithin a polynomial number of arithmetic operations. Next, we evaluate how\noften this inequality holds, and we give evidence that the probability that the\ninequality is satisfied depends strongly on the number of squares. More\nprecisely, we show that if M is picked uniformly at random among the subsets of\nn + k + 1 quadratic monomials containing at least $\\Omega$(n 1/2+$\\epsilon$)\nsquares, then the probability that the inequality holds tends to 1 as n grows.\nInterestingly, this phenomenon is related with the matching number of random\ngraphs in the Erd{\\\"o}s-Renyi model. Finally, we provide experimental results\nshowing that certificates in inconsistency can be computed for systems with\nmore than 10000 variables and equations."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930897", 
    "link": "http://arxiv.org/pdf/1605.06126v1", 
    "title": "Computation of the Similarity Class of the p-Curvature", 
    "arxiv-id": "1605.06126v1", 
    "author": "Eric Schost", 
    "publish": "2016-05-19T20:05:49Z", 
    "summary": "The $p$-curvature of a system of linear differential equations in positive\ncharacteristic $p$ is a matrix that measures how far the system is from having\na basis of polynomial solutions. We show that the similarity class of the\n$p$-curvature can be determined without computing the $p$-curvature itself.\nMore precisely, we design an algorithm that computes the invariant factors of\nthe $p$-curvature in time quasi-linear in $\\sqrt p$. This is much less than the\nsize of the $p$-curvature, which is generally linear in $p$. The new algorithm\nallows to answer a question originating from the study of the Ising model in\nstatistical physics."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930897", 
    "link": "http://arxiv.org/pdf/1605.07433v1", 
    "title": "Bit complexity for multi-homogeneous polynomial system solving   Application to polynomial minimization", 
    "arxiv-id": "1605.07433v1", 
    "author": "Eric Schost", 
    "publish": "2016-05-24T13:01:34Z", 
    "summary": "Multi-homogeneous polynomial systems arise in many applications. We provide\nbit complexity estimates for solving them which, up to a few extra other\nfactors, are quadratic in the number of solutions and linear in the height of\nthe input system under some genericity assumptions. The assumptions essentially\nimply that the Jacobian matrix of the system under study has maximal rank at\nthe solution set and that this solution set if finite. The algorithm is\nprobabilistic and a probability analysis is provided. Next, we apply these\nresults to the problem of optimizing a linear map on the real trace of an\nalgebraic set. Under some genericity assumptions, we provide bit complexity\nestimates for solving this polynomial minimization problem."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930897", 
    "link": "http://arxiv.org/pdf/1607.01967v1", 
    "title": "Rigorous Multiple-Precision Evaluation of D-Finite Functions in SageMath", 
    "arxiv-id": "1607.01967v1", 
    "author": "Marc Mezzarobba", 
    "publish": "2016-07-07T11:33:10Z", 
    "summary": "We present a new open source implementation in the SageMath computer algebra\nsystem of algorithms for the numerical solution of linear ODEs with polynomial\ncoefficients. Our code supports regular singular connection problems and\nprovides rigorous error bounds."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsco.1997.0115", 
    "link": "http://arxiv.org/pdf/1607.02016v1", 
    "title": "Numeric Deduction in Symbolic Computation. Application to Normalizing   Transformations", 
    "arxiv-id": "1607.02016v1", 
    "author": "Ivan I. Shevchenko", 
    "publish": "2016-05-27T12:52:49Z", 
    "summary": "Algorithms of numeric (in exact arithmetic) deduction of analytical\nexpressions, proposed and described by Shevchenko and Vasiliev (1993), are\ndeveloped and implemented in a computer algebra code. This code is built as a\nsuperstructure for the computer algebra package by Shevchenko and Sokolsky\n(1993a) for normalization of Hamiltonian systems of ordinary differential\nequations, in order that high complexity problems of normalization could be\nsolved. As an example, a resonant normal form of a Hamiltonian describing the\nhyperboloidal precession of a dynamically symmetric satellite is derived by\nmeans of the numeric deduction technique. The technique provides a considerable\neconomy, about 30 times in this particular application, in computer memory\nconsumption. It is naturally parallelizable. Thus the economy of memory\nconsumption is convertible into a gain in computation speed."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsco.1997.0115", 
    "link": "http://arxiv.org/pdf/1607.04176v1", 
    "title": "Fast, deterministic computation of the Hermite normal form and   determinant of a polynomial matrix", 
    "arxiv-id": "1607.04176v1", 
    "author": "Wei Zhou", 
    "publish": "2016-07-14T16:01:59Z", 
    "summary": "Given a nonsingular $n \\times n$ matrix of univariate polynomials over a\nfield $\\mathbb{K}$, we give fast and deterministic algorithms to compute its\ndeterminant and its Hermite normal form. Our algorithms use\n$\\widetilde{\\mathcal{O}}(n^\\omega \\lceil s \\rceil)$ operations in $\\mathbb{K}$,\nwhere $s$ is bounded from above by both the average of the degrees of the rows\nand that of the columns of the matrix and $\\omega$ is the exponent of matrix\nmultiplication. The soft-$O$ notation indicates that logarithmic factors in the\nbig-$O$ are omitted while the ceiling function indicates that the cost is\n$\\widetilde{\\mathcal{O}}(n^\\omega)$ when $s = o(1)$. Our algorithms are based\non a fast and deterministic triangularization method for computing the diagonal\nentries of the Hermite form of a nonsingular matrix."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsco.1997.0115", 
    "link": "http://arxiv.org/pdf/1609.01010v1", 
    "title": "Automatic Library Generation for Modular Polynomial Multiplication", 
    "arxiv-id": "1609.01010v1", 
    "author": "Lingchuan Meng", 
    "publish": "2016-09-05T01:11:45Z", 
    "summary": "Polynomial multiplication is a key algorithm underlying computer algebra\nsystems (CAS) and its efficient implementation is crucial for the performance\nof CAS. In this paper we design and implement algorithms for polynomial\nmultiplication using approaches based the fast Fourier transform (FFT) and the\ntruncated Fourier transform (TFT). We improve on the state-of-the-art in both\ntheoretical and practical performance. The {\\SPIRAL} library generation system\nis extended and used to automatically generate and tune the performance of a\npolynomial multiplication library that is optimized for memory hierarchy,\nvectorization and multi-threading, using new and existing algorithms. The\nperformance tuning has been aided by the use of automation where many code\nchoices are generated and intelligent search is utilized to find the \"best\"\nimplementation on a given architecture. The performance of autotuned\nimplementations is comparable to, and in some cases better than, the best\nhand-tuned code."
},{
    "category": "cs.SC", 
    "doi": "10.1006/jsco.1997.0115", 
    "link": "http://arxiv.org/pdf/1609.03768v1", 
    "title": "Some Open Problems related to Creative Telescoping", 
    "arxiv-id": "1609.03768v1", 
    "author": "Manuel Kauers", 
    "publish": "2016-09-13T11:16:29Z", 
    "summary": "Creative telescoping is the method of choice for obtaining information about\ndefinite sums or integrals. It has been intensively studied since the early\n1990s, and can now be considered as a classical technique in computer algebra.\nAt the same time, it is still subject of ongoing research. In this paper, we\npresent a selection of open problems in this context. We would be curious to\nhear about any substantial progress on any of these problems."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1609.04259v1", 
    "title": "A Fast Algorithm for Computing the Truncated Resultant", 
    "arxiv-id": "1609.04259v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2016-09-14T13:25:33Z", 
    "summary": "Let P and Q be two polynomials in K[x, y] with degree at most d, where K is a\nfield. Denoting by R $\\in$ K[x] the resultant of P and Q with respect to y, we\npresent an algorithm to compute R mod x^k in O~(kd) arithmetic operations in K,\nwhere the O~ notation indicates that we omit polylogarithmic factors. This is\nan improvement over state-of-the-art algorithms that require to compute R in\nO~(d^3) operations before computing its first k coefficients."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1611.02569v1", 
    "title": "Sparse multivariate factorization by mean of a few bivariate   factorizations", 
    "arxiv-id": "1611.02569v1", 
    "author": "Bernard Parisse", 
    "publish": "2016-11-08T15:53:13Z", 
    "summary": "We describe an algorithm to factor sparse multivariate polynomials using O(d)\nbivariate factorizations where d is the number of variables. This algorithm is\nimplemented in the Giac/Xcas computer algebra system."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1611.06548v1", 
    "title": "A note about \"Faster algorithms for computing Hong's bound on absolute   positiveness\" by K. Mehlhorn and S. Ray", 
    "arxiv-id": "1611.06548v1", 
    "author": "Przemys\u0142aw Koprowski", 
    "publish": "2016-11-20T17:09:25Z", 
    "summary": "We show that a linear-time algorithm for computing Hong's bound for positive\nroots of a univariate polynomial, described by K. Mehlhorn and S. Ray in an\narticle \"Faster algorithms for computing Hong's bound on absolute\npositiveness\", is incorrect. We present a corrected version."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1611.07421v1", 
    "title": "Reduction-Based Creative Telescoping for Fuchsian D-finite Functions", 
    "arxiv-id": "1611.07421v1", 
    "author": "Christoph Koutschan", 
    "publish": "2016-11-22T17:05:04Z", 
    "summary": "Continuing a series of articles in the past few years on creative telescoping\nusing reductions, we adapt Trager's Hermite reduction for algebraic functions\nto fuchsian D-finite functions and develop a reduction-based creative\ntelescoping algorithm for this class of functions, thereby generalizing our\nrecent reduction-based algorithm for algebraic functions, presented at ISSAC\n2016."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1612.04588v1", 
    "title": "Reverse Engineering of Irreducible Polynomials in GF(2^m) Arithmetic", 
    "arxiv-id": "1612.04588v1", 
    "author": "Maciej Ciesielski", 
    "publish": "2016-12-14T11:41:05Z", 
    "summary": "Current techniques for formally verifying circuits implemented in Galois\nfield (GF) arithmetic are limited to those with a known irreducible polynomial\nP(x). This paper presents a computer algebra based technique that extracts the\nirreducible polynomial P(x) used in the implementation of a multiplier in\nGF(2^m). The method is based on first extracting a unique polynomial in Galois\nfield of each output bit independently. P(x) is then obtained by analyzing the\nalgebraic expression in GF(2^m) of each output bit. We demonstrate that this\nmethod is able to reverse engineer the irreducible polynomial of an n-bit GF\nmultiplier in n threads. Experiments were performed on Mastrovito and\nMontgomery multipliers with different P (x), including NIST-recommended\npolynomials and optimal polynomials for different microprocessor architectures."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1612.05403v1", 
    "title": "Efficient sparse polynomial factoring using the Funnel heap", 
    "arxiv-id": "1612.05403v1", 
    "author": "Karl Gemayel", 
    "publish": "2016-12-16T09:42:59Z", 
    "summary": "This work is a comprehensive extension of Abu-Salem et al. (2015) that\ninvestigates the prowess of the Funnel Heap for implementing sums of products\nin the polytope method for factoring polynomials, when the polynomials are in\nsparse distributed representation. We exploit that the work and cache\ncomplexity of an Insert operation using Funnel Heap can be refined to de- pend\non the rank of the inserted monomial product, where rank corresponds to its\nlifetime in Funnel Heap. By optimising on the pattern by which insertions and\nextractions occur during the Hensel lifting phase of the polytope method, we\nare able to obtain an adaptive Funnel Heap that minimises all of the work,\ncache, and space complexity of this phase. Additionally, we conduct a detailed\nempirical study confirming the superiority of Funnel Heap over the generic\nBinary Heap once swaps to external memory begin to take place. We demonstrate\nthat Funnel Heap is a more efficient merger than the cache oblivious k-merger,\nwhich fails to achieve its optimal (and amortised) cache complexity when used\nfor performing sums of products. This provides an empirical proof of concept\nthat the overlapping approach for perform- ing sums of products using one\nglobal Funnel Heap is more suited than the serialised approach, even when the\nlatter uses the best merging structures available."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1612.05518v1", 
    "title": "Computing solutions of linear Mahler equations", 
    "arxiv-id": "1612.05518v1", 
    "author": "Marc Mezzarobba", 
    "publish": "2016-12-16T15:56:27Z", 
    "summary": "Mahler equations relate evaluations of the same function $f$ at iterated\n$b$th powers of the variable. They arise in particular in the study of\nautomatic sequences and in the complexity analysis of divide-and-conquer\nalgorithms. Recently, the problem of solving Mahler equations in closed form\nhas occurred in connection with number-theoretic questions. A difficulty in the\nmanipulation of Mahler equations is the exponential blow-up of degrees when\napplying a Mahler operator to a polynomial. In this work, we present algorithms\nfor solving linear Mahler equations for series, polynomials, and rational\nfunctions, and get polynomial-time complexity under a mild assumption.\nIncidentally, we develop an algorithm for computing the gcrd of a family of\nlinear Mahler operators with nonzero constant terms."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1612.05766v1", 
    "title": "Fast Matrix Multiplication and Symbolic Computation", 
    "arxiv-id": "1612.05766v1", 
    "author": "Victor Pan", 
    "publish": "2016-12-17T13:51:17Z", 
    "summary": "The complexity of matrix multiplication (hereafter MM) has been intensively\nstudied since 1969, when Strassen surprisingly decreased the exponent 3 in the\ncubic cost of the straightforward classical MM to log 2 (7) $\\approx$ 2.8074.\nApplications to some fundamental problems of Linear Algebra and Computer\nScience have been immediately recognized, but the researchers in Computer\nAlgebra keep discovering more and more applications even today, with no sign of\nslowdown. We survey the unfinished history of decreasing the exponent towards\nits information lower bound 2, recall some important techniques discovered in\nthis process and linked to other fields of computing, reveal sample surprising\napplications to fast computation of the inner products of two vectors and\nsummation of integers, and discuss the curse of recursion, which separates the\nprogress in fast MM into its most acclaimed and purely theoretical part and\ninto valuable acceleration of MM of feasible sizes. Then, in the second part of\nour paper, we cover fast MM in realistic symbolic computations and discuss\napplications and implementation of fast exact matrix multiplication. We first\nreview how most of exact linear algebra can be reduced to matrix multiplication\nover small finite fields. Then we highlight the differences in the design of\napproximate and exact implementations of fast MM, taking into account nowadays\nprocessor and memory hierarchies. In the concluding section we comment on\ncurrent perspectives of the study of fast MM."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1612.06069v1", 
    "title": "Comparative study of space filling curves for cache oblivious TU   Decomposition", 
    "arxiv-id": "1612.06069v1", 
    "author": "Mira Al Arab", 
    "publish": "2016-12-19T08:07:16Z", 
    "summary": "We examine several matrix layouts based on space-filling curves that allow\nfor a cache-oblivious adaptation of parallel TU decomposition for rectangular\nmatrices over finite fields. The TU algorithm of \\cite{Dumas} requires index\nconversion routines for which the cost to encode and decode the chosen curve is\nsignificant. Using a detailed analysis of the number of bit operations required\nfor the encoding and decoding procedures, and filtering the cost of lookup\ntables that represent the recursive decomposition of the Hilbert curve, we show\nthat the Morton-hybrid order incurs the least cost for index conversion\nroutines that are required throughout the matrix decomposition as compared to\nthe Hilbert, Peano, or Morton orders. The motivation lies in that cache\nefficient parallel adaptations for which the natural sequential evaluation\norder demonstrates lower cache miss rate result in overall faster performance\non parallel machines with private or shared caches, on GPU's, or even cloud\ncomputing platforms. We report on preliminary experiments that demonstrate how\nthe TURBO algorithm in Morton-hybrid layout attains orders of magnitude\nimprovement in performance as the input matrices increase in size. For example,\nwhen $N = 2^{13}$, the row major TURBO algorithm concludes within about 38.6\nhours, whilst the Morton-hybrid algorithm with truncation size equal to $64$\nconcludes within 10.6 hours."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1701.00396v1", 
    "title": "Time and space efficient generators for quasiseparable matrices", 
    "arxiv-id": "1701.00396v1", 
    "author": "Arne Storjohann", 
    "publish": "2017-01-02T14:12:20Z", 
    "summary": "The class of quasiseparable matrices is defined by the property that any\nsubmatrix entirely below or above the main diagonal has small rank, namely\nbelow a bound called the order of quasiseparability. These matrices arise\nnaturally in solving PDE's for particle interaction with the Fast Multi-pole\nMethod (FMM), or computing generalized eigenvalues. From these application\nfields, structured representations and algorithms have been designed in\nnumerical linear algebra to compute with these matrices in time linear in the\nmatrix dimension and either quadratic or cubic in the quasiseparability order.\nMotivated by the design of the general purpose exact linear algebra library\nLinBox, and by algorithmic applications in algebraic computing, we adapt\nexisting techniques introduce novel ones to use quasiseparable matrices in\nexact linear algebra, where sub-cubic matrix arithmetic is available. In\nparticular, we will show, the connection between the notion of\nquasiseparability and the rank profile matrix invariant, that we have\nintroduced in 2015. It results in two new structured representations, one being\na simpler variation on the hierarchically semiseparable storage, and the second\none exploiting the generalized Bruhat decomposition. As a consequence, most\nbasic operations, such as computing the quasiseparability orders, applying a\nvector, a block vector, multiplying two quasiseparable matrices together,\ninverting a quasiseparable matrix, can be at least as fast and often faster\nthan previous existing algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1701.03529v1", 
    "title": "Functional Decomposition using Principal Subfields", 
    "arxiv-id": "1701.03529v1", 
    "author": "Juliane Capaverde", 
    "publish": "2017-01-12T23:14:56Z", 
    "summary": "Let $f\\in K(t)$ be a univariate rational function. It is well known that any\nnon-trivial decomposition $g \\circ h$, with $g,h\\in K(t)$, corresponds to a\nnon-trivial subfield $K(f(t))\\subsetneq L \\subsetneq K(t)$ and vice-versa. In\nthis paper we use the idea of principal subfields and fast\nsubfield-intersection techniques to compute the subfield lattice of\n$K(t)/K(f(t))$. This yields a Las Vegas algorithm with improved complexity and\nbetter run times for finding all non-equivalent complete decompositions of $f$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1701.06248v1", 
    "title": "Criteria for Finite Difference Groebner Bases of Normal Binomial   Difference Ideals", 
    "arxiv-id": "1701.06248v1", 
    "author": "Xiao-Shan Gao", 
    "publish": "2017-01-23T01:39:32Z", 
    "summary": "In this paper, we give decision criteria for normal binomial difference\npolynomial ideals in the univariate difference polynomial ring F{y} to have\nfinite difference Groebner bases and an algorithm to compute the finite\ndifference Groebner bases if these criteria are satisfied. The novelty of these\ncriteria lies in the fact that complicated properties about difference\npolynomial ideals are reduced to elementary properties of univariate\npolynomials in Z[x]."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1701.07802v2", 
    "title": "Bounds for D-finite Substitution", 
    "arxiv-id": "1701.07802v2", 
    "author": "Gleb Pogudin", 
    "publish": "2017-01-26T18:12:52Z", 
    "summary": "It is well-known that the composition of a D-finite function with an\nalgebraic function is again D-finite. We give the first estimates for the\norders and the degrees of annihilating operators for the compositions. We find\nthat the analysis of removable singularities leads to an order-degree curve\nwhich is much more accurate than the order-degree curve obtained from the usual\nlinear algebra reasoning."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1701.08487v1", 
    "title": "Riemann Tensor Polynomial Canonicalization by Graph Algebra Extension", 
    "arxiv-id": "1701.08487v1", 
    "author": "Yang Li", 
    "publish": "2017-01-30T05:50:51Z", 
    "summary": "Tensor expression simplification is an \"ancient\" topic in computer algebra, a\nrepresentative of which is the canonicalization of Riemann tensor polynomials.\nPractically fast algorithms exist for monoterm canonicalization, but not for\nmultiterm canonicalization. Targeting the multiterm difficulty, in this paper\nwe establish the extension theory of graph algebra, and propose a\ncanonicalization algorithm for Riemann tensor polynomials based on this theory."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1702.03755v1", 
    "title": "Certificates for triangular equivalence and rank profiles", 
    "arxiv-id": "1702.03755v1", 
    "author": "Clement Pernet", 
    "publish": "2017-02-13T13:03:55Z", 
    "summary": "In this paper, we give novel certificates for triangular equivalence and rank\nprofiles. These certificates enable to verify the row or column rank profiles\nor the whole rank profile matrix faster than recomputing them, with a\nnegligible overall overhead. We first provide quadratic time and space\nnon-interactive certificates saving the logarithmic factors of previously known\nones. Then we propose interactive certificates for the same problems whose\nMonte Carlo verification complexity requires a small constant number of\nmatrix-vector multiplications, a linear space, and a linear number of extra\nfield operations. As an application we also give an interactive protocol ,\ncertifying the determinant of dense matrices, faster than the best previously\nknown one."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930931", 
    "link": "http://arxiv.org/pdf/1702.07060v1", 
    "title": "Algorithm for computing semi-Fourier sequences of expressions involving   exponentiations and integrations", 
    "arxiv-id": "1702.07060v1", 
    "author": "Adam Strzebonski", 
    "publish": "2017-02-23T01:24:29Z", 
    "summary": "We provide an algorithm for computing semi-Fourier sequences for expressions\nconstructed from arithmetic operations, exponentiations and integrations. The\nsemi-Fourier sequence is a relaxed version of Fourier sequence for polynomials\n(expressions made of additions and multiplications)."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-15274-0_16", 
    "link": "http://arxiv.org/pdf/1702.07242v1", 
    "title": "Fast generalized Bruhat decomposition", 
    "arxiv-id": "1702.07242v1", 
    "author": "Gennadi Malaschonok", 
    "publish": "2017-02-23T14:49:37Z", 
    "summary": "The deterministic recursive pivot-free algorithms for the computation of\ngeneralized Bruhat decomposition of the matrix in the field and for the\ncomputation of the inverse matrix are presented. This method has the same\ncomplexity as algorithm of matrix multiplication and it is suitable for the\nparallel computer systems."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-24021-3_22", 
    "link": "http://arxiv.org/pdf/1702.07243v1", 
    "title": "Triangular Decomposition of Matrices in a Domain", 
    "arxiv-id": "1702.07243v1", 
    "author": "Anton Scherbinin", 
    "publish": "2017-02-23T14:50:00Z", 
    "summary": "Deterministic recursive algorithms for the computation of matrix triangular\ndecompositions with permutations like LU and Bruhat decomposition are presented\nfor the case of commutative domains. This decomposition can be considered as a\ngeneralization of LU and Bruhat decompositions, because they both may be easily\nobtained from this triangular decomposition. Algorithms have the same\ncomplexity as the algorithm of matrix multiplication."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/1702.07248v1", 
    "title": "Generalized Bruhat decomposition in commutative domains", 
    "arxiv-id": "1702.07248v1", 
    "author": "Gennadi Malaschonok", 
    "publish": "2017-02-23T14:59:12Z", 
    "summary": "Deterministic recursive algorithms for the computation of generalized Bruhat\ndecomposition of the matrix in commutative domain are presented. This method\nhas the same complexity as the algorithm of matrix multiplication."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/1702.08664v1", 
    "title": "Decomposition of polynomial sets into characteristic pairs", 
    "arxiv-id": "1702.08664v1", 
    "author": "Chenqi Mou", 
    "publish": "2017-02-28T06:33:50Z", 
    "summary": "A characteristic pair is a pair (G,C) of polynomial sets in which G is a\nreduced lexicographic Groebner basis, C is the minimal triangular set contained\nin G, and C is normal. In this paper, we show that any finite polynomial set P\ncan be decomposed algorithmically into finitely many characteristic pairs with\nassociated zero relations, which provide representations for the zero set of P\nin terms of those of Groebner bases and those of triangular sets. The algorithm\nwe propose for the decomposition makes use of the inherent connection between\nRitt characteristic sets and lexicographic Groebner bases and is based\nessentially on the structural properties and the computation of lexicographic\nGroebner bases. Several nice properties about the decomposition and the\nresulting characteristic pairs, in particular relationships between the\nGroebner basis and the triangular set in each pair, are established. Examples\nare given to illustrate the algorithm and some of the properties."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/1703.01974v1", 
    "title": "Symbolic Solutions of Simultaneous First-order PDEs in One Unknown", 
    "arxiv-id": "1703.01974v1", 
    "author": "C\u00e9lestin Wafo Soh", 
    "publish": "2017-02-14T20:13:52Z", 
    "summary": "We propose and implement an algorithm for solving an overdetermined system of\npartial differential equations in one unknown. Our approach relies on\nBour-Mayer method to determine compatibility conditions via Jacobi-Mayer\nbrackets. We solve compatible systems recursively by imitating what one would\ndo with pen and paper: Solve one equation, substitute the solution into the\nremaining equations and iterate the process until the equations of the system\nare exhausted. The method we employ for assessing the consistency of the\nunderlying system differs from the traditional use of differential Gr\\\"obner\nbases yet seems more efficient and straightforward to implement. We are not\naware of a computer algebra system that adopts the procedure we advocate in\nthis work."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/1703.02077v1", 
    "title": "A lattice formulation of the F4 completion procedure", 
    "arxiv-id": "1703.02077v1", 
    "author": "Chenavier Cyrille", 
    "publish": "2017-03-06T19:31:36Z", 
    "summary": "We write a procedure for constructing noncommutative Groebner bases.\nReductions are done by particular linear projectors, called reduction\noperators. The operators enable us to use a lattice construction to reduce\nsimultaneously each S-polynomial into a unique normal form. We write an\nimplementation as well as an example to illustrate our procedure. Moreover, the\nlattice construction is done by Gaussian elimination, which relates our\nprocedure to the F4 algorithm for constructing commutative Groebner bases."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/1703.06120v1", 
    "title": "Roots multiplicity without companion matrices", 
    "arxiv-id": "1703.06120v1", 
    "author": "Przemys\u0142aw Koprowski", 
    "publish": "2017-03-17T17:28:23Z", 
    "summary": "We show a method for constructing a polynomial interpolating roots'\nmultiplicities of another polynomial, that does not use companion matrices.\nThis leads to a modification to Guersenzvaig--Szechtman square-free\ndecomposition algorithm that is more efficient both in theory and in practice."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/9811017v1", 
    "title": "Formulas as Programs", 
    "arxiv-id": "cs/9811017v1", 
    "author": "Marc Bezem", 
    "publish": "1998-11-11T14:05:13Z", 
    "summary": "We provide here a computational interpretation of first-order logic based on\na constructive interpretation of satisfiability w.r.t. a fixed but arbitrary\ninterpretation. In this approach the formulas themselves are programs. This\ncontrasts with the so-called formulas as types approach in which the proofs of\nthe formulas are typed terms that can be taken as programs. This view of\ncomputing is inspired by logic programming and constraint logic programming but\ndiffers from them in a number of crucial aspects.\n  Formulas as programs is argued to yield a realistic approach to programming\nthat has been realized in the implemented programming language ALMA-0 (Apt et\nal.) that combines the advantages of imperative and logic programming. The work\nhere reported can also be used to reason about the correctness of non-recursive\nALMA-0 programs that do not include destructive assignment."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/9901006v1", 
    "title": "Object Oriented and Functional Programming for Symbolic Manipulation", 
    "arxiv-id": "cs/9901006v1", 
    "author": "Alexander Yu. Vlasov", 
    "publish": "1999-01-13T20:40:04Z", 
    "summary": "The advantages of mixed approach with using different kinds of programming\ntechniques for symbolic manipulation are discussed. The main purpose of\napproach offered is merge the methods of object oriented programming that\nconvenient for presentation data and algorithms for user with advantages of\nfunctional languages for data manipulation, internal presentation, and\nportability of software."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/0106042v1", 
    "title": "MACE 2.0 Reference Manual and Guide", 
    "arxiv-id": "cs/0106042v1", 
    "author": "William McCune", 
    "publish": "2001-06-19T16:11:19Z", 
    "summary": "MACE is a program that searches for finite models of first-order statements.\nThe statement to be modeled is first translated to clauses, then to relational\nclauses; finally for the given domain size, the ground instances are\nconstructed. A Davis-Putnam-Loveland-Logeman procedure decides the\npropositional problem, and any models found are translated to first-order\nmodels. MACE is a useful complement to the theorem prover Otter, with Otter\nsearching for proofs and MACE looking for countermodels."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/0206010v2", 
    "title": "Performance Comparison of Function Evaluation Methods", 
    "arxiv-id": "cs/0206010v2", 
    "author": "Leo Liberti", 
    "publish": "2002-06-06T09:10:39Z", 
    "summary": "We perform a comparison of the performance and efficiency of four different\nfunction evaluation methods: black-box functions, binary trees, $n$-ary trees\nand string parsing. The test consists in evaluating 8 different functions of\ntwo variables $x,y$ over 5000 floating point values of the pair $(x,y)$. The\noutcome of the test indicates that the $n$-ary tree representation of algebraic\nexpressions is the fastest method, closely followed by black-box function\nmethod, then by binary trees and lastly by string parsing."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/0301028v1", 
    "title": "The integration of systems of linear PDEs using conservation laws of   syzygies", 
    "arxiv-id": "cs/0301028v1", 
    "author": "Thomas Wolf", 
    "publish": "2003-01-28T05:20:44Z", 
    "summary": "A new integration technique is presented for systems of linear partial\ndifferential equations (PDEs) for which syzygies can be formulated that obey\nconservation laws. These syzygies come for free as a by-product of the\ndifferential Groebner Basis computation. Compared with the more obvious way of\nintegrating a single equation and substituting the result in other equations\nthe new technique integrates more than one equation at once and therefore\nintroduces temporarily fewer new functions of integration that in addition\ndepend on fewer variables. Especially for high order PDE systems in many\nvariables the conventional integration technique may lead to an explosion of\nthe number of functions of integration which is avoided with the new method. A\nfurther benefit is that redundant free functions in the solution are either\nprevented or that their number is at least reduced."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/0302037v4", 
    "title": "Hidden Polynomial(s) Cryptosystems", 
    "arxiv-id": "cs/0302037v4", 
    "author": "Ilia Toli", 
    "publish": "2003-02-26T18:30:49Z", 
    "summary": "We propose variations of the class of hidden monomial cryptosystems in order\nto make it resistant to all known attacks. We use identities built upon a\nsingle bivariate polynomial equation with coefficients in a finite field.\nIndeed, it can be replaced by a ``small'' ideal, as well. Throughout, we set up\nprobabilistic encryption protocols, too. The same ideas extend to digital\nsignature algorithms, as well. Our schemes work as well on differential fields\nof positive characteristic, and elsewhere."
},{
    "category": "cs.SE", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/0303027v1", 
    "title": "Numerical Coverage Estimation for the Symbolic Simulation of Real-Time   Systems", 
    "arxiv-id": "cs/0303027v1", 
    "author": "Fang Yu", 
    "publish": "2003-03-25T21:57:50Z", 
    "summary": "Three numerical coverage metrics for the symbolic simulation of dense-time\nsystems and their estimation methods are presented. Special techniques to\nderive numerical estimations of dense-time state-spaces have also been\ndeveloped. Properties of the metrics are also discussed with respect to four\ncriteria. Implementation and experiments are then reported."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-3-319-02297-0_20", 
    "link": "http://arxiv.org/pdf/cs/0304013v1", 
    "title": "Hidden Polynomial(s) Cryptosystems", 
    "arxiv-id": "cs/0304013v1", 
    "author": "Ilia Toli", 
    "publish": "2003-04-09T12:28:35Z", 
    "summary": "We propose public-key cryptosystems with public key a system of polynomial\nequations, algebraic or differential, and private key a single polynomial or a\nsmall-size ideal. We set up probabilistic encryption, signature, and\nsigncryption protocols."
},{
    "category": "cs.SC", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0304043v1", 
    "title": "gTybalt - a free computer algebra system", 
    "arxiv-id": "cs/0304043v1", 
    "author": "Stefan Weinzierl", 
    "publish": "2003-04-29T18:22:47Z", 
    "summary": "This article documents the free computer algebra system \"gTybalt\". The\nprogram is build on top of other packages, among others GiNaC, TeXmacs and\nRoot. It offers the possibility of interactive symbolic calculations within the\nC++ programming language. Mathematical formulae are visualized using TeX fonts."
},{
    "category": "cs.CR", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0305034v3", 
    "title": "Cryptanalysis of HFE", 
    "arxiv-id": "cs/0305034v3", 
    "author": "Ilia Toli", 
    "publish": "2003-05-17T19:41:32Z", 
    "summary": "I transform the trapdoor problem of HFE into a linear algebra problem."
},{
    "category": "cs.PL", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0309003v1", 
    "title": "Model Checking Linear Logic Specifications", 
    "arxiv-id": "cs/0309003v1", 
    "author": "M. Martelli", 
    "publish": "2003-09-01T09:34:15Z", 
    "summary": "The overall goal of this paper is to investigate the theoretical foundations\nof algorithmic verification techniques for first order linear logic\nspecifications. The fragment of linear logic we consider in this paper is based\non the linear logic programming language called LO enriched with universally\nquantified goal formulas. Although LO was originally introduced as a\ntheoretical foundation for extensions of logic programming languages, it can\nalso be viewed as a very general language to specify a wide range of\ninfinite-state concurrent systems.\n  Our approach is based on the relation between backward reachability and\nprovability highlighted in our previous work on propositional LO programs.\nFollowing this line of research, we define here a general framework for the\nbottom-up evaluation of first order linear logic specifications. The evaluation\nprocedure is based on an effective fixpoint operator working on a symbolic\nrepresentation of infinite collections of first order linear logic formulas.\nThe theory of well quasi-orderings can be used to provide sufficient conditions\nfor the termination of the evaluation of non trivial fragments of first order\nlinear logic."
},{
    "category": "cs.SC", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0309050v1", 
    "title": "Computing Igusa's Local Zeta Functions of Univariate Polynomials, and   Linear Feedback Shift Registers", 
    "arxiv-id": "cs/0309050v1", 
    "author": "W. A. Zuniga-Galindo", 
    "publish": "2003-09-26T22:57:24Z", 
    "summary": "We give a polynomial time algorithm for computing the Igusa local zeta\nfunction $Z(s,f)$ attached to a polynomial $f(x)\\in \\QTR{Bbb}{Z}[x]$, in one\nvariable, with splitting field $\\QTR{Bbb}{Q}$, and a prime number $p$. We also\npropose a new class of Linear Feedback Shift Registers based on the computation\nof Igusa's local zeta function."
},{
    "category": "cs.SC", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0310055v1", 
    "title": "Mace4 Reference Manual and Guide", 
    "arxiv-id": "cs/0310055v1", 
    "author": "William McCune", 
    "publish": "2003-10-28T16:56:44Z", 
    "summary": "Mace4 is a program that searches for finite models of first-order formulas.\nFor a given domain size, all instances of the formulas over the domain are\nconstructed. The result is a set of ground clauses with equality. Then, a\ndecision procedure based on ground equational rewriting is applied. If\nsatisfiability is detected, one or more models are printed. Mace4 is a useful\ncomplement to first-order theorem provers, with the prover searching for proofs\nand Mace4 looking for countermodels, and it is useful for work on finite\nalgebras. Mace4 performs better on equational problems than did our previous\nmodel-searching program Mace2."
},{
    "category": "cs.SC", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0310056v1", 
    "title": "OTTER 3.3 Reference Manual", 
    "arxiv-id": "cs/0310056v1", 
    "author": "William McCune", 
    "publish": "2003-10-28T19:17:38Z", 
    "summary": "OTTER is a resolution-style theorem-proving program for first-order logic\nwith equality. OTTER includes the inference rules binary resolution,\nhyperresolution, UR-resolution, and binary paramodulation. Some of its other\nabilities and features are conversion from first-order formulas to clauses,\nforward and back subsumption, factoring, weighting, answer literals, term\nordering, forward and back demodulation, evaluable functions and predicates,\nKnuth-Bendix completion, and the hints strategy. OTTER is coded in ANSI C, is\nfree, and is portable to many different kinds of computer."
},{
    "category": "cs.SC", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0311053v1", 
    "title": "Weak Bezout inequality for D-modules", 
    "arxiv-id": "cs/0311053v1", 
    "author": "Dima Grigoriev", 
    "publish": "2003-11-28T15:28:04Z", 
    "summary": "Let $\\{w_{i,j}\\}_{1\\leq i\\leq n, 1\\leq j\\leq s} \\subset\nL_m=F(X_1,...,X_m)[{\\partial \\over \\partial X_1},..., {\\partial \\over \\partial\nX_m}]$ be linear partial differential operators of orders with respect to\n${\\partial \\over \\partial X_1},..., {\\partial \\over \\partial X_m}$ at most $d$.\nWe prove an upper bound n(4m^2d\\min\\{n,s\\})^{4^{m-t-1}(2(m-t))} on the leading\ncoefficient of the Hilbert-Kolchin polynomial of the left $L_m$-module\n$<\\{w_{1,j}, ..., w_{n,j}\\}_{1\\leq j \\leq s} > \\subset L_m^n$ having the\ndifferential type $t$ (also being equal to the degree of the Hilbert-Kolchin\npolynomial). The main technical tool is the complexity bound on solving systems\nof linear equations over {\\it algebras of fractions} of the form\n$$L_m(F[X_1,..., X_m, {\\partial \\over \\partial X_1},..., {\\partial \\over\n\\partial X_k}])^{-1}.$$"
},{
    "category": "cs.SC", 
    "doi": "10.1016/S0010-4655(03)00468-5", 
    "link": "http://arxiv.org/pdf/cs/0401012v2", 
    "title": "Algebraic Elimination of epsilon-transitions", 
    "arxiv-id": "cs/0401012v2", 
    "author": "Eric Laugerotte", 
    "publish": "2004-01-15T16:12:51Z", 
    "summary": "We present here algebraic formulas associating a k-automaton to a\nk-epsilon-automaton. The existence depends on the definition of the star of\nmatrices and of elements in the semiring k. For this reason, we present the\ntheorem which allows the transformation of k-epsilon-automata into k-automata.\nThe two automata have the same behaviour."
},{
    "category": "cs.CC", 
    "doi": "10.1007/s00224-006-1322-y", 
    "link": "http://arxiv.org/pdf/cs/0405021v1", 
    "title": "Computing Multi-Homogeneous Bezout Numbers is Hard", 
    "arxiv-id": "cs/0405021v1", 
    "author": "Klaus Meer", 
    "publish": "2004-05-05T14:33:19Z", 
    "summary": "The multi-homogeneous Bezout number is a bound for the number of solutions of\na system of multi-homogeneous polynomial equations, in a suitable product of\nprojective spaces.\n  Given an arbitrary, not necessarily multi-homogeneous system, one can ask for\nthe optimal multi-homogenization that would minimize the Bezout number.\n  In this paper, it is proved that the problem of computing, or even estimating\nthe optimal multi-homogeneous Bezout number is actually NP-hard.\n  In terms of approximation theory for combinatorial optimization, the problem\nof computing the best multi-homogeneous structure does not belong to APX,\nunless P = NP.\n  Moreover, polynomial time algorithms for estimating the minimal\nmulti-homogeneous Bezout number up to a fixed factor cannot exist even in a\nrandomized setting, unless BPP contains NP."
},{
    "category": "cs.AI", 
    "doi": "10.1007/s00224-006-1322-y", 
    "link": "http://arxiv.org/pdf/cs/0405107v1", 
    "title": "A Framework for Combining Defeasible Argumentation with Labeled   Deduction", 
    "arxiv-id": "cs/0405107v1", 
    "author": "Guillermo Ricardo Simari", 
    "publish": "2004-05-27T18:54:31Z", 
    "summary": "In the last years, there has been an increasing demand of a variety of\nlogical systems, prompted mostly by applications of logic in AI and other\nrelated areas. Labeled Deductive Systems (LDS) were developed as a flexible\nmethodology to formalize such a kind of complex logical systems. Defeasible\nargumentation has proven to be a successful approach to formalizing commonsense\nreasoning, encompassing many other alternative formalisms for defeasible\nreasoning. Argument-based frameworks share some common notions (such as the\nconcept of argument, defeater, etc.) along with a number of particular features\nwhich make it difficult to compare them with each other from a logical\nviewpoint. This paper introduces LDSar, a LDS for defeasible argumentation in\nwhich many important issues concerning defeasible argumentation are captured\nwithin a unified logical framework. We also discuss some logical properties and\nextensions that emerge from the proposed framework."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0406030v2", 
    "title": "Abstract Canonical Inference", 
    "arxiv-id": "cs/0406030v2", 
    "author": "Nachum Dershowitz", 
    "publish": "2004-06-17T10:13:04Z", 
    "summary": "An abstract framework of canonical inference is used to explore how different\nproof orderings induce different variants of saturation and completeness.\nNotions like completion, paramodulation, saturation, redundancy elimination,\nand rewrite-system reduction are connected to proof orderings. Fairness of\ndeductive mechanisms is defined in terms of proof orderings, distinguishing\nbetween (ordinary) \"fairness,\" which yields completeness, and \"uniform\nfairness,\" which yields saturation."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0407059v1", 
    "title": "On rational definite summation", 
    "arxiv-id": "cs/0407059v1", 
    "author": "Sergey P. Tsarev", 
    "publish": "2004-07-24T14:11:57Z", 
    "summary": "We present a partial proof of van Hoeij-Abramov conjecture about the\nalgorithmic possibility of computation of finite sums of rational functions.\nThe theoretical results proved in this paper provide an algorithm for\ncomputation of a large class of sums $ S(n) = \\sum_{k=0}^{n-1}R(k,n)$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0409006v1", 
    "title": "Maple+GrTensorII libraries for cosmology", 
    "arxiv-id": "cs/0409006v1", 
    "author": "Valentina D. Vulcanov", 
    "publish": "2004-09-04T12:52:22Z", 
    "summary": "The article mainly presents some results in using MAPLE platform for computer\nalgebra and GrTensorII package in doing calculations for theoretical and\nnumerical cosmology"
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0409029v2", 
    "title": "Efficient polynomial time algorithms computing industrial-strength   primitive roots", 
    "arxiv-id": "cs/0409029v2", 
    "author": "Jean-Guillaume Dumas", 
    "publish": "2004-09-14T15:43:15Z", 
    "summary": "E. Bach, following an idea of T. Itoh, has shown how to build a small set of\nnumbers modulo a prime p such that at least one element of this set is a\ngenerator of $\\pF{p}$\\cite{Bach:1997:sppr,Itoh:2001:PPR}. E. Bach suggests also\nthat at least half of his set should be generators. We show here that a slight\nvariant of this set can indeed be made to contain a ratio of primitive roots as\nclose to 1 as necessary. We thus derive several algorithms computing primitive\nroots correct with very high probability in polynomial time. In particular we\npresent an asymptotically $O^{\\sim}(\\sqrt{\\frac{1}{\\epsilon}}log^1.5(p) +\n\\log^2(p))$ algorithm providing primitive roots of $p$ with probability of\ncorrectness greater than $1-\\epsilon$ and several $O(log^\\alpha(p))$, $\\alpha\n\\leq 5.23$ algorithms computing \"Industrial-strength\" primitive roots with\nprobabilities e.g. greater than the probability of \"hardware malfunctions\"."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0502015v1", 
    "title": "Can Computer Algebra be Liberated from its Algebraic Yoke ?", 
    "arxiv-id": "cs/0502015v1", 
    "author": "R. Barrere", 
    "publish": "2005-02-03T17:28:01Z", 
    "summary": "So far, the scope of computer algebra has been needlessly restricted to exact\nalgebraic methods. Its possible extension to approximate analytical methods is\ndiscussed. The entangled roles of functional analysis and symbolic programming,\nespecially the functional and transformational paradigms, are put forward. In\nthe future, algebraic algorithms could constitute the core of extended symbolic\nmanipulation systems including primitives for symbolic approximations."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0502044v1", 
    "title": "The complexity of computing the Hilbert polynomial of smooth   equidimensional complex projective varieties", 
    "arxiv-id": "cs/0502044v1", 
    "author": "Martin Lotz", 
    "publish": "2005-02-08T17:10:00Z", 
    "summary": "We continue the study of counting complexity begun in [Buergisser, Cucker 04]\nand [Buergisser, Cucker, Lotz 05] by proving upper and lower bounds on the\ncomplexity of computing the Hilbert polynomial of a homogeneous ideal. We show\nthat the problem of computing the Hilbert polynomial of a smooth\nequidimensional complex projective variety can be reduced in polynomial time to\nthe problem of counting the number of complex common zeros of a finite set of\nmultivariate polynomials. Moreover, we prove that the more general problem of\ncomputing the Hilbert polynomial of a homogeneous ideal is polynomial space\nhard. This implies polynomial space lower bounds for both the problems of\ncomputing the rank and the Euler characteristic of cohomology groups of\ncoherent sheaves on projective space, improving the #P-lower bound of Bach (JSC\n1999)."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0505030v1", 
    "title": "Computing the Rank and a Small Nullspace Basis of a Polynomial Matrix", 
    "arxiv-id": "cs/0505030v1", 
    "author": "Gilles Villard", 
    "publish": "2005-05-11T18:29:00Z", 
    "summary": "We reduce the problem of computing the rank and a nullspace basis of a\nunivariate polynomial matrix to polynomial matrix multiplication. For an input\nn x n matrix of degree d over a field K we give a rank and nullspace algorithm\nusing about the same number of operations as for multiplying two matrices of\ndimension n and degree d. If the latter multiplication is done in\nMM(n,d)=softO(n^omega d) operations, with omega the exponent of matrix\nmultiplication over K, then the algorithm uses softO(MM(n,d)) operations in K.\nThe softO notation indicates some missing logarithmic factors. The method is\nrandomized with Las Vegas certification. We achieve our results in part through\na combination of matrix Hensel high-order lifting and matrix minimal fraction\nreconstruction, and through the computation of minimal or small degree vectors\nin the nullspace seen as a K[x]-module"
},{
    "category": "cs.SC", 
    "doi": "10.1145/1182613.1182619", 
    "link": "http://arxiv.org/pdf/cs/0508113v1", 
    "title": "Asymptotically fast polynomial matrix algorithms for multivariable   systems", 
    "arxiv-id": "cs/0508113v1", 
    "author": "Gilles Villard", 
    "publish": "2005-08-25T13:52:56Z", 
    "summary": "We present the asymptotically fastest known algorithms for some basic\nproblems on univariate polynomial matrices: rank, nullspace, determinant,\ngeneric inverse, reduced form. We show that they essentially can be reduced to\ntwo computer algebra techniques, minimal basis computations and matrix fraction\nexpansion/reconstruction, and to polynomial matrix multiplication. Such\nreductions eventually imply that all these problems can be solved in about the\nsame amount of time as polynomial matrix multiplication."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.171", 
    "link": "http://arxiv.org/pdf/cs/0509070v2", 
    "title": "A Maple Package for Computing Groebner Bases for Linear Recurrence   Relations", 
    "arxiv-id": "cs/0509070v2", 
    "author": "Daniel Robertz", 
    "publish": "2005-09-22T15:45:35Z", 
    "summary": "A Maple package for computing Groebner bases of linear difference ideals is\ndescribed. The underlying algorithm is based on Janet and Janet-like monomial\ndivisions associated with finite difference operators. The package can be used,\nfor example, for automatic generation of difference schemes for linear partial\ndifferential equations and for reduction of multiloop Feynman integrals. These\ntwo possible applications are illustrated by simple examples of the Laplace\nequation and a one-loop scalar integral of propagator type"
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.171", 
    "link": "http://arxiv.org/pdf/cs/0510014v4", 
    "title": "Computing the Kalman form", 
    "arxiv-id": "cs/0510014v4", 
    "author": "Gilles Villard", 
    "publish": "2005-10-05T14:16:15Z", 
    "summary": "We present two algorithms for the computation of the Kalman form of a linear\ncontrol system. The first one is based on the technique developed by\nKeller-Gehrig for the computation of the characteristic polynomial. The cost is\na logarithmic number of matrix multiplications. To our knowledge, this improves\nthe best previously known algebraic complexity by an order of magnitude. Then\nwe also present a cubic algorithm proven to more efficient in practice."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nima.2005.11.171", 
    "link": "http://arxiv.org/pdf/cs/0512072v1", 
    "title": "Computations with one and two real algebraic numbers", 
    "arxiv-id": "cs/0512072v1", 
    "author": "Elias P. Tsigaridas", 
    "publish": "2005-12-18T16:58:35Z", 
    "summary": "We present algorithmic and complexity results concerning computations with\none and two real algebraic numbers, as well as real solving of univariate\npolynomials and bivariate polynomial systems with integer coefficients using\nSturm-Habicht sequences.\n  Our main results, in the univariate case, concern the problems of real root\nisolation (Th. 19) and simultaneous inequalities (Cor.26) and in the bivariate,\nthe problems of system real solving (Th.42), sign evaluation (Th. 37) and\nsimultaneous inequalities (Cor. 43)."
},{
    "category": "cs.PL", 
    "doi": "10.1016/j.nima.2005.11.171", 
    "link": "http://arxiv.org/pdf/cs/0602008v1", 
    "title": "Demand Analysis with Partial Predicates", 
    "arxiv-id": "cs/0602008v1", 
    "author": "Juan Jose Moreno-Navarro", 
    "publish": "2006-02-04T20:22:34Z", 
    "summary": "In order to alleviate the inefficiencies caused by the interaction of the\nlogic and functional sides, integrated languages may take advantage of\n\\emph{demand} information -- i.e. knowing in advance which computations are\nneeded and, to which extent, in a particular context. This work studies\n\\emph{demand analysis} -- which is closely related to \\emph{backwards\nstrictness analysis} -- in a semantic framework of \\emph{partial predicates},\nwhich in turn are constructive realizations of ideals in a domain. This will\nallow us to give a concise, unified presentation of demand analysis, to relate\nit to other analyses based on abstract interpretation or strictness logics,\nsome hints for the implementation, and, more important, to prove the soundness\nof our analysis based on \\emph{demand equations}. There are also some\ninnovative results. One of them is that a set constraint-based analysis has\nbeen derived in a stepwise manner using ideas taken from the area of program\ntransformation. The other one is the possibility of using program\ntransformation itself to perform the analysis, specially in those domains of\nproperties where algorithms based on constraint solving are too weak."
},{
    "category": "cs.SC", 
    "doi": "10.2178/jsl/1230396909", 
    "link": "http://arxiv.org/pdf/cs/0603063v3", 
    "title": "Unary Primitive Recursive Functions", 
    "arxiv-id": "cs/0603063v3", 
    "author": "Daniel E. Severin", 
    "publish": "2006-03-16T17:20:25Z", 
    "summary": "In this article, we study some new characterizations of primitive recursive\nfunctions based on restricted forms of primitive recursion, improving the\npioneering work of R. M. Robinson and M. D. Gladstone in this area. We reduce\ncertain recursion schemes (mixed/pure iteration without parameters) and we\ncharacterize one-argument primitive recursive functions as the closure under\nsubstitution and iteration of certain optimal sets."
},{
    "category": "cs.LO", 
    "doi": "10.2178/jsl/1230396909", 
    "link": "http://arxiv.org/pdf/cs/0603071v1", 
    "title": "An Explicit Solution to Post's Problem over the Reals", 
    "arxiv-id": "cs/0603071v1", 
    "author": "Martin Ziegler", 
    "publish": "2006-03-17T16:12:23Z", 
    "summary": "In the BCSS model of real number computations we prove a concrete and\nexplicit semi-decidable language to be undecidable yet not reducible from (and\nthus strictly easier than) the real Halting Language. This solution to Post's\nProblem over the reals significantly differs from its classical, discrete\nvariant where advanced diagonalization techniques are only known to yield the\nexistence of such intermediate Turing degrees. Strengthening the above result,\nwe construct (that is, obtain again explicitly) as well an uncountable number\nof incomparable semi-decidable Turing degrees below the real Halting problem in\nthe BCSS model. Finally we show the same to hold for the linear BCSS model,\nthat is over (R,+,-,<) rather than (R,+,-,*,/,<)."
},{
    "category": "cs.PF", 
    "doi": "10.2178/jsl/1230396909", 
    "link": "http://arxiv.org/pdf/cs/0603099v1", 
    "title": "Benchmark Problems for Constraint Solving", 
    "arxiv-id": "cs/0603099v1", 
    "author": "Tudor Muresan", 
    "publish": "2006-03-26T20:19:59Z", 
    "summary": "Constraint Programming is roughly a new software technology introduced by\nJaffar and Lassez in 1987 for description and effective solving of large,\nparticularly combinatorial, problems especially in areas of planning and\nscheduling. In the following we define three problems for constraint solving\nfrom the domain of electrical networks; based on them we define 43 related\nproblems. For the defined set of problems we benchmarked five systems: ILOG\nOPL, AMPL, GAMS, Mathematica and UniCalc. As expected some of the systems\nperformed very well for some problems while others performed very well on\nothers."
},{
    "category": "cs.LO", 
    "doi": "10.2178/jsl/1230396909", 
    "link": "http://arxiv.org/pdf/cs/0604032v3", 
    "title": "Real Computational Universality: The Word Problem for a class of groups   with infinite presentation", 
    "arxiv-id": "cs/0604032v3", 
    "author": "Klaus Meer", 
    "publish": "2006-04-07T23:57:46Z", 
    "summary": "The word problem for discrete groups is well-known to be undecidable by a\nTuring Machine; more precisely, it is reducible both to and from and thus\nequivalent to the discrete Halting Problem.\n  The present work introduces and studies a real extension of the word problem\nfor a certain class of groups which are presented as quotient groups of a free\ngroup and a normal subgroup. Most important, the free group will be generated\nby an uncountable set of generators with index running over certain sets of\nreal numbers. This allows to include many mathematically important groups which\nare not captured in the framework of the classical word problem.\n  Our contribution extends computational group theory from the discrete to the\nBlum-Shub-Smale (BSS) model of real number computation. We believe this to be\nan interesting step towards applying BSS theory, in addition to semi-algebraic\ngeometry, also to further areas of mathematics.\n  The main result establishes the word problem for such groups to be not only\nsemi-decidable (and thus reducible FROM) but also reducible TO the Halting\nProblem for such machines. It thus provides the first non-trivial example of a\nproblem COMPLETE, that is, computationally universal for this model."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2006.11.007", 
    "link": "http://arxiv.org/pdf/cs/0604052v2", 
    "title": "Extension of the functionality of the symbolic program FORM by external   software", 
    "arxiv-id": "cs/0604052v2", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2006-04-12T16:03:03Z", 
    "summary": "We describe the implementation of facilities for the communication with\nexternal resources in the Symbolic Manipulation System FORM. This is done\naccording to the POSIX standards defined for the UNIX operating system. We\npresent a number of examples that illustrate the increased power due to these\nnew capabilities."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2006.11.007", 
    "link": "http://arxiv.org/pdf/cs/0604084v1", 
    "title": "A Recursive Method for Determining the One-Dimensional Submodules of   Laurent-Ore Modules", 
    "arxiv-id": "cs/0604084v1", 
    "author": "Dabin Zheng", 
    "publish": "2006-04-21T16:04:40Z", 
    "summary": "We present a method for determining the one-dimensional submodules of a\nLaurent-Ore module. The method is based on a correspondence between\nhyperexponential solutions of associated systems and one-dimensional\nsubmodules. The hyperexponential solutions are computed recursively by solving\na sequence of first-order ordinary matrix equations. As the recursion proceeds,\nthe matrix equations will have constant coefficients with respect to the\noperators that have been considered."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2006.11.007", 
    "link": "http://arxiv.org/pdf/cs/0605082v1", 
    "title": "Efficient algorithm for computing the Euler-Poincar\u00e9 characteristic of   a semi-algebraic set defined by few quadratic inequalities", 
    "arxiv-id": "cs/0605082v1", 
    "author": "Saugata Basu", 
    "publish": "2006-05-18T18:03:29Z", 
    "summary": "We present an algorithm which takes as input a closed semi-algebraic set, $S\n\\subset \\R^k$, defined by \\[ P_1 \\leq 0, ..., P_\\ell \\leq 0, P_i \\in\n\\R[X_1,...,X_k], \\deg(P_i) \\leq 2, \\] and computes the Euler-Poincar\\'e\ncharacteristic of $S$. The complexity of the algorithm is $k^{O(\\ell)}$."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0606091v1", 
    "title": "On computing fixpoints in well-structured regular model checking, with   applications to lossy channel systems", 
    "arxiv-id": "cs/0606091v1", 
    "author": "Ph. Schnoebelen", 
    "publish": "2006-06-21T15:49:13Z", 
    "summary": "We prove a general finite convergence theorem for \"upward-guarded\" fixpoint\nexpressions over a well-quasi-ordered set. This has immediate applications in\nregular model checking of well-structured systems, where a main issue is the\neventual convergence of fixpoint computations. In particular, we are able to\ndirectly obtain several new decidability results on lossy channel systems."
},{
    "category": "cs.PL", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0608016v1", 
    "title": "ACD Term Rewriting", 
    "arxiv-id": "cs/0608016v1", 
    "author": "Sebastian Brand", 
    "publish": "2006-08-03T02:55:16Z", 
    "summary": "We introduce Associative Commutative Distributive Term Rewriting (ACDTR), a\nrewriting language for rewriting logical formulae. ACDTR extends AC term\nrewriting by adding distribution of conjunction over other operators.\nConjunction is vital for expressive term rewriting systems since it allows us\nto require that multiple conditions hold for a term rewriting rule to be used.\nACDTR uses the notion of a \"conjunctive context\", which is the conjunction of\nconstraints that must hold in the context of a term, to enable the programmer\nto write very expressive and targeted rewriting rules. ACDTR can be seen as a\ngeneral logic programming language that extends Constraint Handling Rules and\nAC term rewriting. In this paper we define the semantics of ACDTR and describe\nour prototype implementation."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0608032v2", 
    "title": "Satisfying KBO Constraints", 
    "arxiv-id": "cs/0608032v2", 
    "author": "Aart Middeldorp", 
    "publish": "2006-08-06T12:42:31Z", 
    "summary": "This paper presents two new approaches to prove termination of rewrite\nsystems with the Knuth-Bendix order efficiently. The constraints for the weight\nfunction and for the precedence are encoded in (pseudo-)propositional logic and\nthe resulting formula is tested for satisfiability. Any satisfying assignment\nrepresents a weight function and a precedence such that the induced\nKnuth-Bendix order orients the rules of the encoded rewrite system from left to\nright."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0608064v2", 
    "title": "A linear algebra approach to the differentiation index of generic DAE   systems", 
    "arxiv-id": "cs/0608064v2", 
    "author": "Pablo Solerno", 
    "publish": "2006-08-15T21:57:24Z", 
    "summary": "The notion of differentiation index for DAE systems of arbitrary order with\ngeneric second members is discussed by means of the study of the behavior of\nthe ranks of certain Jacobian associated sub-matrices. As a by-product, we\nobtain upper bounds for the regularity of the Hilbert-Kolchin function and the\norder of the ideal associated to the DAE systems under consideration, not\ndepending on characteristic sets. Some quantitative and algorithmic results\nconcerning differential transcendence bases and induced equivalent explicit ODE\nsystems are also established."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0609075v2", 
    "title": "On factorization and solution of multidimensional linear partial   differential equations", 
    "arxiv-id": "cs/0609075v2", 
    "author": "S. P. Tsarev", 
    "publish": "2006-09-13T13:28:18Z", 
    "summary": "We describe a method of obtaining closed-form complete solutions of certain\nsecond-order linear partial differential equations with more than two\nindependent variables. This method generalizes the classical method of Laplace\ntransformations of second-order hyperbolic equations in the plane and is based\non an idea given by Ulisse Dini in 1902."
},{
    "category": "cs.CG", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0701121v1", 
    "title": "Signature Sequence of Intersection Curve of Two Quadrics for Exact   Morphological Classification", 
    "arxiv-id": "cs/0701121v1", 
    "author": "Jiaye Wang", 
    "publish": "2007-01-19T08:08:24Z", 
    "summary": "We present an efficient method for classifying the morphology of the\nintersection curve of two quadrics (QSIC) in PR3, 3D real projective space;\nhere, the term morphology is used in a broad sense to mean the shape,\ntopological, and algebraic properties of a QSIC, including singularity,\nreducibility, the number of connected components, and the degree of each\nirreducible component, etc. There are in total 35 different QSIC morphologies\nwith non-degenerate quadric pencils. For each of these 35 QSIC morphologies,\nthrough a detailed study of the eigenvalue curve and the index function jump we\nestablish a characterizing algebraic condition expressed in terms of the Segre\ncharacteristics and the signature sequence of a quadric pencil. We show how to\ncompute a signature sequence with rational arithmetic so as to determine the\nmorphology of the intersection curve of any two given quadrics. Two immediate\napplications of our results are the robust topological classification of QSIC\nin computing B-rep surface representation in solid modeling and the derivation\nof algebraic conditions for collision detection of quadric primitives."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0701183v1", 
    "title": "Certification of the QR factor R, and of lattice basis reducedness", 
    "arxiv-id": "cs/0701183v1", 
    "author": "Gilles Villard", 
    "publish": "2007-01-29T09:15:35Z", 
    "summary": "Given a lattice basis of n vectors in Z^n, we propose an algorithm using\n12n^3+O(n^2) floating point operations for checking whether the basis is\nLLL-reduced. If the basis is reduced then the algorithm will hopefully answer\n''yes''. If the basis is not reduced, or if the precision used is not\nsufficient with respect to n, and to the numerical properties of the basis, the\nalgorithm will answer ''failed''. Hence a positive answer is a rigorous\ncertificate. For implementing the certificate itself, we propose a floating\npoint algorithm for computing (certified) error bounds for the entries of the R\nfactor of the QR matrix factorization. This algorithm takes into account all\npossible approximation and rounding errors. The cost 12n^3+O(n^2) of the\ncertificate is only six times more than the cost of numerical algorithms for\ncomputing the QR factorization itself, and the certificate may be implemented\nusing matrix library routines only. We report experiments that show that for a\nreduced basis of adequate dimension and quality the certificate succeeds, and\nestablish the effectiveness of the certificate. This effectiveness is applied\nfor certifying the output of fastest existing floating point heuristics of LLL\nreduction, without slowing down the whole process."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0701188v1", 
    "title": "Faster Inversion and Other Black Box Matrix Computations Using Efficient   Block Projections", 
    "arxiv-id": "cs/0701188v1", 
    "author": "Gilles Villard", 
    "publish": "2007-01-29T18:20:30Z", 
    "summary": "Block projections have been used, in [Eberly et al. 2006], to obtain an\nefficient algorithm to find solutions for sparse systems of linear equations. A\nbound of softO(n^(2.5)) machine operations is obtained assuming that the input\nmatrix can be multiplied by a vector with constant-sized entries in softO(n)\nmachine operations. Unfortunately, the correctness of this algorithm depends on\nthe existence of efficient block projections, and this has been conjectured. In\nthis paper we establish the correctness of the algorithm from [Eberly et al.\n2006] by proving the existence of efficient block projections over sufficiently\nlarge fields. We demonstrate the usefulness of these projections by deriving\nimproved bounds for the cost of several matrix problems, considering, in\nparticular, ``sparse'' matrices that can be be multiplied by a vector using\nsoftO(n) field operations. We show how to compute the inverse of a sparse\nmatrix over a field F using an expected number of softO(n^(2.27)) operations in\nF. A basis for the null space of a sparse matrix, and a certification of its\nrank, are obtained at the same cost. An application to Kaltofen and Villard's\nBaby-Steps/Giant-Steps algorithms for the determinant and Smith Form of an\ninteger matrix yields algorithms requiring softO(n^(2.66)) machine operations.\nThe derived algorithms are all probabilistic of the Las Vegas type."
},{
    "category": "cs.SC", 
    "doi": "10.1007/11916277_24", 
    "link": "http://arxiv.org/pdf/cs/0702010v1", 
    "title": "A canonical form for some piecewise defined functions", 
    "arxiv-id": "cs/0702010v1", 
    "author": "Jacques Carette", 
    "publish": "2007-02-01T17:54:50Z", 
    "summary": "We define a canonical form for piecewise defined functions. We show that this\nhas a wider range of application as well as better complexity properties than\nprevious work."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1277548.1277553", 
    "link": "http://arxiv.org/pdf/cs/0703121v2", 
    "title": "Differential Equations for Algebraic Functions", 
    "arxiv-id": "cs/0703121v2", 
    "author": "\u00c9ric Schost", 
    "publish": "2007-03-23T19:20:35Z", 
    "summary": "It is classical that univariate algebraic functions satisfy linear\ndifferential equations with polynomial coefficients. Linear recurrences follow\nfor the coefficients of their power series expansions. We show that the linear\ndifferential equation of minimal order has coefficients whose degree is cubic\nin the degree of the function. We also show that there exists a linear\ndifferential equation of order linear in the degree whose coefficients are only\nof quadratic degree. Furthermore, we prove the existence of recurrences of\norder and degree close to optimal. We study the complexity of computing these\ndifferential equations and recurrences. We deduce a fast algorithm for the\nexpansion of algebraic series."
},{
    "category": "hep-ph", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/hep-ph/0702279v1", 
    "title": "The Multithreaded version of FORM", 
    "arxiv-id": "hep-ph/0702279v1", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2007-02-27T16:35:00Z", 
    "summary": "We present TFORM, the version of the symbolic manipulation system FORM that\ncan make simultaneous use of several processors in a shared memory\narchitecture. The implementation uses Posix threads, also called pthreads, and\nis therefore easily portable between various operating systems. Most existing\nFORM programs will be able to take advantage of the increased processing power,\nwithout the need for modifications. In some cases some minor additions may be\nneeded. For a computer with two processors a typical improvement factor in the\nrunning time is 1.7 when compared to the traditional version of FORM. In the\ncase of computers with 4 processors a typical improvement factor in the\nexecution time is slightly above 3."
},{
    "category": "hep-th", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/hep-th/0305176v1", 
    "title": "Mapping the vacuum structure of gauged maximal supergravities: an   application of high-performance symbolic algebra", 
    "arxiv-id": "hep-th/0305176v1", 
    "author": "Thomas Fischbacher", 
    "publish": "2003-05-20T13:42:15Z", 
    "summary": "The analysis of the extremal structure of the scalar potentials of gauged\nmaximally extended supergravity models in five, four, and three dimensions, and\nhence the determination of possible vacuum states of these models is a\ncomputationally challenging task due to the occurrence of the exceptional Lie\ngroups $E_6$, $E_7$, $E_8$ in the definition of these potentials. At present,\nthe most promising approach to gain information about nontrivial vacua of these\nmodels is to perform a truncation of the potential to submanifolds of the $G/H$\ncoset manifold of scalars which are invariant under a subgroup of the gauge\ngroup and of sufficiently low dimension to make an analytic treatment possible.\n  New tools are presented which allow a systematic and highly effective study\nof these potentials up to a previously unreached level of complexity. Explicit\nforms of new truncations of the potentials of four- and three-dimensional\nmodels are given, and for N=16, D=3 supergravities, which are much more rich in\nstructure than their higher-dimensional cousins, a series of new nontrivial\nvacua is identified and analysed."
},{
    "category": "math.GR", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/math/0304305v1", 
    "title": "Balanced presentations of the trivial group on two generators and the   Andrews-Curtis conjecture", 
    "arxiv-id": "math/0304305v1", 
    "author": "Alexei G. Myasnikov", 
    "publish": "2003-04-21T21:01:49Z", 
    "summary": "The Andrews-Curtis conjecture states that every balanced presentation of the\ntrivial group can be reduced to the standard one by a sequence of the\nelementary Nielsen transformations and conjugations. In this paper we describe\nall balanced presentations of the trivial group on two generators and with the\ntotal length of relators <= 12. We show that all these presentations satisfy\nthe Andrews-Curtis conjecture."
},{
    "category": "math.OC", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/math/0502172v3", 
    "title": "An hybrid system approach to nonlinear optimal control problems", 
    "arxiv-id": "math/0502172v3", 
    "author": "Aude Rondepierre", 
    "publish": "2005-02-08T20:49:45Z", 
    "summary": "We consider a nonlinear ordinary differential equation and want to control\nits behavior so that it reaches a target by minimizing a cost function. Our\napproach is to use hybrid systems to solve this problem: the complex dynamic is\nreplaced by piecewise affine approximations which allow an analytical\nresolution. The sequence of affine models then forms a sequence of states of a\nhybrid automaton. Given a sequence of states, we introduce an hybrid\napproximation of the nonlinear controllable domain and propose a new algorithm\ncomputing a controllable, piecewise convex approximation. The same way the\nnonlinear optimal control problem is replaced by an hybrid piecewise affine\none. Stating a hybrid maximum principle suitable to our hybrid model, we deduce\nthe global structure of the hybrid optimal control steering the system to the\ntarget."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/math/0603263v1", 
    "title": "Computing the First Few Betti Numbers of Semi-algebraic Sets in Single   Exponential Time", 
    "arxiv-id": "math/0603263v1", 
    "author": "Saugata Basu", 
    "publish": "2006-03-10T21:32:18Z", 
    "summary": "In this paper we describe an algorithm that takes as input a description of a\nsemi-algebraic set $S \\subset \\R^k$, defined by a Boolean formula with atoms of\nthe form $P > 0, P < 0, P=0$ for $P \\in {\\mathcal P} \\subset \\R[X_1,...,X_k],$\nand outputs the first $\\ell+1$ Betti numbers of $S$, $b_0(S),...,b_\\ell(S).$\nThe complexity of the algorithm is $(sd)^{k^{O(\\ell)}},$ where where $s =\n#({\\mathcal P})$ and $d = \\max_{P\\in {\\mathcal P}}{\\rm deg}(P),$ which is\nsingly exponential in $k$ for $\\ell$ any fixed constant. Previously, singly\nexponential time algorithms were known only for computing the Euler-Poincar\\'e\ncharacteristic, the zero-th and the first Betti numbers."
},{
    "category": "math.CO", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/math/0609360v3", 
    "title": "Minimal Polynomials for the Coordinates of the Harborth Graph", 
    "arxiv-id": "math/0609360v3", 
    "author": "Eberhard H. -A. Gerbracht", 
    "publish": "2006-09-13T17:27:55Z", 
    "summary": "The Harborth graph is the smallest known example of a 4-regular planar\nunit-distance graph. In this paper we give an analytical description of the\ncoordinates of its vertices for a particular embedding in the Euclidean plane.\nMore precisely, we show, how to calculate the minimal polynomials of the\ncoordinates of its vertices (with the help of a computer algebra system), and\nlist those. Furthermore some algebraic properties of these polynomials, and\nconsequences to the structure of the Harborth graph are determined."
},{
    "category": "nlin.SI", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/nlin/0605009v3", 
    "title": "Sufficient set of integrability conditions of an orthonomic system", 
    "arxiv-id": "nlin/0605009v3", 
    "author": "M. Marvan", 
    "publish": "2006-05-03T18:51:52Z", 
    "summary": "Every orthonomic system of partial differential equations is known to possess\na finite number of integrability conditions sufficient to ensure the validity\nof all. Herewith we offer an efficient algorithm to construct a sufficient set\nof integrability conditions free of redundancies."
},{
    "category": "cs.LG", 
    "doi": "10.1016/j.cpc.2010.04.009", 
    "link": "http://arxiv.org/pdf/0704.1020v1", 
    "title": "The on-line shortest path problem under partial monitoring", 
    "arxiv-id": "0704.1020v1", 
    "author": "Gyorgy Ottucsak", 
    "publish": "2007-04-08T10:15:54Z", 
    "summary": "The on-line shortest path problem is considered under various models of\npartial monitoring. Given a weighted directed acyclic graph whose edge weights\ncan change in an arbitrary (adversarial) way, a decision maker has to choose in\neach round of a game a path between two distinguished vertices such that the\nloss of the chosen path (defined as the sum of the weights of its composing\nedges) be as small as possible. In a setting generalizing the multi-armed\nbandit problem, after choosing a path, the decision maker learns only the\nweights of those edges that belong to the chosen path. For this problem, an\nalgorithm is given whose average cumulative loss in n rounds exceeds that of\nthe best path, matched off-line to the entire sequence of the edge weights, by\na quantity that is proportional to 1/\\sqrt{n} and depends only polynomially on\nthe number of edges of the graph. The algorithm can be implemented with linear\ncomplexity in the number of rounds n and in the number of edges. An extension\nto the so-called label efficient setting is also given, in which the decision\nmaker is informed about the weights of the edges corresponding to the chosen\npath at a total of m << n time instances. Another extension is shown where the\ndecision maker competes against a time-varying path, a generalization of the\nproblem of tracking the best expert. A version of the multi-armed bandit\nsetting for shortest path is also discussed where the decision maker learns\nonly the total weight of the chosen path but not the weights of the individual\nedges on the path. Applications to routing in packet switched networks along\nwith simulation results are also presented."
},{
    "category": "cs.SC", 
    "doi": "10.1080/10586458.2008.10129032", 
    "link": "http://arxiv.org/pdf/0706.1409v2", 
    "title": "A Proof of a Recursion for Bessel Moments", 
    "arxiv-id": "0706.1409v2", 
    "author": "Bruno Salvy", 
    "publish": "2007-06-11T06:45:39Z", 
    "summary": "We provide a proof of a conjecture in (Bailey, Borwein, Borwein, Crandall\n2007) on the existence and form of linear recursions for moments of powers of\nthe Bessel function $K_0$."
},{
    "category": "math.CA", 
    "doi": "10.1080/10586458.2008.10129032", 
    "link": "http://arxiv.org/pdf/0709.2935v1", 
    "title": "An Extension to an Algebraic Method for Linear Time-Invariant System and   Network Theory: The full AC-Calculus", 
    "arxiv-id": "0709.2935v1", 
    "author": "Eberhard H. -A. Gerbracht", 
    "publish": "2007-09-19T00:17:40Z", 
    "summary": "Being inspired by phasor analysis in linear circuit theory, and its algebraic\ncounterpart - the AC-(operational)-calculus for sinusoids developed by W.\nMarten and W. Mathis - we define a complex structure on several spaces of\nreal-valued elementary functions. This is used to algebraize inhomogeneous\nlinear ordinary differential equations with inhomogenities stemming from these\nspaces. Thus we deduce an effective method to calculate particular solutions of\nthese ODEs in a purely algebraic way."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0710.4318v4", 
    "title": "Differential invariants of a Lie group action: syzygies on a generating   set", 
    "arxiv-id": "0710.4318v4", 
    "author": "Evelyne Hubert", 
    "publish": "2007-10-23T19:20:10Z", 
    "summary": "Given a group action, known by its infinitesimal generators, we exhibit a\ncomplete set of syzygies on a generating set of differential invariants. For\nthat we elaborate on the reinterpretation of Cartan's moving frame by Fels and\nOlver (1999). This provides constructive tools for exploring algebras of\ndifferential invariants."
},{
    "category": "cs.PL", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0711.0917v1", 
    "title": "SWI-Prolog and the Web", 
    "arxiv-id": "0711.0917v1", 
    "author": "Lourens van der Meij", 
    "publish": "2007-11-06T16:22:39Z", 
    "summary": "Where Prolog is commonly seen as a component in a Web application that is\neither embedded or communicates using a proprietary protocol, we propose an\narchitecture where Prolog communicates to other components in a Web application\nusing the standard HTTP protocol. By avoiding embedding in external Web servers\ndevelopment and deployment become much easier. To support this architecture, in\naddition to the transfer protocol, we must also support parsing, representing\nand generating the key Web document types such as HTML, XML and RDF.\n  This paper motivates the design decisions in the libraries and extensions to\nProlog for handling Web documents and protocols. The design has been guided by\nthe requirement to handle large documents efficiently. The described libraries\nsupport a wide range of Web applications ranging from HTML and XML documents to\nSemantic Web RDF processing.\n  To appear in Theory and Practice of Logic Programming (TPLP)"
},{
    "category": "math.RA", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0712.0917v1", 
    "title": "Some properties of finite meadows", 
    "arxiv-id": "0712.0917v1", 
    "author": "Piet Rodenburg", 
    "publish": "2007-12-06T11:27:44Z", 
    "summary": "The aim of this note is to describe the structure of finite meadows. We will\nshow that the class of finite meadows is the closure of the class of finite\nfields under finite products. As a corollary, we obtain a unique representation\nof minimal meadows in terms of prime fields."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0712.4046v1", 
    "title": "Faster polynomial multiplication via multipoint Kronecker substitution", 
    "arxiv-id": "0712.4046v1", 
    "author": "David Harvey", 
    "publish": "2007-12-25T04:57:04Z", 
    "summary": "We give several new algorithms for dense polynomial multiplication based on\nthe Kronecker substitution method. For moderately sized input polynomials, the\nnew algorithms improve on the performance of the standard Kronecker\nsubstitution by a sizeable constant, both in theory and in empirical tests."
},{
    "category": "math.CA", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0712.4124v2", 
    "title": "Introduction to the Galois Theory of Linear Differential Equations", 
    "arxiv-id": "0712.4124v2", 
    "author": "Michael F. Singer", 
    "publish": "2007-12-26T02:40:19Z", 
    "summary": "This is an expanded version of the 10 lectures given as the 2006 London\nMathematical Society Invited Lecture Series at the Heriot-Watt University 31\nJuly - 4 August 2006."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0801.1416v3", 
    "title": "Fast Integer Multiplication using Modular Arithmetic", 
    "arxiv-id": "0801.1416v3", 
    "author": "Ramprasad Saptharishi", 
    "publish": "2008-01-09T12:44:55Z", 
    "summary": "We give an $O(N\\cdot \\log N\\cdot 2^{O(\\log^*N)})$ algorithm for multiplying\ntwo $N$-bit integers that improves the $O(N\\cdot \\log N\\cdot \\log\\log N)$\nalgorithm by Sch\\\"{o}nhage-Strassen. Both these algorithms use modular\narithmetic. Recently, F\\\"{u}rer gave an $O(N\\cdot \\log N\\cdot 2^{O(\\log^*N)})$\nalgorithm which however uses arithmetic over complex numbers as opposed to\nmodular arithmetic. In this paper, we use multivariate polynomial\nmultiplication along with ideas from F\\\"{u}rer's algorithm to achieve this\nimprovement in the modular setting. Our algorithm can also be viewed as a\n$p$-adic version of F\\\"{u}rer's algorithm. Thus, we show that the two seemingly\ndifferent approaches to integer multiplication, modular and complex arithmetic,\nare similar."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jsc.2008.08.003", 
    "link": "http://arxiv.org/pdf/0802.2027v2", 
    "title": "Kolmogorov Complexity Theory over the Reals", 
    "arxiv-id": "0802.2027v2", 
    "author": "Wouter M. Koolen", 
    "publish": "2008-02-14T18:30:55Z", 
    "summary": "Kolmogorov Complexity constitutes an integral part of computability theory,\ninformation theory, and computational complexity theory -- in the discrete\nsetting of bits and Turing machines. Over real numbers, on the other hand, the\nBSS-machine (aka real-RAM) has been established as a major model of\ncomputation. This real realm has turned out to exhibit natural counterparts to\nmany notions and results in classical complexity and recursion theory; although\nusually with considerably different proofs. The present work investigates\nsimilarities and differences between discrete and real Kolmogorov Complexity as\nintroduced by Montana and Pardo (1998)."
},{
    "category": "cs.SE", 
    "doi": "10.1109/ENC.2005.52", 
    "link": "http://arxiv.org/pdf/0802.2258v1", 
    "title": "Using Alloy to model-check visual design notations", 
    "arxiv-id": "0802.2258v1", 
    "author": "Carlos Alberto Fernandez-y-Fernandez", 
    "publish": "2008-02-15T18:25:50Z", 
    "summary": "This paper explores the process of validation for the abstract syntax of a\ngraphical notation. We define an unified specification for five of the UML\ndiagrams used by the Discovery Method and, in this document, we illustrate how\ndiagrams can be represented in Alloy and checked against our specification in\norder to know if these are valid under the Discovery notation."
},{
    "category": "cs.SC", 
    "doi": "10.1109/ENC.2005.52", 
    "link": "http://arxiv.org/pdf/0803.2319v1", 
    "title": "Two Algorithms for Solving A General Backward Pentadiagonal Linear   Systems", 
    "arxiv-id": "0803.2319v1", 
    "author": "A. A. Karawia", 
    "publish": "2008-03-15T20:04:18Z", 
    "summary": "In this paper we present an efficient computational and symbolic algorithms\nfor solving a backward pentadiagonal linear systems. The implementation of the\nalgorithms using Computer Algebra Systems (CAS) such as MAPLE, MACSYMA,\nMATHEMATICA, and MATLAB are straightforward. An examples are given in order to\nillustrate the algorithms. The symbolic algorithm is competitive the other\nmethods for solving a backward pentadiagonal linear systems."
},{
    "category": "cs.SC", 
    "doi": "10.1109/ENC.2005.52", 
    "link": "http://arxiv.org/pdf/0803.3435v1", 
    "title": "Twenty-Five Moves Suffice for Rubik's Cube", 
    "arxiv-id": "0803.3435v1", 
    "author": "Tomas Rokicki", 
    "publish": "2008-03-24T19:37:09Z", 
    "summary": "How many moves does it take to solve Rubik's Cube? Positions are known that\nrequire 20 moves, and it has already been shown that there are no positions\nthat require 27 or more moves; this is a surprisingly large gap. This paper\ndescribes a program that is able to find solutions of length 20 or less at a\nrate of more than 16 million positions a second. We use this program, along\nwith some new ideas and incremental improvements in other techniques, to show\nthat there is no position that requires 26 moves."
},{
    "category": "cs.AI", 
    "doi": "10.1109/ENC.2005.52", 
    "link": "http://arxiv.org/pdf/0803.3812v1", 
    "title": "Preferred extensions as stable models", 
    "arxiv-id": "0803.3812v1", 
    "author": "Ulises Cort\u00e9s", 
    "publish": "2008-03-26T20:08:31Z", 
    "summary": "Given an argumentation framework AF, we introduce a mapping function that\nconstructs a disjunctive logic program P, such that the preferred extensions of\nAF correspond to the stable models of P, after intersecting each stable model\nwith the relevant atoms. The given mapping function is of polynomial size\nw.r.t. AF. In particular, we identify that there is a direct relationship\nbetween the minimal models of a propositional formula and the preferred\nextensions of an argumentation framework by working on representing the\ndefeated arguments. Then we show how to infer the preferred extensions of an\nargumentation framework by using UNSAT algorithms and disjunctive stable model\nsolvers. The relevance of this result is that we define a direct relationship\nbetween one of the most satisfactory argumentation semantics and one of the\nmost successful approach of non-monotonic reasoning i.e., logic programming\nwith the stable model semantics."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.ffa.2005.08.004", 
    "link": "http://arxiv.org/pdf/0803.3976v2", 
    "title": "On Ritt's decomposition Theorem in the case of finite fields", 
    "arxiv-id": "0803.3976v2", 
    "author": "David Sevilla", 
    "publish": "2008-03-27T16:39:03Z", 
    "summary": "A classical theorem by Ritt states that all the complete decomposition chains\nof a univariate polynomial satisfying a certain tameness condition have the\nsame length. In this paper we present our conclusions about the generalization\nof these theorem in the case of finite coefficient fields when the tameness\ncondition is dropped."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.1021v1", 
    "title": "Differentiation of Kaltofen's division-free determinant algorithm", 
    "arxiv-id": "0804.1021v1", 
    "author": "Gilles Villard", 
    "publish": "2008-04-07T12:37:43Z", 
    "summary": "Kaltofen has proposed a new approach in [Kaltofen 1992] for computing matrix\ndeterminants. The algorithm is based on a baby steps/giant steps construction\nof Krylov subspaces, and computes the determinant as the constant term of a\ncharacteristic polynomial. For matrices over an abstract field and by the\nresults of Baur and Strassen 1983, the determinant algorithm, actually a\nstraight-line program, leads to an algorithm with the same complexity for\ncomputing the adjoint of a matrix [Kaltofen 1992]. However, the latter is\nobtained by the reverse mode of automatic differentiation and somehow is not\n``explicit''. We study this adjoint algorithm, show how it can be implemented\n(without resorting to an automatic transformation), and demonstrate its use on\npolynomial matrices."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.1649v1", 
    "title": "On decomposition of tame polynomials and rational functions", 
    "arxiv-id": "0804.1649v1", 
    "author": "David Sevilla", 
    "publish": "2008-04-10T09:31:04Z", 
    "summary": "In this paper we present algorithmic considerations and theoretical results\nabout the relation between the orders of certain groups associated to the\ncomponents of a polynomial and the order of the group that corresponds to the\npolynomial, proving it for arbitrary tame polynomials, and considering the case\nof rational functions."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.1679v1", 
    "title": "Computation of unirational fields", 
    "arxiv-id": "0804.1679v1", 
    "author": "David Sevilla", 
    "publish": "2008-04-10T11:59:15Z", 
    "summary": "One of the main contributions which Volker Weispfenning made to mathematics\nis related to Groebner bases theory. In this paper we present an algorithm for\ncomputing all algebraic intermediate subfields in a separably generated\nunirational field extension (which in particular includes the zero\ncharacteristic case). One of the main tools is Groebner bases theory. Our\nalgorithm also requires computing primitive elements and factoring over\nalgebraic extensions. Moreover, the method can be extended to finitely\ngenerated K-algebras."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.1687v1", 
    "title": "Building counterexamples to generalizations for rational functions of   Ritt's decomposition theorem", 
    "arxiv-id": "0804.1687v1", 
    "author": "David Sevilla", 
    "publish": "2008-04-10T12:42:16Z", 
    "summary": "The classical Ritt's Theorems state several properties of univariate\npolynomial decomposition. In this paper we present new counterexamples to\nRitt's first theorem, which states the equality of length of decomposition\nchains of a polynomial, in the case of rational functions. Namely, we provide\nan explicit example of a rational function with coefficients in Q and two\ndecompositions of different length.\n  Another aspect is the use of some techniques that could allow for other\ncounterexamples, namely, relating groups and decompositions and using the fact\nthat the alternating group A_4 has two subgroup chains of different lengths;\nand we provide more information about the generalizations of another property\nof polynomial decomposition: the stability of the base field. We also present\nan algorithm for computing the fixing group of a rational function providing\nthe complexity over Q."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.1707v1", 
    "title": "Computation of unirational fields (extended abstract)", 
    "arxiv-id": "0804.1707v1", 
    "author": "David Sevilla", 
    "publish": "2008-04-10T14:00:10Z", 
    "summary": "In this paper we present an algorithm for computing all algebraic\nintermediate subfields in a separably generated unirational field extension\n(which in particular includes the zero characteristic case). One of the main\ntools is Groebner bases theory. Our algorithm also requires computing computing\nprimitive elements and factoring over algebraic extensions. Moreover, the\nmethod can be extended to finitely generated K-algebras."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.1974v1", 
    "title": "Schemes for Deterministic Polynomial Factoring", 
    "arxiv-id": "0804.1974v1", 
    "author": "Nitin Saxena", 
    "publish": "2008-04-11T23:04:17Z", 
    "summary": "In this work we relate the deterministic complexity of factoring polynomials\n(over finite fields) to certain combinatorial objects we call m-schemes. We\nextend the known conditional deterministic subexponential time polynomial\nfactoring algorithm for finite fields to get an underlying m-scheme. We\ndemonstrate how the properties of m-schemes relate to improvements in the\ndeterministic complexity of factoring polynomials over finite fields assuming\nthe generalized Riemann Hypothesis (GRH). In particular, we give the first\ndeterministic polynomial time algorithm (assuming GRH) to find a nontrivial\nfactor of a polynomial of prime degree n where (n-1) is a smooth number."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.2992v1", 
    "title": "\"E pluribus unum\" or How to Derive Single-equation Descriptions for   Output-quantities in Nonlinear Circuits using Differential Algebra", 
    "arxiv-id": "0804.2992v1", 
    "author": "Eberhard H. -A. Gerbracht", 
    "publish": "2008-04-18T19:55:58Z", 
    "summary": "In this paper we describe by a number of examples how to deduce one single\ncharacterizing higher order differential equation for output quantities of an\nanalog circuit.\n  In the linear case, we apply basic \"symbolic\" methods from linear algebra to\nthe system of differential equations which is used to model the analog circuit.\nFor nonlinear circuits and their corresponding nonlinear differential\nequations, we show how to employ computer algebra tools implemented in Maple,\nwhich are based on differential algebra."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.3023v2", 
    "title": "Experiments in Model-Checking Optimistic Replication Algorithms", 
    "arxiv-id": "0804.3023v2", 
    "author": "Abdessamad Imine", 
    "publish": "2008-04-18T14:04:38Z", 
    "summary": "This paper describes a series of model-checking experiments to verify\noptimistic replication algorithms based on Operational Transformation (OT)\napproach used for supporting collaborative edition. We formally define, using\ntool UPPAAL, the behavior and the main consistency requirement (i.e.\nconvergence property) of the collaborative editing systems, as well as the\nabstract behavior of the environment where these systems are supposed to\noperate. Due to data replication and the unpredictable nature of user\ninteractions, such systems have infinitely many states. So, we show how to\nexploit some features of the UPPAAL specification language to attenuate the\nsevere state explosion problem. Two models are proposed. The first one, called\nconcrete model, is very close to the system implementation but runs up against\na severe explosion of states. The second model, called symbolic model, aims to\novercome the limitation of the concrete model by delaying the effective\nselection and execution of editing operations until the construction of\nsymbolic execution traces of all sites is completed. Experimental results have\nshown that the symbolic model allows a significant gain in both space and time.\nUsing the symbolic model, we have been able to show that if the number of sites\nexceeds 2 then the convergence property is not satisfied for all OT algorithms\nconsidered here. A counterexample is provided for every algorithm."
},{
    "category": "math.DG", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0804.3193v1", 
    "title": "Symbolic computations in differential geometry", 
    "arxiv-id": "0804.3193v1", 
    "author": "Diego Conti", 
    "publish": "2008-04-20T14:55:56Z", 
    "summary": "We introduce the C++ library Wedge, based on GiNaC, for symbolic computations\nin differential geometry. We show how Wedge makes it possible to use the\nlanguage C++ to perform such computations, and illustrate some advantages of\nthis approach with explicit examples. In particular, we describe a short\nprogram to determine whether a given linear exterior differential system is\ninvolutive."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0805.1296v1", 
    "title": "A Simple Dynamic Mind-map Framework To Discover Associative   Relationships in Transactional Data Streams", 
    "arxiv-id": "0805.1296v1", 
    "author": "Christoph Schommer", 
    "publish": "2008-05-09T08:10:09Z", 
    "summary": "In this paper, we informally introduce dynamic mind-maps that represent a new\napproach on the basis of a dynamic construction of connectionist structures\nduring the processing of a data stream. This allows the representation and\nprocessing of recursively defined structures and avoids the problem of a more\ntraditional, fixed-size architecture with the processing of input structures of\nunknown size. For a data stream analysis with association discovery, the\nincremental analysis of data leads to results on demand. Here, we describe a\nframework that uses symbolic cells to calculate associations based on\ntransactional data streams as it exists in e.g. bibliographic databases. We\nfollow a natural paradigm of applying simple operations on cells yielding on a\nmind-map structure that adapts over time."
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0805.1696v2", 
    "title": "Grammatical Evolution with Restarts for Fast Fractal Generation", 
    "arxiv-id": "0805.1696v2", 
    "author": "Alfonso Ortega", 
    "publish": "2008-05-12T17:55:59Z", 
    "summary": "In a previous work, the authors proposed a Grammatical Evolution algorithm to\nautomatically generate Lindenmayer Systems which represent fractal curves with\na pre-determined fractal dimension. This paper gives strong statistical\nevidence that the probability distributions of the execution time of that\nalgorithm exhibits a heavy tail with an hyperbolic probability decay for long\nexecutions, which explains the erratic performance of different executions of\nthe algorithm. Three different restart strategies have been incorporated in the\nalgorithm to mitigate the problems associated to heavy tail distributions: the\nfirst assumes full knowledge of the execution time probability distribution,\nthe second and third assume no knowledge. These strategies exploit the fact\nthat the probability of finding a solution in short executions is\nnon-negligible and yield a severe reduction, both in the expected execution\ntime (up to one order of magnitude) and in its variance, which is reduced from\nan infinite to a finite value."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0805.2311v1", 
    "title": "Aplicacion de la descomposicion racional univariada a monstrous   moonshine (in Spanish)", 
    "arxiv-id": "0805.2311v1", 
    "author": "David Sevilla", 
    "publish": "2008-05-15T14:02:45Z", 
    "summary": "This paper shows how to use Computational Algebra techniques, namely the\ndecomposition of rational functions in one variable, to explore a certain set\nof modular functions, called replicable functions, that arise in Monstrous\nMoonshine. In particular, we have computed all the rational relations with\ncoefficients in Z between pairs of replicable functions.\n  -----\n  En este articulo mostramos como usar tecnicas de Algebra Computacional,\nconcretamente la descomposcion de funciones racionales univariadas, para\nestudiar un cierto conjunto de funciones modulares, llamadas funciones\nreplicables, que aparecen en Monstrous Moonshine. En concreto, hemos calculado\ntodas las relaciones racionales con coeficientes en Z entre pares de funciones\nreplicables."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0805.2331v1", 
    "title": "Computing the fixing group of a rational function", 
    "arxiv-id": "0805.2331v1", 
    "author": "David Sevilla", 
    "publish": "2008-05-15T14:58:18Z", 
    "summary": "Let G=Aut_K (K(x)) be the Galois group of the transcendental degree one pure\nfield extension K(x)/K. In this paper we describe polynomial time algorithms\nfor computing the field Fix(H) fixed by a subgroup H < G and for computing the\nfixing group G_f of a rational function f in K(x)."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0805.2338v1", 
    "title": "Unirational fields of transcendence degree one and functional   decomposition", 
    "arxiv-id": "0805.2338v1", 
    "author": "David Sevilla", 
    "publish": "2008-05-15T15:19:44Z", 
    "summary": "In this paper we present an algorithm to compute all unirational fields of\ntranscendence degree one containing a given finite set of multivariate rational\nfunctions. In particular, we provide an algorithm to decompose a multivariate\nrational function f of the form f=g(h), where g is a univariate rational\nfunction and h a multivariate one."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jsc.2010.08.012", 
    "link": "http://arxiv.org/pdf/0806.0478v1", 
    "title": "Subresultants in Recursive Polynomial Remainder Sequence", 
    "arxiv-id": "0806.0478v1", 
    "author": "Akira Terui", 
    "publish": "2008-06-03T10:09:36Z", 
    "summary": "We introduce concepts of \"recursive polynomial remainder sequence (PRS)\" and\n\"recursive subresultant,\" and investigate their properties. In calculating PRS,\nif there exists the GCD (greatest common divisor) of initial polynomials, we\ncalculate \"recursively\" with new PRS for the GCD and its derivative, until a\nconstant is derived. We call such a PRS a recursive PRS. We define recursive\nsubresultants to be determinants representing the coefficients in recursive PRS\nby coefficients of initial polynomials. Finally, we discuss usage of recursive\nsubresultants in approximate algebraic computation, which motivates the present\nwork."
},{
    "category": "math.AC", 
    "doi": "10.1007/11555964_38", 
    "link": "http://arxiv.org/pdf/0806.0488v1", 
    "title": "Recursive Polynomial Remainder Sequence and the Nested Subresultants", 
    "arxiv-id": "0806.0488v1", 
    "author": "Akira Terui", 
    "publish": "2008-06-03T10:24:55Z", 
    "summary": "We give two new expressions of subresultants, nested subresultant and reduced\nnested subresultant, for the recursive polynomial remainder sequence (PRS)\nwhich has been introduced by the author. The reduced nested subresultant\nreduces the size of the subresultant matrix drastically compared with the\nrecursive subresultant proposed by the authors before, hence it is much more\nuseful for investigation of the recursive PRS. Finally, we discuss usage of the\nreduced nested subresultant in approximate algebraic computation, which\nmotivates the present work."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jalgebra.2007.12.023", 
    "link": "http://arxiv.org/pdf/0806.0495v1", 
    "title": "Recursive Polynomial Remainder Sequence and its Subresultants", 
    "arxiv-id": "0806.0495v1", 
    "author": "Akira Terui", 
    "publish": "2008-06-03T10:52:48Z", 
    "summary": "We introduce concepts of \"recursive polynomial remainder sequence (PRS)\" and\n\"recursive subresultant,\" along with investigation of their properties. A\nrecursive PRS is defined as, if there exists the GCD (greatest common divisor)\nof initial polynomials, a sequence of PRSs calculated \"recursively\" for the GCD\nand its derivative until a constant is derived, and recursive subresultants are\ndefined by determinants representing the coefficients in recursive PRS as\nfunctions of coefficients of initial polynomials. We give three different\nconstructions of subresultant matrices for recursive subresultants; while the\nfirst one is built-up just with previously defined matrices thus the size of\nthe matrix increases fast as the recursion deepens, the last one reduces the\nsize of the matrix drastically by the Gaussian elimination on the second one\nwhich has a \"nested\" expression, i.e. a Sylvester matrix whose elements are\nthemselves determinants."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:8)2008", 
    "link": "http://arxiv.org/pdf/0806.1749v3", 
    "title": "Consistency and Completeness of Rewriting in the Calculus of   Constructions", 
    "arxiv-id": "0806.1749v3", 
    "author": "Jacek Chrzaszcz", 
    "publish": "2008-06-10T20:27:28Z", 
    "summary": "Adding rewriting to a proof assistant based on the Curry-Howard isomorphism,\nsuch as Coq, may greatly improve usability of the tool. Unfortunately adding an\narbitrary set of rewrite rules may render the underlying formal system\nundecidable and inconsistent. While ways to ensure termination and confluence,\nand hence decidability of type-checking, have already been studied to some\nextent, logical consistency has got little attention so far. In this paper we\nshow that consistency is a consequence of canonicity, which in turn follows\nfrom the assumption that all functions defined by rewrite rules are complete.\nWe provide a sound and terminating, but necessarily incomplete algorithm to\nverify this property. The algorithm accepts all definitions that follow\ndependent pattern matching schemes presented by Coquand and studied by McBride\nin his PhD thesis. It also accepts many definitions by rewriting, containing\nrules which depart from standard pattern matching."
},{
    "category": "cs.NE", 
    "doi": "10.2168/LMCS-4(3:8)2008", 
    "link": "http://arxiv.org/pdf/0806.3646v2", 
    "title": "Round Trip Time Prediction Using the Symbolic Function Network Approach", 
    "arxiv-id": "0806.3646v2", 
    "author": "Sung Goo Yoo", 
    "publish": "2008-06-23T10:04:14Z", 
    "summary": "In this paper, we develop a novel approach to model the Internet round trip\ntime using a recently proposed symbolic type neural network model called\nsymbolic function network. The developed predictor is shown to have good\ngeneralization performance and simple representation compared to the multilayer\nperceptron based predictors."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-4(3:8)2008", 
    "link": "http://arxiv.org/pdf/0808.0555v2", 
    "title": "Pairing Functions, Boolean Evaluation and Binary Decision Diagrams in   Prolog", 
    "arxiv-id": "0808.0555v2", 
    "author": "Paul Tarau", 
    "publish": "2008-08-05T05:33:09Z", 
    "summary": "A \"pairing function\" J associates a unique natural number z to any two\nnatural numbers x,y such that for two \"unpairing functions\" K and L, the\nequalities K(J(x,y))=x, L(J(x,y))=y and J(K(z),L(z))=z hold. Using pairing\nfunctions on natural number representations of truth tables, we derive an\nencoding for Binary Decision Diagrams with the unique property that its boolean\nevaluation faithfully mimics its structural conversion to a a natural number\nthrough recursive application of a matching pairing function. We then use this\nresult to derive {\\em ranking} and {\\em unranking} functions for BDDs and\nreduced BDDs. The paper is organized as a self-contained literate Prolog\nprogram, available at http://logic.csci.unt.edu/tarau/research/2008/pBDD.zip\n  Keywords: logic programming and computational mathematics, pairing/unpairing\nfunctions, encodings of boolean functions, binary decision diagrams, natural\nnumber representations of truth tables"
},{
    "category": "cs.NE", 
    "doi": "10.2168/LMCS-4(3:8)2008", 
    "link": "http://arxiv.org/pdf/0808.1378v1", 
    "title": "A Novel Symbolic Type Neural Network Model- Application to River Flow   Forecasting", 
    "arxiv-id": "0808.1378v1", 
    "author": "Amir F. Atiya", 
    "publish": "2008-08-09T22:05:48Z", 
    "summary": "In this paper we introduce a new symbolic type neural tree network called\nsymbolic function network (SFN) that is based on using elementary functions to\nmodel systems in a symbolic form. The proposed formulation permits feature\nselection, functional selection, and flexible structure. We applied this model\non the River Flow forecasting problem. The results found to be superior in both\nfitness and sparsity."
},{
    "category": "math.AG", 
    "doi": "10.2168/LMCS-4(3:8)2008", 
    "link": "http://arxiv.org/pdf/0808.3038v2", 
    "title": "Tschirnhaus-Weierstrass curves", 
    "arxiv-id": "0808.3038v2", 
    "author": "David Sevilla", 
    "publish": "2008-08-22T08:00:36Z", 
    "summary": "We define the concept of Tschirnhaus-Weierstrass curve, named after the\nWeierstrass form of an elliptic curve and Tschirnhaus transformations. Every\npointed curve has a Tschirnhaus-Weierstrass form, and this representation is\nunique up to a scaling of variables. This is useful for computing isomorphisms\nbetween curves."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0809.0063v1", 
    "title": "Simultaneous Modular Reduction and Kronecker Substitution for Small   Finite Fields", 
    "arxiv-id": "0809.0063v1", 
    "author": "Bruno Salvy", 
    "publish": "2008-08-30T14:28:23Z", 
    "summary": "We present algorithms to perform modular polynomial multiplication or modular\ndot product efficiently in a single machine word. We pack polynomials into\nintegers and perform several modular operations with machine integer or\nfloating point arithmetic. The modular polynomials are converted into integers\nusing Kronecker substitution (evaluation at a sufficiently large integer). With\nsome control on the sizes and degrees, arithmetic operations on the polynomials\ncan be performed directly with machine integers or floating point numbers and\nthe number of conversions can be reduced. We also present efficient ways to\nrecover the modular values of the coefficients. This leads to practical gains\nof quite large constant factors for polynomial multiplication, prime field\nlinear algebra and small extension field arithmetic."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0809.1476v1", 
    "title": "Obtaining Exact Interpolation Multivariate Polynomial by Approximation", 
    "arxiv-id": "0809.1476v1", 
    "author": "Xun Yuan", 
    "publish": "2008-09-09T02:33:30Z", 
    "summary": "In some fields such as Mathematics Mechanization, automated reasoning and\nTrustworthy Computing etc., exact results are needed. Symbolic computations are\nused to obtain the exact results. Symbolic computations are of high complexity.\nIn order to improve the situation, exactly interpolating methods are often\nproposed for the exact results and approximate interpolating methods for the\napproximate ones. In this paper, we study how to obtain exact interpolation\npolynomial with rational coefficients by approximate interpolating methods."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0809.2696v1", 
    "title": "An Unified Definition of Data Mining", 
    "arxiv-id": "0809.2696v1", 
    "author": "Christoph Schommer", 
    "publish": "2008-09-16T13:13:17Z", 
    "summary": "Since many years, theoretical concepts of Data Mining have been developed and\nimproved. Data Mining has become applied to many academic and industrial\nsituations, and recently, soundings of public opinion about privacy have been\ncarried out. However, a consistent and standardized definition is still\nmissing, and the initial explanation given by Frawley et al. has pragmatically\noften changed over the years. Furthermore, alternative terms like Knowledge\nDiscovery have been conjured and forged, and a necessity of a Data Warehouse\nhas been endeavoured to persuade the users. In this work, we pick up current\ndefinitions and introduce an unified definition that covers existing attempted\nexplanations. For this, we appeal to the natural original of chemical states of\naggregation."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0810.1481v2", 
    "title": "An Evidential Path Logic for Multi-Relational Networks", 
    "arxiv-id": "0810.1481v2", 
    "author": "Joe Geldart", 
    "publish": "2008-10-08T17:49:15Z", 
    "summary": "Multi-relational networks are used extensively to structure knowledge.\nPerhaps the most popular instance, due to the widespread adoption of the\nSemantic Web, is the Resource Description Framework (RDF). One of the primary\npurposes of a knowledge network is to reason; that is, to alter the topology of\nthe network according to an algorithm that uses the existing topological\nstructure as its input. There exist many such reasoning algorithms. With\nrespect to the Semantic Web, the bivalent, monotonic reasoners of the RDF\nSchema (RDFS) and the Web Ontology Language (OWL) are the most prevalent.\nHowever, nothing prevents other forms of reasoning from existing in the\nSemantic Web. This article presents a non-bivalent, non-monotonic, evidential\nlogic and reasoner that is an algebraic ring over a multi-relational network\nequipped with two binary operations that can be composed to execute various\nforms of inference. Given its multi-relational grounding, it is possible to use\nthe presented evidential framework as another method for structuring knowledge\nand reasoning in the Semantic Web. The benefits of this framework are that it\nworks with arbitrary, partial, and contradictory knowledge while, at the same\ntime, it supports a tractable approximate reasoning process."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0810.1574v1", 
    "title": "Liouvillian Solutions of Difference-Differential Equations", 
    "arxiv-id": "0810.1574v1", 
    "author": "Min Wu", 
    "publish": "2008-10-09T05:16:48Z", 
    "summary": "For a field k$with an automorphism \\sigma and a derivation \\delta, we\nintroduce the notion of liouvillian solutions of linear difference-differential\nsystems {\\sigma(Y) = AY, \\delta(Y) = BY} over k and characterize the existence\nof liouvillian solutions in terms of the Galois group of the systems. We will\ngive an algorithm to decide whether such a system has liouvillian solutions\nwhen k = C(x,t), \\sigma(x) = x+1, \\delta = d/dt$ and the size of the system is\na prime."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0810.3203v1", 
    "title": "A cache-friendly truncated FFT", 
    "arxiv-id": "0810.3203v1", 
    "author": "David Harvey", 
    "publish": "2008-10-17T17:36:27Z", 
    "summary": "We describe a cache-friendly version of van der Hoeven's truncated FFT and\ninverse truncated FFT, focusing on the case of `large' coefficients, such as\nthose arising in the Schonhage--Strassen algorithm for multiplication in Z[x].\nWe describe two implementations and examine their performance."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0810.5647v1", 
    "title": "Kaltofen's division-free determinant algorithm differentiated for matrix   adjoint computation", 
    "arxiv-id": "0810.5647v1", 
    "author": "Gilles Villard", 
    "publish": "2008-10-31T09:43:48Z", 
    "summary": "Kaltofen has proposed a new approach in 1992 for computing matrix\ndeterminants without divisions. The algorithm is based on a baby steps/giant\nsteps construction of Krylov subspaces, and computes the determinant as the\nconstant term of a characteristic polynomial. For matrices over an abstract\nring, by the results of Baur and Strassen, the determinant algorithm, actually\na straight-line program, leads to an algorithm with the same complexity for\ncomputing the adjoint of a matrix. However, the latter adjoint algorithm is\nobtained by the reverse mode of automatic differentiation, hence somehow is not\n\"explicit\". We present an alternative (still closely related) algorithm for the\nadjoint thatcan be implemented directly, we mean without resorting to an\nautomatic transformation. The algorithm is deduced by applying program\ndifferentiation techniques \"by hand\" to Kaltofen's method, and is completely\ndecribed. As subproblem, we study the differentiation of programs that compute\nminimum polynomials of lineraly generated sequences, and we use a lazy\npolynomial evaluation mechanism for reducing the cost of Strassen's avoidance\nof divisions in our case."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0811.3165v2", 
    "title": "Trading GRH for algebra: algorithms for factoring polynomials and   related structures", 
    "arxiv-id": "0811.3165v2", 
    "author": "Nitin Saxena", 
    "publish": "2008-11-19T17:57:25Z", 
    "summary": "In this paper we develop techniques that eliminate the need of the\nGeneralized Riemann Hypothesis (GRH) from various (almost all) known results\nabout deterministic polynomial factoring over finite fields. Our main result\nshows that given a polynomial f(x) of degree n over a finite field k, we can\nfind in deterministic poly(n^{\\log n},\\log |k|) time \"either\" a nontrivial\nfactor of f(x) \"or\" a nontrivial automorphism of k[x]/(f(x)) of order n. This\nmain tool leads to various new GRH-free results, most striking of which are:\n  (1) Given a noncommutative algebra over a finite field, we can find a zero\ndivisor in deterministic subexponential time.\n  (2) Given a positive integer r such that either 8|r or r has at least two\ndistinct odd prime factors. There is a deterministic polynomial time algorithm\nto find a nontrivial factor of the r-th cyclotomic polynomial over a finite\nfield.\n  In this paper, following the seminal work of Lenstra (1991) on constructing\nisomorphisms between finite fields, we further generalize classical Galois\ntheory constructs like cyclotomic extensions, Kummer extensions, Teichmuller\nsubgroups, to the case of commutative semisimple algebras with automorphisms.\nThese generalized constructs help eliminate the dependence on GRH."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0811.3521v1", 
    "title": "Craig Interpolation for Quantifier-Free Presburger Arithmetic", 
    "arxiv-id": "0811.3521v1", 
    "author": "Thomas Wahl", 
    "publish": "2008-11-21T11:44:22Z", 
    "summary": "Craig interpolation has become a versatile algorithmic tool for improving\nsoftware verification. Interpolants can, for instance, accelerate the\nconvergence of fixpoint computations for infinite-state systems. They also help\nimprove the refinement of iteratively computed lazy abstractions. Efficient\ninterpolation procedures have been presented only for a few theories. In this\npaper, we introduce a complete interpolation method for the full range of\nquantifier-free Presburger arithmetic formulas. We propose a novel convex\nvariable projection for integer inequalities and a technique to combine them\nwith equalities. The derivation of the interpolant has complexity low-degree\npolynomial in the size of the refutation proof and is typically fast in\npractice."
},{
    "category": "cs.SE", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0811.4061v2", 
    "title": "Benchmarking the solar dynamo with Maxima", 
    "arxiv-id": "0811.4061v2", 
    "author": "Valery V. Pipin", 
    "publish": "2008-11-25T11:35:35Z", 
    "summary": "Recently, Jouve et al(A&A, 2008) published the paper that presents the\nnumerical benchmark for the solar dynamo models. Here, I would like to show a\nway how to get it with help of computer algebra system Maxima. This way was\nused in our paper (Pipin & Seehafer, A&A 2008, in print) to test some new ideas\nin the large-scale stellar dynamos. In the present paper I complement the\ndynamo benchmark with the standard test that address the problem of the\nfree-decay modes in the sphere which is submerged in vacuum."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0811.4720v1", 
    "title": "Automated Induction for Complex Data Structures", 
    "arxiv-id": "0811.4720v1", 
    "author": "Florent Jacquemard", 
    "publish": "2008-11-28T13:58:46Z", 
    "summary": "We propose a procedure for automated implicit inductive theorem proving for\nequational specifications made of rewrite rules with conditions and\nconstraints. The constraints are interpreted over constructor terms\n(representing data values), and may express syntactic equality, disequality,\nordering and also membership in a fixed tree language. Constrained equational\naxioms between constructor terms are supported and can be used in order to\nspecify complex data structures like sets, sorted lists, trees, powerlists...\n  Our procedure is based on tree grammars with constraints, a formalism which\ncan describe exactly the initial model of the given specification (when it is\nsufficiently complete and terminating). They are used in the inductive proofs\nfirst as an induction scheme for the generation of subgoals at induction steps,\nsecond for checking validity and redundancy criteria by reduction to an\nemptiness problem, and third for defining and solving membership constraints.\n  We show that the procedure is sound and refutationally complete. It\ngeneralizes former test set induction techniques and yields natural proofs for\nseveral non-trivial examples presented in the paper, these examples are\ndifficult to specify and carry on automatically with related induction\nprocedures."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2010.08.015", 
    "link": "http://arxiv.org/pdf/0812.2563v1", 
    "title": "A Sparse Flat Extension Theorem for Moment Matrices", 
    "arxiv-id": "0812.2563v1", 
    "author": "Bernard Mourrain", 
    "publish": "2008-12-15T07:49:22Z", 
    "summary": "In this note we prove a generalization of the flat extension theorem of Curto\nand Fialkow for truncated moment matrices. It applies to moment matrices\nindexed by an arbitrary set of monomials and its border, assuming that this set\nis connected to 1. When formulated in a basis-free setting, this gives an\nequivalent result for truncated Hankel operators."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0901.2778v1", 
    "title": "On the Computation of Matrices of Traces and Radicals of Ideals", 
    "arxiv-id": "0901.2778v1", 
    "author": "Agnes Szanto", 
    "publish": "2009-01-19T07:57:18Z", 
    "summary": "Let $f_1,...,f_s \\in \\mathbb{K}[x_1,...,x_m]$ be a system of polynomials\ngenerating a zero-dimensional ideal $\\I$, where $\\mathbb{K}$ is an arbitrary\nalgebraically closed field. We study the computation of \"matrices of traces\"\nfor the factor algebra $\\A := \\CC[x_1, ..., x_m]/ \\I$, i.e. matrices with\nentries which are trace functions of the roots of $\\I$. Such matrices of traces\nin turn allow us to compute a system of multiplication matrices\n$\\{M_{x_i}|i=1,...,m\\}$ of the radical $\\sqrt{\\I}$. We first propose a method\nusing Macaulay type resultant matrices of $f_1,...,f_s$ and a polynomial $J$ to\ncompute moment matrices, and in particular matrices of traces for $\\A$. Here\n$J$ is a polynomial generalizing the Jacobian. We prove bounds on the degrees\nneeded for the Macaulay matrix in the case when $\\I$ has finitely many\nprojective roots in $\\mathbb{P}^m_\\CC$. We also extend previous results which\nwork only for the case where $\\A$ is Gorenstein to the non-Gorenstein case. The\nsecond proposed method uses Bezoutian matrices to compute matrices of traces of\n$\\A$. Here we need the assumption that $s=m$ and $f_1,...,f_m$ define an affine\ncomplete intersection. This second method also works if we have higher\ndimensional components at infinity. A new explicit description of the\ngenerators of $\\sqrt{\\I}$ are given in terms of Bezoutians."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0901.3657v1", 
    "title": "Homotopy methods for multiplication modulo triangular sets", 
    "arxiv-id": "0901.3657v1", 
    "author": "Eric Schost", 
    "publish": "2009-01-23T11:35:57Z", 
    "summary": "We study the cost of multiplication modulo triangular families of\npolynomials. Following previous work by Li, Moreno Maza and Schost, we propose\nan algorithm that relies on homotopy and fast evaluation-interpolation\ntechniques. We obtain a quasi-linear time complexity for substantial families\nof examples, for which no such result was known before. Applications are given\nto notably addition of algebraic numbers in small characteristic."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0901.3706v2", 
    "title": "Symmetric tensor decomposition", 
    "arxiv-id": "0901.3706v2", 
    "author": "Elias Tsigaridas", 
    "publish": "2009-01-23T16:21:18Z", 
    "summary": "We present an algorithm for decomposing a symmetric tensor, of dimension n\nand order d as a sum of rank-1 symmetric tensors, extending the algorithm of\nSylvester devised in 1886 for binary forms. We recall the correspondence\nbetween the decomposition of a homogeneous polynomial in n variables of total\ndegree d as a sum of powers of linear forms (Waring's problem), incidence\nproperties on secant varieties of the Veronese Variety and the representation\nof linear forms as a linear combination of evaluations at distinct points. Then\nwe reformulate Sylvester's approach from the dual point of view. Exploiting\nthis duality, we propose necessary and sufficient conditions for the existence\nof such a decomposition of a given rank, using the properties of Hankel (and\nquasi-Hankel) matrices, derived from multivariate polynomials and normal form\ncomputations. This leads to the resolution of polynomial equations of small\ndegree in non-generic cases. We propose a new algorithm for symmetric tensor\ndecomposition, based on this characterization and on linear algebra\ncomputations with these Hankel matrices. The impact of this contribution is\ntwo-fold. First it permits an efficient computation of the decomposition of any\ntensor of sub-generic rank, as opposed to widely used iterative algorithms with\nunproved global convergence (e.g. Alternate Least Squares or gradient\ndescents). Second, it gives tools for understanding uniqueness conditions, and\nfor detecting the rank."
},{
    "category": "cs.SE", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0901.4404v1", 
    "title": "Performance of Buchberger's Improved Algorithm using Prime Based   Ordering", 
    "arxiv-id": "0901.4404v1", 
    "author": "John Carminati", 
    "publish": "2009-01-28T05:47:24Z", 
    "summary": "Prime-based ordering which is proved to be admissible, is the encoding of\nindeterminates in power-products with prime numbers and ordering them by using\nthe natural number order. Using Eiffel, four versions of Buchberger's improved\nalgorithm for obtaining Groebner Bases have been developed: two total degree\nversions, representing power products as strings and the other two as integers\nbased on prime-based ordering. The versions are further distinguished by\nimplementing coefficients as 64-bit integers and as multiple-precision\nintegers. By using primebased power product coding, iterative or recursive\noperations on power products are replaced with integer operations. It is found\nthat on a series of example polynomial sets, significant reductions in\ncomputation time of 30% or more are almost always obtained."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0902.0514v1", 
    "title": "Graphical Reasoning in Compact Closed Categories for Quantum Computation", 
    "arxiv-id": "0902.0514v1", 
    "author": "Ross Duncan", 
    "publish": "2009-02-03T14:21:01Z", 
    "summary": "Compact closed categories provide a foundational formalism for a variety of\nimportant domains, including quantum computation. These categories have a\nnatural visualisation as a form of graphs. We present a formalism for\nequational reasoning about such graphs and develop this into a generic proof\nsystem with a fixed logical kernel for equational reasoning about compact\nclosed categories. Automating this reasoning process is motivated by the slow\nand error prone nature of manual graph manipulation. A salient feature of our\nsystem is that it provides a formal and declarative account of derived results\nthat can include `ellipses'-style notation. We illustrate the framework by\ninstantiating it for a graphical language of quantum computation and show how\nthis can be used to perform symbolic computation."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0902.0828v1", 
    "title": "Finding Exact Minimal Polynomial by Approximations", 
    "arxiv-id": "0902.0828v1", 
    "author": "Jingzhong Zhang", 
    "publish": "2009-02-05T00:49:13Z", 
    "summary": "We present a new algorithm for reconstructing an exact algebraic number from\nits approximate value using an improved parameterized integer relation\nconstruction method. Our result is consistent with the existence of error\ncontrolling on obtaining an exact rational number from its approximation. The\nalgorithm is applicable for finding exact minimal polynomial by its approximate\nroot. This also enables us to provide an efficient method of converting the\nrational approximation representation to the minimal polynomial representation,\nand devise a simple algorithm to factor multivariate polynomials with rational\ncoefficients.\n  Compared with other methods, this method has the numerical computation\nadvantage of high efficiency. The experimental results show that the method is\nmore efficient than \\emph{identify} in \\emph{Maple} 11 for obtaining an exact\nalgebraic number from its approximation. In this paper, we completely implement\nhow to obtain exact results by numerical approximate computations."
},{
    "category": "cs.DS", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0902.1871v1", 
    "title": "Abstraction and Refinement in Static Model-Checking", 
    "arxiv-id": "0902.1871v1", 
    "author": "Kaninda Musumbu", 
    "publish": "2009-02-11T12:46:17Z", 
    "summary": "interpretation is a general methodology for building static analyses of\nprograms. It was introduced by P. and R. Cousot in \\cite{cc}. We present, in\nthis paper, an application of a generic abstract interpretation to domain of\nmodel-checking. Dynamic checking are usually easier to use, because the concept\nare establishe d and wide well know. But they are usually limited to systems\nwhose states space is finite. In an other part, certain faults cannot be\ndetected dynamically, even by keeping track of the history of the states\nspace.Indeed, the classical problem of finding the right test cases is far from\ntrivial and limit the abilities of dynamic checkers further. Static checking\nhave the advantage that they work on a more abstract level than dynamic checker\nand can verify system properties for all inputs. Problem, it is hard to\nguarantee that a violation of a modeled property corresponds to a fault in the\nconcrete system. We propose an approach, in which we generate counter-examples\ndynamically using the abstract interpretation techniques."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0902.2407v1", 
    "title": "Group-Theoretic Partial Matrix Multiplication", 
    "arxiv-id": "0902.2407v1", 
    "author": "Martijn van Schaardenburg", 
    "publish": "2009-02-13T22:46:54Z", 
    "summary": "A generalization of recent group-theoretic matrix multiplication algorithms\nto an analogue of the theory of partial matrix multiplication is presented. We\ndemonstrate that the added flexibility of this approach can in some cases\nimprove upper bounds on the exponent of matrix multiplication yielded by\ngroup-theoretic full matrix multiplication. The group theory behind our partial\nmatrix multiplication algorithms leads to the problem of maximizing a quantity\nrepresenting the \"fullness\" of a given partial matrix pattern. This problem is\nshown to be NP-hard, and two algorithms, one optimal and another non-optimal\nbut polynomial-time, are given for solving it."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0902.2853v4", 
    "title": "A formal calculus on the Riordan near algebra", 
    "arxiv-id": "0902.2853v4", 
    "author": "G\u00e9rard Duchamp", 
    "publish": "2009-02-17T08:13:27Z", 
    "summary": "The Riordan group is the semi-direct product of a multiplicative group of\ninvertible series and a group, under substitution, of non units. The Riordan\nnear algebra, as introduced in this paper, is the Cartesian product of the\nalgebra of formal power series and its principal ideal of non units, equipped\nwith a product that extends the multiplication of the Riordan group. The later\nis naturally embedded as a subgroup of units into the former. In this paper, we\nprove the existence of a formal calculus on the Riordan algebra. This formal\ncalculus plays a role similar to those of holomorphic calculi in the Banach or\nFr\\'echet algebras setting, but without the constraint of a radius of\nconvergence. Using this calculus, we define \\emph{en passant} a notion of\ngeneralized powers in the Riordan group."
},{
    "category": "cs.AI", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0902.2995v1", 
    "title": "ASF+ --- eine ASF-aehnliche Spezifikationssprache", 
    "arxiv-id": "0902.2995v1", 
    "author": "Claus-Peter Wirth", 
    "publish": "2009-02-17T20:52:11Z", 
    "summary": "Maintaining the main aspects of the algebraic specification language ASF as\npresented in [Bergstra&al.89] we have extend ASF with the following concepts:\nWhile once exported names in ASF must stay visible up to the top the module\nhierarchy, ASF+ permits a more sophisticated hiding of signature names. The\nerroneous merging of distinct structures that occurs when importing different\nactualizations of the same parameterized module in ASF is avoided in ASF+ by a\nmore adequate form of parameter binding. The new ``Namensraum''-concept of ASF+\npermits the specifier on the one hand directly to identify the origin of hidden\nnames and on the other to decide whether an imported module is only to be\naccessed or whether an important property of it is to be modified. In the first\ncase he can access one single globally provided version; in the second he has\nto import a copy of the module. Finally ASF+ permits semantic conditions on\nparameters and the specification of tasks for a theorem prover."
},{
    "category": "cs.PL", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0904.2136v1", 
    "title": "On the Cooperation of the Constraint Domains H, R and FD in CFLP", 
    "arxiv-id": "0904.2136v1", 
    "author": "A. J. Fern\u00e1ndez", 
    "publish": "2009-04-14T14:58:46Z", 
    "summary": "This paper presents a computational model for the cooperation of constraint\ndomains and an implementation for a particular case of practical importance.\nThe computational model supports declarative programming with lazy and possibly\nhigher-order functions, predicates, and the cooperation of different constraint\ndomains equipped with their respective solvers, relying on a so-called\nConstraint Functional Logic Programming (CFLP) scheme. The implementation has\nbeen developed on top of the CFLP system TOY, supporting the cooperation of the\nthree domains H, R and FD, which supply equality and disequality constraints\nover symbolic terms, arithmetic constraints over the real numbers, and finite\ndomain constraints over the integers, respectively. The computational model has\nbeen proved sound and complete w.r.t. the declarative semantics provided by the\n$CFLP$ scheme, while the implemented system has been tested with a set of\nbenchmarks and shown to behave quite efficiently in comparison to the closest\nrelated approach we are aware of.\n  To appear in Theory and Practice of Logic Programming (TPLP)"
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0904.4064v3", 
    "title": "Multihomogeneous Resultant Formulae for Systems with Scaled Support", 
    "arxiv-id": "0904.4064v3", 
    "author": "Angelos Mantzaflaris", 
    "publish": "2009-04-26T21:51:10Z", 
    "summary": "Constructive methods for matrices of multihomogeneous (or multigraded)\nresultants for unmixed systems have been studied by Weyman, Zelevinsky,\nSturmfels, Dickenstein and Emiris. We generalize these constructions to mixed\nsystems, whose Newton polytopes are scaled copies of one polytope, thus taking\na step towards systems with arbitrary supports. First, we specify matrices\nwhose determinant equals the resultant and characterize the systems that admit\nsuch formulae. Bezout-type determinantal formulae do not exist, but we describe\nall possible Sylvester-type and hybrid formulae. We establish tight bounds for\nall corresponding degree vectors, and specify domains that will surely contain\nsuch vectors; the latter are new even for the unmixed case. Second, we make use\nof multiplication tables and strong duality theory to specify resultant\nmatrices explicitly, for a general scaled system, thus including unmixed\nsystems. The encountered matrices are classified; these include a new type of\nSylvester-type matrix as well as Bezout-type matrices, known as partial\nBezoutians. Our public-domain Maple implementation includes efficient storage\nof complexes in memory, and construction of resultant matrices."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0905.2212v4", 
    "title": "Castelnuovo-Mumford Regularity and Computing the de Rham Cohomology of   Smooth Projective Varieties", 
    "arxiv-id": "0905.2212v4", 
    "author": "Peter Scheiblechner", 
    "publish": "2009-05-13T22:24:17Z", 
    "summary": "We describe a parallel polynomial time algorithm for computing the\ntopological Betti numbers of a smooth complex projective variety $X$. It is the\nfirst single exponential time algorithm for computing the Betti numbers of a\nsignificant class of complex varieties of arbitrary dimension. Our main\ntheoretical result is that the Castelnuovo-Mumford regularity of the sheaf of\ndifferential $p$-forms on $X$ is bounded by $p(em+1)D$, where $e$, $m$, and $D$\nare the maximal codimension, dimension, and degree, respectively, of all\nirreducible components of $X$. It follows that, for a union $V$ of generic\nhyperplane sections in $X$, the algebraic de Rham cohomology of $X\\setminus V$\nis described by differential forms with poles along $V$ of single exponential\norder. This yields a similar description of the de Rham cohomology of $X$,\nwhich allows its efficient computation. Furthermore, we give a parallel\npolynomial time algorithm for testing whether a projective variety is smooth."
},{
    "category": "cs.DM", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0906.0937v1", 
    "title": "Spherical Distribution of 5 Points with Maximal Distance Sum", 
    "arxiv-id": "0906.0937v1", 
    "author": "Junwei Shao", 
    "publish": "2009-06-04T15:48:05Z", 
    "summary": "In this paper, we mainly consider the problem of spherical distribution of 5\npoints, that is, how to configure 5 points on a sphere such that the mutual\ndistance sum attains the maximum. It is conjectured that the sum of distances\nis maximal if 5 points form a bipyramid configuration in which case two points\nare positioned at two poles of the sphere and the other three are positioned\nuniformly on the equator. We study this problem using interval methods and\nrelated technics, and give a proof for the conjecture through computers in\nfinite time."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.08.020", 
    "link": "http://arxiv.org/pdf/0906.3065v1", 
    "title": "Real Solution Isolation with Multiplicity of Zero-Dimensional Triangular   Systems", 
    "arxiv-id": "0906.3065v1", 
    "author": "Bican Xia", 
    "publish": "2009-06-17T03:29:37Z", 
    "summary": "Existing algorithms for isolating real solutions of zero-dimensional\npolynomial systems do not compute the multiplicities of the solutions. In this\npaper, we define in a natural way the multiplicity of solutions of\nzero-dimensional triangular polynomial systems and prove that our definition is\nequivalent to the classical definition of local (intersection) multiplicity.\nThen we present an effective and complete algorithm for isolating real\nsolutions with multiplicities of zero-dimensional triangular polynomial systems\nusing our definition. The algorithm is based on interval arithmetic and\nsquare-free factorization of polynomials with real algebraic coefficients. The\ncomputational results on some examples from the literature are presented."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-04103-7_12", 
    "link": "http://arxiv.org/pdf/0906.4121v1", 
    "title": "On computing the Hermite form of a matrix of differential polynomials", 
    "arxiv-id": "0906.4121v1", 
    "author": "Myung Sub Kim", 
    "publish": "2009-06-22T20:29:09Z", 
    "summary": "Given an n x n matrix over the ring of differential polynomials\nF(t)[\\D;\\delta], we show how to compute the Hermite form H of A, and a\nunimodular matrix U such that UA=H. The algorithm requires a polynomial number\nof operations in terms of n, deg_D(A), and deg_t(A). When F is the field of\nrational numbers, it also requires time polynomial in the bit-length of the\ncoefficients."
},{
    "category": "math.AG", 
    "doi": "10.1007/978-3-642-04103-7_12", 
    "link": "http://arxiv.org/pdf/0906.4377v1", 
    "title": "On the minimum of a positive polynomial over the standard simplex", 
    "arxiv-id": "0906.4377v1", 
    "author": "Daniel Perrucci", 
    "publish": "2009-06-23T23:40:34Z", 
    "summary": "We present a new positive lower bound for the minimum value taken by a\npolynomial P with integer coefficients in k variables over the standard simplex\nof R^k, assuming that P is positive on the simplex. This bound depends only on\nthe number of variables, the degree and the bitsize of the coefficients of P\nand improves all previous bounds for arbitrary polynomials which are positive\nover the simplex."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-04103-7_12", 
    "link": "http://arxiv.org/pdf/0906.4917v2", 
    "title": "Simultaneous Integer Relation Detection and Its an Application", 
    "arxiv-id": "0906.4917v2", 
    "author": "Zhang Jing-zhong", 
    "publish": "2009-06-26T13:07:52Z", 
    "summary": "Let $\\mathbf{x_1}, ..., \\mathbf{x_t} \\in \\mathbb{R}^{n}$. A simultaneous\ninteger relation (SIR) for $\\mathbf{x_1}, ..., \\mathbf{x_t}$ is a vector\n$\\mathbf{m} \\in \\mathbb{Z}^{n}\\setminus\\{\\textbf{0}\\}$ such that\n$\\mathbf{x_i}^T\\mathbf{m} = 0$ for $i = 1, ..., t$. In this paper, we propose\nan algorithm SIRD to detect an SIR for real vectors, which constructs an SIR\nwithin $\\mathcal {O}(n^4 + n^3 \\log \\lambda(X))$ arithmetic operations, where\n$\\lambda(X)$ is the least Euclidean norm of SIRs for $\\mathbf{x_1}, >...,\n\\mathbf{x_t}$. One can easily generalize SIRD to complex number field.\nExperimental results show that SIRD is practical and better than another\ndetecting algorithm in the literature. In its application, we present a new\nalgorithm for finding the minimal polynomial of an arbitrary complex algebraic\nnumber from its an approximation, which is not based on LLL. We also provide a\nsufficient condition on the precision of the approximate value, which depends\nonly on the height and the degree of the algebraic number."
},{
    "category": "cs.NA", 
    "doi": "10.1007/978-3-642-04103-7_12", 
    "link": "http://arxiv.org/pdf/0906.5561v2", 
    "title": "An Improved Algorithm based on Shannon-Happ Formula for Calculating   Transfer Function from Signal Flow Graph and Its Visualization", 
    "arxiv-id": "0906.5561v2", 
    "author": "Shanglian Bao", 
    "publish": "2009-06-30T15:47:42Z", 
    "summary": "A new method based on Shannon-Happ formula to calculate transfer function\nfrom Signal Flow Graph (SFG) is presented. The algorithm provides an explicit\napproach to get the transfer function in a format with both numerical and\nsymbolic expressions. The adoption of the symbolic variable in SFG, which could\nrepresent the nonlinear item or the independent sub-system, is achieved by\nvariable separation approach. An investigation is given for the solutions of\nseveral special conditions of SFG. To improve the efficiency of the algorithm,\na new technique combined with Johnson method for generating the combinations of\nthe non-touching loops is developed. It uses the previous combinations in lower\norder to get the ones in higher order. There is an introduction about the\nvisualization of SFG and the subroutines for system performance analysis in the\nsoftware, AVANT."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-04103-7_12", 
    "link": "http://arxiv.org/pdf/0907.5038v1", 
    "title": "An Explicit Construction of Gauss-Jordan Elimination Matrix", 
    "arxiv-id": "0907.5038v1", 
    "author": "Yi Li", 
    "publish": "2009-07-29T02:01:45Z", 
    "summary": "A constructive approach to get the reduced row echelon form of a given matrix\n$A$ is presented. It has been shown that after the $k$th step of the\nGauss-Jordan procedure, each entry $a^k_{ij}(i<>j; j > k)$ in the new matrix\n$A^k$ can always be expressed as a ratio of two determinants whose entries are\nfrom the original matrix $A$. The new method also gives a more general\ngeneralization of Cramer's rule than existing methods."
},{
    "category": "math.CO", 
    "doi": "10.1007/978-3-642-04103-7_12", 
    "link": "http://arxiv.org/pdf/0909.1965v1", 
    "title": "The complete Generating Function for Gessel Walks is Algebraic", 
    "arxiv-id": "0909.1965v1", 
    "author": "Manuel Kauers", 
    "publish": "2009-09-10T14:58:14Z", 
    "summary": "Gessel walks are lattice walks in the quarter plane $\\set N^2$ which start at\nthe origin $(0,0)\\in\\set N^2$ and consist only of steps chosen from the set\n$\\{\\leftarrow,\\swarrow,\\nearrow,\\to\\}$. We prove that if $g(n;i,j)$ denotes the\nnumber of Gessel walks of length $n$ which end at the point $(i,j)\\in\\set N^2$,\nthen the trivariate generating series $G(t;x,y)=\\sum_{n,i,j\\geq 0} g(n;i,j)x^i\ny^j t^n$ is an algebraic function."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0909.3248v1", 
    "title": "Topology of 2D and 3D Rational Curves", 
    "arxiv-id": "0909.3248v1", 
    "author": "Gema Maria Diaz-Toca", 
    "publish": "2009-09-17T14:58:09Z", 
    "summary": "In this paper we present algorithms for computing the topology of planar and\nspace rational curves defined by a parametrization. The algorithms given here\nwork directly with the parametrization of the curve, and do not require to\ncompute or use the implicit equation of the curve (in the case of planar\ncurves) or of any projection (in the case of space curves). Moreover, these\nalgorithms have been implemented in Maple; the examples considered and the\ntimings obtained show good performance skills."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0909.4955v2", 
    "title": "On the Different Shapes Arising in a Family of Rational Curves Depending   on a Parameter", 
    "arxiv-id": "0909.4955v2", 
    "author": "Juan Gerardo Alcazar", 
    "publish": "2009-09-27T18:47:17Z", 
    "summary": "Given a family of rational curves depending on a real parameter, defined by\nits parametric equations, we provide an algorithm to compute a finite partition\nof the parameter space (${\\Bbb R}$, in general) so that the shape of the family\nstays invariant along each element of the partition. So, from this partition\nthe topology types in the family can be determined. The algorithm is based on a\ngeometric interpretation of previous work (\\cite{JGRS}) for the implicit case.\nHowever, in our case the algorithm works directly with the parametrization of\nthe family, and the implicit equation does not need to be computed. Timings\ncomparing the algorithm in the implicit and the parametric cases are given;\nthese timings show that the parametric algorithm developed here provides in\ngeneral better results than the known algorithm for the implicit case."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0909.4956v1", 
    "title": "Local Shape of Generalized Offsets to Algebraic Curves", 
    "arxiv-id": "0909.4956v1", 
    "author": "Juan Gerardo Alcazar", 
    "publish": "2009-09-27T19:38:00Z", 
    "summary": "In this paper we study the local behavior of an algebraic curve under a\ngeometric construction which is a variation of the usual offsetting\nconstruction, namely the {\\it generalized} offsetting process (\\cite {SS99}).\nMore precisely, here we discuss when and how this geometric construction may\ncause local changes in the shape of an algebraic curve, and we compare our\nresults with those obtained for the case of classical offsets (\\cite{JGS07}).\nFor these purposes, we use well-known notions of Differential Geometry, and\nalso the notion of {\\it local shape} introduced in \\cite{JGS07}."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0910.1926v1", 
    "title": "Faster algorithms for the square root and reciprocal of power series", 
    "arxiv-id": "0910.1926v1", 
    "author": "David Harvey", 
    "publish": "2009-10-10T15:41:04Z", 
    "summary": "We give new algorithms for the computation of square roots and reciprocals of\npower series in C[[x]]. If M(n) denotes the cost of multiplying polynomials of\ndegree n, the square root to order n costs (1.333... + o(1)) M(n) and the\nreciprocal costs (1.444... + o(1)) M(n). These improve on the previous best\nresults, respectively (1.8333... + o(1)) M(n) and (1.5 + o(1)) M(n)."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0910.2853v3", 
    "title": "Decreasing Diagrams and Relative Termination", 
    "arxiv-id": "0910.2853v3", 
    "author": "Aart Middeldorp", 
    "publish": "2009-10-15T12:34:04Z", 
    "summary": "In this paper we use the decreasing diagrams technique to show that a\nleft-linear term rewrite system R is confluent if all its critical pairs are\njoinable and the critical pair steps are relatively terminating with respect to\nR. We further show how to encode the rule-labeling heuristic for decreasing\ndiagrams as a satisfiability problem. Experimental data for both methods are\npresented."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0911.1340v1", 
    "title": "Bounding the radii of balls meeting every connected component of   semi-algebraic sets", 
    "arxiv-id": "0911.1340v1", 
    "author": "Marie-Francoise Roy", 
    "publish": "2009-11-06T19:53:54Z", 
    "summary": "We prove explicit bounds on the radius of a ball centered at the origin which\nis guaranteed to contain all bounded connected components of a semi-algebraic\nset $S \\subset \\mathbbm{R}^k$ defined by a quantifier-free formula involving\n$s$ polynomials in $\\mathbbm{Z}[X_1, ..., X_k]$ having degrees at most $d$, and\nwhose coefficients have bitsizes at most $\\tau$. Our bound is an explicit\nfunction of $s, d, k$ and $\\tau$, and does not contain any undetermined\nconstants. We also prove a similar bound on the radius of a ball guaranteed to\nintersect every connected component of $S$ (including the unbounded\ncomponents). While asymptotic bounds of the form $2^{\\tau d^{O (k)}}$ on these\nquantities were known before, some applications require bounds which are\nexplicit and which hold for all values of $s, d, k$ and $\\tau$. The bounds\nproved in this paper are of this nature."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0911.1412v2", 
    "title": "From Abstract Rewriting Systems to Abstract Proof Systems", 
    "arxiv-id": "0911.1412v2", 
    "author": "Clemens Grabmayer", 
    "publish": "2009-11-07T12:48:23Z", 
    "summary": "Some personal recollections on the introduction of `abstract proof systems'\nas a framework for formulating syntax-independent, general results about rule\nderivability and admissibility. With a particular eye on the inspiration I owe\nto Roel de Vrijer: the analogy with abstract rewriting systems."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0911.3110v1", 
    "title": "Faster exponentials of power series", 
    "arxiv-id": "0911.3110v1", 
    "author": "David Harvey", 
    "publish": "2009-11-16T18:22:48Z", 
    "summary": "We describe a new algorithm for computing exp(f) where f is a power series in\nC[[x]]. If M(n) denotes the cost of multiplying polynomials of degree n, the\nnew algorithm costs (2.1666... + o(1)) M(n) to compute exp(f) to order n. This\nimproves on the previous best result, namely (2.333... + o(1)) M(n)."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0911.3503v2", 
    "title": "The Hilbert scheme of points and its link with border basis", 
    "arxiv-id": "0911.3503v2", 
    "author": "Bernard Mourrain", 
    "publish": "2009-11-18T10:50:19Z", 
    "summary": "In this paper, we give new explicit representations of the Hilbert scheme of\n$\\mu$ points in $\\PP^{r}$ as a projective subvariety of a Grassmanniann\nvariety. This new explicit description of the Hilbert scheme is simpler than\nthe previous ones and global. It involves equations of degree $2$. We show how\nthese equations are deduced from the commutation relations characterizing\nborder bases. Next, we consider infinitesimal perturbations of an input system\nof equations on this Hilbert scheme and describe its tangent space. We propose\nan effective criterion to test if it is a flat deformation, that is if the\nperturbed system remains on the Hilbert scheme of the initial equations. This\ncriterion involves in particular formal reduction with respect to border bases."
},{
    "category": "cs.DS", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0911.4940v1", 
    "title": "Efficient Higher Order Derivatives of Objective Functions Composed of   Matrix Operations", 
    "arxiv-id": "0911.4940v1", 
    "author": "Sebastian F. Walter", 
    "publish": "2009-11-25T20:05:24Z", 
    "summary": "This paper is concerned with the efficient evaluation of higher-order\nderivatives of functions $f$ that are composed of matrix operations. I.e., we\nwant to compute the $D$-th derivative tensor $\\nabla^D f(X) \\in \\mathbb\nR^{N^D}$, where $f:\\mathbb R^{N} \\to \\mathbb R$ is given as an algorithm that\nconsists of many matrix operations. We propose a method that is a combination\nof two well-known techniques from Algorithmic Differentiation (AD): univariate\nTaylor propagation on scalars (UTPS) and first-order forward and reverse on\nmatrices. The combination leads to a technique that we would like to call\nunivariate Taylor propagation on matrices (UTPM). The method inherits many\ndesirable properties: It is easy to implement, it is very efficient and it\nreturns not only $\\nabla^D f$ but yields in the process also the derivatives\n$\\nabla^d f$ for $d \\leq D$. As performance test we compute the gradient\n$\\nabla f(X)$ % and the Hessian $\\nabla_A^2 f(A)$ by a combination of forward\nand reverse mode of $f(X) = \\trace (X^{-1})$ in the reverse mode of AD for $X\n\\in \\mathbb R^{n \\times n}$. We observe a speedup of about 100 compared to\nUTPS. Due to the nature of the method, the memory footprint is also small and\ntherefore can be used to differentiate functions that are not accessible by\nstandard methods due to limited physical memory."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0911.5707v1", 
    "title": "Linear Solving for Sign Determination", 
    "arxiv-id": "0911.5707v1", 
    "author": "Daniel Perrucci", 
    "publish": "2009-11-30T18:12:58Z", 
    "summary": "We give a specific method to solve with quadratic complexity the linear\nsystems arising in known algorithms to deal with the sign determination\nproblem. In particular, this enable us to improve the complexity bound for sign\ndetermination in the univariate case."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/0912.4438v1", 
    "title": "The weighted difference substitutions and Nonnegativity Decision of   Forms", 
    "arxiv-id": "0912.4438v1", 
    "author": "Junwei Shao", 
    "publish": "2009-12-22T16:31:16Z", 
    "summary": "In this paper, we study the weighted difference substitutions from\ngeometrical views. First, we give the geometric meanings of the weighted\ndifference substitutions, and introduce the concept of convergence of the\nsequence of substitution sets. Then it is proven that the sequence of the\nsuccessive weighted difference substitution sets is convergent. Based on the\nconvergence of the sequence of the successive weighted difference sets, a new,\nsimpler method to prove that if the form F is positive definite on T_n, then\nthe sequence of sets {SDS^m(F)} is positively terminating is presented, which\nis different from the one given in [11]. That is, we can decide the\nnonnegativity of a positive definite form by successively running the weighted\ndifference substitutions finite times. Finally, an algorithm for deciding an\nindefinite form with a counter-example is obtained, and some examples are\nlisted by using the obtained algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/1001.2940v1", 
    "title": "Parallel computation of real solving bivariate polynomial systems by   zero-matching method", 
    "arxiv-id": "1001.2940v1", 
    "author": "Jingzhong Zhang", 
    "publish": "2010-01-18T01:57:49Z", 
    "summary": "We present a new algorithm for solving the real roots of a bivariate\npolynomial system $\\Sigma=\\{f(x,y),g(x,y)\\}$ with a finite number of solutions\nby using a zero-matching method. The method is based on a lower bound for\nbivariate polynomial system when the system is non-zero. Moreover, the\nmultiplicities of the roots of $\\Sigma=0$ can be obtained by a given\nneighborhood. From this approach, the parallelization of the method arises\nnaturally. By using a multidimensional matching method this principle can be\ngeneralized to the multivariate equation systems."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/1001.4150v1", 
    "title": "Generic design of Chinese remaindering schemes", 
    "arxiv-id": "1001.4150v1", 
    "author": "Jean-Louis Roch", 
    "publish": "2010-01-23T12:34:28Z", 
    "summary": "We propose a generic design for Chinese remainder algorithms. A Chinese\nremainder computation consists in reconstructing an integer value from its\nresidues modulo non coprime integers. We also propose an efficient linear data\nstructure, a radix ladder, for the intermediate storage and computations. Our\ndesign is structured into three main modules: a black box residue computation\nin charge of computing each residue; a Chinese remaindering controller in\ncharge of launching the computation and of the termination decision; an integer\nbuilder in charge of the reconstruction computation. We then show that this\ndesign enables many different forms of Chinese remaindering (e.g.\ndeterministic, early terminated, distributed, etc.), easy comparisons between\nthese forms and e.g. user-transparent parallelism at different parallel grains."
},{
    "category": "cs.GT", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/1001.4887v1", 
    "title": "Some Algebraic Properties of a Subclass of Finite Normal Form Games", 
    "arxiv-id": "1001.4887v1", 
    "author": "Ratnik Gandhi", 
    "publish": "2010-01-27T12:22:16Z", 
    "summary": "We study the problem of computing all Nash equilibria of a subclass of finite\nnormal form games. With algebraic characterization of the games, we present a\nmethod for computing all its Nash equilibria. Further, we present a method for\ndeciding membership to the class of games with its related results. An\nappendix, containing an example to show working of each of the presented\nmethods, concludes the work."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/1002.0739v1", 
    "title": "Gradual sub-lattice reduction and a new complexity for factoring   polynomials", 
    "arxiv-id": "1002.0739v1", 
    "author": "Andrew Novocin", 
    "publish": "2010-02-03T13:34:49Z", 
    "summary": "We present a lattice algorithm specifically designed for some classical\napplications of lattice reduction. The applications are for lattice bases with\na generalized knapsack-type structure, where the target vectors are boundably\nshort. For such applications, the complexity of the algorithm improves\ntraditional lattice reduction by replacing some dependence on the bit-length of\nthe input vectors by some dependence on the bound for the output vectors. If\nthe bit-length of the target vectors is unrelated to the bit-length of the\ninput, then our algorithm is only linear in the bit-length of the input\nentries, which is an improvement over the quadratic complexity floating-point\nLLL algorithms. To illustrate the usefulness of this algorithm we show that a\ndirect application to factoring univariate polynomials over the integers leads\nto the first complexity bound improvement since 1984. A second application is\nalgebraic number reconstruction, where a new complexity bound is obtained as\nwell."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/1002.2594v1", 
    "title": "Fast Arithmetics in Artin-Schreier Towers over Finite Fields", 
    "arxiv-id": "1002.2594v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2010-02-12T16:44:18Z", 
    "summary": "An Artin-Schreier tower over the finite field F_p is a tower of field\nextensions generated by polynomials of the form X^p - X - a. Following Cantor\nand Couveignes, we give algorithms with quasi-linear time complexity for\narithmetic operations in such towers. As an application, we present an\nimplementation of Couveignes' algorithm for computing isogenies between\nelliptic curves using the p-torsion."
},{
    "category": "cs.MS", 
    "doi": "10.1016/j.cagd.2010.07.001", 
    "link": "http://arxiv.org/pdf/1002.3180v1", 
    "title": "Factorization of Non-Commutative Polynomials", 
    "arxiv-id": "1002.3180v1", 
    "author": "Fabrizio Caruso", 
    "publish": "2010-02-16T22:17:56Z", 
    "summary": "We describe an algorithm for the factorization of non-commutative polynomials\nover a field. The first sketch of this algorithm appeared in an unpublished\nmanuscript (literally hand written notes) by James H. Davenport more than 20\nyears ago. This version of the algorithm contains some improvements with\nrespect to the original sketch. An improved version of the algorithm has been\nfully implemented in the Axiom computer algebra system."
},{
    "category": "math.CO", 
    "doi": "10.1073/pnas.1019186108", 
    "link": "http://arxiv.org/pdf/1002.4384v2", 
    "title": "Proof of George Andrews's and David Robbins's q-TSPP Conjecture", 
    "arxiv-id": "1002.4384v2", 
    "author": "Doron Zeilberger", 
    "publish": "2010-02-23T18:09:17Z", 
    "summary": "The conjecture that the orbit-counting generating function for totally\nsymmetric plane partitions can be written as an explicit product formula, has\nbeen stated independently by George Andrews and David Robbins around 1983. We\npresent a proof of this long-standing conjecture."
},{
    "category": "cs.SC", 
    "doi": "10.1073/pnas.1019186108", 
    "link": "http://arxiv.org/pdf/1003.3181v1", 
    "title": "Stability Analysis of Linear Uncertain Systems via Checking Positivity   of Forms on Simplices", 
    "arxiv-id": "1003.3181v1", 
    "author": "Junwei Shao", 
    "publish": "2010-03-16T16:42:15Z", 
    "summary": "In this paper, we mainly study the robust stability of linear continuous\nsystems with parameter uncertainties, a more general kind of uncertainties for\nsystem matrices is considered, i.e., entries of system matrices are rational\nfunctions of uncertain parameters which are varying in intervals. we present a\nmethod which can check the robust Hurwitz stability of such uncertain systems\nin finite steps. Examples show the efficiency of our approach."
},{
    "category": "cs.CR", 
    "doi": "10.1073/pnas.1019186108", 
    "link": "http://arxiv.org/pdf/1003.5384v2", 
    "title": "Protocol indepedence through disjoint encryption under Exclusive-OR", 
    "arxiv-id": "1003.5384v2", 
    "author": "Sreekanth Malladi", 
    "publish": "2010-03-28T18:01:04Z", 
    "summary": "Multi-protocol attacks due to protocol interaction has been a notorious\nproblem for security. Gutman-Thayer proved that they can be prevented by\nensuring that encrypted messages are distinguishable across protocols, under a\nfree algebra. In this paper, we prove that a similar suggestion prevents these\nattacks under commonly used operators such as Exclusive-OR, that induce\nequational theories, breaking the free algebra assumption."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11786-010-0055-0", 
    "link": "http://arxiv.org/pdf/1004.3314v2", 
    "title": "A Fast Approach to Creative Telescoping", 
    "arxiv-id": "1004.3314v2", 
    "author": "Christoph Koutschan", 
    "publish": "2010-04-19T22:03:57Z", 
    "summary": "In this note we reinvestigate the task of computing creative telescoping\nrelations in differential-difference operator algebras. Our approach is based\non an ansatz that explicitly includes the denominators of the delta parts. We\ncontribute several ideas of how to make an implementation of this approach\nreasonably fast and provide such an implementation. A selection of examples\nshows that it can be superior to existing methods by a large factor."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11786-010-0055-0", 
    "link": "http://arxiv.org/pdf/1004.4641v2", 
    "title": "Chunky and Equal-Spaced Polynomial Multiplication", 
    "arxiv-id": "1004.4641v2", 
    "author": "Daniel S. Roche", 
    "publish": "2010-04-26T20:12:37Z", 
    "summary": "Finding the product of two polynomials is an essential and basic problem in\ncomputer algebra. While most previous results have focused on the worst-case\ncomplexity, we instead employ the technique of adaptive analysis to give an\nimprovement in many \"easy\" cases. We present two adaptive measures and methods\nfor polynomial multiplication, and also show how to effectively combine them to\ngain both advantages. One useful feature of these algorithms is that they\nessentially provide a gradient between existing \"sparse\" and \"dense\" methods.\nWe prove that these approaches provide significant improvements in many cases\nbut in the worst case are still comparable to the fastest existing algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2010.05.001", 
    "link": "http://arxiv.org/pdf/1004.5285v1", 
    "title": "Nearly Optimal Algorithms for the Decomposition of Multivariate Rational   Functions and the Extended L\u00fcroth's Theorem", 
    "arxiv-id": "1004.5285v1", 
    "author": "Guillaume Ch\u00e8ze", 
    "publish": "2010-04-29T13:46:26Z", 
    "summary": "The extended L\\\"uroth's Theorem says that if the transcendence degree of\n$\\KK(\\mathsf{f}_1,\\dots,\\mathsf{f}_m)/\\KK$ is 1 then there exists $f \\in\n\\KK(\\underline{X})$ such that $\\KK(\\mathsf{f}_1,\\dots,\\mathsf{f}_m)$ is equal\nto $\\KK(f)$. In this paper we show how to compute $f$ with a probabilistic\nalgorithm. We also describe a probabilistic and a deterministic algorithm for\nthe decomposition of multivariate rational functions. The probabilistic\nalgorithms proposed in this paper are softly optimal when $n$ is fixed and $d$\ntends to infinity. We also give an indecomposability test based on gcd\ncomputations and Newton's polytope. In the last section, we show that we get a\npolynomial time algorithm, with a minor modification in the exponential time\ndecomposition algorithm proposed by Gutierez-Rubio-Sevilla in 2001."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2010.05.001", 
    "link": "http://arxiv.org/pdf/1004.5549v1", 
    "title": "Symbolic Domain Decomposition", 
    "arxiv-id": "1004.5549v1", 
    "author": "Stephen M. Watt", 
    "publish": "2010-04-30T15:02:47Z", 
    "summary": "Decomposing the domain of a function into parts has many uses in mathematics.\nA domain may naturally be a union of pieces, a function may be defined by\ncases, or different boundary conditions may hold on different regions. For any\nparticular problem the domain can be given explicitly, but when dealing with a\nfamily of problems given in terms of symbolic parameters, matters become more\ndifficult. This article shows how hybrid sets, that is multisets allowing\nnegative multiplicity, may be used to express symbolic domain decompositions in\nan efficient, elegant and uniform way, simplifying both computation and\nreasoning. We apply this theory to the arithmetic of piecewise functions and\nsymbolic matrices and show how certain operations may be reduced from\nexponential to linear complexity."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1837210.1837218", 
    "link": "http://arxiv.org/pdf/1005.0830v1", 
    "title": "Generic design of Chinese remaindering schemes", 
    "arxiv-id": "1005.0830v1", 
    "author": "Jean-Louis Roch", 
    "publish": "2010-05-05T19:45:22Z", 
    "summary": "We propose a generic design for Chinese remainder algorithms. A Chinese\nremainder computation consists in reconstructing an integer value from its\nresidues modulo non coprime integers. We also propose an efficient linear data\nstructure, a radix ladder, for the intermediate storage and computations. Our\ndesign is structured into three main modules: a black box residue computation\nin charge of computing each residue; a Chinese remaindering controller in\ncharge of launching the computation and of the termination decision; an integer\nbuilder in charge of the reconstruction computation. We then show that this\ndesign enables many different forms of Chinese remaindering (e.g.\ndeterministic, early terminated, distributed, etc.), easy comparisons between\nthese forms and e.g. user-transparent parallelism at different parallel grains."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1837210.1837218", 
    "link": "http://arxiv.org/pdf/1005.0990v1", 
    "title": "Polynomial integration on regions defined by a triangle and a conic", 
    "arxiv-id": "1005.0990v1", 
    "author": "Daniel Wachsmuth", 
    "publish": "2010-05-06T12:55:28Z", 
    "summary": "We present an efficient solution to the following problem, of relevance in a\nnumerical optimization scheme: calculation of integrals of the type \\[\\iint_{T\n\\cap \\{f\\ge0\\}} \\phi_1\\phi_2 \\, dx\\,dy\\] for quadratic polynomials\n$f,\\phi_1,\\phi_2$ on a plane triangle $T$. The naive approach would involve\nconsideration of the many possible shapes of $T\\cap\\{f\\geq0\\}$ (possibly after\na convenient transformation) and parameterizing its border, in order to\nintegrate the variables separately. Our solution involves partitioning the\ntriangle into smaller triangles on which integration is much simpler."
},{
    "category": "math.AC", 
    "doi": "10.1145/1837210.1837218", 
    "link": "http://arxiv.org/pdf/1005.1087v1", 
    "title": "Composition collisions and projective polynomials", 
    "arxiv-id": "1005.1087v1", 
    "author": "Konstantin Ziegler", 
    "publish": "2010-05-06T21:19:06Z", 
    "summary": "The functional decomposition of polynomials has been a topic of great\ninterest and importance in pure and computer algebra and their applications.\nThe structure of compositions of (suitably normalized) polynomials f=g(h) over\nfinite fields is well understood in many cases, but quite poorly when the\ndegrees of both components are divisible by the characteristic p. This work\ninvestigates the decomposition of polynomials whose degree is a power of p."
},{
    "category": "math.AG", 
    "doi": "10.1145/1837210.1837218", 
    "link": "http://arxiv.org/pdf/1005.3257v1", 
    "title": "Constructive $D$-module Theory with \\textsc{Singular}", 
    "arxiv-id": "1005.3257v1", 
    "author": "Hans Sch\u00f6nemann", 
    "publish": "2010-05-18T17:15:05Z", 
    "summary": "We overview numerous algorithms in computational $D$-module theory together\nwith the theoretical background as well as the implementation in the computer\nalgebra system \\textsc{Singular}. We discuss new approaches to the computation\nof Bernstein operators, of logarithmic annihilator of a polynomial, of\nannihilators of rational functions as well as complex powers of polynomials. We\nanalyze algorithms for local Bernstein-Sato polynomials and also algorithms,\nrecovering any kind of Bernstein-Sato polynomial from partial knowledge of its\nroots. We address a novel way to compute the Bernstein-Sato polynomial for an\naffine variety algorithmically. All the carefully selected nontrivial examples,\nwhich we present, have been computed with our implementation. We address such\napplications as the computation of a zeta-function for certain integrals and\nrevealing the algebraic dependence between pairwise commuting elements."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1837210.1837218", 
    "link": "http://arxiv.org/pdf/1005.3731v1", 
    "title": "Nominal Unification from a Higher-Order Perspective", 
    "arxiv-id": "1005.3731v1", 
    "author": "Mateu Villaret", 
    "publish": "2010-05-20T15:10:27Z", 
    "summary": "Nominal Logic is a version of first-order logic with equality, name-binding,\nrenaming via name-swapping and freshness of names. Contrarily to higher-order\nlogic, bindable names, called atoms, and instantiable variables are considered\nas distinct entities. Moreover, atoms are capturable by instantiations,\nbreaking a fundamental principle of lambda-calculus. Despite these differences,\nnominal unification can be seen from a higher-order perspective. From this\nview, we show that nominal unification can be reduced to a particular fragment\nof higher-order unification problems: Higher-Order Pattern Unification. This\nreduction proves that nominal unification can be decided in quadratic\ndeterministic time, using the linear algorithm for Higher-Order Pattern\nUnification. We also prove that the translation preserves most generality of\nunifiers."
},{
    "category": "cs.GT", 
    "doi": "10.1145/1837210.1837218", 
    "link": "http://arxiv.org/pdf/1005.5507v1", 
    "title": "An Algebraic Approach for Computing Equilibria of a Subclass of Finite   Normal Form Games", 
    "arxiv-id": "1005.5507v1", 
    "author": "Ratnik Gandhi", 
    "publish": "2010-05-30T07:38:29Z", 
    "summary": "A Nash equilibrium has become important solution concept for analyzing the\ndecision making in Game theory. In this paper, we consider the problem of\ncomputing Nash equilibria of a subclass of generic finite normal form games. We\ndefine \"rational payoff irrational equilibria games\" to be the games with all\nrational payoffs and all irrational equilibria. We present a purely algebraic\nmethod for computing all Nash equilibria of these games that uses knowledge of\nGalois groups. Some results, showing properties of the class of games, and an\nexample to show working of the method concludes the paper."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00283-010-9192-1", 
    "link": "http://arxiv.org/pdf/1006.0200v2", 
    "title": "The 1958 Pekeris-Accad-WEIZAC Ground-Breaking Collaboration that   Computed Ground States of Two-Electron Atoms (and its 2010 Redux)", 
    "arxiv-id": "1006.0200v2", 
    "author": "Doron Zeilberger", 
    "publish": "2010-06-01T17:55:11Z", 
    "summary": "In order to appreciate how well off we mathematicians and scientists are\ntoday, with extremely fast hardware and lots and lots of memory, as well as\nwith powerful software, both for numeric and symbolic computation, it may be a\ngood idea to go back to the early days of electronic computers and compare how\nthings went then. We have chosen, as a case study, a problem that was\nconsidered a huge challenge at the time. Namely, we looked at C.L. Pekeris's\nseminal 1958 work on the ground state energies of two-electron atoms. We went\nthrough all the computations ab initio with today's software and hardware, with\na special emphasis on the symbolic computations which in 1958 had to be made by\nhand, and which nowadays can be automated and generalized."
},{
    "category": "hep-ph", 
    "doi": "10.1007/s00283-010-9192-1", 
    "link": "http://arxiv.org/pdf/1006.2099v1", 
    "title": "Parallel versions of the symbolic manipulation system FORM", 
    "arxiv-id": "1006.2099v1", 
    "author": "J. Vollinga", 
    "publish": "2010-06-10T18:07:15Z", 
    "summary": "The symbolic manipulation program FORM is specialized to handle very large\nalgebraic expressions. Some specific features of its internal structure make\nFORM very well suited for parallelization.\n  We have now two parallel versions of FORM, one is based on POSIX threads and\nis optimal for modern multicore computers while another one uses MPI and can be\nused to parallelize FORM on clusters and Massive Parallel Processing systems.\nMost existing FORM programs will be able to take advantage of the parallel\nexecution without the need for modifications."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00283-010-9192-1", 
    "link": "http://arxiv.org/pdf/1006.5768v1", 
    "title": "A Unified Formal Description of Arithmetic and Set Theoretical Data   Types", 
    "arxiv-id": "1006.5768v1", 
    "author": "Paul Tarau", 
    "publish": "2010-06-30T05:07:40Z", 
    "summary": "We provide a \"shared axiomatization\" of natural numbers and hereditarily\nfinite sets built around a polymorphic abstraction of bijective base-2\narithmetics.\n  The \"axiomatization\" is described as a progressive refinement of Haskell type\nclasses with examples of instances converging to an efficient implementation in\nterms of arbitrary length integers and bit operations. As an instance, we\nderive algorithms to perform arithmetic operations efficiently directly with\nhereditarily finite sets.\n  The self-contained source code of the paper is available at\nhttp://logic.cse.unt.edu/tarau/research/2010/unified.hs ."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1008.4104v2", 
    "title": "Quartic Curves and Their Bitangents", 
    "arxiv-id": "1008.4104v2", 
    "author": "Cynthia Vinzant", 
    "publish": "2010-08-24T18:27:48Z", 
    "summary": "A smooth quartic curve in the complex projective plane has 36 inequivalent\nrepresentations as a symmetric determinant of linear forms and 63\nrepresentations as a sum of three squares. These correspond to Cayley octads\nand Steiner complexes respectively. We present exact algorithms for computing\nthese objects from the 28 bitangents. This expresses Vinnikov quartics as\nspectrahedra and positive quartics as Gram matrices. We explore the geometry of\nGram spectrahedra and we find equations for the variety of Cayley octads.\nInterwoven is an exposition of much of the 19th century theory of plane\nquartics."
},{
    "category": "q-bio.QM", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1008.4938v1", 
    "title": "Towards Solving the Inverse Protein Folding Problem", 
    "arxiv-id": "1008.4938v1", 
    "author": "Randen L. Patterson", 
    "publish": "2010-08-29T15:34:02Z", 
    "summary": "Accurately assigning folds for divergent protein sequences is a major\nobstacle to structural studies and underlies the inverse protein folding\nproblem. Herein, we outline our theories for fold-recognition in the\n\"twilight-zone\" of sequence similarity (<25% identity). Our analyses\ndemonstrate that structural sequence profiles built using Position-Specific\nScoring Matrices (PSSMs) significantly outperform multiple popular\nhomology-modeling algorithms for relating and predicting structures given only\ntheir amino acid sequences. Importantly, structural sequence profiles\nreconstitute SCOP fold classifications in control and test datasets. Results\nfrom our experiments suggest that structural sequence profiles can be used to\nrapidly annotate protein folds at proteomic scales. We propose that encoding\nthe entire Protein DataBank (~1070 folds) into structural sequence profiles\nwould extract interoperable information capable of improving most if not all\nmethods of structural modeling."
},{
    "category": "math.CA", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1008.5080v1", 
    "title": "A Geometric Index Reduction Method for Implicit Systems of Differential   Algebraic Equations", 
    "arxiv-id": "1008.5080v1", 
    "author": "Pablo Solern\u00f3", 
    "publish": "2010-08-30T13:31:52Z", 
    "summary": "This paper deals with the index reduction problem for the class of\nquasi-regular DAE systems. It is shown that any of these systems can be\ntransformed to a generically equivalent first order DAE system consisting of a\nsingle purely algebraic (polynomial) equation plus an under-determined ODE\n(that is, a semi-explicit DAE system of differentiation index 1) in as many\nvariables as the order of the input system. This can be done by means of a\nKronecker-type algorithm with bounded complexity."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1009.0148v2", 
    "title": "Intersection Theory in Differential Algebraic Geometry: Generic   Intersections and the Differential Chow Form", 
    "arxiv-id": "1009.0148v2", 
    "author": "Chun-Ming Yuan", 
    "publish": "2010-09-01T09:54:02Z", 
    "summary": "In this paper, an intersection theory for generic differential polynomials is\npresented. The intersection of an irreducible differential variety of dimension\n$d$ and order $h$ with a generic differential hypersurface of order $s$ is\nshown to be an irreducible variety of dimension $d-1$ and order $h+s$. As a\nconsequence, the dimension conjecture for generic differential polynomials is\nproved. Based on the intersection theory, the Chow form for an irreducible\ndifferential variety is defined and most of the properties of the Chow form in\nthe algebraic case are established for its differential counterpart.\nFurthermore, the generalized differential Chow form is defined and its\nproperties are proved. As an application of the generalized differential Chow\nform, the differential resultant of $n+1$ generic differential polynomials in\n$n$ variables is defined and properties similar to that of the Macaulay\nresultant for multivariate polynomials are proved."
},{
    "category": "cs.RO", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1010.6214v1", 
    "title": "The assembly modes of rigid 11-bar linkages", 
    "arxiv-id": "1010.6214v1", 
    "author": "Guillaume Moroz", 
    "publish": "2010-10-29T14:05:57Z", 
    "summary": "Designing an m-bar linkage with a maximal number of assembly modes is\nimportant in robot kinematics, and has further applications in structural\nbiology and computational geometry. A related question concerns the number of\nassembly modes of rigid mechanisms as a function of their nodes n, which is\nuniquely defined given m. Rigid 11-bar linkages, where n=7, are the simplest\nplanar linkages for which these questions were still open. It will be proven\nthat the maximal number of assembly modes of such linkages is exactly 56. The\nrigidity of a linkage is captured by a polynomial system derived from distance,\nor Cayley-Menger, matrices. The upper bound on the number of assembly modes is\nobtained as the mixed volume of a 5x5 system. An 11-bar linkage admitting 56\nconfigurations is constructed using stochastic optimisation methods. This\nyields a general lower bound of $\\Omega(2.3^n)$ on the number of assembly\nmodes, slightly improving the current record of $\\Omega(2.289^n)$, while the\nbest known upper bound is roughly $4^n$. Our methods are straightforward and\nhave been implemented in Maple. They are described in general terms\nillustrating the fact that they can be readily extended to other planar or\nspatial linkages."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1011.1578v1", 
    "title": "The $z$-Transform and Automata-Recognizable Systems of Nonhomogeneous   Linear Recurrence Equations over Semirings", 
    "arxiv-id": "1011.1578v1", 
    "author": "Edoardo Carta-Gerardino", 
    "publish": "2010-11-06T18:50:05Z", 
    "summary": "A nonhomogeneous system of linear recurrence equations can be recognized by\nan automaton $\\mathcal{A}$ over a one-letter alphabet $A = \\{z\\}$. Conversely,\nthe automaton $\\mathcal{A}$ generates precisely this nonhomogeneous system of\nlinear recurrence equations. We present the solutions of these systems and\napply the $z$-transform to these solutions to obtain their series\nrepresentation. Finally, we show some results that simplify the series\nrepresentation of the $z$-transform of these solutions. We consider single\nsystems as well as the composition of two systems."
},{
    "category": "math.RA", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1011.2039v2", 
    "title": "An algorithm for determining copositive matrices", 
    "arxiv-id": "1011.2039v2", 
    "author": "Yong Yao", 
    "publish": "2010-11-09T11:04:25Z", 
    "summary": "In this paper, we present an algorithm of simple exponential growth called\nCOPOMATRIX for determining the copositivity of a real symmetric matrix. The\ncore of this algorithm is a decomposition theorem, which is used to deal with\nsimplicial subdivision of $\\hat{T}^{-}=\\{y\\in \\Delta_{m}| \\beta^Ty\\leq 0\\}$ on\nthe standard simplex $\\Delta_m$, where each component of the vector $\\beta$ is\n-1, 0 or 1."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1011.3721v1", 
    "title": "On the Inverse Of General Cyclic Heptadiagonal and Anti-Heptadiagonal   Matrices", 
    "arxiv-id": "1011.3721v1", 
    "author": "A. A. Karawia", 
    "publish": "2010-11-15T11:42:22Z", 
    "summary": "In the current work, the author present a symbolic algorithm for finding the\ndeterminant of any general nonsingular cyclic heptadiagonal matrices and\ninverse of anti-cyclic heptadiagonal matrices. The algorithms are mainly based\non the work presented in [A. A. KARAWIA, A New Algorithm for Inverting General\nCyclic Heptadiagonal Matrices Recursively, arXiv:1011.2306v1 [cs.SC]]. The\nsymbolic algorithms are suited for implementation using Computer Algebra\nSystems (CAS) such as MATLAB, MAPLE and MATHEMATICA. An illustrative example is\ngiven."
},{
    "category": "cs.CR", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1011.5545v1", 
    "title": "On Functional Decomposition of Multivariate Polynomials with   Differentiation and Homogenization", 
    "arxiv-id": "1011.5545v1", 
    "author": "Xiao-Shan Gao", 
    "publish": "2010-11-25T03:11:19Z", 
    "summary": "In this paper, we give a theoretical analysis for the algorithms to compute\nfunctional decomposition for multivariate polynomials based on differentiation\nand homogenization which are proposed by Ye, Dai, Lam (1999) and Faug$\\mu$ere,\nPerret (2006, 2008, 2009). We show that a degree proper functional\ndecomposition for a set of randomly decomposable quartic homogenous polynomials\ncan be computed using the algorithm with high probability. This solves a\nconjecture proposed by Ye, Dai, and Lam (1999). We also propose a conjecture\nsuch that the decomposition for a set of polynomials can be computed from that\nof its homogenization with high probability. Finally, we prove that the right\ndecomposition factors for a set of polynomials can be computed from its right\ndecomposition factor space. Combining these results together, we prove that the\nalgorithm can compute a degree proper decomposition for a set of randomly\ndecomposable quartic polynomials with probability one when the base field is of\ncharacteristic zero, and with probability close to one when the base field is a\nfinite field with sufficiently large number under the assumption that the\nconjeture is correct."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1011.6505v1", 
    "title": "Efficient Characteristic Set Algorithms for Equation Solving in Finite   Fields and Applications in Cryptanalysis", 
    "arxiv-id": "1011.6505v1", 
    "author": "Zhenyu Huang", 
    "publish": "2010-11-30T09:51:40Z", 
    "summary": "Efficient characteristic set methods for computing solutions of polynomial\nequation systems in a finite field are proposed. The concept of proper\ntriangular sets is introduced and an explicit formula for the number of\nsolutions of a proper and monic (or regular) triangular set is given. An\nimproved zero decomposition algorithm which can be used to reduce the zero set\nof an equation system in general form to the union of zero sets of monic proper\ntriangular sets is proposed. As a consequence, we can give an explicit formula\nfor the number of solutions of an equation system. Bitsize complexity for the\nalgorithm is given in the case of Boolean polynomials. We also give a\nmultiplication free characteristic set method for Boolean polynomials, where\nthe sizes of the polynomials are effectively controlled. The algorithms are\nimplemented in the case of Boolean polynomials and extensive experiments show\nthat they are quite efficient for solving certain classes of Boolean equations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1012.0096v2", 
    "title": "Isomorphisms of Algebraic Number Fields", 
    "arxiv-id": "1012.0096v2", 
    "author": "Vivek Pal", 
    "publish": "2010-12-01T05:19:45Z", 
    "summary": "Let $\\mathbb{Q}(\\alpha)$ and $\\mathbb{Q}(\\beta)$ be algebraic number fields.\nWe describe a new method to find (if they exist) all isomorphisms,\n$\\mathbb{Q}(\\beta) \\rightarrow \\mathbb{Q}(\\alpha)$. The algorithm is\nparticularly efficient if the number of isomorphisms is one."
},{
    "category": "math.FA", 
    "doi": "10.1016/j.jsc.2011.01.007", 
    "link": "http://arxiv.org/pdf/1012.2453v3", 
    "title": "How to refine polynomial functions", 
    "arxiv-id": "1012.2453v3", 
    "author": "Henning Thielemann", 
    "publish": "2010-12-11T12:31:25Z", 
    "summary": "Research on refinable functions in wavelet theory is mostly focused to\nlocalized functions. However it is known, that polynomial functions are\nrefinable, too. In our paper we investigate on conversions between refinement\nmasks and polynomials and their uniqueness."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.42.2", 
    "link": "http://arxiv.org/pdf/1012.4891v1", 
    "title": "Unification modulo a partial theory of exponentiation", 
    "arxiv-id": "1012.4891v1", 
    "author": "Paliath Narendran", 
    "publish": "2010-12-22T07:07:45Z", 
    "summary": "Modular exponentiation is a common mathematical operation in modern\ncryptography. This, along with modular multiplication at the base and exponent\nlevels (to different moduli) plays an important role in a large number of key\nagreement protocols. In our earlier work, we gave many decidability as well as\nundecidability results for multiple equational theories, involving various\nproperties of modular exponentiation. Here, we consider a partial subtheory\nfocussing only on exponentiation and multiplication operators. Two main results\nare proved. The first result is positive, namely, that the unification problem\nfor the above theory (in which no additional property is assumed of the\nmultiplication operators) is decidable. The second result is negative: if we\nassume that the two multiplication operators belong to two different abelian\ngroups, then the unification problem becomes undecidable."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1012.4894v1", 
    "title": "On the Complexity of the Tiden-Arnborg Algorithm for Unification modulo   One-Sided Distributivity", 
    "arxiv-id": "1012.4894v1", 
    "author": "Bibhu Mahapatra", 
    "publish": "2010-12-22T07:08:05Z", 
    "summary": "We prove that the Tiden and Arnborg algorithm for equational unification\nmodulo one-sided distributivity is not polynomial time bounded as previously\nthought. A set of counterexamples is developed that demonstrates that the\nalgorithm goes through exponentially many steps."
},{
    "category": "math.AC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1012.5210v1", 
    "title": "Modular absolute decomposition of equidimensional polynomial ideals", 
    "arxiv-id": "1012.5210v1", 
    "author": "Cristina Bertone", 
    "publish": "2010-12-23T14:21:36Z", 
    "summary": "In this paper, we present a modular strategy which describes key properties\nof the absolute primary decomposition of an equidimensional polynomial ideal\ndefined by polynomials with rational coefficients. The algorithm we design is\nbased on the classical technique of elimination of variables and colon ideals\nand uses a tricky choice of prime integers to work with. Thanks to this\ntechnique, we can obtain the number of absolute irreducible components, their\ndegree, multiplicity and also the affine Hilbert function of the reduced\ncomponents (namely, their initial ideal w.r.t. a degree-compatible term\nordering) ."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1012.5425v2", 
    "title": "A new conception for computing gr\u00f6bner basis and its applications", 
    "arxiv-id": "1012.5425v2", 
    "author": "Lei Huang", 
    "publish": "2010-12-24T19:24:22Z", 
    "summary": "This paper presents a conception for computing gr\\\"{o}bner basis. We convert\nsome of gr\\\"{o}bner-computing algorithms, e.g., F5, extended F5 and GWV\nalgorithms into a special type of algorithm. The new algorithm's finite\ntermination problem can be described by equivalent conditions, so all the above\nalgorithms can be determined when they terminate finitely. At last, a new\ncriterion is presented. It is an improvement for the Rewritten and Signature\nCriterion."
},{
    "category": "hep-ph", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1101.0511v1", 
    "title": "FORM development", 
    "arxiv-id": "1101.0511v1", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2011-01-03T12:59:35Z", 
    "summary": "I give an overview of FORM development based on a few pilot projects,\nexplaining how they have influenced the FORM capabilities. Next I explain what\nis happnening right now in the field of Open Sourcing and the FORM Forum."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1101.3218v3", 
    "title": "A Symbolic Transformation Language and its Application to a Multiscale   Method", 
    "arxiv-id": "1101.3218v3", 
    "author": "Michel Lenczner", 
    "publish": "2011-01-17T14:06:26Z", 
    "summary": "The context of this work is the design of a software, called MEMSALab,\ndedicated to the automatic derivation of multiscale models of arrays of micro-\nand nanosystems. In this domain a model is a partial differential equation.\nMultiscale methods approximate it by another partial differential equation\nwhich can be numerically simulated in a reasonable time. The challenge consists\nin taking into account a wide range of geometries combining thin and periodic\nstructures with the possibility of multiple nested scales.\n  In this paper we present a transformation language that will make the\ndevelopment of MEMSALab more feasible. It is proposed as a Maple package for\nrule-based programming, rewriting strategies and their combination with\nstandard Maple code. We illustrate the practical interest of this language by\nusing it to encode two examples of multiscale derivations, namely the two-scale\nlimit of the derivative operator and the two-scale model of the stationary heat\nequation."
},{
    "category": "math.AC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1101.3589v3", 
    "title": "Signature-based algorithms to compute Groebner bases", 
    "arxiv-id": "1101.3589v3", 
    "author": "John Perry", 
    "publish": "2011-01-19T00:15:41Z", 
    "summary": "This paper describes a Buchberger-style algorithm to compute a Groebner basis\nof a polynomial ideal, allowing for a selection strategy based on \"signatures\".\nWe explain how three recent algorithms can be viewed as different strategies\nfor the new algorithm, and how other selection strategies can be formulated. We\ndescribe a fourth as an example. We analyze the strategies both theoretically\nand empirically, leading to some surprising results."
},{
    "category": "math.CO", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1101.4497v3", 
    "title": "Independence of hyperlogarithms over function fields via algebraic   combinatorics", 
    "arxiv-id": "1101.4497v3", 
    "author": "Allan I. Solomon", 
    "publish": "2011-01-24T11:07:32Z", 
    "summary": "We obtain a necessary and sufficient condition for the linear independence of\nsolutions of differential equations for hyperlogarithms. The key fact is that\nthe multiplier (i.e. the factor $M$ in the differential equation $dS=MS$) has\nonly singularities of first order (Fuchsian-type equations) and this implies\nthat they freely span a space which contains no primitive. We give direct\napplications where we extend the property of linear independence to the largest\nknown ring of coefficients."
},{
    "category": "math.GR", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1101.5598v2", 
    "title": "A Note on the Group-theoretic Approach to Fast Matrix Multiplication", 
    "arxiv-id": "1101.5598v2", 
    "author": "Ivo Hedtke", 
    "publish": "2011-01-28T18:22:51Z", 
    "summary": "In 2003 COHN and UMANS introduced a group-theoretic approach to fast matrix\nmultiplication. This involves finding large subsets S, T and U of a group G\nsatisfying the Triple Product Property (TPP) as a means to bound the exponent\n$\\omega$ of the matrix multiplication. We show that S, T and U may be be\nassumed to contain the identity and be otherwise disjoint. We also give a much\nshorter proof of the upper bound |S|+|T|+|U| <= |G|+2."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1102.0705v2", 
    "title": "Computing Semi-algebraic Invariants for Polynomial Dynamical Systems", 
    "arxiv-id": "1102.0705v2", 
    "author": "Hengjun Zhao", 
    "publish": "2011-02-03T15:30:53Z", 
    "summary": "In this paper, we consider an extended concept of invariant for polynomial\ndynamical system (PDS) with domain and initial condition, and establish a sound\nand complete criterion for checking semi-algebraic invariants (SAI) for such\nPDSs. The main idea is encoding relevant dynamical properties as conditions on\nthe high order Lie derivatives of polynomials occurring in the SAI. A direct\nconsequence of this criterion is a relatively complete method of SAI generation\nbased on template assumption and semi-algebraic constraint solving. Relative\ncompleteness means if there is an SAI in the form of a predefined template,\nthen our method can indeed find one using this template."
},{
    "category": "cs.DS", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1102.5266v1", 
    "title": "SqFreeEVAL: An (almost) optimal real-root isolation algorithm", 
    "arxiv-id": "1102.5266v1", 
    "author": "Felix Krahmer", 
    "publish": "2011-02-25T15:13:13Z", 
    "summary": "Let f be a univariate polynomial with real coefficients, f in R[X].\nSubdivision algorithms based on algebraic techniques (e.g., Sturm or Descartes\nmethods) are widely used for isolating the real roots of f in a given interval.\nIn this paper, we consider a simple subdivision algorithm whose primitives are\npurely numerical (e.g., function evaluation). The complexity of this algorithm\nis adaptive because the algorithm makes decisions based on local data. The\ncomplexity analysis of adaptive algorithms (and this algorithm in particular)\nis a new challenge for computer science. In this paper, we compute the size of\nthe subdivision tree for the SqFreeEVAL algorithm.\n  The SqFreeEVAL algorithm is an evaluation-based numerical algorithm which is\nwell-known in several communities. The algorithm itself is simple, but prior\nattempts to compute its complexity have proven to be quite technical and have\nyielded sub-optimal results. Our main result is a simple O(d(L+ln d)) bound on\nthe size of the subdivision tree for the SqFreeEVAL algorithm on the benchmark\nproblem of isolating all real roots of an integer polynomial f of degree d and\nwhose coefficients can be written with at most L bits.\n  Our proof uses two amortization-based techniques: First, we use the algebraic\namortization technique of the standard Mahler-Davenport root bounds to\ninterpret the integral in terms of d and L. Second, we use a continuous\namortization technique based on an integral to bound the size of the\nsubdivision tree. This paper is the first to use the novel analysis technique\nof continuous amortization to derive state of the art complexity bounds."
},{
    "category": "math.AG", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1103.4689v1", 
    "title": "Deciding trigonality of algebraic curves", 
    "arxiv-id": "1103.4689v1", 
    "author": "David Sevilla", 
    "publish": "2011-03-24T07:53:56Z", 
    "summary": "Let C be a non-hyperelliptic algebraic curve of genus at least 3. Enriques\nand Babbage proved that its canonical image is the intersection of the quadrics\nthat contain it, except when C is trigonal (that is, it has a linear system of\ndegree 3 and dimension 1) or C is isomorphic to a plane quintic (genus 6). We\npresent a method to decide whether a given algebraic curve is trigonal, and in\nthe affirmative case to compute a map from C to the projective line whose\nfibers cut out the linear system. It is based on the Lie algebra method\npresented in Schicho (2006). Our algorithm is part of a larger effort to\ndetermine whether a given algebraic curve admits a radical parametrization."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.42.5", 
    "link": "http://arxiv.org/pdf/1105.4525v1", 
    "title": "Symbolic-manipulation constructions of Hilbert-space metrics in quantum   mechanics", 
    "arxiv-id": "1105.4525v1", 
    "author": "Miloslav Znojil", 
    "publish": "2011-05-23T15:00:05Z", 
    "summary": "The problem of the determination of the Hilbert-space metric which renders a\ngiven Hamiltonian $H$ self-adjoint is addressed from the point of view of\napplicability of computer-assisted algebraic manipulations. An exactly solvable\nexample of the so called Gegenbauerian quantum-lattice oscillator is recalled\nfor the purpose. Both the construction of suitable metric (basically, the\nsolution of the Dieudonne's operator equation) and the determination of its\ndomain of positivity are shown facilitated by the symbolic algebraic\nmanipulations and by MAPLE-supported numerics and graphics."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-8(1:16)2012", 
    "link": "http://arxiv.org/pdf/1105.4537v3", 
    "title": "Deciding Kleene Algebras in Coq", 
    "arxiv-id": "1105.4537v3", 
    "author": "Damien Pous", 
    "publish": "2011-05-20T13:27:27Z", 
    "summary": "We present a reflexive tactic for deciding the equational theory of Kleene\nalgebras in the Coq proof assistant. This tactic relies on a careful\nimplementation of efficient finite automata algorithms, so that it solves\ncasual equations instantaneously and properly scales to larger expressions. The\ndecision procedure is proved correct and complete: correctness is established\nw.r.t. any model by formalising Kozen's initiality theorem; a counter-example\nis returned when the given equation does not hold. The correctness proof is\nchallenging: it involves both a precise analysis of the underlying automata\nalgorithms and a lot of algebraic reasoning. In particular, we have to\nformalise the theory of matrices over a Kleene algebra. We build on the recent\naddition of firstorder typeclasses in Coq in order to work efficiently with the\ninvolved algebraic structures."
},{
    "category": "math.DS", 
    "doi": "10.2168/LMCS-8(1:16)2012", 
    "link": "http://arxiv.org/pdf/1106.0932v1", 
    "title": "A New Algorithm for Proving Global Asymptotic Stability of Rational   Difference Equations", 
    "arxiv-id": "1106.0932v1", 
    "author": "Doron Zeilberger", 
    "publish": "2011-06-05T21:35:30Z", 
    "summary": "Global asymptotic stability of rational difference equations is an area of\nresearch that has been well studied. In contrast to the many current methods\nfor proving global asymptotic stability, we propose an algorithmic approach.\nThe algorithm we summarize here employs the idea of contractions. Given a\nparticular rational difference equation, defined by a function $Q$ which maps\nthe $k+1$ dimensional real numbers to itself, we attempt to find an integer,\n$K$, for which $Q^K$ shrinks distances to the difference equation's equilibrium\npoint. We state some general results that our algorithm has been able to prove,\nand also mention the implementation of our algorithm using Maple."
},{
    "category": "math.AC", 
    "doi": "10.2168/LMCS-8(1:16)2012", 
    "link": "http://arxiv.org/pdf/1107.0687v1", 
    "title": "Decomposition of Polynomials", 
    "arxiv-id": "1107.0687v1", 
    "author": "Raoul Blankertz", 
    "publish": "2011-07-04T17:46:30Z", 
    "summary": "This diploma thesis is concerned with functional decomposition $f = g \\circ\nh$ of polynomials. First an algorithm is described which computes\ndecompositions in polynomial time. This algorithm was originally proposed by\nZippel (1991). A bound for the number of minimal collisions is derived. Finally\na proof of a conjecture in von zur Gathen, Giesbrecht & Ziegler (2010) is\ngiven, which states a classification for a special class of decomposable\npolynomials."
},{
    "category": "math.AG", 
    "doi": "10.2168/LMCS-8(1:16)2012", 
    "link": "http://arxiv.org/pdf/1107.3205v1", 
    "title": "Differential Chow Form for Projective Differential Variety", 
    "arxiv-id": "1107.3205v1", 
    "author": "Xiao-Shan Gao", 
    "publish": "2011-07-16T08:12:06Z", 
    "summary": "In this paper, a generic intersection theorem in projective differential\nalgebraic geometry is presented. Precisely, the intersection of an irreducible\nprojective differential variety of dimension d>0 and order h with a generic\nprojective differential hyperplane is shown to be an irreducible projective\ndifferential variety of dimension d-1 and order h. Based on the generic\nintersection theorem, the Chow form for an irreducible projective differential\nvariety is defined and most of the properties of the differential Chow form in\naffine differential case are established for its projective differential\ncounterpart. Finally, we apply the differential Chow form to a result of linear\ndependence over projective varieties given by Kolchin."
},{
    "category": "cs.SC", 
    "doi": "10.2168/LMCS-8(1:16)2012", 
    "link": "http://arxiv.org/pdf/1108.1108v1", 
    "title": "On Two-generated Non-commutative Algebras Subject to the Affine Relation", 
    "arxiv-id": "1108.1108v1", 
    "author": "Oleksandr Motsak", 
    "publish": "2011-08-04T14:56:43Z", 
    "summary": "We consider algebras over a field K, generated by two variables x and y\nsubject to the single relation yx = qxy + ax + by + c for q in K^* and a, b, c\nin K. We prove, that among such algebras there are precisely five isomorphism\nclasses. The representatives of these classes, which are ubiquitous operator\nalgebras, are called model algebras. We derive explicit multiplication formulas\nfor y^m*x^n in terms of standard monomials x^i*y^j for many algebras of the\nconsidered type. Such formulas are used in establishing formulas of binomial\ntype and in implementing non-commutative multiplication in a computer algebra\nsystem. By using the formulas we also study centers and ring-theoretic\nproperties of the non-commutative model algebras."
},{
    "category": "cs.SC", 
    "doi": "10.2168/LMCS-8(1:16)2012", 
    "link": "http://arxiv.org/pdf/1108.1486v1", 
    "title": "A New Algorithmic Scheme for Computing Characteristic Sets", 
    "arxiv-id": "1108.1486v1", 
    "author": "Dongming Wang", 
    "publish": "2011-08-06T14:28:07Z", 
    "summary": "Ritt-Wu's algorithm of characteristic sets is the most representative for\ntriangularizing sets of multivariate polynomials. Pseudo-division is the main\noperation used in this algorithm. In this paper we present a new algorithmic\nscheme for computing generalized characteristic sets by introducing other\nadmissible reductions than pseudo-division. A concrete subalgorithm is designed\nto triangularize polynomial sets using selected admissible reductions and\nseveral effective elimination strategies and to replace the algorithm of basic\nsets (used in Ritt-Wu's algorithm). The proposed algorithm has been implemented\nand experimental results show that it performs better than Ritt-Wu's algorithm\nin terms of computing time and simplicity of output for a number of non-trivial\ntest examples."
},{
    "category": "math.CO", 
    "doi": "10.1088/1751-8113/46/12/125005", 
    "link": "http://arxiv.org/pdf/1108.2164v2", 
    "title": "Lattice Green's Functions of the Higher-Dimensional Face-Centered Cubic   Lattices", 
    "arxiv-id": "1108.2164v2", 
    "author": "Christoph Koutschan", 
    "publish": "2011-08-10T12:33:08Z", 
    "summary": "We study the face-centered cubic lattice (fcc) in up to six dimensions. In\nparticular, we are concerned with lattice Green's functions (LGF) and return\nprobabilities. Computer algebra techniques, such as the method of creative\ntelescoping, are used for deriving an ODE for a given LGF. For the four- and\nfive-dimensional fcc lattices, we give rigorous proofs of the ODEs that were\nconjectured by Guttmann and Broadhurst. Additionally, we find the ODE of the\nLGF of the six-dimensional fcc lattice, a result that was not believed to be\nachievable with current computer hardware."
},{
    "category": "cs.SC", 
    "doi": "10.1134/S0361768811020113", 
    "link": "http://arxiv.org/pdf/1108.4487v1", 
    "title": "The Parametric Solution of Underdetermined linear ODEs", 
    "arxiv-id": "1108.4487v1", 
    "author": "Thomas Wolf", 
    "publish": "2011-08-23T03:37:42Z", 
    "summary": "The purpose of this paper is twofold. An immediate practical use of the\npresented algorithm is its applicability to the parametric solution of\nunderdetermined linear ordinary differential equations (ODEs) with coefficients\nthat are arbitrary analytic functions in the independent variable. A second\nconceptual aim is to present an algorithm that is in some sense dual to the\nfundamental Euclids algorithm, and thus an alternative to the special case of a\nGroebner basis algorithm as it is used for solving linear ODE-systems. In the\npaper Euclids algorithm and the new `dual version' are compared and their\ncomplementary strengths are analysed on the task of solving underdetermined\nODEs. An implementation of the described algorithm is interactively accessible\nunder http://lie.math.brocku.ca/crack/demo."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2012.05.004", 
    "link": "http://arxiv.org/pdf/1108.4853v2", 
    "title": "Algorithms for integrals of holonomic functions over domains defined by   polynomial inequalities", 
    "arxiv-id": "1108.4853v2", 
    "author": "Toshinori Oaku", 
    "publish": "2011-08-24T14:38:50Z", 
    "summary": "We present an algorithm for computing a holonomic system for a definite\nintegral of a holonomic function over a domain defined by polynomial\ninequalities. If the integrand satisfies a holonomic difference-differential\nsystem including parameters, then a holonomic difference-differential system\nfor the integral can also be computed. In the algorithm, holonomic\ndistributions (generalized functions in the sense of L. Schwartz) are\ninevitably involved even if the integrand is a usual function."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2012.05.004", 
    "link": "http://arxiv.org/pdf/1108.5985v4", 
    "title": "An Oracle-based, Output-sensitive Algorithm for Projections of Resultant   Polytopes", 
    "arxiv-id": "1108.5985v4", 
    "author": "Luis Pe\u00f1aranda", 
    "publish": "2011-08-30T15:38:54Z", 
    "summary": "We design an algorithm to compute the Newton polytope of the resultant, known\nas resultant polytope, or its orthogonal projection along a given direction.\nThe resultant is fundamental in algebraic elimination, optimization, and\ngeometric modeling. Our algorithm exactly computes vertex- and\nhalfspace-representations of the polytope using an oracle producing resultant\nvertices in a given direction, thus avoiding walking on the polytope whose\ndimension is alpha-n-1, where the input consists of alpha points in Z^n. Our\napproach is output-sensitive as it makes one oracle call per vertex and facet.\nIt extends to any polytope whose oracle-based definition is advantageous, such\nas the secondary and discriminant polytopes. Our publicly available\nimplementation uses the experimental CGAL package triangulation. Our method\ncomputes 5-, 6- and 7-dimensional polytopes with 35K, 23K and 500 vertices,\nrespectively, within 2hrs, and the Newton polytopes of many important surface\nequations encountered in geometric modeling in <1sec, whereas the corresponding\nsecondary polytopes are intractable. It is faster than tropical geometry\nsoftware up to dimension 5 or 6. Hashing determinantal predicates accelerates\nexecution up to 100 times. One variant computes inner and outer approximations\nwith, respectively, 90% and 105% of the true volume, up to 25 times faster."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.70.5", 
    "link": "http://arxiv.org/pdf/1110.4674v1", 
    "title": "Implementing an Automatic Differentiator in ACL2", 
    "arxiv-id": "1110.4674v1", 
    "author": "Ruben Gamboa", 
    "publish": "2011-10-21T00:45:44Z", 
    "summary": "The foundational theory of differentiation was developed as part of the\noriginal release of ACL2(r). In work reported at the last ACL2 Workshop, we\npresented theorems justifying the usual differentiation rules, including the\nchain rule and the derivative of inverse functions. However, the process of\napplying these theorems to formalize the derivative of a particular function is\ncompletely manual. More recently, we developed a macro and supporting functions\nthat can automate this process. This macro uses the ACL2 table facility to keep\ntrack of functions and their derivatives, and it also interacts with the macro\nthat introduces inverse functions in ACL2(r), so that their derivatives can\nalso be automated. In this paper, we present the implementation of this macro\nand related functions."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.70.5", 
    "link": "http://arxiv.org/pdf/1110.6275v2", 
    "title": "Stability of Triangular Decomposition and Comprehensive Triangular   Decomposition", 
    "arxiv-id": "1110.6275v2", 
    "author": "Bican Xia", 
    "publish": "2011-10-28T08:40:53Z", 
    "summary": "A new concept, decomposition-unstable (DU) variety of a parametric polynomial\nsystem, is introduced in this paper and the stabilities of several triangular\ndecomposition methods, such as characteristic set decomposition, relatively\nsimplicial decomposition and regular chain decomposition, for parametric\npolynomial systems are discussed in detail. The concept leads to a definition\nof weakly comprehensive triangular decomposition (WCTD) and a new algorithm for\ncomputing comprehensive triangular decomposition (CTD) which was first\nintroduced in [4] for computing an analogue of comprehensive Groebner systems\nfor parametric polynomial systems. Our algorithm takes advantage of a\nhierarchical solving strategy and a self-adaptive order of parameters. The\nalgorithm has been implemented with Maple 15 and experimented with a number of\nbenchmarks from the literature. Comparison with the Maple package\nRegularChains, which contains an implementation of the algorithm in [4], is\nprovided and the results illustrate that the time costs by our program for\ncomputing CTDs of most examples are no more than those by RegularChains."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.70.5", 
    "link": "http://arxiv.org/pdf/1111.1084v3", 
    "title": "Sparse Differential Resultant for Laurent Differential Polynomials", 
    "arxiv-id": "1111.1084v3", 
    "author": "Xiao-Shan Gao", 
    "publish": "2011-11-04T10:20:46Z", 
    "summary": "In this paper, we first introduce the concept of Laurent differentially\nessential systems and give a criterion for Laurent differentially essential\nsystems in terms of their supports. Then the sparse differential resultant for\na Laurent differentially essential system is defined and its basic properties\nare proved. In particular, order and degree bounds for the sparse differential\nresultant are given. Based on these bounds, an algorithm to compute the sparse\ndifferential resultant is proposed, which is single exponential in terms of the\nnumber of indeterminates, the Jacobi number of the system, and the size of the\nsystem."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.70.5", 
    "link": "http://arxiv.org/pdf/1111.4877v1", 
    "title": "Adleman-Manders-Miller Root Extraction Method Revisited", 
    "arxiv-id": "1111.4877v1", 
    "author": "Xiao Fan", 
    "publish": "2011-11-21T14:11:47Z", 
    "summary": "In 1977, Adleman, Manders and Miller had briefly described how to extend\ntheir square root extraction method to the general $r$th root extraction over\nfinite fields, but not shown enough details. Actually, there is a dramatic\ndifference between the square root extraction and the general $r$th root\nextraction because one has to solve discrete logarithms for $r$th root\nextraction. In this paper, we clarify their method and analyze its complexity.\nOur heuristic presentation is helpful to grasp the method entirely and deeply."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00026-013-0183-8", 
    "link": "http://arxiv.org/pdf/1112.0647v3", 
    "title": "Advanced Computer Algebra for Determinants", 
    "arxiv-id": "1112.0647v3", 
    "author": "Thotsaporn \"Aek\" Thanatipanonda", 
    "publish": "2011-12-03T11:26:40Z", 
    "summary": "We prove three conjectures concerning the evaluation of determinants, which\nare related to the counting of plane partitions and rhombus tilings. One of\nthem was posed by George Andrews in 1980, the other two were by Guoce Xin and\nChristian Krattenthaler. Our proofs employ computer algebra methods, namely,\nthe holonomic ansatz proposed by Doron Zeilberger and variations thereof. These\nvariations make Zeilberger's original approach even more powerful and allow for\naddressing a wider variety of determinants. Finally, we present, as a challenge\nproblem, a conjecture about a closed-form evaluation of Andrews's determinant."
},{
    "category": "cs.MS", 
    "doi": "10.1007/s00026-013-0183-8", 
    "link": "http://arxiv.org/pdf/1112.5717v2", 
    "title": "Rank-profile revealing Gaussian elimination and the CUP matrix   decomposition", 
    "arxiv-id": "1112.5717v2", 
    "author": "Arne Storjohann", 
    "publish": "2011-12-24T11:30:09Z", 
    "summary": "Transforming a matrix over a field to echelon form, or decomposing the matrix\nas a product of structured matrices that reveal the rank profile, is a\nfundamental building block of computational exact linear algebra. This paper\nsurveys the well known variations of such decompositions and transformations\nthat have been proposed in the literature. We present an algorithm to compute\nthe CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra,\nMoran and Hui (1982), and show reductions from the other most common Gaussian\nelimination based matrix transformations and decompositions to the CUP\ndecomposition. We discuss the advantages of the CUP algorithm over other\nexisting algorithms by studying time and space complexities: the asymptotic\ntime complexity is rank sensitive, and comparing the constants of the leading\nterms, the algorithms for computing matrix invariants based on the CUP\ndecomposition are always at least as good except in one case. We also show that\nthe CUP algorithm, as well as the computation of other invariants such as\ntransformation to reduced column echelon form using the CUP algorithm, all work\nin place, allowing for example to compute the inverse of a matrix on the same\nstorage as the input matrix."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2012.07.001", 
    "link": "http://arxiv.org/pdf/1112.6263v2", 
    "title": "On the Complexity of Solving Quadratic Boolean Systems", 
    "arxiv-id": "1112.6263v2", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2011-12-29T10:05:53Z", 
    "summary": "A fundamental problem in computer science is to find all the common zeroes of\n$m$ quadratic polynomials in $n$ unknowns over $\\mathbb{F}_2$. The\ncryptanalysis of several modern ciphers reduces to this problem. Up to now, the\nbest complexity bound was reached by an exhaustive search in $4\\log_2 n\\,2^n$\noperations. We give an algorithm that reduces the problem to a combination of\nexhaustive search and sparse linear algebra. This algorithm has several\nvariants depending on the method used for the linear algebra step. Under\nprecise algebraic assumptions on the input system, we show that the\ndeterministic variant of our algorithm has complexity bounded by\n$O(2^{0.841n})$ when $m=n$, while a probabilistic variant of the Las Vegas type\nhas expected complexity $O(2^{0.792n})$. Experiments on random systems show\nthat the algebraic assumptions are satisfied with probability very close to~1.\nWe also give a rough estimate for the actual threshold between our method and\nexhaustive search, which is as low as~200, and thus very relevant for\ncryptographic applications."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2012.07.001", 
    "link": "http://arxiv.org/pdf/1201.3198v1", 
    "title": "An algorithm to compute the differential equations for the logarithm of   a polynomial", 
    "arxiv-id": "1201.3198v1", 
    "author": "Toshinori Oaku", 
    "publish": "2012-01-16T10:20:19Z", 
    "summary": "We present an algorithm to compute the annihilator of (i.e., the linear\ndifferential equations for) the logarithm of a polynomial in the ring of\ndifferential operators with polynomial coefficients. The algorithm consists of\ndifferentiation with respect to the parameter s of the annihilator of f^s for a\npolynomial f and quotient computation. More generally, the annihilator of\nf^s(log f)^m for a complex number s and a positive integer m can be computed,\nwhich constitutes what is called a holonomic system in D-module theory. This\nenables us to compute a holonomic system for the integral of a function\ninvolving the logarithm of a polynomial by using integration algorithm for\nD-modules."
},{
    "category": "cs.SE", 
    "doi": "10.1016/j.jco.2012.07.001", 
    "link": "http://arxiv.org/pdf/1201.4219v2", 
    "title": "Exact Safety Verification of Hybrid Systems Based on Bilinear SOS   Representation", 
    "arxiv-id": "1201.4219v2", 
    "author": "Wang Lin", 
    "publish": "2012-01-20T07:09:20Z", 
    "summary": "In this paper, we address the problem of safety verification of nonlinear\nhybrid systems. A hybrid symbolic-numeric method is presented to compute exact\ninequality invariants of hybrid systems efficiently. Some numerical invariants\nof a hybrid system can be obtained by solving a bilinear SOS programming via\nPENBMI solver or iterative method, then the modified Newton refinement and\nrational vector recovery techniques are applied to obtain exact polynomial\ninvariants with rational coefficients, which {\\it exactly} satisfy the\nconditions of invariants. Experiments on some benchmarks are given to\nillustrate the efficiency of our algorithm."
},{
    "category": "math.CO", 
    "doi": "10.1016/j.jco.2012.07.001", 
    "link": "http://arxiv.org/pdf/1201.5253v2", 
    "title": "Zeilberger's Holonomic Ansatz for Pfaffians", 
    "arxiv-id": "1201.5253v2", 
    "author": "Christoph Koutschan", 
    "publish": "2012-01-25T12:43:18Z", 
    "summary": "A variation of Zeilberger's holonomic ansatz for symbolic determinant\nevaluations is proposed which is tailored to deal with Pfaffians. The method is\nalso applicable to determinants of skew-symmetric matrices, for which the\noriginal approach does not work. As Zeilberger's approach is based on the\nLaplace expansion (cofactor expansion) of the determinant, we derive our\napproach from the cofactor expansion of the Pfaffian. To demonstrate the power\nof our method, we prove, using computer algebra algorithms, some conjectures\nproposed in the paper \"Pfaffian decomposition and a Pfaffian analogue of\nq-Catalan Hankel determinants\" by Ishikawa, Tagawa, and Zeng. A minor summation\nformula related to partitions and Motzkin paths follows as a corollary."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2012.07.001", 
    "link": "http://arxiv.org/pdf/1201.5365v2", 
    "title": "Fast Computation of Smith Forms of Sparse Matrices Over Local Rings", 
    "arxiv-id": "1201.5365v2", 
    "author": "B. David Saunders", 
    "publish": "2012-01-25T20:32:55Z", 
    "summary": "We present algorithms to compute the Smith Normal Form of matrices over two\nfamilies of local rings.\n  The algorithms use the \\emph{black-box} model which is suitable for sparse\nand structured matrices. The algorithms depend on a number of tools, such as\nmatrix rank computation over finite fields, for which the best-known time- and\nmemory-efficient algorithms are probabilistic.\n  For an $\\nxn$ matrix $A$ over the ring $\\Fzfe$, where $f^e$ is a power of an\nirreducible polynomial $f \\in \\Fz$ of degree $d$, our algorithm requires\n$\\bigO(\\eta de^2n)$ operations in $\\F$, where our black-box is assumed to\nrequire $\\bigO(\\eta)$ operations in $\\F$ to compute a matrix-vector product by\na vector over $\\Fzfe$ (and $\\eta$ is assumed greater than $\\Pden$). The\nalgorithm only requires additional storage for $\\bigO(\\Pden)$ elements of $\\F$.\nIn particular, if $\\eta=\\softO(\\Pden)$, then our algorithm requires only\n$\\softO(n^2d^2e^3)$ operations in $\\F$, which is an improvement on known dense\nmethods for small $d$ and $e$.\n  For the ring $\\ZZ/p^e\\ZZ$, where $p$ is a prime, we give an algorithm which\nis time- and memory-efficient when the number of nontrivial invariant factors\nis small. We describe a method for dimension reduction while preserving the\ninvariant factors. The time complexity is essentially linear in $\\mu n r e \\log\np,$ where $\\mu$ is the number of operations in $\\ZZ/p\\ZZ$ to evaluate the\nblack-box (assumed greater than $n$) and $r$ is the total number of non-zero\ninvariant factors.\n  To avoid the practical cost of conditioning, we give a Monte Carlo\ncertificate, which at low cost, provides either a high probability of success\nor a proof of failure. The quest for a time- and memory-efficient solution\nwithout restrictions on the number of nontrivial invariant factors remains\nopen. We offer a conjecture which may contribute toward that end."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jco.2012.07.001", 
    "link": "http://arxiv.org/pdf/1201.6439v2", 
    "title": "A baby step-giant step roadmap algorithm for general algebraic sets", 
    "arxiv-id": "1201.6439v2", 
    "author": "\u00c9ric Schost", 
    "publish": "2012-01-31T04:37:58Z", 
    "summary": "Let $\\mathrm{R}$ be a real closed field and $\\mathrm{D} \\subset \\mathrm{R}$\nan ordered domain. We give an algorithm that takes as input a polynomial $Q \\in\n\\mathrm{D}[X_1,\\ldots,X_k]$, and computes a description of a roadmap of the set\nof zeros, $\\mathrm{Zer}(Q,\\mathrm{R}^k)$, of $Q$ in $\\mathrm{R}^k$. The\ncomplexity of the algorithm, measured by the number of arithmetic operations in\nthe ordered domain $\\mathrm{D}$, is bounded by $d^{O(k \\sqrt{k})}$, where $d =\n\\mathrm{deg}(Q)\\ge 2$. As a consequence, there exist algorithms for computing\nthe number of semi-algebraically connected components of a real algebraic set,\n$\\mathrm{Zer}(Q,\\mathrm{R}^k)$, whose complexity is also bounded by $d^{O(k\n\\sqrt{k})}$, where $d = \\mathrm{deg}(Q)\\ge 2$. The best previously known\nalgorithm for constructing a roadmap of a real algebraic subset of\n$\\mathrm{R}^k$ defined by a polynomial of degree $d$ has complexity\n$d^{O(k^2)}$."
},{
    "category": "math.OC", 
    "doi": "10.1134/S0005117912120041", 
    "link": "http://arxiv.org/pdf/1202.1777v2", 
    "title": "Counting and computing regions of $D$-decomposition: algebro-geometric   approach", 
    "arxiv-id": "1202.1777v2", 
    "author": "Oleg O. Vasil'ev", 
    "publish": "2012-02-08T17:41:35Z", 
    "summary": "New methods for $D$-decomposition analysis are presented. They are based on\ntopology of real algebraic varieties and computational real algebraic geometry.\nThe estimate of number of root invariant regions for polynomial parametric\nfamilies of polynomial and matrices is given. For the case of two parametric\nfamily more sharp estimate is proven. Theoretic results are supported by\nvarious numerical simulations that show higher precision of presented methods\nwith respect to traditional ones. The presented methods are inherently global\nand could be applied for studying $D$-decomposition for the space of parameters\nas a whole instead of some prescribed regions. For symbolic computations the\nMaple v.14 software and its package RegularChains are used."
},{
    "category": "cs.MS", 
    "doi": "10.4204/EPTCS.79.3", 
    "link": "http://arxiv.org/pdf/1202.4830v1", 
    "title": "Automatic Deduction in Dynamic Geometry using Sage", 
    "arxiv-id": "1202.4830v1", 
    "author": "Miguel A. Ab\u00e1nades", 
    "publish": "2012-02-22T06:41:37Z", 
    "summary": "We present a symbolic tool that provides robust algebraic methods to handle\nautomatic deduction tasks for a dynamic geometry construction. The main\nprototype has been developed as two different worksheets for the open source\ncomputer algebra system Sage, corresponding to two different ways of coding a\ngeometric construction. In one worksheet, diagrams constructed with the open\nsource dynamic geometry system GeoGebra are accepted. In this worksheet,\nGroebner bases are used to either compute the equation of a geometric locus in\nthe case of a locus construction or to determine the truth of a general\ngeometric statement included in the GeoGebra construction as a boolean\nvariable. In the second worksheet, locus constructions coded using the common\nfile format for dynamic geometry developed by the Intergeo project are accepted\nfor computation. The prototype and several examples are provided for testing.\nMoreover, a third Sage worksheet is presented in which a novel algorithm to\neliminate extraneous parts in symbolically computed loci has been implemented.\nThe algorithm, based on a recent work on the Groebner cover of parametric\nsystems, identifies degenerate components and extraneous adherence points in\nloci, both natural byproducts of general polynomial algebraic methods. Detailed\nexamples are discussed."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jsc.2013.06.001", 
    "link": "http://arxiv.org/pdf/1202.5810v3", 
    "title": "Compositions and collisions at degree p^2", 
    "arxiv-id": "1202.5810v3", 
    "author": "Konstantin Ziegler", 
    "publish": "2012-02-27T01:00:19Z", 
    "summary": "A univariate polynomial f over a field is decomposable if f = g o h = g(h)\nfor nonlinear polynomials g and h. In order to count the decomposables, one\nwants to know, under a suitable normalization, the number of equal-degree\ncollisions of the form f = g o h = g^* o h^* with (g, h) = (g^*, h^*) and deg g\n= deg g^*. Such collisions only occur in the wild case, where the field\ncharacteristic p divides deg f. Reasonable bounds on the number of\ndecomposables over a finite field are known, but they are less sharp in the\nwild case, in particular for degree p^2.\n  We provide a classification of all polynomials of degree p^2 with a\ncollision. It yields the exact number of decomposable polynomials of degree p^2\nover a finite field of characteristic p. We also present an efficient algorithm\nthat determines whether a given polynomial of degree p^2 has a collision or\nnot."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jsc.2013.06.001", 
    "link": "http://arxiv.org/pdf/1202.6344v2", 
    "title": "Effective Differential L\u00fcroth's Theorem", 
    "arxiv-id": "1202.6344v2", 
    "author": "Pablo Solern\u00f3", 
    "publish": "2012-02-28T20:19:21Z", 
    "summary": "This paper focuses on effectivity aspects of the L\\\"uroth's theorem in\ndifferential fields. Let $\\mathcal{F}$ be an ordinary differential field of\ncharacteristic 0 and $\\mathcal{F}<u>$ be the field of differential rational\nfunctions generated by a single indeterminate $u$. Let be given non constant\nrational functions $v_1,...,v_n\\in \\mathcal{F}<u>$ generating a differential\nsubfield $\\mathcal{G}\\subseteq \\mathcal{F}<e u>$. The differential L\\\"uroth's\ntheorem proved by Ritt in 1932 states that there exists $v\\in \\mathcal G$ such\nthat $\\mathcal{G}= \\mathcal{F}<v>$. Here we prove that the total order and\ndegree of a generator $v$ are bounded by $\\min_j \\textrm{ord} (v_j)$ and\n$(nd(e+1)+1)^{2e+1}$, respectively, where $e:=\\max_j \\textrm{ord} (v_j)$ and\n$d:=\\max_j \\textrm{deg} (v_j)$. As a byproduct, our techniques enable us to\ncompute a L\\\"uroth generator by dealing with a polynomial ideal in a polynomial\nring in finitely many variables."
},{
    "category": "cs.MS", 
    "doi": "10.1016/j.jsc.2013.06.001", 
    "link": "http://arxiv.org/pdf/1203.1023v1", 
    "title": "Can the Eureqa symbolic regression program, computer algebra and   numerical analysis help each other?", 
    "arxiv-id": "1203.1023v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2012-03-05T19:49:02Z", 
    "summary": "The Eureqa symbolic regression program has recently received extensive press\npraise. A representative quote is\n  \"There are very clever 'thinking machines' in existence today, such as\nWatson, the IBM computer that conquered Jeopardy! last year. But next to\nEureqa, Watson is merely a glorified search engine.\"\n  The program was designed to work with noisy experimental data. However, if\nthe data is generated from an expression for which there exists more concise\nequivalent expressions, sometimes some of the Eureqa results are one or more of\nthose more concise equivalents. If not, perhaps one or more of the returned\nEureqa results might be a sufficiently accurate approximation that is more\nconcise than the given expression. Moreover, when there is no known closed form\nexpression, the data points can be generated by numerical methods, enabling\nEureqa to find expressions that concisely fit those data points with sufficient\naccuracy. In contrast to typical regression software, the user does not have to\nexplicitly or implicitly provide a specific expression or class of expressions\ncontainiing unknown constants for the software to determine.\n  Is Eureqa useful enough in these regards to provide an additional tool for\nexperimental mathematics, computer algebra users and numerical analysis? Yes if\nused carefully. Can computer algebra and numerical methods help Eureqa?\nDefinitely."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00453-013-9799-7", 
    "link": "http://arxiv.org/pdf/1203.1122v4", 
    "title": "An Algorithmic Characterization of Polynomial Functions over $Z_{p^n}$", 
    "arxiv-id": "1203.1122v4", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2012-03-06T07:48:30Z", 
    "summary": "In this paper we consider polynomial representability of functions defined\nover $Z_{p^n}$, where $p$ is a prime and $n$ is a positive integer. Our aim is\nto provide an algorithmic characterization that (i) answers the decision\nproblem: to determine whether a given function over $Z_{p^n}$ is polynomially\nrepresentable or not, and (ii) finds the polynomial if it is polynomially\nrepresentable. The previous characterizations given by Kempner (1921) and\nCarlitz (1964) are existential in nature and only lead to an exhaustive search\nmethod, i.e., algorithm with complexity exponential in size of the input. Our\ncharacterization leads to an algorithm whose running time is linear in size of\ninput. We also extend our result to the multivariate case."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00453-013-9799-7", 
    "link": "http://arxiv.org/pdf/1203.1295v1", 
    "title": "Subtotal ordering -- a pedagogically advantageous algorithm for   computing total degree reverse lexicographic order", 
    "arxiv-id": "1203.1295v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2012-03-06T19:51:48Z", 
    "summary": "Total degree reverse lexicographic order is currently generally regarded as\nmost often fastest for computing Groebner bases. This article describes an\nalternate less mysterious algorithm for computing this order using exponent\nsubtotals and describes why it should be very nearly the same speed the\ntraditional algorithm, all other things being equal. However, experimental\nevidence suggests that subtotal order is actually slightly faster for the\nMathematica Groebner basis implementation more often than not. This is probably\nbecause the weight vectors associated with the natural subtotal weight matrix\nand with the usual total degree reverse lexicographic weight matrix are\ndifferent, and Mathematica also uses those the corresponding weight vectors to\nhelp select successive S polynomials and divisor polynomials: Those selection\nheuristics appear to work slightly better more often with subtotal weight\nvectors.\n  However, the most important advantage of exponent subtotals is pedagogical.\nIt is easier to understand than the total degree reverse lexicographic\nalgorithm, and it is more evident why the resulting order is often the fastest\nknown order for computing Groebner bases.\n  Keywords: Term order, Total degree reverse lexicographic, tdeg, grevlex,\nGroebner basis"
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00453-013-9799-7", 
    "link": "http://arxiv.org/pdf/1203.1350v1", 
    "title": "Simplifying products of fractional powers of powers", 
    "arxiv-id": "1203.1350v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2012-03-06T23:02:46Z", 
    "summary": "Most computer algebra systems incorrectly simplify (z - z)/(sqrt(w^2)/w^3 -\n1/(w*sqrt(w^2))) to 0 rather than to 0/0. The reasons for this are:\n  1. The default simplification doesn't succeed in simplifying the denominator\nto 0.\n  2. There is a rule that 0 is the result of 0 divided by anything that doesn't\nsimplify to either 0 or 0/0.\n  Try it on your computer algebra systems!\n  This article describes how to simplify products of the form w^a*(w^b1)^g1 ...\n(w^bn)^gn correctly and well, where w is any real or complex expression and the\nexponents are rational numbers.\n  It might seem that correct good simplification of such a restrictive\nexpression class must already be published and/or built into at least one\nwidely used computer-algebra system, but apparently this issue has been\noverlooked. Default and relevant optional simplification was tested with 86\nexamples for n=1 on Derive, Maple, Mathematica, Maxima and TI-CAS. Totaled over\nall five systems, 11% of the results were not equivalent to the input\neverywhere, 50% of the results did not simplify to 0 a result that was\nequivalent to 0, and at least 16% of the results exhibited one or more of four\nadditional flaw types. There was substantial room for improvement in all five\nsystems, including the two for which I was a co-author.\n  The good news is: These flaws are easy to fix."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00453-013-9799-7", 
    "link": "http://arxiv.org/pdf/1203.1357v1", 
    "title": "Series misdemeanors", 
    "arxiv-id": "1203.1357v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2012-03-07T00:34:35Z", 
    "summary": "Puiseux series are power series in which the exponents can be fractional\nand/or negative rational numbers. Several computer algebra systems have one or\nmore built-in or loadable functions for computing truncated Puiseux series --\nperhaps generalized to allow coefficients containing functions of the series\nvariable that are dominated by any power of that variable, such as logarithms\nand nested logarithms of the series variable. Some computer-algebra systems\nalso offer functions that can compute more-general truncated recursive\nhierarchical series. However, for all of these kinds of truncated series there\nare important implementation details that haven't been addressed before in the\npublished literature and in current implementations.\n  For implementers this article contains ideas for designing more convenient,\ncorrect, and efficient implementations or improving existing ones. For users,\nthis article is a warning about some of these limitations. Many of the ideas in\nthis article have been implemented in the computer-algebra within the TI-Nspire\ncalculator, Windows and Macintosh products."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00453-013-9799-7", 
    "link": "http://arxiv.org/pdf/1203.5846v1", 
    "title": "Series Crimes", 
    "arxiv-id": "1203.5846v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2012-03-27T00:31:28Z", 
    "summary": "Puiseux series are power series in which the exponents can be fractional\nand/or negative rational numbers. Several computer algebra systems have one or\nmore built-in or loadable functions for computing truncated Puiseux series.\nSome are generalized to allow coefficients containing functions of the series\nvariable that are dominated by any power of that variable, such as logarithms\nand nested logarithms of the series variable. Some computer algebra systems\nalso have built-in or loadable functions that compute infinite Puiseux series.\nUnfortunately, there are some little-known pitfalls in computing Puiseux\nseries. The most serious of these is expansions within branch cuts or at branch\npoints that are incorrect for some directions in the complex plane. For example\nwith each series implementation accessible to you:\n  Compare the value of (z^2 + z^3)^(3/2) with that of its truncated series\nexpansion about z = 0, approximated at z = -0.01. Does the series converge to a\nvalue that is the negative of the correct value?\n  Compare the value of ln(z^2 + z^3) with its truncated series expansion about\nz = 0, approximated at z = -0.01 + 0.1i. Does the series converge to a value\nthat is incorrect by 2pi i?\n  Compare arctanh(-2 + ln(z)z) with its truncated series expansion about z = 0,\napproximated at z = -0.01. Does the series converge to a value that is\nincorrect by about pi i?\n  At the time of this writing, most implementations that accommodate such\nseries exhibit such errors. This article describes how to avoid these errors\nboth for manual derivation of series and when implementing series packages."
},{
    "category": "cs.SY", 
    "doi": "10.1007/s00453-013-9799-7", 
    "link": "http://arxiv.org/pdf/1203.6025v2", 
    "title": "A \"Hybrid\" Approach for Synthesizing Optimal Controllers of Hybrid   Systems: A Case Study of the Oil Pump Industrial Example", 
    "arxiv-id": "1203.6025v2", 
    "author": "Kim G. Larsen", 
    "publish": "2012-03-26T14:03:38Z", 
    "summary": "In this paper, we propose an approach to reduce the optimal controller\nsynthesis problem of hybrid systems to quantifier elimination; furthermore, we\nalso show how to combine quantifier elimination with numerical computation in\norder to make it more scalable but at the same time, keep arising errors due to\ndiscretization manageable and within bounds. A major advantage of our approach\nis not only that it avoids errors due to numerical computation, but it also\ngives a better optimal controller. In order to illustrate our approach, we use\nthe real industrial example of an oil pump provided by the German company HYDAC\nwithin the European project Quasimodo as a case study throughout this paper,\nand show that our method improves (up to 7.5%) the results reported in [3]\nbased on game theory and model checking."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2012.12.028", 
    "link": "http://arxiv.org/pdf/1203.6543v1", 
    "title": "FORM version 4.0", 
    "arxiv-id": "1203.6543v1", 
    "author": "J. Vollinga", 
    "publish": "2012-03-29T14:55:52Z", 
    "summary": "We present version 4.0 of the symbolic manipulation system FORM. The most\nimportant new features are manipulation of rational polynomials and the\nfactorization of expressions. Many other new functions and commands are also\nadded; some of them are very general, while others are designed for building\nspecific high level packages, such as one for Groebner bases. New is also the\ncheckpoint facility, that allows for periodic backups during long calculations.\nLastly, FORM 4.0 has become available as open source under the GNU General\nPublic License version 3."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2012.12.028", 
    "link": "http://arxiv.org/pdf/1205.1223v4", 
    "title": "Proving Inequalities and Solving Global Optimization Problems via   Simplified CAD Projection", 
    "arxiv-id": "1205.1223v4", 
    "author": "Bican Xia", 
    "publish": "2012-05-06T15:12:19Z", 
    "summary": "Let $\\xx_n=(x_1,\\ldots,x_n)$ and $f\\in \\R[\\xx_n,k]$. The problem of finding\nall $k_0$ such that $f(\\xx_n,k_0)\\ge 0$ on $\\mathbb{R}^n$ is considered in this\npaper, which obviously takes as a special case the problem of computing the\nglobal infimum or proving the semi-definiteness of a polynomial.\n  For solving the problems, we propose a simplified Brown's CAD projection\noperator, \\Nproj, of which the projection scale is always no larger than that\nof Brown's. For many problems, the scale is much smaller than that of Brown's.\nAs a result, the lifting phase is also simplified. Some new algorithms based on\n\\Nproj\\ for solving those problems are designed and proved to be correct.\nComparison to some existing tools on some examples is reported to illustrate\nthe effectiveness of our new algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.09.002", 
    "link": "http://arxiv.org/pdf/1205.2926v2", 
    "title": "Faster arithmetic for number-theoretic transforms", 
    "arxiv-id": "1205.2926v2", 
    "author": "David Harvey", 
    "publish": "2012-05-14T01:34:22Z", 
    "summary": "We show how to improve the efficiency of the computation of fast Fourier\ntransforms over F_p where p is a word-sized prime. Our main technique is\noptimisation of the basic arithmetic, in effect decreasing the total number of\nreductions modulo p, by making use of a redundant representation for integers\nmodulo p. We give performance results showing a significant improvement over\nShoup's NTL library."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2013.09.002", 
    "link": "http://arxiv.org/pdf/1205.6285v1", 
    "title": "Speeding up Cylindrical Algebraic Decomposition by Gr\u00f6bner Bases", 
    "arxiv-id": "1205.6285v1", 
    "author": "James H. Davenport", 
    "publish": "2012-05-29T07:45:12Z", 
    "summary": "Gr\\\"obner Bases and Cylindrical Algebraic Decomposition are generally thought\nof as two, rather different, methods of looking at systems of equations and, in\nthe case of Cylindrical Algebraic Decomposition, inequalities. However, even\nfor a mixed system of equalities and inequalities, it is possible to apply\nGr\\\"obner bases to the (conjoined) equalities before invoking CAD. We see that\nthis is, quite often but not always, a beneficial preconditioning of the CAD\nproblem.\n  It is also possible to precondition the (conjoined) inequalities with respect\nto the equalities, and this can also be useful in many cases."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.jsc.2013.09.002", 
    "link": "http://arxiv.org/pdf/1206.0087v3", 
    "title": "Computing arithmetic Kleinian groups", 
    "arxiv-id": "1206.0087v3", 
    "author": "Aurel Page", 
    "publish": "2012-06-01T06:12:47Z", 
    "summary": "Arithmetic Kleinian groups are arithmetic lattices in PSL_2(C). We present an\nalgorithm which, given such a group Gamma, returns a fundamental domain and a\nfinite presentation for Gamma with a computable isomorphism."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2012.12.004", 
    "link": "http://arxiv.org/pdf/1206.1456v2", 
    "title": "First Steps Towards Radical Parametrization of Algebraic Surfaces", 
    "arxiv-id": "1206.1456v2", 
    "author": "David Sevilla", 
    "publish": "2012-06-07T11:42:07Z", 
    "summary": "We introduce the notion of radical parametrization of a surface, and we\nprovide algorithms to compute such type of parametrizations for families of\nsurfaces, like: Fermat surfaces, surfaces with a high multiplicity (at least\nthe degree minus 4) singularity, all irreducible surfaces of degree at most 5,\nall irreducible singular surfaces of degree 6, and surfaces containing a pencil\nof low-genus curves. In addition, we prove that radical parametrizations are\npreserved under certain type of geometric constructions that include offset and\nconchoids."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2012.12.004", 
    "link": "http://arxiv.org/pdf/1206.3463v2", 
    "title": "Computation of Difference Groebner Bases", 
    "arxiv-id": "1206.3463v2", 
    "author": "Daniel Robertz", 
    "publish": "2012-06-15T13:38:40Z", 
    "summary": "To compute difference Groebner bases of ideals generated by linear\npolynomials we adopt to difference polynomial rings the involutive algorithm\nbased on Janet-like division. The algorithm has been implemented in Maple in\nthe form of the package LDA (Linear Difference Algebra) and we describe the\nmain features of the package. Its applications are illustrated by generation of\nfinite difference approximations to linear partial differential equations and\nby reduction of Feynman integrals. We also present the algorithm for an ideal\ngenerated by a finite set of nonlinear difference polynomials. If the algorithm\nterminates, then it constructs a Groebner basis of the ideal."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2465506.2465932", 
    "link": "http://arxiv.org/pdf/1206.4224v3", 
    "title": "Factoring bivariate lacunary polynomials without heights", 
    "arxiv-id": "1206.4224v3", 
    "author": "Yann Strozecki", 
    "publish": "2012-06-19T14:30:37Z", 
    "summary": "We present an algorithm which computes the multilinear factors of bivariate\nlacunary polynomials. It is based on a new Gap Theorem which allows to test\nwhether a polynomial of the form P(X,X+1) is identically zero in time\npolynomial in the number of terms of P(X,Y). The algorithm we obtain is more\nelementary than the one by Kaltofen and Koiran (ISSAC'05) since it relies on\nthe valuation of polynomials of the previous form instead of the height of the\ncoefficients. As a result, it can be used to find some linear factors of\nbivariate lacunary polynomials over a field of large finite characteristic in\nprobabilistic polynomial time."
},{
    "category": "cs.CC", 
    "doi": "10.1109/FOCS.2012.57", 
    "link": "http://arxiv.org/pdf/1208.3639v1", 
    "title": "Quasi-optimal multiplication of linear differential operators", 
    "arxiv-id": "1208.3639v1", 
    "author": "Joris van der Hoeven", 
    "publish": "2012-08-17T17:10:34Z", 
    "summary": "We show that linear differential operators with polynomial coefficients over\na field of characteristic zero can be multiplied in quasi-optimal time. This\nanswers an open question raised by van der Hoeven."
},{
    "category": "math.AC", 
    "doi": "10.1007/s00200-014-0216-5", 
    "link": "http://arxiv.org/pdf/1209.2379v3", 
    "title": "Reducing the size and number of linear programs in a dynamic Gr\u00f6bner   basis algorithm", 
    "arxiv-id": "1209.2379v3", 
    "author": "John Perry", 
    "publish": "2012-09-11T17:48:19Z", 
    "summary": "The dynamic algorithm to compute a Gr\\\"obner basis is nearly twenty years\nold, yet it seems to have arrived stillborn; aside from two initial\npublications, there have been no published followups. One reason for this may\nbe that, at first glance, the added overhead seems to outweigh the benefit; the\nalgorithm must solve many linear programs with many linear constraints. This\npaper describes two methods of reducing the cost substantially, answering the\nproblem effectively."
},{
    "category": "math.AG", 
    "doi": "10.1007/s00200-014-0216-5", 
    "link": "http://arxiv.org/pdf/1209.3080v2", 
    "title": "The expansion of real forms on the simplex and applications", 
    "arxiv-id": "1209.3080v2", 
    "author": "Jingzhong Zhang", 
    "publish": "2012-09-14T02:49:19Z", 
    "summary": "If n points B_1,---,B_n$ in the standard simplex \\Delta_n are affinely\nindependent, then they can span an (n-1)-simplex denoted by\n\\Lambda=Con(B_1,---,B_n). Here \\Lambda corresponds to an n*n matrix [\\Lambda]\nwhose columns are B_1,---,B_n. In this paper, we firstly proved that if \\Lambda\nof diameter sufficiently small contains a point $P$, and f(P)>0 (<0) for a form\nf in R[X], then the coefficients of f([\\Lambda] X) are all positive (negative).\nNext, as an application of this result, a necessary and sufficient condition\nfor determining the real zeros on \\Delta_n of a system of homogeneous algebraic\nequations with integral coefficients is established."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00200-014-0216-5", 
    "link": "http://arxiv.org/pdf/1209.3555v1", 
    "title": "logcf: An Efficient Tool for Real Root Isolation", 
    "arxiv-id": "1209.3555v1", 
    "author": "Bican Xia", 
    "publish": "2012-09-17T05:27:33Z", 
    "summary": "This paper revisits an algorithm for isolating real roots of univariate\npolynomials based on continued fractions. It follows the work of Vincent,\nUspen- sky, Collins and Akritas, Johnson and Krandick. We use some tricks,\nespecially a new algorithm for computing an upper bound of positive roots. In\nthis way, the algorithm of isolating real roots is improved. The complexity of\nour method for computing an upper bound of positive roots is O(n log(u+1))\nwhere u is the optimal upper bound satisfying Theorem 3 and n is the degree of\nthe polynomial. Our method has been implemented as a software package logcf\nusing C++ language. For many benchmarks logcf is two or three times faster than\nthe function RootIntervals of Mathematica. And it is much faster than another\ncontinued fractions based software CF, which seems to be one of the fastest\navailable open software for exact real root isolation. For those benchmarks\nwhich have only real roots, logcf is much faster than Sleeve and eigensolve\nwhich are based on numerical computation."
},{
    "category": "cs.DM", 
    "doi": "10.1007/s00200-014-0216-5", 
    "link": "http://arxiv.org/pdf/1209.5160v1", 
    "title": "A new edge selection heuristic for computing the Tutte polynomial of an   undirected graph", 
    "arxiv-id": "1209.5160v1", 
    "author": "Michael Monagan", 
    "publish": "2012-09-24T06:38:22Z", 
    "summary": "We present a new edge selection heuristic and vertex ordering heuristic that\ntogether enable one to compute the Tutte polynomial of much larger sparse\ngraphs than was previously doable. As a specific example, we are able to\ncompute the Tutte polynomial of the truncated icosahedron graph using our Maple\nimplementation in under 4 minutes on a single CPU. This compares with a recent\nresult of Haggard, Pearce and Royle whose special purpose C++ software took one\nweek on 150 computers."
},{
    "category": "cs.SC", 
    "doi": "10.1109/TC.2013.94", 
    "link": "http://arxiv.org/pdf/1209.6626v3", 
    "title": "On Newton-Raphson iteration for multiplicative inverses modulo prime   powers", 
    "arxiv-id": "1209.6626v3", 
    "author": "Jean-Guillaume Dumas", 
    "publish": "2012-09-28T19:52:06Z", 
    "summary": "We study algorithms for the fast computation of modular inverses.\nNewton-Raphson iteration over $p$-adic numbers gives a recurrence relation\ncomputing modular inverse modulo $p^m$, that is logarithmic in $m$. We solve\nthe recurrence to obtain an explicit formula for the inverse. Then we study\ndifferent implementation variants of this iteration and show that our explicit\nformula is interesting for small exponent values but slower or large exponent,\nsay of more than 700 bits. Overall we thus propose a hybrid combination of our\nexplicit formula and the best asymptotic variants. This hybrid combination\nyields then a constant factor improvement, also for large exponents."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jco.2012.10.001", 
    "link": "http://arxiv.org/pdf/1210.1451v1", 
    "title": "On the Complexity of the Multivariate Resultant", 
    "arxiv-id": "1210.1451v1", 
    "author": "Natacha Portier", 
    "publish": "2012-10-04T14:11:43Z", 
    "summary": "The multivariate resultant is a fundamental tool of computational algebraic\ngeometry. It can in particular be used to decide whether a system of n\nhomogeneous equations in n variables is satisfiable (the resultant is a\npolynomial in the system's coefficients which vanishes if and only if the\nsystem is satisfiable). In this paper, we investigate the complexity of\ncomputing the multivariate resultant.\n  First, we study the complexity of testing the multivariate resultant for\nzero. Our main result is that this problem is NP-hard under deterministic\nreductions in any characteristic, for systems of low-degree polynomials with\ncoefficients in the ground field (rather than in an extension). In\ncharacteristic zero, we observe that this problem is in the Arthur-Merlin class\nAM if the generalized Riemann hypothesis holds true, while the best known upper\nbound in positive characteristic remains PSPACE.\n  Second, we study the classical algorithms to compute the resultant. They\nusually rely on the computation of the determinant of an exponential-size\nmatrix, known as Macaulay matrix. We show that this matrix belongs to a class\nof succinctly representable matrices, for which testing the determinant for\nzero is proved PSPACE-complete. This means that improving Canny's PSPACE upper\nbound requires either to look at the fine structure of the Macaulay matrix to\nfind an ad hoc algorithm for computing its determinant, or to use altogether\ndifferent techniques."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1210.2951v1", 
    "title": "Regular and Singular Boundary Problems in Maple", 
    "arxiv-id": "1210.2951v1", 
    "author": "Markus Rosenkranz", 
    "publish": "2012-10-10T15:13:55Z", 
    "summary": "We describe a new Maple package for treating boundary problems for linear\nordinary differential equations, allowing two-/multipoint as well as Stieltjes\nboundary conditions. For expressing differential operators, boundary\nconditions, and Green's operators, we employ the algebra of\nintegro-differential operators. The operations implemented for regular boundary\nproblems include computing Green's operators as well as composing and factoring\nboundary problems. Our symbolic approach to singular boundary problems is new;\nit provides algorithms for computing compatibility conditions and generalized\nGreen's operators."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1210.4662v1", 
    "title": "A New Recursive Algorithm For Inverting A General Comrade Matrix", 
    "arxiv-id": "1210.4662v1", 
    "author": "A. A. Karawia", 
    "publish": "2012-10-17T08:09:08Z", 
    "summary": "In this paper, the author present a reliable symbolic computational algorithm\nfor inverting a general comrade matrix by using parallel computing along with\nrecursion. The computational cost of our algorithm is O(n^2). The algorithm is\nimplementable to the Computer Algebra System (CAS) such as MAPLE, MATLAB and\nMATHEMATICA. Three examples are presented for the sake of illustration."
},{
    "category": "math.CO", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1210.6366v1", 
    "title": "On the Summability of Bivariate Rational Functions", 
    "arxiv-id": "1210.6366v1", 
    "author": "Michael F. Singer", 
    "publish": "2012-10-23T20:12:42Z", 
    "summary": "We present criteria for deciding whether a bivariate rational function in two\nvariables can be written as a sum of two (q-)differences of bivariate rational\nfunctions. Using these criteria, we show how certain double sums can be\nevaluated, first, in terms of single sums and, finally, in terms of values of\nspecial functions."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1211.2430v2", 
    "title": "On the Existence of Telescopers for Mixed Hypergeometric Terms", 
    "arxiv-id": "1211.2430v2", 
    "author": "Ziming Li", 
    "publish": "2012-11-11T15:09:59Z", 
    "summary": "We present a criterion for the existence of telescopers for mixed\nhypergeometric terms, which is based on multiplicative and additive\ndecompositions. The criterion enables us to determine the termination of\nZeilberger's algorithms for mixed hypergeometric inputs."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1211.3959v1", 
    "title": "How to compute the constant term of a power of a Laurent polynomial   efficiently", 
    "arxiv-id": "1211.3959v1", 
    "author": "Pavel Metelitsyn", 
    "publish": "2012-11-16T17:25:36Z", 
    "summary": "We present an algorithm for efficient computation of the constant term of a\npower of a multivariate Laurent polynomial. The algorithm is based on\nunivariate interpolation, does not require the storage of intermediate data and\ncan be easily parallelized. As an application we compute the power series\nexpansion of the principal period of some toric Calabi-Yau varieties and find\npreviously unknown differential operators of Calabi-Yau type."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1211.5590v1", 
    "title": "Theano: new features and speed improvements", 
    "arxiv-id": "1211.5590v1", 
    "author": "Yoshua Bengio", 
    "publish": "2012-11-23T20:42:41Z", 
    "summary": "Theano is a linear algebra compiler that optimizes a user's\nsymbolically-specified mathematical computations to produce efficient low-level\nimplementations. In this paper, we present new features and efficiency\nimprovements to Theano, and benchmarks demonstrating Theano's performance\nrelative to Torch7, a recently introduced machine learning library, and to\nRNNLM, a C++ library targeted at recurrent neural networks."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1212.3090v2", 
    "title": "Sparse Difference Resultant", 
    "arxiv-id": "1212.3090v2", 
    "author": "Xiao-Shan Gao", 
    "publish": "2012-12-13T09:02:32Z", 
    "summary": "In this paper, the concept of sparse difference resultant for a Laurent\ntransformally essential system of difference polynomials is introduced and a\nsimple criterion for the existence of sparse difference resultant is given. The\nconcept of transformally homogenous polynomial is introduced and the sparse\ndifference resultant is shown to be transformally homogenous. It is shown that\nthe vanishing of the sparse difference resultant gives a necessary condition\nfor the corresponding difference polynomial system to have non-zero solutions.\nThe order and degree bounds for sparse difference resultant are given. Based on\nthese bounds, an algorithm to compute the sparse difference resultant is\nproposed, which is single exponential in terms of the number of variables, the\nJacobi number, and the size of the Laurent transformally essential system.\nFurthermore, the precise order and degree, a determinant representation, and a\nPoisson-type product formula for the difference resultant are given."
},{
    "category": "math.CO", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1302.5391v7", 
    "title": "Combinatorics of $\u03c6$-deformed stuffle Hopf algebras", 
    "arxiv-id": "1302.5391v7", 
    "author": "Nguyen Hoang Nghia", 
    "publish": "2013-02-21T19:53:26Z", 
    "summary": "In order to extend the Sch\\\"utzenberger's factorization to general\nperturbations, the combinatorial aspects of the Hopf algebra of the\n$\\phi$-deformed stuffle product is developed systematically in a parallel way\nwith those of the shuffle product."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1302.5674v3", 
    "title": "Factorization of Z-homogeneous polynomials in the First (q)-Weyl Algebra", 
    "arxiv-id": "1302.5674v3", 
    "author": "Viktor Levandovskyy", 
    "publish": "2013-01-20T18:37:47Z", 
    "summary": "We present algorithms to factorize weighted homogeneous elements in the first\npolynomial Weyl algebra and $q$-Weyl algebra, which are both viewed as a\n$\\mathbb{Z}$-graded rings. We show, that factorization of homogeneous\npolynomials can be almost completely reduced to commutative univariate\nfactorization over the same base field with some additional uncomplicated\ncombinatorial steps. This allows to deduce the complexity of our algorithms in\ndetail. Furthermore, we will show for homogeneous polynomials that\nirreducibility in the polynomial first Weyl algebra also implies irreducibility\nin the rational one, which is of interest for practical reasons. We report on\nour implementation in the computer algebra system \\textsc{Singular}. It\noutperforms for homogeneous polynomials currently available implementations\ndealing with factorization in the first Weyl algebra both in speed and elegancy\nof the results."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-23568-9_22", 
    "link": "http://arxiv.org/pdf/1302.5974v1", 
    "title": "Exact Safety Verification of Interval Hybrid Systems Based on   Symbolic-Numeric Computation", 
    "arxiv-id": "1302.5974v1", 
    "author": "Wang Lin", 
    "publish": "2013-02-25T01:54:41Z", 
    "summary": "In this paper, we address the problem of safety verification of interval\nhybrid systems in which the coefficients are intervals instead of explicit\nnumbers. A hybrid symbolic-numeric method, based on SOS relaxation and interval\narithmetic certification, is proposed to generate exact inequality invariants\nfor safety verification of interval hybrid systems. As an application, an\napproach is provided to verify safety properties of non-polynomial hybrid\nsystems. Experiments on the benchmark hybrid systems are given to illustrate\nthe efficiency of our method."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.110", 
    "link": "http://arxiv.org/pdf/1302.5997v1", 
    "title": "Proceedings 7th International Workshop on Computing with Terms and   Graphs", 
    "arxiv-id": "1302.5997v1", 
    "author": "Detlef Plump", 
    "publish": "2013-02-25T05:49:14Z", 
    "summary": "This volume contains the proceedings of the Seventh International Workshop on\nComputing with Terms and Graphs (TERMGRAPH 2013). The workshop took place in\nRome, Italy, on March 23rd, 2013, as part of the sixteenth edition of the\nEuropean Joint Conferences on Theory and Practice of Software (ETAPS 2013).\n  Research in term and graph rewriting ranges from theoretical questions to\npractical issues. Computing with graphs handles the sharing of common\nsubexpressions in a natural and seamless way, and improves the efficiency of\ncomputations in space and time. Sharing is ubiquitous in several research\nareas, as witnessed by the modelling of first- and higher-order term rewriting\nby (acyclic or cyclic) graph rewriting, the modelling of biological or chemical\nabstract machines, and the implementation techniques of programming languages:\nmany implementations of functional, logic, object-oriented, concurrent and\nmobile calculi are based on term graphs. Term graphs are also used in automated\ntheorem proving and symbolic computation systems working on shared structures.\nThe aim of this workshop is to bring together researchers working in different\ndomains on term and graph transformation and to foster their interaction, to\nprovide a forum for presenting new ideas and work in progress, and to enable\nnewcomers to learn about current activities in term graph rewriting.\n  These proceedings contain six accepted papers and the abstracts of two\ninvited talks. All submissions were subject to careful refereeing. The topics\nof accepted papers range over a wide spectrum, including theoretical aspects of\nterm graph rewriting, concurrency, semantics as well as application issues of\nterm graph transformation."
},{
    "category": "math.AC", 
    "doi": "10.4204/EPTCS.110", 
    "link": "http://arxiv.org/pdf/1302.6383v1", 
    "title": "Module Border Bases", 
    "arxiv-id": "1302.6383v1", 
    "author": "Markus Kriegl", 
    "publish": "2013-02-26T10:22:12Z", 
    "summary": "In this paper, we generalize the notion of border bases of zero-dimensional\npolynomial ideals to the module setting. To this end, we introduce order\nmodules as a generalization of order ideals and module border bases of\nsubmodules with finite codimension in a free module as a generalization of\nborder bases of zero-dimensional ideals in the first part of this paper. In\nparticular, we extend the division algorithm for border bases to the module\nsetting, show the existence and uniqueness of module border bases, and\ncharacterize module border bases analogously like border bases via the special\ngeneration property, border form modules, rewrite rules, commuting matrices,\nand liftings of border syzygies. Furthermore, we deduce Buchberger's Criterion\nfor Module Border Bases and give an algorithm for the computation of module\nborder bases that uses linear algebra techniques. In the second part, we\nfurther generalize the notion of module border bases to quotient modules. We\nthen show the connection between quotient module border bases and special\nmodule border bases and deduce characterizations similar to the ones for module\nborder bases. Moreover, we give an algorithm for the computation of quotient\nmodule border bases using linear algebra techniques, again. At last, we prove\nthat subideal border bases are isomorphic to special quotient module border\nbases. This isomorphy immediately yields characterizations and an algorithm for\nthe computation of subideal border bases."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.110", 
    "link": "http://arxiv.org/pdf/1302.7194v1", 
    "title": "Normalization of Polynomials in Algebraic Invariants of   Three-Dimensional Orthogonal Geometry", 
    "arxiv-id": "1302.7194v1", 
    "author": "Hongbo Li", 
    "publish": "2013-02-27T05:59:29Z", 
    "summary": "In classical invariant theory, the Gr\\\"obner base of the ideal of syzygies\nand the normal forms of polynomials of invariants are two core contents. To\nimprove the performance of invariant theory in symbolic computing of classical\ngeometry, advanced invariants are introduced via Clifford product. This paper\naddresses and solves the two key problems in advanced invariant theory: the\nGr\\\"obner base of the ideal of syzygies among advanced invariants, and the\nnormal forms of polynomials of advanced invariants. These results beautifully\nextend the straightening of Young tableaux to advanced invariants."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cnsns.2013.12.001", 
    "link": "http://arxiv.org/pdf/1303.0452v1", 
    "title": "Domain-of-Attraction Estimation for Uncertain Non-polynomial Systems", 
    "arxiv-id": "1303.0452v1", 
    "author": "Wang Lin", 
    "publish": "2013-03-03T03:01:29Z", 
    "summary": "In this paper, we consider the problem of computing estimates of the\ndomain-of-attraction for non-polynomial systems. A polynomial approximation\ntechnique, based on multivariate polynomial interpolation and error analysis\nfor remaining functions, is applied to compute an uncertain polynomial system,\nwhose set of trajectories contains that of the original non-polynomial system.\nExperiments on the benchmark non-polynomial systems show that our approach\ngives better estimates of the domain-of-attraction."
},{
    "category": "cs.DS", 
    "doi": "10.1016/j.cnsns.2013.12.001", 
    "link": "http://arxiv.org/pdf/1303.3445v1", 
    "title": "New modular multiplication and division algorithms based on continued   fraction expansion", 
    "arxiv-id": "1303.3445v1", 
    "author": "Mourad Gouicem", 
    "publish": "2013-03-14T13:44:44Z", 
    "summary": "In this paper, we apply results on number systems based on continued fraction\nexpansions to modular arithmetic. We provide two new algorithms in order to\ncompute modular multiplication and modular division. The presented algorithms\nare based on the Euclidean algorithm and are of quadratic complexity."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cnsns.2013.12.001", 
    "link": "http://arxiv.org/pdf/1303.5041v2", 
    "title": "Separating linear forms for bivariate systems", 
    "arxiv-id": "1303.5041v2", 
    "author": "Fabrice Rouillier", 
    "publish": "2013-03-20T19:38:45Z", 
    "summary": "We present an algorithm for computing a separating linear form of a system of\nbivariate polynomials with integer coefficients, that is a linear combination\nof the variables that takes different values when evaluated at distinct\n(complex) solutions of the system. In other words, a separating linear form\ndefines a shear of the coordinate system that sends the algebraic system in\ngeneric position, in the sense that no two distinct solutions are vertically\naligned. The computation of such linear forms is at the core of most algorithms\nthat solve algebraic systems by computing rational parameterizations of the\nsolutions and, moreover, the computation a separating linear form is the\nbottleneck of these algorithms, in terms of worst-case bit complexity. Given\ntwo bivariate polynomials of total degree at most $d$ with integer coefficients\nof bitsize at most~$\\tau$, our algorithm computes a separating linear form in\n$\\sOB(d^{8}+d^7\\tau)$ bit operations in the worst case, where the previously\nknown best bit complexity for this problem was $\\sOB(d^{10}+d^9\\tau)$ (where\n$\\sO$ refers to the complexity where polylogarithmic factors are omitted and\n$O_B$ refers to the bit complexity)."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cnsns.2013.12.001", 
    "link": "http://arxiv.org/pdf/1303.5042v2", 
    "title": "Rational Univariate Representations of Bivariate Systems and   Applications", 
    "arxiv-id": "1303.5042v2", 
    "author": "Fabrice Rouillier", 
    "publish": "2013-03-20T19:39:37Z", 
    "summary": "We address the problem of solving systems of two bivariate polynomials of\ntotal degree at most $d$ with integer coefficients of maximum bitsize $\\tau$.\nIt is known that a linear separating form, that is a linear combination of the\nvariables that takes different values at distinct solutions of the system, can\nbe computed in $\\sOB(d^{8}+d^7\\tau)$ bit operations (where $O_B$ refers to bit\ncomplexities and $\\sO$ to complexities where polylogarithmic factors are\nomitted) and we focus here on the computation of a Rational Univariate\nRepresentation (RUR) given a linear separating form. We present an algorithm\nfor computing a RUR with worst-case bit complexity in $\\sOB(d^7+d^6\\tau)$ and\nbound the bitsize of its coefficients by $\\sO(d^2+d\\tau)$. We show in addition\nthat isolating boxes of the solutions of the system can be computed from the\nRUR with $\\sOB(d^{8}+d^7\\tau)$ bit operations. Finally, we show how a RUR can\nbe used to evaluate the sign of a bivariate polynomial (of degree at most $d$\nand bitsize at most $\\tau$) at one real solution of the system in\n$\\sOB(d^{8}+d^7\\tau)$ bit operations and at all the $\\Theta(d^2)$ {real}\nsolutions in only $O(d)$ times that for one solution."
},{
    "category": "math.NA", 
    "doi": "10.1016/j.cnsns.2013.12.001", 
    "link": "http://arxiv.org/pdf/1303.5503v1", 
    "title": "Numerical method for real root isolation of semi-algebraic system and   its applications", 
    "arxiv-id": "1303.5503v1", 
    "author": "Yong Feng", 
    "publish": "2013-03-22T02:27:43Z", 
    "summary": "In this paper, based on the homotopy continuation method and the interval\nNewton method, an efficient algorithm is introduced to isolate the real roots\nof semi-algebraic system.\n  Tests on some random examples and a variety of problems including\ntranscendental functions arising in many applications show that the new\nalgorithm reduces the cost substantially compared with the traditional symbolic\napproaches."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2644288.2644293", 
    "link": "http://arxiv.org/pdf/1308.6523v1", 
    "title": "Branch Cuts in Maple 17", 
    "arxiv-id": "1308.6523v1", 
    "author": "D. Wilson", 
    "publish": "2013-08-29T17:06:18Z", 
    "summary": "Accurate and comprehensible knowledge about the position of branch cuts is\nessential for correctly working with multi-valued functions, such as the square\nroot and logarithm. We discuss the new tools in Maple 17 for calculating and\nvisualising the branch cuts of such functions, and others built up from them.\nThe cuts are described in an intuitive and accurate form, offering substantial\nimprovement on the descriptions previously available."
},{
    "category": "cs.CG", 
    "doi": "10.1109/SYNASC.2013.14", 
    "link": "http://arxiv.org/pdf/1309.1588v2", 
    "title": "A \"Piano Movers\" Problem Reformulated", 
    "arxiv-id": "1309.1588v2", 
    "author": "Russell Bradford", 
    "publish": "2013-09-06T10:20:14Z", 
    "summary": "It has long been known that cylindrical algebraic decompositions (CADs) can\nin theory be used for robot motion planning. However, in practice even the\nsimplest examples can be too complicated to tackle. We consider in detail a\n\"Piano Mover's Problem\" which considers moving an infinitesimally thin piano\n(or ladder) through a right-angled corridor.\n  Producing a CAD for the original formulation of this problem is still\ninfeasible after 25 years of improvements in both CAD theory and computer\nhardware. We review some alternative formulations in the literature which use\ndiffering levels of geometric analysis before input to a CAD algorithm. Simpler\nformulations allow CAD to easily address the question of the existence of a\npath. We provide a new formulation for which both a CAD can be constructed and\nfrom which an actual path could be determined if one exists, and analyse the\nCADs produced using this approach for variations of the problem.\n  This emphasises the importance of the precise formulation of such problems\nfor CAD. We analyse the formulations and their CADs considering a variety of\nheuristics and general criteria, leading to conclusions about tackling other\nproblems of this form."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2013.14", 
    "link": "http://arxiv.org/pdf/1309.2877v1", 
    "title": "Rigorous high-precision computation of the Hurwitz zeta function and its   derivatives", 
    "arxiv-id": "1309.2877v1", 
    "author": "Fredrik Johansson", 
    "publish": "2013-09-11T16:22:35Z", 
    "summary": "We study the use of the Euler-Maclaurin formula to numerically evaluate the\nHurwitz zeta function $\\zeta(s,a)$ for $s, a \\in \\mathbb{C}$, along with an\narbitrary number of derivatives with respect to $s$, to arbitrary precision\nwith rigorous error bounds. Techniques that lead to a fast implementation are\ndiscussed. We present new record computations of Stieltjes constants, Keiper-Li\ncoefficients and the first nontrivial zero of the Riemann zeta function,\nobtained using an open source implementation of the algorithms described in\nthis paper."
},{
    "category": "cs.DS", 
    "doi": "10.1109/SYNASC.2013.14", 
    "link": "http://arxiv.org/pdf/1309.5991v1", 
    "title": "Applications of Continuous Amortization to Bisection-based Root   Isolation", 
    "arxiv-id": "1309.5991v1", 
    "author": "Michael A. Burr", 
    "publish": "2013-09-23T21:48:06Z", 
    "summary": "Continuous amortization is a technique for computing the complexity of\nalgorithms, and it was first presented by the author in Burr, Krahmer, & Yap\n(2009). Continuous amortization can result in simpler and more straight-forward\ncomplexity analyses, and it was used in Burr, Krahmer, & Yap (2009), Burr &\nKrahmer (2012), and Sharma & Yap (2012) to provide complexity bounds for simple\nroot isolation algorithms. This paper greatly extends the reach of continuous\namortization to serve as an overarching technique which can be used to compute\ncomplexity of many root isolation techniques in a straight-forward manner.\nAdditionally, the technique of continuous amortization is extended to higher\ndimensions and to the computation of the bit-complexity of algorithms. In this\npaper, six continuous amortization calculations are performed to compute\ncomplexity bounds (on either the size of the subdivision tree or the bit\ncomplexity) for several algorithms (including algorithms based on Sturm\nsequences, Descartes' rule of signs, and polynomial evaluation); in each case,\ncontinuous amortization achieves an optimal complexity bound."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2013.14", 
    "link": "http://arxiv.org/pdf/1311.5694v1", 
    "title": "Computing the multilinear factors of lacunary polynomials without   heights", 
    "arxiv-id": "1311.5694v1", 
    "author": "Yann Strozecki", 
    "publish": "2013-11-22T10:15:20Z", 
    "summary": "We present a deterministic polynomial-time algorithm which computes the\nmultilinear factors of multivariate lacunary polynomials over number fields. It\nis based on a new Gap theorem which allows to test whether $P(X)=\\sum_{j=1}^k\na_j X^{\\alpha_j}(vX+t)^{\\beta_j}(uX+w)^{\\gamma_j}$ is identically zero in\npolynomial time. Previous algorithms for this task were based on Gap Theorems\nexpressed in terms of the height of the coefficients. Our Gap Theorem is based\non the valuation of the polynomial and is valid for any field of characteristic\nzero. As a consequence we obtain a faster and more elementary algorithm.\nFurthermore, we can partially extend the algorithm to other situations, such as\nabsolute and approximate factorizations.\n  We also give a version of our Gap Theorem valid for fields of large\ncharacteristic, and deduce a randomized polynomial-time algorithm to compute\nmultilinear factors with at least three monomials of multivariate lacunary\npolynomials of finite fields of large characteristic. We provide\n$\\mathsf{NP}$-hardness results to explain our inability to compute binomial\nfactors."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2013.14", 
    "link": "http://arxiv.org/pdf/1402.0622v1", 
    "title": "Divide-And-Conquer Computation of Cylindrical Algebraic Decomposition", 
    "arxiv-id": "1402.0622v1", 
    "author": "Adam Strzebonski", 
    "publish": "2014-02-04T05:52:47Z", 
    "summary": "We present a divide-and-conquer version of the Cylindrical Algebraic\nDecomposition (CAD) algorithm. The algorithm represents the input as a Boolean\ncombination of subformulas, computes cylindrical algebraic decompositions of\nsolution sets of the subformulas, and combines the results. We propose a\ngraph-based heuristic to find a suitable partitioning of the input and present\nempirical comparison with direct CAD computation."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jsc.2015.03.007", 
    "link": "http://arxiv.org/pdf/1402.2930v2", 
    "title": "An Algorithm to Compute the Topological Euler Characteristic,   Chern-Schwartz-MacPherson Class and Segre Class of Projective Varieties", 
    "arxiv-id": "1402.2930v2", 
    "author": "Martin Helmer", 
    "publish": "2014-02-12T18:52:38Z", 
    "summary": "Let $V$ be a closed subscheme of a projective space $\\mathbb{P}^n$. We give\nan algorithm to compute the Chern-Schwartz-MacPherson class, Euler\ncharacteristic and Segre class of $ V$. The algorithm can be implemented using\neither symbolic or numerical methods. The algorithm is based on a new method\nfor calculating the projective degrees of a rational map defined by a\nhomogeneous ideal. Using this result and known formulas for the\nChern-Schwartz-MacPherson class of a projective hypersurface and the Segre\nclass of a projective variety in terms of the projective degrees of certain\nrational maps we give algorithms to compute the Chern-Schwartz-MacPherson class\nand Segre class of a projective variety. Since the Euler characteristic of $V$\nis the degree of the zero dimensional component of the\nChern-Schwartz-MacPherson class of $V$ our algorithm also computes the Euler\ncharacteristic $\\chi(V)$. Relationships between the algorithm developed here\nand other existing algorithms are discussed. The algorithm is tested on several\nexamples and performs favourably compared to current algorithms for computing\nChern-Schwartz-MacPherson classes, Segre classes and Euler characteristics."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2015.03.007", 
    "link": "http://arxiv.org/pdf/1402.3501v1", 
    "title": "Parallel computation of echelon forms", 
    "arxiv-id": "1402.3501v1", 
    "author": "Ziad Sultan", 
    "publish": "2014-02-14T15:35:37Z", 
    "summary": "We propose efficient parallel algorithms and implementations on shared memory\narchitectures of LU factorization over a finite field. Compared to the\ncorresponding numerical routines, we have identified three main difficulties\nspecific to linear algebra over finite fields. First, the arithmetic complexity\ncould be dominated by modular reductions. Therefore, it is mandatory to delay\nas much as possible these reductions while mixing fine-grain parallelizations\nof tiled iterative and recursive algorithms. Second, fast linear algebra\nvariants, e.g., using Strassen-Winograd algorithm, never suffer from\ninstability and can thus be widely used in cascade with the classical\nalgorithms. There, trade-offs are to be made between size of blocks well suited\nto those fast variants or to load and communication balancing. Third, many\napplications over finite fields require the rank profile of the matrix (quite\noften rank deficient) rather than the solution to a linear system. It is thus\nimportant to design parallel algorithms that preserve and compute this rank\nprofile. Moreover, as the rank profile is only discovered during the algorithm,\nblock size has then to be dynamic. We propose and compare several block\ndecomposition: tile iterative with left-looking, right-looking and Crout\nvariants, slab and tile recursive. Experiments demonstrate that the tile\nrecursive variant performs better and matches the performance of reference\nnumerical software when no rank deficiency occur. Furthermore, even in the most\nheterogeneous case, namely when all pivot blocks are rank deficient, we show\nthat it is possbile to maintain a high efficiency."
},{
    "category": "cs.RO", 
    "doi": "10.1016/j.mechmachtheory.2015.07.010", 
    "link": "http://arxiv.org/pdf/1402.5761v3", 
    "title": "A Technique for Deriving Equational Conditions on the Denavit-Hartenberg   Parameters of 6R Linkages that are Necessary for Movability", 
    "arxiv-id": "1402.5761v3", 
    "author": "Josef Schicho", 
    "publish": "2014-02-24T09:45:18Z", 
    "summary": "A closed 6R linkage is generically rigid. Special cases may be mobile. Many\nfamilies of mobile 6R linkages have been characterised in terms of the\ninvariant Denavit-Hartenberg parameters of the linkage. In other words, many\nsufficient conditions for mobility are known. In this paper we give, for the\nfirst time, equational conditions on the invariant Denavit-Hartenberg\nparameters that are necessary for mobility. The method is based on the theory\nof bonds. We illustrate the method by deriving the equational conditions for\nvarious well-known linkages (Bricard's line symmetric linkage, Hooke's linkage,\nDietmaier's linkage, and recent a generalization of Bricard's orthogonal\nlinkage), starting from their bond diagrams; and by deriving the equations for\nanother bond diagram, thereby discovering a new mobile 6R linkage."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.mechmachtheory.2015.07.010", 
    "link": "http://arxiv.org/pdf/1402.5945v1", 
    "title": "Tame Decompositions and Collisions", 
    "arxiv-id": "1402.5945v1", 
    "author": "Konstantin Ziegler", 
    "publish": "2014-02-24T20:57:07Z", 
    "summary": "A univariate polynomial f over a field is decomposable if f = g o h = g(h)\nfor nonlinear polynomials g and h. It is intuitively clear that the\ndecomposable polynomials form a small minority among all polynomials over a\nfinite field. The tame case, where the characteristic p of Fq does not divide n\n= deg f, is fairly well-understood, and we have reasonable bounds on the number\nof decomposables of degree n. Nevertheless, no exact formula is known if $n$\nhas more than two prime factors. In order to count the decomposables, one wants\nto know, under a suitable normalization, the number of collisions, where\nessentially different (g, h) yield the same f. In the tame case, Ritt's Second\nTheorem classifies all 2-collisions.\n  We introduce a normal form for multi-collisions of decompositions of\narbitrary length with exact description of the (non)uniqueness of the\nparameters. We obtain an efficiently computable formula for the exact number of\nsuch collisions at degree n over a finite field of characteristic coprime to p.\nThis leads to an algorithm for the exact number of decomposable polynomials at\ndegree n over a finite field Fq in the tame case."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756665", 
    "link": "http://arxiv.org/pdf/1402.6675v2", 
    "title": "Matrix-F5 algorithms and tropical Gr\u00f6bner bases computation", 
    "arxiv-id": "1402.6675v2", 
    "author": "Tristan Vaccon", 
    "publish": "2014-02-26T20:36:48Z", 
    "summary": "Let $K$ be a field equipped with a valuation. Tropical varieties over $K$ can\nbe defined with a theory of Gr\\\"obner bases taking into account the valuation\nof $K$. Because of the use of the valuation, this theory is promising for\nstable computations over polynomial rings over a $p$-adic fields.We design a\nstrategy to compute such tropical Gr\\\"obner bases by adapting the Matrix-F5\nalgorithm. Two variants of the Matrix-F5 algorithm, depending on how the\nMacaulay matrices are built, are available to tropical computation with\nrespective modifications. The former is more numerically stable while the\nlatter is faster.Our study is performed both over any exact field with\nvaluation and some inexact fields like $\\mathbb{Q}\\_p$ or $\\mathbb{F}\\_q\n\\llbracket t \\rrbracket.$ In the latter case, we track the loss in precision,\nand show that the numerical stability can compare very favorably to the case of\nclassical Gr\\\"obner bases when the valuation is non-trivial. Numerical examples\nare provided."
},{
    "category": "math.CA", 
    "doi": "10.1145/2755996.2756665", 
    "link": "http://arxiv.org/pdf/1402.6778v2", 
    "title": "Nonnegative Trigonometric Polynomials, Sturms Theorem, and Symbolic   Computation", 
    "arxiv-id": "1402.6778v2", 
    "author": "Man Kam Kwong", 
    "publish": "2014-02-27T03:07:02Z", 
    "summary": "In this paper, we explain a procedure based on a classical result of Sturm\nthat can be used to determine rigorously whether a given trigonometric\npolynomial is nonnegative in a certain interval or not. Many examples are\ngiven. This technique has been employed by the author in several recent works.\n  The procedure often involves tedious computations that are time-consuming and\nerror-prone. Fortunately, symbolic computation software is available to\nautomate the procedure. In this paper, we give the details of its\nimplementation in MAPLE 13. Some who are strongly attached to a more\ntraditional theoretical research framework may find such details boring or even\nconsider computer-assisted proofs suspicious. However, we emphasize again that\nthe procedure is completely mathematically rigorous."
},{
    "category": "math.NT", 
    "doi": "10.1112/S1461157014000357", 
    "link": "http://arxiv.org/pdf/1402.7142v1", 
    "title": "Tracking p-adic precision", 
    "arxiv-id": "1402.7142v1", 
    "author": "Tristan Vaccon", 
    "publish": "2014-02-28T06:12:22Z", 
    "summary": "We present a new method to propagate $p$-adic precision in computations,\nwhich also applies to other ultrametric fields. We illustrate it with many\nexamples and give a toy application to the stable computation of the SOMOS 4\nsequence."
},{
    "category": "math.AC", 
    "doi": "10.1112/S1461157014000357", 
    "link": "http://arxiv.org/pdf/1404.0161v1", 
    "title": "Predicting zero reductions in Gr\u00f6bner basis computations", 
    "arxiv-id": "1404.0161v1", 
    "author": "Christian Eder", 
    "publish": "2014-04-01T08:24:36Z", 
    "summary": "Since Buchberger's initial algorithm for computing Gr\\\"obner bases in 1965\nmany attempts have been taken to detect zero reductions in advance.\nBuchberger's Product and Chain criteria may be known the most, especially in\nthe installaton of Gebauer and M\\\"oller. A relatively new approach are\nsignature-based criteria which were first used in Faug\\`ere's F5 algorithm in\n2002. For regular input sequences these criteria are known to compute no zero\nreduction at all. In this paper we give a detailed discussion on zero\nreductions and the corresponding syzygies. We explain how the different methods\nto predict them compare to each other and show advantages and drawbacks in\ntheory and practice. With this a new insight into algebraic structures\nunderlying Gr\\\"obner bases and their computations might be achieved."
},{
    "category": "math.AC", 
    "doi": "10.1112/S1461157014000357", 
    "link": "http://arxiv.org/pdf/1404.1774v1", 
    "title": "A survey on signature-based Gr\u00f6bner basis computations", 
    "arxiv-id": "1404.1774v1", 
    "author": "Jean-Charles Faug\u00e8re", 
    "publish": "2014-04-07T13:03:01Z", 
    "summary": "This paper is a survey on the area of signature-based Gr\\\"obner basis\nalgorithms that was initiated by Faug\\`ere's F5 algorithm in 2002. We explain\nthe general ideas behind the usage of signatures. We show how to classify the\nvarious known variants by 3 different orderings. For this we give translations\nbetween different notations and show that besides notations many approaches are\njust the same. Moreover, we give a general description of how the idea of\nsignatures is quite natural when performing the reduction process using linear\nalgebra. This survey shall help to outline this field of active research."
},{
    "category": "cs.SC", 
    "doi": "10.1090/mcom/3054", 
    "link": "http://arxiv.org/pdf/1404.5069v3", 
    "title": "Computing periods of rational integrals", 
    "arxiv-id": "1404.5069v3", 
    "author": "Pierre Lairez", 
    "publish": "2014-04-20T20:35:44Z", 
    "summary": "A period of a rational integral is the result of integrating, with respect to\none or several variables, a rational function over a closed path. This work\nfocuses particularly on periods depending on a parameter: in this case the\nperiod under consideration satisfies a linear differential equation, the\nPicard-Fuchs equation. I give a reduction algorithm that extends the\nGriffiths-Dwork reduction and apply it to the computation of Picard-Fuchs\nequations. The resulting algorithm is elementary and has been successfully\napplied to problems that were previously out of reach."
},{
    "category": "cs.NA", 
    "doi": "10.1090/mcom/3054", 
    "link": "http://arxiv.org/pdf/1404.5525v1", 
    "title": "Global Newton Iteration over Archimedean and non-Archimedean Fields", 
    "arxiv-id": "1404.5525v1", 
    "author": "Agnes Szanto", 
    "publish": "2014-04-17T20:00:33Z", 
    "summary": "In this paper, we study iterative methods on the coefficients of the rational\nunivariate representation (RUR) of a given algebraic set, called global Newton\niteration. We compare two natural approaches to define locally quadratically\nconvergent iterations: the first one involves Newton iteration applied to the\napproximate roots individually and then interpolation to find the RUR of these\napproximate roots; the second one considers the coefficients in the exact RUR\nas zeroes of a high dimensional map defined by polynomial reduction, and\napplies Newton iteration on this map. We prove that over fields with a p-adic\nvaluation these two approaches give the same iteration function, but over\nfields equipped with the usual Archimedean absolute value, they are not\nequivalent. In the latter case, we give explicitly the iteration function for\nboth approaches. Finally, we analyze the parallel complexity of the different\nversions of the global Newton iteration, compare them, and demonstrate that\nthey can be efficiently computed. The motivation for this study comes from the\ncertification of approximate roots of overdetermined and singular polynomial\nsystems via the recovery of an exact RUR from approximate numerical data."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1404.6369v1", 
    "title": "Applying machine learning to the problem of choosing a heuristic to   select the variable ordering for cylindrical algebraic decomposition", 
    "arxiv-id": "1404.6369v1", 
    "author": "James Bridge", 
    "publish": "2014-04-25T09:43:05Z", 
    "summary": "Cylindrical algebraic decomposition(CAD) is a key tool in computational\nalgebraic geometry, particularly for quantifier elimination over real-closed\nfields. When using CAD, there is often a choice for the ordering placed on the\nvariables. This can be important, with some problems infeasible with one\nvariable ordering but easy with another. Machine learning is the process of\nfitting a computer model to a complex function based on properties learned from\nmeasured data. In this paper we use machine learning (specifically a support\nvector machine) to select between heuristics for choosing a variable ordering,\noutperforming each of the separate heuristics."
},{
    "category": "math.AG", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1404.7580v2", 
    "title": "Binomial Difference Ideal and Toric Difference Variety", 
    "arxiv-id": "1404.7580v2", 
    "author": "Chun-Ming Yuan", 
    "publish": "2014-04-30T02:54:10Z", 
    "summary": "In this paper, the concepts of binomial difference ideals and toric\ndifference varieties are defined and their properties are proved. Two canonical\nrepresentations for Laurent binomial difference ideals are given using the\nreduced Groebner basis of Z[x]-lattices and regular and coherent difference\nascending chains, respectively. Criteria for a Laurent binomial difference\nideal to be reflexive, prime, well-mixed, perfect, and toric are given in terms\nof their support lattices which are Z[x]-lattices. The reflexive, well-mixed,\nand perfect closures of a Laurent binomial difference ideal are shown to be\nbinomial. Four equivalent definitions for toric difference varieties are\npresented. Finally, algorithms are given to check whether a given Laurent\nbinomial difference ideal I is reflexive, prime, well-mixed, perfect, or toric,\nand in the negative case, to compute the reflexive, well-mixed, and perfect\nclosures of I. An algorithm is given to decompose a finitely generated perfect\nbinomial difference ideal as the intersection of reflexive prime binomial\ndifference ideals."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1406.0907v2", 
    "title": "Computing GCRDs of Approximate Differential Polynomials", 
    "arxiv-id": "1406.0907v2", 
    "author": "Joseph Haraldson", 
    "publish": "2014-06-03T23:52:08Z", 
    "summary": "Differential (Ore) type polynomials with approximate polynomial coefficients\nare introduced. These provide a useful representation of approximate\ndifferential operators with a strong algebraic structure, which has been used\nsuccessfully in the exact, symbolic, setting. We then present an algorithm for\nthe approximate Greatest Common Right Divisor (GCRD) of two approximate\ndifferential polynomials, which intuitively is the differential operator whose\nsolutions are those common to the two inputs operators. More formally, given\napproximate differential polynomials $f$ and $g$, we show how to find \"nearby\"\npolynomials $\\widetilde f$ and $\\widetilde g$ which have a non-trivial GCRD.\nHere \"nearby\" is under a suitably defined norm. The algorithm is a\ngeneralization of the SVD-based method of Corless et al. (1995) for the\napproximate GCD of regular polynomials. We work on an appropriately\n\"linearized\" differential Sylvester matrix, to which we apply a block SVD. The\nalgorithm has been implemented in Maple and a demonstration of its robustness\nis presented."
},{
    "category": "math.AG", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1406.2140v3", 
    "title": "Covering Rational Ruled Surfaces", 
    "arxiv-id": "1406.2140v3", 
    "author": "Carlos Villarino", 
    "publish": "2014-06-09T11:22:34Z", 
    "summary": "We present an algorithm that covers any given rational ruled surface with two\nrational parametrizations. In addition, we present an algorithm that transforms\nany rational surface parametrization into a new rational surface\nparametrization without affine base points and such that the degree of the\ncorresponding maps is preserved."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1406.3163v3", 
    "title": "Solving the \"Isomorphism of Polynomials with Two Secrets\" Problem for   all Pairs of Quadratic Forms", 
    "arxiv-id": "1406.3163v3", 
    "author": "Gilles Macario-Rat", 
    "publish": "2014-06-12T09:26:31Z", 
    "summary": "We study the Isomorphism of Polynomial (IP2S) problem with m=2 homogeneous\nquadratic polynomials of n variables over a finite field of odd characteristic:\ngiven two quadratic polynomials (a, b) on n variables, we find two bijective\nlinear maps (s,t) such that b=t . a . s. We give an algorithm computing s and t\nin time complexity O~(n^4) for all instances, and O~(n^3) in a dominant set of\ninstances.\n  The IP2S problem was introduced in cryptography by Patarin back in 1996. The\nspecial case of this problem when t is the identity is called the isomorphism\nwith one secret (IP1S) problem. Generic algebraic equation solvers (for example\nusing Gr\\\"obner bases) solve quite well random instances of the IP1S problem.\nFor the particular cyclic instances of IP1S, a cubic-time algorithm was later\ngiven and explained in terms of pencils of quadratic forms over all finite\nfields; in particular, the cyclic IP1S problem in odd characteristic reduces to\nthe computation of the square root of a matrix.\n  We give here an algorithm solving all cases of the IP1S problem in odd\ncharacteristic using two new tools, the Kronecker form for a singular quadratic\npencil, and the reduction of bilinear forms over a non-commutative algebra.\nFinally, we show that the second secret in the IP2S problem may be recovered in\ncubic time."
},{
    "category": "math.RA", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1406.3523v3", 
    "title": "Deterministic polynomial-time test for prime ideals in a Dedekind domain   with finite rank", 
    "arxiv-id": "1406.3523v3", 
    "author": "Yingpu Deng", 
    "publish": "2014-06-13T12:52:39Z", 
    "summary": "We describe a deterministic polynomial-time test that determining whether a\nnonzero ideal is a prime ideal in a Dedekind domain with finite rank. The\ntechniques which we used are basis representation of finite rings and the\nHermite and Smith normal forms."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-08434-3_8", 
    "link": "http://arxiv.org/pdf/1408.2473v1", 
    "title": "An Algorithm for Deciding the Summability of Bivariate Rational   Functions", 
    "arxiv-id": "1408.2473v1", 
    "author": "Rong-Hua Wang", 
    "publish": "2014-06-26T02:38:19Z", 
    "summary": "Let $\\Delta_x f(x,y)=f(x+1,y)-f(x,y)$ and $\\Delta_y f(x,y)=f(x,y+1)-f(x,y)$\nbe the difference operators with respect to $x$ and $y$. A rational function\n$f(x,y)$ is called summable if there exist rational functions $g(x,y)$ and\n$h(x,y)$ such that $f(x,y)=\\Delta_x g(x,y) + \\Delta_y h(x,y)$. Recently, Chen\nand Singer presented a method for deciding whether a rational function is\nsummable. To implement their method in the sense of algorithms, we need to\nsolve two problems. The first is to determine the shift equivalence of two\nbivariate polynomials. We solve this problem by presenting an algorithm for\ncomputing the dispersion sets of any two bivariate polynomials. The second is\nto solve a univariate difference equation in an algebraically closed field. By\nconsidering the irreducible factorization of the denominator of $f(x,y)$ in a\ngeneral field, we present a new criterion which requires only finding a\nrational solution of a bivariate difference equation. This goal can be achieved\nby deriving a universal denominator of the rational solutions and a degree\nbound on the numerator. Combining these two algorithms, we can decide the\nsummability of a bivariate rational function."
},{
    "category": "cs.SC", 
    "doi": "10.1109/IC3.2014.6897161", 
    "link": "http://arxiv.org/pdf/1408.4942v1", 
    "title": "Computing Multiplicative Order and Primitive Root in Finite Cyclic Group", 
    "arxiv-id": "1408.4942v1", 
    "author": "Shri Prakash Dwivedi", 
    "publish": "2014-08-21T10:36:15Z", 
    "summary": "Multiplicative order of an element $a$ of group $G$ is the least positive\ninteger $n$ such that $a^n=e$, where $e$ is the identity element of $G$. If the\norder of an element is equal to $|G|$, it is called generator or primitive\nroot. This paper describes the algorithms for computing multiplicative order\nand primitive root in $\\mathbb{Z}^*_{p}$, we also present a logarithmic\nimprovement over classical algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1109/IC3.2014.6897161", 
    "link": "http://arxiv.org/pdf/1408.5512v1", 
    "title": "Desingularization of Ore Operators", 
    "arxiv-id": "1408.5512v1", 
    "author": "Michael F. Singer", 
    "publish": "2014-08-23T16:52:18Z", 
    "summary": "We show that Ore operators can be desingularized by calculating a least\ncommon left multiple with a random operator of appropriate order. Our result\ngeneralizes a classical result about apparent singularities of linear\ndifferential equations, and it gives rise to a surprisingly simple\ndesingularization algorithm."
},{
    "category": "cs.SC", 
    "doi": "10.1109/IC3.2014.6897161", 
    "link": "http://arxiv.org/pdf/1408.5514v1", 
    "title": "Bounds for D-finite closure properties", 
    "arxiv-id": "1408.5514v1", 
    "author": "Manuel Kauers", 
    "publish": "2014-08-23T16:56:26Z", 
    "summary": "We provide bounds on the size of operators obtained by algorithms for\nexecuting D-finite closure properties. For operators of small order, we give\nbounds on the degree and on the height (bit-size). For higher order operators,\nwe give degree bounds that are parameterized with respect to the order and\nreflect the phenomenon that higher order operators may have lower degrees\n(order-degree curves)."
},{
    "category": "math.AG", 
    "doi": "10.1109/IC3.2014.6897161", 
    "link": "http://arxiv.org/pdf/1409.6215v2", 
    "title": "Tropical Effective Primary and Dual Nullstellens\u00e4tze", 
    "arxiv-id": "1409.6215v2", 
    "author": "Vladimir V. Podolskii", 
    "publish": "2014-09-22T15:56:27Z", 
    "summary": "Tropical algebra is an emerging field with a number of applications in\nvarious areas of mathematics. In many of these applications appeal to tropical\npolynomials allows to study properties of mathematical objects such as\nalgebraic varieties and algebraic curves from the computational point of view.\nThis makes it important to study both mathematical and computational aspects of\ntropical polynomials.\n  In this paper we prove a tropical Nullstellensatz and moreover we show an\neffective formulation of this theorem. Nullstellensatz is a natural step in\nbuilding algebraic theory of tropical polynomials and its effective version is\nrelevant for computational aspects of this field.\n  On our way we establish a simple formulation of min-plus and tropical linear\ndualities. We also observe a close connection between tropical and min-plus\npolynomial systems."
},{
    "category": "math.AG", 
    "doi": "10.1109/IC3.2014.6897161", 
    "link": "http://arxiv.org/pdf/1501.02755v1", 
    "title": "Computation of Differential Chow Forms for Prime Differential Ideals", 
    "arxiv-id": "1501.02755v1", 
    "author": "Yinghong Li", 
    "publish": "2015-01-12T19:14:47Z", 
    "summary": "In this paper, we propose algorithms to compute differential Chow forms for\nprime differential ideals which are given by their characteristic sets. The\nmain algorithm is based on an optimal bound for the order of a prime\ndifferential ideal in terms of its characteristic set under an arbitrary\nranking, which shows the Jacobi bound conjecture holds in this case. Apart from\nthe order bound, we also give a degree bound for the differential Chow form. In\naddition, for prime differential ideals given by their characteristic sets\nunder an orderly ranking, a much more simpler algorithm is given to compute its\ndifferential Chow form. The computational complexity of both is single\nexponential in terms of the Jacobi number, the maximal degree of the\ndifferential polynomials in the characteristic set and the number of variables."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756658", 
    "link": "http://arxiv.org/pdf/1501.03691v2", 
    "title": "Integral D-Finite Functions", 
    "arxiv-id": "1501.03691v2", 
    "author": "Christoph Koutschan", 
    "publish": "2015-01-15T14:29:19Z", 
    "summary": "We propose a differential analog of the notion of integral closure of\nalgebraic function fields. We present an algorithm for computing the integral\nclosure of the algebra defined by a linear differential operator. Our algorithm\nis a direct analog of van Hoeij's algorithm for computing integral bases of\nalgebraic function fields."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756658", 
    "link": "http://arxiv.org/pdf/1501.04668v2", 
    "title": "A Modified Abramov-Petkovsek Reduction and Creative Telescoping for   Hypergeometric Terms", 
    "arxiv-id": "1501.04668v2", 
    "author": "Ziming Li", 
    "publish": "2015-01-19T23:00:12Z", 
    "summary": "The Abramov-Petkovsek reduction computes an additive decomposition of a\nhypergeometric term, which extends the functionality of the Gosper algorithm\nfor indefinite hypergeometric summation. We modify the Abramov-Petkovsek\nreduction so as to decompose a hypergeometric term as the sum of a summable\nterm and a non-summable one. The outputs of the Abramov-Petkovsek reduction and\nour modified version share the same required properties. The modified reduction\ndoes not solve any auxiliary linear difference equation explicitly. It is also\nmore efficient than the original reduction according to computational\nexperiments. Based on this reduction, we design a new algorithm to compute\nminimal telescopers for bivariate hypergeometric terms. The new algorithm can\navoid the costly computation of certificates."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756658", 
    "link": "http://arxiv.org/pdf/1501.05098v1", 
    "title": "Better Answers to Real Questions", 
    "arxiv-id": "1501.05098v1", 
    "author": "Andreas Dolzmann", 
    "publish": "2015-01-21T09:14:26Z", 
    "summary": "We consider existential problems over the reals. Extended quantifier\nelimination generalizes the concept of regular quantifier elimination by\nproviding in addition answers, which are descriptions of possible assignments\nfor the quantified variables. Implementations of extended quantifier\nelimination via virtual substitution have been successfully applied to various\nproblems in science and engineering. So far, the answers produced by these\nimplementations included infinitesimal and infinite numbers, which are hard to\ninterpret in practice. We introduce here a post-processing procedure to\nconvert, for fixed parameters, all answers into standard real numbers. The\nrelevance of our procedure is demonstrated by application of our implementation\nto various examples from the literature, where it significantly improves the\nquality of the results."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756658", 
    "link": "http://arxiv.org/pdf/1501.05826v1", 
    "title": "A Generalized Framework for Virtual Substitution", 
    "arxiv-id": "1501.05826v1", 
    "author": "Thomas Sturm", 
    "publish": "2015-01-23T15:13:43Z", 
    "summary": "We generalize the framework of virtual substitution for real quantifier\nelimination to arbitrary but bounded degrees. We make explicit the\nrepresentation of test points in elimination sets using roots of parametric\nunivariate polynomials described by Thom codes. Our approach follows an early\nsuggestion by Weispfenning, which has never been carried out explicitly.\nInspired by virtual substitution for linear formulas, we show how to\nsystematically construct elimination sets containing only test points\nrepresenting lower bounds."
},{
    "category": "math.AC", 
    "doi": "10.1145/2755996.2756658", 
    "link": "http://arxiv.org/pdf/1007.1834v1", 
    "title": "GPGCD, an Iterative Method for Calculating Approximate GCD of Univariate   Polynomials, with the Complex Coefficients", 
    "arxiv-id": "1007.1834v1", 
    "author": "Akira Terui", 
    "publish": "2010-07-12T07:16:31Z", 
    "summary": "We present an extension of our GPGCD method, an iterative method for\ncalculating approximate greatest common divisor (GCD) of univariate\npolynomials, to polynomials with the complex coefficients. For a given pair of\npolynomials and a degree, our algorithm finds a pair of polynomials which has a\nGCD of the given degree and whose coefficients are perturbed from those in the\noriginal inputs, making the perturbations as small as possible, along with the\nGCD. In our GPGCD method, the problem of approximate GCD is transfered to a\nconstrained minimization problem, then solved with a so-called modified Newton\nmethod, which is a generalization of the gradient-projection method, by\nsearching the solution iteratively. While our original method is designed for\npolynomials with the real coefficients, we extend it to accept polynomials with\nthe complex coefficients in this paper."
},{
    "category": "math.AC", 
    "doi": "10.1007/978-3-642-15274-0_22", 
    "link": "http://arxiv.org/pdf/1007.1836v1", 
    "title": "GPGCD, an Iterative Method for Calculating Approximate GCD, for Multiple   Univariate Polynomials", 
    "arxiv-id": "1007.1836v1", 
    "author": "Akira Terui", 
    "publish": "2010-07-12T07:35:54Z", 
    "summary": "We present an extension of our GPGCD method, an iterative method for\ncalculating approximate greatest common divisor (GCD) of univariate\npolynomials, to multiple polynomial inputs. For a given pair of polynomials and\na degree, our algorithm finds a pair of polynomials which has a GCD of the\ngiven degree and whose coefficients are perturbed from those in the original\ninputs, making the perturbations as small as possible, along with the GCD. In\nour GPGCD method, the problem of approximate GCD is transferred to a\nconstrained minimization problem, then solved with the so-called modified\nNewton method, which is a generalization of the gradient-projection method, by\nsearching the solution iteratively. In this paper, we extend our method to\naccept more than two polynomials with the real coefficients as an input."
},{
    "category": "math.NA", 
    "doi": "10.1007/978-3-642-15274-0_22", 
    "link": "http://arxiv.org/pdf/1007.2117v2", 
    "title": "Strassen's Matrix Multiplication Algorithm for Matrices of Arbitrary   Order", 
    "arxiv-id": "1007.2117v2", 
    "author": "Ivo Hedtke", 
    "publish": "2010-07-13T14:44:15Z", 
    "summary": "The well known algorithm of Volker Strassen for matrix multiplication can\nonly be used for $(m2^k \\times m2^k)$ matrices. For arbitrary $(n \\times n)$\nmatrices one has to add zero rows and columns to the given matrices to use\nStrassen's algorithm. Strassen gave a strategy of how to set $m$ and $k$ for\narbitrary $n$ to ensure $n\\leq m2^k$. In this paper we study the number $d$ of\nadditional zero rows and columns and the influence on the number of flops used\nby the algorithm in the worst case ($d=n/16$), best case ($d=1$) and in the\naverage case ($d\\approx n/48$). The aim of this work is to give a detailed\nanalysis of the number of additional zero rows and columns and the additional\nwork caused by Strassen's bad parameters. Strassen used the parameters $m$ and\n$k$ to show that his matrix multiplication algorithm needs less than\n$4.7n^{\\log_2 7}$ flops. We can show in this paper, that these parameters cause\nan additional work of approx. 20 % in the worst case in comparison to the\noptimal strategy for the worst case. This is the main reason for the search for\nbetter parameters."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-15274-0_22", 
    "link": "http://arxiv.org/pdf/1007.3615v1", 
    "title": "Connecting Gr\u00f6bner Bases Programs with Coq to do Proofs in Algebra,   Geometry and Arithmetics", 
    "arxiv-id": "1007.3615v1", 
    "author": "Lo\u00efc Pottier", 
    "publish": "2010-07-21T11:16:48Z", 
    "summary": "We describe how we connected three programs that compute Groebner bases to\nCoq, to do automated proofs on algebraic, geometrical and arithmetical\nexpressions. The result is a set of Coq tactics and a certificate mechanism\n(downloadable at http://www-sop.inria.fr/marelle/Loic.Pottier/gb-keappa.tgz).\nThe programs are: F4, GB \\, and gbcoq. F4 and GB are the fastest (up to our\nknowledge) available programs that compute Groebner bases. Gbcoq is slow in\ngeneral but is proved to be correct (in Coq), and we adapted it to our specific\nproblem to be efficient. The automated proofs concern equalities and\nnon-equalities on polynomials with coefficients and indeterminates in R or Z,\nand are done by reducing to Groebner computation, via Hilbert's\nNullstellensatz. We adapted also the results of Harrison, to allow to prove\nsome theorems about modular arithmetics. The connection between Coq and the\nprograms that compute Groebner bases is done using the \"external\" tactic of Coq\nthat allows to call arbitrary programs accepting xml inputs and outputs. We\nalso produce certificates in order to make the proof scripts independant from\nthe external programs."
},{
    "category": "cs.CC", 
    "doi": "10.1090/conm/556", 
    "link": "http://arxiv.org/pdf/1007.3804v4", 
    "title": "Symmetric Determinantal Representation of Formulas and Weakly Skew   Circuits", 
    "arxiv-id": "1007.3804v4", 
    "author": "Natacha Portier", 
    "publish": "2010-07-22T06:07:33Z", 
    "summary": "We deploy algebraic complexity theoretic techniques for constructing\nsymmetric determinantal representations of for00504925mulas and weakly skew\ncircuits. Our representations produce matrices of much smaller dimensions than\nthose given in the convex geometry literature when applied to polynomials\nhaving a concise representation (as a sum of monomials, or more generally as an\narithmetic formula or a weakly skew circuit). These representations are valid\nin any field of characteristic different from 2. In characteristic 2 we are led\nto an almost complete solution to a question of B\\\"urgisser on the\nVNP-completeness of the partial permanent. In particular, we show that the\npartial permanent cannot be VNP-complete in a finite field of characteristic 2\nunless the polynomial hierarchy collapses."
},{
    "category": "math.FA", 
    "doi": "10.1090/conm/556", 
    "link": "http://arxiv.org/pdf/1007.5442v1", 
    "title": "Dominance in the family of Sugeno-Weber t-norms", 
    "arxiv-id": "1007.5442v1", 
    "author": "Susanne Saminger-Platz", 
    "publish": "2010-07-30T13:25:32Z", 
    "summary": "The dominance relationship between two members of the family of Sugeno Weber\nt-norms is proven by using a quantifer elimination algorithm. Further it is\nshown that dominance is a transitive, and therefore also an order relation, on\nthis family of t-norms."
},{
    "category": "cs.SC", 
    "doi": "10.1090/conm/556", 
    "link": "http://arxiv.org/pdf/1104.0689v1", 
    "title": "Algorithms for Computing Triangular Decompositions of Polynomial Systems", 
    "arxiv-id": "1104.0689v1", 
    "author": "Marc Moreno Maza", 
    "publish": "2011-04-04T20:52:03Z", 
    "summary": "We propose new algorithms for computing triangular decompositions of\npolynomial systems incrementally. With respect to previous works, our\nimprovements are based on a {\\em weakened} notion of a polynomial GCD modulo a\nregular chain, which permits to greatly simplify and optimize the\nsub-algorithms. Extracting common work from similar expensive computations is\nalso a key feature of our algorithms. In our experimental results the\nimplementation of our new algorithms, realized with the {\\RegularChains}\nlibrary in {\\Maple}, outperforms solvers with similar specifications by several\norders of magnitude on sufficiently difficult problems."
},{
    "category": "cs.SC", 
    "doi": "10.1090/conm/556", 
    "link": "http://arxiv.org/pdf/1104.0746v1", 
    "title": "Quantifier Elimination over Finite Fields Using Gr\u00f6bner Bases", 
    "arxiv-id": "1104.0746v1", 
    "author": "Edmund M. Clarke", 
    "publish": "2011-04-05T06:58:39Z", 
    "summary": "We give an algebraic quantifier elimination algorithm for the first-order\ntheory over any given finite field using Gr\\\"obner basis methods. The algorithm\nrelies on the strong Nullstellensatz and properties of elimination ideals over\nfinite fields. We analyze the theoretical complexity of the algorithm and show\nits application in the formal analysis of a biological controller model."
},{
    "category": "math.AG", 
    "doi": "10.1090/conm/556", 
    "link": "http://arxiv.org/pdf/1104.2470v1", 
    "title": "Effective radical parametrization of trigonal curves", 
    "arxiv-id": "1104.2470v1", 
    "author": "David Sevilla", 
    "publish": "2011-04-13T12:37:45Z", 
    "summary": "Let $C$ be a non-hyperelliptic algebraic curve. It is known that its\ncanonical image is the intersection of the quadrics that contain it, except\nwhen $C$ is trigonal (that is, it has a linear system of degree 3 and dimension\n1) or isomorphic to a plane quintic (genus 6). In this context, we present a\nmethod to decide whether a given algebraic curve is trigonal, and in the\naffirmative case to compute a map from $C$ to the projective line whose fibers\ncut out the linear system."
},{
    "category": "math.AC", 
    "doi": "10.1090/conm/556", 
    "link": "http://arxiv.org/pdf/1104.2724v1", 
    "title": "Computing Border Bases without using a Term Ordering", 
    "arxiv-id": "1104.2724v1", 
    "author": "Stefan Kaspar", 
    "publish": "2011-04-14T11:22:58Z", 
    "summary": "Border bases, a generalization of Groebner bases, have actively been\nresearched during recent years due to their applicability to industrial\nproblems. A. Kehrein and M. Kreuzer formulated the so called Border Basis\nAlgorithm, an algorithm which allows the computation of border bases that\nrelate to a degree compatible term ordering. In this paper we extend the\noriginal Border Basis Algorithm in such a way that also border bases that do\nnot relate to any term ordering can be computed by it."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-7(2:6)2011", 
    "link": "http://arxiv.org/pdf/1104.4131v4", 
    "title": "Automated Synthesis of Tableau Calculi", 
    "arxiv-id": "1104.4131v4", 
    "author": "Dmitry Tishkovsky", 
    "publish": "2011-04-20T21:22:43Z", 
    "summary": "This paper presents a method for synthesising sound and complete tableau\ncalculi. Given a specification of the formal semantics of a logic, the method\ngenerates a set of tableau inference rules that can then be used to reason\nwithin the logic. The method guarantees that the generated rules form a\ncalculus which is sound and constructively complete. If the logic can be shown\nto admit finite filtration with respect to a well-defined first-order semantics\nthen adding a general blocking mechanism provides a terminating tableau\ncalculus. The process of generating tableau rules can be completely automated\nand produces, together with the blocking mechanism, an automated procedure for\ngenerating tableau decision procedures. For illustration we show the\nworkability of the approach for a description logic with transitive roles and\npropositional intuitionistic logic."
},{
    "category": "math.NA", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1104.4208v2", 
    "title": "Computer Algebra meets Finite Elements: an Efficient Implementation for   Maxwell's Equations", 
    "arxiv-id": "1104.4208v2", 
    "author": "Joachim Schoeberl", 
    "publish": "2011-04-21T09:02:17Z", 
    "summary": "We consider the numerical discretization of the time-domain Maxwell's\nequations with an energy-conserving discontinuous Galerkin finite element\nformulation. This particular formulation allows for higher order approximations\nof the electric and magnetic field. Special emphasis is placed on an efficient\nimplementation which is achieved by taking advantage of recurrence properties\nand the tensor-product structure of the chosen shape functions. These\nrecurrences have been derived symbolically with computer algebra methods\nreminiscent of the holonomic systems approach."
},{
    "category": "math.NT", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1104.4557v1", 
    "title": "Square root Bound on the Least Power Non-residue using a   Sylvester-Vandermonde Determinant", 
    "arxiv-id": "1104.4557v1", 
    "author": "Chandan Saha", 
    "publish": "2011-04-23T13:37:14Z", 
    "summary": "We give a new elementary proof of the fact that the value of the least\n$k^{th}$ power non-residue in an arithmetic progression $\\{bn+c\\}_{n=0,1...}$,\nover a prime field $\\F_p$, is bounded by $7/\\sqrt{5} \\cdot b \\cdot \\sqrt{p/k} +\n4b + c$. Our proof is inspired by the so called \\emph{Stepanov method}, which\ninvolves bounding the size of the solution set of a system of equations by\nconstructing a non-zero low degree auxiliary polynomial that vanishes with high\nmultiplicity on the solution set. The proof uses basic algebra and number\ntheory along with a determinant identity that generalizes both the Sylvester\nand the Vandermonde determinant."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1109.0686v2", 
    "title": "A Majorization Order on Monomials and Termination of a Successive   Difference Substitution Algorithm", 
    "arxiv-id": "1109.0686v2", 
    "author": "Yong Yao", 
    "publish": "2011-09-04T08:26:22Z", 
    "summary": "We introduce a majorization order on monomials. With the help of this order,\nwe derive a necessary condition on the positive termination of a general\nsuccessive difference substitution algorithm (KSDS) for an input form $f$."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1109.2785v1", 
    "title": "Solving large linear algebraic systems in the context of integrable   non-abelian Laurent ODEs", 
    "arxiv-id": "1109.2785v1", 
    "author": "Kenneth Webster", 
    "publish": "2011-09-13T13:44:17Z", 
    "summary": "The paper reports on a computer algebra program LSSS (Linear Selective\nSystems Solver) for solving linear algebraic systems with rational\ncoefficients. The program is especially efficient for very large sparse systems\nthat have a solution in which many variables take the value zero. The program\nis applied to the symmetry investigation of a non-abelian Laurent ODE\nintroduced recently by M. Kontsevich. The computed symmetries confirmed that a\nLax pair found for this system earlier generates all first integrals of degree\nat least up to 14."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1109.6279v1", 
    "title": "When Newton meets Descartes: A Simple and Fast Algorithm to Isolate the   Real Roots of a Polynomial", 
    "arxiv-id": "1109.6279v1", 
    "author": "Michael Sagraloff", 
    "publish": "2011-09-28T17:39:07Z", 
    "summary": "We introduce a new algorithm denoted DSC2 to isolate the real roots of a\nunivariate square-free polynomial f with integer coefficients. The algorithm\niteratively subdivides an initial interval which is known to contain all real\nroots of f. The main novelty of our approach is that we combine Descartes' Rule\nof Signs and Newton iteration. More precisely, instead of using a fixed\nsubdivision strategy such as bisection in each iteration, a Newton step based\non the number of sign variations for an actual interval is considered, and,\nonly if the Newton step fails, we fall back to bisection. Following this\napproach, our analysis shows that, for most iterations, we can achieve\nquadratic convergence towards the real roots. In terms of complexity, our\nmethod induces a recursion tree of almost optimal size O(nlog(n tau)), where n\ndenotes the degree of the polynomial and tau the bitsize of its coefficients.\nThe latter bound constitutes an improvement by a factor of tau upon all\nexisting subdivision methods for the task of isolating the real roots. In\naddition, we provide a bit complexity analysis showing that DSC2 needs only\n\\tilde{O}(n^3tau) bit operations to isolate all real roots of f. This matches\nthe best bound known for this fundamental problem. However, in comparison to\nthe much more involved algorithms by Pan and Sch\\\"onhage (for the task of\nisolating all complex roots) which achieve the same bit complexity, DSC2\nfocuses on real root isolation, is very easy to access and easy to implement."
},{
    "category": "math.NT", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1204.1294v1", 
    "title": "New techniques for computing the ideal class group and a system of   fundamental units in number fields", 
    "arxiv-id": "1204.1294v1", 
    "author": "Claus Fieker", 
    "publish": "2012-04-05T18:17:30Z", 
    "summary": "We describe a new algorithm for computing the ideal class group, the\nregulator and a system of fundamental units in number fields under the\ngeneralized Riemann hypothesis. We use sieving techniques adapted from the\nnumber field sieve algorithm to derive relations between elements of the ideal\nclass group, and $p$-adic approximations to manage the loss of precision during\nthe computation of units. This new algorithm is particularily efficient for\nnumber fields of small degree for which a speed-up of an order of magnitude is\nachieved with respect to the standard methods."
},{
    "category": "math.NT", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1204.1300v1", 
    "title": "Improvements in the computation of ideal class groups of imaginary   quadratic number fields", 
    "arxiv-id": "1204.1300v1", 
    "author": "Jean-Fran\u00e7ois Biasse", 
    "publish": "2012-04-05T18:27:51Z", 
    "summary": "We investigate improvements to the algorithm for the computation of ideal\nclass groups described by Jacobson in the imaginary quadratic case. These\nimprovements rely on the large prime strategy and a new method for performing\nthe linear algebra phase. We achieve a significant speed-up and are able to\ncompute ideal class groups with discriminants of 110 decimal digits in less\nthan a week."
},{
    "category": "cs.SY", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1204.2857v1", 
    "title": "Synthesis of Minimal Error Control Software", 
    "arxiv-id": "1204.2857v1", 
    "author": "Majid Zamani", 
    "publish": "2012-04-12T23:23:56Z", 
    "summary": "Software implementations of controllers for physical systems are at the core\nof many embedded systems. The design of controllers uses the theory of\ndynamical systems to construct a mathematical control law that ensures that the\ncontrolled system has certain properties, such as asymptotic convergence to an\nequilibrium point, while optimizing some performance criteria. However, owing\nto quantization errors arising from the use of fixed-point arithmetic, the\nimplementation of this control law can only guarantee practical stability:\nunder the actions of the implementation, the trajectories of the controlled\nsystem converge to a bounded set around the equilibrium point, and the size of\nthe bounded set is proportional to the error in the implementation. The problem\nof verifying whether a controller implementation achieves practical stability\nfor a given bounded set has been studied before. In this paper, we change the\nemphasis from verification to automatic synthesis. Using synthesis, the need\nfor formal verification can be considerably reduced thereby reducing the design\ntime as well as design cost of embedded control software.\n  We give a methodology and a tool to synthesize embedded control software that\nis Pareto optimal w.r.t. both performance criteria and practical stability\nregions. Our technique is a combination of static analysis to estimate\nquantization errors for specific controller implementations and stochastic\nlocal search over the space of possible controllers using particle swarm\noptimization. The effectiveness of our technique is illustrated using examples\nof various standard control systems: in most examples, we achieve controllers\nwith close LQR-LQG performance but with implementation errors, hence regions of\npractical stability, several times as small."
},{
    "category": "cs.LO", 
    "doi": "10.1007/978-3-7091-0794-2_6", 
    "link": "http://arxiv.org/pdf/1204.3513v2", 
    "title": "Delta-Complete Decision Procedures for Satisfiability over the Reals", 
    "arxiv-id": "1204.3513v2", 
    "author": "Edmund Clarke", 
    "publish": "2012-04-16T15:09:39Z", 
    "summary": "We introduce the notion of \"\\delta-complete decision procedures\" for solving\nSMT problems over the real numbers, with the aim of handling a wide range of\nnonlinear functions including transcendental functions and solutions of\nLipschitz-continuous ODEs. Given an SMT problem \\varphi and a positive rational\nnumber \\delta, a \\delta-complete decision procedure determines either that\n\\varphi is unsatisfiable, or that the \"\\delta-weakening\" of \\varphi is\nsatisfiable. Here, the \\delta-weakening of \\varphi is a variant of \\varphi that\nallows \\delta-bounded numerical perturbations on \\varphi. We prove the\nexistence of \\delta-complete decision procedures for bounded SMT over reals\nwith functions mentioned above. For functions in Type 2 complexity class C,\nunder mild assumptions, the bounded \\delta-SMT problem is in NP^C.\n\\delta-Complete decision procedures can exploit scalable numerical methods for\nhandling nonlinearity, and we propose to use this notion as an ideal\nrequirement for numerically-driven decision procedures. As a concrete example,\nwe formally analyze the DPLL<ICP> framework, which integrates Interval\nConstraint Propagation (ICP) in DPLL(T), and establish necessary and sufficient\nconditions for its \\delta-completeness. We discuss practical applications of\n\\delta-complete decision procedures for correctness-critical applications\nincluding formal verification and theorem proving."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.tcs.2012.10.023", 
    "link": "http://arxiv.org/pdf/1207.0630v3", 
    "title": "GPGCD: An iterative method for calculating approximate GCD of univariate   polynomials", 
    "arxiv-id": "1207.0630v3", 
    "author": "Akira Terui", 
    "publish": "2012-07-03T10:37:03Z", 
    "summary": "We present an iterative algorithm for calculating approximate greatest common\ndivisor (GCD) of univariate polynomials with the real or the complex\ncoefficients. For a given pair of polynomials and a degree, our algorithm finds\na pair of polynomials which has a GCD of the given degree and whose\ncoefficients are perturbed from those in the original inputs, making the\nperturbations as small as possible, along with the GCD. The problem of\napproximate GCD is transfered to a constrained minimization problem, then\nsolved with the so-called modified Newton method, which is a generalization of\nthe gradient-projection method, by searching the solution iteratively. We\ndemonstrate that, in some test cases, our algorithm calculates approximate GCD\nwith perturbations as small as those calculated by a method based on the\nstructured total least norm (STLN) method and the UVGCD method, while our\nmethod runs significantly faster than theirs by approximately up to 30 or 10\ntimes, respectively, compared with their implementation. We also show that our\nalgorithm properly handles some ill-conditioned polynomials which have a GCD\nwith small or large leading coefficient."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.tcs.2012.10.023", 
    "link": "http://arxiv.org/pdf/1207.2243v1", 
    "title": "Metric Problems for Quadrics in Multidimensional Space", 
    "arxiv-id": "1207.2243v1", 
    "author": "Marina V. Yashina", 
    "publish": "2012-07-10T07:03:36Z", 
    "summary": "Given the equations of the first and the second order surfaces in\nmultidimensional space, our goal is to construct a univariate polynomial one of\nthe zeros of which coincides with the square of the distance between these\nsurfaces. To achieve this goal we employ Elimination Theory methods. The\nproposed approach is also extended for the case of parameter dependent\nsurfaces."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cagd.2014.02.004", 
    "link": "http://arxiv.org/pdf/1207.4047v7", 
    "title": "Detecting Symmetries of Rational Plane and Space Curves", 
    "arxiv-id": "1207.4047v7", 
    "author": "G. Muntingh", 
    "publish": "2012-07-17T16:14:18Z", 
    "summary": "This paper addresses the problem of determining the symmetries of a plane or\nspace curve defined by a rational parametrization. We provide effective methods\nto compute the involution and rotation symmetries for the planar case. As for\nspace curves, our method finds the involutions in all cases, and all the\nrotation symmetries in the particular case of Pythagorean-hodograph curves. Our\nalgorithms solve these problems without converting to implicit form. Instead,\nwe make use of a relationship between two proper parametrizations of the same\ncurve, which leads to algorithms that involve only univariate polynomials.\nThese algorithms have been implemented and tested in the Sage system."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2014.02.004", 
    "link": "http://arxiv.org/pdf/1301.5038v1", 
    "title": "Hermite Reduction and Creative Telescoping for Hyperexponential   Functions", 
    "arxiv-id": "1301.5038v1", 
    "author": "Guoce Xin", 
    "publish": "2013-01-21T23:21:44Z", 
    "summary": "We present a reduction algorithm that simultaneously extends Hermite's\nreduction for rational functions and the Hermite-like reduction for\nhyperexponential functions. It yields a unique additive decomposition and\nallows to decide hyperexponential integrability. Based on this reduction\nalgorithm, we design a new method to compute minimal telescopers for bivariate\nhyperexponential functions. One of its main features is that it can avoid the\ncostly computation of certificates. Its implementation outperforms Maple's\nfunction DEtools[Zeilberger]. Moreover, we derive an order bound on minimal\ntelescopers, which is more general and tighter than the known one."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2014.02.004", 
    "link": "http://arxiv.org/pdf/1301.5046v2", 
    "title": "On the Structure of Compatible Rational Functions", 
    "arxiv-id": "1301.5046v2", 
    "author": "Ziming Li", 
    "publish": "2013-01-22T00:37:06Z", 
    "summary": "A finite number of rational functions are compatible if they satisfy the\ncompatibility conditions of a first-order linear functional system involving\ndifferential, shift and q-shift operators. We present a theorem that describes\nthe structure of compatible rational functions. The theorem enables us to\ndecompose a solution of such a system as a product of a rational function,\nseveral symbolic powers, a hyperexponential function, a hypergeometric term,\nand a q-hypergeometric term. We outline an algorithm for computing this\nproduct, and present an application."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2014.02.004", 
    "link": "http://arxiv.org/pdf/1301.5798v1", 
    "title": "Superfast solution of Toeplitz systems based on syzygy reduction", 
    "arxiv-id": "1301.5798v1", 
    "author": "Michelle Schatzman", 
    "publish": "2013-01-24T14:45:50Z", 
    "summary": "We present a new superfast algorithm for solving Toeplitz systems. This\nalgorithm is based on a relation between the solution of such problems and\nsyzygies of polynomials or moving lines. We show an explicit connection between\nthe generators of a Toeplitz matrix and the generators of the corresponding\nmodule of syzygies. We show that this module is generated by two elements and\nthe solution of a Toeplitz system T u=g can be reinterpreted as the remainder\nof a vector depending on g, by these two generators. We obtain these generators\nand this remainder with computational complexity O(n log^2 n) for a Toeplitz\nmatrix of size nxn."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2014.02.004", 
    "link": "http://arxiv.org/pdf/1301.6021v1", 
    "title": "Fast algorithms for ell-adic towers over finite fields", 
    "arxiv-id": "1301.6021v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2013-01-25T11:54:48Z", 
    "summary": "Inspired by previous work of Shoup, Lenstra-De Smit and Couveignes-Lercier,\nwe give fast algorithms to compute in (the first levels of) the ell-adic\nclosure of a finite field. In many cases, our algorithms have quasi-linear\ncomplexity."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cagd.2014.02.004", 
    "link": "http://arxiv.org/pdf/1304.5809v1", 
    "title": "Plane mixed discriminants and toric jacobians", 
    "arxiv-id": "1304.5809v1", 
    "author": "Anna Karasoulou", 
    "publish": "2013-04-21T22:48:15Z", 
    "summary": "Polynomial algebra offers a standard approach to handle several problems in\ngeometric modeling. A key tool is the discriminant of a univariate polynomial,\nor of a well-constrained system of polynomial equations, which expresses the\nexistence of a multiple root. We concentrate on bivariate polynomials and\nestablish an original formula that relates the mixed discriminant of two\nbivariate Laurent polynomials with fixed support, with the sparse resultant of\nthese polynomials and their toric Jacobian. This allows us to obtain a new\nproof for the bidegree of the mixed discriminant as well as to establish\nmultipicativity formulas arising when one polynomial can be factored."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2014.01.001", 
    "link": "http://arxiv.org/pdf/1304.6889v5", 
    "title": "Reduced Gr\u00f6bner Bases and Macaulay-Buchberger Basis Theorem over   Noetherian Rings", 
    "arxiv-id": "1304.6889v5", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2013-04-25T12:14:49Z", 
    "summary": "In this paper, we extend the characterization of $\\mathbb{Z}[x]/\\ < f \\ >$,\nwhere $f \\in \\mathbb{Z}[x]$ to be a free $\\mathbb{Z}$-module to multivariate\npolynomial rings over any commutative Noetherian ring, $A$. The\ncharacterization allows us to extend the Gr\\\"obner basis method of computing a\n$\\Bbbk$-vector space basis of residue class polynomial rings over a field\n$\\Bbbk$ (Macaulay-Buchberger Basis Theorem) to rings, i.e.\n$A[x_1,\\ldots,x_n]/\\mathfrak{a}$, where $\\mathfrak{a} \\subseteq\nA[x_1,\\ldots,x_n]$ is an ideal. We give some insights into the characterization\nfor two special cases, when $A = \\mathbb{Z}$ and $A =\n\\Bbbk[\\theta_1,\\ldots,\\theta_m]$. As an application of this characterization,\nwe show that the concept of border bases can be extended to rings when the\ncorresponding residue class ring is a finitely generated, free $A$-module."
},{
    "category": "cs.MS", 
    "doi": "10.1007/978-3-642-39320-4_9", 
    "link": "http://arxiv.org/pdf/1304.7223v3", 
    "title": "Understanding Branch Cuts of Expressions", 
    "arxiv-id": "1304.7223v3", 
    "author": "David Wilson", 
    "publish": "2013-04-26T16:46:48Z", 
    "summary": "We assume some standard choices for the branch cuts of a group of functions\nand consider the problem of then calculating the branch cuts of expressions\ninvolving those functions. Typical examples include the addition formulae for\ninverse trigonometric functions. Understanding these cuts is essential for\nworking with the single-valued counterparts, the common approach to encoding\nmulti-valued functions in computer algebra systems. While the defining choices\nare usually simple (typically portions of either the real or imaginary axes)\nthe cuts induced by the expression may be surprisingly complicated. We have\nmade explicit and implemented techniques for calculating the cuts in the\ncomputer algebra programme Maple. We discuss the issues raised, classifying the\ndifferent cuts produced. The techniques have been gathered in the BranchCuts\npackage, along with tools for visualising the cuts. The package is included in\nMaple 17 as part of the FunctionAdvisor tool."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1305.2461v2", 
    "title": "Numerical Reparametrization of Rational Parametric Plane Curves", 
    "arxiv-id": "1305.2461v2", 
    "author": "Li-Yong Shen", 
    "publish": "2013-05-11T01:44:28Z", 
    "summary": "In this paper, we present an algorithm for reparametrizing algebraic plane\ncurves from a numerical point of view. That is, we deal with mathematical\nobjects that are assumed to be given approximately. More precisely, given a\ntolerance $\\epsilon>0$ and a rational parametrization $\\cal P$ with perturbed\nfloat coefficients of a plane curve $\\cal C$, we present an algorithm that\ncomputes a parametrization $\\cal Q$ of a new plane curve $\\cal D$ such that\n${\\cal Q}$ is an {\\it $\\epsilon$--proper reparametrization} of $\\cal D$. In\naddition, the error bound is carefully discussed and we present a formula that\nmeasures the \"closeness\" between the input curve $\\cal C$ and the output curve\n$\\cal D$."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1305.3215v1", 
    "title": "A computer algebra user interface manifesto", 
    "arxiv-id": "1305.3215v1", 
    "author": "David R. Stoutemyer", 
    "publish": "2013-05-14T17:21:29Z", 
    "summary": "Many computer algebra systems have more than 1000 built-in functions, making\nexpertise difficult. Using mock dialog boxes, this article describes a proposed\ninteractive general-purpose wizard for organizing optional transformations and\nallowing easy fine grain control over the form of the result even by amateurs.\nThis wizard integrates ideas including:\n  * flexible subexpression selection;\n  * complete control over the ordering of variables and commutative operands,\nwith well-chosen defaults;\n  * interleaving the choice of successively less main variables with applicable\nfunction choices to provide detailed control without incurring a combinatorial\nnumber of applicable alternatives at any one level;\n  * quick applicability tests to reduce the listing of inapplicable\ntransformations;\n  * using an organizing principle to order the alternatives in a helpful\nmanner;\n  * labeling quickly-computed alternatives in dialog boxes with a preview of\ntheir results,\n  * using ellipsis elisions if necessary or helpful;\n  * allowing the user to retreat from a sequence of choices to explore other\nbranches of the tree of alternatives or to return quickly to branches already\nvisited;\n  * allowing the user to accumulate more than one of the alternative forms;\n  * integrating direct manipulation into the wizard; and\n  * supporting not only the usual input-result pair mode, but also the useful\nalternative derivational and in situ replacement modes in a unified window."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1305.4131v1", 
    "title": "Zero-nonzero and real-nonreal sign determination", 
    "arxiv-id": "1305.4131v1", 
    "author": "Marie-Francoise Roy", 
    "publish": "2013-05-17T16:46:18Z", 
    "summary": "We consider first the zero-nonzero determination problem, which consists in\ndetermining the list of zero-nonzero conditions realized by a finite list of\npolynomials on a finite set Z included in C^k with C an algebraic closed field.\nWe describe an algorithm to solve the zero-nonzero determination problem and we\nperform its bit complexity analysis. This algorithm, which is in many ways an\nadaptation of the methods used to solve the more classical sign determination\nproblem, presents also new ideas which can be used to improve sign\ndetermination. Then, we consider the real-nonreal sign determination problem,\nwhich deals with both the sign determination and the zero-nonzero determination\nproblem. We describe an algorithm to solve the real-nonreal sign determination\nproblem, we perform its bit complexity analysis and we discuss this problem in\na parametric context."
},{
    "category": "math.CO", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1305.4447v1", 
    "title": "Dual bases for non commutative symmetric and quasi-symmetric functions   via monoidal factorization", 
    "arxiv-id": "1305.4447v1", 
    "author": "Christophe Tollu", 
    "publish": "2013-05-20T06:36:08Z", 
    "summary": "In this work, an effective construction, via Sch\\\"utzenberger's monoidal\nfactorization, of dual bases for the non commutative symmetric and\nquasi-symmetric functions is proposed."
},{
    "category": "math.CO", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1305.4450v1", 
    "title": "Sch\u00fctzenberger's factorization on the (completed) Hopf algebra of   $q-$stuffle product", 
    "arxiv-id": "1305.4450v1", 
    "author": "Vincel Hoang Ngoc Minh", 
    "publish": "2013-05-20T07:25:06Z", 
    "summary": "In order to extend the Sch\\\"utzenberger's factorization, the combinatorial\nHopf algebra of the $q$-stuffles product is developed systematically in a\nparallel way with that of the shuffle product and and in emphasizing the Lie\nelements as studied by Ree. In particular, we will give here an effective\nconstruction of pair of bases in duality."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1305.6298v2", 
    "title": "Effective Differential Nullstellensatz for Ordinary DAE Systems with   Constant Coefficients", 
    "arxiv-id": "1305.6298v2", 
    "author": "Pablo Solern\u00f3", 
    "publish": "2013-05-27T19:14:14Z", 
    "summary": "We give upper bounds for the differential Nullstellensatz in the case of\nordinary systems of differential algebraic equations over any field of\nconstants $K$ of characteristic $0$. Let $\\vec{x}$ be a set of $n$ differential\nvariables, $\\vec{f}$ a finite family of differential polynomials in the ring\n$K\\{\\vec{x}\\}$ and $f\\in K\\{\\vec{x}\\}$ another polynomial which vanishes at\nevery solution of the differential equation system $\\vec{f}=0$ in any\ndifferentially closed field containing $K$. Let $d:=\\max\\{\\deg(\\vec{f}),\n\\deg(f)\\}$ and $\\epsilon:=\\max\\{2,{\\rm{ord}}(\\vec{f}), {\\rm{ord}}(f)\\}$. We\nshow that $f^M$ belongs to the algebraic ideal generated by the successive\nderivatives of $\\vec{f}$ of order at most $L = (n\\epsilon\nd)^{2^{c(n\\epsilon)^3}}$, for a suitable universal constant $c>0$, and\n$M=d^{n(\\epsilon +L+1)}$. The previously known bounds for $L$ and $M$ are not\nelementary recursive."
},{
    "category": "math.AP", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1306.1113v2", 
    "title": "Intertwining Laplace Transformations of Linear Partial Differential   Equations", 
    "arxiv-id": "1306.1113v2", 
    "author": "Elena I. Ganzha", 
    "publish": "2013-05-25T10:22:37Z", 
    "summary": "We propose a generalization of Laplace transformations to the case of linear\npartial differential operators (LPDOs) of arbitrary order in R^n. Practically\nall previously proposed differential transformations of LPDOs are particular\ncases of this transformation (intertwining Laplace transformation, ILT). We\ngive a complete algorithm of construction of ILT and describe the classes of\noperators in R^n suitable for this transformation.\n  Keywords: Integration of linear partial differential equations, Laplace\ntransformation, differential transformation"
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1306.3390v2", 
    "title": "Degeneracy loci and polynomial equation solving", 
    "arxiv-id": "1306.3390v2", 
    "author": "Pablo Solern\u00f3", 
    "publish": "2013-06-14T13:23:48Z", 
    "summary": "Let V be a smooth equidimensional quasi-affine variety of dimension r over\nthe complex numbers $C$ and let $F$ be a $(p\\times s)$-matrix of coordinate\nfunctions of $C[V]$, where $s\\ge p+r$. The pair $(V,F)$ determines a vector\nbundle $E$ of rank $s-p$ over $W:=\\{x\\in V:\\mathrm{rk} F(x)=p\\}$. We associate\nwith $(V,F)$ a descending chain of degeneracy loci of E (the generic polar\nvarieties of $V$ represent a typical example of this situation).\n  The maximal degree of these degeneracy loci constitutes the essential\ningredient for the uniform, bounded error probabilistic pseudo-polynomial time\nalgorithm which we are going to design and which solves a series of\ncomputational elimination problems that can be formulated in this framework. We\ndescribe applications to polynomial equation solving over the reals and to the\ncomputation of a generic fiber of a dominant endomorphism of an affine space."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1306.3714v1", 
    "title": "An approach to first principles electronic structure calculation by   symbolic-numeric computation", 
    "arxiv-id": "1306.3714v1", 
    "author": "Akihito Kikuchi", 
    "publish": "2013-06-17T00:09:39Z", 
    "summary": "This article is an introduction to a new approach to first principles\nelectronic structure calculation. The starting point is the\nHartree-Fock-Roothaan equation, in which molecular integrals are approximated\nby polynomials by way of Taylor expansion with respect to atomic coordinates\nand other variables. It leads to a set of polynomial equations whose solutions\nare eigenstate, which is designated as algebraic molecular orbital equation.\nSymbolic computation, especially, Gr\\\"obner bases theory, enables us to rewrite\nthe polynomial equations into more trimmed and tractable forms with identical\nroots, from which we can unravel the relationship between physical parameters\n(wave function, atomic coordinates, and others) and numerically evaluate them\none by one in order. Furthermore, this method is a unified way to solve the\nelectronic structure calculation, the optimization of physical parameters, and\nthe inverse problem as a forward problem."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1306.4263v1", 
    "title": "Ore Polynomials in Sage", 
    "arxiv-id": "1306.4263v1", 
    "author": "Fredrik Johansson", 
    "publish": "2013-06-18T16:34:18Z", 
    "summary": "We present a Sage implementation of Ore algebras. The main features for the\nmost common instances include basic arithmetic and actions; gcrd and lclm;\nD-finite closure properties; natural transformations between related algebras;\nguessing; desingularization; solvers for polynomials, rational functions and\n(generalized) power series. This paper is a tutorial on how to use the package."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.cam.2014.09.012", 
    "link": "http://arxiv.org/pdf/1307.1627v1", 
    "title": "Computing Puiseux Expansions at Cusps of the Modular Curve X0(N)", 
    "arxiv-id": "1307.1627v1", 
    "author": "Mark van Hoeij", 
    "publish": "2013-07-05T14:57:13Z", 
    "summary": "The goal in this preprint is to give an efficient algorithm to compute\nPuiseux expansions at cusps of X0(N). It is based on a relation with a\nhypergeometric function that holds for any N."
},{
    "category": "cs.DS", 
    "doi": "10.1049/cp.2013.2209", 
    "link": "http://arxiv.org/pdf/1307.2735v1", 
    "title": "An Efficient Multiplication Algorithm Using Nikhilam Method", 
    "arxiv-id": "1307.2735v1", 
    "author": "Shri Prakash Dwivedi", 
    "publish": "2013-07-10T09:58:07Z", 
    "summary": "Multiplication is one of the most important operation in computer arithmetic.\nMany integer operations such as squaring, division and computing reciprocal\nrequire same order of time as multiplication whereas some other operations such\nas computing GCD and residue operation require at most a factor of $\\log n$\ntime more than multiplication. We propose an integer multiplication algorithm\nusing Nikhilam method of Vedic mathematics which can be used to multiply two\nbinary numbers efficiently."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-39320-4_4", 
    "link": "http://arxiv.org/pdf/1307.3231v1", 
    "title": "Certification of Bounds of Non-linear Functions: the Templates Method", 
    "arxiv-id": "1307.3231v1", 
    "author": "Benjamin Werner", 
    "publish": "2013-07-10T09:53:14Z", 
    "summary": "The aim of this work is to certify lower bounds for real-valued multivariate\nfunctions, defined by semialgebraic or transcendental expressions. The\ncertificate must be, eventually, formally provable in a proof system such as\nCoq. The application range for such a tool is widespread; for instance Hales'\nproof of Kepler's conjecture yields thousands of inequalities. We introduce an\napproximation algorithm, which combines ideas of the max-plus basis method (in\noptimal control) and of the linear templates method developed by Manna et al.\n(in static analysis). This algorithm consists in bounding some of the\nconstituents of the function by suprema of quadratic forms with a well chosen\ncurvature. This leads to semialgebraic optimization problems, solved by\nsum-of-squares relaxations. Templates limit the blow up of these relaxations at\nthe price of coarsening the approximation. We illustrate the efficiency of our\nframework with various examples from the literature and discuss the interfacing\nwith Coq."
},{
    "category": "quant-ph", 
    "doi": "10.1007/978-3-642-39320-4_4", 
    "link": "http://arxiv.org/pdf/1307.4906v1", 
    "title": "Functional framework for representing and transforming quantum channels", 
    "arxiv-id": "1307.4906v1", 
    "author": "Jaros\u0142aw Adam Miszczak", 
    "publish": "2013-07-18T11:16:22Z", 
    "summary": "We develop a framework which aims to simplify the analysis of quantum states\nand quantum operations by harnessing the potential of function programming\nparadigm. We show that the introduced framework allows a seamless manipulation\nof quantum channels, in particular to convert between different representations\nof quantum channels, and thus that the use of functional programming concepts\nfacilitates the manipulation of abstract objects used in the language of\nquantum theory.\n  For the purpose of our presentation we will use Mathematica computer algebra\nsystem. This choice is motivated twofold. First, it offers a rich programming\nlanguage based on the functional paradigm. Second, this programming language is\ncombined with powerful symbolic and numeric manipulation capabilities."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2015.04.001", 
    "link": "http://arxiv.org/pdf/1307.4974v5", 
    "title": "Polynomial-Time Algorithms for Quadratic Isomorphism of Polynomials: The   Regular Case", 
    "arxiv-id": "1307.4974v5", 
    "author": "Ludovic Perret", 
    "publish": "2013-07-18T15:18:02Z", 
    "summary": "Let $\\mathbf{f}=(f\\_1,\\ldots,f\\_m)$ and $\\mathbf{g}=(g\\_1,\\ldots,g\\_m)$ be\ntwo sets of $m\\geq 1$ nonlinear polynomials over $\\mathbb{K}[x\\_1,\\ldots,x\\_n]$\n($\\mathbb{K}$ being a field). We consider the computational problem of finding\n-- if any -- an invertible transformation on the variables mapping $\\mathbf{f}$\nto $\\mathbf{g}$. The corresponding equivalence problem is known as {\\tt\nIsomorphism of Polynomials with one Secret} ({\\tt IP1S}) and is a fundamental\nproblem in multivariate cryptography. The main result is a randomized\npolynomial-time algorithm for solving {\\tt IP1S} for quadratic instances, a\nparticular case of importance in cryptography and somewhat justifying {\\it a\nposteriori} the fact that {\\it Graph Isomorphism} reduces to only cubic\ninstances of {\\tt IP1S} (Agrawal and Saxena). To this end, we show that {\\tt\nIP1S} for quadratic polynomials can be reduced to a variant of the classical\nmodule isomorphism problem in representation theory, which involves to test the\northogonal simultaneous conjugacy of symmetric matrices. We show that we can\nessentially {\\it linearize} the problem by reducing quadratic-{\\tt IP1S} to\ntest the orthogonal simultaneous similarity of symmetric matrices; this latter\nproblem was shown by Chistov, Ivanyos and Karpinski to be equivalent to finding\nan invertible matrix in the linear space $\\mathbb{K}^{n \\times n}$ of $n \\times\nn$ matrices over $\\mathbb{K}$ and to compute the square root in a matrix\nalgebra. While computing square roots of matrices can be done efficiently using\nnumerical methods, it seems difficult to control the bit complexity of such\nmethods. However, we present exact and polynomial-time algorithms for computing\nthe square root in $\\mathbb{K}^{n \\times n}$ for various fields (including\nfinite fields). We then consider \\\\#{\\tt IP1S}, the counting version of {\\tt\nIP1S} for quadratic instances. In particular, we provide a (complete)\ncharacterization of the automorphism group of homogeneous quadratic\npolynomials. Finally, we also consider the more general {\\it Isomorphism of\nPolynomials} ({\\tt IP}) problem where we allow an invertible linear\ntransformation on the variables \\emph{and} on the set of polynomials. A\nrandomized polynomial-time algorithm for solving {\\tt IP} when\n\\(\\mathbf{f}=(x\\_1^d,\\ldots,x\\_n^d)\\) is presented. From an algorithmic point\nof view, the problem boils down to factoring the determinant of a linear matrix\n(\\emph{i.e.}\\ a matrix whose components are linear polynomials). This extends\nto {\\tt IP} a result of Kayal obtained for {\\tt PolyProj}."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jco.2015.04.001", 
    "link": "http://arxiv.org/pdf/1307.5330v2", 
    "title": "On Computing the Elimination Ideal Using Resultants with Applications to   Gr\u00f6bner Bases", 
    "arxiv-id": "1307.5330v2", 
    "author": "Zafeirakis Zafeirakopoulos", 
    "publish": "2013-07-19T20:08:11Z", 
    "summary": "Resultants and Gr\\\"obner bases are crucial tools in studying polynomial\nelimination theory. We investigate relations between the variety of the\nresultant of two polynomials and the variety of the ideal they generate. Then\nwe focus on the bivariate case, in which the elimination ideal is principal. We\nstudy - by means of elementary tools - the difference between the multiplicity\nof the factors of the generator of the elimination ideal and the multiplicity\nof the factors of the resultant."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.122", 
    "link": "http://arxiv.org/pdf/1307.8029v1", 
    "title": "Proceedings Fourth International Symposium on Symbolic Computation in   Software Science", 
    "arxiv-id": "1307.8029v1", 
    "author": "Fairouz Kamareddine", 
    "publish": "2013-07-30T16:01:33Z", 
    "summary": "Symbolic computation is the science of computing with symbolic objects\n(terms, formulae, programs, algebraic objects, geometrical objects, etc).\nPowerful symbolic algorithms have been developed during the past decades and\nhave played an influential role in theorem proving, automated reasoning,\nsoftware verification, model checking, rewriting, formalisation of mathematics,\nnetwork security, Groebner bases, characteristic sets, etc.\n  The international Symposium on \"Symbolic Computation in Software Science\" is\nthe fourth in the SCSS workshop series. SCSS 2008 and 2010 took place at the\nResearch Institute for Symbolic Computation (RISC), Hagenberg, Austria, and,\nSCSS 2009 took place in Gammarth, Tunisia. These symposium grew out of internal\nworkshops that bring together researchers from: a) SCORE (Symbolic Computation\nResearch Group) at the University of Tsukuba, Japan, b) Theorema Group at the\nResearch Institute for Symbolic Computation, Johannes Kepler University Linz,\nAustria, c) SSFG (Software Science Foundation Group) at Kyoto University,\nJapan, and d) Sup'Com (Higher School of Communication of Tunis) at the\nUniversity of Carthage, Tunisia."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.122", 
    "link": "http://arxiv.org/pdf/1307.8281v2", 
    "title": "Probabilistic Algorithm for Polynomial Optimization over a Real   Algebraic Set", 
    "arxiv-id": "1307.8281v2", 
    "author": "Mohab Safey El Din", 
    "publish": "2013-07-31T11:01:20Z", 
    "summary": "Let $f, f_1, \\ldots, f_\\nV$ be polynomials with rational coefficients in the\nindeterminates $\\bfX=X_1, \\ldots, X_n$ of maximum degree $D$ and $V$ be the set\nof common complex solutions of $\\F=(f_1,\\ldots, f_\\nV)$. We give an algorithm\nwhich, up to some regularity assumptions on $\\F$, computes an exact\nrepresentation of the global infimum $f^\\star=\\inf_{x\\in V\\cap\\R^n} f\\Par{x}$,\ni.e. a univariate polynomial vanishing at $f^\\star$ and an isolating interval\nfor $f^\\star$. Furthermore, this algorithm decides whether $f^\\star$ is reached\nand if so, it returns $x^\\star\\in V\\cap\\R^n$ such that\n$f\\Par{x^\\star}=f^\\star$. This algorithm is probabilistic. It makes use of the\nnotion of polar varieties. Its complexity is essentially cubic in $\\Par{\\nV\nD}^n$ and linear in the complexity of evaluating the input. This fits within\nthe best known deterministic complexity class $D^{O(n)}$. We report on some\npractical experiments of a first implementation that is available as a Maple\npackage. It appears that it can tackle global optimization problems that were\nunreachable by previous exact algorithms and can manage instances that are hard\nto solve with purely numeric techniques. As far as we know, even under the\nextra genericity assumptions on the input, it is the first probabilistic\nalgorithm that combines practical efficiency with good control of complexity\nfor this problem."
},{
    "category": "math.AP", 
    "doi": "10.1016/j.aam.2015.07.002", 
    "link": "http://arxiv.org/pdf/1310.2081v2", 
    "title": "Differential elimination by differential specialization of Sylvester   style matrices", 
    "arxiv-id": "1310.2081v2", 
    "author": "Sonia L. Rueda", 
    "publish": "2013-10-08T10:36:51Z", 
    "summary": "Differential resultant formulas are defined, for a system $\\mathcal{P}$ of\n$n$ ordinary Laurent differential polynomials in $n-1$ differential variables.\nThese are determinants of coefficient matrices of an extended system of\npolynomials obtained from $\\mathcal{P}$ through derivations and multiplications\nby Laurent monomials. To start, through derivations, a system $ps(\\mathcal{P})$\nof $L$ polynomials in $L-1$ algebraic variables is obtained, which is non\nsparse in the order of derivation. This enables the use of existing formulas\nfor the computation of algebraic resultants, of the multivariate sparse\nalgebraic polynomials in $ps(\\mathcal{P})$, to obtain polynomials in the\ndifferential elimination ideal generated by $\\mathcal{P}$. The formulas\nobtained are multiples of the sparse differential resultant defined by Li, Yuan\nand Gao, and provide order and degree bounds in terms of mixed volumes in the\ngeneric case."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.aam.2015.07.002", 
    "link": "http://arxiv.org/pdf/1310.7007v1", 
    "title": "Code Optimization in FORM", 
    "arxiv-id": "1310.7007v1", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2013-10-25T19:37:32Z", 
    "summary": "We describe the implementation of output code optimization in the open source\ncomputer algebra system FORM. This implementation is based on recently\ndiscovered techniques of Monte Carlo tree search to find efficient multivariate\nHorner schemes, in combination with other optimization algorithms, such as\ncommon subexpression elimination. For systems for which no specific knowledge\nis provided it performs significantly better than other methods we could\ncompare with. Because the method has a number of free parameters, we also show\nsome methods by which to tune them to different types of problems."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.aam.2015.07.002", 
    "link": "http://arxiv.org/pdf/1312.3009v4", 
    "title": "Large Galois groups with applications to Zariski density", 
    "arxiv-id": "1312.3009v4", 
    "author": "Igor Rivin", 
    "publish": "2013-12-11T00:35:56Z", 
    "summary": "We introduce the first provably efficient algorithm to check if a finitely\ngenerated subgroup of an almost simple semi-simple group over the rationals is\nZariski-dense. We reduce this question to one of computing Galois groups, and\nto this end we describe efficient algorithms to check if the Galois group of a\npolynomial $p$ with integer coefficients is \"generic\" (which, for arbitrary\npolynomials of degree $n$ means the full symmetric group $S_n,$ while for\nreciprocal polynomials of degree $2n$ it means the hyperoctahedral group $C_2\n\\wr S_n.$). We give efficient algorithms to verify that a polynomial has Galois\ngroup $S_n,$ and that a reciprocal polynomial has Galois group $C_2 \\wr S_n.$\nWe show how these algorithms give efficient algorithms to check if a set of\nmatrices $\\mathcal{G}$ in $\\mathop{SL}(n, \\mathbb{Z})$ or $\\mathop{Sp}(2n,\n\\mathbb{Z})$ generate a \\emph{Zariski dense} subgroup.\n  The complexity of doing this in$\\mathop{SL}(n, \\mathbb{Z})$ is of order\n$O(n^4 \\log n \\log \\|\\mathcal{G}\\|)\\log \\epsilon$ and in $\\mathop{Sp}(2n,\n\\mathbb{Z})$ the complexity is of order $O(n^8 \\log n\\log \\|\\mathcal{G}\\|)\\log\n\\epsilon$ In general semisimple groups we show that Zariski density can be\nconfirmed or denied in time of order $O(n^14 \\log \\|\\mathcal{G}\\|\\log\n\\epsilon),$ where $\\epsilon$ is the probability of a wrong \"NO\" answer, while\n$\\|\\mathcal{G}\\|$ is the measure of complexity of the input (the maximum of the\nFrobenius norms of the generating matrices). The algorithms work essentially\nwithout change over algebraic number fields, and in other semi-simple groups.\nHowever, we restrict to the case of the special linear and symplectic groups\nand rational coefficients in the interest of clarity."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.aam.2015.07.002", 
    "link": "http://arxiv.org/pdf/1312.3270v2", 
    "title": "Misfortunes of a mathematicians' trio using Computer Algebra Systems:   Can we trust?", 
    "arxiv-id": "1312.3270v2", 
    "author": "Juan L. Varona", 
    "publish": "2013-12-11T18:25:46Z", 
    "summary": "Computer algebra systems are a great help for mathematical research but\nsometimes unexpected errors in the software can also badly affect it. As an\nexample, we show how we have detected an error of Mathematica computing\ndeterminants of matrices of integer numbers: not only it computes the\ndeterminants wrongly, but also it produces different results if one evaluates\nthe same determinant twice."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.aam.2015.07.002", 
    "link": "http://arxiv.org/pdf/1312.6331v1", 
    "title": "On modular computation of Groebner bases with integer coefficients", 
    "arxiv-id": "1312.6331v1", 
    "author": "S. Yu. Orevkov", 
    "publish": "2013-12-22T02:35:07Z", 
    "summary": "Let $I_1\\subset I_2\\subset\\dots$ be an increasing sequence of ideals of the\nring $\\Bbb Z[X]$, $X=(x_1,\\dots,x_n)$ and let $I$ be their union. We propose an\nalgorithm to compute the Gr\\\"obner base of $I$ under the assumption that the\nGr\\\"obner bases of the ideal $\\Bbb Q I$ of the ring $\\Bbb Q[X]$ and the the\nideals $I\\otimes(\\Bbb Z/m\\Bbb Z)$ of the rings $(\\Bbb Z/m\\Bbb Z)[X]$ are known.\n  Such an algorithmic problem arises, for example, in the construction of\nMarkov and semi-Markov traces on cubic Hecke algebras."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11786-014-0191-z", 
    "link": "http://arxiv.org/pdf/1401.0647v2", 
    "title": "Cylindrical Algebraic Sub-Decompositions", 
    "arxiv-id": "1401.0647v2", 
    "author": "M. England", 
    "publish": "2014-01-03T13:49:31Z", 
    "summary": "Cylindrical algebraic decompositions (CADs) are a key tool in real algebraic\ngeometry, used primarily for eliminating quantifiers over the reals and\nstudying semi-algebraic sets. In this paper we introduce cylindrical algebraic\nsub-decompositions (sub-CADs), which are subsets of CADs containing all the\ninformation needed to specify a solution for a given problem.\n  We define two new types of sub-CAD: variety sub-CADs which are those cells in\na CAD lying on a designated variety; and layered sub-CADs which have only those\ncells of dimension higher than a specified value. We present algorithms to\nproduce these and describe how the two approaches may be combined with each\nother and the recent theory of truth-table invariant CAD.\n  We give a complexity analysis showing that these techniques can offer\nsubstantial theoretical savings, which is supported by experimentation using an\nimplementation in Maple."
},{
    "category": "math.NA", 
    "doi": "10.1007/s11786-014-0191-z", 
    "link": "http://arxiv.org/pdf/1401.1874v1", 
    "title": "A Fast Algorithm for the Inversion of Quasiseparable Vandermonde-like   Matrices", 
    "arxiv-id": "1401.1874v1", 
    "author": "Vadim Olshevsky", 
    "publish": "2014-01-09T01:17:17Z", 
    "summary": "The results on Vandermonde-like matrices were introduced as a generalization\nof polynomial Vandermonde matrices, and the displacement structure of these\nmatrices was used to derive an inversion formula. In this paper we first\npresent a fast Gaussian elimination algorithm for the polynomial\nVandermonde-like matrices. Later we use the said algorithm to derive fast\ninversion algorithms for quasiseparable, semiseparable and well-free\nVandermonde-like matrices having $\\mathcal{O}(n^2)$ complexity. To do so we\nidentify structures of displacement operators in terms of generators and the\nrecurrence relations(2-term and 3-term) between the columns of the basis\ntransformation matrices for quasiseparable, semiseparable and well-free\npolynomials. Finally we present an $\\mathcal{O}(n^2)$ algorithm to compute the\ninversion of quasiseparable Vandermonde-like matrices."
},{
    "category": "math.RA", 
    "doi": "10.1088/1742-6596/532/1/012019", 
    "link": "http://arxiv.org/pdf/1401.2566v3", 
    "title": "Melikyan algebra is a deformation of a Poisson algebra", 
    "arxiv-id": "1401.2566v3", 
    "author": "Pasha Zusmanovich", 
    "publish": "2014-01-11T20:29:02Z", 
    "summary": "We prove, using computer, that the restricted Melikyan algebra of dimension\n125 is a deformation of a Poisson algebra."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/532/1/012019", 
    "link": "http://arxiv.org/pdf/1401.4666v1", 
    "title": "Parallel Telescoping and Parameterized Picard--Vessiot Theory", 
    "arxiv-id": "1401.4666v1", 
    "author": "Michael F. Singer", 
    "publish": "2014-01-19T13:34:20Z", 
    "summary": "Parallel telescoping is a natural generalization of differential\ncreative-telescoping for single integrals to line integrals. It computes a\nlinear ordinary differential operator $L$, called a parallel telescoper, for\nseveral multivariate functions, such that the applications of $L$ to the\nfunctions yield antiderivatives of a single function. We present a necessary\nand sufficient condition guaranteeing the existence of parallel telescopers for\ndifferentially finite functions, and develop an algorithm to compute minimal\nones for compatible hyperexponential functions. Besides computing annihilators\nof parametric line integrals, we use the parallel telescoping for determining\nGalois groups of parameterized partial differential systems of first order."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/532/1/012019", 
    "link": "http://arxiv.org/pdf/1401.5086v1", 
    "title": "Over-constrained Weierstrass iteration and the nearest consistent system", 
    "arxiv-id": "1401.5086v1", 
    "author": "Agnes Szanto", 
    "publish": "2014-01-20T21:07:54Z", 
    "summary": "We propose a generalization of the Weierstrass iteration for over-constrained\nsystems of equations and we prove that the proposed method is the Gauss-Newton\niteration to find the nearest system which has at least $k$ common roots and\nwhich is obtained via a perturbation of prescribed structure. In the univariate\ncase we show the connection of our method to the optimization problem\nformulated by Karmarkar and Lakshman for the nearest GCD. In the multivariate\ncase we generalize the expressions of Karmarkar and Lakshman, and give\nexplicitly several iteration functions to compute the optimum.\n  The arithmetic complexity of the iterations is detailed."
},{
    "category": "cs.LO", 
    "doi": "10.1088/1742-6596/532/1/012019", 
    "link": "http://arxiv.org/pdf/1401.5910v2", 
    "title": "Applications of the Gauss-Jordan algorithm, done right", 
    "arxiv-id": "1401.5910v2", 
    "author": "Jose Divas\u00f3n", 
    "publish": "2014-01-23T09:40:01Z", 
    "summary": "Computer Algebra systems are widely spread because of some of their\nremarkable features such as their ease of use and performance. Nonetheless,\nthis focus on performance sometimes leads to unwanted consequences: algorithms\nand computations are implemented and carried out in a way which is sometimes\nnot transparent to the users, and that can lead to unexpected failures. In this\npaper we present a formalisation in a proof assistant system of a \\emph{naive}\nversion of the Gauss-Jordan algorithm, with explicit proofs of some of its\napplications, and additionally a process to obtain versions of this algorithm\nin two different functional languages (SML and Haskell) by means of code\ngeneration techniques from the verified algorithm. The obtained programs are\nthen applied to test cases, which, despite the simplicity of the original\nalgorithm, have shown remarkable features in comparison to some Computer\nAlgebra systems, such as Mathematica\\textsuperscript{\\textregistered} (where\nsome of these computations are even incorrect), or Sage (in comparison to which\nthe generated programs show a compelling performance). The aim of the paper is\nto show that, with the current technology in Theorem Proving, formalising\nLinear Algebra procedures is a challenging but rewarding task, which provides\nprograms that can be compared in some aspects to \\emph{state of the art}\nprocedures in Computer Algebra systems, and whose correctness is formally\nproved."
},{
    "category": "math.AC", 
    "doi": "10.1088/1742-6596/532/1/012019", 
    "link": "http://arxiv.org/pdf/1401.5959v1", 
    "title": "The Differential Dimension Polynomial for Characterizable Differential   Ideals", 
    "arxiv-id": "1401.5959v1", 
    "author": "Markus Lange-Hegermann", 
    "publish": "2014-01-23T12:39:17Z", 
    "summary": "We generalize the differential dimension polynomial from prime differential\nideals to characterizable differential ideals. Its computation is algorithmic,\nits degree and leading coefficient remain differential birational invariants,\nand it decides equality of characterizable differential ideals contained in\neach other."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1401.6310v3", 
    "title": "Truth Table Invariant Cylindrical Algebraic Decomposition by Regular   Chains", 
    "arxiv-id": "1401.6310v3", 
    "author": "D. Wilson", 
    "publish": "2014-01-24T10:52:25Z", 
    "summary": "A new algorithm to compute cylindrical algebraic decompositions (CADs) is\npresented, building on two recent advances. Firstly, the output is truth table\ninvariant (a TTICAD) meaning given formulae have constant truth value on each\ncell of the decomposition. Secondly, the computation uses regular chains theory\nto first build a cylindrical decomposition of complex space (CCD) incrementally\nby polynomial. Significant modification of the regular chains technology was\nused to achieve the more sophisticated invariance criteria. Experimental\nresults on an implementation in the RegularChains Library for Maple verify that\ncombining these advances gives an algorithm superior to its individual\ncomponents and competitive with the state of the art."
},{
    "category": "math.NT", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1401.6667v2", 
    "title": "Ranks of Quotients, Remainders and $p$-Adic Digits of Matrices", 
    "arxiv-id": "1401.6667v2", 
    "author": "Mark Giesbrecht", 
    "publish": "2014-01-26T16:50:00Z", 
    "summary": "For a prime $p$ and a matrix $A \\in \\mathbb{Z}^{n \\times n}$, write $A$ as $A\n= p (A \\,\\mathrm{quo}\\, p) + (A \\,\\mathrm{rem}\\, p)$ where the remainder and\nquotient operations are applied element-wise. Write the $p$-adic expansion of\n$A$ as $A = A^{[0]} + p A^{[1]} + p^2 A^{[2]} + \\cdots$ where each $A^{[i]} \\in\n\\mathbb{Z}^{n \\times n}$ has entries between $[0, p-1]$. Upper bounds are\nproven for the $\\mathbb{Z}$-ranks of $A \\,\\mathrm{rem}\\, p$, and $A\n\\,\\mathrm{quo}\\, p$. Also, upper bounds are proven for the\n$\\mathbb{Z}/p\\mathbb{Z}$-rank of $A^{[i]}$ for all $i \\ge 0$ when $p = 2$, and\na conjecture is presented for odd primes."
},{
    "category": "cs.MS", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1403.1140v1", 
    "title": "Matrix Methods for Solving Algebraic Systems", 
    "arxiv-id": "1403.1140v1", 
    "author": "Ioannis Z. Emiris", 
    "publish": "2014-03-05T14:14:12Z", 
    "summary": "We present our public-domain software for the following tasks in sparse (or\ntoric) elimination theory, given a well-constrained polynomial system. First, C\ncode for computing the mixed volume of the system. Second, Maple code for\ndefining an overconstrained system and constructing a Sylvester-type matrix of\nits sparse resultant. Third, C code for a Sylvester-type matrix of the sparse\nresultant and a superset of all common roots of the initial well-constrained\nsystem by computing the eigen-decomposition of a square matrix obtained from\nthe resultant matrix. We conclude with experiments in computing molecular\nconformations."
},{
    "category": "cs.DS", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1403.1279v1", 
    "title": "Design, Implementation and Evaluation of MTBDD based Fuzzy Sets and   Binary Fuzzy Relations", 
    "arxiv-id": "1403.1279v1", 
    "author": "Bahram Sadeghi Bigham", 
    "publish": "2014-03-05T21:48:58Z", 
    "summary": "For fast and efficient analysis of large sets of fuzzy data, elimination of\nredundancies in the memory representation is needed. We used MTBDDs as the\nunderlying data-structure to represent fuzzy sets and binary fuzzy relations.\nThis leads to elimination of redundancies in the representation, less\ncomputations, and faster analyses. We have also extended a BDD package (BuDDy)\nto support MTBDDs in general and fuzzy sets and relations in particular.\nDifferent fuzzy operations such as max, min and max-min composition were\nimplemented based on our representation. Effectiveness of our representation is\nshown by applying it on fuzzy connectedness and image segmentation problem.\nCompared to a base implementation, the running time of our MTBDD based\nimplementation was faster (in our test cases) by a factor ranging from 2 to 27.\nAlso, when the MTBDD based data-structure was employed, the memory needed to\nrepresent the final results was improved by a factor ranging from 37.9 to\n265.5."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1403.5464v2", 
    "title": "Matrix-F5 algorithms over finite-precision complete discrete valuation   fields", 
    "arxiv-id": "1403.5464v2", 
    "author": "Tristan Vaccon", 
    "publish": "2014-03-20T12:37:01Z", 
    "summary": "Let $(f\\_1,\\dots, f\\_s) \\in \\mathbb{Q}\\_p [X\\_1,\\dots, X\\_n]^s$ be a sequence\nof homogeneous polynomials with $p$-adic coefficients. Such system may happen,\nfor example, in arithmetic geometry. Yet, since $\\mathbb{Q}\\_p$ is not an\neffective field, classical algorithm does not apply.We provide a definition for\nan approximate Gr{\\\"o}bner basis with respect to a monomial order $w.$ We\ndesign a strategy to compute such a basis, when precision is enough and under\nthe assumption that the input sequence is regular and the ideals $\\langle\nf\\_1,\\dots,f\\_i \\rangle$ are weakly-$w$-ideals. The conjecture of Moreno-Socias\nstates that for the grevlex ordering, such sequences are generic.Two variants\nof that strategy are available, depending on whether one lean more on precision\nor time-complexity. For the analysis of these algorithms, we study the loss of\nprecision of the Gauss row-echelon algorithm, and apply it to an adapted\nMatrix-F5 algorithm. Numerical examples are provided.Moreover, the fact that\nunder such hypotheses, Gr{\\\"o}bner bases can be computed stably has many\napplications. Firstly, the mapping sending $(f\\_1,\\dots,f\\_s)$ to the reduced\nGr{\\\"o}bner basis of the ideal they span is differentiable, and its\ndifferential can be given explicitly. Secondly, these hypotheses allows to\nperform lifting on the Grobner bases, from $\\mathbb{Z}/p^k \\mathbb{Z}$ to\n$\\mathbb{Z}/p^{k+k'} \\mathbb{Z}$ or $\\mathbb{Z}.$ Finally, asking for the same\nhypotheses on the highest-degree homogeneous components of the entry\npolynomials allows to extend our strategy to the affine case."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1405.0472v5", 
    "title": "Border Bases for Polynomial Rings over Noetherian Rings", 
    "arxiv-id": "1405.0472v5", 
    "author": "Maria Francis", 
    "publish": "2014-05-02T18:49:07Z", 
    "summary": "The theory of border bases for zero-dimensional ideals has attracted several\nresearchers in symbolic computation due to their numerical stability and\nmathematical elegance. As shown in (Francis & Dukkipati, J. Symb. Comp., 2014),\none can extend the concept of border bases over Noetherian rings whenever the\ncorresponding residue class ring is finitely generated and free. In this paper\nwe address the following problem: Can the concept of border basis over\nNoetherian rings exists for ideals when the corresponding residue class rings\nare finitely generated but need not necessarily be free modules? We present a\nborder division algorithm and prove the termination of the algorithm for a\nspecial class of border bases. We show the existence of such border bases over\nNoetherian rings and present some characterizations in this regard. We also\nshow that certain reduced Gr\\\"{o}bner bases over Noetherian rings are contained\nin this class of border bases."
},{
    "category": "cs.CG", 
    "doi": "10.1007/978-3-319-10515-4_4", 
    "link": "http://arxiv.org/pdf/1405.4740v1", 
    "title": "Improved algorithm for computing separating linear forms for bivariate   systems", 
    "arxiv-id": "1405.4740v1", 
    "author": "Fabrice Rouillier", 
    "publish": "2014-05-19T14:31:22Z", 
    "summary": "We address the problem of computing a linear separating form of a system of\ntwo bivariate polynomials with integer coefficients, that is a linear\ncombination of the variables that takes different values when evaluated at the\ndistinct solutions of the system. The computation of such linear forms is at\nthe core of most algorithms that solve algebraic systems by computing rational\nparameterizations of the solutions and this is the bottleneck of these\nalgorithms in terms of worst-case bit complexity. We present for this problem a\nnew algorithm of worst-case bit complexity $\\sOB(d^7+d^6\\tau)$ where $d$ and\n$\\tau$ denote respectively the maximum degree and bitsize of the input (and\nwhere $\\sO$ refers to the complexity where polylogarithmic factors are omitted\nand $O_B$ refers to the bit complexity). This algorithm simplifies and\ndecreases by a factor $d$ the worst-case bit complexity presented for this\nproblem by Bouzidi et al. \\cite{bouzidiJSC2014a}. This algorithm also yields,\nfor this problem, a probabilistic Las-Vegas algorithm of expected bit\ncomplexity $\\sOB(d^5+d^4\\tau)$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1405.6885v2", 
    "title": "On the design of an expert help system for computer algebra systems", 
    "arxiv-id": "1405.6885v2", 
    "author": "Waldir L. Roque", 
    "publish": "2014-05-27T12:33:27Z", 
    "summary": "It is our intention here only to discuss the nature, complexity and tools\nconcerning the design of Smart Help, an expert help facility for aiding users\nof Computer Algebra Systems. Although the expert help system presented here has\nbeen particularly oriented to REDUCE (as a consequence of our former experience\nwith this system), we point out that the concept of Smart Help can be extended\nto other Computer Algebra Systems. Technically, Smart Help is a Production\nSystem on the top of a particular implementation of MANTRA, a hybrid knowledge\nrepresentation system, which has REDUCE integrated as an additional knowledge\nrepresentation module. Since the heuristic level of MANTRA has not yet been\nimplemented, being presently represented by the Lisp language itself, Smart\nHelp is coded in Lisp and resides in the same Lisp session of MANTRA. A\nprototype of Smart Help is now running on a SUN work-station on an experimental\nbasis."
},{
    "category": "math.AG", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1405.7115v1", 
    "title": "Geometric involutive bases for positive dimensional polynomial ideals   and SDP methods", 
    "arxiv-id": "1405.7115v1", 
    "author": "Wenyuan Wu", 
    "publish": "2014-05-28T04:31:43Z", 
    "summary": "Geometric involutive bases for polynomial systems of equations have their\norigin in the prolongation and projection methods of the geometers Cartan and\nKuranishi for systems of PDE. They are useful for numerical ideal membership\ntesting and the solution of polynomial systems. In this paper we further\ndevelop our symbolic-numeric methods for such bases. We give methods to\nexplicitly extract and decrease the degree of intermediate systems and the\noutput basis. Algorithms for the numerical computation of involutivity criteria\nfor positive dimensional ideals are also discussed.\n  We were also motivated by some remarkable recent work by Lasserre and\ncollaborators who employed our prolongation projection involutive criteria as a\npart of their semi-definite based programming (SDP) method for identifying the\nreal radical of zero dimensional polynomial ideals. Consequently in this paper\nwe begin an exploration of the interaction between geometric involutive bases\nand these methods particularly in the positive dimensional case. Motivated by\nthe extension of these methods to the positive dimensional case we explore the\ninterplay between geometric involutive bases and the new SDP methods."
},{
    "category": "math.AC", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1407.2799v1", 
    "title": "Resultant of an equivariant polynomial system with respect to the   symmetric group", 
    "arxiv-id": "1407.2799v1", 
    "author": "Anna Karasoulou", 
    "publish": "2014-07-10T14:23:28Z", 
    "summary": "Given a system of n homogeneous polynomials in n variables which is\nequivariant with respect to the canonical actions of the symmetric group of n\nsymbols on the variables and on the polynomials, it is proved that its\nresultant can be decomposed into a product of several smaller resultants that\nare given in terms of some divided differences. As an application, we obtain a\ndecomposition formula for the discriminant of a multivariate homogeneous\nsymmetric polynomial."
},{
    "category": "cs.SC", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1407.2802v1", 
    "title": "Rigorous uniform approximation of D-finite functions using Chebyshev   expansions", 
    "arxiv-id": "1407.2802v1", 
    "author": "Marc Mezzarobba", 
    "publish": "2014-07-10T14:27:23Z", 
    "summary": "A wide range of numerical methods exists for computing polynomial\napproximations of solutions of ordinary differential equations based on\nChebyshev series expansions or Chebyshev interpolation polynomials. We consider\nthe application of such methods in the context of rigorous computing (where we\nneed guarantees on the accuracy of the result), and from the complexity point\nof view. It is well-known that the order-n truncation of the Chebyshev\nexpansion of a function over a given interval is a near-best uniform polynomial\napproximation of the function on that interval. In the case of solutions of\nlinear differential equations with polynomial coefficients, the coefficients of\nthe expansions obey linear recurrence relations with polynomial coefficients.\nUnfortunately, these recurrences do not lend themselves to a direct recursive\ncomputation of the coefficients, owing among other things to a lack of initial\nconditions. We show how they can nevertheless be used, as part of a validated\nprocess, to compute good uniform approximations of D-finite functions together\nwith rigorous error bounds, and we study the complexity of the resulting\nalgorithms. Our approach is based on a new view of a classical numerical method\ngoing back to Clenshaw, combined with a functional enclosure method."
},{
    "category": "math.AC", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1407.2970v1", 
    "title": "Survey on counting special types of polynomials", 
    "arxiv-id": "1407.2970v1", 
    "author": "Konstantin Ziegler", 
    "publish": "2014-07-10T21:25:48Z", 
    "summary": "Most integers are composite and most univariate polynomials over a finite\nfield are reducible. The Prime Number Theorem and a classical result of\nGau{\\ss} count the remaining ones, approximately and exactly.\n  For polynomials in two or more variables, the situation changes dramatically.\nMost multivariate polynomials are irreducible. This survey presents counting\nresults for some special classes of multivariate polynomials over a finite\nfield, namely the the reducible ones, the s-powerful ones (divisible by the\ns-th power of a nonconstant polynomial), the relatively irreducible ones\n(irreducible but reducible over an extension field), the decomposable ones, and\nalso for reducible space curves. These come as exact formulas and as\napproximations with relative errors that essentially decrease exponentially in\nthe input size.\n  Furthermore, a univariate polynomial f is decomposable if f = g o h for some\nnonlinear polynomials g and h. It is intuitively clear that the decomposable\npolynomials form a small minority among all polynomials. The tame case, where\nthe characteristic p of Fq does not divide n = deg f, is fairly\nwell-understood, and we obtain closely matching upper and lower bounds on the\nnumber of decomposable polynomials. In the wild case, where p does divide n,\nthe bounds are less satisfactory, in particular when p is the smallest prime\ndivisor of n and divides n exactly twice. The crux of the matter is to count\nthe number of collisions, where essentially different (g, h) yield the same f.\nWe present a classification of all collisions at degree n = p^2 which yields an\nexact count of those decomposable polynomials."
},{
    "category": "hep-th", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1407.4721v1", 
    "title": "Nested (inverse) binomial sums and new iterated integrals for massive   Feynman diagrams", 
    "arxiv-id": "1407.4721v1", 
    "author": "Carsten Schneider", 
    "publish": "2014-07-17T16:11:42Z", 
    "summary": "Nested sums containing binomial coefficients occur in the computation of\nmassive operator matrix elements. Their associated iterated integrals lead to\nalphabets including radicals, for which we determined a suitable basis. We\ndiscuss algorithms for converting between sum and integral representations,\nmainly relying on the Mellin transform. To aid the conversion we worked out\ndedicated rewrite rules, based on which also some general patterns emerging in\nthe process can be obtained."
},{
    "category": "cs.SC", 
    "doi": "10.1145/101108.101110", 
    "link": "http://arxiv.org/pdf/1407.6180v1", 
    "title": "The package HarmonicSums: Computer Algebra and Analytic aspects of   Nested Sums", 
    "arxiv-id": "1407.6180v1", 
    "author": "Jakob Ablinger", 
    "publish": "2014-07-23T11:33:32Z", 
    "summary": "This paper summarizes the essential functionality of the computer algebra\npackage HarmonicSums. On the one hand HarmonicSums can work with nested sums\nsuch as harmonic sums and their generalizations and on the other hand it can\ntreat iterated integrals of the Poincare and Chen-type, such as harmonic\npolylogarithms and their generalizations. The interplay of these\nrepresentations and the analytic aspects are illustrated by concrete examples."
},{
    "category": "cs.DS", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1407.6794v1", 
    "title": "GCD Computation of n Integers", 
    "arxiv-id": "1407.6794v1", 
    "author": "Shri Prakash Dwivedi", 
    "publish": "2014-07-25T06:55:58Z", 
    "summary": "Greatest Common Divisor (GCD) computation is one of the most important\noperation of algorithmic number theory. In this paper we present the algorithms\nfor GCD computation of $n$ integers. We extend the Euclid's algorithm and\nbinary GCD algorithm to compute the GCD of more than two integers."
},{
    "category": "cs.MS", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1410.0564v1", 
    "title": "Automatic Generation of Loop-Invariants for Matrix Operations", 
    "arxiv-id": "1410.0564v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2014-10-02T14:27:17Z", 
    "summary": "In recent years it has been shown that for many linear algebra operations it\nis possible to create families of algorithms following a very systematic\nprocedure. We do not refer to the fine tuning of a known algorithm, but to a\nmethodology for the actual generation of both algorithms and routines to solve\na given target matrix equation. Although systematic, the methodology relies on\ncomplex algebraic manipulations and non-obvious pattern matching, making the\nprocedure challenging to be performed by hand, our goal is the development of a\nfully automated system that from the sole description of a target equation\ncreates multiple algorithms and routines. We present CL1ck, a symbolic system\nwritten in Mathematica, that starts with an equation, decomposes it into\nmultiple equations, and returns a set of loop-invariants for the algorithms --\nyet to be generated -- that will solve the equation. In a successive step each\nloop-invariant is then mapped to its corresponding algorithm and routine. For a\nlarge class of equations, the methodology generates known algorithms as well as\nmany previously unknown ones. Most interestingly, the methodology unifies\nalgorithms traditionally developed in isolation. As an example, the five well\nknown algorithms for the LU factorization are for the first time unified under\na common root."
},{
    "category": "cs.MS", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1410.0567v1", 
    "title": "Knowledge-Based Automatic Generation of Partitioned Matrix Expressions", 
    "arxiv-id": "1410.0567v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2014-10-02T14:33:43Z", 
    "summary": "In a series of papers it has been shown that for many linear algebra\noperations it is possible to generate families of algorithms by following a\nsystematic procedure. Although powerful, such a methodology involves complex\nalgebraic manipulation, symbolic computations and pattern matching, making the\ngeneration a process challenging to be performed by hand. We aim for a fully\nautomated system that from the sole description of a target operation creates\nmultiple algorithms without any human intervention. Our approach consists of\nthree main stages. The first stage yields the core object for the entire\nprocess, the Partitioned Matrix Expression (PME), which establishes how the\ntarget problem may be decomposed in terms of simpler sub-problems. In the\nsecond stage the PME is inspected to identify predicates, the Loop-Invariants,\nto be used to set up the skeleton of a family of proofs of correctness. In the\nthird and last stage the actual algorithms are constructed so that each of them\nsatisfies its corresponding proof of correctness. In this paper we focus on the\nfirst stage of the process, the automatic generation of Partitioned Matrix\nExpressions. In particular, we discuss the steps leading to a PME and the\nknowledge necessary for a symbolic system to perform such steps. We also\nintroduce Cl1ck, a prototype system written in Mathematica that generates PMEs\nautomatically."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1410.2011v3", 
    "title": "On Ideal Lattices, Gr\u00f6bner Bases and Generalized Hash Functions", 
    "arxiv-id": "1410.2011v3", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2014-10-08T08:04:56Z", 
    "summary": "In this paper, we draw connections between ideal lattices and multivariate\npolynomial rings over integers using Gr\\\"obner bases. Ideal lattices are ideals\nin the residue class ring, $\\mathbb{Z}[x]/\\langle f \\rangle$ (here $f$ is a\nmonic polynomial), and cryptographic primitives have been built based on these\nobjects. As ideal lattices in the univariate case are generalizations of cyclic\nlattices, we introduce the notion of multivariate cyclic lattices and show that\nmultivariate ideal lattices are indeed a generalization of them. Based on\nmultivariate ideal lattices, we establish the existence of collision resistant\nhash functions using Gr\\\"obner basis techniques. For the construction of hash\nfunctions, we define a worst case problem, shortest substitution problem w.r.t.\nan ideal in $\\mathbb{Z}[x_1,\\ldots, x_n]$, and establish hardness results using\nfunctional fields."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1410.3628v1", 
    "title": "Recognizing implicitly given rational canal surfaces", 
    "arxiv-id": "1410.3628v1", 
    "author": "Miroslav L\u00e1vi\u010dka", 
    "publish": "2014-10-14T09:46:44Z", 
    "summary": "It is still a challenging task of today to recognize the type of a given\nalgebraic surface which is described only by its implicit representation.\nIn~this paper we will investigate in more detail the case of canal surfaces\nthat are often used in geometric modelling, Computer-Aided Design and technical\npractice (e.g. as blending surfaces smoothly joining two parts with circular\nends). It is known that if the squared medial axis transform is a rational\ncurve then so is also the corresponding surface. However, starting from a\npolynomial it is not known how to decide if the corresponding algebraic surface\nis rational canal surface or not. Our goal is to formulate a simple and\nefficient algorithm whose input is a~polynomial with the coefficients from some\nsubfield of real numbers and the output is the answer whether the surface is a\nrational canal surface. In the affirmative case we also compute a rational\nparameterization of the squared medial axis transform which can be then used\nfor finding a rational parameterization of the implicitly given canal surface."
},{
    "category": "math.AG", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1410.4113v2", 
    "title": "A Direct Algorithm to Compute the Topological Euler Characteristic and   Chern-Schwartz-MacPherson Class of Projective Complete Intersection Varieties", 
    "arxiv-id": "1410.4113v2", 
    "author": "Martin Helmer", 
    "publish": "2014-10-15T16:15:52Z", 
    "summary": "Let $V$ be a possibly singular scheme-theoretic complete intersection\nsubscheme of $\\mathbb{P}^n$ over an algebraically closed field of\ncharacteristic zero. Using a recent result of Fullwood (\"On Milnor classes via\ninvariants of singular subschemes\", Journal of Singularities) we develop an\nalgorithm to compute the Chern-Schwartz-MacPherson class and Euler\ncharacteristic of $V$. This algorithm complements existing algorithms by\nproviding performance improvements in the computation of the\nChern-Schwartz-MacPherson class and Euler characteristic for certain types of\ncomplete intersection subschemes of $\\mathbb{P}^n$."
},{
    "category": "math.AG", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1410.5458v1", 
    "title": "Missing sets in rational parametrizations of surfaces of revolution", 
    "arxiv-id": "1410.5458v1", 
    "author": "Carlos Villarino", 
    "publish": "2014-10-20T20:42:59Z", 
    "summary": "Parametric representations do not cover, in general, the whole geometric\nobject that they parametrize. This can be a problem in practical applications.\nIn this paper we analyze the question for surfaces of revolution generated by\nreal rational profile curves, and we describe a simple small superset of the\nreal zone of the surface not covered by the parametrization. This superset\nconsists, in the worst case, of the union of a circle and the mirror curve of\nthe profile curve."
},{
    "category": "math.AG", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1411.2846v1", 
    "title": "Sparse implicitization by interpolation: Geometric computations using   matrix representations", 
    "arxiv-id": "1411.2846v1", 
    "author": "Christos Konaxis", 
    "publish": "2014-11-11T15:13:03Z", 
    "summary": "Based on the computation of a superset of the implicit support,\nimplicitization of a parametrically given hyper-surface is reduced to computing\nthe nullspace of a numeric matrix. Our approach exploits the sparseness of the\ngiven parametric equations and of the implicit polynomial. In this work, we\nstudy how this interpolation matrix can be used to reduce some key geometric\npredicates on the hyper-surface to simple numerical operations on the matrix,\nnamely membership and sidedness for given query points. We illustrate our\nresults with examples based on our Maple implementation."
},{
    "category": "math.NT", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1411.6346v3", 
    "title": "Sparse Univariate Polynomials with Many Roots Over Finite Fields", 
    "arxiv-id": "1411.6346v3", 
    "author": "Daqing Wan", 
    "publish": "2014-11-24T04:20:25Z", 
    "summary": "Suppose $q$ is a prime power and $f\\in\\mathbb{F}_q[x]$ is a univariate\npolynomial with exactly $t$ monomial terms and degree $<q-1$. To establish a\nfinite field analogue of Descartes' Rule, Bi, Cheng, and Rojas (2013) proved an\nupper bound of $2(q-1)^{\\frac{t-2}{t-1}}$ on the number of cosets in\n$\\mathbb{F}^*_q$ needed to cover the roots of $f$ in $\\mathbb{F}^*_q$. Here, we\ngive explicit $f$ with root structure approaching this bound: For $q$ a\n$(t-1)$-st power of a prime we give an explicit $t$-nomial vanishing on\n$q^{\\frac{t-2}{t-1}}$ distinct cosets of $\\mathbb{F}^*_q$. Over prime fields\n$\\mathbb{F}_p$, computational data we provide suggests that it is harder to\nconstruct explicit sparse polynomials with many roots. Nevertheless, assuming\nthe Generalized Riemann Hypothesis, we find explicit trinomials having\n$\\Omega\\left(\\frac{\\log p}{\\log \\log p}\\right)$ distinct roots in\n$\\mathbb{F}_p$."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1412.4088v2", 
    "title": "Faster Sparse Multivariate Polynomial Interpolation of Straight-Line   Programs", 
    "arxiv-id": "1412.4088v2", 
    "author": "Daniel S. Roche", 
    "publish": "2014-12-12T19:12:15Z", 
    "summary": "Given a straight-line program whose output is a polynomial function of the\ninputs, we present a new algorithm to compute a concise representation of that\nunknown function. Our algorithm can handle any case where the unknown function\nis a multivariate polynomial, with coefficients in an arbitrary finite field,\nand with a reasonable number of nonzero terms but possibly very large degree.\nIt is competitive with previously known sparse interpolation algorithms that\nwork over an arbitrary finite field, and provides an improvement when there are\na large number of variables."
},{
    "category": "math.NA", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1412.4155v2", 
    "title": "On the Inverting of A General Heptadiagonal Matrix", 
    "arxiv-id": "1412.4155v2", 
    "author": "A. A. Karawia", 
    "publish": "2014-12-12T22:41:35Z", 
    "summary": "In this paper, we developed new numeric and symbolic algorithms to find the\ninverse of any nonsingular heptadiagonal matrix. Symbolic algorithm will not\nbreak and it is without setting any restrictive conditions. The computational\ncost of our algorithms is $O(n)$. The algorithms are suitable for\nimplementation using computer algebra system such as MAPLE, MATLAB and\nMATHEMATICA. Examples are given to illustrate the efficiency of the algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1412.5873v1", 
    "title": "Real root finding for determinants of linear matrices", 
    "arxiv-id": "1412.5873v1", 
    "author": "Mohab Safey El Din", 
    "publish": "2014-12-18T14:28:36Z", 
    "summary": "Let $\\A_0, \\A_1, \\ldots, \\A_n$ be given square matrices of size $m$ with\nrational coefficients. The paper focuses on the exact computation of one point\nin each connected component of the real determinantal variety $\\{\\X \\in\\RR^n \\:\n:\\: \\det(\\A_0+x_1\\A_1+\\cdots+x_n\\A_n)=0\\}$. Such a problem finds applications\nin many areas such as control theory, computational geometry, optimization,\netc. Using standard complexity results this problem can be solved using\n$m^{O(n)}$ arithmetic operations. Under some genericity assumptions on the\ncoefficients of the matrices, we provide an algorithm solving this problem\nwhose runtime is essentially quadratic in ${{n+m}\\choose{n}}^{3}$. We also\nreport on experiments with a computer implementation of this algorithm. Its\npractical performance illustrates the complexity estimates. In particular, we\nemphasize that for subfamilies of this problem where $m$ is fixed, the\ncomplexity is polynomial in $n$."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1502.03967v1", 
    "title": "Extractions: Computable and Visible Analogues of Localizations for   Polynomial Ideals", 
    "arxiv-id": "1502.03967v1", 
    "author": "Ye Liang", 
    "publish": "2015-02-13T12:52:45Z", 
    "summary": "When studying local properties of a polynomial ideal, one usually needs a\ntheoretic technique called localization. For most cases, in spite of its\nimportance, the computation in a localized ring cannot be algorithmically\npreformed. On the other hand, the standard basis method is very effective for\nthe computation in a special kind of localized rings, but for a general\nsemigroup order the geometry of the localization of a positive-dimensional\nideal is difficult to interpret.\n  In this paper, we introduce a new ideal operation called extraction. For an\nideal $I$ in a polynomial ring $K[x_1,\\ldots,x_n]$ over a field $K$, we use\nanother ideal $J$ to control the primary components of $I$ and the result\n$\\beta(I,J)$ is called the extraction of $I$ by $J$. It is still a polynomial\nideal and has a concrete geometric meaning in $\\bar{K}^n$, i.e., we keep the\nbranches of $\\textbf{V}(I) \\subset \\bar{K}^n$ that intersect with\n$\\textbf{V}(J) \\subset \\bar{K}^n$ and delete others, where $\\bar{K}$ is the\nalgebraic closure of $K$. This is what we mean by visible. On the other hand,\nwe can use the standard basis method to compute a localized ideal corresponding\nto $\\beta(I,J)$ without a complete primary decomposition, and can do further\ncomputation in the localized ring such as determining the membership problem of\n$\\beta(I,J)$. Moreover, we prove that extractions are as powerful as\nlocalizations in the sense that for any multiplicatively closed subset $S$ of\n$K[x_1,\\ldots,x_n]$ and any polynomial ideal $I$, there always exists a\npolynomial ideal $J$ such that $\\beta(I,J)=(S^{-1}I)^c$."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1502.05767v2", 
    "title": "Automatic differentiation in machine learning: a survey", 
    "arxiv-id": "1502.05767v2", 
    "author": "Jeffrey Mark Siskind", 
    "publish": "2015-02-20T04:20:47Z", 
    "summary": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in\nmachine learning. Automatic differentiation (AD) is a technique for calculating\nderivatives of numeric functions expressed as computer programs efficiently and\naccurately, used in fields such as computational fluid dynamics, nuclear\nengineering, and atmospheric sciences. Despite its advantages and use in other\nfields, machine learning practitioners have been little influenced by AD and\nmake scant use of available tools. We survey the intersection of AD and machine\nlearning, cover applications where AD has the potential to make a big impact,\nand report on some recent developments in the adoption of this technique. We\naim to dispel some misconceptions that we contend have impeded the use of AD\nwithin the machine learning community."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1502.07600v1", 
    "title": "Factorization of Motion Polynomials", 
    "arxiv-id": "1502.07600v1", 
    "author": "Hans-Peter Schr\u00f6cker", 
    "publish": "2015-02-26T15:42:46Z", 
    "summary": "In this paper, we consider the existence of a factorization of a monic,\nbounded motion polynomial. We prove existence of factorizations, possibly after\nmultiplication with a real polynomial and provide algorithms for computing\npolynomial factor and factorizations. The first algorithm is conceptually\nsimpler but may require a high degree of the polynomial factor. The second\nalgorithm gives an optimal degree."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1502.08010v1", 
    "title": "Tropical differential equations", 
    "arxiv-id": "1502.08010v1", 
    "author": "Dima Grigoriev", 
    "publish": "2015-02-27T19:28:44Z", 
    "summary": "Tropical differential equations are introduced and an algorithm is designed\nwhich tests solvability of a system of tropical linear differential equations\nwithin the complexity polynomial in the size of the system and in its\ncoefficients. Moreover, we show that there exists a minimal solution, and the\nalgorithm constructs it (in case of solvability). This extends a similar\ncomplexity bound established for tropical linear systems. In case of tropical\nlinear differential systems in one variable a polynomial complexity algorithm\nfor testing its solvability is designed.\n  We prove also that the problem of solvability of a system of tropical\nnon-linear differential equations in one variable is $NP$-hard, and this\nproblem for arbitrary number of variables belongs to $NP$. Similar to tropical\nalgebraic equations, a tropical differential equation expresses the (necessary)\ncondition on the dominant term in the issue of solvability of a differential\nequation in power series."
},{
    "category": "cs.SC", 
    "doi": "10.1109/RAECS.2014.6799612", 
    "link": "http://arxiv.org/pdf/1503.06126v1", 
    "title": "Polynomial complexity recognizing a tropical linear variety", 
    "arxiv-id": "1503.06126v1", 
    "author": "Dima Grigoriev", 
    "publish": "2015-03-20T15:58:25Z", 
    "summary": "A polynomial complexity algorithm is designed which tests whether a point\nbelongs to a given tropical linear variety."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-21362-0_3", 
    "link": "http://arxiv.org/pdf/1504.06484v1", 
    "title": "Recent Advances in Real Geometric Reasoning", 
    "arxiv-id": "1504.06484v1", 
    "author": "Matthew England", 
    "publish": "2015-04-24T12:23:32Z", 
    "summary": "In the 1930s Tarski showed that real quantifier elimination was possible, and\nin 1975 Collins gave a remotely practicable method, albeit with\ndoubly-exponential complexity, which was later shown to be inherent. We discuss\nsome of the recent major advances in Collins method: such as an alternative\napproach based on passing via the complexes, and advances which come closer to\n\"solving the question asked\" rather than \"solving all problems to do with these\npolynomials\"."
},{
    "category": "math.AC", 
    "doi": "10.1007/978-3-319-21362-0_3", 
    "link": "http://arxiv.org/pdf/1505.02532v2", 
    "title": "On the last fall degree of zero-dimensional Weil descent systems", 
    "arxiv-id": "1505.02532v2", 
    "author": "Sze Ling Yeo", 
    "publish": "2015-05-11T09:20:25Z", 
    "summary": "In this article we will discuss a new, mostly theoretical, method for solving\n(zero-dimensional) polynomial systems, which lies in between Gr\\\"obner basis\ncomputations and the heuristic first fall degree assumption and is not based on\nany heuristic. This method relies on the new concept of last fall degree.\n  Let $k$ be a finite field of cardinality $q^n$ and let $k'$ be its subfield\nof cardinality $q$. Let $\\mathcal{F} \\subset k[X_0,\\ldots,X_{m-1}]$ be a finite\nsubset generating a zero-dimensional ideal. We give an upper bound of the last\nfall degree of the Weil descent system of $\\mathcal{F}$, which depends on $q$,\n$m$, the last fall degree of $\\mathcal{F}$, the degree of $\\mathcal{F}$ and the\nnumber of solutions of $\\mathcal{F}$, but not on $n$. This shows that such Weil\ndescent systems can be solved efficiently if $n$ grows. In particular, we apply\nthese results for multi-HFE and essentially show that multi-HFE is insecure.\n  Finally, we discuss that the degree of regularity (or last fall degree) of\nWeil descent systems coming from summation polynomials to solve the elliptic\ncurve discrete logarithm problem might depend on $n$, since such systems\nwithout field equations are not zero-dimensional."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-21362-0_3", 
    "link": "http://arxiv.org/pdf/1505.02947v1", 
    "title": "Pfaffian Systems of A-Hypergeometric Systems II --- Holonomic Gradient   Method", 
    "arxiv-id": "1505.02947v1", 
    "author": "Nobuki Takayama", 
    "publish": "2015-05-12T10:26:10Z", 
    "summary": "We give two efficient methods to derive Pfaffian systems for A-hypergeometric\nsystems for the application to the holonomic gradient method for statistics. We\nutilize the Hilbert driven Buchberger algorithm and Macaulay type matrices in\nthe two methods."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-21362-0_3", 
    "link": "http://arxiv.org/pdf/1505.03445v1", 
    "title": "Symbolic-numeric methods for improving structural analysis of   differential-algebraic equation systems", 
    "arxiv-id": "1505.03445v1", 
    "author": "John D. Pryce", 
    "publish": "2015-05-13T16:11:42Z", 
    "summary": "Systems of differential-algebraic equations (DAEs) are generated routinely by\nsimulation and modeling environments such as Modelica and MapleSim. Before a\nsimulation starts and a numerical solution method is applied, some kind of\nstructural analysis is performed to determine the structure and the index of a\nDAE. Structural analysis methods serve as a necessary preprocessing stage, and\namong them, Pantelides's algorithm is widely used.\n  Recently Pryce's $\\Sigma$-method is becoming increasingly popular, owing to\nits straightforward approach and capability of analyzing high-order systems.\nBoth methods are equivalent in the sense that when one succeeds, producing a\nnonsingular system Jacobian, the other also succeeds, and the two give the same\nstructural index.\n  Although provably successful on fairly many problems of interest, the\nstructural analysis methods can fail on some simple, solvable DAEs and give\nincorrect structural information including the index. In this report, we focus\non the $\\Sigma$-method. We investigate its failures, and develop two\nsymbolic-numeric conversion methods for converting a DAE, on which the\n$\\Sigma$-method fails, to an equivalent problem on which this method succeeds.\nAimed at making structural analysis methods more reliable, our conversion\nmethods exploit structural information of a DAE, and require a symbolic tool\nfor their implementation."
},{
    "category": "cs.SY", 
    "doi": "10.1007/978-3-319-21362-0_3", 
    "link": "http://arxiv.org/pdf/1506.00695v3", 
    "title": "On the Skolem Problem for Continuous Linear Dynamical Systems", 
    "arxiv-id": "1506.00695v3", 
    "author": "James Worrell", 
    "publish": "2015-06-01T22:30:59Z", 
    "summary": "The Continuous Skolem Problem asks whether a real-valued function satisfying\na linear differential equation has a zero in a given interval of real numbers.\nThis is a fundamental reachability problem for continuous linear dynamical\nsystems, such as linear hybrid automata and continuous-time Markov chains.\nDecidability of the problem is currently open---indeed decidability is open\neven for the sub-problem in which a zero is sought in a bounded interval. In\nthis paper we show decidability of the bounded problem subject to Schanuel's\nConjecture, a unifying conjecture in transcendental number theory. We\nfurthermore analyse the unbounded problem in terms of the frequencies of the\ndifferential equation, that is, the imaginary parts of the characteristic\nroots. We show that the unbounded problem can be reduced to the bounded problem\nif there is at most one rationally linearly independent frequency, or if there\nare two rationally linearly independent frequencies and all characteristic\nroots are simple. We complete the picture by showing that decidability of the\nunbounded problem in the case of two (or more) rationally linearly independent\nfrequencies would entail a major new effectiveness result in Diophantine\napproximation, namely computability of the Diophantine-approximation types of\nall real algebraic numbers."
},{
    "category": "cs.MS", 
    "doi": "10.1145/2893803.2893807", 
    "link": "http://arxiv.org/pdf/1506.03726v2", 
    "title": "Lacunaryx: Computing bounded-degree factors of lacunary polynomials", 
    "arxiv-id": "1506.03726v2", 
    "author": "Bruno Grenet", 
    "publish": "2015-06-11T16:08:54Z", 
    "summary": "In this paper, we report on an implementation in the free software Mathemagix\nof lacunary factorization algorithms, distributed as a library called\nLacunaryx. These algorithms take as input a polynomial in sparse\nrepresentation, that is as a list of nonzero monomials, and an integer $d$, and\ncompute its irreducible degree-$\\le d$ factors. The complexity of these\nalgorithms is polynomial in the sparse size of the input polynomial and $d$."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2893803.2893807", 
    "link": "http://arxiv.org/pdf/1506.04215v1", 
    "title": "Parallel sparse interpolation using small primes", 
    "arxiv-id": "1506.04215v1", 
    "author": "Xisen Tian", 
    "publish": "2015-06-13T03:41:43Z", 
    "summary": "To interpolate a supersparse polynomial with integer coefficients, two\nalternative approaches are the Prony-based \"big prime\" technique, which acts\nover a single large finite field, or the more recently-proposed \"small primes\"\ntechnique, which reduces the unknown sparse polynomial to many low-degree dense\npolynomials. While the latter technique has not yet reached the same\ntheoretical efficiency as Prony-based methods, it has an obvious potential for\nparallelization. We present a heuristic \"small primes\" interpolation algorithm\nand report on a low-level C implementation using FLINT and MPI."
},{
    "category": "math.NT", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1506.05644v1", 
    "title": "p-Adic Stability In Linear Algebra", 
    "arxiv-id": "1506.05644v1", 
    "author": "Tristan Vaccon", 
    "publish": "2015-06-18T12:13:41Z", 
    "summary": "Using the differential precision methods developed previously by the same\nauthors, we study the p-adic stability of standard operations on matrices and\nvector spaces. We demonstrate that lattice-based methods surpass naive methods\nin many applications, such as matrix multiplication and sums and intersections\nof subspaces. We also analyze determinants , characteristic polynomials and LU\nfactorization using these differential methods. We supplement our observations\nwith numerical experiments."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1506.05897v1", 
    "title": "Real root finding for low rank linear matrices", 
    "arxiv-id": "1506.05897v1", 
    "author": "Mohab Safey El Din", 
    "publish": "2015-06-19T07:59:36Z", 
    "summary": "The problem of finding low rank $m\\times m$ matrices in a real affine\nsubspace of dimension n has many applications in information and systems\ntheory, where low rank is synonymous of structure and parcimony. We design a\nsymbolic computation algorithm to solve this problem efficiently, exactly and\nrigorously: the input are the rational coefficients of the matrices spanning\nthe affine subspace as well as the expected maximum rank, and the output is a\nrational parametrization encoding a finite set of points that intersects each\nconnected component of the low rank real algebraic set. The complexity of our\nalgorithm is studied thoroughly. It is essentially polynomial in\nbinomial(n+m(m--r),n) where r is the expected maximum rank; it improves on the\nstate-of-the-art in the field. Moreover, computer experiments show the\npractical efficiency of our approach."
},{
    "category": "math.AC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1506.08994v1", 
    "title": "On the Connection Between Ritt Characteristic Sets and   Buchberger-Gr\u00f6bner Bases", 
    "arxiv-id": "1506.08994v1", 
    "author": "Dongming Wang", 
    "publish": "2015-06-30T08:43:44Z", 
    "summary": "For any polynomial ideal $I$, let the minimal triangular set contained in the\nreduced Buchberger-Gr\\\"obner basis of $I$ with respect to the purely\nlexicographical term order be called the W-characteristic set of $I$. In this\npaper, we establish a strong connection between Ritt's characteristic sets and\nBuchberger's Gr\\\"obner bases of polynomial ideals by showing that the\nW-characteristic set $C$ of $I$ is a Ritt characteristic set of $I$ whenever\n$C$ is an ascending set, and a Ritt characteristic set of $I$ can always be\ncomputed from $C$ with simple pseudo-division when $C$ is regular. We also\nprove that under certain variable ordering, either the W-characteristic set of\n$I$ is normal, or irregularity occurs for the $j$th, but not the $(j+1)$th,\nelimination ideal of $I$ for some $j$. In the latter case, we provide explicit\npseudo-divisibility relations, which lead to nontrivial factorizations of\ncertain polynomials in the Buchberger-Gr\\\"obner basis and thus reveal the\nstructure of such polynomials. The pseudo-divisibility relations may be used to\ndevise an algorithm to decompose arbitrary polynomial sets into normal\ntriangular sets based on Buchberger-Gr\\\"obner bases computation."
},{
    "category": "cs.CR", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1507.03480v1", 
    "title": "Middle-Solving Grobner bases algorithm for cryptanalysis over finite   fields", 
    "arxiv-id": "1507.03480v1", 
    "author": "Heliang Huang", 
    "publish": "2015-07-13T14:46:05Z", 
    "summary": "Algebraic cryptanalysis usually requires to recover the secret key by solving\npolynomial equations. Grobner bases algorithm is a well-known method to solve\nthis problem. However, a serious drawback exists in the Grobner bases based\nalgebraic attacks, namely, any information won't be got if we couldn't work out\nthe Grobner bases of the polynomial equations system. In this paper, firstly, a\ngeneralized model of Grobner basis algorithms is presented, which provides us a\nplatform to analyze and solve common problems of the algorithms. Secondly, we\ngive and prove the degree bound of the polynomials appeared during the\ncomputation of Grobner basis after field polynomials is added. Finally, by\ndetecting the temporary basis during the computation of Grobner bases and then\nextracting the univariate polynomials contained unique solution in the\ntemporary basis, a heuristic strategy named Middle-Solving is presented to\nsolve these polynomials at each iteration of the algorithm. Farther, two\nspecific application mode of Middle-Solving strategy for the incremental and\nnon-incremental Grobner bases algorithms are presented respectively. By using\nthe Middle-Solving strategy, even though we couldn't work out the final Grobner\nbases, some information of the variables still leak during the computational\nprocess."
},{
    "category": "cs.CR", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1507.03674v1", 
    "title": "Algorithm for Solving Massively Underdefined Systems of Multivariate   Quadratic Equations over Finite Fields", 
    "arxiv-id": "1507.03674v1", 
    "author": "Wansu Bao", 
    "publish": "2015-07-14T00:51:29Z", 
    "summary": "Solving systems of m multivariate quadratic equations in n variables\n(MQ-problem) over finite fields is NP-hard. The security of many cryptographic\nsystems is based on this problem. Up to now, the best algorithm for solving the\nunderdefined MQ-problem is Hiroyuki Miura et al.'s algorithm, which is a\npolynomial-time algorithm when \\[n \\ge m(m + 3)/2\\] and the characteristic of\nthe field is even. In order to get a wider applicable range, we reduce the\nunderdefined MQ-problem to the problem of finding square roots over finite\nfield, and then combine with the guess and determine method. In this way, the\napplicable range is extended to \\[n \\ge m(m + 1)/2\\], which is the widest range\nuntil now. Theory analysis indicates that the complexity of our algorithm is\n\\[O(q{n^\\omega }m{(\\log {\\kern 1pt} {\\kern 1pt} q)^2}){\\kern 1pt} \\] when\ncharacteristic of the field is even and \\[O(q{2^m}{n^\\omega }m{(\\log {\\kern\n1pt} {\\kern 1pt} q)^2})\\] when characteristic of the field is odd, where \\[2\n\\le \\omega \\le 3\\] is the complexity of Gaussian elimination."
},{
    "category": "math.CO", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1507.04840v1", 
    "title": "Proof of the Wilf-Zeilberger Conjecture", 
    "arxiv-id": "1507.04840v1", 
    "author": "Christoph Koutschan", 
    "publish": "2015-07-17T05:50:02Z", 
    "summary": "In 1992, Wilf and Zeilberger conjectured that a hypergeometric term in\nseveral discrete and continuous variables is holonomic if and only if it is\nproper. Strictly speaking the conjecture does not hold, but it is true when\nreformulated properly: Payne proved a piecewise interpretation in 1997, and\nindependently, Abramov and Petkovsek in 2002 proved a conjugate interpretation.\nBoth results address the pure discrete case of the conjecture. In this paper we\nextend their work to hypergeometric terms in several discrete and continuous\nvariables and prove the conjugate interpretation of the Wilf-Zeilberger\nconjecture in this mixed setting."
},{
    "category": "math.NT", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1507.06502v1", 
    "title": "Resultants and subresultants of p-adic polynomials", 
    "arxiv-id": "1507.06502v1", 
    "author": "Xavier Caruso", 
    "publish": "2015-07-23T14:07:54Z", 
    "summary": "We address the problem of the stability of the computations of resultants and\nsubresultants of polynomials defined over complete discrete valuation rings\n(e.g. Zp or k[[t]] where k is a field). We prove that Euclide-like algorithms\nare highly unstable on average and we explain, in many cases, how one can\nstabilize them without sacrifying the complexity. On the way, we completely\ndetermine the distribution of the valuation of the principal subresultants of\ntwo random monic p-adic polynomials having the same degree."
},{
    "category": "math.OC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1508.03715v3", 
    "title": "Exact algorithms for linear matrix inequalities", 
    "arxiv-id": "1508.03715v3", 
    "author": "Mohab Safey El Din", 
    "publish": "2015-08-15T09:10:18Z", 
    "summary": "Let $A(x)=A\\_0+x\\_1A\\_1+...+x\\_nA\\_n$ be a linear matrix, or pencil,\ngenerated by given symmetric matrices $A\\_0,A\\_1,...,A\\_n$ of size $m$ with\nrational entries. The set of real vectors x such that the pencil is positive\nsemidefinite is a convex semi-algebraic set called spectrahedron, described by\na linear matrix inequality (LMI). We design an exact algorithm that, up to\ngenericity assumptions on the input matrices, computes an exact algebraic\nrepresentation of at least one point in the spectrahedron, or decides that it\nis empty. The algorithm does not assume the existence of an interior point, and\nthe computed point minimizes the rank of the pencil on the spectrahedron. The\ndegree $d$ of the algebraic representation of the point coincides\nexperimentally with the algebraic degree of a generic semidefinite program\nassociated to the pencil. We provide explicit bounds for the complexity of our\nalgorithm, proving that the maximum number of arithmetic operations that are\nperformed is essentially quadratic in a multilinear B\\'ezout bound of $d$. When\n$m$ (resp. $n$) is fixed, such a bound, and hence the complexity, is polynomial\nin $n$ (resp. $m$). We conclude by providing results of experiments showing\npractical improvements with respect to state-of-the-art computer algebra\nalgorithms."
},{
    "category": "math.AG", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1508.03785v3", 
    "title": "Computing characteristic classes of subschemes of smooth toric varieties", 
    "arxiv-id": "1508.03785v3", 
    "author": "Martin Helmer", 
    "publish": "2015-08-16T03:26:21Z", 
    "summary": "Let $X_{\\Sigma}$ be a smooth complete toric variety defined by a fan $\\Sigma$\nand let $V=V(I)$ be a subscheme of $X_{\\Sigma}$ defined by an ideal $I$\nhomogeneous with respect to the grading on the total coordinate ring of\n$X_{\\Sigma}$. We show a new expression for the Segre class $s(V,X_{\\Sigma})$ in\nterms of the projective degrees of a rational map specified by the generators\nof $I$ when each generator corresponds to a numerically effective (nef)\ndivisor. Restricting to the case where $X_{\\Sigma}$ is a smooth projective\ntoric variety and dehomogenizing the total homogeneous coordinate ring of\n$X_{\\Sigma}$ via a dehomogenizing ideal we also give an expression for the\nprojective degrees of this rational map in terms of the dimension of an\nexplicit quotient ring. Under an additional technical assumption we construct\nwhat we call a general dehomogenizing ideal and apply this construction to give\neffective algorithms to compute the Segre class $s(V,X_{\\Sigma})$, the\nChern-Schwartz-MacPherson class $c_{SM}(V)$ and the topological Euler\ncharacteristic $\\chi(V)$ of $V$. These algorithms can, in particular, be used\nfor subschemes of any product of projective spaces $\\mathbb{P}^{n_1} \\times\n\\cdots \\times \\mathbb{P}^{n_j}$ or for subschemes of many other projective\ntoric varieties. Running time bounds for several of the algorithms are given\nand the algorithms are tested on a variety of examples. In all applicable cases\nour algorithms to compute these characteristic classes are found to offer\nsignificantly increased performance over other known algorithms."
},{
    "category": "math.AG", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1508.07219v2", 
    "title": "Computing the Chow variety of quadratic space curves", 
    "arxiv-id": "1508.07219v2", 
    "author": "Bernd Sturmfels", 
    "publish": "2015-08-28T14:13:17Z", 
    "summary": "Quadrics in the Grassmannian of lines in 3-space form a 19-dimensional\nprojective space. We study the subvariety of coisotropic hypersurfaces.\nFollowing Gel'fand, Kapranov and Zelevinsky, it decomposes into Chow forms of\nplane conics, Chow forms of pairs of lines, and Hurwitz forms of quadric\nsurfaces. We compute the ideals of these loci."
},{
    "category": "math.AG", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1509.03722v2", 
    "title": "Computing isolated orbifolds in weighted flag varieties", 
    "arxiv-id": "1509.03722v2", 
    "author": "Muhammad Imran Qureshi", 
    "publish": "2015-09-12T09:03:48Z", 
    "summary": "Given a weighted flag variety $w\\Sigma(\\mu,u)$ corresponding to chosen fixed\nparameters $\\mu$ and $u$, we present an algorithm to compute lists of all\npossible projectively Gorenstein $n$-folds, having canonical weight $k$ and\nisolated orbifold points, appearing as weighted complete intersections in\n$w\\Sigma(\\mu,u) $ or some projective cone(s) over $w\\Sigma(\\mu,u)$. We apply\nour algorithm to compute lists of interesting classes of polarized 3-folds with\nisolated orbifold points in the codimension 8 weighted $G_2$ variety. We also\nshow the existence of some families of log-terminal $\\mathbb Q$-Fano 3-folds in\ncodimension 8 by explicitly constructing them as quasilinear sections of a\nweighted $G_2$-variety."
},{
    "category": "cs.PL", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1510.05201v2", 
    "title": "Termination Analysis of Polynomial Programs with Equality Conditions", 
    "arxiv-id": "1510.05201v2", 
    "author": "Guohua Wu", 
    "publish": "2015-10-18T06:21:35Z", 
    "summary": "In this paper, we investigate the termination problem of a family of\npolynomial programs, in which all assignments to program variables are\npolynomials, and test conditions of loops and conditional statements are\npolynomial equations. Our main result is that the non-terminating inputs of\nsuch a polynomial program is algorithmically computable according to a strictly\ndescending chain of algebraic sets, which implies that the termination problem\nof these programs is decidable. The complexity of the algorithm follows\nimmediately from the length of the chain, which can be computed by Hilbert's\nfunction and Macaulay's theorem. To the best of our knowledge, the considered\nfamily of polynomial programs should be the largest one with a decidable\ntermination problem so far. The experimental results indicate the efficiency of\nour approach."
},{
    "category": "math.AG", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1510.05622v2", 
    "title": "Sparse Polynomial Systems with many Positive Solutions from Bipartite   Simplicial Complexes", 
    "arxiv-id": "1510.05622v2", 
    "author": "Pierre-Jean Spaenlehauer", 
    "publish": "2015-10-19T19:01:26Z", 
    "summary": "Consider a regular triangulation of the convex-hull $P$ of a set $\\mathcal A$\nof $n$ points in $\\mathbb R^d$, and a real matrix $C$ of size $d \\times n$. A\nversion of Viro's method allows to construct from these data an unmixed\npolynomial system with support $\\mathcal A$ and coefficient matrix $C$ whose\nnumber of positive solutions is bounded from below by the number of\n$d$-simplices which are positively decorated by $C$. We show that all the\n$d$-simplices of a triangulation can be positively decorated if and only if the\ntriangulation is balanced, which in turn is equivalent to the fact that its\ndual graph is bipartite. This allows us to identify, among classical families,\nmonomial supports which admit maximally positive systems, i.e. systems all\ntoric complex solutions of which are real and positive. These families give\nsome evidence in favor of a conjecture due to Bihan. We also use this technique\nin order to construct fewnomial systems with many positive solutions. This is\ndone by considering a simplicial complex with bipartite dual graph included in\na regular triangulation of the cyclic polytope."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1510.07487v2", 
    "title": "Multiple binomial sums", 
    "arxiv-id": "1510.07487v2", 
    "author": "Bruno Salvy", 
    "publish": "2015-10-26T14:18:51Z", 
    "summary": "Multiple binomial sums form a large class of multi-indexed sequences, closed\nunder partial summation, which contains most of the sequences obtained by\nmultiple summation of products of binomial coefficients and also all the\nsequences with algebraic generating function. We study the representation of\nthe generating functions of binomial sums by integrals of rational functions.\nThe outcome is twofold. Firstly, we show that a univariate sequence is a\nmultiple binomial sum if and only if its generating function is the diagonal of\na rational function. Secondly, we propose algorithms that decide the equality\nof multiple binomial sums and that compute recurrence relations for them. In\nconjunction with geometric simplifications of the integral representations,\nthis approach behaves well in practice. The process avoids the computation of\ncertificates and the problem of the appearance of spurious singularities that\nafflicts discrete creative telescoping, both in theory and in practice."
},{
    "category": "math.AC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1511.03234v1", 
    "title": "A unifying form for noetherian polynomial reductions", 
    "arxiv-id": "1511.03234v1", 
    "author": "Margherita Roggero", 
    "publish": "2015-11-10T19:28:53Z", 
    "summary": "Polynomial reduction is one of the main tools in computational algebra with\ninnumerable applications in many areas, both pure and applied. Since many years\nboth the theory and an efficient design of the related algorithm have been\nsolidly established.\n  This paper presents a general definition of polynomial reduction structure,\nstudies its features and highlights the aspects needed in order to grant and to\nefficiently test the main properties (noetherianity, confluence, ideal\nmembership).\n  The most significant aspect of this analysis is a negative reappraisal of the\nrole of the notion of term order which is usually considered a central and\ncrucial tool in the theory. In fact, as it was already established in the\ncomputer science context in relation with termination of algorithms, most of\nthe properties can be obtained simply considering a well-founded ordering,\nwhile the classical requirement that it be preserved by multiplication is\nirrelevant.\n  The last part of the paper shows how the polynomial basis concepts present in\nliterature are interpreted in our language and their properties are\nconsequences of the general results established in the first part of the paper."
},{
    "category": "cs.RO", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1511.05060v1", 
    "title": "Solving the Forward Position Problem of an In-Parallel Planar   Manipulator in the Gauss Plane", 
    "arxiv-id": "1511.05060v1", 
    "author": "Sureyya Sahin", 
    "publish": "2015-11-16T17:48:44Z", 
    "summary": "We study determining the posture of an in-parallel planar manipulator, which\nhas three connectors composed of revolute, prismatic and revolute joints, from\nspecified active joint variables. We construct an ideal in the field of complex\nnumbers, and we introduce self inversive polynomials. We provide results for an\nin-parallel planar manipulator, which has a base and moving platform in right\ntriangular shape. Using Sage computer algebra system, we compute its Groebner\nbases. We illustrate that the single variable polynomials obtained from the\nGroebner bases are self reciprocal."
},{
    "category": "cs.CY", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1511.07087v1", 
    "title": "Visualization in teaching and learning mathematics in elementary,   secondary and higher education", 
    "arxiv-id": "1511.07087v1", 
    "author": "Bojan Banjac", 
    "publish": "2015-11-22T23:38:14Z", 
    "summary": "In this paper we present our experience in using visualization in mathematics\neducation. The experience with our university courses: \"Computer tools in\nmatematics\" and \"Symbolic algebra\" provides the basis for mathematics teacher\neducation program http://vizuelizacija.etf.rs/. The program is intended for\nelementary and high school teachers. The education program deals with modern\ntechniques of visualization by using technologies such as GeoGegebra, JAVA and\nHTML."
},{
    "category": "math.RA", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1512.08365v1", 
    "title": "The Module Isomorphism Problem for Finite Rings and Related Results", 
    "arxiv-id": "1512.08365v1", 
    "author": "Iuliana Cioc\u0103nea-Teodorescu", 
    "publish": "2015-12-28T10:18:50Z", 
    "summary": "Let $R$ be a finite ring and let $M, N$ be two finite left $R$-modules. We\npresent two distinct deterministic algorithms that decide in polynomial time\nwhether or not $M$ and $N$ are isomorphic, and if they are, exhibit an\nisomorphism. As by-products, we are able to determine the largest isomorphic\ncommon direct summand between two modules and the minimum number of generators\nof a module. By not requiring $R$ to contain a field, avoiding computation of\nthe Jacobson radical and not distinguishing between large and small\ncharacteristic, both algorithms constitute improvements to known results."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1601.01067v2", 
    "title": "A Polynomial-time Algorithm to Compute Generalized Hermite Normal Form   of Matrices over Z[x]", 
    "arxiv-id": "1601.01067v2", 
    "author": "Xiao-Shan Gao", 
    "publish": "2016-01-06T03:32:37Z", 
    "summary": "In this paper, a polynomial-time algorithm is given to compute the\ngeneralized Hermite normal form for a matrix F over Z[x], or equivalently, the\nreduced Groebner basis of the Z[x]-module generated by the column vectors of F.\nThe algorithm is also shown to be practically more efficient than existing\nalgorithms. The algorithm is based on three key ingredients. First, an F4 style\nalgorithm to compute the Groebner basis is adopted, where a novel prolongation\nis designed such that the coefficient matrices under consideration have\npolynomial sizes. Second, fast algorithms to compute Hermite normal forms of\nmatrices over Z are used. Third, the complexity of the algorithm are guaranteed\nby a nice estimation for the degree and height bounds of the polynomials in the\ngeneralized Hermite normal form."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1601.03080v1", 
    "title": "Existence Problem of Telescopers: Beyond the Bivariate Case", 
    "arxiv-id": "1601.03080v1", 
    "author": "Rong-Hua Wang", 
    "publish": "2016-01-12T22:00:59Z", 
    "summary": "In this paper, we solve the existence problem of telescopers for rational\nfunctions in three discrete variables. We reduce the problem to that of\ndeciding the summability of bivariate rational functions, which has been solved\nrecently. The existence criteria we present is needed for detecting the\ntermination of Zeilberger's algorithm to the function classes studied in this\npaper."
},{
    "category": "math.AG", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1601.05826v2", 
    "title": "Descartes' Rule of Signs for Polynomial Systems supported on Circuits", 
    "arxiv-id": "1601.05826v2", 
    "author": "Alicia Dickenstein", 
    "publish": "2016-01-21T22:01:22Z", 
    "summary": "We give a multivariate version of Descartes' rule of signs to bound the\nnumber of positive real roots of a system of polynomial equations in n\nvariables with n+2 monomials, in terms of the sign variation of a sequence\nassociated both to the exponent vectors and the given coefficients. We show\nthat our bound is sharp and is related to the signature of the circuit."
},{
    "category": "math.AC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1601.06626v1", 
    "title": "Computing the decomposition group of a zero-dimensional ideal by   elimination method", 
    "arxiv-id": "1601.06626v1", 
    "author": "Yongbin Li", 
    "publish": "2016-01-22T08:59:42Z", 
    "summary": "In this note, we show that the decomposition group $Dec(I)$ of a\nzero-dimensional radical ideal $I$ in ${\\bf K}[x_1,\\ldots,x_n]$ can be\nrepresented as the direct sum of several symmetric groups of polynomials based\nupon using Gr\\\"{o}bner bases. The new method makes a theoretical contribution\nto discuss the decomposition group of $I$ by using Computer Algebra without\nconsidering the complexity. As one application, we also present an approach to\nyield new triangular sets in computing triangular decomposition of polynomial\nsets ${\\mathbb P}$ if $Dec(<{\\mathbb P}>)$ is known."
},{
    "category": "cs.SY", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1602.00431v3", 
    "title": "Solving rank-constrained semidefinite programs in exact arithmetic", 
    "arxiv-id": "1602.00431v3", 
    "author": "Simone Naldi", 
    "publish": "2016-02-01T08:58:49Z", 
    "summary": "We consider the problem of minimizing a linear function over an affine\nsection of the cone of positive semidefinite matrices, with the additional\nconstraint that the feasible matrix has prescribed rank. When the rank\nconstraint is active, this is a non-convex optimization problem, otherwise it\nis a semidefinite program. Both find numerous applications especially in\nsystems control theory and combinatorial optimization, but even in more general\ncontexts such as polynomial optimization or real algebra. While numerical\nalgorithms exist for solving this problem, such as interior-point or\nNewton-like algorithms, in this paper we propose an approach based on symbolic\ncomputation. We design an exact algorithm for solving rank-constrained\nsemidefinite programs, whose complexity is essentially quadratic on natural\ndegree bounds associated to the given optimization problem: for subfamilies of\nthe problem where the size of the feasible matrix is fixed, the complexity is\npolynomial in the number of variables. The algorithm works under assumptions on\nthe input data: we prove that these assumptions are generically satisfied. We\nalso implement it in Maple and discuss practical experiments."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2755996.2756655", 
    "link": "http://arxiv.org/pdf/1602.00454v1", 
    "title": "Holonomic Tools for Basic Hypergeometric Functions", 
    "arxiv-id": "1602.00454v1", 
    "author": "Peter Paule", 
    "publish": "2016-02-01T10:04:20Z", 
    "summary": "With the exception of q-hypergeometric summation, the use of computer algebra\npackages implementing Zeilberger's \"holonomic systems approach\" in a broader\nmathematical sense is less common in the field of q-series and basic\nhypergeometric functions. A major objective of this article is to popularize\nthe usage of such tools also in these domains. Concrete case studies showing\nsoftware in action introduce to the basic techniques. An application highlight\nis a new computer-assisted proof of the celebrated Ismail-Zhang formula, an\nimportant q-analog of a classical expansion formula of plane waves in terms of\nGegenbauer polynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930904", 
    "link": "http://arxiv.org/pdf/1602.00545v2", 
    "title": "Fast Computation of the Nth Term of an Algebraic Series over a Finite   Prime Field", 
    "arxiv-id": "1602.00545v2", 
    "author": "Philippe Dumas", 
    "publish": "2016-02-01T14:42:39Z", 
    "summary": "We address the question of computing one selected term of an algebraic power\nseries. In characteristic zero, the best algorithm currently known for\ncomputing the $N$th coefficient of an algebraic series uses differential\nequations and has arithmetic complexity quasi-linear in $\\sqrt{N}$. We show\nthat over a prime field of positive characteristic $p$, the complexity can be\nlowered to $O(\\log N)$. The mathematical basis for this dramatic improvement is\na classical theorem stating that a formal power series with coefficients in a\nfinite field is algebraic if and only if the sequence of its coefficients can\nbe generated by an automaton. We revisit and enhance two constructive proofs of\nthis result for finite prime fields. The first proof uses Mahler equations,\nwhose sizes appear to be prohibitively large. The second proof relies on\ndiagonals of rational functions; we turn it into an efficient algorithm, of\ncomplexity linear in $\\log N$ and quasi-linear in $p$."
},{
    "category": "math.NA", 
    "doi": "10.1145/2930889.2930904", 
    "link": "http://arxiv.org/pdf/1602.00700v1", 
    "title": "Numerically validating the completeness of the real solution set of a   system of polynomial equations", 
    "arxiv-id": "1602.00700v1", 
    "author": "Alan C. Liddell", 
    "publish": "2016-02-01T21:01:07Z", 
    "summary": "Computing the real solutions to a system of polynomial equations is a\nchallenging problem, particularly verifying that all solutions have been\ncomputed. We describe an approach that combines numerical algebraic geometry\nand sums of squares programming to test whether a given set is \"complete\" with\nrespect to the real solution set. Specifically, we test whether the Zariski\nclosure of that given set is indeed equal to the solution set of the real\nradical of the ideal generated by the given polynomials. Examples with finitely\nand infinitely many real solutions are provided, along with an example having\npolynomial inequalities."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930904", 
    "link": "http://arxiv.org/pdf/1602.00848v1", 
    "title": "On the p-adic stability of the FGLM algorithm", 
    "arxiv-id": "1602.00848v1", 
    "author": "Tristan Vaccon", 
    "publish": "2016-02-02T09:30:28Z", 
    "summary": "Nowadays, many strategies to solve polynomial systems use the computation of\na Gr{\\\"o}bner basis for the graded reverse lexicographical ordering, followed\nby a change of ordering algorithm to obtain a Gr{\\\"o}bner basis for the\nlexicographical ordering. The change of ordering algorithm is crucial for these\nstrategies. We study the p-adic stability of the main change of ordering\nalgorithm, FGLM. We show that FGLM is stable and give explicit upper bound on\nthe loss of precision occuring in its execution. The variant of FGLM designed\nto pass from the grevlex ordering to a Gr{\\\"o}bner basis in shape position is\nalso stable. Our study relies on the application of Smith Normal Form\ncomputations for linear algebra."
},{
    "category": "math.NT", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1602.01303v1", 
    "title": "Division and Slope Factorization of p-Adic Polynomials", 
    "arxiv-id": "1602.01303v1", 
    "author": "Tristan Vaccon", 
    "publish": "2016-02-03T14:03:53Z", 
    "summary": "We study two important operations on polynomials defined over complete\ndiscrete valuation fields: Euclidean division and factorization. In particular,\nwe design a simple and efficient algorithm for computing slope factorizations,\nbased on Newton iteration. One of its main features is that we avoid working\nwith fractional exponents. We pay particular attention to stability, and\nanalyze the behavior of the algorithm using several precision models."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1602.01304v2", 
    "title": "Inverse Inequality Estimates with Symbolic Computation", 
    "arxiv-id": "1602.01304v2", 
    "author": "Cristian-Silviu Radu", 
    "publish": "2016-02-03T14:04:03Z", 
    "summary": "In the convergence analysis of numerical methods for solving partial\ndifferential equations (such as finite element methods) one arrives at certain\ngeneralized eigenvalue problems, whose maximal eigenvalues need to be estimated\nas accurately as possible. We apply symbolic computation methods to the\nsituation of square elements and are able to improve the previously known upper\nbound, given in \"p- and hp-finite element methods\" (Schwab, 1998), by a factor\nof 8. More precisely, we try to evaluate the corresponding determinant using\nthe holonomic ansatz, which is a powerful tool for dealing with determinants,\nproposed by Zeilberger in 2007. However, it turns out that this method does not\nsucceed on the problem at hand. As a solution we present a variation of the\noriginal holonomic ansatz that is applicable to a larger class of determinants,\nincluding the one we are dealing with here. We obtain an explicit closed form\nfor the determinant, whose special form enables us to derive new and tight\nupper resp. lower bounds on the maximal eigenvalue, as well as its asymptotic\nbehaviour."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1603.03959v1", 
    "title": "On the computation of the straight lines contained in a rational surface", 
    "arxiv-id": "1603.03959v1", 
    "author": "Jorge Caravantes", 
    "publish": "2016-03-12T19:59:49Z", 
    "summary": "In this paper we present an algorithm to compute the real and complex\nstraight lines contained in a rational surface, defined by a rational\nparametrization. The algorithm relies on the well-known theorem of Differential\nGeometry that char- acterizes real straight lines contained in a surface as\ncurves that are simulta- neously asymptotic lines, and geodesics. We also\nreport on an implementation carried out in Maple 18. Examples and timings show\nthe efficiency of the algo- rithm for moderate degrees, compared with a\nbrute-force approach."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1603.03987v1", 
    "title": "Binomial Difference Ideals", 
    "arxiv-id": "1603.03987v1", 
    "author": "Chun-Ming Yuan", 
    "publish": "2016-03-13T03:49:01Z", 
    "summary": "In this paper, binomial difference ideals are studied. Three canonical\nrepresentations for Laurent binomial difference ideals are given in terms of\nthe reduced Groebner basis of Z[x]-lattices, regular and coherent difference\nascending chains, and partial characters over Z[x]-lattices, respectively.\nCriteria for a Laurent binomial difference ideal to be reflexive, prime,\nwell-mixed, and perfect are given in terms of their support lattices. The\nreflexive, well-mixed, and perfect closures of a Laurent binomial difference\nideal are shown to be binomial. Most of the properties of Laurent binomial\ndifference ideals are extended to the case of difference binomial ideals.\nFinally, algorithms are given to check whether a given Laurent binomial\ndifference ideal I is reflexive, prime, well-mixed, or perfect, and in the\nnegative case, to compute the reflexive, well-mixed, and perfect closures of I.\nAn algorithm is given to decompose a finitely generated perfect binomial\ndifference ideal as the intersection of reflexive prime binomial difference\nideals."
},{
    "category": "cs.CG", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1603.04582v2", 
    "title": "Extraction of cylinders and cones from minimal point sets", 
    "arxiv-id": "1603.04582v2", 
    "author": "Jiajun Zhang", 
    "publish": "2016-03-15T07:37:29Z", 
    "summary": "We propose new algebraic methods for extracting cylinders and cones from\nminimal point sets, including oriented points. More precisely, we are\ninterested in computing efficiently cylinders through a set of three points,\none of them being oriented, or through a set of five simple points. We are also\ninterested in computing efficiently cones through a set of two oriented points,\nthrough a set of four points, one of them being oriented, or through a set of\nsix points. For these different interpolation problems, we give optimal bounds\non the number of solutions. Moreover, we describe algebraic methods targeted to\nsolve these problems efficiently."
},{
    "category": "cs.CR", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1603.07699v1", 
    "title": "Secure cloud computations: Description of (fully)homomorphic ciphers   within the P-adic model of encryption", 
    "arxiv-id": "1603.07699v1", 
    "author": "Ekaterina Yurova", 
    "publish": "2016-03-24T18:43:49Z", 
    "summary": "In this paper we consider the description of homomorphic and fully\nhomomorphic ciphers in the $p$-adic model of encryption. This model describes a\nwide class of ciphers, but certainly not all. Homomorphic and fully homomorphic\nciphers are used to ensure the credibility of remote computing, including cloud\ntechnology. The model describes all homomorphic ciphers with respect to\narithmetic and coordinate-wise logical operations in the ring of $p$-adic\nintegers $Z_p$. We show that there are no fully homomorphic ciphers for each\npair of the considered set of arithmetic and coordinate-wise logical operations\non $Z_p$. We formulate the problem of constructing a fully homomorphic cipher\nas follows. We consider a homomorphic cipher with respect to operation \"$*$\" on\n$Z_p$. Then, we describe the complete set of operations \"$G$\", for which the\ncipher is homomorphic. As a result, we construct a fully homomorphic cipher\nwith respect to the operations \"$*$\" and \"$G$\". We give a description of all\noperations \"$G$\", for which we obtain fully homomorphic ciphers with respect to\nthe operations \"$+$\" and \"$G$\" from the homomorphic cipher constructed with\nrespect to the operation \"$+$\". We also present examples of such \"new\"\noperations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1604.01958v1", 
    "title": "Toric Difference Variety", 
    "arxiv-id": "1604.01958v1", 
    "author": "Chun-Ming Yuan", 
    "publish": "2016-04-07T11:23:29Z", 
    "summary": "In this paper, the concept of toric difference varieties is defined and four\nequivalent descriptions for toric difference varieties are presented in terms\nof difference rational parametrization, difference coordinate rings, toric\ndifference ideals, and group actions by difference tori. Connections between\ntoric difference varieties and affine N[x]-semimodules are established by\nproving the correspondence between the irreducible invariant difference\nsubvarieties and the faces of the N[x]-submodules and the orbit-face\ncorrespondence. Finally, an algorithm is given to decide whether a binomial\ndifference ideal represented by a Z[x]-lattice defines a toric difference\nvariety."
},{
    "category": "cs.CR", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1604.02277v1", 
    "title": "A modified block Lanczos algorithm with fewer vectors", 
    "arxiv-id": "1604.02277v1", 
    "author": "Emmanuel Thom\u00e9", 
    "publish": "2016-04-08T08:49:24Z", 
    "summary": "The block Lanczos algorithm proposed by Peter Montgomery is an efficient\nmeans to tackle the sparse linear algebra problem which arises in the context\nof the number field sieve factoring algorithm and its predecessors. We present\nhere a modified version of the algorithm, which incorporates several\nimprovements: we discuss how to efficiently handle homogeneous systems and how\nto reduce the number of vectors stored in the course of the computation. We\nalso provide heuristic justification for the success probability of our\nmodified algorithm. While the overall complexity and expected number of steps\nof the block Lanczos is not changed by the modifications presented in this\narticle, we expect these to be useful for implementations of the block Lanczos\nalgorithm where the storage of auxiliary vectors sometimes has a non-negligible\ncost. 1 Linear systems for integer factoring For factoring a composite integer\nN, algorithms based on the technique of combination of congruences look for\nseveral pairs of integers (x, y) such that x 2 $\\not\\equiv$ y 2 mod N. This\nequality is hoped to be non trivial for at least one of the obtained pairs,\nletting gcd(x -- y, N) unveil a factor of the integer N. Several algorithms use\nthis strategy: the CFRAC algorithm, the quadratic sieve and its variants, and\nthe number field sieve. Pairs (x, y) as above are obtained by combining\nrelations which have been collected as a step of these algorithms. Relations\nare written multiplicatively as a set of valuations. All the algorithms\nconsidered seek a multiplicative combination of these relations which can be\nrewritten as an equality of squares. This is achieved by solving a system of\nlinear equations defined over F 2, where equations are parity constraints on"
},{
    "category": "cs.CG", 
    "doi": "10.1016/j.aam.2016.04.005", 
    "link": "http://arxiv.org/pdf/1604.03603v1", 
    "title": "Algorithmic computation of polynomial amoebas", 
    "arxiv-id": "1604.03603v1", 
    "author": "T. M. Sadykov", 
    "publish": "2016-04-12T22:11:15Z", 
    "summary": "We present algorithms for computation and visualization of amoebas, their\ncontours, compactified amoebas and sections of three-dimensional amoebas by\ntwo-dimensional planes. We also provide method and an algorithm for the\ncomputation of~polynomials whose amoebas exhibit the most complicated topology\namong all polynomials with a fixed Newton polytope. The presented algorithms\nare implemented in computer algebra systems Matlab 8 and Mathematica 9."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930893", 
    "link": "http://arxiv.org/pdf/1604.08059v4", 
    "title": "New Bounds for Hypergeometric Creative Telescoping", 
    "arxiv-id": "1604.08059v4", 
    "author": "Hui Huang", 
    "publish": "2016-04-27T13:28:12Z", 
    "summary": "Based on a modified version of Abramov-Petkov\\v{s}ek reduction, a new\nalgorithm to compute minimal telescopers for bivariate hypergeometric terms was\ndeveloped last year. We investigate further in this paper and present a new\nargument for the termination of this algorithm, which provides an independent\nproof of the existence of telescopers and even enables us to derive lower as\nwell as upper bounds for the order of telescopers for hypergeometric terms.\nCompared to the known bounds in the literature, our bounds are sometimes\nbetter, and never worse than the known ones."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930893", 
    "link": "http://arxiv.org/pdf/1604.08944v1", 
    "title": "On the Complexity of Solving Zero-Dimensional Polynomial Systems via   Projection", 
    "arxiv-id": "1604.08944v1", 
    "author": "Michael Sagraloff", 
    "publish": "2016-04-29T19:42:38Z", 
    "summary": "Given a zero-dimensional polynomial system consisting of n integer\npolynomials in n variables, we propose a certified and complete method to\ncompute all complex solutions of the system as well as a corresponding\nseparating linear form l with coefficients of small bit size. For computing l,\nwe need to project the solutions into one dimension along O(n) distinct\ndirections but no further algebraic manipulations. The solutions are then\ndirectly reconstructed from the considered projections. The first step is\ndeterministic, whereas the second step uses randomization, thus being\nLas-Vegas.\n  The theoretical analysis of our approach shows that the overall cost for the\ntwo problems considered above is dominated by the cost of carrying out the\nprojections. We also give bounds on the bit complexity of our algorithms that\nare exclusively stated in terms of the number of variables, the total degree\nand the bitsize of the input polynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1605.00402v1", 
    "title": "Symbolic-Numeric Tools for Analytic Combinatorics in Several Variables", 
    "arxiv-id": "1605.00402v1", 
    "author": "Bruno Salvy", 
    "publish": "2016-05-02T09:28:32Z", 
    "summary": "Analytic combinatorics studies the asymptotic behaviour of sequences through\nthe analytic properties of their generating functions. This article provides\neffective algorithms required for the study of analytic combinatorics in\nseveral variables, together with their complexity analyses. Given a\nmultivariate rational function we show how to compute its smooth isolated\ncritical points, with respect to a polynomial map encoding asymptotic\nbehaviour, in complexity singly exponential in the degree of its denominator.\nWe introduce a numerical Kronecker representation for solutions of polynomial\nsystems with rational coefficients and show that it can be used to decide\nseveral properties (0 coordinate, equal coordinates, sign conditions for real\nsolutions, and vanishing of a polynomial) in good bit complexity. Among the\ncritical points, those that are minimal---a property governed by inequalities\non the moduli of the coordinates---typically determine the dominant asymptotics\nof the diagonal coefficient sequence. When the Taylor expansion at the origin\nhas all non-negative coefficients (known as the `combinatorial case') and under\nregularity conditions, we utilize this Kronecker representation to determine\nprobabilistically the minimal critical points in complexity singly exponential\nin the degree of the denominator, with good control over the exponent in the\nbit complexity estimate. Generically in the combinatorial case, this allows one\nto automatically and rigorously determine asymptotics for the diagonal\ncoefficient sequence. Examples obtained with a preliminary implementation show\nthe wide applicability of this approach."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1605.00422v1", 
    "title": "Munchausen Iteration", 
    "arxiv-id": "1605.00422v1", 
    "author": "Sebastian Muskalla", 
    "publish": "2016-05-02T10:32:39Z", 
    "summary": "We present a method for solving polynomial equations over idempotent\nomega-continuous semirings. The idea is to iterate over the semiring of\nfunctions rather than the semiring of interest, and only evaluate when needed.\nThe key operation is substitution. In the initial step, we compute a linear\ncompletion of the system of equations that exhaustively inserts the equations\ninto one another. With functions as approximants, the following steps insert\nthe current approximant into itself. Since the iteration improves its precision\nby substitution rather than computation we named it Munchausen, after the\nfictional baron that pulled himself out of a swamp by his own hair. The first\nresult shows that an evaluation of the n-th Munchausen approximant coincides\nwith the 2^n-th Newton approximant. Second, we show how to compute linear\ncompletions with standard techniques from automata theory. In particular, we\nare not bound to (but can use) the notion of differentials prominent in Newton\niteration."
},{
    "category": "cs.MS", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1605.02532v2", 
    "title": "HLinear: Exact Dense Linear Algebra in Haskell", 
    "arxiv-id": "1605.02532v2", 
    "author": "Martin Westerholt-Raum", 
    "publish": "2016-05-09T11:24:39Z", 
    "summary": "We present an implementation in the functional programming language Haskell\nof the PLE decomposition of matrices over division rings. We discover in our\nbenchmarks that in a relevant number of cases it is significantly faster than\nthe C-based implementation provided in FLINT. Describing the guiding principles\nof our work, we introduce the reader to basic ideas from high performance\nfunctional programming."
},{
    "category": "cs.PL", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1605.02765v1", 
    "title": "Synthesizing Probabilistic Invariants via Doob's Decomposition", 
    "arxiv-id": "1605.02765v1", 
    "author": "Justin Hsu", 
    "publish": "2016-05-09T20:30:20Z", 
    "summary": "When analyzing probabilistic computations, a powerful approach is to first\nfind a martingale---an expression on the program variables whose expectation\nremains invariant---and then apply the optional stopping theorem in order to\ninfer properties at termination time. One of the main challenges, then, is to\nsystematically find martingales.\n  We propose a novel procedure to synthesize martingale expressions from an\narbitrary initial expression. Contrary to state-of-the-art approaches, we do\nnot rely on constraint solving. Instead, we use a symbolic construction based\non Doob's decomposition. This procedure can produce very complex martingales,\nexpressed in terms of conditional expectations.\n  We show how to automatically generate and simplify these martingales, as well\nas how to apply the optional stopping theorem to infer properties at\ntermination time. This last step typically involves some simplification steps,\nand is usually done manually in current approaches. We implement our techniques\nin a prototype tool and demonstrate our process on several classical examples.\nSome of them go beyond the capability of current semi-automatic approaches."
},{
    "category": "math.AG", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1605.06862v1", 
    "title": "Segmentation of real algebraic plane curves", 
    "arxiv-id": "1605.06862v1", 
    "author": "Manuel Dubinsky", 
    "publish": "2016-05-22T23:00:47Z", 
    "summary": "In this article we give an implementation of the standard algorithm to\nsegment a real algebraic plane curve defined implicitly. Our implementation is\nefficient and simpler than previous. We use global information to count the\nnumber of half-branches at a critical point."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1606.01140v1", 
    "title": "The Complexity of Computing all Subfields of an Algebraic Number Field", 
    "arxiv-id": "1606.01140v1", 
    "author": "Mark van Hoeij", 
    "publish": "2016-06-03T15:31:45Z", 
    "summary": "For a finite separable field extension K/k, all subfields can be obtained by\nintersecting so-called principal subfields of K/k. In this work we present a\nway to quickly compute these intersections. If the number of subfields is high,\nthen this leads to faster run times and an improved complexity."
},{
    "category": "cs.SC", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1606.01576v1", 
    "title": "Computing Hypergeometric Solutions of Second Order Linear Differential   Equations using Quotients of Formal Solutions and Integral Bases", 
    "arxiv-id": "1606.01576v1", 
    "author": "Mark van Hoeij", 
    "publish": "2016-06-05T22:41:58Z", 
    "summary": "We present two algorithms for computing hypergeometric solutions of second\norder linear differential operators with rational function coefficients. Our\nfirst algorithm searches for solutions of the form \\[ \\exp(\\int r \\,\ndx)\\cdot{_{2}F_1}(a_1,a_2;b_1;f) \\] where $r,f \\in \\overline{\\mathbb{Q}(x)}$,\nand $a_1,a_2,b_1 \\in \\mathbb{Q}$. It uses modular reduction and Hensel lifting.\nOur second algorithm tries to find solutions in the form \\[ \\exp(\\int r \\,\ndx)\\cdot \\left( r_0 \\cdot{_{2}F_1}(a_1,a_2;b_1;f) + r_1\n\\cdot{_{2}F_1}'(a_1,a_2;b_1;f) \\right) \\] where $r_0, r_1 \\in\n\\overline{\\mathbb{Q}(x)}$, as follows: It tries to transform the input equation\nto another equation with solutions of the first type, and then uses the first\nalgorithm."
},{
    "category": "math.CO", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1606.02982v3", 
    "title": "Hypergeometric Expressions for Generating Functions of Walks with Small   Steps in the Quarter Plane", 
    "arxiv-id": "1606.02982v3", 
    "author": "Lucien Pech", 
    "publish": "2016-06-09T14:56:04Z", 
    "summary": "We study nearest-neighbors walks on the two-dimensional square lattice, that\nis, models of walks on $\\mathbb{Z}^2$ defined by a fixed step set that is a\nsubset of the non-zero vectors with coordinates 0, 1 or $-1$. We concern\nourselves with the enumeration of such walks starting at the origin and\nconstrained to remain in the quarter plane $\\mathbb{N}^2$, counted by their\nlength and by the position of their ending point. Bousquet-M\\'elou and Mishna\n[Contemp. Math., pp. 1--39, Amer. Math. Soc., 2010] identified 19 models of\nwalks that possess a D-finite generating function; linear differential\nequations have then been guessed in these cases by Bostan and Kauers [FPSAC\n2009, Discrete Math. Theor. Comput. Sci. Proc., pp. 201--215, 2009]. We give\nhere the first proof that these equations are indeed satisfied by the\ncorresponding generating functions. As a first corollary, we prove that all\nthese 19 generating functions can be expressed in terms of Gauss'\nhypergeometric functions that are intimately related to elliptic integrals. As\na second corollary, we show that all the 19 generating functions are\ntranscendental, and that among their $19 \\times 4$ combinatorially meaningful\nspecializations only four are algebraic functions."
},{
    "category": "math.CO", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1606.07597v1", 
    "title": "Asymptotic and exact results on the complexity of the   Novelli--Pak--Stoyanovskii algorithm", 
    "arxiv-id": "1606.07597v1", 
    "author": "Robin Sulzgruber", 
    "publish": "2016-06-24T08:21:54Z", 
    "summary": "The Novelli--Pak--Stoyanovskii algorithm is a sorting algorithm for Young\ntableaux of a fixed shape that was originally devised to give a bijective proof\nof the hook-length formula. We obtain new asymptotic results on the average\ncase and worst case complexity of this algorithm as the underlying shape tends\nto a fixed limit curve. Furthermore, using the summation package Sigma we prove\nan exact formula for the average case complexity when the underlying shape\nconsists of only two rows. We thereby answer questions posed by Krattenthaler\nand M{\\\"u}ller."
},{
    "category": "math.AC", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1607.02135v1", 
    "title": "Finding binomials in polynomial ideals", 
    "arxiv-id": "1607.02135v1", 
    "author": "Lukas Katth\u00e4n", 
    "publish": "2016-07-07T19:56:31Z", 
    "summary": "We describe an algorithm which finds binomials in a given ideal\n$I\\subset\\mathbb{Q}[x_1,\\dots,x_n]$ and in particular decides whether binomials\nexist in $I$ at all. We demonstrate with several examples that binomials in\npolynomial ideals can be well hidden. For example, the lowest degree of a\nbinomial cannot be bounded as a function of the number of indeterminates, the\ndegree of the generators, or the Castelnuovo--Mumford regularity. We approach\nthe detection problem by reduction to the Artinian case using tropical\ngeometry. The Artinian case is solved with algorithms from computational number\ntheory."
},{
    "category": "cs.CR", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1607.03629v1", 
    "title": "Private Multi-party Matrix Multiplication and Trust Computations", 
    "arxiv-id": "1607.03629v1", 
    "author": "Maxime Puys", 
    "publish": "2016-07-13T08:03:57Z", 
    "summary": "This paper deals with distributed matrix multiplication. Each player owns\nonly one row of both matrices and wishes to learn about one distinct row of the\nproduct matrix, without revealing its input to the other players. We first\nimprove on a weighted average protocol, in order to securely compute a\ndot-product with a quadratic volume of communications and linear number of\nrounds. We also propose a protocol with five communication rounds, using a\nPaillier-like underlying homomorphic public key cryptosystem, which is secure\nin the semi-honest model or secure with high probability in the malicious\nadversary model. Using ProVerif, a cryptographic protocol verification tool, we\nare able to check the security of the protocol and provide a countermeasure for\neach attack found by the tool. We also give a randomization method to avoid\ncollusion attacks. As an application, we show that this protocol enables a\ndistributed and secure evaluation of trust relationships in a network, for a\nlarge class of trust evaluation schemes."
},{
    "category": "math.CO", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1607.05314v1", 
    "title": "Evaluation of binomial double sums involving absolute values", 
    "arxiv-id": "1607.05314v1", 
    "author": "Carsten Schneider", 
    "publish": "2016-07-18T20:25:16Z", 
    "summary": "We show that double sums of the form $$ \\sum_{i,j=-n} ^{n}\n|i^sj^t(i^k-j^k)^\\beta| \\binom {2n} {n+i} \\binom {2n} {n+j} $$ can always be\nexpressed in terms of a linear combination of just four functions, namely\n$\\binom {4n}{2n}$, ${\\binom {2n}n}^2$, $4^n\\binom {2n}n$, and $16^n$, with\ncoefficients that are rational in $n$. We provide two different proofs: one is\nalgorithmic and uses the second author's computer algebra package Sigma; the\nsecond is based on complex contour integrals."
},{
    "category": "cs.CC", 
    "doi": "10.1145/2930889.2930913", 
    "link": "http://arxiv.org/pdf/1607.05420v2", 
    "title": "Reconstruction Algorithms for Sums of Affine Powers", 
    "arxiv-id": "1607.05420v2", 
    "author": "Timoth\u00e9e Pecatte", 
    "publish": "2016-07-19T06:28:56Z", 
    "summary": "In this paper we study sums of powers of affine functions in (mostly) one\nvariable. Although quite simple, this model is a generalization of two\nwell-studied models: Waring decomposition and sparsest shift. For these three\nmodels there are natural extensions to several variables, but this paper is\nmostly focused on univariate polynomials. We present structural results which\ncompare the expressive power of the three models; and we propose algorithms\nthat find the smallest decomposition of f in the first model (sums of affine\npowers) for an input polynomial f given in dense representation. We also begin\na study of the multivariate case. This work could be extended in several\ndirections. In particular, just as for Sparsest Shift and Waring decomposition,\none could consider extensions to \"supersparse\" polynomials and attempt a fuller\nstudy of the multi-variate case. We also point out that the basic univariate\nproblem studied in the present paper is far from completely solved: our\nalgorithms all rely on some assumptions for the exponents in an optimal\ndecomposition, and some algorithms also rely on a distinctness assumption for\nthe shifts. It would be very interesting to weaken these assumptions, or even\nto remove them entirely. Another related and poorly understood issue is that of\nthe bit size of the constants appearing in an optimal decomposition: is it\nalways polynomially related to the bit size of the input polynomial given in\ndense representation?"
},{
    "category": "cs.SC", 
    "doi": "10.1145/3055282.3055285", 
    "link": "http://arxiv.org/pdf/1607.06945v1", 
    "title": "Satisfiability Checking and Symbolic Computation", 
    "arxiv-id": "1607.06945v1", 
    "author": "T. Sturm", 
    "publish": "2016-07-23T14:52:23Z", 
    "summary": "Symbolic Computation and Satisfiability Checking are viewed as individual\nresearch areas, but they share common interests in the development,\nimplementation and application of decision procedures for arithmetic theories.\nDespite these commonalities, the two communities are currently only weakly\nconnected. We introduce a new project SC-square to build a joint community in\nthis area, supported by a newly accepted EU (H2020-FETOPEN-CSA) project of the\nsame name. We aim to strengthen the connection between these communities by\ncreating common platforms, initiating interaction and exchange, identifying\ncommon challenges, and developing a common roadmap. This abstract and\naccompanying poster describes the motivation and aims for the project, and\nreports on the first activities."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-42547-4_3", 
    "link": "http://arxiv.org/pdf/1607.08028v1", 
    "title": "Satisfiability Checking meets Symbolic Computation (Project Paper)", 
    "arxiv-id": "1607.08028v1", 
    "author": "T. Sturm", 
    "publish": "2016-07-27T10:38:53Z", 
    "summary": "Symbolic Computation and Satisfiability Checking are two research areas, both\nhaving their individual scientific focus but sharing also common interests in\nthe development, implementation and application of decision procedures for\narithmetic theories. Despite their commonalities, the two communities are\nrather weakly connected. The aim of our newly accepted SC-square project\n(H2020-FETOPEN-CSA) is to strengthen the connection between these communities\nby creating common platforms, initiating interaction and exchange, identifying\ncommon challenges, and developing a common roadmap from theory along the way to\ntools and (industrial) applications. In this paper we report on the aims and on\nthe first activities of this project, and formalise some relevant challenges\nfor the unified SC-square community."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-319-42547-4_3", 
    "link": "http://arxiv.org/pdf/1608.00697v1", 
    "title": "Rational Solutions of Underdetermined Polynomial Equations", 
    "arxiv-id": "1608.00697v1", 
    "author": "Chimaobi Amadi", 
    "publish": "2016-08-02T05:13:54Z", 
    "summary": "In this paper we report on an application of computer algebra in which\nmathematical puzzles are generated of a type that had been widely used in\nmathematics contests by a large number of participants worldwide.\n  The algorithmic aspect of our work provides a method to compute rational\nsolutions of single polynomial equations that are typically large with $10^2\n\\ldots 10^5$ terms and that are heavily underdetermined. This functionality was\nobtained by adding modules for a new type of splitting of equations to the\nexisting package CRACK that is normally used to solve polynomial algebraic and\ndifferential systems."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2016.020", 
    "link": "http://arxiv.org/pdf/1608.04219v1", 
    "title": "Using Machine Learning to Decide When to Precondition Cylindrical   Algebraic Decomposition With Groebner Bases", 
    "arxiv-id": "1608.04219v1", 
    "author": "Lawrence C. Paulson", 
    "publish": "2016-08-15T09:44:29Z", 
    "summary": "Cylindrical Algebraic Decomposition (CAD) is a key tool in computational\nalgebraic geometry, particularly for quantifier elimination over real-closed\nfields. However, it can be expensive, with worst case complexity doubly\nexponential in the size of the input. Hence it is important to formulate the\nproblem in the best manner for the CAD algorithm. One possibility is to\nprecondition the input polynomials using Groebner Basis (GB) theory. Previous\nexperiments have shown that while this can often be very beneficial to the CAD\nalgorithm, for some problems it can significantly worsen the CAD performance.\n  In the present paper we investigate whether machine learning, specifically a\nsupport vector machine (SVM), may be used to identify those CAD problems which\nbenefit from GB preconditioning. We run experiments with over 1000 problems\n(many times larger than previous studies) and find that the machine learned\nchoice does better than the human-made heuristic."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2016.020", 
    "link": "http://arxiv.org/pdf/1608.06691v1", 
    "title": "Conversion Methods for Improving Structural Analysis of   Differential-Algebraic Equation Systems", 
    "arxiv-id": "1608.06691v1", 
    "author": "John D. Pryce", 
    "publish": "2016-08-24T02:20:55Z", 
    "summary": "Differential-algebraic equation systems (DAEs) are generated routinely by\nsimulation and modeling environments. Before a simulation starts and a\nnumerical method is applied, some kind of structural analysis (SA) is used to\ndetermine which equations to be differentiated, and how many times. Both\nPantelides's algorithm and Pryce's $\\Sigma$-method are equivalent: if one of\nthem finds correct structural information, the other does also. Nonsingularity\nof the Jacobian produced by SA indicates a success, which occurs on many\nproblems of interest. However, these methods can fail on simple, solvable DAEs\nand give incorrect structural information including the index. This article\ninvestigates $\\Sigma$-method's failures and presents two conversion methods for\nfixing them. Both methods convert a DAE on which the $\\Sigma$-method fails to\nan equivalent problem on which this SA is more likely to succeed."
},{
    "category": "cs.SC", 
    "doi": "10.1109/SYNASC.2016.020", 
    "link": "http://arxiv.org/pdf/1608.06693v1", 
    "title": "Conversion Methods, Block Triangularization, and Structural Analysis of   Differential-Algebraic Equation Systems", 
    "arxiv-id": "1608.06693v1", 
    "author": "John D. Pryce", 
    "publish": "2016-08-24T02:32:50Z", 
    "summary": "In a previous article, the authors developed two conversion methods to\nimprove the $\\Sigma$-method for structural analysis (SA) of\ndifferential-algebraic equations (DAEs). These methods reformulate a DAE on\nwhich the $\\Sigma$-method fails into an equivalent problem on which this SA is\nmore likely to succeed with a generically nonsingular Jacobian. The basic\nversion of these methods processes the DAE as a whole. This article presents\nthe block version that exploits block triangularization of a DAE. Using a block\ntriangular form of a Jacobian sparsity pattern, we identify which diagonal\nblocks of the Jacobian are identically singular and then perform a conversion\non each such block. This approach improves the efficiency of finding a suitable\nconversion for fixing SA's failures. All of our conversion methods can be\nimplemented in a computer algebra system so that every conversion can be\nautomated."
},{
    "category": "math.AG", 
    "doi": "10.1109/SYNASC.2016.020", 
    "link": "http://arxiv.org/pdf/1608.06828v2", 
    "title": "Efficient algorithms for computing the Euler-Poincar\u00e9 characteristic   of symmetric semi-algebraic sets", 
    "arxiv-id": "1608.06828v2", 
    "author": "Cordian Riener", 
    "publish": "2016-08-24T14:14:38Z", 
    "summary": "Let $\\mathrm{R}$ be a real closed field and $\\mathrm{D} \\subset \\mathrm{R}$\nan ordered domain. We consider the algorithmic problem of computing the\ngeneralized Euler-Poincar\\'e characteristic of real algebraic as well as\nsemi-algebraic subsets of $\\mathrm{R}^k$, which are defined by symmetric\npolynomials with coefficients in $\\mathrm{D}$. We give algorithms for computing\nthe generalized EulerPoincar\\'e characteristic of such sets, whose complexities\nmeasured by the number the number of arithmetic operations in $\\mathrm{D}$, are\npolynomially bounded in terms of $k$ and the number of polynomials in the\ninput, assuming that the degrees of the input polynomials are bounded by a\nconstant. This is in contrast to the best complexity of the known algorithms\nfor the same problems in the non-symmetric situation, which are singly\nexponential. This singly exponential complexity for the latter problem is\nunlikely to be improved because of hardness result ($\\#\\mathbf{P}$-hardness)\ncoming from discrete complexity theory."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.225", 
    "link": "http://arxiv.org/pdf/1609.03014v1", 
    "title": "Proceedings 9th International Workshop on Computing with Terms and   Graphs", 
    "arxiv-id": "1609.03014v1", 
    "author": "Hans Zantema", 
    "publish": "2016-09-10T08:38:13Z", 
    "summary": "This volume contains the proceedings of TERMGRAPH 2016, the Ninth\nInternational Workshop on Computing with Terms and Graphs which was held on\nApril 8, 2016 in Eindhoven, The Netherlands, as a satellite event of the\nEuropean Joint Conferences on Theory and Practice of Software (ETAPS 2016)."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.225", 
    "link": "http://arxiv.org/pdf/1609.09269v1", 
    "title": "Experience with Heuristics, Benchmarks & Standards for Cylindrical   Algebraic Decomposition", 
    "arxiv-id": "1609.09269v1", 
    "author": "James H. Davenport", 
    "publish": "2016-09-29T09:30:22Z", 
    "summary": "In the paper which inspired the SC-Square project, [E. Abraham, Building\nBridges between Symbolic Computation and Satisfiability Checking, Proc. ISSAC\n'15, pp. 1-6, ACM, 2015] the author identified the use of sophisticated\nheuristics as a technique that the Satisfiability Checking community excels in\nand from which it is likely the Symbolic Computation community could learn and\nprosper. To start this learning process we summarise our experience with\nheuristic development for the computer algebra algorithm Cylindrical Algebraic\nDecomposition. We also propose and discuss standards and benchmarks as another\narea where Symbolic Computation could prosper from Satisfiability Checking\nexpertise, noting that these have been identified as initial actions for the\nnew SC-Square community in the CSA project, as described in [E.~Abraham et al.,\nSC$^2$: Satisfiability Checking meets Symbolic Computation (Project Paper)},\nIntelligent Computer Mathematics (LNCS 9761), pp. 28--43, Springer, 2015]."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cagd.2017.01.002", 
    "link": "http://arxiv.org/pdf/1609.09760v2", 
    "title": "Algebraic and algorithmic aspects of radical parametrizations", 
    "arxiv-id": "1609.09760v2", 
    "author": "Carlos Villarino", 
    "publish": "2016-09-30T14:48:24Z", 
    "summary": "In this article algebraic constructions are introduced in order to study the\nvariety defined by a radical parametrization (a tuple of functions involving\ncomplex numbers, $n$ variables, the four field operations and radical\nextractions). We provide algorithms to implicitize radical parametrizations and\nto check whether a radical parametrization can be reparametrized into a\nrational parametrization."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.cagd.2017.01.002", 
    "link": "http://arxiv.org/pdf/1611.05901v2", 
    "title": "D-finite Numbers", 
    "arxiv-id": "1611.05901v2", 
    "author": "Manuel Kauers", 
    "publish": "2016-11-17T21:20:58Z", 
    "summary": "D-finite functions and P-recursive sequences are defined in terms of linear\ndifferential and recurrence equations with polynomial coefficients. In this\npaper, we introduce a class of numbers closely related to D-finite functions\nand P-recursive sequences. It consists of the limits of convergent P-recursive\nsequences. Typically, this class contains many well-known mathematical\nconstants in addition to the algebraic numbers. Our definition of the class of\nD-finite numbers depends on two subrings of the field of complex numbers. We\ninvestigate how difference choices of these two subrings affect the class.\nMoreover, we show that D-finite numbers over the Gaussian rational field are\nessentially the same as the values of D-finite functions at non-singular\nalgebraic number arguments. This result makes it easier to recognize certain\nnumbers as D-finite."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.cagd.2017.01.002", 
    "link": "http://arxiv.org/pdf/1611.07306v1", 
    "title": "Groebner Bases for Everyone with CoCoA-5 and CoCoALib", 
    "arxiv-id": "1611.07306v1", 
    "author": "Anna Maria Bigatti", 
    "publish": "2016-11-22T14:10:27Z", 
    "summary": "We present a survey on the developments on Groebner bases showing explicit\nexamples in CoCoA. The CoCoA project dates back to 1987: its aim was to create\na mathematician-friendly laboratory for studying Commutative Algebra, most\nespecially Groebner bases. Since then, always maintaining this \"friendly\"\ntradition, it has evolved and has been completely rewritten. CoCoA offers\nGroebner bases for all levels of interest: from the basic quick call in the\ninteractive system CoCoA-5, to problem-specific optimized implementations, to\nthe computer--computer communication with the open source C++ software library,\nCoCoALib, or the prototype OpenMath-based server. The openness and clean design\nof CoCoALib and CoCoA-5 are intended to offer different levels of usage, and to\nencourage external contributions."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2017.01.002", 
    "link": "http://arxiv.org/pdf/1612.02731v2", 
    "title": "Implementing Operational calculus on programming spaces for   Differentiable computing", 
    "arxiv-id": "1612.02731v2", 
    "author": "\u017diga Sajovic", 
    "publish": "2016-12-08T17:06:29Z", 
    "summary": "We provide an illustrative implementation of an analytic,\ninfinitely-differentiable virtual machine, implementing\ninfinitely-differentiable programming spaces and operators acting upon them, as\nconstructed in the paper Operational calculus on programming spaces.\nImplementation closely follows theorems and derivations of the paper, intended\nas an educational guide for those transitioning from automatic differentiation\nto this general theory."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2017.01.002", 
    "link": "http://arxiv.org/pdf/1612.05778v1", 
    "title": "Parallel Integer Polynomial Multiplication", 
    "arxiv-id": "1612.05778v1", 
    "author": "Yuzhen Xie", 
    "publish": "2016-12-17T14:54:52Z", 
    "summary": "We propose a new algorithm for multiplying dense polynomials with integer\ncoefficients in a parallel fashion, targeting multi-core processor\narchitectures. Complexity estimates and experimental comparisons demonstrate\nthe advantages of this new approach."
},{
    "category": "math.NT", 
    "doi": "10.1112/S1461157014000291", 
    "link": "http://arxiv.org/pdf/1612.09176v1", 
    "title": "Computing in quotients of rings of integers", 
    "arxiv-id": "1612.09176v1", 
    "author": "Claus Fieker", 
    "publish": "2016-12-29T15:45:01Z", 
    "summary": "We develop algorithms to turn quotients of rings of rings of integers into\neffective Euclidean rings by giving polynomial algorithms for all fundamental\nring operations. In addition, we study normal forms for modules over such rings\nand their behavior under certain quotients. We illustrate the power of our\nideas in a new modular normal form algorithm for modules over rings of\nintegers, vastly outperforming classical algorithms."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.jsc.2016.07.027", 
    "link": "http://arxiv.org/pdf/1612.09428v1", 
    "title": "On the computation of the HNF of a module over the ring of integers of a   number field", 
    "arxiv-id": "1612.09428v1", 
    "author": "Tommy Hofmann", 
    "publish": "2016-12-30T09:15:17Z", 
    "summary": "We present a variation of the modular algorithm for computing the Hermite\nnormal form of an $\\mathcal O_K$-module presented by Cohen, where $\\mathcal\nO_K$ is the ring of integers of a number field $K$. An approach presented in\n(Cohen 1996) based on reductions modulo ideals was conjectured to run in\npolynomial time by Cohen, but so far, no such proof was available in the\nliterature. In this paper, we present a modification of the approach of Cohen\nto prevent the coefficient swell and we rigorously assess its complexity with\nrespect to the size of the input and the invariants of the field $K$."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2016.07.027", 
    "link": "http://arxiv.org/pdf/1701.01994v1", 
    "title": "Computing Approximate Greatest Common Right Divisors of Differential   Polynomials", 
    "arxiv-id": "1701.01994v1", 
    "author": "Erich Kaltofen", 
    "publish": "2017-01-08T18:06:21Z", 
    "summary": "Differential (Ore) type polynomials with \"approximate\" polynomial\ncoefficients are introduced. These provide an effective notion of approximate\ndifferential operators, with a strong algebraic structure. We introduce the\napproximate Greatest Common Right Divisor Problem (GCRD) of differential\npolynomials, as a non-commutative generalization of the well-studied\napproximate GCD problem.\n  Given two differential polynomials, we present an algorithm to find nearby\ndifferential polynomials with a non-trivial GCRD, where nearby is defined with\nrespect to a suitable coefficient norm. Intuitively, given two linear\ndifferential polynomials as input, the (approximate) GCRD problem corresponds\nto finding the (approximate) differential polynomial whose solution space is\nthe intersection of the solution spaces of the two inputs.\n  The approximate GCRD problem is proven to be locally well-posed. A method\nbased on the singular value decomposition of a differential Sylvester matrix is\ndeveloped to produce an initial approximation of the GCRD. With a sufficiently\ngood initial approximation, Newton iteration is shown to converge quadratically\nto an optimal solution. Finally, sufficient conditions for existence of a\nsolution to the global problem are presented along with examples demonstrating\nthat no solution exists when these conditions are not satisfied."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2016.07.027", 
    "link": "http://arxiv.org/pdf/1701.08294v1", 
    "title": "A proof of Hilbert's theorem on ternary quartic forms with the ladder   technique", 
    "arxiv-id": "1701.08294v1", 
    "author": "Yong Yao", 
    "publish": "2017-01-28T15:43:32Z", 
    "summary": "This paper proposes a totally constructive approach for the proof of\nHilbert's theorem on ternary quartic forms. The main contribution is the ladder\ntechnique, with which the Hilbert's theorem is proved vividly."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.jsc.2016.07.027", 
    "link": "http://arxiv.org/pdf/1702.01653v1", 
    "title": "Characteristic polynomials of p-adic matrices", 
    "arxiv-id": "1702.01653v1", 
    "author": "Tristan Vaccon", 
    "publish": "2017-02-06T15:28:31Z", 
    "summary": "We analyze the precision of the characteristic polynomial of an $n\\times n$\np-adic matrix A using differential precision methods developed previously. When\nA is integral with precision O(p^N), we give a criterion (checkable in time\nO~(n^omega)) for $\\chi$(A) to have precision exactly O(p^N). We also give a\nO~(n^3) algorithm for determining the optimal precision when the criterion is\nnot satisfied, and give examples when the precision is larger than O(p^N)."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.01665v1", 
    "title": "Fast multiplication for skew polynomials", 
    "arxiv-id": "1702.01665v1", 
    "author": "J\u00e9r\u00e9my Le Borgne", 
    "publish": "2017-02-06T15:47:28Z", 
    "summary": "We describe an algorithm for fast multiplication of skew polynomials. It is\nbased on fast modular multiplication of such skew polynomials, for which we\ngive an algorithm relying on evaluation and interpolation on normal bases. Our\nalgorithms improve the best known complexity for these problems, and reach the\noptimal asymptotic complexity bound for large degree. We also give an\nadaptation of our algorithm for polynomials of small degree. Finally, we use\nour methods to improve on the best known complexities for various arithmetics\nproblems."
},{
    "category": "math.CA", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.03829v2", 
    "title": "Algorithmic Verification of Linearizability for Ordinary Differential   Equations", 
    "arxiv-id": "1702.03829v2", 
    "author": "Dominik Michels", 
    "publish": "2017-02-13T15:42:19Z", 
    "summary": "For a nonlinear ordinary differential equation solved with respect to the\nhighest order derivative and rational in the other derivatives and in the\nindependent variable, we devise two algorithms to check if the equation can be\nreduced to a linear one by a point transformation of the dependent and\nindependent variables. The first algorithm is based on a construction of the\nLie point symmetry algebra and on the computation of its derived algebra. The\nsecond algorithm exploits the differential Thomas decomposition and allows not\nonly to test the linearizability, but also to generate a system of nonlinear\npartial differential equations that determines the point transformation and the\ncoefficients of the linearized equation. Both algorithms have been implemented\nin Maple and their application is illustrated using several examples."
},{
    "category": "cs.NA", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.04274v1", 
    "title": "Hybrid System Modelling and Simulation with Dirac Deltas", 
    "arxiv-id": "1702.04274v1", 
    "author": "Hans Vangheluwe", 
    "publish": "2017-02-14T16:04:20Z", 
    "summary": "For a wide variety of problems, creating detailed continuous models of\n(continuous) physical systems is, at the very least, impractical. Hybrid models\ncan abstract away short transient behaviour (thus introducing discontinuities)\nin order to simplify the study of such systems. For example, when modelling a\nbouncing ball, the bounce can be abstracted as a discontinuous change of the\nvelocity, instead of resorting to the physics of the ball (de-)compression to\nkeep the velocity signal continuous. Impulsive differential equations can be\nused to model and simulate hybrid systems such as the bouncing ball. In this\napproach, the force acted on the ball by the floor is abstracted as an\ninfinitely large function in an infinitely small interval of time, that is, an\nimpulse. Current simulators cannot handle such approximations well due to the\nlimitations of machine precision.\n  In this paper, we explore the simulation of impulsive differential equations,\nwhere impulses are first class citizens. We present two approaches for the\nsimulation of impulses: symbolic and numerical. Our contribution is a\ntheoretically founded description of the implementation of both approaches in a\nCausal Block Diagram modelling and simulation tool. Furthermore, we investigate\nthe conditions for which one approach is better than the other."
},{
    "category": "math.AG", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.06920v1", 
    "title": "Bad Primes in Computational Algebraic Geometry", 
    "arxiv-id": "1702.06920v1", 
    "author": "Gerhard Pfister", 
    "publish": "2017-02-22T18:03:38Z", 
    "summary": "Computations over the rational numbers often suffer from intermediate\ncoefficient swell. One solution to this problem is to apply the given algorithm\nmodulo a number of primes and then lift the modular results to the rationals.\nThis method is guaranteed to work if we use a sufficiently large set of good\nprimes. In many applications, however, there is no efficient way of excluding\nbad primes. In this note, we describe a technique for rational reconstruction\nwhich will nevertheless return the correct result, provided the number of good\nprimes in the selected set of primes is large enough. We give a number of\nillustrating examples which are implemented using the computer algebra system\nSingular and the programming language Julia. We discuss applications of our\ntechnique in computational algebraic geometry."
},{
    "category": "math.AC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.07262v1", 
    "title": "Computing and Using Minimal Polynomials", 
    "arxiv-id": "1702.07262v1", 
    "author": "Lorenzo Robbiano", 
    "publish": "2017-02-23T15:34:29Z", 
    "summary": "Given a zero-dimensional ideal I in a polynomial ring, many computations\nstart by finding univariate polynomials in I. Searching for a univariate\npolynomial in I is a particular case of considering the minimal polynomial of\nan element in P/I. It is well known that minimal polynomials may be computed\nvia elimination, therefore this is considered to be a \"resolved problem\". But\nbeing the key of so many computations, it is worth investigating its meaning,\nits optimization, its applications."
},{
    "category": "math.CA", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.07911v1", 
    "title": "The natural algorithmic approach of mixed trigonometric-polynomial   problems", 
    "arxiv-id": "1702.07911v1", 
    "author": "Cristinel Mortici", 
    "publish": "2017-02-25T16:02:45Z", 
    "summary": "The aim of this paper is to present a new algorithm for proving mixed\ntrigonometric-polynomial inequalities by reducing to polynomial inequalities.\nFinally, we show the great applicability of this algorithm and as examples, we\nuse it to analyze some new rational (Pade) approximations of the function\n$\\cos^2(x)$, and to improve a class of inequalities by Z.-H. Yang. The results\nof our analysis could be implemented by means of an automated proof assistant,\nso our work is a contribution to the library of automatic support tools for\nproving various analytic inequalities."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1702.08114v1", 
    "title": "Faster Tensor Canonicalization", 
    "arxiv-id": "1702.08114v1", 
    "author": "Benjamin E. Niehoff", 
    "publish": "2017-02-27T00:21:38Z", 
    "summary": "The Butler-Portugal algorithm for obtaining the canonical form of a tensor\nexpression with respect to slot symmetries and dummy-index renaming suffers, in\ncertain cases with a high degree of symmetry, from $O(n!)$ explosion in both\ncomputation time and memory. We present a modified algorithm which alleviates\nthis problem in the most common cases---tensor expressions with subsets of\nindices which are totally symmetric or totally antisymmetric---in polynomial\ntime. We also present an implementation of the label-renaming mechanism which\nimproves upon that of the original Butler-Portugal algorithm, thus providing a\nsignificant speed increase for the average case as well as the highly-symmetric\nspecial case. The worst-case behavior remains $O(n!)$, although it occurs in\nmore limited situations unlikely to appear in actual computations. We comment\non possible strategies to take if the nature of a computation should make these\nsituations more likely."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1703.00640v1", 
    "title": "Faster truncated integer multiplication", 
    "arxiv-id": "1703.00640v1", 
    "author": "David Harvey", 
    "publish": "2017-03-02T07:12:12Z", 
    "summary": "We present new algorithms for computing the low n bits or the high n bits of\nthe product of two n-bit integers. We show that these problems may be solved in\nasymptotically 75% of the time required to compute the full 2n-bit product,\nassuming that the underlying integer multiplication algorithm relies on\ncomputing cyclic convolutions of real sequences."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1703.03734v1", 
    "title": "On matrices with displacement structure: generalized operators and   faster algorithms", 
    "arxiv-id": "1703.03734v1", 
    "author": "\u00c9ric Schost", 
    "publish": "2017-03-10T16:03:26Z", 
    "summary": "For matrices with displacement structure, basic operations like\nmultiplication, inversion, and linear system solving can all be expressed in\nterms of the following task: evaluate the product $\\mathsf{A}\\mathsf{B}$, where\n$\\mathsf{A}$ is a structured $n \\times n$ matrix of displacement rank $\\alpha$,\nand $\\mathsf{B}$ is an arbitrary $n\\times\\alpha$ matrix. Given $\\mathsf{B}$ and\na so-called \"generator\" of $\\mathsf{A}$, this product is classically computed\nwith a cost ranging from $O(\\alpha^2 \\mathscr{M}(n))$ to $O(\\alpha^2\n\\mathscr{M}(n)\\log(n))$ arithmetic operations, depending on the type of\nstructure of $\\mathsf{A}$; here, $\\mathscr{M}$ is a cost function for\npolynomial multiplication. In this paper, we first generalize classical\ndisplacement operators, based on block diagonal matrices with companion\ndiagonal blocks, and then design fast algorithms to perform the task above for\nthis extended class of structured matrices. The cost of these algorithms ranges\nfrom $O(\\alpha^{\\omega-1} \\mathscr{M}(n))$ to $O(\\alpha^{\\omega-1}\n\\mathscr{M}(n)\\log(n))$, with $\\omega$ such that two $n \\times n$ matrices over\na field can be multiplied using $O(n^\\omega)$ field operations. By combining\nthis result with classical randomized regularization techniques, we obtain\nfaster Las Vegas algorithms for structured inversion and linear system solving."
},{
    "category": "cs.CV", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1703.05289v1", 
    "title": "A clever elimination strategy for efficient minimal solvers", 
    "arxiv-id": "1703.05289v1", 
    "author": "Tomas Pajdla", 
    "publish": "2017-03-15T17:44:37Z", 
    "summary": "We present a new insight into the systematic generation of minimal solvers in\ncomputer vision, which leads to smaller and faster solvers. Many minimal\nproblem formulations are coupled sets of linear and polynomial equations where\nimage measurements enter the linear equations only. We show that it is useful\nto solve such systems by first eliminating all the unknowns that do not appear\nin the linear equations and then extending solutions to the rest of unknowns.\nThis can be generalized to fully non-linear systems by linearization via\nlifting. We demonstrate that this approach leads to more efficient solvers in\nthree problems of partially calibrated relative camera pose computation with\nunknown focal length and/or radial distortion. Our approach also generates new\ninteresting constraints on the fundamental matrices of partially calibrated\ncameras, which were not known before."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/1703.05580v1", 
    "title": "Ultimate Positivity of Diagonals of Quasi-rational Functions", 
    "arxiv-id": "1703.05580v1", 
    "author": "Hui Huang", 
    "publish": "2017-03-16T12:21:51Z", 
    "summary": "The problem to decide whether a given multivariate (quasi-)rational function\nhas only positive coefficients in its power series expansion has a long\nhistory. It dates back to Szego in 1933 who showed certain quasi-rational\nfunction to be positive, in the sense that all the series coefficients are\npositive, using an involved theory of special functions. In contrast to the\nsimplicity of the statement, the method was surprisingly difficult. This\ndependency motivated further research for positivity of (quasi-)rational\nfunctions. More and more (quasi-)rational functions have been proven to be\npositive, and some of the proofs are even quite simple. However, there are also\nothers whose positivity are still open conjectures. In this talk, we focus on a\nless difficult but also interesting question to decide whether the diagonal of\na given quasi-rational function is ultimately positive, especially for the one\nconjectured to be positive by Kauers in 2007. To solve this question, it\nsuffices to compute the asymptotics of the diagonal coefficients, which can be\ndone by the multivariate singularity analysis developed by Baryshnikov,\nPemantle and Wilson. Note that the ultimate positivity is a necessary condition\nfor the positivity, and therefore can be used to either exclude the nonpositive\ncases or further support the conjectural positivity."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/9811002v1", 
    "title": "Factorization of linear partial differential operators and Darboux   integrability of nonlinear PDEs", 
    "arxiv-id": "cs/9811002v1", 
    "author": "Serguei P. Tsarev", 
    "publish": "1998-10-31T09:09:05Z", 
    "summary": "Using a new definition of generalized divisors we prove that the lattice of\nsuch divisors for a given linear partial differential operator is modular and\nobtain analogues of the well-known theorems of the Loewy-Ore theory of\nfactorization of linear ordinary differential operators. Possible applications\nto factorized Groebner bases computations in the commutative and\nnon-commutative cases are discussed, an application to finding criterions of\nDarboux integrability of nonlinear PDEs is given."
},{
    "category": "cs.SE", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/9906029v2", 
    "title": "Events in Property Patterns", 
    "arxiv-id": "cs/9906029v2", 
    "author": "D. Paun", 
    "publish": "1999-06-28T17:06:51Z", 
    "summary": "A pattern-based approach to the presentation, codification and reuse of\nproperty specifications for finite-state verification was proposed by Dwyer and\nhis collegues. The patterns enable non-experts to read and write formal\nspecifications for realistic systems and facilitate easy conversion of\nspecifications between formalisms, such as LTL, CTL, QRE. In this paper, we\nextend the pattern system with events - changes of values of variables in the\ncontext of LTL."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0004015v2", 
    "title": "Introduction to the GiNaC Framework for Symbolic Computation within the   C++ Programming Language", 
    "arxiv-id": "cs/0004015v2", 
    "author": "Richard Kreckel", 
    "publish": "2000-04-27T10:30:58Z", 
    "summary": "The traditional split-up into a low level language and a high level language\nin the design of computer algebra systems may become obsolete with the advent\nof more versatile computer languages. We describe GiNaC, a special-purpose\nsystem that deliberately denies the need for such a distinction. It is entirely\nwritten in C++ and the user can interact with it directly in that language. It\nwas designed to provide efficient handling of multivariate polynomials,\nalgebras and special functions that are needed for loop calculations in\ntheoretical quantum field theory. It also bears some potential to become a more\ngeneral purpose symbolic package."
},{
    "category": "cs.PL", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0011008v1", 
    "title": "A Lambda-Calculus with letrec, case, constructors and non-determinism", 
    "arxiv-id": "cs/0011008v1", 
    "author": "Michael Huber", 
    "publish": "2000-11-06T14:52:33Z", 
    "summary": "A non-deterministic call-by-need lambda-calculus \\calc with case,\nconstructors, letrec and a (non-deterministic) erratic choice, based on\nrewriting rules is investigated. A standard reduction is defined as a variant\nof left-most outermost reduction. The semantics is defined by contextual\nequivalence of expressions instead of using $\\alpha\\beta(\\eta)$-equivalence. It\nis shown that several program transformations are correct, for example all\n(deterministic) rules of the calculus, and in addition the rules for garbage\ncollection, removing indirections and unique copy.\n  This shows that the combination of a context lemma and a meta-rewriting on\nreductions using complete sets of commuting (forking, resp.) diagrams is a\nuseful and successful method for providing a semantics of a functional\nprogramming language and proving correctness of program transformations."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0011043v1", 
    "title": "Rewriting Calculus: Foundations and Applications", 
    "arxiv-id": "cs/0011043v1", 
    "author": "Horatiu Cirstea", 
    "publish": "2000-11-28T15:01:07Z", 
    "summary": "This thesis is devoted to the study of a calculus that describes the\napplication of conditional rewriting rules and the obtained results at the same\nlevel of representation. We introduce the rewriting calculus, also called the\nrho-calculus, which generalizes the first order term rewriting and\nlambda-calculus, and makes possible the representation of the non-determinism.\nIn our approach the abstraction operator as well as the application operator\nare objects of calculus. The result of a reduction in the rewriting calculus is\neither an empty set representing the application failure, or a singleton\nrepresenting a deterministic result, or a set having several elements\nrepresenting a not-deterministic choice of results.\n  In this thesis we concentrate on the properties of the rewriting calculus\nwhere a syntactic matching is used in order to bind the variables to their\ncurrent values. We define evaluation strategies ensuring the confluence of the\ncalculus and we show that these strategies become trivial for restrictions of\nthe general rewriting calculus to simpler calculi like the lambda-calculus. The\nrewriting calculus is not terminating in the untyped case but the strong\nnormalization is obtained for the simply typed calculus.\n  In the rewriting calculus extended with an operator allowing to test the\napplication failure we define terms representing innermost and outermost\nnormalizations with respect to a set of rewriting rules. By using these terms,\nwe obtain a natural and concise description of the conditional rewriting.\nFinally, starting from the representation of the conditional rewriting rules,\nwe show how the rewriting calculus can be used to give a semantics to ELAN, a\nlanguage based on the application of rewriting rules controlled by strategies."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0105033v1", 
    "title": "Lectures on Reduce and Maple at UAM I - Mexico", 
    "arxiv-id": "cs/0105033v1", 
    "author": "Marc Toussaint", 
    "publish": "2001-05-25T15:08:13Z", 
    "summary": "These lectures give a brief introduction to the Computer Algebra systems\nReduce and Maple. The aim is to provide a systematic survey of most important\ncommands and concepts. In particular, this includes a discussion of\nsimplification schemes and the handling of simplification and substitution\nrules (e.g., a Lie Algebra is implemented in Reduce by means of simplification\nrules).\n  Another emphasis is on the different implementations of tensor calculi and\nthe exterior calculus by Reduce and Maple and their application in Gravitation\ntheory and Differential Geometry.\n  I held the lectures at the Universidad Autonoma Metropolitana-Iztapalapa,\nDepartamento de Fisica, Mexico, in November 1999."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0106013v1", 
    "title": "The Set of Equations to Evaluate Objects", 
    "arxiv-id": "cs/0106013v1", 
    "author": "Larissa Ismailova", 
    "publish": "2001-06-08T09:28:46Z", 
    "summary": "The notion of an equational shell is studied to involve the objects and their\nenvironment. Appropriate methods are studied as valid embeddings of refined\nobjects. The refinement process determines the linkages between the variety of\npossible representations giving rise to variants of computations. The case\nstudy is equipped with the adjusted equational systems that validate the\ninitial applicative framework."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0107036v2", 
    "title": "TeXmacs interfaces to Maxima, MuPAD and REDUCE", 
    "arxiv-id": "cs/0107036v2", 
    "author": "A. G. Grozin", 
    "publish": "2001-07-29T11:00:59Z", 
    "summary": "GNU TeXmacs is a free wysiwyg word processor providing an excellent\ntypesetting quality of texts and formulae. It can also be used as an interface\nto Computer Algebra Systems (CASs). In the present work, interfaces to three\ngeneral-purpose CASs have been implemented."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0110023v2", 
    "title": "Set Unification", 
    "arxiv-id": "cs/0110023v2", 
    "author": "Gianfranco Rossi", 
    "publish": "2001-10-09T10:57:56Z", 
    "summary": "The unification problem in algebras capable of describing sets has been\ntackled, directly or indirectly, by many researchers and it finds important\napplications in various research areas--e.g., deductive databases, theorem\nproving, static analysis, rapid software prototyping. The various solutions\nproposed are spread across a large literature. In this paper we provide a\nuniform presentation of unification of sets, formalizing it at the level of set\ntheory. We address the problem of deciding existence of solutions at an\nabstract level. This provides also the ability to classify different types of\nset unification problems. Unification algorithms are uniformly proposed to\nsolve the unification problem in each of such classes.\n  The algorithms presented are partly drawn from the literature--and properly\nrevisited and analyzed--and partly novel proposals. In particular, we present a\nnew goal-driven algorithm for general ACI1 unification and a new simpler\nalgorithm for general (Ab)(Cl) unification."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0301027v2", 
    "title": "A comparison of four approaches to the calculation of conservation laws", 
    "arxiv-id": "cs/0301027v2", 
    "author": "Thomas Wolf", 
    "publish": "2003-01-25T04:42:12Z", 
    "summary": "The paper compares computational aspects of four approaches to compute\nconservation laws of single differential equations (DEs) or systems of them,\nODEs and PDEs. The only restriction, required by two of the four corresponding\ncomputer algebra programs, is that each DE has to be solvable for a leading\nderivative. Extra constraints for the conservation laws can be specified.\nExamples include new conservation laws that are non-polynomial in the\nfunctions, that have an explicit variable dependence and families of\nconservation laws involving arbitrary functions. The following equations are\ninvestigated in examples: Ito, Liouville, Burgers, Kadomtsev-Petviashvili,\nKarney-Sen-Chu-Verheest, Boussinesq, Tzetzeica, Benney."
},{
    "category": "cs.PL", 
    "doi": "10.1145/1235", 
    "link": "http://arxiv.org/pdf/cs/0309045v1", 
    "title": "A uniform approach to constraint-solving for lists, multisets, compact   lists, and sets", 
    "arxiv-id": "cs/0309045v1", 
    "author": "Gianfranco Rossi", 
    "publish": "2003-09-24T10:08:00Z", 
    "summary": "Lists, multisets, and sets are well-known data structures whose usefulness is\nwidely recognized in various areas of Computer Science. These data structures\nhave been analyzed from an axiomatic point of view with a parametric approach\nin (*) where the relevant unification algorithms have been developed. In this\npaper we extend these results considering more general constraints including\nnot only equality but also membership constraints as well as their negative\ncounterparts.\n  (*) A. Dovier, A. Policriti, and G. Rossi. A uniform axiomatic view of lists,\nmultisets, and sets, and the relevant unification algorithms. Fundamenta\nInformaticae, 36(2/3):201--234, 1998."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0403008v3", 
    "title": "Polynomial-time computing over quadratic maps I: sampling in real   algebraic sets", 
    "arxiv-id": "cs/0403008v3", 
    "author": "Dmitrii V. Pasechnik", 
    "publish": "2004-03-06T08:20:38Z", 
    "summary": "Given a quadratic map Q : K^n -> K^k defined over a computable subring D of a\nreal closed field K, and a polynomial p(Y_1,...,Y_k) of degree d, we consider\nthe zero set Z=Z(p(Q(X)),K^n) of the polynomial p(Q(X_1,...,X_n)). We present a\nprocedure that computes, in (dn)^O(k) arithmetic operations in D, a set S of\n(real univariate representations of) sampling points in K^n that intersects\nnontrivially each connected component of Z. As soon as k=o(n), this is faster\nthan the standard methods that all have exponential dependence on n in the\ncomplexity. In particular, our procedure is polynomial-time for constant k. In\ncontrast, the best previously known procedure (due to A.Barvinok) is only\ncapable of deciding in n^O(k^2) operations the nonemptiness (rather than\nconstructing sampling points) of the set Z in the case of p(Y)=sum_i Y_i^2 and\nhomogeneous Q.\n  A by-product of our procedure is a bound (dn)^O(k) on the number of connected\ncomponents of Z.\n  The procedure consists of exact symbolic computations in D and outputs\nvectors of algebraic numbers. It involves extending K by infinitesimals and\nsubsequent limit computation by a novel procedure that utilizes knowledge of an\nexplicit isomorphism between real algebraic sets."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0407066v1", 
    "title": "ParFORM: Parallel Version of the Symbolic Manipulation Program FORM", 
    "arxiv-id": "cs/0407066v1", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2004-07-30T10:06:16Z", 
    "summary": "After an introduction to the sequential version of FORM and the mechanisms\nbehind, we report on the status of our project of parallelization. We have now\na parallel version of FORM running on Cluster- and SMP-architectures. This\nversion can be used to run arbitrary FORM programs in parallel."
},{
    "category": "cs.MS", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0410044v5", 
    "title": "An Example of Clifford Algebras Calculations with GiNaC", 
    "arxiv-id": "cs/0410044v5", 
    "author": "Vladimir V. Kisil", 
    "publish": "2004-10-18T17:39:51Z", 
    "summary": "This example of Clifford algebras calculations uses GiNaC\n(http://www.ginac.de/) library, which includes a support for generic Clifford\nalgebra starting from version~1.3.0. Both symbolic and numeric calculation are\npossible and can be blended with other functions of GiNaC. This calculations\nwas made for the paper math.CV/0410399.\n  Described features of GiNaC are already available at PyGiNaC\n(http://sourceforge.net/projects/pyginac/) and due to course should propagate\ninto other software like GNU Octave (http://www.octave.org/), gTybalt\n(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as\ntheir back-end."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0412061v1", 
    "title": "Free quasi-symmetric functions, product actions and quantum field theory   of partitions", 
    "arxiv-id": "cs/0412061v1", 
    "author": "Christophe Tollu", 
    "publish": "2004-12-13T19:37:11Z", 
    "summary": "We examine two associative products over the ring of symmetric functions\nrelated to the intransitive and Cartesian products of permutation groups. As an\napplication, we give an enumeration of some Feynman type diagrams arising in\nBender's QFT of partitions. We end by exploring possibilities to construct\nnoncommutative analogues."
},{
    "category": "cs.CG", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0501003v1", 
    "title": "Implementation of Motzkin-Burger algorithm in Maple", 
    "arxiv-id": "cs/0501003v1", 
    "author": "P. A. Burovsky", 
    "publish": "2005-01-01T04:55:40Z", 
    "summary": "Subject of this paper is an implementation of a well-known Motzkin-Burger\nalgorithm, which solves the problem of finding the full set of solutions of a\nsystem of linear homogeneous inequalities. There exist a number of\nimplementations of this algorithm, but there was no one in Maple, to the best\nof the author's knowledge."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0501030v1", 
    "title": "Generalized Laplace transformations and integration of hyperbolic   systems of linear partial differential equations", 
    "arxiv-id": "cs/0501030v1", 
    "author": "Sergey P. Tsarev", 
    "publish": "2005-01-15T15:57:19Z", 
    "summary": "We give a new procedure for generalized factorization and construction of the\ncomplete solution of strictly hyperbolic linear partial differential equations\nor strictly hyperbolic systems of such equations in the plane. This procedure\ngeneralizes the classical theory of Laplace transformations of second-order\nequations in the plane."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0503008v1", 
    "title": "Approximation of dynamical systems using S-systems theory : application   to biological systems", 
    "arxiv-id": "cs/0503008v1", 
    "author": "Laurent Tournier", 
    "publish": "2005-03-03T06:32:17Z", 
    "summary": "In this paper we propose a new symbolic-numeric algorithm to find positive\nequilibria of a n-dimensional dynamical system. This algorithm implies a\nsymbolic manipulation of ODE in order to give a local approximation of\ndifferential equations with power-law dynamics (S-systems). A numerical\ncalculus is then needed to converge towards an equilibrium, giving at the same\ntime a S-system approximating the initial system around this equilibrium. This\nalgorithm is applied to a real biological example in 14 dimensions which is a\nsubsystem of a metabolic pathway in Arabidopsis Thaliana."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0504039v1", 
    "title": "TeXmacs-maxima interface", 
    "arxiv-id": "cs/0504039v1", 
    "author": "A. G. Grozin", 
    "publish": "2005-04-11T16:39:16Z", 
    "summary": "This tutorial presents features of the new and improved TeXmacs-maxima\ninterface. It is designed for running maxima-5.9.2 from TeXmacs-1.0.5 (or\nlater)."
},{
    "category": "cs.AI", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0509025v3", 
    "title": "A formally verified proof of the prime number theorem", 
    "arxiv-id": "cs/0509025v3", 
    "author": "Paul Raff", 
    "publish": "2005-09-09T15:47:35Z", 
    "summary": "The prime number theorem, established by Hadamard and de la Vall'ee Poussin\nindependently in 1896, asserts that the density of primes in the positive\nintegers is asymptotic to 1 / ln x. Whereas their proofs made serious use of\nthe methods of complex analysis, elementary proofs were provided by Selberg and\nErd\"os in 1948. We describe a formally verified version of Selberg's proof,\nobtained using the Isabelle proof assistant."
},{
    "category": "cs.PL", 
    "doi": "10.1007/s00037-005-0189-7", 
    "link": "http://arxiv.org/pdf/cs/0512067v1", 
    "title": "Solving Partial Order Constraints for LPO Termination", 
    "arxiv-id": "cs/0512067v1", 
    "author": "Peter J. Stuckey", 
    "publish": "2005-12-16T01:28:25Z", 
    "summary": "This paper introduces a new kind of propositional encoding for reasoning\nabout partial orders. The symbols in an unspecified partial order are viewed as\nvariables which take integer values and are interpreted as indices in the\norder. For a partial order statement on n symbols each index is represented in\nlog2 n propositional variables and partial order constraints between symbols\nare modeled on the bit representations. We illustrate the application of our\napproach to determine LPO termination for term rewrite systems. Experimental\nresults are unequivocal, indicating orders of magnitude speedups in comparison\nwith current implementations for LPO termination. The proposed encoding is\ngeneral and relevant to other applications which involve propositional\nreasoning about partial orders."
},{
    "category": "cs.MS", 
    "doi": "10.1007/s00006-006-0017-4", 
    "link": "http://arxiv.org/pdf/cs/0512073v12", 
    "title": "Schwerdtfeger-Fillmore-Springer-Cnops Construction Implemented in GiNaC", 
    "arxiv-id": "cs/0512073v12", 
    "author": "Vladimir V. Kisil", 
    "publish": "2005-12-17T15:09:11Z", 
    "summary": "This paper presents an implementation of the\nSchwerdtfeger-Fillmore-Springer-Cnops construction (SFSCc) along with\nillustrations of its usage. SFSCc linearises the linear-fraction action of the\nMoebius group in R^n. This has clear advantages in several theoretical and\napplied fields including engineering. Our implementation is based on the\nClifford algebra capacities of the GiNaC computer algebra system\n(http://www.ginac.de/), which were described in cs.MS/0410044.\n  The core of this realisation of SFSCc is done for an arbitrary dimension of\nR^n with a metric given by an arbitrary bilinear form. We also present a\nsubclass for two dimensional cycles (i.e. circles, parabolas and hyperbolas),\nwhich add some 2D specific routines including a visualisation to PostScript\nfiles through the MetaPost (http://www.tug.org/metapost.html) or Asymptote\n(http://asymptote.sourceforge.net/) packages.\n  This software is the backbone of many results published in math.CV/0512416\nand we use its applications their for demonstration. The library can be ported\n(with various level of required changes) to other CAS with Clifford algebras\ncapabilities similar to GiNaC.\n  There is an ISO image of a Live Debian DVD attached to this paper as an\nauxiliary file, a copy is stored on Google Drive as well."
},{
    "category": "cs.AI", 
    "doi": "10.1007/s00006-006-0017-4", 
    "link": "http://arxiv.org/pdf/cs/0601051v2", 
    "title": "A Constructive Semantic Characterization of Aggregates in ASP", 
    "arxiv-id": "cs/0601051v2", 
    "author": "Enrico Pontelli", 
    "publish": "2006-01-13T16:09:36Z", 
    "summary": "This technical note describes a monotone and continuous fixpoint operator to\ncompute the answer sets of programs with aggregates. The fixpoint operator\nrelies on the notion of aggregate solution. Under certain conditions, this\noperator behaves identically to the three-valued immediate consequence operator\n$\\Phi^{aggr}_P$ for aggregate programs, independently proposed Pelov et al.\nThis operator allows us to closely tie the computational complexity of the\nanswer set checking and answer sets existence problems to the cost of checking\na solution of the aggregates in the program. Finally, we relate the semantics\ndescribed by the operator to other proposals for logic programming with\naggregates.\n  To appear in Theory and Practice of Logic Programming (TPLP)."
},{
    "category": "cs.NA", 
    "doi": "10.1007/s00006-006-0017-4", 
    "link": "http://arxiv.org/pdf/cs/0601104v2", 
    "title": "The complexity of class polynomial computation via floating point   approximations", 
    "arxiv-id": "cs/0601104v2", 
    "author": "Andreas Enge", 
    "publish": "2006-01-24T11:01:46Z", 
    "summary": "We analyse the complexity of computing class polynomials, that are an\nimportant ingredient for CM constructions of elliptic curves, via complex\nfloating point approximations of their roots. The heart of the algorithm is the\nevaluation of modular functions in several arguments. The fastest one of the\npresented approaches uses a technique devised by Dupont to evaluate modular\nfunctions by Newton iterations on an expression involving the\narithmetic-geometric mean. It runs in time $O (|D| \\log^5 |D| \\log \\log |D|) =\nO (|D|^{1 + \\epsilon}) = O (h^{2 + \\epsilon})$ for any $\\epsilon > 0$, where\n$D$ is the CM discriminant and $h$ is the degree of the class polynomial.\nAnother fast algorithm uses multipoint evaluation techniques known from\nsymbolic computation; its asymptotic complexity is worse by a factor of $\\log\n|D|$. Up to logarithmic factors, this running time matches the size of the\nconstructed polynomials. The estimate also relies on a new result concerning\nthe complexity of enumerating the class group of an imaginary-quadratic order\nand on a rigorously proven upper bound for the height of class polynomials."
},{
    "category": "cs.DC", 
    "doi": "10.1007/s00006-006-0017-4", 
    "link": "http://arxiv.org/pdf/cs/0602068v1", 
    "title": "Parallel Symbolic Computation of Curvature Invariants in General   Relativity", 
    "arxiv-id": "cs/0602068v1", 
    "author": "K. R. Koehler", 
    "publish": "2006-02-19T19:28:44Z", 
    "summary": "We present a practical application of parallel symbolic computation in\nGeneral Relativity: the calculation of curvature invariants for large\ndimension. We discuss the structure of the calculations, an implementation of\nthe technique and scaling of the computation with spacetime dimension for\nvarious invariants."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00006-006-0017-4", 
    "link": "http://arxiv.org/pdf/cs/0604066v1", 
    "title": "Univariate polynomial real root isolation: Continued Fractions revisited", 
    "arxiv-id": "cs/0604066v1", 
    "author": "Ioannis Z. Emiris", 
    "publish": "2006-04-17T10:52:35Z", 
    "summary": "We present algorithmic, complexity and implementation results concerning real\nroot isolation of integer univariate polynomials using the continued fraction\nexpansion of real algebraic numbers. One motivation is to explain the method's\ngood performance in practice. We improve the previously known bound by a factor\nof $d \\tau$, where $d$ is the polynomial degree and $\\tau$ bounds the\ncoefficient bitsize, thus matching the current record complexity for real root\nisolation by exact methods. Namely, the complexity bound is $\\sOB(d^4 \\tau^2)$\nusing the standard bound on the expected bitsize of the integers in the\ncontinued fraction expansion. We show how to compute the multiplicities within\nthe same complexity and extend the algorithm to non square-free polynomials.\nFinally, we present an efficient open-source \\texttt{C++} implementation in the\nalgebraic library \\synaps, and illustrate its efficiency as compared to other\navailable software. We use polynomials with coefficient bitsize up to 8000 and\ndegree up to 1000."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2007.01.003", 
    "link": "http://arxiv.org/pdf/cs/0608005v2", 
    "title": "A field-theory motivated approach to symbolic computer algebra", 
    "arxiv-id": "cs/0608005v2", 
    "author": "Kasper Peeters", 
    "publish": "2006-08-01T19:05:20Z", 
    "summary": "Field theory is an area in physics with a deceptively compact notation.\nAlthough general purpose computer algebra systems, built around generic\nlist-based data structures, can be used to represent and manipulate\nfield-theory expressions, this often leads to cumbersome input formats,\nunexpected side-effects, or the need for a lot of special-purpose code. This\nmakes a direct translation of problems from paper to computer and back\nneedlessly time-consuming and error-prone. A prototype computer algebra system\nis presented which features TeX-like input, graph data structures, lists with\nYoung-tableaux symmetries and a multiple-inheritance property system. The\nusefulness of this approach is illustrated with a number of explicit\nfield-theory problems."
},{
    "category": "cs.CC", 
    "doi": "10.1090/S0025-5718-08-02066-8", 
    "link": "http://arxiv.org/pdf/cs/0609020v1", 
    "title": "Fast algorithms for computing isogenies between elliptic curves", 
    "arxiv-id": "cs/0609020v1", 
    "author": "Eric Schost", 
    "publish": "2006-09-06T12:10:17Z", 
    "summary": "We survey algorithms for computing isogenies between elliptic curves defined\nover a field of characteristic either 0 or a large prime. We introduce a new\nalgorithm that computes an isogeny of degree $\\ell$ ($\\ell$ different from the\ncharacteristic) in time quasi-linear with respect to $\\ell$. This is based in\nparticular on fast algorithms for power series expansion of the Weierstrass\n$\\wp$-function and related functions."
},{
    "category": "cs.IT", 
    "doi": "10.1090/S0025-5718-08-02066-8", 
    "link": "http://arxiv.org/pdf/cs/0610132v1", 
    "title": "List Decoding of Hermitian Codes using Groebner Bases", 
    "arxiv-id": "cs/0610132v1", 
    "author": "Michael E. O'Sullivan", 
    "publish": "2006-10-23T07:52:42Z", 
    "summary": "List decoding of Hermitian codes is reformulated to allow an efficient and\nsimple algorithm for the interpolation step. The algorithm is developed using\nthe theory of Groebner bases of modules. The computational complexity of the\nalgorithm seems comparable to previously known algorithms achieving the same\ntask, and the algorithm is better suited for hardware implementation."
},{
    "category": "cs.LO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0612003v2", 
    "title": "Predicate Abstraction via Symbolic Decision Procedures", 
    "arxiv-id": "cs/0612003v2", 
    "author": "Byron Cook", 
    "publish": "2006-12-01T19:56:11Z", 
    "summary": "We present a new approach for performing predicate abstraction based on\nsymbolic decision procedures. Intuitively, a symbolic decision procedure for a\ntheory takes a set of predicates in the theory and symbolically executes a\ndecision procedure on all the subsets over the set of predicates. The result of\nthe symbolic decision procedure is a shared expression (represented by a\ndirected acyclic graph) that implicitly represents the answer to a predicate\nabstraction query.\n  We present symbolic decision procedures for the logic of Equality and\nUninterpreted Functions (EUF) and Difference logic (DIFF) and show that these\nprocedures run in pseudo-polynomial (rather than exponential) time. We then\nprovide a method to construct symbolic decision procedures for simple mixed\ntheories (including the two theories mentioned above) using an extension of the\nNelson-Oppen combination method. We present preliminary evaluation of our\nProcedure on predicate abstraction benchmarks from device driver verification\nin SLAM."
},{
    "category": "cs.CL", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0612033v1", 
    "title": "Acronym-Meaning Extraction from Corpora Using Multi-Tape Weighted   Finite-State Machines", 
    "arxiv-id": "cs/0612033v1", 
    "author": "Andr\u00e9 Kempe", 
    "publish": "2006-12-06T10:13:12Z", 
    "summary": "The automatic extraction of acronyms and their meaning from corpora is an\nimportant sub-task of text mining. It can be seen as a special case of string\nalignment, where a text chunk is aligned with an acronym. Alternative\nalignments have different cost, and ideally the least costly one should give\nthe correct meaning of the acronym. We show how this approach can be\nimplemented by means of a 3-tape weighted finite-state machine (3-WFSM) which\nreads a text chunk on tape 1 and an acronym on tape 2, and generates all\nalternative alignments on tape 3. The 3-WFSM can be automatically generated\nfrom a simple regular expression. No additional algorithms are required at any\nstage. Our 3-WFSM has a size of 27 states and 64 transitions, and finds the\nbest analysis of an acronym in a few milliseconds."
},{
    "category": "cs.CL", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0612041v1", 
    "title": "Viterbi Algorithm Generalized for n-Tape Best-Path Search", 
    "arxiv-id": "cs/0612041v1", 
    "author": "Andr\u00e9 Kempe", 
    "publish": "2006-12-07T08:42:46Z", 
    "summary": "We present a generalization of the Viterbi algorithm for identifying the path\nwith minimal (resp. maximal) weight in a n-tape weighted finite-state machine\n(n-WFSM), that accepts a given n-tuple of input strings (s_1,... s_n). It also\nallows us to compile the best transduction of a given input n-tuple by a\nweighted (n+m)-WFSM (transducer) with n input and m output tapes. Our algorithm\nhas a worst-case time complexity of O(|s|^n |E| log (|s|^n |Q|)), where n and\n|s| are the number and average length of the strings in the n-tuple, and |Q|\nand |E| the number of states and transitions in the n-WFSM, respectively. A\nstraight forward alternative, consisting in intersection followed by classical\nshortest-distance search, operates in O(|s|^n (|E|+|Q|) log (|s|^n |Q|)) time."
},{
    "category": "cs.SC", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0612050v2", 
    "title": "Explicit factors of some iterated resultants and discriminants", 
    "arxiv-id": "cs/0612050v2", 
    "author": "Bernard Mourrain", 
    "publish": "2006-12-08T14:10:38Z", 
    "summary": "In this paper, the result of applying iterative univariate resultant\nconstructions to multivariate polynomials is analyzed. We consider the input\npolynomials as generic polynomials of a given degree and exhibit explicit\ndecompositions into irreducible factors of several constructions involving two\ntimes iterated univariate resultants and discriminants over the integer\nuniversal ring of coefficients of the entry polynomials. Cases involving from\ntwo to four generic polynomials and resultants or discriminants in one of their\nvariables are treated. The decompositions into irreducible factors we get are\nobtained by exploiting fundamental properties of the univariate resultants and\ndiscriminants and induction on the degree of the polynomials. As a consequence,\neach irreducible factor can be separately and explicitly computed in terms of a\ncertain multivariate resultant. With this approach, we also obtain as direct\ncorollaries some results conjectured by Collins and McCallum which correspond\nto the case of polynomials whose coefficients are themselves generic\npolynomials in other variables. Finally, a geometric interpretation of the\nalgebraic factorization of the iterated discriminant of a single polynomial is\ndetailled."
},{
    "category": "cs.IT", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0701117v2", 
    "title": "Maximum Entropy in the framework of Algebraic Statistics: A First Step", 
    "arxiv-id": "cs/0701117v2", 
    "author": "Ambedkar Dukkipati", 
    "publish": "2007-01-18T15:23:29Z", 
    "summary": "Algebraic statistics is a recently evolving field, where one would treat\nstatistical models as algebraic objects and thereby use tools from\ncomputational commutative algebra and algebraic geometry in the analysis and\ncomputation of statistical models. In this approach, calculation of parameters\nof statistical models amounts to solving set of polynomial equations in several\nvariables, for which one can use celebrated Grobner bases theory. Owing to the\nimportant role of information theory in statistics, this paper as a first step,\nexplores the possibility of describing maximum and minimum entropy (ME) models\nin the framework of algebraic statistics. We show that ME-models are toric\nmodels (a class of algebraic statistical models) when the constraint functions\n(that provide the information about the underlying random variable) are integer\nvalued functions, and the set of statistical models that results from\nME-methods are indeed an affine variety."
},{
    "category": "cs.AI", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/cs/0701174v3", 
    "title": "A Prototype for Educational Planning Using Course Constraints to   Simulate Student Populations", 
    "arxiv-id": "cs/0701174v3", 
    "author": "V. Mitsionis", 
    "publish": "2007-01-26T08:32:10Z", 
    "summary": "Distance learning universities usually afford their students the flexibility\nto advance their studies at their own pace. This can lead to a considerable\nfluctuation of student populations within a program's courses, possibly\naffecting the academic viability of a program as well as the related required\nresources. Providing a method that estimates this population could be of\nsubstantial help to university management and academic personnel. We describe\nhow to use course precedence constraints to calculate alternative tuition paths\nand then use Markov models to estimate future populations. In doing so, we\nidentify key issues of a large scale potential deployment."
},{
    "category": "gr-qc", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/gr-qc/0209096v2", 
    "title": "Gravity, torsion, Dirac field and computer algebra using MAPLE and   REDUCE", 
    "arxiv-id": "gr-qc/0209096v2", 
    "author": "D. N. Vulcanov", 
    "publish": "2002-09-25T13:34:17Z", 
    "summary": "The article presents computer algebra procedures and routines applied to the\nstudy of the Dirac field on curved spacetimes. The main part of the procedures\nis devoted to the construction of Pauli and Dirac matrices algebra on an\nanholonomic orthonormal reference frame. Then these procedures are used to\ncompute the Dirac equation on curved spacetimes in a sequence of special\ndedicated routines. A comparative review of such procedures obtained for two\ncomputer algebra platforms (REDUCE + EXCALC and MAPLE + GRTensorII) is carried\nout. Applications for the calculus of Dirac equation on specific examples of\nspacetimes with or without torsion are pointed out."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0207135v1", 
    "title": "The Hilbert Zonotope and a Polynomial Time Algorithm for Universal   Grobner Bases", 
    "arxiv-id": "math/0207135v1", 
    "author": "Rekha Thomas", 
    "publish": "2002-07-16T20:55:36Z", 
    "summary": "We provide a polynomial time algorithm for computing the universal Gr\\\"obner\nbasis of any polynomial ideal having a finite set of common zeros in fixed\nnumber of variables. One ingredient of our algorithm is an effective\nconstruction of the state polyhedron of any member of the Hilbert scheme\nHilb^d_n of n-long d-variate ideals, enabled by introducing the Hilbert\nzonotope H^d_n and showing that it simultaneously refines all state polyhedra\nof ideals on Hilb^d_n."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0211156v1", 
    "title": "Ideal decompositions and computation of tensor normal forms", 
    "arxiv-id": "math/0211156v1", 
    "author": "B. Fiedler", 
    "publish": "2002-11-09T18:47:36Z", 
    "summary": "Symmetry properties of r-times covariant tensors T can be described by\ncertain linear subspaces W of the group ring K[S_r] of a symmetric group S_r.\nIf for a class of tensors T such a W is known, the elements of the orthogonal\nsubspace W^{\\bot} of W within the dual space of K[S_r] yield linear identities\nneeded for a treatment of the term combination problem for the coordinates of\nthe T. We give the structure of these W for every situation which appears in\nsymbolic tensor calculations by computer. Characterizing idempotents of such W\ncan be determined by means of an ideal decomposition algorithm which works in\nevery semisimple ring up to an isomorphism. Furthermore, we use tools such as\nthe Littlewood-Richardson rule, plethysms and discrete Fourier transforms for\nS_r to increase the efficience of calculations. All described methods were\nimplemented in a Mathematica package called PERMS."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0212278v2", 
    "title": "Determination of the structure of algebraic curvature tensors by means   of Young symmetrizers", 
    "arxiv-id": "math/0212278v2", 
    "author": "B. Fiedler", 
    "publish": "2002-12-19T20:26:42Z", 
    "summary": "For a positive definite fundamental tensor all known examples of Osserman\nalgebraic curvature tensors have a typical structure. They can be produced from\na metric tensor and a finite set of skew-symmetric matrices which fulfil\nClifford commutation relations. We show by means of Young symmetrizers and a\ntheorem of S. A. Fulling, R. C. King, B. G. Wybourne and C. J. Cummins that\nevery algebraic curvature tensor has a structure which is very similar to that\nof the above Osserman curvature tensors. We verify our results by means of the\nLittlewood-Richardson rule and plethysms. For certain symbolic calculations we\nused the Mathematica packages MathTensor, Ricci and PERMS."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0301042v1", 
    "title": "On the symmetry classes of the first covariant derivatives of tensor   fields", 
    "arxiv-id": "math/0301042v1", 
    "author": "B. Fiedler", 
    "publish": "2003-01-06T16:28:59Z", 
    "summary": "We show that the symmetry classes of torsion-free covariant derivatives\n$\\nabla T$ of r-times covariant tensor fields T can be characterized by\nLittlewood-Richardson products $\\sigma [1]$ where $\\sigma$ is a representation\nof the symmetric group $S_r$ which is connected with the symmetry class of T.\nIf $\\sigma = [\\lambda]$ is irreducible then $\\sigma [1]$ has a multiplicity\nfree reduction $[\\lambda][1] = \\sum [\\mu]$ and all primitive idempotents\nbelonging to that sum can be calculated from a generating idempotent e of the\nsymmetry class of T by means of the irreducible characters or of a discrete\nFourier transform of $S_{r+1}$. We apply these facts to derivatives $\\nabla S$,\n$\\nabla A$ of symmetric or alternating tensor fields. The symmetry classes of\nthe differences $\\nabla S - sym(\\nabla S)$ and $\\nabla A - alt(\\nabla A)$ are\ncharacterized by Young frames (r, 1) and (2, 1^{r-1}), respectively. However,\nwhile the symmetry class of $\\nabla A - alt(\\nabla A)$ can be generated by\nYoung symmetrizers of (2, 1^{r-1}), no Young symmetrizer of (r, 1) generates\nthe symmetry class of $\\nabla S - sym(\\nabla S)$. Furthermore we show in the\ncase r = 2 that $\\nabla S - sym(\\nabla S)$ and $\\nabla A - alt(\\nabla A)$ can\nbe applied in generator formulas of algebraic covariant derivative curvature\ntensors. For certain symbolic calculations we used the Mathematica packages\nRicci and PERMS."
},{
    "category": "math.AC", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0304192v1", 
    "title": "On reconstructing n-point configurations from the distribution of   distances or areas", 
    "arxiv-id": "math/0304192v1", 
    "author": "Gregor Kemper", 
    "publish": "2003-04-15T10:01:26Z", 
    "summary": "One way to characterize configurations of points up to congruence is by\nconsidering the distribution of all mutual distances between points. This paper\ndeals with the question if point configurations are uniquely determined by this\ndistribution. After giving some counterexamples, we prove that this is the case\nfor the vast majority of configurations. In the second part of the paper, the\ndistribution of areas of sub-triangles is used for characterizing point\nconfigurations. Again it turns out that most configurations are reconstructible\nfrom the distribution of areas, though there are counterexamples."
},{
    "category": "math.GR", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0304283v1", 
    "title": "Whitehead method and Genetic Algorithms", 
    "arxiv-id": "math/0304283v1", 
    "author": "Alexei G. Myasnikov", 
    "publish": "2003-04-20T16:24:44Z", 
    "summary": "In this paper we discuss a genetic version (GWA) of the Whitehead's\nalgorithm, which is one of the basic algorithms in combinatorial group theory.\nIt turns out that GWA is surprisingly fast and outperforms the standard\nWhitehead's algorithm in free groups of rank >= 5. Experimenting with GWA we\ncollected an interesting numerical data that clarifies the time-complexity of\nthe Whitehead's Problem in general. These experiments led us to several\nmathematical conjectures. If confirmed they will shed light on hidden\nmechanisms of Whitehead Method and geometry of automorphic orbits in free\ngroups."
},{
    "category": "math.GR", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0304306v1", 
    "title": "Genetic algorithms and the Andrews-Curtis conjecture", 
    "arxiv-id": "math/0304306v1", 
    "author": "Alexei D. Miasnikov", 
    "publish": "2003-04-21T21:07:18Z", 
    "summary": "The Andrews-Curtis conjecture claims that every balanced presentation of the\ntrivial group can be transformed into the trivial presentation by a finite\nsequence of \"elementary transformations\" which are Nielsen transformations\ntogether with an arbitrary conjugation of a relator. It is believed that the\nAndrews-Curtis conjecture is false; however, not so many possible\ncounterexamples are known. It is not a trivial matter to verify whether the\nconjecture holds for a given balanced presentation or not. The purpose of this\npaper is to describe some non-deterministic methods, called Genetic Algorithms,\ndesigned to test the validity of the Andrews-Curtis conjecture. Using such\nalgorithm we have been able to prove that all known (to us) balanced\npresentations of the trivial group where the total length of the relators is at\nmost 12 satisfy the conjecture. In particular, the Andrews-Curtis conjecture\nholds for the presentation <x,y|x y x = y x y, x^2 = y^3> which was one of the\nwell known potential counterexamples."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0310020v1", 
    "title": "Generators of algebraic covariant derivative curvature tensors and Young   symmetrizers", 
    "arxiv-id": "math/0310020v1", 
    "author": "B. Fiedler", 
    "publish": "2003-10-02T11:37:41Z", 
    "summary": "We show that the space of algebraic covariant derivative curvature tensors R'\nis generated by Young symmetrized tensor products W*U or U*W, where W and U are\ncovariant tensors of order 2 and 3 whose symmetry classes are irreducible and\ncharacterized by the following pairs of partitions: {(2),(3)}, {(2),(2 1)} or\n{(1 1),(2 1)}. Each of the partitions (2), (3) and (1 1) describes exactly one\nsymmetry class, whereas the partition (2 1) characterizes an infinite set S of\nirreducible symmetry classes. This set S contains exactly one symmetry class\nS_0 whose elements U can not play the role of generators of tensors R'. The\ntensors U of all other symmetry classes from S\\{S_0} can be used as generators\nfor tensors R'. Foundation of our investigations is a theorem of S. A. Fulling,\nR. C. King, B. G. Wybourne and C. J. Cummins about a Young symmetrizer that\ngenerates the symmetry class of algebraic covariant derivative curvature\ntensors. Furthermore we apply ideals and idempotents in group rings C[Sr], the\nLittlewood-Richardson rule and discrete Fourier transforms for symmetric groups\nSr. For certain symbolic calculations we used the Mathematica packages Ricci\nand PERMS."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0312171v1", 
    "title": "Short formulas for algebraic covariant derivative curvature tensors via   Algebraic Combinatorics", 
    "arxiv-id": "math/0312171v1", 
    "author": "Bernd Fiedler", 
    "publish": "2003-12-08T19:31:51Z", 
    "summary": "We consider generators of algebraic covariant derivative curvature tensors R'\nwhich can be constructed by a Young symmetrization of product tensors W*U or\nU*W, where W and U are covariant tensors of order 2 and 3. W is a symmetric or\nalternating tensor whereas U belongs to a class of the infinite set S of\nirreducible symmetry classes characterized by the partition (2,1). Using\nComputer Algebra we search for such generators whose coordinate representations\nare polynomials with a minimal number of summands. For a generic choice of the\nsymmetry class of U we obtain lengths of 16 or 20 summands if W is symmetric or\nskew-symmetric, respectively. In special cases these numbers can be reduced to\nthe minima 12 or 10. If these minima occur then U admits an index commutation\nsymmetry. Furthermore minimal lengths are possible if U is formed from\ntorsion-free covariant derivatives of symmetric or alternating 2-tensor fields.\nFoundation of our investigations is a theorem of S. A. Fulling, R. C. King, B.\nG. Wybourne and C. J. Cummins about a Young symmetrizer that generates the\nsymmetry class of algebraic covariant derivative curvature tensors. Furthermore\nwe apply ideals and idempotents in group rings C[S_r] and discrete Fourier\ntransforms for symmetric groups S_r. For symbolic calculations we used the\nMathematica packages Ricci and PERMS."
},{
    "category": "math.DG", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0411056v1", 
    "title": "Generators of algebraic curvature tensors based on a (2,1)-symmetry", 
    "arxiv-id": "math/0411056v1", 
    "author": "Bernd Fiedler", 
    "publish": "2004-11-02T23:05:35Z", 
    "summary": "We consider generators of algebraic curvature tensors R which can be\nconstructed by a Young symmetrization of product tensors U*w or w*U, where U\nand w are covariant tensors of order 3 and 1. We assume that U belongs to a\nclass of the infinite set S of irreducible symmetry classes characterized by\nthe partition (2,1). We show that the set S contains exactly one symmetry class\nS_0 whose elements U can not play the role of generators of tensors R. The\ntensors U of all other symmetry classes from S\\{S_0} can be used as generators\nfor tensors R. Using Computer Algebra we search for such generators whose\ncoordinate representations are polynomials with a minimal number of summands.\nFor a generic choice of the symmetry class of U we obtain lengths of 8\nsummands. In special cases these numbers can be reduced to the minimum 4. If\nthis minimum occurs then U admits an index commutation symmetry. Furthermore\nminimal lengths are possible if U is formed from torsion-free covariant\nderivatives of alternating 2-tensor fields. We apply ideals and idempotents of\ngroup rings C[S_r] of symmetric groups S_r, Young symmetrizers, discrete\nFourier transforms and Littlewood-Richardson products. For symbolic\ncalculations we used the Mathematica packages Ricci and PERMS."
},{
    "category": "math.CO", 
    "doi": "10.2168/LMCS-3(2:1)2007", 
    "link": "http://arxiv.org/pdf/math/0507410v1", 
    "title": "Methods for the construction of generators of algebraic curvature   tensors", 
    "arxiv-id": "math/0507410v1", 
    "author": "Bernd Fiedler", 
    "publish": "2005-07-20T16:18:29Z", 
    "summary": "We demonstrate the use of several tools from Algebraic Combinatorics such as\nYoung tableaux, symmetry operators, the Littlewood-Richardson rule and discrete\nFourier transforms of symmetric groups in investigations of algebraic curvature\ntensors."
},{
    "category": "math.DG", 
    "doi": "10.1088/1742-6596/30/1/018", 
    "link": "http://arxiv.org/pdf/math/0510304v1", 
    "title": "Stationary or static space-times and Young tableaux", 
    "arxiv-id": "math/0510304v1", 
    "author": "Bernd Fiedler", 
    "publish": "2005-10-14T16:28:48Z", 
    "summary": "Algebraic curvature tensors possess generators which can be formed from\nsymmetric or alternating tensors S, A or tensors \\theta with an irreducible\n(2,1)-symmetry. In differential geometry examples of curvature formulas are\nknown which contain generators on the basis of S or A realized by\ndifferentiable tensor fields in a natural way. We show that certain curvature\nformulas for stationary or static space-times contain such differentiable\nrealizations of generators based on \\theta. The tensor \\theta is connected with\nthe timelike Killing vector field of the space-time. \\theta lies in a special\nsymmetry class from the infinite family of irreducible (2,1)-symmetry classes.\nWe determine characteristics of this class. In particular, this class allows a\nmaximal reduction of the length of the curvature formulas. We use a projection\nformalism by Vladimirov, Young symmetrizers and Littlewood-Richardson products.\nComputer calculations were carried out by means of the packages Ricci and\nPERMS."
},{
    "category": "math.AG", 
    "doi": "10.1088/1742-6596/30/1/018", 
    "link": "http://arxiv.org/pdf/math/0603248v1", 
    "title": "Computing the First Betti Numberand Describing the Connected Components   of Semi-algebraic Sets", 
    "arxiv-id": "math/0603248v1", 
    "author": "Marie-Francoise Roy", 
    "publish": "2006-03-10T20:00:21Z", 
    "summary": "In this paper we describe a singly exponential algorithm for computing the\nfirst Betti number of a given semi-algebraic set. Singly exponential algorithms\nfor computing the zero-th Betti number, and the Euler-Poincar\\'e\ncharacteristic, were known before. No singly exponential algorithm was known\nfor computing any of the individual Betti numbers other than the zero-th one.\nWe also give algorithms for obtaining semi-algebraic descriptions of the\nsemi-algebraically connected components of any given real algebraic or\nsemi-algebraic set in single-exponential time improving on previous results."
},{
    "category": "math.RA", 
    "doi": "10.3842/SIGMA.2006.051", 
    "link": "http://arxiv.org/pdf/math/0605334v1", 
    "title": "Gr\u00f6bner Bases and Generation of Difference Schemes for Partial   Differential Equations", 
    "arxiv-id": "math/0605334v1", 
    "author": "Vladimir V. Mozzhilkin", 
    "publish": "2006-05-12T13:34:41Z", 
    "summary": "In this paper we present an algorithmic approach to the generation of fully\nconservative difference schemes for linear partial differential equations. The\napproach is based on enlargement of the equations in their integral\nconservation law form by extra integral relations between unknown functions and\ntheir derivatives, and on discretization of the obtained system. The structure\nof the discrete system depends on numerical approximation methods for the\nintegrals occurring in the enlarged system. As a result of the discretization,\na system of linear polynomial difference equations is derived for the unknown\nfunctions and their partial derivatives. A difference scheme is constructed by\nelimination of all the partial derivatives. The elimination can be achieved by\nselecting a proper elimination ranking and by computing a Gr\\\"obner basis of\nthe linear difference ideal generated by the polynomials in the discrete\nsystem. For these purposes we use the difference form of Janet-like Gr\\\"obner\nbases and their implementation in Maple. As illustration of the described\nmethods and algorithms, we construct a number of difference schemes for Burgers\nand Falkowich-Karman equations and discuss their numerical properties."
},{
    "category": "math.CO", 
    "doi": "10.3842/SIGMA.2006.051", 
    "link": "http://arxiv.org/pdf/math/0607368v1", 
    "title": "The Newton Polytope of the Implicit Equation", 
    "arxiv-id": "math/0607368v1", 
    "author": "Josephine Yu", 
    "publish": "2006-07-16T05:55:34Z", 
    "summary": "We apply tropical geometry to study the image of a map defined by Laurent\npolynomials with generic coefficients. If this image is a hypersurface then our\napproach gives a construction of its Newton polytope."
},{
    "category": "math.CO", 
    "doi": "10.3842/SIGMA.2006.051", 
    "link": "http://arxiv.org/pdf/math/0607411v1", 
    "title": "Extending the scalars of minimizations", 
    "arxiv-id": "math/0607411v1", 
    "author": "Jean-Gabriel Luque", 
    "publish": "2006-07-18T07:06:59Z", 
    "summary": "In the classical theory of formal languages, finite state automata allow to\nrecognize the words of a rational subset of $\\Sigma^*$ where $\\Sigma$ is a set\nof symbols (or the alphabet). Now, given a semiring $(\\K,+,.)$, one can\nconstruct $\\K$-subsets of $\\Sigma^*$ in the sense of Eilenberg, that are\nalternatively called noncommutative formal power series for which a framework\nvery similar to language theory has been constructed Particular noncommutative\nformal power series, which are called rational series, are the behaviour of a\nfamily of weighted automata (or $\\K$-automata). In order to get an efficient\nencoding, it may be interesting to point out one of them with the smallest\nnumber of states. Minimization processes of $\\K$-automata already exist for\n$\\K$ being: {\\bf a)} a field, {\\bf b)} a noncommutative field, {\\bf c)} a PID .\nWhen $\\K$ is the bolean semiring, such a minimization process (with\nisomorphisms of minimal objects) is known within the category of deterministic\nautomata. Minimal automata have been proved to be isomorphic in cases {\\bf (a)}\nand {\\bf (b)}. But the proof given for (b) is not constructive. In fact, it\nlays on the existence of a basis for a submodule of $\\K^n$. Here we give an\nindependent algorithm which reproves this fact and an example of a pair of\nnonisomorphic minimal automata. Moreover, we examine the possibility of\nextending {\\bf (c)}. To this end, we provide an {\\em Effective Minimization\nProcess} (or {\\em EMP}) which can be used for more general sets of\ncoefficients."
},{
    "category": "math.CO", 
    "doi": "10.3842/SIGMA.2006.051", 
    "link": "http://arxiv.org/pdf/math/0607412v1", 
    "title": "Direct and dual laws for automata with multiplicities", 
    "arxiv-id": "math/0607412v1", 
    "author": "Jean-Gabriel Luque", 
    "publish": "2006-07-18T07:08:35Z", 
    "summary": "We present here theoretical results coming from the implementation of the\npackage called AMULT (automata with multiplicities in several noncommutative\nvariables). We show that classical formulas are ``almost every time'' optimal,\ncharacterize the dual laws preserving rationality and also relators that are\ncompatible with these laws."
},{
    "category": "math.CO", 
    "doi": "10.3842/SIGMA.2006.051", 
    "link": "http://arxiv.org/pdf/math/0607420v1", 
    "title": "Transitive factorizations of free partially commutative monoids and Lie   algebras", 
    "arxiv-id": "math/0607420v1", 
    "author": "G\u00e9rard Henry Edmond Duchamp", 
    "publish": "2006-07-18T12:42:33Z", 
    "summary": "Let $\\M(A,\\theta)$ be a free partially commutative monoid. We give here a\nnecessary and sufficient condition on a subalphabet $B\\subset A$ such that the\nright factor of a bisection $\\M(A,\\theta)=\\M(B,\\theta\\_B).T$ be also partially\ncommutative free. This extends strictly the (classical) elimination theory on\npartial commutations and allows to construct new factorizations of\n$\\M(A,\\theta)$ and associated bases of $L\\_K(A,\\theta)$."
},{
    "category": "math.NT", 
    "doi": "10.3842/SIGMA.2006.051", 
    "link": "http://arxiv.org/pdf/math/0610121v3", 
    "title": "Fast Jacobian group operations for C_{3,4} curves over a large finite   field", 
    "arxiv-id": "math/0610121v3", 
    "author": "Kamal Khuri-Makdisi", 
    "publish": "2006-10-03T16:13:39Z", 
    "summary": "Let C be an arbitrary smooth algebraic curve of genus g over a large finite\nfield K. We revisit fast addition algorithms in the Jacobian of C due to\nKhuri-Makdisi (math.NT/0409209, to appear in Math. Comp.). The algorithms,\nwhich reduce to linear algebra in vector spaces of dimension O(g) once |K| >>\ng, and which asymptotically require O(g^{2.376}) field operations using fast\nlinear algebra, are shown to perform efficiently even for certain low genus\ncurves. Specifically, we provide explicit formulae for performing the group law\non Jacobians of C_{3,4} curves of genus 3. We show that, typically, the\naddition of two distinct elements in the Jacobian of a C_{3,4} curve requires\n117 multiplications and 2 inversions in K, and an element can be doubled using\n129 multiplications and 2 inversions in K. This represents an improvement of\napproximately 20% over previous methods."
},{
    "category": "math-ph", 
    "doi": "10.1016/S0010-4655(02)00261-8", 
    "link": "http://arxiv.org/pdf/math-ph/0201011v2", 
    "title": "Symbolic Expansion of Transcendental Functions", 
    "arxiv-id": "math-ph/0201011v2", 
    "author": "Stefan Weinzierl", 
    "publish": "2002-01-04T09:55:42Z", 
    "summary": "Higher transcendental function occur frequently in the calculation of Feynman\nintegrals in quantum field theory. Their expansion in a small parameter is a\nnon-trivial task. We report on a computer program which allows the systematic\nexpansion of certain classes of functions. The algorithms are based on the Hopf\nalgebra of nested sums. The program is written in C++ and uses the GiNaC\nlibrary."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2007.05.015", 
    "link": "http://arxiv.org/pdf/0704.1756v1", 
    "title": "The Invar Tensor Package", 
    "arxiv-id": "0704.1756v1", 
    "author": "Leon R. U. Manssur", 
    "publish": "2007-04-13T13:03:59Z", 
    "summary": "The Invar package is introduced, a fast manipulator of generic scalar\npolynomial expressions formed from the Riemann tensor of a four-dimensional\nmetric-compatible connection. The package can maximally simplify any polynomial\ncontaining tensor products of up to seven Riemann tensors within seconds. It\nhas been implemented both in Mathematica and Maple algebraic systems."
},{
    "category": "math.KT", 
    "doi": "10.1016/j.cpc.2007.05.015", 
    "link": "http://arxiv.org/pdf/0704.2351v2", 
    "title": "Parallel computation of the rank of large sparse matrices from algebraic   K-theory", 
    "arxiv-id": "0704.2351v2", 
    "author": "Anna Urbanska", 
    "publish": "2007-04-18T14:29:28Z", 
    "summary": "This paper deals with the computation of the rank and of some integer Smith\nforms of a series of sparse matrices arising in algebraic K-theory. The number\nof non zero entries in the considered matrices ranges from 8 to 37 millions.\nThe largest rank computation took more than 35 days on 50 processors. We report\non the actual algorithms we used to build the matrices, their link to the\nmotivic cohomology and the linear algebra and parallelizations required to\nperform such huge computations. In particular, these results are part of the\nfirst computation of the cohomology of the linear group GL_7(Z)."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2007.05.015", 
    "link": "http://arxiv.org/pdf/0706.0564v2", 
    "title": "Tropical Implicitization and Mixed Fiber Polytopes", 
    "arxiv-id": "0706.0564v2", 
    "author": "Josephine Yu", 
    "publish": "2007-06-05T00:53:37Z", 
    "summary": "The software TrIm offers implementations of tropical implicitization and\ntropical elimination, as developed by Tevelev and the authors. Given a\npolynomial map with generic coefficients, TrIm computes the tropical variety of\nthe image. When the image is a hypersurface, the output is the Newton polytope\nof the defining polynomial. TrIm can thus be used to compute mixed fiber\npolytopes, including secondary polytopes."
},{
    "category": "math.OC", 
    "doi": "10.1016/j.cpc.2007.05.015", 
    "link": "http://arxiv.org/pdf/0708.2078v1", 
    "title": "Obstructions to Genericity in Study of Parametric Problems in Control   Theory", 
    "arxiv-id": "0708.2078v1", 
    "author": "Eva Zerz", 
    "publish": "2007-08-15T19:12:15Z", 
    "summary": "We investigate systems of equations, involving parameters from the point of\nview of both control theory and computer algebra. The equations might involve\nlinear operators such as partial (q-)differentiation, (q-)shift, (q-)difference\nas well as more complicated ones, which act trivially on the parameters. Such a\nsystem can be identified algebraically with a certain left module over a\nnon-commutative algebra, where the operators commute with the parameters. We\ndevelop, implement and use in practice the algorithm for revealing all the\nexpressions in parameters, for which e.g. homological properties of a system\ndiffer from the generic properties. We use Groebner bases and Groebner basics\nin rings of solvable type as main tools. In particular, we demonstrate an\noptimized algorithm for computing the left inverse of a matrix over a ring of\nsolvable type. We illustrate the article with interesting examples. In\nparticular, we provide a complete solution to the \"two pendula, mounted on a\ncart\" problem from the classical book of Polderman and Willems, including the\ncase, where the friction at the joints is essential . To the best of our\nknowledge, the latter example has not been solved before in a complete way."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2007.05.015", 
    "link": "http://arxiv.org/pdf/0708.2213v1", 
    "title": "Moderate Growth Time Series for Dynamic Combinatorics Modelisation", 
    "arxiv-id": "0708.2213v1", 
    "author": "Cyrille Bertelle", 
    "publish": "2007-08-16T14:58:35Z", 
    "summary": "Here, we present a family of time series with a simple growth constraint.\nThis family can be the basis of a model to apply to emerging computation in\nbusiness and micro-economy where global functions can be expressed from local\nrules. We explicit a double statistics on these series which allows to\nestablish a one-to-one correspondence between three other ballot-like\nstrunctures."
},{
    "category": "math.AG", 
    "doi": "10.1137/070711141", 
    "link": "http://arxiv.org/pdf/0708.3522v2", 
    "title": "Bounding the Betti numbers and computing the Euler-Poincar\u00e9   characteristic of semi-algebraic sets defined by partly quadratic systems of   polynomials", 
    "arxiv-id": "0708.3522v2", 
    "author": "Marie-Francoise Roy", 
    "publish": "2007-08-27T01:31:17Z", 
    "summary": "Let $\\R$ be a real closed field, $ {\\mathcal Q} \\subset\n\\R[Y_1,...,Y_\\ell,X_1,...,X_k], $ with $ \\deg_{Y}(Q) \\leq 2, \\deg_{X}(Q) \\leq\nd, Q \\in {\\mathcal Q}, #({\\mathcal Q})=m,$ and $ {\\mathcal P} \\subset\n\\R[X_1,...,X_k] $ with $\\deg_{X}(P) \\leq d, P \\in {\\mathcal P}, #({\\mathcal\nP})=s$, and $S \\subset \\R^{\\ell+k}$ a semi-algebraic set defined by a Boolean\nformula without negations, with atoms $P=0, P \\geq 0, P \\leq 0, P \\in {\\mathcal\nP} \\cup {\\mathcal Q}$. We prove that the sum of the Betti numbers of $S$ is\nbounded by \\[ \\ell^2 (O(s+\\ell+m)\\ell d)^{k+2m}. \\] This is a common\ngeneralization of previous results on bounding the Betti numbers of closed\nsemi-algebraic sets defined by polynomials of degree $d$ and 2, respectively.\n  We also describe an algorithm for computing the Euler-Poincar\\'e\ncharacteristic of such sets, generalizing similar algorithms known before. The\ncomplexity of the algorithm is bounded by $(\\ell s m d)^{O(m(m+k))}$."
},{
    "category": "math.AG", 
    "doi": "10.1145/1277548.1277559", 
    "link": "http://arxiv.org/pdf/0708.4230v1", 
    "title": "Implicitization of Bihomogeneous Parametrizations of Algebraic Surfaces   via Linear Syzygies", 
    "arxiv-id": "0708.4230v1", 
    "author": "Marc Dohm", 
    "publish": "2007-08-30T20:31:00Z", 
    "summary": "We show that the implicit equation of a surface in 3-dimensional projective\nspace parametrized by bi-homogeneous polynomials of bi-degree (d,d), for a\ngiven positive integer d, can be represented and computed from the linear\nsyzygies of its parametrization if the base points are isolated and form\nlocally a complete intersection."
},{
    "category": "cs.CC", 
    "doi": "10.1016/j.jco.2008.03.001", 
    "link": "http://arxiv.org/pdf/0710.4508v2", 
    "title": "A Numerical Algorithm for Zero Counting. I: Complexity and Accuracy", 
    "arxiv-id": "0710.4508v2", 
    "author": "Mario Wschebor", 
    "publish": "2007-10-24T16:33:07Z", 
    "summary": "We describe an algorithm to count the number of distinct real zeros of a\npolynomial (square) system f. The algorithm performs O(n D kappa(f)) iterations\nwhere n is the number of polynomials (as well as the dimension of the ambient\nspace), D is a bound on the polynomials' degree, and kappa(f) is a condition\nnumber for the system. Each iteration uses an exponential number of operations.\nThe algorithm uses finite-precision arithmetic and a polynomial bound for the\nprecision required to ensure the returned output is correct is exhibited. This\nbound is a major feature of our algorithm since it is in contrast with the\nexponential precision required by the existing (symbolic) algorithms for\ncounting real zeros. The algorithm parallelizes well in the sense that each\niteration can be computed in parallel polynomial time with an exponential\nnumber of processors."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jco.2008.03.001", 
    "link": "http://arxiv.org/pdf/0712.2671v2", 
    "title": "On the equations of the moving curve ideal of a rational algebraic plane   curve", 
    "arxiv-id": "0712.2671v2", 
    "author": "Laurent Bus\u00e9", 
    "publish": "2007-12-17T10:12:33Z", 
    "summary": "Given a parametrization of a rational plane algebraic curve C, some explicit\nadjoint pencils on C are described in terms of determinants. Moreover, some\ngenerators of the Rees algebra associated to this parametrization are\npresented. The main ingredient developed in this paper is a detailed study of\nthe elimination ideal of two homogeneous polynomials in two homogeneous\nvariables that form a regular sequence."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2008.03.001", 
    "link": "http://arxiv.org/pdf/0712.4248v2", 
    "title": "Computer algebra in systems biology", 
    "arxiv-id": "0712.4248v2", 
    "author": "Bernd Sturmfels", 
    "publish": "2007-12-27T16:01:35Z", 
    "summary": "Systems biology focuses on the study of entire biological systems rather than\non their individual components. With the emergence of high-throughput data\ngeneration technologies for molecular biology and the development of advanced\nmathematical modeling techniques, this field promises to provide important new\ninsights. At the same time, with the availability of increasingly powerful\ncomputers, computer algebra has developed into a useful tool for many\napplications. This article illustrates the use of computer algebra in systems\nbiology by way of a well-known gene regulatory network, the Lac Operon in the\nbacterium E. coli."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jco.2008.03.001", 
    "link": "http://arxiv.org/pdf/0801.0586v2", 
    "title": "On sign conditions over real multivariate polynomials", 
    "arxiv-id": "0801.0586v2", 
    "author": "Juan Sabia", 
    "publish": "2008-01-03T20:03:05Z", 
    "summary": "We present a new probabilistic algorithm to find a finite set of points\nintersecting the closure of each connected component of the realization of\nevery sign condition over a family of real polynomials defining regular\nhypersurfaces that intersect transversally. This enables us to show a\nprobabilistic procedure to list all feasible sign conditions over the\npolynomials. In addition, we extend these results to the case of closed sign\nconditions over an arbitrary family of real multivariate polynomials. The\ncomplexity bounds for these procedures improve the known ones."
},{
    "category": "quant-ph", 
    "doi": "10.1016/j.jco.2008.03.001", 
    "link": "http://arxiv.org/pdf/0802.0249v1", 
    "title": "Hopf Algebras in General and in Combinatorial Physics: a practical   introduction", 
    "arxiv-id": "0802.0249v1", 
    "author": "A. I. Solomon", 
    "publish": "2008-02-02T15:06:41Z", 
    "summary": "This tutorial is intended to give an accessible introduction to Hopf\nalgebras. The mathematical context is that of representation theory, and we\nalso illustrate the structures with examples taken from combinatorics and\nquantum physics, showing that in this latter case the axioms of Hopf algebra\narise naturally. The text contains many exercises, some taken from physics,\naimed at expanding and exemplifying the concepts introduced."
},{
    "category": "quant-ph", 
    "doi": "10.1088/1742-6596/104/1/012031", 
    "link": "http://arxiv.org/pdf/0802.1162v1", 
    "title": "Approximate substitutions and the normal ordering problem", 
    "arxiv-id": "0802.1162v1", 
    "author": "K. A. Penson", 
    "publish": "2008-02-08T14:52:52Z", 
    "summary": "In this paper, we show that the infinite generalised Stirling matrices\nassociated with boson strings with one annihilation operator are projective\nlimits of approximate substitutions, the latter being characterised by a finite\nset of algebraic equations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2008.04.018", 
    "link": "http://arxiv.org/pdf/0802.1274v1", 
    "title": "The Invar tensor package: Differential invariants of Riemann", 
    "arxiv-id": "0802.1274v1", 
    "author": "Renato Portugal", 
    "publish": "2008-02-11T16:38:05Z", 
    "summary": "The long standing problem of the relations among the scalar invariants of the\nRiemann tensor is computationally solved for all 6x10^23 objects with up to 12\nderivatives of the metric. This covers cases ranging from products of up to 6\nundifferentiated Riemann tensors to cases with up to 10 covariant derivatives\nof a single Riemann. We extend our computer algebra system Invar to produce\nwithin seconds a canonical form for any of those objects in terms of a basis.\nThe process is as follows: (1) an invariant is converted in real time into a\ncanonical form with respect to the permutation symmetries of the Riemann\ntensor; (2) Invar reads a database of more than 6x10^5 relations and applies\nthose coming from the cyclic symmetry of the Riemann tensor; (3) then applies\nthe relations coming from the Bianchi identity, (4) the relations coming from\ncommutations of covariant derivatives, (5) the dimensionally-dependent\nidentities for dimension 4, and finally (6) simplifies invariants that can be\nexpressed as product of dual invariants. Invar runs on top of the tensor\ncomputer algebra systems xTensor (for Mathematica) and Canon (for Maple)."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2008.05.009", 
    "link": "http://arxiv.org/pdf/0803.0862v1", 
    "title": "xPerm: fast index canonicalization for tensor computer algebra", 
    "arxiv-id": "0803.0862v1", 
    "author": "Jose M. Martin-Garcia", 
    "publish": "2008-03-06T13:26:32Z", 
    "summary": "We present a very fast implementation of the Butler-Portugal algorithm for\nindex canonicalization with respect to permutation symmetries. It is called\nxPerm, and has been written as a combination of a Mathematica package and a C\nsubroutine. The latter performs the most demanding parts of the computations\nand can be linked from any other program or computer algebra system. We\ndemonstrate with tests and timings the effectively polynomial performance of\nthe Butler-Portugal algorithm with respect to the number of indices, though we\nalso show a case in which it is exponential. Our implementation handles generic\ntensorial expressions with several dozen indices in hundredths of a second, or\none hundred indices in a few seconds, clearly outperforming all other current\ncanonicalizers. The code has been already under intensive testing for several\nyears and has been essential in recent investigations in large-scale tensor\ncomputer algebra."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.cpc.2008.05.009", 
    "link": "http://arxiv.org/pdf/0803.1110v1", 
    "title": "On the Computation of the Topology of a Non-Reduced Implicit Space Curve", 
    "arxiv-id": "0803.1110v1", 
    "author": "Olivier Ruatta", 
    "publish": "2008-03-07T15:28:52Z", 
    "summary": "An algorithm is presented for the computation of the topology of a\nnon-reduced space curve defined as the intersection of two implicit algebraic\nsurfaces. It computes a Piecewise Linear Structure (PLS) isotopic to the\noriginal space curve. The algorithm is designed to provide the exact result for\nall inputs. It's a symbolic-numeric algorithm based on subresultant\ncomputation. Simple algebraic criteria are given to certify the output of the\nalgorithm. The algorithm uses only one projection of the non-reduced space\ncurve augmented with adjacency information around some \"particular points\" of\nthe space curve. The algorithm is implemented with the Mathemagix Computer\nAlgebra System (CAS) using the SYNAPS library as a backend."
},{
    "category": "math.NT", 
    "doi": "10.1016/j.cpc.2008.05.009", 
    "link": "http://arxiv.org/pdf/0803.3419v2", 
    "title": "Decomposing replicable functions", 
    "arxiv-id": "0803.3419v2", 
    "author": "David Sevilla", 
    "publish": "2008-03-24T16:02:26Z", 
    "summary": "We describe an algorithm to decompose rational functions from which we\ndetermine the poset of groups fixing these functions."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.cpc.2008.05.009", 
    "link": "http://arxiv.org/pdf/0805.4543v2", 
    "title": "Determination of the basis of the space of all root functionals of a   system of polynomial equations and of the basis of its ideal by the operation   of the extension of bounded root functionals", 
    "arxiv-id": "0805.4543v2", 
    "author": "Timur R. Seifullin", 
    "publish": "2008-05-29T18:15:22Z", 
    "summary": "It is proposed the algorithm that find a basis of the ideal and a basis of\nthe space of all root functionals by using the extension operation for bounded\nroot functionals, when the number of polynomials is equal to the number of\nvariables, if it is known that the ideal of polynomials is 0-dimensional. The\nasyptotic complexity of this algorithm is d^{O(n)} operations, where n is the\nnumber of polynomials and the number of variables, d is the maximal degree of\npolynomials. The extension operation has connection with the multivariate\nBezoutian construction."
},{
    "category": "cs.AI", 
    "doi": "10.1016/j.cpc.2008.05.009", 
    "link": "http://arxiv.org/pdf/0806.0250v1", 
    "title": "Checking the Quality of Clinical Guidelines using Automated Reasoning   Tools", 
    "arxiv-id": "0806.0250v1", 
    "author": "Patrick van Bommel", 
    "publish": "2008-06-02T11:02:40Z", 
    "summary": "Requirements about the quality of clinical guidelines can be represented by\nschemata borrowed from the theory of abductive diagnosis, using temporal logic\nto model the time-oriented aspects expressed in a guideline. Previously, we\nhave shown that these requirements can be verified using interactive theorem\nproving techniques. In this paper, we investigate how this approach can be\nmapped to the facilities of a resolution-based theorem prover, Otter, and a\ncomplementary program that searches for finite models of first-order\nstatements, Mace. It is shown that the reasoning required for checking the\nquality of a guideline can be mapped to such fully automated theorem-proving\nfacilities. The medical quality of an actual guideline concerning diabetes\nmellitus 2 is investigated in this way."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jsc.2008.06.001", 
    "link": "http://arxiv.org/pdf/0806.4127v1", 
    "title": "The implicit equation of a canal surface", 
    "arxiv-id": "0806.4127v1", 
    "author": "Severinas Zube", 
    "publish": "2008-06-25T15:22:16Z", 
    "summary": "A canal surface is an envelope of a one parameter family of spheres. In this\npaper we present an efficient algorithm for computing the implicit equation of\na canal surface generated by a rational family of spheres. By using Laguerre\nand Lie geometries, we relate the equation of the canal surface to the equation\nof a dual variety of a certain curve in 5-dimensional projective space. We\ndefine the \\mu-basis for arbitrary dimension and give a simple algorithm for\nits computation. This is then applied to the dual variety, which allows us to\ndeduce the implicit equations of the the dual variety, the canal surface and\nany offset to the canal surface."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2008.06.001", 
    "link": "http://arxiv.org/pdf/0808.0753v1", 
    "title": "Ranking Catamorphisms and Unranking Anamorphisms on Hereditarily Finite   Datatypes", 
    "arxiv-id": "0808.0753v1", 
    "author": "Paul Tarau", 
    "publish": "2008-08-06T00:54:05Z", 
    "summary": "Using specializations of unfold and fold on a generic tree data type we\nderive unranking and ranking functions providing natural number encodings for\nvarious Hereditarily Finite datatypes.\n  In this context, we interpret unranking operations as instances of a generic\nanamorphism and ranking operations as instances of the corresponding\ncatamorphism.\n  Starting with Ackerman's Encoding from Hereditarily Finite Sets to Natural\nNumbers we define pairings and tuple encodings that provide building blocks for\na theory of Hereditarily Finite Functions.\n  The more difficult problem of ranking and unranking Hereditarily Finite\nPermutations is then tackled using Lehmer codes and factoradics.\n  The self-contained source code of the paper, as generated from a literate\nHaskell program, is available at\n\\url{http://logic.csci.unt.edu/tarau/research/2008/fFUN.zip}.\n  Keywords: ranking/unranking, pairing/tupling functions, Ackermann encoding,\nhereditarily finite sets, hereditarily finite functions, permutations and\nfactoradics, computational mathematics, Haskell data representations"
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2008.01.001", 
    "link": "http://arxiv.org/pdf/0808.2543v1", 
    "title": "A Refined Difference Field Theory for Symbolic Summation", 
    "arxiv-id": "0808.2543v1", 
    "author": "Carsten Schneider", 
    "publish": "2008-08-19T07:46:04Z", 
    "summary": "In this article we present a refined summation theory based on Karr's\ndifference field approach. The resulting algorithms find sum representations\nwith optimal nested depth. For instance, the algorithms have been applied\nsuccessively to evaluate Feynman integrals from Perturbative Quantum Field\nTheory."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jsc.2008.01.001", 
    "link": "http://arxiv.org/pdf/0808.2596v1", 
    "title": "Parameterized Telescoping Proves Algebraic Independence of Sums", 
    "arxiv-id": "0808.2596v1", 
    "author": "Carsten Schneider", 
    "publish": "2008-08-19T13:58:01Z", 
    "summary": "Usually creative telescoping is used to derive recurrences for sums. In this\narticle we show that the non-existence of a creative telescoping solution, and\nmore generally, of a parameterized telescoping solution, proves algebraic\nindependence of certain types of sums. Combining this fact with\nsummation-theory shows transcendence of whole classes of sums. Moreover, this\nresult throws new light on the question why, e.g., Zeilberger's algorithm fails\nto find a recurrence with minimal order."
},{
    "category": "math.MG", 
    "doi": "10.1090/S0025-5718-2010-02378-6", 
    "link": "http://arxiv.org/pdf/0809.2083v3", 
    "title": "How to Integrate a Polynomial over a Simplex", 
    "arxiv-id": "0809.2083v3", 
    "author": "Mich\u00e8le Vergne", 
    "publish": "2008-09-11T19:00:12Z", 
    "summary": "This paper settles the computational complexity of the problem of integrating\na polynomial function f over a rational simplex. We prove that the problem is\nNP-hard for arbitrary polynomials via a generalization of a theorem of Motzkin\nand Straus. On the other hand, if the polynomial depends only on a fixed number\nof variables, while its degree and the dimension of the simplex are allowed to\nvary, we prove that integration can be done in polynomial time. As a\nconsequence, for polynomials of fixed total degree, there is a polynomial time\nalgorithm as well. We conclude the article with extensions to other polytopes,\ndiscussion of other available methods and experimental results."
},{
    "category": "math-ph", 
    "doi": "10.1090/S0025-5718-2010-02378-6", 
    "link": "http://arxiv.org/pdf/0809.4983v1", 
    "title": "Poisson Homology in Degree 0 for some Rings of Symplectic Invariants", 
    "arxiv-id": "0809.4983v1", 
    "author": "Fr\u00e9d\u00e9ric Butin", 
    "publish": "2008-09-29T15:16:33Z", 
    "summary": "Let $\\go{g}$ be a finite-dimensional semi-simple Lie algebra, $\\go{h}$ a\nCartan subalgebra of $\\go{g}$, and $W$ its Weyl group. The group $W$ acts\ndiagonally on $V:=\\go{h}\\oplus\\go{h}^*$, as well as on $\\mathbb{C}[V]$. The\npurpose of this article is to study the Poisson homology of the algebra of\ninvariants $\\mathbb{C}[V]^W$ endowed with the standard symplectic bracket. To\nbegin with, we give general results about the Poisson homology space in degree\n0, denoted by $HP_0(\\mathbb{C}[V]^W)$, in the case where $\\go{g}$ is of type\n$B_n-C_n$ or $D_n$, results which support Alev's conjecture. Then we are\nfocusing the interest on the particular cases of ranks 2 and 3, by computing\nthe Poisson homology space in degree 0 in the cases where $\\go{g}$ is of type\n$B_2$ ($\\go{so}_5$), $D_2$ ($\\go{so}_4$), then $B_3$ ($\\go{so}_7$), and\n$D_3=A_3$ ($\\go{so}_6\\simeq\\go{sl}_4$). In order to do this, we make use of a\nfunctional equation introduced by Y. Berest, P. Etingof and V. Ginzburg. We\nrecover, by a different method, the result established by J. Alev and L.\nFoissy, according to which the dimension of $HP_0(\\mathbb{C}[V]^W)$ equals 2\nfor $B_2$. Then we calculate the dimension of this space and we show that it is\nequal to 1 for $D_2$. We also calculate it for the rank 3 cases, we show that\nit is equal to 3 for $B_3-C_3$ and 1 for $D_3=A_3$."
},{
    "category": "cs.CG", 
    "doi": "10.1090/S0025-5718-2010-02378-6", 
    "link": "http://arxiv.org/pdf/0810.1997v2", 
    "title": "Characterizing 1-Dof Henneberg-I graphs with efficient configuration   spaces", 
    "arxiv-id": "0810.1997v2", 
    "author": "Meera Sitharam", 
    "publish": "2008-10-12T20:17:21Z", 
    "summary": "We define and study exact, efficient representations of realization spaces of\na natural class of underconstrained 2D Euclidean Distance Constraint\nSystems(EDCS) or Frameworks based on 1-dof Henneberg-I graphs. Each\nrepresentation corresponds to a choice of parameters and yields a different\nparametrized configuration space. Our notion of efficiency is based on the\nalgebraic complexities of sampling the configuration space and of obtaining a\nrealization from the sample (parametrized) configuration. Significantly, we\ngive purely combinatorial characterizations that capture (i) the class of\ngraphs that have efficient configuration spaces and (ii) the possible choices\nof representation parameters that yield efficient configuration spaces for a\ngiven graph. Our results automatically yield an efficient algorithm for\nsampling realizations, without missing extreme or boundary realizations. In\naddition, our results formally show that our definition of efficient\nconfiguration space is robust and that our characterizations are tight. We\nchoose the class of 1-dof Henneberg-I graphs in order to take the next step in\na systematic and graded program of combinatorial characterizations of efficient\nconfiguration spaces. In particular, the results presented here are the first\ncharacterizations that go beyond graphs that have connected and convex\nconfiguration spaces."
},{
    "category": "cs.SC", 
    "doi": "10.1090/S0025-5718-2010-02378-6", 
    "link": "http://arxiv.org/pdf/0810.3641v1", 
    "title": "Rational Hadamard products via Quantum Diagonal Operators", 
    "arxiv-id": "0810.3641v1", 
    "author": "Karol A. Penson", 
    "publish": "2008-10-20T19:16:29Z", 
    "summary": "We use the remark that, through Bargmann-Fock representation, diagonal\noperators of the Heisenberg-Weyl algebra are scalars for the Hadamard product\nto give some properties (like the stability of periodic fonctions) of the\nHadamard product by a rational fraction. In particular, we provide through this\nway explicit formulas for the multiplication table of the Hadamard product in\nthe algebra of rational functions in $\\C[[z]]$."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s00037-010-0294-0", 
    "link": "http://arxiv.org/pdf/0810.5685v6", 
    "title": "Interpolation of Shifted-Lacunary Polynomials", 
    "arxiv-id": "0810.5685v6", 
    "author": "Daniel S. Roche", 
    "publish": "2008-10-31T13:35:08Z", 
    "summary": "Given a \"black box\" function to evaluate an unknown rational polynomial f in\nQ[x] at points modulo a prime p, we exhibit algorithms to compute the\nrepresentation of the polynomial in the sparsest shifted power basis. That is,\nwe determine the sparsity t, the shift s (a rational), the exponents 0 <= e1 <\ne2 < ... < et, and the coefficients c1,...,ct in Q\\{0} such that f(x) =\nc1(x-s)^e1+c2(x-s)^e2+...+ct(x-s)^et. The computed sparsity t is absolutely\nminimal over any shifted power basis. The novelty of our algorithm is that the\ncomplexity is polynomial in the (sparse) representation size, and in particular\nis logarithmic in deg(f). Our method combines previous celebrated results on\nsparse interpolation and computing sparsest shifts, and provides a way to\nhandle polynomials with extremely high degree which are, in some sense, sparse\nin information."
},{
    "category": "math.AG", 
    "doi": "10.1007/s00037-010-0294-0", 
    "link": "http://arxiv.org/pdf/0812.0601v3", 
    "title": "Polynomial relations among principal minors of a 4x4-matrix", 
    "arxiv-id": "0812.0601v3", 
    "author": "Bernd Sturmfels", 
    "publish": "2008-12-02T21:34:51Z", 
    "summary": "The image of the principal minor map for n x n-matrices is shown to be\nclosed. In the 19th century, Nansen and Muir studied the implicitization\nproblem of finding all relations among principal minors when n=4. We complete\ntheir partial results by constructing explicit polynomials of degree 12 that\nscheme-theoretically define this affine variety and also its projective closure\nin $\\PP^{15}$. The latter is the main component in the singular locus of the 2\nx 2 x 2 x 2-hyperdeterminant."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0812.4706v2", 
    "title": "On the total order of reducibility of a pencil of algebraic plane curves", 
    "arxiv-id": "0812.4706v2", 
    "author": "Guillaume Ch\u00e8ze", 
    "publish": "2008-12-26T20:56:46Z", 
    "summary": "In this paper, the problem of bounding the number of reducible curves in a\npencil of algebraic plane curves is addressed. Unlike most of the previous\nrelated works, each reducible curve of the pencil is here counted with its\nappropriate multiplicity. It is proved that this number of reducible curves,\ncounted with multiplicity, is bounded by d^2-1 where d is the degree of the\npencil. Then, a sharper bound is given by taking into account the Newton's\npolygon of the pencil."
},{
    "category": "math.SP", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0812.4974v1", 
    "title": "Using a computer algebra system to simplify expressions for   Titchmarsh-Weyl m-functions associated with the Hydrogen Atom on the half   line", 
    "arxiv-id": "0812.4974v1", 
    "author": "Charles Fulton", 
    "publish": "2008-12-29T21:10:17Z", 
    "summary": "In this paper we give simplified formulas for certain polynomials which arise\nin some new Titchmarsh-Weyl m-functions for the radial part of the separated\nHydrogen atom on the half line and two independent programs for generating them\nusing the symbolic manipulator Mathematica."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0901.2612v1", 
    "title": "Some Open Problems in Combinatorial Physics", 
    "arxiv-id": "0901.2612v1", 
    "author": "H. Cheballah", 
    "publish": "2009-01-17T07:11:12Z", 
    "summary": "We point out four problems which have arisen during the recent research in\nthe domain of Combinatorial Physics."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0902.0239v3", 
    "title": "The acoustic wave equation in the expanding universe. Sachs-Wolfe   theorem", 
    "arxiv-id": "0902.0239v3", 
    "author": "Andrzej Woszczyna", 
    "publish": "2009-02-02T10:36:47Z", 
    "summary": "In this paper the acoustic field propagating in the early hot ($p=\\epsilon/$)\nuniverse of arbitrary space curvature ($K=0, \\pm 1$) is considered. The field\nequations are reduced to the d'Alembert equation in an auxiliary static\nRoberson-Walker space-time. Symbolic computation in {\\em Mathematica} is\napplied."
},{
    "category": "cs.CY", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0903.0194v1", 
    "title": "A Graph Analysis of the Linked Data Cloud", 
    "arxiv-id": "0903.0194v1", 
    "author": "Marko A. Rodriguez", 
    "publish": "2009-03-02T04:47:28Z", 
    "summary": "The Linked Data community is focused on integrating Resource Description\nFramework (RDF) data sets into a single unified representation known as the Web\nof Data. The Web of Data can be traversed by both man and machine and shows\npromise as the \\textit{de facto} standard for integrating data world wide much\nlike the World Wide Web is the \\textit{de facto} standard for integrating\ndocuments. On February 27$^\\text{th}$ of 2009, an updated Linked Data cloud\nvisualization was made publicly available. This visualization represents the\nvarious RDF data sets currently in the Linked Data cloud and their interlinking\nrelationships. For the purposes of this article, this visual representation was\nmanually transformed into a directed graph and analyzed."
},{
    "category": "cs.AI", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0903.1659v1", 
    "title": "Heuristic Reasoning on Graph and Game Complexity of Sudoku", 
    "arxiv-id": "0903.1659v1", 
    "author": "Zhe Chen", 
    "publish": "2009-03-09T22:35:14Z", 
    "summary": "The Sudoku puzzle has achieved worldwide popularity recently, and attracted\ngreat attention of the computational intelligence community. Sudoku is always\nconsidered as Satisfiability Problem or Constraint Satisfaction Problem. In\nthis paper, we propose to focus on the essential graph structure underlying the\nSudoku puzzle. First, we formalize Sudoku as a graph. Then a solving algorithm\nbased on heuristic reasoning on the graph is proposed. The related r-Reduction\ntheorem, inference theorem and their properties are proved, providing the\nformal basis for developments of Sudoku solving systems. In order to evaluate\nthe difficulty levels of puzzles, a quantitative measurement of the complexity\nlevel of Sudoku puzzles based on the graph structure and information theory is\nproposed. Experimental results show that all the puzzles can be solved fast\nusing the proposed heuristic reasoning, and that the proposed game complexity\nmetrics can discriminate difficulty levels of puzzles perfectly."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0903.2101v2", 
    "title": "Combinatorial Deformations of Algebras: Twisting and Perturbations", 
    "arxiv-id": "0903.2101v2", 
    "author": "Gleb Koshevoy", 
    "publish": "2009-03-12T06:12:32Z", 
    "summary": "The framework used to prove the multiplicative law deformation of the algebra\nof Feynman-Bender diagrams is a \\textit{twisted shifted dual law} (in fact,\ntwice). We give here a clear interpretation of its two parameters. The crossing\nparameter is a deformation of the tensor structure whereas the superposition\nparameters is a perturbation of the shuffle coproduct of Hoffman type which, in\nturn, can be interpreted as the diagonal restriction of a superproduct. Here,\nwe systematically detail these constructions."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0903.2158v1", 
    "title": "Supernodal Analysis Revisited", 
    "arxiv-id": "0903.2158v1", 
    "author": "Eberhard H. -A. Gerbracht", 
    "publish": "2009-03-12T12:25:45Z", 
    "summary": "In this paper we show how to extend the known algorithm of nodal analysis in\nsuch a way that, in the case of circuits without nullors and controlled sources\n(but allowing for both, independent current and voltage sources), the system of\nnodal equations describing the circuit is partitioned into one part, where the\nnodal variables are explicitly given as linear combinations of the voltage\nsources and the voltages of certain reference nodes, and another, which\ncontains the node variables of these reference nodes only and which moreover\ncan be read off directly from the given circuit. Neither do we need\npreparational graph transformations, nor do we need to introduce additional\ncurrent variables (as in MNA). Thus this algorithm is more accessible to\nstudents, and consequently more suitable for classroom presentations."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0904.0981v3", 
    "title": "Dependency Pairs and Polynomial Path Orders", 
    "arxiv-id": "0904.0981v3", 
    "author": "Georg Moser", 
    "publish": "2009-04-06T18:10:53Z", 
    "summary": "We show how polynomial path orders can be employed efficiently in conjunction\nwith weak innermost dependency pairs to automatically certify polynomial\nruntime complexity of term rewrite systems and the polytime computability of\nthe functions computed. The established techniques have been implemented and we\nprovide ample experimental data to assess the new method."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jalgebra.2011.06.006", 
    "link": "http://arxiv.org/pdf/0904.2323v1", 
    "title": "A Symbolic Summation Approach to Find Optimal Nested Sum Representations", 
    "arxiv-id": "0904.2323v1", 
    "author": "Carsten Schneider", 
    "publish": "2009-04-15T14:00:07Z", 
    "summary": "We consider the following problem: Given a nested sum expression, find a sum\nrepresentation such that the nested depth is minimal. We obtain a symbolic\nsummation framework that solves this problem for sums defined, e.g., over\nhypergeometric, $q$-hypergeometric or mixed hypergeometric expressions.\nRecently, our methods have found applications in quantum field theory."
},{
    "category": "cond-mat.stat-mech", 
    "doi": "10.1088/1367-2630/11/2/023001", 
    "link": "http://arxiv.org/pdf/0904.4010v1", 
    "title": "Counting Complex Disordered States by Efficient Pattern Matching:   Chromatic Polynomials and Potts Partition Functions", 
    "arxiv-id": "0904.4010v1", 
    "author": "Sebastian Stolzenberg", 
    "publish": "2009-04-27T12:49:26Z", 
    "summary": "Counting problems, determining the number of possible states of a large\nsystem under certain constraints, play an important role in many areas of\nscience. They naturally arise for complex disordered systems in physics and\nchemistry, in mathematical graph theory, and in computer science. Counting\nproblems, however, are among the hardest problems to access computationally.\nHere, we suggest a novel method to access a benchmark counting problem, finding\nchromatic polynomials of graphs. We develop a vertex-oriented symbolic pattern\nmatching algorithm that exploits the equivalence between the chromatic\npolynomial and the zero-temperature partition function of the Potts\nantiferromagnet on the same graph. Implementing this bottom-up algorithm using\nappropriate computer algebra, the new method outperforms standard top-down\nmethods by several orders of magnitude, already for moderately sized graphs. As\na first application, we compute chromatic polynomials of samples of the simple\ncubic lattice, for the first time computationally accessing three-dimensional\nlattices of physical relevance. The method offers straightforward\ngeneralizations to several other counting problems."
},{
    "category": "hep-th", 
    "doi": "10.1088/1367-2630/11/2/023001", 
    "link": "http://arxiv.org/pdf/0905.2705v2", 
    "title": "Programming Realization of Symbolic Computations for Non-linear   Commutator Superalgebras over the Heisenberg--Weyl Superalgebra: Data   Structures and Processing Methods", 
    "arxiv-id": "0905.2705v2", 
    "author": "A. A. Reshetnyak", 
    "publish": "2009-05-16T21:29:03Z", 
    "summary": "We suggest a programming realization of an algorithm for verifying a given\nset of algebraic relations in the form of a supercommutator multiplication\ntable for the Verma module, which is constructed according to a generalized\nCartan procedure for a quadratic superalgebra and whose elements are realized\nas a formal power series with respect to non-commuting elements. To this end,\nwe propose an algebraic procedure of Verma module construction and its\nrealization in terms of non-commuting creation and annihilation operators of a\ngiven Heisenberg--Weyl superalgebra. In doing so, we set up a problem which\nnaturally arises within a Lagrangian description of higher-spin fields in\nanti-de-Sitter (AdS) spaces: to verify the fact that the resulting Verma module\nelements obey the given commutator multiplication for the original non-linear\nsuperalgebra. The problem setting is based on a restricted principle of\nmathematical induction, in powers of inverse squared radius of the AdS-space.\nFor a construction of an algorithm resolving this problem, we use a two-level\ndata model within the object-oriented approach, which is realized on a basis of\nthe programming language C#. The program allows one to consider objects (of a\nless general nature than non-linear commutator superalgebras) that fall under\nthe class of so-called $GR$-algebras, for whose treatment one widely uses the\nmodule \\emph{Plural} of the system \\emph{Singular} of symbolic computations for\npolynomials."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1367-2630/11/2/023001", 
    "link": "http://arxiv.org/pdf/0906.1018v1", 
    "title": "Eliminating Human Insight: An Algorithmic Proof of Stembridge's TSPP   Theorem", 
    "arxiv-id": "0906.1018v1", 
    "author": "Christoph Koutschan", 
    "publish": "2009-06-04T22:56:08Z", 
    "summary": "We present a new proof of Stembridge's theorem about the enumeration of\ntotally symmetric plane partitions using the methodology suggested in the\nrecent Koutschan-Kauers-Zeilberger semi-rigorous proof of the Andrews-Robbins\nq-TSPP conjecture. Our proof makes heavy use of computer algebra and is\ncompletely automatic. We describe new methods that make the computations\nfeasible in the first place. The tantalizing aspect of this work is that the\nsame methods can be applied to prove the q-TSPP conjecture (that is a\nq-analogue of Stembridge's theorem and open for more than 25 years); the only\nhurdle here is still the computational complexity."
},{
    "category": "math.RA", 
    "doi": "10.1080/10586458.2012.738538", 
    "link": "http://arxiv.org/pdf/0906.1272v3", 
    "title": "The alternative operad is not Koszul", 
    "arxiv-id": "0906.1272v3", 
    "author": "Pasha Zusmanovich", 
    "publish": "2009-06-06T12:44:23Z", 
    "summary": "Using computer calculations, we prove the statement in the title."
},{
    "category": "math.NT", 
    "doi": "10.1080/10586458.2012.738538", 
    "link": "http://arxiv.org/pdf/0906.2925v1", 
    "title": "Noether's forms for the study of non-composite rational functions and   their spectrum", 
    "arxiv-id": "0906.2925v1", 
    "author": "Salah Najib", 
    "publish": "2009-06-16T13:10:18Z", 
    "summary": "In this paper, the spectrum and the decomposability of a multivariate\nrational function are studied by means of the effective Noether's\nirreducibility theorem given by Ruppert. With this approach, some new effective\nresults are obtained. In particular, we show that the reduction modulo p of the\nspectrum of a given integer multivariate rational function r coincides with the\nspectrum of the reduction of r modulo p for p a prime integer greater or equal\nto an explicit bound. This bound is given in terms of the degree, the height\nand the number of variables of r. With the same strategy, we also study the\ndecomposability of r modulo p. Some similar explicit results are also provided\nfor the case of polynomials with coefficients in a polynomial ring."
},{
    "category": "cs.LO", 
    "doi": "10.1080/10586458.2012.738538", 
    "link": "http://arxiv.org/pdf/0907.5527v2", 
    "title": "Proof Theory at Work: Complexity Analysis of Term Rewrite Systems", 
    "arxiv-id": "0907.5527v2", 
    "author": "Georg Moser", 
    "publish": "2009-07-31T13:19:25Z", 
    "summary": "This thesis is concerned with investigations into the \"complexity of term\nrewriting systems\". Moreover the majority of the presented work deals with the\n\"automation\" of such a complexity analysis. The aim of this introduction is to\npresent the main ideas in an easily accessible fashion to make the result\npresented accessible to the general public. Necessarily some technical points\nare stated in an over-simplified way."
},{
    "category": "math.CO", 
    "doi": "10.1080/10586458.2012.738538", 
    "link": "http://arxiv.org/pdf/0908.2332v2", 
    "title": "Ladder Operators and Endomorphisms in Combinatorial Physics", 
    "arxiv-id": "0908.2332v2", 
    "author": "Andrzej Horzela", 
    "publish": "2009-08-17T11:40:06Z", 
    "summary": "Starting with the Heisenberg-Weyl algebra, fundamental to quantum physics, we\nfirst show how the ordering of the non-commuting operators intrinsic to that\nalgebra gives rise to generalizations of the classical Stirling Numbers of\nCombinatorics. These may be expressed in terms of infinite, but {\\em\nrow-finite}, matrices, which may also be considered as endomorphisms of\n$\\C[[x]]$. This leads us to consider endomorphisms in more general spaces, and\nthese in turn may be expressed in terms of generalizations of the\nladder-operators familiar in physics."
},{
    "category": "cs.SC", 
    "doi": "10.1080/10586458.2012.738538", 
    "link": "http://arxiv.org/pdf/0909.4950v2", 
    "title": "Implementing Gr\u00f6bner bases for operads", 
    "arxiv-id": "0909.4950v2", 
    "author": "Mikael Vejdemo-Johansson", 
    "publish": "2009-09-27T16:54:34Z", 
    "summary": "We present an implementation of the algorithm for computing Groebner bases\nfor operads due to the first author and A. Khoroshkin. We discuss the actual\nalgorithms, the choices made for the implementation platform and the data\nrepresentation, and strengths and weaknesses of our approach."
},{
    "category": "cs.SC", 
    "doi": "10.1080/10586458.2012.738538", 
    "link": "http://arxiv.org/pdf/0910.2973v1", 
    "title": "Computing rational points in convex semi-algebraic sets and SOS   decompositions", 
    "arxiv-id": "0910.2973v1", 
    "author": "Lihong Zhi", 
    "publish": "2009-10-15T19:18:05Z", 
    "summary": "Let ${\\cal P}=\\{h_1, ..., h_s\\}\\subset \\Z[Y_1, ..., Y_k]$, $D\\geq \\deg(h_i)$\nfor $1\\leq i \\leq s$, $\\sigma$ bounding the bit length of the coefficients of\nthe $h_i$'s, and $\\Phi$ be a quantifier-free ${\\cal P}$-formula defining a\nconvex semi-algebraic set. We design an algorithm returning a rational point in\n${\\cal S}$ if and only if ${\\cal S}\\cap \\Q\\neq\\emptyset$. It requires\n$\\sigma^{\\bigO(1)}D^{\\bigO(k^3)}$ bit operations. If a rational point is\noutputted its coordinates have bit length dominated by $\\sigma D^{\\bigO(k^3)}$.\nUsing this result, we obtain a procedure deciding if a polynomial $f\\in \\Z[X_1,\n>..., X_n]$ is a sum of squares of polynomials in $\\Q[X_1, ..., X_n]$. Denote\nby $d$ the degree of $f$, $\\tau$ the maximum bit length of the coefficients in\n$f$, $D={{n+d}\\choose{n}}$ and $k\\leq D(D+1)-{{n+2d}\\choose{n}}$. This\nprocedure requires $\\tau^{\\bigO(1)}D^{\\bigO(k^3)}$ bit operations and the\ncoefficients of the outputted polynomials have bit length dominated by $\\tau\nD^{\\bigO(k^3)}$."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TIT.2010.2054150", 
    "link": "http://arxiv.org/pdf/0911.0130v3", 
    "title": "Minimal Polynomial Algorithms for Finite Sequences", 
    "arxiv-id": "0911.0130v3", 
    "author": "Graham H. Norton", 
    "publish": "2009-11-02T04:06:37Z", 
    "summary": "We show that a straightforward rewrite of a known minimal polynomial\nalgorithm yields a simpler version of a recent algorithm of A. Salagean."
},{
    "category": "cs.SC", 
    "doi": "10.1109/TIT.2010.2054150", 
    "link": "http://arxiv.org/pdf/0911.3674v1", 
    "title": "Deciding Regularity of the Set of Instances of a Set of Terms with   Regular Constraints is EXPTIME-Complete", 
    "arxiv-id": "0911.3674v1", 
    "author": "Sebastian Maneth", 
    "publish": "2009-11-18T23:02:12Z", 
    "summary": "Finite-state tree automata are a well studied formalism for representing term\nlanguages. This paper studies the problem of determining the regularity of the\nset of instances of a finite set of terms with variables, where each variable\nis restricted to instantiations of a regular set given by a tree automaton. The\nproblem was recently proved decidable, but with an unknown complexity. Here,\nthe exact complexity of the problem is determined by proving\nEXPTIME-completeness. The main contribution is a new, exponential time\nalgorithm that performs various exponential transformations on the involved\nterms and tree automata, and decides regularity by analyzing formulas over\ninequality and height predicates."
},{
    "category": "cs.LO", 
    "doi": "10.1109/TIT.2010.2054150", 
    "link": "http://arxiv.org/pdf/0911.4051v1", 
    "title": "A computational definition of the notion of vectorial space", 
    "arxiv-id": "0911.4051v1", 
    "author": "Gilles Dowek", 
    "publish": "2009-11-20T13:56:14Z", 
    "summary": "We usually define an algebraic structure by a set, some operations defined on\nthis set and some propositions that the algebraic structure must validate. In\nsome cases, we can replace these propositions by an algorithm on terms\nconstructed upon these operations that the algebraic structure must validate.\nWe show in this note that this is the case for the notions of vectorial space\nand bilinear operation. KEYWORDS: Rewrite system, vector space, bilinear\noperation, tensorial product, semantics, quantum programming languages,\nprobabilistic programming languages."
},{
    "category": "cs.CG", 
    "doi": "10.1109/TIT.2010.2054150", 
    "link": "http://arxiv.org/pdf/0911.4375v3", 
    "title": "Automated Proofs in Geometry : Computing Upper Bounds for the Heilbronn   Problem for Triangles", 
    "arxiv-id": "0911.4375v3", 
    "author": "Jean-Paul Delahaye", 
    "publish": "2009-11-23T11:43:21Z", 
    "summary": "We propose a method for computing upper bounds for the Heilbronn problem for\ntriangles."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TIT.2010.2054150", 
    "link": "http://arxiv.org/pdf/0911.5459v3", 
    "title": "Shortest Two-way Linear Recurrences", 
    "arxiv-id": "0911.5459v3", 
    "author": "Graham H. Norton", 
    "publish": "2009-11-29T04:36:32Z", 
    "summary": "Let $s$ be a finite sequence over a field of length $n$. It is well-known\nthat if $s$ satisfies a linear recurrence of order $d$ with non-zero constant\nterm, then the reverse of $s$ also satisfies a recurrence of order $d$ (with\ncoefficients in reverse order). A recent article of A. Salagean proposed an\nalgorithm to find such a shortest 'two-way' recurrence -- which may be longer\nthan a linear recurrence for $s$ of shortest length $\\LC_n$.\n  We give a new and simpler algorithm to compute a shortest two-way linear\nrecurrence. First we show that the pairs of polynomials we use to construct a\nminimal polynomial iteratively are always relatively prime; we also give the\nextended multipliers. Then we combine degree lower bounds with a\nstraightforward rewrite of a published algorithm due to the author to obtain\nour simpler algorithm. The increase in shortest length is\n$\\max\\{n+1-2\\LC_n,0\\}$."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.14.7", 
    "link": "http://arxiv.org/pdf/0912.2554v1", 
    "title": "Parallelizing Deadlock Resolution in Symbolic Synthesis of Distributed   Programs", 
    "arxiv-id": "0912.2554v1", 
    "author": "Sandeep S. Kulkarni", 
    "publish": "2009-12-14T00:15:37Z", 
    "summary": "Previous work has shown that there are two major complexity barriers in the\nsynthesis of fault-tolerant distributed programs: (1) generation of fault-span,\nthe set of states reachable in the presence of faults, and (2) resolving\ndeadlock states, from where the program has no outgoing transitions. Of these,\nthe former closely resembles with model checking and, hence, techniques for\nefficient verification are directly applicable to it. Hence, we focus on\nexpediting the latter with the use of multi-core technology.\n  We present two approaches for parallelization by considering different design\nchoices. The first approach is based on the computation of equivalence classes\nof program transitions (called group computation) that are needed due to the\nissue of distribution (i.e., inability of processes to atomically read and\nwrite all program variables). We show that in most cases the speedup of this\napproach is close to the ideal speedup and in some cases it is superlinear. The\nsecond approach uses traditional technique of partitioning deadlock states\namong multiple threads. However, our experiments show that the speedup for this\napproach is small. Consequently, our analysis demonstrates that a simple\napproach of parallelizing the group computation is likely to be the effective\nmethod for using multi-core computing in the context of deadlock resolution."
},{
    "category": "cs.IT", 
    "doi": "10.4204/EPTCS.14.7", 
    "link": "http://arxiv.org/pdf/1001.1597v3", 
    "title": "The Berlekamp-Massey Algorithm via Minimal Polynomials", 
    "arxiv-id": "1001.1597v3", 
    "author": "Graham H. Norton", 
    "publish": "2010-01-11T11:40:51Z", 
    "summary": "We present a recursive minimal polynomial theorem for finite sequences over a\ncommutative integral domain $D$. This theorem is relative to any element of\n$D$. The ingredients are: the arithmetic of Laurent polynomials over $D$, a\nrecursive 'index function' and simple mathematical induction. Taking\nreciprocals gives a 'Berlekamp-Massey theorem' i.e. a recursive construction of\nthe polynomials arising in the Berlekamp-Massey algorithm, relative to any\nelement of $D$. The recursive theorem readily yields the iterative minimal\npolynomial algorithm due to the author and a transparent derivation of the\niterative Berlekamp-Massey algorithm.\n  We give an upper bound for the sum of the linear complexities of $s$ which is\ntight if $s$ has a perfect linear complexity profile. This implies that over a\nfield, both iterative algorithms require at most $2\\lfloor\n\\frac{n^2}{4}\\rfloor$ multiplications."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.15", 
    "link": "http://arxiv.org/pdf/1001.4573v1", 
    "title": "Proceedings Ninth International Workshop on Reduction Strategies in   Rewriting and Programming", 
    "arxiv-id": "1001.4573v1", 
    "author": "Maribel Fern\u00e1ndez", 
    "publish": "2010-01-26T01:05:09Z", 
    "summary": "This volume contains selected papers presented at the 9th International\nWorkshop on Reduction Strategies in Rewriting and Programming, WRS2009, which\nwas held in Brasilia on the 28th June 2009, associated to RTA 2009 (the 20th\nInternational Conference on Rewriting Techniques and Applications) at RDP, the\nFederated Conference on Rewriting, Deduction and Programming. Reduction\nstrategies define which (sub)expression(s) should be selected for evaluation\nand which rule(s) should be applied. These choices affect fundamental\nproperties of reductions, such as completeness, laziness and efficiency in\ngeneral. The WRS workshops promote research and collaboration in the area of\nreduction strategies and their applications in specification and programming,\ntheorem proving, software engineering, etc."
},{
    "category": "cs.DS", 
    "doi": "10.4204/EPTCS.15", 
    "link": "http://arxiv.org/pdf/1001.5272v1", 
    "title": "An in-place truncated Fourier transform and applications to polynomial   multiplication", 
    "arxiv-id": "1001.5272v1", 
    "author": "Daniel S. Roche", 
    "publish": "2010-01-28T21:10:41Z", 
    "summary": "The truncated Fourier transform (TFT) was introduced by van der Hoeven in\n2004 as a means of smoothing the \"jumps\" in running time of the ordinary FFT\nalgorithm that occur at power-of-two input sizes. However, the TFT still\nintroduces these jumps in memory usage. We describe in-place variants of the\nforward and inverse TFT algorithms, achieving time complexity O(n log n) with\nonly O(1) auxiliary space. As an application, we extend the second author's\nresults on space-restricted FFT-based polynomial multiplication to polynomials\nof arbitrary degree."
},{
    "category": "q-bio.NC", 
    "doi": "10.4204/EPTCS.15", 
    "link": "http://arxiv.org/pdf/1001.5420v1", 
    "title": "Stability and Bifurcation Analysis of Coupled Fitzhugh-Nagumo   Oscillators", 
    "arxiv-id": "1001.5420v1", 
    "author": "Sepanda Pouryahya", 
    "publish": "2010-01-29T15:25:26Z", 
    "summary": "Neurons are the central biological objects in understanding how the brain\nworks. The famous Hodgkin-Huxley model, which describes how action potentials\nof a neuron are initiated and propagated, consists of four coupled nonlinear\ndifferential equations. Because these equations are difficult to deal with,\nthere also exist several simplified models, of which many exhibit\npolynomial-like non-linearity. Examples of such models are the Fitzhugh-Nagumo\n(FHN) model, the Hindmarsh-Rose (HR) model, the Morris-Lecar (ML) model and the\nIzhikevich model. In this work, we first prescribe the biologically relevant\nparameter ranges for the FHN model and subsequently study the dynamical\nbehaviour of coupled neurons on small networks of two or three nodes. To do\nthis, we use a computational real algebraic geometry method called the\nDiscriminant Variety (DV) method to perform the stability and bifurcation\nanalysis of these small networks. A time series analysis of the FHN model can\nbe found elsewhere in related work[15]."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.15", 
    "link": "http://arxiv.org/pdf/1002.0012v1", 
    "title": "The Power of Vocabulary: The Case of Cyclotomic Polynomials", 
    "arxiv-id": "1002.0012v1", 
    "author": "James H. Davenport", 
    "publish": "2010-01-29T21:23:05Z", 
    "summary": "We observe that the vocabulary used to construct the \"answer\" to problems in\ncomputer algebra can have a dramatic effect on the computational complexity of\nsolving that problem. We recall a formalization of this observation and explain\nthe classic example of sparse polynomial arithmetic. For this case, we show\nthat it is possible to extend the vocabulary so as reap the benefits of\nconciseness whilst avoiding the obvious pitfall of repeating the problem\nstatement as the \"solution\".\n  It is possible to extend the vocabulary either by irreducible cyclotomics or\nby $x^n-1$: we look at the options and suggest that the pragmatist might opt\nfor both."
},{
    "category": "cs.IT", 
    "doi": "10.4204/EPTCS.15", 
    "link": "http://arxiv.org/pdf/1002.0179v2", 
    "title": "B\u00e9zout Identities Associated to a Finite Sequence", 
    "arxiv-id": "1002.0179v2", 
    "author": "Graham H. Norton", 
    "publish": "2010-02-01T04:56:36Z", 
    "summary": "We consider finite sequences $s\\in D^n$ where $D$ is a commutative, unital,\nintegral domain. We prove three sets of identities (possibly with repetitions),\neach involving $2n$ polynomials associated to $s$. The right-hand side of these\nidentities is a recursively-defined (non-zero) 'product-of-discrepancies'.\nThere are implied iterative algorithms (of quadratic complexity) for the\nleft-hand side coefficients; when the ground domain is factorial, the\nidentities are in effect B\\'ezout identities.\n  We give a number of applications: an algorithm to compute B\\'ezout\ncoefficients over a field; the outputs of the Berlekamp-Massey algorithm;\nsequences with perfect linear complexity profile; annihilating polynomials\nwhich do not vanish at zero and have minimal degree: we simplify and extend an\nalgorithm of Salagean to sequences over $D$. In the Appendix, we give a new\nproof of a theorem of Imamura and Yoshida on the linear complexity of reverse\nsequences, initially proved using Hankel matrices over a field and now valid\nfor sequences over a factorial domain."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.15", 
    "link": "http://arxiv.org/pdf/1002.4784v2", 
    "title": "Triangular Decomposition of Semi-algebraic Systems", 
    "arxiv-id": "1002.4784v2", 
    "author": "Rong Xiao", 
    "publish": "2010-02-25T13:39:09Z", 
    "summary": "Regular chains and triangular decompositions are fundamental and\nwell-developed tools for describing the complex solutions of polynomial\nsystems. This paper proposes adaptations of these tools focusing on solutions\nof the real analogue: semi-algebraic systems. We show that any such system can\nbe decomposed into finitely many {\\em regular semi-algebraic systems}. We\npropose two specifications of such a decomposition and present corresponding\nalgorithms. Under some assumptions, one type of decomposition can be computed\nin singly exponential time w.r.t.\\ the number of variables. We implement our\nalgorithms and the experimental results illustrate their effectiveness."
},{
    "category": "math.OA", 
    "doi": "10.1112/jlms/jdq054", 
    "link": "http://arxiv.org/pdf/1003.0502v2", 
    "title": "Stable polynomial division and essential normality of graded Hilbert   modules", 
    "arxiv-id": "1003.0502v2", 
    "author": "Orr Shalit", 
    "publish": "2010-03-02T05:21:42Z", 
    "summary": "The purpose of this paper is to initiate a new attack on Arveson's resistant\nconjecture, that all graded submodules of the $d$-shift Hilbert module $H^2$\nare essentially normal. We introduce the stable division property for modules\n(and ideals): a normed module $M$ over the ring of polynomials in $d$ variables\nhas the stable division property if it has a generating set $\\{f_1, ..., f_k\\}$\nsuch that every $h \\in M$ can be written as $h = \\sum_i a_i f_i$ for some\npolynomials $a_i$ such that $\\sum \\|a_i f_i\\| \\leq C\\|h\\|$. We show that\ncertain classes of modules have this property, and that the stable\ndecomposition $h = \\sum a_i f_i$ may be obtained by carefully applying\ntechniques from computational algebra. We show that when the algebra of\npolynomials in $d$ variables is given the natural $\\ell^1$ norm, then every\nideal is linearly equivalent to an ideal that has the stable division property.\nWe then show that a module $M$ that has the stable division property (with\nrespect to the appropriate norm) is $p$-essentially normal for $p > \\dim(M)$,\nas conjectured by Douglas. This result is used to give a new, unified proof\nthat certain classes of graded submodules are essentially normal. Finally, we\nreduce the problem of determining whether all graded submodules of the\n$d$-shift Hilbert module are essentially normal, to the problem of determining\nwhether all ideals generated by quadratic scalar valued polynomials are\nessentially normal."
},{
    "category": "math.AG", 
    "doi": "10.1112/jlms/jdq054", 
    "link": "http://arxiv.org/pdf/1003.3478v1", 
    "title": "Algorithms for Checking Rational Roots of $b$-functions and their   Applications", 
    "arxiv-id": "1003.3478v1", 
    "author": "Jorge Mart\u00edn-Morales", 
    "publish": "2010-03-17T21:12:36Z", 
    "summary": "Bernstein-Sato polynomial of a hypersurface is an important object with\nnumerous applications. It is known, that it is complicated to obtain it\ncomputationally, as a number of open questions and challenges indicate. In this\npaper we propose a family of algorithms called \\texttt{checkRoot} for optimized\ncheck of whether a given rational number is a root of Bernstein-Sato polynomial\nand the computations of its multiplicity. This algorithms are used in the new\napproach to compute the whole global or local Bernstein-Sato polynomial and\n$b$-function of a holonomic ideal with respect to weights. They are applied in\nnumerous situations, where there is a possibility to compute an upper bound for\nthe polynomial. Namely, it can be achieved by means of embedded resolution, for\ntopologically equivalent singularities or using the formula of A'Campo and\nspectral numbers. We also present approaches to the logarithmic comparison\nproblem and the intersection homology D-module. Several applications are\npresented as well as solutions to some challenges which were intractable with\nthe classical methods. One of the main applications consists of computing of a\nstratification of affine space with the local $b$-function being constant on\neach stratum. Notably, the algorithm we propose does not employ primary\ndecomposition. Also we apply our results for the computation of Bernstein-Sato\npolynomials for varieties. The methods from this paper have been implemented in\n{\\sc Singular:Plural} as libraries {\\tt dmod.lib} and {\\tt bfun.lib}. All the\nexamples from the paper have been computed with this implementation."
},{
    "category": "math.RA", 
    "doi": "10.1016/j.jsc.2010.10.009", 
    "link": "http://arxiv.org/pdf/1003.3785v1", 
    "title": "Computing diagonal form and Jacobson normal form of a matrix using   Gr\u00f6bner bases", 
    "arxiv-id": "1003.3785v1", 
    "author": "Kristina Schindelar", 
    "publish": "2010-03-19T12:41:04Z", 
    "summary": "In this paper we present two algorithms for the computation of a diagonal\nform of a matrix over non-commutative Euclidean domain over a field with the\nhelp of Gr\\\"obner bases. This can be viewed as the pre-processing for the\ncomputation of Jacobson normal form and also used for the computation of Smith\nnormal form in the commutative case. We propose a general framework for\nhandling, among other, operator algebras with rational coefficients. We employ\nspecial \"polynomial\" strategy in Ore localizations of non-commutative\n$G$-algebras and show its merits. In particular, for a given matrix $M$ we\nprovide an algorithm to compute $U,V$ and $D$ with fraction-free entries such\nthat $UMV=D$ holds. The polynomial approach allows one to obtain more precise\ninformation, than the rational one e. g. about singularities of the system.\n  Our implementation of polynomial strategy shows very impressive performance,\ncompared with methods, which directly use fractions. In particular, we\nexperience quite moderate swell of coefficients and obtain uncomplicated\ntransformation matrices. This shows that this method is well suitable for\nsolving nontrivial practical problems. We present an implementation of\nalgorithms in SINGULAR:PLURAL and compare it with other available systems. We\nleave questions on the algorithmic complexity of this algorithm open, but we\nstress the practical applicability of the proposed method to a bigger class of\nnon-commutative algebras."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jsc.2010.10.009", 
    "link": "http://arxiv.org/pdf/1003.4369v1", 
    "title": "A Modal Logic for Termgraph Rewriting", 
    "arxiv-id": "1003.4369v1", 
    "author": "A. Herzig", 
    "publish": "2010-03-23T10:34:14Z", 
    "summary": "We propose a modal logic tailored to describe graph transformations and\ndiscuss some of its properties. We focus on a particular class of graphs called\ntermgraphs. They are first-order terms augmented with sharing and cycles.\nTermgraphs allow one to describe classical data-structures (possibly with\npointers) such as doubly-linked lists, circular lists etc. We show how the\nproposed logic can faithfully describe (i) termgraphs as well as (ii) the\napplication of a termgraph rewrite rule (i.e. matching and replacement) and\n(iii) the computation of normal forms with respect to a given rewrite system.\nWe also show how the proposed logic, which is more expressive than\npropositional dynamic logic, can be used to specify shapes of classical\ndata-structures (e.g. binary trees, circular lists etc.)."
},{
    "category": "cs.CR", 
    "doi": "10.1016/j.jsc.2010.10.009", 
    "link": "http://arxiv.org/pdf/1003.5406v2", 
    "title": "Disabling equational theories in unification for cryptographic protocol   analysis through tagging", 
    "arxiv-id": "1003.5406v2", 
    "author": "Sreekanth Malladi", 
    "publish": "2010-03-28T23:54:50Z", 
    "summary": "In this paper, we show a new tagging scheme for cryptographic protocol\nmessages. Under this tagging, equational theories of operators such as\nexclusive-or, binary addition etc. are effectively disabled, when terms are\nunified. We believe that this result has a significant impact on protocol\nanalysis and security, since unification is at the heart of symbolic protocol\nanalysis. Hence, disabling equational theories in unification implies disabling\nthem altogether in protocol analysis for most operators and theories."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jsc.2010.10.009", 
    "link": "http://arxiv.org/pdf/1004.1262v2", 
    "title": "Syntactic Abstraction of B Models to Generate Tests", 
    "arxiv-id": "1004.1262v2", 
    "author": "Pierre-Alain Masson", 
    "publish": "2010-04-08T07:15:48Z", 
    "summary": "In a model-based testing approach as well as for the verification of\nproperties, B models provide an interesting solution. However, for industrial\napplications, the size of their state space often makes them hard to handle. To\nreduce the amount of states, an abstraction function can be used, often\ncombining state variable elimination and domain abstractions of the remaining\nvariables. This paper complements previous results, based on domain abstraction\nfor test generation, by adding a preliminary syntactic abstraction phase, based\non variable elimination. We define a syntactic transformation that suppresses\nsome variables from a B event model, in addition to a method that chooses\nrelevant variables according to a test purpose. We propose two methods to\ncompute an abstraction A of an initial model M. The first one computes A as a\nsimulation of M, and the second one computes A as a bisimulation of M. The\nabstraction process produces a finite state system. We apply this abstraction\ncomputation to a Model Based Testing process."
},{
    "category": "math.OC", 
    "doi": "10.1016/j.jsc.2011.08.001", 
    "link": "http://arxiv.org/pdf/1004.2924v1", 
    "title": "Exact linear modeling using Ore algebras", 
    "arxiv-id": "1004.2924v1", 
    "author": "Eva Zerz", 
    "publish": "2010-04-16T20:31:57Z", 
    "summary": "Linear exact modeling is a problem coming from system identification: Given a\nset of observed trajectories, the goal is find a model (usually, a system of\npartial differential and/or difference equations) that explains the data as\nprecisely as possible. The case of operators with constant coefficients is well\nstudied and known in the systems theoretic literature, whereas the operators\nwith varying coefficients were addressed only recently. This question can be\ntackled either using Gr\\\"obner bases for modules over Ore algebras or by\nfollowing the ideas from differential algebra and computing in commutative\nrings. In this paper, we present algorithmic methods to compute \"most powerful\nunfalsified models\" (MPUM) and their counterparts with variable coefficients\n(VMPUM) for polynomial and polynomial-exponential signals. We also study the\nstructural properties of the resulting models, discuss computer algebraic\ntechniques behind algorithms and provide several examples."
},{
    "category": "cs.DC", 
    "doi": "10.1145/1837210.1837224", 
    "link": "http://arxiv.org/pdf/1004.3719v1", 
    "title": "Exact Sparse Matrix-Vector Multiplication on GPU's and Multicore   Architectures", 
    "arxiv-id": "1004.3719v1", 
    "author": "Pascal Giorgi", 
    "publish": "2010-04-21T14:52:36Z", 
    "summary": "We propose different implementations of the sparse matrix--dense vector\nmultiplication (\\spmv{}) for finite fields and rings $\\Zb/m\\Zb$. We take\nadvantage of graphic card processors (GPU) and multi-core architectures. Our\naim is to improve the speed of \\spmv{} in the \\linbox library, and henceforth\nthe speed of its black box algorithms. Besides, we use this and a new\nparallelization of the sigma-basis algorithm in a parallel block Wiedemann rank\nimplementation over finite fields."
},{
    "category": "cs.LO", 
    "doi": "10.1145/1837210.1837224", 
    "link": "http://arxiv.org/pdf/1004.5034v1", 
    "title": "Formal Proof of SCHUR Conjugate Function", 
    "arxiv-id": "1004.5034v1", 
    "author": "Fr\u00e9d\u00e9ric Toumazet", 
    "publish": "2010-04-28T14:12:43Z", 
    "summary": "The main goal of our work is to formally prove the correctness of the key\ncommands of the SCHUR software, an interactive program for calculating with\ncharacters of Lie groups and symmetric functions. The core of the computations\nrelies on enumeration and manipulation of combinatorial structures. As a first\n\"proof of concept\", we present a formal proof of the conjugate function,\nwritten in C. This function computes the conjugate of an integer partition. To\nformally prove this program, we use the Frama-C software. It allows us to\nannotate C functions and to generate proof obligations, which are proved using\nseveral automated theorem provers. In this paper, we also draw on methodology,\ndiscussing on how to formally prove this kind of program."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1837210.1837224", 
    "link": "http://arxiv.org/pdf/1005.0749v1", 
    "title": "Integrating multiple sources to answer questions in Algebraic Topology", 
    "arxiv-id": "1005.0749v1", 
    "author": "Julio Rubio", 
    "publish": "2010-04-27T07:46:10Z", 
    "summary": "We present in this paper an evolution of a tool from a user interface for a\nconcrete Computer Algebra system for Algebraic Topology (the Kenzo system), to\na front-end allowing the interoperability among different sources for\ncomputation and deduction. The architecture allows the system not only to\ninterface several systems, but also to make them cooperate in shared\ncalculations."
},{
    "category": "cs.AI", 
    "doi": "10.1145/1837210.1837224", 
    "link": "http://arxiv.org/pdf/1005.1475v2", 
    "title": "How to correctly prune tropical trees", 
    "arxiv-id": "1005.1475v2", 
    "author": "Luca Saiu", 
    "publish": "2010-05-10T09:06:26Z", 
    "summary": "We present tropical games, a generalization of combinatorial min-max games\nbased on tropical algebras. Our model breaks the traditional symmetry of\nrational zero-sum games where players have exactly opposed goals (min vs. max),\nis more widely applicable than min-max and also supports a form of pruning,\ndespite it being less effective than alpha-beta. Actually, min-max games may be\nseen as particular cases where both the game and its dual are tropical: when\nthe dual of a tropical game is also tropical, the power of alpha-beta is\ncompletely recovered. We formally develop the model and prove that the tropical\npruning strategy is correct, then conclude by showing how the problem of\napproximated parsing can be modeled as a tropical game, profiting from pruning."
},{
    "category": "cs.SC", 
    "doi": "10.1145/1837210.1837224", 
    "link": "http://arxiv.org/pdf/1005.5273v2", 
    "title": "Holonomic Gradient Descent and its Application to Fisher-Bingham   Integral", 
    "arxiv-id": "1005.5273v2", 
    "author": "Katsuyoshi Ohara", 
    "publish": "2010-05-28T12:02:21Z", 
    "summary": "We give a new algorithm to find local maximum and minimum of a holonomic\nfunction and apply it for the Fisher-Bingham integral on the sphere $S^n$,\nwhich is used in the directional statistics. The method utilizes the theory and\nalgorithms of holonomic systems."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.tcs.2012.10.019", 
    "link": "http://arxiv.org/pdf/1006.3246v4", 
    "title": "Sparse approaches for the exact distribution of patterns in long state   sequences generated by a Markov source", 
    "arxiv-id": "1006.3246v4", 
    "author": "Jean-Guillaume Dumas", 
    "publish": "2010-06-16T15:24:54Z", 
    "summary": "We present two novel approaches for the computation of the exact distribution\nof a pattern in a long sequence. Both approaches take into account the sparse\nstructure of the problem and are two-part algorithms. The first approach relies\non a partial recursion after a fast computation of the second largest\neigenvalue of the transition matrix of a Markov chain embedding. The second\napproach uses fast Taylor expansions of an exact bivariate rational\nreconstruction of the distribution. We illustrate the interest of both\napproaches on a simple toy-example and two biological applications: the\ntranscription factors of the Human Chromosome 5 and the PROSITE signatures of\nfunctional motifs in proteins. On these example our methods demonstrate their\ncomplementarity and their hability to extend the domain of feasibility for\nexact computations in pattern problems to a new level."
},{
    "category": "hep-ph", 
    "doi": "10.1016/j.nuclphysbps.2010.08.027", 
    "link": "http://arxiv.org/pdf/1006.4512v1", 
    "title": "FORM facts", 
    "arxiv-id": "1006.4512v1", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2010-06-23T14:33:29Z", 
    "summary": "Some of the new features of the symbolic manipulation system FORM are\ndiscussed. Then some recent results running its multithreaded version TFORM are\nshown. Finally the plans for the future are presented."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.nuclphysbps.2010.08.027", 
    "link": "http://arxiv.org/pdf/1006.5372v3", 
    "title": "The MAPLE package for calculating Poincar\u00e9 series", 
    "arxiv-id": "1006.5372v3", 
    "author": "Leonid Bedratyuk", 
    "publish": "2010-06-24T19:16:53Z", 
    "summary": "We offer a Maple package {\\tt Poincare\\_Series} for calculating the\nPoincar\\'e series for the algebras of invariants/covariants of binary forms,\nfor the algebras of joint invariants/covariants of several binary forms, for\nthe kernel of Weitzenb\\\"ock derivations and for the multivariate Poincar\\'e\nseries of algebras of joint invariants/covariants of several binary forms."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.nuclphysbps.2010.08.027", 
    "link": "http://arxiv.org/pdf/1008.3596v1", 
    "title": "Exact Bivariate Polynomial Factorization in Q by Approximation of Roots", 
    "arxiv-id": "1008.3596v1", 
    "author": "Jingzhong Zhang", 
    "publish": "2010-08-21T03:28:20Z", 
    "summary": "Factorization of polynomials is one of the foundations of symbolic\ncomputation. Its applications arise in numerous branches of mathematics and\nother sciences. However, the present advanced programming languages such as C++\nand J++, do not support symbolic computation directly. Hence, it leads to\ndifficulties in applying factorization in engineering fields. In this paper, we\npresent an algorithm which use numerical method to obtain exact factors of a\nbivariate polynomial with rational coefficients. Our method can be directly\nimplemented in efficient programming language such C++ together with the GNU\nMultiple-Precision Library. In addition, the numerical computation part often\nonly requires double precision and is easily parallelizable."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.nuclphysbps.2010.08.027", 
    "link": "http://arxiv.org/pdf/1008.3667v1", 
    "title": "Pattern Classification In Symbolic Streams via Semantic Annihilation of   Information", 
    "arxiv-id": "1008.3667v1", 
    "author": "Asok Ray", 
    "publish": "2010-08-21T21:24:42Z", 
    "summary": "We propose a technique for pattern classification in symbolic streams via\nselective erasure of observed symbols, in cases where the patterns of interest\nare represented as Probabilistic Finite State Automata (PFSA). We define an\nadditive abelian group for a slightly restricted subset of probabilistic finite\nstate automata (PFSA), and the group sum is used to formulate pattern-specific\nsemantic annihilators. The annihilators attempt to identify pre-specified\npatterns via removal of essentially all inter-symbol correlations from observed\nsequences, thereby turning them into symbolic white noise. Thus a perfect\nannihilation corresponds to a perfect pattern match. This approach of\nclassification via information annihilation is shown to be strictly\nadvantageous, with theoretical guarantees, for a large class of PFSA models.\nThe results are supported by simulation experiments."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.nuclphysbps.2010.08.027", 
    "link": "http://arxiv.org/pdf/1009.0673v1", 
    "title": "System Description: H-PILoT (Version 1.9)", 
    "arxiv-id": "1009.0673v1", 
    "author": "Viorica Sofronie-Stokkermans", 
    "publish": "2010-09-03T14:02:24Z", 
    "summary": "This system description provides an overview of H-PILoT (Hierarchical Proving\nby Instantiation in Local Theory extensions), a program for hierarchical\nreasoning in extensions of logical theories. H-PILoT reduces deduction problems\nin the theory extension to deduction problems in the base theory. Specialized\nprovers and standard SMT solvers can be used for testing the satisfiability of\nthe formulae obtained after the reduction. For a certain type of theory\nextension (namely for local theory extensions) this hierarchical reduction is\nsound and complete and -- if the formulae obtained this way belong to a\nfragment decidable in the base theory -- H-PILoT provides a decision procedure\nfor testing satisfiability of ground formulae, and can also be used for model\ngeneration."
},{
    "category": "cs.SE", 
    "doi": "10.1016/j.nuclphysbps.2010.08.027", 
    "link": "http://arxiv.org/pdf/1009.1317v1", 
    "title": "LinBox founding scope allocation, parallel building blocks, and separate   compilation", 
    "arxiv-id": "1009.1317v1", 
    "author": "B. David Saunders", 
    "publish": "2010-07-28T12:20:06Z", 
    "summary": "To maximize efficiency in time and space, allocations and deallocations, in\nthe exact linear algebra library \\linbox, must always occur in the founding\nscope. This provides a simple lightweight allocation model. We present this\nmodel and its usage for the rebinding of matrices between different coefficient\ndomains. We also present automatic tools to speed-up the compilation of\ntemplate libraries and a software abstraction layer for the introduction of\ntransparent parallelism at the algorithmic level."
},{
    "category": "math.CA", 
    "doi": "10.1016/j.jco.2010.10.004", 
    "link": "http://arxiv.org/pdf/1009.2876v1", 
    "title": "Computation of Darboux polynomials and rational first integrals with   bounded degree in polynomial time", 
    "arxiv-id": "1009.2876v1", 
    "author": "Guillaume Ch\u00e8ze", 
    "publish": "2010-09-15T09:24:46Z", 
    "summary": "In this paper we study planar polynomial differential systems of this form:\ndX/dt=A(X, Y), dY/dt= B(X, Y), where A,B belongs to Z[X, Y], degA \\leq d, degB\n\\leq d, and the height of A and B is smaller than H. A lot of properties of\nplanar polynomial differential systems are related to irreducible Darboux\npolynomials of the corresponding derivation: D =A(X, Y)dX + B(X, Y)dY . Darboux\npolynomials are usually computed with the method of undetermined coefficients.\nWith this method we have to solve a polynomial system. We show that this\napproach can give rise to the computation of an exponential number of reducible\nDarboux polynomials. Here we show that the Lagutinskii-Pereira's algorithm\ncomputes irreducible Darboux polynomials with degree smaller than N, with a\npolynomial number, relatively to d, log(H) and N, binary operations. We also\ngive a polynomial-time method to compute, if it exists, a rational first\nintegral with bounded degree."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2010.10.004", 
    "link": "http://arxiv.org/pdf/1009.3214v2", 
    "title": "Computing sparse multiples of polynomials", 
    "arxiv-id": "1009.3214v2", 
    "author": "Hrushikesh Tilak", 
    "publish": "2010-09-16T16:21:15Z", 
    "summary": "We consider the problem of finding a sparse multiple of a polynomial. Given f\nin F[x] of degree d over a field F, and a desired sparsity t, our goal is to\ndetermine if there exists a multiple h in F[x] of f such that h has at most t\nnon-zero terms, and if so, to find such an h. When F=Q and t is constant, we\ngive a polynomial-time algorithm in d and the size of coefficients in h. When F\nis a finite field, we show that the problem is at least as hard as determining\nthe multiplicative order of elements in an extension field of F (a problem\nthought to have complexity similar to that of factoring integers), and this\nlower bound is tight when t=2."
},{
    "category": "cs.MS", 
    "doi": "10.1016/j.jco.2010.10.004", 
    "link": "http://arxiv.org/pdf/1010.1386v1", 
    "title": "An Elimination Method for Solving Bivariate Polynomial Systems:   Eliminating the Usual Drawbacks", 
    "arxiv-id": "1010.1386v1", 
    "author": "Michael Sagraloff", 
    "publish": "2010-10-07T10:18:32Z", 
    "summary": "We present an exact and complete algorithm to isolate the real solutions of a\nzero-dimensional bivariate polynomial system. The proposed algorithm\nconstitutes an elimination method which improves upon existing approaches in a\nnumber of points. First, the amount of purely symbolic operations is\nsignificantly reduced, that is, only resultant computation and square-free\nfactorization is still needed. Second, our algorithm neither assumes generic\nposition of the input system nor demands for any change of the coordinate\nsystem. The latter is due to a novel inclusion predicate to certify that a\ncertain region is isolating for a solution. Our implementation exploits\ngraphics hardware to expedite the resultant computation. Furthermore, we\nintegrate a number of filtering techniques to improve the overall performance.\nEfficiency of the proposed method is proven by a comparison of our\nimplementation with two state-of-the-art implementations, that is, LPG and\nMaple's isolate. For a series of challenging benchmark instances, experiments\nshow that our implementation outperforms both contestants."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.jco.2010.10.004", 
    "link": "http://arxiv.org/pdf/1010.1982v1", 
    "title": "Detecting Simultaneous Integer Relations for Several Real Vectors", 
    "arxiv-id": "1010.1982v1", 
    "author": "Jingzhong Zhang", 
    "publish": "2010-10-11T01:26:08Z", 
    "summary": "An algorithm which either finds an nonzero integer vector ${\\mathbf m}$ for\ngiven $t$ real $n$-dimensional vectors ${\\mathbf x}_1,...,{\\mathbf x}_t$ such\nthat ${\\mathbf x}_i^T{\\mathbf m}=0$ or proves that no such integer vector with\nnorm less than a given bound exists is presented in this paper. The cost of the\nalgorithm is at most ${\\mathcal O}(n^4 + n^3 \\log \\lambda(X))$ exact arithmetic\noperations in dimension $n$ and the least Euclidean norm $\\lambda(X)$ of such\ninteger vectors. It matches the best complexity upper bound known for this\nproblem. Experimental data show that the algorithm is better than an already\nexisting algorithm in the literature. In application, the algorithm is used to\nget a complete method for finding the minimal polynomial of an unknown complex\nalgebraic number from its approximation, which runs even faster than the\ncorresponding \\emph{Maple} built-in function."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.jco.2010.10.004", 
    "link": "http://arxiv.org/pdf/1010.2669v1", 
    "title": "Fast Gr\u00f6bner Basis Computation for Boolean Polynomials", 
    "arxiv-id": "1010.2669v1", 
    "author": "Elizabeth Arnold", 
    "publish": "2010-10-13T14:28:29Z", 
    "summary": "We introduce the Macaulay2 package BooleanGB, which computes a Gr\\\"obner\nbasis for Boolean polynomials using a binary representation rather than\nsymbolic. We compare the runtime of several Boolean models from systems in\nbiology and give an application to Sudoku."
},{
    "category": "math-ph", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1011.0523v2", 
    "title": "An interface between physics and number theory", 
    "arxiv-id": "1011.0523v2", 
    "author": "Silvia Goodenough", 
    "publish": "2010-11-02T06:53:32Z", 
    "summary": "We extend the Hopf algebra description of a simple quantum system given\npreviously, to a more elaborate Hopf algebra, which is rich enough to encompass\nthat related to a description of perturbative quantum field theory (pQFT). This\nprovides a {\\em mathematical} route from an algebraic description of\nnon-relativistic, non-field theoretic quantum statistical mechanics to one of\nrelativistic quantum field theory. Such a description necessarily involves\ntreating the algebra of polyzeta functions, extensions of the Riemann Zeta\nfunction, since these occur naturally in pQFT. This provides a link between\nphysics, algebra and number theory. As a by-product of this approach, we are\nled to indicate {\\it inter alia} a basis for concluding that the Euler gamma\nconstant $\\gamma$ may be rational."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1011.0972v1", 
    "title": "A recombination algorithm for the decomposition of multivariate rational   functions", 
    "arxiv-id": "1011.0972v1", 
    "author": "Guillaume Ch\u00e8ze", 
    "publish": "2010-11-03T19:01:48Z", 
    "summary": "In this paper we show how we can compute in a deterministic way the\ndecomposition of a multivariate rational function with a recombination\nstrategy. The key point of our recombination strategy is the used of Darboux\npolynomials. We study the complexity of this strategy and we show that this\nmethod improves the previous ones. In appendix, we explain how the strategy\nproposed recently by J. Berthomieu and G. Lecerf for the sparse factorization\ncan be used in the decomposition setting. Then we deduce a decomposition\nalgorithm in the sparse bivariate case and we give its complexity"
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1011.1634v1", 
    "title": "Zero Decomposition with Multiplicity of Zero-Dimensional Polynomial   Systems", 
    "arxiv-id": "1011.1634v1", 
    "author": "Zhihai Zhang", 
    "publish": "2010-11-07T12:04:15Z", 
    "summary": "We present a zero decomposition theorem and an algorithm based on Wu's\nmethod, which computes a zero decomposition with multiplicity for a given\nzero-dimensional polynomial system. If the system satisfies some condition, the\nzero decomposition is of triangular form."
},{
    "category": "math.GR", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1011.2024v2", 
    "title": "Group extensions over infinite words", 
    "arxiv-id": "1011.2024v2", 
    "author": "Alexei Myasnikov", 
    "publish": "2010-11-09T10:13:22Z", 
    "summary": "We construct an extension $E(A,G)$ of a given group $G$ by infinite\nnon-Archimedean words over an discretely ordered abelian group like $Z^n$. This\nyields an effective and uniform method to study various groups that \"behave\nlike $G$\". We show that the Word Problem for f.g. subgroups in the extension is\ndecidable if and only if and only if the Cyclic Membership Problem in $G$ is\ndecidable.\n  The present paper embeds the partial monoid of infinite words as defined by\nMyasnikov, Remeslennikov, and Serbin (Contemp. Math., Amer. Math. Soc.,\n378:37-77, 2005) into $E(A,G)$. Moreover, we define the extension group\n$E(A,G)$ for arbitrary groups $G$ and not only for free groups as done in\nprevious work. We show some structural results about the group (existence and\ntype of torsion elements, generation by elements of order 2) and we show that\nsome interesting HNN extensions of $G$ embed naturally in the larger group\n$E(A,G)$."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1011.2306v3", 
    "title": "A New Algorithm for Inverting General Cyclic Heptadiagonal Matrices   Recursively", 
    "arxiv-id": "1011.2306v3", 
    "author": "A. A. Karawia", 
    "publish": "2010-11-10T08:27:42Z", 
    "summary": "In this paper, we describe a reliable symbolic computational algorithm for\ninverting general cyclic heptadiagonal matrices by using parallel computing\nalong with recursion. The algorithm is implementable to the Computer Algebra\nSystem(CAS) such as MAPLE, Matlab and Mathematica . An example is presented for\nthe sake of illustration."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1101.0270v1", 
    "title": "\"On the engineers' new toolbox\" or Analog Circuit Design, using Symbolic   Analysis, Computer Algebra, and Elementary Network Transformations", 
    "arxiv-id": "1101.0270v1", 
    "author": "Eberhard H. -A. Gerbracht", 
    "publish": "2010-12-31T16:30:04Z", 
    "summary": "In this paper, by way of three examples - a fourth order low pass active RC\nfilter, a rudimentary BJT amplifier, and an LC ladder - we show, how the\nalgebraic capabilities of modern computer algebra systems can, or in the last\nexample, might be brought to use in the task of designing analog circuits."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1101.3682v3", 
    "title": "Diversification improves interpolation", 
    "arxiv-id": "1101.3682v3", 
    "author": "Daniel S. Roche", 
    "publish": "2011-01-19T13:14:32Z", 
    "summary": "We consider the problem of interpolating an unknown multivariate polynomial\nwith coefficients taken from a finite field or as numerical approximations of\ncomplex numbers. Building on the recent work of Garg and Schost, we improve on\nthe best-known algorithm for interpolation over large finite fields by\npresenting a Las Vegas randomized algorithm that uses fewer black box\nevaluations. Using related techniques, we also address numerical interpolation\nof sparse polynomials with complex coefficients, and provide the first provably\nstable algorithm (in the sense of relative error) for this problem, at the cost\nof modestly more evaluations. A key new technique is a randomization which\nmakes all coefficients of the unknown polynomial distinguishable, producing\nwhat we call a diverse polynomial. Another departure from most previous\napproaches is that our algorithms do not rely on root finding as a subroutine.\nWe show how these improvements affect the practical performance with trial\nimplementations."
},{
    "category": "math.CA", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1103.4298v1", 
    "title": "Special Values of Generalized Log-sine Integrals", 
    "arxiv-id": "1103.4298v1", 
    "author": "Armin Straub", 
    "publish": "2011-03-22T16:28:04Z", 
    "summary": "We study generalized log-sine integrals at special values. At $\\pi$ and\nmultiples thereof explicit evaluations are obtained in terms of Nielsen\npolylogarithms at $\\pm1$. For general arguments we present algorithmic\nevaluations involving Nielsen polylogarithms at related arguments. In\nparticular, we consider log-sine integrals at $\\pi/3$ which evaluate in terms\nof polylogarithms at the sixth root of unity. An implementation of our results\nfor the computer algebra systems Mathematica and SAGE is provided."
},{
    "category": "cs.IT", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1103.5740v2", 
    "title": "Generating and Searching Families of FFT Algorithms", 
    "arxiv-id": "1103.5740v2", 
    "author": "Heidi Haynal", 
    "publish": "2011-03-29T19:46:24Z", 
    "summary": "A fundamental question of longstanding theoretical interest is to prove the\nlowest exact count of real additions and multiplications required to compute a\npower-of-two discrete Fourier transform (DFT). For 35 years the split-radix\nalgorithm held the record by requiring just 4n log n - 6n + 8 arithmetic\noperations on real numbers for a size-n DFT, and was widely believed to be the\nbest possible. Recent work by Van Buskirk et al. demonstrated improvements to\nthe split-radix operation count by using multiplier coefficients or \"twiddle\nfactors\" that are not n-th roots of unity for a size-n DFT. This paper presents\na Boolean Satisfiability-based proof of the lowest operation count for certain\nclasses of DFT algorithms. First, we present a novel way to choose new yet\nvalid twiddle factors for the nodes in flowgraphs generated by common\npower-of-two fast Fourier transform algorithms, FFTs. With this new technique,\nwe can generate a large family of FFTs realizable by a fixed flowgraph. This\nsolution space of FFTs is cast as a Boolean Satisfiability problem, and a\nmodern Satisfiability Modulo Theory solver is applied to search for FFTs\nrequiring the fewest arithmetic operations. Surprisingly, we find that there\nare FFTs requiring fewer operations than the split-radix even when all twiddle\nfactors are n-th roots of unity."
},{
    "category": "math-ph", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1105.1884v1", 
    "title": "About a conjectured basis for Multiple Zeta Values", 
    "arxiv-id": "1105.1884v1", 
    "author": "J. A. M. Vermaseren", 
    "publish": "2011-05-10T08:55:41Z", 
    "summary": "We confirm a conjecture about the construction of basis elements for the\nmultiple zeta values (MZVs) at weight 27 and weight 28. Both show as expected\none element that is twofold extended. This is done with some lengthy computer\nalgebra calculations using TFORM to determine explicit bases for the MZVs at\nthese weights."
},{
    "category": "math.LO", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1105.4421v1", 
    "title": "On the Generation of Positivstellensatz Witnesses in Degenerate Cases", 
    "arxiv-id": "1105.4421v1", 
    "author": "Pierre Corbineau", 
    "publish": "2011-05-23T07:35:35Z", 
    "summary": "One can reduce the problem of proving that a polynomial is nonnegative, or\nmore generally of proving that a system of polynomial inequalities has no\nsolutions, to finding polynomials that are sums of squares of polynomials and\nsatisfy some linear equality (Positivstellensatz). This produces a witness for\nthe desired property, from which it is reasonably easy to obtain a formal proof\nof the property suitable for a proof assistant such as Coq. The problem of\nfinding a witness reduces to a feasibility problem in semidefinite programming,\nfor which there exist numerical solvers. Unfortunately, this problem is in\ngeneral not strictly feasible, meaning the solution can be a convex set with\nempty interior, in which case the numerical optimization method fails.\nPreviously published methods thus assumed strict feasibility; we propose a\nworkaround for this difficulty. We implemented our method and illustrate its\nuse with examples, including extractions of proofs to Coq."
},{
    "category": "cs.SC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1105.4456v2", 
    "title": "Explicit formula for the generating series of diagonal 3D rook paths", 
    "arxiv-id": "1105.4456v2", 
    "author": "Lucien Pech", 
    "publish": "2011-05-23T10:12:12Z", 
    "summary": "Let $a_n$ denote the number of ways in which a chess rook can move from a\ncorner cell to the opposite corner cell of an $n \\times n \\times n$\nthree-dimensional chessboard, assuming that the piece moves closer to the goal\ncell at each step. We describe the computer-driven \\emph{discovery and proof}\nof the fact that the generating series $G(x)= \\sum_{n \\geq 0} a_n x^n$ admits\nthe following explicit expression in terms of a Gaussian hypergeometric\nfunction: \\[ G(x) = 1 + 6 \\cdot \\int_0^x \\frac{\\,\\pFq21{1/3}{2/3}{2} {\\frac{27\nw(2-3w)}{(1-4w)^3}}}{(1-4w)(1-64w)} \\, dw.\\]"
},{
    "category": "math.AG", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1105.4881v2", 
    "title": "PHCpack in Macaulay2", 
    "arxiv-id": "1105.4881v2", 
    "author": "Jan Verschelde", 
    "publish": "2011-05-24T20:15:08Z", 
    "summary": "The Macaulay2 package PHCpack.m2 provides an interface to PHCpack, a\ngeneral-purpose polynomial system solver that uses homotopy continuation. The\nmain method is a numerical blackbox solver which is implemented for all Laurent\nsystems. The package also provides a fast mixed volume computation, the ability\nto filter solutions, homotopy path tracking, and a numerical irreducible\ndecomposition method. As the size of many problems in applied algebraic\ngeometry often surpasses the capabilities of symbolic software, this package\nwill be of interest to those working on problems involving large polynomial\nsystems."
},{
    "category": "math.AC", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1105.5509v1", 
    "title": "A parallel Buchberger algorithm for multigraded ideals", 
    "arxiv-id": "1105.5509v1", 
    "author": "Jason Dusek", 
    "publish": "2011-05-27T09:46:53Z", 
    "summary": "We demonstrate a method to parallelize the computation of a Gr\\\"obner basis\nfor a homogenous ideal in a multigraded polynomial ring. Our method uses\nanti-chains in the lattice $\\mathbb N^k$ to separate mutually independent\nS-polynomials for reduction."
},{
    "category": "cs.MS", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1106.1862v1", 
    "title": "The MathScheme Library: Some Preliminary Experiments", 
    "arxiv-id": "1106.1862v1", 
    "author": "Quang M. Tran", 
    "publish": "2011-06-09T17:16:38Z", 
    "summary": "We present some of the experiments we have performed to best test our design\nfor a library for MathScheme, the mechanized mathematics software system we are\nbuilding. We wish for our library design to use and reflect, as much as\npossible, the mathematical structure present in the objects which populate the\nlibrary."
},{
    "category": "math.RA", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1106.6191v3", 
    "title": "Splitting full matrix algebras over algebraic number fields", 
    "arxiv-id": "1106.6191v3", 
    "author": "Josef Schicho", 
    "publish": "2011-06-30T11:27:48Z", 
    "summary": "Let K be an algebraic number field of degree d and discriminant D over Q. Let\nA be an associative algebra over K given by structure constants such that A is\nisomorphic to the algebra M_n(K) of n by n matrices over K for some positive\ninteger n. Suppose that d, n and D are bounded. Then an isomorphism of A with\nM_n(K) can be constructed by a polynomial time ff-algorithm. (An ff-algorithm\nis a deterministic procedure which is allowed to call oracles for factoring\nintegers and factoring univariate polynomials over finite fields.)\n  As a consequence, we obtain a polynomial time ff-algorithm to compute\nisomorphisms of central simple algebras of bounded degree over K."
},{
    "category": "cs.CG", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1107.2312v2", 
    "title": "Computing the Distance between Piecewise-Linear Bivariate Functions", 
    "arxiv-id": "1107.2312v2", 
    "author": "Boris Aronov", 
    "publish": "2011-07-12T14:56:31Z", 
    "summary": "We consider the problem of computing the distance between two\npiecewise-linear bivariate functions $f$ and $g$ defined over a common domain\n$M$. We focus on the distance induced by the $L_2$-norm, that is\n$\\|f-g\\|_2=\\sqrt{\\iint_M (f-g)^2}$. If $f$ is defined by linear interpolation\nover a triangulation of $M$ with $n$ triangles, while $g$ is defined over\nanother such triangulation, the obvious na\\\"ive algorithm requires\n$\\Theta(n^2)$ arithmetic operations to compute this distance. We show that it\nis possible to compute it in $\\O(n\\log^4 n)$ arithmetic operations, by reducing\nthe problem to multi-point evaluation of a certain type of polynomials. We also\npresent an application to terrain matching."
},{
    "category": "math.AT", 
    "doi": "10.1088/1742-6596/284/1/012023", 
    "link": "http://arxiv.org/pdf/1107.3396v1", 
    "title": "Computing the homology of groups: the geometric way", 
    "arxiv-id": "1107.3396v1", 
    "author": "Julio Rubio", 
    "publish": "2011-07-18T10:41:08Z", 
    "summary": "In this paper we present several algorithms related with the computation of\nthe homology of groups, from a geometric perspective (that is to say, carrying\nout the calculations by means of simplicial sets and using techniques of\nAlgebraic Topology). More concretely, we have developed some algorithms which,\nmaking use of the effective homology method, construct the homology groups of\nEilenberg-MacLane spaces K(G,1) for different groups G, allowing one in\nparticular to determine the homology groups of G.\n  Our algorithms have been programmed as new modules for the Kenzo system,\nenhancing it with the following new functionalities:\n  - construction of the effective homology of K(G,1) from a given finite free\nresolution of the group G;\n  - construction of the effective homology of K(A,1) for every finitely\ngenerated Abelian group A (as a consequence, the effective homology of K(A,n)\nis also available in Kenzo, for all n);\n  - computation of homology groups of some 2-types;\n  - construction of the effective homology for central extensions.\n  In addition, an inverse problem is also approached in this work: given a\ngroup G such that K(G,1) has effective homology, can a finite free resolution\nof the group G be obtained? We provide some algorithms to solve this problem,\nbased on a notion of norm of a group, allowing us to control the convergence of\nthe process when building such a resolution."
},{
    "category": "math.AP", 
    "doi": "10.1007/978-3-642-28212-6", 
    "link": "http://arxiv.org/pdf/1107.4269v5", 
    "title": "Consistency Analysis of Finite Difference Approximations to PDE Systems", 
    "arxiv-id": "1107.4269v5", 
    "author": "Vladimir P. Gerdt", 
    "publish": "2011-07-21T13:29:31Z", 
    "summary": "In the given paper we consider finite difference approximations to systems of\npolynomially-nonlinear partial differential equations whose coefficients are\nrational functions over rationals in the independent variables. The notion of\nstrong consistency which we introduced earlier for linear systems is extended\nto nonlinear ones. For orthogonal and uniform grids we describe an algorithmic\nprocedure for verification of strong consistency based on computation of\ndifference standard bases. The concepts and algorithmic methods of the present\npaper are illustrated by two finite difference approximations to the\ntwo-dimensional Navier-Stokes equations. One of these approximations is\nstrongly consistent and another is not."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-28212-6", 
    "link": "http://arxiv.org/pdf/1108.2830v3", 
    "title": "A New General-Purpose Method to Multiply 3x3 Matrices Using Only 23   Multiplications", 
    "arxiv-id": "1108.2830v3", 
    "author": "Daniel Hulme", 
    "publish": "2011-08-14T00:23:37Z", 
    "summary": "One of the most famous conjectures in computer algebra is that matrix\nmultiplication might be feasible in not much more than quadratic time. The best\nknown exponent is 2.376, due to Coppersmith and Winograd. Many attempts to\nsolve this problems in the literature work by solving, fixed-size problems and\nthen apply the solution recursively. This leads to pure combinatorial\noptimisation problems with fixed size. These problems are unlikely to be\nsolvable in polynomial time.\n  In 1976 Laderman published a method to multiply two 3x3 matrices using only\n23 multiplications. This result is non-commutative, and therefore can be\napplied recursively to smaller sub-matrices. In 35 years nobody was able to do\nbetter and it remains an open problem if this can be done with 22\nmultiplications. We proceed by solving the so called Brent equations [7]. We\nhave implemented a method to converting this very hard problem to a SAT\nproblem, and we have attempted to solve it, with our portfolio of some 500 SAT\nsolvers. With this new method we were able to produce new solutions to the\nLaderman's problem. We present a new fully general non-commutative solution\nwith 23 multiplications and show that this solution is new and is NOT an\nequivalent variant of the Laderman's original solution. This result\ndemonstrates that the space of solutions to Laderman's problem is larger than\nexpected, and therefore it becomes now more plausible that a solution with 22\nmultiplications exists. If it exists, we might be able to find it soon just by\nrunning our algorithms longer, or due to further improvements in the SAT solver\nalgorithms."
},{
    "category": "math.RA", 
    "doi": "10.1007/978-3-642-28212-6", 
    "link": "http://arxiv.org/pdf/1108.3261v1", 
    "title": "A Variant of Gerdt's Algorithm for Computing Involutive Bases", 
    "arxiv-id": "1108.3261v1", 
    "author": "Benyamin M. -Alizadeh", 
    "publish": "2011-08-16T15:02:23Z", 
    "summary": "Ihe first author presented an efficient algorithm for computing involutive\n(and reduced Groebner) bases. In this paper, we consider a modification of this\nalgorithm which simplifies matters to understand it and to implement. We prove\ncorrectness and termination of the modified algorithm and also correctness of\nthe used criteria. The proposed algorithm has been implemented in Maple. We\npresent experimental comparison, via some examples, of performance of the\nmodified algorithm with its original form which has been implemented in Maple\ntoo. In doing so, we have taken care to provide uniform implementation details\nfor the both algorithms."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-28212-6", 
    "link": "http://arxiv.org/pdf/1110.2263v1", 
    "title": "Asymptotic Methods of ODEs: Exploring Singularities of the Second Kind", 
    "arxiv-id": "1110.2263v1", 
    "author": "Christopher J. Winfield", 
    "publish": "2011-10-11T04:03:22Z", 
    "summary": "We develop symbolic methods of asymptotic approximations for solutions of\nlinear ordinary differential equations and use to them stabilize numerical\ncalculations. Our method follows classical analysis for first-order systems and\nhigher-order scalar equations where growth behavior is expressed in terms of\nelementary functions. We then recast our equations in mollified form - thereby\nobtaining stability."
},{
    "category": "math.AG", 
    "doi": "10.1007/978-3-642-28212-6", 
    "link": "http://arxiv.org/pdf/1110.3038v2", 
    "title": "Affine solution sets of sparse polynomial systems", 
    "arxiv-id": "1110.3038v2", 
    "author": "Juan Sabia", 
    "publish": "2011-10-13T19:53:30Z", 
    "summary": "This paper focuses on the equidimensional decomposition of affine varieties\ndefined by sparse polynomial systems. For generic systems with fixed supports,\nwe give combinatorial conditions for the existence of positive dimensional\ncomponents which characterize the equidimensional decomposition of the\nassociated affine variety. This result is applied to design an equidimensional\ndecomposition algorithm for generic sparse systems. For arbitrary sparse\nsystems of n polynomials in n variables with fixed supports, we obtain an upper\nbound for the degree of the affine variety defined and we present an algorithm\nwhich computes finite sets of points representing its equidimensional\ncomponents."
},{
    "category": "cs.MS", 
    "doi": "10.4204/EPTCS.70.4", 
    "link": "http://arxiv.org/pdf/1110.4673v1", 
    "title": "How Can I Do That with ACL2? Recent Enhancements to ACL2", 
    "arxiv-id": "1110.4673v1", 
    "author": "J Strother Moore", 
    "publish": "2011-10-21T00:45:38Z", 
    "summary": "The last several years have seen major enhancements to ACL2 functionality,\nlargely driven by requests from its user community, including utilities now in\ncommon use such as 'make-event', 'mbe', and trust tags. In this paper we\nprovide user-level summaries of some ACL2 enhancements introduced after the\nrelease of Version 3.5 (in May, 2009, at about the time of the 2009 ACL2\nworkshop) up through the release of Version 4.3 in July, 2011, roughly a couple\nof years later. Many of these features are not particularly well known yet, but\nmost ACL2 users could take advantage of at least some of them. Some of the\nchanges could affect existing proof efforts, such as a change that treats pairs\nof functions such as 'member' and 'member-equal' as the same function."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.70.4", 
    "link": "http://arxiv.org/pdf/1110.4801v1", 
    "title": "Improvement Of Barreto-Voloch Algorithm For Computing $r$th Roots Over   Finite Fields", 
    "arxiv-id": "1110.4801v1", 
    "author": "Xiao Fan", 
    "publish": "2011-10-19T13:39:05Z", 
    "summary": "Root extraction is a classical problem in computers algebra. It plays an\nessential role in cryptosystems based on elliptic curves. In 2006, Barreto and\nVoloch proposed an algorithm to compute $r$th roots in ${F}_{q^m} $ for certain\nchoices of $m$ and $q$. If $r\\,||\\,q-1$ and $ (m, r)=1, $ they proved that the\ncomplexity of their method is $\\widetilde{\\mathcal {O}}(r(\\log m+\\log\\log\nq)m\\log q) $. In this paper, we extend the Barreto-Voloch algorithm to the\ngeneral case that $r\\,||\\,q^m-1$, without the restrictions $r\\,||\\,q-1$ and\n$(m, r)=1 $. We also specify the conditions that the Barreto-Voloch algorithm\ncan be preferably applied."
},{
    "category": "math.RA", 
    "doi": "10.4204/EPTCS.70.4", 
    "link": "http://arxiv.org/pdf/1110.5468v1", 
    "title": "Fraction-free algorithm for the computation of diagonal forms matrices   over Ore domains using Gr{\u00f6}bner bases", 
    "arxiv-id": "1110.5468v1", 
    "author": "Kristina Schindelar", 
    "publish": "2011-10-25T11:25:01Z", 
    "summary": "This paper is a sequel to \"Computing diagonal form and Jacobson normal form\nof a matrix using Groebner bases\", J. of Symb. Computation, 46 (5), 2011. We\npresent a new fraction-free algorithm for the computation of a diagonal form of\na matrix over a certain non-commutative Euclidean domain over a computable\nfield with the help of Gr\\\"obner bases. This algorithm is formulated in a\ngeneral constructive framework of non-commutative Ore localizations of\n$G$-algebras (OLGAs). We split the computation of a normal form of a matrix\ninto the diagonalization and the normalization processes. Both of them can be\nmade fraction-free. For a matrix $M$ over an OLGA we provide a diagonalization\nalgorithm to compute $U,V$ and $D$ with fraction-free entries such that $UMV=D$\nholds and $D$ is diagonal. The fraction-free approach gives us more information\non the system of linear functional equations and its solutions, than the\nclassical setup of an operator algebra with rational functions coefficients. In\nparticular, one can handle distributional solutions together with, say,\nmeromorphic ones. We investigate Ore localizations of common operator algebras\nover $K[x]$ and use them in the unimodularity analysis of transformation\nmatrices $U,V$. In turn, this allows to lift the isomorphism of modules over an\nOLGA Euclidean domain to a polynomial subring of it. We discuss the relation of\nthis lifting with the solutions of the original system of equations. Moreover,\nwe prove some new results concerning normal forms of matrices over non-simple\ndomains. Our implementation in the computer algebra system {\\sc\nSingular:Plural} follows the fraction-free strategy and shows impressive\nperformance, compared with methods which directly use fractions. Since we\nexperience moderate swell of coefficients and obtain simple transformation\nmatrices, the method we propose is well suited for solving nontrivial practical\nproblems."
},{
    "category": "math.AG", 
    "doi": "10.4204/EPTCS.70.4", 
    "link": "http://arxiv.org/pdf/1112.1012v1", 
    "title": "Mixed Discriminants", 
    "arxiv-id": "1112.1012v1", 
    "author": "Bernd Sturmfels", 
    "publish": "2011-12-05T17:39:08Z", 
    "summary": "The mixed discriminant of n Laurent polynomials in n variables is the\nirreducible polynomial in the coefficients which vanishes whenever two of the\nroots coincide. The Cayley trick expresses the mixed discriminant as an\nA-discriminant. We show that the degree of the mixed discriminant is a\npiecewise linear function in the Plucker coordinates of a mixed Grassmannian.\nAn explicit degree formula is given for the case of plane curves."
},{
    "category": "cs.CC", 
    "doi": "10.4204/EPTCS.70.4", 
    "link": "http://arxiv.org/pdf/1112.2012v1", 
    "title": "Lie algebra conjugacy", 
    "arxiv-id": "1112.2012v1", 
    "author": "Joshua A. Grochow", 
    "publish": "2011-12-09T03:24:19Z", 
    "summary": "We study the problem of matrix Lie algebra conjugacy. Lie algebras arise\ncentrally in areas as diverse as differential equations, particle physics,\ngroup theory, and the Mulmuley--Sohoni Geometric Complexity Theory program. A\nmatrix Lie algebra is a set L of matrices such that $A, B\\in L$ implies $AB -\nBA \\in L$. Two matrix Lie algebras are conjugate if there is an invertible\nmatrix $M$ such that $L_1 = M L_2 M^{-1}$.\n  We show that certain cases of Lie algebra conjugacy are equivalent to graph\nisomorphism. On the other hand, we give polynomial-time algorithms for other\ncases of Lie algebra conjugacy, which allow us to essentially derandomize a\nrecent result of Kayal on affine equivalence of polynomials. Affine equivalence\nis related to many complexity problems such as factoring integers, graph\nisomorphism, matrix multiplication, and permanent versus determinant.\n  Specifically, we show:\n  Abelian Lie algebra conjugacy is equivalent to the code equivalence problem,\nand hence is as hard as graph isomorphism.\n  Abelian Lie algebra conjugacy of $n \\times n$ matrices can be solved in\npoly(n) time when the Lie algebras have dimension O(1).\n  Semisimple Lie algebra conjugacy is equivalent to graph isomorphism. A Lie\nalgebra is semisimple if it is a direct sum of simple Lie algebras.\n  Semisimple Lie algebra conjugacy of $n \\times n$ matrices can be solved in\npolynomial time when the Lie algebras consist of only $O(\\log n)$ simple direct\nsummands.\n  Conjugacy of completely reducible Lie algebras---that is, a direct sum of an\nabelian and a semisimple Lie algebra---can be solved in polynomial time when\nthe abelian part has dimension O(1) and the semisimple part has $O(\\log n)$\nsimple direct summands."
},{
    "category": "math.AC", 
    "doi": "10.4204/EPTCS.70.4", 
    "link": "http://arxiv.org/pdf/1112.2949v2", 
    "title": "The fundamental invariants of 3 x 3 x 3 arrays", 
    "arxiv-id": "1112.2949v2", 
    "author": "Jiaxiong Hu", 
    "publish": "2011-12-13T16:40:21Z", 
    "summary": "We determine the three fundamental invariants in the entries of a $3 \\times 3\n\\times 3$ array over $\\mathbb{C}$ as explicit polynomials in the 27 variables\n$x_{ijk}$ for $1 \\le i, j, k \\le 3$. By the work of Vinberg on $\\theta$-groups,\nit is known that these homogeneous polynomials have degrees 6, 9 and 12; they\nfreely generate the algebra of invariants for the Lie group $SL_3(\\mathbb{C})\n\\times SL_3(\\mathbb{C}) \\times SL_3(\\mathbb{C})$ acting irreducibly on its\nnatural representation $\\mathbb{C}^3 \\otimes \\mathbb{C}^3 \\otimes\n\\mathbb{C}^3$. These generators have respectively 1152, 9216 and 209061 terms;\nwe find compact expressions in terms of the orbits of the finite group $(S_3\n\\times S_3 \\times S_3) \\rtimes S_3$ acting on monomials of weight zero for the\naction of the Lie algebra $\\mathfrak{sl}_3(\\mathbb{C}) \\oplus\n\\mathfrak{sl}_3(\\mathbb{C}) \\oplus \\mathfrak{sl}_3(\\mathbb{C})$."
},{
    "category": "math.AG", 
    "doi": "10.1112/S1461157012001179", 
    "link": "http://arxiv.org/pdf/1112.4881v2", 
    "title": "Computing zeta functions of sparse nondegenerate hypersurfaces", 
    "arxiv-id": "1112.4881v2", 
    "author": "John Voight", 
    "publish": "2011-12-20T23:26:07Z", 
    "summary": "Using the cohomology theory of Dwork, as developed by Adolphson and Sperber,\nwe exhibit a deterministic algorithm to compute the zeta function of a\nnondegenerate hypersurface defined over a finite field. This algorithm is\nparticularly well-suited to work with polynomials in small characteristic that\nhave few monomials (relative to their dimension). Our method covers toric,\naffine, and projective hypersurfaces and also can be used to compute the\nL-function of an exponential sum."
},{
    "category": "cs.SC", 
    "doi": "10.1112/S1461157012001179", 
    "link": "http://arxiv.org/pdf/1201.1954v2", 
    "title": "Telescopers for Rational and Algebraic Functions via Residues", 
    "arxiv-id": "1201.1954v2", 
    "author": "Michael F. Singer", 
    "publish": "2012-01-10T02:23:14Z", 
    "summary": "We show that the problem of constructing telescopers for functions of m\nvariables is equivalent to the problem of constructing telescopers for\nalgebraic functions of m -1 variables and present a new algorithm to construct\ntelescopers for algebraic functions of two variables. These considerations are\nbased on analyzing the residues of the input. According to experiments, the\nresulting algorithm for rational functions of three variables is faster than\nknown algorithms, at least in some examples of combinatorial interest. The\nalgorithm for algebraic functions implies a new bound on the order of the\ntelescopers."
},{
    "category": "math.GT", 
    "doi": "10.1112/S1461157012001179", 
    "link": "http://arxiv.org/pdf/1201.3353v2", 
    "title": "Twisting q-holonomic sequences by complex roots of unity", 
    "arxiv-id": "1201.3353v2", 
    "author": "Christoph Koutschan", 
    "publish": "2012-01-16T20:25:05Z", 
    "summary": "A sequence $f_n(q)$ is $q$-holonomic if it satisfies a nontrivial linear\nrecurrence with coefficients polynomials in $q$ and $q^n$. Our main theorems\nstate that $q$-holonomicity is preserved under twisting, i.e., replacing $q$ by\n$\\omega q$ where $\\omega$ is a complex root of unity, and under the\nsubstitution $q \\to q^{\\alpha}$ where $\\alpha$ is a rational number. Our proofs\nare constructive, work in the multivariate setting of $\\partial$-finite\nsequences and are implemented in the Mathematica package HolonomicFunctions.\nOur results are illustrated by twisting natural $q$-holonomic sequences which\nappear in quantum topology, namely the colored Jones polynomial of pretzel\nknots and twist knots. The recurrence of the twisted colored Jones polynomial\ncan be used to compute the asymptotics of the Kashaev invariant of a knot at an\narbitrary complex root of unity."
},{
    "category": "cs.SC", 
    "doi": "10.1112/S1461157012001179", 
    "link": "http://arxiv.org/pdf/1201.3401v2", 
    "title": "Computing Puiseux Series for Algebraic Surfaces", 
    "arxiv-id": "1201.3401v2", 
    "author": "Jan Verschelde", 
    "publish": "2012-01-17T00:16:44Z", 
    "summary": "In this paper we outline an algorithmic approach to compute Puiseux series\nexpansions for algebraic surfaces. The series expansions originate at the\nintersection of the surface with as many coordinate planes as the dimension of\nthe surface. Our approach starts with a polyhedral method to compute cones of\nnormal vectors to the Newton polytopes of the given polynomial system that\ndefines the surface. If as many vectors in the cone as the dimension of the\nsurface define an initial form system that has isolated solutions, then those\nvectors are potential tropisms for the initial term of the Puiseux series\nexpansion. Our preliminary methods produce exact representations for solution\nsets of the cyclic $n$-roots problem, for $n = m^2$, corresponding to a result\nof Backelin."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2012.09.001", 
    "link": "http://arxiv.org/pdf/1201.4050v2", 
    "title": "On the Shape of Curves that are Rational in Polar Coordinates", 
    "arxiv-id": "1201.4050v2", 
    "author": "G. M. D\u00edaz-Toca", 
    "publish": "2012-01-19T13:01:17Z", 
    "summary": "In this paper we provide a computational approach to the shape of curves\nwhich are rational in polar coordinates, i.e. which are defined by means of a\nparametrization (r(t),\\theta(t)) where both r(t),\\theta(t) are rational\nfunctions. Our study includes theoretical aspects on the shape of these curves,\nand algorithmic results which eventually lead to an algorithm for plotting the\n\"interesting parts\" of the curve, i.e. the parts showing the main geometrical\nfeatures of it. On the theoretical side, we prove that these curves, with the\nexceptions of lines and circles, cannot be algebraic (in cartesian\ncoordinates), we characterize the existence of infinitely many\nself-intersections, and we connect this with certain phenomena which are not\npossible in the algebraic world, namely the existence of limit circles, limit\npoints, or spiral branches. On the practical side, we provide an algorithm\nwhich has been implemented in the computer algebra system Maple to visualize\nthis kind of curves. Our implementation makes use (and improves some aspects\nof) the command polarplot currently available in Maple for plotting curves in\npolar form."
},{
    "category": "cs.SE", 
    "doi": "10.1016/j.cagd.2012.09.001", 
    "link": "http://arxiv.org/pdf/1201.5086v2", 
    "title": "Generating Program Invariants via Interpolation", 
    "arxiv-id": "1201.5086v2", 
    "author": "Rong Xiao", 
    "publish": "2012-01-24T18:43:37Z", 
    "summary": "This article focuses on automatically generating polynomial equations that\nare inductive loop invariants of computer programs. We propose a new algorithm\nfor this task, which is based on polynomial interpolation. Though the proposed\nalgorithm is not complete, it is efficient and can be applied to a broader\nrange of problems compared to existing methods targeting similar problems. The\nefficiency of our approach is testified by experiments on a large collection of\nprograms. The current implementation of our method is based on dense\ninterpolation, for which a total degree bound is needed. On the theoretical\nfront, we study the degree and dimension of the invariant ideal of loops which\nhave no branches and where the assignments define a P-solvable recurrence. In\naddition, we obtain sufficient conditions for non-trivial polynomial equation\ninvariants to exist (resp. not to exist)."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cagd.2012.09.001", 
    "link": "http://arxiv.org/pdf/1201.5810v1", 
    "title": "A General Solver Based on Sparse Resultants", 
    "arxiv-id": "1201.5810v1", 
    "author": "Ioannis Z. Emiris", 
    "publish": "2012-01-27T16:01:53Z", 
    "summary": "Sparse (or toric) elimination exploits the structure of polynomials by\nmeasuring their complexity in terms of Newton polytopes instead of total\ndegree. The sparse, or Newton, resultant generalizes the classical homogeneous\nresultant and its degree is a function of the mixed volumes of the Newton\npolytopes. We sketch the sparse resultant constructions of Canny and Emiris and\nshow how they reduce the problem of root-finding to an eigenproblem. A novel\nmethod for achieving this reduction is presented which does not increase the\ndimension of the problem. Together with an implementation of the sparse\nresultant construction, it provides a general solver for polynomial systems. We\ndiscuss the overall implementation and illustrate its use by applying it to\nconcrete problems from vision, robotics and structural biology. The high\nefficiency and accuracy of the solutions suggest that sparse elimination may be\nthe method of choice for systems of moderate size."
},{
    "category": "cs.IT", 
    "doi": "10.1007/s10623-016-0226-3", 
    "link": "http://arxiv.org/pdf/1201.5921v1", 
    "title": "An iterative algorithm for parametrization of shortest length shift   registers over finite rings", 
    "arxiv-id": "1201.5921v1", 
    "author": "R. Pinto", 
    "publish": "2012-01-28T03:08:41Z", 
    "summary": "The construction of shortest feedback shift registers for a finite sequence\nS_1,...,S_N is considered over the finite ring Z_{p^r}. A novel algorithm is\npresented that yields a parametrization of all shortest feedback shift\nregisters for the sequence of numbers S_1,...,S_N, thus solving an open problem\nin the literature. The algorithm iteratively processes each number, starting\nwith S_1, and constructs at each step a particular type of minimal Gr\\\"obner\nbasis. The construction involves a simple update rule at each step which leads\nto computational efficiency. It is shown that the algorithm simultaneously\ncomputes a similar parametrization for the reciprocal sequence S_N,...,S_1."
},{
    "category": "math-ph", 
    "doi": "10.1007/s10623-016-0226-3", 
    "link": "http://arxiv.org/pdf/1202.4303v1", 
    "title": "Evaluation of Multi-Sums for Large Scale Problems", 
    "arxiv-id": "1202.4303v1", 
    "author": "C. Schneider", 
    "publish": "2012-02-20T12:40:56Z", 
    "summary": "A big class of Feynman integrals, in particular, the coefficients of their\nLaurent series expansion w.r.t.\\ the dimension parameter $\\ep$ can be\ntransformed to multi-sums over hypergeometric terms and harmonic sums. In this\narticle, we present a general summation method based on difference fields that\nsimplifies these multi--sums by transforming them from inside to outside to\nrepresentations in terms of indefinite nested sums and products. In particular,\nwe present techniques that assist in the task to simplify huge expressions of\nsuch multi-sums in a completely automatic fashion. The ideas are illustrated on\nnew calculations coming from 3-loop topologies of gluonic massive operator\nmatrix elements containing two fermion lines, which contribute to the\ntransition matrix elements in the variable flavor scheme."
},{
    "category": "cs.SY", 
    "doi": "10.4204/EPTCS.79", 
    "link": "http://arxiv.org/pdf/1202.4535v1", 
    "title": "Proceedings First Workshop on CTP Components for Educational Software", 
    "arxiv-id": "1202.4535v1", 
    "author": "Ralph-Johan Back", 
    "publish": "2012-02-21T05:56:10Z", 
    "summary": "The THedu'11 workshop received thirteen submissions, twelve of which were\naccepted and presented during the workshop. For the post-conference proceedings\nnine submission where received and accepted. The submissions are within the\nscope of the following points, which have been announced in the call of papers:\nCTP-based software tools for education; CTP technology combined with novel\ninterfaces, drag and drop, etc.; technologies to access ITP knowledge relevant\nfor a certain step of problem solving; usability considerations on representing\nITP knowledge; combination of deduction and computation; formal problem\nspecifications; effectiveness of ATP in checking user input; formats for\ndeductive content in proof documents, geometric constructions, etc; formal\ndomain models for e-learning in mathematics and applications."
},{
    "category": "cs.AI", 
    "doi": "10.4204/EPTCS.79.1", 
    "link": "http://arxiv.org/pdf/1202.4828v1", 
    "title": "Towards an Intelligent Tutor for Mathematical Proofs", 
    "arxiv-id": "1202.4828v1", 
    "author": "Marvin Schiller", 
    "publish": "2012-02-22T06:41:20Z", 
    "summary": "Computer-supported learning is an increasingly important form of study since\nit allows for independent learning and individualized instruction. In this\npaper, we discuss a novel approach to developing an intelligent tutoring system\nfor teaching textbook-style mathematical proofs. We characterize the\nparticularities of the domain and discuss common ITS design models. Our\napproach is motivated by phenomena found in a corpus of tutorial dialogs that\nwere collected in a Wizard-of-Oz experiment. We show how an intelligent tutor\nfor textbook-style mathematical proofs can be built on top of an adapted\nassertion-level proof assistant by reusing representations and proof search\nstrategies originally developed for automated and interactive theorem proving.\nThe resulting prototype was successfully evaluated on a corpus of tutorial\ndialogs and yields good results."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.79.4", 
    "link": "http://arxiv.org/pdf/1202.4831v1", 
    "title": "Formalization and Implementation of Algebraic Methods in Geometry", 
    "arxiv-id": "1202.4831v1", 
    "author": "Predrag Jani\u010di\u0107", 
    "publish": "2012-02-22T06:41:45Z", 
    "summary": "We describe our ongoing project of formalization of algebraic methods for\ngeometry theorem proving (Wu's method and the Groebner bases method), their\nimplementation and integration in educational tools. The project includes\nformal verification of the algebraic methods within Isabelle/HOL proof\nassistant and development of a new, open-source Java implementation of the\nalgebraic methods. The project should fill-in some gaps still existing in this\narea (e.g., the lack of formal links between algebraic methods and synthetic\ngeometry and the lack of self-contained implementations of algebraic methods\nsuitable for integration with dynamic geometry tools) and should enable new\napplications of theorem proving in education."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1202.4834v1", 
    "title": "Computer-Assisted Program Reasoning Based on a Relational Semantics of   Programs", 
    "arxiv-id": "1202.4834v1", 
    "author": "Wolfgang Schreiner", 
    "publish": "2012-02-22T06:42:11Z", 
    "summary": "We present an approach to program reasoning which inserts between a program\nand its verification conditions an additional layer, the denotation of the\nprogram expressed in a declarative form. The program is first translated into\nits denotation from which subsequently the verification conditions are\ngenerated. However, even before (and independently of) any verification\nattempt, one may investigate the denotation itself to get insight into the\n\"semantic essence\" of the program, in particular to see whether the denotation\nindeed gives reason to believe that the program has the expected behavior.\nErrors in the program and in the meta-information may thus be detected and\nfixed prior to actually performing the formal verification. More concretely,\nfollowing the relational approach to program semantics, we model the effect of\na program as a binary relation on program states. A formal calculus is devised\nto derive from a program a logic formula that describes this relation and is\nsubject for inspection and manipulation. We have implemented this idea in a\ncomprehensive form in the RISC ProgramExplorer, a new program reasoning\nenvironment for educational purposes which encompasses the previously developed\nRISC ProofNavigator as an interactive proving assistant."
},{
    "category": "math.CO", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1203.4200v1", 
    "title": "Residues and Telescopers for Rational Functions", 
    "arxiv-id": "1203.4200v1", 
    "author": "Michael F. Singer", 
    "publish": "2012-03-19T18:56:35Z", 
    "summary": "We give necessary and sufficient conditions for the existence of telescopers\nfor rational functions of two variables in the continuous, discrete and\nq-discrete settings and characterize which operators can occur as telescopers.\nUsing this latter characterization, we reprove results of Furstenberg and\nZeilberger concerning diagonals of power series representing rational\nfunctions. The key concept behind these considerations is a generalization of\nthe notion of residue in the continuous case to an analogous concept in the\ndiscrete and q-discrete cases."
},{
    "category": "cs.SE", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1203.6806v1", 
    "title": "State Space Exploration of RT Systems in the Cloud", 
    "arxiv-id": "1203.6806v1", 
    "author": "Mattia Monga", 
    "publish": "2012-03-30T13:13:49Z", 
    "summary": "The growing availability of distributed and cloud computing frameworks make\nit possible to face complex computational problems in a more effective and\nconvenient way. A notable example is state-space exploration of discrete-event\nsystems specified in a formal way. The exponential complexity of this task is a\nmajor limitation to the usage of consolidated analysis techniques and tools. We\npresent and compare two different approaches to state-space explosion, relying\non distributed and cloud frameworks, respectively. These approaches were\ndesigned and implemented following the same computational schema, a sort of map\n& fold. They are applied on symbolic state-space exploration of real-time\nsystems specified by (a timed extension of) Petri Nets, by readapting a\nsequential algorithm implemented as a command-line Java tool. The outcome of\nseveral tests performed on a benchmarking specification are presented, thus\nshowing the convenience of cloud approaches."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1205.0456v1", 
    "title": "An efficient implementation of the algorithm computing the Borel-fixed   points of a Hilbert scheme", 
    "arxiv-id": "1205.0456v1", 
    "author": "Paolo Lella", 
    "publish": "2012-05-02T15:11:48Z", 
    "summary": "Borel-fixed ideals play a key role in the study of Hilbert schemes. Indeed\neach component and each intersection of components of a Hilbert scheme contains\nat least one Borel-fixed point, i.e. a point corresponding to a subscheme\ndefined by a Borel-fixed ideal. Moreover Borel-fixed ideals have good\ncombinatorial properties, which make them very interesting in an algorithmic\nperspective. In this paper, we propose an implementation of the algorithm\ncomputing all the saturated Borel-fixed ideals with number of variables and\nHilbert polynomial assigned, introduced from a theoretical point of view in the\npaper \"Segment ideals and Hilbert schemes of points\", Discrete Mathematics 311\n(2011)."
},{
    "category": "cs.MS", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1205.5975v1", 
    "title": "A Domain-Specific Compiler for Linear Algebra Operations", 
    "arxiv-id": "1205.5975v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2012-05-27T15:22:23Z", 
    "summary": "We present a prototypical linear algebra compiler that automatically exploits\ndomain-specific knowledge to generate high-performance algorithms. The input to\nthe compiler is a target equation together with knowledge of both the structure\nof the problem and the properties of the operands. The output is a variety of\nhigh-performance algorithms, and the corresponding source code, to solve the\ntarget equation. Our approach consists in the decomposition of the input\nequation into a sequence of library-supported kernels. Since in general such a\ndecomposition is not unique, our compiler returns not one but a number of\nalgorithms. The potential of the compiler is shown by means of its application\nto a challenging equation arising within the genome-wide association study. As\na result, the compiler produces multiple \"best\" algorithms that outperform the\nbest existing libraries."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1205.6671v1", 
    "title": "Quasi-Stability versus Genericity", 
    "arxiv-id": "1205.6671v1", 
    "author": "Werner M. Seiler", 
    "publish": "2012-05-30T13:34:13Z", 
    "summary": "Quasi-stable ideals appear as leading ideals in the theory of Pommaret bases.\nWe show that quasi-stable leading ideals share many of the properties of the\ngeneric initial ideal. In contrast to genericity, quasi-stability is a\ncharacteristic independent property that can be effectively verified. We also\nrelate Pommaret bases to some invariants associated with local cohomology,\nexhibit the existence of linear quotients in Pommaret bases and prove some\nresults on componentwise linear ideals."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.79.8", 
    "link": "http://arxiv.org/pdf/1206.0181v2", 
    "title": "Comprehensive Involutive Systems", 
    "arxiv-id": "1206.0181v2", 
    "author": "Amir Hashemi", 
    "publish": "2012-06-01T13:45:27Z", 
    "summary": "In this paper, we consider parametric ideals and introduce a notion of\ncomprehensive involutive system. This notion plays the same role in theory of\ninvolutive bases as the notion of comprehensive Groebner system in theory of\nGroebner bases. Given a parametric ideal, the space of parameters is decomposed\ninto a finite set of cells. Each cell yields the corresponding involutive basis\nof the ideal for the values of parameters in that cell. Using the Gerdt-Blinkov\nalgorithm for computing involutive bases and also the Montes algorithm for\ncomputing comprehensive Groebner systems, we present an algorithm for\nconstruction of comprehensive involutive systems. The proposed algorithm has\nbeen implemented in Maple, and we provide an illustrative example showing the\nstep-by-step construction of comprehensive involutive system by our algorithm."
},{
    "category": "math.DS", 
    "doi": "10.1090/conm/549", 
    "link": "http://arxiv.org/pdf/1206.6345v1", 
    "title": "A Reduction Method for Higher Order Variational Equations of Hamiltonian   Systems", 
    "arxiv-id": "1206.6345v1", 
    "author": "Jacques-Arthur Weil", 
    "publish": "2012-06-27T17:38:40Z", 
    "summary": "Let $\\mathbf{k}$ be a differential field and let $[A]\\,:\\,Y'=A\\,Y$ be a\nlinear differential system where $A\\in\\mathrm{Mat}(n\\,,\\,\\mathbf{k})$. We say\nthat $A$ is in a reduced form if $A\\in\\mathfrak{g}(\\bar{\\mathbf{k}})$ where\n$\\mathfrak{g}$ is the Lie algebra of $[A]$ and $\\bar{\\mathbf{k}}$ denotes the\nalgebraic closure of $\\mathbf{k}$. We owe the existence of such reduced forms\nto a result due to Kolchin and Kovacic \\cite{Ko71a}. This paper is devoted to\nthe study of reduced forms, of (higher order) variational equations along a\nparticular solution of a complex analytical hamiltonian system $X$. Using a\nprevious result \\cite{ApWea}, we will assume that the first order variational\nequation has an abelian Lie algebra so that, at first order, there are no\nGaloisian obstructions to Liouville integrability. We give a strategy to\n(partially) reduce the variational equations at order $m+1$ if the variational\nequations at order $m$ are already in a reduced form and their Lie algebra is\nabelian. Our procedure stops when we meet obstructions to the meromorphic\nintegrability of $X$. We make strong use both of the lower block triangular\nstructure of the variational equations and of the notion of associated Lie\nalgebra of a linear differential system (based on the works of Wei and Norman\nin \\cite{WeNo63a}). Obstructions to integrability appear when at some step we\nobtain a non-trivial commutator between a diagonal element and a nilpotent\n(subdiagonal) element of the associated Lie algebra. We use our method coupled\nwith a reasoning on polylogarithms to give a new and systematic proof of the\nnon-integrability of the H\\'enon-Heiles system. We conjecture that our method\nis not only a partial reduction procedure but a complete reduction algorithm.\nIn the context of complex Hamiltonian systems, this would mean that our method\nwould be an effective version of the Morales-Ramis-Sim\\'o theorem."
},{
    "category": "math.CA", 
    "doi": "10.1090/conm/549", 
    "link": "http://arxiv.org/pdf/1206.6661v2", 
    "title": "A Characterization of Reduced Forms of Linear Differential Systems", 
    "arxiv-id": "1206.6661v2", 
    "author": "Jacques-Arthur Weil", 
    "publish": "2012-06-28T12:36:24Z", 
    "summary": "A differential system $[A] : \\; Y'=AY$, with $A\\in \\mathrm{Mat}(n, \\bar{k})$\nis said to be in reduced form if $A\\in \\mathfrak{g}(\\bar{k})$ where\n$\\mathfrak{g}$ is the Lie algebra of the differential Galois group $G$ of\n$[A]$. In this article, we give a constructive criterion for a system to be in\nreduced form. When $G$ is reductive and unimodular, the system $[A]$ is in\nreduced form if and only if all of its invariants (rational solutions of\nappropriate symmetric powers) have constant coefficients (instead of rational\nfunctions). When $G$ is non-reductive, we give a similar characterization via\nthe semi-invariants of $G$. In the reductive case, we propose a decision\nprocedure for putting the system into reduced form which, in turn, gives a\nconstructive proof of the classical Kolchin-Kovacic reduction theorem."
},{
    "category": "cs.SC", 
    "doi": "10.1090/conm/549", 
    "link": "http://arxiv.org/pdf/1206.6940v1", 
    "title": "Practical Groebner Basis Computation", 
    "arxiv-id": "1206.6940v1", 
    "author": "Michael Stillman", 
    "publish": "2012-06-29T05:15:19Z", 
    "summary": "We report on our experiences exploring state of the art Groebner basis\ncomputation. We investigate signature based algorithms in detail. We also\nintroduce new practical data structures and computational techniques for use in\nboth signature based Groebner basis algorithms and more traditional variations\nof the classic Buchberger algorithm. Our conclusions are based on experiments\nusing our new freely available open source standalone C++ library."
},{
    "category": "cs.CE", 
    "doi": "10.4204/EPTCS.92.5", 
    "link": "http://arxiv.org/pdf/1208.3852v1", 
    "title": "Hybrid Automata and \u03b5-Analysis on a Neural Oscillator", 
    "arxiv-id": "1208.3852v1", 
    "author": "Carla Piazza", 
    "publish": "2012-08-19T16:01:27Z", 
    "summary": "In this paper we propose a hybrid model of a neural oscillator, obtained by\npartially discretizing a well-known continuous model. Our construction points\nout that in this case the standard techniques, based on replacing sigmoids with\nstep functions, is not satisfactory. Then, we study the hybrid model through\nboth symbolic methods and approximation techniques. This last analysis, in\nparticular, allows us to show the differences between the considered\napproximation approaches. Finally, we focus on approximations via\nepsilon-semantics, proving how these can be computed in practice."
},{
    "category": "cs.SC", 
    "doi": "10.4204/EPTCS.92.5", 
    "link": "http://arxiv.org/pdf/1209.5127v4", 
    "title": "A proposal to first principles electronic structure calculation:   Symbolic-Numeric method", 
    "arxiv-id": "1209.5127v4", 
    "author": "Akihito Kikuchi", 
    "publish": "2012-09-23T23:50:56Z", 
    "summary": "This study proposes an approach toward the first principles electronic\nstructure calculation with the aid of symbolic-numeric solving. The symbolic\ncomputation enables us to express the Hartree-Fock-Roothaan equation and the\nmolecular integrals in analytic forms and approximate them as a set of\npolynomial equations. By use of the Grobner bases technique, the polynomial\nequations are transformed into other ones which have identical roots. The\nconverted equations take more convenient forms which will simplify numerical\nprocedures, from which we can derive necessary physical properties in order, in\nan a la carte way. This method enables us to solve the electronic structure\ncalculation, the optimization of any kind, or the inverse problem as a forward\nproblem in a unified way, in which there is no need for iterative\nself-consistent procedures with trials and errors."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-0794-2_13", 
    "link": "http://arxiv.org/pdf/1210.2950v1", 
    "title": "Symbolic Analysis for Boundary Problems: From Rewriting to Parametrized   Gr\u00f6bner Bases", 
    "arxiv-id": "1210.2950v1", 
    "author": "Bruno Buchberger", 
    "publish": "2012-10-10T15:11:49Z", 
    "summary": "We review our algebraic framework for linear boundary problems (concentrating\non ordinary differential equations). Its starting point is an appropriate\nalgebraization of the domain of functions, which we have named\nintegro-differential algebras. The algebraic treatment of boundary problems\nbrings up two new algebraic structures whose symbolic representation and\ncomputational realization is based on canonical forms in certain commutative\nand noncommutative polynomial domains. The first of these, the ring of\nintegro-differential operators, is used for both stating and solving linear\nboundary problems. The other structure, called integro-differential\npolynomials, is the key tool for describing extensions of integro-differential\nalgebras. We use the canonical simplifier for integro-differential polynomials\nfor generating an automated proof establishing a canonical simplifier for\nintegro-differential operators. Our approach is fully implemented in the\nTheorema system; some code fragments and sample computations are included."
},{
    "category": "cs.MS", 
    "doi": "10.1007/978-3-7091-0794-2_13", 
    "link": "http://arxiv.org/pdf/1211.4047v2", 
    "title": "Unified Form Language: A domain-specific language for weak formulations   of partial differential equations", 
    "arxiv-id": "1211.4047v2", 
    "author": "Garth N. Wells", 
    "publish": "2012-11-16T21:56:02Z", 
    "summary": "We present the Unified Form Language (UFL), which is a domain-specific\nlanguage for representing weak formulations of partial differential equations\nwith a view to numerical approximation. Features of UFL include support for\nvariational forms and functionals, automatic differentiation of forms and\nexpressions, arbitrary function space hierarchies for multi-field problems,\ngeneral differential operators and flexible tensor algebra. With these\nfeatures, UFL has been used to effortlessly express finite element methods for\ncomplex systems of partial differential equations in near-mathematical\nnotation, resulting in compact, intuitive and readable programs. We present in\nthis work the language and its construction. An implementation of UFL is freely\navailable as an open-source software library. The library generates abstract\nsyntax tree representations of variational problems, which are used by other\nsoftware libraries to generate concrete low-level implementations. Some\napplication examples are presented and libraries that support UFL are\nhighlighted."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-7091-0794-2_13", 
    "link": "http://arxiv.org/pdf/1211.4892v1", 
    "title": "Confusion of Tagged Perturbations in Forward Automatic Differentiation   of Higher-Order Functions", 
    "arxiv-id": "1211.4892v1", 
    "author": "Jeffrey Mark Siskind", 
    "publish": "2012-11-20T22:08:31Z", 
    "summary": "Forward Automatic Differentiation (AD) is a technique for augmenting programs\nto both perform their original calculation and also compute its directional\nderivative. The essence of Forward AD is to attach a derivative value to each\nnumber, and propagate these through the computation. When derivatives are\nnested, the distinct derivative calculations, and their associated attached\nvalues, must be distinguished. In dynamic languages this is typically\naccomplished by creating a unique tag for each application of the derivative\noperator, tagging the attached values, and overloading the arithmetic\noperators. We exhibit a subtle bug, present in fielded implementations, in\nwhich perturbations are confused despite the tagging machinery."
},{
    "category": "math.GT", 
    "doi": "10.2140/agt.2013.13.3261", 
    "link": "http://arxiv.org/pdf/1211.6020v3", 
    "title": "Irreducibility of q-difference operators and the knot 7_4", 
    "arxiv-id": "1211.6020v3", 
    "author": "Christoph Koutschan", 
    "publish": "2012-11-26T16:49:57Z", 
    "summary": "Our goal is to compute the minimal-order recurrence of the colored Jones\npolynomial of the 7_4 knot, as well as for the first four double twist knots.\nAs a corollary, we verify the AJ Conjecture for the simplest knot 7_4 with\nreducible non-abelian SL(2,C) character variety. To achieve our goal, we use\nsymbolic summation techniques of Zeilberger's holonomic systems approach and an\nirreducibility criterion for q-difference operators. For the latter we use an\nimproved version of the qHyper algorithm of Abramov-Paule-Petkovsek to show\nthat a given q-difference operator has no linear right factors. En route, we\nintroduce exterior power Adams operations on the ring of bivariate polynomials\nand on the corresponding affine curves."
},{
    "category": "math.CA", 
    "doi": "10.2140/agt.2013.13.3261", 
    "link": "http://arxiv.org/pdf/1212.6103v3", 
    "title": "Pfaffian Systems of A-Hypergeometric Equations I: Bases of Twisted   Cohomology Groups", 
    "arxiv-id": "1212.6103v3", 
    "author": "Nobuki Takayama", 
    "publish": "2012-12-25T23:49:03Z", 
    "summary": "This is the third revision. We study bases of Pfaffian systems for\n$A$-hypergeometric system. Gr\\\"obner deformations give bases. These bases also\ngive those for twisted cohomology groups. For hypergeometric system associated\nto a class of order polytopes, these bases have a combinatorial description.\nThe size of the bases associated to a subclass of the order polytopes have the\ngrowth rate of the polynomial order. Bases associated to two chain posets and\nbouquets are studied."
},{
    "category": "cs.SC", 
    "doi": "10.2140/agt.2013.13.3261", 
    "link": "http://arxiv.org/pdf/1302.1219v2", 
    "title": "Introduction to Redberry: a computer algebra system designed for tensor   manipulation", 
    "arxiv-id": "1302.1219v2", 
    "author": "S. V. Poslavsky", 
    "publish": "2013-02-05T22:15:43Z", 
    "summary": "In this paper we introduce Redberry --- an open source computer algebra\nsystem with native support of tensorial expressions. It provides basic computer\nalgebra tools (algebraic manipulations, substitutions, basic simplifications\netc.) which are aware of specific features of indexed expressions: contractions\nof indices, permutational symmetries, multiple index types etc. Redberry\nsupports conventional \\LaTeX-style input notation for tensorial expressions.\nThe high energy physics package includes tools for Feynman diagrams\ncalculation: Dirac and SU(N) algebra, Levi-Civita simplifications and tools for\none-loop calculations in quantum field theory. In the paper we give detailed\noverview of Redberry features: from basic manipulations with tensors to real\nFeynman diagrams calculation, accompanied by many examples. Redberry is written\nin Java 7 and provides convenient Groovy-based user interface inside the\nhigh-level general purpose programming language environment. Redberry is\navailable from http://redberry.cc"
},{
    "category": "cs.CC", 
    "doi": "10.2140/agt.2013.13.3261", 
    "link": "http://arxiv.org/pdf/1303.0084v2", 
    "title": "Explicit Noether Normalization for Simultaneous Conjugation via   Polynomial Identity Testing", 
    "arxiv-id": "1303.0084v2", 
    "author": "Amir Shpilka", 
    "publish": "2013-03-01T04:44:00Z", 
    "summary": "Mulmuley recently gave an explicit version of Noether's Normalization lemma\nfor ring of invariants of matrices under simultaneous conjugation, under the\nconjecture that there are deterministic black-box algorithms for polynomial\nidentity testing (PIT). He argued that this gives evidence that constructing\nsuch algorithms for PIT is beyond current techniques. In this work, we show\nthis is not the case. That is, we improve Mulmuley's reduction and\ncorrespondingly weaken the conjecture regarding PIT needed to give explicit\nNoether Normalization. We then observe that the weaker conjecture has recently\nbeen nearly settled by the authors, who gave quasipolynomial size hitting sets\nfor the class of read-once oblivious algebraic branching programs (ROABPs).\nThis gives the desired explicit Noether Normalization unconditionally, up to\nquasipolynomial factors.\n  As a consequence of our proof we give a deterministic parallel\npolynomial-time algorithm for deciding if two matrix tuples have intersecting\norbit closures, under simultaneous conjugation.\n  We also study the strength of conjectures that Mulmuley requires to obtain\nsimilar results as ours. We prove that his conjectures are stronger, in the\nsense that the computational model he needs PIT algorithms for is equivalent to\nthe well-known algebraic branching program (ABP) model, which is provably\nstronger than the ROABP model.\n  Finally, we consider the depth-3 diagonal circuit model as defined by Saxena,\nas PIT algorithms for this model also have implications in Mulmuley's work.\nPrevious work have given quasipolynomial size hitting sets for this model. In\nthis work, we give a much simpler construction of such hitting sets, using\ntechniques of Shpilka and Volkovich."
},{
    "category": "math.AG", 
    "doi": "10.2140/agt.2013.13.3261", 
    "link": "http://arxiv.org/pdf/1303.0266v3", 
    "title": "Elimination for generic sparse polynomial systems", 
    "arxiv-id": "1303.0266v3", 
    "author": "Juan Sabia", 
    "publish": "2013-03-01T20:12:54Z", 
    "summary": "We present a new probabilistic symbolic algorithm that, given a variety\ndefined in an n-dimensional affine space by a generic sparse system with fixed\nsupports, computes the Zariski closure of its projection to an l-dimensional\ncoordinate affine space with l < n. The complexity of the algorithm depends\npolynomially on combinatorial invariants associated to the supports."
},{
    "category": "cs.SC", 
    "doi": "10.2140/agt.2013.13.3261", 
    "link": "http://arxiv.org/pdf/1303.0738v1", 
    "title": "New Symbolic Algorithms For Solving A General Bordered Tridiagonal   Linear System", 
    "arxiv-id": "1303.0738v1", 
    "author": "A. A. Karawia", 
    "publish": "2013-03-04T15:52:39Z", 
    "summary": "In this paper, the author present reliable symbolic algorithms for solving a\ngeneral bordered tridiagonal linear system. The first algorithm is based on the\nLU decomposition of the coefficient matrix and the computational cost of it is\nO(n). The second is based on The Sherman-Morrison-Woodbury formula. The\nalgorithms are implementable to the Computer Algebra System (CAS) such as\nMAPLE, MATLAB and MATHEMATICA. Three examples are presented for the sake of\nillustration."
},{
    "category": "math.AG", 
    "doi": "10.1007/s11786-014-0185-x", 
    "link": "http://arxiv.org/pdf/1303.1132v2", 
    "title": "Tropicalization of classical moduli spaces", 
    "arxiv-id": "1303.1132v2", 
    "author": "Bernd Sturmfels", 
    "publish": "2013-03-05T18:36:36Z", 
    "summary": "The image of the complement of a hyperplane arrangement under a monomial map\ncan be tropicalized combinatorially using matroid theory. We apply this to\nclassical moduli spaces that are associated with complex reflection\narrangements. Starting from modular curves, we visit the Segre cubic, the Igusa\nquartic, and moduli of marked del Pezzo surfaces of degrees 2 and 3. Our\nprimary example is the Burkhardt quartic, whose tropicalization is a\n3-dimensional fan in 39-dimensional space. This effectuates a synthesis of\nconcrete and abstract approaches to tropical moduli of genus 2 curves."
},{
    "category": "math.AG", 
    "doi": "10.1007/s11786-014-0185-x", 
    "link": "http://arxiv.org/pdf/1303.6296v1", 
    "title": "A Variant of the Gr\u00f6bner Basis Algorithm for Computing Hilbert Bases", 
    "arxiv-id": "1303.6296v1", 
    "author": "Karl-Heinz Zimmermann", 
    "publish": "2013-03-25T20:03:06Z", 
    "summary": "Gr\\\"obner bases can be used for computing the Hilbert basis of a numerical\nsubmonoid. By using these techniques, we provide an algorithm that calculates a\nbasis of a subspace of a finite-dimensional vector space over a finite prime\nfield given as a matrix kernel."
},{
    "category": "cs.SC", 
    "doi": "10.1007/s11786-014-0185-x", 
    "link": "http://arxiv.org/pdf/1303.7425v1", 
    "title": "Highly Scalable Multiplication for Distributed Sparse Multivariate   Polynomials on Many-core Systems", 
    "arxiv-id": "1303.7425v1", 
    "author": "Jacques Laskar", 
    "publish": "2013-03-29T15:47:45Z", 
    "summary": "We present a highly scalable algorithm for multiplying sparse multivariate\npolynomials represented in a distributed format. This algo- rithm targets not\nonly the shared memory multicore computers, but also computers clusters or\nspecialized hardware attached to a host computer, such as graphics processing\nunits or many-core coprocessors. The scal- ability on the large number of cores\nis ensured by the lacks of synchro- nizations, locks and false-sharing during\nthe main parallel step."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2014.02.006", 
    "link": "http://arxiv.org/pdf/1308.3493v1", 
    "title": "xTras: a field-theory inspired xAct package for Mathematica", 
    "arxiv-id": "1308.3493v1", 
    "author": "Teake Nutma", 
    "publish": "2013-08-15T20:00:02Z", 
    "summary": "We present the tensor computer algebra package xTras, which provides\nfunctions and methods frequently needed when doing (classical) field theory.\nAmongst others, it can compute contractions, make Ans\\\"atze, and solve\ntensorial equations. It is built upon the tensor computer algebra system xAct,\na collection of packages for Mathematica."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2014.02.006", 
    "link": "http://arxiv.org/pdf/1308.4088v2", 
    "title": "Computing Real Roots of Real Polynomials", 
    "arxiv-id": "1308.4088v2", 
    "author": "Kurt Mehlhorn", 
    "publish": "2013-08-19T18:14:39Z", 
    "summary": "Computing the roots of a univariate polynomial is a fundamental and\nlong-studied problem of computational algebra with applications in mathematics,\nengineering, computer science, and the natural sciences. For isolating as well\nas for approximating all complex roots, the best algorithm known is based on an\nalmost optimal method for approximate polynomial factorization, introduced by\nPan in 2002. Pan's factorization algorithm goes back to the splitting circle\nmethod from Schoenhage in 1982. The main drawbacks of Pan's method are that it\nis quite involved and that all roots have to be computed at the same time. For\nthe important special case, where only the real roots have to be computed, much\nsimpler methods are used in practice; however, they considerably lag behind\nPan's method with respect to complexity.\n  In this paper, we resolve this discrepancy by introducing a hybrid of the\nDescartes method and Newton iteration, denoted ANEWDSC, which is simpler than\nPan's method, but achieves a run-time comparable to it. Our algorithm computes\nisolating intervals for the real roots of any real square-free polynomial,\ngiven by an oracle that provides arbitrary good approximations of the\npolynomial's coefficients. ANEWDSC can also be used to only isolate the roots\nin a given interval and to refine the isolating intervals to an arbitrary small\nsize; it achieves near optimal complexity for the latter task."
},{
    "category": "cs.MS", 
    "doi": "10.1007/s10107-014-0827-4", 
    "link": "http://arxiv.org/pdf/1309.5479v1", 
    "title": "Higher-order Reverse Automatic Differentiation with emphasis on the   third-order", 
    "arxiv-id": "1309.5479v1", 
    "author": "Artur L. Gower", 
    "publish": "2013-09-21T14:00:40Z", 
    "summary": "It is commonly assumed that calculating third order information is too\nexpensive for most applications. But we show that the directional derivative of\nthe Hessian ($D^3f(x)\\cdot d$) can be calculated at a cost proportional to that\nof a state-of-the-art method for calculating the Hessian matrix. We do this by\nfirst presenting a simple procedure for designing high order reverse methods\nand applying it to deduce several methods including a reverse method that\ncalculates $D^3f(x)\\cdot d$. We have implemented this method taking into\naccount symmetry and sparsity, and successfully calculated this derivative for\nfunctions with a million variables. These results indicate that the use of\nthird order information in a general nonlinear solver, such as Halley-Chebyshev\nmethods, could be a practical alternative to Newton's method."
},{
    "category": "hep-ph", 
    "doi": "10.1016/j.cpc.2014.01.017", 
    "link": "http://arxiv.org/pdf/1309.7287v2", 
    "title": "Finding Linear Dependencies in Integration-By-Parts Equations: A Monte   Carlo Approach", 
    "arxiv-id": "1309.7287v2", 
    "author": "Philipp Kant", 
    "publish": "2013-09-27T16:23:42Z", 
    "summary": "The reduction of a large number of scalar integrals to a small set of master\nintegrals via Laporta's algorithm is common practice in multi-loop\ncalculations. It is also a major bottleneck in terms of running time and memory\nconsumption. It involves solving a large set of linear equations where many of\nthe equations are linearly dependent. We propose a simple algorithm that\neliminates all linearly dependent equations from a given system, reducing the\ntime and space requirements of a subsequent run of Laporta's algorithm."
},{
    "category": "math.OC", 
    "doi": "10.1016/j.cpc.2014.01.017", 
    "link": "http://arxiv.org/pdf/1311.2376v3", 
    "title": "Exact Solutions in Structured Low-Rank Approximation", 
    "arxiv-id": "1311.2376v3", 
    "author": "Bernd Sturmfels", 
    "publish": "2013-11-11T08:22:26Z", 
    "summary": "Structured low-rank approximation is the problem of minimizing a weighted\nFrobenius distance to a given matrix among all matrices of fixed rank in a\nlinear space of matrices. We study exact solutions to this problem by way of\ncomputational algebraic geometry. A particular focus lies on Hankel matrices,\nSylvester matrices and generic linear spaces."
},{
    "category": "cs.DS", 
    "doi": "10.1016/j.cpc.2014.01.017", 
    "link": "http://arxiv.org/pdf/1311.3731v1", 
    "title": "Chapter 10: Algebraic Algorithms", 
    "arxiv-id": "1311.3731v1", 
    "author": "Elias P. Tsigaridas", 
    "publish": "2013-11-15T05:50:38Z", 
    "summary": "Our Chapter in the upcoming Volume I: Computer Science and Software\nEngineering of Computing Handbook (Third edition), Allen Tucker, Teo Gonzales\nand Jorge L. Diaz-Herrera, editors, covers Algebraic Algorithms, both symbolic\nand numerical, for matrix computations and root-finding for polynomials and\nsystems of polynomials equations. We cover part of these large subjects and\ninclude basic bibliography for further study. To meet space limitation we cite\nbooks, surveys, and comprehensive articles with pointers to further references,\nrather than including all the original technical papers."
},{
    "category": "cs.IT", 
    "doi": "10.1016/j.cpc.2014.01.017", 
    "link": "http://arxiv.org/pdf/1402.0643v2", 
    "title": "Faster Algorithms for Multivariate Interpolation with Multiplicities and   Simultaneous Polynomial Approximations", 
    "arxiv-id": "1402.0643v2", 
    "author": "Gilles Villard", 
    "publish": "2014-02-04T07:23:14Z", 
    "summary": "The interpolation step in the Guruswami-Sudan algorithm is a bivariate\ninterpolation problem with multiplicities commonly solved in the literature\nusing either structured linear algebra or basis reduction of polynomial\nlattices. This problem has been extended to three or more variables; for this\ngeneralization, all fast algorithms proposed so far rely on the lattice\napproach. In this paper, we reduce this multivariate interpolation problem to a\nproblem of simultaneous polynomial approximations, which we solve using fast\nstructured linear algebra. This improves the best known complexity bounds for\nthe interpolation step of the list-decoding of Reed-Solomon codes,\nParvaresh-Vardy codes, and folded Reed-Solomon codes. In particular, for\nReed-Solomon list-decoding with re-encoding, our approach has complexity\n$\\mathcal{O}\\tilde{~}(\\ell^{\\omega-1}m^2(n-k))$, where $\\ell,m,n,k$ are the\nlist size, the multiplicity, the number of sample points and the dimension of\nthe code, and $\\omega$ is the exponent of linear algebra; this accelerates the\npreviously fastest known algorithm by a factor of $\\ell / m$."
},{
    "category": "cs.SC", 
    "doi": "10.1134/S0361768813030031", 
    "link": "http://arxiv.org/pdf/1402.6635v1", 
    "title": "Tensor computations in computer algebra systems", 
    "arxiv-id": "1402.6635v1", 
    "author": "L. A. Sevastyanov", 
    "publish": "2014-02-22T15:47:58Z", 
    "summary": "This paper considers three types of tensor computations. On their basis, we\nattempt to formulate criteria that must be satisfied by a computer algebra\nsystem dealing with tensors. We briefly overview the current state of tensor\ncomputations in different computer algebra systems. The tensor computations are\nillustrated with appropriate examples implemented in specific systems: Cadabra\nand Maxima."
},{
    "category": "cs.CC", 
    "doi": "10.1134/S0361768813030031", 
    "link": "http://arxiv.org/pdf/1402.6658v1", 
    "title": "Computing discrete logarithms in subfields of residue class rings", 
    "arxiv-id": "1402.6658v1", 
    "author": "Anand Kumar Narayanan", 
    "publish": "2014-02-26T19:40:38Z", 
    "summary": "Recent breakthrough methods \\cite{gggz,joux,bgjt} on computing discrete\nlogarithms in small characteristic finite fields share an interesting feature\nin common with the earlier medium prime function field sieve method \\cite{jl}.\nTo solve discrete logarithms in a finite extension of a finite field $\\F$, a\npolynomial $h(x) \\in \\F[x]$ of a special form is constructed with an\nirreducible factor $g(x) \\in \\F[x]$ of the desired degree. The special form of\n$h(x)$ is then exploited in generating multiplicative relations that hold in\nthe residue class ring $\\F[x]/h(x)\\F[x]$ hence also in the target residue class\nfield $\\F[x]/g(x)\\F[x]$. An interesting question in this context and addressed\nin this paper is: when and how does a set of relations on the residue class\nring determine the discrete logarithms in the finite fields contained in it? We\ngive necessary and sufficient conditions for a set of relations on the residue\nclass ring to determine discrete logarithms in the finite fields contained in\nit. We also present efficient algorithms to derive discrete logarithms from the\nrelations when the conditions are met. The derived necessary conditions allow\nus to clearly identify structural obstructions intrinsic to the special\npolynomial $h(x)$ in each of the aforementioned methods, and propose\nmodifications to the selection of $h(x)$ so as to avoid obstructions."
},{
    "category": "cs.SC", 
    "doi": "10.1134/S0361768813030031", 
    "link": "http://arxiv.org/pdf/1404.0002v1", 
    "title": "Factoring Differential Operators in n Variables", 
    "arxiv-id": "1404.0002v1", 
    "author": "Viktor Levandovskyy", 
    "publish": "2014-03-31T13:34:19Z", 
    "summary": "In this paper, we present a new algorithm and an experimental implementation\nfor factoring elements in the polynomial n'th Weyl algebra, the polynomial n'th\nshift algebra, and ZZ^n-graded polynomials in the n'th q-Weyl algebra.\n  The most unexpected result is that this noncommutative problem of factoring\npartial differential operators can be approached effectively by reducing it to\nthe problem of solving systems of polynomial equations over a commutative ring.\nIn the case where a given polynomial is ZZ^n-graded, we can reduce the problem\ncompletely to factoring an element in a commutative multivariate polynomial\nring.\n  The implementation in Singular is effective on a broad range of polynomials\nand increases the ability of computer algebra systems to address this important\nproblem. We compare the performance and output of our algorithm with other\nimplementations in commodity computer algebra systems on nontrivial examples."
},{
    "category": "cs.LG", 
    "doi": "10.1134/S0361768813030031", 
    "link": "http://arxiv.org/pdf/1404.7456v1", 
    "title": "Automatic Differentiation of Algorithms for Machine Learning", 
    "arxiv-id": "1404.7456v1", 
    "author": "Barak A. Pearlmutter", 
    "publish": "2014-04-28T17:19:25Z", 
    "summary": "Automatic differentiation---the mechanical transformation of numeric computer\nprograms to calculate derivatives efficiently and accurately---dates to the\norigin of the computer age. Reverse mode automatic differentiation both\nantedates and generalizes the method of backwards propagation of errors used in\nmachine learning. Despite this, practitioners in a variety of fields, including\nmachine learning, have been little influenced by automatic differentiation, and\nmake scant use of available tools. Here we review the technique of automatic\ndifferentiation, describe its two main modes, and explain how it can benefit\nmachine learning practitioners. To reach the widest possible audience our\ntreatment assumes only elementary differential calculus, and does not assume\nany knowledge of linear algebra."
},{
    "category": "cs.IT", 
    "doi": "10.1134/S0361768813030031", 
    "link": "http://arxiv.org/pdf/1406.0053v1", 
    "title": "Fast K\u00f6tter-Nielsen-H\u00f8holdt Interpolation in the Guruswami-Sudan   Algorithm", 
    "arxiv-id": "1406.0053v1", 
    "author": "Johan S. R. Nielsen", 
    "publish": "2014-05-31T07:57:56Z", 
    "summary": "The K\\\"otter-Nielsen-H{\\o}holdt algorithm is a popular way to construct the\nbivariate interpolation polynomial in the Guruswami-Sudan decoding algorithm\nfor Reed-Solomon codes. In this paper, we show how one can use Divide & Conquer\ntechniques to provide an asymptotic speed-up of the algorithm, rendering its\ncomplexity quasi-linear in n. Several of our observations can also provide a\npractical speed-up to the classical version of the algorithm."
},{
    "category": "hep-ph", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1406.4513v2", 
    "title": "A novel approach to integration by parts reduction", 
    "arxiv-id": "1406.4513v2", 
    "author": "Robert M. Schabinger", 
    "publish": "2014-06-17T20:00:24Z", 
    "summary": "Integration by parts reduction is a standard component of most modern\nmulti-loop calculations in quantum field theory. We present a novel strategy\nconstructed to overcome the limitations of currently available reduction\nprograms based on Laporta's algorithm. The key idea is to construct algebraic\nidentities from numerical samples obtained from reductions over finite fields.\nWe expect the method to be highly amenable to parallelization, show a low\nmemory footprint during the reduction step, and allow for significantly better\nrun-times."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1406.4600v1", 
    "title": "Gr\u00f6bner Bases for Linearized Polynomials", 
    "arxiv-id": "1406.4600v1", 
    "author": "Anna-Lena Trautmann", 
    "publish": "2014-06-18T05:25:46Z", 
    "summary": "In this work we develop the theory of Gr\\\"obner bases for modules over the\nring of univariate linearized polynomials with coefficients from a finite\nfield."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1408.2721v1", 
    "title": "Certifying solutions to overdetermined and singular polynomial systems   over Q", 
    "arxiv-id": "1408.2721v1", 
    "author": "Agnes Szanto", 
    "publish": "2014-08-12T14:18:37Z", 
    "summary": "This paper is concerned with certifying that a given point is near an exact\nroot of an overdetermined or singular polynomial system with rational\ncoefficients. The difficulty lies in the fact that consistency of\noverdetermined systems is not a continuous property. Our certification is based\non hybrid symbolic-numeric methods to compute the exact \"rational univariate\nrepresentation\" (RUR) of a component of the input system from approximate\nroots. For overdetermined polynomial systems with simple roots, we compute an\ninitial RUR from approximate roots. The accuracy of the RUR is increased via\nNewton iterations until the exact RUR is found, which we certify using exact\narithmetic. Since the RUR is well-constrained, we can use it to certify the\ngiven approximate roots using alpha-theory. To certify isolated singular roots,\nwe use a determinantal form of the \"isosingular deflation\", which adds new\npolynomials to the original system without introducing new variables. The\nresulting polynomial system is overdetermined, but the roots are now simple,\nthereby reducing the problem to the overdetermined case. We prove that our\nalgorithms have complexity that are polynomial in the input plus the output\nsize upon successful convergence, and we use worst case upper bounds for\ntermination when our iteration does not converge to an exact RUR. Examples are\nincluded to demonstrate the approach."
},{
    "category": "math.AG", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1409.1534v1", 
    "title": "Algorithms in Real Algebraic Geometry: A Survey", 
    "arxiv-id": "1409.1534v1", 
    "author": "Saugata Basu", 
    "publish": "2014-09-04T19:00:00Z", 
    "summary": "We survey both old and new developments in the theory of algorithms in real\nalgebraic geometry -- starting from effective quantifier elimination in the\nfirst order theory of reals due to Tarski and Seidenberg, to more recent\nalgorithms for computing topological invariants of semi-algebraic sets. We\nemphasize throughout the complexity aspects of these algorithms and also\ndiscuss the computational hardness of the underlying problems. We also describe\nsome recent results linking the computational hardness of decision problems in\nthe first order theory of the reals, with that of computing certain topological\ninvariants of semi-algebraic sets. Even though we mostly concentrate on exact\nalgorithms, we also discuss some numerical approaches involving semi-definite\nprogramming that have gained popularity in recent times."
},{
    "category": "math.NA", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1409.4802v3", 
    "title": "On Solving Pentadiagonal Linear Systems via Transformations", 
    "arxiv-id": "1409.4802v3", 
    "author": "A. A. Karawia", 
    "publish": "2014-09-16T20:59:27Z", 
    "summary": "Many authors studied numeric algorithms for solving the linear systems of the\npentadiagonal type. The well-known Fast Pentadiagonal System Solver algorithm\nis an example of such algorithms. The current article are described new numeric\nand symbolic algorithms for solving pentadiagonal linear systems via\ntransformations. New algorithms are natural generalization of the work\npresented in [Moawwad El- Mikkawy and Faiz Atlan, Algorithms for Solving Linear\nSystems of Equations of Tridiagonal Type via Transformations, Applied\nMathematics, 2014, 5, 413-422]. The symbolic algorithms remove the cases where\nthe numeric algorithms fail. The computational cost of our algorithms is given.\nSome examples are given in order to illustrate the effectiveness of the\nproposed algorithms. All of the experiments are performed on a computer with\nthe aid of programs written in MATLAB."
},{
    "category": "cs.NA", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1501.00160v3", 
    "title": "Accurate solution of near-colliding Prony systems via decimation and   homotopy continuation", 
    "arxiv-id": "1501.00160v3", 
    "author": "Dmitry Batenkov", 
    "publish": "2014-12-31T15:56:37Z", 
    "summary": "We consider polynomial systems of Prony type, appearing in many areas of\nmathematics. Their robust numerical solution is considered to be difficult,\nespecially in \"near-colliding\" situations. We consider a case when the\nstructure of the system is a-priori fixed. We transform the nonlinear part of\nthe Prony system into a Hankel-type polynomial system. Combining this\nrepresentation with a recently discovered \"decimation\" technique, we present an\nalgorithm which applies homotopy continuation to an appropriately chosen\nHankel-type system as above. In this way, we are able to solve for the\nnonlinear variables of the original system with high accuracy when the data is\nperturbed."
},{
    "category": "math.AC", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1501.04543v1", 
    "title": "A test for monomial containment", 
    "arxiv-id": "1501.04543v1", 
    "author": "Thomas Kremer", 
    "publish": "2015-01-19T16:35:34Z", 
    "summary": "We present an algorithm to decide whether a given ideal in the polynomial\nring contains a monomial without using Gr\\\"obner bases, factorization or\nsub-resultant computations."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1501.05296v3", 
    "title": "Output-sensitive algorithms for sumset and sparse polynomial   multiplication", 
    "arxiv-id": "1501.05296v3", 
    "author": "Daniel S. Roche", 
    "publish": "2015-01-21T04:43:58Z", 
    "summary": "We present randomized algorithms to compute the sumset (Minkowski sum) of two\ninteger sets, and to multiply two univariate integer polynomials given by\nsparse representations. Our algorithm for sumset has cost softly linear in the\ncombined size of the inputs and output. This is used as part of our sparse\nmultiplication algorithm, whose cost is softly linear in the combined size of\nthe inputs, output, and the sumset of the supports of the inputs. As a\nsubroutine, we present a new method for computing the coefficients of a sparse\npolynomial, given a set containing its support. Our multiplication algorithm\nextends to multivariate Laurent polynomials over finite fields and rational\nnumbers. Our techniques are based on sparse interpolation algorithms and\nresults from analytic number theory."
},{
    "category": "math.CO", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1501.07773v1", 
    "title": "Polyhedral Omega: A New Algorithm for Solving Linear Diophantine Systems", 
    "arxiv-id": "1501.07773v1", 
    "author": "Zafeirakis Zafeirakopoulos", 
    "publish": "2015-01-30T13:50:31Z", 
    "summary": "Polyhedral Omega is a new algorithm for solving linear Diophantine systems\n(LDS), i.e., for computing a multivariate rational function representation of\nthe set of all non-negative integer solutions to a system of linear equations\nand inequalities. Polyhedral Omega combines methods from partition analysis\nwith methods from polyhedral geometry. In particular, we combine MacMahon's\niterative approach based on the Omega operator and explicit formulas for its\nevaluation with geometric tools such as Brion decompositions and Barvinok's\nshort rational function representations. In this way, we connect two recent\nbranches of research that have so far remained separate, unified by the concept\nof symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega\nis significantly faster than previous solvers based on partition analysis and\nit is competitive with state-of-the-art LDS solvers based on geometric methods.\nMost importantly, this synthesis of ideas makes Polyhedral Omega the simplest\nalgorithm for solving linear Diophantine systems available to date. Moreover,\nwe provide an illustrated geometric interpretation of partition analysis, with\nthe aim of making ideas from both areas accessible to readers from a wide range\nof backgrounds."
},{
    "category": "cs.NA", 
    "doi": "10.1016/j.physletb.2015.03.029", 
    "link": "http://arxiv.org/pdf/1501.07774v1", 
    "title": "Near Optimal Subdivision Algorithms for Real Root Isolation", 
    "arxiv-id": "1501.07774v1", 
    "author": "Prashant Batra", 
    "publish": "2015-01-30T13:53:37Z", 
    "summary": "We describe a subroutine that improves the running time of any subdivision\nalgorithm for real root isolation. The subroutine first detects clusters of\nroots using a result of Ostrowski, and then uses Newton iteration to converge\nto them. Near a cluster, we switch to subdivision, and proceed recursively. The\nsubroutine has the advantage that it is independent of the predicates used to\nterminate the subdivision. This gives us an alternative and simpler approach to\nrecent developments of Sagraloff (2012) and Sagraloff-Mehlhorn (2013), assuming\nexact arithmetic.\n  The subdivision tree size of our algorithm using predicates based on\nDescartes's rule of signs is bounded by $O(n\\log n)$, which is better by\n$O(n\\log L)$ compared to known results. Our analysis differs in two key\naspects. First, we use the general technique of continuous amortization from\nBurr-Krahmer-Yap (2009), and second, we use the geometry of clusters of roots\ninstead of the Davenport-Mahler bound. The analysis naturally extends to other\npredicates."
},{
    "category": "cs.AI", 
    "doi": "10.4204/EPTCS.29.5", 
    "link": "http://arxiv.org/pdf/1007.1024v1", 
    "title": "Model Counting in Product Configuration", 
    "arxiv-id": "1007.1024v1", 
    "author": "Wolfgang K\u00fcchlin", 
    "publish": "2010-07-07T00:13:11Z", 
    "summary": "We describe how to use propositional model counting for a quantitative\nanalysis of product configuration data. Our approach computes valuable meta\ninformation such as the total number of valid configurations or the relative\nfrequency of components. This information can be used to assess the severity of\ndocumentation errors or to measure documentation quality. As an application\nexample we show how we apply these methods to product documentation formulas of\nthe Mercedes-Benz line of vehicles. In order to process these large formulas we\ndeveloped and implemented a new model counter for non-CNF formulas. Our model\ncounter can process formulas, whose CNF representations could not be processed\nup till now."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.26.16", 
    "link": "http://arxiv.org/pdf/1007.3794v1", 
    "title": "Open Graphs and Computational Reasoning", 
    "arxiv-id": "1007.3794v1", 
    "author": "Aleks Kissinger", 
    "publish": "2010-07-22T03:31:39Z", 
    "summary": "We present a form of algebraic reasoning for computational objects which are\nexpressed as graphs. Edges describe the flow of data between primitive\noperations which are represented by vertices. These graphs have an interface\nmade of half-edges (edges which are drawn with an unconnected end) and enjoy\nrich compositional principles by connecting graphs along these half-edges. In\nparticular, this allows equations and rewrite rules to be specified between\ngraphs. Particular computational models can then be encoded as an axiomatic set\nof such rules. Further rules can be derived graphically and rewriting can be\nused to simulate the dynamics of a computational system, e.g. evaluating a\nprogram on an input. Examples of models which can be formalised in this way\ninclude traditional electronic circuits as well as recent categorical accounts\nof quantum information."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.camwa.2007.07.014", 
    "link": "http://arxiv.org/pdf/1104.1690v1", 
    "title": "Effective partitioning method for computing weighted Moore-Penrose   inverse", 
    "arxiv-id": "1104.1690v1", 
    "author": "M. B", 
    "publish": "2011-04-09T11:31:06Z", 
    "summary": "We introduce a method and an algorithm for computing the weighted\nMoore-Penrose inverse of multiple-variable polynomial matrix and the related\nalgorithm which is appropriated for sparse polynomial matrices. These methods\nand algorithms are generalizations of algorithms developed in [M.B. Tasic, P.S.\nStanimirovic, M.D. Petkovic, Symbolic computation of weighted Moore-Penrose\ninverse using partitioning method, Appl. Math. Comput. 189 (2007) 615-640] to\nmultiple-variable rational and polynomial matrices and improvements of these\nalgorithms on sparse matrices. Also, these methods are generalizations of the\npartitioning method for computing the Moore-Penrose inverse of rational and\npolynomial matrices introduced in [P.S. Stanimirovic, M.B. Tasic, Partitioning\nmethod for rational and polynomial matrices, Appl. Math. Comput. 155 (2004)\n137-163; M.D. Petkovic, P.S. Stanimirovic, Symbolic computation of the\nMoore-Penrose inverse using partitioning method, Internat. J. Comput. Math. 82\n(2005) 355-367] to the case of weighted Moore-Penrose inverse. Algorithms are\nimplemented in the symbolic computational package MATHEMATICA."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.amc.2006.11.114", 
    "link": "http://arxiv.org/pdf/1104.1696v1", 
    "title": "Symbolic computation of weighted Moore-Penrose inverse using   partitioning method", 
    "arxiv-id": "1104.1696v1", 
    "author": "M. D", 
    "publish": "2011-04-09T11:54:31Z", 
    "summary": "We propose a method and algorithm for computing the weighted Moore-Penrose\ninverse of one-variable rational matrices. Continuing this idea, we develop an\nalgorithm for computing the weighted Moore-Penrose inverse of one-variable\npolynomial matrix. These methods and algorithms are generalizations of the\nmethod for computing the weighted Moore-Penrose inverse for constant matrices,\noriginated in Wang and Chen [G.R. Wang, Y.L. Chen, A recursive algorithm for\ncomputing the weighted Moore-Penrose inverse AMN, J. Comput. Math. 4 (1986)\n74-85], and the partitioning method for computing the Moore-Penrose inverse of\nrational and polynomial matrices introduced in Stanimirovic and Tasic [P.S.\nStanimirovic, M.B. Tasic, Partitioning method for rational and polynomial\nmatrices, Appl. Math. Comput. 155 (2004) 137-163]. Algorithms are implemented\nin the symbolic computational package MATHEMATICA."
},{
    "category": "cs.SC", 
    "doi": "10.1080/00207160701582077", 
    "link": "http://arxiv.org/pdf/1104.1697v1", 
    "title": "Computing generalized inverses using LU factorization of matrix product", 
    "arxiv-id": "1104.1697v1", 
    "author": "M. B", 
    "publish": "2011-04-09T12:03:07Z", 
    "summary": "An algorithm for computing {2, 3}, {2, 4}, {1, 2, 3}, {1, 2, 4} -inverses and\nthe Moore-Penrose inverse of a given rational matrix A is established. Classes\nA(2, 3)s and A(2, 4)s are characterized in terms of matrix products (R*A)+R*\nand T*(AT*)+, where R and T are rational matrices with appropriate dimensions\nand corresponding rank. The proposed algorithm is based on these general\nrepresentations and the Cholesky factorization of symmetric positive matrices.\nThe algorithm is implemented in programming languages MATHEMATICA and DELPHI,\nand illustrated via examples. Numerical results of the algorithm, corresponding\nto the Moore-Penrose inverse, are compared with corresponding results obtained\nby several known methods for computing the Moore-Penrose inverse."
},{
    "category": "cs.SC", 
    "doi": "10.1080/00207160701582077", 
    "link": "http://arxiv.org/pdf/1104.4025v1", 
    "title": "Methods in Mathematica for Solving Ordinary Differential Equations", 
    "arxiv-id": "1104.4025v1", 
    "author": "Devendra Kapadia", 
    "publish": "2011-04-20T13:49:04Z", 
    "summary": "An overview of the solution methods for ordinary differential equations in\nthe Mathematica function DSolve is presented."
},{
    "category": "cs.SC", 
    "doi": "10.1080/00207160701582077", 
    "link": "http://arxiv.org/pdf/1104.4026v1", 
    "title": "Symbolic Computation of Recursion Operators for Nonlinear   Differential-Difference equations", 
    "arxiv-id": "1104.4026v1", 
    "author": "Willy Hereman", 
    "publish": "2011-04-20T13:58:42Z", 
    "summary": "An algorithm for the symbolic computation of recursion operators for systems\nof nonlinear differential-difference equations (DDEs) is presented. Recursion\noperators allow one to generate an infinite sequence of generalized symmetries.\nThe existence of a recursion operator therefore guarantees the complete\nintegrability of the DDE. The algo-rithm is based in part on the concept of\ndilation invariance and uses our earlier algorithms for the symbolic\ncomputation of conservation laws and generalized symmetries.\n  The algorithm has been applied to a number of well-known DDEs, including the\nKac-van Moerbeke (Volterra), Toda, and Ablowitz-Ladik lattices, for which\nrecursion opera-tors are shown. The algorithm has been implemented in\nMathematica, a leading com-puter algebra system. The package\nDDERecursionOperator.m is briefly discussed."
},{
    "category": "cs.SC", 
    "doi": "10.1080/00207160701582077", 
    "link": "http://arxiv.org/pdf/1104.4954v1", 
    "title": "On the Complexity of Solving a Bivariate Polynomial System", 
    "arxiv-id": "1104.4954v1", 
    "author": "Michael Sagraloff", 
    "publish": "2011-04-26T15:57:43Z", 
    "summary": "We study the complexity of computing the real solutions of a bivariate\npolynomial system using the recently proposed algorithm BISOLVE. BISOLVE is a\nclassical elimination method which first projects the solutions of a system\nonto the $x$- and $y$-axes and, then, selects the actual solutions from the so\ninduced candidate set. However, unlike similar algorithms, BISOLVE requires no\ngenericity assumption on the input nor it needs any change of the coordinate\nsystem. Furthermore, extensive benchmarks from \\cite{bes-bisolve-2011} confirm\nthat the algorithm outperforms state of the art approaches by a large factor.\nIn this work, we show that, for two polynomials $f,g\\in\\mathbb{Z}[x,y]$ of\ntotal degree at most $n$ with integer coefficients bounded by $2^\\tau$, BISOLVE\ncomputes isolating boxes for all real solutions of the system $f=g=0$ using\n$\\Otilde(n^8\\tau^{2})$ bit operations, thereby improving the previous record\nbound by a factor of at least $n^{2}$."
},{
    "category": "math.GR", 
    "doi": "10.1515/gcc-2012-0006", 
    "link": "http://arxiv.org/pdf/1104.5097v2", 
    "title": "Search and test algorithms for Triple Product Property triples", 
    "arxiv-id": "1104.5097v2", 
    "author": "Sandeep Murthy", 
    "publish": "2011-04-27T09:36:31Z", 
    "summary": "In 2003 COHN and UMANS introduced a group-theoretic approach to fast matrix\nmultiplication. This involves finding large subsets of a group $G$ satisfying\nthe Triple Product Property (TPP) as a means to bound the exponent $\\omega$ of\nmatrix multiplication. We present two new characterizations of the TPP, which\nare useful for theoretical considerations and for TPP test algorithms. With\nthis we describe all known TPP tests and implement them in GAP algorithms. We\nalso compare their runtime. Furthermore we show that the search for subgroup\nTPP triples of nontrivial size in a nonabelian group can be restricted to the\nset of all nonnormal subgroups of that group. Finally we describe brute-force\nsearch algorithms for maximal subgroup and subset TPP triples. In addition we\npresent the results of the subset brute-force search for all groups of order\nless than 25 and selected results of the subgroup brute-force search for\n2-groups, $SL(n,q)$ and $PSL(2,q)$."
},{
    "category": "cs.DC", 
    "doi": "10.1515/gcc-2012-0006", 
    "link": "http://arxiv.org/pdf/1109.0545v1", 
    "title": "Quality Up in Polynomial Homotopy Continuation by Multithreaded Path   Tracking", 
    "arxiv-id": "1109.0545v1", 
    "author": "Genady Yoffe", 
    "publish": "2011-09-02T20:06:55Z", 
    "summary": "Speedup measures how much faster we can solve the same problem using many\ncores. If we can afford to keep the execution time fixed, then quality up\nmeasures how much better the solution will be computed using many cores. In\nthis paper we describe our multithreaded implementation to track one solution\npath defined by a polynomial homotopy. Limiting quality to accuracy and\nconfusing accuracy with precision, we strive to offset the cost of\nmultiprecision arithmetic running multithreaded code on many cores."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1515/bpasts-2017-0003", 
    "link": "http://arxiv.org/pdf/1109.4244v2", 
    "title": "Symbolic integration with respect to the Haar measure on the unitary   group", 
    "arxiv-id": "1109.4244v2", 
    "author": "Jaros\u0142aw Adam Miszczak", 
    "publish": "2011-09-20T09:07:33Z", 
    "summary": "We present IntU package for Mathematica computer algebra system. The\npresented package performs a symbolic integration of polynomial functions over\nthe unitary group with respect to unique normalized Haar measure. We describe a\nnumber of special cases which can be used to optimize the calculation speed for\nsome classes of integrals. We also provide some examples of usage of the\npresented package."
},{
    "category": "cs.MS", 
    "doi": "10.1007/978-3-642-31374-5_14", 
    "link": "http://arxiv.org/pdf/1204.0053v2", 
    "title": "Theory Presentation Combinators", 
    "arxiv-id": "1204.0053v2", 
    "author": "Russell O'Connor", 
    "publish": "2012-03-31T00:56:44Z", 
    "summary": "We motivate and give semantics to theory presentation combinators as the\nfoundational building blocks for a scalable library of theories. The key\nobservation is that the category of contexts and fibered categories are the\nideal theoretical tools for this purpose."
},{
    "category": "cs.DS", 
    "doi": "10.1007/978-3-642-31374-5_14", 
    "link": "http://arxiv.org/pdf/1204.1111v2", 
    "title": "Faster Algorithms for Rectangular Matrix Multiplication", 
    "arxiv-id": "1204.1111v2", 
    "author": "Fran\u00e7ois Le Gall", 
    "publish": "2012-04-05T02:14:37Z", 
    "summary": "Let {\\alpha} be the maximal value such that the product of an n x n^{\\alpha}\nmatrix by an n^{\\alpha} x n matrix can be computed with n^{2+o(1)} arithmetic\noperations. In this paper we show that \\alpha>0.30298, which improves the\nprevious record \\alpha>0.29462 by Coppersmith (Journal of Complexity, 1997).\nMore generally, we construct a new algorithm for multiplying an n x n^k matrix\nby an n^k x n matrix, for any value k\\neq 1. The complexity of this algorithm\nis better than all known algorithms for rectangular matrix multiplication. In\nthe case of square matrix multiplication (i.e., for k=1), we recover exactly\nthe complexity of the algorithm by Coppersmith and Winograd (Journal of\nSymbolic Computation, 1990).\n  These new upper bounds can be used to improve the time complexity of several\nknown algorithms that rely on rectangular matrix multiplication. For example,\nwe directly obtain a O(n^{2.5302})-time algorithm for the all-pairs shortest\npaths problem over directed graphs with small integer weights, improving over\nthe O(n^{2.575})-time algorithm by Zwick (JACM 2002), and also improve the time\ncomplexity of sparse square matrix multiplication."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-31374-5_14", 
    "link": "http://arxiv.org/pdf/1204.1298v1", 
    "title": "A polynomial time algorithm for computing the HNF of a module over the   integers of a number field", 
    "arxiv-id": "1204.1298v1", 
    "author": "Claus Fieker", 
    "publish": "2012-04-05T18:25:59Z", 
    "summary": "We present a variation of the modular algorithm for computing the Hermite\nNormal Form of an $\\OK$-module presented by Cohen, where $\\OK$ is the ring of\nintegers of a number field K. The modular strategy was conjectured to run in\npolynomial time by Cohen, but so far, no such proof was available in the\nliterature. In this paper, we provide a new method to prevent the coefficient\nexplosion and we rigorously assess its complexity with respect to the size of\nthe input and the invariants of the field K."
},{
    "category": "cs.SC", 
    "doi": "10.1007/978-3-642-31374-5_14", 
    "link": "http://arxiv.org/pdf/1204.4347v1", 
    "title": "Change-Of-Bases Abstractions for Non-Linear Systems", 
    "arxiv-id": "1204.4347v1", 
    "author": "Sriram Sankaranarayanan", 
    "publish": "2012-04-19T13:40:45Z", 
    "summary": "We present abstraction techniques that transform a given non-linear dynamical\nsystem into a linear system or an algebraic system described by polynomials of\nbounded degree, such that, invariant properties of the resulting abstraction\ncan be used to infer invariants for the original system. The abstraction\ntechniques rely on a change-of-basis transformation that associates each state\nvariable of the abstract system with a function involving the state variables\nof the original system. We present conditions under which a given change of\nbasis transformation for a non-linear system can define an abstraction.\nFurthermore, the techniques developed here apply to continuous systems defined\nby Ordinary Differential Equations (ODEs), discrete systems defined by\ntransition systems and hybrid systems that combine continuous as well as\ndiscrete subsystems. The techniques presented here allow us to discover, given\na non-linear system, if a change of bases transformation involving\ndegree-bounded polynomials yielding an algebraic abstraction exists. If so, our\ntechnique yields the resulting abstract system, as well. This approach is\nfurther extended to search for a change of bases transformation that abstracts\na given non-linear system into a system of linear differential inclusions. Our\ntechniques enable the use of analysis techniques for linear systems to infer\ninvariants for non-linear systems. We present preliminary evidence of the\npractical feasibility of our ideas using a prototype implementation."
},{
    "category": "cs.SC", 
    "doi": "10.1016/j.cpc.2013.05.008", 
    "link": "http://arxiv.org/pdf/1207.7079v1", 
    "title": "Improving multivariate Horner schemes with Monte Carlo tree search", 
    "arxiv-id": "1207.7079v1", 
    "author": "H. J. van den Herik", 
    "publish": "2012-07-30T20:00:11Z", 
    "summary": "Optimizing the cost of evaluating a polynomial is a classic problem in\ncomputer science. For polynomials in one variable, Horner's method provides a\nscheme for producing a computationally efficient form. For multivariate\npolynomials it is possible to generalize Horner's method, but this leaves\nfreedom in the order of the variables. Traditionally, greedy schemes like\nmost-occurring variable first are used. This simple textbook algorithm has\ngiven remarkably efficient results. Finding better algorithms has proved\ndifficult. In trying to improve upon the greedy scheme we have implemented\nMonte Carlo tree search, a recent search method from the field of artificial\nintelligence. This results in better Horner schemes and reduces the cost of\nevaluating polynomials, sometimes by factors up to two."
},lol]