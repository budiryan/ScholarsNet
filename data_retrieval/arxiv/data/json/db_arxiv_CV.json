[{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/9810003v1", 
    "title": "A Linear Shift Invariant Multiscale Transform", 
    "arxiv-id": "cs/9810003v1", 
    "author": "Andreas Siebert", 
    "publish": "1998-10-02T03:34:38Z", 
    "summary": "This paper presents a multiscale decomposition algorithm. Unlike standard\nwavelet transforms, the proposed operator is both linear and shift invariant.\nThe central idea is to obtain shift invariance by averaging the aligned wavelet\ntransform projections over all circular shifts of the signal. It is shown how\nthe same transform can be obtained by a linear filter bank."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/9810017v1", 
    "title": "General Theory of Image Normalization", 
    "arxiv-id": "cs/9810017v1", 
    "author": "Stephen L. Adler", 
    "publish": "1998-10-19T20:46:16Z", 
    "summary": "We give a systematic, abstract formulation of the image normalization method\nas applied to a general group of image transformations, and then illustrate the\nabstract analysis by applying it to the hierarchy of viewing transformations of\na planar object."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/9908017v1", 
    "title": "A Differential Invariant for Zooming", 
    "arxiv-id": "cs/9908017v1", 
    "author": "Andreas Siebert", 
    "publish": "1999-08-26T17:18:49Z", 
    "summary": "This paper presents an invariant under scaling and linear brightness change.\nThe invariant is based on differentials and therefore is a local feature.\nRotationally invariant 2-d differential Gaussian operators up to third order\nare proposed for the implementation of the invariant. The performance is\nanalyzed by simulating a camera zoom-out."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/0001024v1", 
    "title": "A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images", 
    "arxiv-id": "cs/0001024v1", 
    "author": "L. Prasad", 
    "publish": "2000-01-25T16:09:37Z", 
    "summary": "We describe a simple, but efficient algorithm for the generation of dilated\ncontours from bilevel images. The initial part of the contour extraction is\nexplained to be a good candidate for parallel computer code generation. The\nremainder of the algorithm is of linear nature."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0003065v1", 
    "title": "Image Compression with Iterated Function Systems, Finite Automata and   Zerotrees: Grand Unification", 
    "arxiv-id": "cs/0003065v1", 
    "author": "Paul Fisher", 
    "publish": "2000-03-15T19:31:51Z", 
    "summary": "Fractal image compression, Culik's image compression and zerotree prediction\ncoding of wavelet image decomposition coefficients succeed only because typical\nimages being compressed possess a significant degree of self-similarity.\nBesides the common concept, these methods turn out to be even more tightly\nrelated, to the point of algorithmical reducibility of one technique to\nanother. The goal of the present paper is to demonstrate these relations.\n  The paper offers a plain-term interpretation of Culik's image compression, in\nregular image processing terms, without resorting to finite state machines and\nsimilar lofty language. The interpretation is shown to be algorithmically\nrelated to an IFS fractal image compression method: an IFS can be exactly\ntransformed into Culik's image code. Using this transformation, we will prove\nthat in a self-similar (part of an) image any zero wavelet coefficient is the\nroot of a zerotree, or its branch.\n  The paper discusses the zerotree coding of (wavelet/projection) coefficients\nas a common predictor/corrector, applied vertically through different layers of\na multiresolutional decomposition, rather than within the same view. This\ninterpretation leads to an insight into the evolution of image compression\ntechniques: from a causal single-layer prediction, to non-causal same-view\npredictions (wavelet decomposition among others) and to a causal cross-layer\nprediction (zero-trees, Culik's method)."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0003079v1", 
    "title": "Differential Invariants under Gamma Correction", 
    "arxiv-id": "cs/0003079v1", 
    "author": "Andreas Siebert", 
    "publish": "2000-03-26T23:18:43Z", 
    "summary": "This paper presents invariants under gamma correction and similarity\ntransformations. The invariants are local features based on differentials which\nare implemented using derivatives of the Gaussian. The use of the proposed\ninvariant representation is shown to yield improved correlation results in a\ntemplate matching scenario."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0004012v1", 
    "title": "Assisted Video Sequences Indexing : Motion Analysis Based on Interest   Points", 
    "arxiv-id": "cs/0004012v1", 
    "author": "Jean-Michel Jolion", 
    "publish": "2000-04-21T17:32:29Z", 
    "summary": "This work deals with content-based video indexing. Our viewpoint is\nsemi-automatic analysis of compressed video. We consider the possible\napplications of motion analysis and moving object detection : assisting moving\nobject indexing, summarising videos, and allowing image and motion queries. We\npropose an approach based on interest points. As first results, we test and\ncompare the stability of different types of interest point detectors in\ncompressed sequences."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0005001v1", 
    "title": "Robustness of Regional Matching Scheme over Global Matching Scheme", 
    "arxiv-id": "cs/0005001v1", 
    "author": "Naoyuki Tokuda", 
    "publish": "2000-05-03T08:49:28Z", 
    "summary": "The paper has established and verified the theory prevailing widely among\nimage and pattern recognition specialists that the bottom-up indirect regional\nmatching process is the more stable and the more robust than the global\nmatching process against concentrated types of noise represented by clutter,\noutlier or occlusion in the imagery. We have demonstrated this by analyzing the\neffect of concentrated noise on a typical decision making process of a\nsimplified two candidate voting model where our theorem establishes the lower\nbounds to a critical breakdown point of election (or decision) result by the\nbottom-up matching process are greater than the exact bound of the global\nmatching process implying that the former regional process is capable of\naccommodating a higher level of noise than the latter global process before the\nresult of decision overturns. We present a convincing experimental verification\nsupporting not only the theory by a white-black flag recognition problem in the\npresence of localized noise but also the validity of the conjecture by a facial\nrecognition problem that the theorem remains valid for other decision making\nprocesses involving an important dimension-reducing transform such as principal\ncomponent analysis or a Gabor transform."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0006001v1", 
    "title": "Boosting the Differences: A fast Bayesian classifier neural network", 
    "arxiv-id": "cs/0006001v1", 
    "author": "K. Babu Joseph", 
    "publish": "2000-05-31T23:37:48Z", 
    "summary": "A Bayesian classifier that up-weights the differences in the attribute values\nis discussed. Using four popular datasets from the UCI repository, some\ninteresting features of the network are illustrated. The network is suitable\nfor classification problems."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0006002v1", 
    "title": "Distorted English Alphabet Identification : An application of Difference   Boosting Algorithm", 
    "arxiv-id": "cs/0006002v1", 
    "author": "K. Babu Joseph", 
    "publish": "2000-05-31T23:52:31Z", 
    "summary": "The difference-boosting algorithm is used on letters dataset from the UCI\nrepository to classify distorted raster images of English alphabets. In\ncontrast to rather complex networks, the difference-boosting is found to\nproduce comparable or better classification efficiency on this complex problem."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0006047v1", 
    "title": "Geometric Morphology of Granular Materials", 
    "arxiv-id": "cs/0006047v1", 
    "author": "A. N. Skourikhine", 
    "publish": "2000-06-30T22:17:42Z", 
    "summary": "We present a new method to transform the spectral pixel information of a\nmicrograph into an affine geometric description, which allows us to analyze the\nmorphology of granular materials. We use spectral and pulse-coupled neural\nnetwork based segmentation techniques to generate blobs, and a newly developed\nalgorithm to extract dilated contours. A constrained Delaunay tesselation of\nthe contour points results in a triangular mesh. This mesh is the basic\ningredient of the Chodal Axis Transform, which provides a morphological\ndecomposition of shapes. Such decomposition allows for grain separation and the\nefficient computation of the statistical features of granular materials."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0208005v1", 
    "title": "Probabilistic Search for Object Segmentation and Recognition", 
    "arxiv-id": "cs/0208005v1", 
    "author": "Gerd Hirzinger", 
    "publish": "2002-08-05T10:57:09Z", 
    "summary": "The problem of searching for a model-based scene interpretation is analyzed\nwithin a probabilistic framework. Object models are formulated as generative\nmodels for range data of the scene. A new statistical criterion, the truncated\nobject probability, is introduced to infer an optimal sequence of object\nhypotheses to be evaluated for their match to the data. The truncated\nprobability is partly determined by prior knowledge of the objects and partly\nlearned from data. Some experiments on sequence quality and object segmentation\nand recognition from stereo data are presented. The article recovers classic\nconcepts from object recognition (grouping, geometric hashing, alignment) from\nthe probabilistic perspective and adds insight into the optimal ordering of\nobject hypotheses for evaluation. Moreover, it introduces point-relation\ndensities, a key component of the truncated probability, as statistical models\nof local surface shape."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0301001v1", 
    "title": "Least squares fitting of circles and lines", 
    "arxiv-id": "cs/0301001v1", 
    "author": "C. Lesort", 
    "publish": "2003-01-01T19:58:03Z", 
    "summary": "We study theoretical and computational aspects of the least squares fit (LSF)\nof circles and circular arcs. First we discuss the existence and uniqueness of\nLSF and various parametrization schemes. Then we evaluate several popular\ncircle fitting algorithms and propose a new one that surpasses the existing\nmethods in reliability. We also discuss and compare direct (algebraic) circle\nfits."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0303015v1", 
    "title": "Statistical efficiency of curve fitting algorithms", 
    "arxiv-id": "cs/0303015v1", 
    "author": "C. Lesort", 
    "publish": "2003-03-18T21:30:36Z", 
    "summary": "We study the problem of fitting parametrized curves to noisy data. Under\ncertain assumptions (known as Cartesian and radial functional models), we\nderive asymptotic expressions for the bias and the covariance matrix of the\nparameter estimates. We also extend Kanatani's version of the Cramer-Rao lower\nbound, which he proved for unbiased estimates only, to more general estimates\nthat include many popular algorithms (most notably, the orthogonal least\nsquares and algebraic fits). We then show that the gradient-weighted algebraic\nfit is statistically efficient and describe all other statistically efficient\nalgebraic fits."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307045v1", 
    "title": "Flexible Camera Calibration Using a New Analytical Radial Undistortion   Formula with Application to Mobile Robot Localization", 
    "arxiv-id": "cs/0307045v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-20T02:35:38Z", 
    "summary": "Most algorithms in 3D computer vision rely on the pinhole camera model\nbecause of its simplicity, whereas virtually all imaging devices introduce\ncertain amount of nonlinear distortion, where the radial distortion is the most\nsevere part. Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved. An application of the new radial distortion model is non-iterative\nyellow line alignment with a calibrated camera on ODIS, a robot built in our\nCSOIS."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307046v1", 
    "title": "A New Analytical Radial Distortion Model for Camera Calibration", 
    "arxiv-id": "cs/0307046v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-20T05:18:59Z", 
    "summary": "Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307047v1", 
    "title": "Rational Radial Distortion Models with Analytical Undistortion Formulae", 
    "arxiv-id": "cs/0307047v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-20T05:54:42Z", 
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nclass of rational radial distortion models with easy analytical undistortion\nformulae. Experimental results are presented to show that with this class of\nrational radial distortion models, satisfactory and comparable accuracy is\nachieved."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307051v1", 
    "title": "An Analytical Piecewise Radial Distortion Model for Precision Camera   Calibration", 
    "arxiv-id": "cs/0307051v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-21T16:30:11Z", 
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\npiecewise radial distortion model with easy analytical undistortion formula.\nThe motivation for seeking a piecewise radial distortion model is that, when a\ncamera is resulted in a low quality during manufacturing, the nonlinear radial\ndistortion can be complex. Using low order polynomials to approximate the\nradial distortion might not be precise enough. On the other hand, higher order\npolynomials suffer from the inverse problem. With the new piecewise radial\ndistortion function, more flexibility is obtained and the radial undistortion\ncan be performed analytically. Experimental results are presented to show that\nwith this new piecewise radial distortion model, better performance is achieved\nthan that using the single function. Furthermore, a comparable performance with\nthe conventional polynomial model using 2 coefficients can also be\naccomplished."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307072v1", 
    "title": "Camera Calibration: a USU Implementation", 
    "arxiv-id": "cs/0307072v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-31T19:33:48Z", 
    "summary": "The task of camera calibration is to estimate the intrinsic and extrinsic\nparameters of a camera model. Though there are some restricted techniques to\ninfer the 3-D information about the scene from uncalibrated cameras, effective\ncamera calibration procedures will open up the possibility of using a wide\nrange of existing algorithms for 3-D reconstruction and recognition.\n  The applications of camera calibration include vision-based metrology, robust\nvisual platooning and visual docking of mobile robots where the depth\ninformation is important."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0308003v1", 
    "title": "A Family of Simplified Geometric Distortion Models for Camera   Calibration", 
    "arxiv-id": "cs/0308003v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-08-02T01:39:38Z", 
    "summary": "The commonly used radial distortion model for camera calibration is in fact\nan assumption or a restriction. In practice, camera distortion could happen in\na general geometrical manner that is not limited to the radial sense. This\npaper proposes a simplified geometrical distortion modeling method by using two\ndifferent radial distortion functions in the two image axes. A family of\nsimplified geometric distortion models is proposed, which are either simple\npolynomials or the rational functions of polynomials. Analytical geometric\nundistortion is possible using two of the distortion functions discussed in\nthis paper and their performance can be improved by applying a piecewise\nfitting idea. Our experimental results show that the geometrical distortion\nmodels always perform better than their radial distortion counterparts.\nFurthermore, the proposed geometric modeling method is more appropriate for\ncameras whose distortion is not perfectly radially symmetric around the center\nof distortion."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0308034v1", 
    "title": "Fingerprint based bio-starter and bio-access", 
    "arxiv-id": "cs/0308034v1", 
    "author": "F. Rotulo", 
    "publish": "2003-08-21T10:47:27Z", 
    "summary": "In the paper will be presented a safety and security system based on\nfingerprint technology. The results suggest a new scenario where the new cars\ncan use a fingerprint sensor integrated in car handle to allow access and in\nthe dashboard as starter button."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0308035v1", 
    "title": "IS (Iris Security)", 
    "arxiv-id": "cs/0308035v1", 
    "author": "F. S. Tortoriello", 
    "publish": "2003-08-21T10:52:53Z", 
    "summary": "In the paper will be presented a safety system based on iridology. The\nresults suggest a new scenario where the security problem in supervised and\nunsupervised areas can be treat with the present system and the iris image\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0401017v2", 
    "title": "Better Foreground Segmentation Through Graph Cuts", 
    "arxiv-id": "cs/0401017v2", 
    "author": "Alexandra Deschamps", 
    "publish": "2004-01-21T20:06:51Z", 
    "summary": "For many tracking and surveillance applications, background subtraction\nprovides an effective means of segmenting objects moving in front of a static\nbackground. Researchers have traditionally used combinations of morphological\noperations to remove the noise inherent in the background-subtracted result.\nSuch techniques can effectively isolate foreground objects, but tend to lose\nfidelity around the borders of the segmentation, especially for noisy input.\nThis paper explores the use of a minimum graph cut algorithm to segment the\nforeground, resulting in qualitatively and quantitiatively cleaner\nsegmentations. Experiments on both artificial and real data show that the\ngraph-based method reduces the error around segmented foreground objects. A\nMATLAB code implementation is available at\nhttp://www.cs.smith.edu/~nhowe/research/code/#fgseg"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0401018v1", 
    "title": "Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on   the South of Russian Far East", 
    "arxiv-id": "cs/0401018v1", 
    "author": "I. V. Golycheva", 
    "publish": "2004-01-22T05:53:30Z", 
    "summary": "A method of temporal factor prognosis of TE (tick-borne encephalitis)\ninfection has been developed. The high precision of the prognosis results for a\nnumber of geographical regions of Primorsky Krai has been achieved. The method\ncan be applied not only to epidemiological research but also to others."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0402020v1", 
    "title": "Geometrical Complexity of Classification Problems", 
    "arxiv-id": "cs/0402020v1", 
    "author": "Tin Kam Ho", 
    "publish": "2004-02-11T16:34:16Z", 
    "summary": "Despite encouraging recent progresses in ensemble approaches, classification\nmethods seem to have reached a plateau in development. Further advances depend\non a better understanding of geometrical and topological characteristics of\npoint sets in high-dimensional spaces, the preservation of such characteristics\nunder feature transformations and sampling processes, and their interaction\nwith geometrical models used in classifiers. We discuss an attempt to measure\nsuch properties from data sets and relate them to classifier accuracies."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0405093v2", 
    "title": "Computerized Face Detection and Recognition", 
    "arxiv-id": "cs/0405093v2", 
    "author": "Vytautas Perlibakas", 
    "publish": "2004-05-25T11:36:34Z", 
    "summary": "This publication presents methods for face detection, analysis and\nrecognition: fast normalized cross-correlation (fast correlation coefficient)\nbetween multiple templates based face pre-detection method, method for\ndetection of exact face contour based on snakes and Generalized Gradient Vector\nFlow field, method for combining recognition algorithms based on Cumulative\nMatch Characteristics in order to increase recognition speed and accuracy, and\nface recognition method based on Principal Component Analysis of the Wavelet\nPacket Decomposition allowing to use PCA - based recognition method with large\nnumber of training images. For all the methods are presented experimental\nresults and comparisons of speed and accuracy with large face databases."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0405095v1", 
    "title": "Blind Detection and Compensation of Camera Lens Geometric Distortions", 
    "arxiv-id": "cs/0405095v1", 
    "author": "Kevin L. Moore", 
    "publish": "2004-05-25T22:40:42Z", 
    "summary": "This paper presents a blind detection and compensation technique for camera\nlens geometric distortions. The lens distortion introduces higher-order\ncorrelations in the frequency domain and in turn it can be detected using\nhigher-order spectral analysis tools without assuming any specific calibration\ntarget. The existing blind lens distortion removal method only considered a\nsingle-coefficient radial distortion model. In this paper, two coefficients are\nconsidered to model approximately the geometric distortion. All the models\nconsidered have analytical closed-form inverse formulae."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0406008v1", 
    "title": "Image compression by rectangular wavelet transform", 
    "arxiv-id": "cs/0406008v1", 
    "author": "Vyacheslav Zavadsky", 
    "publish": "2004-06-04T12:28:06Z", 
    "summary": "We study image compression by a separable wavelet basis\n$\\big\\{\\psi(2^{k_1}x-i)\\psi(2^{k_2}y-j),$ $\\phi(x-i)\\psi(2^{k_2}y-j),$\n$\\psi(2^{k_1}(x-i)\\phi(y-j),$ $\\phi(x-i)\\phi(y-i)\\big\\},$ where $k_1, k_2 \\in\n\\mathbb{Z}_+$; $i,j\\in\\mathbb{Z}$; and $\\phi,\\psi$ are elements of a standard\nbiorthogonal wavelet basis in $L_2(\\mathbb{R})$. Because $k_1\\ne k_2$, the\nsupports of the basis elements are rectangles, and the corresponding transform\nis known as the {\\em rectangular wavelet transform}. We prove that if\none-dimensional wavelet basis has $M$ dual vanishing moments then the rate of\napproximation by $N$ coefficients of rectangular wavelet transform is\n$\\mathcal{O}(N^{-M}\\log^C N)$ for functions with mixed derivative of order $M$\nin each direction.\n  The square wavelet transform yields the approximation rate is\n$\\mathcal{O}(N^{-M/2})$ for functions with all derivatives of the total order\n$M$. Thus, the rectangular wavelet transform can outperform the square one if\nan image has a mixed derivative. We provide experimental comparison of image\ncompression which shows that rectangular wavelet transform outperform the\nsquare one."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0502095v2", 
    "title": "Gradient Vector Flow Models for Boundary Extraction in 2D Images", 
    "arxiv-id": "cs/0502095v2", 
    "author": "Paulo S. Rodrigues", 
    "publish": "2005-02-28T15:09:08Z", 
    "summary": "The Gradient Vector Flow (GVF) is a vector diffusion approach based on\nPartial Differential Equations (PDEs). This method has been applied together\nwith snake models for boundary extraction medical images segmentation. The key\nidea is to use a diffusion-reaction PDE to generate a new external force field\nthat makes snake models less sensitivity to initialization as well as improves\nthe snake's ability to move into boundary concavities. In this paper, we\nfirstly review basic results about convergence and numerical analysis of usual\nGVF schemes. We point out that GVF presents numerical problems due to\ndiscontinuities image intensity. This point is considered from a practical\nviewpoint from which the GVF parameters must follow a relationship in order to\nimprove numerical convergence. Besides, we present an analytical analysis of\nthe GVF dependency from the parameters values. Also, we observe that the method\ncan be used for multiply connected domains by just imposing the suitable\nboundary condition. In the experimental results we verify these theoretical\npoints and demonstrate the utility of GVF on a segmentation approach that we\nhave developed based on snakes."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0505006v1", 
    "title": "Searching for image information content, its discovery, extraction, and   representation", 
    "arxiv-id": "cs/0505006v1", 
    "author": "Emanuel Diamant", 
    "publish": "2005-05-02T03:17:02Z", 
    "summary": "Image information content is known to be a complicated and controvercial\nproblem. This paper posits a new image information content definition.\nFollowing the theory of Solomonoff-Kolmogorov-Chaitin's complexity, we define\nimage information content as a set of descriptions of imafe data structures.\nThree levels of such description can be generally distinguished: 1)the global\nlevel, where the coarse structure of the entire scene is initially outlined; 2)\nthe intermediate level, where structures of separate, non-overlapping image\nregions usually associated with individual scene objects are deliniated; and 3)\nthe low-level description, where local image structures observed in a limited\nand restricted field of view are resolved. A technique for creating such image\ninformation content descriptors is developed. Its algorithm is presented and\nelucidated with some examples, which demonstrate the effectiveness of the\nproposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0507058v1", 
    "title": "Paving the Way for Image Understanding: A New Kind of Image   Decomposition is Desired", 
    "arxiv-id": "cs/0507058v1", 
    "author": "Emanuel Diamant", 
    "publish": "2005-07-22T12:18:44Z", 
    "summary": "In this paper we present an unconventional image segmentation approach which\nis devised to meet the requirements of image understanding and pattern\nrecognition tasks. Generally image understanding assumes interplay of two\nsub-processes: image information content discovery and image information\ncontent interpretation. Despite of its widespread use, the notion of \"image\ninformation content\" is still ill defined, intuitive, and ambiguous. Most\noften, it is used in the Shannon's sense, which means information content\nassessment averaged over the whole signal ensemble. Humans, however,rarely\nresort to such estimates. They are very effective in decomposing images into\ntheir meaningful constituents and focusing attention to the perceptually\nrelevant image parts. We posit that following the latest findings in human\nattention vision studies and the concepts of Kolmogorov's complexity theory an\nunorthodox segmentation approach can be proposed that provides effective image\ndecomposition to information preserving image fragments well suited for\nsubsequent image interpretation. We provide some illustrative examples,\ndemonstrating effectiveness of this approach."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0509081v1", 
    "title": "Automatic Face Recognition System Based on Local Fourier-Bessel Features", 
    "arxiv-id": "cs/0509081v1", 
    "author": "Regis de A. Barbosa", 
    "publish": "2005-09-27T15:25:36Z", 
    "summary": "We present an automatic face verification system inspired by known properties\nof biological systems. In the proposed algorithm the whole image is converted\nfrom the spatial to polar frequency domain by a Fourier-Bessel Transform (FBT).\nUsing the whole image is compared to the case where only face image regions\n(local analysis) are considered. The resulting representations are embedded in\na dissimilarity space, where each image is represented by its distance to all\nthe other images, and a Pseudo-Fisher discriminator is built. Verification test\nresults on the FERET database showed that the local-based algorithm outperforms\nthe global-FBT version. The local-FBT algorithm performed as state-of-the-art\nmethods under different testing conditions, indicating that the proposed system\nis highly robust for expression, age, and illumination variations. We also\nevaluated the performance of the proposed system under strong occlusion\nconditions and found that it is highly robust for up to 50% of face occlusion.\nFinally, we automated completely the verification system by implementing face\nand eye detection algorithms. Under this condition, the local approach was only\nslightly superior to the global approach."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0509082v1", 
    "title": "Face Recognition Based on Polar Frequency Features", 
    "arxiv-id": "cs/0509082v1", 
    "author": "Roberto M. Cesar-JR", 
    "publish": "2005-09-27T15:50:27Z", 
    "summary": "A novel biologically motivated face recognition algorithm based on polar\nfrequency is presented. Polar frequency descriptors are extracted from face\nimages by Fourier-Bessel transform (FBT). Next, the Euclidean distance between\nall images is computed and each image is now represented by its dissimilarity\nto the other images. A Pseudo-Fisher Linear Discriminant was built on this\ndissimilarity space. The performance of Discrete Fourier transform (DFT)\ndescriptors, and a combination of both feature types was also evaluated. The\nalgorithms were tested on a 40- and 1196-subjects face database (ORL and FERET,\nrespectively). With 5 images per subject in the training and test datasets,\nerror rate on the ORL database was 3.8, 1.25 and 0.2% for the FBT, DFT, and the\ncombined classifier, respectively, as compared to 2.6% achieved by the best\nprevious algorithm. The most informative polar frequency features were\nconcentrated at low-to-medium angular frequencies coupled to low radial\nfrequencies. On the FERET database, where an affine normalization\npre-processing was applied, the FBT algorithm outperformed only the PCA in a\nrank recognition test. However, it achieved performance comparable to\nstate-of-the-art methods when evaluated by verification tests. These results\nindicate the high informative value of the polar frequency content of face\nimages in relation to recognition and verification tasks, and that the\nCartesian frequency content can complement information about the subjects'\nidentity, but possibly only when the images are not pre-normalized. Possible\nimplications for human face recognition are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0509083v1", 
    "title": "Face Verification in Polar Frequency Domain: a Biologically Motivated   Approach", 
    "arxiv-id": "cs/0509083v1", 
    "author": "Matthew Turk", 
    "publish": "2005-09-27T16:06:22Z", 
    "summary": "We present a novel local-based face verification system whose components are\nanalogous to those of biological systems. In the proposed system, after global\nregistration and normalization, three eye regions are converted from the\nspatial to polar frequency domain by a Fourier-Bessel Transform. The resulting\nrepresentations are embedded in a dissimilarity space, where each image is\nrepresented by its distance to all the other images. In this dissimilarity\nspace a Pseudo-Fisher discriminator is built. ROC and equal error rate\nverification test results on the FERET database showed that the system\nperformed at least as state-of-the-art methods and better than a system based\non polar Fourier features. The local-based system is especially robust to\nfacial expression and age variations, but sensitive to registration errors."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TMI.2006.879967", 
    "link": "http://arxiv.org/pdf/cs/0510001v2", 
    "title": "Retinal Vessel Segmentation Using the 2-D Morlet Wavelet and Supervised   Classification", 
    "arxiv-id": "cs/0510001v2", 
    "author": "Michael J. Cree", 
    "publish": "2005-09-30T22:27:45Z", 
    "summary": "We present a method for automated segmentation of the vasculature in retinal\nimages. The method produces segmentations by classifying each image pixel as\nvessel or non-vessel, based on the pixel's feature vector. Feature vectors are\ncomposed of the pixel's intensity and continuous two-dimensional Morlet wavelet\ntransform responses taken at multiple scales. The Morlet wavelet is capable of\ntuning to specific frequencies, thus allowing noise filtering and vessel\nenhancement in a single step. We use a Bayesian classifier with\nclass-conditional probability density functions (likelihoods) described as\nGaussian mixtures, yielding a fast classification, while being able to model\ncomplex decision surfaces and compare its performance with the linear minimum\nsquared error classifier. The probability distributions are estimated based on\na training set of labeled pixels obtained from manual segmentations. The\nmethod's performance is evaluated on publicly available DRIVE and STARE\ndatabases of manually labeled non-mydriatic images. On the DRIVE database, it\nachieves an area under the receiver operating characteristic (ROC) curve of\n0.9598, being slightly superior than that presented by the method of Staal et\nal."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0510026v1", 
    "title": "A decision support system for ship identification based on the curvature   scale space representation", 
    "arxiv-id": "cs/0510026v1", 
    "author": "Carlos Dorronsoro", 
    "publish": "2005-10-11T08:43:04Z", 
    "summary": "In this paper, a decision support system for ship identification is\npresented. The system receives as input a silhouette of the vessel to be\nidentified, previously extracted from a side view of the object. This view\ncould have been acquired with imaging sensors operating at different spectral\nranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and\ncompared to those stored in a database, retrieving a small number of potential\nmatches ranked by their similarity to the target silhouette. This set of\npotential matches is presented to the system operator, who makes the final ship\nidentification. This system makes use of an evolved version of the Curvature\nScale Space (CSS) representation. In the proposed approach, it is curvature\nextrema, instead of zero crossings, that are tracked during silhouette\nevolution, hence improving robustness and enabling to cope successfully with\ncases where the standard CCS representation is found to be unstable. Also, the\nuse of local curvature was replaced with the more robust concept of lobe\nconcavity, with significant additional gains in performance. Experimental\nresults on actual operational imagery prove the excellent performance and\nrobustness of the developed method."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0512084v1", 
    "title": "Understanding physics from interconnected data", 
    "arxiv-id": "cs/0512084v1", 
    "author": "Hanna Makaruk", 
    "publish": "2005-12-21T20:23:38Z", 
    "summary": "Metal melting on release after explosion is a physical system far from\nquilibrium. A complete physical model of this system does not exist, because\nmany interrelated effects have to be considered. General methodology needs to\nbe developed so as to describe and understand physical phenomena involved.\n  The high noise of the data, moving blur of images, the high degree of\nuncertainty due to the different types of sensors, and the information\nentangled and hidden inside the noisy images makes reasoning about the physical\nprocesses very difficult. Major problems include proper information extraction\nand the problem of reconstruction, as well as prediction of the missing data.\nIn this paper, several techniques addressing the first problem are given,\nbuilding the basis for tackling the second problem."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0601105v3", 
    "title": "The Perceptron Algorithm: Image and Signal Decomposition, Compression,   and Analysis by Iterative Gaussian Blurring", 
    "arxiv-id": "cs/0601105v3", 
    "author": "Vassilios S. Vassiliadis", 
    "publish": "2006-01-24T17:23:17Z", 
    "summary": "A novel algorithm for tunable compression to within the precision of\nreproduction targets, or storage, is proposed. The new algorithm is termed the\n`Perceptron Algorithm', which utilises simple existing concepts in a novel way,\nhas multiple immediate commercial application aspects as well as it opens up a\nmultitude of fronts in computational science and technology. The aims of this\npaper are to present the concepts underlying the algorithm, observations by its\napplication to some example cases, and the identification of a multitude of\npotential areas of applications such as: image compression by orders of\nmagnitude, signal compression including sound as well, image analysis in a\nmultilayered detailed analysis, pattern recognition and matching and rapid\ndatabase searching (e.g. face recognition), motion analysis, biomedical\napplications e.g. in MRI and CAT scan image analysis and compression, as well\nas hints on the link of these ideas to the way how biological memory might work\nleading to new points of view in neural computation. Commercial applications of\nimmediate interest are the compression of images at the source (e.g.\nphotographic equipment, scanners, satellite imaging systems), DVD film\ncompression, pay-per-view downloads acceleration and many others identified in\nthe present paper at its conclusion and future work section."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0601106v1", 
    "title": "The `Face on Mars': a photographic approach for the search of signs of   past civilizations from a macroscopic point of view, factoring long-term   erosion in image reconstruction", 
    "arxiv-id": "cs/0601106v1", 
    "author": "Vassilios S. Vassiliadis", 
    "publish": "2006-01-24T18:12:00Z", 
    "summary": "This short article presents an alternative view of high resolution imaging\nfrom various sources with the aim of the discovery of potential sites of\narchaeological importance, or sites that exhibit `anomalies' such that they may\nmerit closer inspection and analysis. It is conjectured, and to a certain\nextent demonstrated here, that it is possible for advanced civilizations to\nfactor in erosion by natural processes into a large scale design so that main\nfeatures be preserved even with the passage of millions of years. Alternatively\nviewed, even without such intent embedded in a design left for posterity, it is\npossible that a gigantic construction may naturally decay in such a way that\neven cataclysmic (massive) events may leave sufficient information intact with\nthe passage of time, provided one changes the point of view from high\nresolution images to enhanced blurred renderings of the sites in question."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0602044v1", 
    "title": "Multilevel Thresholding for Image Segmentation through a Fast   Statistical Recursive Algorithm", 
    "arxiv-id": "cs/0602044v1", 
    "author": "Prasanta K. Panigrahi", 
    "publish": "2006-02-12T18:22:41Z", 
    "summary": "A novel algorithm is proposed for segmenting an image into multiple levels\nusing its mean and variance. Starting from the extreme pixel values at both\nends of the histogram plot, the algorithm is applied recursively on sub-ranges\ncomputed from the previous step, so as to find a threshold level and a new\nsub-range for the next step, until no significant improvement in image quality\ncan be achieved. The method makes use of the fact that a number of\ndistributions tend towards Dirac delta function, peaking at the mean, in the\nlimiting condition of vanishing variance. The procedure naturally provides for\nvariable size segmentation with bigger blocks near the extreme pixel values and\nfiner divisions around the mean or other chosen value for better visualization.\nExperiments on a variety of images show that the new algorithm effectively\nsegments the image in computationally very less time."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0603041v1", 
    "title": "Locally Adaptive Block Thresholding Method with Continuity Constraint", 
    "arxiv-id": "cs/0603041v1", 
    "author": "Prasanta K. Panigrahi", 
    "publish": "2006-03-09T17:14:00Z", 
    "summary": "We present an algorithm that enables one to perform locally adaptive block\nthresholding, while maintaining image continuity. Images are divided into\nsub-images based some standard image attributes and thresholding technique is\nemployed over the sub-images. The present algorithm makes use of the thresholds\nof neighboring sub-images to calculate a range of values. The image continuity\nis taken care by choosing the threshold of the sub-image under consideration to\nlie within the above range. After examining the average range values for\nvarious sub-image sizes of a variety of images, it was found that the range of\nacceptable threshold values is substantially high, justifying our assumption of\nexploiting the freedom of range for bringing out local details."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0603086v1", 
    "title": "Matching Edges in Images ; Application to Face Recognition", 
    "arxiv-id": "cs/0603086v1", 
    "author": "Mickael Urrutia", 
    "publish": "2006-03-22T14:51:53Z", 
    "summary": "This communication describes a representation of images as a set of edges\ncharacterized by their position and orientation. This representation allows the\ncomparison of two images and the computation of their similarity. The first\nstep in this computation of similarity is the seach of a geometrical basis of\nthe two dimensional space where the two images are represented simultaneously\nafter transformation of one of them. Presently, this simultaneous\nrepresentation takes into account a shift and a scaling ; it may be extended to\nrotations or other global geometrical transformations. An elementary\nprobabilistic computation shows that a sufficient but not excessive number of\ntrials (a few tens) ensures that the exhibition of this common basis is\nguaranteed in spite of possible errors in the detection of edges. When this\nfirst step is performed, the search of similarity between the two images\nreduces to counting the coincidence of edges in the two images. The approach\nmay be applied to many problems of pattern matching ; it was checked on face\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0603116v2", 
    "title": "Fourier Analysis and Holographic Representations of 1D and 2D Signals", 
    "arxiv-id": "cs/0603116v2", 
    "author": "J. C. de Oliveira", 
    "publish": "2006-03-29T19:07:52Z", 
    "summary": "In this paper, we focus on Fourier analysis and holographic transforms for\nsignal representation. For instance, in the case of image processing, the\nholographic representation has the property that an arbitrary portion of the\ntransformed image enables reconstruction of the whole image with details\nmissing. We focus on holographic representation defined through the Fourier\nTransforms. Thus, We firstly review some results in Fourier transform and\nFourier series. Next, we review the Discrete Holographic Fourier Transform\n(DHFT) for image representation. Then, we describe the contributions of our\nwork. We show a simple scheme for progressive transmission based on the DHFT.\nNext, we propose the Continuous Holographic Fourier Transform (CHFT) and\ndiscuss some theoretical aspects of it for 1D signals. Finally, some testes are\npresented in the experimental results"
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0604062v1", 
    "title": "Biologically Inspired Hierarchical Model for Feature Extraction and   Localization", 
    "arxiv-id": "cs/0604062v1", 
    "author": "Liang Wu", 
    "publish": "2006-04-14T04:40:29Z", 
    "summary": "Feature extraction and matching are among central problems of computer\nvision. It is inefficent to search features over all locations and scales.\nNeurophysiological evidence shows that to locate objects in a digital image the\nhuman visual system employs visual attention to a specific object while\nignoring others. The brain also has a mechanism to search from coarse to fine.\nIn this paper, we present a feature extractor and an associated hierarchical\nsearching model to simulate such processes. With the hierarchical\nrepresentation of the object, coarse scanning is done through the matching of\nthe larger scale and precise localization is conducted through the matching of\nthe smaller scale. Experimental results justify the proposed model in its\neffectiveness and efficiency to localize features."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0605025v1", 
    "title": "Face Recognition using Principal Component Analysis and Log-Gabor   Filters", 
    "arxiv-id": "cs/0605025v1", 
    "author": "Vytautas Perlibakas", 
    "publish": "2006-05-07T13:30:09Z", 
    "summary": "In this article we propose a novel face recognition method based on Principal\nComponent Analysis (PCA) and Log-Gabor filters. The main advantages of the\nproposed method are its simple implementation, training, and very high\nrecognition accuracy. For recognition experiments we used 5151 face images of\n1311 persons from different sets of the FERET and AR databases that allow to\nanalyze how recognition accuracy is affected by the change of facial\nexpressions, illumination, and aging. Recognition experiments with the FERET\ndatabase (containing photographs of 1196 persons) showed that our method can\nachieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error\nRate. The experiments also showed that the accuracy of our method is less\naffected by eye location errors and used image normalization method than of\ntraditional PCA -based recognition method."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0605027v1", 
    "title": "Recognition of expression variant faces using masked log-Gabor features   and Principal Component Analysis", 
    "arxiv-id": "cs/0605027v1", 
    "author": "Vytautas Perlibakas", 
    "publish": "2006-05-07T15:02:53Z", 
    "summary": "In this article we propose a method for the recognition of faces with\ndifferent facial expressions. For recognition we extract feature vectors by\nusing log-Gabor filters of multiple orientations and scales. Using sliding\nwindow algorithm and variances -based masking these features are extracted at\nimage regions that are less affected by the changes of facial expressions.\nExtracted features are passed to the Principal Component Analysis (PCA) -based\nrecognition method. The results of face recognition experiments using\nexpression variant faces showed that the proposed method could achieve higher\nrecognition accuracy than many other methods. For development and testing we\nused facial images from the AR and FERET databases. Using facial photographs of\nmore than one thousand persons from the FERET database the proposed method\nachieved 96.6-98.9% first one recognition rate and 0.2-0.6% Equal Error Rate\n(EER)."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0605131v2", 
    "title": "Notes on Geometric Measure Theory Applications to Image Processing;   De-noising, Segmentation, Pattern, Texture, Lines, Gestalt and Occlusion", 
    "arxiv-id": "cs/0605131v2", 
    "author": "Simon P Morgan", 
    "publish": "2006-05-29T13:27:38Z", 
    "summary": "Regularization functionals that lower level set boundary length when used\nwith L^1 fidelity functionals on signal de-noising on images create artifacts.\nThese are (i) rounding of corners, (ii) shrinking of radii, (iii) shrinking of\ncusps, and (iv) non-smoothing of staircasing. Regularity functionals based upon\ntotal curvature of level set boundaries do not create artifacts (i) and (ii).\nAn adjusted fidelity term based on the flat norm on the current (a\ndistributional graph) representing the density of curvature of level sets\nboundaries can minimize (iii) by weighting the position of a cusp. A regularity\nterm to eliminate staircasing can be based upon the mass of the current\nrepresenting the graph of an image function or its second derivatives.\nDensities on the Grassmann bundle of the Grassmann bundle of the ambient space\nof the graph can be used to identify patterns, textures, occlusion and lines."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609010v1", 
    "title": "An effective edge--directed frequency filter for removal of aliasing in   upsampled images", 
    "arxiv-id": "cs/0609010v1", 
    "author": "Artur Rataj", 
    "publish": "2006-09-04T13:04:57Z", 
    "summary": "Raster images can have a range of various distortions connected to their\nraster structure. Upsampling them might in effect substantially yield the\nraster structure of the original image, known as aliasing. The upsampling\nitself may introduce aliasing into the upsampled image as well. The presented\nmethod attempts to remove the aliasing using frequency filters based on the\ndiscrete fast Fourier transform, and applied directionally in certain regions\nplaced along the edges in the image.\n  As opposed to some anisotropic smoothing methods, the presented algorithm\naims to selectively reduce only the aliasing, preserving the sharpness of image\ndetails.\n  The method can be used as a post--processing filter along with various\nupsampling algorithms. It was experimentally shown that the method can improve\nthe visual quality of the upsampled images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609100v1", 
    "title": "Total Variation Minimization and Graph Cuts for Moving Objects   Segmentation", 
    "arxiv-id": "cs/0609100v1", 
    "author": "Fran\u00e7oise Dibos", 
    "publish": "2006-09-18T06:40:44Z", 
    "summary": "In this paper, we are interested in the application to video segmentation of\nthe discrete shape optimization problem involving the shape weighted perimeter\nand an additional term depending on a parameter. Based on recent works and in\nparticular the one of Darbon and Sigelle, we justify the equivalence of the\nshape optimization problem and a weighted total variation regularization. For\nsolving this problem, we adapt the projection algorithm proposed recently for\nsolving the basic TV regularization problem. Another solution to the shape\noptimization investigated here is the graph cut technique. Both methods have\nthe advantage to lead to a global minimum. Since we can distinguish moving\nobjects from static elements of a scene by analyzing norm of the optical flow\nvectors, we choose the optical flow norm as initial data. In order to have the\ncontour as close as possible to an edge in the image, we use a classical edge\ndetector function as the weight of the weighted total variation. This model has\nbeen used in one of our former works. We also apply the same methods to a video\nsegmentation model used by Jehan-Besson, Barlaud and Aubert. In this case, only\nstandard perimeter is incorporated in the shape functional. We also propose\nanother way for finding moving objects by using an a contrario detection of\nobjects on the image obtained by solving the Rudin-Osher-Fatemi Total Variation\nregularization problem.We can notice the segmentation can be associated to a\nlevel set in the former methods."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609164v1", 
    "title": "Conditional Expressions for Blind Deconvolution: Multi-point form", 
    "arxiv-id": "cs/0609164v1", 
    "author": "F. M. Toyama", 
    "publish": "2006-09-29T13:48:35Z", 
    "summary": "We present conditional expression (CE) for finding blurs convolved in given\nimages. The CE is given in terms of the zero-values of the blurs evaluated at\nmulti-point. The CE can detect multiple blur all at once. We illustrate the\nmultiple blur-detection by using a test image."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609165v1", 
    "title": "Simple method to eliminate blur based on Lane and Bates algorithm", 
    "arxiv-id": "cs/0609165v1", 
    "author": "F. M. Toyama", 
    "publish": "2006-09-29T13:50:12Z", 
    "summary": "A simple search method for finding a blur convolved in a given image is\npresented. The method can be easily extended to a large blur. The method has\nbeen experimentally tested with a model blurred image."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0610002v1", 
    "title": "Conditional Expressions for Blind Deconvolution: Derivative form", 
    "arxiv-id": "cs/0610002v1", 
    "author": "F. M. Toyama", 
    "publish": "2006-09-30T08:05:02Z", 
    "summary": "We developed novel conditional expressions (CEs) for Lane and Bates' blind\ndeconvolution. The CEs are given in term of the derivatives of the zero-values\nof the z-transform of given images. The CEs make it possible to automatically\ndetect multiple blur convolved in the given images all at once without\nperforming any analysis of the zero-sheets of the given images. We illustrate\nthe multiple blur-detection by the CEs for a model image"
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0610059v2", 
    "title": "Camera motion estimation through planar deformation determination", 
    "arxiv-id": "cs/0610059v2", 
    "author": "Georges Koepfler", 
    "publish": "2006-10-11T09:31:52Z", 
    "summary": "In this paper, we propose a global method for estimating the motion of a\ncamera which films a static scene. Our approach is direct, fast and robust, and\ndeals with adjacent frames of a sequence. It is based on a quadratic\napproximation of the deformation between two images, in the case of a scene\nwith constant depth in the camera coordinate system. This condition is very\nrestrictive but we show that provided translation and depth inverse variations\nare small enough, the error on optical flow involved by the approximation of\ndepths by a constant is small. In this context, we propose a new model of\ncamera motion, that allows to separate the image deformation in a similarity\nand a ``purely'' projective application, due to change of optical axis\ndirection. This model leads to a quadratic approximation of image deformation\nthat we estimate with an M-estimator; we can immediatly deduce camera motion\nparameters."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0611115v1", 
    "title": "A higher-order active contour model of a `gas of circles' and its   application to tree crown extraction", 
    "arxiv-id": "cs/0611115v1", 
    "author": "Josiane Zerubia", 
    "publish": "2006-11-22T13:44:11Z", 
    "summary": "Many image processing problems involve identifying the region in the image\ndomain occupied by a given entity in the scene. Automatic solution of these\nproblems requires models that incorporate significant prior knowledge about the\nshape of the region. Many methods for including such knowledge run into\ndifficulties when the topology of the region is unknown a priori, for example\nwhen the entity is composed of an unknown number of similar objects.\nHigher-order active contours (HOACs) represent one method for the modelling of\nnon-trivial prior knowledge about shape without necessarily constraining region\ntopology, via the inclusion of non-local interactions between region boundary\npoints in the energy defining the model. The case of an unknown number of\ncircular objects arises in a number of domains, e.g. medical, biological,\nnanotechnological, and remote sensing imagery. Regions composed of an a priori\nunknown number of circles may be referred to as a `gas of circles'. In this\nreport, we present a HOAC model of a `gas of circles'. In order to guarantee\nstable circles, we conduct a stability analysis via a functional Taylor\nexpansion of the HOAC energy around a circular shape. This analysis fixes one\nof the model parameters in terms of the others and constrains the rest. In\nconjunction with a suitable likelihood energy, we apply the model to the\nextraction of tree crowns from aerial imagery, and show that the new model\noutperforms other techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0701150v1", 
    "title": "Contains and Inside relationships within combinatorial Pyramids", 
    "arxiv-id": "cs/0701150v1", 
    "author": "Walter G. Kropatsch", 
    "publish": "2007-01-24T15:13:06Z", 
    "summary": "Irregular pyramids are made of a stack of successively reduced graphs\nembedded in the plane. Such pyramids are used within the segmentation framework\nto encode a hierarchy of partitions. The different graph models used within the\nirregular pyramid framework encode different types of relationships between\nregions. This paper compares different graph models used within the irregular\npyramid framework according to a set of relationships between regions. We also\ndefine a new algorithm based on a pyramid of combinatorial maps which allows to\ndetermine if one region contains the other using only local calculus."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0703053v1", 
    "title": "Extraction of cartographic objects in high resolution satellite images   for object model generation", 
    "arxiv-id": "cs/0703053v1", 
    "author": "Nicolas Lom\u00e9nie", 
    "publish": "2007-03-12T15:57:23Z", 
    "summary": "The aim of this study is to detect man-made cartographic objects in\nhigh-resolution satellite images. New generation satellites offer a sub-metric\nspatial resolution, in which it is possible (and necessary) to develop methods\nat object level rather than at pixel level, and to exploit structural features\nof objects. With this aim, a method to generate structural object models from\nmanually segmented images has been developed. To generate the model from\nnon-segmented images, extraction of the objects from the sample images is\nrequired. A hybrid method of extraction (both in terms of input sources and\nsegmentation algorithms) is proposed: A region based segmentation is applied on\na 10 meter resolution multi-spectral image. The result is used as marker in a\n\"marker-controlled watershed method using edges\" on a 2.5 meter resolution\npanchromatic image. Very promising results have been obtained even on images\nwhere the limits of the target objects are not apparent."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0704.1267v1", 
    "title": "Text Line Segmentation of Historical Documents: a Survey", 
    "arxiv-id": "0704.1267v1", 
    "author": "Bruno Taconet", 
    "publish": "2007-04-10T16:26:42Z", 
    "summary": "There is a huge amount of historical documents in libraries and in various\nNational Archives that have not been exploited electronically. Although\nautomatic reading of complete pages remains, in most cases, a long-term\nobjective, tasks such as word spotting, text/image alignment, authentication\nand extraction of specific fields are in use today. For all these tasks, a\nmajor step is document segmentation into text lines. Because of the low quality\nand the complexity of these documents (background noise, artifacts due to\naging, interfering lines),automatic text line segmentation remains an open\nresearch field. The objective of this paper is to present a survey of existing\nmethods, developed during the last decade, and dedicated to documents of\nhistorical interest."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0214v1", 
    "title": "Riemannian level-set methods for tensor-valued data", 
    "arxiv-id": "0705.0214v1", 
    "author": "Maher Moakher", 
    "publish": "2007-05-02T07:32:58Z", 
    "summary": "We present a novel approach for the derivation of PDE modeling\ncurvature-driven flows for matrix-valued data. This approach is based on the\nRiemannian geometry of the manifold of Symmetric Positive Definite Matrices\nPos(n)."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0449v1", 
    "title": "Multiresolution Approximation of Polygonal Curves in Linear Complexity", 
    "arxiv-id": "0705.0449v1", 
    "author": "Gilbas M\u00e9nier", 
    "publish": "2007-05-03T12:47:31Z", 
    "summary": "We propose a new algorithm to the problem of polygonal curve approximation\nbased on a multiresolution approach. This algorithm is suboptimal but still\nmaintains some optimality between successive levels of resolution using dynamic\nprogramming. We show theoretically and experimentally that this algorithm has a\nlinear complexity in time and space. We experimentally compare the outcomes of\nour algorithm to the optimal \"full search\" dynamic programming solution and\nfinally to classical merge and split approaches. The experimental evaluations\nconfirm the theoretical derivations and show that the proposed approach\nevaluated on 2D coastal maps either show a lower time complexity or provide\npolygonal approximations closer to the input discrete curves."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0781v1", 
    "title": "Medical Image Segmentation and Localization using Deformable Templates", 
    "arxiv-id": "0705.0781v1", 
    "author": "T. Marwala", 
    "publish": "2007-05-06T06:02:46Z", 
    "summary": "This paper presents deformable templates as a tool for segmentation and\nlocalization of biological structures in medical images. Structures are\nrepresented by a prototype template, combined with a parametric warp mapping\nused to deform the original shape. The localization procedure is achieved using\na multi-stage, multi-resolution algorithm de-signed to reduce computational\ncomplexity and time. The algorithm initially identifies regions in the image\nmost likely to contain the desired objects and then examines these regions at\nprogressively increasing resolutions. The final stage of the algorithm involves\nwarping the prototype template to match the localized objects. The algorithm is\npresented along with the results of four example applications using MRI, x-ray\nand ultrasound images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0828v1", 
    "title": "Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field   Annealing", 
    "arxiv-id": "0705.0828v1", 
    "author": "T. Marwala", 
    "publish": "2007-05-06T23:08:04Z", 
    "summary": "Nuclear medicine (NM) images inherently suffer from large amounts of noise\nand blur. The purpose of this research is to reduce the noise and blur while\nmaintaining image integrity for improved diagnosis. The proposed solution is to\nincrease image quality after the standard pre- and post-processing undertaken\nby a gamma camera system. Mean Field Annealing (MFA) is the image processing\ntechnique used in this research. It is a computational iterative technique that\nmakes use of the Point Spread Function (PSF) and the noise associated with the\nNM image. MFA is applied to NM images with the objective of reducing noise\nwhile not compromising edge integrity. Using a sharpening filter as a\npost-processing technique (after MFA) yields image enhancement of planar NM\nimages."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0952v1", 
    "title": "An Independent Evaluation of Subspace Face Recognition Algorithms", 
    "arxiv-id": "0705.0952v1", 
    "author": "Tshilidzi Marwala", 
    "publish": "2007-05-07T19:19:55Z", 
    "summary": "This paper explores a comparative study of both the linear and kernel\nimplementations of three of the most popular Appearance-based Face Recognition\nprojection classes, these being the methodologies of Principal Component\nAnalysis, Linear Discriminant Analysis and Independent Component Analysis. The\nexperimental procedure provides a platform of equal working conditions and\nexamines the ten algorithms in the categories of expression, illumination,\nocclusion and temporal delay. The results are then evaluated based on a\nsequential combination of assessment tools that facilitate both intuitive and\nstatistical decisiveness among the intra and interclass comparisons. The best\ncategorical algorithms are then incorporated into a hybrid methodology, where\nthe advantageous effects of fusion strategies are considered."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.3593v2", 
    "title": "MI image registration using prior knowledge", 
    "arxiv-id": "0705.3593v2", 
    "author": "P. de Groen", 
    "publish": "2007-05-24T14:41:11Z", 
    "summary": "Subtraction of aligned images is a means to assess changes in a wide variety\nof clinical applications. In this paper we explore the information theoretical\norigin of Mutual Information (MI), which is based on Shannon's entropy.However,\nthe interpretation of standard MI registration as a communication channel\nsuggests that MI is too restrictive a criterion. In this paper the concept of\nMutual Information (MI) is extended to (Normalized) Focussed Mutual Information\n(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We\nuse this to develop new methodologies to successfully address specific\nregistration problems, the follow-up of dental restorations, cephalometry, and\nthe monitoring of implants."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0706.0300v1", 
    "title": "Automatic Detection of Pulmonary Embolism using Computational   Intelligence", 
    "arxiv-id": "0706.0300v1", 
    "author": "David Rubin", 
    "publish": "2007-06-03T05:17:38Z", 
    "summary": "This article describes the implementation of a system designed to\nautomatically detect the presence of pulmonary embolism in lung scans. These\nimages are firstly segmented, before alignment and feature extraction using\nPCA. The neural network was trained using the Hybrid Monte Carlo method,\nresulting in a committee of 250 neural networks and good results are obtained."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0709.1771v1", 
    "title": "Variational local structure estimation for image super-resolution", 
    "arxiv-id": "0709.1771v1", 
    "author": "Heng Lian", 
    "publish": "2007-09-12T08:41:36Z", 
    "summary": "Super-resolution is an important but difficult problem in image/video\nprocessing. If a video sequence or some training set other than the given\nlow-resolution image is available, this kind of extra information can greatly\naid in the reconstruction of the high-resolution image. The problem is\nsubstantially more difficult with only a single low-resolution image on hand.\nThe image reconstruction methods designed primarily for denoising is\ninsufficient for super-resolution problem in the sense that it tends to\noversmooth images with essentially no noise. We propose a new adaptive linear\ninterpolation method based on variational method and inspired by local linear\nembedding (LLE). The experimental result shows that our method avoids the\nproblem of oversmoothing and preserves image structures well."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0709.1920v2", 
    "title": "Bandwidth selection for kernel estimation in mixed multi-dimensional   spaces", 
    "arxiv-id": "0709.1920v2", 
    "author": "Patrick P\u00e9rez", 
    "publish": "2007-09-12T16:02:25Z", 
    "summary": "Kernel estimation techniques, such as mean shift, suffer from one major\ndrawback: the kernel bandwidth selection. The bandwidth can be fixed for all\nthe data set or can vary at each points. Automatic bandwidth selection becomes\na real challenge in case of multidimensional heterogeneous features. This paper\npresents a solution to this problem. It is an extension of \\cite{Comaniciu03a}\nwhich was based on the fundamental property of normal distributions regarding\nthe bias of the normalized density gradient. The selection is done iteratively\nfor each type of features, by looking for the stability of local bandwidth\nestimates across a predefined range of bandwidths. A pseudo balloon mean shift\nfiltering and partitioning are introduced. The validity of the method is\ndemonstrated in the context of color image segmentation based on a\n5-dimensional space."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0709.3013v2", 
    "title": "Supervised learning on graphs of spatio-temporal similarity in satellite   image sequences", 
    "arxiv-id": "0709.3013v2", 
    "author": "Mihai Datcu", 
    "publish": "2007-09-19T13:18:18Z", 
    "summary": "High resolution satellite image sequences are multidimensional signals\ncomposed of spatio-temporal patterns associated to numerous and various\nphenomena. Bayesian methods have been previously proposed in (Heas and Datcu,\n2005) to code the information contained in satellite image sequences in a graph\nrepresentation using Bayesian methods. Based on such a representation, this\npaper further presents a supervised learning methodology of semantics\nassociated to spatio-temporal patterns occurring in satellite image sequences.\nIt enables the recognition and the probabilistic retrieval of similar events.\nIndeed, graphs are attached to statistical models for spatio-temporal\nprocesses, which at their turn describe physical changes in the observed scene.\nTherefore, we adjust a parametric model evaluating similarity types between\ngraph patterns in order to represent user-specific semantics attached to\nspatio-temporal phenomena. The learning step is performed by the incremental\ndefinition of similarity types via user-provided spatio-temporal pattern\nexamples attached to positive or/and negative semantics. From these examples,\nprobabilities are inferred using a Bayesian network and a Dirichlet model. This\nenables to links user interest to a specific similarity model between graph\npatterns. According to the current state of learning, semantic posterior\nprobabilities are updated for all possible graph patterns so that similar\nspatio-temporal phenomena can be recognized and retrieved from the image\nsequence. Few experiments performed on a multi-spectral SPOT image sequence\nillustrate the proposed spatio-temporal recognition method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.0043v2", 
    "title": "Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching", 
    "arxiv-id": "0710.0043v2", 
    "author": "Marconi S. Barbosa", 
    "publish": "2007-09-29T06:19:09Z", 
    "summary": "A recent paper \\cite{CaeCaeSchBar06} proposed a provably optimal, polynomial\ntime method for performing near-isometric point pattern matching by means of\nexact probabilistic inference in a chordal graphical model. Their fundamental\nresult is that the chordal graph in question is shown to be globally rigid,\nimplying that exact inference provides the same matching solution as exact\ninference in a complete graphical model. This implies that the algorithm is\noptimal when there is no noise in the point patterns. In this paper, we present\na new graph which is also globally rigid but has an advantage over the graph\nproposed in \\cite{CaeCaeSchBar06}: its maximal clique size is smaller,\nrendering inference significantly more efficient. However, our graph is not\nchordal and thus standard Junction Tree algorithms cannot be directly applied.\nNevertheless, we show that loopy belief propagation in such a graph converges\nto the optimal solution. This allows us to retain the optimality guarantee in\nthe noiseless case, while substantially reducing both memory requirements and\nprocessing time. Our experimental results show that the accuracy of the\nproposed solution is indistinguishable from that of \\cite{CaeCaeSchBar06} when\nthere is noise in the point patterns."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.0243v1", 
    "title": "High-Order Nonparametric Belief-Propagation for Fast Image Inpainting", 
    "arxiv-id": "0710.0243v1", 
    "author": "Tiberio S. Caetano", 
    "publish": "2007-10-01T09:18:36Z", 
    "summary": "In this paper, we use belief-propagation techniques to develop fast\nalgorithms for image inpainting. Unlike traditional gradient-based approaches,\nwhich may require many iterations to converge, our techniques achieve\ncompetitive results after only a few iterations. On the other hand, while\nbelief-propagation techniques are often unable to deal with high-order models\ndue to the explosion in the size of messages, we avoid this problem by\napproximating our high-order prior model using a Gaussian mixture. By using\nsuch an approximation, we are able to inpaint images quickly while at the same\ntime retaining good visual results."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.2037v2", 
    "title": "An Affinity Propagation Based method for Vector Quantization Codebook   Design", 
    "arxiv-id": "0710.2037v2", 
    "author": "Qiao-liang Xiang", 
    "publish": "2007-10-10T15:12:20Z", 
    "summary": "In this paper, we firstly modify a parameter in affinity propagation (AP) to\nimprove its convergence ability, and then, we apply it to vector quantization\n(VQ) codebook design problem. In order to improve the quality of the resulted\ncodebook, we combine the improved AP (IAP) with the conventional LBG algorithm\nto generate an effective algorithm call IAP-LBG. According to the experimental\nresults, the proposed method not only enhances the convergence abilities but\nalso is capable of providing higher-quality codebooks than conventional LBG\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.2231v1", 
    "title": "Comparison and Combination of State-of-the-art Techniques for   Handwritten Character Recognition: Topping the MNIST Benchmark", 
    "arxiv-id": "0710.2231v1", 
    "author": "Daniel Keysers", 
    "publish": "2007-10-11T12:22:27Z", 
    "summary": "Although the recognition of isolated handwritten digits has been a research\ntopic for many years, it continues to be of interest for the research community\nand for commercial applications. We show that despite the maturity of the\nfield, different approaches still deliver results that vary enough to allow\nimprovements by using their combination. We do so by choosing four\nwell-motivated state-of-the-art recognition systems for which results on the\nstandard MNIST benchmark are available. When comparing the errors made, we\nobserve that the errors made differ between all four systems, suggesting the\nuse of classifier combination. We then determine the error rate of a\nhypothetical system that combines the output of the four systems. The result\nobtained in this manner is an error rate of 0.35% on the MNIST data, the best\nresult published so far. We furthermore discuss the statistical significance of\nthe combined result and of the results of the individual classifiers."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.0131v1", 
    "title": "Learning Similarity for Character Recognition and 3D Object Recognition", 
    "arxiv-id": "0712.0131v1", 
    "author": "Thomas M. Breuel", 
    "publish": "2007-12-02T10:02:01Z", 
    "summary": "I describe an approach to similarity motivated by Bayesian methods. This\nyields a similarity function that is learnable using a standard Bayesian\nmethods. The relationship of the approach to variable kernel and variable\nmetric methods is discussed. The approach is related to variable kernel\nExperimental results on character recognition and 3D object recognition are\npresented.."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.0136v1", 
    "title": "Learning View Generalization Functions", 
    "arxiv-id": "0712.0136v1", 
    "author": "Thomas M. Breuel", 
    "publish": "2007-12-02T10:54:40Z", 
    "summary": "Learning object models from views in 3D visual object recognition is usually\nformulated either as a function approximation problem of a function describing\nthe view-manifold of an object, or as that of learning a class-conditional\ndensity. This paper describes an alternative framework for learning in visual\nobject recognition, that of learning the view-generalization function. Using\nthe view-generalization function, an observer can perform Bayes-optimal 3D\nobject recognition given one or more 2D training views directly, without the\nneed for a separate model acquisition step. The paper shows that view\ngeneralization functions can be computationally practical by restating two\nwidely-used methods, the eigenspace and linear combination of views approaches,\nin a view generalization framework. The paper relates the approach to recent\nmethods for object recognition based on non-uniform blurring. The paper\npresents results both on simulated 3D ``paperclip'' objects and real-world\nimages from the COIL-100 database showing that useful view-generalization\nfunctions can be realistically be learned from a comparatively small number of\ntraining examples."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.0137v1", 
    "title": "View Based Methods can achieve Bayes-Optimal 3D Recognition", 
    "arxiv-id": "0712.0137v1", 
    "author": "Thomas M. Breuel", 
    "publish": "2007-12-02T11:02:37Z", 
    "summary": "This paper proves that visual object recognition systems using only 2D\nEuclidean similarity measurements to compare object views against previously\nseen views can achieve the same recognition performance as observers having\naccess to all coordinate information and able of using arbitrary 3D models\ninternally. Furthermore, it demonstrates that such systems do not require more\ntraining views than Bayes-optimal 3D model-based systems. For building computer\nvision systems, these results imply that using view-based or appearance-based\ntechniques with carefully constructed combination of evidence mechanisms may\nnot be at a disadvantage relative to 3D model-based systems. For computational\napproaches to human vision, they show that it is impossible to distinguish\nview-based and 3D model-based techniques for 3D object recognition solely by\ncomparing the performance achievable by human and 3D model-based systems.}"
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.1878v1", 
    "title": "Hierarchy construction schemes within the Scale set framework", 
    "arxiv-id": "0712.1878v1", 
    "author": "Luc Brun", 
    "publish": "2007-12-12T07:45:08Z", 
    "summary": "Segmentation algorithms based on an energy minimisation framework often\ndepend on a scale parameter which balances a fit to data and a regularising\nterm. Irregular pyramids are defined as a stack of graphs successively reduced.\nWithin this framework, the scale is often defined implicitly as the height in\nthe pyramid. However, each level of an irregular pyramid can not usually be\nreadily associated to the global optimum of an energy or a global criterion on\nthe base level graph. This last drawback is addressed by the scale set\nframework designed by Guigues. The methods designed by this author allow to\nbuild a hierarchy and to design cuts within this hierarchy which globally\nminimise an energy. This paper studies the influence of the construction scheme\nof the initial hierarchy on the resulting optimal cuts. We propose one\nsequential and one parallel method with two variations within both. Our\nsequential methods provide partitions near the global optima while parallel\nmethods require less execution times than the sequential method of Guigues even\non sequential machines."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.2923v1", 
    "title": "A Class of LULU Operators on Multi-Dimensional Arrays", 
    "arxiv-id": "0712.2923v1", 
    "author": "Inger Plaskitt", 
    "publish": "2007-12-18T10:43:23Z", 
    "summary": "The LULU operators for sequences are extended to multi-dimensional arrays via\nthe morphological concept of connection in a way which preserves their\nessential properties, e.g. they are separators and form a four element fully\nordered semi-group. The power of the operators is demonstrated by deriving a\ntotal variation preserving discrete pulse decomposition of images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.4015v1", 
    "title": "A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased   Estimators", 
    "arxiv-id": "0712.4015v1", 
    "author": "Jaideva C. Goswami", 
    "publish": "2007-12-24T17:11:56Z", 
    "summary": "This paper proposes a novel method for segmentation of images by hierarchical\nmultilevel thresholding. The method is global, agglomerative in nature and\ndisregards pixel locations. It involves the optimization of the ratio of the\nunbiased estimators of within class to between class variances. We obtain a\nrecursive relation at each step for the variances which expedites the process.\nThe efficacy of the method is shown in a comparison with some well-known\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0801.4807v1", 
    "title": "Automatic Text Area Segmentation in Natural Images", 
    "arxiv-id": "0801.4807v1", 
    "author": "Edward J. Delp", 
    "publish": "2008-01-31T01:46:32Z", 
    "summary": "We present a hierarchical method for segmenting text areas in natural images.\nThe method assumes that the text is written with a contrasting color on a more\nor less uniform background. But no assumption is made regarding the language or\ncharacter set used to write the text. In particular, the text can contain\nsimple graphics or symbols. The key feature of our approach is that we first\nconcentrate on finding the background of the text, before testing whether there\nis actually text on the background. Since uniform areas are easy to find in\nnatural images, and since text backgrounds define areas which contain \"holes\"\n(where the text is written) we thus look for uniform areas containing \"holes\"\nand label them as text backgrounds candidates. Each candidate area is then\nfurther tested for the presence of text within its convex hull. We tested our\nmethod on a database of 65 images including English and Urdu text. The method\ncorrectly segmented all the text areas in 63 of these images, and in only 4 of\nthese were areas that do not contain text also segmented."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0802.3528v1", 
    "title": "Wavelet and Curvelet Moments for Image Classification: Application to   Aggregate Mixture Grading", 
    "arxiv-id": "0802.3528v1", 
    "author": "Jean-Luc Starck", 
    "publish": "2008-02-24T18:25:51Z", 
    "summary": "We show the potential for classifying images of mixtures of aggregate, based\nthemselves on varying, albeit well-defined, sizes and shapes, in order to\nprovide a far more effective approach compared to the classification of\nindividual sizes and shapes. While a dominant (additive, stationary) Gaussian\nnoise component in image data will ensure that wavelet coefficients are of\nGaussian distribution, long tailed distributions (symptomatic, for example, of\nextreme values) may well hold in practice for wavelet coefficients. Energy (2nd\norder moment) has often been used for image characterization for image\ncontent-based retrieval, and higher order moments may be important also, not\nleast for capturing long tailed distributional behavior. In this work, we\nassess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet\nand curvelet transform -- coefficients as features. As analysis methodology,\ntaking account of image types, multiresolution transforms, and moments of\ncoefficients in the scales or bands, we use correspondence analysis as well as\nk-nearest neighbors supervised classification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0803.1586v1", 
    "title": "Spatio-activity based object detection", 
    "arxiv-id": "0803.1586v1", 
    "author": "Jeroen Vendrig", 
    "publish": "2008-03-11T13:40:42Z", 
    "summary": "We present the SAMMI lightweight object detection method which has a high\nlevel of accuracy and robustness, and which is able to operate in an\nenvironment with a large number of cameras. Background modeling is based on DCT\ncoefficients provided by cameras. Foreground detection uses similarity in\ntemporal characteristics of adjacent blocks of pixels, which is a\ncomputationally inexpensive way to make use of object coherence. Scene model\nupdating uses the approximated median method for improved performance.\nEvaluation at pixel level and application level shows that SAMMI object\ndetection performs better and faster than the conventional Mixture of Gaussians\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0803.2812v2", 
    "title": "Using Spatially Varying Pixels Exposures and Bayer-covered Photosensors   for High Dynamic Range Imaging", 
    "arxiv-id": "0803.2812v2", 
    "author": "Mikhail V. Konnik", 
    "publish": "2008-03-19T14:55:15Z", 
    "summary": "The method of a linear high dynamic range imaging using solid-state\nphotosensors with Bayer colour filters array is provided in this paper. Using\ninformation from neighbour pixels, it is possible to reconstruct linear images\nwith wide dynamic range from the oversaturated images. Bayer colour filters\narray is considered as an array of neutral filters in a quasimonochromatic\nlight. If the camera's response function to the desirable light source is known\nthen one can calculate correction coefficients to reconstruct oversaturated\nimages. Reconstructed images are linearized in order to provide a linear high\ndynamic range images for optical-digital imaging systems. The calibration\nprocedure for obtaining the camera's response function to the desired light\nsource is described. Experimental results of the reconstruction of the images\nfrom the oversaturated images are presented for red, green, and blue\nquasimonochromatic light sources. Quantitative analysis of the accuracy of the\nreconstructed images is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0804.1982v2", 
    "title": "Linear Time Recognition Algorithms for Topological Invariants in 3D", 
    "arxiv-id": "0804.1982v2", 
    "author": "Yongwu Rong", 
    "publish": "2008-04-12T03:13:33Z", 
    "summary": "In this paper, we design linear time algorithms to recognize and determine\ntopological invariants such as the genus and homology groups in 3D. These\nproperties can be used to identify patterns in 3D image recognition. This has\ntremendous amount of applications in 3D medical image analysis. Our method is\nbased on cubical images with direct adjacency, also called (6,26)-connectivity\nimages in discrete geometry. According to the fact that there are only six\ntypes of local surface points in 3D and a discrete version of the well-known\nGauss-Bonnett Theorem in differential geometry, we first determine the genus of\na closed 2D-connected component (a closed digital surface). Then, we use\nAlexander duality to obtain the homology groups of a 3D object in 3D space."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.1854v2", 
    "title": "A New Algorithm for Interactive Structural Image Segmentation", 
    "arxiv-id": "0805.1854v2", 
    "author": "Isabelle Bloch", 
    "publish": "2008-05-13T13:39:19Z", 
    "summary": "This paper proposes a novel algorithm for the problem of structural image\nsegmentation through an interactive model-based approach. Interaction is\nexpressed in the model creation, which is done according to user traces drawn\nover a given input image. Both model and input are then represented by means of\nattributed relational graphs derived on the fly. Appearance features are taken\ninto account as object attributes and structural properties are expressed as\nrelational attributes. To cope with possible topological differences between\nboth graphs, a new structure called the deformation graph is introduced. The\nsegmentation process corresponds to finding a labelling of the input graph that\nminimizes the deformations introduced in the model when it is updated with\ninput information. This approach has shown to be faster than other segmentation\nmethods, with competitive output quality. Therefore, the method solves the\nproblem of multiple label segmentation in an efficient way. Encouraging results\non both natural and target-specific color images, as well as examples showing\nthe reusability of the model, are presented and discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.2324v1", 
    "title": "A multilateral filtering method applied to airplane runway image", 
    "arxiv-id": "0805.2324v1", 
    "author": "Wang Run-quan", 
    "publish": "2008-05-15T13:15:08Z", 
    "summary": "By considering the features of the airport runway image filtering, an\nimproved bilateral filtering method was proposed which can remove noise with\nedge preserving. Firstly the steerable filtering decomposition is used to\ncalculate the sub-band parameters of 4 orients, and the texture feature matrix\nis then obtained from the sub-band local median energy. The texture similar,\nthe spatial closer and the color similar functions are used to filter the\nimage.The effect of the weighting function parameters is qualitatively analyzed\nalso. In contrast with the standard bilateral filter and the simulation results\nfor the real airport runway image show that the multilateral filtering is more\neffective than the standard bilateral filtering."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.2690v1", 
    "title": "Increasing Linear Dynamic Range of Commercial Digital Photocamera Used   in Imaging Systems with Optical Coding", 
    "arxiv-id": "0805.2690v1", 
    "author": "S. N. Starikov", 
    "publish": "2008-05-17T17:15:26Z", 
    "summary": "Methods of increasing linear optical dynamic range of commercial photocamera\nfor optical-digital imaging systems are described. Use of such methods allows\nto use commercial photocameras for optical measurements. Experimental results\nare reported."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.3217v1", 
    "title": "Statistical region-based active contours with exponential family   observations", 
    "arxiv-id": "0805.3217v1", 
    "author": "Marinette Revenu", 
    "publish": "2008-05-21T07:54:07Z", 
    "summary": "In this paper, we focus on statistical region-based active contour models\nwhere image features (e.g. intensity) are random variables whose distribution\nbelongs to some parametric family (e.g. exponential) rather than confining\nourselves to the special Gaussian case. Using shape derivation tools, our\neffort focuses on constructing a general expression for the derivative of the\nenergy (with respect to a domain) and derive the corresponding evolution speed.\nA general result is stated within the framework of multi-parameter exponential\nfamily. More particularly, when using Maximum Likelihood estimators, the\nevolution speed has a closed-form expression that depends simply on the\nprobability density function, while complicating additive terms appear when\nusing other estimators, e.g. moments method. Experimental results on both\nsynthesized and real images demonstrate the applicability of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.3218v1", 
    "title": "Region-based active contour with noise and shape priors", 
    "arxiv-id": "0805.3218v1", 
    "author": "Eric Saloux", 
    "publish": "2008-05-21T08:06:01Z", 
    "summary": "In this paper, we propose to combine formally noise and shape priors in\nregion-based active contours. On the one hand, we use the general framework of\nexponential family as a prior model for noise. On the other hand, translation\nand scale invariant Legendre moments are considered to incorporate the shape\nprior (e.g. fidelity to a reference shape). The combination of the two prior\nterms in the active contour functional yields the final evolution equation\nwhose evolution speed is rigorously derived using shape derivative tools.\nExperimental results on both synthetic images and real life cardiac echography\ndata clearly demonstrate the robustness to initialization and noise,\nflexibility and large potential applicability of our segmentation algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0805.3964v2", 
    "title": "DimReduction - Interactive Graphic Environment for Dimensionality   Reduction", 
    "arxiv-id": "0805.3964v2", 
    "author": "Roberto M. Cesar-Jr", 
    "publish": "2008-05-26T14:16:06Z", 
    "summary": "Feature selection is a pattern recognition approach to choose important\nvariables according to some criteria to distinguish or explain certain\nphenomena. There are many genomic and proteomic applications which rely on\nfeature selection to answer questions such as: selecting signature genes which\nare informative about some biological state, e.g. normal tissues and several\ntypes of cancer; or defining a network of prediction or inference among\nelements such as genes, proteins, external stimuli and other elements of\ninterest. In these applications, a recurrent problem is the lack of samples to\nperform an adequate estimate of the joint probabilities between element states.\nA myriad of feature selection algorithms and criterion functions are proposed,\nalthough it is difficult to point the best solution in general. The intent of\nthis work is to provide an open-source multiplataform graphical environment to\napply, test and compare many feature selection approaches suitable to be used\nin bioinformatics problems."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.0689v1", 
    "title": "Directional Cross Diamond Search Algorithm for Fast Block Motion   Estimation", 
    "arxiv-id": "0806.0689v1", 
    "author": "Li Zhang", 
    "publish": "2008-06-04T05:05:19Z", 
    "summary": "In block-matching motion estimation (BMME), the search patterns have a\nsignificant impact on the algorithm's performance, both the search speed and\nthe search quality. The search pattern should be designed to fit the motion\nvector probability (MVP) distribution characteristics of the real-world\nsequences. In this paper, we build a directional model of MVP distribution to\ndescribe the directional-center-biased characteristic of the MVP distribution\nand the directional characteristics of the conditional MVP distribution more\nexactly based on the detailed statistical data of motion vectors of eighteen\npopular sequences. Three directional search patterns are firstly designed by\nutilizing the directional characteristics and they are the smallest search\npatterns among the popular ones. A new algorithm is proposed using the\nhorizontal cross search pattern as the initial step and the horizontal/vertical\ndiamond search pattern as the subsequent step for the fast BMME, which is\ncalled the directional cross diamond search (DCDS) algorithm. The DCDS\nalgorithm can obtain the motion vector with fewer search points than CDS, DS or\nHEXBS while maintaining the similar or even better search quality. The gain on\nspeedup of DCDS over CDS or DS can be up to 54.9%. The simulation results show\nthat DCDS is efficient, effective and robust, and it can always give the faster\nsearch speed on different sequences than other fast block-matching algorithm in\ncommon use."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.1446v1", 
    "title": "Fast Wavelet-Based Visual Classification", 
    "arxiv-id": "0806.1446v1", 
    "author": "Jean-Jacques Slotine", 
    "publish": "2008-06-08T10:15:04Z", 
    "summary": "We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.1984v1", 
    "title": "Classification of curves in 2D and 3D via affine integral signatures", 
    "arxiv-id": "0806.1984v1", 
    "author": "H. Krim", 
    "publish": "2008-06-12T01:12:25Z", 
    "summary": "We propose a robust classification algorithm for curves in 2D and 3D, under\nthe special and full groups of affine transformations. To each plane or spatial\ncurve we assign a plane signature curve. Curves, equivalent under an affine\ntransformation, have the same signature. The signatures introduced in this\npaper are based on integral invariants, which behave much better on noisy\nimages than classically known differential invariants. The comparison with\nother types of invariants is given in the introduction. Though the integral\ninvariants for planar curves were known before, the affine integral invariants\nfor spatial curves are proposed here for the first time. Using the inductive\nvariation of the moving frame method we compute affine invariants in terms of\nEuclidean invariants. We present two types of signatures, the global signature\nand the local signature. Both signatures are independent of parameterization\n(curve sampling). The global signature depends on the choice of the initial\npoint and does not allow us to compare fragments of curves, and is therefore\nsensitive to occlusions. The local signature, although is slightly more\nsensitive to noise, is independent of the choice of the initial point and is\nnot sensitive to occlusions in an image. It helps establish local equivalence\nof curves. The robustness of these invariants and signatures in their\napplication to the problem of classification of noisy spatial curves extracted\nfrom a 3D object is analyzed."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.3885v1", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   1: the framework", 
    "arxiv-id": "0806.3885v1", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T13:43:06Z", 
    "summary": "Adams and Bishop have proposed in 1994 a novel region growing algorithm\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\nintroduces a framework to implement an algorithm using SRGPA. This framework is\nbuilt around two concepts: localization and organization of applied action.\nThis conceptualization gives a quick implementation of algorithms, a direct\ntranslation between the mathematical idea and the numerical implementation, and\nan improvement of algorithms efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.3887v1", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   2: how to localize a final partition invariant about the seeded region   initialisation order", 
    "arxiv-id": "0806.3887v1", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T13:34:15Z", 
    "summary": "In the previous paper, we have conceptualized the localization and the\norganization of seeded region growing by pixels aggregation (SRGPA) but we do\nnot give the issue when there is a collision between two distinct regions\nduring the growing process. In this paper, we propose two implementations to\nmanage two classical growing processes: one without a boundary region region to\ndivide the other regions and another with. Unfortunately, as noticed by Mehnert\nand Jakway (1997), this partition depends on the seeded region initialisation\norder (SRIO). We propose a growing process, invariant about SRIO such as the\nboundary region is the set of ambiguous pixels."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.3928v1", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   3: a wide range of algorithms", 
    "arxiv-id": "0806.3928v1", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T17:02:47Z", 
    "summary": "In the two previous papers of this serie, we have created a library, called\nPopulation, dedicated to seeded region growing by pixels aggregation and we\nhave proposed different growing processes to get a partition with or without a\nboundary region to divide the other regions or to get a partition invariant\nabout the seeded region initialisation order. Using this work, we implement\nsome algorithms belonging to the field of SRGPA using this library and these\ngrowing processes."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0806.3939v2", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   4: Simple, generic and robust extraction of grains in granular materials   obtained by X-ray tomography", 
    "arxiv-id": "0806.3939v2", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T17:40:25Z", 
    "summary": "This paper proposes a simple, generic and robust method to extract the grains\nfrom experimental tridimensionnal images of granular materials obtained by\nX-ray tomography. This extraction has two steps: segmentation and splitting.\nFor the segmentation step, if there is a sufficient contrast between the\ndifferent components, a classical threshold procedure followed by a succession\nof morphological filters can be applied. If not, and if the boundary needs to\nbe localized precisely, a watershed transformation controlled by labels is\napplied. The basement of this transformation is to localize a label included in\nthe component and another label in the component complementary. A \"soft\"\nthreshold following by an opening is applied on the initial image to localize a\nlabel in a component. For any segmentation procedure, the visualisation shows a\nproblem: some groups of two grains, close one to each other, become connected.\nSo if a classical cluster procedure is applied on the segmented binary image,\nthese numerical connected grains are considered as a single grain. To overcome\nthis problem, we applied a procedure introduced by L. Vincent in 1993. This\ngrains extraction is tested for various complexes porous media and granular\nmaterial, to predict various properties (diffusion, electrical conductivity,\ndeformation field) in a good agreement with experiment data."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0807.2047v3", 
    "title": "The Five Points Pose Problem : A New and Accurate Solution Adapted to   any Geometric Configuration", 
    "arxiv-id": "0807.2047v3", 
    "author": "Nicolas Paparoditis", 
    "publish": "2008-07-13T18:37:06Z", 
    "summary": "The goal of this paper is to estimate directly the rotation and translation\nbetween two stereoscopic images with the help of five homologous points. The\nmethodology presented does not mix the rotation and translation parameters,\nwhich is comparably an important advantage over the methods using the\nwell-known essential matrix. This results in correct behavior and accuracy for\nsituations otherwise known as quite unfavorable, such as planar scenes, or\npanoramic sets of images (with a null base length), while providing quite\ncomparable results for more \"standard\" cases. The resolution of the algebraic\npolynomials resulting from the modeling of the coplanarity constraint is made\nwith the help of powerful algebraic solver tools (the Groebner bases and the\nRational Univariate Representation)."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0807.4701v1", 
    "title": "An image processing analysis of skin textures", 
    "arxiv-id": "0807.4701v1", 
    "author": "R. Marazzato", 
    "publish": "2008-07-29T16:28:44Z", 
    "summary": "Colour and coarseness of skin are visually different. When image processing\nis involved in the skin analysis, it is important to quantitatively evaluate\nsuch differences using texture features. In this paper, we discuss a texture\nanalysis and measurements based on a statistical approach to the pattern\nrecognition. Grain size and anisotropy are evaluated with proper diagrams. The\npossibility to determine the presence of pattern defects is also discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0808.2227v1", 
    "title": "Higher Order Moments Generation by Mellin Transform for Compound Models   of Clutter", 
    "arxiv-id": "0808.2227v1", 
    "author": "C Bhattacharya", 
    "publish": "2008-08-16T01:34:48Z", 
    "summary": "The compound models of clutter statistics are found suitable to describe the\nnonstationary nature of radar backscattering from high-resolution observations.\nIn this letter, we show that the properties of Mellin transform can be utilized\nto generate higher order moments of simple and compound models of clutter\nstatistics in a compact manner."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0809.1802v1", 
    "title": "Automatic Identification and Data Extraction from 2-Dimensional Plots in   Digital Documents", 
    "arxiv-id": "0809.1802v1", 
    "author": "C. L. Giles", 
    "publish": "2008-09-10T14:43:37Z", 
    "summary": "Most search engines index the textual content of documents in digital\nlibraries. However, scholarly articles frequently report important findings in\nfigures for visual impact and the contents of these figures are not indexed.\nThese contents are often invaluable to the researcher in various fields, for\nthe purposes of direct comparison with their own work. Therefore, searching for\nfigures and extracting figure data are important problems. To the best of our\nknowledge, there exists no tool to automatically extract data from figures in\ndigital documents. If we can extract data from these images automatically and\nstore them in a database, an end-user can query and combine data from multiple\ndigital documents simultaneously and efficiently. We propose a framework based\non image analysis and machine learning to extract information from 2-D plot\nimages and store them in a database. The proposed algorithm identifies a 2-D\nplot and extracts the axis labels, legend and the data points from the 2-D\nplot. We also segregate overlapping shapes that correspond to different data\npoints. We demonstrate performance of individual algorithms, using a\ncombination of generated and real-life images."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0809.3083v1", 
    "title": "Supervised Dictionary Learning", 
    "arxiv-id": "0809.3083v1", 
    "author": "Andrew Zisserman", 
    "publish": "2008-09-18T07:16:34Z", 
    "summary": "It is now well established that sparse signal models are well suited to\nrestoration tasks and can effectively be learned from audio, image, and video\ndata. Recent research has been aimed at learning discriminative sparse models\ninstead of purely reconstructive ones. This paper proposes a new step in that\ndirection, with a novel sparse representation for signals belonging to\ndifferent classes in terms of a shared dictionary and multiple class-decision\nfunctions. The linear variant of the proposed model admits a simple\nprobabilistic interpretation, while its most general variant admits an\ninterpretation in terms of kernels. An optimization framework for learning all\nthe components of the proposed model is presented, along with experimental\nresults on standard handwritten digit and texture classification tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0809.3690v1", 
    "title": "Modeling and Control with Local Linearizing Nadaraya Watson Regression", 
    "arxiv-id": "0809.3690v1", 
    "author": "Clemens G\u00fchmann", 
    "publish": "2008-09-22T12:08:24Z", 
    "summary": "Black box models of technical systems are purely descriptive. They do not\nexplain why a system works the way it does. Thus, black box models are\ninsufficient for some problems. But there are numerous applications, for\nexample, in control engineering, for which a black box model is absolutely\nsufficient. In this article, we describe a general stochastic framework with\nwhich such models can be built easily and fully automated by observation.\nFurthermore, we give a practical example and show how this framework can be\nused to model and control a motorcar powertrain."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0810.3579v1", 
    "title": "Hierarchical Bag of Paths for Kernel Based Shape Classification", 
    "arxiv-id": "0810.3579v1", 
    "author": "Luc Brun", 
    "publish": "2008-10-20T15:13:18Z", 
    "summary": "Graph kernels methods are based on an implicit embedding of graphs within a\nvector space of large dimension. This implicit embedding allows to apply to\ngraphs methods which where until recently solely reserved to numerical data.\nWithin the shape classification framework, graphs are often produced by a\nskeletonization step which is sensitive to noise. We propose in this paper to\nintegrate the robustness to structural noise by using a kernel based on a bag\nof path where each path is associated to a hierarchy encoding successive\nsimplifications of the path. Several experiments prove the robustness and the\nflexibility of our approach compared to alternative shape classification\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0810.4426v2", 
    "title": "Camera distortion self-calibration using the plumb-line constraint and   minimal Hough entropy", 
    "arxiv-id": "0810.4426v2", 
    "author": "Rohan Loveland", 
    "publish": "2008-10-24T10:50:59Z", 
    "summary": "In this paper we present a simple and robust method for self-correction of\ncamera distortion using single images of scenes which contain straight lines.\nSince the most common distortion can be modelled as radial distortion, we\nillustrate the method using the Harris radial distortion model, but the method\nis applicable to any distortion model. The method is based on transforming the\nedgels of the distorted image to a 1-D angular Hough space, and optimizing the\ndistortion correction parameters which minimize the entropy of the\ncorresponding normalized histogram. Properly corrected imagery will have fewer\ncurved lines, and therefore less spread in Hough space. Since the method does\nnot rely on any image structure beyond the existence of edgels sharing some\ncommon orientations and does not use edge fitting, it is applicable to a wide\nvariety of image types. For instance, it can be applied equally well to images\nof texture with weak but dominant orientations, or images with strong vanishing\npoints. Finally, the method is performed on both synthetic and real data\nrevealing that it is particularly robust to noise."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0810.4617v2", 
    "title": "Graph-based classification of multiple observation sets", 
    "arxiv-id": "0810.4617v2", 
    "author": "Pascal Frossard", 
    "publish": "2008-10-25T16:02:32Z", 
    "summary": "We consider the problem of classification of an object given multiple\nobservations that possibly include different transformations. The possible\ntransformations of the object generally span a low-dimensional manifold in the\noriginal signal space. We propose to take advantage of this manifold structure\nfor the effective classification of the object represented by the observation\nset. In particular, we design a low complexity solution that is able to exploit\nthe properties of the data manifolds with a graph-based algorithm. Hence, we\nformulate the computation of the unknown label matrix as a smoothing process on\nthe manifold under the constraint that all observations represent an object of\none single class. It results into a discrete optimization problem, which can be\nsolved by an efficient and low complexity algorithm. We demonstrate the\nperformance of the proposed graph-based algorithm in the classification of sets\nof multiple images. Moreover, we show its high potential in video-based face\nrecognition, where it outperforms state-of-the-art solutions that fall short of\nexploiting the manifold structure of the face image data sets."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0810.5325v1", 
    "title": "3D Face Recognition with Sparse Spherical Representations", 
    "arxiv-id": "0810.5325v1", 
    "author": "P. Frossard", 
    "publish": "2008-10-29T17:43:54Z", 
    "summary": "This paper addresses the problem of 3D face recognition using simultaneous\nsparse approximations on the sphere. The 3D face point clouds are first aligned\nwith a novel and fully automated registration process. They are then\nrepresented as signals on the 2D sphere in order to preserve depth and geometry\ninformation. Next, we implement a dimensionality reduction process with\nsimultaneous sparse approximations and subspace projection. It permits to\nrepresent each 3D face by only a few spherical functions that are able to\ncapture the salient facial characteristics, and hence to preserve the\ndiscriminant facial information. We eventually perform recognition by effective\nmatching in the reduced space, where Linear Discriminant Analysis can be\nfurther activated for improved recognition performance. The 3D face recognition\nalgorithm is evaluated on the FRGC v.1.0 data set, where it is shown to\noutperform classical state-of-the-art solutions that work with depth images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0811.4699v2", 
    "title": "Mapping Images with the Coherence Length Diagrams", 
    "arxiv-id": "0811.4699v2", 
    "author": "R. Marazzato", 
    "publish": "2008-11-28T12:11:21Z", 
    "summary": "Statistical pattern recognition methods based on the Coherence Length Diagram\n(CLD) have been proposed for medical image analyses, such as quantitative\ncharacterisation of human skin textures, and for polarized light microscopy of\nliquid crystal textures. Further investigations are made on image maps\noriginated from such diagram and some examples related to irregularity of\nmicrostructures are shown."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0812.1340v2", 
    "title": "Obtaining Depth Maps From Color Images By Region Based Stereo Matching   Algorithms", 
    "arxiv-id": "0812.1340v2", 
    "author": "B. Baykant Alagoz", 
    "publish": "2008-12-07T11:42:41Z", 
    "summary": "In the paper, region based stereo matching algorithms are developed for\nextraction depth information from two color stereo image pair. A filter\neliminating unreliable disparity estimation was used for increasing reliability\nof the disparity map. Obtained results by algorithms were represented and\ncompared."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0812.2892v1", 
    "title": "Sparse Component Analysis (SCA) in Random-valued and Salt and Pepper   Noise Removal", 
    "arxiv-id": "0812.2892v1", 
    "author": "Massoud. Babaie-Zadeh", 
    "publish": "2008-12-15T19:24:45Z", 
    "summary": "In this paper, we propose a new method for impulse noise removal from images.\nIt uses the sparsity of images in the Discrete Cosine Transform (DCT) domain.\nThe zeros in this domain give us the exact mathematical equation to reconstruct\nthe pixels that are corrupted by random-value impulse noises. The proposed\nmethod can also detect and correct the corrupted pixels. Moreover, in a simpler\ncase that salt and pepper noise is the brightest and darkest pixels in the\nimage, we propose a simpler version of our method. In addition to the proposed\nmethod, we suggest a combination of the traditional median filter method with\nour method to yield better results when the percentage of the corrupted samples\nis high."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0901.4953v1", 
    "title": "A Keygraph Classification Framework for Real-Time Object Detection", 
    "arxiv-id": "0901.4953v1", 
    "author": "Roberto M. Cesar Jr", 
    "publish": "2009-01-30T19:38:44Z", 
    "summary": "In this paper, we propose a new approach for keypoint-based object detection.\nTraditional keypoint-based methods consist in classifying individual points and\nusing pose estimation to discard misclassifications. Since a single point\ncarries no relational features, such methods inherently restrict the usage of\nstructural information to the pose estimation phase. Therefore, the classifier\nconsiders purely appearance-based feature vectors, thus requiring\ncomputationally expensive feature extraction or complex probabilistic modelling\nto achieve satisfactory robustness. In contrast, our approach consists in\nclassifying graphs of keypoints, which incorporates structural information\nduring the classification phase and allows the extraction of simpler feature\nvectors that are naturally robust. In the present work, 3-vertices graphs have\nbeen considered, though the methodology is general and larger order graphs may\nbe adopted. Successful experimental results obtained for real-time object\ndetection in video sequences are reported."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0902.2788v2", 
    "title": "Using SLP Neural Network to Persian Handwritten Digits Recognition", 
    "arxiv-id": "0902.2788v2", 
    "author": "Seyed Mohammad Ahadi", 
    "publish": "2009-02-16T21:13:35Z", 
    "summary": "This paper has been withdrawn by the author ali pourmohammad."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0902.4073v1", 
    "title": "Dipole and Quadrupole Moments in Image Processing", 
    "arxiv-id": "0902.4073v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-02-24T20:34:43Z", 
    "summary": "This paper proposes an algorithm for image processing, obtained by adapting\nto image maps the definitions of two well-known physical quantities. These\nquantities are the dipole and quadrupole moments of a charge distribution. We\nwill see how it is possible to define dipole and quadrupole moments for the\ngray-tone maps and apply them in the development of algorithms for edge\ndetection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0902.4663v1", 
    "title": "Dipole Vectors in Images Processing", 
    "arxiv-id": "0902.4663v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-02-26T18:42:30Z", 
    "summary": "Instead of evaluating the gradient field of the brightness map of an image,\nwe propose the use of dipole vectors. This approach is obtained by adapting to\nthe image gray-tone distribution the definition of the dipole moment of charge\ndistributions. We will show how to evaluate the dipoles and obtain a vector\nfield, which can be a good alternative to the gradient field in pattern\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0903.0134v2", 
    "title": "Recognition of Regular Shapes in Satelite Images", 
    "arxiv-id": "0903.0134v2", 
    "author": "Ali Pourmohammad", 
    "publish": "2009-03-01T11:10:27Z", 
    "summary": "This paper has been withdrawn by the author ali pourmohammad."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0903.0538v1", 
    "title": "Real-time Texture Error Detection", 
    "arxiv-id": "0903.0538v1", 
    "author": "Adriana Balta", 
    "publish": "2009-03-03T14:08:24Z", 
    "summary": "This paper advocates an improved solution for real-time error detection of\ntexture errors that occurs in the production process in textile industry. The\nresearch is focused on the mono-color products with 3D texture model (Jaquard\nfabrics). This is a more difficult task than, for example, 2D multicolor\ntextures."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0903.5045v1", 
    "title": "Digital Restoration of Ancient Papyri", 
    "arxiv-id": "0903.5045v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-03-30T06:00:15Z", 
    "summary": "Image processing can be used for digital restoration of ancient papyri, that\nis, for a restoration performed on their digital images. The digital\nmanipulation allows reducing the background signals and enhancing the\nreadability of texts. In the case of very old and damaged documents, this is\nfundamental for identification of the patterns of letters. Some examples of\nrestoration, obtained with an image processing which uses edges detection and\nFourier filtering, are shown. One of them concerns 7Q5 fragment of the Dead Sea\nScrolls."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0904.0962v1", 
    "title": "Color Dipole Moments for Edge Detection", 
    "arxiv-id": "0904.0962v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-04-06T16:25:08Z", 
    "summary": "Dipole and higher moments are physical quantities used to describe a charge\ndistribution. In analogy with electromagnetism, it is possible to define the\ndipole moments for a gray-scale image, according to the single aspect of a\ngray-tone map. In this paper we define the color dipole moments for color\nimages. For color maps in fact, we have three aspects, the three primary\ncolors, to consider. Associating three color charges to each pixel, color\ndipole moments can be easily defined and used for edge detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0904.1613v1", 
    "title": "On the closed-form solution of the rotation matrix arising in computer   vision problems", 
    "arxiv-id": "0904.1613v1", 
    "author": "Xubo Song", 
    "publish": "2009-04-09T22:15:25Z", 
    "summary": "We show the closed-form solution to the maximization of trace(A'R), where A\nis given and R is unknown rotation matrix. This problem occurs in many computer\nvision tasks involving optimal rotation matrix estimation. The solution has\nbeen continuously reinvented in different fields as part of specific problems.\nWe summarize the historical evolution of the problem and present the general\nproof of the solution. We contribute to the proof by considering the degenerate\ncases of A and discuss the uniqueness of R."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.46", 
    "link": "http://arxiv.org/pdf/0905.2635v1", 
    "title": "Point-Set Registration: Coherent Point Drift", 
    "arxiv-id": "0905.2635v1", 
    "author": "Xubo Song", 
    "publish": "2009-05-15T22:28:00Z", 
    "summary": "Point set registration is a key component in many computer vision tasks. The\ngoal of point set registration is to assign correspondences between two sets of\npoints and to recover the transformation that maps one point set to the other.\nMultiple factors, including an unknown non-rigid spatial transformation, large\ndimensionality of point set, noise and outliers, make the point set\nregistration a challenging problem. We introduce a probabilistic method, called\nthe Coherent Point Drift (CPD) algorithm, for both rigid and non-rigid point\nset registration. We consider the alignment of two point sets as a probability\ndensity estimation problem. We fit the GMM centroids (representing the first\npoint set) to the data (the second point set) by maximizing the likelihood. We\nforce the GMM centroids to move coherently as a group to preserve the\ntopological structure of the point sets. In the rigid case, we impose the\ncoherence constraint by re-parametrization of GMM centroid locations with rigid\nparameters and derive a closed form solution of the maximization step of the EM\nalgorithm in arbitrary dimensions. In the non-rigid case, we impose the\ncoherence constraint by regularizing the displacement field and using the\nvariational calculus to derive the optimal transformation. We also introduce a\nfast algorithm that reduces the method computation complexity to linear. We\ntest the CPD algorithm for both rigid and non-rigid transformations in the\npresence of noise, outliers and missing points, where CPD shows accurate\nresults and outperforms current state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.46", 
    "link": "http://arxiv.org/pdf/0905.2924v1", 
    "title": "Colorization of Natural Images via L1 Optimization", 
    "arxiv-id": "0905.2924v1", 
    "author": "Alexander Balinsky", 
    "publish": "2009-05-18T16:07:52Z", 
    "summary": "Natural images in the colour space YUV have been observed to have a\nnon-Gaussian, heavy tailed distribution (called 'sparse') when the filter\nG(U)(r) = U(r) - sum_{s \\in N(r)} w{(Y)_{rs}} U(s), is applied to the\nchromacity channel U (and equivalently to V), where w is a weighting function\nconstructed from the intensity component Y [1]. In this paper we develop\nBayesian analysis of the colorization problem using the filter response as a\nregularization term to arrive at a non-convex optimization problem. This\nproblem is convexified using L1 optimization which often gives the same results\nfor sparse signals [2]. It is observed that L1 optimization, in many cases,\nover-performs the famous colorization algorithm by Levin et al [3]."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.46", 
    "link": "http://arxiv.org/pdf/0905.2958v3", 
    "title": "A statistical learning approach to color demosaicing", 
    "arxiv-id": "0905.2958v3", 
    "author": "J. H. Oaknin", 
    "publish": "2009-05-18T19:44:58Z", 
    "summary": "A statistical learning/inference framework for color demosaicing is\npresented. We start with simplistic assumptions about color constancy, and\nrecast color demosaicing as a blind linear inverse problem: color parameterizes\nthe unknown kernel, while brightness takes on the role of a latent variable. An\nexpectation-maximization algorithm naturally suggests itself for the estimation\nof them both. Then, as we gradually broaden the family of hypothesis where\ncolor is learned, we let our demosaicing behave adaptively, in a manner that\nreflects our prior knowledge about the statistics of color images. We show that\nwe can incorporate realistic, learned priors without essentially changing the\ncomplexity of the simple expectation-maximization algorithm we started with."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0905.3964v1", 
    "title": "A New Solution to the Relative Orientation Problem using only 3 Points   and the Vertical Direction", 
    "arxiv-id": "0905.3964v1", 
    "author": "JeanPierre Guedon", 
    "publish": "2009-05-25T08:29:01Z", 
    "summary": "This paper presents a new method to recover the relative pose between two\nimages, using three points and the vertical direction information. The vertical\ndirection can be determined in two ways: 1- using direct physical measurement\nlike IMU (inertial measurement unit), 2- using vertical vanishing point. This\nknowledge of the vertical direction solves 2 unknowns among the 3 parameters of\nthe relative rotation, so that only 3 homologous points are requested to\nposition a couple of images. Rewriting the coplanarity equations leads to a\nsimpler solution. The remaining unknowns resolution is performed by an\nalgebraic method using Grobner bases. The elements necessary to build a\nspecific algebraic solver are given in this paper, allowing for a real-time\nimplementation. The results on real and synthetic data show the efficiency of\nthis method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.1763v2", 
    "title": "Segmentation of Facial Expressions Using Semi-Definite Programming and   Generalized Principal Component Analysis", 
    "arxiv-id": "0906.1763v2", 
    "author": "Wassim M. Haddad", 
    "publish": "2009-06-09T19:50:10Z", 
    "summary": "In this paper, we use semi-definite programming and generalized principal\ncomponent analysis (GPCA) to distinguish between two or more different facial\nexpressions. In the first step, semi-definite programming is used to reduce the\ndimension of the image data and \"unfold\" the manifold which the data points\n(corresponding to facial expressions) reside on. Next, GPCA is used to fit a\nseries of subspaces to the data points and associate each data point with a\nsubspace. Data points that belong to the same subspace are claimed to belong to\nthe same facial expression category. An example is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.2770v1", 
    "title": "Combinatorial pyramids and discrete geometry for energy-minimizing   segmentation", 
    "arxiv-id": "0906.2770v1", 
    "author": "Jacques-Olivier Lachaud", 
    "publish": "2009-06-15T19:33:21Z", 
    "summary": "This paper defines the basis of a new hierarchical framework for segmentation\nalgorithms based on energy minimization schemes. This new framework is based on\ntwo formal tools. First, a combinatorial pyramid encode efficiently a hierarchy\nof partitions. Secondly, discrete geometric estimators measure precisely some\nimportant geometric parameters of the regions. These measures combined with\nphotometrical and topological features of the partition allows to design energy\nterms based on discrete measures. Our segmentation framework exploits these\nenergies to build a pyramid of image partitions with a minimization scheme.\nSome experiments illustrating our framework are shown and discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.3068v1", 
    "title": "Deformable Model with a Complexity Independent from Image Resolution", 
    "arxiv-id": "0906.3068v1", 
    "author": "Benjamin Taton", 
    "publish": "2009-06-17T04:42:39Z", 
    "summary": "We present a parametric deformable model which recovers image components with\na complexity independent from the resolution of input images. The proposed\nmodel also automatically changes its topology and remains fully compatible with\nthe general framework of deformable models. More precisely, the image space is\nequipped with a metric that expands salient image details according to their\nstrength and their curvature. During the whole evolution of the model, the\nsampling of the contour is kept regular with respect to this metric. By this\nway, the vertex density is reduced along most parts of the curve while a high\nquality of shape representation is preserved. The complexity of the deformable\nmodel is thus improved and is no longer influenced by feature-preserving\nchanges in the resolution of input images. Building the metric requires a prior\nestimation of contour curvature. It is obtained using a robust estimator which\ninvestigates the local variations in the orientation of image gradient.\nExperimental results on both computer generated and biomedical images are\npresented to illustrate the advantages of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.3323v1", 
    "title": "Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid   Image Registration", 
    "arxiv-id": "0906.3323v1", 
    "author": "Xubo Song", 
    "publish": "2009-06-17T23:24:38Z", 
    "summary": "We introduce an adaptive regularization approach. In contrast to conventional\nTikhonov regularization, which specifies a fixed regularization operator, we\nestimate it simultaneously with parameters. From a Bayesian perspective we\nestimate the prior distribution on parameters assuming that it is close to some\ngiven model distribution. We constrain the prior distribution to be a\nGauss-Markov random field (GMRF), which allows us to solve for the prior\ndistribution analytically and provides a fast optimization algorithm. We apply\nour approach to non-rigid image registration to estimate the spatial\ntransformation between two images. Our evaluation shows that the adaptive\nregularization approach significantly outperforms standard variational methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.3770v1", 
    "title": "Automatic Defect Detection and Classification Technique from Image: A   Special Case Using Ceramic Tiles", 
    "arxiv-id": "0906.3770v1", 
    "author": "Md. Mobarak Hossain", 
    "publish": "2009-06-20T03:00:37Z", 
    "summary": "Quality control is an important issue in the ceramic tile industry. On the\nother hand maintaining the rate of production with respect to time is also a\nmajor issue in ceramic tile manufacturing. Again, price of ceramic tiles also\ndepends on purity of texture, accuracy of color, shape etc. Considering this\ncriteria, an automated defect detection and classification technique has been\nproposed in this report that can have ensured the better quality of tiles in\nmanufacturing process as well as production rate. Our proposed method plays an\nimportant role in ceramic tiles industries to detect the defects and to control\nthe quality of ceramic tiles. This automated classification method helps us to\nacquire knowledge about the pattern of defect within a very short period of\ntime and also to decide about the recovery process so that the defected tiles\nmay not be mixed with the fresh tiles."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.4131v2", 
    "title": "Automatic Spatially-Adaptive Balancing of Energy Terms for Image   Segmentation", 
    "arxiv-id": "0906.4131v2", 
    "author": "Rafeef Abugharbieh", 
    "publish": "2009-06-22T21:10:46Z", 
    "summary": "Image segmentation techniques are predominately based on parameter-laden\noptimization. The objective function typically involves weights for balancing\ncompeting image fidelity and segmentation regularization cost terms. Setting\nthese weights suitably has been a painstaking, empirical process. Even if such\nideal weights are found for a novel image, most current approaches fix the\nweight across the whole image domain, ignoring the spatially-varying properties\nof object shape and image appearance. We propose a novel technique that\nautonomously balances these terms in a spatially-adaptive manner through the\nincorporation of image reliability in a graph-based segmentation framework. We\nvalidate on synthetic data achieving a reduction in mean error of 47% (p-value\n<< 0.05) when compared to the best fixed parameter segmentation. We also\npresent results on medical images (including segmentations of the corpus\ncallosum and brain tissue in MRI data) and on natural images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.4789v1", 
    "title": "Efficient IRIS Recognition through Improvement of Feature Extraction and   subset Selection", 
    "arxiv-id": "0906.4789v1", 
    "author": "Hamid Reza Pourreza", 
    "publish": "2009-06-25T20:14:42Z", 
    "summary": "The selection of the optimal feature subset and the classification has become\nan important issue in the field of iris recognition. In this paper we propose\nseveral methods for iris feature subset selection and vector creation. The\ndeterministic feature sequence is extracted from the iris image by using the\ncontourlet transform technique. Contourlet transform captures the intrinsic\ngeometrical structures of iris image. It decomposes the iris image into a set\nof directional sub-bands with texture details captured in different\norientations at various scales so for reducing the feature vector dimensions we\nuse the method for extract only significant bit and information from normalized\niris images. In this method we ignore fragile bits. And finally we use SVM\n(Support Vector Machine) classifier for approximating the amount of people\nidentification in our proposed system. Experimental result show that most\nproposed method reduces processing time and increase the classification\naccuracy and also the iris feature vector length is much smaller versus the\nother methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.5039v1", 
    "title": "A new approach for digit recognition based on hand gesture analysis", 
    "arxiv-id": "0906.5039v1", 
    "author": "Abdelmajid Ben Hamadou", 
    "publish": "2009-06-27T04:46:23Z", 
    "summary": "We present in this paper a new approach for hand gesture analysis that allows\ndigit recognition. The analysis is based on extracting a set of features from a\nhand image and then combining them by using an induction graph. The most\nimportant features we extract from each image are the fingers locations, their\nheights and the distance between each pair of fingers. Our approach consists of\nthree steps: (i) Hand detection and localization, (ii) fingers extraction and\n(iii) features identification and combination to digit recognition. Each input\nimage is assumed to contain only one person, thus we apply a fuzzy classifier\nto identify the skin pixels. In the finger extraction step, we attempt to\nremove all the hand components except the fingers, this process is based on the\nhand anatomy properties. The final step consists on representing histogram of\nthe detected fingers in order to extract features that will be used for digit\nrecognition. The approach is invariant to scale, rotation and translation of\nthe hand. Some experiments have been undertaken to show the effectiveness of\nthe proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.0204v1", 
    "title": "Multi-Label MRF Optimization via Least Squares s-t Cuts", 
    "arxiv-id": "0907.0204v1", 
    "author": "Ghassan Hamarneh", 
    "publish": "2009-07-01T17:18:46Z", 
    "summary": "There are many applications of graph cuts in computer vision, e.g.\nsegmentation. We present a novel method to reformulate the NP-hard, k-way graph\npartitioning problem as an approximate minimal s-t graph cut problem, for which\na globally optimal solution is found in polynomial time. Each non-terminal\nvertex in the original graph is replaced by a set of ceil(log_2(k)) new\nvertices. The original graph edges are replaced by new edges connecting the new\nvertices to each other and to only two, source s and sink t, terminal nodes.\nThe weights of the new edges are obtained using a novel least squares solution\napproximating the constraints of the initial k-way setup. The minimal s-t cut\nlabels each new vertex with a binary (s vs t) \"Gray\" encoding, which is then\ndecoded into a decimal label number that assigns each of the original vertices\nto one of k classes. We analyze the properties of the approximation and present\nquantitative as well as qualitative segmentation results."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.0288v1", 
    "title": "An Iterative Fingerprint Enhancement Algorithm Based on Accurate   Determination of Orientation Flow", 
    "arxiv-id": "0907.0288v1", 
    "author": "Simant Dube", 
    "publish": "2009-07-02T04:57:32Z", 
    "summary": "We describe an algorithm to enhance and binarize a fingerprint image. The\nalgorithm is based on accurate determination of orientation flow of the ridges\nof the fingerprint image by computing variance of the neighborhood pixels\naround a pixel in different directions. We show that an iterative algorithm\nwhich captures the mutual interdependence of orientation flow computation,\nenhancement and binarization gives very good results on poor quality images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.0418v1", 
    "title": "Bounding the Probability of Error for High Precision Recognition", 
    "arxiv-id": "0907.0418v1", 
    "author": "Erik Learned-Miller", 
    "publish": "2009-07-02T16:09:47Z", 
    "summary": "We consider models for which it is important, early in processing, to\nestimate some variables with high precision, but perhaps at relatively low\nrates of recall. If some variables can be identified with near certainty, then\nthey can be conditioned upon, allowing further inference to be done\nefficiently. Specifically, we consider optical character recognition (OCR)\nsystems that can be bootstrapped by identifying a subset of correctly\ntranslated document words with very high precision. This \"clean set\" is\nsubsequently used as document-specific training data. While many current OCR\nsystems produce measures of confidence for the identity of each letter or word,\nthresholding these confidence values, even at very high values, still produces\nsome errors.\n  We introduce a novel technique for identifying a set of correct words with\nvery high precision. Rather than estimating posterior probabilities, we bound\nthe probability that any given word is incorrect under very general\nassumptions, using an approximate worst case analysis. As a result, the\nparameters of the model are nearly irrelevant, and we are able to identify a\nsubset of words, even in noisy documents, of which we are highly confident. On\nour set of 10 documents, we are able to identify about 6% of the words on\naverage without making a single error. This ability to produce word lists with\nvery high precision allows us to use a family of models which depends upon such\nclean word lists."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.1545v1", 
    "title": "Augmenting Light Field to model Wave Optics effects", 
    "arxiv-id": "0907.1545v1", 
    "author": "Ramesh Raskar", 
    "publish": "2009-07-09T13:43:12Z", 
    "summary": "The ray-based 4D light field representation cannot be directly used to\nanalyze diffractive or phase--sensitive optical elements. In this paper, we\nexploit tools from wave optics and extend the light field representation via a\nnovel \"light field transform\". We introduce a key modification to the\nray--based model to support the transform. We insert a \"virtual light source\",\nwith potentially negative valued radiance for certain emitted rays. We create a\nlook-up table of light field transformers of canonical optical elements. The\ntwo key conclusions are that (i) in free space, the 4D light field completely\nrepresents wavefront propagation via rays with real (positive as well as\nnegative) valued radiance and (ii) at occluders, a light field composed of\nlight field transformers plus insertion of (ray--based) virtual light sources\nrepresents resultant phase and amplitude of wavefronts. For free--space\npropagation, we analyze different wavefronts and coherence possibilities. For\noccluders, we show that the light field transform is simply based on a\nconvolution followed by a multiplication operation. This formulation brings\npowerful concepts from wave optics to computer vision and graphics. We show\napplications in cubic-phase plate imaging and holographic displays."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.2075v1", 
    "title": "Multiresolution Elastic Medical Image Registration in Standard Intensity   Scale", 
    "arxiv-id": "0907.2075v1", 
    "author": "Li Bai", 
    "publish": "2009-07-12T22:39:34Z", 
    "summary": "Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.3209v1", 
    "title": "Registration of Standardized Histological Images in Feature Space", 
    "arxiv-id": "0907.3209v1", 
    "author": "Li Bai", 
    "publish": "2009-07-18T11:28:41Z", 
    "summary": "In this paper, we propose three novel and important methods for the\nregistration of histological images for 3D reconstruction. First, possible\nintensity variations and nonstandardness in images are corrected by an\nintensity standardization process which maps the image scale into a standard\nscale where the similar intensities correspond to similar tissues meaning.\nSecond, 2D histological images are mapped into a feature space where continuous\nvariables are used as high confidence image features for accurate registration.\nThird, we propose an automatic best reference slice selection algorithm that\nimproves reconstruction quality based on both image entropy and mean square\nerror of the registration process. We demonstrate that the choice of reference\nslice has a significant impact on registration error, standardization, feature\nspace and entropy information. After 2D histological slices are registered\nthrough an affine transformation with respect to an automatically chosen\nreference, the 3D volume is reconstructed by co-registering 2D slices\nelastically."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.3215v1", 
    "title": "Fully Automatic 3D Reconstruction of Histological Images", 
    "arxiv-id": "0907.3215v1", 
    "author": "Li Bai", 
    "publish": "2009-07-18T12:32:27Z", 
    "summary": "In this paper, we propose a computational framework for 3D volume\nreconstruction from 2D histological slices using registration algorithms in\nfeature space. To improve the quality of reconstructed 3D volume, first,\nintensity variations in images are corrected by an intensity standardization\nprocess which maps image intensity scale to a standard scale where similar\nintensities correspond to similar tissues. Second, a subvolume approach is\nproposed for 3D reconstruction by dividing standardized slices into groups.\nThird, in order to improve the quality of the reconstruction process, an\nautomatic best reference slice selection algorithm is developed based on an\niterative assessment of image entropy and mean square error of the registration\nprocess. Finally, we demonstrate that the choice of the reference slice has a\nsignificant impact on registration quality and subsequent 3D reconstruction."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.3218v1", 
    "title": "Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face   Recognition", 
    "arxiv-id": "0907.3218v1", 
    "author": "Li Bai", 
    "publish": "2009-07-18T13:03:19Z", 
    "summary": "In this paper, the problem of automatic Gabor wavelet selection for face\nrecognition is tackled by introducing an automatic algorithm based on Parallel\nAdaBoosting method. Incorporating mutual information into the algorithm leads\nto the selection procedure not only based on classification accuracy but also\non efficiency. Effective image features are selected by using properly chosen\nGabor wavelets optimised with Parallel AdaBoost method and mutual information\nto get high recognition rates with low computational cost. Experiments are\nconducted using the well-known FERET face database. In proposed framework,\nmemory and computation costs are reduced significantly and high classification\naccuracy is obtained."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.4354v1", 
    "title": "Learning Object Location Predictors with Boosting and Grammar-Guided   Feature Extraction", 
    "arxiv-id": "0907.4354v1", 
    "author": "David Helmbold", 
    "publish": "2009-07-24T18:01:08Z", 
    "summary": "We present BEAMER: a new spatially exploitative approach to learning object\ndetectors which shows excellent results when applied to the task of detecting\nobjects in greyscale aerial imagery in the presence of ambiguous and noisy\ndata. There are four main contributions used to produce these results. First,\nwe introduce a grammar-guided feature extraction system, enabling the\nexploration of a richer feature space while constraining the features to a\nuseful subset. This is specified with a rule-based generative grammar crafted\nby a human expert. Second, we learn a classifier on this data using a newly\nproposed variant of AdaBoost which takes into account the spatially correlated\nnature of the data. Third, we perform another round of training to optimize the\nmethod of converting the pixel classifications generated by boosting into a\nhigh quality set of (x, y) locations. Lastly, we carefully define three common\nproblems in object detection and define two evaluation criteria that are\ntightly matched to these problems. Major strengths of this approach are: (1) a\nway of randomly searching a broad feature space, (2) its performance when\nevaluated on well-matched evaluation criteria, and (3) its use of the location\nprediction domain to learn object detectors as well as to generate detections\nthat perform well on several tasks: object counting, tracking, and target\ndetection. We demonstrate the efficacy of BEAMER with a comprehensive\nexperimental evaluation on a challenging data set."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.4984v1", 
    "title": "Automatic local Gabor Features extraction for face recognition", 
    "arxiv-id": "0907.4984v1", 
    "author": "Sana Khanfir", 
    "publish": "2009-07-28T20:02:15Z", 
    "summary": "We present in this paper a biometric system of face detection and recognition\nin color images. The face detection technique is based on skin color\ninformation and fuzzy classification. A new algorithm is proposed in order to\ndetect automatically face features (eyes, mouth and nose) and extract their\ncorrespondent geometrical points. These fiducial points are described by sets\nof wavelet components which are used for recognition. To achieve the face\nrecognition, we use neural networks and we study its performances for different\ninputs. We compare the two types of features used for recognition: geometric\ndistances and Gabor coefficients which can be used either independently or\njointly. This comparison shows that Gabor coefficients are more powerful than\ngeometric distances. We show with experimental results how the importance\nrecognition ratio makes our system an effective tool for automatic face\ndetection and recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0907.5321v2", 
    "title": "Multiple pattern classification by sparse subspace decomposition", 
    "arxiv-id": "0907.5321v2", 
    "author": "Tomoya Sakai", 
    "publish": "2009-07-30T12:23:25Z", 
    "summary": "A robust classification method is developed on the basis of sparse subspace\ndecomposition. This method tries to decompose a mixture of subspaces of\nunlabeled data (queries) into class subspaces as few as possible. Each query is\nclassified into the class whose subspace significantly contributes to the\ndecomposed subspace. Multiple queries from different classes can be\nsimultaneously classified into their respective classes. A practical greedy\nalgorithm of the sparse subspace decomposition is designed for the\nclassification. The present method achieves high recognition rate and robust\nperformance exploiting joint sparsity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0908.1369v1", 
    "title": "Segmentation for radar images based on active contour", 
    "arxiv-id": "0908.1369v1", 
    "author": "Pengfei Zhang", 
    "publish": "2009-08-10T18:33:51Z", 
    "summary": "We exam various geometric active contour methods for radar image\nsegmentation. Due to special properties of radar images, we propose our new\nmodel based on modified Chan-Vese functional. Our method is efficient in\nseparating non-meteorological noises from meteorological images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0908.1919v3", 
    "title": "A dyadic solution of relative pose problems", 
    "arxiv-id": "0908.1919v3", 
    "author": "Patrick Erik Bradley", 
    "publish": "2009-08-13T15:41:44Z", 
    "summary": "A hierarchical interval subdivision is shown to lead to a $p$-adic encoding\nof image data. This allows in the case of the relative pose problem in computer\nvision and photogrammetry to derive equations having 2-adic numbers as\ncoefficients, and to use Hensel's lifting method to their solution. This method\nis applied to the linear and non-linear equations coming from eight, seven or\nfive point correspondences. An inherent property of the method is its\nrobustness."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0908.4386v1", 
    "title": "Handwritten Farsi Character Recognition using Artificial Neural Network", 
    "arxiv-id": "0908.4386v1", 
    "author": "Mohammad Farajpoor Ahangar", 
    "publish": "2009-08-30T11:55:48Z", 
    "summary": "Neural Networks are being used for character recognition from last many years\nbut most of the work was confined to English character recognition. Till date,\na very little work has been reported for Handwritten Farsi Character\nrecognition. In this paper, we have made an attempt to recognize handwritten\nFarsi characters by using a multilayer perceptron with one hidden layer. The\nerror backpropagation algorithm has been used to train the MLP network. In\naddition, an analysis has been carried out to determine the number of hidden\nnodes to achieve high performance of backpropagation network in the recognition\nof handwritten Farsi characters. The system has been trained using several\ndifferent forms of handwriting provided by both male and female participants of\ndifferent age groups. Finally, this rigorous training results an automatic HCR\nsystem using MLP network. In this work, the experiments were carried out on two\nhundred fifty samples of five writers. The results showed that the MLP networks\ntrained by the error backpropagation algorithm are superior in recognition\naccuracy and memory usage. The result indicates that the backpropagation\nnetwork provides good recognition accuracy of more than 80% of handwritten\nFarsi characters."
},{
    "category": "cs.CV", 
    "doi": "10.3390/e11030513", 
    "link": "http://arxiv.org/pdf/0909.0481v1", 
    "title": "Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models   in Image Segmentation", 
    "arxiv-id": "0909.0481v1", 
    "author": "Jean-Luc Starck", 
    "publish": "2009-09-02T17:46:08Z", 
    "summary": "By a \"covering\" we mean a Gaussian mixture model fit to observed data.\nApproximations of the Bayes factor can be availed of to judge model fit to the\ndata within a given Gaussian mixture model. Between families of Gaussian\nmixture models, we propose the R\\'enyi quadratic entropy as an excellent and\ntractable model comparison framework. We exemplify this using the segmentation\nof an MRI image volume, based (1) on a direct Gaussian mixture model applied to\nthe marginal distribution function, and (2) Gaussian model fit through k-means\napplied to the 4D multivalued image volume furnished by the wavelet transform.\nVisual preference for one model over another is not immediate. The R\\'enyi\nquadratic entropy allows us to show clearly that one of these modelings is\nsuperior to the other."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457627", 
    "link": "http://arxiv.org/pdf/0909.1605v1", 
    "title": "Kernel Spectral Curvature Clustering (KSCC)", 
    "arxiv-id": "0909.1605v1", 
    "author": "G. Lerman", 
    "publish": "2009-09-09T01:58:23Z", 
    "summary": "Multi-manifold modeling is increasingly used in segmentation and data\nrepresentation tasks in computer vision and related fields. While the general\nproblem, modeling data by mixtures of manifolds, is very challenging, several\napproaches exist for modeling data by mixtures of affine subspaces (which is\noften referred to as hybrid linear modeling). We translate some important\ninstances of multi-manifold modeling to hybrid linear modeling in embedded\nspaces, without explicitly performing the embedding but applying the kernel\ntrick. The resulting algorithm, Kernel Spectral Curvature Clustering, uses\nkernels at two levels - both as an implicit embedding method to linearize\nnonflat manifolds and as a principled method to convert a multiway affinity\nproblem into a spectral clustering one. We demonstrate the effectiveness of the\nmethod by comparing it with other state-of-the-art methods on both synthetic\ndata and a real-world problem of segmenting multiple motions from two\nperspective camera views."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.1608v1", 
    "title": "Motion Segmentation by SCC on the Hopkins 155 Database", 
    "arxiv-id": "0909.1608v1", 
    "author": "G. Lerman", 
    "publish": "2009-09-09T02:12:22Z", 
    "summary": "We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark\ndatabase of 155 motion sequences, and show that it outperforms all other\nstate-of-the-art methods. The average misclassification rate by SCC is 1.41%\nfor sequences having two motions and 4.85% for three motions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.3911v1", 
    "title": "A Method for Extraction and Recognition of Isolated License Plate   Characters", 
    "arxiv-id": "0909.3911v1", 
    "author": "Tien Der Yeh", 
    "publish": "2009-09-22T05:38:32Z", 
    "summary": "A method to extract and recognize isolated characters in license plates is\nproposed. In extraction stage, the proposed method detects isolated characters\nby using Difference-of-Gaussian (DOG) function, The DOG function, similar to\nLaplacian of Gaussian function, was proven to produce the most stable image\nfeatures compared to a range of other possible image functions. The candidate\ncharacters are extracted by doing connected component analysis on different\nscale DOG images. In recognition stage, a novel feature vector named\naccumulated gradient projection vector (AGPV) is used to compare the candidate\ncharacter with the standard ones. The AGPV is calculated by first projecting\npixels of similar gradient orientations onto specific axes, and then\naccumulates the projected gradient magnitudes by each axis. In the experiments,\nthe AGPVs are proven to be invariant from image scaling and rotation, and\nrobust to noise and illumination change."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.5458v1", 
    "title": "Information tracking approach to segmentation of ultrasound imagery of   prostate", 
    "arxiv-id": "0909.5458v1", 
    "author": "Magdy Salama", 
    "publish": "2009-09-29T22:39:19Z", 
    "summary": "The size and geometry of the prostate are known to be pivotal quantities used\nby clinicians to assess the condition of the gland during prostate cancer\nscreening. As an alternative to palpation, an increasing number of methods for\nestimation of the above-mentioned quantities are based on using imagery data of\nprostate. The necessity to process large volumes of such data creates a need\nfor automatic segmentation tools which would allow the estimation to be carried\nout with maximum accuracy and efficiency. In particular, the use of transrectal\nultrasound (TRUS) imaging in prostate cancer screening seems to be becoming a\nstandard clinical practice due to the high benefit-to-cost ratio of this\nimaging modality. Unfortunately, the segmentation of TRUS images is still\nhampered by relatively low contrast and reduced SNR of the images, thereby\nrequiring the segmentation algorithms to incorporate prior knowledge about the\ngeometry of the gland. In this paper, a novel approach to the problem of\nsegmenting the TRUS images is described. The proposed approach is based on the\nconcept of distribution tracking, which provides a unified framework for\nmodeling and fusing image-related and morphological features of the prostate.\nMoreover, the same framework allows the segmentation to be regularized via\nusing a new type of \"weak\" shape priors, which minimally bias the estimation\nprocedure, while rendering the latter stable and robust."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.5460v2", 
    "title": "Iterative Shrinkage Approach to Restoration of Optical Imagery", 
    "arxiv-id": "0909.5460v2", 
    "author": "O. Michailovich", 
    "publish": "2009-09-29T22:33:10Z", 
    "summary": "The problem of reconstruction of digital images from their degraded\nmeasurements is regarded as a problem of central importance in various fields\nof engineering and imaging sciences. In such cases, the degradation is\ntypically caused by the resolution limitations of an imaging device in use\nand/or by the destructive influence of measurement noise. Specifically, when\nthe noise obeys a Poisson probability law, standard approaches to the problem\nof image reconstruction are based on using fixed-point algorithms which follow\nthe methodology first proposed by Richardson and Lucy. The practice of using\nthese methods, however, shows that their convergence properties tend to\ndeteriorate at relatively high noise levels. Accordingly, in the present paper,\na novel method for de-noising and/or de-blurring of digital images corrupted by\nPoisson noise is introduced. The proposed method is derived under the\nassumption that the image of interest can be sparsely represented in the domain\nof a linear transform. Consequently, a shrinkage-based iterative procedure is\nproposed, which guarantees the solution to converge to the global maximizer of\nan associated maximum-a-posteriori criterion. It is shown in a series of both\ncomputer-simulated and real-life experiments that the proposed method\noutperforms a number of existing alternatives in terms of stability, precision,\nand computational efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0910.1295v1", 
    "title": "Modular Traffic Sign Recognition applied to on-vehicle real-time visual   detection of American and European speed limit signs", 
    "arxiv-id": "0910.1295v1", 
    "author": "Lowik Chanussot", 
    "publish": "2009-10-07T15:43:01Z", 
    "summary": "We present a new modular traffic signs recognition system, successfully\napplied to both American and European speed limit signs. Our sign detection\nstep is based only on shape-detection (rectangles or circles). This enables it\nto work on grayscale images, contrary to most European competitors, which eases\nrobustness to illumination conditions (notably night operation). Speed sign\ncandidates are classified (or rejected) by segmenting potential digits inside\nthem (which is rather original and has several advantages), and then applying a\nneural digit recognition. The global detection rate is ~90% for both (standard)\nU.S. and E.U. speed signs, with a misclassification rate <1%, and no validated\nfalse alarm in >150 minutes of video. The system processes in real-time ~20\nframes/s on a standard high-end laptop."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0910.1844v1", 
    "title": "3D/2D Registration of Mapping Catheter Images for Arrhythmia   Interventional Assistance", 
    "arxiv-id": "0910.1844v1", 
    "author": "Pascal Fallavollita", 
    "publish": "2009-10-09T20:07:11Z", 
    "summary": "Radiofrequency (RF) catheter ablation has transformed treatment for\ntachyarrhythmias and has become first-line therapy for some tachycardias. The\nprecise localization of the arrhythmogenic site and the positioning of the RF\ncatheter over that site are problematic: they can impair the efficiency of the\nprocedure and are time consuming (several hours). Electroanatomic mapping\ntechnologies are available that enable the display of the cardiac chambers and\nthe relative position of ablation lesions. However, these are expensive and use\ncustom-made catheters. The proposed methodology makes use of standard catheters\nand inexpensive technology in order to create a 3D volume of the heart chamber\naffected by the arrhythmia. Further, we propose a novel method that uses a\npriori 3D information of the mapping catheter in order to estimate the 3D\nlocations of multiple electrodes across single view C-arm images. The monoplane\nalgorithm is tested for feasibility on computer simulations and initial canine\ndata."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0910.1849v1", 
    "title": "Color Image Clustering using Block Truncation Algorithm", 
    "arxiv-id": "0910.1849v1", 
    "author": "Manish Maheshwari", 
    "publish": "2009-10-09T20:21:23Z", 
    "summary": "With the advancement in image capturing device, the image data been generated\nat high volume. If images are analyzed properly, they can reveal useful\ninformation to the human users. Content based image retrieval address the\nproblem of retrieving images relevant to the user needs from image databases on\nthe basis of low-level visual features that can be derived from the images.\nGrouping images into meaningful categories to reveal useful information is a\nchallenging and important problem. Clustering is a data mining technique to\ngroup a set of unsupervised data based on the conceptual clustering principal:\nmaximizing the intraclass similarity and minimizing the interclass similarity.\nProposed framework focuses on color as feature. Color Moment and Block\nTruncation Coding (BTC) are used to extract features for image dataset.\nExperimental study using K-Means clustering algorithm is conducted to group the\nimage dataset into various clusters."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0910.2381v4", 
    "title": "Fractional differentiation based image processing", 
    "arxiv-id": "0910.2381v4", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2009-10-13T12:37:32Z", 
    "summary": "There are many resources useful for processing images, most of them freely\navailable and quite friendly to use. In spite of this abundance of tools, a\nstudy of the processing methods is still worthy of efforts. Here, we want to\ndiscuss the possibilities arising from the use of fractional differential\ncalculus. This calculus evolved in the research field of pure mathematics until\n1920, when applied science started to use it. Only recently, fractional\ncalculus was involved in image processing methods. As we shall see, the\nfractional calculation is able to enhance the quality of images, with\ninteresting possibilities in edge detection and image restoration. We suggest\nalso the fractional differentiation as a tool to reveal faint objects in\nastronomical images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0910.2917v1", 
    "title": "Behavior Subtraction", 
    "arxiv-id": "0910.2917v1", 
    "author": "J. Konrad", 
    "publish": "2009-10-15T16:09:18Z", 
    "summary": "Background subtraction has been a driving engine for many computer vision and\nvideo analytics tasks. Although its many variants exist, they all share the\nunderlying assumption that photometric scene properties are either static or\nexhibit temporal stationarity. While this works in some applications, the model\nfails when one is interested in discovering {\\it changes in scene dynamics}\nrather than those in a static background; detection of unusual pedestrian and\nmotor traffic patterns is but one example. We propose a new model and\ncomputational framework that address this failure by considering stationary\nscene dynamics as a ``background'' with which observed scene dynamics are\ncompared. Central to our approach is the concept of an {\\it event}, that we\ndefine as short-term scene dynamics captured over a time window at a specific\nspatial location in the camera field of view. We compute events by\ntime-aggregating motion labels, obtained by background subtraction, as well as\nobject descriptors (e.g., object size). Subsequently, we characterize events\nprobabilistically, but use a low-memory, low-complexity surrogates in practical\nimplementation. Using these surrogates amounts to {\\it behavior subtraction}, a\nnew algorithm with some surprising properties. As demonstrated here, behavior\nsubtraction is an effective tool in anomaly detection and localization. It is\nresilient to spurious background motion, such as one due to camera jitter, and\nis content-blind, i.e., it works equally well on humans, cars, animals, and\nother objects in both uncluttered and highly-cluttered scenes. Clearly,\ntreating video as a collection of events rather than colored pixels opens new\npossibilities for video analytics."
},{
    "category": "cs.CV", 
    "doi": "10.1134/S2070046610010048", 
    "link": "http://arxiv.org/pdf/0910.4839v2", 
    "title": "A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting", 
    "arxiv-id": "0910.4839v2", 
    "author": "Patrick Erik Bradley", 
    "publish": "2009-10-26T09:34:29Z", 
    "summary": "A $p$-adic variation of the Ran(dom) Sa(mple) C(onsensus) method for solving\nthe relative pose problem in stereo vision is developped. From two 2-adically\nencoded images a random sample of five pairs of corresponding points is taken,\nand the equations for the essential matrix are solved by lifting solutions\nmodulo 2 to the 2-adic integers. A recently devised $p$-adic hierarchical\nclassification algorithm imitating the known LBG quantisation method classifies\nthe solutions for all the samples after having determined the number of\nclusters using the known intra-inter validity of clusterings. In the successful\ncase, a cluster ranking will determine the cluster containing a 2-adic\napproximation to the \"true\" solution of the problem."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0910.5002v1", 
    "title": "An Iterative Shrinkage Approach to Total-Variation Image Restoration", 
    "arxiv-id": "0910.5002v1", 
    "author": "Oleg Michailovich", 
    "publish": "2009-10-26T22:50:18Z", 
    "summary": "The problem of restoration of digital images from their degraded measurements\nplays a central role in a multitude of practically important applications. A\nparticularly challenging instance of this problem occurs in the case when the\ndegradation phenomenon is modeled by an ill-conditioned operator. In such a\ncase, the presence of noise makes it impossible to recover a valuable\napproximation of the image of interest without using some a priori information\nabout its properties. Such a priori information is essential for image\nrestoration, rendering it stable and robust to noise. Particularly, if the\noriginal image is known to be a piecewise smooth function, one of the standard\npriors used in this case is defined by the Rudin-Osher-Fatemi model, which\nresults in total variation (TV) based image restoration. The current arsenal of\nalgorithms for TV-based image restoration is vast. In the present paper, a\ndifferent approach to the solution of the problem is proposed based on the\nmethod of iterative shrinkage (aka iterated thresholding). In the proposed\nmethod, the TV-based image restoration is performed through a recursive\napplication of two simple procedures, viz. linear filtering and soft\nthresholding. Therefore, the method can be identified as belonging to the group\nof first-order algorithms which are efficient in dealing with images of\nrelatively large sizes. Another valuable feature of the proposed method\nconsists in its working directly with the TV functional, rather then with its\nsmoothed versions. Moreover, the method provides a single solution for both\nisotropic and anisotropic definitions of the TV functional, thereby\nestablishing a useful connection between the two formulae."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0911.0481v1", 
    "title": "An Optimal Method For Wake Detection In SAR Images Using Radon   Transformation Combined With Wavelet Filters", 
    "arxiv-id": "0911.0481v1", 
    "author": "P. Subashini", 
    "publish": "2009-11-03T03:37:03Z", 
    "summary": "A new fangled method for ship wake detection in synthetic aperture radar\n(SAR) images is explored here. Most of the detection procedure applies the\nRadon transform as its properties outfit more than any other transformation for\nthe detection purpose. But still it holds problems when the transform is\napplied to an image with a high level of noise. Here this paper articulates the\ncombination between the radon transformation and the shrinkage methods which\nincrease the mode of wake detection process. The latter shrinkage method with\nRT maximize the signal to noise ratio hence it leads to most optimal detection\nof lines in the SAR images. The originality mainly works on the denoising\nsegment of the proposed algorithm. Experimental work outs are carried over both\nin simulated and real SAR images. The detection process is more adequate with\nthe proposed method and improves better than the conventional methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0911.0490v1", 
    "title": "Breast Cancer Detection Using Multilevel Thresholding", 
    "arxiv-id": "0911.0490v1", 
    "author": "S. Thamarai Selvi", 
    "publish": "2009-11-03T04:33:55Z", 
    "summary": "This paper presents an algorithm which aims to assist the radiologist in\nidentifying breast cancer at its earlier stages. It combines several image\nprocessing techniques like image negative, thresholding and segmentation\ntechniques for detection of tumor in mammograms. The algorithm is verified by\nusing mammograms from Mammographic Image Analysis Society. The results obtained\nby applying these techniques are described."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0911.4874v2", 
    "title": "Non-photorealistic image processing: an Impressionist rendering", 
    "arxiv-id": "0911.4874v2", 
    "author": "Roberto Marazzato", 
    "publish": "2009-11-25T15:16:53Z", 
    "summary": "The paper describes an image processing for a non-photorealistic rendering.\nThe algorithm is based on a random choice of a set of pixels from those ot the\noriginal image and substitution of them with colour spots. An iterative\nprocedure is applied to cover, at a desired level, the canvas. The resulting\neffect mimics the impressionist painting and Pointillism."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0911.5462v1", 
    "title": "Pigment Melanin: Pattern for Iris Recognition", 
    "arxiv-id": "0911.5462v1", 
    "author": "Hamid Soltanian-Zadeh", 
    "publish": "2009-11-29T07:07:54Z", 
    "summary": "Recognition of iris based on Visible Light (VL) imaging is a difficult\nproblem because of the light reflection from the cornea. Nonetheless, pigment\nmelanin provides a rich feature source in VL, unavailable in Near-Infrared\n(NIR) imaging. This is due to biological spectroscopy of eumelanin, a chemical\nnot stimulated in NIR. In this case, a plausible solution to observe such\npatterns may be provided by an adaptive procedure using a variational technique\non the image histogram. To describe the patterns, a shape analysis method is\nused to derive feature-code for each subject. An important question is how much\nthe melanin patterns, extracted from VL, are independent of iris texture in\nNIR. With this question in mind, the present investigation proposes fusion of\nfeatures extracted from NIR and VL to boost the recognition performance. We\nhave collected our own database (UTIRIS) consisting of both NIR and VL images\nof 158 eyes of 79 individuals. This investigation demonstrates that the\nproposed algorithm is highly sensitive to the patterns of cromophores and\nimproves the iris recognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.0600v1", 
    "title": "Sequential Clustering based Facial Feature Extraction Method for   Automatic Creation of Facial Models from Orthogonal Views", 
    "arxiv-id": "0912.0600v1", 
    "author": "Reza Aghaeizadeh Zoroofi", 
    "publish": "2009-12-03T08:54:24Z", 
    "summary": "Multiview 3D face modeling has attracted increasing attention recently and\nhas become one of the potential avenues in future video systems. We aim to make\nmore reliable and robust automatic feature extraction and natural 3D feature\nconstruction from 2D features detected on a pair of frontal and profile view\nface images. We propose several heuristic algorithms to minimize possible\nerrors introduced by prevalent nonperfect orthogonal condition and noncoherent\nluminance. In our approach, we first extract the 2D features that are visible\nto both cameras in both views. Then, we estimate the coordinates of the\nfeatures in the hidden profile view based on the visible features extracted in\nthe two orthogonal views. Finally, based on the coordinates of the extracted\nfeatures, we deform a 3D generic model to perform the desired 3D clone\nmodeling. Present study proves the scope of resulted facial models for\npractical applications like face recognition and facial animation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.1310v1", 
    "title": "Automatic creation of urban velocity fields from aerial video", 
    "arxiv-id": "0912.1310v1", 
    "author": "Mark Hickman", 
    "publish": "2009-12-07T19:04:41Z", 
    "summary": "In this paper, we present a system for modelling vehicle motion in an urban\nscene from low frame-rate aerial video. In particular, the scene is modelled as\na probability distribution over velocities at every pixel in the image.\n  We describe the complete system for acquiring this model. The video is\ncaptured from a helicopter and stabilized by warping the images to match an\northorectified image of the area. A pixel classifier is applied to the\nstabilized images, and the response is segmented to determine car locations and\norientations. The results are fed in to a tracking scheme which tracks cars for\nthree frames, creating tracklets. This allows the tracker to use a combination\nof velocity, direction, appearance, and acceleration cues to keep only tracks\nlikely to be correct. Each tracklet provides a measurement of the car velocity\nat every point along the tracklet's length, and these are then aggregated to\ncreate a histogram of vehicle velocities at every pixel in the image.\n  The results demonstrate that the velocity probability distribution prior can\nbe used to infer a variety of information about road lane directions, speed\nlimits, vehicle speeds and common trajectories, and traffic bottlenecks, as\nwell as providing a means of describing environmental knowledge about traffic\nrules that can be used in tracking."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.3589v1", 
    "title": "Matching 2-D Ellipses to 3-D Circles with Application to Vehicle Pose   Estimation", 
    "arxiv-id": "0912.3589v1", 
    "author": "Nathan Brewer", 
    "publish": "2009-12-18T05:58:54Z", 
    "summary": "Finding the three-dimensional representation of all or a part of a scene from\na single two dimensional image is a challenging task. In this paper we propose\na method for identifying the pose and location of objects with circular\nprotrusions in three dimensions from a single image and a 3d representation or\nmodel of the object of interest. To do this, we present a method for\nidentifying ellipses and their properties quickly and reliably with a novel\ntechnique that exploits intensity differences between objects and a geometric\ntechnique for matching an ellipse in 2d to a circle in 3d.\n  We apply these techniques to the specific problem of determining the pose and\nlocation of vehicles, particularly cars, from a single image. We have achieved\nexcellent pose recovery performance on artificially generated car images and\nshow promising results on real vehicle images. We also make use of the ellipse\ndetection method to identify car wheels from images, with a very high\nsuccessful match rate."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.3973v2", 
    "title": "A Novel Feature Extraction for Robust EMG Pattern Recognition", 
    "arxiv-id": "0912.3973v2", 
    "author": "Pornchai Phukpattaranont", 
    "publish": "2009-12-20T03:49:21Z", 
    "summary": "Varieties of noises are major problem in recognition of Electromyography\n(EMG) signal. Hence, methods to remove noise become most significant in EMG\nsignal analysis. White Gaussian noise (WGN) is used to represent interference\nin this paper. Generally, WGN is difficult to be removed using typical\nfiltering and solutions to remove WGN are limited. In addition, noise removal\nis an important step before performing feature extraction, which is used in\nEMG-based recognition. This research is aimed to present a novel feature that\ntolerate with WGN. As a result, noise removal algorithm is not needed. Two\nnovel mean and median frequencies (MMNF and MMDF) are presented for robust\nfeature extraction. Sixteen existing features and two novelties are evaluated\nin a noisy environment. WGN with various signal-to-noise ratios (SNRs), i.e.\n20-0 dB, was added to the original EMG signal. The results showed that MMNF\nperformed very well especially in weak EMG signal compared with others. The\nerror of MMNF in weak EMG signal with very high noise, 0 dB SNR, is about 5-10\npercent and closed by MMDF and Histogram, whereas the error of other features\nis more than 20 percent. While in strong EMG signal, the error of MMNF is\nbetter than those from other features. Moreover, the combination of MMNF,\nHistrogram of EMG and Willison amplitude is used as feature vector in\nclassification task. The experimental result shows the better recognition\nresult in noisy environment than other success feature candidates. From the\nabove results demonstrate that MMNF can be used for new robust feature\nextraction."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/0912.5502v1", 
    "title": "Writer Identification Using Inexpensive Signal Processing Techniques", 
    "arxiv-id": "0912.5502v1", 
    "author": "Ching Y. Suen", 
    "publish": "2009-12-30T18:19:53Z", 
    "summary": "We propose to use novel and classical audio and text signal-processing and\notherwise techniques for \"inexpensive\" fast writer identification tasks of\nscanned hand-written documents \"visually\". The \"inexpensive\" refers to the\nefficiency of the identification process in terms of CPU cycles while\npreserving decent accuracy for preliminary identification. This is a\ncomparative study of multiple algorithm combinations in a pattern recognition\npipeline implemented in Java around an open-source Modular Audio Recognition\nFramework (MARF) that can do a lot more beyond audio. We present our\npreliminary experimental findings in such an identification task. We simulate\n\"visual\" identification by \"looking\" at the hand-written document as a whole\nrather than trying to extract fine-grained features out of it prior\nclassification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.0927v1", 
    "title": "Accelerating Competitive Learning Graph Quantization", 
    "arxiv-id": "1001.0927v1", 
    "author": "Klaus Obermayer", 
    "publish": "2010-01-06T16:05:25Z", 
    "summary": "Vector quantization(VQ) is a lossy data compression technique from signal\nprocessing for which simple competitive learning is one standard method to\nquantize patterns from the input space. Extending competitive learning VQ to\nthe domain of graphs results in competitive learning for quantizing input\ngraphs. In this contribution, we propose an accelerated version of competitive\nlearning graph quantization (GQ) without trading computational time against\nsolution quality. For this, we lift graphs locally to vectors in order to avoid\nunnecessary calculations of intractable graph distances. In doing so, the\naccelerated version of competitive learning GQ gradually turns locally into a\ncompetitive learning VQ with increasing number of iterations. Empirical results\nshow a significant speedup by maintaining a comparable solution quality."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.1221v1", 
    "title": "Boosting k-NN for categorization of natural scenes", 
    "arxiv-id": "1001.1221v1", 
    "author": "Michel Barlaud", 
    "publish": "2010-01-08T08:30:51Z", 
    "summary": "The k-nearest neighbors (k-NN) classification rule has proven extremely\nsuccessful in countless many computer vision applications. For example, image\ncategorization often relies on uniform voting among the nearest prototypes in\nthe space of descriptors. In spite of its good properties, the classic k-NN\nrule suffers from high variance when dealing with sparse prototype datasets in\nhigh dimensions. A few techniques have been proposed to improve k-NN\nclassification, which rely on either deforming the nearest neighborhood\nrelationship or modifying the input space. In this paper, we propose a novel\nboosting algorithm, called UNN (Universal Nearest Neighbors), which induces\nleveraged k-NN, thus generalizing the classic k-NN rule. We redefine the voting\nrule as a strong classifier that linearly combines predictions from the k\nclosest prototypes. Weak classifiers are learned by UNN so as to minimize a\nsurrogate risk. A major feature of UNN is the ability to learn which prototypes\nare the most relevant for a given class, thus allowing one for effective data\nreduction. Experimental results on the synthetic two-class dataset of Ripley\nshow that such a filtering strategy is able to reject \"noisy\" prototypes. We\ncarried out image categorization experiments on a database containing eight\nclasses of natural scenes. We show that our method outperforms significantly\nthe classic k-NN classification, while enabling significant reduction of the\ncomputational cost by means of data filtering."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.1968v1", 
    "title": "A Topological derivative based image segmentation for sign language   recognition system using isotropic filter", 
    "arxiv-id": "1001.1968v1", 
    "author": "Dr. V. Radha", 
    "publish": "2010-01-12T18:18:10Z", 
    "summary": "The need of sign language is increasing radically especially to hearing\nimpaired community. Only few research groups try to automatically recognize\nsign language from video, colored gloves and etc. Their approach requires a\nvalid segmentation of the data that is used for training and of the data that\nis used to be recognized. Recognition of a sign language image sequence is\nchallenging because of the variety of hand shapes and hand motions. Here, this\npaper proposes to apply a combination of image segmentation with restoration\nusing topological derivatives for achieving high recognition accuracy. Image\nquality measures are conceded here to differentiate the methods both\nsubjectively as well as objectively. Experiments show that the additional use\nof the restoration before segmenting the postures significantly improves the\ncorrect rate of hand detection, and that the discrete derivatives yields a high\nrate of discrimination between different static hand postures as well as\nbetween hand postures and the scene background. Eventually, the research is to\ncontribute to the implementation of automated sign language recognition system\nmainly established for the welfare purpose."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3487v1", 
    "title": "Features Based Text Similarity Detection", 
    "arxiv-id": "1001.3487v1", 
    "author": "Naomie Salim", 
    "publish": "2010-01-20T07:46:23Z", 
    "summary": "As the Internet help us cross cultural border by providing different\ninformation, plagiarism issue is bound to arise. As a result, plagiarism\ndetection becomes more demanding in overcoming this issue. Different plagiarism\ndetection tools have been developed based on various detection techniques.\nNowadays, fingerprint matching technique plays an important role in those\ndetection tools. However, in handling some large content articles, there are\nsome weaknesses in fingerprint matching technique especially in space and time\nconsumption issue. In this paper, we propose a new approach to detect\nplagiarism which integrates the use of fingerprint matching technique with four\nkey features to assist in the detection process. These proposed features are\ncapable to choose the main point or key sentence in the articles to be\ncompared. Those selected sentence will be undergo the fingerprint matching\nprocess in order to detect the similarity between the sentences. Hence, time\nand space usage for the comparison process is reduced without affecting the\neffectiveness of the plagiarism detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3502v1", 
    "title": "3D Skull Recognition Using 3D Matching Technique", 
    "arxiv-id": "1001.3502v1", 
    "author": "A. A Zaidan", 
    "publish": "2010-01-20T08:17:26Z", 
    "summary": "Biometrics has become a \"hot\" area. Governments are funding research programs\nfocused on biometrics. In this paper the problem of person recognition and\nverification based on a different biometric application has been addressed. The\nsystem is based on the 3DSkull recognition using 3D matching technique, in fact\nthis paper present several bio-metric approaches in order of assign the weak\npoint in term of used the biometric from the authorize person and insure the\nperson who access the data is the real person. The feature of the simulate\nsystem shows the capability of using 3D matching system as an efficient way to\nidentify the person through his or her skull by match it with database, this\ntechnique grantee fast processing with optimizing the false positive and\nnegative as well ."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3503v1", 
    "title": "Hybrid Medical Image Classification Using Association Rule Mining with   Decision Tree Algorithm", 
    "arxiv-id": "1001.3503v1", 
    "author": "M. Madheswaran", 
    "publish": "2010-01-20T08:19:48Z", 
    "summary": "The main focus of image mining in the proposed method is concerned with the\nclassification of brain tumor in the CT scan brain images. The major steps\ninvolved in the system are: pre-processing, feature extraction, association\nrule mining and hybrid classifier. The pre-processing step has been done using\nthe median filtering process and edge features have been extracted using canny\nedge detection technique. The two image mining approaches with a hybrid manner\nhave been proposed in this paper. The frequent patterns from the CT scan images\nare generated by frequent pattern tree (FP-Tree) algorithm that mines the\nassociation rules. The decision tree method has been used to classify the\nmedical images for diagnosis. This system enhances the classification process\nto be more accurate. The hybrid method improves the efficiency of the proposed\nmethod than the traditional image mining methods. The experimental result on\nprediagnosed database of brain images showed 97% sensitivity and 95% accuracy\nrespectively. The physicians can make use of this accurate decision tree\nclassification phase for classifying the brain images into normal, benign and\nmalignant for effective medical diagnosis."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3735v1", 
    "title": "Gradient Based Seeded Region Grow method for CT Angiographic Image   Segmentation", 
    "arxiv-id": "1001.3735v1", 
    "author": "T. R. Gopalakrishnan Nair", 
    "publish": "2010-01-21T07:15:29Z", 
    "summary": "Segmentation of medical images using seeded region growing technique is\nincreasingly becoming a popular method because of its ability to involve\nhigh-level knowledge of anatomical structures in seed selection process. Region\nbased segmentation of medical images are widely used in varied clinical\napplications like visualization, bone detection, tumor detection and\nunsupervised image retrieval in clinical databases. As medical images are\nmostly fuzzy in nature, segmenting regions based intensity is the most\nchallenging task. In this paper, we discuss about popular seeded region grow\nmethodology used for segmenting anatomical structures in CT Angiography images.\nWe have proposed a gradient based homogeneity criteria to control the region\ngrow process while segmenting CTA images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.4189v1", 
    "title": "Detection and Demarcation of Tumor using Vector Quantization in MRI   images", 
    "arxiv-id": "1001.4189v1", 
    "author": "Saylee M. Gharge", 
    "publish": "2010-01-23T19:00:44Z", 
    "summary": "Segmenting a MRI images into homogeneous texture regions representing\ndisparate tissue types is often a useful preprocessing step in the\ncomputer-assisted detection of breast cancer. That is why we proposed new\nalgorithm to detect cancer in mammogram breast cancer images. In this paper we\nproposed segmentation using vector quantization technique. Here we used Linde\nBuzo-Gray algorithm (LBG) for segmentation of MRI images. Initially a codebook\nof size 128 was generated for MRI images. These code vectors were further\nclustered in 8 clusters using same LBG algorithm. These 8 images were displayed\nas a result. This approach does not leads to over segmentation or under\nsegmentation. For the comparison purpose we displayed results of watershed\nsegmentation and Entropy using Gray Level Co-occurrence Matrix along with this\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.4297v1", 
    "title": "Multi-camera Realtime 3D Tracking of Multiple Flying Animals", 
    "arxiv-id": "1001.4297v1", 
    "author": "Michael H. Dickinson", 
    "publish": "2010-01-25T01:40:40Z", 
    "summary": "Automated tracking of animal movement allows analyses that would not\notherwise be possible by providing great quantities of data. The additional\ncapability of tracking in realtime - with minimal latency - opens up the\nexperimental possibility of manipulating sensory feedback, thus allowing\ndetailed explorations of the neural basis for control of behavior. Here we\ndescribe a new system capable of tracking the position and body orientation of\nanimals such as flies and birds. The system operates with less than 40 msec\nlatency and can track multiple animals simultaneously. To achieve these\nresults, a multi target tracking algorithm was developed based on the Extended\nKalman Filter and the Nearest Neighbor Standard Filter data association\nalgorithm. In one implementation, an eleven camera system is capable of\ntracking three flies simultaneously at 60 frames per second using a gigabit\nnetwork of nine standard Intel Pentium 4 and Core 2 Duo computers. This\nmanuscript presents the rationale and details of the algorithms employed and\nshows three implementations of the system. An experiment was performed using\nthe tracking system to measure the effect of visual contrast on the flight\nspeed of Drosophila melanogaster. At low contrasts, speed is more variable and\nfaster on average than at high contrasts. Thus, the system is already a useful\ntool to study the neurobiology and behavior of freely flying animals. If\ncombined with other techniques, such as `virtual reality'-type computer\ngraphics or genetic manipulation, the tracking system would offer a powerful\nnew way to investigate the biology of flying animals."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.5352v1", 
    "title": "Kannada Character Recognition System A Review", 
    "arxiv-id": "1001.5352v1", 
    "author": "S. Sethu Selvi", 
    "publish": "2010-01-29T08:29:57Z", 
    "summary": "Intensive research has been done on optical character recognition ocr and a\nlarge number of articles have been published on this topic during the last few\ndecades. Many commercial OCR systems are now available in the market, but most\nof these systems work for Roman, Chinese, Japanese and Arabic characters. There\nare no sufficient number of works on Indian language character recognition\nespecially Kannada script among 12 major scripts in India. This paper presents\na review of existing work on printed Kannada script and their results. The\ncharacteristics of Kannada script and Kannada Character Recognition System kcr\nare discussed in detail. Finally fusion at the classifier level is proposed to\nincrease the recognition accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.5359v1", 
    "title": "Threshold Based Indexing of Commercial Shoe Print to Create Reference   and Recovery Images", 
    "arxiv-id": "1001.5359v1", 
    "author": "S. Arumugam", 
    "publish": "2010-01-29T09:03:48Z", 
    "summary": "One of the important evidence in a crime scene that is normally overlooked\nbut very important evidence is shoe print as the criminal is normally unaware\nof the mask for this. In this paper we use image processing technique to\nprocess reference shoe images to make it index-able for a search from the\ndatabase the shoe print impressions available in the commercial market. This is\nachieved first by converting the commercially available image through the\nprocess of converting them to gray scale then apply image enhancement and\nrestoration techniques and finally do image segmentation to store the segmented\nparameter as index in the database storage. We use histogram method for image\nenhancement, inverse filtering for image restoration and threshold method for\nindexing. We use global threshold as index of the shoe print. The paper\ndescribes this method and simulation results are included to validate the\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1002.1148v1", 
    "title": "A Comparative Study of Removal Noise from Remote Sensing Image", 
    "arxiv-id": "1002.1148v1", 
    "author": "S. D. Khamitkar", 
    "publish": "2010-02-05T08:34:39Z", 
    "summary": "This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.843969", 
    "link": "http://arxiv.org/pdf/1002.1285v1", 
    "title": "The Influence of Intensity Standardization on Medical Image Registration", 
    "arxiv-id": "1002.1285v1", 
    "author": "Li Bai", 
    "publish": "2010-02-05T17:35:49Z", 
    "summary": "Acquisition-to-acquisition signal intensity variations (non-standardness) are\ninherent in MR images. Standardization is a post processing method for\ncorrecting inter-subject intensity variations through transforming all images\nfrom the given image gray scale into a standard gray scale wherein similar\nintensities achieve similar tissue meanings. The lack of a standard image\nintensity scale in MRI leads to many difficulties in tissue characterizability,\nimage display, and analysis, including image segmentation. This phenomenon has\nbeen documented well; however, effects of standardization on medical image\nregistration have not been studied yet. In this paper, we investigate the\ninfluence of intensity standardization in registration tasks with systematic\nand analytic evaluations involving clinical MR images. We conducted nearly\n20,000 clinical MR image registration experiments and evaluated the quality of\nregistrations both quantitatively and qualitatively. The evaluations show that\nintensity variations between images degrades the accuracy of registration\nperformance. The results imply that the accuracy of image registration not only\ndepends on spatial and geometric similarity but also on the similarity of the\nintensity values for the same tissues in different images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.1288v1", 
    "title": "Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical   Images", 
    "arxiv-id": "1002.1288v1", 
    "author": "Xinjian Chen", 
    "publish": "2010-02-05T17:54:36Z", 
    "summary": "This paper investigates, using prior shape models and the concept of ball\nscale (b-scale), ways of automatically recognizing objects in 3D images without\nperforming elaborate searches or optimization. That is, the goal is to place\nthe model in a single shot close to the right pose (position, orientation, and\nscale) in a given image so that the model boundaries fall in the close vicinity\nof object boundaries in the image. This is achieved via the following set of\nkey ideas: (a) A semi-automatic way of constructing a multi-object shape model\nassembly. (b) A novel strategy of encoding, via b-scale, the pose relationship\nbetween objects in the training images and their intensity patterns captured in\nb-scale images. (c) A hierarchical mechanism of positioning the model, in a\none-shot way, in a given image from a knowledge of the learnt pose relationship\nand the b-scale image of the given image to be segmented. The evaluation\nresults on a set of 20 routine clinical abdominal female and male CT data sets\nindicate the following: (1) Incorporating a large number of objects improves\nthe recognition accuracy dramatically. (2) The recognition algorithm can be\nthought as a hierarchical framework such that quick replacement of the model\nassembly is defined as coarse recognition and delineation itself is known as\nfinest recognition. (3) Scale yields useful information about the relationship\nbetween the model assembly and any given image such that the recognition\nresults in a placement of the model close to the actual pose without doing any\nelaborate searches or optimization. (4) Effective object recognition can make\ndelineation most accurate."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.2182v1", 
    "title": "Detection of Microcalcification in Mammograms Using Wavelet Transform   and Fuzzy Shell Clustering", 
    "arxiv-id": "1002.2182v1", 
    "author": "C. Gowri Shankar", 
    "publish": "2010-02-10T19:22:25Z", 
    "summary": "Microcalcifications in mammogram have been mainly targeted as a reliable\nearliest sign of breast cancer and their early detection is vital to improve\nits prognosis. Since their size is very small and may be easily overlooked by\nthe examining radiologist, computer-based detection output can assist the\nradiologist to improve the diagnostic accuracy. In this paper, we have proposed\nan algorithm for detecting microcalcification in mammogram. The proposed\nmicrocalcification detection algorithm involves mammogram quality enhancement\nusing multirresolution analysis based on the dyadic wavelet transform and\nmicrocalcification detection by fuzzy shell clustering. It may be possible to\ndetect nodular components such as microcalcification accurately by introducing\nshape information. The effectiveness of the proposed algorithm for\nmicrocalcification detection is confirmed by experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.2408v1", 
    "title": "Automatic diagnosis of retinal diseases from color retinal images", 
    "arxiv-id": "1002.2408v1", 
    "author": "S. SwarnaParvathi", 
    "publish": "2010-02-11T19:54:08Z", 
    "summary": "Teleophthalmology holds a great potential to improve the quality, access, and\naffordability in health care. For patients, it can reduce the need for travel\nand provide the access to a superspecialist. Ophthalmology lends itself easily\nto telemedicine as it is a largely image based diagnosis. The main goal of the\nproposed system is to diagnose the type of disease in the retina and to\nautomatically detect and segment retinal diseases without human supervision or\ninteraction. The proposed system will diagnose the disease present in the\nretina using a neural network based classifier.The extent of the disease spread\nin the retina can be identified by extracting the textural features of the\nretina. This system will diagnose the following type of diseases: Diabetic\nRetinopathy and Drusen."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.2418v1", 
    "title": "Medical Image Compression using Wavelet Decomposition for Prediction   Method", 
    "arxiv-id": "1002.2418v1", 
    "author": "A. Shanmugam", 
    "publish": "2010-02-11T20:16:33Z", 
    "summary": "In this paper offers a simple and lossless compression method for compression\nof medical images. Method is based on wavelet decomposition of the medical\nimages followed by the correlation analysis of coefficients. The correlation\nanalyses are the basis of prediction equation for each sub band. Predictor\nvariable selection is performed through coefficient graphic method to avoid\nmulticollinearity problem and to achieve high prediction accuracy and\ncompression rate. The method is applied on MRI and CT images. Results show that\nthe proposed approach gives a high compression rate for MRI and CT images\ncomparing with state of the art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.3985v1", 
    "title": "Supervised Learning of Digital image restoration based on Quantization   Nearest Neighbor algorithm", 
    "arxiv-id": "1002.3985v1", 
    "author": "Syed Golam Rajib", 
    "publish": "2010-02-21T18:34:10Z", 
    "summary": "In this paper, an algorithm is proposed for Image Restoration. Such algorithm\nis different from the traditional approaches in this area, by utilizing priors\nthat are learned from similar images. Original images and their degraded\nversions by the known degradation operators are utilized for designing the\nQuantization. The code vectors are designed using the blurred images. For each\nsuch vector, the high frequency information obtained from the original images\nis also available. During restoration, the high frequency information of a\ngiven degraded image is estimated from its low frequency information based on\nthe artificial noise. For the restoration problem, a number of techniques are\ndesigned corresponding to various versions of the blurring function. Given a\nnoisy and blurred image, one of the techniques is chosen based on a similarity\nmeasure, therefore providing the identification of the blur. To make the\nrestoration process computationally efficient, the Quantization Nearest\nNeighborhood approaches are utilized."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0487v1", 
    "title": "Scalable Large-Margin Mahalanobis Distance Metric Learning", 
    "arxiv-id": "1003.0487v1", 
    "author": "Lei Wang", 
    "publish": "2010-03-02T01:12:34Z", 
    "summary": "For many machine learning algorithms such as $k$-Nearest Neighbor ($k$-NN)\nclassifiers and $ k $-means clustering, often their success heavily depends on\nthe metric used to calculate distances between different data points.\n  An effective solution for defining such a metric is to learn it from a set of\nlabeled training samples. In this work, we propose a fast and scalable\nalgorithm to learn a Mahalanobis distance metric. By employing the principle of\nmargin maximization to achieve better generalization performances, this\nalgorithm formulates the metric learning as a convex optimization problem and a\npositive semidefinite (psd) matrix is the unknown variable. a specialized\ngradient descent method is proposed. our algorithm is much more efficient and\nhas a better performance in scalability compared with existing methods.\nExperiments on benchmark data sets suggest that, compared with state-of-the-art\nmetric learning algorithms, our algorithm can achieve a comparable\nclassification accuracy with reduced computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0642v2", 
    "title": "Text Region Extraction from Business Card Images for Mobile Devices", 
    "arxiv-id": "1003.0642v2", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-03-02T17:45:26Z", 
    "summary": "Designing a Business Card Reader (BCR) for mobile devices is a challenge to\nthe researchers because of huge deformation in acquired images, multiplicity in\nnature of the business cards and most importantly the computational constraints\nof the mobile devices. This paper presents a text extraction method designed in\nour work towards developing a BCR for mobile devices. At first, the background\nof a camera captured image is eliminated at a coarse level. Then, various rule\nbased techniques are applied on the Connected Components (CC) to filter out the\nnoises and picture regions. The CCs identified as text are then binarized using\nan adaptive but light-weight binarization technique. Experiments show that the\ntext extraction accuracy is around 98% for a wide range of resolutions with\nvarying computation time and memory requirements. The optimum performance is\nachieved for the images of resolution 1024x768 pixels with text extraction\naccuracy of 98.54% and, space and time requirements as 1.1 MB and 0.16 seconds\nrespectively."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0645v2", 
    "title": "Binarizing Business Card Images for Mobile Devices", 
    "arxiv-id": "1003.0645v2", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-03-02T18:02:40Z", 
    "summary": "Business card images are of multiple natures as these often contain graphics,\npictures and texts of various fonts and sizes both in background and\nforeground. So, the conventional binarization techniques designed for document\nimages can not be directly applied on mobile devices. In this paper, we have\npresented a fast binarization technique for camera captured business card\nimages. A card image is split into small blocks. Some of these blocks are\nclassified as part of the background based on intensity variance. Then the\nnon-text regions are eliminated and the text ones are skew corrected and\nbinarized using a simple yet adaptive technique. Experiment shows that the\ntechnique is fast, efficient and applicable for the mobile devices."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0776v1", 
    "title": "Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays", 
    "arxiv-id": "1003.0776v1", 
    "author": "Inger Fabris-Rotelli", 
    "publish": "2010-03-03T10:58:20Z", 
    "summary": "This report presents properties of the Discrete Pulse Transform on\nmulti-dimensional arrays introduced by the authors two or so years ago. The\nmain result given here in Lemma 2.1 is also formulated in a paper to appear in\nIEEE Transactions on Image Processing. However, the proof, being too technical,\nwas omitted there and hence it appears in full in this publication."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1072v2", 
    "title": "An Offline Technique for Localization of License Plates for Indian   Commercial Vehicles", 
    "arxiv-id": "1003.1072v2", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-03-04T15:57:41Z", 
    "summary": "Automatic License Plate Recognition (ALPR) is a challenging area of research\ndue to its importance to variety of commercial applications. The overall\nproblem may be subdivided into two key modules, firstly, localization of\nlicense plates from vehicle images, and secondly, optical character recognition\nof extracted license plates. In the current work, we have concentrated on the\nfirst part of the problem, i.e., localization of license plate regions from\nIndian commercial vehicles as a significant step towards development of a\ncomplete ALPR system for Indian vehicles. The technique is based on color based\nsegmentation of vehicle images and identification of potential license plate\nregions. True license plates are finally localized based on four spatial and\nhorizontal contrast features. The technique successfully localizes the actual\nlicense plates in 73.4% images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1511v1", 
    "title": "Clinical gait data analysis based on Spatio-Temporal features", 
    "arxiv-id": "1003.1511v1", 
    "author": "Dr. Vinay Kumar Pathak", 
    "publish": "2010-03-07T18:46:12Z", 
    "summary": "Analysing human gait has found considerable interest in recent computer\nvision research. So far, however, contributions to this topic exclusively dealt\nwith the tasks of person identification or activity recognition. In this paper,\nwe consider a different application for gait analysis and examine its use as a\nmeans of deducing the physical well-being of people. The proposed method is\nbased on transforming the joint motion trajectories using wavelets to extract\nspatio-temporal features which are then fed as input to a vector quantiser; a\nself-organising map for classification of walking patterns of individuals with\nand without pathology. We show that our proposed algorithm is successful in\nextracting features that successfully discriminate between individuals with and\nwithout locomotion impairment."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1803v1", 
    "title": "Nonlinear Filter Based Image Denoising Using AMF Approach", 
    "arxiv-id": "1003.1803v1", 
    "author": "RM. Chandrasekaran", 
    "publish": "2010-03-09T07:05:47Z", 
    "summary": "This paper proposes a new technique based on nonlinear Adaptive Median filter\n(AMF) for image restoration. Image denoising is a common procedure in digital\nimage processing aiming at the removal of noise, which may corrupt an image\nduring its acquisition or transmission, while retaining its quality. This\nprocedure is traditionally performed in the spatial or frequency domain by\nfiltering. The aim of image enhancement is to reconstruct the true image from\nthe corrupted image. The process of image acquisition frequently leads to\ndegradation and the quality of the digitized image becomes inferior to the\noriginal image. Filtering is a technique for enhancing the image. Linear filter\nis the filtering in which the value of an output pixel is a linear combination\nof neighborhood values, which can produce blur in the image. Thus a variety of\nsmoothing techniques have been developed that are non linear. Median filter is\nthe one of the most popular non-linear filter. When considering a small\nneighborhood it is highly efficient but for large window and in case of high\nnoise it gives rise to more blurring to image. The Centre Weighted Median (CWM)\nfilter has got a better average performance over the median filter [8]. However\nthe original pixel corrupted and noise reduction is substantial under high\nnoise condition. Hence this technique has also blurring affect on the image. To\nillustrate the superiority of the proposed approach by overcoming the existing\nproblem, the proposed new scheme (AMF) Adaptive Median Filter has been\nsimulated along with the standard ones and various performance measures have\nbeen compared."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1819v1", 
    "title": "Facial Gesture Recognition Using Correlation And Mahalanobis Distance", 
    "arxiv-id": "1003.1819v1", 
    "author": "Rahul Bhatia", 
    "publish": "2010-03-09T07:39:03Z", 
    "summary": "Augmenting human computer interaction with automated analysis and synthesis\nof facial expressions is a goal towards which much research effort has been\ndevoted recently. Facial gesture recognition is one of the important component\nof natural human-machine interfaces; it may also be used in behavioural\nscience, security systems and in clinical practice. Although humans recognise\nfacial expressions virtually without effort or delay, reliable expression\nrecognition by machine is still a challenge. The face expression recognition\nproblem is challenging because different individuals display the same\nexpression differently. This paper presents an overview of gesture recognition\nin real time using the concepts of correlation and Mahalanobis distance.We\nconsider the six universal emotional categories namely joy, anger, fear,\ndisgust, sadness and surprise."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1826v1", 
    "title": "A GA based Window Selection Methodology to Enhance Window based Multi   wavelet transformation and thresholding aided CT image denoising technique", 
    "arxiv-id": "1003.1826v1", 
    "author": "K. Lal kishore", 
    "publish": "2010-03-09T08:09:02Z", 
    "summary": "Image denoising is getting more significance, especially in Computed\nTomography (CT), which is an important and most common modality in medical\nimaging. This is mainly due to that the effectiveness of clinical diagnosis\nusing CT image lies on the image quality. The denoising technique for CT images\nusing window-based Multi-wavelet transformation and thresholding shows the\neffectiveness in denoising, however, a drawback exists in selecting the closer\nwindows in the process of window-based multi-wavelet transformation and\nthresholding. Generally, the windows of the duplicate noisy image that are\ncloser to each window of original noisy image are obtained by the checking them\nsequentially. This leads to the possibility of missing out very closer windows\nand so enhancement is required in the aforesaid process of the denoising\ntechnique. In this paper, we propose a GA-based window selection methodology to\ninclude the denoising technique. With the aid of the GA-based window selection\nmethodology, the windows of the duplicate noisy image that are very closer to\nevery window of the original noisy image are extracted in an effective manner.\nBy incorporating the proposed GA-based window selection methodology, the\ndenoising the CT image is performed effectively. Eventually, a comparison is\nmade between the denoising technique with and without the proposed GA-based\nwindow selection methodology."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1827v1", 
    "title": "Investigation and Assessment of Disorder of Ultrasound B-mode Images", 
    "arxiv-id": "1003.1827v1", 
    "author": "Vibhakar shrimali", 
    "publish": "2010-03-09T08:13:37Z", 
    "summary": "Digital image plays a vital role in the early detection of cancers, such as\nprostate cancer, breast cancer, lungs cancer, cervical cancer. Ultrasound\nimaging method is also suitable for early detection of the abnormality of\nfetus. The accurate detection of region of interest in ultrasound image is\ncrucial. Since the result of reflection, refraction and deflection of\nultrasound waves from different types of tissues with different acoustic\nimpedance. Usually, the contrast in ultrasound image is very low and weak edges\nmake the image difficult to identify the fetus region in the ultrasound image.\nSo the analysis of ultrasound image is more challenging one. We try to develop\na new algorithmic approach to solve the problem of non clarity and find\ndisorder of it. Generally there is no common enhancement approach for noise\nreduction. This paper proposes different filtering techniques based on\nstatistical methods for the removal of various noise. The quality of the\nenhanced images is measured by the statistical quantity measures:\nSignal-to-Noise Ratio (SNR), Peak Signal-to-Noise Ratio (PSNR), and Root Mean\nSquare Error (RMSE)."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1891v1", 
    "title": "Handwritten Arabic Numeral Recognition using a Multi Layer Perceptron", 
    "arxiv-id": "1003.1891v1", 
    "author": "Syed Sahidul Haque", 
    "publish": "2010-03-09T14:56:00Z", 
    "summary": "Handwritten numeral recognition is in general a benchmark problem of Pattern\nRecognition and Artificial Intelligence. Compared to the problem of printed\nnumeral recognition, the problem of handwritten numeral recognition is\ncompounded due to variations in shapes and sizes of handwritten characters.\nConsidering all these, the problem of handwritten numeral recognition is\naddressed under the present work in respect to handwritten Arabic numerals.\nArabic is spoken throughout the Arab World and the fifth most popular language\nin the world slightly before Portuguese and Bengali. For the present work, we\nhave developed a feature set of 88 features is designed to represent samples of\nhandwritten Arabic numerals for this work. It includes 72 shadow and 16 octant\nfeatures. A Multi Layer Perceptron (MLP) based classifier is used here for\nrecognition handwritten Arabic digits represented with the said feature set. On\nexperimentation with a database of 3000 samples, the technique yields an\naverage recognition rate of 94.93% evaluated after three-fold cross validation\nof results. It is useful for applications related to OCR of handwritten Arabic\nDigit and can also be extended to include OCR of handwritten characters of\nArabic alphabet."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1894v1", 
    "title": "A comparative study of different feature sets for recognition of   handwritten Arabic numerals using a Multi Layer Perceptron", 
    "arxiv-id": "1003.1894v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-09T15:05:37Z", 
    "summary": "The work presents a comparative assessment of seven different feature sets\nfor recognition of handwritten Arabic numerals using a Multi Layer Perceptron\n(MLP) based classifier. The seven feature sets employed here consist of shadow\nfeatures, octant centroids, longest runs, angular distances, effective spans,\ndynamic centers of gravity, and some of their combinations. On experimentation\nwith a database of 3000 samples, the maximum recognition rate of 95.80% is\nobserved with both of two separate combinations of features. One of these\ncombinations consists of shadow and centriod features, i. e. 88 features in\nall, and the other shadow, centroid and longest run features, i. e. 124\nfeatures in all. Out of these two, the former combination having a smaller\nnumber of features is finally considered effective for applications related to\nOptical Character Recognition (OCR) of handwritten Arabic numerals. The work\ncan also be extended to include OCR of handwritten characters of Arabic\nalphabet."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.3266v1", 
    "title": "Pattern recognition using inverse resonance filtration", 
    "arxiv-id": "1003.3266v1", 
    "author": "Roman Kvetnyy", 
    "publish": "2010-03-16T22:30:12Z", 
    "summary": "An approach to textures pattern recognition based on inverse resonance\nfiltration (IRF) is considered. A set of principal resonance harmonics of\ntextured image signal fluctuations eigen harmonic decomposition (EHD) is used\nfor the IRF design. It was shown that EHD is invariant to textured image linear\nshift. The recognition of texture is made by transfer of its signal into\nunstructured signal which simple statistical parameters can be used for texture\npattern recognition. Anomalous variations of this signal point on foreign\nobjects. Two methods of 2D EHD parameters estimation are considered with the\naccount of texture signal breaks presence. The first method is based on the\nlinear symmetry model that is not sensitive to signal phase jumps. The\ncondition of characteristic polynomial symmetry provides the model stationarity\nand periodicity. Second method is based on the eigenvalues problem of matrices\npencil projection into principal vectors space of singular values decomposition\n(SVD) of 2D correlation matrix. Two methods of classification of retrieval from\ntextured image foreign objects are offered."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.3654v1", 
    "title": "Sliding window approach based Text Binarisation from Complex Textual   images", 
    "arxiv-id": "1003.3654v1", 
    "author": "D. Manjula", 
    "publish": "2010-03-18T19:01:56Z", 
    "summary": "Text binarisation process classifies individual pixels as text or background\nin the textual images. Binarization is necessary to bridge the gap between\nlocalization and recognition by OCR. This paper presents Sliding window method\nto binarise text from textual images with textured background. Suitable\npreprocessing techniques are applied first to increase the contrast of the\nimage and blur the background noises due to textured background. Then Edges are\ndetected by iterative thresholding. Subsequently formed edge boxes are analyzed\nto remove unwanted edges due to complex background and binarised by sliding\nwindow approach based character size uniformity check algorithm. The proposed\nmethod has been applied on localized region from heterogeneous textual images\nand compared with Otsu, Niblack methods and shown encouraging performance of\nthe proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.4021v1", 
    "title": "System-theoretic approach to image interest point detection", 
    "arxiv-id": "1003.4021v1", 
    "author": "Vitaly Pimenov", 
    "publish": "2010-03-21T20:21:09Z", 
    "summary": "Interest point detection is a common task in various computer vision\napplications. Although a big variety of detector are developed so far\ncomputational efficiency of interest point based image analysis remains to be\nthe problem. Current paper proposes a system-theoretic approach to interest\npoint detection. Starting from the analysis of interdependency between detector\nand descriptor it is shown that given a descriptor it is possible to introduce\nto notion of detector redundancy. Furthermore for each detector it is possible\nto construct its irredundant and equivalent modification. Modified detector\npossesses lower computational complexity and is preferable. It is also shown\nthat several known approaches to reduce computational complexity of image\nregistration can be generalized in terms of proposed theory."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.4053v1", 
    "title": "A Comprehensive Review of Image Enhancement Techniques", 
    "arxiv-id": "1003.4053v1", 
    "author": "Himanshu Aggarwal", 
    "publish": "2010-03-22T03:39:46Z", 
    "summary": "Principle objective of Image enhancement is to process an image so that\nresult is more suitable than original image for specific application. Digital\nimage enhancement techniques provide a multitude of choices for improving the\nvisual quality of images. Appropriate choice of such techniques is greatly\ninfluenced by the imaging modality, task at hand and viewing conditions. This\npaper will provide an overview of underlying concepts, along with algorithms\ncommonly used for image enhancement. The paper focuses on spatial domain\ntechniques for image enhancement, with particular reference to point processing\nmethods and histogram processing."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.4087v1", 
    "title": "Land-cover Classification and Mapping for Eastern Himalayan State Sikkim", 
    "arxiv-id": "1003.4087v1", 
    "author": "M. K. Ghose", 
    "publish": "2010-03-22T06:49:30Z", 
    "summary": "Area of classifying satellite imagery has become a challenging task in\ncurrent era where there is tremendous growth in settlement i.e. construction of\nbuildings, roads, bridges, dam etc. This paper suggests an improvised k-means\nand Artificial Neural Network (ANN) classifier for land-cover mapping of\nEastern Himalayan state Sikkim. The improvised k-means algorithm shows\nsatisfactory results compared to existing methods that includes k-Nearest\nNeighbor and maximum likelihood classifier. The strength of the Artificial\nNeural Network (ANN) classifier lies in the fact that they are fast and have\ngood recognition rate and it's capability of self-learning compared to other\nclassification algorithms has made it widely accepted. Classifier based on ANN\nshows satisfactory and accurate result in comparison with the classical method."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5249v1", 
    "title": "Active Testing for Face Detection and Localization", 
    "arxiv-id": "1003.5249v1", 
    "author": "Bruno Jedynak", 
    "publish": "2010-03-27T00:17:19Z", 
    "summary": "We provide a novel search technique, which uses a hierarchical model and a\nmutual information gain heuristic to efficiently prune the search space when\nlocalizing faces in images. We show exponential gains in computation over\ntraditional sliding window approaches, while keeping similar performance\nlevels."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5320v1", 
    "title": "The Video Genome", 
    "arxiv-id": "1003.5320v1", 
    "author": "Ron Kimmel", 
    "publish": "2010-03-27T20:57:47Z", 
    "summary": "Fast evolution of Internet technologies has led to an explosive growth of\nvideo data available in the public domain and created unprecedented challenges\nin the analysis, organization, management, and control of such content. The\nproblems encountered in video analysis such as identifying a video in a large\ndatabase (e.g. detecting pirated content in YouTube), putting together video\nfragments, finding similarities and common ancestry between different versions\nof a video, have analogous counterpart problems in genetic research and\nanalysis of DNA and protein sequences. In this paper, we exploit the analogy\nbetween genetic sequences and videos and propose an approach to video analysis\nmotivated by genomic research. Representing video information as video DNA\nsequences and applying bioinformatic algorithms allows to search, match, and\ncompare videos in large-scale databases. We show an application for\ncontent-based metadata mapping between versions of annotated video."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5821v1", 
    "title": "Tuning CLD Maps", 
    "arxiv-id": "1003.5821v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2010-03-30T13:58:08Z", 
    "summary": "The Coherence Length Diagram and the related maps have been shown to\nrepresent a useful tool for image analysis. Setting threshold parameters is one\nof the most important issues when dealing with such applications, as they\naffect both the computability, which is outlined by the support map, and the\nappearance of the coherence length diagram itself and of defect maps. A coupled\noptimization analysis, returning a range for the basic (saturation) threshold,\nand a histogram based method, yielding suitable values for a desired map\nappearance, are proposed for an effective control of the analysis process."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5861v1", 
    "title": "Robust multi-camera view face recognition", 
    "arxiv-id": "1003.5861v1", 
    "author": "Jamuna Kanta Sing", 
    "publish": "2010-03-30T16:26:39Z", 
    "summary": "This paper presents multi-appearance fusion of Principal Component Analysis\n(PCA) and generalization of Linear Discriminant Analysis (LDA) for multi-camera\nview offline face recognition (verification) system. The generalization of LDA\nhas been extended to establish correlations between the face classes in the\ntransformed representation and this is called canonical covariate. The proposed\nsystem uses Gabor filter banks for characterization of facial features by\nspatial frequency, spatial locality and orientation to make compensate to the\nvariations of face instances occurred due to illumination, pose and facial\nexpression changes. Convolution of Gabor filter bank to face images produces\nGabor face representations with high dimensional feature vectors. PCA and\ncanonical covariate are then applied on the Gabor face representations to\nreduce the high dimensional feature spaces into low dimensional Gabor\neigenfaces and Gabor canonical faces. Reduced eigenface vector and canonical\nface vector are fused together using weighted mean fusion rule. Finally,\nsupport vector machines (SVM) have trained with augmented fused set of features\nand perform the recognition task. The system has been evaluated with UMIST face\ndatabase consisting of multiview faces. The experimental results demonstrate\nthe efficiency and robustness of the proposed system for multi-view face images\nwith high recognition rates. Complexity analysis of the proposed system is also\npresented at the end of the experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5886v1", 
    "title": "Development of a multi-user handwriting recognition system using   Tesseract open source OCR engine", 
    "arxiv-id": "1003.5886v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:22:44Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of lower case\nRoman script using Tesseract open source Optical Character Recognition (OCR)\nengine under Apache License 2.0. Handwritten data samples containing isolated\nand free-flow text were collected from different users. Tesseract is trained\nwith user-specific data samples of both the categories of document pages to\ngenerate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated and free-flow handwritten test samples\ncollected from the designated user. On a three user model, the system is\ntrained with 1844, 1535 and 1113 isolated handwritten character samples\ncollected from three different users and the performance is tested on 1133,\n1186 and 1204 character samples, collected form the test sets of the three\nusers respectively. The user specific character level accuracies were obtained\nas 87.92%, 81.53% and 65.71% respectively. The overall character-level accuracy\nof the system is observed as 78.39%. The system fails to segment 10.96%\ncharacters and erroneously classifies 10.65% characters on the overall dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5891v1", 
    "title": "Recognition of Handwritten Roman Script Using Tesseract Open source OCR   Engine", 
    "arxiv-id": "1003.5891v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:35:37Z", 
    "summary": "In the present work, we have used Tesseract 2.01 open source Optical\nCharacter Recognition (OCR) Engine under Apache License 2.0 for recognition of\nhandwriting samples of lower case Roman script. Handwritten isolated and\nfree-flow text samples were collected from multiple users. Tesseract is trained\nto recognize user-specific handwriting samples of both the categories of\ndocument pages. On a single user model, the system is trained with 1844\nisolated handwritten characters and the performance is tested on 1133\ncharacters, taken form the test set. The overall character-level accuracy of\nthe system is observed as 83.5%. The system fails to segment 5.56% characters\nand erroneously classifies 10.94% characters."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5893v1", 
    "title": "Recognition of Handwritten Textual Annotations using Tesseract Open   Source OCR Engine for information Just In Time (iJIT)", 
    "arxiv-id": "1003.5893v1", 
    "author": "Hisashi Ikeda", 
    "publish": "2010-03-30T18:48:47Z", 
    "summary": "Objective of the current work is to develop an Optical Character Recognition\n(OCR) engine for information Just In Time (iJIT) system that can be used for\nrecognition of handwritten textual annotations of lower case Roman script.\nTesseract open source OCR engine under Apache License 2.0 is used to develop\nuser-specific handwriting recognition models, viz., the language sets, for the\nsaid system, where each user is identified by a unique identification tag\nassociated with the digital pen. To generate the language set for any user,\nTesseract is trained with labeled handwritten data samples of isolated and\nfree-flow texts of Roman script, collected exclusively from that user. The\ndesigned system is tested on five different language sets with free- flow\nhandwritten annotations as test samples. The system could successfully segment\nand subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80%\nhandwritten characters in the test samples of five different users."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5897v1", 
    "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla   Basic Characters and Digits", 
    "arxiv-id": "1003.5897v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:54:57Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5898v1", 
    "title": "Recognition of handwritten Roman Numerals using Tesseract open source   OCR engine", 
    "arxiv-id": "1003.5898v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:59:49Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of Roman\nnumerals using Tesseract open source Optical Character Recognition (OCR)\nengine. Tesseract is trained with data samples of different persons to generate\none user-independent language model, representing the handwritten Roman\ndigit-set. The system is trained with 1226 digit samples collected form the\ndifferent users. The performance is tested on two different datasets, one\nconsisting of samples collected from the known users (those who prepared the\ntraining data samples) and the other consisting of handwritten data samples of\nunknown users. The overall recognition accuracy is obtained as 92.1% and 86.59%\non these test datasets respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.6052v2", 
    "title": "Development of an automated Red Light Violation Detection System (RLVDS)   for Indian vehicles", 
    "arxiv-id": "1003.6052v2", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-03-31T13:44:29Z", 
    "summary": "Integrated Traffic Management Systems (ITMS) are now implemented in different\ncities in India to primarily address the concerns of road-safety and security.\nAn automated Red Light Violation Detection System (RLVDS) is an integral part\nof the ITMS. In our present work we have designed and developed a complete\nsystem for generating the list of all stop-line violating vehicle images\nautomatically from video snapshots of road-side surveillance cameras. The\nsystem first generates adaptive background images for each camera view,\nsubtracts captured images from the corresponding background images and analyses\npotential occlusions over the stop-line in a traffic signal. Considering\nround-the-clock operations in a real-life test environment, the developed\nsystem could successfully track 92% images of vehicles with violations on the\nstop-line in a \"Red\" traffic signal."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.6059v2", 
    "title": "A novel scheme for binarization of vehicle images using hierarchical   histogram equalization technique", 
    "arxiv-id": "1003.6059v2", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-03-31T14:00:16Z", 
    "summary": "Automatic License Plate Recognition system is a challenging area of research\nnow-a-days and binarization is an integral and most important part of it. In\ncase of a real life scenario, most of existing methods fail to properly\nbinarize the image of a vehicle in a congested road, captured through a CCD\ncamera. In the current work we have applied histogram equalization technique\nover the complete image and also over different hierarchy of image\npartitioning. A novel scheme is formulated for giving the membership value to\neach pixel for each hierarchy of histogram equalization. Then the image is\nbinarized depending on the net membership value of each pixel. The technique is\nexhaustively evaluated on the vehicle image dataset as well as the license\nplate dataset, giving satisfactory performances."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.0512v1", 
    "title": "Analysis, Interpretation, and Recognition of Facial Action Units and   Expressions Using Neuro-Fuzzy Modeling", 
    "arxiv-id": "1004.0512v1", 
    "author": "Ali A. Kiaei", 
    "publish": "2010-04-04T15:20:27Z", 
    "summary": "In this paper an accurate real-time sequence-based system for representation,\nrecognition, interpretation, and analysis of the facial action units (AUs) and\nexpressions is presented. Our system has the following characteristics: 1)\nemploying adaptive-network-based fuzzy inference systems (ANFIS) and temporal\ninformation, we developed a classification scheme based on neuro-fuzzy modeling\nof the AU intensity, which is robust to intensity variations, 2) using both\ngeometric and appearance-based features, and applying efficient dimension\nreduction techniques, our system is robust to illumination changes and it can\nrepresent the subtle changes as well as temporal information involved in\nformation of the facial expressions, and 3) by continuous values of intensity\nand employing top-down hierarchical rule-based classifiers, we can develop\naccurate human-interpretable AU-to-expression converters. Extensive experiments\non Cohn-Kanade database show the superiority of the proposed method, in\ncomparison with support vector machines, hidden Markov models, and neural\nnetwork classifiers. Keywords: biased discriminant analysis (BDA), classifier\ndesign and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy\nmodeling."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1215v1", 
    "title": "Regularized Richardson-Lucy Algorithm for Sparse Reconstruction of   Poissonian Images", 
    "arxiv-id": "1004.1215v1", 
    "author": "Oleg Michailovich", 
    "publish": "2010-04-08T01:08:30Z", 
    "summary": "Restoration of digital images from their degraded measurements has always\nbeen a problem of great theoretical and practical importance in numerous\napplications of imaging sciences. A specific solution to the problem of image\nrestoration is generally determined by the nature of degradation phenomenon as\nwell as by the statistical properties of measurement noises. The present study\nis concerned with the case in which the images of interest are corrupted by\nconvolutional blurs and Poisson noises. To deal with such problems, there\nexists a range of solution methods which are based on the principles\noriginating from the fixed-point algorithm of Richardson and Lucy (RL). In this\npaper, we provide conceptual and experimental proof that such methods tend to\nconverge to sparse solutions, which makes them applicable only to those images\nwhich can be represented by a relatively small number of non-zero samples in\nthe spatial domain. Unfortunately, the set of such images is relatively small,\nwhich restricts the applicability of RL-type methods. On the other hand,\nvirtually all practical images admit sparse representations in the domain of a\nproperly designed linear transform. To take advantage of this fact, it is\ntherefore tempting to modify the RL algorithm so as to make it recover\nrepresentation coefficients, rather than the values of their associated image.\nSuch modification is introduced in this paper. Apart from the generality of its\nassumptions, the proposed method is also superior to many established\nreconstruction approaches in terms of estimation accuracy and computational\ncomplexity. This and other conclusions of this study are validated through a\nseries of numerical experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1227v1", 
    "title": "Signature Recognition using Multi Scale Fourier Descriptor And Wavelet   Transform", 
    "arxiv-id": "1004.1227v1", 
    "author": "Ahmed H. Samak", 
    "publish": "2010-04-08T02:39:49Z", 
    "summary": "This paper present a novel off-line signature recognition method based on\nmulti scale Fourier Descriptor and wavelet transform . The main steps of\nconstructing a signature recognition system are discussed and experiments on\nreal data sets show that the average error rate can reach 1%. Finally we\ncompare 8 distance measures between feature vectors with respect to the\nrecognition performance.\n  Key words: signature recognition; Fourier Descriptor; Wavelet transform;\npersonal verification"
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1679v1", 
    "title": "A Robust Fuzzy Clustering Technique with Spatial Neighborhood   Information for Effective Medical Image Segmentation", 
    "arxiv-id": "1004.1679v1", 
    "author": "K. Senthamaraikannan", 
    "publish": "2010-04-10T04:04:12Z", 
    "summary": "Medical image segmentation demands an efficient and robust segmentation\nalgorithm against noise. The conventional fuzzy c-means algorithm is an\nefficient clustering algorithm that is used in medical image segmentation. But\nFCM is highly vulnerable to noise since it uses only intensity values for\nclustering the images. This paper aims to develop a novel and efficient fuzzy\nspatial c-means clustering algorithm which is robust to noise. The proposed\nclustering algorithm uses fuzzy spatial information to calculate membership\nvalue. The input image is clustered using proposed ISFCM algorithm. A\ncomparative study has been made between the conventional FCM and proposed\nISFCM. The proposed approach is found to be outperforming the conventional FCM."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1768v1", 
    "title": "A New Approach to Lung Image Segmentation using Fuzzy Possibilistic   C-Means Algorithm", 
    "arxiv-id": "1004.1768v1", 
    "author": "P. Thangaraj", 
    "publish": "2010-04-11T08:01:08Z", 
    "summary": "Image segmentation is a vital part of image processing. Segmentation has its\napplication widespread in the field of medical images in order to diagnose\ncurious diseases. The same medical images can be segmented manually. But the\naccuracy of image segmentation using the segmentation algorithms is more when\ncompared with the manual segmentation. In the field of medical diagnosis an\nextensive diversity of imaging techniques is presently available, such as\nradiography, computed tomography (CT) and magnetic resonance imaging (MRI).\nMedical image segmentation is an essential step for most consequent image\nanalysis tasks. Although the original FCM algorithm yields good results for\nsegmenting noise free images, it fails to segment images corrupted by noise,\noutliers and other imaging artifact. This paper presents an image segmentation\napproach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic\nc-means algorithm (FPCM). This approach is a generalized version of standard\nFuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM\ntechnique is eliminated in modifying the standard technique. The Modified FCM\nalgorithm is formulated by modifying the distance measurement of the standard\nFCM algorithm to permit the labeling of a pixel to be influenced by other\npixels and to restrain the noise effect during segmentation. Instead of having\none term in the objective function, a second term is included, forcing the\nmembership to be as high as possible without a maximum limit constraint of one.\nExperiments are conducted on real images to investigate the performance of the\nproposed modified FCM technique in segmenting the medical images. Standard FCM,\nModified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to\nexplore the accuracy of our proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1886v1", 
    "title": "Feature Level Fusion of Face and Palmprint Biometrics by Isomorphic   Graph-based Improved K-Medoids Partitioning", 
    "arxiv-id": "1004.1886v1", 
    "author": "Jamuna Kanta Sing", 
    "publish": "2010-04-12T07:34:39Z", 
    "summary": "This paper presents a feature level fusion approach which uses the improved\nK-medoids clustering algorithm and isomorphic graph for face and palmprint\nbiometrics. Partitioning around medoids (PAM) algorithm is used to partition\nthe set of n invariant feature points of the face and palmprint images into k\nclusters. By partitioning the face and palmprint images with scale invariant\nfeatures SIFT points, a number of clusters is formed on both the images. Then\non each cluster, an isomorphic graph is drawn. In the next step, the most\nprobable pair of graphs is searched using iterative relaxation algorithm from\nall possible isomorphic graphs for a pair of corresponding face and palmprint\nimages. Finally, graphs are fused by pairing the isomorphic graphs into\naugmented groups in terms of addition of invariant SIFT points and in terms of\ncombining pair of keypoint descriptors by concatenation rule. Experimental\nresults obtained from the extensive evaluation show that the proposed feature\nlevel fusion with the improved K-medoids partitioning algorithm increases the\nperformance of the system with utmost level of accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.1887v1", 
    "title": "Maximized Posteriori Attributes Selection from Facial Salient Landmarks   for Face Recognition", 
    "arxiv-id": "1004.1887v1", 
    "author": "Massimo Tistarelli", 
    "publish": "2010-04-12T07:42:09Z", 
    "summary": "This paper presents a robust and dynamic face recognition technique based on\nthe extraction and matching of devised probabilistic graphs drawn on SIFT\nfeatures related to independent face areas. The face matching strategy is based\non matching individual salient facial graph characterized by SIFT features as\nconnected to facial landmarks such as the eyes and the mouth. In order to\nreduce the face matching errors, the Dempster-Shafer decision theory is applied\nto fuse the individual matching scores obtained from each pair of salient\nfacial features. The proposed algorithm is evaluated with the ORL and the IITK\nface databases. The experimental results demonstrate the effectiveness and\npotential of the proposed face recognition technique also in case of partially\noccluded faces."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3257v1", 
    "title": "Offline Handwriting Recognition using Genetic Algorithm", 
    "arxiv-id": "1004.3257v1", 
    "author": "Ritu Tiwari", 
    "publish": "2010-04-19T17:49:28Z", 
    "summary": "Handwriting Recognition enables a person to scribble something on a piece of\npaper and then convert it into text. If we look into the practical reality\nthere are enumerable styles in which a character may be written. These styles\ncan be self combined to generate more styles. Even if a small child knows the\nbasic styles a character can be written, he would be able to recognize\ncharacters written in styles intermediate between them or formed by their\nmixture. This motivates the use of Genetic Algorithms for the problem. In order\nto prove this, we made a pool of images of characters. We converted them to\ngraphs. The graph of every character was intermixed to generate styles\nintermediate between the styles of parent character. Character recognition\ninvolved the matching of the graph generated from the unknown character image\nwith the graphs generated by mixing. Using this method we received an accuracy\nof 98.44%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3276v1", 
    "title": "Color Image Compression Based On Wavelet Packet Best Tree", 
    "arxiv-id": "1004.3276v1", 
    "author": "V. H. Patil", 
    "publish": "2010-04-19T18:28:46Z", 
    "summary": "In Image Compression, the researchers' aim is to reduce the number of bits\nrequired to represent an image by removing the spatial and spectral\nredundancies. Recently discrete wavelet transform and wavelet packet has\nemerged as popular techniques for image compression. The wavelet transform is\none of the major processing components of image compression. The result of the\ncompression changes as per the basis and tap of the wavelet used. It is\nproposed that proper selection of mother wavelet on the basis of nature of\nimages, improve the quality as well as compression ratio remarkably. We suggest\nthe novel technique, which is based on wavelet packet best tree based on\nThreshold Entropy with enhanced run-length encoding. This method reduces the\ntime complexity of wavelet packets decomposition as complete tree is not\ndecomposed. Our algorithm selects the sub-bands, which include significant\ninformation based on threshold entropy. The enhanced run length encoding\ntechnique is suggested provides better results than RLE. The result when\ncompared with JPEG-2000 proves to be better."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3549v1", 
    "title": "Signature Region of Interest using Auto cropping", 
    "arxiv-id": "1004.3549v1", 
    "author": "Islam H. AlTarawneh", 
    "publish": "2010-04-20T20:04:17Z", 
    "summary": "A new approach for signature region of interest pre-processing was presented.\nIt used new auto cropping preparation on the basis of the image content, where\nthe intensity value of pixel is the source of cropping. This approach provides\nboth the possibility of improving the performance of security systems based on\nsignature images, and also the ability to use only the region of interest of\nthe used image to suit layout design of biometric systems. Underlying the\napproach is a novel segmentation method which identifies the exact region of\nforeground of signature for feature extraction usage. Evaluation results of\nthis approach shows encouraging prospects by eliminating the need for false\nregion isolating, reduces the time cost associated with signature false points\ndetection, and addresses enhancement issues. A further contribution of this\npaper is an automated cropping stage in bio-secure based systems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3629v1", 
    "title": "Simultaneous Bayesian inference of motion velocity fields and   probabilistic models in successive video-frames described by spatio-temporal   MRFs", 
    "arxiv-id": "1004.3629v1", 
    "author": "Jun-ichi Inoue", 
    "publish": "2010-04-21T06:27:47Z", 
    "summary": "We numerically investigate a mean-field Bayesian approach with the assistance\nof the Markov chain Monte Carlo method to estimate motion velocity fields and\nprobabilistic models simultaneously in consecutive digital images described by\nspatio-temporal Markov random fields. Preliminary to construction of our\nprocedure, we find that mean-field variables in the iteration diverge due to\nimproper normalization factor of regularization terms appearing in the\nposterior. To avoid this difficulty, we rescale the regularization term by\nintroducing a scaling factor and optimizing it by means of minimization of the\nmean-square error. We confirm that the optimal scaling factor stabilizes the\nmean-field iterative process of the motion velocity estimation. We next attempt\nto estimate the optimal values of hyper-parameters including the regularization\nterm, which define our probabilistic model macroscopically, by using the\nBoltzmann-machine type learning algorithm based on gradient descent of marginal\nlikelihood (type-II likelihood) with respect to the hyper-parameters. In our\nframework, one can estimate both the probabilistic model (hyper-parameters) and\nmotion velocity fields simultaneously. We find that our motion estimation is\nmuch better than the result obtained by Zhang and Hanouer (1995) in which the\nhyper-parameters are set to some ad-hoc values without any theoretical\njustification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3980v1", 
    "title": "Hashing Image Patches for Zooming", 
    "arxiv-id": "1004.3980v1", 
    "author": "Mithun Das Gupta", 
    "publish": "2010-04-22T18:42:03Z", 
    "summary": "In this paper we present a Bayesian image zooming/super-resolution algorithm\nbased on a patch based representation. We work on a patch based model with\noverlap and employ a Locally Linear Embedding (LLE) based approach as our data\nfidelity term in the Bayesian inference. The image prior imposes continuity\nconstraints across the overlapping patches. We apply an error back-projection\ntechnique, with an approximate cross bilateral filter. The problem of nearest\nneighbor search is handled by a variant of the locality sensitive hashing (LSH)\nscheme. The novelty of our work lies in the speed up achieved by the hashing\nscheme and the robustness and inherent modularity and parallel structure\nachieved by the LLE setup. The ill-posedness of the image reconstruction\nproblem is handled by the introduction of regularization priors which encode\nthe knowledge present in vast collections of natural images. We present\ncomparative results for both run-time as well as visual image quality based\nmeasurements."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4373v1", 
    "title": "Spatially-Adaptive Reconstruction in Computed Tomography Based on   Statistical Learning", 
    "arxiv-id": "1004.4373v1", 
    "author": "Michael Elad", 
    "publish": "2010-04-25T19:10:26Z", 
    "summary": "We propose a direct reconstruction algorithm for Computed Tomography, based\non a local fusion of a few preliminary image estimates by means of a non-linear\nfusion rule. One such rule is based on a signal denoising technique which is\nspatially adaptive to the unknown local smoothness. Another, more powerful\nfusion rule, is based on a neural network trained off-line with a high-quality\ntraining set of images. Two types of linear reconstruction algorithms for the\npreliminary images are employed for two different reconstruction tasks. For an\nentire image reconstruction from full projection data, the proposed scheme uses\na sequence of Filtered Back-Projection algorithms with a gradually growing\ncut-off frequency. To recover a Region Of Interest only from local projections,\nstatistically-trained linear reconstruction algorithms are employed. Numerical\nexperiments display the improvement in reconstruction quality when compared to\nlinear reconstruction algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4448v1", 
    "title": "Deblured Gaussian Blurred Images", 
    "arxiv-id": "1004.4448v1", 
    "author": "Khamitkar S. D", 
    "publish": "2010-04-26T09:32:28Z", 
    "summary": "This paper attempts to undertake the study of Restored Gaussian Blurred\nImages. by using four types of techniques of deblurring image as Wiener filter,\nRegularized filter, Lucy Richardson deconvlutin algorithm and Blind\ndeconvlution algorithm with an information of the Point Spread Function (PSF)\ncorrupted blurred image with Different values of Size and Alfa and then\ncorrupted by Gaussian noise. The same is applied to the remote sensing image\nand they are compared with one another, So as to choose the base technique for\nrestored or deblurring image.This paper also attempts to undertake the study of\nrestored Gaussian blurred image with no any information about the Point Spread\nFunction (PSF) by using same four techniques after execute the guess of the\nPSF, the number of iterations and the weight threshold of it. To choose the\nbase guesses for restored or deblurring image of this techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4467v1", 
    "title": "An Efficient Watermarking Algorithm to Improve Payload and Robustness   without Affecting Image Perceptual Quality", 
    "arxiv-id": "1004.4467v1", 
    "author": "Er. Anantdeep", 
    "publish": "2010-04-26T10:17:53Z", 
    "summary": "Capacity, Robustness, & Perceptual quality of watermark data are very\nimportant issues to be considered. A lot of research is going on to increase\nthese parameters for watermarking of the digital images, as there is always a\ntradeoff among them. . In this paper an efficient watermarking algorithm to\nimprove payload and robustness without affecting perceptual quality of image\ndata based on DWT is discussed. The aim of the paper is to employ the nested\nwatermarks in wavelet domain which increases the capacity and ultimately the\nrobustness against attacks and selection of different scaling factor values for\nLL & HH bands and during embedding not to create the visible artifacts in the\noriginal image and therefore the original and watermarked image is similar."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4793v1", 
    "title": "Logical methods of object recognition on satellite images using spatial   constraints", 
    "arxiv-id": "1004.4793v1", 
    "author": "R. K. Fedorov", 
    "publish": "2010-04-27T13:22:36Z", 
    "summary": "A logical approach to object recognition on image is proposed. The main idea\nof the approach is to perform the object recognition as a logical inference on\na set of rules describing an object shape."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2010.5539866", 
    "link": "http://arxiv.org/pdf/1005.0858v1", 
    "title": "Randomized hybrid linear modeling by local best-fit flats", 
    "arxiv-id": "1005.0858v1", 
    "author": "Gilad Lerman", 
    "publish": "2010-05-05T21:46:13Z", 
    "summary": "The hybrid linear modeling problem is to identify a set of d-dimensional\naffine sets in a D-dimensional Euclidean space. It arises, for example, in\nobject tracking and structure from motion. The hybrid linear model can be\nconsidered as the second simplest (behind linear) manifold model of data. In\nthis paper we will present a very simple geometric method for hybrid linear\nmodeling based on selecting a set of local best fit flats that minimize a\nglobal l1 error measure. The size of the local neighborhoods is determined\nautomatically by the Jones' l2 beta numbers; it is proven under certain\ngeometric conditions that good local neighborhoods exist and are found by our\nmethod. We also demonstrate how to use this algorithm for fast determination of\nthe number of affine subspaces. We give extensive experimental evidence\ndemonstrating the state of the art accuracy and speed of the algorithm on\nsynthetic and real hybrid linear data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2010.5539866", 
    "link": "http://arxiv.org/pdf/1005.0907v1", 
    "title": "Multistage Hybrid Arabic/Indian Numeral OCR System", 
    "arxiv-id": "1005.0907v1", 
    "author": "Abdul Ahad Siddiqi", 
    "publish": "2010-05-06T07:25:23Z", 
    "summary": "The use of OCR in postal services is not yet universal and there are still\nmany countries that process mail sorting manually. Automated Arabic/Indian\nnumeral Optical Character Recognition (OCR) systems for Postal services are\nbeing used in some countries, but still there are errors during the mail\nsorting process, thus causing a reduction in efficiency. The need to\ninvestigate fast and efficient recognition algorithms/systems is important so\nas to correctly read the postal codes from mail addresses and to eliminate any\nerrors during the mail sorting stage. The objective of this study is to\nrecognize printed numerical postal codes from mail addresses. The proposed\nsystem is a multistage hybrid system which consists of three different feature\nextraction methods, i.e., binary, zoning, and fuzzy features, and three\ndifferent classifiers, i.e., Hamming Nets, Euclidean Distance, and Fuzzy Neural\nNetwork Classifiers. The proposed system, systematically compares the\nperformance of each of these methods, and ensures that the numerals are\nrecognized correctly. Comprehensive results provide a very high recognition\nrate, outperforming the other known developed methods in literature."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.0945v1", 
    "title": "An Efficient Vein Pattern-based Recognition System", 
    "arxiv-id": "1005.0945v1", 
    "author": "Phalguni Gupta", 
    "publish": "2010-05-06T09:34:21Z", 
    "summary": "This paper presents an efficient human recognition system based on vein\npattern from the palma dorsa. A new absorption based technique has been\nproposed to collect good quality images with the help of a low cost camera and\nlight source. The system automatically detects the region of interest from the\nimage and does the necessary preprocessing to extract features. A Euclidean\nDistance based matching technique has been used for making the decision. It has\nbeen tested on a data set of 1750 image samples collected from 341 individuals.\nThe accuracy of the verification system is found to be 99.26% with false\nrejection rate (FRR) of 0.03%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.1471v1", 
    "title": "Classification via Incoherent Subspaces", 
    "arxiv-id": "1005.1471v1", 
    "author": "Pierre Vandergheynst", 
    "publish": "2010-05-10T08:49:56Z", 
    "summary": "This article presents a new classification framework that can extract\nindividual features per class. The scheme is based on a model of incoherent\nsubspaces, each one associated to one class, and a model on how the elements in\na class are represented in this subspace. After the theoretical analysis an\nalternate projection algorithm to find such a collection is developed. The\nclassification performance and speed of the proposed method is tested on the AR\nand YaleB databases and compared to that of Fisher's LDA and a recent approach\nbased on on $\\ell_1$ minimisation. Finally connections of the presented scheme\nto already existing work are discussed and possible ways of extensions are\npointed out."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.2715v1", 
    "title": "On the Subspace of Image Gradient Orientations", 
    "arxiv-id": "1005.2715v1", 
    "author": "Stefanos Zafeiriou", 
    "publish": "2010-05-16T00:31:19Z", 
    "summary": "We introduce the notion of Principal Component Analysis (PCA) of image\ngradient orientations. As image data is typically noisy, but noise is\nsubstantially different from Gaussian, traditional PCA of pixel intensities\nvery often fails to estimate reliably the low-dimensional subspace of a given\ndata population. We show that replacing intensities with gradient orientations\nand the $\\ell_2$ norm with a cosine-based distance measure offers, to some\nextend, a remedy to this problem. Our scheme requires the eigen-decomposition\nof a covariance matrix and is as computationally efficient as standard $\\ell_2$\nPCA. We demonstrate some of its favorable properties on robust subspace\nestimation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4020v1", 
    "title": "Image Segmentation by Using Threshold Techniques", 
    "arxiv-id": "1005.4020v1", 
    "author": "Khamitkar S. D.", 
    "publish": "2010-05-21T17:30:08Z", 
    "summary": "This paper attempts to undertake the study of segmentation image techniques\nby using five threshold methods as Mean method, P-tile method, Histogram\nDependent Technique (HDT), Edge Maximization Technique (EMT) and visual\nTechnique and they are compared with one another so as to choose the best\ntechnique for threshold segmentation techniques image. These techniques applied\non three satellite images to choose base guesses for threshold segmentation\nimage."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4034v1", 
    "title": "Face Synthesis (FASY) System for Generation of a Face Image from Human   Description", 
    "arxiv-id": "1005.4034v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-05-21T18:03:44Z", 
    "summary": "This paper aims at generating a new face based on the human like description\nusing a new concept. The FASY (FAce SYnthesis) System is a Face Database\nRetrieval and new Face generation System that is under development. One of its\nmain features is the generation of the requested face when it is not found in\nthe existing database, which allows a continuous growing of the database also."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4035v1", 
    "title": "Classification of Polar-Thermal Eigenfaces using Multilayer Perceptron   for Human Face Recognition", 
    "arxiv-id": "1005.4035v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-05-21T18:07:42Z", 
    "summary": "This paper presents a novel approach to handle the challenges of face\nrecognition. In this work thermal face images are considered, which minimizes\nthe affect of illumination changes and occlusion due to moustache, beards,\nadornments etc. The proposed approach registers the training and testing\nthermal face images in polar coordinate, which is capable to handle\ncomplicacies introduced by scaling and rotation. Polar images are projected\ninto eigenspace and finally classified using a multi-layer perceptron. In the\nexperiments we have used Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database benchmark thermal face images. Experimental results\nshow that the proposed approach significantly improves the verification and\nidentification performance and the success rate is 97.05%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4044v1", 
    "title": "Reduction of Feature Vectors Using Rough Set Theory for Human Face   Recognition", 
    "arxiv-id": "1005.4044v1", 
    "author": "M. Kundu", 
    "publish": "2010-05-21T19:13:39Z", 
    "summary": "In this paper we describe a procedure to reduce the size of the input feature\nvector. A complex pattern recognition problem like face recognition involves\nhuge dimension of input feature vector. To reduce that dimension here we have\nused eigenspace projection (also called as Principal Component Analysis), which\nis basically transformation of space. To reduce further we have applied feature\nselection method to select indispensable features, which will remain in the\nfinal feature vectors. Features those are not selected are removed from the\nfinal feature vector considering them as redundant or superfluous. For\nselection of features we have used the concept of reduct and core from rough\nset theory. This method has shown very good performance. It is worth to mention\nthat in some cases the recognition rate increases with the decrease in the\nfeature vector dimension."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4103v1", 
    "title": "LACBoost and FisherBoost: Optimally Building Cascade Classifiers", 
    "arxiv-id": "1005.4103v1", 
    "author": "Hanxi Li", 
    "publish": "2010-05-22T04:22:57Z", 
    "summary": "Object detection is one of the key tasks in computer vision. The cascade\nframework of Viola and Jones has become the de facto standard. A classifier in\neach node of the cascade is required to achieve extremely high detection rates,\ninstead of low overall classification error. Although there are a few reported\nmethods addressing this requirement in the context of object detection, there\nis no a principled feature selection method that explicitly takes into account\nthis asymmetric node learning objective. We provide such a boosting algorithm\nin this work. It is inspired by the linear asymmetric classifier (LAC) of Wu et\nal. in that our boosting algorithm optimizes a similar cost function. The new\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on face detection\nsuggest that our proposed boosting algorithms can improve the state-of-the-art\nmethods in detection performance."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.4118v1", 
    "title": "Incremental Training of a Detector Using Online Sparse   Eigen-decomposition", 
    "arxiv-id": "1005.4118v1", 
    "author": "Jian Zhang", 
    "publish": "2010-05-22T11:05:58Z", 
    "summary": "The ability to efficiently and accurately detect objects plays a very crucial\nrole for many computer vision tasks. Recently, offline object detectors have\nshown a tremendous success. However, one major drawback of offline techniques\nis that a complete set of training data has to be collected beforehand. In\naddition, once learned, an offline detector can not make use of newly arriving\ndata. To alleviate these drawbacks, online learning has been adopted with the\nfollowing objectives: (1) the technique should be computationally and storage\nefficient; (2) the updated classifier must maintain its high classification\naccuracy. In this paper, we propose an effective and efficient framework for\nlearning an adaptive online greedy sparse linear discriminant analysis (GSLDA)\nmodel. Unlike many existing online boosting detectors, which usually apply\nexponential or logistic loss, our online algorithm makes use of LDA's learning\ncriterion that not only aims to maximize the class-separation criterion but\nalso incorporates the asymmetrical property of training data distributions. We\nprovide a better alternative for online boosting algorithms in the context of\ntraining a visual object detector. We demonstrate the robustness and efficiency\nof our methods on handwriting digit and face data sets. Our results confirm\nthat object detection tasks benefit significantly when trained in an online\nmanner."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.4216v1", 
    "title": "Classification of LULC Change Detection using Remotely Sensed Data for   Coimbatore City, Tamilnadu, India", 
    "arxiv-id": "1005.4216v1", 
    "author": "K. ThanushKodi", 
    "publish": "2010-05-23T18:16:49Z", 
    "summary": "Maps are used to describe far-off places . It is an aid for navigation and\nmilitary strategies. Mapping of the lands are important and the mapping work is\nbased on (i). Natural resource management & development (ii). Information\ntechnology ,(iii). Environmental development ,(iv). Facility management and\n(v). e-governance. The Landuse / Landcover system espoused by almost all\nOrganisations and scientists, engineers and remote sensing community who are\ninvolved in mapping of earth surface features, is a system which is derived\nfrom the united States Geological Survey (USGS) LULC classification system. The\napplication of RS and GIS involves influential of homogeneous zones, drift\nanalysis of land use integration of new area changes or change detection\netc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a\ngeneralized LULC classification system respect to the Indian conditions based\non the various categories of Earth surface features , resolution of available\nsatellite data, capabilities of sensors and present and future applications.\nThe profusion information of the earth surface offered by the high resolution\nsatellite images for remote sensing applications. Using change detection\nmethodologies to extract the target changes in the areas from high resolution\nimages and rapidly updates geodatabase information processing.Traditionally,\nclassification approaches have focused on per-pixel technologies. Pixels within\nareas assumed to be automatically homogeneous are analyzed independently."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.4292v1", 
    "title": "Application Of Fuzzy System In Segmentation Of MRI Brain Tumor", 
    "arxiv-id": "1005.4292v1", 
    "author": "Swati Sheoran", 
    "publish": "2010-05-24T09:59:08Z", 
    "summary": "Segmentation of images holds an important position in the area of image\nprocessing. It becomes more important whi le typically dealing with medical\nimages where presurgery and post surgery decisions are required for the purpose\nof initiating and speeding up the recovery process. Segmentation of 3-D tumor\nstructures from magnetic resonance images (MRI) is a very challenging problem\ndue to the variability of tumor geometry and intensity patterns. Level set\nevolution combining global smoothness with the flexibility of topology changes\noffers significant advantages over the conventional statistical classification\nfollowed by mathematical morphology. Level set evolution with constant\npropagation needs to be initialized either completely inside or outside the\ntumor and can leak through weak or missing boundary parts. Replacing the\nconstant propagation term by a statistical force overcomes these limitations\nand results in a convergence to a stable solution. Using MR images presenting\ntumors, probabilities for background and tumor regions are calculated from a\npre- and post-contrast difference image and mixture modeling fit of the\nhistogram. The whole image is used for initialization of the level set\nevolution to segment the tumor boundaries."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.5181v1", 
    "title": "Compression Rate Method for Empirical Science and Application to   Computer Vision", 
    "arxiv-id": "1005.5181v1", 
    "author": "Daniel Burfoot", 
    "publish": "2010-05-27T21:27:43Z", 
    "summary": "This philosophical paper proposes a modified version of the scientific\nmethod, in which large databases are used instead of experimental observations\nas the necessary empirical ingredient. This change in the source of the\nempirical data allows the scientific method to be applied to several aspects of\nphysical reality that previously resisted systematic interrogation. Under the\nnew method, scientific theories are compared by instantiating them as\ncompression programs, and examining the codelengths they achieve on a database\nof measurements related to a phenomenon of interest. Because of the\nimpossibility of compressing random data, \"real world\" data can only be\ncompressed by discovering and exploiting the empirical structure it exhibits.\nThe method also provides a new way of thinking about two longstanding issues in\nthe philosophy of science: the problem of induction and the problem of\ndemarcation.\n  The second part of the paper proposes to reformulate computer vision as an\nempirical science of visual reality, by applying the new method to large\ndatabases of natural images. The immediate goal of the proposed reformulation\nis to repair the chronic difficulties in evaluation experienced by the field of\ncomputer vision. The reformulation should bring a wide range of benefits,\nincluding a substantially increased degree of methodological rigor, the ability\nto justify complex theories without overfitting, a scalable evaluation\nparadigm, and the potential to make systematic progress. A crucial argument is\nthat the change is not especially drastic, because most computer vision tasks\ncan be reformulated as specialized image compression techniques. Finally, a\nconcrete proposal is discussed in which a database is produced by recording\nfrom a roadside video camera, and compression is achieved by developing a\ncomputational understanding of the appearance of moving cars."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2010.2206", 
    "link": "http://arxiv.org/pdf/1005.5437v1", 
    "title": "Content Based Image Retrieval Using Exact Legendre Moments and Support   Vector Machine", 
    "arxiv-id": "1005.5437v1", 
    "author": "B. Chandra Mohan", 
    "publish": "2010-05-29T08:12:16Z", 
    "summary": "Content Based Image Retrieval (CBIR) systems based on shape using invariant\nimage moments, viz., Moment Invariants (MI) and Zernike Moments (ZM) are\navailable in the literature. MI and ZM are good at representing the shape\nfeatures of an image. However, non-orthogonality of MI and poor reconstruction\nof ZM restrict their application in CBIR. Therefore, an efficient and\northogonal moment based CBIR system is needed. Legendre Moments (LM) are\northogonal, computationally faster, and can represent image shape features\ncompactly. CBIR system using Exact Legendre Moments (ELM) for gray scale images\nis proposed in this work. Superiority of the proposed CBIR system is observed\nover other moment based methods, viz., MI and ZM in terms of retrieval\nefficiency and retrieval time. Further, the classification efficiency is\nimproved by employing Support Vector Machine (SVM) classifier. Improved\nretrieval results are obtained over existing CBIR algorithm based on Stacked\nEuler Vector (SERVE) combined with Modified Moment Invariants (MMI)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2010.2201", 
    "link": "http://arxiv.org/pdf/1005.5439v1", 
    "title": "Detection of Bleeding in Wireless Capsule Endoscopy Images Using Range   Ratio Color", 
    "arxiv-id": "1005.5439v1", 
    "author": "Abdelshakour A. Abuzneid", 
    "publish": "2010-05-29T08:25:50Z", 
    "summary": "Wireless Capsule Endoscopy (WCE) is device to detect abnormalities in\ncolon,esophagus,small intestinal and stomach, to distinguish bleeding in WCE\nimages from non bleeding is a hard job by human reviewing and very time\nconsuming. Consequently, automation for classifying bleeding frames not only\nwill expedite the process but will reduce the burden on the doctors. Using the\npurity of the red color we can detect the Bleeding areas in WCE images. But, we\ncould find various intensity of red color values in different parts of the\nsmall intestinal,so it is not enough to depend on the red color feature alone.\nWe select RGB(Red,Green,Blue) because it takes raw level values and it is easy\nto use. In this paper we will put range ratio color for each of R,G,and B.\nTherefore, we divide each image into multiple pixels and apply the range ratio\ncolor condition for each pixel. Then we count the number of the pixels that\nachieved our condition. If the number of pixels grater than zero, then the\nframe is classified as a bleeding type. Otherwise, it is a non-bleeding. Our\nexperimental results show that this method could achieve a very high accuracy\nin detecting bleeding images for the different parts of the small intestinal"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.1187v1", 
    "title": "Biometric Authentication using Nonparametric Methods", 
    "arxiv-id": "1006.1187v1", 
    "author": "K. R. Radhika", 
    "publish": "2010-06-07T07:15:37Z", 
    "summary": "The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy kmeans classifiers. The best performance was obtained for MMU\ndatabase consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.2700v1", 
    "title": "Image Segmentation Using Weak Shape Priors", 
    "arxiv-id": "1006.2700v1", 
    "author": "Magdy Salama", 
    "publish": "2010-06-14T12:43:37Z", 
    "summary": "The problem of image segmentation is known to become particularly challenging\nin the case of partial occlusion of the object(s) of interest, background\nclutter, and the presence of strong noise. To overcome this problem, the\npresent paper introduces a novel approach segmentation through the use of\n\"weak\" shape priors. Specifically, in the proposed method, an segmenting active\ncontour is constrained to converge to a configuration at which its geometric\nparameters attain their empirical probability densities closely matching the\ncorresponding model densities that are learned based on training samples. It is\nshown through numerical experiments that the proposed shape modeling can be\nregarded as \"weak\" in the sense that it minimally influences the segmentation,\nwhich is allowed to be dominated by data-related forces. On the other hand, the\npriors provide sufficient constraints to regularize the convergence of\nsegmentation, while requiring substantially smaller training sets to yield less\nbiased results as compared to the case of PCA-based regularization methods. The\nmain advantages of the proposed technique over some existing alternatives is\ndemonstrated in a series of experiments."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.2734v1", 
    "title": "Penalized K-Nearest-Neighbor-Graph Based Metrics for Clustering", 
    "arxiv-id": "1006.2734v1", 
    "author": "Pablo M. Granitto", 
    "publish": "2010-06-14T15:07:45Z", 
    "summary": "A difficult problem in clustering is how to handle data with a manifold\nstructure, i.e. data that is not shaped in the form of compact clouds of\npoints, forming arbitrary shapes or paths embedded in a high-dimensional space.\nIn this work we introduce the Penalized k-Nearest-Neighbor-Graph (PKNNG) based\nmetric, a new tool for evaluating distances in such cases. The new metric can\nbe used in combination with most clustering algorithms. The PKNNG metric is\nbased on a two-step procedure: first it constructs the k-Nearest-Neighbor-Graph\nof the dataset of interest using a low k-value and then it adds edges with an\nexponentially penalized weight for connecting the sub-graphs produced by the\nfirst step. We discuss several possible schemes for connecting the different\nsub-graphs. We use three artificial datasets in four different embedding\nsituations to evaluate the behavior of the new metric, including a comparison\namong different clustering methods. We also evaluate the new metric in a real\nworld application, clustering the MNIST digits dataset. In all cases the PKNNG\nmetric shows promising clustering results."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.2804v1", 
    "title": "An Effective Fingerprint Verification Technique", 
    "arxiv-id": "1006.2804v1", 
    "author": "D K Bhattacharyya", 
    "publish": "2010-06-14T18:57:35Z", 
    "summary": "This paper presents an effective method for fingerprint verification based on\na data mining technique called minutiae clustering and a graph-theoretic\napproach to analyze the process of fingerprint comparison to give a feature\nspace representation of minutiae and to produce a lower bound on the number of\ndetectably distinct fingerprints. The method also proving the invariance of\neach individual fingerprint by using both the topological behavior of the\nminutiae graph and also using a distance measure called Hausdorff distance.The\nmethod provides a graph based index generation mechanism of fingerprint\nbiometric data. The self-organizing map neural network is also used for\nclassifying the fingerprints."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.3056v1", 
    "title": "Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian   Mixture Models to Structured Sparsity", 
    "arxiv-id": "1006.3056v1", 
    "author": "St\u00e9phane Mallat", 
    "publish": "2010-06-15T19:29:08Z", 
    "summary": "A general framework for solving image inverse problems is introduced in this\npaper. The approach is based on Gaussian mixture models, estimated via a\ncomputationally efficient MAP-EM algorithm. A dual mathematical interpretation\nof the proposed framework with structured sparse estimation is described, which\nshows that the resulting piecewise linear estimate stabilizes the estimation\nwhen compared to traditional sparse inverse problem techniques. This\ninterpretation also suggests an effective dictionary motivated initialization\nfor the MAP-EM algorithm. We demonstrate that in a number of image inverse\nproblems, including inpainting, zooming, and deblurring, the same algorithm\nproduces either equal, often significantly better, or very small margin worse\nresults than the best published ones, at a lower computational cost."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.3506v1", 
    "title": "Action Recognition in Videos: from Motion Capture Labs to the Web", 
    "arxiv-id": "1006.3506v1", 
    "author": "Arnaldo Albuquerque de Ara\u00fajo", 
    "publish": "2010-06-17T16:27:35Z", 
    "summary": "This paper presents a survey of human action recognition approaches based on\nvisual data recorded from a single video camera. We propose an organizing\nframework which puts in evidence the evolution of the area, with techniques\nmoving from heavily constrained motion capture scenarios towards more\nchallenging, realistic, \"in the wild\" videos. The proposed organization is\nbased on the representation used as input for the recognition task, emphasizing\nthe hypothesis assumed and thus, the constraints imposed on the type of video\nthat each technique is able to address. Expliciting the hypothesis and\nconstraints makes the framework particularly useful to select a method, given\nan application. Another advantage of the proposed organization is that it\nallows categorizing newest approaches seamlessly with traditional ones, while\nproviding an insightful perspective of the evolution of the action recognition\ntask up to now. That perspective is the basis for the discussion in the end of\nthe paper, where we also present the main open issues in the area."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.4175v1", 
    "title": "Optimization of Weighted Curvature for Image Segmentation", 
    "arxiv-id": "1006.4175v1", 
    "author": "Leo Grady", 
    "publish": "2010-06-21T20:59:43Z", 
    "summary": "Minimization of boundary curvature is a classic regularization technique for\nimage segmentation in the presence of noisy image data. Techniques for\nminimizing curvature have historically been derived from descent methods which\ncould be trapped in a local minimum and therefore required a good\ninitialization. Recently, combinatorial optimization techniques have been\napplied to the optimization of curvature which provide a solution that achieves\nnearly a global optimum. However, when applied to image segmentation these\nmethods required a meaningful data term. Unfortunately, for many images,\nparticularly medical images, it is difficult to find a meaningful data term.\nTherefore, we propose to remove the data term completely and instead weight the\ncurvature locally, while still achieving a global optimum."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.4588v1", 
    "title": "Efficient Region-Based Image Querying", 
    "arxiv-id": "1006.4588v1", 
    "author": "U. Sayed", 
    "publish": "2010-06-23T16:52:26Z", 
    "summary": "Retrieving images from large and varied repositories using visual contents\nhas been one of major research items, but a challenging task in the image\nmanagement community. In this paper we present an efficient approach for\nregion-based image classification and retrieval using a fast multi-level neural\nnetwork model. The advantages of this neural model in image classification and\nretrieval domain will be highlighted. The proposed approach accomplishes its\ngoal in three main steps. First, with the help of a mean-shift based\nsegmentation algorithm, significant regions of the image are isolated.\nSecondly, color and texture features of each region are extracted by using\ncolor moments and 2D wavelets decomposition technique. Thirdly the multi-level\nneural classifier is trained in order to classify each region in a given image\ninto one of five predefined categories, i.e., \"Sky\", \"Building\", \"SandnRock\",\n\"Grass\" and \"Water\". Simulation results show that the proposed method is\npromising in terms of classification and retrieval accuracy results. These\nresults compare favorably with the best published results obtained by other\nstate-of-the-art image retrieval techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.4910v2", 
    "title": "3D Visual Tracking with Particle and Kalman Filters", 
    "arxiv-id": "1006.4910v2", 
    "author": "Burak Bayramli", 
    "publish": "2010-06-25T04:51:32Z", 
    "summary": "One of the most visually demonstrable and straightforward uses of filtering\nis in the field of Computer Vision. In this document we will try to outline the\nissues encountered while designing and implementing a particle and kalman\nfilter based tracking system."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5902v1", 
    "title": "Performance Comparison of SVM and ANN for Handwritten Devnagari   Character Recognition", 
    "arxiv-id": "1006.5902v1", 
    "author": "D. K. Basu", 
    "publish": "2010-06-30T16:16:43Z", 
    "summary": "Classification methods based on learning from examples have been widely\napplied to character recognition from the 1990s and have brought forth\nsignificant improvements of recognition accuracies. This class of methods\nincludes statistical methods, artificial neural networks, support vector\nmachines (SVM), multiple classifier combination, etc. In this paper, we discuss\nthe characteristics of the some classification methods that have been\nsuccessfully applied to handwritten Devnagari character recognition and results\nof SVM and ANNs classification method, applied on Handwritten Devnagari\ncharacters. After preprocessing the character image, we extracted shadow\nfeatures, chain code histogram features, view based features and longest run\nfeatures. These features are then fed to Neural classifier and in support\nvector machine for classification. In neural classifier, we explored three ways\nof combining decisions of four MLP's designed for four different features."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5908v1", 
    "title": "Recognition of Non-Compound Handwritten Devnagari Characters using a   Combination of MLP and Minimum Edit Distance", 
    "arxiv-id": "1006.5908v1", 
    "author": "M. Kundu", 
    "publish": "2010-06-30T16:25:21Z", 
    "summary": "This paper deals with a new method for recognition of offline Handwritten\nnon-compound Devnagari Characters in two stages. It uses two well known and\nestablished pattern recognition techniques: one using neural networks and the\nother one using minimum edit distance. Each of these techniques is applied on\ndifferent sets of characters for recognition. In the first stage, two sets of\nfeatures are computed and two classifiers are applied to get higher recognition\naccuracy. Two MLP's are used separately to recognize the characters. For one of\nthe MLP's the characters are represented with their shadow features and for the\nother chain code histogram feature is used. The decision of both MLP's is\ncombined using weighted majority scheme. Top three results produced by combined\nMLP's in the first stage are used to calculate the relative difference values.\nIn the second stage, based on these relative differences character set is\ndivided into two. First set consists of the characters with distinct shapes and\nsecond set consists of confused characters, which appear very similar in\nshapes. Characters of distinct shapes of first set are classified using MLP.\nConfused characters in second set are classified using minimum edit distance\nmethod. Method of minimum edit distance makes use of corner detected in a\ncharacter image using modified Harris corner detection technique. Experiment on\nthis method is carried out on a database of 7154 samples. The overall\nrecognition is found to be 90.74%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5911v1", 
    "title": "Application of Statistical Features in Handwritten Devnagari Character   Recognition", 
    "arxiv-id": "1006.5911v1", 
    "author": "M. Kundu", 
    "publish": "2010-06-30T16:33:01Z", 
    "summary": "In this paper a scheme for offline Handwritten Devnagari Character\nRecognition is proposed, which uses different feature extraction methodologies\nand recognition algorithms. The proposed system assumes no constraints in\nwriting style or size. First the character is preprocessed and features namely\n: Chain code histogram and moment invariant features are extracted and fed to\nMultilayer Perceptrons as a preliminary recognition step. Finally the results\nof both MLP's are combined using weighted majority scheme. The proposed system\nis tested on 1500 handwritten devnagari character database collected from\ndifferent people. It is observed that the proposed system achieves recognition\nrates 98.03% for top 5 results and 89.46% for top 1 result."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5913v1", 
    "title": "Multiple Classifier Combination for Off-line Handwritten Devnagari   Character Recognition", 
    "arxiv-id": "1006.5913v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-06-30T16:38:02Z", 
    "summary": "This work presents the application of weighted majority voting technique for\ncombination of classification decision obtained from three Multi_Layer\nPerceptron(MLP) based classifiers for Recognition of Handwritten Devnagari\ncharacters using three different feature sets. The features used are\nintersection, shadow feature and chain code histogram features. Shadow features\nare computed globally for character image while intersection features and chain\ncode histogram features are computed by dividing the character image into\ndifferent segments. On experimentation with a dataset of 4900 samples the\noverall recognition rate observed is 92.16% as we considered top five choices\nresults. This method is compared with other recent methods for Handwritten\nDevnagari Character Recognition and it has been observed that this approach has\nbetter success rate than other methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5920v1", 
    "title": "A Two Stage Classification Approach for Handwritten Devanagari   Characters", 
    "arxiv-id": "1006.5920v1", 
    "author": "Latesh Malik", 
    "publish": "2010-06-30T16:54:43Z", 
    "summary": "The paper presents a two stage classification approach for handwritten\ndevanagari characters The first stage is using structural properties like\nshirorekha, spine in character and second stage exploits some intersection\nfeatures of characters which are fed to a feedforward neural network. Simple\nhistogram based method does not work for finding shirorekha, vertical bar\n(Spine) in handwritten devnagari characters. So we designed a differential\ndistance based technique to find a near straight line for shirorekha and spine.\nThis approach has been tested for 50000 samples and we got 89.12% success"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5924v1", 
    "title": "A novel approach for handwritten Devnagari character recognition", 
    "arxiv-id": "1006.5924v1", 
    "author": "Mita Nasipuri", 
    "publish": "2010-06-30T17:09:39Z", 
    "summary": "In this paper a method for recognition of handwritten devanagari characters\nis described. Here, feature vector is constituted by accumulated directional\ngradient changes in different segments, number of intersections points for the\ncharacter, type of spine present and type of shirorekha present in the\ncharacter. One Multi-layer Perceptron with conjugate-gradient training is used\nto classify these feature vectors. This method is applied to a database with\n1000 sample characters and the recognition rate obtained is 88.12%"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5927v1", 
    "title": "Classification Of Gradient Change Features Using MLP For Handwritten   Character Recognition", 
    "arxiv-id": "1006.5927v1", 
    "author": "Mita Nasipuri", 
    "publish": "2010-06-30T17:14:40Z", 
    "summary": "A novel, generic scheme for off-line handwritten English alphabets character\nimages is proposed. The advantage of the technique is that it can be applied in\na generic manner to different applications and is expected to perform better in\nuncertain and noisy environments. The recognition scheme is using a multilayer\nperceptron(MLP) neural networks. The system was trained and tested on a\ndatabase of 300 samples of handwritten characters. For improved generalization\nand to avoid overtraining, the whole available dataset has been divided into\ntwo subsets: training set and test set. We achieved 99.10% and 94.15% correct\nrecognition rates on training and test sets respectively. The purposed scheme\nis robust with respect to various writing styles and size as well as presence\nof considerable noise."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5942v1", 
    "title": "FPGA Based Assembling of Facial Components for Human Face Construction", 
    "arxiv-id": "1006.5942v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-06-30T18:01:47Z", 
    "summary": "This paper aims at VLSI realization for generation of a new face from textual\ndescription. The FASY (FAce SYnthesis) System is a Face Database Retrieval and\nnew Face generation System that is under development. One of its main features\nis the generation of the requested face when it is not found in the existing\ndatabase. The new face generation system works in three steps - searching\nphase, assembling phase and tuning phase. In this paper the tuning phase using\nhardware description language and its implementation in a Field Programmable\nGate Array (FPGA) device is presented."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5945v2", 
    "title": "Fuzzy Classification of Facial Component Parameters", 
    "arxiv-id": "1006.5945v2", 
    "author": "M. Kundu", 
    "publish": "2010-06-30T18:07:35Z", 
    "summary": "This paper presents a novel type-2 Fuzzy logic System to define the Shape of\na facial component with the crisp output. This work is the part of our main\nresearch effort to design a system (called FASY) which offers a novel face\nconstruction approach based on the textual description and also extracts and\nanalyzes the facial components from a face image by an efficient technique. The\nFuzzy model, designed in this paper, takes crisp value of width and height of a\nfacial component and produces the crisp value of Shape for different facial\ncomponents. This method is designed using Matlab 6.5 and Visual Basic 6.0 and\ntested with the facial components extracted from 200 male and female face\nimages of different ages from different face databases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1008.1695v1", 
    "title": "Biometric Authentication using Nonparametric Methods", 
    "arxiv-id": "1008.1695v1", 
    "author": "K. R. Radhika", 
    "publish": "2010-08-10T11:38:29Z", 
    "summary": "The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy k-means classifiers. The best performance was obtained for\nMMU database consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1008.3346v1", 
    "title": "A Miniature-Based Image Retrieval System", 
    "arxiv-id": "1008.3346v1", 
    "author": "Md. Haider Ali", 
    "publish": "2010-08-19T16:38:35Z", 
    "summary": "Due to the rapid development of World Wide Web (WWW) and imaging technology,\nmore and more images are available in the Internet and stored in databases.\nSearching the related images by the querying image is becoming tedious and\ndifficult. Most of the images on the web are compressed by methods based on\ndiscrete cosine transform (DCT) including Joint Photographic Experts\nGroup(JPEG) and H.261. This paper presents an efficient content-based image\nindexing technique for searching similar images using discrete cosine transform\nfeatures. Experimental results demonstrate its superiority with the existing\ntechniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1008.3742v1", 
    "title": "Optimally Training a Cascade Classifier", 
    "arxiv-id": "1008.3742v1", 
    "author": "Anton van den Hengel", 
    "publish": "2010-08-23T03:06:34Z", 
    "summary": "Cascade classifiers are widely used in real-time object detection. Different\nfrom conventional classifiers that are designed for a low overall\nclassification error rate, a classifier in each node of the cascade is required\nto achieve an extremely high detection rate and moderate false positive rate.\nAlthough there are a few reported methods addressing this requirement in the\ncontext of object detection, there is no a principled feature selection method\nthat explicitly takes into account this asymmetric node learning objective. We\nprovide such an algorithm here. We show a special case of the biased minimax\nprobability machine has the same formulation as the linear asymmetric\nclassifier (LAC) of \\cite{wu2005linear}. We then design a new boosting\nalgorithm that directly optimizes the cost function of LAC. The resulting\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on object detection\nverify the effectiveness of the proposed boosting algorithm as a node\nclassifier in cascade object detection, and show performance better than that\nof the current state-of-the-art."
},{
    "category": "cs.CV", 
    "doi": "10.2147/PLMI.S11116", 
    "link": "http://arxiv.org/pdf/1008.3798v1", 
    "title": "Proliferating cell nuclear antigen (PCNA) allows the automatic   identification of follicles in microscopic images of human ovarian tissue", 
    "arxiv-id": "1008.3798v1", 
    "author": "Francisco C\u00f3ppola Gonz\u00e1lvez", 
    "publish": "2010-08-23T11:37:43Z", 
    "summary": "Human ovarian reserve is defined by the population of nongrowing follicles\n(NGFs) in the ovary. Direct estimation of ovarian reserve involves the\nidentification of NGFs in prepared ovarian tissue. Previous studies involving\nhuman tissue have used hematoxylin and eosin (HE) stain, with NGF populations\nestimated by human examination either of tissue under a microscope, or of\nimages taken of this tissue. In this study we replaced HE with proliferating\ncell nuclear antigen (PCNA), and automated the identification and enumeration\nof NGFs that appear in the resulting microscopic images. We compared the\nautomated estimates to those obtained by human experts, with the \"gold\nstandard\" taken to be the average of the conservative and liberal estimates by\nthree human experts. The automated estimates were within 10% of the \"gold\nstandard\", for images at both 100x and 200x magnifications. Automated analysis\ntook longer than human analysis for several hundred images, not allowing for\nbreaks from analysis needed by humans. Our results both replicate and improve\non those of previous studies involving rodent ovaries, and demonstrate the\nviability of large-scale studies of human ovarian reserve using a combination\nof immunohistochemistry and computational image analysis techniques."
},{
    "category": "cs.CV", 
    "doi": "10.3923/itj.2010.811.817", 
    "link": "http://arxiv.org/pdf/1008.4206v1", 
    "title": "Comparative Study of Statistical Skin Detection Algorithms for   Sub-Continental Human Images", 
    "arxiv-id": "1008.4206v1", 
    "author": "Zerina Begum", 
    "publish": "2010-08-25T05:33:04Z", 
    "summary": "Object detection has been a focus of research in human-computer interaction.\nSkin area detection has been a key to different recognitions like face\nrecognition, human motion detection, pornographic and nude image prediction,\netc. Most of the research done in the fields of skin detection has been trained\nand tested on human images of African, Mongolian and Anglo-Saxon ethnic\norigins. Although there are several intensity invariant approaches to skin\ndetection, the skin color of Indian sub-continentals have not been focused\nseparately. The approach of this research is to make a comparative study\nbetween three image segmentation approaches using Indian sub-continental human\nimages, to optimize the detection criteria, and to find some efficient\nparameters to detect the skin area from these images. The experiments observed\nthat HSV color model based approach to Indian sub-continental skin detection is\nmore suitable with considerable success rate of 91.1% true positives and 88.1%\ntrue negatives."
},{
    "category": "cs.CV", 
    "doi": "10.3923/itj.2010.811.817", 
    "link": "http://arxiv.org/pdf/1009.0623v2", 
    "title": "Weighted Attribute Fusion Model for Face Recognition", 
    "arxiv-id": "1009.0623v2", 
    "author": "R. Lakshmipathi", 
    "publish": "2010-09-03T10:05:20Z", 
    "summary": "Recognizing a face based on its attributes is an easy task for a human to\nperform as it is a cognitive process. In recent years, Face Recognition is\nachieved with different kinds of facial features which were used separately or\nin a combined manner. Currently, Feature fusion methods and parallel methods\nare the facial features used and performed by integrating multiple feature sets\nat different levels. However, this integration and the combinational methods do\nnot guarantee better result. Hence to achieve better results, the feature\nfusion model with multiple weighted facial attribute set is selected. For this\nfeature model, face images from predefined data set has been taken from\nOlivetti Research Laboratory (ORL) and applied on different methods like\nPrincipal Component Analysis (PCA) based Eigen feature extraction technique,\nDiscrete Cosine Transformation (DCT) based feature extraction technique,\nHistogram Based Feature Extraction technique and Simple Intensity based\nfeatures. The extracted feature set obtained from these methods were compared\nand tested for accuracy. In this work we have developed a model which will use\nthe above set of feature extraction techniques with different levels of weights\nto attain better accuracy. The results show that the selection of optimum\nweight for a particular feature will lead to improvement in recognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr.2008.0172", 
    "link": "http://arxiv.org/pdf/1009.0854v1", 
    "title": "Fast Color Space Transformations Using Minimax Approximations", 
    "arxiv-id": "1009.0854v1", 
    "author": "Fatih Celiker", 
    "publish": "2010-09-04T17:44:06Z", 
    "summary": "Color space transformations are frequently used in image processing,\ngraphics, and visualization applications. In many cases, these transformations\nare complex nonlinear functions, which prohibits their use in time-critical\napplications. In this paper, we present a new approach called Minimax\nApproximations for Color-space Transformations (MACT).We demonstrate MACT on\nthree commonly used color space transformations. Extensive experiments on a\nlarge and diverse image set and comparisons with well-known multidimensional\nlookup table interpolation methods show that MACT achieves an excellent balance\namong four criteria: ease of implementation, memory usage, accuracy, and\ncomputational speed."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr.2008.0172", 
    "link": "http://arxiv.org/pdf/1009.0892v2", 
    "title": "Effective Pedestrian Detection Using Center-symmetric Local   Binary/Trinary Patterns", 
    "arxiv-id": "1009.0892v2", 
    "author": "Xinsheng Huang", 
    "publish": "2010-09-05T05:16:11Z", 
    "summary": "Accurately detecting pedestrians in images plays a critically important role\nin many computer vision applications. Extraction of effective features is the\nkey to this task. Promising features should be discriminative, robust to\nvarious variations and easy to compute. In this work, we present novel\nfeatures, termed dense center-symmetric local binary patterns (CS-LBP) and\npyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for\npedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4}\nmainly captures the texture information. The proposed CS-LBP feature, in\ncontrast, captures the gradient information and some texture information.\nMoreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to\nimplement and computationally efficient, which is desirable for real-time\napplications. Experiments on the INRIA pedestrian dataset show that the dense\nCS-LBP feature with linear supporct vector machines (SVMs) is comparable with\nthe histograms of oriented gradients (HOG) feature with linear SVMs, and the\npyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and\nthe start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection\nkernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP\nfeature and the PHOG feature could significantly improve the detection\nperformance-producing state-of-the-art accuracy on the INRIA pedestrian\ndataset."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr.2009.0056", 
    "link": "http://arxiv.org/pdf/1009.0957v1", 
    "title": "Distance Measures for Reduced Ordering Based Vector Filters", 
    "arxiv-id": "1009.0957v1", 
    "author": "M. Emre Celebi", 
    "publish": "2010-09-05T23:49:38Z", 
    "summary": "Reduced ordering based vector filters have proved successful in removing\nlong-tailed noise from color images while preserving edges and fine image\ndetails. These filters commonly utilize variants of the Minkowski distance to\norder the color vectors with the aim of distinguishing between noisy and\nnoise-free vectors. In this paper, we review various alternative distance\nmeasures and evaluate their performance on a large and diverse set of images\nusing several effectiveness and efficiency criteria. The results demonstrate\nthat there are in fact strong alternatives to the popular Minkowski metrics."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr:20080080", 
    "link": "http://arxiv.org/pdf/1009.0958v1", 
    "title": "Real-Time Implementation of Order-Statistics Based Directional Filters", 
    "arxiv-id": "1009.0958v1", 
    "author": "M. Emre Celebi", 
    "publish": "2010-09-05T23:53:27Z", 
    "summary": "Vector filters based on order-statistics have proved successful in removing\nimpulsive noise from color images while preserving edges and fine image\ndetails. Among these filters, the ones that involve the cosine distance\nfunction (directional filters) have particularly high computational\nrequirements, which limits their use in time critical applications. In this\npaper, we introduce two methods to speed up these filters. Experiments on a\ndiverse set of color images show that the proposed methods provide substantial\ncomputational gains without significant loss of accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.26.001518", 
    "link": "http://arxiv.org/pdf/1009.0959v1", 
    "title": "Cost-Effective Implementation of Order-Statistics Based Vector Filters   Using Minimax Approximations", 
    "arxiv-id": "1009.0959v1", 
    "author": "Fatih Celiker", 
    "publish": "2010-09-06T00:02:35Z", 
    "summary": "Vector operators based on robust order statistics have proved successful in\ndigital multichannel imaging applications, particularly color image filtering\nand enhancement, in dealing with impulsive noise while preserving edges and\nfine image details. These operators often have very high computational\nrequirements which limits their use in time-critical applications. This paper\nintroduces techniques to speed up vector filters using the minimax\napproximation theory. Extensive experiments on a large and diverse set of color\nimages show that proposed approximations achieve an excellent balance among\nease of implementation, accuracy, and computational speed."
},{
    "category": "cs.CV", 
    "doi": "10.2352/J.ImagingSci.Technol.(2007)51:2(155)", 
    "link": "http://arxiv.org/pdf/1009.0961v1", 
    "title": "A Fast Switching Filter for Impulsive Noise Removal from Color Images", 
    "arxiv-id": "1009.0961v1", 
    "author": "Y. Alp Aslandogan", 
    "publish": "2010-09-06T00:13:25Z", 
    "summary": "In this paper, we present a fast switching filter for impulsive noise removal\nfrom color images. The filter exploits the HSL color space, and is based on the\npeer group concept, which allows for the fast detection of noise in a\nneighborhood without resorting to pairwise distance computations between each\npixel. Experiments on large set of diverse images demonstrate that the proposed\napproach is not only extremely fast, but also gives excellent results in\ncomparison to various state-of-the-art filters."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.2772639", 
    "link": "http://arxiv.org/pdf/1009.0962v1", 
    "title": "Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images", 
    "arxiv-id": "1009.0962v1", 
    "author": "Y. Alp Aslandogan", 
    "publish": "2010-09-06T00:22:58Z", 
    "summary": "In this paper, a comprehensive survey of 48 filters for impulsive noise\nremoval from color images is presented. The filters are formulated using a\nuniform notation and categorized into 8 families. The performance of these\nfilters is compared on a large set of images that cover a variety of domains\nusing three effectiveness and one efficiency criteria. In order to ensure a\nfair efficiency comparison, a fast and accurate approximation for the inverse\ncosine function is introduced. In addition, commonly used distance measures\n(Minkowski, angular, and directional-distance) are analyzed and evaluated.\nFinally, suggestions are provided on how to choose a filter given certain\nrequirements."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.08.003", 
    "link": "http://arxiv.org/pdf/1009.1013v1", 
    "title": "Automatic Detection of Blue-White Veil and Related Structures in   Dermoscopy Images", 
    "arxiv-id": "1009.1013v1", 
    "author": "H. Peter Soyer", 
    "publish": "2010-09-06T10:29:18Z", 
    "summary": "Dermoscopy is a non-invasive skin imaging technique, which permits\nvisualization of features of pigmented melanocytic neoplasms that are not\ndiscernable by examination with the naked eye. One of the most important\nfeatures for the diagnosis of melanoma in dermoscopy images is the blue-white\nveil (irregular, structureless areas of confluent blue pigmentation with an\noverlying white \"ground-glass\" film). In this article, we present a machine\nlearning approach to the detection of blue-white veil and related structures in\ndermoscopy images. The method involves contextual pixel classification using a\ndecision tree classifier. The percentage of blue-white areas detected in a\nlesion combined with a simple shape descriptor yielded a sensitivity of 69.35%\nand a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity\nrises to 78.20% for detection of blue veil in those cases where it is a primary\nfeature for melanoma recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00387.x", 
    "link": "http://arxiv.org/pdf/1009.1020v1", 
    "title": "An Improved Objective Evaluation Measure for Border Detection in   Dermoscopy Images", 
    "arxiv-id": "1009.1020v1", 
    "author": "James M. Grichnik", 
    "publish": "2010-09-06T10:53:21Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, dermoscopy image analysis has become\nan important research area. One of the most important steps in dermoscopy image\nanalysis is the automated detection of lesion borders. Although numerous\nmethods have been developed for the detection of lesion borders, very few\nstudies were comprehensive in the evaluation of their results. Methods: In this\npaper, we evaluate five recent border detection methods on a set of 90\ndermoscopy images using three sets of dermatologist-drawn borders as the\nground-truth. In contrast to previous work, we utilize an objective measure,\nthe Normalized Probabilistic Rand Index, which takes into account the\nvariations in the ground-truth images. Conclusion: The results demonstrate that\nthe differences between four of the evaluated border detection methods are in\nfact smaller than those predicted by the commonly used XOR measure."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.1362v1", 
    "title": "Approximate Lesion Localization in Dermoscopy Images", 
    "arxiv-id": "1009.1362v1", 
    "author": "William V. Stoecker", 
    "publish": "2010-09-06T11:01:53Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, automated analysis of dermoscopy\nimages has become an important research area. Border detection is often the\nfirst step in this analysis. Methods: In this article, we present an\napproximate lesion localization method that serves as a preprocessing step for\ndetecting borders in dermoscopy images. In this method, first the black frame\naround the image is removed using an iterative algorithm. The approximate\nlocation of the lesion is then determined using an ensemble of thresholding\nalgorithms. Results: The method is tested on a set of 428 dermoscopy images.\nThe localization error is quantified by a metric that uses dermatologist\ndetermined borders as the ground truth. Conclusion: The results demonstrate\nthat the method presented here achieves both fast and accurate localization of\nlesions in dermoscopy images."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.1983v1", 
    "title": "Evolutionary Computational Method of Facial Expression Analysis for   Content-based Video Retrieval using 2-Dimensional Cellular Automata", 
    "arxiv-id": "1009.1983v1", 
    "author": "Vasumathi Narayanan", 
    "publish": "2010-09-10T11:25:17Z", 
    "summary": "In this paper, Deterministic Cellular Automata (DCA) based video shot\nclassification and retrieval is proposed. The deterministic 2D Cellular\nautomata model captures the human facial expressions, both spontaneous and\nposed. The determinism stems from the fact that the facial muscle actions are\nstandardized by the encodings of Facial Action Coding System (FACS) and Action\nUnits (AUs). Based on these encodings, we generate the set of evolutionary\nupdate rules of the DCA for each facial expression. We consider a\nPerson-Independent Facial Expression Space (PIFES) to analyze the facial\nexpressions based on Partitioned 2D-Cellular Automata which capture the\ndynamics of facial expressions and classify the shots based on it. Target video\nshot is retrieved by comparing the similar expression is obtained for the query\nframe's face with respect to the key faces expressions in the database video.\nConsecutive key face expressions in the database that are highly similar to the\nquery frame's face, then the key faces are used to generate the set of\nretrieved video shots from the database. A concrete example of its application\nwhich realizes an affective interaction between the computer and the user is\nproposed. In the affective interaction, the computer can recognize the facial\nexpression of any given video shot. This interaction endows the computer with\ncertain ability to adapt to the user's feedback."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.3029v1", 
    "title": "Invariant Spectral Hashing of Image Saliency Graph", 
    "arxiv-id": "1009.3029v1", 
    "author": "Benoit Macq", 
    "publish": "2010-09-15T20:11:11Z", 
    "summary": "Image hashing is the process of associating a short vector of bits to an\nimage. The resulting summaries are useful in many applications including image\nindexing, image authentication and pattern recognition. These hashes need to be\ninvariant under transformations of the image that result in similar visual\ncontent, but should drastically differ for conceptually distinct contents. This\npaper proposes an image hashing method that is invariant under rotation,\nscaling and translation of the image. The gist of our approach relies on the\ngeometric characterization of salient point distribution in the image. This is\nachieved by the definition of a \"saliency graph\" connecting these points\njointly with an image intensity function on the graph nodes. An invariant hash\nis then obtained by considering the spectrum of this function in the\neigenvector basis of the Laplacian graph, that is, its graph Fourier transform.\nInterestingly, this spectrum is invariant under any relabeling of the graph\nnodes. The graph reveals geometric information of the image, making the hash\nrobust to image transformation, yet distinct for different visual content. The\nefficiency of the proposed method is assessed on a set of MRI 2-D slices and on\na database of faces."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.3078v1", 
    "title": "Asymmetric Totally-corrective Boosting for Real-time Object Detection", 
    "arxiv-id": "1009.3078v1", 
    "author": "Zhang Ren", 
    "publish": "2010-09-16T02:45:59Z", 
    "summary": "Real-time object detection is one of the core problems in computer vision.\nThe cascade boosting framework proposed by Viola and Jones has become the\nstandard for this problem. In this framework, the learning goal for each node\nis asymmetric, which is required to achieve a high detection rate and a\nmoderate false positive rate. We develop new boosting algorithms to address\nthis asymmetric learning problem. We show that our methods explicitly optimize\nasymmetric loss objectives in a totally corrective fashion. The methods are\ntotally corrective in the sense that the coefficients of all selected weak\nclassifiers are updated at each iteration. In contract, conventional boosting\nlike AdaBoost is stage-wise in that only the current weak classifier's\ncoefficient is updated. At the heart of the totally corrective boosting is the\ncolumn generation technique. Experiments on face detection show that our\nmethods outperform the state-of-the-art asymmetric boosting methods."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4581v1", 
    "title": "3D-Mesh denoising using an improved vertex based anisotropic diffusion", 
    "arxiv-id": "1009.4581v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2010-09-23T11:26:37Z", 
    "summary": "This paper deals with an improvement of vertex based nonlinear diffusion for\nmesh denoising. This method directly filters the position of the vertices using\nLaplace, reduced centered Gaussian and Rayleigh probability density functions\nas diffusivities. The use of these PDFs improves the performance of a\nvertex-based diffusion method which are adapted to the underlying mesh\nstructure. We also compare the proposed method to other mesh denoising methods\nsuch as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To\nevaluate these methods of filtering, we use two error metrics. The first is\nbased on the vertices and the second is based on the normals. Experimental\nresults demonstrate the effectiveness of our proposed method in comparison with\nthe existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4739v1", 
    "title": "Balancing clusters to reduce response time variability in large scale   image search", 
    "arxiv-id": "1009.4739v1", 
    "author": "Herv\u00e9 J\u00e9gou", 
    "publish": "2010-09-21T11:31:02Z", 
    "summary": "Many algorithms for approximate nearest neighbor search in high-dimensional\nspaces partition the data into clusters. At query time, in order to avoid\nexhaustive search, an index selects the few (or a single) clusters nearest to\nthe query point. Clusters are often produced by the well-known $k$-means\napproach since it has several desirable properties. On the downside, it tends\nto produce clusters having quite different cardinalities. Imbalanced clusters\nnegatively impact both the variance and the expectation of query response\ntimes. This paper proposes to modify $k$-means centroids to produce clusters\nwith more comparable sizes without sacrificing the desirable properties.\nExperiments with a large scale collection of image descriptors show that our\nalgorithm significantly reduces the variance of response times without\nseriously impacting the search quality."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4757v3", 
    "title": "Modeling Instantaneous Changes In Natural Scenes", 
    "arxiv-id": "1009.4757v3", 
    "author": "Vikram Dhillon", 
    "publish": "2010-09-24T03:32:28Z", 
    "summary": "This project aims to create 3d model of the natural world and model changes\nin it instantaneously. A framework for modeling instantaneous changes natural\nscenes in real time using Lagrangian Particle Framework and a fluid-particle\ngrid approach is presented. This project is presented in the form of a\nproof-based system where we show that the design is very much possible but\ncurrently we only have selective scripts that accomplish the given job, a\ncomplete software however is still under work. This research can be divided\ninto 3 distinct sections: the first one discusses a multi-camera rig that can\nmeasure ego-motion accurately up to 88%, how this device becomes the backbone\nof our framework, and some improvements devised to optimize a know framework\nfor depth maps and 3d structure estimation from a single still image called\nmake3d. The second part discusses the fluid-particle framework to model natural\nscenes, presents some algorithms that we are using to accomplish this task and\nwe show how an application of our framework can extend make3d to model natural\nscenes in real time. This part of the research constructs a bridge between\ncomputer vision and computer graphics so that now ideas, answers and intuitions\nthat arose in the domain of computer graphics can now be applied to computer\nvision and natural modeling. The final part of this research improves upon what\nmight become the first general purpose vision system using deep belief\narchitectures and provides another framework to improve the lower bound on\ntraining images for boosting by using a variation of Restricted Boltzmann\nmachines (RBM). We also discuss other applications that might arise from our\nwork in these areas."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4823v1", 
    "title": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques", 
    "arxiv-id": "1009.4823v1", 
    "author": "Cristian Sminchisescu", 
    "publish": "2010-09-24T12:32:02Z", 
    "summary": "We propose a mid-level image segmentation framework that combines multiple\nfigure-ground hypothesis (FG) constrained at different locations and scales,\ninto interpretations that tile the entire image. The problem is cast as\noptimization over sets of maximal cliques sampled from the graph connecting\nnon-overlapping, putative figure-ground segment hypotheses. Potential functions\nover cliques combine unary Gestalt-based figure quality scores and pairwise\ncompatibilities among spatially neighboring segments, constrained by\nT-junctions and the boundary interface statistics resulting from projections of\nreal 3d scenes. Learning the model parameters is formulated as rank\noptimization, alternating between sampling image tilings and optimizing their\npotential function parameters. State of the art results are reported on both\nthe Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was\nachieved."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4974v1", 
    "title": "Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis   Function Networks", 
    "arxiv-id": "1009.4974v1", 
    "author": "Mohammad Shamsul Alam", 
    "publish": "2010-09-25T05:46:31Z", 
    "summary": "This paper introduces a novel method for human face detection with its\norientation by using wavelet, principle component analysis (PCA) and redial\nbasis networks. The input image is analyzed by two-dimensional wavelet and a\ntwo-dimensional stationary wavelet. The common goals concern are the image\nclearance and simplification, which are parts of de-noising or compression. We\napplied an effective procedure to reduce the dimension of the input vectors\nusing PCA. Radial Basis Function (RBF) neural network is then used as a\nfunction approximation network to detect where either the input image is\ncontained a face or not and if there is a face exists then tell about its\norientation. We will show how RBF can perform well then back-propagation\nalgorithm and give some solution for better regularization of the RBF (GRNN)\nnetwork. Compared with traditional RBF networks, the proposed network\ndemonstrates better capability of approximation to underlying functions, faster\nlearning speed, better size of network, and high robustness to outliers."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.5758v1", 
    "title": "Face Detection with Effective Feature Extraction", 
    "arxiv-id": "1009.5758v1", 
    "author": "Jian Zhang", 
    "publish": "2010-09-29T03:13:09Z", 
    "summary": "There is an abundant literature on face detection due to its important role\nin many vision applications. Since Viola and Jones proposed the first real-time\nAdaBoost based face detector, Haar-like features have been adopted as the\nmethod of choice for frontal face detection. In this work, we show that simple\nfeatures other than Haar-like features can also be applied for training an\neffective face detector. Since, single feature is not discriminative enough to\nseparate faces from difficult non-faces, we further improve the generalization\nperformance of our simple features by introducing feature co-occurrences. We\ndemonstrate that our proposed features yield a performance improvement compared\nto Haar-like features. In addition, our findings indicate that features play a\ncrucial role in the ability of the system to generalize."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.0417v1", 
    "title": "Visual-hint Boundary to Segment Algorithm for Image Segmentation", 
    "arxiv-id": "1010.0417v1", 
    "author": "Margaret H. Dunham", 
    "publish": "2010-10-03T15:27:56Z", 
    "summary": "Image segmentation has been a very active research topic in image analysis\narea. Currently, most of the image segmentation algorithms are designed based\non the idea that images are partitioned into a set of regions preserving\nhomogeneous intra-regions and inhomogeneous inter-regions. However, human\nvisual intuition does not always follow this pattern. A new image segmentation\nmethod named Visual-Hint Boundary to Segment (VHBS) is introduced, which is\nmore consistent with human perceptions. VHBS abides by two visual hint rules\nbased on human perceptions: (i) the global scale boundaries tend to be the real\nboundaries of the objects; (ii) two adjacent regions with quite different\ncolors or textures tend to result in the real boundaries between them. It has\nbeen demonstrated by experiments that, compared with traditional image\nsegmentation method, VHBS has better performance and also preserves higher\ncomputational efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.0422v1", 
    "title": "Convolutional Matching Pursuit and Dictionary Training", 
    "arxiv-id": "1010.0422v1", 
    "author": "Yann LeCun", 
    "publish": "2010-10-03T16:55:56Z", 
    "summary": "Matching pursuit and K-SVD is demonstrated in the translation invariant\nsetting"
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.3867v1", 
    "title": "Joint interpretation of on-board vision and static GPS cartography for   determination of correct speed limit", 
    "arxiv-id": "1010.3867v1", 
    "author": "Anne-Sophie Puthon", 
    "publish": "2010-10-19T12:03:16Z", 
    "summary": "We present here a first prototype of a \"Speed Limit Support\" Advance Driving\nAssistance System (ADAS) producing permanent reliable information on the\ncurrent speed limit applicable to the vehicle. Such a module can be used either\nfor information of the driver, or could even serve for automatic setting of the\nmaximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on\na joint interpretation of cartographic information (for static reference\ninformation) with on-board vision, used for traffic sign detection and\nrecognition (including supplementary sub-signs) and visual road lines\nlocalization (for detection of lane changes). The visual traffic sign detection\npart is quite robust (90% global correct detection and recognition for main\nspeed signs, and 80% for exit-lane sub-signs detection). Our approach for joint\ninterpretation with cartography is original, and logic-based rather than\nprobability-based, which allows correct behaviour even in cases, which do\nhappen, when both vision and cartography may provide the same erroneous\ninformation."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.3935v1", 
    "title": "3-D Rigid Models from Partial Views - Global Factorization", 
    "arxiv-id": "1010.3935v1", 
    "author": "Bruno B. Gon\u00e7alves", 
    "publish": "2010-10-19T14:45:55Z", 
    "summary": "The so-called factorization methods recover 3-D rigid structure from motion\nby factorizing an observation matrix that collects 2-D projections of features.\nThese methods became popular due to their robustness - they use a large number\nof views, which constrains adequately the solution - and computational\nsimplicity - the large number of unknowns is computed through an SVD, avoiding\nnon-linear optimization. However, they require that all the entries of the\nobservation matrix are known. This is unlikely to happen in practice, due to\nself-occlusion and limited field of view. Also, when processing long videos,\nregions that become occluded often appear again later. Current factorization\nmethods process these as new regions, leading to less accurate estimates of 3-D\nstructure. In this paper, we propose a global factorization method that infers\ncomplete 3-D models directly from the 2-D projections in the entire set of\navailable video frames. Our method decides whether a region that has become\nvisible is a region that was seen before, or a previously unseen region, in a\nglobal way, i.e., by seeking the simplest rigid object that describes well the\nentire set of observations. This global approach increases significantly the\naccuracy of the estimates of the 3-D shape of the scene and the 3-D motion of\nthe camera. Experiments with artificial and real videos illustrate the good\nperformance of our method."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.3947v1", 
    "title": "Maximum Likelihood Mosaics", 
    "arxiv-id": "1010.3947v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2010-10-19T15:13:40Z", 
    "summary": "The majority of the approaches to the automatic recovery of a panoramic image\nfrom a set of partial views are suboptimal in the sense that the input images\nare aligned, or registered, pair by pair, e.g., consecutive frames of a video\nclip. These approaches lead to propagation errors that may be very severe,\nparticularly when dealing with videos that show the same region at disjoint\ntime intervals. Although some authors have proposed a post-processing step to\nreduce the registration errors in these situations, there have not been\nattempts to compute the optimal solution, i.e., the registrations leading to\nthe panorama that best matches the entire set of partial views}. This is our\ngoal. In this paper, we use a generative model for the partial views of the\npanorama and develop an algorithm to compute in an efficient way the Maximum\nLikelihood estimate of all the unknowns involved: the parameters describing the\nalignment of all the images and the panorama itself."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.4021v1", 
    "title": "ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of   Unlabeled Points)", 
    "arxiv-id": "1010.4021v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2010-10-19T19:48:41Z", 
    "summary": "In image analysis, many tasks require representing two-dimensional (2D)\nshape, often specified by a set of 2D points, for comparison purposes. The\nchallenge of the representation is that it must not only capture the\ncharacteristics of the shape but also be invariant to relevant transformations.\nInvariance to geometric transformations, such as translation, rotation, and\nscale, has received attention in the past, usually under the assumption that\nthe points are previously labeled, i.e., that the shape is characterized by an\nordered set of landmarks. However, in many practical scenarios, the points\ndescribing the shape are obtained from automatic processes, e.g., edge or\ncorner detection, thus without labels or natural ordering. Obviously, the\ncombinatorial problem of computing the correspondences between the points of\ntwo shapes in the presence of the aforementioned geometrical distortions\nbecomes a quagmire when the number of points is large. We circumvent this\nproblem by representing shapes in a way that is invariant to the permutation of\nthe landmarks, i.e., we represent bags of unlabeled 2D points. Within our\nframework, a shape is mapped to an analytic function on the complex plane,\nleading to what we call its analytic signature (ANSIG). To store an ANSIG, it\nsuffices to sample it along a closed contour in the complex plane. We show that\nthe ANSIG is a maximal invariant with respect to the permutation group, i.e.,\nthat different shapes have different ANSIGs and shapes that differ by a\npermutation (or re-labeling) of the landmarks have the same ANSIG. We further\nshow how easy it is to factor out geometric transformations when comparing\nshapes using the ANSIG representation. Finally, we illustrate these\ncapabilities with shape-based image classification experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.4203v1", 
    "title": "Revisiting Complex Moments For 2D Shape Representation and Image   Normalization", 
    "arxiv-id": "1010.4203v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2010-10-18T20:12:29Z", 
    "summary": "When comparing 2D shapes, a key issue is their normalization. Translation and\nscale are easily taken care of by removing the mean and normalizing the energy.\nHowever, defining and computing the orientation of a 2D shape is not so simple.\nIn fact, although for elongated shapes the principal axis can be used to define\none of two possible orientations, there is no such tool for general shapes. As\nwe show in the paper, previous approaches fail to compute the orientation of\neven noiseless observations of simple shapes. We address this problem. In the\npaper, we show how to uniquely define the orientation of an arbitrary 2D shape,\nin terms of what we call its Principal Moments. We show that a small subset of\nthese moments suffice to represent the underlying 2D shape and propose a new\nmethod to efficiently compute the shape orientation: Principal Moment Analysis.\nFinally, we discuss how this method can further be applied to normalize\ngrey-level images. Besides the theoretical proof of correctness, we describe\nexperiments demonstrating robustness to noise and illustrating the method with\nreal images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.4314v1", 
    "title": "Statistical Compressive Sensing of Gaussian Mixture Models", 
    "arxiv-id": "1010.4314v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2010-10-20T20:22:26Z", 
    "summary": "A new framework of compressive sensing (CS), namely statistical compressive\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution and achieving accurate reconstruction on\naverage, is introduced. For signals following a Gaussian distribution, with\nGaussian or Bernoulli sensing matrices of O(k) measurements, considerably\nsmaller than the O(k log(N/k)) required by conventional CS, where N is the\nsignal dimension, and with an optimal decoder implemented with linear\nfiltering, significantly faster than the pursuit decoders applied in\nconventional CS, the error of SCS is shown tightly upper bounded by a constant\ntimes the k-best term approximation error, with overwhelming probability. The\nfailure probability is also significantly smaller than that of conventional CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the k-best term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For signals following Gaussian mixture models, SCS with a piecewise\nlinear decoder is introduced and shown to produce for real images better\nresults than conventional CS based on sparse models."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.4893v1", 
    "title": "Collaborative Sources Identification in Mixed Signals via Hierarchical   Sparse Modeling", 
    "arxiv-id": "1010.4893v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2010-10-23T16:47:16Z", 
    "summary": "A collaborative framework for detecting the different sources in mixed\nsignals is presented in this paper. The approach is based on C-HiLasso, a\nconvex collaborative hierarchical sparse model, and proceeds as follows. First,\nwe build a structured dictionary for mixed signals by concatenating a set of\nsub-dictionaries, each one of them learned to sparsely model one of a set of\npossible classes. Then, the coding of the mixed signal is performed by\nefficiently solving a convex optimization problem that combines standard\nsparsity with group and collaborative sparsity. The present sources are\nidentified by looking at the sub-dictionaries automatically selected in the\ncoding. The collaborative filtering in C-HiLasso takes advantage of the\ntemporal/spatial redundancy in the mixed signals, letting collections of\nsamples collaborate in identifying the classes, while allowing individual\nsamples to have different internal sparse representations. This collaboration\nis critical to further stabilize the sparse representation of signals, in\nparticular the class/sub-dictionary selection. The internal sparsity inside the\nsub-dictionaries, as naturally incorporated by the hierarchical aspects of\nC-HiLasso, is critical to make the model consistent with the essence of the\nsub-dictionaries that have been trained for sparse representation of each\nindividual class. We present applications from speaker and instrument\nidentification and texture separation. In the case of audio signals, we use\nsparse modeling to describe the short-term power spectrum envelopes of harmonic\nsounds. The proposed pitch independent method automatically detects the number\nof sources on a recording."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.5610v1", 
    "title": "Selective Image Super-Resolution", 
    "arxiv-id": "1010.5610v1", 
    "author": "Loong-Fah Cheong", 
    "publish": "2010-10-27T08:58:48Z", 
    "summary": "In this paper we propose a vision system that performs image Super Resolution\n(SR) with selectivity. Conventional SR techniques, either by multi-image fusion\nor example-based construction, have failed to capitalize on the intrinsic\nstructural and semantic context in the image, and performed \"blind\" resolution\nrecovery to the entire image area. By comparison, we advocate example-based\nselective SR whereby selectivity is exemplified in three aspects: region\nselectivity (SR only at object regions), source selectivity (object SR with\ntrained object dictionaries), and refinement selectivity (object boundaries\nrefinement using matting). The proposed system takes over-segmented\nlow-resolution images as inputs, assimilates recent learning techniques of\nsparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to\na framework for joint figure-ground separation and interest object SR. The\nefficiency of our framework is manifested in our experiments with subsets of\nthe VOC2009 and MSRC datasets. We also demonstrate several interesting vision\napplications that can build on our system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1011.0596v1", 
    "title": "Multiple View Reconstruction of Calibrated Images using Singular Value   Decomposition", 
    "arxiv-id": "1011.0596v1", 
    "author": "Amlan Chakrabarti", 
    "publish": "2010-11-02T12:25:04Z", 
    "summary": "Calibration in a multi camera network has widely been studied for over\nseveral years starting from the earlier days of photogrammetry. Many authors\nhave presented several calibration algorithms with their relative advantages\nand disadvantages. In a stereovision system, multiple view reconstruction is a\nchallenging task. However, the total computational procedure in detail has not\nbeen presented before. Here in this work, we are dealing with the problem that,\nwhen a world coordinate point is fixed in space, image coordinates of that 3D\npoint vary for different camera positions and orientations. In computer vision\naspect, this situation is undesirable. That is, the system has to be designed\nin such a way that image coordinate of the world coordinate point will be fixed\nirrespective of the position & orientation of the cameras. We have done it in\nan elegant fashion. Firstly, camera parameters are calculated in its local\ncoordinate system. Then, we use global coordinate data to transfer all local\ncoordinate data of stereo cameras into same global coordinate system, so that\nwe can register everything into this global coordinate system. After all the\ntransformations, when the image coordinate of the world coordinate point is\ncalculated, it gives same coordinate value for all camera positions &\norientations. That is, the whole system is calibrated."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.0640v1", 
    "title": "Lesion Border Detection in Dermoscopy Images", 
    "arxiv-id": "1011.0640v1", 
    "author": "William V. Stoecker", 
    "publish": "2010-10-30T17:17:02Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, computerized analysis of dermoscopy\nimages has become an important research area. One of the most important steps\nin dermoscopy image analysis is the automated detection of lesion borders.\nMethods: In this article, we present a systematic overview of the recent border\ndetection methods in the literature paying particular attention to\ncomputational issues and evaluation aspects. Conclusion: Common problems with\nthe existing approaches include the acquisition, size, and diagnostic\ndistribution of the test image set, the evaluation of the results, and the\ninadequate description of the employed methods. Border determination by\ndermatologists appears to depend upon higher-level knowledge, therefore it is\nlikely that the incorporation of domain knowledge in automated methods will\nenable them to perform better, especially in sets of images with a variety of\ndiagnoses."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.1035v1", 
    "title": "Featureless 2D-3D Pose Estimation by Minimising an   Illumination-Invariant Loss", 
    "arxiv-id": "1011.1035v1", 
    "author": "Nathan Brewer", 
    "publish": "2010-11-03T23:44:46Z", 
    "summary": "The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision ranging from robotic vision\nto image analysis. Our proposed method of registering a 3D model of a known\nobject on a given 2D photo of the object has numerous advantages over existing\nmethods: It does neither require prior training nor learning, nor knowledge of\nthe camera parameters, nor explicit point correspondences or matching features\nbetween image and model. Unlike techniques that estimate a partial 3D pose (as\nin an overhead view of traffic or machine parts on a conveyor belt), our method\nestimates the complete 3D pose of the object, and works on a single static\nimage from a given view, and under varying and unknown lighting conditions. For\nthis purpose we derive a novel illumination-invariant distance measure between\n2D photo and projected 3D model, which is then minimised to find the best pose\nparameters. Results for vehicle pose detection are presented."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.2272v1", 
    "title": "Single Frame Image super Resolution using Learned Directionlets", 
    "arxiv-id": "1011.2272v1", 
    "author": "Thomas Tessamma", 
    "publish": "2010-11-10T04:43:44Z", 
    "summary": "In this paper, a new directionally adaptive, learning based, single image\nsuper resolution method using multiple direction wavelet transform, called\nDirectionlets is presented. This method uses directionlets to effectively\ncapture directional features and to extract edge information along different\ndirections of a set of available high resolution images .This information is\nused as the training set for super resolving a low resolution input image and\nthe Directionlet coefficients at finer scales of its high-resolution image are\nlearned locally from this training set and the inverse Directionlet transform\nrecovers the super-resolved high resolution image. The simulation results\nshowed that the proposed approach outperforms standard interpolation techniques\nlike Cubic spline interpolation as well as standard Wavelet-based learning,\nboth visually and in terms of the mean squared error (mse) values. This method\ngives good result with aliased images also."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.3019v1", 
    "title": "Bounded Multivariate Surfaces On Monovariate Internal Functions", 
    "arxiv-id": "1011.3019v1", 
    "author": "Gert J. ter Horst", 
    "publish": "2010-11-12T19:48:13Z", 
    "summary": "Combining the properties of monovariate internal functions as proposed in\nKolmogorov superimposition theorem, in tandem with the bounds wielded by the\nmultivariate formulation of Chebyshev inequality, a hybrid model is presented,\nthat decomposes images into homogeneous probabilistically bounded multivariate\nsurfaces. Given an image, the model shows a novel way of working on reduced\nimage representation while processing and capturing the interaction among the\nmultidimensional information that describes the content of the same. Further,\nit tackles the practical issues of preventing leakage by bounding the growth of\nsurface and reducing the problem sample size. The model if used, also sheds\nlight on how the Chebyshev parameter relates to the number of pixels and the\ndimensionality of the feature space that associates with a pixel. Initial\nsegmentation results on the Berkeley image segmentation benchmark indicate the\neffectiveness of the proposed decomposition algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.3023v4", 
    "title": "Classification with Scattering Operators", 
    "arxiv-id": "1011.3023v4", 
    "author": "St\u00e9phane Mallat", 
    "publish": "2010-11-12T20:15:25Z", 
    "summary": "A scattering vector is a local descriptor including multiscale and\nmulti-direction co-occurrence information. It is computed with a cascade of\nwavelet decompositions and complex modulus. This scattering representation is\nlocally translation invariant and linearizes deformations. A supervised\nclassification algorithm is computed with a PCA model selection on scattering\nvectors. State of the art results are obtained for handwritten digit\nrecognition and texture classification."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.3177v3", 
    "title": "The Data Replication Method for the Classification with Reject Option", 
    "arxiv-id": "1011.3177v3", 
    "author": "Jaime S. Cardoso", 
    "publish": "2010-11-14T02:48:02Z", 
    "summary": "Classification is one of the most important tasks of machine learning.\nAlthough the most well studied model is the two-class problem, in many\nscenarios there is the opportunity to label critical items for manual revision,\ninstead of trying to automatically classify every item. In this paper we adapt\na paradigm initially proposed for the classification of ordinal data to address\nthe classification problem with reject option. The technique reduces the\nproblem of classifying with reject option to the standard two-class problem.\nThe introduced method is then mapped into support vector machines and neural\nnetworks. Finally, the framework is extended to multiclass ordinal data with\nreject option. An experimental study with synthetic and real data sets,\nverifies the usefulness of the proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.4321v1", 
    "title": "A Fuzzy Clustering Model for Fuzzy Data with Outliers", 
    "arxiv-id": "1011.4321v1", 
    "author": "Zahra S. Razaee", 
    "publish": "2010-11-18T22:20:45Z", 
    "summary": "In this paper a fuzzy clustering model for fuzzy data with outliers is\nproposed. The model is based on Wasserstein distance between interval valued\ndata which is generalized to fuzzy data. In addition, Keller's approach is used\nto identify outliers and reduce their influences. We have also defined a\ntransformation to change our distance to the Euclidean distance. With the help\nof this approach, the problem of fuzzy clustering of fuzzy data is reduced to\nfuzzy clustering of crisp data. In order to show the performance of the\nproposed clustering algorithm, two simulation experiments are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2011.2158428", 
    "link": "http://arxiv.org/pdf/1011.4615v2", 
    "title": "Generalized Tree-Based Wavelet Transform", 
    "arxiv-id": "1011.4615v2", 
    "author": "Israel Cohen", 
    "publish": "2010-11-20T21:32:36Z", 
    "summary": "In this paper we propose a new wavelet transform applicable to functions\ndefined on graphs, high dimensional data and networks. The proposed method\ngeneralizes the Haar-like transform proposed in [1], and it is defined via a\nhierarchical tree, which is assumed to capture the geometry and structure of\nthe input data. It is applied to the data using a modified version of the\ncommon one-dimensional (1D) wavelet filtering and decimation scheme, which can\nemploy different wavelet filters. In each level of this wavelet decomposition\nscheme, a permutation derived from the tree is applied to the approximation\ncoefficients, before they are filtered. We propose a tree construction method\nthat results in an efficient representation of the input function in the\ntransform domain. We show that the proposed transform is more efficient than\nboth the 1D and two-dimensional (2D) separable wavelet transforms in\nrepresenting images. We also explore the application of the proposed transform\nto image denoising, and show that combined with a subimage averaging scheme, it\nachieves denoising results which are similar to those obtained with the K-SVD\nalgorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2011.2158428", 
    "link": "http://arxiv.org/pdf/1011.5962v1", 
    "title": "Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces", 
    "arxiv-id": "1011.5962v1", 
    "author": "Sergios Theodoridis", 
    "publish": "2010-11-27T10:24:12Z", 
    "summary": "The goal of this paper is the development of a novel approach for the problem\nof Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces\n(RKHS). The problem is cast as an optimization task in a RKHS, by taking\nadvantage of the celebrated semiparametric Representer Theorem. Examples verify\nthat in the presence of gaussian noise the proposed method performs relatively\nwell compared to wavelet based technics and outperforms them significantly in\nthe presence of impulse or mixed noise.\n  A more detailed version of this work has been published in the IEEE Trans.\nIm. Proc. : P. Bouboulis, K. Slavakis and S. Theodoridis, Adaptive Kernel-based\nImage Denoising employing Semi-Parametric Regularization, IEEE Transactions on\nImage Processing, vol 19(6), 2010, 1465 - 1479."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1011.6656v2", 
    "title": "Learning sparse representations of depth", 
    "arxiv-id": "1011.6656v2", 
    "author": "Benjamin J. Culpepper", 
    "publish": "2010-11-30T19:55:21Z", 
    "summary": "This paper introduces a new method for learning and inferring sparse\nrepresentations of depth (disparity) maps. The proposed algorithm relaxes the\nusual assumption of the stationary noise model in sparse coding. This enables\nlearning from data corrupted with spatially varying noise or uncertainty,\ntypically obtained by laser range scanners or structured light depth cameras.\nSparse representations are learned from the Middlebury database disparity maps\nand then exploited in a two-layer graphical model for inferring depth from\nstereo, by including a sparsity prior on the learned features. Since they\ncapture higher-order dependencies in the depth structure, these priors can\ncomplement smoothness priors commonly used in depth inference based on Markov\nRandom Field (MRF) models. Inference on the proposed graph is achieved using an\nalternating iterative optimization technique, where the first layer is solved\nusing an existing MRF-based stereo matching algorithm, then held fixed as the\nsecond layer is solved using the proposed non-stationary sparse coding\nalgorithm. This leads to a general method for improving solutions of state of\nthe art MRF-based depth estimation algorithms. Our experimental results first\nshow that depth inference using learned representations leads to state of the\nart denoising of depth maps obtained from laser range scanners and a time of\nflight camera. Furthermore, we show that adding sparse priors improves the\nresults of two depth estimation methods: the classical graph cut algorithm by\nBoykov et al. and the more recent algorithm of Woodford et al."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1012.2138v2", 
    "title": "Sparse motion segmentation using multiple six-point consistencies", 
    "arxiv-id": "1012.2138v2", 
    "author": "Liam Ellis", 
    "publish": "2010-12-09T22:56:02Z", 
    "summary": "We present a method for segmenting an arbitrary number of moving objects in\nimage sequences using the geometry of 6 points in 2D to infer motion\nconsistency. The method has been evaluated on the Hopkins 155 database and\nsurpasses current state-of-the-art methods such as SSC, both in terms of\noverall performance on two and three motions but also in terms of maximum\nerrors. The method works by finding initial clusters in the spatial domain, and\nthen classifying each remaining point as belonging to the cluster that\nminimizes a motion consistency score. In contrast to most other motion\nsegmentation methods that are based on an affine camera model, the proposed\nmethod is fully projective."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.2491v1", 
    "title": "Affine Invariant, Model-Based Object Recognition Using Robust Metrics   and Bayesian Statistics", 
    "arxiv-id": "1012.2491v1", 
    "author": "Bernard Buxton", 
    "publish": "2010-12-11T21:48:51Z", 
    "summary": "We revisit the problem of model-based object recognition for intensity images\nand attempt to address some of the shortcomings of existing Bayesian methods,\nsuch as unsuitable priors and the treatment of residuals with a non-robust\nerror norm. We do so by using a refor- mulation of the Huber metric and\ncarefully chosen prior distributions. Our proposed method is invariant to\n2-dimensional affine transforma- tions and, because it is relatively easy to\ntrain and use, it is suited for general object matching problems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.2603v1", 
    "title": "Real-time Visual Tracking Using Sparse Representation", 
    "arxiv-id": "1012.2603v1", 
    "author": "Qinfeng Shi", 
    "publish": "2010-12-12T23:41:56Z", 
    "summary": "The $\\ell_1$ tracker obtains robustness by seeking a sparse representation of\nthe tracking object via $\\ell_1$ norm minimization \\cite{Xue_ICCV_09_Track}.\nHowever, the high computational complexity involved in the $ \\ell_1 $ tracker\nrestricts its further applications in real time processing scenario. Hence we\npropose a Real Time Compressed Sensing Tracking (RTCST) by exploiting the\nsignal recovery power of Compressed Sensing (CS). Dimensionality reduction and\na customized Orthogonal Matching Pursuit (OMP) algorithm are adopted to\naccelerate the CS tracking. As a result, our algorithm achieves a real-time\nspeed that is up to $6,000$ times faster than that of the $\\ell_1$ tracker.\nMeanwhile, RTCST still produces competitive (sometimes even superior) tracking\naccuracy comparing to the existing $\\ell_1$ tracker. Furthermore, for a\nstationary camera, a further refined tracker is designed by integrating a\nCS-based background model (CSBM). This CSBM-equipped tracker coined as RTCST-B,\noutperforms most state-of-the-arts with respect to both accuracy and\nrobustness. Finally, our experimental results on various video sequences, which\nare verified by a new metric---Tracking Success Probability (TSP), show the\nexcellence of the proposed algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.3216v1", 
    "title": "TILT: Transform Invariant Low-rank Textures", 
    "arxiv-id": "1012.3216v1", 
    "author": "Yi Ma", 
    "publish": "2010-12-15T02:55:25Z", 
    "summary": "In this paper, we show how to efficiently and effectively extract a class of\n\"low-rank textures\" in a 3D scene from 2D images despite significant\ncorruptions and warping. The low-rank textures capture geometrically meaningful\nstructures in an image, which encompass conventional local features such as\nedges and corners as well as all kinds of regular, symmetric patterns\nubiquitous in urban environments and man-made objects. Our approach to finding\nthese low-rank textures leverages the recent breakthroughs in convex\noptimization that enable robust recovery of a high-dimensional low-rank matrix\ndespite gross sparse errors. In the case of planar regions with significant\naffine or projective deformation, our method can accurately recover both the\nintrinsic low-rank texture and the precise domain transformation, and hence the\n3D geometry and appearance of the planar regions. Extensive experimental\nresults demonstrate that this new technique works effectively for many regular\nand near-regular patterns or objects that are approximately low-rank, such as\nsymmetrical patterns, building facades, printed texts, and human faces."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.3802v1", 
    "title": "Detecting Image Forgeries using Geometric Cues", 
    "arxiv-id": "1012.3802v1", 
    "author": "Yang Wang", 
    "publish": "2010-12-17T03:27:54Z", 
    "summary": "This chapter presents a framework for detecting fake regions by using various\nmethods including watermarking technique and blind approaches. In particular,\nwe describe current categories on blind approaches which can be divided into\nfive: pixel-based techniques, format-based techniques, camera-based techniques,\nphysically-based techniques and geometric-based techniques. Then we take a\nsecond look on the geometric-based techniques and further categorize them in\ndetail. In the following section, the state-of-the-art methods involved in the\ngeometric technique are elaborated."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1012.3951v1", 
    "title": "Diffusion-geometric maximally stable component detection in deformable   shapes", 
    "arxiv-id": "1012.3951v1", 
    "author": "Michael M. Bronstein", 
    "publish": "2010-12-17T18:23:35Z", 
    "summary": "Maximally stable component detection is a very popular method for feature\nanalysis in images, mainly due to its low computation cost and high\nrepeatability. With the recent advance of feature-based methods in geometric\nshape analysis, there is significant interest in finding analogous approaches\nin the 3D world. In this paper, we formulate a diffusion-geometric framework\nfor stable component detection in non-rigid 3D shapes, which can be used for\ngeometric feature detection and description. A quantitative evaluation of our\nmethod on the SHREC'10 feature detection benchmark shows its potential as a\nsource of high-quality features."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1012.5933v1", 
    "title": "Affine-invariant diffusion geometry for the analysis of deformable 3D   shapes", 
    "arxiv-id": "1012.5933v1", 
    "author": "Nir Sochen", 
    "publish": "2010-12-29T13:11:41Z", 
    "summary": "We introduce an (equi-)affine invariant diffusion geometry by which surfaces\nthat go through squeeze and shear transformations can still be properly\nanalyzed. The definition of an affine invariant metric enables us to construct\nan invariant Laplacian from which local and global geometric structures are\nextracted. Applications of the proposed framework demonstrate its power in\ngeneralizing and enriching the existing set of tools for shape analysis."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1012.5936v1", 
    "title": "Affine-invariant geodesic geometry of deformable 3D shapes", 
    "arxiv-id": "1012.5936v1", 
    "author": "Nir Sochen", 
    "publish": "2010-12-29T13:33:01Z", 
    "summary": "Natural objects can be subject to various transformations yet still preserve\nproperties that we refer to as invariants. Here, we use definitions of affine\ninvariant arclength for surfaces in R^3 in order to extend the set of existing\nnon-rigid shape analysis tools. In fact, we show that by re-defining the\nsurface metric as its equi-affine version, the surface with its modified metric\ntensor can be treated as a canonical Euclidean object on which most classical\nEuclidean processing and analysis tools can be applied. The new definition of a\nmetric is used to extend the fast marching method technique for computing\ngeodesic distances on surfaces, where now, the distances are defined with\nrespect to an affine invariant arclength. Applications of the proposed\nframework demonstrate its invariance, efficiency, and accuracy in shape\nanalysis."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.0237v1", 
    "title": "A Framework for Real-Time Face and Facial Feature Tracking using Optical   Flow Pre-estimation and Template Tracking", 
    "arxiv-id": "1101.0237v1", 
    "author": "Michael S. Lew", 
    "publish": "2010-12-31T12:16:29Z", 
    "summary": "This work presents a framework for tracking head movements and capturing the\nmovements of the mouth and both the eyebrows in real-time. We present a head\ntracker which is a combination of a optical flow and a template based tracker.\nThe estimation of the optical flow head tracker is used as starting point for\nthe template tracker which fine-tunes the head estimation. This approach\ntogether with re-updating the optical flow points prevents the head tracker\nfrom drifting. This combination together with our switching scheme, makes our\ntracker very robust against fast movement and motion-blur. We also propose a\nway to reduce the influence of partial occlusion of the head. In both the\noptical flow and the template based tracker we identify and exclude occluded\npoints."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.0242v1", 
    "title": "Binary and nonbinary description of hypointensity in human brain MR   images", 
    "arxiv-id": "1101.0242v1", 
    "author": "Michael S. Lew", 
    "publish": "2010-12-31T12:26:04Z", 
    "summary": "Accumulating evidence has shown that iron is involved in the mechanism\nunderlying many neurodegenerative diseases, such as Alzheimer's disease,\nParkinson's disease and Huntington's disease. Abnormal (higher) iron\naccumulation has been detected in the brains of most neurodegenerative\npatients, especially in the basal ganglia region. Presence of iron leads to\nchanges in MR signal in both magnitude and phase. Accordingly, tissues with\nhigh iron concentration appear hypo-intense (darker than usual) in MR\ncontrasts. In this report, we proposed an improved binary hypointensity\ndescription and a novel nonbinary hypointensity description based on principle\ncomponents analysis. Moreover, Kendall's rank correlation coefficient was used\nto compare the complementary and redundant information provided by the two\nmethods in order to better understand the individual descriptions of iron\naccumulation in the brain."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.0384v1", 
    "title": "Combining Neural Networks for Skin Detection", 
    "arxiv-id": "1101.0384v1", 
    "author": "Sigeru Omatu", 
    "publish": "2011-01-02T04:53:22Z", 
    "summary": "Two types of combining strategies were evaluated namely combining skin\nfeatures and combining skin classifiers. Several combining rules were applied\nwhere the outputs of the skin classifiers are combined using binary operators\nsuch as the AND and the OR operators, \"Voting\", \"Sum of Weights\" and a new\nneural network. Three chrominance components from the YCbCr colour space that\ngave the highest correct detection on their single feature MLP were selected as\nthe combining parameters. A major issue in designing a MLP neural network is to\ndetermine the optimal number of hidden units given a set of training patterns.\nTherefore, a \"coarse to fine search\" method to find the number of neurons in\nthe hidden layer is proposed. The strategy of combining Cb/Cr and Cr features\nimproved the correct detection by 3.01% compared to the best single feature MLP\ngiven by Cb-Cr. The strategy of combining the outputs of three skin classifiers\nusing the \"Sum of Weights\" rule further improved the correct detection by 4.38%\ncompared to the best single feature MLP."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.0457v1", 
    "title": "Segmentation of Camera Captured Business Card Images for Mobile Devices", 
    "arxiv-id": "1101.0457v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-01-03T06:15:08Z", 
    "summary": "Due to huge deformation in the camera captured images, variety in nature of\nthe business cards and the computational constraints of the mobile devices,\ndesign of an efficient Business Card Reader (BCR) is challenging to the\nresearchers. Extraction of text regions and segmenting them into characters is\none of such challenges. In this paper, we have presented an efficient character\nsegmentation technique for business card images captured by a cell-phone\ncamera, designed in our present work towards developing an efficient BCR. At\nfirst, text regions are extracted from the card images and then the skewed ones\nare corrected using a computationally efficient skew correction technique. At\nlast, these skew corrected text regions are segmented into lines and characters\nbased on horizontal and vertical histogram. Experiments show that the present\ntechnique is efficient and applicable for mobile devices, and the mean\nsegmentation accuracy of 97.48% is achieved with 3 mega-pixel (500-600 dpi)\nimages. It takes only 1.1 seconds for segmentation including all the\npreprocessing steps on a moderately powerful notebook (DualCore T2370, 1.73\nGHz, 1GB RAM, 1MB L2 Cache)."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.1602v1", 
    "title": "Application of Freeman Chain Codes: An Alternative Recognition Technique   for Malaysian Car Plates", 
    "arxiv-id": "1101.1602v1", 
    "author": "Jasni Mohamad Zain", 
    "publish": "2011-01-08T16:22:20Z", 
    "summary": "Various applications of car plate recognition systems have been developed\nusing various kinds of methods and techniques by researchers all over the\nworld. The applications developed were only suitable for specific country due\nto its standard specification endorsed by the transport department of\nparticular countries. The Road Transport Department of Malaysia also has\nendorsed a specification for car plates that includes the font and size of\ncharacters that must be followed by car owners. However, there are cases where\nthis specification is not followed. Several applications have been developed in\nMalaysia to overcome this problem. However, there is still problem in achieving\n100% recognition accuracy. This paper is mainly focused on conducting an\nexperiment using chain codes technique to perform recognition for different\ntypes of fonts used in Malaysian car plates."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.2243v1", 
    "title": "Illustrating Color Evolution and Color Blindness by the Decoding Model   of Color Vision", 
    "arxiv-id": "1101.2243v1", 
    "author": "Chenguang Lu", 
    "publish": "2010-12-12T20:49:00Z", 
    "summary": "A symmetrical model of color vision, the decoding model as a new version of\nzone model, was introduced. The model adopts new continuous-valued logic and\nworks in a way very similar to the way a 3-8 decoder in a numerical circuit\nworks. By the decoding model, Young and Helmholtz's tri-pigment theory and\nHering's opponent theory are unified more naturally; opponent process, color\nevolution, and color blindness are illustrated more concisely. According to the\ndecoding model, we can obtain a transform from RGB system to HSV system, which\nis formally identical to the popular transform for computer graphics provided\nby Smith (1978). Advantages, problems, and physiological tests of the decoding\nmodel are also discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.2312v1", 
    "title": "Automatic segmentation of HeLa cell images", 
    "arxiv-id": "1101.2312v1", 
    "author": "Jan Urban", 
    "publish": "2011-01-12T10:16:11Z", 
    "summary": "In this work, the possibilities for segmentation of cells from their\nbackground and each other in digital image were tested, combined and improoved.\nLot of images with young, adult and mixture cells were able to prove the\nquality of described algorithms. Proper segmentation is one of the main task of\nimage analysis and steps order differ from work to work, depending on input\nimages. Reply for biologicaly given question was looking for in this work,\nincluding filtration, details emphasizing, segmentation and sphericity\ncomputing. Order of algorithms and way to searching for them was also\ndescribed. Some questions and ideas for further work were mentioned in the\nconclusion part."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.2491v1", 
    "title": "A Review of Research on Devnagari Character Recognition", 
    "arxiv-id": "1101.2491v1", 
    "author": "V H Mankar", 
    "publish": "2011-01-13T04:00:30Z", 
    "summary": "English Character Recognition (CR) has been extensively studied in the last\nhalf century and progressed to a level, sufficient to produce technology driven\napplications. But same is not the case for Indian languages which are\ncomplicated in terms of structure and computations. Rapidly growing\ncomputational power may enable the implementation of Indic CR methodologies.\nDigital document processing is gaining popularity for application to office and\nlibrary automation, bank and postal services, publishing houses and\ncommunication technology. Devnagari being the national language of India,\nspoken by more than 500 million people, should be given special attention so\nthat document retrieval and analysis of rich ancient and modern Indian\nliterature can be effectively done. This article is intended to serve as a\nguide and update for the readers, working in the Devnagari Optical Character\nRecognition (DOCR) area. An overview of DOCR systems is presented and the\navailable DOCR techniques are reviewed. The current status of DOCR is discussed\nand directions for future research are suggested."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1101.4301v1", 
    "title": "Diffusion framework for geometric and photometric data fusion in   non-rigid shape analysis", 
    "arxiv-id": "1101.4301v1", 
    "author": "Ron Kimmel", 
    "publish": "2011-01-22T16:41:20Z", 
    "summary": "In this paper, we explore the use of the diffusion geometry framework for the\nfusion of geometric and photometric information in local and global shape\ndescriptors. Our construction is based on the definition of a diffusion process\non the shape manifold embedded into a high-dimensional space where the\nembedding coordinates represent the photometric information. Experimental\nresults show that such data fusion is useful in coping with different\nchallenges of shape analysis where pure geometric and pure photometric methods\nfail."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1101.5320v2", 
    "title": "A Panorama on Multiscale Geometric Representations, Intertwining   Spatial, Directional and Frequency Selectivity", 
    "arxiv-id": "1101.5320v2", 
    "author": "Gabriel Peyr\u00e9", 
    "publish": "2011-01-27T15:53:30Z", 
    "summary": "The richness of natural images makes the quest for optimal representations in\nimage processing and computer vision challenging. The latter observation has\nnot prevented the design of image representations, which trade off between\nefficiency and complexity, while achieving accurate rendering of smooth regions\nas well as reproducing faithful contours and textures. The most recent ones,\nproposed in the past decade, share an hybrid heritage highlighting the\nmultiscale and oriented nature of edges and patterns in images. This paper\npresents a panorama of the aforementioned literature on decompositions in\nmultiscale, multi-orientation bases or dictionaries. They typically exhibit\nredundancy to improve sparsity in the transformed domain and sometimes its\ninvariance with respect to simple geometric deformations (translation,\nrotation). Oriented multiscale dictionaries extend traditional wavelet\nprocessing and may offer rotation invariance. Highly redundant dictionaries\nrequire specific algorithms to simplify the search for an efficient (sparse)\nrepresentation. We also discuss the extension of multiscale geometric\ndecompositions to non-Euclidean domains such as the sphere or arbitrary meshed\nsurfaces. The etymology of panorama suggests an overview, based on a choice of\npartially overlapping \"pictures\". We hope that this paper will contribute to\nthe appreciation and apprehension of a stream of current research directions in\nimage understanding."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.1292v1", 
    "title": "Modeling Dynamic Swarms", 
    "arxiv-id": "1102.1292v1", 
    "author": "Narendra Ahuja", 
    "publish": "2011-02-07T12:29:30Z", 
    "summary": "This paper proposes the problem of modeling video sequences of dynamic swarms\n(DS). We define DS as a large layout of stochastically repetitive spatial\nconfigurations of dynamic objects (swarm elements) whose motions exhibit local\nspatiotemporal interdependency and stationarity, i.e., the motions are similar\nin any small spatiotemporal neighborhood. Examples of DS abound in nature,\ne.g., herds of animals and flocks of birds. To capture the local spatiotemporal\nproperties of the DS, we present a probabilistic model that learns both the\nspatial layout of swarm elements and their joint dynamics that are modeled as\nlinear transformations. To this end, a spatiotemporal neighborhood is\nassociated with each swarm element, in which local stationarity is enforced\nboth spatially and temporally. We assume that the prior on the swarm dynamics\nis distributed according to an MRF in both space and time. Embedding this model\nin a MAP framework, we iterate between learning the spatial layout of the swarm\nand its dynamics. We learn the swarm transformations using ICM, which iterates\nbetween estimating these transformations and updating their distribution in the\nspatiotemporal neighborhoods. We demonstrate the validity of our method by\nconducting experiments on real video sequences. Real sequences of birds, geese,\nrobot swarms, and pedestrians evaluate the applicability of our model to real\nworld data."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.2743v2", 
    "title": "Feature selection via simultaneous sparse approximation for person   specific face verification", 
    "arxiv-id": "1102.2743v2", 
    "author": "Beiji Zou", 
    "publish": "2011-02-14T11:51:35Z", 
    "summary": "There is an increasing use of some imperceivable and redundant local features\nfor face recognition. While only a relatively small fraction of them is\nrelevant to the final recognition task, the feature selection is a crucial and\nnecessary step to select the most discriminant ones to obtain a compact face\nrepresentation. In this paper, we investigate the sparsity-enforced\nregularization-based feature selection methods and propose a multi-task feature\nselection method for building person specific models for face verification. We\nassume that the person specific models share a common subset of features and\nnovelly reformulated the common subset selection problem as a simultaneous\nsparse approximation problem. To the best of our knowledge, it is the first\ntime to apply the sparsity-enforced regularization methods for person specific\nface verification. The effectiveness of the proposed methods is verified with\nthe challenging LFW face databases."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.4258v1", 
    "title": "SHREC 2011: robust feature detection and description benchmark", 
    "arxiv-id": "1102.4258v1", 
    "author": "V. Zobel", 
    "publish": "2011-02-21T15:43:19Z", 
    "summary": "Feature-based approaches have recently become very popular in computer vision\nand image analysis applications, and are becoming a promising direction in\nshape retrieval. SHREC'11 robust feature detection and description benchmark\nsimulates the feature detection and description stages of feature-based shape\nretrieval algorithms. The benchmark tests the performance of shape feature\ndetectors and descriptors under a wide variety of transformations. The\nbenchmark allows evaluating how algorithms cope with certain classes of\ntransformations and strength of the transformations that can be dealt with. The\npresent paper is a report of the SHREC'11 robust feature detection and\ndescription benchmark results."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.5688v1", 
    "title": "A novel super resolution reconstruction of low reoslution images   progressively using dct and zonal filter based denoising", 
    "arxiv-id": "1102.5688v1", 
    "author": "C. N . Ravi Kumar", 
    "publish": "2011-02-28T15:24:06Z", 
    "summary": "Due to the factors like processing power limitations and channel capabilities\nimages are often down sampled and transmitted at low bit rates resulting in a\nlow resolution compressed image. High resolution images can be reconstructed\nfrom several blurred, noisy and down sampled low resolution images using a\ncomputational process know as super resolution reconstruction. Super-resolution\nis the process of combining multiple aliased low-quality images to produce a\nhigh resolution, high-quality image. The problem of recovering a high\nresolution image progressively from a sequence of low resolution compressed\nimages is considered. In this paper we propose a novel DCT based progressive\nimage display algorithm by stressing on the encoding and decoding process. At\nthe encoder we consider a set of low resolution images which are corrupted by\nadditive white Gaussian noise and motion blur. The low resolution images are\ncompressed using 8 by 8 blocks DCT and noise is filtered using our proposed\nnovel zonal filter. Multiframe fusion is performed in order to obtain a single\nnoise free image. At the decoder the image is reconstructed progressively by\ntransmitting the coarser image first followed by the detail image. And finally\na super resolution image is reconstructed by applying our proposed novel\nadaptive interpolation technique. We have performed both objective and\nsubjective analysis of the reconstructed image, and the resultant image has\nbetter super resolution factor, and a higher ISNR and PSNR. A comparative study\ndone with Iterative Back Projection (IBP) and Projection on to Convex Sets\n(POCS),Papoulis Grechberg, FFT based Super resolution Reconstruction shows that\nour method has out performed the previous contributions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.0120v2", 
    "title": "Automatic Detection of Ringworm using Local Binary Pattern (LBP)", 
    "arxiv-id": "1103.0120v2", 
    "author": "Mita Nasipuri", 
    "publish": "2011-03-01T10:06:31Z", 
    "summary": "In this paper we present a novel approach for automatic recognition of ring\nworm skin disease based on LBP (Local Binary Pattern) feature extracted from\nthe affected skin images. The proposed method is evaluated by extensive\nexperiments on the skin images collected from internet. The dataset is tested\nusing three different classifiers i.e. Bayesian, MLP and SVM. Experimental\nresults show that the proposed methodology efficiently discriminates between a\nring worm skin and a normal skin. It is a low cost technique and does not\nrequire any special imaging devices."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.1475v1", 
    "title": "A Semi-Automatic Graph-Based Approach for Determining the Boundary of   Eloquent Fiber Bundles in the Human Brain", 
    "arxiv-id": "1103.1475v1", 
    "author": "Christopher Nimsky", 
    "publish": "2011-03-08T09:39:21Z", 
    "summary": "Diffusion Tensor Imaging (DTI) allows estimating the position, orientation\nand dimension of bundles of nerve pathways. This non-invasive imaging technique\ntakes advantage of the diffusion of water molecules and determines the\ndiffusion coefficients for every voxel of the data set. The identification of\nthe diffusion coefficients and the derivation of information about fiber\nbundles is of major interest for planning and performing neurosurgical\ninterventions. To minimize the risk of neural deficits during brain surgery as\ntumor resection (e.g. glioma), the segmentation and integration of the results\nin the operating room is of prime importance. In this contribution, a robust\nand efficient graph-based approach for segmentating tubular fiber bundles in\nthe human brain is presented. To define a cost function, the fractional\nanisotropy (FA) is used, derived from the DTI data, but this value may differ\nfrom patient to patient. Besides manually definining seed regions describing\nthe structure of interest, additionally a manual definition of the cost\nfunction by the user is necessary. To improve the approach the contribution\nintroduces a solution for automatically determining the cost function by using\ndifferent 3D masks for each individual data set."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.1587v2", 
    "title": "All Roads Lead To Rome", 
    "arxiv-id": "1103.1587v2", 
    "author": "Xin Li", 
    "publish": "2011-03-08T17:50:56Z", 
    "summary": "This short article presents a class of projection-based solution algorithms\nto the problem considered in the pioneering work on compressed sensing -\nperfect reconstruction of a phantom image from 22 radial lines in the frequency\ndomain. Under the framework of projection-based image reconstruction, we will\nshow experimentally that several old and new tools of nonlinear filtering\n(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant\nthresholding and SA-DCT thresholding) all lead to perfect reconstruction of the\nphantom image."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.1952v1", 
    "title": "Ray-Based and Graph-Based Methods for Fiber Bundle Boundary Estimation", 
    "arxiv-id": "1103.1952v1", 
    "author": "Christopher Nimsky", 
    "publish": "2011-03-10T07:19:23Z", 
    "summary": "Diffusion Tensor Imaging (DTI) provides the possibility of estimating the\nlocation and course of eloquent structures in the human brain. Knowledge about\nthis is of high importance for preoperative planning of neurosurgical\ninterventions and for intraoperative guidance by neuronavigation in order to\nminimize postoperative neurological deficits. Therefore, the segmentation of\nthese structures as closed, three-dimensional object is necessary. In this\ncontribution, two methods for fiber bundle segmentation between two defined\nregions are compared using software phantoms (abstract model and anatomical\nphantom modeling the right corticospinal tract). One method uses evaluation\npoints from sampled rays as candidates for boundary points, the other method\nsets up a directed and weighted (depending on a scalar measure) graph and\nperforms a min-cut for optimal segmentation results. Comparison is done by\nusing the Dice Similarity Coefficient (DSC), a measure for spatial overlap of\ndifferent segmentation results."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.3440v1", 
    "title": "Off-Line Handwritten Signature Identification Using Rotated Complex   Wavelet Filters", 
    "arxiv-id": "1103.3440v1", 
    "author": "Manesh Kokare", 
    "publish": "2011-03-17T15:52:15Z", 
    "summary": "In this paper, a new method for handwritten signature identification based on\nrotated complex wavelet filters is proposed. We have proposed to use the\nrotated complex wavelet filters (RCWF) and dual tree complex wavelet\ntransform(DTCWT) together to derive signature feature extraction, which\ncaptures information in twelve different directions. In identification phase,\nCanberra distance measure is used. The proposed method is compared with\ndiscrete wavelet transform (DWT). From experimental results it is found that\nsignature identification rate of proposed method is superior over DWT"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.4723v3", 
    "title": "Automatic Extraction of Open Space Area from High Resolution Urban   Satellite Imagery", 
    "arxiv-id": "1103.4723v3", 
    "author": "P. S. Hiremath", 
    "publish": "2011-03-24T10:40:00Z", 
    "summary": "In the 21st century, Aerial and satellite images are information rich. They\nare also complex to analyze. For GIS systems, many features require fast and\nreliable extraction of open space area from high resolution satellite imagery.\nIn this paper we will study efficient and reliable automatic extraction\nalgorithm to find out the open space area from the high resolution urban\nsatellite imagery. This automatic extraction algorithm uses some filters and\nsegmentations and grouping is applying on satellite images. And the result\nimages may use to calculate the total available open space area and the built\nup area. It may also use to compare the difference between present and past\nopen space area using historical urban satellite images of that same projection"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.4913v1", 
    "title": "Automatic Open Space Area Extraction and Change Detection from High   Resolution Urban Satellite Images", 
    "arxiv-id": "1103.4913v1", 
    "author": "P. S. Hiremath", 
    "publish": "2011-03-25T07:02:09Z", 
    "summary": "In this paper, we study efficient and reliable automatic extraction algorithm\nto find out the open space area from the high resolution urban satellite\nimagery, and to detect changes from the extracted open space area during the\nperiod 2003, 2006 and 2008. This automatic extraction and change detection\nalgorithm uses some filters, segmentation and grouping that are applied on\nsatellite images. The resultant images may be used to calculate the total\navailable open space area and the built up area. It may also be used to compare\nthe difference between present and past open space area using historical urban\nsatellite images of that same projection, which is an important geo spatial\ndata management application."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2206", 
    "link": "http://arxiv.org/pdf/1103.5621v1", 
    "title": "Application of Threshold Techniques for Readability Improvement of Jawi   Historical Manuscript Images", 
    "arxiv-id": "1103.5621v1", 
    "author": "Amzari Jihadi Ghazali", 
    "publish": "2011-03-29T12:34:53Z", 
    "summary": "Historical documents such as old books and manuscripts have a high aesthetic\nvalue and highly appreciated. Unfortunately, there are some documents cannot be\nread due to quality problems like faded paper, ink expand, uneven colour tone,\ntorn paper and other elements disruption such as the existence of small spots.\nThe study aims to produce a copy of manuscript that shows clear wordings so\nthey can easily be read and the copy can also be displayed for visitors. 16\nsamples of Jawi historical manuscript with different quality problems were\nobtained from The Royal Museum of Pahang, Malaysia. We applied three\nbinarization techniques; Otsu's method represents global threshold technique;\nSauvola and Niblack method which are categorized as local threshold techniques.\nWe compared the binarized images with the original manuscript to be visually\ninspected by the museum's curator. The unclear features were marked and\nanalyzed. Most of the examined images show that with optimal parameters and\neffective pre processing technique, local thresholding methods are work well\ncompare with the other one. Niblack's and Sauvola's techniques seem to be the\nsuitable approaches for these types of images. Most of binarized images with\nthese two methods show improvement for readability and character recognition.\nFor this research, even the differences of image result were hard to be\ndistinguished by human capabilities, after comparing the time cost and overall\nachievement rate of recognized symbols, Niblack's method is performing better\nthan Sauvola's. We could improve the post processing step by adding edge\ndetection techniques and further enhanced by an innovative image refinement\ntechnique and a formulation of a class proper method."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2206", 
    "link": "http://arxiv.org/pdf/1103.5808v1", 
    "title": "Improved Edge Awareness in Discontinuity Preserving Smoothing", 
    "arxiv-id": "1103.5808v1", 
    "author": "Wesley E. Snyder", 
    "publish": "2011-03-30T01:57:09Z", 
    "summary": "Discontinuity preserving smoothing is a fundamentally important procedure\nthat is useful in a wide variety of image processing contexts. It is directly\nuseful for noise reduction, and frequently used as an intermediate step in\nhigher level algorithms. For example, it can be particularly useful in edge\ndetection and segmentation. Three well known algorithms for discontinuity\npreserving smoothing are nonlinear anisotropic diffusion, bilateral filtering,\nand mean shift filtering. Although slight differences make them each better\nsuited to different tasks, all are designed to preserve discontinuities while\nsmoothing. However, none of them satisfy this goal perfectly: they each have\nexception cases in which smoothing may occur across hard edges. The principal\ncontribution of this paper is the identification of a property we call edge\nawareness that should be satisfied by any discontinuity preserving smoothing\nalgorithm. This constraint can be incorporated into existing algorithms to\nimprove quality, and usually has negligible changes in runtime performance\nand/or complexity. We present modifications necessary to augment diffusion and\nmean shift, as well as a new formulation of the bilateral filter that unifies\nthe spatial and range spaces to achieve edge awareness."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2206", 
    "link": "http://arxiv.org/pdf/1103.6052v1", 
    "title": "Internal Constraints of the Trifocal Tensor", 
    "arxiv-id": "1103.6052v1", 
    "author": "Wesley E. Snyder", 
    "publish": "2011-03-30T21:47:41Z", 
    "summary": "The fundamental matrix and trifocal tensor are convenient algebraic\nrepresentations of the epipolar geometry of two and three view configurations,\nrespectively. The estimation of these entities is central to most\nreconstruction algorithms, and a solid understanding of their properties and\nconstraints is therefore very important. The fundamental matrix has 1 internal\nconstraint which is well understood, whereas the trifocal tensor has 8\nindependent algebraic constraints. The internal tensor constraints can be\nrepresented in many ways, although there is only one minimal and sufficient set\nof 8 constraints known. In this paper, we derive a second set of minimal and\nsufficient constraints that is simpler. We also show how this can be used in a\nnew parameterization of the trifocal tensor. We hope that this increased\nunderstanding of the internal constraints may lead to improved algorithms for\nestimating the trifocal tensor, although the primary contribution is an\nimproved theoretical understanding."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3218", 
    "link": "http://arxiv.org/pdf/1105.0079v1", 
    "title": "An Automated Size Recognition Technique for Acetabular Implant in Total   Hip Replacement", 
    "arxiv-id": "1105.0079v1", 
    "author": "Abdul Yazid Mohd Kassim", 
    "publish": "2011-04-30T12:07:11Z", 
    "summary": "Preoperative templating in Total Hip Replacement (THR) is a method to\nestimate the optimal size and position of the implant. Today, observational\n(manual) size recognition techniques are still used to find a suitable implant\nfor the patient. Therefore, a digital and automated technique should be\ndeveloped so that the implant size recognition process can be effectively\nimplemented. For this purpose, we have introduced the new technique for\nacetabular implant size recognition in THR preoperative planning based on the\ndiameter of acetabulum size. This technique enables the surgeon to recognise a\ndigital acetabular implant size automatically. Ten randomly selected X-rays of\nunidentified patients were used to test the accuracy and utility of an\nautomated implant size recognition technique. Based on the testing result, the\nnew technique yielded very close results to those obtained by the observational\nmethod in nine studies (90%)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3218", 
    "link": "http://arxiv.org/pdf/1105.0821v1", 
    "title": "Considerations and Results in Multimedia and DVB Application Development   on Philips Nexperia Platform", 
    "arxiv-id": "1105.0821v1", 
    "author": "Ciprian Ilioaei", 
    "publish": "2011-05-04T13:40:16Z", 
    "summary": "This paper presents some experiments regarding applications development on\nhigh performance media processors included in Philips Nexperia Family. The\nPNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded\nto overcome these limitations and to make possible a general-purpose use of\nthis kit. For exemplification two typical applications, important both for\nmultimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio\ndecoding. These original implementations are compared (in speed, memory\nrequirements and costs) with Philips Nexperia Library."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3218", 
    "link": "http://arxiv.org/pdf/1105.2491v2", 
    "title": "A Multiple Component Matching Framework for Person Re-Identification", 
    "arxiv-id": "1105.2491v2", 
    "author": "Vittorio Murino", 
    "publish": "2011-05-12T14:46:01Z", 
    "summary": "Person re-identification consists in recognizing an individual that has\nalready been observed over a network of cameras. It is a novel and challenging\nresearch topic in computer vision, for which no reference framework exists yet.\nDespite this, previous works share similar representations of human body based\non part decomposition and the implicit concept of multiple instances. Building\non these similarities, we propose a Multiple Component Matching (MCM) framework\nfor the person re-identification problem, which is inspired by Multiple\nComponent Learning, a framework recently proposed for object detection. We show\nthat previous techniques for person re-identification can be considered\nparticular implementations of our MCM framework. We then present a novel person\nre-identification technique as a direct, simple implementation of our\nframework, focused in particular on robustness to varying lighting conditions,\nand show that it can attain state of the art performances."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.540754", 
    "link": "http://arxiv.org/pdf/1105.2797v1", 
    "title": "Face Recognition using 3D Facial Shape and Color Map Information:   Comparison and Combination", 
    "arxiv-id": "1105.2797v1", 
    "author": "Patrick Grother", 
    "publish": "2011-05-13T18:25:28Z", 
    "summary": "In this paper, we investigate the use of 3D surface geometry for face\nrecognition and compare it to one based on color map information. The 3D\nsurface and color map data are from the CAESAR anthropometric database. We find\nthat the recognition performance is not very different between 3D surface and\ncolor map information using a principal component analysis algorithm. We also\ndiscuss the different techniques for the combination of the 3D surface and\ncolor map information for multi-modal recognition by using different fusion\napproaches and show that there is significant improvement in results. The\neffectiveness of various techniques is compared and evaluated on a dataset with\n200 subjects in two different positions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2010.12.009", 
    "link": "http://arxiv.org/pdf/1105.3559v4", 
    "title": "Invariant Representative Cocycles of Cohomology Generators using   Irregular Graph Pyramids", 
    "arxiv-id": "1105.3559v4", 
    "author": "Walter G. Kropatsch", 
    "publish": "2011-05-18T08:18:42Z", 
    "summary": "Structural pattern recognition describes and classifies data based on the\nrelationships of features and parts. Topological invariants, like the Euler\nnumber, characterize the structure of objects of any dimension. Cohomology can\nprovide more refined algebraic invariants to a topological space than does\nhomology. It assigns `quantities' to the chains used in homology to\ncharacterize holes of any dimension. Graph pyramids can be used to describe\nsubdivisions of the same object at multiple levels of detail. This paper\npresents cohomology in the context of structural pattern recognition and\nintroduces an algorithm to efficiently compute representative cocycles (the\nbasic elements of cohomology) in 2D using a graph pyramid. An extension to\nobtain scanning and rotation invariant cocycles is given."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2010.12.009", 
    "link": "http://arxiv.org/pdf/1105.3828v2", 
    "title": "An Algorithmic Solution to the Five-Point Pose Problem Based on the   Cayley Representation of Rotations", 
    "arxiv-id": "1105.3828v2", 
    "author": "Evgeniy Martyushev", 
    "publish": "2011-05-19T09:50:01Z", 
    "summary": "We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2010.12.009", 
    "link": "http://arxiv.org/pdf/1105.3834v1", 
    "title": "A Multiple-Choice Test Recognition System based on the Gamera Framework", 
    "arxiv-id": "1105.3834v1", 
    "author": "Vanni Rizzo", 
    "publish": "2011-05-19T10:09:44Z", 
    "summary": "This article describes JECT-OMR, a system that analyzes digital images\nrepresenting scans of multiple-choice tests compiled by students. The system\nperforms a structural analysis of the document in order to get the chosen\nanswer for each question, and it also contains a bar-code decoder, used for the\nidentification of additional information encoded in the document. JECT-OMR was\nimplemented using the Python programming language, and leverages the power of\nthe Gamera framework in order to accomplish its task. The system exhibits an\naccuracy of over 99% in the recognition of marked and non-marked squares\nrepresenting answers, thus making it suitable for real world applications"
},{
    "category": "cs.CV", 
    "doi": "10.1002/ima.20271", 
    "link": "http://arxiv.org/pdf/1105.4183v1", 
    "title": "Cubical Cohomology Ring of 3D Photographs", 
    "arxiv-id": "1105.4183v1", 
    "author": "Belen Medrano", 
    "publish": "2011-05-20T22:12:41Z", 
    "summary": "Cohomology and cohomology ring of three-dimensional (3D) objects are\ntopological invariants that characterize holes and their relations. Cohomology\nring has been traditionally computed on simplicial complexes. Nevertheless,\ncubical complexes deal directly with the voxels in 3D images, no additional\ntriangulation is necessary, facilitating efficient algorithms for the\ncomputation of topological invariants in the image context. In this paper, we\npresent formulas to directly compute the cohomology ring of 3D cubical\ncomplexes without making use of any additional triangulation. Starting from a\ncubical complex $Q$ that represents a 3D binary-valued digital picture whose\nforeground has one connected component, we compute first the cohomological\ninformation on the boundary of the object, $\\partial Q$ by an incremental\ntechnique; then, using a face reduction algorithm, we compute it on the whole\nobject; finally, applying the mentioned formulas, the cohomology ring is\ncomputed from such information."
},{
    "category": "cs.CV", 
    "doi": "10.1109/IV.2011.89", 
    "link": "http://arxiv.org/pdf/1105.4354v2", 
    "title": "Preprocessing for Automating Early Detection of Cervical Cancer", 
    "arxiv-id": "1105.4354v2", 
    "author": "Debasis Bhattacharyya", 
    "publish": "2011-05-22T17:06:59Z", 
    "summary": "Uterine Cervical Cancer is one of the most common forms of cancer in women\nworldwide. Most cases of cervical cancer can be prevented through screening\nprograms aimed at detecting precancerous lesions. During Digital Colposcopy,\ncolposcopic images or cervigrams are acquired in raw form. They contain\nspecular reflections which appear as bright spots heavily saturated with white\nlight and occur due to the presence of moisture on the uneven cervix surface\nand. The cervix region occupies about half of the raw cervigram image. Other\nparts of the image contain irrelevant information, such as equipment, frames,\ntext and non-cervix tissues. This irrelevant information can confuse automatic\nidentification of the tissues within the cervix. Therefore we focus on the\ncervical borders, so that we have a geometric boundary on the relevant image\narea. Our novel technique eliminates the SR, identifies the region of interest\nand makes the cervigram ready for segmentation algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.dam.2004.09.014", 
    "link": "http://arxiv.org/pdf/1105.4477v1", 
    "title": "On the Cohomology of 3D Digital Images", 
    "arxiv-id": "1105.4477v1", 
    "author": "Pedro Real", 
    "publish": "2011-05-23T12:06:18Z", 
    "summary": "We propose a method for computing the cohomology ring of three--dimensional\n(3D) digital binary-valued pictures. We obtain the cohomology ring of a 3D\ndigital binary--valued picture $I$, via a simplicial complex K(I)topologically\nrepresenting (up to isomorphisms of pictures) the picture I. The usefulness of\na simplicial description of the \"digital\" cohomology ring of 3D digital\nbinary-valued pictures is tested by means of a small program visualizing the\ndifferent steps of the method. Some examples concerning topological thinning,\nthe visualization of representative (co)cycles of (co)homology generators and\nthe computation of the cup product on the cohomology of simple pictures are\nshowed."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.4480v1", 
    "title": "A Tool for Integer Homology Computation: Lambda-At Model", 
    "arxiv-id": "1105.4480v1", 
    "author": "Pedro Real", 
    "publish": "2011-05-23T12:40:06Z", 
    "summary": "In this paper, we formalize the notion of lambda-AT-model (where $\\lambda$ is\na non-null integer) for a given chain complex, which allows the computation of\nhomological information in the integer domain avoiding using the Smith Normal\nForm of the boundary matrices. We present an algorithm for computing such a\nmodel, obtaining Betti numbers, the prime numbers p involved in the invariant\nfactors of the torsion subgroup of homology, the amount of invariant factors\nthat are a power of p and a set of representative cycles of generators of\nhomology mod p, for each p. Moreover, we establish the minimum valid lambda for\nsuch a construction, what cuts down the computational costs related to the\ntorsion subgroup. The tools described here are useful to determine topological\ninformation of nD structured objects such as simplicial, cubical or simploidal\ncomplexes and are applicable to extract such an information from digital\npictures."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.4712v1", 
    "title": "Image Splicing Detection Using Inherent Lens Radial Distortion", 
    "arxiv-id": "1105.4712v1", 
    "author": "Lalitha Rangarajan", 
    "publish": "2011-05-24T09:05:04Z", 
    "summary": "Image splicing is a common form of image forgery. Such alterations may leave\nno visual clues of tampering. In recent works camera characteristics\nconsistency across the image has been used to establish the authenticity and\nintegrity of digital images. Such constant camera characteristic properties are\ninherent from camera manufacturing processes and are unique. The majority of\ndigital cameras are equipped with spherical lens and this introduces radial\ndistortions on images. This aberration is often disturbed and fails to be\nconsistent across the image, when an image is spliced. This paper describes the\ndetection of splicing operation on images by estimating radial distortion from\ndifferent portions of the image using line-based calibration. For the first\ntime, the detection of image splicing through the verification of consistency\nof lens radial distortion has been explored in this paper. The conducted\nexperiments demonstrate the efficacy of our proposed approach for the detection\nof image splicing on both synthetic and real images."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.6014v1", 
    "title": "Neural Networks for Emotion Classification", 
    "arxiv-id": "1105.6014v1", 
    "author": "Yafei Sun", 
    "publish": "2011-05-30T15:19:55Z", 
    "summary": "It is argued that for the computer to be able to interact with humans, it\nneeds to have the communication skills of humans. One of these skills is the\nability to understand the emotional state of the person. This thesis describes\na neural network-based approach for emotion classification. We learn a\nclassifier that can recognize six basic emotions with an average accuracy of\n77% over the Cohn-Kanade database. The novelty of this work is that instead of\nempirically selecting the parameters of the neural network, i.e. the learning\nrate, activation function parameter, momentum number, the number of nodes in\none layer, etc. we developed a strategy that can automatically select\ncomparatively better combination of these parameters. We also introduce another\nway to perform back propagation. Instead of using the partial differential of\nthe error function, we use optimal algorithm; namely Powell's direction set to\nminimize the error function. We were also interested in construction an\nauthentic emotion databases. This is a very important task because nowadays\nthere is no such database available. Finally, we perform several experiments\nand show that our neural network approach can be successfully used for emotion\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.6060v1", 
    "title": "Alignment of Microtubule Imagery", 
    "arxiv-id": "1105.6060v1", 
    "author": "Erwin M. Bakker", 
    "publish": "2011-05-30T18:30:51Z", 
    "summary": "This work discusses preliminary work aimed at simulating and visualizing the\ngrowth process of a tiny structure inside the cell---the microtubule.\nDifficulty of recording the process lies in the fact that the tissue\npreparation method for electronic microscopes is highly destructive to live\ncells. Here in this paper, our approach is to take pictures of microtubules at\ndifferent time slots and then appropriately combine these images into a\ncoherent video. Experimental results are given on real data."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.6277v1", 
    "title": "Incremental Top-k List Comparison Approach to Robust Multi-Structure   Model Fitting", 
    "arxiv-id": "1105.6277v1", 
    "author": "David Suter", 
    "publish": "2011-05-31T13:45:46Z", 
    "summary": "Random hypothesis sampling lies at the core of many popular robust fitting\ntechniques such as RANSAC. In this paper, we propose a novel hypothesis\nsampling scheme based on incremental computation of distances between partial\nrankings (top-$k$ lists) derived from residual sorting information. Our method\nsimultaneously (1) guides the sampling such that hypotheses corresponding to\nall true structures can be quickly retrieved and (2) filters the hypotheses\nsuch that only a small but very promising subset remain. This permits the usage\nof simple agglomerative clustering on the surviving hypotheses for accurate\nmodel selection. The outcome is a highly efficient multi-structure robust\nestimation technique. Experiments on synthetic and real data show the superior\nperformance of our approach over previous methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2301", 
    "link": "http://arxiv.org/pdf/1106.0371v1", 
    "title": "A Novel Image Segmentation Enhancement Technique based on Active Contour   and Topological Alignments", 
    "arxiv-id": "1106.0371v1", 
    "author": "Nazar Zaki", 
    "publish": "2011-06-02T06:31:13Z", 
    "summary": "Topological alignments and snakes are used in image processing, particularly\nin locating object boundaries. Both of them have their own advantages and\nlimitations. To improve the overall image boundary detection system, we focused\non developing a novel algorithm for image processing. The algorithm we propose\nto develop will based on the active contour method in conjunction with\ntopological alignments method to enhance the image detection approach. The\nalgorithm presents novel technique to incorporate the advantages of both\nTopological Alignments and snakes. Where the initial segmentation by\nTopological Alignments is firstly transformed into the input of the snake model\nand begins its evolvement to the interested object boundary. The results show\nthat the algorithm can deal with low contrast images and shape cells,\ndemonstrate the segmentation accuracy under weak image boundaries, which\nresponsible for lacking accuracy in image detecting techniques. We have\nachieved better segmentation and boundary detecting for the image, also the\nability of the system to improve the low contrast and deal with over and under\nsegmentation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2301", 
    "link": "http://arxiv.org/pdf/1106.0962v1", 
    "title": "An efficient circle detection scheme in digital images using ant system   algorithm", 
    "arxiv-id": "1106.0962v1", 
    "author": "A. Konar", 
    "publish": "2011-06-06T05:52:09Z", 
    "summary": "Detection of geometric features in digital images is an important exercise in\nimage analysis and computer vision. The Hough Transform techniques for\ndetection of circles require a huge memory space for data processing hence\nrequiring a lot of time in computing the locations of the data space, writing\nto and searching through the memory space. In this paper we propose a novel and\nefficient scheme for detecting circles in edge-detected grayscale digital\nimages. We use Ant-system algorithm for this purpose which has not yet found\nmuch application in this field. The main feature of this scheme is that it can\ndetect both intersecting as well as non-intersecting circles with a time\nefficiency that makes it useful in real time applications. We build up an ant\nsystem of new type which finds out closed loops in the image and then tests\nthem for circles."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SOFA.2010.5565599", 
    "link": "http://arxiv.org/pdf/1106.2357v1", 
    "title": "Comparing Haar-Hilbert and Log-Gabor Based Iris Encoders on Bath Iris   Image Database", 
    "arxiv-id": "1106.2357v1", 
    "author": "Valentina E. Balas", 
    "publish": "2011-06-12T23:14:05Z", 
    "summary": "This papers introduces a new family of iris encoders which use 2-dimensional\nHaar Wavelet Transform for noise attenuation, and Hilbert Transform to encode\nthe iris texture. In order to prove the usefulness of the newly proposed iris\nencoding approach, the recognition results obtained by using these new encoders\nare compared to those obtained using the classical Log- Gabor iris encoder.\nTwelve tests involving single/multienrollment and conducted on Bath Iris Image\nDatabase are presented here. One of these tests achieves an Equal Error Rate\ncomparable to the lowest value reported so far for this database. New Matlab\ntools for iris image processing are also released together with this paper: a\nsecond version of the Circular Fuzzy Iris Segmentator (CFIS2), a fast Log-Gabor\nencoder and two Haar-Hilbert based encoders."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SOFA.2010.5565599", 
    "link": "http://arxiv.org/pdf/1106.2695v1", 
    "title": "Robust Mobile Object Tracking Based on Multiple Feature Similarity and   Trajectory Filtering", 
    "arxiv-id": "1106.2695v1", 
    "author": "Etienne Corvee", 
    "publish": "2011-06-14T12:45:05Z", 
    "summary": "This paper presents a new algorithm to track mobile objects in different\nscene conditions. The main idea of the proposed tracker includes estimation,\nmulti-features similarity measures and trajectory filtering. A feature set\n(distance, area, shape ratio, color histogram) is defined for each tracked\nobject to search for the best matching object. Its best matching object and its\nstate estimated by the Kalman filter are combined to update position and size\nof the tracked object. However, the mobile object trajectories are usually\nfragmented because of occlusions and misdetections. Therefore, we also propose\na trajectory filtering, named global tracker, aims at removing the noisy\ntrajectories and fusing the fragmented trajectories belonging to a same mobile\nobject. The method has been tested with five videos of different scene\nconditions. Three of them are provided by the ETISEO benchmarking project\n(http://www-sop.inria.fr/orion/ETISEO) in which the proposed tracker\nperformance has been compared with other seven tracking algorithms. The\nadvantages of our approach over the existing state of the art ones are: (i) no\nprior knowledge information is required (e.g. no calibration and no contextual\nmodels are needed), (ii) the tracker is more reliable by combining multiple\nfeature similarities, (iii) the tracker can perform in different scene\nconditions: single/several mobile objects, weak/strong illumination,\nindoor/outdoor scenes, (iv) a trajectory filtering is defined and applied to\nimprove the tracker performance, (v) the tracker performance outperforms many\nalgorithms of the state of the art."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3464v1", 
    "title": "Polar Fusion Technique Analysis for Evaluating the Performances of Image   Fusion of Thermal and Visual Images for Human Face Recognition", 
    "arxiv-id": "1106.3464v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-06-17T12:25:30Z", 
    "summary": "This paper presents a comparative study of two different methods, which are\nbased on fusion and polar transformation of visual and thermal images. Here,\ninvestigation is done to handle the challenges of face recognition, which\ninclude pose variations, changes in facial expression, partial occlusions,\nvariations in illumination, rotation through different angles, change in scale\netc. To overcome these obstacles we have implemented and thoroughly examined\ntwo different fusion techniques through rigorous experimentation. In the first\nmethod log-polar transformation is applied to the fused images obtained after\nfusion of visual and thermal images whereas in second method fusion is applied\non log-polar transformed individual visual and thermal images. After this step,\nwhich is thus obtained in one form or another, Principal Component Analysis\n(PCA) is applied to reduce dimension of the fused images. Log-polar transformed\nimages are capable of handling complicacies introduced by scaling and rotation.\nThe main objective of employing fusion is to produce a fused image that\nprovides more detailed and reliable information, which is capable to overcome\nthe drawbacks present in the individual visual and thermal face images.\nFinally, those reduced fused images are classified using a multilayer\nperceptron neural network. The database used for the experiments conducted here\nis Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database\nbenchmark thermal and visual face images. The second method has shown better\nperformance, which is 95.71% (maximum) and on an average 93.81% as correct\nrecognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3466v1", 
    "title": "Next Level of Data Fusion for Human Face Recognition", 
    "arxiv-id": "1106.3466v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-06-17T12:31:30Z", 
    "summary": "This paper demonstrates two different fusion techniques at two different\nlevels of a human face recognition process. The first one is called data fusion\nat lower level and the second one is the decision fusion towards the end of the\nrecognition process. At first a data fusion is applied on visual and\ncorresponding thermal images to generate fused image. Data fusion is\nimplemented in the wavelet domain after decomposing the images through\nDaubechies wavelet coefficients (db2). During the data fusion maximum of\napproximate and other three details coefficients are merged together. After\nthat Principle Component Analysis (PCA) is applied over the fused coefficients\nand finally two different artificial neural networks namely Multilayer\nPerceptron(MLP) and Radial Basis Function(RBF) networks have been used\nseparately to classify the images. After that, for decision fusion based\ndecisions from both the classifiers are combined together using Bayesian\nformulation. For experiments, IRIS thermal/visible Face Database has been used.\nExperimental results show that the performance of multiple classifier system\nalong with decision fusion works well over the single classifier system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3467v1", 
    "title": "High Performance Human Face Recognition using Independent High Intensity   Gabor Wavelet Responses: A Statistical Approach", 
    "arxiv-id": "1106.3467v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2011-06-17T12:42:26Z", 
    "summary": "In this paper, we present a technique by which high-intensity feature vectors\nextracted from the Gabor wavelet transformation of frontal face images, is\ncombined together with Independent Component Analysis (ICA) for enhanced face\nrecognition. Firstly, the high-intensity feature vectors are automatically\nextracted using the local characteristics of each individual face from the\nGabor transformed images. Then ICA is applied on these locally extracted\nhigh-intensity feature vectors of the facial images to obtain the independent\nhigh intensity feature (IHIF) vectors. These IHIF forms the basis of the work.\nFinally, the image classification is done using these IHIF vectors, which are\nconsidered as representatives of the images. The importance behind implementing\nICA along with the high-intensity features of Gabor wavelet transformation is\ntwofold. On the one hand, selecting peaks of the Gabor transformed face images\nexhibit strong characteristics of spatial locality, scale, and orientation\nselectivity. Thus these images produce salient local features that are most\nsuitable for face recognition. On the other hand, as the ICA employs locally\nsalient features from the high informative facial parts, it reduces redundancy\nand represents independent features explicitly. These independent features are\nmost useful for subsequent facial discrimination and associative recall. The\nefficiency of IHIF method is demonstrated by the experiment on frontal facial\nimages dataset, selected from the FERET, FRAV2D, and the ORL database."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3517v1", 
    "title": "DWT Based Fingerprint Recognition using Non Minutiae Features", 
    "arxiv-id": "1106.3517v1", 
    "author": "Sabyasachi Pattanaik", 
    "publish": "2011-06-17T15:52:56Z", 
    "summary": "Forensic applications like criminal investigations, terrorist identification\nand National security issues require a strong fingerprint data base and\nefficient identification system. In this paper we propose DWT based Fingerprint\nRecognition using Non Minutiae (DWTFR) algorithm. Fingerprint image is\ndecomposed into multi resolution sub bands of LL, LH, HL and HH by applying 3\nlevel DWT. The Dominant local orientation angle {\\theta} and Coherence are\ncomputed on LL band only. The Centre Area Features and Edge Parameters are\ndetermined on each DWT level by considering all four sub bands. The comparison\nof test fingerprint with database fingerprint is decided based on the Euclidean\nDistance of all the features. It is observed that the values of FAR, FRR and\nTSR are improved compared to the existing algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.4907v1", 
    "title": "Face Identification from Manipulated Facial Images using SIFT", 
    "arxiv-id": "1106.4907v1", 
    "author": "Veerabhadrappa", 
    "publish": "2011-06-24T08:30:15Z", 
    "summary": "Editing on digital images is ubiquitous. Identification of deliberately\nmodified facial images is a new challenge for face identification system. In\nthis paper, we address the problem of identification of a face or person from\nheavily altered facial images. In this face identification problem, the input\nto the system is a manipulated or transformed face image and the system reports\nback the determined identity from a database of known individuals. Such a\nsystem can be useful in mugshot identification in which mugshot database\ncontains two views (frontal and profile) of each criminal. We considered only\nfrontal view from the available database for face identification and the query\nimage is a manipulated face generated by face transformation software tool\navailable online. We propose SIFT features for efficient face identification in\nthis scenario. Further comparative analysis has been given with well known\neigenface approach. Experiments have been conducted with real case images to\nevaluate the performance of both methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5156v2", 
    "title": "Morphological Reconstruction for Word Level Script Identification", 
    "arxiv-id": "1106.5156v2", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2011-06-25T18:16:59Z", 
    "summary": "A line of a bilingual document page may contain text words in regional\nlanguage and numerals in English. For Optical Character Recognition (OCR) of\nsuch a document page, it is necessary to identify different script forms before\nrunning an individual OCR system. In this paper, we have identified a tool of\nmorphological opening by reconstruction of an image in different directions and\nregional descriptors for script identification at word level, based on the\nobservation that every text has a distinct visual appearance. The proposed\nsystem is developed for three Indian major bilingual documents, Kannada, Telugu\nand Devnagari containing English numerals. The nearest neighbour and k-nearest\nneighbour algorithms are applied to classify new word images. The proposed\nalgorithm is tested on 2625 words with various font styles and sizes. The\nresults obtained are quite encouraging"
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5186v1", 
    "title": "Learning Shape and Texture Characteristics of CT Tree-in-Bud Opacities   for CAD Systems", 
    "arxiv-id": "1106.5186v1", 
    "author": "Daniel J. Mollura", 
    "publish": "2011-06-26T03:35:08Z", 
    "summary": "Although radiologists can employ CAD systems to characterize malignancies,\npulmonary fibrosis and other chronic diseases; the design of imaging techniques\nto quantify infectious diseases continue to lag behind. There exists a need to\ncreate more CAD systems capable of detecting and quantifying characteristic\npatterns often seen in respiratory tract infections such as influenza,\nbacterial pneumonia, or tuborculosis. One of such patterns is Tree-in-bud (TIB)\nwhich presents \\textit{thickened} bronchial structures surrounding by clusters\nof \\textit{micro-nodules}. Automatic detection of TIB patterns is a challenging\ntask because of their weak boundary, noisy appearance, and small lesion size.\nIn this paper, we present two novel methods for automatically detecting TIB\npatterns: (1) a fast localization of candidate patterns using information from\nlocal scale of the images, and (2) a M\\\"{o}bius invariant feature extraction\nmethod based on learned local shape and texture properties. A comparative\nevaluation of the proposed methods is presented with a dataset of 39 laboratory\nconfirmed viral bronchiolitis human parainfluenza (HPIV) CTs and 21 normal lung\nCTs. Experimental results demonstrate that the proposed CAD system can achieve\nhigh detection rate with an overall accuracy of 90.96%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5460v1", 
    "title": "Automated segmentation of the pulmonary arteries in low-dose CT by   vessel tracking", 
    "arxiv-id": "1106.5460v1", 
    "author": "Anthony Reeves", 
    "publish": "2011-06-27T17:47:23Z", 
    "summary": "We present a fully automated method for top-down segmentation of the\npulmonary arterial tree in low-dose thoracic CT images. The main basal\npulmonary arteries are identified near the lung hilum by searching for\ncandidate vessels adjacent to known airways, identified by our previously\nreported airway segmentation method. Model cylinders are iteratively fit to the\nvessels to track them into the lungs. Vessel bifurcations are detected by\nmeasuring the rate of change of vessel radii, and child vessels are segmented\nby initiating new trackers at bifurcation points. Validation is accomplished\nusing our novel sparse surface (SS) evaluation metric. The SS metric was\ndesigned to quantify the magnitude of the segmentation error per vessel while\nsignificantly decreasing the manual marking burden for the human user. A total\nof 210 arteries and 205 veins were manually marked across seven test cases.\n134/210 arteries were correctly segmented, with a specificity for arteries of\n90%, and average segmentation error of 0.15 mm. This fully-automated\nsegmentation is a promising method for improving lung nodule detection in\nlow-dose CT screening scans, by separating vessels from surrounding\niso-intensity objects."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5569v1", 
    "title": "Augmented Reality Implementation Methods in Mainstream Applications", 
    "arxiv-id": "1106.5569v1", 
    "author": "Tomas Koubek", 
    "publish": "2011-06-28T05:57:37Z", 
    "summary": "Augmented reality has became an useful tool in many areas from space\nexploration to military applications. Although used theoretical principles are\nwell known for almost a decade, the augmented reality is almost exclusively\nused in high budget solutions with a special hardware. However, in last few\nyears we could see rising popularity of many projects focused on deployment of\nthe augmented reality on different mobile devices. Our article is aimed on\ndevelopers who consider development of an augmented reality application for the\nmainstream market. Such developers will be forced to keep the application\nprice, therefore also the development price, at reasonable level. Usage of\nexisting image processing software library could bring a significant cut-down\nof the development costs. In the theoretical part of the article is presented\nan overview of the augmented reality application structure. Further, an\napproach for selection appropriate library as well as the review of the\nexisting software libraries focused in this area is described. The last part of\nthe article outlines our implementation of key parts of the augmented reality\napplication using the OpenCV library."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5571v1", 
    "title": "Mobile Augmented Reality Applications", 
    "arxiv-id": "1106.5571v1", 
    "author": "Jiri Stastny", 
    "publish": "2011-06-28T06:08:38Z", 
    "summary": "Augmented reality have undergone considerable improvement in past years. Many\nspecial techniques and hardware devices were developed, but the crucial\nbreakthrough came with the spread of intelligent mobile phones. This enabled\nmass spread of augmented reality applications. However mobile devices have\nlimited hardware capabilities, which narrows down the methods usable for scene\nanalysis. In this article we propose an augmented reality application which is\nusing cloud computing to enable using of more complex computational methods\nsuch as neural networks. Our goal is to create an affordable augmented reality\napplication suitable which will help car designers in by 'virtualizing' car\nmodifications."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5737v1", 
    "title": "Fingerprint: DWT, SVD Based Enhancement and Significant Contrast for   Ridges and Valleys Using Fuzzy Measures", 
    "arxiv-id": "1106.5737v1", 
    "author": "Dr. S. Arumuga Perumal", 
    "publish": "2011-06-23T16:25:22Z", 
    "summary": "The performance of the Fingerprint recognition system will be more accurate\nwith respect of enhancement for the fingerprint images. In this paper we\ndevelop a novel method for Fingerprint image contrast enhancement technique\nbased on the discrete wavelet transform (DWT) and singular value decomposition\n(SVD) has been proposed. This technique is compared with conventional image\nequalization techniques such as standard general histogram equalization and\nlocal histogram equalization. An automatic histogram threshold approach based\non a fuzziness measure is presented. Then, using an index of fuzziness, a\nsimilarity process is started to find the threshold point. A significant\ncontrast between ridges and valleys of the best, medium and poor finger image\nfeatures to extract from finger images and get maximum recognition rate using\nfuzzy measures. The experimental results show the recognition of superiority of\nthe proposed method to get maximum performance up gradation to the\nimplementation of this approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5928v1", 
    "title": "Image denoising assessment using anisotropic stack filtering", 
    "arxiv-id": "1106.5928v1", 
    "author": "Gabriel Cristobal", 
    "publish": "2011-06-29T13:12:56Z", 
    "summary": "In this paper we propose a measure of anisotropy as a quality parameter to\nestimate the amount of noise in noisy images. The anisotropy of an image can be\ndetermined through a directional measure, using an appropriate statistical\ndistribution of the information contained in the image. This new measure is\nachieved through a stack filtering paradigm. First, we define a local\ndirectional entropy, based on the distribution of 0's and 1's in the\nneigborhood of every pixel location of each stack level. Then the entropy\nvariation of this directional entropy is used to define an anisotropic measure.\nThe empirical results have shown that this measure can be regarded as an\nexcellent image noise indicator, which is particularly relevant for quality\nassessment of denoising algorithms. The method has been evaluated with\nartificial and real-world degraded images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.0845v4", 
    "title": "Automatic Road Lighting System (ARLS) Model Based on Image Processing of   Moving Object", 
    "arxiv-id": "1107.0845v4", 
    "author": "Sparisoma Viridi", 
    "publish": "2011-07-05T11:06:04Z", 
    "summary": "Using a vehicle toy (in next future called vehicle) as a moving object an\nautomatic road lighting system (ARLS) model is constructed. A digital video\ncamera with 25 fps is used to capture the vehicle motion as it moves in the\ntest segment of the road. Captured images are then processed to calculate\nvehicle speed. This information of the speed together with position of vehicle\nis then used to control the lighting system along the path that passes by the\nvehicle. Length of the road test segment is 1 m, the video camera is positioned\nabout 1.1 m above the test segment, and the vehicle toy dimension is 13 cm\n\\times 9.3 cm. In this model, the maximum speed that ARLS can handle is about\n1.32 m/s, and the highest performance is obtained about 91% at speed 0.93 m/s."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.1058v1", 
    "title": "Online Vehicle Detection For Estimating Traffic Status", 
    "arxiv-id": "1107.1058v1", 
    "author": "Ranch Y. Q. Lai", 
    "publish": "2011-07-06T08:43:38Z", 
    "summary": "We propose a traffic congestion estimation system based on unsupervised\non-line learning algorithm. The system does not rely on background extraction\nor motion detection. It extracts local features inside detection regions of\nvariable size which are drawn on lanes in advance. The extracted features are\nthen clustered into two classes using K-means and Gaussian Mixture Models(GMM).\nA Bayes classifier is used to detect vehicles according to the previous cluster\ninformation which keeps updated whenever system is running by on-line EM\nalgorithm. Experimental result shows that our system can be adapted to various\ntraffic scenes for estimating traffic status."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.1081v1", 
    "title": "Spatial Features for Multi-Font/Multi-Size Kannada Numerals and Vowels   Recognition", 
    "arxiv-id": "1107.1081v1", 
    "author": "Gururaj Mukarambi", 
    "publish": "2011-07-06T10:02:42Z", 
    "summary": "This paper presents multi-font/multi-size Kannada numerals and vowels\nrecognition based on spatial features. Directional spatial features viz stroke\ndensity, stroke length and the number of stokes in an image are employed as\npotential features to characterize the printed Kannada numerals and vowels.\nBased on these features 1100 numerals and 1400 vowels are classified with\nMulti-class Support Vector Machines (SVM). The proposed system achieves the\nrecognition accuracy as 98.45% and 90.64% for numerals and vowels respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.1561v1", 
    "title": "Analysis and Improvement of Low Rank Representation for Subspace   segmentation", 
    "arxiv-id": "1107.1561v1", 
    "author": "Lin Zhouchen", 
    "publish": "2011-07-08T05:44:57Z", 
    "summary": "We analyze and improve low rank representation (LRR), the state-of-the-art\nalgorithm for subspace segmentation of data. We prove that for the noiseless\ncase, the optimization model of LRR has a unique solution, which is the shape\ninteraction matrix (SIM) of the data matrix. So in essence LRR is equivalent to\nfactorization methods. We also prove that the minimum value of the optimization\nmodel of LRR is equal to the rank of the data matrix. For the noisy case, we\nshow that LRR can be approximated as a factorization method that combines noise\nremoval by column sparse robust PCA. We further propose an improved version of\nLRR, called Robust Shape Interaction (RSI), which uses the corrected data as\nthe dictionary instead of the noisy data. RSI is more robust than LRR when the\ncorruption in data is heavy. Experiments on both synthetic and real data\ntestify to the improved robustness of RSI."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2085v1", 
    "title": "Kunchenko's Polynomials for Template Matching", 
    "arxiv-id": "1107.2085v1", 
    "author": "Taras Slipets", 
    "publish": "2011-07-11T18:44:17Z", 
    "summary": "This paper reviews Kunchenko's polynomials using as template matching method\nto recognize template in one-dimensional input signal. Kunchenko's polynomials\nmethod is compared with classical methods - cross-correlation and sum of\nsquared differences according to numerical statistical example."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2336v1", 
    "title": "A Variation of the Box-Counting Algorithm Applied to Colour Images", 
    "arxiv-id": "1107.2336v1", 
    "author": "C. C. Tsouros", 
    "publish": "2011-07-12T16:21:06Z", 
    "summary": "The box counting method for fractal dimension estimation had not been applied\nto large or colour images thus far due to the processing time required. In this\nletter we present a fast, easy to implement and very easily expandable to any\nnumber of dimensions variation, the box merging method. It is applied here in\nRGB images which are considered as sets in 5-D space."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2553v1", 
    "title": "Learning Hypergraph Labeling for Feature Matching", 
    "arxiv-id": "1107.2553v1", 
    "author": "Ahmed Elgammal", 
    "publish": "2011-07-13T14:01:50Z", 
    "summary": "This study poses the feature correspondence problem as a hypergraph node\nlabeling problem. Candidate feature matches and their subsets (usually of size\nlarger than two) are considered to be the nodes and hyperedges of a hypergraph.\nA hypergraph labeling algorithm, which models the subset-wise interaction by an\nundirected graphical model, is applied to label the nodes (feature\ncorrespondences) as correct or incorrect. We describe a method to learn the\ncost function of this labeling algorithm from labeled examples using a\ngraphical model training algorithm. The proposed feature matching algorithm is\ndifferent from the most of the existing learning point matching methods in\nterms of the form of the objective function, the cost function to be learned\nand the optimization method applied to minimize it. The results on standard\ndatasets demonstrate how learning over a hypergraph improves the matching\nperformance over existing algorithms, notably one that also uses higher order\ninformation without learning."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2693v1", 
    "title": "A Fuzzy View on k-Means Based Signal Quantization with Application in   Iris Segmentation", 
    "arxiv-id": "1107.2693v1", 
    "author": "Nicolaie Popescu-Bodorin", 
    "publish": "2011-07-13T22:46:58Z", 
    "summary": "This paper shows that the k-means quantization of a signal can be interpreted\nboth as a crisp indicator function and as a fuzzy membership assignment\ndescribing fuzzy clusters and fuzzy boundaries. Combined crisp and fuzzy\nindicator functions are defined here as natural generalizations of the ordinary\ncrisp and fuzzy indicator functions, respectively. An application to iris\nsegmentation is presented together with a demo program."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SYNASC.2009.45", 
    "link": "http://arxiv.org/pdf/1107.2696v1", 
    "title": "Exploring New Directions in Iris Recognition", 
    "arxiv-id": "1107.2696v1", 
    "author": "Nicolaie Popescu-Bodorin", 
    "publish": "2011-07-13T23:18:57Z", 
    "summary": "A new approach in iris recognition based on Circular Fuzzy Iris Segmentation\n(CFIS) and Gabor Analytic Iris Texture Binary Encoder (GAITBE) is proposed and\ntested here. CFIS procedure is designed to guarantee that similar iris segments\nwill be obtained for similar eye images, despite the fact that the degree of\nocclusion may vary from one image to another. Its result is a circular iris\nring (concentric with the pupil) which approximates the actual iris. GAITBE\nproves better encoding of statistical independence between the iris codes\nextracted from different irides using Hilbert Transform. Irides from University\nof Bath Iris Database are binary encoded on two different lengths (768 / 192\nbytes) and tested in both single-enrollment and multi-enrollment identification\nscenarios. All cases illustrate the capacity of the newly proposed methodology\nto narrow down the distribution of inter-class matching scores, and\nconsequently, to guarantee a steeper descent of the False Accept Rate."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.2723v1", 
    "title": "Topographic Feature Extraction for Bengali and Hindi Character Images", 
    "arxiv-id": "1107.2723v1", 
    "author": "Gaurav Harit", 
    "publish": "2011-07-14T04:05:23Z", 
    "summary": "Feature selection and extraction plays an important role in different\nclassification based problems such as face recognition, signature verification,\noptical character recognition (OCR) etc. The performance of OCR highly depends\non the proper selection and extraction of feature set. In this paper, we\npresent novel features based on the topography of a character as visible from\ndifferent viewing directions on a 2D plane. By topography of a character we\nmean the structural features of the strokes and their spatial relations. In\nthis work we develop topographic features of strokes visible with respect to\nviews from different directions (e.g. North, South, East, and West). We\nconsider three types of topographic features: closed region, convexity of\nstrokes, and straight line strokes. These features are represented as a\nshape-based graph which acts as an invariant feature set for discriminating\nvery similar type characters efficiently. We have tested the proposed method on\nprinted and handwritten Bengali and Hindi character images. Initial results\ndemonstrate the efficacy of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.2781v1", 
    "title": "Face Recognition using Curvelet Transform", 
    "arxiv-id": "1107.2781v1", 
    "author": "Rami Cohen", 
    "publish": "2011-07-14T10:44:01Z", 
    "summary": "Face recognition has been studied extensively for more than 20 years now.\nSince the beginning of 90s the subject has became a major issue. This\ntechnology is used in many important real-world applications, such as video\nsurveillance, smart cards, database security, internet and intranet access.\nThis report reviews recent two algorithms for face recognition which take\nadvantage of a relatively new multiscale geometric analysis tool - Curvelet\ntransform, for facial processing and feature extraction. This transform proves\nto be efficient especially due to its good ability to detect curves and lines,\nwhich characterize the human's face. An algorithm which is based on the two\nalgorithms mentioned above is proposed, and its performance is evaluated on\nthree data bases of faces: AT&T (ORL), Essex Grimace and Georgia-Tech.\nk-nearest neighbour (k-NN) and Support vector machine (SVM) classifiers are\nused, along with Principal Component Analysis (PCA) for dimensionality\nreduction. This algorithm shows good results, and it even outperforms other\nalgorithms in some cases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.3194v1", 
    "title": "Fingerprint recognition using standardized fingerprint model", 
    "arxiv-id": "1107.3194v1", 
    "author": "Ha Nhat Tam", 
    "publish": "2011-07-16T03:04:22Z", 
    "summary": "Fingerprint recognition is one of most popular and accuracy Biometric\ntechnologies. Nowadays, it is used in many real applications. However,\nrecognizing fingerprints in poor quality images is still a very complex\nproblem. In recent years, many algorithms, models...are given to improve the\naccuracy of recognition system. This paper discusses on the standardized\nfingerprint model which is used to synthesize the template of fingerprints. In\nthis model, after pre-processing step, we find the transformation between\ntemplates, adjust parameters, synthesize fingerprint, and reduce noises. Then,\nwe use the final fingerprint to match with others in FVC2004 fingerprint\ndatabase (DB4) to show the capability of the model."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.3195v1", 
    "title": "Facial Expression Classification Based on Multi Artificial Neural   Network and Two Dimensional Principal Component Analysis", 
    "arxiv-id": "1107.3195v1", 
    "author": "Hai Tran", 
    "publish": "2011-07-16T03:15:40Z", 
    "summary": "Facial expression classification is a kind of image classification and it has\nreceived much attention, in recent years. There are many approaches to solve\nthese problems with aiming to increase efficient classification. One of famous\nsuggestions is described as first step, project image to different spaces;\nsecond step, in each of these spaces, images are classified into responsive\nclass and the last step, combine the above classified results into the final\nresult. The advantages of this approach are to reflect fulfill and multiform of\nimage classified. In this paper, we use 2D-PCA and its variants to project the\npattern or image into different spaces with different grouping strategies. Then\nwe develop a model which combines many Neural Networks applied for the last\nstep. This model evaluates the reliability of each space and gives the final\nclassification conclusion. Our model links many Neural Networks together, so we\ncall it Multi Artificial Neural Network (MANN). We apply our proposal model for\n6 basic facial expressions on JAFFE database consisting 213 images posed by 10\nJapanese female models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.3348v2", 
    "title": "Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion   Techniques", 
    "arxiv-id": "1107.3348v2", 
    "author": "Ali A. Al-Zuky", 
    "publish": "2011-07-18T01:41:37Z", 
    "summary": "In remote sensing, image fusion technique is a useful tool used to fuse high\nspatial resolution panchromatic images (PAN) with lower spatial resolution\nmultispectral images (MS) to create a high spatial resolution multispectral of\nimage fusion (F) while preserving the spectral information in the multispectral\nimage (MS).There are many PAN sharpening techniques or Pixel-Based image fusion\ntechniques that have been developed to try to enhance the spatial resolution\nand the spectral property preservation of the MS. This paper attempts to\nundertake the study of image fusion, by using two types of pixel-based image\nfusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods\nof Pixel-Based Image Fusion Techniques. The first type includes Brovey\nTransform (BT), Color Normalized Transformation (CN) and Multiplicative Method\n(MLT). The second type include High-Pass Filter Additive Method (HPFA),\nHigh-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and\nThe Wavelet transform-based fusion method (WT). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including Standard Deviation (SD),\nEntropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR),\nNormalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to\nestimate the quality and degree of information improvement of a fused image\nquantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4396v2", 
    "title": "The IHS Transformations Based Image Fusion", 
    "arxiv-id": "1107.4396v2", 
    "author": "Ali A. Al-Zuky", 
    "publish": "2011-07-19T06:18:56Z", 
    "summary": "The IHS sharpening technique is one of the most commonly used techniques for\nsharpening. Different transformations have been developed to transfer a color\nimage from the RGB space to the IHS space. Through literature, it appears that,\nvarious scientists proposed alternative IHS transformations and many papers\nhave reported good results whereas others show bad ones as will as not those\nobtained which the formula of IHS transformation were used. In addition to\nthat, many papers show different formulas of transformation matrix such as IHS\ntransformation. This leads to confusion what is the exact formula of the IHS\ntransformation?. Therefore, the main purpose of this work is to explore\ndifferent IHS transformation techniques and experiment it as IHS based image\nfusion. The image fusion performance was evaluated, in this study, using\nvarious methods to estimate the quality and degree of information improvement\nof a fused image quantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4667v2", 
    "title": "Correlation Estimation from Compressed Images", 
    "arxiv-id": "1107.4667v2", 
    "author": "Pascal Frossard", 
    "publish": "2011-07-23T08:51:17Z", 
    "summary": "This paper addresses the problem of correlation estimation in sets of\ncompressed images. We consider a framework where images are represented under\nthe form of linear measurements due to low complexity sensing or security\nrequirements. We assume that the images are correlated through the displacement\nof visual objects due to motion or viewpoint change and the correlation is\neffectively represented by optical flow or motion field models. The correlation\nis estimated in the compressed domain by jointly processing the linear\nmeasurements. We first show that the correlated images can be efficiently\nrelated using a linear operator. Using this linear relationship we then\ndescribe the dependencies between images in the compressed domain. We further\ncast a regularized optimization problem where the correlation is estimated in\norder to satisfy both data consistency and motion smoothness objectives with a\nGraph Cut algorithm. We analyze in detail the correlation estimation\nperformance and quantify the penalty due to image compression. Extensive\nexperiments in stereo and video imaging applications show that our novel\nsolution stays competitive with methods that implement complex image\nreconstruction steps prior to correlation estimation. We finally use the\nestimated correlation in a novel joint image reconstruction scheme that is\nbased on an optimization problem with sparsity priors on the reconstructed\nimages. Additional experiments show that our correlation estimation algorithm\nleads to an effective reconstruction of pairs of images in distributed image\ncoding schemes that outperform independent reconstruction algorithms by 2 to 4\ndB."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4763v1", 
    "title": "Diffeomorphic Metric Mapping of High Angular Resolution Diffusion   Imaging based on Riemannian Structure of Orientation Distribution Functions", 
    "arxiv-id": "1107.4763v1", 
    "author": "Anqi Qiu", 
    "publish": "2011-07-24T15:34:27Z", 
    "summary": "In this paper, we propose a novel large deformation diffeomorphic\nregistration algorithm to align high angular resolution diffusion images\n(HARDI) characterized by orientation distribution functions (ODFs). Our\nproposed algorithm seeks an optimal diffeomorphism of large deformation between\ntwo ODF fields in a spatial volume domain and at the same time, locally\nreorients an ODF in a manner such that it remains consistent with the\nsurrounding anatomical structure. To this end, we first review the Riemannian\nmanifold of ODFs. We then define the reorientation of an ODF when an affine\ntransformation is applied and subsequently, define the diffeomorphic group\naction to be applied on the ODF based on this reorientation. We incorporate the\nRiemannian metric of ODFs for quantifying the similarity of two HARDI images\ninto a variational problem defined under the large deformation diffeomorphic\nmetric mapping (LDDMM) framework. We finally derive the gradient of the cost\nfunction in both Riemannian spaces of diffeomorphisms and the ODFs, and present\nits numerical implementation. Both synthetic and real brain HARDI data are used\nto illustrate the performance of our registration algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4958v1", 
    "title": "Efficient and Accurate Gaussian Image Filtering Using Running Sums", 
    "arxiv-id": "1107.4958v1", 
    "author": "Michael Werman", 
    "publish": "2011-07-25T14:20:34Z", 
    "summary": "This paper presents a simple and efficient method to convolve an image with a\nGaussian kernel. The computation is performed in a constant number of\noperations per pixel using running sums along the image rows and columns. We\ninvestigate the error function used for kernel approximation and its relation\nto the properties of the input signal. Based on natural image statistics we\npropose a quadratic form kernel error function so that the output image l2\nerror is minimized. We apply the proposed approach to approximate the Gaussian\nkernel by linear combination of constant functions. This results in very\nefficient Gaussian filtering method. Our experiments show that the proposed\ntechnique is faster than state of the art methods while preserving a similar\naccuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.5850v2", 
    "title": "Confidence-Based Dynamic Classifier Combination For Mean-Shift Tracking", 
    "arxiv-id": "1107.5850v2", 
    "author": "Hakan Erdogan", 
    "publish": "2011-07-29T01:08:52Z", 
    "summary": "We introduce a novel tracking technique which uses dynamic confidence-based\nfusion of two different information sources for robust and efficient tracking\nof visual objects. Mean-shift tracking is a popular and well known method used\nin object tracking problems. Originally, the algorithm uses a similarity\nmeasure which is optimized by shifting a search area to the center of a\ngenerated weight image to track objects. Recent improvements on the original\nmean-shift algorithm involves using a classifier that differentiates the object\nfrom its surroundings. We adopt this classifier-based approach and propose an\napplication of a classifier fusion technique within this classifier-based\ncontext in this work. We use two different classifiers, where one comes from a\nbackground modeling method, to generate the weight image and we calculate\ncontributions of the classifiers dynamically using their confidences to\ngenerate a final weight image to be used in tracking. The contributions of the\nclassifiers are calculated by using correlations between histograms of their\nweight images and histogram of a defined ideal weight image in the previous\nframe. We show with experiments that our dynamic combination scheme selects\ngood contributions for classifiers for different cases and improves tracking\naccuracy significantly."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1108.1122v1", 
    "title": "Leveraging Billions of Faces to Overcome Performance Barriers in   Unconstrained Face Recognition", 
    "arxiv-id": "1108.1122v1", 
    "author": "Lior Wolf", 
    "publish": "2011-08-04T15:51:19Z", 
    "summary": "We employ the face recognition technology developed in house at face.com to a\nwell accepted benchmark and show that without any tuning we are able to\nconsiderably surpass state of the art results. Much of the improvement is\nconcentrated in the high-valued performance point of zero false positive\nmatches, where the obtained recall rate almost doubles the best reported result\nto date. We discuss the various components and innovations of our system that\nenable this significant performance gap. These components include extensive\nutilization of an accurate 3D reconstructed shape model dealing with challenges\narising from pose and illumination. In addition, discriminative models based on\nbillions of faces are used in order to overcome aging and facial expression as\nwell as low light and overexposure. Finally, we identify a challenging set of\nidentification queries that might provide useful focus for future research."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1108.1169v1", 
    "title": "Learning Representations by Maximizing Compression", 
    "arxiv-id": "1108.1169v1", 
    "author": "Yann LeCun", 
    "publish": "2011-08-04T19:00:14Z", 
    "summary": "We give an algorithm that learns a representation of data through\ncompression. The algorithm 1) predicts bits sequentially from those previously\nseen and 2) has a structure and a number of computations similar to an\nautoencoder. The likelihood under the model can be calculated exactly, and\narithmetic coding can be used directly for compression. When training on digits\nthe algorithm learns filters similar to those of restricted boltzman machines\nand denoising autoencoders. Independent samples can be drawn from the model by\na single sweep through the pixels. The algorithm has a good compression\nperformance when compared to other methods that work under random ordering of\npixels."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1108.1353v1", 
    "title": "Real time face recognition using adaboost improved fast PCA algorithm", 
    "arxiv-id": "1108.1353v1", 
    "author": "R C Tripathi", 
    "publish": "2011-08-05T15:41:31Z", 
    "summary": "This paper presents an automated system for human face recognition in a real\ntime background world for a large homemade dataset of persons face. The task is\nvery difficult as the real time background subtraction in an image is still a\nchallenge. Addition to this there is a huge variation in human face image in\nterms of size, pose and expression. The system proposed collapses most of this\nvariance. To detect real time human face AdaBoost with Haar cascade is used and\na simple fast PCA and LDA is used to recognize the faces detected. The matched\nface is then used to mark attendance in the laboratory, in our case. This\nbiometric system is a real time attendance system based on the human face\nrecognition with a simple and fast algorithms and gaining a high accuracy\nrate.."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2191780", 
    "link": "http://arxiv.org/pdf/1108.2632v1", 
    "title": "Compressive Imaging using Approximate Message Passing and a Markov-Tree   Prior", 
    "arxiv-id": "1108.2632v1", 
    "author": "Philip Schniter", 
    "publish": "2011-08-12T14:41:49Z", 
    "summary": "We propose a novel algorithm for compressive imaging that exploits both the\nsparsity and persistence across scales found in the 2D wavelet transform\ncoefficients of natural images. Like other recent works, we model wavelet\nstructure using a hidden Markov tree (HMT) but, unlike other works, ours is\nbased on loopy belief propagation (LBP). For LBP, we adopt a recently proposed\n\"turbo\" message passing schedule that alternates between exploitation of HMT\nstructure and exploitation of compressive-measurement structure. For the\nlatter, we leverage Donoho, Maleki, and Montanari's recently proposed\napproximate message passing (AMP) algorithm. Experiments with a large image\ndatabase suggest that, relative to existing schemes, our turbo LBP approach\nyields state-of-the-art reconstruction performance with substantial reduction\nin complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2191780", 
    "link": "http://arxiv.org/pdf/1108.3250v1", 
    "title": "The Statistical methods of Pixel-Based Image Fusion Techniques", 
    "arxiv-id": "1108.3250v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2011-08-12T16:51:21Z", 
    "summary": "There are many image fusion methods that can be used to produce\nhigh-resolution mutlispectral images from a high-resolution panchromatic (PAN)\nimage and low-resolution multispectral (MS) of remote sensed images. This paper\nattempts to undertake the study of image fusion techniques with different\nStatistical techniques for image fusion as Local Mean Matching (LMM), Local\nMean and Variance Matching (LMVM), Regression variable substitution (RVS),\nLocal Correlation Modeling (LCM) and they are compared with one another so as\nto choose the best technique, that can be applied on multi-resolution satellite\nimages. This paper also devotes to concentrate on the analytical techniques for\nevaluating the quality of image fusion (F) by using various methods including\nStandard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to\nNoise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation\nIndex (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2191780", 
    "link": "http://arxiv.org/pdf/1108.3251v1", 
    "title": "Advanced phase retrieval: maximum likelihood technique with sparse   regularization of phase and amplitude", 
    "arxiv-id": "1108.3251v1", 
    "author": "Jaakko Astola", 
    "publish": "2011-08-15T09:37:15Z", 
    "summary": "Sparse modeling is one of the efficient techniques for imaging that allows\nrecovering lost information. In this paper, we present a novel iterative\nphase-retrieval algorithm using a sparse representation of the object amplitude\nand phase. The algorithm is derived in terms of a constrained maximum\nlikelihood, where the wave field reconstruction is performed using a number of\nnoisy intensity-only observations with a zero-mean additive Gaussian noise. The\ndeveloped algorithm enables the optimal solution for the object wave field\nreconstruction. Our goal is an improvement of the reconstruction quality with\nrespect to the conventional algorithms. Sparse regularization results in\nadvanced reconstruction accuracy, and numerical simulations demonstrate\nsignificant enhancement of imaging."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2012.262", 
    "link": "http://arxiv.org/pdf/1108.3605v2", 
    "title": "Hierarchical Object Parsing from Structured Noisy Point Clouds", 
    "arxiv-id": "1108.3605v2", 
    "author": "Adrian Barbu", 
    "publish": "2011-08-18T02:11:34Z", 
    "summary": "Object parsing and segmentation from point clouds are challenging tasks\nbecause the relevant data is available only as thin structures along object\nboundaries or other features, and is corrupted by large amounts of noise. To\nhandle this kind of data, flexible shape models are desired that can accurately\nfollow the object boundaries. Popular models such as Active Shape and Active\nAppearance models lack the necessary flexibility for this task, while recent\napproaches such as the Recursive Compositional Models make model\nsimplifications in order to obtain computational guarantees. This paper\ninvestigates a hierarchical Bayesian model of shape and appearance in a\ngenerative setting. The input data is explained by an object parsing layer,\nwhich is a deformation of a hidden PCA shape model with Gaussian prior. The\npaper also introduces a novel efficient inference algorithm that uses informed\ndata-driven proposals to initialize local searches for the hidden variables.\nApplied to the problem of object parsing from structured point clouds such as\nedge detection images, the proposed approach obtains state of the art parsing\nerrors on two standard datasets without using any intensity information."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2012.262", 
    "link": "http://arxiv.org/pdf/1108.4098v1", 
    "title": "Multisensor Images Fusion Based on Feature-Level", 
    "arxiv-id": "1108.4098v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2011-08-20T07:43:46Z", 
    "summary": "Until now, of highest relevance for remote sensing data processing and\nanalysis have been techniques for pixel level image fusion. So, This paper\nattempts to undertake the study of Feature-Level based image fusion. For this\npurpose, feature based fusion techniques, which are usually based on empirical\nor heuristic rules, are employed. Hence, in this paper we consider feature\nextraction (FE) for fusion. It aims at finding a transformation of the original\nspace that would produce such new features, which preserve or improve as much\nas possible. This study introduces three different types of Image fusion\ntechniques including Principal Component Analysis based Feature Fusion (PCA),\nSegment Fusion (SF) and Edge fusion (EF). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including (SD), (En), (CC), (SNR), (NRMSE)\nand (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.1179/1743131X11Y.0000000013", 
    "link": "http://arxiv.org/pdf/1108.4315v1", 
    "title": "Edge detection based on morphological amoebas", 
    "arxiv-id": "1108.4315v1", 
    "author": "Dong Hoon Lim", 
    "publish": "2011-08-22T13:49:57Z", 
    "summary": "Detecting the edges of objects within images is critical for quality image\nprocessing. We present an edge-detecting technique that uses morphological\namoebas that adjust their shape based on variation in image contours. We\nevaluate the method both quantitatively and qualitatively for edge detection of\nimages, and compare it to classic morphological methods. Our amoeba-based\nedge-detection system performed better than the classic edge detectors."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1108.6294v1", 
    "title": "Biometric Authorization System using Gait Biometry", 
    "arxiv-id": "1108.6294v1", 
    "author": "Dr. R Bhavani", 
    "publish": "2011-08-31T17:22:51Z", 
    "summary": "Human gait, which is a new biometric aimed to recognize individuals by the\nway they walk have come to play an increasingly important role in visual\nsurveillance applications. In this paper a novel hybrid holistic approach is\nproposed to show how behavioural walking characteristics can be used to\nrecognize unauthorized and suspicious persons when they enter a surveillance\narea. Initially background is modelled from the input video captured from\ncameras deployed for security and the foreground moving object in the\nindividual frames are segmented using the background subtraction algorithm.\nThen gait representing spatial, temporal and wavelet components are extracted\nand fused for training and testing multi class support vector machine models\n(SVM). The proposed system is evaluated using side view videos of NLPR\ndatabase. The experimental results demonstrate that the proposed system\nachieves a pleasing recognition rate and also the results indicate that the\nclassification ability of SVM with Radial Basis Function (RBF) is better than\nwith other kernel functions."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.0264v1", 
    "title": "Face Recognition using Optimal Representation Ensemble", 
    "arxiv-id": "1110.0264v1", 
    "author": "Yongsheng Gao", 
    "publish": "2011-10-03T04:44:47Z", 
    "summary": "Recently, the face recognizers based on linear representations have been\nshown to deliver state-of-the-art performance. In real-world applications,\nhowever, face images usually suffer from expressions, disguises and random\nocclusions. The problematic facial parts undermine the validity of the\nlinear-subspace assumption and thus the recognition performance deteriorates\nsignificantly. In this work, we address the problem in a\nlearning-inference-mixed fashion. By observing that the linear-subspace\nassumption is more reliable on certain face patches rather than on the holistic\nface, some Bayesian Patch Representations (BPRs) are randomly generated and\ninterpreted according to the Bayes' theory. We then train an ensemble model\nover the patch-representations by minimizing the empirical risk w.r.t the\n\"leave-one-out margins\". The obtained model is termed Optimal Representation\nEnsemble (ORE), since it guarantees the optimality from the perspective of\nEmpirical Risk Minimization. To handle the unknown patterns in test faces, a\nrobust version of BPR is proposed by taking the non-face category into\nconsideration. Equipped with the Robust-BPRs, the inference ability of ORE is\nincreased dramatically and several record-breaking accuracies (99.9% on Yale-B\nand 99.5% on AR) and desirable efficiencies (below 20 ms per face in Matlab)\nare achieved. It also overwhelms other modular heuristics on the faces with\nrandom occlusions, extreme expressions and disguises. Furthermore, to\naccommodate immense BPRs sets, a boosting-like algorithm is also derived. The\nboosted model, a.k.a Boosted-ORE, obtains similar performance to its prototype.\nBesides the empirical superiorities, two desirable features of the proposed\nmethods, namely, the training-determined model-selection and the\ndata-weight-free boosting procedure, are also theoretically verified."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.0585v1", 
    "title": "Discriminately Decreasing Discriminability with Learned Image Filters", 
    "arxiv-id": "1110.0585v1", 
    "author": "Javier Movellan", 
    "publish": "2011-10-04T06:48:29Z", 
    "summary": "In machine learning and computer vision, input images are often filtered to\nincrease data discriminability. In some situations, however, one may wish to\npurposely decrease discriminability of one classification task (a \"distractor\"\ntask), while simultaneously preserving information relevant to another (the\ntask-of-interest): For example, it may be important to mask the identity of\npersons contained in face images before submitting them to a crowdsourcing site\n(e.g., Mechanical Turk) when labeling them for certain facial attributes.\nAnother example is inter-dataset generalization: when training on a dataset\nwith a particular covariance structure among multiple attributes, it may be\nuseful to suppress one attribute while preserving another so that a trained\nclassifier does not learn spurious correlations between attributes. In this\npaper we present an algorithm that finds optimal filters to give high\ndiscriminability to one task while simultaneously giving low discriminability\nto a distractor task. We present results showing the effectiveness of the\nproposed technique on both simulated data and natural face images."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.0872v1", 
    "title": "Non-Gaussian Scale Space Filtering with 2 by 2 Matrix of Linear Filters", 
    "arxiv-id": "1110.0872v1", 
    "author": "Toshiro Kubota", 
    "publish": "2011-10-04T23:58:55Z", 
    "summary": "Construction of a scale space with a convolution filter has been studied\nextensively in the past. It has been proven that the only convolution kernel\nthat satisfies the scale space requirements is a Gaussian type. In this paper,\nwe consider a matrix of convolution filters introduced in [1] as a building\nkernel for a scale space, and shows that we can construct a non-Gaussian scale\nspace with a $2\\times 2$ matrix of filters. The paper derives sufficient\nconditions for the matrix of filters for being a scale space kernel, and\npresent some numerical demonstrations."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.1485v1", 
    "title": "A Face Recognition Scheme using Wavelet Based Dominant Features", 
    "arxiv-id": "1110.1485v1", 
    "author": "Shaikh Anowarul Fattah", 
    "publish": "2011-10-07T11:16:17Z", 
    "summary": "In this paper, a multi-resolution feature extraction algorithm for face\nrecognition is proposed based on two-dimensional discrete wavelet transform\n(2D-DWT), which efficiently exploits the local spatial variations in a face\nimage. For the purpose of feature extraction, instead of considering the entire\nface image, an entropy-based local band selection criterion is developed, which\nselects high-informative horizontal segments from the face image. In order to\ncapture the local spatial variations within these highinformative horizontal\nbands precisely, the horizontal band is segmented into several small spatial\nmodules. Dominant wavelet coefficients corresponding to each local region\nresiding inside those horizontal bands are selected as features. In the\nselection of the dominant coefficients, a threshold criterion is proposed,\nwhich not only drastically reduces the feature dimension but also provides high\nwithin-class compactness and high between-class separability. A principal\ncomponent analysis is performed to further reduce the dimensionality of the\nfeature space. Extensive experimentation is carried out upon standard face\ndatabases and a very high degree of recognition accuracy is achieved by the\nproposed method in comparison to those obtained by some of the existing\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3318", 
    "link": "http://arxiv.org/pdf/1110.1509v1", 
    "title": "A Comparative Experiment of Several Shape Methods in Recognizing Plants", 
    "arxiv-id": "1110.1509v1", 
    "author": "P. I. Santosa", 
    "publish": "2011-10-07T12:43:38Z", 
    "summary": "Shape is an important aspects in recognizing plants. Several approaches have\nbeen introduced to identify objects, including plants. Combination of geometric\nfeatures such as aspect ratio, compactness, and dispersion, or moments such as\nmoment invariants were usually used toidentify plants. In this research, a\ncomparative experiment of 4 methods to identify plants using shape features was\naccomplished. Two approaches have never been used in plants identification yet,\nZernike moments and Polar Fourier Transform (PFT), were incorporated. The\nexperimental comparison was done on 52 kinds of plants with various shapes. The\nresult, PFT gave best performance with 64% in accuracy and outperformed the\nother methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2301", 
    "link": "http://arxiv.org/pdf/1110.1513v1", 
    "title": "Foliage Plant Retrieval using Polar Fourier Transform, Color Moments and   Vein Features", 
    "arxiv-id": "1110.1513v1", 
    "author": "Paulus Insap Santosa", 
    "publish": "2011-10-07T13:00:03Z", 
    "summary": "This paper proposed a method that combines Polar Fourier Transform, color\nmoments, and vein features to retrieve leaf images based on a leaf image. The\nmethod is very useful to help people in recognizing foliage plants. Foliage\nplants are plants that have various colors and unique patterns in the leaf.\nTherefore, the colors and its patterns are information that should be counted\non in the processing of plant identification. To compare the performance of\nretrieving system to other result, the experiments used Flavia dataset, which\nis very popular in recognizing plants. The result shows that the method gave\nbetter performance than PNN, SVM, and Fourier Transform. The method was also\ntested using foliage plants with various colors. The accuracy was 90.80% for 50\nkinds of plants."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2301", 
    "link": "http://arxiv.org/pdf/1110.2053v3", 
    "title": "Steps Towards a Theory of Visual Information: Active Perception,   Signal-to-Symbol Conversion and the Interplay Between Sensing and Control", 
    "arxiv-id": "1110.2053v3", 
    "author": "Stefano Soatto", 
    "publish": "2011-10-10T14:28:41Z", 
    "summary": "This manuscript describes the elements of a theory of information tailored to\ncontrol and decision tasks and specifically to visual data. The concept of\nActionable Information is described, that relates to a notion of information\nchampioned by J. Gibson, and a notion of \"complete information\" that relates to\nthe minimal sufficient statistics of a complete representation. It is shown\nthat the \"actionable information gap\" between the two can be reduced by\nexercising control on the sensing process. Thus, senging, control and\ninformation are inextricably tied. This has consequences in the so-called\n\"signal-to-symbol barrier\" problem, as well as in the analysis and design of\nactive sensing systems. It has ramifications in vision-based control,\nnavigation, 3-D reconstruction and rendering, as well as detection,\nlocalization, recognition and categorization of objects and scenes in live\nvideo.\n  This manuscript has been developed from a set of lecture notes for a summer\ncourse at the First International Computer Vision Summer School (ICVSS) in\nScicli, Italy, in July of 2008. They were later expanded and amended for\nsubsequent lectures in the same School in July 2009. Starting on November 1,\n2009, they were further expanded for a special topics course, CS269, taught at\nUCLA in the Spring term of 2010."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.2210v1", 
    "title": "Closed-Loop Learning of Visual Control Policies", 
    "arxiv-id": "1110.2210v1", 
    "author": "J. H. Piater", 
    "publish": "2011-10-10T21:56:36Z", 
    "summary": "In this paper we present a general, flexible framework for learning mappings\nfrom images to actions by interacting with the environment. The basic idea is\nto introduce a feature-based image classifier in front of a reinforcement\nlearning algorithm. The classifier partitions the visual space according to the\npresence or absence of few highly informative local descriptors that are\nincrementally selected in a sequence of attempts to remove perceptual aliasing.\nWe also address the problem of fighting overfitting in such a greedy algorithm.\nFinally, we show how high-level visual features can be generated when the power\nof local descriptors is insufficient for completely disambiguating the aliased\nstates. This is done by building a hierarchy of composite features that consist\nof recursive spatial combinations of visual features. We demonstrate the\nefficacy of our algorithms by solving three visual navigation tasks and a\nvisual version of the classical Car on the Hill control problem."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.3194v1", 
    "title": "Controlled Total Variation regularization for inverse problems", 
    "arxiv-id": "1110.3194v1", 
    "author": "Quansheng Liu", 
    "publish": "2011-10-14T13:02:36Z", 
    "summary": "This paper provides a new algorithm for solving inverse problems, based on\nthe minimization of the $L^2$ norm and on the control of the Total Variation.\nIt consists in relaxing the role of the Total Variation in the classical Total\nVariation minimization approach, which permits us to get better approximation\nto the inverse problems. The numerical results on the deconvolution problem\nshow that our method outperforms some previous ones."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.4970v1", 
    "title": "Studying Satellite Image Quality Based on the Fusion Techniques", 
    "arxiv-id": "1110.4970v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2011-10-22T13:26:00Z", 
    "summary": "Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. However,\nthe jury is still out on the benefits of a fused image compared to its original\nimages. There is also a lack of measures for assessing the objective quality of\nthe spatial resolution for the fusion methods. Therefore, an objective quality\nof the spatial resolution assessment for fusion images is required. So, this\nstudy attempts to develop a new qualitative assessment to evaluate the spatial\nquality of the pan sharpened images by many spatial quality metrics. Also, this\npaper deals with a comparison of various image fusion techniques based on pixel\nand feature fusion techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.5404v1", 
    "title": "Face Recognition Based on SVM and 2DPCA", 
    "arxiv-id": "1110.5404v1", 
    "author": "Len Bui", 
    "publish": "2011-10-25T03:54:51Z", 
    "summary": "The paper will present a novel approach for solving face recognition problem.\nOur method combines 2D Principal Component Analysis (2DPCA), one of the\nprominent methods for extracting feature vectors, and Support Vector Machine\n(SVM), the most powerful discriminative method for classification. Experiments\nbased on proposed method have been conducted on two public data sets FERET and\nAT&T; the results show that the proposed method could improve the\nclassification rates."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.5450v1", 
    "title": "Hand Tracking based on Hierarchical Clustering of Range Data", 
    "arxiv-id": "1110.5450v1", 
    "author": "Marvin Lindner", 
    "publish": "2011-10-25T09:24:25Z", 
    "summary": "Fast and robust hand segmentation and tracking is an essential basis for\ngesture recognition and thus an important component for contact-less\nhuman-computer interaction (HCI). Hand gesture recognition based on 2D video\ndata has been intensively investigated. However, in practical scenarios purely\nintensity based approaches suffer from uncontrollable environmental conditions\nlike cluttered background colors. In this paper we present a real-time hand\nsegmentation and tracking algorithm using Time-of-Flight (ToF) range cameras\nand intensity data. The intensity and range information is fused into one pixel\nvalue, representing its combined intensity-depth homogeneity. The scene is\nhierarchically clustered using a GPU based parallel merging algorithm, allowing\na robust identification of both hands even for inhomogeneous backgrounds. After\nthe detection, both hands are tracked on the CPU. Our tracking algorithm can\ncope with the situation that one hand is temporarily covered by the other hand."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.5945v1", 
    "title": "A New Similarity Measure for Non-Local Means Filtering of MRI Images", 
    "arxiv-id": "1110.5945v1", 
    "author": "Oleg V. Michailovich", 
    "publish": "2011-10-26T23:14:57Z", 
    "summary": "The acquisition of MRI images offers a trade-off in terms of acquisition\ntime, spatial/temporal resolution and signal-to-noise ratio (SNR). Thus, for\ninstance, increasing the time efficiency of MRI often comes at the expense of\nreduced SNR. This, in turn, necessitates the use of post-processing tools for\nnoise rejection, which makes image de-noising an indispensable component of\ncomputer assistance diagnosis. In the field of MRI, a multitude of image\nde-noising methods have been proposed hitherto. In this paper, the application\nof a particular class of de-noising algorithms - known as non-local mean (NLM)\nfilters - is investigated. Such filters have been recently applied for MRI data\nenhancement and they have been shown to provide more accurate results as\ncompared to many alternative de-noising algorithms. Unfortunately, virtually\nall existing methods for NLM filtering have been derived under the assumption\nof additive white Gaussian (AWG) noise contamination. Since this assumption is\nknown to fail at low values of SNR, an alternative formulation of NLM filtering\nis required, which would take into consideration the correct Rician statistics\nof MRI noise. Accordingly, the contribution of the present paper is two-fold.\nFirst, it points out some principal disadvantages of the earlier methods of NLM\nfiltering of MRI images and suggests means to rectify them. Second, the paper\nintroduces a new similarity measure for NLM filtering of MRI Images, which is\nderived under bona fide statistical assumptions and results in more accurate\nreconstruction of MR scans as compared to alternative NLM approaches. Finally,\nthe utility and viability of the proposed method is demonstrated through a\nseries of numerical experiments using both in silico and in vivo MRI data."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1111.0885v1", 
    "title": "Graph Regularized Nonnegative Matrix Factorization for Hyperspectral   Data Unmixing", 
    "arxiv-id": "1111.0885v1", 
    "author": "Hassan Ghassemian", 
    "publish": "2011-11-03T15:46:47Z", 
    "summary": "Spectral unmixing is an important tool in hyperspectral data analysis for\nestimating endmembers and abundance fractions in a mixed pixel. This paper\nexamines the applicability of a recently developed algorithm called graph\nregularized nonnegative matrix factorization (GNMF) for this aim. The proposed\napproach exploits the intrinsic geometrical structure of the data besides\nconsidering positivity and full additivity constraints. Simulated data based on\nthe measured spectral signatures, is used for evaluating the proposed\nalgorithm. Results in terms of abundance angle distance (AAD) and spectral\nangle distance (SAD) show that this method can effectively unmix hyperspectral\ndata."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1111.1014v1", 
    "title": "Sparsity and Robustness in Face Recognition", 
    "arxiv-id": "1111.1014v1", 
    "author": "Yi Ma", 
    "publish": "2011-11-03T23:50:36Z", 
    "summary": "This report concerns the use of techniques for sparse signal representation\nand sparse error correction for automatic face recognition. Much of the recent\ninterest in these techniques comes from the paper \"Robust Face Recognition via\nSparse Representation\" by Wright et al. (2009), which showed how, under certain\ntechnical conditions, one could cast the face recognition problem as one of\nseeking a sparse representation of a given input face image in terms of a\n\"dictionary\" of training images and images of individual pixels. In this\nreport, we have attempted to clarify some frequently encountered questions\nabout this work and particularly, on the validity of using sparse\nrepresentation techniques for face recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1111.1090v1", 
    "title": "A robust, low-cost approach to Face Detection and Face Recognition", 
    "arxiv-id": "1111.1090v1", 
    "author": "M. Mani Roja", 
    "publish": "2011-11-04T10:36:43Z", 
    "summary": "In the domain of Biometrics, recognition systems based on iris, fingerprint\nor palm print scans etc. are often considered more dependable due to extremely\nlow variance in the properties of these entities with respect to time. However,\nover the last decade data processing capability of computers has increased\nmanifold, which has made real-time video content analysis possible. This shows\nthat the need of the hour is a robust and highly automated Face Detection and\nRecognition algorithm with credible accuracy rate. The proposed Face Detection\nand Recognition system using Discrete Wavelet Transform (DWT) accepts face\nframes as input from a database containing images from low cost devices such as\nVGA cameras, webcams or even CCTV's, where image quality is inferior. Face\nregion is then detected using properties of L*a*b* color space and only Frontal\nFace is extracted such that all additional background is eliminated. Further,\nthis extracted image is converted to grayscale and its dimensions are resized\nto 128 x 128 pixels. DWT is then applied to entire image to obtain the\ncoefficients. Recognition is carried out by comparison of the DWT coefficients\nbelonging to the test image with those of the registered reference image. On\ncomparison, Euclidean distance classifier is deployed to validate the test\nimage from the database. Accuracy for various levels of DWT Decomposition is\nobtained and hence, compared."
},{
    "category": "cs.CV", 
    "doi": "10.2478/s13540-012-0024-1", 
    "link": "http://arxiv.org/pdf/1111.1311v1", 
    "title": "Covariant fractional extension of the modified Laplace-operator used in   3D-shape recovery", 
    "arxiv-id": "1111.1311v1", 
    "author": "Richard Herrmann", 
    "publish": "2011-11-05T14:09:05Z", 
    "summary": "Extending the Liouville-Caputo definition of a fractional derivative to a\nnonlocal covariant generalization of arbitrary bound operators acting on\nmultidimensional Riemannian spaces an appropriate approach for the 3D shape\nrecovery of aperture afflicted 2D slide sequences is proposed. We demonstrate,\nthat the step from a local to a nonlocal algorithm yields an order of magnitude\nin accuracy and by using the specific fractional approach an additional factor\n2 in accuracy of the derived results."
},{
    "category": "cs.CV", 
    "doi": "10.2478/s13540-012-0024-1", 
    "link": "http://arxiv.org/pdf/1111.1461v1", 
    "title": "Multimodal diff-hash", 
    "arxiv-id": "1111.1461v1", 
    "author": "Michael M. Bronstein", 
    "publish": "2011-11-07T00:28:37Z", 
    "summary": "Many applications require comparing multimodal data with different structure\nand dimensionality that cannot be compared directly. Recently, there has been\nincreasing interest in methods for learning and efficiently representing such\nmultimodal similarity. In this paper, we present a simple algorithm for\nmultimodal similarity-preserving hashing, trying to map multimodal data into\nthe Hamming space while preserving the intra- and inter-modal similarities. We\nshow that our method significantly outperforms the state-of-the-art method in\nthe field."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3506", 
    "link": "http://arxiv.org/pdf/1111.1562v1", 
    "title": "Iris Recognition Based on LBP and Combined LVQ Classifier", 
    "arxiv-id": "1111.1562v1", 
    "author": "R. M. El-Awady", 
    "publish": "2011-11-07T12:35:29Z", 
    "summary": "Iris recognition is considered as one of the best biometric methods used for\nhuman identification and verification, this is because of its unique features\nthat differ from one person to another, and its importance in the security\nfield. This paper proposes an algorithm for iris recognition and classification\nusing a system based on Local Binary Pattern and histogram properties as a\nstatistical approaches for feature extraction, and Combined Learning Vector\nQuantization Classifier as Neural Network approach for classification, in order\nto build a hybrid model depends on both features. The localization and\nsegmentation techniques are presented using both Canny edge detection and Hough\nCircular Transform in order to isolate an iris from the whole eye image and for\nnoise detection .Feature vectors results from LBP is applied to a Combined LVQ\nclassifier with different classes to determine the minimum acceptable\nperformance, and the result is based on majority voting among several LVQ\nclassifier. Different iris datasets CASIA, MMU1, MMU2, and LEI with different\nextensions and size are presented. Since LBP is working on a grayscale level so\ncolored iris images should be transformed into a grayscale level. The proposed\nsystem gives a high recognition rate 99.87 % on different iris datasets\ncompared with other methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3506", 
    "link": "http://arxiv.org/pdf/1111.1599v1", 
    "title": "Efficient Hierarchical Markov Random Fields for Object Detection on a   Mobile Robot", 
    "arxiv-id": "1111.1599v1", 
    "author": "Jason J. Corso", 
    "publish": "2011-11-07T14:46:16Z", 
    "summary": "Object detection and classification using video is necessary for intelligent\nplanning and navigation on a mobile robot. However, current methods can be too\nslow or not sufficient for distinguishing multiple classes. Techniques that\nrely on binary (foreground/background) labels incorrectly identify areas with\nmultiple overlapping objects as single segment. We propose two Hierarchical\nMarkov Random Field models in efforts to distinguish connected objects using\ntiered, binary label sets. Near-realtime performance has been achieved using\nefficient optimization methods which runs up to 11 frames per second on a dual\ncore 2.2 Ghz processor. Evaluation of both models is done using footage taken\nfrom a robot obstacle course at the 2010 Intelligent Ground Vehicle\nCompetition."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.1752v1", 
    "title": "New Method for 3D Shape Retrieval", 
    "arxiv-id": "1111.1752v1", 
    "author": "Omar El Beqqali", 
    "publish": "2011-11-07T21:24:36Z", 
    "summary": "The recent technological progress in acquisition, modeling and processing of\n3D data leads to the proliferation of a large number of 3D objects databases.\nConsequently, the techniques used for content based 3D retrieval has become\nnecessary. In this paper, we introduce a new method for 3D objects recognition\nand retrieval by using a set of binary images CLI (Characteristic level\nimages). We propose a 3D indexing and search approach based on the similarity\nbetween characteristic level images using Hu moments for it indexing. To\nmeasure the similarity between 3D objects we compute the Hausdorff distance\nbetween a vectors descriptor. The performance of this new approach is evaluated\nat set of 3D object of well known database, is NTU (National Taiwan University)\ndatabase."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.1947v1", 
    "title": "Discriminative Local Sparse Representations for Robust Face Recognition", 
    "arxiv-id": "1111.1947v1", 
    "author": "Trac D. Tran", 
    "publish": "2011-11-08T16:04:58Z", 
    "summary": "A key recent advance in face recognition models a test face image as a sparse\nlinear combination of a set of training face images. The resulting sparse\nrepresentations have been shown to possess robustness against a variety of\ndistortions like random pixel corruption, occlusion and disguise. This approach\nhowever makes the restrictive (in many scenarios) assumption that test faces\nmust be perfectly aligned (or registered) to the training data prior to\nclassification. In this paper, we propose a simple yet robust local block-based\nsparsity model, using adaptively-constructed dictionaries from local features\nin the training data, to overcome this misalignment problem. Our approach is\ninspired by human perception: we analyze a series of local discriminative\nfeatures and combine them to arrive at the final classification decision. We\npropose a probabilistic graphical model framework to explicitly mine the\nconditional dependencies between these distinct sparse local features. In\nparticular, we learn discriminative graphs on sparse representations obtained\nfrom distinct local slices of a face. Conditional correlations between these\nsparse features are first discovered (in the training phase), and subsequently\nexploited to bring about significant improvements in recognition rates.\nExperimental results obtained on benchmark face databases demonstrate the\neffectiveness of the proposed algorithms in the presence of multiple\nregistration errors (such as translation, rotation, and scaling) as well as\nunder variations of pose and illumination."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.2391v1", 
    "title": "A Novel Approach to Texture classification using statistical feature", 
    "arxiv-id": "1111.2391v1", 
    "author": "V. Subbiah Bharathi", 
    "publish": "2011-11-10T04:28:08Z", 
    "summary": "Texture is an important spatial feature which plays a vital role in content\nbased image retrieval. The enormous growth of the internet and the wide use of\ndigital data have increased the need for both efficient image database creation\nand retrieval procedure. This paper describes a new approach for texture\nclassification by combining statistical texture features of Local Binary\nPattern and Texture spectrum. Since most significant information of a texture\noften appears in the high frequency channels, the features are extracted by the\ncomputation of LBP and Texture Spectrum and Legendre Moments. Euclidean\ndistance is used for similarity measurement. The experimental result shows that\n97.77% classification accuracy is obtained by the proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.3818v1", 
    "title": "Good Pairs of Adjacency Relations in Arbitrary Dimensions", 
    "arxiv-id": "1111.3818v1", 
    "author": "Martin H\u00fcnniger", 
    "publish": "2011-11-16T14:37:07Z", 
    "summary": "In this text we show, that the notion of a \"good pair\" that was introduced in\nthe paper \"Digital Manifolds and the Theorem of Jordan-Brouwer\" has actually\nknown models. We will show, how to choose cubical adjacencies, the\ngeneralizations of the well known 4- and 8-neighborhood to arbitrary\ndimensions, in order to find good pairs. Furthermore, we give another proof for\nthe well known fact that the Khalimsky-topology implies good pairs. The outcome\nis consistent with the known theory as presented by T.Y. Kong, A. Rosenfeld,\nG.T. Herman and M. Khachan et.al and gives new insights in higher dimensions."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.4052v1", 
    "title": "A Facial Expression Classification System Integrating Canny, Principal   Component Analysis and Artificial Neural Network", 
    "arxiv-id": "1111.4052v1", 
    "author": "Tran Son Hai", 
    "publish": "2011-11-17T10:43:08Z", 
    "summary": "Facial Expression Classification is an interesting research problem in recent\nyears. There are a lot of methods to solve this problem. In this research, we\npropose a novel approach using Canny, Principal Component Analysis (PCA) and\nArtificial Neural Network. Firstly, in preprocessing phase, we use Canny for\nlocal region detection of facial images. Then each of local region's features\nwill be presented based on Principal Component Analysis (PCA). Finally, using\nArtificial Neural Network (ANN)applies for Facial Expression Classification. We\napply our proposal method (Canny_PCA_ANN) for recognition of six basic facial\nexpressions on JAFFE database consisting 213 images posed by 10 Japanese female\nmodels. The experimental result shows the feasibility of our proposal method."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.4290v1", 
    "title": "A Single Euler Number Feature for Multi-font Multi-size Kannada Numeral   Recognition", 
    "arxiv-id": "1111.4290v1", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2011-11-18T06:34:07Z", 
    "summary": "In this paper a novel approach is proposed based on single Euler number\nfeature which is free from thinning and size normalization for multi-font and\nmulti-size Kannada numeral recognition system. A nearest neighbor\nclassification is used for classification of Kannada numerals by considering\nthe Euclidian distance. A total 1500 numeral images with different font sizes\nbetween (10..84) are tested for algorithm efficiency and the overall the\nclassification accuracy is found to be 99.00% .The said method is thinning\nfree, fast, and showed encouraging results on varying font styles and sizes of\nKannada numerals."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.4291v1", 
    "title": "Multi-font Multi-size Kannada Numeral Recognition Based on Structural   Features", 
    "arxiv-id": "1111.4291v1", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2011-11-18T06:59:35Z", 
    "summary": "In this paper a fast and novel method is proposed for multi-font multi-size\nKannada numeral recognition which is thinning free and without size\nnormalization approach. The different structural feature are used for numeral\nrecognition namely, directional density of pixels in four directions, water\nreservoirs, maximum profile distances, and fill hole density are used for the\nrecognition of Kannada numerals. A Euclidian minimum distance criterion is used\nto find minimum distances and K-nearest neighbor classifier is used to classify\nthe Kannada numerals by varying the size of numeral image from 16 to 50 font\nsizes for the 20 different font styles from NUDI and BARAHA popular word\nprocessing Kannada software. The total 1150 numeral images are tested and the\noverall accuracy of classification is found to be 100%. The average time taken\nby this method is 0.1476 seconds."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.4619v1", 
    "title": "Redundant Wavelets on Graphs and High Dimensional Data Clouds", 
    "arxiv-id": "1111.4619v1", 
    "author": "Israel Cohen", 
    "publish": "2011-11-20T08:58:45Z", 
    "summary": "In this paper, we propose a new redundant wavelet transform applicable to\nscalar functions defined on high dimensional coordinates, weighted graphs and\nnetworks. The proposed transform utilizes the distances between the given data\npoints. We modify the filter-bank decomposition scheme of the redundant wavelet\ntransform by adding in each decomposition level linear operators that reorder\nthe approximation coefficients. These reordering operators are derived by\norganizing the tree-node features so as to shorten the path that passes through\nthese points. We explore the use of the proposed transform to image denoising,\nand show that it achieves denoising results that are close to those obtained\nwith the BM3D algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.4654v1", 
    "title": "A self-portrait of young Leonardo", 
    "arxiv-id": "1111.4654v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2011-11-20T17:41:01Z", 
    "summary": "One of the most famous drawings by Leonardo da Vinci is a self-portrait in\nred chalk, where he looks quite old. In fact, there is a sketch in one of his\nnotebooks, partially covered by written notes, that can be a self-portrait of\nthe artist when he was young. The use of image processing, to remove the\nhandwritten text and improve the image, allows a comparison of the two\nportraits."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.4676v1", 
    "title": "Facial Asymmetry and Emotional Expression", 
    "arxiv-id": "1111.4676v1", 
    "author": "Andrew Pickin", 
    "publish": "2011-11-20T20:55:07Z", 
    "summary": "This report is about facial asymmetry, its connection to emotional\nexpression, and methods of measuring facial asymmetry in videos of faces. The\nresearch was motivated by two factors: firstly, there was a real opportunity to\ndevelop a novel measure of asymmetry that required minimal human involvement\nand that improved on earlier measures in the literature; and secondly, the\nstudy of the relationship between facial asymmetry and emotional expression is\nboth interesting in its own right, and important because it can inform\nneuropsychological theory and answer open questions concerning emotional\nprocessing in the brain. The two aims of the research were: first, to develop\nan automatic frame-by-frame measure of facial asymmetry in videos of faces that\nimproved on previous measures; and second, to use the measure to analyse the\nrelationship between facial asymmetry and emotional expression, and connect our\nfindings with previous research of the relationship."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.5108v1", 
    "title": "A Theory for Optical flow-based Transport on Image Manifolds", 
    "arxiv-id": "1111.5108v1", 
    "author": "Richard G. Baraniuk", 
    "publish": "2011-11-22T05:55:25Z", 
    "summary": "An image articulation manifold (IAM) is the collection of images formed when\nan object is articulated in front of a camera. IAMs arise in a variety of image\nprocessing and computer vision applications, where they provide a natural\nlow-dimensional embedding of the collection of high-dimensional images. To date\nIAMs have been studied as embedded submanifolds of Euclidean spaces.\nUnfortunately, their promise has not been realized in practice, because real\nworld imagery typically contains sharp edges that render an IAM\nnon-differentiable and hence non-isometric to the low-dimensional parameter\nspace under the Euclidean metric. As a result, the standard tools from\ndifferential geometry, in particular using linear tangent spaces to transport\nalong the IAM, have limited utility. In this paper, we explore a nonlinear\ntransport operator for IAMs based on the optical flow between images and\ndevelop new analytical tools reminiscent of those from differential geometry\nusing the idea of optical flow manifolds (OFMs). We define a new metric for\nIAMs that satisfies certain local isometry conditions, and we show how to use\nthis metric to develop a new tools such as flow fields on IAMs, parallel flow\nfields, parallel transport, as well as a intuitive notion of curvature. The\nspace of optical flow fields along a path of constant curvature has a natural\nmulti-scale structure via a monoid structure on the space of all flow fields\nalong a path. We also develop lower bounds on approximation errors while\napproximating non-parallel flow fields by parallel flow fields."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.6030v2", 
    "title": "An image processing of a Raphael's portrait of Leonardo", 
    "arxiv-id": "1111.6030v2", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2011-11-25T15:46:37Z", 
    "summary": "In one of his paintings, the School of Athens, Raphael is depicting Leonardo\nda Vinci as the philosopher Plato. Some image processing tools can help us in\ncomparing this portrait with two Leonardo's portraits, considered as\nself-portraits."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.7271v1", 
    "title": "Invariant texture analysis through Local Binary Patterns", 
    "arxiv-id": "1111.7271v1", 
    "author": "Boris Escalante-Ram\u00edrez", 
    "publish": "2011-11-30T18:58:53Z", 
    "summary": "In many image processing applications, such as segmentation and\nclassification, the selection of robust features descriptors is crucial to\nimprove the discrimination capabilities in real world scenarios. In particular,\nit is well known that image textures constitute power visual cues for feature\nextraction and classification. In the past few years the local binary pattern\n(LBP) approach, a texture descriptor method proposed by Ojala et al., has\ngained increased acceptance due to its computational simplicity and more\nimportantly for encoding a powerful signature for describing textures. However,\nthe original algorithm presents some limitations such as noise sensitivity and\nits lack of rotational invariance which have led to many proposals or\nextensions in order to overcome such limitations. In this paper we performed a\nquantitative study of the Ojala's original LBP proposal together with other\nrecently proposed LBP extensions in the presence of rotational, illumination\nand noisy changes. In the experiments we have considered two different\ndatabases: Brodatz and CUReT for different sizes of LBP masks. Experimental\nresults demonstrated the effectiveness and robustness of the described texture\ndescriptors for images that are subjected to geometric or radiometric changes."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1112.0059v1", 
    "title": "Local Naive Bayes Nearest Neighbor for Image Classification", 
    "arxiv-id": "1112.0059v1", 
    "author": "David G. Lowe", 
    "publish": "2011-12-01T01:19:08Z", 
    "summary": "We present Local Naive Bayes Nearest Neighbor, an improvement to the NBNN\nimage classification algorithm that increases classification accuracy and\nimproves its ability to scale to large numbers of object classes. The key\nobservation is that only the classes represented in the local neighborhood of a\ndescriptor contribute significantly and reliably to their posterior probability\nestimates. Instead of maintaining a separate search structure for each class,\nwe merge all of the reference data together into one search structure, allowing\nquick identification of a descriptor's local neighborhood. We show an increase\nin classification accuracy when we ignore adjustments to the more distant\nclasses and show that the run time grows with the log of the number of classes\nrather than linearly in the number of classes as did the original. This gives a\n100 times speed-up over the original method on the Caltech 256 dataset. We also\nprovide the first head-to-head comparison of NBNN against spatial pyramid\nmethods using a common set of input features. We show that local NBNN\noutperforms all previous NBNN based methods and the original spatial pyramid\nmodel. However, we find that local NBNN, while competitive with, does not beat\nstate-of-the-art spatial pyramid methods that use local soft assignment and\nmax-pooling."
},{
    "category": "cs.CV", 
    "doi": "10.1103/PhysRevE.85.041918", 
    "link": "http://arxiv.org/pdf/1112.0655v1", 
    "title": "A Biomimetic Model of the Outer Plexiform Layer by Incorporating   Memristive Devices", 
    "arxiv-id": "1112.0655v1", 
    "author": "Tamas Roska", 
    "publish": "2011-12-03T13:53:54Z", 
    "summary": "In this paper we present a biorealistic model for the first part of the early\nvision processing by incorporating memristive nanodevices. The architecture of\nthe proposed network is based on the organisation and functioning of the outer\nplexiform layer (OPL) in the vertebrate retina. We demonstrate that memristive\ndevices are indeed a valuable building block for neuromorphic architectures, as\ntheir highly non-linear and adaptive response could be exploited for\nestablishing ultra-dense networks with similar dynamics to their biological\ncounterparts. We particularly show that hexagonal memristive grids can be\nemployed for faithfully emulating the smoothing-effect occurring at the OPL for\nenhancing the dynamic range of the system. In addition, we employ a\nmemristor-based thresholding scheme for detecting the edges of grayscale\nimages, while the proposed system is also evaluated for its adaptation and\nfault tolerance capacity against different light or noise conditions as well as\ndistinct device yields."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1187v1", 
    "title": "Meaningful Matches in Stereovision", 
    "arxiv-id": "1112.1187v1", 
    "author": "Jean-Michel Morel", 
    "publish": "2011-12-06T08:06:45Z", 
    "summary": "This paper introduces a statistical method to decide whether two blocks in a\npair of of images match reliably. The method ensures that the selected block\nmatches are unlikely to have occurred \"just by chance.\" The new approach is\nbased on the definition of a simple but faithful statistical \"background model\"\nfor image blocks learned from the image itself. A theorem guarantees that under\nthis model not more than a fixed number of wrong matches occurs (on average)\nfor the whole image. This fixed number (the number of false alarms) is the only\nmethod parameter. Furthermore, the number of false alarms associated with each\nmatch measures its reliability. This \"a contrario\" block-matching method,\nhowever, cannot rule out false matches due to the presence of periodic objects\nin the images. But it is successfully complemented by a parameterless\n\"self-similarity threshold.\" Experimental evidence shows that the proposed\nmethod also detects occlusions and incoherent motions due to vehicles and\npedestrians in non simultaneous stereo."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1200v1", 
    "title": "A multi-feature tracking algorithm enabling adaptation to context   variations", 
    "arxiv-id": "1112.1200v1", 
    "author": "Monique Thonnat", 
    "publish": "2011-12-06T09:19:17Z", 
    "summary": "We propose in this paper a tracking algorithm which is able to adapt itself\nto different scene contexts. A feature pool is used to compute the matching\nscore between two detected objects. This feature pool includes 2D, 3D\ndisplacement distances, 2D sizes, color histogram, histogram of oriented\ngradient (HOG), color covariance and dominant color. An offline learning\nprocess is proposed to search for useful features and to estimate their weights\nfor each context. In the online tracking process, a temporal window is defined\nto establish the links between the detected objects. This enables to find the\nobject trajectories even if the objects are misdetected in some frames. A\ntrajectory filter is proposed to remove noisy trajectories. Experimentation on\ndifferent contexts is shown. The proposed tracker has been tested in videos\nbelonging to three public datasets and to the Caretaker European project. The\nexperimental results prove the effect of the proposed feature weight learning,\nand the robustness of the proposed tracker compared to some methods in the\nstate of the art. The contributions of our approach over the state of the art\ntrackers are: (i) a robust tracking algorithm based on a feature pool, (ii) a\nsupervised learning scheme to learn feature weights for each context, (iii) a\nnew method to quantify the reliability of HOG descriptor, (iv) a combination of\ncolor covariance and dominant color features with spatial pyramid distance to\nmanage the case of object occlusion."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1484v1", 
    "title": "POCS Based Super-Resolution Image Reconstruction Using an Adaptive   Regularization Parameter", 
    "arxiv-id": "1112.1484v1", 
    "author": "G. Jena", 
    "publish": "2011-12-07T06:29:07Z", 
    "summary": "Crucial information barely visible to the human eye is often embedded in a\nseries of low-resolution images taken of the same scene. Super-resolution\nenables the extraction of this information by reconstructing a single image, at\na high resolution than is present in any of the individual images. This is\nparticularly useful in forensic imaging, where the extraction of minute details\nin an image can help to solve a crime. Super-resolution image restoration has\nbeen one of the most important research areas in recent years which goals to\nobtain a high resolution (HR) image from several low resolutions (LR) blurred,\nnoisy, under sampled and displaced images. Relation of the HR image and LR\nimages can be modeled by a linear system using a transformation matrix and\nadditive noise. However, a unique solution may not be available because of the\nsingularity of transformation matrix. To overcome this problem, POCS method has\nbeen used. However, their performance is not good because the effect of noise\nenergy has been ignored. In this paper, we propose an adaptive regularization\napproach based on the fact that the regularization parameter should be a linear\nfunction of noise variance. The performance of the proposed approach has been\ntested on several images and the obtained results demonstrate the superiority\nof our approach compared with existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1496v3", 
    "title": "Re-initialization Free Level Set Evolution via Reaction Diffusion", 
    "arxiv-id": "1112.1496v3", 
    "author": "David Zhang", 
    "publish": "2011-12-07T08:16:48Z", 
    "summary": "This paper presents a novel reaction-diffusion (RD) method for implicit\nactive contours, which is completely free of the costly re-initialization\nprocedure in level set evolution (LSE). A diffusion term is introduced into\nLSE, resulting in a RD-LSE equation, to which a piecewise constant solution can\nbe derived. In order to have a stable numerical solution of the RD based LSE,\nwe propose a two-step splitting method (TSSM) to iteratively solve the RD-LSE\nequation: first iterating the LSE equation, and then solving the diffusion\nequation. The second step regularizes the level set function obtained in the\nfirst step to ensure stability, and thus the complex and costly\nre-initialization procedure is completely eliminated from LSE. By successfully\napplying diffusion to LSE, the RD-LSE model is stable by means of the simple\nfinite difference method, which is very easy to implement. The proposed RD\nmethod can be generalized to solve the LSE for both variational level set\nmethod and PDE-based level set method. The RD-LSE method shows very good\nperformance on boundary anti-leakage, and it can be readily extended to high\ndimensional level set method. The extensive and promising experimental results\non synthetic and real images validate the effectiveness of the proposed RD-LSE\napproach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijist.2011.1303", 
    "link": "http://arxiv.org/pdf/1112.2386v1", 
    "title": "Improvement of BM3D Algorithm and Employment to Satellite and CFA Images   Denoising", 
    "arxiv-id": "1112.2386v1", 
    "author": "'Gholamali Rezai-rad'", 
    "publish": "2011-12-11T18:57:10Z", 
    "summary": "This paper proposes a new procedure in order to improve the performance of\nblock matching and 3-D filtering (BM3D) image denoising algorithm. It is\ndemonstrated that it is possible to achieve a better performance than that of\nBM3D algorithm in a variety of noise levels. This method changes BM3D algorithm\nparameter values according to noise level, removes prefiltering, which is used\nin high noise level; therefore Peak Signal-to-Noise Ratio (PSNR) and visual\nquality get improved, and BM3D complexities and processing time are reduced.\nThis improved BM3D algorithm is extended and used to denoise satellite and\ncolor filter array (CFA) images. Output results show that the performance has\nupgraded in comparison with current methods of denoising satellite and CFA\nimages. In this regard this algorithm is compared with Adaptive PCA algorithm,\nthat has led to superior performance for denoising CFA images, on the subject\nof PSNR and visual quality. Also the processing time has decreased\nsignificantly."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijist.2011.1303", 
    "link": "http://arxiv.org/pdf/1112.2903v1", 
    "title": "Large Scale Correlation Clustering Optimization", 
    "arxiv-id": "1112.2903v1", 
    "author": "Meirav Galun", 
    "publish": "2011-12-13T14:28:12Z", 
    "summary": "Clustering is a fundamental task in unsupervised learning. The focus of this\npaper is the Correlation Clustering functional which combines positive and\nnegative affinities between the data points. The contribution of this paper is\ntwo fold: (i) Provide a theoretic analysis of the functional. (ii) New\noptimization algorithms which can cope with large scale problems (>100K\nvariables) that are infeasible using existing methods. Our theoretic analysis\nprovides a probabilistic generative interpretation for the functional, and\njustifies its intrinsic \"model-selection\" capability. Furthermore, we draw an\nanalogy between optimizing this functional and the well known Potts energy\nminimization. This analogy allows us to suggest several new optimization\nalgorithms, which exploit the intrinsic \"model-selection\" capability of the\nfunctional to automatically recover the underlying number of clusters. We\ncompare our algorithms to existing methods on both synthetic and real data. In\naddition we suggest two new applications that are made possible by our\nalgorithms: unsupervised face identification and interactive multi-object\nsegmentation by rough boundary delineation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijist.2011.1303", 
    "link": "http://arxiv.org/pdf/1112.2988v2", 
    "title": "Supervised Generative Reconstruction: An Efficient Way To Flexibly Store   and Recognize Patterns", 
    "arxiv-id": "1112.2988v2", 
    "author": "Tsvi Achler", 
    "publish": "2011-12-13T18:10:11Z", 
    "summary": "Matching animal-like flexibility in recognition and the ability to quickly\nincorporate new information remains difficult. Limits are yet to be adequately\naddressed in neural models and recognition algorithms. This work proposes a\nconfiguration for recognition that maintains the same function of conventional\nalgorithms but avoids combinatorial problems. Feedforward recognition\nalgorithms such as classical artificial neural networks and machine learning\nalgorithms are known to be subject to catastrophic interference and forgetting.\nModifying or learning new information (associations between patterns and\nlabels) causes loss of previously learned information. I demonstrate using\nmathematical analysis how supervised generative models, with feedforward and\nfeedback connections, can emulate feedforward algorithms yet avoid catastrophic\ninterference and forgetting. Learned information in generative models is stored\nin a more intuitive form that represents the fixed points or solutions of the\nnetwork and moreover displays similar difficulties as cognitive phenomena.\nBrain-like capabilities and limits associated with generative models suggest\nthe brain may perform recognition and store information using a similar\napproach. Because of the central role of recognition, progress understanding\nthe underlying principles may reveal significant insight on how to better study\nand integrate with the brain."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0038897", 
    "link": "http://arxiv.org/pdf/1112.3697v1", 
    "title": "Insights from Classifying Visual Concepts with Multiple Kernel Learning", 
    "arxiv-id": "1112.3697v1", 
    "author": "Motoaki Kawanabe", 
    "publish": "2011-12-16T01:06:47Z", 
    "summary": "Combining information from various image features has become a standard\ntechnique in concept recognition tasks. However, the optimal way of fusing the\nresulting kernel functions is usually unknown in practical applications.\nMultiple kernel learning (MKL) techniques allow to determine an optimal linear\ncombination of such similarity matrices. Classical approaches to MKL promote\nsparse mixtures. Unfortunately, so-called 1-norm MKL variants are often\nobserved to be outperformed by an unweighted sum kernel. The contribution of\nthis paper is twofold: We apply a recently developed non-sparse MKL variant to\nstate-of-the-art concept recognition tasks within computer vision. We provide\ninsights on benefits and limits of non-sparse MKL and compare it against its\ndirect competitors, the sum kernel SVM and the sparse MKL. We report empirical\nresults for the PASCAL VOC 2009 Classification and ImageCLEF2010 Photo\nAnnotation challenge data sets. About to be submitted to PLoS ONE."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-15907-7_26", 
    "link": "http://arxiv.org/pdf/1112.4060v1", 
    "title": "A real time vehicles detection algorithm for vision based sensors", 
    "arxiv-id": "1112.4060v1", 
    "author": "Bart\u0142omiej P\u0142aczek", 
    "publish": "2011-12-17T14:50:50Z", 
    "summary": "A vehicle detection plays an important role in the traffic control at\nsignalised intersections. This paper introduces a vision-based algorithm for\nvehicles presence recognition in detection zones. The algorithm uses linguistic\nvariables to evaluate local attributes of an input image. The image attributes\nare categorised as vehicle, background or unknown features. Experimental\nresults on complex traffic scenes show that the proposed algorithm is effective\nfor a real-time vehicles detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.4064v1", 
    "title": "Vehicles Recognition Using Fuzzy Descriptors of Image Segments", 
    "arxiv-id": "1112.4064v1", 
    "author": "Bart\u0142omiej P\u0142aczek", 
    "publish": "2011-12-17T15:21:22Z", 
    "summary": "In this paper a vision-based vehicles recognition method is presented.\nProposed method uses fuzzy description of image segments for automatic\nrecognition of vehicles recorded in image data. The description takes into\naccount selected geometrical properties and shape coefficients determined for\nsegments of reference image (vehicle model). The proposed method was\nimplemented using reasoning system with fuzzy rules. A vehicles recognition\nalgorithm was developed based on the fuzzy rules describing shape and\narrangement of the image segments that correspond to visible parts of a\nvehicle. An extension of the algorithm with set of fuzzy rules defined for\ndifferent reference images (and various vehicle shapes) enables vehicles\nclassification in traffic scenes. The devised method is suitable for\napplication in video sensors for road traffic control and surveillance systems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.4135v1", 
    "title": "A Reduced Reference Image Quality Measure Using Bessel K Forms Model for   Tetrolet Coefficients", 
    "arxiv-id": "1112.4135v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2011-12-18T08:11:59Z", 
    "summary": "In this paper, we introduce a Reduced Reference Image Quality Assessment\n(RRIQA) measure based on the natural image statistic approach. A new adaptive\ntransform called \"Tetrolet\" is applied to both reference and distorted images.\nTo model the marginal distribution of tetrolet coefficients Bessel K Forms\n(BKF) density is proposed. Estimating the parameters of this distribution\nallows to summarize the reference image with a small amount of side\ninformation. Five distortion measures based on the BKF parameters of the\noriginal and processed image are used to predict quality scores. A comparison\nbetween these measures is presented showing a good consistency with human\njudgment."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.4164v5", 
    "title": "A Geometric Approach For Fully Automatic Chromosome Segmentation", 
    "arxiv-id": "1112.4164v5", 
    "author": "Babak Hossein Khalaj", 
    "publish": "2011-12-18T15:46:18Z", 
    "summary": "A fundamental task in human chromosome analysis is chromosome segmentation.\nSegmentation plays an important role in chromosome karyotyping. The first step\nin segmentation is to remove intrusive objects such as stain debris and other\nnoises. The next step is detection of touching and overlapping chromosomes, and\nthe final step is separation of such chromosomes. Common methods for separation\nbetween touching chromosomes are interactive and require human intervention for\ncorrect separation between touching and overlapping chromosomes. In this paper,\na geometric-based method is used for automatic detection of touching and\noverlapping chromosomes and separating them. The proposed scheme performs\nsegmentation in two phases. In the first phase, chromosome clusters are\ndetected using three geometric criteria, and in the second phase, chromosome\nclusters are separated using a cut-line. Most of earlier methods did not work\nproperly in case of chromosome clusters that contained more than two\nchromosomes. Our method, on the other hand, is quite efficient in separation of\nsuch chromosome clusters. At each step, one separation will be performed and\nthis algorithm is repeated until all individual chromosomes are separated.\nAnother important point about the proposed method is that it uses the geometric\nfeatures of chromosomes which are independent of the type of images and it can\neasily be applied to any type of images such as binary images and does not\nrequire multispectral images as well. We have applied our method to a database\ncontaining 62 touching and partially overlapping chromosomes and a success rate\nof 91.9% is achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.5298v1", 
    "title": "Zero-Temperature Limit of a Convergent Algorithm to Minimize the Bethe   Free Energy", 
    "arxiv-id": "1112.5298v1", 
    "author": "Tomas Werner", 
    "publish": "2011-12-22T13:10:05Z", 
    "summary": "After the discovery that fixed points of loopy belief propagation coincide\nwith stationary points of the Bethe free energy, several researchers proposed\nprovably convergent algorithms to directly minimize the Bethe free energy.\nThese algorithms were formulated only for non-zero temperature (thus finding\nfixed points of the sum-product algorithm) and their possible extension to zero\ntemperature is not obvious. We present the zero-temperature limit of the\ndouble-loop algorithm by Heskes, which converges a max-product fixed point. The\ninner loop of this algorithm is max-sum diffusion. Under certain conditions,\nthe algorithm combines the complementary advantages of the max-product belief\npropagation and max-sum diffusion (LP relaxation): it yields good approximation\nof both ground states and max-marginals."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2155077", 
    "link": "http://arxiv.org/pdf/1112.5638v1", 
    "title": "Discretization of Parametrizable Signal Manifolds", 
    "arxiv-id": "1112.5638v1", 
    "author": "Pascal Frossard", 
    "publish": "2011-12-23T19:08:10Z", 
    "summary": "Transformation-invariant analysis of signals often requires the computation\nof the distance from a test pattern to a transformation manifold. In\nparticular, the estimation of the distances between a transformed query signal\nand several transformation manifolds representing different classes provides\nessential information for the classification of the signal. In many\napplications the computation of the exact distance to the manifold is costly,\nwhereas an efficient practical solution is the approximation of the manifold\ndistance with the aid of a manifold grid. In this paper, we consider a setting\nwith transformation manifolds of known parameterization. We first present an\nalgorithm for the selection of samples from a single manifold that permits to\nminimize the average error in the manifold distance estimation. Then we propose\na method for the joint discretization of multiple manifolds that represent\ndifferent signal classes, where we optimize the transformation-invariant\nclassification accuracy yielded by the discrete manifold representation.\nExperimental results show that sampling each manifold individually by\nminimizing the manifold distance estimation error outperforms baseline sampling\nsolutions with respect to registration and classification accuracy. Performing\nan additional joint optimization on all samples improves the classification\nperformance further. Moreover, given a fixed total number of samples to be\nselected from all manifolds, an asymmetric distribution of samples to different\nmanifolds depending on their geometric structures may also increase the\nclassification accuracy in comparison with the equal distribution of samples."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.5640v5", 
    "title": "Learning Smooth Pattern Transformation Manifolds", 
    "arxiv-id": "1112.5640v5", 
    "author": "Pascal Frossard", 
    "publish": "2011-12-23T19:13:31Z", 
    "summary": "Manifold models provide low-dimensional representations that are useful for\nprocessing and analyzing data in a transformation-invariant way. In this paper,\nwe study the problem of learning smooth pattern transformation manifolds from\nimage sets that represent observations of geometrically transformed signals. In\norder to construct a manifold, we build a representative pattern whose\ntransformations accurately fit various input images. We examine two objectives\nof the manifold building problem, namely, approximation and classification. For\nthe approximation problem, we propose a greedy method that constructs a\nrepresentative pattern by selecting analytic atoms from a continuous dictionary\nmanifold. We present a DC (Difference-of-Convex) optimization scheme that is\napplicable to a wide range of transformation and dictionary models, and\ndemonstrate its application to transformation manifolds generated by rotation,\ntranslation and anisotropic scaling of a reference pattern. Then, we generalize\nthis approach to a setting with multiple transformation manifolds, where each\nmanifold represents a different class of signals. We present an iterative\nmultiple manifold building algorithm such that the classification accuracy is\npromoted in the learning of the representative patterns. Experimental results\nsuggest that the proposed methods yield high accuracy in the approximation and\nclassification of data compared to some reference methods, while the invariance\nto geometric transformations is achieved due to the transformation manifold\nmodel."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.5895v1", 
    "title": "Online Adaptive Statistical Compressed Sensing of Gaussian Mixture   Models", 
    "arxiv-id": "1112.5895v1", 
    "author": "Lawrence Carin", 
    "publish": "2011-12-26T21:42:22Z", 
    "summary": "A framework of online adaptive statistical compressed sensing is introduced\nfor signals following a mixture model. The scheme first uses non-adaptive\nmeasurements, from which an online decoding scheme estimates the model\nselection. As soon as a candidate model has been selected, an optimal sensing\nscheme for the selected model continues to apply. The final signal\nreconstruction is calculated from the ensemble of both the non-adaptive and the\nadaptive measurements. For signals generated from a Gaussian mixture model, the\nonline adaptive sensing algorithm is given and its performance is analyzed. On\nboth synthetic and real image data, the proposed adaptive scheme considerably\nreduces the average reconstruction error with respect to standard statistical\ncompressed sensing that uses fully random measurements, at a marginally\nincreased computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.5997v3", 
    "title": "Multispectral Palmprint Recognition Using a Hybrid Feature", 
    "arxiv-id": "1112.5997v3", 
    "author": "Emad Fatemizadeh", 
    "publish": "2011-12-27T18:19:04Z", 
    "summary": "Personal identification problem has been a major field of research in recent\nyears. Biometrics-based technologies that exploit fingerprints, iris, face,\nvoice and palmprints, have been in the center of attention to solve this\nproblem. Palmprints can be used instead of fingerprints that have been of the\nearliest of these biometrics technologies. A palm is covered with the same skin\nas the fingertips but has a larger surface, giving us more information than the\nfingertips. The major features of the palm are palm-lines, including principal\nlines, wrinkles and ridges. Using these lines is one of the most popular\napproaches towards solving the palmprint recognition problem. Another robust\nfeature is the wavelet energy of palms. In this paper we used a hybrid feature\nwhich combines both of these features. %Moreover, multispectral analysis is\napplied to improve the performance of the system. At the end, minimum distance\nclassifier is used to match test images with one of the training samples. The\nproposed algorithm has been tested on a well-known multispectral palmprint\ndataset and achieved an average accuracy of 98.8\\%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.6269v1", 
    "title": "Automated PolyU Palmprint sample Registration and Coarse Classification", 
    "arxiv-id": "1112.6269v1", 
    "author": "I. V. Muralikrishna", 
    "publish": "2011-12-29T10:35:01Z", 
    "summary": "Biometric based authentication for secured access to resources has gained\nimportance, due to their reliable, invariant and discriminating features.\nPalmprint is one such biometric entity. Prior to classification and\nidentification registering a sample palmprint is an important activity. In this\npaper we propose a computationally effective method for automated registration\nof samples from PlolyU palmprint database. In our approach we preprocess the\nsample and trace the border to find the nearest point from center of sample.\nAngle between vector representing the nearest point and vector passing through\nthe center is used for automated palm sample registration. The angle of\ninclination between start and end point of heart line and life line is used for\nbasic classification of palmprint samples in left class and right class."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.0566v2", 
    "title": "Learning joint intensity-depth sparse representations", 
    "arxiv-id": "1201.0566v2", 
    "author": "Sarah Drewes", 
    "publish": "2012-01-03T03:47:09Z", 
    "summary": "This paper presents a method for learning overcomplete dictionaries composed\nof two modalities that describe a 3D scene: image intensity and scene depth. We\npropose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse\nfeatures in two modalities using conic programming and integrate it into a\ntwo-step dictionary learning algorithm. JBP differs from related convex\nalgorithms because it finds joint sparsity models with different atoms and\ndifferent coefficient values for intensity and depth. This is crucial for\nrecovering generative models where the same sparse underlying causes (3D\nfeatures) give rise to different signals (intensity and depth). We give a\ntheoretical bound for the sparse coefficient recovery error obtained by JBP,\nand show experimentally that JBP is far superior to the state of the art Group\nLasso algorithm. When applied to the Middlebury depth-intensity database, our\nlearning algorithm converges to a set of related features, such as pairs of\ndepth and intensity edges or image textures and depth slants. Finally, we show\nthat the learned dictionary and JBP achieve the state of the art depth\ninpainting performance on time-of-flight 3D data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.1417v1", 
    "title": "Picture Collage with Genetic Algorithm and Stereo vision", 
    "arxiv-id": "1201.1417v1", 
    "author": "Mahmood Amintoosi", 
    "publish": "2011-11-29T06:24:33Z", 
    "summary": "In this paper, a salient region extraction method for creating picture\ncollage based on stereo vision is proposed. Picture collage is a kind of visual\nimage summary to arrange all input images on a given canvas, allowing overlay,\nto maximize visible visual information. The salient regions of each image are\nfirstly extracted and represented as a depth map. The output picture collage\nshows as many visible salient regions (without being overlaid by others) from\nall images as possible. A very efficient Genetic algorithm is used here for the\noptimization. The experimental results showed the superior performance of the\nproposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.1571v3", 
    "title": "A United Image Force for Deformable Models and Direct Transforming   Geometric Active Contorus to Snakes by Level Sets", 
    "arxiv-id": "1201.1571v3", 
    "author": "Shanglian Bao", 
    "publish": "2012-01-07T15:58:18Z", 
    "summary": "A uniform distribution of the image force field around the object fasts the\nconvergence speed of the segmentation process. However, to achieve this aim, it\ncauses the force constructed from the heat diffusion model unable to indicate\nthe object boundaries accurately. The image force based on electrostatic field\nmodel can perform an exact shape recovery. First, this study introduces a\nfusion scheme of these two image forces, which is capable of extracting the\nobject boundary with high precision and fast speed. Until now, there is no\nsatisfied analysis about the relationship between Snakes and Geometric Active\nContours (GAC). The second contribution of this study addresses that the GAC\nmodel can be deduced directly from Snakes model. It proves that each term in\nGAC and Snakes is correspondent and has similar function. However, the two\nmodels are expressed using different mathematics. Further, since losing the\nability of rotating the contour, adoption of level sets can limits the usage of\nGAC in some circumstances."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2050v1", 
    "title": "Adaptive Noise Reduction Scheme for Salt and Pepper", 
    "arxiv-id": "1201.2050v1", 
    "author": "Dong-Yoon Kim", 
    "publish": "2012-01-10T13:41:56Z", 
    "summary": "In this paper, a new adaptive noise reduction scheme for images corrupted by\nimpulse noise is presented. The proposed scheme efficiently identifies and\nreduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify\npixels which are most likely corrupted by salt and pepper noise that are\ncandidates for further median based noise reduction processing. Directional\nfiltering is then applied after noise reduction to achieve a good tradeoff\nbetween detail preservation and noise removal. The proposed scheme can remove\nsalt and pepper noise with noise density as high as 90% and produce better\nresult in terms of qualitative and quantitative measures of images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2843v1", 
    "title": "Nonparametric Sparse Representation", 
    "arxiv-id": "1201.2843v1", 
    "author": "Babak Seyfe", 
    "publish": "2012-01-13T14:05:59Z", 
    "summary": "This paper suggests a nonparametric scheme to find the sparse solution of the\nunderdetermined system of linear equations in the presence of unknown impulsive\nor non-Gaussian noise. This approach is robust against any variations of the\nnoise model and its parameters. It is based on minimization of rank pseudo norm\nof the residual signal and l_1-norm of the signal of interest, simultaneously.\nWe use the steepest descent method to find the sparse solution via an iterative\nalgorithm. Simulation results show that our proposed method outperforms the\nexistence methods like OMP, BP, Lasso, and BCS whenever the observation vector\nis contaminated with measurement or environmental non-Gaussian noise with\nunknown parameters. Furthermore, for low SNR condition, the proposed method has\nbetter performance in the presence of Gaussian noise."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2905v2", 
    "title": "NegCut: Automatic Image Segmentation based on MRF-MAP", 
    "arxiv-id": "1201.2905v2", 
    "author": "Zhao Qiyang", 
    "publish": "2012-01-13T18:18:03Z", 
    "summary": "Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a\nprevailing method in recent interactive image segmentation tools. Although\nmathematically explicit in its computational targets, and impressive for the\nsegmentation quality, MRF-MAP is hard to accomplish without the interactive\ninformation from users. So it is rarely adopted in the automatic style up to\ntoday. In this paper, we present an automatic image segmentation algorithm,\nNegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is\nNP-hard when the probabilistic models are unknown, and then present an\napproximation function in the form of minimum cuts on graphs with negative\nweights. Finally, the binary segmentation is taken from the largest eigenvector\nof the target matrix, with a tuned version of the Lanczos eigensolver. It is\nshown competitive at the segmentation quality in our experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2995v1", 
    "title": "G-Lets: Signal Processing Using Transformation Groups", 
    "arxiv-id": "1201.2995v1", 
    "author": "K. P. Soman", 
    "publish": "2012-01-14T07:18:06Z", 
    "summary": "We present an algorithm using transformation groups and their irreducible\nrepresentations to generate an orthogonal basis for a signal in the vector\nspace of the signal. It is shown that multiresolution analysis can be done with\namplitudes using a transformation group. G-lets is thus not a single transform,\nbut a group of linear transformations related by group theory. The algorithm\nalso specifies that a multiresolution and multiscale analysis for each\nresolution is possible in terms of frequencies. Separation of low and high\nfrequency components of each amplitude resolution is facilitated by G-lets.\nUsing conjugacy classes of the transformation group, more than one set of basis\nmay be generated, giving a different perspective of the signal through each\nbasis. Applications for this algorithm include edge detection, feature\nextraction, denoising, face recognition, compression, and more. We analyze this\nalgorithm using dihedral groups as an example. We demonstrate the results with\nan ECG signal and the standard `Lena' image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3109v1", 
    "title": "Automatic system for counting cells with elliptical shape", 
    "arxiv-id": "1201.3109v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-15T17:42:07Z", 
    "summary": "This paper presents a new method for automatic quantification of ellipse-like\ncells in images, an important and challenging problem that has been studied by\nthe computer vision community. The proposed method can be described by two main\nsteps. Initially, image segmentation based on the k-means algorithm is\nperformed to separate different types of cells from the background. Then, a\nrobust and efficient strategy is performed on the blob contour for touching\ncells splitting. Due to the contour processing, the method achieves excellent\nresults of detection compared to manual detection performed by specialists."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3153v1", 
    "title": "Fractal and Multi-Scale Fractal Dimension analysis: a comparative study   of Bouligand-Minkowski method", 
    "arxiv-id": "1201.3153v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-16T03:18:22Z", 
    "summary": "Shape is one of the most important visual attributes to characterize objects,\nplaying a important role in pattern recognition. There are various approaches\nto extract relevant information of a shape. An approach widely used in shape\nanalysis is the complexity, and Fractal Dimension and Multi-Scale Fractal\nDimension are both well-known methodologies to estimate it. This papers\npresents a comparative study between Fractal Dimension and Multi-Scale Fractal\nDimension in a shape analysis context. Through experimental comparison using a\nshape database previously classified, both methods are compared. Different\nparameters configuration of each method are considered and a discussion about\nthe results of each method is also presented."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3233v2", 
    "title": "Variations of images to increase their visibility", 
    "arxiv-id": "1201.3233v2", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2012-01-16T12:31:27Z", 
    "summary": "The calculus of variations applied to the image processing requires some\nnumerical models able to perform the variations of images and the extremization\nof appropriate actions. To produce the variations of images, there are several\npossibilities based on the brightness maps. Before a numerical model, I propose\nan experimental approach, based on a tool of Gimp, GNU Image Manipulation\nProgram, in order to visualize how the image variations can be. After the\ndiscussion of this tool, which is able to strongly increase the visibility of\nimages, the variations and a possible functional for the visibility are\nproposed in the framework of a numerical model. The visibility functional is\nanalogous to the fringe visibility of the optical interference."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3612v1", 
    "title": "Spatiotemporal Gabor filters: a new method for dynamic texture   recognition", 
    "arxiv-id": "1201.3612v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-17T20:26:04Z", 
    "summary": "This paper presents a new method for dynamic texture recognition based on\nspatiotemporal Gabor filters. Dynamic textures have emerged as a new field of\ninvestigation that extends the concept of self-similarity of texture image to\nthe spatiotemporal domain. To model a dynamic texture, we convolve the sequence\nof images to a bank of spatiotemporal Gabor filters. For each response, a\nfeature vector is built by calculating the energy statistic. As far as the\nauthors know, this paper is the first to report an effective method for dynamic\ntexture recognition using spatiotemporal Gabor filters. We evaluate the\nproposed method on two challenging databases and the experimental results\nindicate that the proposed method is a robust approach for dynamic texture\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3720v1", 
    "title": "A Multimodal Biometric System Using Linear Discriminant Analysis For   Improved Performance", 
    "arxiv-id": "1201.3720v1", 
    "author": "Adeel Akram", 
    "publish": "2012-01-18T08:20:00Z", 
    "summary": "Essentially a biometric system is a pattern recognition system which\nrecognizes a user by determining the authenticity of a specific anatomical or\nbehavioral characteristic possessed by the user. With the ever increasing\nintegration of computers and Internet into daily life style, it has become\nnecessary to protect sensitive and personal data. This paper proposes a\nmultimodal biometric system which incorporates more than one biometric trait to\nattain higher security and to handle failure to enroll situations for some\nusers. This paper is aimed at investigating a multimodal biometric identity\nsystem using Linear Discriminant Analysis as backbone to both facial and speech\nrecognition and implementing such system in real-time using SignalWAVE."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3803v1", 
    "title": "Image Labeling and Segmentation using Hierarchical Conditional Random   Field Model", 
    "arxiv-id": "1201.3803v1", 
    "author": "Sonali. Nimbhorkar", 
    "publish": "2012-01-16T07:33:56Z", 
    "summary": "The use of hierarchical Conditional Random Field model deal with the problem\nof labeling images . At the time of labeling a new image, selection of the\nnearest cluster and using the related CRF model to label this image. When one\ngive input image, one first use the CRF model to get initial pixel labels then\nfinding the cluster with most similar images. Then at last relabeling the input\nimage by the CRF model associated with this cluster. This paper presents a\napproach to label and segment specific image having correct information."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3821v1", 
    "title": "A PCA-Based Super-Resolution Algorithm for Short Image Sequences", 
    "arxiv-id": "1201.3821v1", 
    "author": "Francisco B. Rodr\u00edguez", 
    "publish": "2012-01-18T15:19:03Z", 
    "summary": "In this paper, we present a novel, learning-based, two-step super-resolution\n(SR) algorithm well suited to solve the specially demanding problem of\nobtaining SR estimates from short image sequences. The first step, devoted to\nincrease the sampling rate of the incoming images, is performed by fitting\nlinear combinations of functions generated from principal components (PC) to\nreproduce locally the sparse projected image data, and using these models to\nestimate image values at nodes of the high-resolution grid. PCs were obtained\nfrom local image patches sampled at sub-pixel level, which were generated in\nturn from a database of high-resolution images by application of a physically\nrealistic observation model. Continuity between local image models is enforced\nby minimizing an adequate functional in the space of model coefficients. The\nsecond step, dealing with restoration, is performed by a linear filter with\ncoefficients learned to restore residual interpolation artifacts in addition to\nlow-resolution blurring, providing an effective coupling between both steps of\nthe method. Results on a demanding five-image scanned sequence of graphics and\ntext are presented, showing the excellent performance of the proposed method\ncompared to several state-of-the-art two-step and Bayesian Maximum a Posteriori\nSR algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3972v1", 
    "title": "A Novel Approach to Fast Image Filtering Algorithm of Infrared Images   based on Intro Sort Algorithm", 
    "arxiv-id": "1201.3972v1", 
    "author": "Jitendra Kumar Niranjan", 
    "publish": "2012-01-19T04:57:36Z", 
    "summary": "In this study we investigate the fast image filtering algorithm based on\nIntro sort algorithm and fast noise reduction of infrared images. Main feature\nof the proposed approach is that no prior knowledge of noise required. It is\ndeveloped based on Stefan- Boltzmann law and the Fourier law. We also\ninvestigate the fast noise reduction approach that has advantage of less\ncomputation load. In addition, it can retain edges, details, text information\neven if the size of the window increases. Intro sort algorithm begins with\nQuick sort and switches to heap sort when the recursion depth exceeds a level\nbased on the number of elements being sorted. This approach has the advantage\nof fast noise reduction by reducing the comparison time. It also significantly\nspeed up the noise reduction process and can apply to real-time image\nprocessing. This approach will extend the Infrared images applications for\nmedicine and video conferencing."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.4139v1", 
    "title": "Image decomposition with anisotropic diffusion applied to leaf-texture   analysis", 
    "arxiv-id": "1201.4139v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-19T18:39:41Z", 
    "summary": "Texture analysis is an important field of investigation that has received a\ngreat deal of interest from computer vision community. In this paper, we\npropose a novel approach for texture modeling based on partial differential\nequation (PDE). Each image $f$ is decomposed into a family of derived\nsub-images. $f$ is split into the $u$ component, obtained with anisotropic\ndiffusion, and the $v$ component which is calculated by the difference between\nthe original image and the $u$ component. After enhancing the texture attribute\n$v$ of the image, Gabor features are computed as descriptors. We validate the\nproposed approach on two texture datasets with high variability. We also\nevaluate our approach on an important real-world application: leaf-texture\nanalysis. Experimental results indicate that our approach can be used to\nproduce higher classification rates and can be successfully employed for\ndifferent texture applications."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.4895v2", 
    "title": "Compressive Acquisition of Dynamic Scenes", 
    "arxiv-id": "1201.4895v2", 
    "author": "Richard G Baraniuk", 
    "publish": "2012-01-23T23:19:59Z", 
    "summary": "Compressive sensing (CS) is a new approach for the acquisition and recovery\nof sparse signals and images that enables sampling rates significantly below\nthe classical Nyquist rate. Despite significant progress in the theory and\nmethods of CS, little headway has been made in compressive video acquisition\nand recovery. Video CS is complicated by the ephemeral nature of dynamic\nevents, which makes direct extensions of standard CS imaging architectures and\nsignal models difficult. In this paper, we develop a new framework for video CS\nfor dynamic textured scenes that models the evolution of the scene as a linear\ndynamical system (LDS). This reduces the video recovery problem to first\nestimating the model parameters of the LDS from compressive measurements, and\nthen reconstructing the image frames. We exploit the low-dimensional dynamic\nparameters (the state sequence) and high-dimensional static parameters (the\nobservation matrix) of the LDS to devise a novel compressive measurement\nstrategy that measures only the dynamic part of the scene at each instant and\naccumulates measurements over time to estimate the static parameters. This\nenables us to lower the compressive measurement rate considerably. We validate\nour approach with a range of experiments involving both video recovery, sensing\nhyper-spectral data, and classification of dynamic scenes from compressive\ndata. Together, these applications demonstrate the effectiveness of the\napproach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.5227v1", 
    "title": "A New Local Adaptive Thresholding Technique in Binarization", 
    "arxiv-id": "1201.5227v1", 
    "author": "Kh. Manglem Singh", 
    "publish": "2012-01-25T10:17:30Z", 
    "summary": "Image binarization is the process of separation of pixel values into two\ngroups, white as background and black as foreground. Thresholding plays a major\nin binarization of images. Thresholding can be categorized into global\nthresholding and local thresholding. In images with uniform contrast\ndistribution of background and foreground like document images, global\nthresholding is more appropriate. In degraded document images, where\nconsiderable background noise or variation in contrast and illumination exists,\nthere exists many pixels that cannot be easily classified as foreground or\nbackground. In such cases, binarization with local thresholding is more\nappropriate. This paper describes a locally adaptive thresholding technique\nthat removes background by using local mean and mean deviation. Normally the\nlocal mean computational time depends on the window size. Our technique uses\nintegral sum image as a prior processing to calculate local mean. It does not\ninvolve calculations of standard deviations as in other local adaptive\ntechniques. This along with the fact that calculations of mean is independent\nof window size speed up the process as compared to other local thresholding\ntechniques."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1201.5404v1", 
    "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture   Models", 
    "arxiv-id": "1201.5404v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2012-01-25T22:25:27Z", 
    "summary": "A framework for adaptive and non-adaptive statistical compressive sensing is\ndeveloped, where a statistical model replaces the standard sparsity model of\nclassical compressive sensing. We propose within this framework optimal\ntask-specific sensing protocols specifically and jointly designed for\nclassification and reconstruction. A two-step adaptive sensing paradigm is\ndeveloped, where online sensing is applied to detect the signal class in the\nfirst step, followed by a reconstruction step adapted to the detected class and\nthe observed samples. The approach is based on information theory, here\ntailored for Gaussian mixture models (GMMs), where an information-theoretic\nobjective relationship between the sensed signals and a representation of the\nspecific task of interest is maximized. Experimental results using synthetic\nsignals, Landsat satellite attributes, and natural images of different sizes\nand with different noise levels show the improvements achieved using the\nproposed framework when compared to more standard sensing protocols. The\nunderlying formulation can be applied beyond GMMs, at the price of higher\nmathematical and computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1201.5938v1", 
    "title": "Comparing Methods for segmentation of Microcalcification Clusters in   Digitized Mammograms", 
    "arxiv-id": "1201.5938v1", 
    "author": "Hossein Khazaei Targhi", 
    "publish": "2012-01-28T09:51:23Z", 
    "summary": "The appearance of microcalcifications in mammograms is one of the early signs\nof breast cancer. So, early detection of microcalcification clusters (MCCs) in\nmammograms can be helpful for cancer diagnosis and better treatment of breast\ncancer. In this paper a computer method has been proposed to support\nradiologists in detection MCCs in digital mammography. First, in order to\nfacilitate and improve the detection step, mammogram images have been enhanced\nwith wavelet transformation and morphology operation. Then for segmentation of\nsuspicious MCCs, two methods have been investigated. The considered methods\nare: adaptive threshold and watershed segmentation. Finally, the detected MCCs\nareas in different algorithms will be compared to find out which segmentation\nmethod is more appropriate for extracting MCCs in mammograms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.0216v1", 
    "title": "The watershed concept and its use in segmentation : a brief history", 
    "arxiv-id": "1202.0216v1", 
    "author": "Fernand Meyer", 
    "publish": "2012-02-01T17:00:45Z", 
    "summary": "The watershed is one of the most used tools in image segmentation. We present\nhow its concept is born and developed over time. Its implementation as an\nalgorithm or a hardwired device evolved together with the technology which\nallowed it. We present also how it is used in practice, first together with\nmarkers, and later introduced in a multiscale framework, in order to produce\nnot a unique partition but a complete hierarchy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.0492v3", 
    "title": "Resolving Implementation Ambiguity and Improving SURF", 
    "arxiv-id": "1202.0492v3", 
    "author": "Peter Abeles", 
    "publish": "2012-02-02T17:10:56Z", 
    "summary": "Speeded Up Robust Features (SURF) has emerged as one of the more popular\nfeature descriptors and detectors in recent years. Performance and algorithmic\ndetails vary widely between implementations due to SURF's complexity and\nambiguities found in its description. To resolve these ambiguities, a set of\ngeneral techniques for feature stability is defined based on the smoothness\nrule. Additional improvements to SURF are proposed for speed and stability. To\nillustrate the importance of these implementation details, a performance study\nof popular SURF implementations is done. By utilizing all the suggested\nimprovements, it is possible to create a SURF implementation that is several\ntimes faster and more stable."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.0549v1", 
    "title": "Comparing Background Subtraction Algorithms and Method of Car Counting", 
    "arxiv-id": "1202.0549v1", 
    "author": "Ahmed Helmy", 
    "publish": "2012-01-29T19:19:33Z", 
    "summary": "In this paper, we compare various image background subtraction algorithms\nwith the ground truth of cars counted. We have given a sample of thousand\nimages, which are the snap shots of current traffic as records at various\nintersections and highways. We have also counted an approximate number of cars\nthat are visible in these images. In order to ascertain the accuracy of\nalgorithms to be used for the processing of million images, we compare them on\nmany metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.0609v1", 
    "title": "Wavelet-based deconvolution of ultrasonic signals in nondestructive   evaluation", 
    "arxiv-id": "1202.0609v1", 
    "author": "Manuel Rodr\u00edguez", 
    "publish": "2012-02-03T05:43:46Z", 
    "summary": "In this paper, the inverse problem of reconstructing reflectivity function of\na medium is examined within a blind deconvolution framework. The ultrasound\npulse is estimated using higher-order statistics, and Wiener filter is used to\nobtain the ultrasonic reflectivity function through wavelet-based models. A new\napproach to the parameter estimation of the inverse filtering step is proposed\nin the nondestructive evaluation field, which is based on the theory of\nFourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be\nviewed as a solution to the open problem of adaptation of the ForWaRD framework\nto perform the convolution kernel estimation and deconvolution\ninterdependently. The results indicate stable solutions of the estimated pulse\nand an improvement in the radio-frequency (RF) signal taking into account its\nsignal-to-noise ratio (SNR) and axial resolution. Simulations and experiments\nshowed that the proposed approach can provide robust and optimal estimates of\nthe reflectivity function."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.1587v1", 
    "title": "Automatic Clustering with Single Optimal Solution", 
    "arxiv-id": "1202.1587v1", 
    "author": "A. V. Dattatreya Rao", 
    "publish": "2012-02-08T03:26:01Z", 
    "summary": "Determining optimal number of clusters in a dataset is a challenging task.\nThough some methods are available, there is no algorithm that produces unique\nclustering solution. The paper proposes an Automatic Merging for Single Optimal\nSolution (AMSOS) which aims to generate unique and nearly optimal clusters for\nthe given datasets automatically. The AMSOS is iteratively merges the closest\nclusters automatically by validating with cluster validity measure to find\nsingle and nearly optimal clusters for the given data set. Experiments on both\nsynthetic and real data have proved that the proposed algorithm finds single\nand nearly optimal clustering structure in terms of number of clusters,\ncompactness and separation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.1685v1", 
    "title": "Combined Haar-Hilbert and Log-Gabor Based Iris Encoders", 
    "arxiv-id": "1202.1685v1", 
    "author": "Alina Barbulescu", 
    "publish": "2012-02-08T13:07:10Z", 
    "summary": "This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris\nrecognition performance leading to a less ambiguous biometric decision\nlandscape in which the overlap between the experimental intra- and interclass\nscore distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and\ncombined Haar-Hilbert and Log-Gabor encoders are tested here both for single\nand dual iris approach. The experimental results confirm that the best\nperformance is obtained for the dual iris approach when the iris code is\ngenerated using the combined Haar-Hilbert and Log-Gabor encoder, and when the\nmatching score fuses the information from both Haar-Hilbert and Log-Gabor\nchannels of the combined encoder."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.1943v1", 
    "title": "3D Model Assisted Image Segmentation", 
    "arxiv-id": "1202.1943v1", 
    "author": "Marcus Hutter", 
    "publish": "2012-02-09T10:53:11Z", 
    "summary": "The problem of segmenting a given image into coherent regions is important in\nComputer Vision and many industrial applications require segmenting a known\nobject into its components. Examples include identifying individual parts of a\ncomponent for process control work in a manufacturing plant and identifying\nparts of a car from a photo for automatic damage detection. Unfortunately most\nof an object's parts of interest in such applications share the same pixel\ncharacteristics, having similar colour and texture. This makes segmenting the\nobject into its components a non-trivial task for conventional image\nsegmentation algorithms. In this paper, we propose a \"Model Assisted\nSegmentation\" method to tackle this problem. A 3D model of the object is\nregistered over the given image by optimising a novel gradient based loss\nfunction. This registration obtains the full 3D pose from an image of the\nobject. The image can have an arbitrary view of the object and is not limited\nto a particular set of views. The segmentation is subsequently performed using\na level-set based method, using the projected contours of the registered 3D\nmodel as initialisation curves. The method is fully automatic and requires no\nuser interaction. Also, the system does not require any prior training. We\npresent our results on photographs of a real car."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.1990v1", 
    "title": "Non-parametric convolution based image-segmentation of ill-posed objects   applying context window approach", 
    "arxiv-id": "1202.1990v1", 
    "author": "Manoj Kumar Pal", 
    "publish": "2012-02-09T14:02:26Z", 
    "summary": "Context-dependence in human cognition process is a well-established fact.\nFollowing this, we introduced the image segmentation method that can use\ncontext to classify a pixel on the basis of its membership to a particular\nobject-class of the concerned image. In the broad methodological steps, each\npixel was defined by its context window (CW) surrounding it the size of which\nwas fixed heuristically. CW texture defined by the intensities of its pixels\nwas convoluted with weights optimized through a non-parametric function\nsupported by a backpropagation network. Result of convolution was used to\nclassify them. The training data points (i.e., pixels) were carefully chosen to\ninclude all variety of contexts of types, i) points within the object, ii)\npoints near the edge but inside the objects, iii) points at the border of the\nobjects, iv) points near the edge but outside the objects, v) points near or at\nthe edge of the image frame. Moreover the training data points were selected\nfrom all the images within image-dataset. CW texture information for 1000\npixels from face area and background area of images were captured, out of which\n700 CWs were used as training input data, and remaining 300 for testing. Our\nwork gives the first time foundation of quantitative enumeration of efficiency\nof image-segmentation which is extendable to segment out more than 2 objects\nwithin an image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1202.2528v1", 
    "title": "Using Covariance Matrices as Feature Descriptors for Vehicle Detection   from a Fixed Camera", 
    "arxiv-id": "1202.2528v1", 
    "author": "Gil Reese", 
    "publish": "2012-02-12T13:40:11Z", 
    "summary": "A method is developed to distinguish between cars and trucks present in a\nvideo feed of a highway. The method builds upon previously done work using\ncovariance matrices as an accurate descriptor for regions. Background\nsubtraction and other similar proven image processing techniques are used to\nidentify the regions where the vehicles are most likely to be, and a distance\nmetric comparing the vehicle inside the region to a fixed library of vehicles\nis used to determine the class of vehicle."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.3021v1", 
    "title": "No-reference image quality assessment through the von Mises distribution", 
    "arxiv-id": "1202.3021v1", 
    "author": "Gabriel Cristobal", 
    "publish": "2012-02-14T12:50:35Z", 
    "summary": "An innovative way of calculating the von Mises distribution (VMD) of image\nentropy is introduced in this paper. The VMD's concentration parameter and some\nfitness parameter that will be later defined, have been analyzed in the\nexperimental part for determining their suitability as a image quality\nassessment measure in some particular distortions such as Gaussian blur or\nadditive Gaussian noise. To achieve such measure, the local R\\'{e}nyi entropy\nis calculated in four equally spaced orientations and used to determine the\nparameters of the von Mises distribution of the image entropy. Considering\ncontextual images, experimental results after applying this model show that the\nbest-in-focus noise-free images are associated with the highest values for the\nvon Mises distribution concentration parameter and the highest approximation of\nimage data to the von Mises distribution model. Our defined von Misses fitness\nparameter experimentally appears also as a suitable no-reference image quality\nassessment indicator for no-contextual images."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.3684v1", 
    "title": "Generalized Boundaries from Multiple Image Interpretations", 
    "arxiv-id": "1202.3684v1", 
    "author": "Cristian Sminchisescu", 
    "publish": "2012-02-16T20:08:11Z", 
    "summary": "Boundary detection is essential for a variety of computer vision tasks such\nas segmentation and recognition. In this paper we propose a unified formulation\nand a novel algorithm that are applicable to the detection of different types\nof boundaries, such as intensity edges, occlusion boundaries or object category\nspecific boundaries. Our formulation leads to a simple method with\nstate-of-the-art performance and significantly lower computational cost than\nexisting methods. We evaluate our algorithm on different types of boundaries,\nfrom low-level boundaries extracted in natural images, to occlusion boundaries\nobtained using motion cues and RGB-D cameras, to boundaries from\nsoft-segmentation. We also propose a novel method for figure/ground\nsoft-segmentation that can be used in conjunction with our boundary detection\nmethod and improve its accuracy at almost no extra computational cost."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.3884v1", 
    "title": "A feature extraction technique based on character geometry for character   recognition", 
    "arxiv-id": "1202.3884v1", 
    "author": "Renu Ramesh", 
    "publish": "2012-02-17T11:41:28Z", 
    "summary": "This paper describes a geometry based technique for feature extraction\napplicable to segmentation-based word recognition systems. The proposed system\nextracts the geometric features of the character contour. This features are\nbased on the basic line types that forms the character skeleton. The system\ngives a feature vector as its output. The feature vectors so generated from a\ntraining set, were then used to train a pattern recognition engine based on\nNeural Networks so that the system can be benchmarked."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.4107v1", 
    "title": "Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin   Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition   of Whale Images on a Network)", 
    "arxiv-id": "1202.4107v1", 
    "author": "Scott A. Hale", 
    "publish": "2012-02-18T21:42:24Z", 
    "summary": "At least two software packages---DARWIN, Eckerd College, and FinScan, Texas\nA&M---exist to facilitate the identification of cetaceans---whales, dolphins,\nporpoises---based upon the naturally occurring features along the edges of\ntheir dorsal fins. Such identification is useful for biological studies of\npopulation, social interaction, migration, etc. The process whereby fin\noutlines are extracted in current fin-recognition software packages is manually\nintensive and represents a major user input bottleneck: it is both time\nconsuming and visually fatiguing. This research aims to develop automated\nmethods (employing unsupervised thresholding and morphological processing\ntechniques) to extract cetacean dorsal fin outlines from digital photographs\nthereby reducing manual user input. Ideally, automatic outline generation will\nimprove the overall user experience and improve the ability of the software to\ncorrectly identify cetaceans. Various transformations from color to gray space\nwere examined to determine which produced a grayscale image in which a suitable\nthreshold could be easily identified. To assist with unsupervised thresholding,\na new metric was developed to evaluate the jaggedness of figures (\"pixelarity\")\nin an image after thresholding. The metric indicates how cleanly a threshold\nsegments background and foreground elements and hence provides a good measure\nof the quality of a given threshold. This research results in successful\nextractions in roughly 93% of images, and significantly reduces user-input\ntime."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2235849", 
    "link": "http://arxiv.org/pdf/1202.4207v2", 
    "title": "Regularized Robust Coding for Face Recognition", 
    "arxiv-id": "1202.4207v2", 
    "author": "David Zhang", 
    "publish": "2012-02-20T02:02:26Z", 
    "summary": "Recently the sparse representation based classification (SRC) has been\nproposed for robust face recognition (FR). In SRC, the testing image is coded\nas a sparse linear combination of the training samples, and the representation\nfidelity is measured by the l2-norm or l1-norm of the coding residual. Such a\nsparse coding model assumes that the coding residual follows Gaussian or\nLaplacian distribution, which may not be effective enough to describe the\ncoding residual in practical FR systems. Meanwhile, the sparsity constraint on\nthe coding coefficients makes SRC's computational cost very high. In this\npaper, we propose a new face coding model, namely regularized robust coding\n(RRC), which could robustly regress a given signal with regularized regression\ncoefficients. By assuming that the coding residual and the coding coefficient\nare respectively independent and identically distributed, the RRC seeks for a\nmaximum a posterior solution of the coding problem. An iteratively reweighted\nregularized robust coding (IR3C) algorithm is proposed to solve the RRC model\nefficiently. Extensive experiments on representative face databases demonstrate\nthat the RRC is much more effective and efficient than state-of-the-art sparse\nrepresentation based methods in dealing with face occlusion, corruption,\nlighting and expression changes, etc."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2235849", 
    "link": "http://arxiv.org/pdf/1202.4237v1", 
    "title": "A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP", 
    "arxiv-id": "1202.4237v1", 
    "author": "Qiyang Zhao", 
    "publish": "2012-02-20T06:56:26Z", 
    "summary": "Color image segmentation is an important topic in the image processing field.\nMRF-MAP is often adopted in the unsupervised segmentation methods, but their\nperformance are far behind recent interactive segmentation tools supervised by\nuser inputs. Furthermore, the existing related unsupervised methods also suffer\nfrom the low efficiency, and high risk of being trapped in the local optima,\nbecause MRF-MAP is currently solved by iterative frameworks with inaccurate\ninitial color distribution models. To address these problems, the letter\ndesigns an efficient method to calculate the energy functions approximately in\nthe non-iteration style, and proposes a new binary segmentation algorithm based\non the slightly tuned Lanczos eigensolver. The experiments demonstrate that the\nnew algorithm achieves competitive performance compared with two state-of-art\nsegmentation methods."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1202.4495v1", 
    "title": "Stochastic-Based Pattern Recognition Analysis", 
    "arxiv-id": "1202.4495v1", 
    "author": "J. L. Rossell\u00f3", 
    "publish": "2012-02-20T23:48:38Z", 
    "summary": "In this work we review the basic principles of stochastic logic and propose\nits application to probabilistic-based pattern-recognition analysis. The\nproposed technique is intrinsically a parallel comparison of input data to\nvarious pre-stored categories using Bayesian techniques. We design smart\npulse-based stochastic-logic blocks to provide an efficient pattern recognition\nanalysis. The proposed rchitecture is applied to a specific navigation problem.\nThe resulting system is orders of magnitude faster than processor-based\nsolutions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1202.6384v1", 
    "title": "Fast approximations to structured sparse coding and applications to   object classification", 
    "arxiv-id": "1202.6384v1", 
    "author": "Yann LeCun", 
    "publish": "2012-02-28T21:27:14Z", 
    "summary": "We describe a method for fast approximation of sparse coding. The input space\nis subdivided by a binary decision tree, and we simultaneously learn a\ndictionary and assignment of allowed dictionary elements for each leaf of the\ntree. We store a lookup table with the assignments and the pseudoinverses for\neach node, allowing for very fast inference. We give an algorithm for learning\nthe tree, the dictionary and the dictionary element assignment, and In the\nprocess of describing this algorithm, we discuss the more general problem of\nlearning the groups in group structured sparse modelling. We show that our\nmethod creates good sparse representations by using it in the object\nrecognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own\nfast version of the SIFT descriptor the whole system runs at 20 frames per\nsecond on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while\nsacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1202.6586v1", 
    "title": "Filling-Based Techniques Applied to Object Projection Feature Estimation", 
    "arxiv-id": "1202.6586v1", 
    "author": "Alejandro J. Le\u00f3n", 
    "publish": "2012-02-29T16:10:10Z", 
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting object projection feature estimation techniques are based on\nray-casting from the inner point. These techniques present three main\ndrawbacks: when the inner point is surrounded by edges, rays may not reach\nother relevant areas; as a consequence of that issue, the estimated features\nmay greatly vary depending on the position of the inner point relative to the\nobject projection; and finally, increasing the number of rays being casted and\nthe ray-casting iterations (which would make the results more accurate and\nstable) increases the processing time to the point the tracking cannot be\nperformed on the fly. In this paper, we analyze an intuitive filling-based\nobject projection feature estimation technique that solves the aforementioned\nproblems but is too sensitive to edge miscalculations. Then, we propose a less\ncomputing-intensive modification to that technique that would not be affected\nby the existing techniques issues and would be no more sensitive to edge\nmiscalculations than ray-casting-based techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1203.0076v1", 
    "title": "Using Barriers to Reduce the Sensitivity to Edge Miscalculations of   Casting-Based Object Projection Feature Estimation", 
    "arxiv-id": "1203.0076v1", 
    "author": "Luis Quesada", 
    "publish": "2012-03-01T02:32:28Z", 
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting reliable object projection feature estimation techniques are based on\nray-casting or grid-filling from the inner point. These techniques assume the\nedge image to be accurate. However, in real case scenarios, edge\nmiscalculations may arise from low contrast between the target object and its\nsurroundings or motion blur caused by low frame rates or fast moving target\nobjects. In this paper, we propose a barrier extension to casting-based\ntechniques that mitigates the effect of edge miscalculations."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1203.0265v1", 
    "title": "Image Fusion and Re-Modified SPIHT for Fused Image", 
    "arxiv-id": "1203.0265v1", 
    "author": "B. Thilakavathi", 
    "publish": "2012-02-29T17:57:12Z", 
    "summary": "This paper presents the Discrete Wavelet based fusion techniques for\ncombining perceptually important image features. SPIHT (Set Partitioning in\nHierarchical Trees) algorithm is an efficient method for lossy and lossless\ncoding of fused image. This paper presents some modifications on the SPIHT\nalgorithm. It is based on the idea of insignificant correlation of wavelet\ncoefficient among the medium and high frequency sub bands. In RE-MSPIHT\nalgorithm, wavelet coefficients are scaled prior to SPIHT coding based on the\nsub band importance, with the goal of minimizing the MSE."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1203.0744v1", 
    "title": "A Report on Multilinear PCA Plus Multilinear LDA to Deal with Tensorial   Data: Visual Classification as An Example", 
    "arxiv-id": "1203.0744v1", 
    "author": "Donghui Wang", 
    "publish": "2012-03-04T15:00:16Z", 
    "summary": "In practical applications, we often have to deal with high order data, such\nas a grayscale image and a video sequence are intrinsically 2nd-order tensor\nand 3rd-order tensor, respectively. For doing clustering or classification of\nthese high order data, it is a conventional way to vectorize these data before\nhand, as PCA or FDA does, which often induce the curse of dimensionality\nproblem. For this reason, experts have developed many methods to deal with the\ntensorial data, such as multilinear PCA, multilinear LDA, and so on. In this\npaper, we still address the problem of high order data representation and\nrecognition, and propose to study the result of merging multilinear PCA and\nmultilinear LDA into one scenario, we name it \\textbf{GDA} for the abbreviation\nof Generalized Discriminant Analysis. To evaluate GDA, we perform a series of\nexperiments, and the experimental results demonstrate our GDA outperforms a\nselection of competing methods such (2D)$^2$PCA, (2D)$^2$LDA, and MDA."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1203.0781v3", 
    "title": "Posterior Mean Super-Resolution with a Compound Gaussian Markov Random   Field Prior", 
    "arxiv-id": "1203.0781v3", 
    "author": "Masato Inoue", 
    "publish": "2012-03-04T22:12:54Z", 
    "summary": "This manuscript proposes a posterior mean (PM) super-resolution (SR) method\nwith a compound Gaussian Markov random field (MRF) prior. SR is a technique to\nestimate a spatially high-resolution image from observed multiple\nlow-resolution images. A compound Gaussian MRF model provides a preferable\nprior for natural images that preserves edges. PM is the optimal estimator for\nthe objective function of peak signal-to-noise ratio (PSNR). This estimator is\nnumerically determined by using variational Bayes (VB). We then solve the\nconjugate prior problem on VB and the exponential-order calculation cost\nproblem of a compound Gaussian MRF prior with simple Taylor approximations. In\nexperiments, the proposed method roughly overcomes existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1203.0856v1", 
    "title": "Online Discriminative Dictionary Learning for Image Classification Based   on Block-Coordinate Descent Method", 
    "arxiv-id": "1203.0856v1", 
    "author": "Donghui Wang", 
    "publish": "2012-03-05T10:43:15Z", 
    "summary": "Previous researches have demonstrated that the framework of dictionary\nlearning with sparse coding, in which signals are decomposed as linear\ncombinations of a few atoms of a learned dictionary, is well adept to\nreconstruction issues. This framework has also been used for discrimination\ntasks such as image classification. To achieve better performances of\nclassification, experts develop several methods to learn a discriminative\ndictionary in a supervised manner. However, another issue is that when the data\nbecome extremely large in scale, these methods will be no longer effective as\nthey are all batch-oriented approaches. For this reason, we propose a novel\nonline algorithm for discriminative dictionary learning, dubbed \\textbf{ODDL}\nin this paper. First, we introduce a linear classifier into the conventional\ndictionary learning formulation and derive a discriminative dictionary learning\nproblem. Then, we exploit an online algorithm to solve the derived problem.\nUnlike the most existing approaches which update dictionary and classifier\nalternately via iteratively solving sub-problems, our approach directly\nexplores them jointly. Meanwhile, it can largely shorten the runtime for\ntraining and is also particularly suitable for large-scale classification\nissues. To evaluate the performance of the proposed ODDL approach in image\nrecognition, we conduct some experiments on three well-known benchmarks, and\nthe experimental results demonstrate ODDL is fairly promising for image\nclassification tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0492-5", 
    "link": "http://arxiv.org/pdf/1203.0905v2", 
    "title": "Autocalibration with the Minimum Number of Cameras with Known Pixel   Shape", 
    "arxiv-id": "1203.0905v2", 
    "author": "Guillermo Gallego", 
    "publish": "2012-03-05T13:18:44Z", 
    "summary": "In 3D reconstruction, the recovery of the calibration parameters of the\ncameras is paramount since it provides metric information about the observed\nscene, e.g., measures of angles and ratios of distances. Autocalibration\nenables the estimation of the camera parameters without using a calibration\ndevice, but by enforcing simple constraints on the camera parameters. In the\nabsence of information about the internal camera parameters such as the focal\nlength and the principal point, the knowledge of the camera pixel shape is\nusually the only available constraint. Given a projective reconstruction of a\nrigid scene, we address the problem of the autocalibration of a minimal set of\ncameras with known pixel shape and otherwise arbitrarily varying intrinsic and\nextrinsic parameters. We propose an algorithm that only requires 5 cameras (the\ntheoretical minimum), thus halving the number of cameras required by previous\nalgorithms based on the same constraint. To this purpose, we introduce as our\nbasic geometric tool the six-line conic variety (SLCV), consisting in the set\nof planes intersecting six given lines of 3D space in points of a conic. We\nshow that the set of solutions of the Euclidean upgrading problem for three\ncameras with known pixel shape can be parameterized in a computationally\nefficient way. This parameterization is then used to solve autocalibration from\nfive or more cameras, reducing the three-dimensional search space to a\ntwo-dimensional one. We provide experiments with real images showing the good\nperformance of the technique."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0492-5", 
    "link": "http://arxiv.org/pdf/1203.1513v2", 
    "title": "Invariant Scattering Convolution Networks", 
    "arxiv-id": "1203.1513v2", 
    "author": "St\u00e9phane Mallat", 
    "publish": "2012-03-05T17:12:42Z", 
    "summary": "A wavelet scattering network computes a translation invariant image\nrepresentation, which is stable to deformations and preserves high frequency\ninformation for classification. It cascades wavelet transform convolutions with\nnon-linear modulus and averaging operators. The first network layer outputs\nSIFT-type descriptors whereas the next layers provide complementary invariant\ninformation which improves classification. The mathematical analysis of wavelet\nscattering networks explains important properties of deep convolution networks\nfor classification.\n  A scattering representation of stationary processes incorporates higher order\nmoments and can thus discriminate textures having the same Fourier power\nspectrum. State of the art classification results are obtained for handwritten\ndigits and texture discrimination, using a Gaussian kernel SVM and a generative\nPCA classifier."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3102", 
    "link": "http://arxiv.org/pdf/1203.1765v1", 
    "title": "A comparative evaluation of two algorithms of detection of masses on   mammograms", 
    "arxiv-id": "1203.1765v1", 
    "author": "John Ngundam", 
    "publish": "2012-03-08T12:07:27Z", 
    "summary": "In this paper, we implement and carry out the comparison of two methods of\ncomputer-aided-detection of masses on mammograms. The two algorithms basically\nconsist of 3 steps each: segmentation, binarization and noise suppression using\ndifferent techniques for each step. A database of 60 images was used to compare\nthe performance of the two algorithms in terms of general detection efficiency,\nconservation of size and shape of detected masses."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3102", 
    "link": "http://arxiv.org/pdf/1203.1985v1", 
    "title": "Substructure and Boundary Modeling for Continuous Action Recognition", 
    "arxiv-id": "1203.1985v1", 
    "author": "Thomas Huang", 
    "publish": "2012-03-09T04:16:33Z", 
    "summary": "This paper introduces a probabilistic graphical model for continuous action\nrecognition with two novel components: substructure transition model and\ndiscriminative boundary model. The first component encodes the sparse and\nglobal temporal transition prior between action primitives in state-space model\nto handle the large spatial-temporal variations within an action class. The\nsecond component enforces the action duration constraint in a discriminative\nway to locate the transition boundaries between actions more accurately. The\ntwo components are integrated into a unified graphical structure to enable\neffective training and inference. Our comprehensive experimental results on\nboth public and in-house datasets show that, with the capability to incorporate\nadditional information that had not been explicitly or efficiently modeled by\nprevious methods, our proposed algorithm achieved significantly improved\nperformance for continuous action recognition."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3102", 
    "link": "http://arxiv.org/pdf/1203.2404v1", 
    "title": "Video Object Tracking and Analysis for Computer Assisted Surgery", 
    "arxiv-id": "1203.2404v1", 
    "author": "Tessamma Thomas", 
    "publish": "2012-03-12T05:39:34Z", 
    "summary": "Pedicle screw insertion technique has made revolution in the surgical\ntreatment of spinal fractures and spinal disorders. Although X- ray fluoroscopy\nbased navigation is popular, there is risk of prolonged exposure to X- ray\nradiation. Systems that have lower radiation risk are generally quite\nexpensive. The position and orientation of the drill is clinically very\nimportant in pedicle screw fixation. In this paper, the position and\norientation of the marker on the drill is determined using pattern recognition\nbased methods, using geometric features, obtained from the input video sequence\ntaken from CCD camera. A search is then performed on the video frames after\npreprocessing, to obtain the exact position and orientation of the drill.\nAnimated graphics, showing the instantaneous position and orientation of the\ndrill is then overlaid on the processed video for real time drill control and\nnavigation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2012.4103", 
    "link": "http://arxiv.org/pdf/1203.2514v1", 
    "title": "Enhancement of Images using Morphological Transformation", 
    "arxiv-id": "1203.2514v1", 
    "author": "B. Panlal", 
    "publish": "2012-03-09T13:22:25Z", 
    "summary": "This paper deals with enhancement of images with poor contrast and detection\nof background. Proposes a frame work which is used to detect the background in\nimages characterized by poor contrast. Image enhancement has been carried out\nby the two methods based on the Weber's law notion. The first method employs\ninformation from image background analysis by blocks, while the second\ntransformation method utilizes the opening operation, closing operation, which\nis employed to define the multi-background gray scale images. The complete\nimage processing is done using MATLAB simulation model. Finally, this paper is\norganized as follows as Morphological transformation and Weber's law. Image\nbackground approximation to the background by means of block analysis in\nconjunction with transformations that enhance images with poor lighting. The\nmultibackground notion is introduced by means of the opening by reconstruction\nshows a comparison among several techniques to improve contrast in images.\nFinally, conclusions are presented."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.2839v1", 
    "title": "Square-Cut: A Segmentation Algorithm on the Basis of a Rectangle Shape", 
    "arxiv-id": "1203.2839v1", 
    "author": "Christopher Nimsky", 
    "publish": "2012-03-13T15:41:14Z", 
    "summary": "We present a rectangle-based segmentation algorithm that sets up a graph and\nperforms a graph cut to separate an object from the background. However,\ngraph-based algorithms distribute the graph's nodes uniformly and equidistantly\non the image. Then, a smoothness term is added to force the cut to prefer a\nparticular shape. This strategy does not allow the cut to prefer a certain\nstructure, especially when areas of the object are indistinguishable from the\nbackground. We solve this problem by referring to a rectangle shape of the\nobject when sampling the graph nodes, i.e., the nodes are distributed\nnonuniformly and non-equidistantly on the image. This strategy can be useful,\nwhen areas of the object are indistinguishable from the background. For\nevaluation, we focus on vertebrae images from Magnetic Resonance Imaging (MRI)\ndatasets to support the time consuming manual slice-by-slice segmentation\nperformed by physicians. The ground truth of the vertebrae boundaries were\nmanually extracted by two clinical experts (neurological surgeons) with several\nyears of experience in spine surgery and afterwards compared with the automatic\nsegmentation results of the proposed scheme yielding an average Dice Similarity\nCoefficient (DSC) of 90.97\\pm62.2%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3114v1", 
    "title": "Integrated three-dimensional reconstruction using reflectance fields", 
    "arxiv-id": "1203.3114v1", 
    "author": "Miguel-Octavio Arias", 
    "publish": "2012-03-14T15:31:16Z", 
    "summary": "A method to obtain three-dimensional data of real-world objects by\nintegrating their material properties is presented. The material properties are\ndefined by capturing the Reflectance Fields of the real-world objects. It is\nshown, unlike conventional reconstruction methods, the method is able to use\nthe reflectance information to recover surface depth for objects having a\nnon-Lambertian surface reflectance. It is, for recovering 3D data of objects\nexhibiting an anisotropic BRDF with an error less than 0.3%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3170v1", 
    "title": "Single Reduct Generation Based on Relative Indiscernibility of Rough Set   Theory", 
    "arxiv-id": "1203.3170v1", 
    "author": "Asit Kr. Das", 
    "publish": "2012-03-14T18:34:05Z", 
    "summary": "In real world everything is an object which represents particular classes.\nEvery object can be fully described by its attributes. Any real world dataset\ncontains large number of attributes and objects. Classifiers give poor\nperformance when these huge datasets are given as input to it for proper\nclassification. So from these huge dataset most useful attributes need to be\nextracted that contribute the maximum to the decision. In the paper, attribute\nset is reduced by generating reducts using the indiscernibility relation of\nRough Set Theory (RST). The method measures similarity among the attributes\nusing relative indiscernibility relation and computes attribute similarity set.\nThen the set is minimized and an attribute similarity table is constructed from\nwhich attribute similar to maximum number of attributes is selected so that the\nresultant minimum set of selected attributes (called reduct) cover all\nattributes of the attribute similarity table. The method has been applied on\nglass dataset collected from the UCI repository and the classification accuracy\nis calculated by various classifiers. The result shows the efficiency of the\nproposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3230v1", 
    "title": "Reconstruction error in a motion capture system", 
    "arxiv-id": "1203.3230v1", 
    "author": "Angelo Cenedese", 
    "publish": "2012-03-14T22:46:29Z", 
    "summary": "Marker-based motion capture (MoCap) systems can be composed by several dozens\nof cameras with the purpose of reconstructing the trajectories of hundreds of\ntargets. With a large amount of cameras it becomes interesting to determine the\noptimal reconstruction strategy. For such aim it is of fundamental importance\nto understand the information provided by different camera measurements and how\nthey are combined, i.e. how the reconstruction error changes by considering\ndifferent cameras. In this work, first, an approximation of the reconstruction\nerror variance is derived. The results obtained in some simulations suggest\nthat the proposed strategy allows to obtain a good approximation of the real\nerror variance with significant reduction of the computational time."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3270v1", 
    "title": "Extraction of Facial Feature Points Using Cumulative Histogram", 
    "arxiv-id": "1203.3270v1", 
    "author": "Saida Bouakaz", 
    "publish": "2012-03-15T05:20:27Z", 
    "summary": "This paper proposes a novel adaptive algorithm to extract facial feature\npoints automatically such as eyebrows corners, eyes corners, nostrils, nose\ntip, and mouth corners in frontal view faces, which is based on cumulative\nhistogram approach by varying different threshold values. At first, the method\nadopts the Viola-Jones face detector to detect the location of face and also\ncrops the face region in an image. From the concept of the human face\nstructure, the six relevant regions such as right eyebrow, left eyebrow, right\neye, left eye, nose, and mouth areas are cropped in a face image. Then the\nhistogram of each cropped relevant region is computed and its cumulative\nhistogram value is employed by varying different threshold values to create a\nnew filtering image in an adaptive way. The connected component of interested\narea for each relevant filtering image is indicated our respective feature\nregion. A simple linear search algorithm for eyebrows, eyes and mouth filtering\nimages and contour algorithm for nose filtering image are applied to extract\nour desired corner points automatically. The method was tested on a large BioID\nfrontal face database in different illuminations, expressions and lighting\nconditions and the experimental results have achieved average success rates of\n95.27%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.4204v1", 
    "title": "Clustering Using Isoperimetric Number of Trees", 
    "arxiv-id": "1203.4204v1", 
    "author": "Basir Shariat Razavi", 
    "publish": "2012-03-19T19:15:25Z", 
    "summary": "In this paper we propose a graph-based data clustering algorithm which is\nbased on exact clustering of a minimum spanning tree in terms of a minimum\nisoperimetry criteria. We show that our basic clustering algorithm runs in $O(n\n\\log n)$ and with post-processing in $O(n^2)$ (worst case) time where $n$ is\nthe size of the data set. We also show that our generalized graph model which\nalso allows the use of potentials at vertices can be used to extract a more\ndetailed pack of information as the {\\it outlier profile} of the data set. In\nthis direction we show that our approach can be used to define the concept of\nan outlier-set in a precise way and we propose approximation algorithms for\nfinding such sets. We also provide a comparative performance analysis of our\nalgorithm with other related ones and we show that the new clustering algorithm\n(without the outlier extraction procedure) behaves quite effectively even on\nhard benchmarks and handmade examples."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.4874v1", 
    "title": "A Co-Prime Blur Scheme for Data Security in Video Surveillance", 
    "arxiv-id": "1203.4874v1", 
    "author": "Jingyi Yu", 
    "publish": "2012-03-22T02:57:53Z", 
    "summary": "This paper presents a novel Coprime Blurred Pair (CBP) model for visual\ndata-hiding for security in camera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream, we introduce a spatial\nencryption scheme by blurring the image/video contents to create a CBP. Our\ngoal is to obscure detail in public video streams by blurring while allowing\nbehavior to be recognized and to quickly deblur the stream so that details are\navailable if behavior is recognized as suspicious. We create a CBP by blurring\nthe same latent image with two unknown kernels. The two kernels are coprime\nwhen mapped to bivariate polynomials in the z domain. To deblur the CBP we\nfirst use the coprime constraint to approximate the kernels and sample the\nbivariate CBP polynomials in one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose the results into a 2D\nkernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of\nthe kernel matrices to recover the coprime kernels and then the latent video\nstream. It is therefore only possible to deblur the video stream if a user has\naccess to both streams. To improve the practicability of our algorithm, we\nimplement our algorithm using a graphics processing unit (GPU) to decrypt the\nblurred video streams in real-time, and extensive experimental results\ndemonstrate that our new scheme can effectively protect sensitive identity\ninformation in surveillance videos and faithfully reconstruct the unblurred\nvideo stream when two blurred sequences are available."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.5078v1", 
    "title": "Kernel Density Feature Points Estimator for Content-Based Image   Retrieval", 
    "arxiv-id": "1203.5078v1", 
    "author": "Seleman M. Ngwira", 
    "publish": "2012-03-22T18:47:57Z", 
    "summary": "Research is taking place to find effective algorithms for content-based image\nrepresentation and description. There is a substantial amount of algorithms\navailable that use visual features (color, shape, texture). Shape feature has\nattracted much attention from researchers that there are many shape\nrepresentation and description algorithms in literature. These shape image\nrepresentation and description algorithms are usually not application\nindependent or robust, making them undesirable for generic shape description.\nThis paper presents an object shape representation using Kernel Density Feature\nPoints Estimator (KDFPE). In this method, the density of feature points within\ndefined rings around the centroid of the image is obtained. The KDFPE is then\napplied to the vector of the image. KDFPE is invariant to translation, scale\nand rotation. This method of image representation shows improved retrieval rate\nwhen compared to Density Histogram Feature Points (DHFP) method. Analytic\nanalysis is done to justify our method, which was compared with the DHFP to\nprove its robustness."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.6329v2", 
    "title": "Analysis of Magnification in Depth from Defocus", 
    "arxiv-id": "1203.6329v2", 
    "author": "Arnav Bhavsar", 
    "publish": "2012-03-28T18:16:46Z", 
    "summary": "In depth from defocus (DFD), when images are captured with different camera\nparameters, a relative magnification is induced between them. Image warping is\na simpler solution to account for magnification than seemingly more accurate\noptical approaches. This work is an investigation into the effects of\nmagnification on the accuracy of DFD. We comment on issues regarding scaling\neffect on relative blur computation. We statistically analyze accountability of\nscale factor, commenting on the bias and efficiency of the estimator that does\nnot consider scale. We also discuss the effect of interpolation errors on blur\nestimation in a warping based solution to handle magnification and carry out\nexperimental analysis to comment on the blur estimation accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.6722v1", 
    "title": "Face Expression Recognition and Analysis: The State of the Art", 
    "arxiv-id": "1203.6722v1", 
    "author": "Vinay Bettadapura", 
    "publish": "2012-03-30T05:47:59Z", 
    "summary": "The automatic recognition of facial expressions has been an active research\ntopic since the early nineties. There have been several advances in the past\nfew years in terms of face detection and tracking, feature extraction\nmechanisms and the techniques used for expression classification. This paper\nsurveys some of the published work since 2001 till date. The paper presents a\ntime-line view of the advances made in this field, the applications of\nautomatic face expression recognizers, the characteristics of an ideal system,\nthe databases that have been used and the advances made in terms of their\nstandardization and a detailed summary of the state of the art. The paper also\ndiscusses facial parameterization using FACS Action Units (AUs) and MPEG-4\nFacial Animation Parameters (FAPs) and the recent advances in face detection,\ntracking and feature extraction methods. Notes have also been presented on\nemotions, expressions and facial features, discussion on the six prototypic\nexpressions and the recent studies on expression classifiers. The paper ends\nwith a note on the challenges and the future work. This paper has been written\nin a tutorial style with the intention of helping students and researchers who\nare new to this field."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3208", 
    "link": "http://arxiv.org/pdf/1205.1644v1", 
    "title": "DBC based Face Recognition using DWT", 
    "arxiv-id": "1205.1644v1", 
    "author": "K B Raja", 
    "publish": "2012-05-08T09:44:03Z", 
    "summary": "The applications using face biometric has proved its reliability in last\ndecade. In this paper, we propose DBC based Face Recognition using DWT (DBC-\nFR) model. The Poly-U Near Infra Red (NIR) database images are scanned and\ncropped to get only the face part in pre-processing. The face part is resized\nto 100*100 and DWT is applied to derive LL, LH, HL and HH subbands. The LL\nsubband of size 50*50 is converted into 100 cells with 5*5 dimention of each\ncell. The Directional Binary Code (DBC) is applied on each 5*5 cell to derive\n100 features. The Euclidian distance measure is used to compare the features of\ntest image and database images. The proposed algorithm render better percentage\nrecognition rate compared to the existing algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.2031v1", 
    "title": "M-FISH Karyotyping - A New Approach Based on Watershed Transform", 
    "arxiv-id": "1205.2031v1", 
    "author": "V. K. Govindan", 
    "publish": "2012-05-09T16:52:23Z", 
    "summary": "Karyotyping is a process in which chromosomes in a dividing cell are properly\nstained, identified and displayed in a standard format, which helps geneticist\nto study and diagnose genetic factors behind various genetic diseases and for\nstudying cancer. M-FISH (Multiplex Fluorescent In-Situ Hybridization) provides\ncolor karyotyping. In this paper, an automated method for M-FISH chromosome\nsegmentation based on watershed transform followed by naive Bayes\nclassification of each region using the features, mean and standard deviation,\nis presented. Also, a post processing step is added to re-classify the small\nchromosome segments to the neighboring larger segment for reducing the chances\nof misclassification. The approach provided improved accuracy when compared to\nthe pixel-by-pixel approach. The approach was tested on 40 images from the\ndataset and achieved an accuracy of 84.21 %."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.2164v1", 
    "title": "Discrimination of English to other Indian languages (Kannada and Hindi)   for OCR system", 
    "arxiv-id": "1205.2164v1", 
    "author": "Vivek Kr Verma", 
    "publish": "2012-05-10T06:14:51Z", 
    "summary": "India is a multilingual multi-script country. In every state of India there\nare two languages one is state local language and the other is English. For\nexample in Andhra Pradesh, a state in India, the document may contain text\nwords in English and Telugu script. For Optical Character Recognition (OCR) of\nsuch a bilingual document, it is necessary to identify the script before\nfeeding the text words to the OCRs of individual scripts. In this paper, we are\nintroducing a simple and efficient technique of script identification for\nKannada, English and Hindi text words of a printed document. The proposed\napproach is based on the horizontal and vertical projection profile for the\ndiscrimination of the three scripts. The feature extraction is done based on\nthe horizontal projection profile of each text words. We analysed 700 different\nwords of Kannada, English and Hindi in order to extract the discrimination\nfeatures and for the development of knowledge base. We use the horizontal\nprojection profile of each text word and based on the horizontal projection\nprofile we extract the appropriate features. The proposed system is tested on\n100 different document images containing more than 1000 text words of each\nscript and a classification rate of 98.25%, 99.25% and 98.87% is achieved for\nKannada, English and Hindi respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.2663v1", 
    "title": "Are visual dictionaries generalizable?", 
    "arxiv-id": "1205.2663v1", 
    "author": "Ricardo da S. Torres", 
    "publish": "2012-05-11T18:54:12Z", 
    "summary": "Mid-level features based on visual dictionaries are today a cornerstone of\nsystems for classification and retrieval of images. Those state-of-the-art\nrepresentations depend crucially on the choice of a codebook (visual\ndictionary), which is usually derived from the dataset. In general-purpose,\ndynamic image collections (e.g., the Web), one cannot have the entire\ncollection in order to extract a representative dictionary. However, based on\nthe hypothesis that the dictionary reflects only the diversity of low-level\nappearances and does not capture semantics, we argue that a dictionary based on\na small subset of the data, or even on an entirely different dataset, is able\nto produce a good representation, provided that the chosen images span a\ndiverse enough portion of the low-level feature space. Our experiments confirm\nthat hypothesis, opening the opportunity to greatly alleviate the burden in\ngenerating the codebook, and confirming the feasibility of employing visual\ndictionaries in large-scale dynamic environments."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.3766v1", 
    "title": "Efficient Topology-Controlled Sampling of Implicit Shapes", 
    "arxiv-id": "1205.3766v1", 
    "author": "John W. Fisher III", 
    "publish": "2012-05-16T19:11:51Z", 
    "summary": "Sampling from distributions of implicitly defined shapes enables analysis of\nvarious energy functionals used for image segmentation. Recent work describes a\ncomputationally efficient Metropolis-Hastings method for accomplishing this\ntask. Here, we extend that framework so that samples are accepted at every\niteration of the sampler, achieving an order of magnitude speed up in\nconvergence. Additionally, we show how to incorporate topological constraints."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.3999v1", 
    "title": "Optimal Weights Mixed Filter for Removing Mixture of Gaussian and   Impulse Noises", 
    "arxiv-id": "1205.3999v1", 
    "author": "Quansheng Liu", 
    "publish": "2012-05-17T18:15:45Z", 
    "summary": "According to the character of Gaussian, we modify the Rank-Ordered Absolute\nDifferences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian\nand impulse noises (ROADG). It will be more effective to detect impulse noise\nwhen the impulse is mixed with Gaussian noise. Combining rightly the ROADG with\nOptimal Weights Filter (OWF), we obtain a new method to deal with the mixed\nnoise, called Optimal Weights Mixed Filter (OWMF). The simulation results show\nthat the method is effective to remove the mixed noise."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.4336v2", 
    "title": "Fuzzy - Rough Feature Selection With \u03a0- Membership Function For   Mammogram Classification", 
    "arxiv-id": "1205.4336v2", 
    "author": "R. Roselin", 
    "publish": "2012-05-19T15:19:38Z", 
    "summary": "Breast cancer is the second leading cause for death among women and it is\ndiagnosed with the help of mammograms. Oncologists are miserably failed in\nidentifying the micro calcification at the early stage with the help of the\nmammogram visually. In order to improve the performance of the breast cancer\nscreening, most of the researchers have proposed Computer Aided Diagnosis using\nimage processing. In this study mammograms are preprocessed and features are\nextracted, then the abnormality is identified through the classification. If\nall the extracted features are used, most of the cases are misidentified. Hence\nfeature selection procedure is sought. In this paper, Fuzzy-Rough feature\nselection with {\\pi} membership function is proposed. The selected features are\nused to classify the abnormalities with help of Ant-Miner and Weka tools. The\nexperimental analysis shows that the proposed method improves the mammograms\nclassification accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.4450v3", 
    "title": "Spectral Graph Cut from a Filtering Point of View", 
    "arxiv-id": "1205.4450v3", 
    "author": "David W. Jacobs", 
    "publish": "2012-05-20T19:30:26Z", 
    "summary": "Spectral graph theory is well known and widely used in computer vision. In\nthis paper, we analyze image segmentation algorithms that are based on spectral\ngraph theory, e.g., normalized cut, and show that there is a natural connection\nbetween spectural graph theory based image segmentationand and edge preserving\nfiltering. Based on this connection we show that the normalized cut algorithm\nis equivalent to repeated iterations of bilateral filtering. Then, using this\nequivalence we present and implement a fast normalized cut algorithm for image\nsegmentation. Experiments show that our implementation can solve the original\noptimization problem in the normalized cut algorithm 10 to 100 times faster.\nFurthermore, we present a new algorithm called conditioned normalized cut for\nimage segmentation that can easily incorporate color image patches and\ndemonstrate how this segmentation problem can be solved with edge preserving\nfiltering."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.4831v1", 
    "title": "Gray Level Co-Occurrence Matrices: Generalisation and Some New Features", 
    "arxiv-id": "1205.4831v1", 
    "author": "Kannan Balakrishnan", 
    "publish": "2012-05-22T08:00:45Z", 
    "summary": "Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques\nused for image texture analysis. In this paper we defined a new feature called\ntrace extracted from the GLCM and its implications in texture analysis are\ndiscussed in the context of Content Based Image Retrieval (CBIR). The\ntheoretical extension of GLCM to n-dimensional gray scale images are also\ndiscussed. The results indicate that trace features outperform Haralick\nfeatures when applied to CBIR."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.5097v1", 
    "title": "Neural Network Approach for Eye Detection", 
    "arxiv-id": "1205.5097v1", 
    "author": "S. Sreehari", 
    "publish": "2012-05-23T05:14:20Z", 
    "summary": "Driving support systems, such as car navigation systems are becoming common\nand they support driver in several aspects. Non-intrusive method of detecting\nFatigue and drowsiness based on eye-blink count and eye directed instruction\ncontrolhelps the driver to prevent from collision caused by drowsy driving. Eye\ndetection and tracking under various conditions such as illumination,\nbackground, face alignment and facial expression makes the problem\ncomplex.Neural Network based algorithm is proposed in this paper to detect the\neyes efficiently. In the proposed algorithm, first the neural Network is\ntrained to reject the non-eye regionbased on images with features of eyes and\nthe images with features of non-eye using Gabor filter and Support Vector\nMachines to reduce the dimension and classify efficiently. In the algorithm,\nfirst the face is segmented using L*a*btransform color space, then eyes are\ndetected using HSV and Neural Network approach. The algorithm is tested on\nnearly 100 images of different persons under different conditions and the\nresults are satisfactory with success rate of 98%.The Neural Network is trained\nwith 50 non-eye images and 50 eye images with different angles using Gabor\nfilter. This paper is a part of research work on \"Development of Non-Intrusive\nsystem for real-time Monitoring and Prediction of Driver Fatigue and\ndrowsiness\" project sponsored by Department of Science & Technology, Govt. of\nIndia, New Delhi at Vignan Institute of Technology and Sciences, Vignan Hills,\nHyderabad."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.5351v2", 
    "title": "Linearized Alternating Direction Method with Adaptive Penalty and Warm   Starts for Fast Solving Transform Invariant Low-Rank Textures", 
    "arxiv-id": "1205.5351v2", 
    "author": "Zhouchen Lin", 
    "publish": "2012-05-24T07:16:14Z", 
    "summary": "Transform Invariant Low-rank Textures (TILT) is a novel and powerful tool\nthat can effectively rectify a rich class of low-rank textures in 3D scenes\nfrom 2D images despite significant deformation and corruption. The existing\nalgorithm for solving TILT is based on the alternating direction method (ADM).\nIt suffers from high computational cost and is not theoretically guaranteed to\nconverge to a correct solution. In this paper, we propose a novel algorithm to\nspeed up solving TILT, with guaranteed convergence. Our method is based on the\nrecently proposed linearized alternating direction method with adaptive penalty\n(LADMAP). To further reduce computation, warm starts are also introduced to\ninitialize the variables better and cut the cost on singular value\ndecomposition. Extensive experimental results on both synthetic and real data\ndemonstrate that this new algorithm works much more efficiently and robustly\nthan the existing algorithm. It could be at least five times faster than the\nprevious method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.5425v1", 
    "title": "Locally Orderless Registration", 
    "arxiv-id": "1205.5425v1", 
    "author": "Jon Sporring", 
    "publish": "2012-05-24T12:56:45Z", 
    "summary": "Image registration is an important tool for medical image analysis and is\nused to bring images into the same reference frame by warping the coordinate\nfield of one image, such that some similarity measure is minimized. We study\nsimilarity in image registration in the context of Locally Orderless Images\n(LOI), which is the natural way to study density estimates and reveals the 3\nfundamental scales: the measurement scale, the intensity scale, and the\nintegration scale.\n  This paper has three main contributions: Firstly, we rephrase a large set of\npopular similarity measures into a common framework, which we refer to as\nLocally Orderless Registration, and which makes full use of the features of\nlocal histograms. Secondly, we extend the theoretical understanding of the\nlocal histograms. Thirdly, we use our framework to compare two state-of-the-art\nintensity density estimators for image registration: The Parzen Window (PW) and\nthe Generalized Partial Volume (GPV), and we demonstrate their differences on a\npopular similarity measure, Normalized Mutual Information (NMI).\n  We conclude, that complicated similarity measures such as NMI may be\nevaluated almost as fast as simple measures such as Sum of Squared Distances\n(SSD) regardless of the choice of PW and GPV. Also, GPV is an asymmetric\nmeasure, and PW is our preferred choice."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6352v4", 
    "title": "Generalized sequential tree-reweighted message passing", 
    "arxiv-id": "1205.6352v4", 
    "author": "Thomas Schoenemann", 
    "publish": "2012-05-29T13:06:58Z", 
    "summary": "This paper addresses the problem of approximate MAP-MRF inference in general\ngraphical models. Following [36], we consider a family of linear programming\nrelaxations of the problem where each relaxation is specified by a set of\nnested pairs of factors for which the marginalization constraint needs to be\nenforced. We develop a generalization of the TRW-S algorithm [9] for this\nproblem, where we use a decomposition into junction chains, monotonic w.r.t.\nsome ordering on the nodes. This generalizes the monotonic chains in [9] in a\nnatural way. We also show how to deal with nested factors in an efficient way.\nExperiments show an improvement over min-sum diffusion, MPLP and subgradient\nascent algorithms on a number of computer vision and natural language\nprocessing problems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6391v2", 
    "title": "A Brief Summary of Dictionary Learning Based Approach for Classification", 
    "arxiv-id": "1205.6391v2", 
    "author": "Wang Donghui", 
    "publish": "2012-05-29T15:28:54Z", 
    "summary": "This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6572v1", 
    "title": "An Unsupervised Dynamic Image Segmentation using Fuzzy Hopfield Neural   Network based Genetic Algorithm", 
    "arxiv-id": "1205.6572v1", 
    "author": "Soumajit Pramanik", 
    "publish": "2012-05-30T08:10:59Z", 
    "summary": "This paper proposes a Genetic Algorithm based segmentation method that can\nautomatically segment gray-scale images. The proposed method mainly consists of\nspatial unsupervised grayscale image segmentation that divides an image into\nregions. The aim of this algorithm is to produce precise segmentation of images\nusing intensity information along with neighborhood relationships. In this\npaper, Fuzzy Hopfield Neural Network (FHNN) clustering helps in generating the\npopulation of Genetic algorithm which there by automatically segments the\nimage. This technique is a powerful method for image segmentation and works for\nboth single and multiple-feature data with spatial information. Validity index\nhas been utilized for introducing a robust technique for finding the optimum\nnumber of components in an image. Experimental results shown that the algorithm\ngenerates good quality segmented image."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6605v1", 
    "title": "Template-Cut: A Pattern-Based Segmentation Paradigm", 
    "arxiv-id": "1205.6605v1", 
    "author": "Tina Kapur", 
    "publish": "2012-05-30T09:44:43Z", 
    "summary": "We present a scale-invariant, template-based segmentation paradigm that sets\nup a graph and performs a graph cut to separate an object from the background.\nTypically graph-based schemes distribute the nodes of the graph uniformly and\nequidistantly on the image, and use a regularizer to bias the cut towards a\nparticular shape. The strategy of uniform and equidistant nodes does not allow\nthe cut to prefer more complex structures, especially when areas of the object\nare indistinguishable from the background. We propose a solution by introducing\nthe concept of a \"template shape\" of the target object in which the nodes are\nsampled non-uniformly and non-equidistantly on the image. We evaluate it on\n2D-images where the object's textures and backgrounds are similar, and large\nareas of the object have the same gray level appearance as the background. We\nalso evaluate it in 3D on 60 brain tumor datasets for neurosurgical planning\npurposes."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6745v1", 
    "title": "Fingerprint Gender Classification using Wavelet Transform and Singular   Value Decomposition", 
    "arxiv-id": "1205.6745v1", 
    "author": "Dr. S Muttan", 
    "publish": "2012-05-30T16:26:23Z", 
    "summary": "A novel method of gender Classification from fingerprint is proposed based on\ndiscrete wavelet transform (DWT) and singular value decomposition (SVD). The\nclassification is achieved by extracting the energy computed from all the\nsub-bands of DWT combined with the spatial features of non-zero singular values\nobtained from the SVD of fingerprint images. K nearest neighbor (KNN) used as a\nclassifier. This method is experimented with the internal database of 3570\nfingerprints finger prints in which 1980 were male fingerprints and 1590 were\nfemale fingerprints. Finger-wise gender classification is achieved which is\n94.32% for the left hand little fingers of female persons and 95.46% for the\nleft hand index finger of male persons. Gender classification for any finger of\nmale persons tested is attained as 91.67% and 84.69% for female persons\nrespectively. Overall classification rate is 88.28% has been achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1206.0238v1", 
    "title": "Rapid Feature Extraction for Optical Character Recognition", 
    "arxiv-id": "1206.0238v1", 
    "author": "Hong Yan", 
    "publish": "2012-06-01T16:20:41Z", 
    "summary": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2012.3203", 
    "link": "http://arxiv.org/pdf/1206.1515v1", 
    "title": "Optimizing Face Recognition Using PCA", 
    "arxiv-id": "1206.1515v1", 
    "author": "Sahar Bo-saeed", 
    "publish": "2012-06-07T14:51:54Z", 
    "summary": "Principle Component Analysis PCA is a classical feature extraction and data\nrepresentation technique widely used in pattern recognition. It is one of the\nmost successful techniques in face recognition. But it has drawback of high\ncomputational especially for big size database. This paper conducts a study to\noptimize the time complexity of PCA (eigenfaces) that does not affects the\nrecognition performance. The authors minimize the participated eigenvectors\nwhich consequently decreases the computational time. A comparison is done to\ncompare the differences between the recognition time in the original algorithm\nand in the enhanced algorithm. The performance of the original and the enhanced\nproposed algorithm is tested on face94 face database. Experimental results show\nthat the recognition time is reduced by 35% by applying our proposed enhanced\nalgorithm. DET Curves are used to illustrate the experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2012.3203", 
    "link": "http://arxiv.org/pdf/1206.1518v1", 
    "title": "Off-Line Arabic Handwriting Character Recognition Using Word   Segmentation", 
    "arxiv-id": "1206.1518v1", 
    "author": "Hanadi H. Al-Fraidi", 
    "publish": "2012-06-07T15:07:08Z", 
    "summary": "The ultimate aim of handwriting recognition is to make computers able to read\nand/or authenticate human written texts, with a performance comparable to or\neven better than that of humans. Reading means that the computer is given a\npiece of handwriting and it provides the electronic transcription of that (e.g.\nin ASCII format). Two types of handwriting: on-line and offline. The most\nimportant purpose of off-line handwriting recognition is in protection systems\nand authentication. Arabic Handwriting scripts are much more complicated in\ncomparison to Latin scripts. This paper introduces a simple and novel\nmethodology to authenticate Arabic handwriting characters. Reaching our aim, we\nbuilt our own character database. The research methodology depends on two\nstages: The first is character extraction where preprocessing the word and then\napply segmentation process to obtain the character. The second is the character\nrecognition by matching the characters comprising the word with the letters in\nthe database. Our results ensure character recognition with 81%. We eliminate\nFAR by using similarity percent between 45-55%. Our research is coded using\nMATLAB."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2012.3203", 
    "link": "http://arxiv.org/pdf/1206.1552v1", 
    "title": "Performance Analysis of Unsymmetrical trimmed median as detector on   image noises and its Fpga implementation", 
    "arxiv-id": "1206.1552v1", 
    "author": "V. Jawahar Senthil Kumar", 
    "publish": "2012-06-07T16:49:36Z", 
    "summary": "This Paper Analyze the performance of Unsymmetrical trimmed median, which is\nused as detector for the detection of impulse noise, Gaussian noise and mixed\nnoise is proposed. The proposed algorithm uses a fixed 3x3 window for the\nincreasing noise densities. The pixels in the current window are arranged in\nsorting order using a improved snake like sorting algorithm with reduced\ncomparator. The processed pixel is checked for the occurrence of outliers, if\nthe absolute difference between processed pixels is greater than fixed\nthreshold. Under high noise densities the processed pixel is also noisy hence\nthe median is checked using the above procedure. if found true then the pixel\nis considered as noisy hence the corrupted pixel is replaced by the median of\nthe current processing window. If median is also noisy then replace the\ncorrupted pixel with unsymmetrical trimmed median else if the pixel is termed\nuncorrupted and left unaltered. The proposed algorithm (PA) is tested on\nvarying detail images for various noises. The proposed algorithm effectively\nremoves the high density fixed value impulse noise, low density random valued\nimpulse noise, low density Gaussian noise and lower proportion of mixed noise.\nThe proposed algorithm is targeted on Xc3e5000-5fg900 FPGA using Xilinx 7.1\ncompiler version which requires less number of slices, optimum speed and low\npower when compared to the other median finding architectures."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.2437v1", 
    "title": "A Novel Windowing Technique for Efficient Computation of MFCC for   Speaker Recognition", 
    "arxiv-id": "1206.2437v1", 
    "author": "Goutam Saha", 
    "publish": "2012-06-12T04:23:38Z", 
    "summary": "In this paper, we propose a novel family of windowing technique to compute\nMel Frequency Cepstral Coefficient (MFCC) for automatic speaker recognition\nfrom speech. The proposed method is based on fundamental property of discrete\ntime Fourier transform (DTFT) related to differentiation in frequency domain.\nClassical windowing scheme such as Hamming window is modified to obtain\nderivatives of discrete time Fourier transform coefficients. It has been\nmathematically shown that the slope and phase of power spectrum are inherently\nincorporated in newly computed cepstrum. Speaker recognition systems based on\nour proposed family of window functions are shown to attain substantial and\nconsistent performance improvement over baseline single tapered Hamming window\nas well as recently proposed multitaper windowing technique."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.2627v2", 
    "title": "Image Similarity Using Sparse Representation and Compression Distance", 
    "arxiv-id": "1206.2627v2", 
    "author": "Rabab K. Ward", 
    "publish": "2012-06-12T19:30:57Z", 
    "summary": "A new line of research uses compression methods to measure the similarity\nbetween signals. Two signals are considered similar if one can be compressed\nsignificantly when the information of the other is known. The existing\ncompression-based similarity methods, although successful in the discrete one\ndimensional domain, do not work well in the context of images. This paper\nproposes a sparse representation-based approach to encode the information\ncontent of an image using information from the other image, and uses the\ncompactness (sparsity) of the representation as a measure of its\ncompressibility (how much can the image be compressed) with respect to the\nother image. The more sparse the representation of an image, the better it can\nbe compressed and the more it is similar to the other image. The efficacy of\nthe proposed measure is demonstrated through the high accuracies achieved in\nimage clustering, retrieval and classification."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.2807v1", 
    "title": "An efficient hierarchical graph based image segmentation", 
    "arxiv-id": "1206.2807v1", 
    "author": "Laurent Najman", 
    "publish": "2012-06-13T13:49:23Z", 
    "summary": "Hierarchical image segmentation provides region-oriented scalespace, i.e., a\nset of image segmentations at different detail levels in which the\nsegmentations at finer levels are nested with respect to those at coarser\nlevels. Most image segmentation algorithms, such as region merging algorithms,\nrely on a criterion for merging that does not lead to a hierarchy, and for\nwhich the tuning of the parameters can be difficult. In this work, we propose a\nhierarchical graph based image segmentation relying on a criterion popularized\nby Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic\nimages, showing efficiency, ease of use, and robustness of our method."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.3559v1", 
    "title": "Real time facial expression recognition using a novel method", 
    "arxiv-id": "1206.3559v1", 
    "author": "Saumil Srivastava", 
    "publish": "2012-05-08T06:54:41Z", 
    "summary": "This paper discusses a novel method for Facial Expression Recognition System\nwhich performs facial expression analysis in a near real time from a live web\ncam feed. Primary objectives were to get results in a near real time with light\ninvariant, person independent and pose invariant way. The system is composed of\ntwo different entities trainer and evaluator. Each frame of video feed is\npassed through a series of steps including haar classifiers, skin detection,\nfeature extraction, feature points tracking, creating a learned Support Vector\nMachine model to classify emotions to achieve a tradeoff between accuracy and\nresult rate. A processing time of 100-120 ms per 10 frames was achieved with\naccuracy of around 60%. We measure our accuracy in terms of variety of\ninteraction and classification scenarios. We conclude by discussing relevance\nof our work to human computer interaction and exploring further measures that\ncan be taken."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.3594v1", 
    "title": "Blind PSF estimation and methods of deconvolution optimization", 
    "arxiv-id": "1206.3594v1", 
    "author": "R. N. Kvetnyy", 
    "publish": "2012-06-15T20:51:39Z", 
    "summary": "We have shown that the left side null space of the autoregression (AR) matrix\noperator is the lexicographical presentation of the point spread function (PSF)\non condition the AR parameters are common for original and blurred images. The\nmethod of inverse PSF evaluation with regularization functional as the function\nof surface area is offered. The inverse PSF was used for primary image\nestimation. Two methods of original image estimate optimization were designed\nbasing on maximum entropy generalization of sought and blurred images\nconditional probability density and regularization. The first method uses\nbalanced variations of convolution and deconvolution transforms to obtaining\niterative schema of image optimization. The variations balance was defined by\ndynamic regularization basing on condition of iteration process convergence.\nThe regularization has dynamic character because depends on current and\nprevious image estimate variations. The second method implements the\nregularization of deconvolution optimization in curved space with metric\ndefined on image estimate surface. It is basing on target functional invariance\nto fluctuations of optimal argument value. The given iterative schemas have\nfaster convergence in comparison with known ones, so they can be used for\nreconstruction of high resolution images series in real time."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.4866v1", 
    "title": "Portraits of Julius Caesar: a proposal for 3D analysis", 
    "arxiv-id": "1206.4866v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2012-06-21T13:14:59Z", 
    "summary": "Here I suggest the use of a 3D scanning and rendering to create some virtual\ncopies of ancient artifacts to study and compare them. In particular, this\napproach could be interesting for some roman marble busts, two of which are\nportraits of Julius Caesar, and the third is a realistic portrait of a man\nrecently found at Arles, France. The comparison of some images indicates that a\nthree-dimensional visualization is necessary."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1206.5065v1", 
    "title": "A generic framework for video understanding applied to group behavior   recognition", 
    "arxiv-id": "1206.5065v1", 
    "author": "Fran\u00e7ois Bremond", 
    "publish": "2012-06-22T06:24:30Z", 
    "summary": "This paper presents an approach to detect and track groups of people in\nvideo-surveillance applications, and to automatically recognize their behavior.\nThis method keeps track of individuals moving together by maintaining a spacial\nand temporal group coherence. First, people are individually detected and\ntracked. Second, their trajectories are analyzed over a temporal window and\nclustered using the Mean-Shift algorithm. A coherence value describes how well\na set of people can be described as a group. Furthermore, we propose a formal\nevent description language. The group events recognition approach is\nsuccessfully validated on 4 camera views from 3 datasets: an airport, a subway,\na shopping center corridor and an entrance hall."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1206.6878v1", 
    "title": "Efficient Selection of Disambiguating Actions for Stereo Vision", 
    "arxiv-id": "1206.6878v1", 
    "author": "Ron Parr", 
    "publish": "2012-06-27T16:31:21Z", 
    "summary": "In many domains that involve the use of sensors, such as robotics or sensor\nnetworks, there are opportunities to use some form of active sensing to\ndisambiguate data from noisy or unreliable sensors. These disambiguating\nactions typically take time and expend energy. One way to choose the next\ndisambiguating action is to select the action with the greatest expected\nentropy reduction, or information gain. In this work, we consider active\nsensing in aid of stereo vision for robotics. Stereo vision is a powerful\nsensing technique for mobile robots, but it can fail in scenes that lack strong\ntexture. In such cases, a structured light source, such as vertical laser line\ncan be used for disambiguation. By treating the stereo matching problem as a\nspecially structured HMM-like graphical model, we demonstrate that for a scan\nline with n columns and maximum stereo disparity d, the entropy minimizing aim\npoint for the laser can be selected in O(nd) time - cost no greater than the\nstereo algorithm itself. In contrast, a typical HMM formulation would suggest\nat least O(nd^2) time for the entropy calculation alone."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.0967v1", 
    "title": "Human Activity Learning using Object Affordances from RGB-D Videos", 
    "arxiv-id": "1208.0967v1", 
    "author": "Ashutosh Saxena", 
    "publish": "2012-08-04T23:44:07Z", 
    "summary": "Human activities comprise several sub-activities performed in a sequence and\ninvolve interactions with various objects. This makes reasoning about the\nobject affordances a central task for activity recognition. In this work, we\nconsider the problem of jointly labeling the object affordances and human\nactivities from RGB-D videos. We frame the problem as a Markov Random Field\nwhere the nodes represent objects and sub-activities, and the edges represent\nthe relationships between object affordances, their relations with\nsub-activities, and their evolution over time. We formulate the learning\nproblem using a structural SVM approach, where labeling over various alternate\ntemporal segmentations are considered as latent variables. We tested our method\non a dataset comprising 120 activity videos collected from four subjects, and\nobtained an end-to-end precision of 81.8% and recall of 80.0% for labeling the\nactivities."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.1670v1", 
    "title": "Performance Measurement and Method Analysis (PMMA) for Fingerprint   Reconstruction", 
    "arxiv-id": "1208.1670v1", 
    "author": "Ramakrishnan Malaisamy", 
    "publish": "2012-08-08T14:15:38Z", 
    "summary": "Fingerprint reconstruction is one of the most well-known and publicized\nbiometrics. Because of their uniqueness and consistency over time, fingerprints\nhave been used for identification over a century, more recently becoming\nautomated due to advancements in computed capabilities. Fingerprint\nreconstruction is popular because of the inherent ease of acquisition, the\nnumerous sources (e.g. ten fingers) available for collection, and their\nestablished use and collections by law enforcement and immigration.\nFingerprints have always been the most practical and positive means of\nidentification. Offenders, being well aware of this, have been coming up with\nways to escape identification by that means. Erasing left over fingerprints,\nusing gloves, fingerprint forgery; are certain examples of methods tried by\nthem, over the years. Failing to prevent themselves, they moved to an extent of\nmutilating their finger skin pattern, to remain unidentified. This article is\nbased upon obliteration of finger ridge patterns and discusses some known cases\nin relation to the same, in chronological order; highlighting the reasons why\noffenders go to an extent of performing such act. The paper gives an overview\nof different methods and performance measurement of the fingerprint\nreconstruction."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.1672v1", 
    "title": "An Efficient Automatic Attendance System Using Fingerprint   Reconstruction Technique", 
    "arxiv-id": "1208.1672v1", 
    "author": "M. Ramakrishnan", 
    "publish": "2012-08-08T14:23:50Z", 
    "summary": "Biometric time and attendance system is one of the most successful\napplications of biometric technology. One of the main advantage of a biometric\ntime and attendance system is it avoids \"buddy-punching\". Buddy punching was a\nmajor loophole which will be exploiting in the traditional time attendance\nsystems. Fingerprint recognition is an established field today, but still\nidentifying individual from a set of enrolled fingerprints is a time taking\nprocess. Most fingerprint-based biometric systems store the minutiae template\nof a user in the database. It has been traditionally assumed that the minutiae\ntemplate of a user does not reveal any information about the original\nfingerprint. This belief has now been shown to be false; several algorithms\nhave been proposed that can reconstruct fingerprint images from minutiae\ntemplates. In this paper, a novel fingerprint reconstruction algorithm is\nproposed to reconstruct the phase image, which is then converted into the\ngrayscale image. The proposed reconstruction algorithm reconstructs the phase\nimage from minutiae. The proposed reconstruction algorithm is used to automate\nthe whole process of taking attendance, manually which is a laborious and\ntroublesome work and waste a lot of time, with its managing and maintaining the\nrecords for a period of time is also a burdensome task. The proposed\nreconstruction algorithm has been evaluated with respect to the success rates\nof type-I attack (match the reconstructed fingerprint against the original\nfingerprint) and type-II attack (match the reconstructed fingerprint against\ndifferent impressions of the original fingerprint) using a commercial\nfingerprint recognition system. Given the reconstructed image from our\nalgorithm, we show that both types of attacks can be effectively launched\nagainst a fingerprint recognition system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.2655v1", 
    "title": "Stable Segmentation of Digital Image", 
    "arxiv-id": "1208.2655v1", 
    "author": "M. Kharinov", 
    "publish": "2012-08-13T18:21:05Z", 
    "summary": "In the paper the optimal image segmentation by means of piecewise constant\napproximations is considered. The optimality is defined by a minimum value of\nthe total squared error or by equivalent value of standard deviation of the\napproximation from the image. The optimal approximations are defined\nindependently on the method of their obtaining and might be generated in\ndifferent algorithms. We investigate the computation of the optimal\napproximation on the grounds of stability with respect to a given set of\nmodifications. To obtain the optimal approximation the Mumford-Shuh model is\ngeneralized and developed, which in the computational part is combined with the\nOtsu method in multi-thresholding version. The proposed solution is proved\nanalytically and experimentally on the example of the standard image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.3133v1", 
    "title": "Color Image Compression Algorithm Based on the DCT Blocks", 
    "arxiv-id": "1208.3133v1", 
    "author": "Wajeb Gharibi", 
    "publish": "2012-08-15T14:51:45Z", 
    "summary": "This paper presents the performance of different blockbased discrete cosine\ntransform (DCT) algorithms for compressing color image. In this RGB component\nof color image are converted to YCbCr before DCT transform is applied. Y is\nluminance component;Cb and Cr are chrominance components of the image. The\nmodification of the image data is done based on the classification of image\nblocks to edge blocks and non-edge blocks, then the edge block of the image is\ncompressed with low compression and the nonedge blocks is compressed with high\ncompression. The analysis results have indicated that the performance of the\nsuggested method is much better, where the constructed images are less\ndistorted and compressed with higher factor."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.3512v1", 
    "title": "Contour Completion Around a Fixation Point", 
    "arxiv-id": "1208.3512v1", 
    "author": "Toshiro Kubota", 
    "publish": "2012-08-16T23:22:50Z", 
    "summary": "The paper presents two edge grouping algorithms for finding a closed contour\nstarting from a particular edge point and enclosing a fixation point. Both\nalgorithms search a shortest simple cycle in \\textit{an angularly ordered\ngraph} derived from an edge image where a vertex is an end point of a contour\nfragment and an undirected arc is drawn between a pair of end-points whose\nvisual angle from the fixation point is less than a threshold value, which is\nset to $\\pi/2$ in our experiments. The first algorithm restricts the search\nspace by disregarding arcs that cross the line extending from the fixation\npoint to the starting point. The second algorithm improves the solution of the\nfirst algorithm in a greedy manner. The algorithms were tested with a large\nnumber of natural images with manually placed fixation and starting points. The\nresults are promising."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIFS.2012.2218597", 
    "link": "http://arxiv.org/pdf/1208.3665v2", 
    "title": "An Evaluation of Popular Copy-Move Forgery Detection Approaches", 
    "arxiv-id": "1208.3665v2", 
    "author": "Elli Angelopoulou", 
    "publish": "2012-08-17T19:41:23Z", 
    "summary": "A copy-move forgery is created by copying and pasting content within the same\nimage, and potentially post-processing it. In recent years, the detection of\ncopy-move forgeries has become one of the most actively researched topics in\nblind image forensics. A considerable number of different algorithms have been\nproposed focusing on different types of postprocessed copies. In this paper, we\naim to answer which copy-move forgery detection algorithms and processing steps\n(e.g., matching, filtering, outlier detection, affine transformation\nestimation) perform best in various postprocessing scenarios. The focus of our\nanalysis is to evaluate the performance of previously proposed feature sets. We\nachieve this by casting existing algorithms in a common pipeline. In this\npaper, we examined the 15 most prominent feature sets. We analyzed the\ndetection performance on a per-image basis and on a per-pixel basis. We created\na challenging real-world copy-move dataset, and a software framework for\nsystematic image manipulation. Experiments show, that the keypoint-based\nfeatures SIFT and SURF, as well as the block-based DCT, DWT, KPCA, PCA and\nZernike features perform very well. These feature sets exhibit the best\nrobustness against various noise sources and downsampling, while reliably\nidentifying the copied regions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIFS.2012.2218597", 
    "link": "http://arxiv.org/pdf/1208.3670v1", 
    "title": "A Survey of Recent View-based 3D Model Retrieval Methods", 
    "arxiv-id": "1208.3670v1", 
    "author": "Qiong Liu", 
    "publish": "2012-08-08T04:45:42Z", 
    "summary": "Extensive research efforts have been dedicated to 3D model retrieval in\nrecent decades. Recently, view-based methods have attracted much research\nattention due to the high discriminative property of multi-views for 3D object\nrepresentation. In this report, we summarize the view-based 3D model methods\nand provide the further research trends. This paper focuses on the scheme for\nmatching between multiple views of 3D models and the application of\nbag-of-visual-words method in 3D model retrieval. For matching between multiple\nviews, the many-to-many matching, probabilistic matching and semisupervised\nlearning methods are introduced. For bag-of-visual-words application in 3D\nmodel retrieval, we first briefly review the bag-of-visual-words works on\nmultimedia and computer vision tasks, where the visual dictionary has been\ndetailed introduced. Then a series of 3D model retrieval methods by using\nbag-of-visual-words description are surveyed in this paper. At last, we\nsummarize the further research content in view-based 3D model retrieval."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIFS.2012.2218597", 
    "link": "http://arxiv.org/pdf/1208.3716v2", 
    "title": "Improved Total Variation based Image Compressive Sensing Recovery by   Nonlocal Regularization", 
    "arxiv-id": "1208.3716v2", 
    "author": "Siwei Ma", 
    "publish": "2012-08-18T01:48:05Z", 
    "summary": "Recently, total variation (TV) based minimization algorithms have achieved\ngreat success in compressive sensing (CS) recovery for natural images due to\nits virtue of preserving edges. However, the use of TV is not able to recover\nthe fine details and textures, and often suffers from undesirable staircase\nartifact. To reduce these effects, this letter presents an improved TV based\nimage CS recovery algorithm by introducing a new nonlocal regularization\nconstraint into CS optimization problem. The nonlocal regularization is built\non the well known nonlocal means (NLM) filtering and takes advantage of\nself-similarity in images, which helps to suppress the staircase effect and\nrestore the fine details. Furthermore, an efficient augmented Lagrangian based\nalgorithm is developed to solve the above combined TV and nonlocal\nregularization constrained problem. Experimental results demonstrate that the\nproposed algorithm achieves significant performance improvements over the\nstate-of-the-art TV based algorithm in both PSNR and visual perception."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.3723v1", 
    "title": "Image Super-Resolution via Dual-Dictionary Learning And Sparse   Representation", 
    "arxiv-id": "1208.3723v1", 
    "author": "Debin Zhao", 
    "publish": "2012-08-18T03:00:03Z", 
    "summary": "Learning-based image super-resolution aims to reconstruct high-frequency (HF)\ndetails from the prior model trained by a set of high- and low-resolution image\npatches. In this paper, HF to be estimated is considered as a combination of\ntwo components: main high-frequency (MHF) and residual high-frequency (RHF),\nand we propose a novel image super-resolution method via dual-dictionary\nlearning and sparse representation, which consists of the main dictionary\nlearning and the residual dictionary learning, to recover MHF and RHF\nrespectively. Extensive experimental results on test images validate that by\nemploying the proposed two-layer progressive scheme, more image details can be\nrecovered and much better results can be achieved than the state-of-the-art\nalgorithms in terms of both PSNR and visual perception."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.3901v2", 
    "title": "Trace transform based method for color image domain identification", 
    "arxiv-id": "1208.3901v2", 
    "author": "Basilio Sierra", 
    "publish": "2012-08-19T22:21:19Z", 
    "summary": "Context categorization is a fundamental pre-requisite for multi-domain\nmultimedia content analysis applications in order to manage contextual\ninformation in an efficient manner. In this paper, we introduce a new color\nimage context categorization method (DITEC) based on the trace transform. The\nproblem of dimensionality reduction of the obtained trace transform signal is\naddressed through statistical descriptors that keep the underlying information.\nThese extracted features offer a highly discriminant behavior for content\ncategorization. The theoretical properties of the method are analyzed and\nvalidated experimentally through two different datasets."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.4316v1", 
    "title": "An Online Character Recognition System to Convert Grantha Script to   Malayalam", 
    "arxiv-id": "1208.4316v1", 
    "author": "Sumam Mary Idicula", 
    "publish": "2012-08-21T17:40:15Z", 
    "summary": "This paper presents a novel approach to recognize Grantha, an ancient script\nin South India and converting it to Malayalam, a prevalent language in South\nIndia using online character recognition mechanism. The motivation behind this\nwork owes its credit to (i) developing a mechanism to recognize Grantha script\nin this modern world and (ii) affirming the strong connection among Grantha and\nMalayalam. A framework for the recognition of Grantha script using online\ncharacter recognition is designed and implemented. The features extracted from\nthe Grantha script comprises mainly of time-domain features based on writing\ndirection and curvature. The recognized characters are mapped to corresponding\nMalayalam characters. The framework was tested on a bed of medium length\nmanuscripts containing 9-12 sample lines and printed pages of a book titled\nSoundarya Lahari writtenin Grantha by Sri Adi Shankara to recognize the words\nand sentences. The manuscript recognition rates with the system are for Grantha\nas 92.11%, Old Malayalam 90.82% and for new Malayalam script 89.56%. The\nrecognition rates of pages of the printed book are for Grantha as 96.16%, Old\nMalayalam script 95.22% and new Malayalam script as 92.32% respectively. These\nresults show the efficiency of the developed system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.4842v1", 
    "title": "The Segmentation Fusion Method On10 Multi-Sensors", 
    "arxiv-id": "1208.4842v1", 
    "author": "N. V. Kalyankar", 
    "publish": "2012-08-23T14:55:30Z", 
    "summary": "The most significant problem may be undesirable effects for the spectral\nsignatures of fused images as well as the benefits of using fused images mostly\ncompared to their source images were acquired at the same time by one sensor.\nThey may or may not be suitable for the fusion of other images. It becomes\ntherefore increasingly important to investigate techniques that allow\nmulti-sensor, multi-date image fusion to make final conclusions can be drawn on\nthe most suitable method of fusion. So, In this study we present a new method\nSegmentation Fusion method (SF) for remotely sensed images is presented by\nconsidering the physical characteristics of sensors, which uses a feature level\nprocessing paradigm. In a particularly, attempts to test the proposed method\nperformance on 10 multi-sensor images and comparing it with different fusion\ntechniques for estimating the quality and degree of information improvement\nquantitatively by using various spatial and spectral metrics."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.5016v1", 
    "title": "WESD - Weighted Spectral Distance for Measuring Shape Dissimilarity", 
    "arxiv-id": "1208.5016v1", 
    "author": "Kilian M. Pohl", 
    "publish": "2012-08-24T17:38:46Z", 
    "summary": "This article presents a new distance for measuring shape dissimilarity\nbetween objects. Recent publications introduced the use of eigenvalues of the\nLaplace operator as compact shape descriptors. Here, we revisit the eigenvalues\nto define a proper distance, called Weighted Spectral Distance (WESD), for\nquantifying shape dissimilarity. The definition of WESD is derived through\nanalysing the heat-trace. This analysis provides the proposed distance an\nintuitive meaning and mathematically links it to the intrinsic geometry of\nobjects. We analyse the resulting distance definition, present and prove its\nimportant theoretical properties. Some of these properties include: i) WESD is\ndefined over the entire sequence of eigenvalues yet it is guaranteed to\nconverge, ii) it is a pseudometric, iii) it is accurately approximated with a\nfinite number of eigenvalues, and iv) it can be mapped to the [0,1) interval.\nLastly, experiments conducted on synthetic and real objects are presented.\nThese experiments highlight the practical benefits of WESD for applications in\nvision and medical image analysis."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.5451v1", 
    "title": "Are You Imitating Me? Unsupervised Sparse Modeling for Group Activity   Analysis from a Single Video", 
    "arxiv-id": "1208.5451v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2012-08-27T17:21:39Z", 
    "summary": "A framework for unsupervised group activity analysis from a single video is\nhere presented. Our working hypothesis is that human actions lie on a union of\nlow-dimensional subspaces, and thus can be efficiently modeled as sparse linear\ncombinations of atoms from a learned dictionary representing the action's\nprimitives. Contrary to prior art, and with the primary goal of spatio-temporal\naction grouping, in this work only one single video segment is available for\nboth unsupervised learning and analysis without any prior training information.\nAfter extracting simple features at a single spatio-temporal scale, we learn a\ndictionary for each individual in the video during each short time lapse. These\ndictionaries allow us to compare the individuals' actions by producing an\naffinity matrix which contains sufficient discriminative information about the\nactions in the scene leading to grouping with simple and efficient tools. With\ndiverse publicly available real videos, we demonstrate the effectiveness of the\nproposed framework and its robustness to cluttered backgrounds, changes of\nhuman appearance, and action variability."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.6137v1", 
    "title": "Benchmarking recognition results on word image datasets", 
    "arxiv-id": "1208.6137v1", 
    "author": "A G Ramakrishnan", 
    "publish": "2012-08-30T11:24:44Z", 
    "summary": "We have benchmarked the maximum obtainable recognition accuracy on various\nword image datasets using manual segmentation and a currently available\ncommercial OCR. We have developed a Matlab program, with graphical user\ninterface, for semi-automated pixel level segmentation of word images. We\ndiscuss the advantages of pixel level annotation. We have covered five\ndatabases adding up to over 3600 word images. These word images have been\ncropped from camera captured scene, born-digital and street view images. We\nrecognize the segmented word image using the trial version of Nuance Omnipage\nOCR. We also discuss, how the degradations introduced during acquisition or\ninaccuracies introduced during creation of word images affect the recognition\nof the word present in the image. Word images for different kinds of\ndegradations and correction for slant and curvy nature of words are also\ndiscussed. The word recognition rates obtained on ICDAR 2003, Sign evaluation,\nStreet view, Born-digital and ICDAR 2011 datasets are 83.9%, 89.3%, 79.6%,\n88.5% and 86.7% respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1208.6335v1", 
    "title": "Comparative Study and Optimization of Feature-Extraction Techniques for   Content based Image Retrieval", 
    "arxiv-id": "1208.6335v1", 
    "author": "Ravdeep Johar", 
    "publish": "2012-08-30T23:50:06Z", 
    "summary": "The aim of a Content-Based Image Retrieval (CBIR) system, also known as Query\nby Image Content (QBIC), is to help users to retrieve relevant images based on\ntheir contents. CBIR technologies provide a method to find images in large\ndatabases by using unique descriptors from a trained image. The image\ndescriptors include texture, color, intensity and shape of the object inside an\nimage. Several feature-extraction techniques viz., Average RGB, Color Moments,\nCo-occurrence, Local Color Histogram, Global Color Histogram and Geometric\nMoment have been critically compared in this paper. However, individually these\ntechniques result in poor performance. So, combinations of these techniques\nhave also been evaluated and results for the most efficient combination of\ntechniques have been presented and optimized for each class of image query. We\nalso propose an improvement in image retrieval performance by introducing the\nidea of Query modification through image cropping. It enables the user to\nidentify a region of interest and modify the initial query to refine and\npersonalize the image retrieval results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1181v1", 
    "title": "FCM Based Blood Vessel Segmentation Method for Retinal Images", 
    "arxiv-id": "1209.1181v1", 
    "author": "Achintya Das", 
    "publish": "2012-09-06T05:12:53Z", 
    "summary": "Segmentation of blood vessels in retinal images provides early diagnosis of\ndiseases like glaucoma, diabetic retinopathy and macular degeneration. Among\nthese diseases occurrence of Glaucoma is most frequent and has serious ocular\nconsequences that can even lead to blindness, if it is not detected early. The\nclinical criteria for the diagnosis of glaucoma include intraocular pressure\nmeasurement, optic nerve head evaluation, retinal nerve fiber layer and visual\nfield defects. This form of blood vessel segmentation helps in early detection\nfor ophthalmic diseases, and potentially reduces the risk of blindness. The\nlow-contrast images at the retina owing to narrow blood vessels of the retina\nare difficult to extract. These low contrast images are, however useful in\nrevealing certain systemic diseases. Motivated by the goals of improving\ndetection of such vessels, this present work proposes an algorithm for\nsegmentation of blood vessels and compares the results between expert\nophthalmologist hand-drawn ground-truths and segmented image(i.e. the output of\nthe present work).Sensitivity, specificity, positive predictive value (PPV),\npositive likelihood ratio (PLR) and accuracy are used to evaluate overall\nperformance.It is found that this work segments blood vessels successfully with\nsensitivity, specificity, PPV, PLR and accuracy of 99.62%, 54.66%, 95.08%,\n219.72 and 95.03%, respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1224v1", 
    "title": "Wavelet Based Normal and Abnormal Heart Sound Identification using   Spectrogram Analysis", 
    "arxiv-id": "1209.1224v1", 
    "author": "Sheli Sinha Chaudhuri", 
    "publish": "2012-09-06T08:37:44Z", 
    "summary": "The present work proposes a computer-aided normal and abnormal heart sound\nidentification based on Discrete Wavelet Transform (DWT), it being useful for\ntele-diagnosis of heart diseases. Due to the presence of Cumulative Frequency\ncomponents in the spectrogram, DWT is applied on the spectro-gram up to n level\nto extract the features from the individual approximation components. One\ndimensional feature vector is obtained by evaluating the Row Mean of the\napproximation components of these spectrograms. For this present approach, the\nset of spectrograms has been considered as the database, rather than raw sound\nsamples. Minimum Euclidean distance is computed between feature vector of the\ntest sample and the feature vectors of the stored samples to identify the heart\nsound. By applying this algorithm, almost 82% of accuracy was achieved."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1558v1", 
    "title": "A Comparative Study between Moravec and Harris Corner Detection of Noisy   Images Using Adaptive Wavelet Thresholding Technique", 
    "arxiv-id": "1209.1558v1", 
    "author": "Subhabrata Chakraborty", 
    "publish": "2012-09-07T14:52:02Z", 
    "summary": "In this paper a comparative study between Moravec and Harris Corner Detection\nhas been done for obtaining features required to track and recognize objects\nwithin a noisy image. Corner detection of noisy images is a challenging task in\nimage processing. Natural images often get corrupted by noise during\nacquisition and transmission. As Corner detection of these noisy images does\nnot provide desired results, hence de-noising is required. Adaptive wavelet\nthresholding approach is applied for the same."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1563v1", 
    "title": "Wavelet Based QRS Complex Detection of ECG Signal", 
    "arxiv-id": "1209.1563v1", 
    "author": "Nilanjan Dey", 
    "publish": "2012-09-07T15:05:57Z", 
    "summary": "The Electrocardiogram (ECG) is a sensitive diagnostic tool that is used to\ndetect various cardiovascular diseases by measuring and recording the\nelectrical activity of the heart in exquisite detail. A wide range of heart\ncondition is determined by thorough examination of the features of the ECG\nreport. Automatic extraction of time plane features is important for\nidentification of vital cardiac diseases. This paper presents a\nmulti-resolution wavelet transform based system for detection 'P', 'Q', 'R',\n'S', 'T' peaks complex from original ECG signal. 'R-R' time lapse is an\nimportant minutia of the ECG signal that corresponds to the heartbeat of the\nconcerned person. Abrupt increase in height of the 'R' wave or changes in the\nmeasurement of the 'R-R' denote various anomalies of human heart. Similarly\n'P-P', 'Q-Q', 'S-S', 'T-T' also corresponds to different anomalies of heart and\ntheir peak amplitude also envisages other cardiac diseases. In this proposed\nmethod the 'PQRST' peaks are marked and stored over the entire signal and the\ntime interval between two consecutive 'R' peaks and other peaks interval are\nmeasured to detect anomalies in behavior of heart, if any. The peaks are\nachieved by the composition of Daubeheissub bands wavelet of original ECG\nsignal. The accuracy of the 'PQRST' complex detection and interval measurement\nis achieved up to 100% with high exactitude by processing and thresholding the\noriginal ECG signal."
},{
    "category": "cs.CV", 
    "doi": "10.1109/3DIMPVT.2012.12", 
    "link": "http://arxiv.org/pdf/1209.1759v1", 
    "title": "Difference of Normals as a Multi-Scale Operator in Unorganized Point   Clouds", 
    "arxiv-id": "1209.1759v1", 
    "author": "Michael Greenspan", 
    "publish": "2012-09-08T22:43:28Z", 
    "summary": "A novel multi-scale operator for unorganized 3D point clouds is introduced.\nThe Difference of Normals (DoN) provides a computationally efficient,\nmulti-scale approach to processing large unorganized 3D point clouds. The\napplication of DoN in the multi-scale filtering of two different real-world\noutdoor urban LIDAR scene datasets is quantitatively and qualitatively\ndemonstrated. In both datasets the DoN operator is shown to segment large 3D\npoint clouds into scale-salient clusters, such as cars, people, and lamp posts\ntowards applications in semi-automatic annotation, and as a pre-processing step\nin automatic object recognition. The application of the operator to\nsegmentation is evaluated on a large public dataset of outdoor LIDAR scenes\nwith ground truth annotations."
},{
    "category": "cs.CV", 
    "doi": "10.1109/3DIMPVT.2012.12", 
    "link": "http://arxiv.org/pdf/1209.1788v1", 
    "title": "On the Use of Lee's Protocol for Speckle-Reducing Techniques", 
    "arxiv-id": "1209.1788v1", 
    "author": "Alejandro C. Frery", 
    "publish": "2012-09-09T10:30:08Z", 
    "summary": "This paper presents two new MAP (Maximum a Posteriori) filters for speckle\nnoise reduction and a Monte Carlo procedure for the assessment of their\nperformance. In order to quantitatively evaluate the results obtained using\nthese new filters, with respect to classical ones, a Monte Carlo extension of\nLee's protocol is proposed. This extension of the protocol shows that its\noriginal version leads to inconsistencies that hamper its use as a general\nprocedure for filter assessment. Some solutions for these inconsistencies are\nproposed, and a consistent comparison of speckle-reducing filters is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1109/3DIMPVT.2012.12", 
    "link": "http://arxiv.org/pdf/1209.2082v3", 
    "title": "Blind Image Deblurring by Spectral Properties of Convolution Operators", 
    "arxiv-id": "1209.2082v3", 
    "author": "Yi Ma", 
    "publish": "2012-09-10T18:19:36Z", 
    "summary": "In this paper, we study the problem of recovering a sharp version of a given\nblurry image when the blur kernel is unknown. Previous methods often introduce\nan image-independent regularizer (such as Gaussian or sparse priors) on the\ndesired blur kernel. We shall show that the blurry image itself encodes rich\ninformation about the blur kernel. Such information can be found through\nanalyzing and comparing how the spectrum of an image as a convolution operator\nchanges before and after blurring. Our analysis leads to an effective convex\nregularizer on the blur kernel which depends only on the given blurry image. We\nshow that the minimizer of this regularizer guarantees to give good\napproximation to the blur kernel if the original image is sharp enough. By\ncombining this powerful regularizer with conventional image deblurring\ntechniques, we show how we could significantly improve the deblurring results\nthrough simulations and experiments on real images. In addition, our analysis\nand experiments help explaining a widely accepted doctrine; that is, the edges\nare good features for deblurring."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3308", 
    "link": "http://arxiv.org/pdf/1209.2515v1", 
    "title": "Wavelet Based Image Coding Schemes : A Recent Survey", 
    "arxiv-id": "1209.2515v1", 
    "author": "M. K. Jeya Kumar", 
    "publish": "2012-09-12T08:08:50Z", 
    "summary": "A variety of new and powerful algorithms have been developed for image\ncompression over the years. Among them the wavelet-based image compression\nschemes have gained much popularity due to their overlapping nature which\nreduces the blocking artifacts that are common phenomena in JPEG compression\nand multiresolution character which leads to superior energy compaction with\nhigh quality reconstructed images. This paper provides a detailed survey on\nsome of the popular wavelet coding techniques such as the Embedded Zerotree\nWavelet (EZW) coding, Set Partitioning in Hierarchical Tree (SPIHT) coding, the\nSet Partitioned Embedded Block (SPECK) Coder, and the Embedded Block Coding\nwith Optimized Truncation (EBCOT) algorithm. Other wavelet-based coding\ntechniques like the Wavelet Difference Reduction (WDR) and the Adaptive Scanned\nWavelet Difference Reduction (ASWDR) algorithms, the Space Frequency\nQuantization (SFQ) algorithm, the Embedded Predictive Wavelet Image Coder\n(EPWIC), Compression with Reversible Embedded Wavelet (CREW), the Stack-Run\n(SR) coding and the recent Geometric Wavelet (GW) coding are also discussed.\nBased on the review, recommendations and discussions are presented for\nalgorithm development and implementation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3308", 
    "link": "http://arxiv.org/pdf/1209.2816v1", 
    "title": "Hirarchical Digital Image Inpainting Using Wavelets", 
    "arxiv-id": "1209.2816v1", 
    "author": "B. Priyalakshmi. Dr. K. P. Soman", 
    "publish": "2012-09-13T08:40:17Z", 
    "summary": "Inpainting is the technique of reconstructing unknown or damaged portions of\nan image in a visually plausible way. Inpainting algorithm automatically fills\nthe damaged region in an image using the information available in undamaged\nregion. Propagation of structure and texture information becomes a challenge as\nthe size of damaged area increases. In this paper, a hierarchical inpainting\nalgorithm using wavelets is proposed. The hierarchical method tries to keep the\nmask size smaller while wavelets help in handling the high pass structure\ninformation and low pass texture information separately. The performance of the\nproposed algorithm is tested using different factors. The results of our\nalgorithm are compared with existing methods such as interpolation, diffusion\nand exemplar techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3308", 
    "link": "http://arxiv.org/pdf/1209.2903v1", 
    "title": "A Novel Approach of Harris Corner Detection of Noisy Images using   Adaptive Wavelet Thresholding Technique", 
    "arxiv-id": "1209.2903v1", 
    "author": "Nilanjana Barman", 
    "publish": "2012-09-13T14:15:16Z", 
    "summary": "In this paper we propose a method of corner detection for obtaining features\nwhich is required to track and recognize objects within a noisy image. Corner\ndetection of noisy images is a challenging task in image processing. Natural\nimages often get corrupted by noise during acquisition and transmission. Though\nCorner detection of these noisy images does not provide desired results, hence\nde-noising is required. Adaptive wavelet thresholding approach is applied for\nthe same."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.3113v1", 
    "title": "Detection and Classification of Viewer Age Range Smart Signs at TV   Broadcast", 
    "arxiv-id": "1209.3113v1", 
    "author": "Murat Ba\u015fkan", 
    "publish": "2012-09-14T07:52:09Z", 
    "summary": "In this paper, the identification and classification of Viewer Age Range\nSmart Signs, designed by the Radio and Television Supreme Council of Turkey, to\ngive age range information for the TV viewers, are realized. Therefore, the\nautomatic detection at the broadcast will be possible, enabling the\nmanufacturing of TV receivers which are sensible to these signs. The most\nimportant step at this process is the pattern recognition. Since the symbols\nthat must be identified are circular, various circle detection techniques can\nbe employed. In our study, first, two different circle segmentation methods for\nstill images are analyzed, their advantages and drawbacks are discussed. A\npopular neural network structure called Multilayer Perceptron is employed for\nthe classification. Afterwards, the same procedures are carried out for\nstreaming video. All of the steps depicted above are realized on a standard PC."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.4317v1", 
    "title": "Image Super-Resolution via Sparse Bayesian Modeling of Natural Images", 
    "arxiv-id": "1209.4317v1", 
    "author": "Yanning Zhang", 
    "publish": "2012-09-19T18:02:41Z", 
    "summary": "Image super-resolution (SR) is one of the long-standing and active topics in\nimage processing community. A large body of works for image super resolution\nformulate the problem with Bayesian modeling techniques and then obtain its\nMaximum-A-Posteriori (MAP) solution, which actually boils down to a regularized\nregression task over separable regularization term. Although straightforward,\nthis approach cannot exploit the full potential offered by the probabilistic\nmodeling, as only the posterior mode is sought. Also, the separable property of\nthe regularization term can not capture any correlations between the sparse\ncoefficients, which sacrifices much on its modeling accuracy. We propose a\nBayesian image SR algorithm via sparse modeling of natural images. The sparsity\nproperty of the latent high resolution image is exploited by introducing latent\nvariables into the high-order Markov Random Field (MRF) which capture the\ncontent adaptive variance by pixel-wise adaptation. The high-resolution image\nis estimated via Empirical Bayesian estimation scheme, which is substantially\nfaster than our previous approach based on Markov Chain Monte Carlo sampling\n[1]. It is shown that the actual cost function for the proposed approach\nactually incorporates a non-factorial regularization term over the sparse\ncoefficients. Experimental results indicate that the proposed method can\ngenerate competitive or better results than \\emph{state-of-the-art} SR\nalgorithms."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.4419v1", 
    "title": "Head Frontal-View Identification Using Extended LLE", 
    "arxiv-id": "1209.4419v1", 
    "author": "Chao Wang", 
    "publish": "2012-09-20T04:15:39Z", 
    "summary": "Automatic head frontal-view identification is challenging due to appearance\nvariations caused by pose changes, especially without any training samples. In\nthis paper, we present an unsupervised algorithm for identifying frontal view\namong multiple facial images under various yaw poses (derived from the same\nperson). Our approach is based on Locally Linear Embedding (LLE), with the\nassumption that with yaw pose being the only variable, the facial images should\nlie in a smooth and low dimensional manifold. We horizontally flip the facial\nimages and present two K-nearest neighbor protocols for the original images and\nthe flipped images, respectively. In the proposed extended LLE, for any facial\nimage (original or flipped one), we search (1) the Ko nearest neighbors among\nthe original facial images and (2) the Kf nearest neighbors among the flipped\nfacial images to construct the same neighborhood graph. The extended LLE\neliminates the differences (because of background, face position and scale in\nthe whole image and some asymmetry of left-right face) between the original\nfacial image and the flipped facial image at the same yaw pose so that the\nflipped facial images can be used effectively. Our approach does not need any\ntraining samples as prior information. The experimental results show that the\nfrontal view of head can be identified reliably around the lowest point of the\npose manifold for multiple facial images, especially the cropped facial images\n(little background and centered face)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.4420v1", 
    "title": "An Efficient Color Face Verification Based on 2-Directional   2-Dimensional Feature Extraction", 
    "arxiv-id": "1209.4420v1", 
    "author": "Lan-Ting LI", 
    "publish": "2012-09-20T04:20:40Z", 
    "summary": "A novel and uniform framework for face verification is presented in this\npaper. First of all, a 2-directional 2-dimensional feature extraction method is\nadopted to extract client-specific template - 2D discrimant projection matrix.\nThen the face skin color information is utilized as an additive feature to\nenhance decision making strategy that makes use of not only 2D grey feature but\nalso 2D skin color feature. A fusion decision of both is applied to experiment\nthe performance on the XM2VTS database according to Lausanne protocol.\nExperimental results show that the framework achieves high verification\naccuracy and verification speed."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5039v1", 
    "title": "Creation of Digital Test Form for Prepress Department", 
    "arxiv-id": "1209.5039v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-23T07:52:01Z", 
    "summary": "The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5040v1", 
    "title": "Image Classification and Optimized Image Reproduction", 
    "arxiv-id": "1209.5040v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-23T08:11:27Z", 
    "summary": "By taking into account the properties and limitations of the human visual\nsystem, images can be more efficiently compressed, colors more accurately\nreproduced, prints better rendered. To show all these advantages in this paper\nnew adapted color charts have been created based on technical and visual image\ncategory analysis. A number of tests have been carried out using extreme images\nwith their key information strictly in dark and light areas. It was shown that\nthe image categorization using the adapted color charts improves the analysis\nof relevant image information with regard to both the image gradation and the\ndetail reproduction. The images with key information in hi-key areas were also\ntest printed using the adapted color charts."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5041v1", 
    "title": "An Implementation of Computer Graphics as Prepress Image Enhancement   Process", 
    "arxiv-id": "1209.5041v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-23T09:15:20Z", 
    "summary": "The production of a printed product involves three stages: prepress, the\nprinting process (press) itself, and finishing (post press). There are various\ntypes of equipments (printers, scanners) and various qualities image are\npresent in the market. These give different color rendering each time during\nreproduction. So, a color key tool has been developed keeping Color Management\nScheme (CMS) in mind so that during reproduction no color rendering takes place\nirrespective of use of any device and resolution level has also been improved."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5417v1", 
    "title": "Model based neuro-fuzzy ASR on Texas processor", 
    "arxiv-id": "1209.5417v1", 
    "author": "Somaye Sobati Moghadam", 
    "publish": "2012-09-24T20:47:27Z", 
    "summary": "In this paper an algorithm for recognizing speech has been proposed. The\nrecognized speech is used to execute related commands which use the MFCC and\ntwo kind of classifiers, first one uses MLP and second one uses fuzzy inference\nsystem as a classifier. The experimental results demonstrate the high gain and\nefficiency of the proposed algorithm. We have implemented this system based on\ngraphical design and tested on a fix point digital signal processor (DSP) of\n600 MHz, with reference DM6437-EVM of Texas instrument."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5494v1", 
    "title": "Segmentation of Breast Regions in Mammogram Based on Density: A Review", 
    "arxiv-id": "1209.5494v1", 
    "author": "Ibrahim Lutfi Shuaib", 
    "publish": "2012-09-25T04:58:55Z", 
    "summary": "The focus of this paper is to review approaches for segmentation of breast\nregions in mammograms according to breast density. Studies based on density\nhave been undertaken because of the relationship between breast cancer and\ndensity. Breast cancer usually occurs in the fibroglandular area of breast\ntissue, which appears bright on mammograms and is described as breast density.\nMost of the studies are focused on the classification methods for glandular\ntissue detection. Others highlighted on the segmentation methods for\nfibroglandular tissue, while few researchers performed segmentation of the\nbreast anatomical regions based on density. There have also been works on the\nsegmentation of other specific parts of breast regions such as either detection\nof nipple position, skin-air interface or pectoral muscles. The problems on the\nevaluation performance of the segmentation results in relation to ground truth\nare also discussed in this paper."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5756v1", 
    "title": "Environmental Sounds Spectrogram Classification using Log-Gabor Filters   and Multiclass Support Vector Machines", 
    "arxiv-id": "1209.5756v1", 
    "author": "Zied Lachiri", 
    "publish": "2012-09-25T20:11:23Z", 
    "summary": "This paper presents novel approaches for efficient feature extraction using\nenvironmental sound magnitude spectrogram. We propose approach based on the\nvisual domain. This approach included three methods. The first method is based\non extraction for each spectrogram a single log-Gabor filter followed by mutual\ninformation procedure. In the second method, the spectrogram is passed by the\nsame steps of the first method but with an averaged bank of 12 log-Gabor\nfilter. The third method consists of spectrogram segmentation into three\npatches, and after that for each spectrogram patch we applied the second\nmethod. The classification results prove that the second method is the most\nefficient in our environmental sound classification system."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6037v1", 
    "title": "Reproduction of Images by Gamut Mapping and Creation of New Test Charts   in Prepress Process", 
    "arxiv-id": "1209.6037v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-26T19:25:56Z", 
    "summary": "With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed"
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6151v1", 
    "title": "Face Alignment Using Active Shape Model And Support Vector Machine", 
    "arxiv-id": "1209.6151v1", 
    "author": "Truong Nhat Vo", 
    "publish": "2012-09-27T07:58:10Z", 
    "summary": "The Active Shape Model (ASM) is one of the most popular local texture models\nfor face alignment. It applies in many fields such as locating facial features\nin the image, face synthesis, etc. However, the experimental results show that\nthe accuracy of the classical ASM for some applications is not high. This paper\nsuggests some improvements on the classical ASM to increase the performance of\nthe model in the application: face alignment. Four of our major improvements\ninclude: i) building a model combining Sobel filter and the 2-D profile in\nsearching face in image; ii) applying Canny algorithm for the enhancement edge\non image; iii) Support Vector Machine (SVM) is used to classify landmarks on\nface, in order to determine exactly location of these landmarks support for\nASM; iv)automatically adjust 2-D profile in the multi-level model based on the\nsize of the input image. The experimental results on Caltech face database and\nTechnical University of Denmark database (imm_face) show that our proposed\nimprovement leads to far better performance."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6189v1", 
    "title": "The Biometric Menagerie - A Fuzzy and Inconsistent Concept", 
    "arxiv-id": "1209.6189v1", 
    "author": "Iulia M. Motoc", 
    "publish": "2012-09-27T11:24:28Z", 
    "summary": "This paper proves that in iris recognition, the concepts of sheep, goats,\nlambs and wolves - as proposed by Doddington and Yager in the so-called\nBiometric Menagerie, are at most fuzzy and at least not quite well defined.\nThey depend not only on the users or on their biometric templates, but also on\nthe parameters that calibrate the iris recognition system. This paper shows\nthat, in the case of iris recognition, the extensions of these concepts have\nvery unsharp and unstable (non-stationary) boundaries. The membership of a user\nto these categories is more often expressed as a degree (as a fuzzy value)\nrather than as a crisp value. Moreover, they are defined by fuzzy Sugeno rules\ninstead of classical (crisp) definitions. For these reasons, we said that the\nBiometric Menagerie proposed by Doddington and Yager could be at most a fuzzy\nconcept of biometry, but even this status is conditioned by improving its\ndefinition. All of these facts are confirmed experimentally in a series of 12\nexhaustive iris recognition tests undertaken for University of Bath Iris Image\nDatabase while using three different iris code dimensions (256x16, 128x8 and\n64x4), two different iris texture encoders (Log-Gabor and Haar-Hilbert) and two\ndifferent types of safety models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6190v1", 
    "title": "Noise Influence on the Fuzzy-Linguistic Partitioning of Iris Code Space", 
    "arxiv-id": "1209.6190v1", 
    "author": "Claudiu G. Ghica", 
    "publish": "2012-09-27T11:31:25Z", 
    "summary": "This paper analyses the set of iris codes stored or used in an iris\nrecognition system as an f-granular space. The f-granulation is given by\nidentifying in the iris code space the extensions of the fuzzy concepts wolves,\ngoats, lambs and sheep (previously introduced by Doddington as 'animals' of the\nbiometric menagerie) - which together form a partitioning of the iris code\nspace. The main question here is how objective (stable / stationary) this\npartitioning is when the iris segments are subject to noisy acquisition. In\norder to prove that the f-granulation of iris code space with respect to the\nfuzzy concepts that define the biometric menagerie is unstable in noisy\nconditions (is sensitive to noise), three types of noise (localvar, motion\nblur, salt and pepper) have been alternatively added to the iris segments\nextracted from University of Bath Iris Image Database. The results of 180\nexhaustive (all-to-all) iris recognition tests are presented and commented\nhere."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0052v1", 
    "title": "Dimensionality Reduction and Classification feature using Mutual   Information applied to Hyperspectral Images : A Filter strategy based   algorithm", 
    "arxiv-id": "1210.0052v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-09-28T23:03:00Z", 
    "summary": "Hyperspectral images (HIS) classification is a high technical remote sensing\ntool. The goal is to reproduce a thematic map that will be compared with a\nreference ground truth map (GT), constructed by expecting the region. The HIS\ncontains more than a hundred bidirectional measures, called bands (or simply\nimages), of the same region. They are taken at juxtaposed frequencies.\nUnfortunately, some bands contain redundant information, others are affected by\nthe noise, and the high dimensionality of features made the accuracy of\nclassification lower. The problematic is how to find the good bands to classify\nthe pixels of regions. Some methods use Mutual Information (MI) and threshold,\nto select relevant bands, without treatment of redundancy. Others control and\neliminate redundancy by selecting the band top ranking the MI, and if its\nneighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll accept the useful redundancy.\nA band contains useful redundancy if it contributes to produce an estimated\nreference map that has higher MI with the GT.nTo control redundancy, we\nintroduce a complementary threshold added to last value of MI. This process is\na Filter strategy; it gets a better performance of classification accuracy and\nnot expensive, but less preferment than Wrapper strategy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0115v2", 
    "title": "Demosaicing and Superresolution for Color Filter Array via Residual   Image Reconstruction and Sparse Representation", 
    "arxiv-id": "1210.0115v2", 
    "author": "Guangling Sun", 
    "publish": "2012-09-29T15:24:37Z", 
    "summary": "A framework of demosaicing and superresolution for color filter array (CFA)\nvia residual image reconstruction and sparse representation is presented.Given\nthe intermediate image produced by certain demosaicing and interpolation\ntechnique, a residual image between the final reconstruction image and the\nintermediate image is reconstructed using sparse representation.The final\nreconstruction image has richer edges and details than that of the intermediate\nimage. Specifically, a generic dictionary is learned from a large set of\ncomposite training data composed of intermediate data and residual data. The\nlearned dictionary implies a mapping between the two data. A specific\ndictionary adaptive to the input CFA is learned thereafter. Using the adaptive\ndictionary, the sparse coefficients of intermediate data are computed and\ntransformed to predict residual image. The residual image is added back into\nthe intermediate image to obtain the final reconstruction image. Experimental\nresults demonstrate the state-of-the-art performance in terms of PSNR and\nsubjective visual perception."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0310v2", 
    "title": "Intra-Retinal Layer Segmentation of 3D Optical Coherence Tomography   Using Coarse Grained Diffusion Map", 
    "arxiv-id": "1210.0310v2", 
    "author": "Milan Sonka", 
    "publish": "2012-10-01T08:52:29Z", 
    "summary": "Optical coherence tomography (OCT) is a powerful and noninvasive method for\nretinal imaging. In this paper, we introduce a fast segmentation method based\non a new variant of spectral graph theory named diffusion maps. The research is\nperformed on spectral domain (SD) OCT images depicting macular and optic nerve\nhead appearance. The presented approach does not require edge-based image\ninformation and relies on regional image texture. Consequently, the proposed\nmethod demonstrates robustness in situations of low image contrast or poor\nlayer-to-layer image gradients. Diffusion mapping is applied to 2D and 3D OCT\ndatasets composed of two steps, one for partitioning the data into important\nand less important sections, and another one for localization of internal\nlayers.In the first step, the pixels/voxels are grouped in rectangular/cubic\nsets to form a graph node.The weights of a graph are calculated based on\ngeometric distances between pixels/voxels and differences of their mean\nintensity.The first diffusion map clusters the data into three parts, the\nsecond of which is the area of interest. The other two sections are eliminated\nfrom the remaining calculations. In the second step, the remaining area is\nsubjected to another diffusion map assessment and the internal layers are\nlocalized based on their textural similarities.The proposed method was tested\non 23 datasets from two patient groups (glaucoma and normals). The mean\nunsigned border positioning errors(mean - SD) was 8.52 - 3.13 and 7.56 - 2.95\nmicrometer for the 2D and 3D methods, respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0347v1", 
    "title": "Enhanced Techniques for PDF Image Segmentation and Text Extraction", 
    "arxiv-id": "1210.0347v1", 
    "author": "E. Chandra", 
    "publish": "2012-10-01T10:38:08Z", 
    "summary": "Extracting text objects from the PDF images is a challenging problem. The\ntext data present in the PDF images contain certain useful information for\nautomatic annotation, indexing etc. However variations of the text due to\ndifferences in text style, font, size, orientation, alignment as well as\ncomplex structure make the problem of automatic text extraction extremely\ndifficult and challenging job. This paper presents two techniques under\nblock-based classification. After a brief introduction of the classification\nmethods, two methods were enhanced and results were evaluated. The performance\nmetrics for segmentation and time consumption are tested for both the models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0386v3", 
    "title": "Combined Descriptors in Spatial Pyramid Domain for Image Classification", 
    "arxiv-id": "1210.0386v3", 
    "author": "Ping Guo", 
    "publish": "2012-10-01T13:05:20Z", 
    "summary": "Recently spatial pyramid matching (SPM) with scale invariant feature\ntransform (SIFT) descriptor has been successfully used in image classification.\nUnfortunately, the codebook generation and feature quantization procedures\nusing SIFT feature have the high complexity both in time and space. To address\nthis problem, in this paper, we propose an approach which combines local binary\npatterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid\ndomain. The proposed method does not need to learn the codebook and feature\nquantization processing, hence it becomes very efficient. Experiments on two\npopular benchmark datasets demonstrate that the proposed method always\nsignificantly outperforms the very popular SPM based SIFT descriptor method\nboth in time and classification accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0528v1", 
    "title": "Band Selection and Classification of Hyperspectral Images using Mutual   Information: An algorithm based on minimizing the error probability using the   inequality of Fano", 
    "arxiv-id": "1210.0528v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-09-28T23:36:26Z", 
    "summary": "Hyperspectral image is a substitution of more than a hundred images, called\nbands, of the same region. They are taken at juxtaposed frequencies. The\nreference image of the region is called Ground Truth map (GT). the problematic\nis how to find the good bands to classify the pixels of regions; because the\nbands can be not only redundant, but a source of confusion, and decreasing so\nthe accuracy of classification. Some methods use Mutual Information (MI) and\nthreshold, to select relevant bands. Recently there's an algorithm selection\nbased on mutual information, using bandwidth rejection and a threshold to\ncontrol and eliminate redundancy. The band top ranking the MI is selected, and\nif its neighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll make difference between\nuseful and useless redundancy. A band contains useful redundancy if it\ncontributes to decreasing error probability. According to this scheme, we\nintroduce new algorithm using also mutual information, but it retains only the\nbands minimizing the error probability of classification. To control\nredundancy, we introduce a complementary threshold. So the good band candidate\nmust contribute to decrease the last error probability augmented by the\nthreshold. This process is a wrapper strategy; it gets high performance of\nclassification accuracy but it is expensive than filter strategy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0818v1", 
    "title": "Multibiometric: Feature Level Fusion Using FKP Multi-Instance biometric", 
    "arxiv-id": "1210.0818v1", 
    "author": "H. S. Sheshadri", 
    "publish": "2012-10-02T16:03:58Z", 
    "summary": "This paper proposed the use of multi-instance feature level fusion as a means\nto improve the performance of Finger Knuckle Print (FKP) verification. A\nlog-Gabor filter has been used to extract the image local orientation\ninformation, and represent the FKP features. Experiments are performed using\nthe FKP database, which consists of 7,920 images. Results indicate that the\nmulti-instance verification approach outperforms higher performance than using\nany single instance. The influence on biometric performance using feature level\nfusion under different fusion rules have been demonstrated in this paper."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6182-8612", 
    "link": "http://arxiv.org/pdf/1210.0829v1", 
    "title": "A Survey of Multibiometric Systems", 
    "arxiv-id": "1210.0829v1", 
    "author": "Maen Zaid AlRwashdeh", 
    "publish": "2012-10-02T16:26:39Z", 
    "summary": "Most biometric systems deployed in real-world applications are unimodal.\nUsing unimodal biometric systems have to contend with a variety of problems\nsuch as: Noise in sensed data; Intra-class variations; Inter-class\nsimilarities; Non-universality; Spoof attacks. These problems have addressed by\nusing multibiometric systems, which expected to be more reliable due to the\npresence of multiple, independent pieces of evidence."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5101", 
    "link": "http://arxiv.org/pdf/1210.1029v1", 
    "title": "Blurred Image Classification based on Adaptive Dictionary", 
    "arxiv-id": "1210.1029v1", 
    "author": "Jie Yin", 
    "publish": "2012-10-03T08:54:01Z", 
    "summary": "Two types of framework for blurred image classification based on adaptive\ndictionary are proposed. Given a blurred image, instead of image deblurring,\nthe semantic category of the image is determined by blur insensitive sparse\ncoefficients calculated depending on an adaptive dictionary. The dictionary is\nadaptive to the Point Spread Function (PSF) estimated from input blurred image.\nThe PSF is assumed to be space invariant and inferred separately in one\nframework or updated combining with sparse coefficients calculation in an\nalternative and iterative algorithm in the other framework. The experiment has\nevaluated three types of blur, naming defocus blur, simple motion blur and\ncamera shake blur. The experiment results confirm the effectiveness of the\nproposed frameworks."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5101", 
    "link": "http://arxiv.org/pdf/1210.1033v1", 
    "title": "Robust Degraded Face Recognition Using Enhanced Local Frequency   Descriptor and Multi-scale Competition", 
    "arxiv-id": "1210.1033v1", 
    "author": "Xinpeng Zhang", 
    "publish": "2012-10-03T09:02:51Z", 
    "summary": "Recognizing degraded faces from low resolution and blurred images are common\nyet challenging task. Local Frequency Descriptor (LFD) has been proved to be\neffective for this task yet it is extracted from a spatial neighborhood of a\npixel of a frequency plane independently regardless of correlations between\nfrequencies. In addition, it uses a fixed window size named single scale of\nshort-term Frequency transform (STFT). To explore the frequency correlations\nand preserve low resolution and blur insensitive simultaneously, we propose\nEnhanced LFD in which information in space and frequency is jointly utilized so\nas to be more descriptive and discriminative than LFD. The multi-scale\ncompetition strategy that extracts multiple descriptors corresponding to\nmultiple window sizes of STFT and take one corresponding to maximum confidence\nas the final recognition result. The experiments conducted on Yale and FERET\ndatabases demonstrate that promising results have been achieved by the proposed\nEnhanced LFD and multi-scale competition strategy."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2014.03.013", 
    "link": "http://arxiv.org/pdf/1210.1316v2", 
    "title": "Learning Locality-Constrained Collaborative Representation for Face   Recognition", 
    "arxiv-id": "1210.1316v2", 
    "author": "Kok Kiong Tan", 
    "publish": "2012-10-04T07:12:49Z", 
    "summary": "The model of low-dimensional manifold and sparse representation are two\nwell-known concise models that suggest each data can be described by a few\ncharacteristics. Manifold learning is usually investigated for dimension\nreduction by preserving some expected local geometric structures from the\noriginal space to a low-dimensional one. The structures are generally\ndetermined by using pairwise distance, e.g., Euclidean distance. Alternatively,\nsparse representation denotes a data point as a linear combination of the\npoints from the same subspace. In practical applications, however, the nearby\npoints in terms of pairwise distance may not belong to the same subspace, and\nvice versa. Consequently, it is interesting and important to explore how to get\na better representation by integrating these two models together. To this end,\nthis paper proposes a novel coding algorithm, called Locality-Constrained\nCollaborative Representation (LCCR), which improves the robustness and\ndiscrimination of data representation by introducing a kind of local\nconsistency. The locality term derives from a biologic observation that the\nsimilar inputs have similar code. The objective function of LCCR has an\nanalytical solution, and it does not involve local minima. The empirical\nstudies based on four public facial databases, ORL, AR, Extended Yale B, and\nMultiple PIE, show that LCCR is promising in recognizing human faces from\nfrontal views with varying expression and illumination, as well as various\ncorruptions and occlusions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2014.03.013", 
    "link": "http://arxiv.org/pdf/1210.1916v1", 
    "title": "A comparative study on face recognition techniques and neural network", 
    "arxiv-id": "1210.1916v1", 
    "author": "Meftah Ur Rahman", 
    "publish": "2012-10-06T06:37:51Z", 
    "summary": "In modern times, face recognition has become one of the key aspects of\ncomputer vision. There are at least two reasons for this trend; the first is\nthe commercial and law enforcement applications, and the second is the\navailability of feasible technologies after years of research. Due to the very\nnature of the problem, computer scientists, neuro-scientists and psychologists\nall share a keen interest in this field. In plain words, it is a computer\napplication for automatically identifying a person from a still image or video\nframe. One of the ways to accomplish this is by comparing selected features\nfrom the image and a facial database. There are hundreds if not thousand\nfactors associated with this. In this paper some of the most common techniques\navailable including applications of neural network in facial recognition are\nstudied and compared with respect to their performance."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2014.03.013", 
    "link": "http://arxiv.org/pdf/1210.3165v1", 
    "title": "Computationally Efficient Implementation of Convolution-based Locally   Adaptive Binarization Techniques", 
    "arxiv-id": "1210.3165v1", 
    "author": "Mita Nasipuri", 
    "publish": "2012-10-11T10:04:44Z", 
    "summary": "One of the most important steps of document image processing is binarization.\nThe computational requirements of locally adaptive binarization techniques make\nthem unsuitable for devices with limited computing facilities. In this paper,\nwe have presented a computationally efficient implementation of convolution\nbased locally adaptive binarization techniques keeping the performance\ncomparable to the original implementation. The computational complexity has\nbeen reduced from O(W2N2) to O(WN2) where WxW is the window size and NxN is the\nimage size. Experiments over benchmark datasets show that the computation time\nhas been reduced by 5 to 15 times depending on the window size while memory\nconsumption remains the same with respect to the state-of-the-art algorithmic\nimplementation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2253484", 
    "link": "http://arxiv.org/pdf/1210.3350v1", 
    "title": "Enhanced Compressed Sensing Recovery with Level Set Normals", 
    "arxiv-id": "1210.3350v1", 
    "author": "Xavier Bresson", 
    "publish": "2012-10-11T19:53:44Z", 
    "summary": "We propose a compressive sensing algorithm that exploits geometric properties\nof images to recover images of high quality from few measurements. The image\nreconstruction is done by iterating the two following steps: 1) estimation of\nnormal vectors of the image level curves and 2) reconstruction of an image\nfitting the normal vectors, the compressed sensing measurements and the\nsparsity constraint. The proposed technique can naturally extend to non local\noperators and graphs to exploit the repetitive nature of textured images in\norder to recover fine detail structures. In both cases, the problem is reduced\nto a series of convex minimization problems that can be efficiently solved with\na combination of variable splitting and augmented Lagrangian methods, leading\nto fast and easy-to-code algorithms. Extended experiments show a clear\nimprovement over related state-of-the-art algorithms in the quality of the\nreconstructed images and the robustness of the proposed method to noise,\ndifferent kind of images and reduced measurements."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2253484", 
    "link": "http://arxiv.org/pdf/1210.3404v2", 
    "title": "A polygon-based interpolation operator for super-resolution imaging", 
    "arxiv-id": "1210.3404v2", 
    "author": "B. M. Herbst", 
    "publish": "2012-10-12T00:31:46Z", 
    "summary": "We outline the super-resolution reconstruction problem posed as a\nmaximization of probability. We then introduce an interpolation method based on\npolygonal pixel overlap, express it as a linear operator, and use it to improve\nreconstruction. Polygon interpolation outperforms the simpler bilinear\ninterpolation operator and, unlike Gaussian modeling of pixels, requires no\nparameter estimation. A free software implementation that reproduces the\nresults shown is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.3832v1", 
    "title": "Image Processing using Smooth Ordering of its Patches", 
    "arxiv-id": "1210.3832v1", 
    "author": "Israel Cohen", 
    "publish": "2012-10-14T20:17:33Z", 
    "summary": "We propose an image processing scheme based on reordering of its patches. For\na given corrupted image, we extract all patches with overlaps, refer to these\nas coordinates in high-dimensional space, and order them such that they are\nchained in the \"shortest possible path\", essentially solving the traveling\nsalesman problem. The obtained ordering applied to the corrupted image, implies\na permutation of the image pixels to what should be a regular signal. This\nenables us to obtain good recovery of the clean image by applying relatively\nsimple 1D smoothing operations (such as filtering or interpolation) to the\nreordered set of pixels. We explore the use of the proposed approach to image\ndenoising and inpainting, and show promising results in both cases."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.4863v1", 
    "title": "DBN-Based Combinatorial Resampling for Articulated Object Tracking", 
    "arxiv-id": "1210.4863v1", 
    "author": "Xuan Son NGuyen", 
    "publish": "2012-10-16T17:38:55Z", 
    "summary": "Particle Filter is an effective solution to track objects in video sequences\nin complex situations. Its key idea is to estimate the density over the\npossible states of the object using a weighted sample whose elements are called\nparticles. One of its crucial step is a resampling step in which particles are\nresampled to avoid some degeneracy problem. In this paper, we introduce a new\nresampling method called Combinatorial Resampling that exploits some features\nof articulated objects to resample over an implicitly created sample of an\nexponential size better representing the density to estimate. We prove that it\nis sound and, through experimentations both on challenging synthetic and real\nvideo sequences, we show that it outperforms all classical resampling methods\nboth in terms of the quality of its results and in terms of response times."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.5653v1", 
    "title": "Identifications of concealed weapon in a Human Body", 
    "arxiv-id": "1210.5653v1", 
    "author": "Sudipta Roy", 
    "publish": "2012-10-20T20:37:22Z", 
    "summary": "The detection of weapons concealed underneath a person cloths is very much\nimportant to the improvement of the security of the public as well as the\nsafety of public assets like airports, buildings and railway stations etc."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.5732v1", 
    "title": "Developing ICC Profile Using Gray Level Control In Offset Printing   Process", 
    "arxiv-id": "1210.5732v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-10-21T14:49:30Z", 
    "summary": "In prepress department RGB image has to be converted to CMYK image. To\ncontrol that amount of black, cyan, magenta and yellow has to be controlled by\nusing color separation method. Graycolor separation method is selected to\ncontrol the amounts of these colors because it increase the quality of printing\nalso. A single printer used for printing the same image on different paper also\nresults in different printed images. To remove this problem a different ICC\nprofile based on gray level control is developedand a sheet offset printer is\ncalibrated using that profile and a subjective evaluation shows satisfactory\nresults for different quality papers."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.6157v1", 
    "title": "Novel Architecture for 3D model in virtual communities from detected   face", 
    "arxiv-id": "1210.6157v1", 
    "author": "Deepti Gahalot", 
    "publish": "2012-10-23T07:57:24Z", 
    "summary": "In this research paper we suggest how to extract a face from an image, modify\nit, characterize it in terms of high-level properties, and apply it to the\ncreation of a personalized avatar. In this research work we tested, we\nimplemented the algorithm on several hundred facial images, including many\ntaken under uncontrolled acquisition conditions, and found to exhibit\nsatisfactory performance for immediate practical use."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.7014v2", 
    "title": "Computer vision tools for the non-invasive assessment of autism-related   behavioral markers", 
    "arxiv-id": "1210.7014v2", 
    "author": "Guillermo Sapiro", 
    "publish": "2012-10-25T22:30:40Z", 
    "summary": "The early detection of developmental disorders is key to child outcome,\nallowing interventions to be initiated that promote development and improve\nprognosis. Research on autism spectrum disorder (ASD) suggests behavioral\nmarkers can be observed late in the first year of life. Many of these studies\ninvolved extensive frame-by-frame video observation and analysis of a child's\nnatural behavior. Although non-intrusive, these methods are extremely\ntime-intensive and require a high level of observer training; thus, they are\nimpractical for clinical and large population research purposes. Diagnostic\nmeasures for ASD are available for infants but are only accurate when used by\nspecialists experienced in early diagnosis. This work is a first milestone in a\nlong-term multidisciplinary project that aims at helping clinicians and general\npractitioners accomplish this early detection/measurement task automatically.\nWe focus on providing computer vision tools to measure and identify ASD\nbehavioral markers based on components of the Autism Observation Scale for\nInfants (AOSI). In particular, we develop algorithms to measure three critical\nAOSI activities that assess visual attention. We augment these AOSI activities\nwith an additional test that analyzes asymmetrical patterns in unsupported\ngait. The first set of algorithms involves assessing head motion by tracking\nfacial features, while the gait analysis relies on joint foreground\nsegmentation and 2D body pose estimation in video. We show results that provide\ninsightful knowledge to augment the clinician's behavioral observations\nobtained from real in-clinic assessments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICRTIT.2011.5972443", 
    "link": "http://arxiv.org/pdf/1210.7102v1", 
    "title": "3D Face Recognition using Significant Point based SULD Descriptor", 
    "arxiv-id": "1210.7102v1", 
    "author": "K. Raghurama Holla", 
    "publish": "2012-10-26T11:27:33Z", 
    "summary": "In this work, we present a new 3D face recognition method based on Speeded-Up\nLocal Descriptor (SULD) of significant points extracted from the range images\nof faces. The proposed model consists of a method for extracting distinctive\ninvariant features from range images of faces that can be used to perform\nreliable matching between different poses of range images of faces. For a given\n3D face scan, range images are computed and the potential interest points are\nidentified by searching at all scales. Based on the stability of the interest\npoint, significant points are extracted. For each significant point we compute\nthe SULD descriptor which consists of vector made of values from the convolved\nHaar wavelet responses located on concentric circles centred on the significant\npoint, and where the amount of Gaussian smoothing is proportional to the radii\nof the circles. Experimental results show that the newly proposed method\nprovides higher recognition rate compared to other existing contemporary models\ndeveloped for 3D face recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICRTIT.2011.5972443", 
    "link": "http://arxiv.org/pdf/1210.7403v1", 
    "title": "Resolution Enhancement of Range Images via Color-Image Segmentation", 
    "arxiv-id": "1210.7403v1", 
    "author": "Arnav Bhavsar", 
    "publish": "2012-10-28T05:27:55Z", 
    "summary": "We report a method for super-resolution of range images. Our approach\nleverages the interpretation of LR image as sparse samples on the HR grid.\nBased on this interpretation, we demonstrate that our recently reported\napproach, which reconstructs dense range images from sparse range data by\nexploiting a registered colour image, can be applied for the task of resolution\nenhancement of range images. Our method only uses a single colour image in\naddition to the range observation in the super-resolution process. Using the\nproposed approach, we demonstrate super-resolution results for large factors\n(e.g. 4) with good localization accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICRTIT.2011.5972443", 
    "link": "http://arxiv.org/pdf/1210.7631v1", 
    "title": "The fortresses of Ejin: an example of outlining a site from satellite   images", 
    "arxiv-id": "1210.7631v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2012-10-29T11:53:35Z", 
    "summary": "From 1960's to 1970's, the Chinese Army built some fortified artificial\nhills. Some of them are located in the Inner Mongolia, Western China. These\nlarge fortresses are surrounded by moats. For some of them it is still possible\nto see earthworks, trenches and ditches, the planning of which could have a\nsymbolic meaning. We can argue this result form their digital outlining,\nobtained after an image processing of satellite images, based on edge\ndetection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2012.2434", 
    "link": "http://arxiv.org/pdf/1210.7669v1", 
    "title": "Performance Evaluation of Different Techniques for texture   Classification", 
    "arxiv-id": "1210.7669v1", 
    "author": "Pooja Maknikar", 
    "publish": "2012-10-29T14:05:27Z", 
    "summary": "Texture is the term used to characterize the surface of a given object or\nphenomenon and is an important feature used in image processing and pattern\nrecognition. Our aim is to compare various Texture analyzing methods and\ncompare the results based on time complexity and accuracy of classification.\nThe project describes texture classification using Wavelet Transform and Co\noccurrence Matrix. Comparison of features of a sample texture with database of\ndifferent textures is performed. In wavelet transform we use the Haar, Symlets\nand Daubechies wavelets. We find that, thee Haar wavelet proves to be the most\nefficient method in terms of performance assessment parameters mentioned above.\nComparison of Haar wavelet and Co-occurrence matrix method of classification\nalso goes in the favor of Haar. Though the time requirement is high in the\nlater method, it gives excellent results for classification accuracy except if\nthe image is rotated."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1210.8262v1", 
    "title": "On the Relation Between the Common Labelling and the Median Graph", 
    "arxiv-id": "1210.8262v1", 
    "author": "Francesc Serratosa", 
    "publish": "2012-10-31T08:29:58Z", 
    "summary": "In structural pattern recognition, given a set of graphs, the computation of\na Generalized Median Graph is a well known problem. Some methods approach the\nproblem by assuming a relation between the Generalized Median Graph and the\nCommon Labelling problem. However, this relation has still not been formally\nproved. In this paper, we analyse such relation between both problems. The main\nresult proves that the cost of the common labelling upper-bounds the cost of\nthe median with respect to the given set. In addition, we show that the two\nproblems are equivalent in some cases."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0055v1", 
    "title": "Dimensionality Reduction and Classification Feature Using Mutual   Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm   Based on Minimizing the Error Probability Using the Inequality of Fano", 
    "arxiv-id": "1211.0055v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-10-31T23:30:59Z", 
    "summary": "In the feature classification domain, the choice of data affects widely the\nresults. For the Hyperspectral image, the bands dont all contain the\ninformation; some bands are irrelevant like those affected by various\natmospheric effects, see Figure.4, and decrease the classification accuracy.\nAnd there exist redundant bands to complicate the learning system and product\nincorrect prediction [14]. Even the bands contain enough information about the\nscene they may can't predict the classes correctly if the dimension of space\nimages, see Figure.3, is so large that needs many cases to detect the\nrelationship between the bands and the scene (Hughes phenomenon) [10]. We can\nreduce the dimensionality of hyperspectral images by selecting only the\nrelevant bands (feature selection or subset selection methodology), or\nextracting, from the original bands, new bands containing the maximal\ninformation about the classes, using any functions, logical or numerical\n(feature extraction methodology) [11][9]. Here we focus on the feature\nselection using mutual information. Hyperspectral images have three advantages\nregarding the multispectral images [6],"
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0191v1", 
    "title": "Performance Evaluation of Random Set Based Pedestrian Tracking   Algorithms", 
    "arxiv-id": "1211.0191v1", 
    "author": "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez", 
    "publish": "2012-10-25T23:21:46Z", 
    "summary": "The paper evaluates the error performance of three random finite set based\nmulti-object trackers in the context of pedestrian video tracking. The\nevaluation is carried out using a publicly available video dataset of 4500\nframes (town centre street) for which the ground truth is available. The input\nto all pedestrian tracking algorithms is an identical set of head and body\ndetections, obtained using the Histogram of Oriented Gradients (HOG) detector.\nThe tracking error is measured using the recently proposed OSPA metric for\ntracks, adopted as the only known mathematically rigorous metric for measuring\nthe distance between two sets of tracks. A comparative analysis is presented\nunder various conditions."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0602v1", 
    "title": "Segmentation of ultrasound images of thyroid nodule for assisting fine   needle aspiration cytology", 
    "arxiv-id": "1211.0602v1", 
    "author": "Hua Tian", 
    "publish": "2012-11-03T06:55:03Z", 
    "summary": "The incidence of thyroid nodule is very high and generally increases with the\nage. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\nnodule can be completely cured if detected early. Fine needle aspiration\ncytology is a recognized early diagnosis method of thyroid nodule. There are\nstill some limitations in the fine needle aspiration cytology, and the\nultrasound diagnosis of thyroid nodule has become the first choice for\nauxiliary examination of thyroid nodular disease. If we could combine medical\nimaging technology and fine needle aspiration cytology, the diagnostic rate of\nthyroid nodule would be improved significantly. The properties of ultrasound\nwill degrade the image quality, which makes it difficult to recognize the edges\nfor physicians. Image segmentation technique based on graph theory has become a\nresearch hotspot at present. Normalized cut (Ncut) is a representative one,\nwhich is suitable for segmentation of feature parts of medical image. However,\nhow to solve the normalized cut has become a problem, which needs large memory\ncapacity and heavy calculation of weight matrix. It always generates over\nsegmentation or less segmentation which leads to inaccurate in the\nsegmentation. The speckle noise in B ultrasound image of thyroid tumor makes\nthe quality of the image deteriorate. In the light of this characteristic, we\ncombine the anisotropic diffusion model with the normalized cut in this paper.\nAfter the enhancement of anisotropic diffusion model, it removes the noise in\nthe B ultrasound image while preserves the important edges and local details.\nThis reduces the amount of computation in constructing the weight matrix of the\nimproved normalized cut and improves the accuracy of the final segmentation\nresults. The feasibility of the method is proved by the experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0613v2", 
    "title": "Application of Symmetric Uncertainty and Mutual Information to   Dimensionality Reduction and Classification of Hyperspectral Images", 
    "arxiv-id": "1211.0613v2", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-11-03T14:01:29Z", 
    "summary": "Remote sensing is a technology to acquire data for disatant substances,\nnecessary to construct a model knowledge for applications as classification.\nRecently Hyperspectral Images (HSI) becomes a high technical tool that the main\ngoal is to classify the point of a region. The HIS is more than a hundred\nbidirectional measures, called bands (or simply images), of the same region\ncalled Ground Truth Map (GT). But some bands are not relevant because they are\naffected by different atmospheric effects; others contain redundant\ninformation; and high dimensionality of HSI features make the accuracy of\nclassification lower. All these bands can be important for some applications;\nbut for the classification a small subset of these is relevant. The problematic\nrelated to HSI is the dimensionality reduction. Many studies use mutual\ninformation (MI) to select the relevant bands. Others studies use the MI\nnormalized forms, like Symmetric Uncertainty, in medical imagery applications.\nIn this paper we introduce an algorithm based also on MI to select relevant\nbands and it apply the Symmetric Uncertainty coefficient to control redundancy\nand increase the accuracy of classification. This algorithm is feature\nselection tool and a Filter strategy. We establish this study on HSI AVIRIS\n92AV3C. This is an effectiveness, and fast scheme to control redundancy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.1252v1", 
    "title": "Implementation of Radon Transformation for Electrical Impedance   Tomography (EIT)", 
    "arxiv-id": "1211.1252v1", 
    "author": "Md. Ahaduzzaman Khan", 
    "publish": "2012-10-16T09:46:12Z", 
    "summary": "Radon Transformation is generally used to construct optical image (like CT\nimage) from the projection data in biomedical imaging. In this paper, the\nconcept of Radon Transformation is implemented to reconstruct Electrical\nImpedance Topographic Image (conductivity or resistivity distribution) of a\ncircular subject. A parallel resistance model of a subject is proposed for\nElectrical Impedance Topography(EIT) or Magnetic Induction Tomography(MIT). A\ncircular subject with embedded circular objects is segmented into equal width\nslices from different angles. For each angle, Conductance and Conductivity of\neach slice is calculated and stored in an array. A back projection method is\nused to generate a two-dimensional image from one-dimensional projections. As a\nback projection method, Inverse Radon Transformation is applied on the\ncalculated conductance and conductivity to reconstruct two dimensional images.\nThese images are compared to the target image. In the time of image\nreconstruction, different filters are used and these images are compared with\neach other and target image."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.1482v4", 
    "title": "Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier   Curve and Statistical Techniques", 
    "arxiv-id": "1211.1482v4", 
    "author": "Sajid Ali", 
    "publish": "2012-11-07T08:19:04Z", 
    "summary": "Motion capture is the process of recording the movement of objects or people.\nIt is used in military, entertainment, sports, and medical applications, and\nfor validation of computer vision[2] and robotics. In filmmaking and video game\ndevelopment, it refers to recording actions of human actors, and using that\ninformation to animate digital character models in 2D or 3D computer animation.\nWhen it includes face and fingers or captures subtle"
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.1650v1", 
    "title": "Different Operating Systems Compatible for Image Prepress Process in   Color Management: Analysis and Performance Testing", 
    "arxiv-id": "1211.1650v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-11-07T19:52:50Z", 
    "summary": "Image computing has become a real catchphrase over the past few years and the\ninterpretations of the meaning of the term vary greatly. The Imagecomputing\nmarket is currently rapidly evolving with high growth prospects and almost\ndaily announcements of new devices and application platforms, which results in\nan increasing diversification of devices, operating system and development\nplatforms. Compared to more traditional information technology markets like the\none of desktop computing, mobile computing is much less consolidated and\nneither standards nor even industry standards have yet been established. There\nare various platforms and interfaces which may be used to perform the desired\ntasks through the device. We have tried to compare the various mobile operating\nsystems and their trade-offs."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2247755", 
    "link": "http://arxiv.org/pdf/1211.1656v1", 
    "title": "James-Stein Type Center Pixel Weights for Non-Local Means Image   Denoising", 
    "arxiv-id": "1211.1656v1", 
    "author": "Joseph P. Noonan", 
    "publish": "2012-11-07T20:10:24Z", 
    "summary": "Non-Local Means (NLM) and variants have been proven to be effective and\nrobust in many image denoising tasks. In this letter, we study the parameter\nselection problem of center pixel weights (CPW) in NLM. Our key contributions\nare: 1) we give a novel formulation of the CPW problem from the statistical\nshrinkage perspective; 2) we introduce the James-Stein type CPWs for NLM; and\n3) we propose a new adaptive CPW that is locally tuned for each image pixel.\nOur experimental results showed that compared to existing CPW solutions, the\nnew proposed CPWs are more robust and effective under various noise levels. In\nparticular, the NLM with the James-Stein type CPWs attain higher means with\nsmaller variances in terms of the peak signal and noise ratio, implying they\nimprove the NLM robustness and make it less sensitive to parameter selection."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2247755", 
    "link": "http://arxiv.org/pdf/1211.1752v1", 
    "title": "3D Scene Grammar for Parsing RGB-D Pointclouds", 
    "arxiv-id": "1211.1752v1", 
    "author": "Sherwin Li", 
    "publish": "2012-11-08T03:11:53Z", 
    "summary": "We pose 3D scene-understanding as a problem of parsing in a grammar. A\ngrammar helps us capture the compositional structure of real-word objects,\ne.g., a chair is composed of a seat, a back-rest and some legs. Having multiple\nrules for an object helps us capture structural variations in objects, e.g., a\nchair can optionally also have arm-rests. Finally, having rules to capture\ncomposition at different levels helps us formulate the entire scene-processing\npipeline as a single problem of finding most likely parse-tree---small segments\ncombine to form parts of objects, parts to objects and objects to a scene. We\nattach a generative probability model to our grammar by having a\nfeature-dependent probability function for every rule. We evaluated it by\nextracting labels for every segment and comparing the results with the\nstate-of-the-art segment-labeling algorithm. Our algorithm was outperformed by\nthe state-or-the-art method. But, Our model can be trained very efficiently\n(within seconds), and it scales only linearly in with the number of rules in\nthe grammar. Also, we think that this is an important problem for the 3D vision\ncommunity. So, we are releasing our dataset and related code."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2247755", 
    "link": "http://arxiv.org/pdf/1211.1800v1", 
    "title": "A Comparative study of Arabic handwritten characters invariant feature", 
    "arxiv-id": "1211.1800v1", 
    "author": "Maher khemakhem", 
    "publish": "2012-11-08T09:24:21Z", 
    "summary": "This paper is practically interested in the unchangeable feature of Arabic\nhandwritten character. It presents results of comparative study achieved on\ncertain features extraction techniques of handwritten character, based on Hough\ntransform, Fourier transform, Wavelet transform and Gabor Filter. Obtained\nresults show that Hough Transform and Gabor filter are insensible to the\nrotation and translation, Fourier Transform is sensible to the rotation but\ninsensible to the translation, in contrast to Hough Transform and Gabor filter,\nWavelets Transform is sensitive to the rotation as well as to the translation."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.1968v2", 
    "title": "Fourier-Bessel rotational invariant eigenimages", 
    "arxiv-id": "1211.1968v2", 
    "author": "Amit Singer", 
    "publish": "2012-11-08T20:59:49Z", 
    "summary": "We present an efficient and accurate algorithm for principal component\nanalysis (PCA) of a large set of two dimensional images, and, for each image,\nthe set of its uniform rotations in the plane and its reflection. The algorithm\nstarts by expanding each image, originally given on a Cartesian grid, in the\nFourier-Bessel basis for the disk. Because the images are bandlimited in the\nFourier domain, we use a sampling criterion to truncate the Fourier-Bessel\nexpansion such that the maximum amount of information is preserved without the\neffect of aliasing. The constructed covariance matrix is invariant to rotation\nand reflection and has a special block diagonal structure. PCA is efficiently\ndone for each block separately. This Fourier-Bessel based PCA detects more\nmeaningful eigenimages and has improved denoising capability compared to\ntraditional PCA for a finite number of noisy images."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2007v1", 
    "title": "Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic   Units for Speech Recognition", 
    "arxiv-id": "1211.2007v1", 
    "author": "Chokri Ben Amar", 
    "publish": "2012-11-08T22:23:54Z", 
    "summary": "In this paper, we propose a novel architecture of wavelet network called\nMulti-input Multi-output Wavelet Network MIMOWN as a generalization of the old\narchitecture of wavelet network. This newel prototype was applied to speech\nrecognition application especially to model acoustic unit of speech. The\noriginality of our work is the proposal of MIMOWN to model acoustic unit of\nspeech. This approach was proposed to overcome limitation of old wavelet\nnetwork model. The use of the multi-input multi-output architecture will allows\ntraining wavelet network on various examples of acoustic units."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2037v1", 
    "title": "Time Complexity Analysis of Binary Space Partitioning Scheme for Image   Compression", 
    "arxiv-id": "1211.2037v1", 
    "author": "M. K. Jeyakumar", 
    "publish": "2012-11-09T03:59:48Z", 
    "summary": "Segmentation-based image coding methods provide high compression ratios when\ncompared with traditional image coding approaches like the transform and sub\nband coding for low bit-rate compression applications. In this paper, a\nsegmentation-based image coding method, namely the Binary Space Partition\nscheme, that divides the desired image using a recursive procedure for coding\nis presented. The BSP approach partitions the desired image recursively by\nusing bisecting lines, selected from a collection of discrete optional lines,\nin a hierarchical manner. This partitioning procedure generates a binary tree,\nwhich is referred to as the BSP-tree representation of the desired image. The\nalgorithm is extremely complex in computation and has high execution time. The\ntime complexity of the BSP scheme is explored in this work."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2082v1", 
    "title": "3D Surface Reconstruction of Underwater Objects", 
    "arxiv-id": "1211.2082v1", 
    "author": "P. U. Praveen Kumar", 
    "publish": "2012-11-09T09:17:26Z", 
    "summary": "In this paper, we propose a novel technique to reconstruct 3D surface of an\nunderwater object using stereo images. Reconstructing the 3D surface of an\nunderwater object is really a challenging task due to degraded quality of\nunderwater images. There are various reason of quality degradation of\nunderwater images i.e., non-uniform illumination of light on the surface of\nobjects, scattering and absorption effects. Floating particles present in\nunderwater produces Gaussian noise on the captured underwater images which\ndegrades the quality of images. The degraded underwater images are preprocessed\nby applying homomorphic, wavelet denoising and anisotropic filtering\nsequentially. The uncalibrated rectification technique is applied to\npreprocessed images to rectify the left and right images. The rectified left\nand right image lies on a common plane. To find the correspondence points in a\nleft and right images, we have applied dense stereo matching technique i.e.,\ngraph cut method. Finally, we estimate the depth of images using triangulation\ntechnique. The experimental result shows that the proposed method reconstruct\n3D surface of underwater objects accurately using captured underwater stereo\nimages."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2116v1", 
    "title": "Localisation of Numerical Date Field in an Indian Handwritten Document", 
    "arxiv-id": "1211.2116v1", 
    "author": "Kalyan Ghosh", 
    "publish": "2012-11-09T12:59:11Z", 
    "summary": "This paper describes a method to localise all those areas which may\nconstitute the date field in an Indian handwritten document. Spatial patterns\nof the date field are studied from various handwritten documents and an\nalgorithm is developed through statistical analysis to identify those sets of\nconnected components which may constitute the date. Common date patterns\nfollowed in India are considered to classify the date formats in different\nclasses. Reported results demonstrate promising performance of the proposed\napproach"
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2150v1", 
    "title": "NF-SAVO: Neuro-Fuzzy system for Arabic Video OCR", 
    "arxiv-id": "1211.2150v1", 
    "author": "Ana Fern\u00e1ndez Vila", 
    "publish": "2012-11-09T14:57:53Z", 
    "summary": "In this paper we propose a robust approach for text extraction and\nrecognition from video clips which is called Neuro-Fuzzy system for Arabic\nVideo OCR. In Arabic video text recognition, a number of noise components\nprovide the text relatively more complicated to separate from the background.\nFurther, the characters can be moving or presented in a diversity of colors,\nsizes and fonts that are not uniform. Added to this, is the fact that the\nbackground is usually moving making text extraction a more intricate process.\nVideo include two kinds of text, scene text and artificial text. Scene text is\nusually text that becomes part of the scene itself as it is recorded at the\ntime of filming the scene. But artificial text is produced separately and away\nfrom the scene and is laid over it at a later stage or during the post\nprocessing time. The emergence of artificial text is consequently vigilantly\ndirected. This type of text carries with it important information that helps in\nvideo referencing, indexing and retrieval."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2500v1", 
    "title": "A New Algorithm Based Entropic Threshold for Edge Detection in Images", 
    "arxiv-id": "1211.2500v1", 
    "author": "Mohamed A. El-Sayed", 
    "publish": "2012-11-12T02:56:08Z", 
    "summary": "Edge detection is one of the most critical tasks in automatic image analysis.\nThere exists no universal edge detection method which works well under all\nconditions. This paper shows the new approach based on the one of the most\nefficient techniques for edge detection, which is entropy-based thresholding.\nThe main advantages of the proposed method are its robustness and its\nflexibility. We present experimental results for this method, and compare\nresults of the algorithm against several leading edge detection methods, such\nas Canny, LOG, and Sobel. Experimental results demonstrate that the proposed\nmethod achieves better result than some classic methods and the quality of the\nedge detector of the output images is robust and decrease the computation time."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2502v1", 
    "title": "New Edge Detection Technique based on the Shannon Entropy in Gray Level   Images", 
    "arxiv-id": "1211.2502v1", 
    "author": "Tarek Abd-El Hafeez", 
    "publish": "2012-11-12T03:06:18Z", 
    "summary": "Edge detection is an important field in image processing. Edges characterize\nobject boundaries and are therefore useful for segmentation, registration,\nfeature extraction, and identification of objects in a scene. In this paper, an\napproach utilizing an improvement of Baljit and Amar method which uses Shannon\nentropy other than the evaluation of derivatives of the image in detecting\nedges in gray level images has been proposed. The proposed method can reduce\nthe CPU time required for the edge detection process and the quality of the\nedge detector of the output images is robust. A standard test images, the\nreal-world and synthetic images are used to compare the results of the proposed\nedge detector with the Baljit and Amar edge detector method. In order to\nvalidate the results, the run time of the proposed method and the pervious\nmethod are presented. It has been observed that the proposed edge detector\nworks effectively for different gray scale digital images. The performance\nevaluation of the proposed technique in terms of the measured CPU time and the\nquality of edge detector method are presented. Experimental results demonstrate\nthat the proposed method achieve better result than the relevant classic\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2863v1", 
    "title": "Multi-Sensor Fusion via Reduction of Dimensionality", 
    "arxiv-id": "1211.2863v1", 
    "author": "Alon Schclar", 
    "publish": "2012-11-13T01:05:42Z", 
    "summary": "Large high-dimensional datasets are becoming more and more popular in an\nincreasing number of research areas. Processing the high dimensional data\nincurs a high computational cost and is inherently inefficient since many of\nthe values that describe a data object are redundant due to noise and inner\ncorrelations. Consequently, the dimensionality, i.e. the number of values that\nare used to describe a data object, needs to be reduced prior to any other\nprocessing of the data. The dimensionality reduction removes, in most cases,\nnoise from the data and reduces substantially the computational cost of\nalgorithms that are applied to the data.\n  In this thesis, a novel coherent integrated methodology is introduced\n(theory, algorithm and applications) to reduce the dimensionality of\nhigh-dimensional datasets. The method constructs a diffusion process among the\ndata coordinates via a random walk. The dimensionality reduction is obtained\nbased on the eigen-decomposition of the Markov matrix that is associated with\nthe random walk. The proposed method is utilized for: (a) segmentation and\ndetection of anomalies in hyper-spectral images; (b) segmentation of\nmulti-contrast MRI images; and (c) segmentation of video sequences.\n  We also present algorithms for: (a) the characterization of materials using\ntheir spectral signatures to enable their identification; (b) detection of\nvehicles according to their acoustic signatures; and (c) classification of\nvascular vessels recordings to detect hyper-tension and cardio-vascular\ndiseases.\n  The proposed methodology and algorithms produce excellent results that\nsuccessfully compete with current state-of-the-art algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.3901v1", 
    "title": "Visual Recognition of Isolated Swedish Sign Language Signs", 
    "arxiv-id": "1211.3901v1", 
    "author": "Hedvig Kjellstrom", 
    "publish": "2012-11-16T14:29:31Z", 
    "summary": "We present a method for recognition of isolated Swedish Sign Language signs.\nThe method will be used in a game intended to help children training signing at\nhome, as a complement to training with a teacher. The target group is not\nprimarily deaf children, but children with language disorders. Using sign\nlanguage as a support in conversation has been shown to greatly stimulate the\nspeech development of such children. The signer is captured with an RGB-D\n(Kinect) sensor, which has three advantages over a regular RGB camera. Firstly,\nit allows complex backgrounds to be removed easily. We segment the hands and\nface based on skin color and depth information. Secondly, it helps with the\nresolution of hand over face occlusion. Thirdly, signs take place in 3D; some\naspects of the signs are defined by hand motion vertically to the image plane.\nThis motion can be estimated if the depth is observable. The 3D motion of the\nhands relative to the torso are used as a cue together with the hand shape, and\nHMMs trained with this input are used for classification. To obtain higher\nrobustness towards differences across signers, Fisher Linear Discriminant\nAnalysis is used to find the combinations of features that are most descriptive\nfor each sign, regardless of signer. Experiments show that the system can\ndistinguish signs from a challenging 94 word vocabulary with a precision of up\nto 94% in the signer dependent case and up to 47% in the signer independent\ncase."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4264v1", 
    "title": "Non-Local Patch Regression: Robust Image Denoising in Patch Space", 
    "arxiv-id": "1211.4264v1", 
    "author": "Amit Singer", 
    "publish": "2012-11-18T22:36:43Z", 
    "summary": "It was recently demonstrated in [Chaudhury et al.,Non-Local Euclidean\nMedians,2012] that the denoising performance of Non-Local Means (NLM) can be\nimproved at large noise levels by replacing the mean by the robust Euclidean\nmedian. Numerical experiments on synthetic and natural images showed that the\nlatter consistently performed better than NLM beyond a certain noise level, and\nsignificantly so for images with sharp edges. The Euclidean mean and median can\nbe put into a common regression (on the patch space) framework, in which the\nl_2 norm of the residuals is considered in the former, while the l_1 norm is\nconsidered in the latter. The natural question then is what happens if we\nconsider l_p (0<p<1) regression? We investigate this possibility in this paper."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4307v1", 
    "title": "Efficient Superimposition Recovering Algorithm", 
    "arxiv-id": "1211.4307v1", 
    "author": "Changshui Zhang", 
    "publish": "2012-11-19T05:44:24Z", 
    "summary": "In this article, we address the issue of recovering latent transparent layers\nfrom superimposition images. Here, we assume we have the estimated\ntransformations and extracted gradients of latent layers. To rapidly recover\nhigh-quality image layers, we propose an Efficient Superimposition Recovering\nAlgorithm (ESRA) by extending the framework of accelerated gradient method. In\naddition, a key building block (in each iteration) in our proposed method is\nthe proximal operator calculating. Here we propose to employ a dual approach\nand present our Parallel Algorithm with Constrained Total Variation (PACTV)\nmethod. Our recovering method not only reconstructs high-quality layers without\ncolor-bias problem, but also theoretically guarantees good convergence\nperformance."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4499v1", 
    "title": "Rate-Distortion Analysis of Multiview Coding in a DIBR Framework", 
    "arxiv-id": "1211.4499v1", 
    "author": "Pascal Frossard", 
    "publish": "2012-11-19T17:09:56Z", 
    "summary": "Depth image based rendering techniques for multiview applications have been\nrecently introduced for efficient view generation at arbitrary camera\npositions. Encoding rate control has thus to consider both texture and depth\ndata. Due to different structures of depth and texture images and their\ndifferent roles on the rendered views, distributing the available bit budget\nbetween them however requires a careful analysis. Information loss due to\ntexture coding affects the value of pixels in synthesized views while errors in\ndepth information lead to shift in objects or unexpected patterns at their\nboundaries. In this paper, we address the problem of efficient bit allocation\nbetween textures and depth data of multiview video sequences. We adopt a\nrate-distortion framework based on a simplified model of depth and texture\nimages. Our model preserves the main features of depth and texture images.\nUnlike most recent solutions, our method permits to avoid rendering at encoding\ntime for distortion estimation so that the encoding complexity is not\naugmented. In addition to this, our model is independent of the underlying\ninpainting method that is used at decoder. Experiments confirm our theoretical\nresults and the efficiency of our rate allocation strategy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4771v1", 
    "title": "Matching Through Features and Features Through Matching", 
    "arxiv-id": "1211.4771v1", 
    "author": "Yanchao Yang", 
    "publish": "2012-11-20T15:15:56Z", 
    "summary": "This paper addresses how to construct features for the problem of image\ncorrespondence, in particular, the paper addresses how to construct features so\nas to maintain the right level of invariance versus discriminability. We show\nthat without additional prior knowledge of the 3D scene, the right tradeoff\ncannot be established in a pre-processing step of the images as is typically\ndone in most feature-based matching methods. However, given knowledge of the\nsecond image to match, the tradeoff between invariance and discriminability of\nfeatures in the first image is less ambiguous. This suggests to setup the\nproblem of feature extraction and matching as a joint estimation problem. We\ndevelop a possible mathematical framework, a possible computational algorithm,\nand we give example demonstration on finding correspondence on images related\nby a scene that undergoes large 3D deformation of non-planar objects and camera\nviewpoint change."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.5355v1", 
    "title": "Cobb Angle Measurement of Scoliosis with Reduced Variability", 
    "arxiv-id": "1211.5355v1", 
    "author": "Prasanna K. Lenka", 
    "publish": "2012-11-22T19:09:29Z", 
    "summary": "Cobb angle, which is a measure of spinal curvature is the standard method for\nquantifying the magnitude of Scoliosis related to spinal deformity in\northopedics. Determining the Cobb angle through manual process is subject to\nhuman errors. In this work, we propose a methodology to measure the magnitude\nof Cobb angle, which appreciably reduces the variability related to its\nmeasurement compared to the related works. The proposed methodology is\nfacilitated by using a suitable new improved version of Non-Local Means for\nimage denoisation and Otsus automatic threshold selection for Canny edge\ndetection. We have selected NLM for preprocessing of the image as it is one of\nthe fine states of art for image denoisation and helps in retaining the image\nquality. Trimmedmean, median are more robust to outliners than mean and\nfollowing this concept we observed that NLM denoising quality performance can\nbe enhanced by using Euclidean trimmed-mean replacing the mean. To prove the\nbetter performance of the Non-Local Euclidean Trimmed-mean denoising filter, we\nhave provided some comparative study results of the proposed denoising\ntechnique with traditional NLM and NonLocal Euclidean Medians. The experimental\nresults for Cobb angle measurement over intra observer and inter observer\nexperimental data reveals the better performance and superiority of the\nproposed approach compared to the related works. MATLAB2009b image processing\ntoolbox was used for the purpose of simulation and verification of the proposed\nmethodology."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1211.5712v1", 
    "title": "Detection of elliptical shapes via cross-entropy clustering", 
    "arxiv-id": "1211.5712v1", 
    "author": "Krzysztof Misztal", 
    "publish": "2012-11-24T23:08:15Z", 
    "summary": "The problem of finding elliptical shapes in an image will be considered. We\ndiscuss the solution which uses cross-entropy clustering. The proposed method\nallows the search for ellipses with predefined sizes and position in the space.\nMoreover, it works well for search of ellipsoids in higher dimensions."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1212.0030v1", 
    "title": "Viewpoint Invariant Object Detector", 
    "arxiv-id": "1212.0030v1", 
    "author": "Andrew Habib", 
    "publish": "2012-11-30T22:35:19Z", 
    "summary": "Object Detection is the task of identifying the existence of an object class\ninstance and locating it within an image. Difficulties in handling high\nintra-class variations constitute major obstacles to achieving high performance\non standard benchmark datasets (scale, viewpoint, lighting conditions and\norientation variations provide good examples). Suggested model aims at\nproviding more robustness to detecting objects suffering severe distortion due\nto < 60{\\deg} viewpoint changes. In addition, several model computational\nbottlenecks have been resolved leading to a significant increase in the model\nperformance (speed and space) without compromising the resulting accuracy.\nFinally, we produced two illustrative applications showing the potential of the\nobject detection technology being deployed in real life applications; namely\ncontent-based image search and content-based video search."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1212.0134v1", 
    "title": "Fingertip Detection: A Fast Method with Natural Hand", 
    "arxiv-id": "1212.0134v1", 
    "author": "Ankit Chaudhary", 
    "publish": "2012-12-01T16:59:07Z", 
    "summary": "Many vision based applications have used fingertips to track or manipulate\ngestures in their applications. Gesture identification is a natural way to pass\nthe signals to the machine, as the human express its feelings most of the time\nwith hand expressions. Here a novel time efficient algorithm has been described\nfor fingertip detection. This method is invariant to hand direction and in\npreprocessing it cuts only hand part from the full image, hence further\ncomputation would be much faster than processing full image. Binary silhouette\nof the input image is generated using HSV color space based skin filter and\nhand cropping done based on intensity histogram of the hand image"
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1212.0291v1", 
    "title": "An Image Based Technique for Enhancement of Underwater Images", 
    "arxiv-id": "1212.0291v1", 
    "author": "P. U. Praveen Kumar", 
    "publish": "2012-12-03T05:57:46Z", 
    "summary": "The underwater images usually suffers from non-uniform lighting, low\ncontrast, blur and diminished colors. In this paper, we proposed an image based\npreprocessing technique to enhance the quality of the underwater images. The\nproposed technique comprises a combination of four filters such as homomorphic\nfiltering, wavelet denoising, bilateral filter and contrast equalization. These\nfilters are applied sequentially on degraded underwater images. The literature\nsurvey reveals that image based preprocessing algorithms uses standard filter\ntechniques with various combinations. For smoothing the image, the image based\npreprocessing algorithms uses the anisotropic filter. The main drawback of the\nanisotropic filter is that iterative in nature and computation time is high\ncompared to bilateral filter. In the proposed technique, in addition to other\nthree filters, we employ a bilateral filter for smoothing the image. The\nexperimentation is carried out in two stages. In the first stage, we have\nconducted various experiments on captured images and estimated optimal\nparameters for bilateral filter. Similarly, optimal filter bank and optimal\nwavelet shrinkage function are estimated for wavelet denoising. In the second\nstage, we conducted the experiments using estimated optimal parameters, optimal\nfilter bank and optimal wavelet shrinkage function for evaluating the proposed\ntechnique. We evaluated the technique using quantitative based criteria such as\na gradient magnitude histogram and Peak Signal to Noise Ratio (PSNR). Further,\nthe results are qualitatively evaluated based on edge detection results. The\nproposed technique enhances the quality of the underwater images and can be\nemployed prior to apply computer vision techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6222-8800", 
    "link": "http://arxiv.org/pdf/1212.0318v1", 
    "title": "Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its   Applications", 
    "arxiv-id": "1212.0318v1", 
    "author": "M. H. M. Krishna Prasad", 
    "publish": "2012-12-03T08:55:52Z", 
    "summary": "Image fusion is the process of integrating multiple images of the same scene\ninto a single fused image to reduce uncertainty and minimizing redundancy while\nextracting all the useful information from the source images. Image fusion\nprocess is required for different applications like medical imaging, remote\nsensing, medical imaging, machine vision, biometrics and military applications\nwhere quality and critical information is required. In this paper, image fusion\nusing fuzzy and neuro fuzzy logic approaches utilized to fuse images from\ndifferent sensors, in order to enhance visualization. The proposed work further\nexplores comparison between fuzzy based image fusion and neuro fuzzy fusion\ntechnique along with quality evaluation indices for image fusion like image\nquality index, mutual information measure, fusion factor, fusion symmetry,\nfusion index, root mean square error, peak signal to noise ratio, entropy,\ncorrelation coefficient and spatial frequency. Experimental results obtained\nfrom fusion process prove that the use of the neuro fuzzy based image fusion\napproach shows better performance in first two test cases while in the third\ntest case fuzzy based image fusion technique gives better results."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0383v1", 
    "title": "GLCM-based chi-square histogram distance for automatic detection of   defects on patterned textures", 
    "arxiv-id": "1212.0383v1", 
    "author": "P. Nagabhushan", 
    "publish": "2012-12-03T13:40:41Z", 
    "summary": "Chi-square histogram distance is one of the distance measures that can be\nused to find dissimilarity between two histograms. Motivated by the fact that\ntexture discrimination by human vision system is based on second-order\nstatistics, we make use of histogram of gray-level co-occurrence matrix (GLCM)\nthat is based on second-order statistics and propose a new machine vision\nalgorithm for automatic defect detection on patterned textures. Input defective\nimages are split into several periodic blocks and GLCMs are computed after\nquantizing the gray levels from 0-255 to 0-63 to keep the size of GLCM compact\nand to reduce computation time. Dissimilarity matrix derived from chi-square\ndistances of the GLCMs is subjected to hierarchical clustering to automatically\nidentify defective and defect-free blocks. Effectiveness of the proposed method\nis demonstrated through experiments on defective real-fabric images of 2 major\nwallpaper groups (pmm and p4m groups)."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0402v1", 
    "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild", 
    "arxiv-id": "1212.0402v1", 
    "author": "Mubarak Shah", 
    "publish": "2012-12-03T14:45:31Z", 
    "summary": "We introduce UCF101 which is currently the largest dataset of human actions.\nIt consists of 101 action classes, over 13k clips and 27 hours of video data.\nThe database consists of realistic user uploaded videos containing camera\nmotion and cluttered background. Additionally, we provide baseline action\nrecognition results on this new dataset using standard bag of words approach\nwith overall performance of 44.5%. To the best of our knowledge, UCF101 is\ncurrently the most challenging dataset of actions due to its large number of\nclasses, large number of clips and also unconstrained nature of such clips."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0433v1", 
    "title": "Compressive Schlieren Deflectometry", 
    "arxiv-id": "1212.0433v1", 
    "author": "Luc Joannes", 
    "publish": "2012-12-03T16:21:07Z", 
    "summary": "Schlieren deflectometry aims at characterizing the deflections undergone by\nrefracted incident light rays at any surface point of a transparent object. For\nsmooth surfaces, each surface location is actually associated with a sparse\ndeflection map (or spectrum). This paper presents a novel method to\ncompressively acquire and reconstruct such spectra. This is achieved by\naltering the way deflection information is captured in a common Schlieren\nDeflectometer, i.e., the deflection spectra are indirectly observed by the\nprinciple of spread spectrum compressed sensing. These observations are\nrealized optically using a 2-D Spatial Light Modulator (SLM) adjusted to the\ncorresponding sensing basis and whose modulations encode the light deviation\nsubsequently recorded by a CCD camera. The efficiency of this approach is\ndemonstrated experimentally on the observation of few test objects. Further,\nusing a simple parametrization of the deflection spectra we show that relevant\nkey parameters can be directly computed using the measurements, avoiding full\nreconstruction."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0888v1", 
    "title": "Unmixing of Hyperspectral Data Using Robust Statistics-based NMF", 
    "arxiv-id": "1212.0888v1", 
    "author": "Hassan Ghassemian", 
    "publish": "2012-12-04T21:59:35Z", 
    "summary": "Mixed pixels are presented in hyperspectral images due to low spatial\nresolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels\nspectra into endmembers spectra and abundance fractions. In this paper using of\nrobust statistics-based nonnegative matrix factorization (RNMF) for spectral\nunmixing of hyperspectral data is investigated. RNMF uses a robust cost\nfunction and iterative updating procedure, so is not sensitive to outliers.\nThis method has been applied to simulated data using USGS spectral library,\nAVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF\nmethod based on SAD and AAD measures. Results demonstrate that this method can\nbe used efficiently for hyperspectral unmixing purposes."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.image.2013.05.001", 
    "link": "http://arxiv.org/pdf/1212.1073v2", 
    "title": "Kernel Estimation from Salient Structure for Robust Motion Deblurring", 
    "arxiv-id": "1212.1073v2", 
    "author": "Xianfeng Gu", 
    "publish": "2012-12-05T16:02:43Z", 
    "summary": "Blind image deblurring algorithms have been improving steadily in the past\nyears. Most state-of-the-art algorithms, however, still cannot perform\nperfectly in challenging cases, especially in large blur setting. In this\npaper, we focus on how to estimate a good kernel estimate from a single blurred\nimage based on the image structure. We found that image details caused by\nblurring could adversely affect the kernel estimation, especially when the blur\nkernel is large. One effective way to eliminate these details is to apply image\ndenoising model based on the Total Variation (TV). First, we developed a novel\nmethod for computing image structures based on TV model, such that the\nstructures undermining the kernel estimation will be removed. Second, to\nmitigate the possible adverse effect of salient edges and improve the\nrobustness of kernel estimation, we applied a gradient selection method. Third,\nwe proposed a novel kernel estimation method, which is capable of preserving\nthe continuity and sparsity of the kernel and reducing the noises. Finally, we\ndeveloped an adaptive weighted spatial prior, for the purpose of preserving\nsharp edges in latent image restoration. The effectiveness of our method is\ndemonstrated by experiments on various kinds of challenging examples."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.image.2013.05.001", 
    "link": "http://arxiv.org/pdf/1212.1329v1", 
    "title": "Automatic Detection of Texture Defects Using Texture-Periodicity and   Gabor Wavelets", 
    "arxiv-id": "1212.1329v1", 
    "author": "P. Nagabhushan", 
    "publish": "2012-12-06T14:17:21Z", 
    "summary": "In this paper, we propose a machine vision algorithm for automatically\ndetecting defects in textures belonging to 16 out of 17 wallpaper groups using\ntexture-periodicity and a family of Gabor wavelets. Input defective images are\nsubjected to Gabor wavelet transformation in multi-scales and\nmulti-orientations and a resultant image is obtained in L2 norm. The resultant\nimage is split into several periodic blocks and energy of each block is used as\na feature space to automatically identify defective and defect-free blocks\nusing Ward's hierarchical clustering. Experiments on defective fabric images of\nthree major wallpaper groups, namely, pmm, p2 and p4m, show that the proposed\nmethod is robust in finding fabric defects without human intervention and can\nbe used for automatic defect detection in fabric industries."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.image.2013.05.001", 
    "link": "http://arxiv.org/pdf/1212.1819v2", 
    "title": "A fair comparison of many max-tree computation algorithms (Extended   version of the paper submitted to ISMM 2013", 
    "arxiv-id": "1212.1819v2", 
    "author": "Thierry G\u00e9raud", 
    "publish": "2012-12-08T17:38:40Z", 
    "summary": "With the development of connected filters for the last decade, many\nalgorithms have been proposed to compute the max-tree. Max-tree allows to\ncompute the most advanced connected operators in a simple way. However, no fair\ncomparison of algorithms has been proposed yet and the choice of an algorithm\nover an other depends on many parameters. Since the need of fast algorithms is\nobvious for production code, we present an in depth comparison of five\nalgorithms and some variations of them in a unique framework. Finally, a\ndecision tree will be proposed to help user in choosing the right algorithm\nwith respect to their data."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2245v1", 
    "title": "Fast and Robust Linear Motion Deblurring", 
    "arxiv-id": "1212.2245v1", 
    "author": "Martin L\u00e4uter", 
    "publish": "2012-12-10T23:00:10Z", 
    "summary": "We investigate efficient algorithmic realisations for robust deconvolution of\ngrey-value images with known space-invariant point-spread function, with\nemphasis on 1D motion blur scenarios. The goal is to make deconvolution\nsuitable as preprocessing step in automated image processing environments with\ntight time constraints. Candidate deconvolution methods are selected for their\nrestoration quality, robustness and efficiency. Evaluation of restoration\nquality and robustness on synthetic and real-world test images leads us to\nfocus on a combination of Wiener filtering with few iterations of robust and\nregularised Richardson-Lucy deconvolution. We discuss algorithmic optimisations\nfor specific scenarios. In the case of uniform linear motion blur in coordinate\ndirection, it is possible to achieve real-time performance (less than 50 ms) in\nsingle-threaded CPU computation on images of $256\\times256$ pixels. For more\ngeneral space-invariant blur settings, still favourable computation times are\nobtained. Exemplary parallel implementations demonstrate that the proposed\nmethod also achieves real-time performance for general 1D motion blurs in a\nmulti-threaded CPU setting, and for general 2D blurs on a GPU."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2278v2", 
    "title": "Inverting and Visualizing Features for Object Detection", 
    "arxiv-id": "1212.2278v2", 
    "author": "Antonio Torralba", 
    "publish": "2012-12-11T01:59:51Z", 
    "summary": "We introduce algorithms to visualize feature spaces used by object detectors.\nThe tools in this paper allow a human to put on `HOG goggles' and perceive the\nvisual world as a HOG based object detector sees it. We found that these\nvisualizations allow us to analyze object detection systems in new ways and\ngain new insight into the detector's failures. For example, when we visualize\nthe features for high scoring false alarms, we discovered that, although they\nare clearly wrong in image space, they do look deceptively similar to true\npositives in feature space. This result suggests that many of these false\nalarms are caused by our choice of feature space, and indicates that creating a\nbetter learning algorithm or building bigger datasets is unlikely to correct\nthese errors. By visualizing feature spaces, we can gain a more intuitive\nunderstanding of our detection systems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2546v1", 
    "title": "A Learning Framework for Morphological Operators using Counter-Harmonic   Mean", 
    "arxiv-id": "1212.2546v1", 
    "author": "J\u00fcrgen Schmidhuber", 
    "publish": "2012-12-11T17:29:04Z", 
    "summary": "We present a novel framework for learning morphological operators using\ncounter-harmonic mean. It combines concepts from morphology and convolutional\nneural networks. A thorough experimental validation analyzes basic\nmorphological operators dilation and erosion, opening and closing, as well as\nthe much more complex top-hat transform, for which we report a real-world\napplication from the steel industry. Using online learning and stochastic\ngradient descent, our system learns both the structuring element and the\ncomposition of operators. It scales well to large datasets and online settings."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2692v1", 
    "title": "Enhanced skin colour classifier using RGB Ratio model", 
    "arxiv-id": "1212.2692v1", 
    "author": "Mohd Nasir Ismail", 
    "publish": "2012-12-12T03:01:00Z", 
    "summary": "Skin colour detection is frequently been used for searching people, face\ndetection, pornographic filtering and hand tracking. The presence of skin or\nnon-skin in digital image can be determined by manipulating pixels colour or\npixels texture. The main problem in skin colour detection is to represent the\nskin colour distribution model that is invariant or least sensitive to changes\nin illumination condition. Another problem comes from the fact that many\nobjects in the real world may possess almost similar skin-tone colour such as\nwood, leather, skin-coloured clothing, hair and sand. Moreover, skin colour is\ndifferent between races and can be different from a person to another, even\nwith people of the same ethnicity. Finally, skin colour will appear a little\ndifferent when different types of camera are used to capture the object or\nscene. The objective in this study is to develop a skin colour classifier based\non pixel-based using RGB ratio model. The RGB ratio model is a newly proposed\nmethod that belongs under the category of an explicitly defined skin region\nmodel. This skin classifier was tested with SIdb dataset and two benchmark\ndatasets; UChile and TDSD datasets to measure classifier performance. The\nperformance of skin classifier was measured based on true positive (TF) and\nfalse positive (FP) indicator. This newly proposed model was compared with\nKovac, Saleh and Swift models. The experimental results showed that the RGB\nratio model outperformed all the other models in term of detection rate. The\nRGB ratio model is able to reduce FP detection that caused by reddish objects\ncolour as well as be able to detect darkened skin and skin covered by shadow."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2823v1", 
    "title": "Tracking Revisited using RGBD Camera: Baseline and Benchmark", 
    "arxiv-id": "1212.2823v1", 
    "author": "Jianxiong Xiao", 
    "publish": "2012-12-12T14:02:41Z", 
    "summary": "Although there has been significant progress in the past decade,tracking is\nstill a very challenging computer vision task, due to problems such as\nocclusion and model drift.Recently, the increased popularity of depth sensors\ne.g. Microsoft Kinect has made it easy to obtain depth data at low cost.This\nmay be a game changer for tracking, since depth information can be used to\nprevent model drift and handle occlusion.In this paper, we construct a\nbenchmark dataset of 100 RGBD videos with high diversity, including deformable\nobjects, various occlusion conditions and moving cameras. We propose a very\nsimple but strong baseline model for RGBD tracking, and present a quantitative\ncomparison of several state-of-the-art tracking algorithms.Experimental results\nshow that including depth information and reasoning about occlusion\nsignificantly improves tracking performance. The datasets, evaluation details,\nsource code for the baseline algorithm, and instructions for submitting new\nmodels will be made available online after acceptance."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0051788", 
    "link": "http://arxiv.org/pdf/1212.2860v1", 
    "title": "Pituitary Adenoma Volumetry with 3D Slicer", 
    "arxiv-id": "1212.2860v1", 
    "author": "Ron Kikinis", 
    "publish": "2012-12-12T16:12:32Z", 
    "summary": "In this study, we present pituitary adenoma volumetry using the free and open\nsource medical image computing platform for biomedical research: (3D) Slicer.\nVolumetric changes in cerebral pathologies like pituitary adenomas are a\ncritical factor in treatment decisions by physicians and in general the volume\nis acquired manually. Therefore, manual slice-by-slice segmentations in\nmagnetic resonance imaging (MRI) data, which have been obtained at regular\nintervals, are performed. In contrast to this manual time consuming\nslice-by-slice segmentation process Slicer is an alternative which can be\nsignificantly faster and less user intensive. In this contribution, we compare\npure manual segmentations of ten pituitary adenomas with semi-automatic\nsegmentations under Slicer. Thus, physicians drew the boundaries completely\nmanually on a slice-by-slice basis and performed a Slicer-enhanced segmentation\nusing the competitive region-growing based module of Slicer named GrowCut.\nResults showed that the time and user effort required for GrowCut-based\nsegmentations were on average about thirty percent less than the pure manual\nsegmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC)\nbetween the manual and the Slicer-based segmentations to proof that the two are\ncomparable yielding an average DSC of 81.97\\pm3.39%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0051788", 
    "link": "http://arxiv.org/pdf/1212.3268v3", 
    "title": "Robust image reconstruction from multi-view measurements", 
    "arxiv-id": "1212.3268v3", 
    "author": "Pierre Vandergheynst", 
    "publish": "2012-12-13T19:00:17Z", 
    "summary": "We propose a novel method to accurately reconstruct a set of images\nrepresenting a single scene from few linear multi-view measurements. Each\nobserved image is modeled as the sum of a background image and a foreground\none. The background image is common to all observed images but undergoes\ngeometric transformations, as the scene is observed from different viewpoints.\nIn this paper, we assume that these geometric transformations are represented\nby a few parameters, e.g., translations, rotations, affine transformations,\netc.. The foreground images differ from one observed image to another, and are\nused to model possible occlusions of the scene. The proposed reconstruction\nalgorithm estimates jointly the images and the transformation parameters from\nthe available multi-view measurements. The ideal solution of this multi-view\nimaging problem minimizes a non-convex functional, and the reconstruction\ntechnique is an alternating descent method built to minimize this functional.\nThe convergence of the proposed algorithm is studied, and conditions under\nwhich the sequence of estimated images and parameters converges to a critical\npoint of the non-convex functional are provided. Finally, the efficiency of the\nalgorithm is demonstrated using numerical simulations for applications such as\ncompressed sensing or super-resolution."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0051788", 
    "link": "http://arxiv.org/pdf/1212.3373v1", 
    "title": "A Novel Directional Weighted Minimum Deviation (DWMD) Based Filter for   Removal of Random Valued Impulse Noise", 
    "arxiv-id": "1212.3373v1", 
    "author": "Somnath Mukhopadhyay", 
    "publish": "2012-12-14T00:13:11Z", 
    "summary": "The most median-based de noising methods works fine for restoring the images\ncorrupted by Randomn Valued Impulse Noise with low noise level but very poor\nwith highly corrupted images. In this paper a directional weighted minimum\ndeviation (DWMD) based filter has been proposed for removal of high random\nvalued impulse noise (RVIN). The proposed approach based on Standard Deviation\n(SD) works in two phases. The first phase detects the contaminated pixels by\ndifferencing between the test pixel and its neighbor pixels aligned with four\nmain directions. The second phase filters only those pixels keeping others\nintact. The filtering scheme is based on minimum standard deviation of the four\ndirectional pixels. Extensive simulations show that the proposed filter not\nonly provide better performance of de noising RVIN but can preserve more\ndetails features even thin lines or dots. This technique shows better\nperformance in terms of PSNR, Image Fidelity and Computational Cost compared to\nthe existing filters."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-013-0488-6", 
    "link": "http://arxiv.org/pdf/1212.3530v5", 
    "title": "A Multi-Orientation Analysis Approach to Retinal Vessel Tracking", 
    "arxiv-id": "1212.3530v5", 
    "author": "Bart ter Haar Romeny", 
    "publish": "2012-12-14T17:04:03Z", 
    "summary": "This paper presents a method for retinal vasculature extraction based on\nbiologically inspired multi-orientation analysis. We apply multi-orientation\nanalysis via so-called invertible orientation scores, modeling the cortical\ncolumns in the visual system of higher mammals. This allows us to generically\ndeal with many hitherto complex problems inherent to vessel tracking, such as\ncrossings, bifurcations, parallel vessels, vessels of varying widths and\nvessels with high curvature. Our approach applies tracking in invertible\norientation scores via a novel geometrical principle for curve optimization in\nthe Euclidean motion group SE(2). The method runs fully automatically and\nprovides a detailed model of the retinal vasculature, which is crucial as a\nsound basis for further quantitative analysis of the retina, especially in\nscreening applications."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-013-0488-6", 
    "link": "http://arxiv.org/pdf/1212.3767v2", 
    "title": "Visual Objects Classification with Sliding Spatial Pyramid Matching", 
    "arxiv-id": "1212.3767v2", 
    "author": "Yong Haur Tay", 
    "publish": "2012-12-16T09:10:54Z", 
    "summary": "We present a method for visual object classification using only a single\nfeature, transformed color SIFT with a variant of Spatial Pyramid Matching\n(SPM) that we called Sliding Spatial Pyramid Matching (SSPM), trained with an\nensemble of linear regression (provided by LINEAR) to obtained state of the art\nresult on Caltech-101 of 83.46%. SSPM is a special version of SPM where instead\nof dividing an image into K number of regions, a subwindow of fixed size is\nslide around the image with a fixed step size. For each subwindow, a histogram\nof visual words is generated. To obtained the visual vocabulary, instead of\nperforming K-means clustering, we randomly pick N exemplars from the training\nset and encode them with a soft non-linear mapping method. We then trained 15\nmodels, each with a different visual word size with linear regression. All 15\nmodels are then averaged together to form a single strong model."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-013-0488-6", 
    "link": "http://arxiv.org/pdf/1212.4527v1", 
    "title": "GMM-Based Hidden Markov Random Field for Color Image and 3D Volume   Segmentation", 
    "arxiv-id": "1212.4527v1", 
    "author": "Quan Wang", 
    "publish": "2012-12-18T22:30:23Z", 
    "summary": "In this project, we first study the Gaussian-based hidden Markov random field\n(HMRF) model and its expectation-maximization (EM) algorithm. Then we\ngeneralize it to Gaussian mixture model-based hidden Markov random field. The\nalgorithm is implemented in MATLAB. We also apply this algorithm to color image\nsegmentation problems and 3D volume segmentation problems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-013-0488-6", 
    "link": "http://arxiv.org/pdf/1212.4608v1", 
    "title": "Perceptually Motivated Shape Context Which Uses Shape Interiors", 
    "arxiv-id": "1212.4608v1", 
    "author": "Ramakrishna Kakarala", 
    "publish": "2012-12-19T09:40:09Z", 
    "summary": "In this paper, we identify some of the limitations of current-day shape\nmatching techniques. We provide examples of how contour-based shape matching\ntechniques cannot provide a good match for certain visually similar shapes. To\novercome this limitation, we propose a perceptually motivated variant of the\nwell-known shape context descriptor. We identify that the interior properties\nof the shape play an important role in object recognition and develop a\ndescriptor that captures these interior properties. We show that our method can\neasily be augmented with any other shape matching algorithm. We also show from\nour experiments that the use of our descriptor can significantly improve the\nretrieval rates."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-013-0488-6", 
    "link": "http://arxiv.org/pdf/1212.5352v1", 
    "title": "On the Adaptability of Neural Network Image Super-Resolution", 
    "arxiv-id": "1212.5352v1", 
    "author": "Yong Haur Tay", 
    "publish": "2012-12-21T07:30:38Z", 
    "summary": "In this paper, we described and developed a framework for Multilayer\nPerceptron (MLP) to work on low level image processing, where MLP will be used\nto perform image super-resolution. Meanwhile, MLP are trained with different\ntypes of images from various categories, hence analyse the behaviour and\nperformance of the neural network. The tests are carried out using qualitative\ntest, in which Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR) and\nStructural Similarity Index (SSIM). The results showed that MLP trained with\nsingle image category can perform reasonably well compared to methods proposed\nby other researchers."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1212.5656v1", 
    "title": "High-precision camera distortion measurements with a \"calibration harp\"", 
    "arxiv-id": "1212.5656v1", 
    "author": "Jean-Michel Morel", 
    "publish": "2012-12-22T05:00:01Z", 
    "summary": "This paper addresses the high precision measurement of the distortion of a\ndigital camera from photographs. Traditionally, this distortion is measured\nfrom photographs of a flat pattern which contains aligned elements.\nNevertheless, it is nearly impossible to fabricate a very flat pattern and to\nvalidate its flatness. This fact limits the attainable measurable precisions.\nIn contrast, it is much easier to obtain physically very precise straight lines\nby tightly stretching good quality strings on a frame. Taking literally\n\"plumb-line methods\", we built a \"calibration harp\" instead of the classic flat\npatterns to obtain a high precision measurement tool, demonstrably reaching\n2/100 pixel precisions. The harp is complemented with the algorithms computing\nautomatically from harp photographs two different and complementary lens\ndistortion measurements. The precision of the method is evaluated on images\ncorrected by state-of-the-art distortion correction algorithms, and by popular\nsoftware. Three applications are shown: first an objective and reliable\nmeasurement of the result of any distortion correction. Second, the harp\npermits to control state-of-the art global camera calibration algorithms: It\npermits to select the right distortion model, thus avoiding internal\ncompensation errors inherent to these methods. Third, the method replaces\nmanual procedures in other distortion correction methods, makes them fully\nautomatic, and increases their reliability and precision."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1212.5720v2", 
    "title": "Hierarchical Graphical Models for Multigroup Shape Analysis using   Expectation Maximization with Sampling in Kendall's Shape Space", 
    "arxiv-id": "1212.5720v2", 
    "author": "Suyash P. Awate", 
    "publish": "2012-12-22T20:27:22Z", 
    "summary": "This paper proposes a novel framework for multi-group shape analysis relying\non a hierarchical graphical statistical model on shapes within a population.The\nframework represents individual shapes as point setsmodulo translation,\nrotation, and scale, following the notion in Kendall shape space.While\nindividual shapes are derived from their group shape model, each group shape\nmodel is derived from a single population shape model. The hierarchical model\nfollows the natural organization of population data and the top level in the\nhierarchy provides a common frame of reference for multigroup shape analysis,\ne.g. classification and hypothesis testing. Unlike typical shape-modeling\napproaches, the proposed model is a generative model that defines a joint\ndistribution of object-boundary data and the shape-model variables.\nFurthermore, it naturally enforces optimal correspondences during the process\nof model fitting and thereby subsumes the so-called correspondence problem. The\nproposed inference scheme employs an expectation maximization (EM) algorithm\nthat treats the individual and group shape variables as hidden random variables\nand integrates them out before estimating the parameters (population mean and\nvariance and the group variances). The underpinning of the EM algorithm is the\nsampling of pointsets, in Kendall shape space, from their posterior\ndistribution, for which we exploit a highly-efficient scheme based on\nHamiltonian Monte Carlo simulation. Experiments in this paper use the fitted\nhierarchical model to perform (1) hypothesis testing for comparison between\npairs of groups using permutation testing and (2) classification for image\nretrieval. The paper validates the proposed framework on simulated data and\ndemonstrates results on real data."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1212.6094v1", 
    "title": "Large Scale Strongly Supervised Ensemble Metric Learning, with   Applications to Face Verification and Retrieval", 
    "arxiv-id": "1212.6094v1", 
    "author": "Kai Yu", 
    "publish": "2012-12-25T22:49:31Z", 
    "summary": "Learning Mahanalobis distance metrics in a high- dimensional feature space is\nvery difficult especially when structural sparsity and low rank are enforced to\nimprove com- putational efficiency in testing phase. This paper addresses both\naspects by an ensemble metric learning approach that consists of sparse block\ndiagonal metric ensembling and join- t metric learning as two consecutive\nsteps. The former step pursues a highly sparse block diagonal metric by\nselecting effective feature groups while the latter one further exploits\ncorrelations between selected feature groups to obtain an accurate and low rank\nmetric. Our algorithm considers all pairwise or triplet constraints generated\nfrom training samples with explicit class labels, and possesses good scala-\nbility with respect to increasing feature dimensionality and growing data\nvolumes. Its applications to face verification and retrieval outperform\nexisting state-of-the-art methods in accuracy while retaining high efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1212.6933v3", 
    "title": "On Automation and Medical Image Interpretation, With Applications for   Laryngeal Imaging", 
    "arxiv-id": "1212.6933v3", 
    "author": "H. J. Moukalled", 
    "publish": "2012-12-31T17:38:02Z", 
    "summary": "Indeed, these are exciting times. We are in the heart of a digital\nrenaissance. Automation and computer technology allow engineers and scientists\nto fabricate processes that amalgamate quality of life. We anticipate much\ngrowth in medical image interpretation and understanding, due to the influx of\ncomputer technologies. This work should serve as a guide to introduce the\nreader to core themes in theoretical computer science, as well as imaging\napplications for understanding vocal-fold vibrations. In this work, we motivate\nthe use of automation, review some mathematical models of computation. We\npresent a proof of a classical problem in image analysis that cannot be\nautomated by means of algorithms. Furthermore, discuss some applications for\nprocessing medical images of the vocal folds, and discuss some of the\nexhilarating directions the art of automation will take vocal-fold image\ninterpretation and quite possibly other areas of biomedical image analysis."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.0446v1", 
    "title": "Sparse Camera Network for Visual Surveillance -- A Comprehensive Survey", 
    "arxiv-id": "1302.0446v1", 
    "author": "Stephen J. Maybank", 
    "publish": "2013-02-03T02:40:29Z", 
    "summary": "Technological advances in sensor manufacture, communication, and computing\nare stimulating the development of new applications that are transforming\ntraditional vision systems into pervasive intelligent camera networks. The\nanalysis of visual cues in multi-camera networks enables a wide range of\napplications, from smart home and office automation to large area surveillance\nand traffic surveillance. While dense camera networks - in which most cameras\nhave large overlapping fields of view - are well studied, we are mainly\nconcerned with sparse camera networks. A sparse camera network undertakes large\narea surveillance using as few cameras as possible, and most cameras have\nnon-overlapping fields of view with one another. The task is challenging due to\nthe lack of knowledge about the topological structure of the network,\nvariations in the appearance and motion of specific tracking targets in\ndifferent views, and the difficulties of understanding composite events in the\nnetwork. In this review paper, we present a comprehensive survey of recent\nresearch results to address the problems of intra-camera tracking, topological\nstructure learning, target appearance modeling, and global activity\nunderstanding in sparse camera networks. A number of current open research\nissues are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.0494v4", 
    "title": "Local Structure Matching Driven by Joint-Saliency-Structure Adaptive   Kernel Regression", 
    "arxiv-id": "1302.0494v4", 
    "author": "Yisong Lv", 
    "publish": "2013-02-03T14:14:27Z", 
    "summary": "For nonrigid image registration, matching the particular structures (or the\noutliers) that have missing correspondence and/or local large deformations, can\nbe more difficult than matching the common structures with small deformations\nin the two images. Most existing works depend heavily on the outlier\nsegmentation to remove the outlier effect in the registration. Moreover, these\nworks do not handle simultaneously the missing correspondences and local large\ndeformations. In this paper, we defined the nonrigid image registration as a\nlocal adaptive kernel regression which locally reconstruct the moving image's\ndense deformation vectors from the sparse deformation vectors in the\nmulti-resolution block matching. The kernel function of the kernel regression\nadapts its shape and orientation to the reference image's structure to gather\nmore deformation vector samples of the same structure for the iterative\nregression computation, whereby the moving image's local deformations could be\ncompliant with the reference image's local structures. To estimate the local\ndeformations around the outliers, we use joint saliency map that highlights the\ncorresponding saliency structures (called Joint Saliency Structures, JSSs) in\nthe two images to guide the dense deformation reconstruction by emphasizing\nthose JSSs' sparse deformation vectors in the kernel regression. The\nexperimental results demonstrate that by using local JSS adaptive kernel\nregression, the proposed method achieves almost the best performance in\nalignment of all challenging image pairs with outlier structures compared with\nother five state-of-the-art nonrigid registration algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.0689v1", 
    "title": "Multi-scale Visual Attention & Saliency Modelling with Decision Theory", 
    "arxiv-id": "1302.0689v1", 
    "author": "Kah-Phooi Seng", 
    "publish": "2013-02-04T14:00:52Z", 
    "summary": "Bottom-up saliency, an early human visual processing, behaves like binary\nclassification of interest and null hypothesis. Its discriminant power, mutual\ninformation of image features and class distribution, is closely related to\nsaliency value by the well-known centre-surround theory. As classification\naccuracy very much depends on window sizes, the discriminant saliency (power)\nvaries according to sampling scales. Discriminating power estimation in\nmulti-scales framework needs integrating with wavelet transformation and then\nestimating statistical discrepancy of two consecutive scales (centre-surround\nwindows) by Hidden Markov Tree (HMT) model. Finally, multi-scale discriminant\nsaliency (MDIS) maps are combined by the maximum information rule to synthesize\na final saliency map. All MDIS maps are evaluated with standard quantitative\ntools (NSS,LCC,AUC) on N.Bruce's database with ground truth data as\neye-tracking locations ; as well assessed qualitatively by visual examination\nof individual cases. For evaluating MDIS against well-known AIM saliency\nmethod, simulations are needed and described in details with several\ninteresting conclusions, drawn for further research directions."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.1007v1", 
    "title": "Image Denoising Using Interquartile Range Filter with Local Averaging", 
    "arxiv-id": "1302.1007v1", 
    "author": "Firas Ajil Jassim", 
    "publish": "2013-02-05T12:02:53Z", 
    "summary": "Image denoising is one of the fundamental problems in image processing. In\nthis paper, a novel approach to suppress noise from the image is conducted by\napplying the interquartile range (IQR) which is one of the statistical methods\nused to detect outlier effect from a dataset. A window of size kXk was\nimplemented to support IQR filter. Each pixel outside the IQR range of the kXk\nwindow is treated as noisy pixel. The estimation of the noisy pixels was\nobtained by local averaging. The essential advantage of applying IQR filter is\nto preserve edge sharpness better of the original image. A variety of test\nimages have been used to support the proposed filter and PSNR was calculated\nand compared with median filter. The experimental results on standard test\nimages demonstrate this filter is simpler and better performing than median\nfilter."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.1294v1", 
    "title": "Image Interpolation Using Kriging Technique for Spatial Data", 
    "arxiv-id": "1302.1294v1", 
    "author": "Fawzi Hasan Altaany", 
    "publish": "2013-02-06T09:22:58Z", 
    "summary": "Image interpolation has been used spaciously by customary interpolation\ntechniques. Recently, Kriging technique has been widely implemented in\nsimulation area and geostatistics for prediction. In this article, Kriging\ntechnique was used instead of the classical interpolation methods to predict\nthe unknown points in the digital image array. The efficiency of the proposed\ntechnique was proven using the PSNR and compared with the traditional\ninterpolation techniques. The results showed that Kriging technique is almost\naccurate as cubic interpolation and in some images Kriging has higher accuracy.\nA miscellaneous test images have been used to consolidate the proposed\ntechnique."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.1296v1", 
    "title": "Hybrid Image Segmentation using Discerner Cluster in FCM and Histogram   Thresholding", 
    "arxiv-id": "1302.1296v1", 
    "author": "Firas Ajil Jassim", 
    "publish": "2013-02-06T09:31:59Z", 
    "summary": "Image thresholding has played an important role in image segmentation. This\npaper presents a hybrid approach for image segmentation based on the\nthresholding by fuzzy c-means (THFCM) algorithm for image segmentation. The\ngoal of the proposed approach is to find a discerner cluster able to find an\nautomatic threshold. The algorithm is formulated by applying the standard FCM\nclustering algorithm to the frequencies (y-values) on the smoothed histogram.\nHence, the frequencies of an image can be used instead of the conventional\nwhole data of image. The cluster that has the highest peak which represents the\nmaximum frequency in the image histogram will play as an excellent role in\ndetermining a discerner cluster to the grey level image. Then, the pixels\nbelong to the discerner cluster represent an object in the gray level histogram\nwhile the other clusters represent a background. Experimental results with\nstandard test images have been obtained through the proposed approach (THFCM)."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.1300v1", 
    "title": "Kriging Interpolation Filter to Reduce High Density Salt and Pepper   Noise", 
    "arxiv-id": "1302.1300v1", 
    "author": "Firas Ajil Jassim", 
    "publish": "2013-02-06T09:45:18Z", 
    "summary": "Image denoising is a critical issue in the field of digital image processing.\nThis paper proposes a novel Salt & Pepper noise suppression by developing a\nKriging Interpolation Filter (KIF) for image denoising. Gray-level images\ndegraded with Salt & Pepper noise have been considered. A sequential search for\nnoise detection was made using kXk window size to determine non-noisy pixels\nonly. The non-noisy pixels are passed into Kriging interpolation method to\npredict their absent neighbor pixels that were noisy pixels at the first phase.\nThe utilization of Kriging interpolation filter proves that it is very\nimpressive to suppress high noise density. It has been found that Kriging\nInterpolation filter achieves noise reduction without loss of edges and\ndetailed information. Comparisons with existing algorithms are done using\nquality metrics like PSNR and MSE to assess the proposed filter."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.1690v1", 
    "title": "A Fast Learning Algorithm for Image Segmentation with Max-Pooling   Convolutional Networks", 
    "arxiv-id": "1302.1690v1", 
    "author": "J\u00fcrgen Schmidhuber", 
    "publish": "2013-02-07T10:17:07Z", 
    "summary": "We present a fast algorithm for training MaxPooling Convolutional Networks to\nsegment images. This type of network yields record-breaking performance in a\nvariety of tasks, but is normally trained on a computationally expensive\npatch-by-patch basis. Our new method processes each training image in a single\npass, which is vastly more efficient.\n  We validate the approach in different scenarios and report a 1500-fold\nspeed-up. In an application to automated steel defect detection and\nsegmentation, we obtain excellent performance with short training times."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.2073v2", 
    "title": "pROST : A Smoothed Lp-norm Robust Online Subspace Tracking Method for   Realtime Background Subtraction in Video", 
    "arxiv-id": "1302.2073v2", 
    "author": "Martin Kleinsteuber", 
    "publish": "2013-02-08T16:14:14Z", 
    "summary": "An increasing number of methods for background subtraction use Robust PCA to\nidentify sparse foreground objects. While many algorithms use the L1-norm as a\nconvex relaxation of the ideal sparsifying function, we approach the problem\nwith a smoothed Lp-norm and present pROST, a method for robust online subspace\ntracking. The algorithm is based on alternating minimization on manifolds.\nImplemented on a graphics processing unit it achieves realtime performance.\nExperimental results on a state-of-the-art benchmark for background subtraction\non real-world video data indicate that the method succeeds at a broad variety\nof background subtraction scenarios, and it outperforms competing approaches\nwhen video quality is deteriorated by camera jitter."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002134", 
    "link": "http://arxiv.org/pdf/1302.3155v1", 
    "title": "Morphological Analusis Of The Left Ventricular Eendocardial Surface   Using A Bag-Of-Features Descriptor", 
    "arxiv-id": "1302.3155v1", 
    "author": "Szilard Voros", 
    "publish": "2013-02-13T16:25:19Z", 
    "summary": "The limitations of conventional imaging techniques have hitherto precluded a\nthorough and formal investigation of the complex morphology of the left\nventricular (LV) endocardial surface and its relation to the severity of\nCoronary Artery Disease (CAD). Recent developments in high-resolution\nMultirow-Detector Computed Tomography (MDCT) scanner technology have enabled\nthe imaging of LV endocardial surface morphology in a single heart beat.\nAnalysis of high-resolution Computed Tomography (CT) images from a 320-MDCT\nscanner allows the study of the relationship between percent Diameter Stenosis\n(DS) of the major coronary arteries and localization of the cardiac segments\naffected by coronary arterial stenosis. In this paper a novel approach for the\nanalysis using a combination of rigid transformation-invariant shape\ndescriptors and a more generalized isometry-invariant Bag-of-Features (BoF)\ndescriptor, is proposed and implemented. The proposed approach is shown to be\nsuccessful in identifying, localizing and quantifying the incidence and extent\nof CAD and thus, is seen to have a potentially significant clinical impact.\nSpecifically, the association between the incidence and extent of CAD,\ndetermined via the percent DS measurements of the major coronary arteries, and\nthe alterations in the endocardial surface morphology is formally quantified. A\nmultivariate regression test performed on a strict leave-one-out basis are\nshown to exhibit a distinct pattern in terms of the correlation coefficient\nwithin the cardiac segments where the incidence of coronary arterial stenosis\nis localized."
},{
    "category": "cs.CV", 
    "doi": "10.1137/130909858", 
    "link": "http://arxiv.org/pdf/1302.3785v2", 
    "title": "Analysis of Descent-Based Image Registration", 
    "arxiv-id": "1302.3785v2", 
    "author": "Pascal Frossard", 
    "publish": "2013-02-15T15:45:32Z", 
    "summary": "We present a performance analysis for image registration with gradient\ndescent methods. We consider a typical multiscale registration setting where\nthe global 2-D translation between a pair of images is estimated by smoothing\nthe images and minimizing the distance between them with gradient descent. Our\nstudy particularly concentrates on the effect of noise and low-pass filtering\non the alignment accuracy. We adopt an analytic representation for images and\nanalyze the well-behavedness of the image distance function by estimating the\nneighborhood of translations for which it is free of undesired local minima.\nThis corresponds to the neighborhood of translation vectors that are correctly\ncomputable with a simple gradient descent minimization. We show that the area\nof this neighborhood increases at least quadratically with the smoothing filter\nsize, which justifies the use of a smoothing step in image registration with\nlocal optimizers such as gradient descent. We then examine the effect of noise\non the alignment accuracy and derive an upper bound for the alignment error in\nterms of the noise properties and filter size. Our main finding is that the\nerror increases at a rate that is at least linear with respect to the filter\nsize. Therefore, smoothing improves the well-behavedness of the distance\nfunction; however, this comes at the cost of amplifying the alignment error in\nnoisy settings. Our results provide a mathematical insight about why\nhierarchical techniques are effective in image registration, suggesting that\nthe multiscale coarse-to-fine alignment strategy of these techniques is very\nsuitable from the perspective of the trade-off between the well-behavedness of\nthe objective function and the registration accuracy. To the best of our\nknowledge, this is the first such study for descent-based image registration."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2005.846030", 
    "link": "http://arxiv.org/pdf/1302.3900v1", 
    "title": "Robust Image Segmentation in Low Depth Of Field Images", 
    "arxiv-id": "1302.3900v1", 
    "author": "Michael Weiler", 
    "publish": "2013-02-15T21:49:26Z", 
    "summary": "In photography, low depth of field (DOF) is an important technique to\nemphasize the object of interest (OOI) within an image. Thus, low DOF images\nare widely used in the application area of macro, portrait or sports\nphotography. When viewing a low DOF image, the viewer implicitly concentrates\non the regions that are sharper regions of the image and thus segments the\nimage into regions of interest and non regions of interest which has a major\nimpact on the perception of the image. Thus, a robust algorithm for the fully\nautomatic detection of the OOI in low DOF images provides valuable information\nfor subsequent image processing and image retrieval. In this paper we propose a\nrobust and parameterless algorithm for the fully automatic segmentation of low\nDOF images. We compare our method with three similar methods and show the\nsuperior robustness even though our algorithm does not require any parameters\nto be set by hand. The experiments are conducted on a real world data set with\nhigh and low DOF images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.4043v1", 
    "title": "A new scheme of signature extraction for iris authentication", 
    "arxiv-id": "1302.4043v1", 
    "author": "Chokri Ben Amar", 
    "publish": "2013-02-17T08:11:58Z", 
    "summary": "Iris recognition, a relatively new biometric technology, has great\nadvantages, such as variability, stability and security, thus is the most\npromising for high security environment. Iris recognition is proposed in this\nreport. We describe some methods, the first one is based on grey level\nhistogram to extract the pupil, the second is based on elliptic and parabolic\nHOUGH transformation to determinate the edge of iris, upper and lower eyelids,\nthe third we used 2D Gabor Wavelets to encode the iris and finally we used the\nHamming distance for authentication."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.4673v1", 
    "title": "Good Recognition is Non-Metric", 
    "arxiv-id": "1302.4673v1", 
    "author": "Terrance E. Boult", 
    "publish": "2013-02-19T17:02:34Z", 
    "summary": "Recognition is the fundamental task of visual cognition, yet how to formalize\nthe general recognition problem for computer vision remains an open issue. The\nproblem is sometimes reduced to the simplest case of recognizing matching\npairs, often structured to allow for metric constraints. However, visual\nrecognition is broader than just pair matching -- especially when we consider\nmulti-class training data and large sets of features in a learning context.\nWhat we learn and how we learn it has important implications for effective\nalgorithms. In this paper, we reconsider the assumption of recognition as a\npair matching test, and introduce a new formal definition that captures the\nbroader context of the problem. Through a meta-analysis and an experimental\nassessment of the top algorithms on popular data sets, we gain a sense of how\noften metric properties are violated by good recognition algorithms. By\nstudying these violations, useful insights come to light: we make the case that\nlocally metric algorithms should leverage outside information to solve the\ngeneral recognition problem."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5189v1", 
    "title": "Object Detection in Real Images", 
    "arxiv-id": "1302.5189v1", 
    "author": "Dilip K. Prasad", 
    "publish": "2013-02-21T06:06:47Z", 
    "summary": "Object detection and recognition are important problems in computer vision.\nSince these problems are meta-heuristic, despite a lot of research, practically\nusable, intelligent, real-time, and dynamic object detection/recognition\nmethods are still unavailable. We propose a new object detection/recognition\nmethod, which improves over the existing methods in every stage of the object\ndetection/recognition process. In addition to the usual features, we propose to\nuse geometric shapes, like linear cues, ellipses and quadrangles, as additional\nfeatures. The full potential of geometric cues is exploited by using them to\nextract other features in a robust, computationally efficient, and less\nmeta-heuristic manner. We also propose a new hierarchical codebook, which\nprovides good generalization and discriminative properties. The codebook\nenables fast multi-path inference mechanisms based on propagation of\nconditional likelihoods, that make it robust to occlusion and noise. It has the\ncapability of dynamic learning. We also propose a new learning method that has\ngenerative and discriminative learning capabilities, does not need large and\nfully supervised training dataset, and is capable of online learning. The\npreliminary work of detecting geometric shapes in real images has been\ncompleted. This preliminary work is the focus of this report. Future path for\nrealizing the proposed object detection/recognition method is also discussed in\nbrief."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5894v1", 
    "title": "Four Side Distance: A New Fourier Shape Signature", 
    "arxiv-id": "1302.5894v1", 
    "author": "Abdolah Chalechale", 
    "publish": "2013-02-24T10:49:39Z", 
    "summary": "Shape is one of the main features in content based image retrieval (CBIR).\nThis paper proposes a new shape signature. In this technique, features of each\nshape are extracted based on four sides of the rectangle that covers the shape.\nThe proposed technique is Fourier based and it is invariant to translation,\nscaling and rotation. The retrieval performance between some commonly used\nFourier based signatures and the proposed four sides distance (FSD) signature\nhas been tested using MPEG-7 database. Experimental results are shown that the\nFSD signature has better performance compared with those signatures."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5957v1", 
    "title": "Shape Characterization via Boundary Distortion", 
    "arxiv-id": "1302.5957v1", 
    "author": "Serguei Komech", 
    "publish": "2013-02-24T21:38:20Z", 
    "summary": "In this paper, we derive new shape descriptors based on a directional\ncharacterization. The main idea is to study the behavior of the shape\nneighborhood under family of transformations. We obtain a description invariant\nwith respect to rotation, reflection, translation and scaling. A well-defined\nmetric is then proposed on the associated feature space. We show the continuity\nof this metric. Some results on shape retrieval are provided on two databases\nto show the accuracy of the proposed shape metric."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5985v1", 
    "title": "A Meta-Theory of Boundary Detection Benchmarks", 
    "arxiv-id": "1302.5985v1", 
    "author": "Christof Koch", 
    "publish": "2013-02-25T03:12:12Z", 
    "summary": "Human labeled datasets, along with their corresponding evaluation algorithms,\nplay an important role in boundary detection. We here present a psychophysical\nexperiment that addresses the reliability of such benchmarks. To find better\nremedies to evaluate the performance of any boundary detection algorithm, we\npropose a computational framework to remove inappropriate human labels and\nestimate the intrinsic properties of boundaries."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.6379v1", 
    "title": "Image-based Face Detection and Recognition: \"State of the Art\"", 
    "arxiv-id": "1302.6379v1", 
    "author": "Zeeshan Ahmed", 
    "publish": "2013-02-26T10:12:30Z", 
    "summary": "Face recognition from image or video is a popular topic in biometrics\nresearch. Many public places usually have surveillance cameras for video\ncapture and these cameras have their significant value for security purpose. It\nis widely acknowledged that the face recognition have played an important role\nin surveillance system as it doesn't need the object's cooperation. The actual\nadvantages of face based identification over other biometrics are uniqueness\nand acceptance. As human face is a dynamic object having high degree of\nvariability in its appearance, that makes face detection a difficult problem in\ncomputer vision. In this field, accuracy and speed of identification is a main\nissue.\n  The goal of this paper is to evaluate various face detection and recognition\nmethods, provide complete solution for image based face detection and\nrecognition with higher accuracy, better response rate as an initial step for\nvideo surveillance. Solution is proposed based on performed tests on various\nface rich databases in terms of subjects, pose, emotions, race and light."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.6957v1", 
    "title": "Ensemble Sparse Models for Image Analysis", 
    "arxiv-id": "1302.6957v1", 
    "author": "Andreas Spanias", 
    "publish": "2013-02-27T18:58:36Z", 
    "summary": "Sparse representations with learned dictionaries have been successful in\nseveral image analysis applications. In this paper, we propose and analyze the\nframework of ensemble sparse models, and demonstrate their utility in image\nrestoration and unsupervised clustering. The proposed ensemble model\napproximates the data as a linear combination of approximations from multiple\n\\textit{weak} sparse models. Theoretical analysis of the ensemble model reveals\nthat even in the worst-case, the ensemble can perform better than any of its\nconstituent individual models. The dictionaries corresponding to the individual\nsparse models are obtained using either random example selection or boosted\napproaches. Boosted approaches learn one dictionary per round such that the\ndictionary learned in a particular round is optimized for the training examples\nhaving high reconstruction error in the previous round. Results with compressed\nrecovery show that the ensemble representations lead to a better performance\ncompared to using a single dictionary obtained with the conventional\nalternating minimization approach. The proposed ensemble models are also used\nfor single image superresolution, and we show that they perform comparably to\nthe recent approaches. In unsupervised clustering, experiments show that the\nproposed model performs better than baseline approaches in several standard\ndatasets."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.7180v1", 
    "title": "Fast Matching by 2 Lines of Code for Large Scale Face Recognition   Systems", 
    "arxiv-id": "1302.7180v1", 
    "author": "Stan Z. Li", 
    "publish": "2013-02-28T12:59:41Z", 
    "summary": "In this paper, we propose a method to apply the popular cascade classifier\ninto face recognition to improve the computational efficiency while keeping\nhigh recognition rate. In large scale face recognition systems, because the\nprobability of feature templates coming from different subjects is very high,\nmost of the matching pairs will be rejected by the early stages of the cascade.\nTherefore, the cascade can improve the matching speed significantly. On the\nother hand, using the nested structure of the cascade, we could drop some\nstages at the end of feature to reduce the memory and bandwidth usage in some\nresources intensive system while not sacrificing the performance too much. The\ncascade is learned by two steps. Firstly, some kind of prepared features are\ngrouped into several nested stages. And then, the threshold of each stage is\nlearned to achieve user defined verification rate (VR). In the paper, we take a\nlandmark based Gabor+LDA face recognition system as baseline to illustrate the\nprocess and advantages of the proposed method. However, the use of this method\nis very generic and not limited in face recognition, which can be easily\ngeneralized to other biometrics as a post-processing module. Experiments on the\nFERET database show the good performance of our baseline and an experiment on a\nself-collected large scale database illustrates that the cascade can improve\nthe matching speed significantly."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1303.0479v2", 
    "title": "Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for   Nonrigid Image Registration", 
    "arxiv-id": "1303.0479v2", 
    "author": "Binjie Qin", 
    "publish": "2013-03-03T09:15:25Z", 
    "summary": "Joint saliency map (JSM) [1] was developed to assign high joint saliency\nvalues to the corresponding saliency structures (called Joint Saliency\nStructures, JSSs) but zero or low joint saliency values to the outliers (or\nmismatches) that are introduced by missing correspondence or local large\ndeformations between the reference and moving images to be registered. JSM\nguides the local structure matching in nonrigid registration by emphasizing\nthese JSSs' sparse deformation vectors in adaptive kernel regression of\nhierarchical sparse deformation vectors for iterative dense deformation\nreconstruction. By designing an effective superpixel-based local structure\nscale estimator to compute the reference structure's structure scale, we\nfurther propose to determine the scale (the width) of kernels in the adaptive\nkernel regression through combining the structure scales to JSM-based scales of\nmismatch between the local saliency structures. Therefore, we can adaptively\nselect the sample size of sparse deformation vectors to reconstruct the dense\ndeformation vectors for accurately matching the every local structures in the\ntwo images. The experimental results demonstrate better accuracy of our method\nin aligning two images with missing correspondence and local large deformation\nthan the state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0582v2", 
    "title": "Multiple Kernel Sparse Representations for Supervised and Unsupervised   Learning", 
    "arxiv-id": "1303.0582v2", 
    "author": "Andreas Spanias", 
    "publish": "2013-03-03T23:41:34Z", 
    "summary": "In complex visual recognition tasks it is typical to adopt multiple\ndescriptors, that describe different aspects of the images, for obtaining an\nimproved recognition performance. Descriptors that have diverse forms can be\nfused into a unified feature space in a principled manner using kernel methods.\nSparse models that generalize well to the test data can be learned in the\nunified kernel space, and appropriate constraints can be incorporated for\napplication in supervised and unsupervised learning. In this paper, we propose\nto perform sparse coding and dictionary learning in the multiple kernel space,\nwhere the weights of the ensemble kernel are tuned based on graph-embedding\nprinciples such that class discrimination is maximized. In our proposed\nalgorithm, dictionaries are inferred using multiple levels of 1-D subspace\nclustering in the kernel space, and the sparse codes are obtained using a\nsimple levelwise pursuit scheme. Empirical results for object recognition and\nimage clustering show that our algorithm outperforms existing sparse coding\nbased approaches, and compares favorably to other state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0633v1", 
    "title": "Omega Model for Human Detection and Counting for application in Smart   Surveillance System", 
    "arxiv-id": "1303.0633v1", 
    "author": "Karen Das", 
    "publish": "2013-03-04T08:01:36Z", 
    "summary": "Driven by the significant advancements in technology and social issues such\nas security management, there is a strong need for Smart Surveillance System in\nour society today. One of the key features of a Smart Surveillance System is\nefficient human detection and counting such that the system can decide and\nlabel events on its own. In this paper we propose a new, novel and robust\nmodel, The Omega Model, for detecting and counting human beings present in the\nscene. The proposed model employs a set of four distinct descriptors for\nidentifying the unique features of the head, neck and shoulder regions of a\nperson. This unique head neck shoulder signature given by the Omega Model\nexploits the challenges such as inter person variations in size and shape of\npeoples head, neck and shoulder regions to achieve robust detection of human\nbeings even under partial occlusion, dynamically changing background and\nvarying illumination conditions. After experimentation we observe and analyze\nthe influences of each of the four descriptors on the system performance and\ncomputation speed and conclude that a weight based decision making system\nproduces the best results. Evaluation results on a number of images indicate\nthe validation of our method in actual situation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0634v1", 
    "title": "Indian Sign Language Recognition Using Eigen Value Weighted Euclidean   Distance Based Classification Technique", 
    "arxiv-id": "1303.0634v1", 
    "author": "Karen Das", 
    "publish": "2013-03-04T08:06:07Z", 
    "summary": "Sign Language Recognition is one of the most growing fields of research\ntoday. Many new techniques have been developed recently in these fields. Here\nin this paper, we have proposed a system using Eigen value weighted Euclidean\ndistance as a classification technique for recognition of various Sign\nLanguages of India. The system comprises of four parts: Skin Filtering, Hand\nCropping, Feature Extraction and Classification. Twenty four signs were\nconsidered in this paper, each having ten samples, thus a total of two hundred\nforty images was considered for which recognition rate obtained was 97 percent."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0635v1", 
    "title": "Recognition of Facial Expression Using Eigenvector Based Distributed   Features and Euclidean Distance Based Decision Making Technique", 
    "arxiv-id": "1303.0635v1", 
    "author": "Karen Das", 
    "publish": "2013-03-04T08:09:22Z", 
    "summary": "In this paper, an Eigenvector based system has been presented to recognize\nfacial expressions from digital facial images. In the approach, firstly the\nimages were acquired and cropping of five significant portions from the image\nwas performed to extract and store the Eigenvectors specific to the\nexpressions. The Eigenvectors for the test images were also computed, and\nfinally the input facial image was recognized when similarity was obtained by\ncalculating the minimum Euclidean distance between the test image and the\ndifferent expressions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0644v1", 
    "title": "Automatic symmetry based cluster approach for anomalous brain   identification in PET scan image : An Analysis", 
    "arxiv-id": "1303.0644v1", 
    "author": "K. Raja", 
    "publish": "2013-03-04T08:52:45Z", 
    "summary": "Medical image segmentation is referred to the segmentation of known anatomic\nstructures from different medical images. Normally, the medical data researches\nare more complicated and an exclusive structures. This computer aided diagnosis\nis used for assisting doctors in evaluating medical imagery or in recognizing\nabnormal findings in a medical image. To integrate the specialized knowledge\nfor medical data processing is helpful to form a real useful healthcare\ndecision making system. This paper studies the different symmetry based\ndistances applied in clustering algorithms and analyzes symmetry approach for\nPositron Emission Tomography (PET) scan image segmentation. Unlike CT and MRI,\nthe PET scan identifies the structure of blood flow to and from organs. PET\nscan also helps in early diagnosis of cancer and heart, brain and gastro\nintestinal ailments and to detect the progress of treatment. In this paper, the\nscope diagnostic task expands for PET image in various brain functions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0645v1", 
    "title": "Symmetry Based Cluster Approach for Automatic Recognition of the   Epileptic Focus in Brain Using PET Scan Image : An Analysis", 
    "arxiv-id": "1303.0645v1", 
    "author": "R. Raja", 
    "publish": "2013-03-04T09:00:23Z", 
    "summary": "Recognition of epileptic focal point is the important diagnosis when\nscreening the epilepsy patients for latent surgical cures. The accurate\nlocalization is challenging one because of the low spatial resolution images\nwith more noisy data. Positron Emission Tomography (PET) has now replaced the\nissues and caring a high resolution. This paper focuses the research of\nautomated localization of epileptic seizures in brain functional images using\nsymmetry based cluster approach. This approach presents a fully automated\nsymmetry based brain abnormality detection method for PET sequences. PET images\nare spatially normalized to Digital Imaging and Communications in Medicine\n(DICOM) standard and then it has been trained using symmetry based cluster\napproach using Medical Image Processing, Analysis & Visualization (MIPAV) tool.\nThe performance evolution is considered by the metric like accuracy of\ndiagnosis. The obtained result is surely assists the surgeon for the automated\nidentification of seizures focus."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0647v1", 
    "title": "Spatial Fuzzy C Means PET Image Segmentation of Neurodegenerative   Disorder", 
    "arxiv-id": "1303.0647v1", 
    "author": "R. Raja", 
    "publish": "2013-03-04T09:08:34Z", 
    "summary": "Nuclear image has emerged as a promising research work in medical field.\nImages from different modality meet its own challenge. Positron Emission\nTomography (PET) image may help to precisely localize disease to assist in\nplanning the right treatment for each case and saving valuable time. In this\npaper, a novel approach of Spatial Fuzzy C Means (PET SFCM) clustering\nalgorithm is introduced on PET scan image datasets. The proposed algorithm is\nincorporated the spatial neighborhood information with traditional FCM and\nupdating the objective function of each cluster. This algorithm is implemented\nand tested on huge data collection of patients with brain neuro degenerative\ndisorder such as Alzheimers disease. It has demonstrated its effectiveness by\ntesting it for real world patient data sets. Experimental results are compared\nwith conventional FCM and K Means clustering algorithm. The performance of the\nPET SFCM provides satisfactory results compared with other two algorithms"
},{
    "category": "cs.CV", 
    "doi": "10.1038/srep01364", 
    "link": "http://arxiv.org/pdf/1303.0964v1", 
    "title": "GBM Volumetry using the 3D Slicer Medical Image Computing Platform", 
    "arxiv-id": "1303.0964v1", 
    "author": "Ron Kikinis", 
    "publish": "2013-03-05T09:40:46Z", 
    "summary": "Volumetric change in glioblastoma multiforme (GBM) over time is a critical\nfactor in treatment decisions. Typically, the tumor volume is computed on a\nslice-by-slice basis using MRI scans obtained at regular intervals. (3D)Slicer\n- a free platform for biomedical research - provides an alternative to this\nmanual slice-by-slice segmentation process, which is significantly faster and\nrequires less user interaction. In this study, 4 physicians segmented GBMs in\n10 patients, once using the competitive region-growing based GrowCut\nsegmentation module of Slicer, and once purely by drawing boundaries completely\nmanually on a slice-by-slice basis. Furthermore, we provide a variability\nanalysis for three physicians for 12 GBMs. The time required for GrowCut\nsegmentation was on an average 61% of the time required for a pure manual\nsegmentation. A comparison of Slicer-based segmentation with manual\nslice-by-slice segmentation resulted in a Dice Similarity Coefficient of 88.43\n+/- 5.23% and a Hausdorff Distance of 2.32 +/- 5.23 mm."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-bmt.2013.0033", 
    "link": "http://arxiv.org/pdf/1303.1624v1", 
    "title": "On Robust Face Recognition via Sparse Encoding: the Good, the Bad, and   the Ugly", 
    "arxiv-id": "1303.1624v1", 
    "author": "Conrad Sanderson", 
    "publish": "2013-03-07T09:30:10Z", 
    "summary": "In the field of face recognition, Sparse Representation (SR) has received\nconsiderable attention during the past few years. Most of the relevant\nliterature focuses on holistic descriptors in closed-set identification\napplications. The underlying assumption in SR-based methods is that each class\nin the gallery has sufficient samples and the query lies on the subspace\nspanned by the gallery of the same class. Unfortunately, such assumption is\neasily violated in the more challenging face verification scenario, where an\nalgorithm is required to determine if two faces (where one or both have not\nbeen seen before) belong to the same person. In this paper, we first discuss\nwhy previous attempts with SR might not be applicable to verification problems.\nWe then propose an alternative approach to face verification via SR.\nSpecifically, we propose to use explicit SR encoding on local image patches\nrather than the entire face. The obtained sparse signals are pooled via\naveraging to form multiple region descriptors, which are then concatenated to\nform an overall face descriptor. Due to the deliberate loss spatial relations\nwithin each region (caused by averaging), the resulting descriptor is robust to\nmisalignment & various image deformations. Within the proposed framework, we\nevaluate several SR encoding techniques: l1-minimisation, Sparse Autoencoder\nNeural Network (SANN), and an implicit probabilistic technique based on\nGaussian Mixture Models. Thorough experiments on AR, FERET, exYaleB, BANCA and\nChokePoint datasets show that the proposed local SR approach obtains\nconsiderably better and more robust performance than several previous\nstate-of-the-art holistic SR methods, in both verification and closed-set\nidentification problems. The experiments also show that l1-minimisation based\nencoding has a considerably higher computational than the other techniques, but\nleads to higher recognition rates."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1667v1", 
    "title": "ALPRS - A New Approach for License Plate Recognition using the Sift   Algorithm", 
    "arxiv-id": "1303.1667v1", 
    "author": "Ricardo Luis Barbosa", 
    "publish": "2013-03-07T12:49:49Z", 
    "summary": "This paper presents a new approach for the automatic license plate\nrecognition, which includes the SIFT algorithm in step to locate the plate in\nthe input image. In this new approach, besides the comparison of the features\nobtained with the SIFT algorithm, the correspondence between the spatial\norientations and the positioning associated with the keypoints is also\nobserved. Afterwards, an algorithm is used for the character recognition of the\nplates, very fast, which makes it possible its application in real time. The\nresults obtained with the proposed approach presented very good success rates,\nso much for locating the characters in the input image, as for their\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1749v2", 
    "title": "Simplifying Energy Optimization using Partial Enumeration", 
    "arxiv-id": "1303.1749v2", 
    "author": "Vladimir Kolmogorov", 
    "publish": "2013-03-07T16:59:11Z", 
    "summary": "Energies with high-order non-submodular interactions have been shown to be\nvery useful in vision due to their high modeling power. Optimization of such\nenergies, however, is generally NP-hard. A naive approach that works for small\nproblem instances is exhaustive search, that is, enumeration of all possible\nlabelings of the underlying graph. We propose a general minimization approach\nfor large graphs based on enumeration of labelings of certain small patches.\nThis partial enumeration technique reduces complex high-order energy\nformulations to pairwise Constraint Satisfaction Problems with unary costs\n(uCSP), which can be efficiently solved using standard methods like TRW-S. Our\napproach outperforms a number of existing state-of-the-art algorithms on well\nknown difficult problems (e.g. curvature regularization, stereo,\ndeconvolution); it gives near global minimum and better speed.\n  Our main application of interest is curvature regularization. In the context\nof segmentation, our partial enumeration technique allows to evaluate curvature\ndirectly on small patches using a novel integral geometry approach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1761v1", 
    "title": "Improving Automatic Emotion Recognition from speech using Rhythm and   Temporal feature", 
    "arxiv-id": "1303.1761v1", 
    "author": "Tim Polzehl", 
    "publish": "2013-03-07T17:33:06Z", 
    "summary": "This paper is devoted to improve automatic emotion recognition from speech by\nincorporating rhythm and temporal features. Research on automatic emotion\nrecognition so far has mostly been based on applying features like MFCCs, pitch\nand energy or intensity. The idea focuses on borrowing rhythm features from\nlinguistic and phonetic analysis and applying them to the speech signal on the\nbasis of acoustic knowledge only. In addition to this we exploit a set of\ntemporal and loudness features. A segmentation unit is employed in starting to\nseparate the voiced/unvoiced and silence parts and features are explored on\ndifferent segments. Thereafter different classifiers are used for\nclassification. After selecting the top features using an IGR filter we are\nable to achieve a recognition rate of 80.60 % on the Berlin Emotion Database\nfor the speaker dependent framework."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1829v1", 
    "title": "Watersheds on edge or node weighted graphs \"par l'exemple\"", 
    "arxiv-id": "1303.1829v1", 
    "author": "Fernand Meyer", 
    "publish": "2013-03-07T21:15:29Z", 
    "summary": "Watersheds have been defined both for node and edge weighted graphs. We show\nthat they are identical: for each edge (resp.\\ node) weighted graph exists a\nnode (resp. edge) weighted graph with the same minima and catchment basin."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.2437v1", 
    "title": "Least-Squares FIR Models of Low-Resolution MR data for Efficient   Phase-Error Compensation with Simultaneous Artefact Removal", 
    "arxiv-id": "1303.2437v1", 
    "author": "Nyjin Thomas", 
    "publish": "2013-03-11T06:40:02Z", 
    "summary": "Signal space models in both phase-encode, and frequency-encode directions are\npresented for extrapolation of 2D partial kspace. Using the boxcar\nrepresentation of low-resolution spatial data, and a geometrical representation\nof signal space vectors in both positive and negative phase-encode directions,\na robust predictor is constructed using a series of signal space projections.\nCompared to some of the existing phase-correction methods that require\nacquisition of a pre-determined set of fractional kspace lines, the proposed\npredictor is found to be more efficient, due to its capability of exhibiting an\nequivalent degree of performance using only half the number of fractional\nlines. Robust filtering of noisy data is achieved using a second signal space\nmodel in the frequency-encode direction, bypassing the requirement of a prior\nhighpass filtering operation. The signal space is constructed from Fourier\nTransformed samples of each row in the low-resolution image. A set of FIR\nfilters are estimated by fitting a least squares model to this signal space.\nPartial kspace extrapolation using the FIR filters is shown to result in\nartifact-free reconstruction, particularly in respect of Gibbs ringing and\nstreaking type artifacts."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.2439v1", 
    "title": "Voxel-wise Weighted MR Image Enhancement using an Extended Neighborhood   Filter", 
    "arxiv-id": "1303.2439v1", 
    "author": "Chandrasekar Kesavadas", 
    "publish": "2013-03-11T06:54:26Z", 
    "summary": "We present an edge preserving and denoising filter for enhancing the features\nin images, which contain an ROI having a narrow spatial extent. Typical\nexamples include angiograms, or ROI spatially distributed in multiple locations\nand contained within an outlying region, such as in multiple-sclerosis. The\nfiltering involves determination of multiplicative weights in the spatial\ndomain using an extended set of neighborhood directions. Equivalently, the\nfiltering operation may be interpreted as a combination of directional filters\nin the frequency domain, with selective weighting for spatial frequencies\ncontained within each direction. The advantages of the proposed filter in\ncomparison to specialized non-linear filters, which operate on diffusion\nprinciple, are illustrated using numerical phantom data. The performance\nevaluation is carried out on simulated images from BrainWeb database for\nmultiple-sclerosis, acute ischemic stroke using clinically acquired FLAIR\nimages and MR angiograms."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2465v1", 
    "title": "A Low-Complexity Algorithm for Static Background Estimation from   Cluttered Image Sequences in Surveillance Contexts", 
    "arxiv-id": "1303.2465v1", 
    "author": "Brian C. Lovell", 
    "publish": "2013-03-11T09:57:49Z", 
    "summary": "For the purposes of foreground estimation, the true background model is\nunavailable in many practical circumstances and needs to be estimated from\ncluttered image sequences. We propose a sequential technique for static\nbackground estimation in such conditions, with low computational and memory\nrequirements. Image sequences are analysed on a block-by-block basis. For each\nblock location a representative set is maintained which contains distinct\nblocks obtained along its temporal line. The background estimation is carried\nout in a Markov Random Field framework, where the optimal labelling solution is\ncomputed using iterated conditional modes. The clique potentials are computed\nbased on the combined frequency response of the candidate block and its\nneighbourhood. It is assumed that the most appropriate block results in the\nsmoothest response, indirectly enforcing the spatial continuity of structures\nwithin a scene. Experiments on real-life surveillance videos demonstrate that\nthe proposed method obtains considerably better background estimates (both\nqualitatively and quantitatively) than median filtering and the recently\nproposed \"intervals of stable intensity\" method. Further experiments on the\nWallflower dataset suggest that the combination of the proposed method with a\nforeground segmentation algorithm results in improved foreground segmentation."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2607v2", 
    "title": "Joint optimization of fitting & matching in multi-view reconstruction", 
    "arxiv-id": "1303.2607v2", 
    "author": "Yuri Boykov", 
    "publish": "2013-03-11T18:14:42Z", 
    "summary": "Many standard approaches for geometric model fitting are based on pre-matched\nimage features. Typically, such pre-matching uses only feature appearances\n(e.g. SIFT) and a large number of non-unique features must be discarded in\norder to control the false positive rate. In contrast, we solve feature\nmatching and multi-model fitting problems in a joint optimization framework.\nThis paper proposes several fit-&-match energy formulations based on a\ngeneralization of the assignment problem. We developed an efficient solver\nbased on min-cost-max-flow algorithm that finds near optimal solutions. Our\napproach significantly increases the number of detected matches. In practice,\nenergy-based joint fitting & matching allows to increase the distance between\nview-points previously restricted by robustness of local SIFT-matching and to\nimprove the model fitting accuracy when compared to state-of-the-art\nmulti-model fitting techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2610v1", 
    "title": "Kernel Sparse Models for Automated Tumor Segmentation", 
    "arxiv-id": "1303.2610v1", 
    "author": "Andreas Spanias", 
    "publish": "2013-03-11T18:33:01Z", 
    "summary": "In this paper, we propose sparse coding-based approaches for segmentation of\ntumor regions from MR images. Sparse coding with data-adapted dictionaries has\nbeen successfully employed in several image recovery and vision problems. The\nproposed approaches obtain sparse codes for each pixel in brain magnetic\nresonance images considering their intensity values and location information.\nSince it is trivial to obtain pixel-wise sparse codes, and combining multiple\nfeatures in the sparse coding setup is not straightforward, we propose to\nperform sparse coding in a high-dimensional feature space where non-linear\nsimilarities can be effectively modeled. We use the training data from\nexpert-segmented images to obtain kernel dictionaries with the kernel K-lines\nclustering procedure. For a test image, sparse codes are computed with these\nkernel dictionaries, and they are used to identify the tumor regions. This\napproach is completely automated, and does not require user intervention to\ninitialize the tumor regions in a test image. Furthermore, a low complexity\nsegmentation approach based on kernel sparse codes, which allows the user to\ninitialize the tumor region, is also presented. Results obtained with both the\nproposed approaches are validated against manual segmentation by an expert\nradiologist, and the proposed methods lead to accurate tumor identification."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2685v1", 
    "title": "Bilateral Filter: Graph Spectral Interpretation and Extensions", 
    "arxiv-id": "1303.2685v1", 
    "author": "Antonio Ortega", 
    "publish": "2013-03-11T20:52:57Z", 
    "summary": "In this paper we study the bilateral filter proposed by Tomasi and Manduchi,\nas a spectral domain transform defined on a weighted graph. The nodes of this\ngraph represent the pixels in the image and a graph signal defined on the nodes\nrepresents the intensity values. Edge weights in the graph correspond to the\nbilateral filter coefficients and hence are data adaptive. Spectrum of a graph\nis defined in terms of the eigenvalues and eigenvectors of the graph Laplacian\nmatrix. We use this spectral interpretation to generalize the bilateral filter\nand propose more flexible and application specific spectral designs of\nbilateral-like filters. We show that these spectral filters can be implemented\nwith k-iterative bilateral filtering operations and do not require expensive\ndiagonalization of the Laplacian matrix."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2751v1", 
    "title": "Gaussian Mixture Model for Handwritten Script Identification", 
    "arxiv-id": "1303.2751v1", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2013-03-12T02:32:02Z", 
    "summary": "This paper presents a Gaussian Mixture Model (GMM) to identify the script of\nhandwritten words of Roman, Devanagari, Kannada and Telugu scripts. It\nemphasizes the significance of directional energies for identification of\nscript of the word. It is robust to varied image sizes and different styles of\nwriting. A GMM is modeled using a set of six novel features derived from\ndirectional energy distributions of the underlying image. The standard\ndeviation of directional energy distributions are computed by decomposing an\nimage matrix into right and left diagonals. Furthermore, deviation of\nhorizontal and vertical distributions of energies is also built-in to GMM. A\ndataset of 400 images out of 800 (200 of each script) are used for training GMM\nand the remaining is for testing. An exhaustive experimentation is carried out\nat bi-script, tri-script and multi-script level and achieved script\nidentification accuracies in percentage as 98.7, 98.16 and 96.91 respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.23", 
    "link": "http://arxiv.org/pdf/1303.2783v1", 
    "title": "Combined Learning of Salient Local Descriptors and Distance Metrics for   Image Set Face Verification", 
    "arxiv-id": "1303.2783v1", 
    "author": "Brian C. Lovell", 
    "publish": "2013-03-12T06:12:59Z", 
    "summary": "In contrast to comparing faces via single exemplars, matching sets of face\nimages increases robustness and discrimination performance. Recent image set\nmatching approaches typically measure similarities between subspaces or\nmanifolds, while representing faces in a rigid and holistic manner. Such\nrepresentations are easily affected by variations in terms of alignment,\nillumination, pose and expression. While local feature based representations\nare considerably more robust to such variations, they have received little\nattention within the image set matching area. We propose a novel image set\nmatching technique, comprised of three aspects: (i) robust descriptors of face\nregions based on local features, partly inspired by the hierarchy in the human\nvisual system, (ii) use of several subspace and exemplar metrics to compare\ncorresponding face regions, (iii) jointly learning which regions are the most\ndiscriminative while finding the optimal mixing weights for combining metrics.\nFace recognition experiments on LFW, PIE and MOBIO face datasets show that the\nproposed algorithm obtains considerably better performance than several recent\nstate-of-the-art techniques, such as Local Principal Angle and the Kernel\nAffine Hull Method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-1-4471-5195-1_21", 
    "link": "http://arxiv.org/pdf/1303.2844v1", 
    "title": "A Stochastic Grammar for Natural Shapes", 
    "arxiv-id": "1303.2844v1", 
    "author": "Pedro F. Felzenszwalb", 
    "publish": "2013-03-12T11:23:47Z", 
    "summary": "We consider object detection using a generic model for natural shapes. A\ncommon approach for object recognition involves matching object models directly\nto images. Another approach involves building intermediate representations via\na generic grouping processes. We argue that these two processes (model-based\nrecognition and grouping) may use similar computational mechanisms. By defining\na generic model for shapes we can use model-based techniques to implement a\nmid-level vision grouping process."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-1-4471-5195-1_21", 
    "link": "http://arxiv.org/pdf/1303.3087v1", 
    "title": "Statistical Texture Features based Handwritten and Printed Text   Classification in South Indian Documents", 
    "arxiv-id": "1303.3087v1", 
    "author": "Rajmohan Pardeshi", 
    "publish": "2013-03-13T04:51:22Z", 
    "summary": "In this paper, we use statistical texture features for handwritten and\nprinted text classification. We primarily aim for word level classification in\nsouth Indian scripts. Words are first extracted from the scanned document. For\neach extracted word, statistical texture features are computed such as mean,\nstandard deviation, smoothness, moment, uniformity, entropy and local range\nincluding local entropy. These feature vectors are then used to classify words\nvia k-NN classifier. We have validated the approach over several different\ndatasets. Scripts like Kannada, Telugu, Malayalam and Hindi i.e., Devanagari\nare primarily employed where an average classification rate of 99.26% is\nachieved. In addition, to provide an extensibility of the approach, we address\nRoman script by using publicly available dataset and interesting results are\nreported."
},{
    "category": "cs.CV", 
    "doi": "10.1088/1742-6596/410/1/012163", 
    "link": "http://arxiv.org/pdf/1303.3152v1", 
    "title": "Material quality assessment of silk nanofibers based on swarm   intelligence", 
    "arxiv-id": "1303.3152v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2013-03-13T13:23:21Z", 
    "summary": "In this paper, we propose a novel approach for texture analysis based on\nartificial crawler model. Our method assumes that each agent can interact with\nthe environment and each other. The evolution process converges to an\nequilibrium state according to the set of rules. For each textured image, the\nfeature vector is composed by signatures of the live agents curve at each time.\nExperimental results revealed that combining the minimum and maximum signatures\ninto one increase the classification rate. In addition, we pioneer the use of\nautonomous agents for characterizing silk fibroin scaffolds. The results\nstrongly suggest that our approach can be successfully employed for texture\nanalysis."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4160v1", 
    "title": "Improved Foreground Detection via Block-based Classifier Cascade with   Probabilistic Decision Integration", 
    "arxiv-id": "1303.4160v1", 
    "author": "Brian C. Lovell", 
    "publish": "2013-03-18T05:48:40Z", 
    "summary": "Background subtraction is a fundamental low-level processing task in numerous\ncomputer vision applications. The vast majority of algorithms process images on\na pixel-by-pixel basis, where an independent decision is made for each pixel. A\ngeneral limitation of such processing is that rich contextual information is\nnot taken into account. We propose a block-based method capable of dealing with\nnoise, illumination variations and dynamic backgrounds, while still obtaining\nsmooth contours of foreground objects. Specifically, image sequences are\nanalysed on an overlapping block-by-block basis. A low-dimensional texture\ndescriptor obtained from each block is passed through an adaptive classifier\ncascade, where each stage handles a distinct problem. A probabilistic\nforeground mask generation approach then exploits block overlaps to integrate\ninterim block-level decisions into final pixel-level foreground segmentation.\nUnlike many pixel-based methods, ad-hoc post-processing of foreground masks is\nnot required. Experiments on the difficult Wallflower and I2R datasets show\nthat the proposed approach obtains on average better results (both\nqualitatively and quantitatively) than several prominent methods. We\nfurthermore propose the use of tracking performance as an unbiased approach for\nassessing the practical usefulness of foreground segmentation methods, and show\nthat the proposed approach leads to considerable improvements in tracking\naccuracy on the CAVIAR dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4614v1", 
    "title": "Handwritten and Printed Text Separation in Real Document", 
    "arxiv-id": "1303.4614v1", 
    "author": "Vincent Poulain D'Andecy", 
    "publish": "2013-03-19T14:23:24Z", 
    "summary": "The aim of the paper is to separate handwritten and printed text from a real\ndocument embedded with noise, graphics including annotations. Relying on\nrun-length smoothing algorithm (RLSA), the extracted pseudo-lines and\npseudo-words are used as basic blocks for classification. To handle this, a\nmulti-class support vector machine (SVM) with Gaussian kernel performs a first\nlabelling of each pseudo-word including the study of local neighbourhood. It\nthen propagates the context between neighbours so that we can correct possible\nlabelling errors. Considering running time complexity issue, we propose linear\ncomplexity methods where we use k-NN with constraint. When using a kd-tree, it\nis almost linearly proportional to the number of pseudo-words. The performance\nof our system is close to 90%, even when very small learning dataset where\nsamples are basically composed of complex administrative documents."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4803v1", 
    "title": "A Survey of Appearance Models in Visual Object Tracking", 
    "arxiv-id": "1303.4803v1", 
    "author": "Anton van den Hengel", 
    "publish": "2013-03-20T01:08:33Z", 
    "summary": "Visual object tracking is a significant computer vision task which can be\napplied to many domains such as visual surveillance, human computer\ninteraction, and video compression. In the literature, researchers have\nproposed a variety of 2D appearance models. To help readers swiftly learn the\nrecent advances in 2D appearance models for visual object tracking, we\ncontribute this survey, which provides a detailed review of the existing 2D\nappearance models. In particular, this survey takes a module-based architecture\nthat enables readers to easily grasp the key points of visual object tracking.\nIn this survey, we first decompose the problem of appearance modeling into two\ndifferent processing stages: visual representation and statistical modeling.\nThen, different 2D appearance models are categorized and discussed with respect\nto their composition modules. Finally, we address several issues of interest as\nwell as the remaining challenges for future research on this topic. The\ncontributions of this survey are four-fold. First, we review the literature of\nvisual representations according to their feature-construction mechanisms\n(i.e., local and global). Second, the existing statistical modeling schemes for\ntracking-by-detection are reviewed according to their model-construction\nmechanisms: generative, discriminative, and hybrid generative-discriminative.\nThird, each type of visual representations or statistical modeling techniques\nis analyzed and discussed from a theoretical or practical viewpoint. Fourth,\nthe existing benchmark resources (e.g., source code and video datasets) are\nexamined in this survey."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4839v1", 
    "title": "The State of the Art Recognize in Arabic Script through Combination of   Online and Offline", 
    "arxiv-id": "1303.4839v1", 
    "author": "Dr. Firoj Parwej", 
    "publish": "2013-03-20T04:54:44Z", 
    "summary": "Handwriting recognition refers to the identification of written characters.\nHandwriting recognition has become an acute research area in recent years for\nthe ease of access of computer science. In this paper primarily discussed\nOn-line and Off-line handwriting recognition methods for Arabic words which are\noften used among then across the Middle East and North Africa People. Arabic\nword online handwriting recognition is a very challenging task due to its\ncursive nature. Because of the characteristic of the whole body of the Arabic\nscript, namely connectivity between the characters, thereby the segmentation of\nAn Arabic script is very difficult. In this paper we introduced an Arabic\nscript multiple classifier system for recognizing notes written on a Starboard.\nThis Arabic script multiple classifier system combines one off-line and on-line\nhandwriting recognition systems. The Arabic script recognizers are all based on\nHidden Markov Models but vary in the way of preprocessing and normalization. To\ncombine the Arabic script output sequences of the recognizers, we incrementally\nalign the word sequences using a norm string matching algorithm. The Arabic\nscript combination we could increase the system performance over the excellent\ncharacter recognizer by about 3%. The proposed technique is also the necessary\nstep towards character recognition, person identification, personality\ndetermination where input data is processed from all perspectives."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4840v1", 
    "title": "Asynchronous Cellular Operations on Gray Images Extracting Topographic   Shape Features and Their Relations", 
    "arxiv-id": "1303.4840v1", 
    "author": "Igor Polkovnikov", 
    "publish": "2013-03-20T04:59:08Z", 
    "summary": "A variety of operations of cellular automata on gray images is presented. All\noperations are of a wave-front nature finishing in a stable state. They are\nused to extract shape descripting gray objects robust to a variety of pattern\ndistortions. Topographic terms are used: \"lakes\", \"dales\", \"dales of dales\". It\nis shown how mutual object relations like \"above\" can be presented in terms of\ngray image analysis and how it can be used for character classification and for\ngray pattern decomposition. Algorithms can be realized with a parallel\nasynchronous architecture. Keywords: Pattern Recognition, Mathematical\nMorphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis,\nTopographical Shape Descriptors, Asynchronous Parallel Processors, Holes,\nCavities, Concavities, Graphs."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4845v2", 
    "title": "On Constructing the Value Function for Optimal Trajectory Problem and   its Application to Image Processing", 
    "arxiv-id": "1303.4845v2", 
    "author": "Gwang-Ho Jong", 
    "publish": "2013-03-20T06:16:55Z", 
    "summary": "We proposed an algorithm for solving Hamilton-Jacobi equation associated to\nan optimal trajectory problem for a vehicle moving inside the pre-specified\ndomain with the speed depending upon the direction of the motion and current\nposition of the vehicle. The dynamics of the vehicle is defined by an ordinary\ndifferential equation, the right hand of which is given by product of control(a\ntime dependent fuction) and a function dependent on trajectory and control. At\nsome unspecified terminal time, the vehicle reaches the boundary of the\npre-specified domain and incurs a terminal cost. We also associate the\ntraveling cost with a type of integral to the trajectory followed by vehicle.\nWe are interested in a numerical method for finding a trajectory that minimizes\nthe sum of the traveling cost and terminal cost. We developed an algorithm\nsolving the value function for general trajectory optimization problem. Our\nalgorithm is closely related to the Tsitsiklis's Fast Marching Method and J. A.\nSethian's OUM and SLF-LLL[1-4] and is a generalization of them. On the basis of\nthese results, We applied our algorithm to the image processing such as\nfingerprint verification."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.4866v1", 
    "title": "A Robust Rapid Approach to Image Segmentation with Optimal Thresholding   and Watershed Transform", 
    "arxiv-id": "1303.4866v1", 
    "author": "Neha S. Satam", 
    "publish": "2013-03-20T08:15:07Z", 
    "summary": "This paper describes a novel method for partitioning image into meaningful\nsegments. The proposed method employs watershed transform, a well-known image\nsegmentation technique. Along with that, it uses various auxiliary schemes such\nas Binary Gradient Masking, dilation which segment the image in proper way. The\nalgorithm proposed in this paper considers all these methods in effective way\nand takes little time. It is organized in such a manner so that it operates on\ninput image adaptively. Its robustness and efficiency makes it more convenient\nand suitable for all types of images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.5691v1", 
    "title": "Cortical Surface Co-Registration based on MRI Images and Photos", 
    "arxiv-id": "1303.5691v1", 
    "author": "Carlo Schaller", 
    "publish": "2013-03-22T19:07:13Z", 
    "summary": "Brain shift, i.e. the change in configuration of the brain after opening the\ndura mater, is a key problem in neuronavigation. We present an approach to\nco-register intra-operative microscope images with pre-operative MRI to adapt\nand optimize intra-operative neuronavigation. The tools are a robust\nclassification of sulci on MRI extracted cortical surfaces, guided user marking\nof most prominent sulci on a microscope image, and the actual variational\nregistration method with a fidelity energy for 3D deformations of the cortical\nsurface combined with a higher order, linear elastica type prior energy.\nFurthermore, the actual registration is validated on an artificial testbed with\nknown ground truth deformation and on real data of a neuro clinical patient."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6066v2", 
    "title": "Asymmetric Pruning for Learning Cascade Detectors", 
    "arxiv-id": "1303.6066v2", 
    "author": "Anton van den Hengel", 
    "publish": "2013-03-25T10:01:19Z", 
    "summary": "Cascade classifiers are one of the most important contributions to real-time\nobject detection. Nonetheless, there are many challenging problems arising in\ntraining cascade detectors. One common issue is that the node classifier is\ntrained with a symmetric classifier. Having a low misclassification error rate\ndoes not guarantee an optimal node learning goal in cascade classifiers, i.e.,\nan extremely high detection rate with a moderate false positive rate. In this\nwork, we present a new approach to train an effective node classifier in a\ncascade detector. The algorithm is based on two key observations: 1) Redundant\nweak classifiers can be safely discarded; 2) The final detector should satisfy\nthe asymmetric learning objective of the cascade architecture. To achieve this,\nwe separate the classifier training into two steps: finding a pool of\ndiscriminative weak classifiers/features and training the final classifier by\npruning weak classifiers which contribute little to the asymmetric learning\ncriterion (asymmetric classifier construction). Our model reduction approach\nhelps accelerate the learning time while achieving the pre-determined learning\nobjective. Experimental results on both face and car data sets verify the\neffectiveness of the proposed algorithm. On the FDDB face data sets, our\napproach achieves the state-of-the-art performance, which demonstrates the\nadvantage of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6455v1", 
    "title": "Performance Evaluation of Edge-Directed Interpolation Methods for Images", 
    "arxiv-id": "1303.6455v1", 
    "author": "Yaoqin Xie", 
    "publish": "2013-03-26T12:35:46Z", 
    "summary": "Many interpolation methods have been developed for high visual quality, but\nfail for inability to preserve image structures. Edges carry heavy structural\ninformation for detection, determination and classification. Edge-adaptive\ninterpolation approaches become a center of focus. In this paper, performance\nof four edge-directed interpolation methods comparing with two traditional\nmethods is evaluated on two groups of images. These methods include new\nedge-directed interpolation (NEDI), edge-guided image interpolation (EGII),\niterative curvature-based interpolation (ICBI), directional cubic convolution\ninterpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic.\nMeanwhile, no parameters are mentioned to measure edge-preserving ability of\nedge-adaptive interpolation approaches and we proposed two. One evaluates\naccuracy and the other measures robustness of edge-preservation ability.\nPerformance evaluation is based on six parameters. Objective assessment and\nvisual analysis are illustrated and conclusions are drawn from theoretical\nbackgrounds and practical results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6619v1", 
    "title": "An N-dimensional approach towards object based classification of   remotely sensed imagery", 
    "arxiv-id": "1303.6619v1", 
    "author": "S. K. Katiyar", 
    "publish": "2013-03-26T19:39:20Z", 
    "summary": "Remote sensing techniques are widely used for land cover classification and\nurban analysis. The availability of high resolution remote sensing imagery\nlimits the level of classification accuracy attainable from pixel-based\napproach. In this paper object-based classification scheme based on a\nhierarchical support vector machine is introduced. By combining spatial and\nspectral information, the amount of overlap between classes can be decreased;\nthereby yielding higher classification accuracy and more accurate land cover\nmaps. We have adopted certain automatic approaches based on the advanced\ntechniques as Cellular automata and Genetic Algorithm for kernel and tuning\nparameter selection. Performance evaluation of the proposed methodology in\ncomparison with the existing approaches is performed with reference to the\nBhopal city study area."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6711v1", 
    "title": "An intelligent approach towards automatic shape modeling and object   extraction from satellite images using cellular automata based algorithm", 
    "arxiv-id": "1303.6711v1", 
    "author": "S. K. Katiyar", 
    "publish": "2013-03-27T00:33:52Z", 
    "summary": "Automatic feature extraction domain has witnessed the application of many\nintelligent methodologies over past decade; however detection accuracy of these\napproaches were limited as object geometry and contextual knowledge were not\ngiven enough consideration. In this paper, we propose a frame work for accurate\ndetection of features along with automatic interpolation, and interpretation by\nmodeling feature shape as well as contextual knowledge using advanced\ntechniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed\nmethodology has been compared with contemporary methods using different\nstatistical measures. Investigations over various satellite images revealed\nthat considerable success was achieved with the CNN approach. CNN has been\neffective in modeling different complex features effectively and complexity of\nthe approach has been considerably reduced using corset optimization. The\nsystem has dynamically used spectral and spatial information for representing\ncontextual knowledge using CNN-prolog approach. System has been also proved to\nbe effective in providing intelligent interpolation and interpretation of\nrandom features."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6926v1", 
    "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing", 
    "arxiv-id": "1303.6926v1", 
    "author": "Arun P. V.", 
    "publish": "2013-03-27T18:57:12Z", 
    "summary": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6927v1", 
    "title": "An investigation towards wavelet based optimization of automatic image   registration techniques", 
    "arxiv-id": "1303.6927v1", 
    "author": "Dr. S. K. Katiyar", 
    "publish": "2013-03-27T19:02:02Z", 
    "summary": "Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.7390v2", 
    "title": "Geometric tree kernels: Classification of COPD from airway tree geometry", 
    "arxiv-id": "1303.7390v2", 
    "author": "Marleen de Bruijne", 
    "publish": "2013-03-29T13:25:17Z", 
    "summary": "Methodological contributions: This paper introduces a family of kernels for\nanalyzing (anatomical) trees endowed with vector valued measurements made along\nthe tree. While state-of-the-art graph and tree kernels use combinatorial\ntree/graph structure with discrete node and edge labels, the kernels presented\nin this paper can include geometric information such as branch shape, branch\nradius or other vector valued properties. In addition to being flexible in\ntheir ability to model different types of attributes, the presented kernels are\ncomputationally efficient and some of them can easily be computed for large\ndatasets (N of the order 10.000) of trees with 30-600 branches. Combining the\nkernels with standard machine learning tools enables us to analyze the relation\nbetween disease and anatomical tree structure and geometry. Experimental\nresults: The kernels are used to compare airway trees segmented from low-dose\nCT, endowed with branch shape descriptors and airway wall area percentage\nmeasurements made along the tree. Using kernelized hypothesis testing we show\nthat the geometric airway trees are significantly differently distributed in\npatients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy\nindividuals. The geometric tree kernels also give a significant increase in the\nclassification accuracy of COPD from geometric tree structure endowed with\nairway wall thickness measurements in comparison with state-of-the-art methods,\ngiving further insight into the relationship between airway wall thickness and\nCOPD. Software: Software for computing kernels and statistical tests is\navailable at http://image.diku.dk/aasa/software.php."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0271v2", 
    "title": "Compositional Dictionaries for Domain Adaptive Face Recognition", 
    "arxiv-id": "1308.0271v2", 
    "author": "Rama Chellappa", 
    "publish": "2013-08-01T17:27:31Z", 
    "summary": "We present a dictionary learning approach to compensate for the\ntransformation of faces due to changes in view point, illumination, resolution,\netc. The key idea of our approach is to force domain-invariant sparse coding,\ni.e., design a consistent sparse representation of the same face in different\ndomains. In this way, classifiers trained on the sparse codes in the source\ndomain consisting of frontal faces for example can be applied to the target\ndomain (consisting of faces in different poses, illumination conditions, etc)\nwithout much loss in recognition accuracy. The approach is to first learn a\ndomain base dictionary, and then describe each domain shift (identity, pose,\nillumination) using a sparse representation over the base dictionary. The\ndictionary adapted to each domain is expressed as sparse linear combinations of\nthe base dictionary. In the context of face recognition, with the proposed\ncompositional dictionary approach, a face image can be decomposed into sparse\nrepresentations for a given subject, pose and illumination respectively. This\napproach has three advantages: first, the extracted sparse representation for a\nsubject is consistent across domains and enables pose and illumination\ninsensitive face recognition. Second, sparse representations for pose and\nillumination can subsequently be used to estimate the pose and illumination\ncondition of a face image. Finally, by composing sparse representations for\nsubject and the different domains, we can also perform pose alignment and\nillumination normalization. Extensive experiments using two public face\ndatasets are presented to demonstrate the effectiveness of our approach for\nface recognition."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0273v1", 
    "title": "Learning Robust Subspace Clustering", 
    "arxiv-id": "1308.0273v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2013-08-01T17:31:37Z", 
    "summary": "We propose a low-rank transformation-learning framework to robustify subspace\nclustering. Many high-dimensional data, such as face images and motion\nsequences, lie in a union of low-dimensional subspaces. The subspace clustering\nproblem has been extensively studied in the literature to partition such\nhigh-dimensional data into clusters corresponding to their underlying\nlow-dimensional subspaces. However, low-dimensional intrinsic structures are\noften violated for real-world observations, as they can be corrupted by errors\nor deviate from ideal models. We propose to address this by learning a linear\ntransformation on subspaces using matrix rank, via its convex surrogate nuclear\nnorm, as the optimization criteria. The learned linear transformation restores\na low-rank structure for data from the same subspace, and, at the same time,\nforces a high-rank structure for data from different subspaces. In this way, we\nreduce variations within the subspaces, and increase separations between the\nsubspaces for more accurate subspace clustering. This proposed learned robust\nsubspace clustering framework significantly enhances the performance of\nexisting subspace clustering methods. To exploit the low-rank structures of the\ntransformed subspaces, we further introduce a subspace clustering technique,\ncalled Robust Sparse Subspace Clustering, which efficiently combines robust PCA\nwith sparse modeling. We also discuss the online learning of the\ntransformation, and learning of the transformation while simultaneously\nreducing the data dimensionality. Extensive experiments using public datasets\nare presented, showing that the proposed approach significantly outperforms\nstate-of-the-art subspace clustering methods."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0275v1", 
    "title": "Domain-invariant Face Recognition using Learned Low-rank Transformation", 
    "arxiv-id": "1308.0275v1", 
    "author": "Ching-Hui Chen", 
    "publish": "2013-08-01T17:34:36Z", 
    "summary": "We present a low-rank transformation approach to compensate for face\nvariations due to changes in visual domains, such as pose and illumination. The\nkey idea is to learn discriminative linear transformations for face images\nusing matrix rank as the optimization criteria. The learned linear\ntransformations restore a shared low-rank structure for faces from the same\nsubject, and, at the same time, force a high-rank structure for faces from\ndifferent subjects. In this way, among the transformed faces, we reduce\nvariations caused by domain changes within the classes, and increase\nseparations between the classes for better face recognition across domains.\nExtensive experiments using public datasets are presented to demonstrate the\neffectiveness of our approach for face recognition across domains. The\npotential of the approach for feature extraction in generic object recognition\nand coded aperture design are discussed as well."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0290v1", 
    "title": "Sparse Dictionary-based Attributes for Action Recognition and   Summarization", 
    "arxiv-id": "1308.0290v1", 
    "author": "Rama Chellappa", 
    "publish": "2013-08-01T18:25:16Z", 
    "summary": "We present an approach for dictionary learning of action attributes via\ninformation maximization. We unify the class distribution and appearance\ninformation into an objective function for learning a sparse dictionary of\naction attributes. The objective function maximizes the mutual information\nbetween what has been learned and what remains to be learned in terms of\nappearance information and class distribution for each dictionary atom. We\npropose a Gaussian Process (GP) model for sparse representation to optimize the\ndictionary objective function. The sparse coding property allows a kernel with\ncompact support in GP to realize a very efficient dictionary learning process.\nHence we can describe an action video by a set of compact and discriminative\naction attributes. More importantly, we can recognize modeled action categories\nin a sparse feature space, which can be generalized to unseen and unmodeled\naction categories. Experimental results demonstrate the effectiveness of our\napproach in action recognition and summarization."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0365v1", 
    "title": "Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes", 
    "arxiv-id": "1308.0365v1", 
    "author": "Khurom H. Kiyani", 
    "publish": "2013-08-01T21:58:33Z", 
    "summary": "In this paper we address the problem of multiple camera calibration in the\npresence of a homogeneous scene, and without the possibility of employing\ncalibration object based methods. The proposed solution exploits salient\nfeatures present in a larger field of view, but instead of employing active\nvision we replace the cameras with stereo rigs featuring a long focal analysis\ncamera, as well as a short focal registration camera. Thus, we are able to\npropose an accurate solution which does not require intrinsic variation models\nas in the case of zooming cameras. Moreover, the availability of the two views\nsimultaneously in each rig allows for pose re-estimation between rigs as often\nas necessary. The algorithm has been successfully validated in an indoor\nsetting, as well as on a difficult scene featuring a highly dense pilgrim crowd\nin Makkah."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0890v1", 
    "title": "Head Gesture Recognition using Optical Flow based Classification with   Reinforcement of GMM based Background Subtraction", 
    "arxiv-id": "1308.0890v1", 
    "author": "Karen Das", 
    "publish": "2013-08-05T05:17:26Z", 
    "summary": "This paper describes a technique of real time head gesture recognition\nsystem. The method includes Gaussian mixture model (GMM) accompanied by optical\nflow algorithm which provided us the required information regarding head\nmovement. The proposed model can be implemented in various control system. We\nare also presenting the result and implementation of both mentioned method."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.1126v1", 
    "title": "Image interpolation using Shearlet based iterative refinement", 
    "arxiv-id": "1308.1126v1", 
    "author": "T. Wiegand", 
    "publish": "2013-08-05T21:33:06Z", 
    "summary": "This paper proposes an image interpolation algorithm exploiting sparse\nrepresentation for natural images. It involves three main steps: (a) obtaining\nan initial estimate of the high resolution image using linear methods like FIR\nfiltering, (b) promoting sparsity in a selected dictionary through iterative\nthresholding, and (c) extracting high frequency information from the\napproximation to refine the initial estimate. For the sparse modeling, a\nshearlet dictionary is chosen to yield a multiscale directional representation.\nThe proposed algorithm is compared to several state-of-the-art methods to\nassess its objective as well as subjective performance. Compared to the cubic\nspline interpolation method, an average PSNR gain of around 0.8 dB is observed\nover a dataset of 200 images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.1374v1", 
    "title": "Bayesian ensemble learning for image denoising", 
    "arxiv-id": "1308.1374v1", 
    "author": "Hyuntaek Oh", 
    "publish": "2013-08-06T18:46:18Z", 
    "summary": "Natural images are often affected by random noise and image denoising has\nlong been a central topic in Computer Vision. Many algorithms have been\nintroduced to remove the noise from the natural images, such as Gaussian,\nWiener filtering and wavelet thresholding. However, many of these algorithms\nremove the fine edges and make them blur. Recently, many promising denoising\nalgorithms have been introduced such as Non-local Means, Fields of Experts, and\nBM3D. In this paper, we explore Bayesian method of ensemble learning for image\ndenoising. Ensemble methods seek to combine multiple different algorithms to\nretain the strengths of all methods and the weaknesses of none. Bayesian\nensemble models are Non-local Means and Fields of Experts, the very successful\nrecent algorithms. The Non-local Means presumes that the image contains an\nextensive amount of self-similarity. The approach of the Fields of Experts\nmodel extends traditional Markov Random Field model by learning potential\nfunctions over extended pixel neighborhoods. The two models are implemented and\nimage denoising is performed on natural images. The experimental results\nobtained are used to compare with the single algorithm and discuss the ensemble\nlearning and their approaches. Comparing to the results of Non-local Means and\nFields of Experts, Ensemble learning showed improvement nearly 1dB."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.1981v3", 
    "title": "A Framework for the Analysis of Computational Imaging Systems with   Practical Applications", 
    "arxiv-id": "1308.1981v3", 
    "author": "Ashok Veeraraghavan", 
    "publish": "2013-08-08T21:21:54Z", 
    "summary": "Over the last decade, a number of Computational Imaging (CI) systems have\nbeen proposed for tasks such as motion deblurring, defocus deblurring and\nmultispectral imaging. These techniques increase the amount of light reaching\nthe sensor via multiplexing and then undo the deleterious effects of\nmultiplexing by appropriate reconstruction algorithms. Given the widespread\nappeal and the considerable enthusiasm generated by these techniques, a\ndetailed performance analysis of the benefits conferred by this approach is\nimportant.\n  Unfortunately, a detailed analysis of CI has proven to be a challenging\nproblem because performance depends equally on three components: (1) the\noptical multiplexing, (2) the noise characteristics of the sensor, and (3) the\nreconstruction algorithm. A few recent papers have performed analysis taking\nmultiplexing and noise characteristics into account. However, analysis of CI\nsystems under state-of-the-art reconstruction algorithms, most of which exploit\nsignal prior models, has proven to be unwieldy. In this paper, we present a\ncomprehensive analysis framework incorporating all three components.\n  In order to perform this analysis, we model the signal priors using a\nGaussian Mixture Model (GMM). A GMM prior confers two unique characteristics.\nFirstly, GMM satisfies the universal approximation property which says that any\nprior density function can be approximated to any fidelity using a GMM with\nappropriate number of mixtures. Secondly, a GMM prior lends itself to\nanalytical tractability allowing us to derive simple expressions for the\n`minimum mean square error' (MMSE), which we use as a metric to characterize\nthe performance of CI systems. We use our framework to analyze several\npreviously proposed CI techniques, giving conclusive answer to the question:\n`How much performance gain is due to use of a signal prior and how much is due\nto multiplexing?"
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.2654v1", 
    "title": "Local image registration a comparison for bilateral registration   mammography", 
    "arxiv-id": "1308.2654v1", 
    "author": "Jos\u00e9 G. Gerardo Tamez-Pena", 
    "publish": "2013-08-12T19:29:49Z", 
    "summary": "Early tumor detection is key in reducing the number of breast cancer death\nand screening mammography is one of the most widely available and reliable\nmethod for early detection. However, it is difficult for the radiologist to\nprocess with the same attention each case, due the large amount of images to be\nread. Computer aided detection (CADe) systems improve tumor detection rate; but\nthe current efficiency of these systems is not yet adequate and the correct\ninterpretation of CADe outputs requires expert human intervention. Computer\naided diagnosis systems (CADx) are being designed to improve cancer diagnosis\naccuracy, but they have not been efficiently applied in breast cancer. CADx\nefficiency can be enhanced by considering the natural mirror symmetry between\nthe right and left breast. The objective of this work is to evaluate\nco-registration algorithms for the accurate alignment of the left to right\nbreast for CADx enhancement. A set of mammograms were artificially altered to\ncreate a ground truth set to evaluate the registration efficiency of DEMONs,\nand SPLINE deformable registration algorithms. The registration accuracy was\nevaluated using mean square errors, mutual information and correlation. The\nresults on the 132 images proved that the SPLINE deformable registration\nover-perform the DEMONS on mammography images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.3052v2", 
    "title": "Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual   Image Quality Index", 
    "arxiv-id": "1308.3052v2", 
    "author": "Alan C. Bovik", 
    "publish": "2013-08-14T07:25:10Z", 
    "summary": "It is an important task to faithfully evaluate the perceptual quality of\noutput images in many applications such as image compression, image restoration\nand multimedia streaming. A good image quality assessment (IQA) model should\nnot only deliver high quality prediction accuracy but also be computationally\nefficient. The efficiency of IQA metrics is becoming particularly important due\nto the increasing proliferation of high-volume visual data in high-speed\nnetworks. We present a new effective and efficient IQA model, called gradient\nmagnitude similarity deviation (GMSD). The image gradients are sensitive to\nimage distortions, while different local structures in a distorted image suffer\ndifferent degrees of degradations. This motivates us to explore the use of\nglobal variation of gradient based local quality map for overall image quality\nprediction. We find that the pixel-wise gradient magnitude similarity (GMS)\nbetween the reference and distorted images combined with a novel pooling\nstrategy the standard deviation of the GMS map can predict accurately\nperceptual image quality. The resulting GMSD algorithm is much faster than most\nstate-of-the-art IQA methods, and delivers highly competitive prediction\naccuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.4440v1", 
    "title": "Influences Combination of Multi-Sensor Images on Classification Accuracy", 
    "arxiv-id": "1308.4440v1", 
    "author": "N. V. Kalyankar", 
    "publish": "2013-08-20T21:34:47Z", 
    "summary": "This paper focuses on two main issues; first one is the impact of combination\nof multi-sensor images on the supervised learning classification accuracy using\nsegment Fusion (SF). The second issue attempts to undertake the study of\nsupervised machine learning classification technique of remote sensing images\nby using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD),\nMaximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their\naccuracies have been evaluated on their respected classification to choose the\nbest technique for classification of remote sensing images. QuickBird\nmultispectral data (MS) and panchromatic data (PAN) have been used in this\nstudy to demonstrate the enhancement and accuracy assessment of fused image\nover the original images using ALwassaiProcess software. According to\nexperimental result of this study, is that the test results indicate the\nsupervised classification results of fusion image, which generated better than\nthe MS did. As well as the result with Euclidean classifier is robust and\nprovides better results than the other classifiers do, despite of the popular\nbelief that the maximum-likelihood classifier is the most accurate classifier."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.4902v1", 
    "title": "A review on handwritten character and numeral recognition for Roman,   Arabic, Chinese and Indian scripts", 
    "arxiv-id": "1308.4902v1", 
    "author": "Siti Mariyam Shamsuddin", 
    "publish": "2013-08-22T15:38:15Z", 
    "summary": "There are a lot of intensive researches on handwritten character recognition\n(HCR) for almost past four decades. The research has been done on some of\npopular scripts such as Roman, Arabic, Chinese and Indian. In this paper we\npresent a review on HCR work on the four popular scripts. We have summarized\nmost of the published paper from 2005 to recent and also analyzed the various\nmethods in creating a robust HCR system. We also added some future direction of\nresearch on HCR."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.5063v1", 
    "title": "Suspicious Object Recognition Method in Video Stream Based on Visual   Attention", 
    "arxiv-id": "1308.5063v1", 
    "author": "Yan Zhang", 
    "publish": "2013-08-23T07:26:56Z", 
    "summary": "We propose a state of the art method for intelligent object recognition and\nvideo surveillance based on human visual attention. Bottom up and top down\nattention are applied respectively in the process of acquiring interested\nobject(saliency map) and object recognition. The revision of 4 channel PFT\nmethod is proposed for bottom up attention and enhances the speed and accuracy.\nInhibit of return (IOR) is applied in judging the sequence of saliency object\npop out. Euclidean distance of color distribution, object center coordinates\nand speed are considered in judging whether the target is match and suspicious.\nThe extensive tests on videos and images show that our method in video analysis\nhas high accuracy and fast speed compared with traditional method. The method\ncan be applied into many fields such as video surveillance and security."
},{
    "category": "cs.CV", 
    "doi": "10.18483/ijSci.251", 
    "link": "http://arxiv.org/pdf/1308.5315v1", 
    "title": "Edge-detection applied to moving sand dunes on Mars", 
    "arxiv-id": "1308.5315v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2013-08-24T11:07:05Z", 
    "summary": "Here we discuss the application of an edge detection filter, the Sobel filter\nof GIMP, to the recently discovered motion of some sand dunes on Mars. The\nfilter allows a good comparison of an image HiRISE of 2007 and an image of 1999\nrecorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,\nmeasuring therefore the motion of the dunes on a longer period of time than\nthat previously investigated."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2283510", 
    "link": "http://arxiv.org/pdf/1308.5876v1", 
    "title": "Hierarchized block wise image approximation by greedy pursuit strategies", 
    "arxiv-id": "1308.5876v1", 
    "author": "Shabnam Bibi", 
    "publish": "2013-08-27T13:57:16Z", 
    "summary": "An approach for effective implementation of greedy selection methodologies,\nto approximate an image partitioned into blocks, is proposed. The method is\nspecially designed for approximating partitions on a transformed image. It\nevolves by selecting, at each iteration step, i) the elements for approximating\neach of the blocks partitioning the image and ii) the hierarchized sequence in\nwhich the blocks are approximated to reach the required global condition on\nsparsity."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6056v1", 
    "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active   Contours", 
    "arxiv-id": "1308.6056v1", 
    "author": "K. Palaniappan", 
    "publish": "2013-08-28T04:48:00Z", 
    "summary": "Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6309v1", 
    "title": "Text recognition in both ancient and cartographic documents", 
    "arxiv-id": "1308.6309v1", 
    "author": "Remy Mullot", 
    "publish": "2013-08-28T20:59:55Z", 
    "summary": "This paper deals with the recognition and matching of text in both\ncartographic maps and ancient documents. The purpose of this work is to find\nsimilar text regions based on statistical and global features. A phase of\nnormalization is done first, in object to well categorize the same quantity of\ninformation. A phase of wordspotting is done next by combining local and global\nfeatures. We make different experiments by combining the different techniques\nof extracting features in order to obtain better results in recognition phase.\nWe applied fontspotting on both ancient documents and cartographic ones. We\nalso applied the wordspotting in which we adopted a new technique which tries\nto compare the images of character and not the entire images words. We present\nthe precision and recall values obtained with three methods for the new method\nof wordspotting applied on characters only."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6311v1", 
    "title": "Categorizing ancient documents", 
    "arxiv-id": "1308.6311v1", 
    "author": "Mohamed Adel Alimi", 
    "publish": "2013-08-28T21:09:35Z", 
    "summary": "The analysis of historical documents is still a topical issue given the\nimportance of information that can be extracted and also the importance given\nby the institutions to preserve their heritage. The main idea in order to\ncharacterize the content of the images of ancient documents after attempting to\nclean the image is segmented blocks texts from the same image and tries to find\nsimilar blocks in either the same image or the entire image database. Most\napproaches of offline handwriting recognition proceed by segmenting words into\nsmaller pieces (usually characters) which are recognized separately.\nRecognition of a word then requires the recognition of all characters (OCR)\nthat compose it. Our work focuses mainly on the characterization of classes in\nimages of old documents. We use Som toolbox for finding classes in documents.\nWe applied also fractal dimensions and points of interest to categorize and\nmatch ancient documents."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6319v1", 
    "title": "A proposition of a robust system for historical document images   indexation", 
    "arxiv-id": "1308.6319v1", 
    "author": "Mohamed Adel Alimi", 
    "publish": "2013-08-28T21:37:08Z", 
    "summary": "Characterizing noisy or ancient documents is a challenging problem up to now.\nMany techniques have been done in order to effectuate feature extraction and\nimage indexation for such documents. Global approaches are in general less\nrobust and exact than local approaches. That's why, we propose in this paper, a\nhybrid system based on global approach(fractal dimension), and a local one\nbased on SIFT descriptor. The Scale Invariant Feature Transform seems to do\nwell with our application since it's rotation invariant and relatively robust\nto changing illumination.In the first step the calculation of fractal dimension\nis applied to images in order to eliminate images which have distant features\nthan image request characteristics. Next, the SIFT is applied to show which\nimages match well the request. However the average matching time using the\nhybrid approach is better than \"fractal dimension\" and \"SIFT descriptor\" if\nthey are used alone."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6388v1", 
    "title": "GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure", 
    "arxiv-id": "1308.6388v1", 
    "author": "Hong Qiao", 
    "publish": "2013-08-29T08:00:20Z", 
    "summary": "In this paper we propose the Graduated NonConvexity and Graduated Concavity\nProcedure (GNCGCP) as a general optimization framework to approximately solve\nthe combinatorial optimization problems on the set of partial permutation\nmatrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC)\nwhich realizes a convex relaxation and graduated concavity (GC) which realizes\na concave relaxation. It is proved that GNCGCP realizes exactly a type of\nconvex-concave relaxation procedure (CCRP), but with a much simpler formulation\nwithout needing convex or concave relaxation in an explicit way. Actually,\nGNCGCP involves only the gradient of the objective function and is therefore\nvery easy to use in practical applications. Two typical NP-hard problems,\n(sub)graph matching and quadratic assignment problem (QAP), are employed to\ndemonstrate its simplicity and state-of-the-art performance."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1308.6401v1", 
    "title": "A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of   Urban Facades from Heterogeneous Cartographic Data", 
    "arxiv-id": "1308.6401v1", 
    "author": "Nicolas Paparoditis", 
    "publish": "2013-08-29T08:47:09Z", 
    "summary": "In this paper we present a practical approach for generating an\nocclusion-free textured 3D map of urban facades by the synergistic use of\nterrestrial images, 3D point clouds and area-based information. Particularly in\ndense urban environments, the high presence of urban objects in front of the\nfacades causes significant difficulties for several stages in computational\nbuilding modeling. Major challenges lie on the one hand in extracting complete\n3D facade quadrilateral delimitations and on the other hand in generating\nocclusion-free facade textures. For these reasons, we describe a\nstraightforward approach for completing and recovering facade geometry and\ntextures by exploiting the data complementarity of terrestrial multi-source\nimagery and area-based information."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1308.6687v1", 
    "title": "Image Set based Collaborative Representation for Face Recognition", 
    "arxiv-id": "1308.6687v1", 
    "author": "David Zhang", 
    "publish": "2013-08-30T09:08:56Z", 
    "summary": "With the rapid development of digital imaging and communication technologies,\nimage set based face recognition (ISFR) is becoming increasingly important. One\nkey issue of ISFR is how to effectively and efficiently represent the query\nface image set by using the gallery face image sets. The set-to-set distance\nbased methods ignore the relationship between gallery sets, while representing\nthe query set images individually over the gallery sets ignores the correlation\nbetween query set images. In this paper, we propose a novel image set based\ncollaborative representation and classification method for ISFR. By modeling\nthe query set as a convex or regularized hull, we represent this hull\ncollaboratively over all the gallery sets. With the resolved representation\ncoefficients, the distance between the query set and each gallery set can then\nbe calculated for classification. The proposed model naturally and effectively\nextends the image based collaborative representation to an image set based one,\nand our extensive experiments on benchmark ISFR databases show the superiority\nof the proposed method to state-of-the-art ISFR methods under different set\nsizes in terms of both recognition rate and efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.0123v2", 
    "title": "A Robust Alternating Direction Method for Constrained Hybrid Variational   Deblurring Model", 
    "arxiv-id": "1309.0123v2", 
    "author": "Tian Xu", 
    "publish": "2013-08-31T14:29:52Z", 
    "summary": "In this work, a new constrained hybrid variational deblurring model is\ndeveloped by combining the non-convex first- and second-order total variation\nregularizers. Moreover, a box constraint is imposed on the proposed model to\nguarantee high deblurring performance. The developed constrained hybrid\nvariational model could achieve a good balance between preserving image details\nand alleviating ringing artifacts. In what follows, we present the\ncorresponding numerical solution by employing an iteratively reweighted\nalgorithm based on alternating direction method of multipliers. The\nexperimental results demonstrate the superior performance of the proposed\nmethod in terms of quantitative and qualitative image quality assessments."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.0213v2", 
    "title": "Learning to Rank for Blind Image Quality Assessment", 
    "arxiv-id": "1309.0213v2", 
    "author": "Xuelong Li", 
    "publish": "2013-09-01T12:26:53Z", 
    "summary": "Blind image quality assessment (BIQA) aims to predict perceptual image\nquality scores without access to reference images. State-of-the-art BIQA\nmethods typically require subjects to score a large number of images to train a\nrobust model. However, the acquisition of image quality scores has several\nlimitations: 1) scores are not precise, because subjects are usually uncertain\nabout which score most precisely represents the perceptual quality of a given\nimage; 2) subjective judgements of quality may be biased by image content; 3)\nthe quality scales between different distortion categories are inconsistent;\nand 4) it is challenging to obtain a large scale database, or to extend\nexisting databases, because of the inconvenience of collecting sufficient\nimages, training the subjects, conducting subjective experiments, and\nrealigning human quality evaluations. To combat these limitations, this paper\nexplores and exploits preference image pairs such as \"the quality of image Ia\nis better than that of image Ib\" for training a robust BIQA model. The\npreference label, representing the relative quality of two images, is generally\nprecise and consistent, and is not sensitive to image content, distortion type,\nor subject identity; such PIPs can be generated at very low cost. The proposed\nBIQA method is one of learning to rank. We first formulate the problem of\nlearning the mapping from the image features to the preference label as one of\nclassification. In particular, we investigate the utilization of a multiple\nkernel learning algorithm based on group lasso (MKLGL) to provide a solution. A\nsimple but effective strategy to estimate perceptual image quality scores is\nthen presented. Experiments show that the proposed BIQA method is highly\neffective and achieves comparable performance to state-of-the-art BIQA\nalgorithms. Moreover, the proposed method can be easily extended to new\ndistortion categories."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.0261v1", 
    "title": "Multi-Column Deep Neural Networks for Offline Handwritten Chinese   Character Classification", 
    "arxiv-id": "1309.0261v1", 
    "author": "J\u00fcrgen Schmidhuber", 
    "publish": "2013-09-01T20:35:17Z", 
    "summary": "Our Multi-Column Deep Neural Networks achieve best known recognition rates on\nChinese characters from the ICDAR 2011 and 2013 offline handwriting\ncompetitions, approaching human performance."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.0309v1", 
    "title": "A Study on Unsupervised Dictionary Learning and Feature Encoding for   Action Classification", 
    "arxiv-id": "1309.0309v1", 
    "author": "Mehtab Afzal", 
    "publish": "2013-09-02T07:06:05Z", 
    "summary": "Many efforts have been devoted to develop alternative methods to traditional\nvector quantization in image domain such as sparse coding and soft-assignment.\nThese approaches can be split into a dictionary learning phase and a feature\nencoding phase which are often closely connected. In this paper, we investigate\nthe effects of these phases by separating them for video-based action\nclassification. We compare several dictionary learning methods and feature\nencoding schemes through extensive experiments on KTH and HMDB51 datasets.\nExperimental results indicate that sparse coding performs consistently better\nthan the other encoding methods in large complex dataset (i.e., HMDB51), and it\nis robust to different dictionaries. For small simple dataset (i.e., KTH) with\nless variation, however, all the encoding strategies perform competitively. In\naddition, we note that the strength of sophisticated encoding approaches comes\nnot from their corresponding dictionaries but the encoding mechanisms, and we\ncan just use randomly selected exemplars as dictionaries for video-based action\nclassification."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.0999v1", 
    "title": "Minutiae Based Thermal Face Recognition using Blood Perfusion Data", 
    "arxiv-id": "1309.0999v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-04T12:18:55Z", 
    "summary": "This paper describes an efficient approach for human face recognition based\non blood perfusion data from infra-red face images. Blood perfusion data are\ncharacterized by the regional blood flow in human tissue and therefore do not\ndepend entirely on surrounding temperature. These data bear a great potential\nfor deriving discriminating facial thermogram for better classification and\nrecognition of face images in comparison to optical image data. Blood perfusion\ndata are related to distribution of blood vessels under the face skin. A\ndistribution of blood vessels are unique for each person and as a set of\nextracted minutiae points from a blood perfusion data of a human face should be\nunique for that face. There may be several such minutiae point sets for a\nsingle face but all of these correspond to that particular face only. Entire\nface image is partitioned into equal blocks and the total number of minutiae\npoints from each block is computed to construct final vector. Therefore, the\nsize of the feature vectors is found to be same as total number of blocks\nconsidered. For classification, a five layer feed-forward backpropagation\nneural network has been used. A number of experiments were conducted to\nevaluate the performance of the proposed face recognition system with varying\nblock sizes. Experiments have been performed on the database created at our own\nlaboratory. The maximum success of 91.47% recognition has been achieved with\nblock size 8X8."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.1000v1", 
    "title": "Automated Thermal Face recognition based on Minutiae Extraction", 
    "arxiv-id": "1309.1000v1", 
    "author": "Dipak Kr. Basu", 
    "publish": "2013-09-04T12:26:50Z", 
    "summary": "In this paper an efficient approach for human face recognition based on the\nuse of minutiae points in thermal face image is proposed. The thermogram of\nhuman face is captured by thermal infra-red camera. Image processing methods\nare used to pre-process the captured thermogram, from which different\nphysiological features based on blood perfusion data are extracted. Blood\nperfusion data are related to distribution of blood vessels under the face\nskin. In the present work, three different methods have been used to get the\nblood perfusion image, namely bit-plane slicing and medial axis transform,\nmorphological erosion and medial axis transform, sobel edge operators.\nDistribution of blood vessels is unique for each person and a set of extracted\nminutiae points from a blood perfusion data of a human face should be unique\nfor that face. Two different methods are discussed for extracting minutiae\npoints from blood perfusion data. For extraction of features entire face image\nis partitioned into equal size blocks and the total number of minutiae points\nfrom each block is computed to construct final feature vector. Therefore, the\nsize of the feature vectors is found to be same as total number of blocks\nconsidered. A five layer feed-forward back propagation neural network is used\nas the classification tool. A number of experiments were conducted to evaluate\nthe performance of the proposed face recognition methodologies with varying\nblock size on the database created at our own laboratory. It has been found\nthat the first method supercedes the other two producing an accuracy of 97.62%\nwith block size 16X16 for bit-plane 4."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.1009v1", 
    "title": "A Comparative Study of Human thermal face recognition based on Haar   wavelet transform (HWT) and Local Binary Pattern (LBP)", 
    "arxiv-id": "1309.1009v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-04T12:41:48Z", 
    "summary": "Thermal infra-red (IR) images focus on changes of temperature distribution on\nfacial muscles and blood vessels. These temperature changes can be regarded as\ntexture features of images. A comparative study of face recognition methods\nworking in thermal spectrum is carried out in this paper. In these study two\nlocal-matching methods based on Haar wavelet transform and Local Binary Pattern\n(LBP) are analyzed. Wavelet transform is a good tool to analyze multi-scale,\nmulti-direction changes of texture. Local binary patterns (LBP) are a type of\nfeature used for classification in computer vision. Firstly, human thermal IR\nface image is preprocessed and cropped the face region only from the entire\nimage. Secondly, two different approaches are used to extract the features from\nthe cropped face region. In the first approach, the training images and the\ntest images are processed with Haar wavelet transform and the LL band and the\naverage of LH/HL/HH bands sub-images are created for each face image. Then a\ntotal confidence matrix is formed for each face image by taking a weighted sum\nof the corresponding pixel values of the LL band and average band. For LBP\nfeature extraction, each of the face images in training and test datasets is\ndivided into 161 numbers of sub images, each of size 8X8 pixels. For each such\nsub images, LBP features are extracted which are concatenated in row wise\nmanner. PCA is performed separately on the individual feature set for\ndimensionality reeducation. Finally two different classifiers are used to\nclassify face images. One such classifier multi-layer feed forward neural\nnetwork and another classifier is minimum distance classifier. The Experiments\nhave been performed on the database created at our own laboratory and Terravic\nFacial IR Database."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.1080v1", 
    "title": "Boosting in Location Space", 
    "arxiv-id": "1309.1080v1", 
    "author": "Ed Rosten", 
    "publish": "2013-09-04T15:49:09Z", 
    "summary": "The goal of object detection is to find objects in an image. An object\ndetector accepts an image and produces a list of locations as $(x,y)$ pairs.\nHere we introduce a new concept: {\\bf location-based boosting}. Location-based\nboosting differs from previous boosting algorithms because it optimizes a new\nspatial loss function to combine object detectors, each of which may have\nmarginal performance, into a single, more accurate object detector. A\nstructured representation of object locations as a list of $(x,y)$ pairs is a\nmore natural domain for object detection than the spatially unstructured\nrepresentation produced by classifiers. Furthermore, this formulation allows us\nto take advantage of the intuition that large areas of the background are\nuninteresting and it is not worth expending computational effort on them. This\nresults in a more scalable algorithm because it does not need to take measures\nto prevent the background data from swamping the foreground data such as\nsubsampling or applying an ad-hoc weighting to the pixels. We first present the\ntheory of location-based boosting, and then motivate it with empirical results\non a challenging data set."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.1155v1", 
    "title": "Minutiae Based Thermal Human Face Recognition using Label Connected   Component Algorithm", 
    "arxiv-id": "1309.1155v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-04T13:32:28Z", 
    "summary": "In this paper, a thermal infra red face recognition system for human\nidentification and verification using blood perfusion data and back propagation\nfeed forward neural network is proposed. The system consists of three steps. At\nthe very first step face region is cropped from the colour 24-bit input images.\nSecondly face features are extracted from the croped region, which will be\ntaken as the input of the back propagation feed forward neural network in the\nthird step and classification and recognition is carried out. The proposed\napproaches are tested on a number of human thermal infra red face images\ncreated at our own laboratory. Experimental results reveal the higher degree\nperformance"
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1309.1156v1", 
    "title": "Thermal Human face recognition based on Haar wavelet transform and   series matching technique", 
    "arxiv-id": "1309.1156v1", 
    "author": "Dipak kr. Basu", 
    "publish": "2013-09-04T13:45:25Z", 
    "summary": "Thermal infrared (IR) images represent the heat patterns emitted from hot\nobject and they do not consider the energies reflected from an object. Objects\nliving or non-living emit different amounts of IR energy according to their\nbody temperature and characteristics. Humans are homoeothermic and hence\ncapable of maintaining constant temperature under different surrounding\ntemperature. Face recognition from thermal (IR) images should focus on changes\nof temperature on facial blood vessels. These temperature changes can be\nregarded as texture features of images and wavelet transform is a very good\ntool to analyze multi-scale and multi-directional texture. Wavelet transform is\nalso used for image dimensionality reduction, by removing redundancies and\npreserving original features of the image. The sizes of the facial images are\nnormally large. So, the wavelet transform is used before image similarity is\nmeasured. Therefore this paper describes an efficient approach of human face\nrecognition based on wavelet transform from thermal IR images. The system\nconsists of three steps. At the very first step, human thermal IR face image is\npreprocessed and the face region is only cropped from the entire image.\nSecondly, Haar wavelet is used to extract low frequency band from the cropped\nface region. Lastly, the image classification between the training images and\nthe test images is done, which is based on low-frequency components. The\nproposed approach is tested on a number of human thermal infrared face images\ncreated at our own laboratory and Terravic Facial IR Database. Experimental\nresults indicated that the thermal infra red face images can be recognized by\nthe proposed system effectively. The maximum success of 95% recognition has\nbeen achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-014-0746-0", 
    "link": "http://arxiv.org/pdf/1309.1539v2", 
    "title": "Practical Matrix Completion and Corruption Recovery using Proximal   Alternating Robust Subspace Minimization", 
    "arxiv-id": "1309.1539v2", 
    "author": "Kim-Chuan Toh", 
    "publish": "2013-09-06T05:38:32Z", 
    "summary": "Low-rank matrix completion is a problem of immense practical importance.\nRecent works on the subject often use nuclear norm as a convex surrogate of the\nrank function. Despite its solid theoretical foundation, the convex version of\nthe problem often fails to work satisfactorily in real-life applications. Real\ndata often suffer from very few observations, with support not meeting the\nrandom requirements, ubiquitous presence of noise and potentially gross\ncorruptions, sometimes with these simultaneously occurring.\n  This paper proposes a Proximal Alternating Robust Subspace Minimization\n(PARSuMi) method to tackle the three problems. The proximal alternating scheme\nexplicitly exploits the rank constraint on the completed matrix and uses the\n$\\ell_0$ pseudo-norm directly in the corruption recovery step. We show that the\nproposed method for the non-convex and non-smooth model converges to a\nstationary point. Although it is not guaranteed to find the global optimal\nsolution, in practice we find that our algorithm can typically arrive at a good\nlocal minimizer when it is supplied with a reasonably good starting point based\non convex optimization. Extensive experiments with challenging synthetic and\nreal data demonstrate that our algorithm succeeds in a much larger range of\npractical problems where convex optimization fails, and it also outperforms\nvarious state-of-the-art algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2348799", 
    "link": "http://arxiv.org/pdf/1309.1628v2", 
    "title": "Topology preserving thinning for cell complexes", 
    "arxiv-id": "1309.1628v2", 
    "author": "Ruben Specogna", 
    "publish": "2013-09-06T13:11:48Z", 
    "summary": "A topology preserving skeleton is a synthetic representation of an object\nthat retains its topology and many of its significant morphological properties.\nThe process of obtaining the skeleton, referred to as skeletonization or\nthinning, is a very active research area. It plays a central role in reducing\nthe amount of information to be processed during image analysis and\nvisualization, computer-aided diagnosis or by pattern recognition algorithms.\n  This paper introduces a novel topology preserving thinning algorithm which\nremoves \\textit{simple cells}---a generalization of simple points---of a given\ncell complex. The test for simple cells is based on \\textit{acyclicity tables}\nautomatically produced in advance with homology computations. Using acyclicity\ntables render the implementation of thinning algorithms straightforward.\nMoreover, the fact that tables are automatically filled for all possible\nconfigurations allows to rigorously prove the generality of the algorithm and\nto obtain fool-proof implementations. The novel approach enables, for the first\ntime, according to our knowledge, to thin a general unstructured simplicial\ncomplex. Acyclicity tables for cubical and simplicial complexes and an open\nsource implementation of the thinning algorithm are provided as additional\nmaterial to allow their immediate use in the vast number of practical\napplications arising in medical imaging and beyond."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.JRS.8.083628", 
    "link": "http://arxiv.org/pdf/1309.1830v1", 
    "title": "Radar shadow detection in SAR images using DEM and projections", 
    "arxiv-id": "1309.1830v1", 
    "author": "O. Haddad", 
    "publish": "2013-09-07T07:14:42Z", 
    "summary": "Synthetic aperture radar (SAR) images are widely used in target recognition\ntasks nowadays. In this letter, we propose an automatic approach for radar\nshadow detection and extraction from SAR images utilizing geometric projections\nalong with the digital elevation model (DEM) which corresponds to the given\ngeo-referenced SAR image. First, the DEM is rotated into the radar geometry so\nthat each row would match that of a radar line of sight. Next, we extract the\nshadow regions by processing row by row until the image is covered fully. We\ntest the proposed shadow detection approach on different DEMs and a simulated\n1D signals and 2D hills and volleys modeled by various variance based Gaussian\nfunctions. Experimental results indicate the proposed algorithm produces good\nresults in detecting shadows in SAR images with high resolution."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5402", 
    "link": "http://arxiv.org/pdf/1309.2057v1", 
    "title": "Single image super resolution in spatial and wavelet domain", 
    "arxiv-id": "1309.2057v1", 
    "author": "Nikunj Patel", 
    "publish": "2013-09-09T07:33:50Z", 
    "summary": "Recently single image super resolution is very important research area to\ngenerate high resolution image from given low resolution image. Algorithms of\nsingle image resolution are mainly based on wavelet domain and spatial domain.\nFilters support to model the regularity of natural images is exploited in\nwavelet domain while edges of images get sharp during up sampling in spatial\ndomain. Here single image super resolution algorithm is presented which based\non both spatial and wavelet domain and take the advantage of both. Algorithm is\niterative and use back projection to minimize reconstruction error. Wavelet\nbased denoising method is also introduced to remove noise."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5402", 
    "link": "http://arxiv.org/pdf/1309.2506v1", 
    "title": "A multi-stream hmm approach to offline handwritten arabic word   recognition", 
    "arxiv-id": "1309.2506v1", 
    "author": "Khaled Satori", 
    "publish": "2013-09-10T13:40:30Z", 
    "summary": "In This paper we presented new approach for cursive Arabic text recognition\nsystem. The objective is to propose methodology analytical offline recognition\nof handwritten Arabic for rapid implementation. The first part in the writing\nrecognition system is the preprocessing phase is the preprocessing phase to\nprepare the data was introduces and extracts a set of simple statistical\nfeatures by two methods : from a window which is sliding long that text line\nthe right to left and the approach VH2D (consists in projecting every character\non the abscissa, on the ordinate and the diagonals 45{\\deg} and 135{\\deg}) . It\nthen injects the resulting feature vectors to Hidden Markov Model (HMM) and\ncombined the two HMM by multi-stream approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.2752v1", 
    "title": "Robust Periocular Recognition By Fusing Sparse Representations of Color   and Geometry Information", 
    "arxiv-id": "1309.2752v1", 
    "author": "Hugo Proenca", 
    "publish": "2013-09-11T08:11:14Z", 
    "summary": "In this paper, we propose a re-weighted elastic net (REN) model for biometric\nrecognition. The new model is applied to data separated into geometric and\ncolor spatial components. The geometric information is extracted using a fast\ncartoon - texture decomposition model based on a dual formulation of the total\nvariation norm allowing us to carry information about the overall geometry of\nimages. Color components are defined using linear and nonlinear color spaces,\nnamely the red-green-blue (RGB), chromaticity-brightness (CB) and\nhue-saturation-value (HSV). Next, according to a Bayesian fusion-scheme, sparse\nrepresentations for classification purposes are obtained. The scheme is\nnumerically solved using a gradient projection (GP) algorithm. In the empirical\nvalidation of the proposed model, we have chosen the periocular region, which\nis an emerging trait known for its robustness against low quality data. Our\nresults were obtained in the publicly available UBIRIS.v2 data set and show\nconsistent improvements in recognition effectiveness when compared to related\nstate-of-the-art techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.3006v2", 
    "title": "The Classification Accuracy of Multiple-Metric Learning Algorithm on   Multi-Sensor Fusion", 
    "arxiv-id": "1309.3006v2", 
    "author": "N. V. Kalyankar", 
    "publish": "2013-09-11T23:58:23Z", 
    "summary": "This paper focuses on two main issues; first one is the impact of Similarity\nSearch to learning the training sample in metric space, and searching based on\nsupervised learning classi-fication. In particular, four metrics space\nsearching are based on spatial information that are introduced as the\nfollowing; Cheby-shev Distance (CD); Bray Curtis Distance (BCD); Manhattan\nDistance (MD) and Euclidean Distance(ED) classifiers. The second issue\ninvestigates the performance of combination of mul-ti-sensor images on the\nsupervised learning classification accura-cy. QuickBird multispectral data (MS)\nand panchromatic data (PAN) have been used in this study to demonstrate the\nenhance-ment and accuracy assessment of fused image over the original images.\nThe supervised classification results of fusion image generated better than the\nMS did. QuickBird and the best results with ED classifier than the other did."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.3418v1", 
    "title": "A Novel Approach in detecting pose orientation of a 3D face required for   face", 
    "arxiv-id": "1309.3418v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-13T10:12:22Z", 
    "summary": "In this paper we present a novel approach that takes as input a 3D image and\ngives as output its pose i.e. it tells whether the face is oriented with\nrespect the X, Y or Z axes with angles of rotation up to 40 degree. All the\nexperiments have been performed on the FRAV3D Database. After applying the\nproposed algorithm to the 3D facial surface we have obtained i.e. on 848 3D\nface images our method detected the pose correctly for 566 face images,thus\ngiving an approximately 67 % of correct pose detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.3425v1", 
    "title": "A method for nose-tip based 3D face registration using maximum intensity   algorithm", 
    "arxiv-id": "1309.3425v1", 
    "author": "Dipak kr. Basu", 
    "publish": "2013-09-13T11:28:29Z", 
    "summary": "In this paper we present a novel technique of registering 3D images across\npose. In this context, we have taken into account the images which are aligned\nacross X, Y and Z axes. We have first determined the angle across which the\nimage is rotated with respect to X, Y and Z axes and then translation is\nperformed on the images. After testing the proposed method on 472 images from\nthe FRAV3D database, the method correctly registers 358 images thus giving a\nperformance rate of 75.84%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.3848v1", 
    "title": "SEEDS: Superpixels Extracted via Energy-Driven Sampling", 
    "arxiv-id": "1309.3848v1", 
    "author": "Luc Van Gool", 
    "publish": "2013-09-16T08:23:10Z", 
    "summary": "Superpixel algorithms aim to over-segment the image by grouping pixels that\nbelong to the same object. Many state-of-the-art superpixel algorithms rely on\nminimizing objective functions to enforce color ho- mogeneity. The optimization\nis accomplished by sophis- ticated methods that progressively build the\nsuperpix- els, typically by adding cuts or growing superpixels. As a result,\nthey are computationally too expensive for real-time applications. We introduce\na new approach based on a simple hill-climbing optimization. Starting from an\ninitial superpixel partitioning, it continuously refines the superpixels by\nmodifying the boundaries. We define a robust and fast to evaluate energy\nfunction, based on enforcing color similarity between the bound- aries and the\nsuperpixel color histogram. In a series of experiments, we show that we achieve\nan excellent com- promise between accuracy and efficiency. We are able to\nachieve a performance comparable to the state-of- the-art, but in real-time on\na single Intel i7 CPU at 2.8GHz."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.4426v1", 
    "title": "GRED: Graph-Regularized 3D Shape Reconstruction from Highly Anisotropic   and Noisy Images", 
    "arxiv-id": "1309.4426v1", 
    "author": "Gunnar R\u00e4tsch", 
    "publish": "2013-09-17T18:55:37Z", 
    "summary": "Analysis of microscopy images can provide insight into many biological\nprocesses. One particularly challenging problem is cell nuclear segmentation in\nhighly anisotropic and noisy 3D image data. Manually localizing and segmenting\neach and every cell nuclei is very time consuming, which remains a bottleneck\nin large scale biological experiments. In this work we present a tool for\nautomated segmentation of cell nuclei from 3D fluorescent microscopic data. Our\ntool is based on state-of-the-art image processing and machine learning\ntechniques and supports a friendly graphical user interface (GUI). We show that\nour tool is as accurate as manual annotation but greatly reduces the time for\nthe registration."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.4573v1", 
    "title": "A novel approach for nose tip detection using smoothing by weighted   median filtering applied to 3D face images in variant poses", 
    "arxiv-id": "1309.4573v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-18T08:40:21Z", 
    "summary": "This paper is based on an application of smoothing of 3D face images followed\nby feature detection i.e. detecting the nose tip. The present method uses a\nweighted mesh median filtering technique for smoothing. In this present\nsmoothing technique we have built the neighborhood surrounding a particular\npoint in 3D face and replaced that with the weighted value of the surrounding\npoints in 3D face image. After applying the smoothing technique to the 3D face\nimages our experimental results show that we have obtained considerable\nimprovement as compared to the algorithm without smoothing. We have used here\nthe maximum intensity algorithm for detecting the nose-tip and this method\ncorrectly detects the nose-tip in case of any pose i.e. along X, Y, and Z axes.\nThe present technique gave us worked successfully on 535 out of 542 3D face\nimages as compared to the method without smoothing which worked only on 521 3D\nface images out of 542 face images. Thus we have obtained a 98.70% performance\nrate over 96.12% performance rate of the algorithm without smoothing. All the\nexperiments have been performed on the FRAV3D database."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.4577v1", 
    "title": "Detection of pose orientation across single and multiple axes in case of   3D face images", 
    "arxiv-id": "1309.4577v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-18T08:47:34Z", 
    "summary": "In this paper, we propose a new approach that takes as input a 3D face image\nacross X, Y and Z axes as well as both Y and X axes and gives output as its\npose i.e. it tells whether the face is oriented with respect the X, Y or Z axes\nor is it oriented across multiple axes with angles of rotation up to 42 degree.\nAll the experiments have been performed on the FRAV3D, GAVADB and Bosphorus\ndatabase which has two figures of each individual across multiple axes. After\napplying the proposed algorithm to the 3D facial surface from FRAV3D on 848 3D\nfaces, 566 3D faces were correctly recognized for pose thus giving 67% of\ncorrect identification rate. We had experimented on 420 images from the GAVADB\ndatabase, and only 336 images were detected for correct pose identification\nrate i.e. 80% and from Bosphorus database on 560 images only 448 images were\ndetected for correct pose identification i.e. 80%.abstract goes here."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.4582v1", 
    "title": "A novel approach to nose-tip and eye corners detection using H-K   Curvature Analysis in case of 3D images", 
    "arxiv-id": "1309.4582v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2013-09-18T09:02:56Z", 
    "summary": "In this paper we present a novel method that combines a HK curvature-based\napproach for three-dimensional (3D) face detection in different poses (X-axis,\nY-axis and Z-axis). Salient face features, such as the eyes and nose, are\ndetected through an analysis of the curvature of the entire facial surface. All\nthe experiments have been performed on the FRAV3D Database. After applying the\nproposed algorithm to the 3D facial surface we have obtained considerably good\nresults i.e. on 752 3D face images our method detected the eye corners for 543\nface images, thus giving a 72.20% of eye corners detection and 743 face images\nfor nose-tip detection thus giving a 98.80% of good nose tip localization"
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.5004v1", 
    "title": "Blind Deconvolution via Maximum Kurtosis Adaptive Filtering", 
    "arxiv-id": "1309.5004v1", 
    "author": "Doron Benzvi", 
    "publish": "2013-09-19T14:45:54Z", 
    "summary": "In this paper, we present an algorithm for identifying a parametrically\ndescribed destructive unknown system based on a non-gaussianity measure. It is\nknown that under certain conditions the output of a linear system is more\ngaussian than the input. Hence, an inverse filter is searched, such that its\noutput is minimally gaussian. We use the kurtosis as a measure of the\nnon-gaussianity of the signal. A maximum of the kurtosis as a function of the\ndeconvolving filter coefficients is searched. The search is done iteratively\nusing the gradient ascent algorithm, and the coefficients at the maximum point\ncorrespond to the inverse filter coefficients. This filter may be applied to\nthe distorted signal to obtain the original undistorted signal. While a similar\napproach has been used before, it was always directed at a particular kind of a\nsignal, commonly of impulsive characteristics. In this paper a successful\nattempt has been made to apply the algorithm to a wider range of signals, such\nas to process distorted audio signals and destructed images. This innovative\nimplementation required the revelation of a way to preprocess the distorted\nsignal at hand. The experimental results show very good performance in terms of\nrecovering audio signals and blurred images, both for an FIR and IIR distorting\nfilters."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.5357v1", 
    "title": "Development of Comprehensive Devnagari Numeral and Character Database   for Offline Handwritten Character Recognition", 
    "arxiv-id": "1309.5357v1", 
    "author": "Vijay H. Mankar", 
    "publish": "2013-08-17T03:09:50Z", 
    "summary": "In handwritten character recognition, benchmark database plays an important\nrole in evaluating the performance of various algorithms and the results\nobtained by various researchers. In Devnagari script, there is lack of such\nofficial benchmark. This paper focuses on the generation of offline benchmark\ndatabase for Devnagari handwritten numerals and characters. The present work\ngenerated 5137 and 20305 isolated samples for numeral and character database,\nrespectively, from 750 writers of all ages, sex, education, and profession. The\noffline sample images are stored in TIFF image format as it occupies less\nmemory. Also, the data is presented in binary level so that memory requirement\nis further reduced. It will facilitate research on handwriting recognition of\nDevnagari script through free access to the researchers."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.5594v2", 
    "title": "Generic Image Classification Approaches Excel on Face Recognition", 
    "arxiv-id": "1309.5594v2", 
    "author": "Chunhua Shen", 
    "publish": "2013-09-22T11:52:03Z", 
    "summary": "The main finding of this work is that the standard image classification\npipeline, which consists of dictionary learning, feature encoding, spatial\npyramid pooling and linear classification, outperforms all state-of-the-art\nface recognition methods on the tested benchmark datasets (we have tested on\nAR, Extended Yale B, the challenging FERET, and LFW-a datasets). This\nsurprising and prominent result suggests that those advances in generic image\nclassification can be directly applied to improve face recognition systems. In\nother words, face recognition may not need to be viewed as a separate object\nclassification problem.\n  While recently a large body of residual based face recognition methods focus\non developing complex dictionary learning algorithms, in this work we show that\na dictionary of randomly extracted patches (even from non-face images) can\nachieve very promising results using the image classification pipeline. That\nmeans, the choice of dictionary learning methods may not be important. Instead,\nwe find that learning multiple dictionaries using different low-level image\nfeatures often improve the final classification accuracy. Our proposed face\nrecognition approach offers the best reported results on the widely-used face\nrecognition benchmark datasets. In particular, on the challenging FERET and\nLFW-a datasets, we improve the best reported accuracies in the literature by\nabout 20% and 30% respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.6195v1", 
    "title": "Scan-based Compressed Terahertz Imaging and Real-Time Reconstruction via   the Complex-valued Fast Block Sparse Bayesian Learning Algorithm", 
    "arxiv-id": "1309.6195v1", 
    "author": "Qiang Fu", 
    "publish": "2013-09-20T23:08:27Z", 
    "summary": "Compressed Sensing based Terahertz imaging (CS-THz) is a computational\nimaging technique. It uses only one THz receiver to accumulate the random\nmodulated image measurements where the original THz image is reconstruct from\nthese measurements using compressed sensing solvers. The advantage of the\nCS-THz is its reduced acquisition time compared with the raster scan mode.\nHowever, when it applied to large-scale two-dimensional (2D) imaging, the\nincreased dimension resulted in both high computational complexity and\nexcessive memory usage. In this paper, we introduced a novel CS-based THz\nimaging system that progressively compressed the THz image column by column.\nTherefore, the CS-THz system could be simplified with a much smaller sized\nmodulator and reduced dimension. In order to utilize the block structure and\nthe correlation of adjacent columns of the THz image, a complex-valued block\nsparse Bayesian learning algorithm was proposed. We conducted systematic\nevaluation of state-of-the-art CS algorithms under the scan based CS-THz\narchitecture. The compression ratios and the choices of the sensing matrices\nwere analyzed in detail using both synthetic and real-life THz images.\nSimulation results showed that both the scan based architecture and the\nproposed recovery algorithm were superior and efficient for large scale CS-THz\napplications."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11265-015-1023-3", 
    "link": "http://arxiv.org/pdf/1309.6379v1", 
    "title": "Diffeomorphic Metric Mapping and Probabilistic Atlas Generation of   Hybrid Diffusion Imaging based on BFOR Signal Basis", 
    "arxiv-id": "1309.6379v1", 
    "author": "Anqi Qiu", 
    "publish": "2013-09-25T01:57:50Z", 
    "summary": "We propose a large deformation diffeomorphic metric mapping algorithm to\nalign multiple b-value diffusion weighted imaging (mDWI) data, specifically\nacquired via hybrid diffusion imaging (HYDI), denoted as LDDMM-HYDI. We then\npropose a Bayesian model for estimating the white matter atlas from HYDIs. We\nadopt the work given in Hosseinbor et al. (2012) and represent the q-space\ndiffusion signal with the Bessel Fourier orientation reconstruction (BFOR)\nsignal basis. The BFOR framework provides the representation of mDWI in the\nq-space and thus reduces memory requirement. In addition, since the BFOR signal\nbasis is orthonormal, the L2 norm that quantifies the differences in the\nq-space signals of any two mDWI datasets can be easily computed as the sum of\nthe squared differences in the BFOR expansion coefficients. In this work, we\nshow that the reorientation of the $q$-space signal due to spatial\ntransformation can be easily defined on the BFOR signal basis. We incorporate\nthe BFOR signal basis into the LDDMM framework and derive the gradient descent\nalgorithm for LDDMM-HYDI with explicit orientation optimization. Additionally,\nwe extend the previous Bayesian atlas estimation framework for scalar-valued\nimages to HYDIs and derive the expectation-maximization algorithm for solving\nthe HYDI atlas estimation problem. Using real HYDI datasets, we show the\nBayesian model generates the white matter atlas with anatomical details.\nMoreover, we show that it is important to consider the variation of mDWI\nreorientation due to a small change in diffeomorphic transformation in the\nLDDMM-HYDI optimization and to incorporate the full information of HYDI for\naligning mDWI."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-1-4471-2155-8_51", 
    "link": "http://arxiv.org/pdf/1309.6390v1", 
    "title": "Contextually learnt detection of unusual motion-based behaviour in   crowded public spaces", 
    "arxiv-id": "1309.6390v1", 
    "author": "Ognjen Arandjelovi\u0107", 
    "publish": "2013-09-25T03:22:59Z", 
    "summary": "In this paper we are interested in analyzing behaviour in crowded public\nplaces at the level of holistic motion. Our aim is to learn, without user\ninput, strong scene priors or labelled data, the scope of \"normal behaviour\"\nfor a particular scene and thus alert to novelty in unseen footage. The first\ncontribution is a low-level motion model based on what we term tracklet\nprimitives, which are scene-specific elementary motions. We propose a\nclustering-based algorithm for tracklet estimation from local approximations to\ntracks of appearance features. This is followed by two methods for motion\nnovelty inference from tracklet primitives: (a) we describe an approach based\non a non-hierarchial ensemble of Markov chains as a means of capturing\nbehavioural characteristics at different scales, and (b) a more flexible\nalternative which exhibits a higher generalizing power by accounting for\nconstraints introduced by intentionality and goal-oriented planning of human\nmotion in a particular scene. Evaluated on a 2h long video of a busy city\nmarketplace, both algorithms are shown to be successful at inferring unusual\nbehaviour, the latter model achieving better performance for novelties at a\nlarger spatial scale."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-17277-9_10", 
    "link": "http://arxiv.org/pdf/1309.6391v1", 
    "title": "Multiple-object tracking in cluttered and crowded public spaces", 
    "arxiv-id": "1309.6391v1", 
    "author": "Ognjen Arandjelovi\u0107", 
    "publish": "2013-09-25T03:34:01Z", 
    "summary": "This paper addresses the problem of tracking moving objects of variable\nappearance in challenging scenes rich with features and texture. Reliable\ntracking is of pivotal importance in surveillance applications. It is made\nparticularly difficult by the nature of objects encountered in such scenes:\nthese too change in appearance and scale, and are often articulated (e.g.\nhumans). We propose a method which uses fast motion detection and segmentation\nas a constraint for both building appearance models and their robust\npropagation (matching) in time. The appearance model is based on sets of local\nappearances automatically clustered using spatio-kinetic similarity, and is\nupdated with each new appearance seen. This integration of all seen appearances\nof a tracked object makes it extremely resilient to errors caused by occlusion\nand the lack of permanence of due to low data quality, appearance change or\nbackground clutter. These theoretical strengths of our algorithm are\nempirically demonstrated on two hour long video footage of a busy city\nmarketplace."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-17277-9_10", 
    "link": "http://arxiv.org/pdf/1309.6691v1", 
    "title": "Characterness: An Indicator of Text in the Wild", 
    "arxiv-id": "1309.6691v1", 
    "author": "Anton van den Hengel", 
    "publish": "2013-09-25T23:30:18Z", 
    "summary": "Text in an image provides vital information for interpreting its contents,\nand text in a scene can aide with a variety of tasks from navigation, to\nobstacle avoidance, and odometry. Despite its value, however, identifying\ngeneral text in images remains a challenging research problem. Motivated by the\nneed to consider the widely varying forms of natural text, we propose a\nbottom-up approach to the problem which reflects the `characterness' of an\nimage region. In this sense our approach mirrors the move from saliency\ndetection methods to measures of `objectness'. In order to measure the\ncharacterness we develop three novel cues that are tailored for character\ndetection, and a Bayesian method for their integration. Because text is made up\nof sets of characters, we then design a Markov random field (MRF) model so as\nto exploit the inherent dependencies between characters.\n  We experimentally demonstrate the effectiveness of our characterness cues as\nwell as the advantage of Bayesian multi-cue integration. The proposed text\ndetector outperforms state-of-the-art methods on a few benchmark scene text\ndetection datasets. We also show that our measurement of `characterness' is\nsuperior than state-of-the-art saliency detection models when applied to the\nsame task."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-17277-9_10", 
    "link": "http://arxiv.org/pdf/1309.6964v4", 
    "title": "Online Algorithms for Factorization-Based Structure from Motion", 
    "arxiv-id": "1309.6964v4", 
    "author": "Camillo J. Taylor", 
    "publish": "2013-09-26T16:46:28Z", 
    "summary": "We present a family of online algorithms for real-time factorization-based\nstructure from motion, leveraging a relationship between incremental singular\nvalue decomposition and recently proposed methods for online matrix completion.\nOur methods are orders of magnitude faster than previous state of the art, can\nhandle missing data and a variable number of feature points, and are robust to\nnoise and sparse outliers. We demonstrate our methods on both real and\nsynthetic sequences and show that they perform well in both online and batch\nsettings. We also provide an implementation which is able to produce 3D models\nin real time using a laptop with a webcam."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2407", 
    "link": "http://arxiv.org/pdf/1309.7276v1", 
    "title": "Adopting level set theory based algorithms to segment human ear", 
    "arxiv-id": "1309.7276v1", 
    "author": "Nimmi I. P", 
    "publish": "2013-09-26T05:48:18Z", 
    "summary": "Human identification has always been a topic that interested researchers\naround the world. Biometric methods are found to be more effective and much\neasier for the users than the traditional identification methods like keys,\nsmart cards and passwords. Unlike with the traditional methods, with biometric\nmethods the data acquisition is most of the times passive, which means the\nusers do not take active part in data acquisition. Data acquisition can be\nperformed using cameras, scanners or sensors. Human physiological biometrics\nsuch as face, eye and ear are good candidates for uniquely identifying an\nindividual. However, human ear scores over face and eye because of certain\nadvantages it has over face. The most challenging phase in human identification\nbased on ear biometric is the segmentation of the ear image from the captured\nimage which may contain many unwanted details. In this work, PDE based image\nprocessing techniques are used to segment out the ear image. Level Set Theory\nbased image processing is employed to obtain the contour of the ear image. A\nfew Level set algorithms are compared for their efficiency in segmenting test\near images."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2407", 
    "link": "http://arxiv.org/pdf/1309.7434v1", 
    "title": "Face Verification Using Boosted Cross-Image Features", 
    "arxiv-id": "1309.7434v1", 
    "author": "Mubarak Shah", 
    "publish": "2013-09-28T06:21:18Z", 
    "summary": "This paper proposes a new approach for face verification, where a pair of\nimages needs to be classified as belonging to the same person or not. This\nproblem is relatively new and not well-explored in the literature. Current\nmethods mostly adopt techniques borrowed from face recognition, and process\neach of the images in the pair independently, which is counter intuitive. In\ncontrast, we propose to extract cross-image features, i.e. features across the\npair of images, which, as we demonstrate, is more discriminative to the\nsimilarity and the dissimilarity of faces. Our features are derived from the\npopular Haar-like features, however, extended to handle the face verification\nproblem instead of face detection. We collect a large bank of cross-image\nfeatures using filters of different sizes, locations, and orientations.\nConsequently, we use AdaBoost to select and weight the most discriminative\nfeatures. We carried out extensive experiments on the proposed ideas using\nthree standard face verification datasets, and obtained promising results\noutperforming state-of-the-art."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2407", 
    "link": "http://arxiv.org/pdf/1309.7484v1", 
    "title": "CSIFT Based Locality-constrained Linear Coding for Image Classification", 
    "arxiv-id": "1309.7484v1", 
    "author": "Kin Hong Wong", 
    "publish": "2013-09-28T18:05:12Z", 
    "summary": "In the past decade, SIFT descriptor has been witnessed as one of the most\nrobust local invariant feature descriptors and widely used in various vision\ntasks. Most traditional image classification systems depend on the\nluminance-based SIFT descriptors, which only analyze the gray level variations\nof the images. Misclassification may happen since their color contents are\nignored. In this article, we concentrate on improving the performance of\nexisting image classification algorithms by adding color information. To\nachieve this purpose, different kinds of colored SIFT descriptors are\nintroduced and implemented. Locality-constrained Linear Coding (LLC), a\nstate-of-the-art sparse coding technology, is employed to construct the image\nclassification system for the evaluation. The real experiments are carried out\non several benchmarks. With the enhancements of color SIFT, the proposed image\nclassification system obtains approximate 3% improvement of classification\naccuracy on the Caltech-101 dataset and approximate 4% improvement of\nclassification accuracy on the Caltech-256 dataset."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2407", 
    "link": "http://arxiv.org/pdf/1309.7609v1", 
    "title": "Identificaci\u00f3n y Registro Catastral de Cuerpos de Agua mediante   T\u00e9cnicas de Procesamiento Digital de Imagenes", 
    "arxiv-id": "1309.7609v1", 
    "author": "Christhian Cardenas Alvarez", 
    "publish": "2013-09-29T15:36:43Z", 
    "summary": "The effects of global climate change on Peruvian glaciers have brought about\nseveral processes of deglaciation during the last few years. The immediate\neffect is the change of size of lakes and rivers. Public institutions that\nmonitor water resources currently have only recent studies which make up less\nthan 10% of the total. The effects of climate change and the lack of updated\ninformation intensify social-economic problems related to water resources in\nPeru. The objective of this research is to develop a software application to\nautomate the Cadastral Registry of Water Bodies in Peru, using techniques of\ndigital image processing, which would provide tools for detection, record,\ntemporal analysis and visualization of water bodies. The images used are from\nthe satellite Landsat5, which undergo a pre-processing of calibration and\ncorrection of the satellite. Detection results are archived into a file that\ncontains location vectors and images of the segmentated bodies of water."
},{
    "category": "cs.CV", 
    "doi": "10.5815/ijigsp.2013.12.08", 
    "link": "http://arxiv.org/pdf/1309.7615v1", 
    "title": "Correcting Multi-focus Images via Simple Standard Deviation for Image   Fusion", 
    "arxiv-id": "1309.7615v1", 
    "author": "Firas A. Jassim", 
    "publish": "2013-09-29T16:14:47Z", 
    "summary": "Image fusion is one of the recent trends in image registration which is an\nessential field of image processing. The basic principle of this paper is to\nfuse multi-focus images using simple statistical standard deviation. Firstly,\nthe simple standard deviation for the k-by-k window inside each of the\nmulti-focus images was computed. The contribution in this paper came from the\nidea that the focused part inside an image had high details rather than the\nunfocused part. Hence, the dispersion between pixels inside the focused part is\nhigher than the dispersion inside the unfocused part. Secondly, a simple\ncomparison between the standard deviation for each k-by-k window in the\nmulti-focus images could be computed. The highest standard deviation between\nall the computed standard deviations for the multi-focus images could be\ntreated as the optimal that is to be placed in the fused image. The\nexperimental visual results show that the proposed method produces very\nsatisfactory results in spite of its simplicity."
},{
    "category": "cs.CV", 
    "doi": "10.5815/ijigsp.2013.12.08", 
    "link": "http://arxiv.org/pdf/1309.7912v1", 
    "title": "An Image-Based Fluid Surface Pattern Model", 
    "arxiv-id": "1309.7912v1", 
    "author": "Francisco Duarte Moura Neto", 
    "publish": "2013-09-30T16:39:21Z", 
    "summary": "This work aims at generating a model of the ocean surface and its dynamics\nfrom one or more video cameras. The idea is to model wave patterns from video\nas a first step towards a larger system of photogrammetric monitoring of marine\nconditions for use in offshore oil drilling platforms. The first part of the\nproposed approach consists in reducing the dimensionality of sensor data made\nup of the many pixels of each frame of the input video streams. This enables\nfinding a concise number of most relevant parameters to model the temporal\ndataset, yielding an efficient data-driven model of the evolution of the\nobserved surface. The second part proposes stochastic modeling to better\ncapture the patterns embedded in the data. One can then draw samples from the\nfinal model, which are expected to simulate the behavior of previously observed\nflow, in order to determine conditions that match new observations. In this\npaper we focus on proposing and discussing the overall approach and on\ncomparing two different techniques for dimensionality reduction in the first\nstage: principal component analysis and diffusion maps. Work is underway on the\nsecond stage of constructing better stochastic models of fluid surface dynamics\nas proposed here."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTARS.2013.2256881", 
    "link": "http://arxiv.org/pdf/1311.0162v1", 
    "title": "Iterative Bilateral Filtering of Polarimetric SAR Data", 
    "arxiv-id": "1311.0162v1", 
    "author": "Olaf Hellwich", 
    "publish": "2013-11-01T12:20:17Z", 
    "summary": "In this paper, we introduce an iterative speckle filtering method for\npolarimetric SAR (PolSAR) images based on the bilateral filter. To locally\nadapt to the spatial structure of images, this filter relies on pixel\nsimilarities in both spatial and radiometric domains. To deal with polarimetric\ndata, we study the use of similarities based on a statistical distance called\nKullback-Leibler divergence as well as two geodesic distances on Riemannian\nmanifolds. To cope with speckle, we propose to progressively refine the result\nthanks to an iterative scheme. Experiments are run over synthetic and\nexperimental data. First, simulations are generated to study the effects of\nfiltering parameters in terms of polarimetric reconstruction error, edge\npreservation and smoothing of homogeneous areas. Comparison with other methods\nshows that our approach compares well to other state of the art methods in the\nextraction of polarimetric information and shows superior performance for edge\nrestoration and noise smoothing. The filter is then applied to experimental\ndata sets from ESAR and FSAR sensors (DLR) at L-band and S-band, respectively.\nThese last experiments show the ability of the filter to restore structures\nsuch as buildings and roads and to preserve boundaries between regions while\nachieving a high amount of smoothing in homogeneous areas."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.1223v1", 
    "title": "Quality Assessment of Pixel-Level ImageFusion Using Fuzzy Logic", 
    "arxiv-id": "1311.1223v1", 
    "author": "M. H. M. Krishna Prasad", 
    "publish": "2013-11-05T21:13:14Z", 
    "summary": "Image fusion is to reduce uncertainty and minimize redundancy in the output\nwhile maximizing relevant information from two or more images of a scene into a\nsingle composite image that is more informative and is more suitable for visual\nperception or processing tasks like medical imaging, remote sensing, concealed\nweapon detection, weather forecasting, biometrics etc. Image fusion combines\nregistered images to produce a high quality fused image with spatial and\nspectral information. The fused image with more information will improve the\nperformance of image analysis algorithms used in different applications. In\nthis paper, we proposed a fuzzy logic method to fuse images from different\nsensors, in order to enhance the quality and compared proposed method with two\nother methods i.e. image fusion using wavelet transform and weighted average\ndiscrete wavelet transform based image fusion using genetic algorithm (here\nonwards abbreviated as GA) along with quality evaluation parameters image\nquality index (IQI), mutual information measure (MIM), root mean square error\n(RMSE), peak signal to noise ratio (PSNR), fusion factor (FF), fusion symmetry\n(FS) and fusion index (FI) and entropy. The results obtained from proposed\nfuzzy based image fusion approach improves quality of fused image as compared\nto earlier reported methods, wavelet transform based image fusion and weighted\naverage discrete wavelet transform based image fusion using genetic algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.1279v1", 
    "title": "Face Recognition via Globality-Locality Preserving Projections", 
    "arxiv-id": "1311.1279v1", 
    "author": "Jiwen Lu", 
    "publish": "2013-11-06T03:16:21Z", 
    "summary": "We present an improved Locality Preserving Projections (LPP) method, named\nGloablity-Locality Preserving Projections (GLPP), to preserve both the global\nand local geometric structures of data. In our approach, an additional\nconstraint of the geometry of classes is imposed to the objective function of\nconventional LPP for respecting some more global manifold structures. Moreover,\nwe formulate a two-dimensional extension of GLPP (2D-GLPP) as an example to\nshow how to extend GLPP with some other statistical techniques. We apply our\nworks to face recognition on four popular face databases, namely ORL, Yale,\nFERET and LFW-A databases, and extensive experimental results demonstrate that\nthe considered global manifold information can significantly improve the\nperformance of LPP and the proposed face recognition methods outperform the\nstate-of-the-arts."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.1694v1", 
    "title": "Biometric Signature Processing & Recognition Using Radial Basis Function   Network", 
    "arxiv-id": "1311.1694v1", 
    "author": "Vibha Wali", 
    "publish": "2013-11-07T14:37:06Z", 
    "summary": "Automatic recognition of signature is a challenging problem which has\nreceived much attention during recent years due to its many applications in\ndifferent fields. Signature has been used for long time for verification and\nauthentication purpose. Earlier methods were manual but nowadays they are\ngetting digitized. This paper provides an efficient method to signature\nrecognition using Radial Basis Function Network. The network is trained with\nsample images in database. Feature extraction is performed before using them\nfor training. For testing purpose, an image is made to undergo\nrotation-translation-scaling correction and then given to network. The network\nsuccessfully identifies the original image and gives correct output for stored\ndatabase images also. The method provides recognition rate of approximately 80%\nfor 200 samples."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.1838v2", 
    "title": "Efficient Regularization of Squared Curvature", 
    "arxiv-id": "1311.1838v2", 
    "author": "Yuri Boykov", 
    "publish": "2013-11-07T22:08:24Z", 
    "summary": "Curvature has received increased attention as an important alternative to\nlength based regularization in computer vision. In contrast to length, it\npreserves elongated structures and fine details. Existing approaches are either\ninefficient, or have low angular resolution and yield results with strong block\nartifacts. We derive a new model for computing squared curvature based on\nintegral geometry. The model counts responses of straight line triple cliques.\nThe corresponding energy decomposes into submodular and supermodular pairwise\npotentials. We show that this energy can be efficiently minimized even for high\nangular resolutions using the trust region framework. Our results confirm that\nwe obtain accurate and visually pleasing solutions without strong artifacts at\nreasonable run times."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.1856v2", 
    "title": "Submodularization for Quadratic Pseudo-Boolean Optimization", 
    "arxiv-id": "1311.1856v2", 
    "author": "Andrew Delong", 
    "publish": "2013-11-08T00:29:44Z", 
    "summary": "Many computer vision problems require optimization of binary non-submodular\nenergies. We propose a general optimization framework based on local submodular\napproximations (LSA). Unlike standard LP relaxation methods that linearize the\nwhole energy globally, our approach iteratively approximates the energies\nlocally. On the other hand, unlike standard local optimization methods (e.g.\ngradient descent or projection techniques) we use non-linear submodular\napproximations and optimize them without leaving the domain of integer\nsolutions. We discuss two specific LSA algorithms based on \"trust region\" and\n\"auxiliary function\" principles, LSA-TR and LSA-AUX. These methods obtain\nstate-of-the-art results on a wide range of applications outperforming many\nstandard techniques such as LBP, QPBO, and TRWS. While our paper is focused on\npairwise energies, our ideas extend to higher-order problems. The code is\navailable online (http://vision.csd.uwo.ca/code/)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.1939v1", 
    "title": "Fast Tracking via Spatio-Temporal Context Learning", 
    "arxiv-id": "1311.1939v1", 
    "author": "David Zhang", 
    "publish": "2013-11-08T11:29:15Z", 
    "summary": "In this paper, we present a simple yet fast and robust algorithm which\nexploits the spatio-temporal context for visual tracking. Our approach\nformulates the spatio-temporal relationships between the object of interest and\nits local context based on a Bayesian framework, which models the statistical\ncorrelation between the low-level features (i.e., image intensity and position)\nfrom the target and its surrounding regions. The tracking problem is posed by\ncomputing a confidence map, and obtaining the best target location by\nmaximizing an object location likelihood function. The Fast Fourier Transform\nis adopted for fast learning and detection in this work. Implemented in MATLAB\nwithout code optimization, the proposed tracker runs at 350 frames per second\non an i7 machine. Extensive experimental results show that the proposed\nalgorithm performs favorably against state-of-the-art methods in terms of\nefficiency, accuracy and robustness."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.2014v1", 
    "title": "A new stopping criterion for the mean shift iterative algorithm", 
    "arxiv-id": "1311.2014v1", 
    "author": "Humberto Sossa", 
    "publish": "2013-11-08T16:27:19Z", 
    "summary": "The mean shift iterative algorithm was proposed in 2006, for using the\nentropy as a stopping criterion. From then on, a theoretical base has been\ndeveloped and a group of applications has been carried out using this\nalgorithm. This paper proposes a new stopping criterion for the mean shift\niterative algorithm, where stopping threshold via entropy is used now, but in\nanother way. Many segmentation experiments were carried out by utilizing\nstandard images and it was verified that a better segmentation was reached, and\nthat the algorithm had better stability. An analysis on the convergence,\nthrough a theorem, with the new stopping criterion was carried out. The goal of\nthis paper is to compare the new stopping criterion with the old criterion. For\nthis reason, the obtained results were not compared with other segmentation\napproaches, since with the old stopping criterion were previously carried out."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3102", 
    "link": "http://arxiv.org/pdf/1311.2102v1", 
    "title": "An Experimental Comparison of Trust Region and Level Sets", 
    "arxiv-id": "1311.2102v1", 
    "author": "Yuri Boykov", 
    "publish": "2013-11-08T22:49:07Z", 
    "summary": "High-order (non-linear) functionals have become very popular in segmentation,\nstereo and other computer vision problems. Level sets is a well established\ngeneral gradient descent framework, which is directly applicable to\noptimization of such functionals and widely used in practice. Recently, another\ngeneral optimization approach based on trust region methodology was proposed\nfor regional non-linear functionals. Our goal is a comprehensive experimental\ncomparison of these two frameworks in regard to practical efficiency,\nrobustness to parameters, and optimality. We experiment on a wide range of\nproblems with non-linear constraints on segment volume, appearance and shape."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2191v2", 
    "title": "Neighborhood filters and the decreasing rearrangement", 
    "arxiv-id": "1311.2191v2", 
    "author": "Juli\u00e1n Velasco", 
    "publish": "2013-11-09T17:53:22Z", 
    "summary": "Nonlocal filters are simple and powerful techniques for image denoising. In\nthis paper, we give new insights into the analysis of one kind of them, the\nNeighborhood filter, by using a classical although not very common\ntransformation: the decreasing rearrangement of a function (the image).\nIndependently of the dimension of the image, we reformulate the Neighborhood\nfilter and its iterative variants as an integral operator defined in a\none-dimensional space. The simplicity of this formulation allows to perform a\ndetailed analysis of its properties. Among others, we prove that the filter\nbehaves asymptotically as a shock filter combined with a border diffusive term,\nresponsible for the staircaising effect and the loss of contrast."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2492v1", 
    "title": "Notes on Elementary Spectral Graph Theory. Applications to Graph   Clustering Using Normalized Cuts", 
    "arxiv-id": "1311.2492v1", 
    "author": "Jean Gallier", 
    "publish": "2013-11-11T16:45:03Z", 
    "summary": "These are notes on the method of normalized graph cuts and its applications\nto graph clustering. I provide a fairly thorough treatment of this deeply\noriginal method due to Shi and Malik, including complete proofs. I include the\nnecessary background on graphs and graph Laplacians. I then explain in detail\nhow the eigenvectors of the graph Laplacian can be used to draw a graph. This\nis an attractive application of graph Laplacians. The main thrust of this paper\nis the method of normalized cuts. I give a detailed account for K = 2 clusters,\nand also for K > 2 clusters, based on the work of Yu and Shi. Three points that\ndo not appear to have been clearly articulated before are elaborated:\n  1. The solutions of the main optimization problem should be viewed as tuples\nin the K-fold cartesian product of projective space RP^{N-1}.\n  2. When K > 2, the solutions of the relaxed problem should be viewed as\nelements of the Grassmannian G(K,N).\n  3. Two possible Riemannian distances are available to compare the closeness\nof solutions: (a) The distance on (RP^{N-1})^K. (b) The distance on the\nGrassmannian.\n  I also clarify what should be the necessary and sufficient conditions for a\nmatrix to represent a partition of the vertices of a graph to be clustered."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2524v5", 
    "title": "Rich feature hierarchies for accurate object detection and semantic   segmentation", 
    "arxiv-id": "1311.2524v5", 
    "author": "Jitendra Malik", 
    "publish": "2013-11-11T18:43:49Z", 
    "summary": "Object detection performance, as measured on the canonical PASCAL VOC\ndataset, has plateaued in the last few years. The best-performing methods are\ncomplex ensemble systems that typically combine multiple low-level image\nfeatures with high-level context. In this paper, we propose a simple and\nscalable detection algorithm that improves mean average precision (mAP) by more\nthan 30% relative to the previous best result on VOC 2012---achieving a mAP of\n53.3%. Our approach combines two key insights: (1) one can apply high-capacity\nconvolutional neural networks (CNNs) to bottom-up region proposals in order to\nlocalize and segment objects and (2) when labeled training data is scarce,\nsupervised pre-training for an auxiliary task, followed by domain-specific\nfine-tuning, yields a significant performance boost. Since we combine region\nproposals with CNNs, we call our method R-CNN: Regions with CNN features. We\nalso compare R-CNN to OverFeat, a recently proposed sliding-window detector\nbased on a similar CNN architecture. We find that R-CNN outperforms OverFeat by\na large margin on the 200-class ILSVRC2013 detection dataset. Source code for\nthe complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2621v1", 
    "title": "Determining Leishmania Infection Levels by Automatic Analysis of   Microscopy Images", 
    "arxiv-id": "1311.2621v1", 
    "author": "P. A Nogueira", 
    "publish": "2013-11-11T21:42:51Z", 
    "summary": "Analysis of microscopy images is one important tool in many fields of\nbiomedical research, as it allows the quantification of a multitude of\nparameters at the cellular level. However, manual counting of these images is\nboth tiring and unreliable and ultimately very time-consuming for biomedical\nresearchers. Not only does this slow down the overall research process, it also\nintroduces counting errors due to a lack of objectivity and consistency\ninherent to the researchers own human nature.\n  This thesis addresses this issue by automatically determining infection\nindexes of macrophages parasite by Leishmania in microscopy images using\ncomputer vision and pattern recognition methodologies. Initially images are\nsubmitted to a pre-processing stage that consists in a normalization of\nillumination conditions. Three algorithms are then applied in parallel to each\nimage. Algorithm A intends to detect macrophage nuclei and consists of\nsegmentation via adaptive multi-threshold, and classification of resulting\nregions using a set of collected features. Algorithm B intends to detect\nparasites and is similar to Algorithm A but the adaptive multi-threshold is\nparameterized with a different constraints vector. Algorithm C intends to\ndetect the macrophages and parasites cytoplasm and consists of a cut-off\nversion of the previous two algorithms, where the classification step is\nskipped. Regions with multiple nuclei or parasites are processed by a voting\nsystem that employs both a Support Vector Machine and a set of region features\nfor determining the number of objects present in each region. The previous vote\nis then taken into account as the number of mixtures to be used in a Gaussian\nMixture Model to decluster the said region. Finally each parasite is assigned\nto, at most, a single macrophage using minimum Euclidean distance to a cell\nnucleus, thus quantifying Leishmania infection levels."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2626v5", 
    "title": "Second-order Shape Optimization for Geometric Inverse Problems in Vision", 
    "arxiv-id": "1311.2626v5", 
    "author": "S. Soatto", 
    "publish": "2013-11-11T21:53:28Z", 
    "summary": "We develop a method for optimization in shape spaces, i.e., sets of surfaces\nmodulo re-parametrization. Unlike previously proposed gradient flows, we\nachieve superlinear convergence rates through a subtle approximation of the\nshape Hessian, which is generally hard to compute and suffers from a series of\ndegeneracies. Our analysis highlights the role of mean curvature motion in\ncomparison with first-order schemes: instead of surface area, our approach\npenalizes deformation, either by its Dirichlet energy or total variation.\nLatter regularizer sparks the development of an alternating direction method of\nmultipliers on triangular meshes. Therein, a conjugate-gradients solver enables\nus to bypass formation of the Gaussian normal equations appearing in the course\nof the overall optimization. We combine all of the aforementioned ideas in a\nversatile geometric variation-regularized Levenberg-Marquardt-type method\napplicable to a variety of shape functionals, depending on intrinsic properties\nof the surface such as normal field and curvature as well as its embedding into\nspace. Promising experimental results are reported."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2642v1", 
    "title": "Volumetric Reconstruction Applied to Perceptual Studies of Size and   Weight", 
    "arxiv-id": "1311.2642v1", 
    "author": "S. Soatto", 
    "publish": "2013-11-11T22:59:33Z", 
    "summary": "We explore the application of volumetric reconstruction from structured-light\nsensors in cognitive neuroscience, specifically in the quantification of the\nsize-weight illusion, whereby humans tend to systematically perceive smaller\nobjects as heavier. We investigate the performance of two commercial\nstructured-light scanning systems in comparison to one we developed\nspecifically for this application. Our method has two main distinct features:\nFirst, it only samples a sparse series of viewpoints, unlike other systems such\nas the Kinect Fusion. Second, instead of building a distance field for the\npurpose of points-to-surface conversion directly, we pursue a first-order\napproach: the distance function is recovered from its gradient by a screened\nPoisson reconstruction, which is very resilient to noise and yet preserves\nhigh-frequency signal components. Our experiments show that the quality of\nmetric reconstruction from structured light sensors is subject to systematic\nbiases, and highlights the factors that influence it. Our main performance\nindex rates estimates of volume (a proxy of size), for which we review a\nwell-known formula applicable to incomplete meshes. Our code and data will be\nmade publicly available upon completion of the anonymous review process."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0522-3", 
    "link": "http://arxiv.org/pdf/1311.2901v3", 
    "title": "Visualizing and Understanding Convolutional Networks", 
    "arxiv-id": "1311.2901v3", 
    "author": "Rob Fergus", 
    "publish": "2013-11-12T20:02:22Z", 
    "summary": "Large Convolutional Network models have recently demonstrated impressive\nclassification performance on the ImageNet benchmark. However there is no clear\nunderstanding of why they perform so well, or how they might be improved. In\nthis paper we address both issues. We introduce a novel visualization technique\nthat gives insight into the function of intermediate feature layers and the\noperation of the classifier. We also perform an ablation study to discover the\nperformance contribution from different model layers. This enables us to find\nmodel architectures that outperform Krizhevsky \\etal on the ImageNet\nclassification benchmark. We show our ImageNet model generalizes well to other\ndatasets: when the softmax classifier is retrained, it convincingly beats the\ncurrent state-of-the-art results on Caltech-101 and Caltech-256 datasets."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3076v1", 
    "title": "An Efficient Method for Recognizing the Low Quality Fingerprint   Verification by Means of Cross Correlation", 
    "arxiv-id": "1311.3076v1", 
    "author": "V. J. Vijayalakshmi", 
    "publish": "2013-11-13T10:50:14Z", 
    "summary": "In this paper, we propose an efficient method to provide personal\nidentification using fingerprint to get better accuracy even in noisy\ncondition. The fingerprint matching based on the number of corresponding\nminutia pairings, has been in use for a long time, which is not very efficient\nfor recognizing the low quality fingerprints. To overcome this problem,\ncorrelation technique is used. The correlation-based fingerprint verification\nsystem is capable of dealing with low quality images from which no minutiae can\nbe extracted reliably and with fingerprints that suffer from non-uniform shape\ndistortions, also in case of damaged and partial images. Orientation Field\nMethodology (OFM) has been used as a preprocessing module, and it converts the\nimages into a field pattern based on the direction of the ridges, loops and\nbifurcations in the image of a fingerprint. The input image is then Cross\nCorrelated (CC) with all the images in the cluster and the highest correlated\nimage is taken as the output. The result gives a good recognition rate, as the\nproposed scheme uses Cross Correlation of Field Orientation (CCFO = OFM + CC)\nfor fingerprint identification."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3269v1", 
    "title": "On a non-local spectrogram for denoising one-dimensional signals", 
    "arxiv-id": "1311.3269v1", 
    "author": "Juli\u00e1n Velasco", 
    "publish": "2013-11-13T19:46:06Z", 
    "summary": "In previous works, we investigated the use of local filters based on partial\ndifferential equations (PDE) to denoise one-dimensional signals through the\nimage processing of time-frequency representations, such as the spectrogram. In\nthis image denoising algorithms, the particularity of the image was hardly\ntaken into account. We turn, in this paper, to study the performance of\nnon-local filters, like Neighborhood or Yaroslavsky filters, in the same\nproblem. We show that, for certain iterative schemes involving the Neighborhood\nfilter, the computational time is drastically reduced with respect to\nYaroslavsky or nonlinear PDE based filters, while the outputs of the filtering\nprocesses are similar. This is heuristically justified by the connection\nbetween the (fast) Neighborhood filter applied to a spectrogram and the\ncorresponding Nonlocal Means filter (accurate) applied to the Wigner-Ville\ndistribution of the signal. This correspondence holds only for time-frequency\nrepresentations of one-dimensional signals, not to usual images, and in this\nsense the particularity of the image is exploited. We compare though a series\nof experiments on synthetic and biomedical signals the performance of local and\nnon-local filters."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3318v1", 
    "title": "A Study of Actor and Action Semantic Retention in Video Supervoxel   Segmentation", 
    "arxiv-id": "1311.3318v1", 
    "author": "Jason J. Corso", 
    "publish": "2013-11-13T21:58:55Z", 
    "summary": "Existing methods in the semantic computer vision community seem unable to\ndeal with the explosion and richness of modern, open-source and social video\ncontent. Although sophisticated methods such as object detection or\nbag-of-words models have been well studied, they typically operate on low level\nfeatures and ultimately suffer from either scalability issues or a lack of\nsemantic meaning. On the other hand, video supervoxel segmentation has recently\nbeen established and applied to large scale data processing, which potentially\nserves as an intermediate representation to high level video semantic\nextraction. The supervoxels are rich decompositions of the video content: they\ncapture object shape and motion well. However, it is not yet known if the\nsupervoxel segmentation retains the semantics of the underlying video content.\nIn this paper, we conduct a systematic study of how well the actor and action\nsemantics are retained in video supervoxel segmentation. Our study has human\nobservers watching supervoxel segmentation videos and trying to discriminate\nboth actor (human or animal) and action (one of eight everyday actions). We\ngather and analyze a large set of 640 human perceptions over 96 videos in 3\ndifferent supervoxel scales. Furthermore, we conduct machine recognition\nexperiments on a feature defined on supervoxel segmentation, called supervoxel\nshape context, which is inspired by the higher order processes in human\nperception. Our ultimate findings suggest that a significant amount of\nsemantics have been well retained in the video supervoxel segmentation and can\nbe used for further video analysis."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3405v2", 
    "title": "The STONE Transform: Multi-Resolution Image Enhancement and Real-Time   Compressive Video", 
    "arxiv-id": "1311.3405v2", 
    "author": "Richard Baraniuk", 
    "publish": "2013-11-14T07:54:28Z", 
    "summary": "Compressed sensing enables the reconstruction of high-resolution signals from\nunder-sampled data. While compressive methods simplify data acquisition, they\nrequire the solution of difficult recovery problems to make use of the\nresulting measurements. This article presents a new sensing framework that\ncombines the advantages of both conventional and compressive sensing. Using the\nproposed \\stone transform, measurements can be reconstructed instantly at\nNyquist rates at any power-of-two resolution. The same data can then be\n\"enhanced\" to higher resolutions using compressive methods that leverage\nsparsity to \"beat\" the Nyquist limit. The availability of a fast direct\nreconstruction enables compressive measurements to be processed on small\nembedded devices. We demonstrate this by constructing a real-time compressive\nvideo camera."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3618v2", 
    "title": "Describing Textures in the Wild", 
    "arxiv-id": "1311.3618v2", 
    "author": "Andrea Vedaldi", 
    "publish": "2013-11-14T19:28:35Z", 
    "summary": "Patterns and textures are defining characteristics of many natural objects: a\nshirt can be striped, the wings of a butterfly can be veined, and the skin of\nan animal can be scaly. Aiming at supporting this analytical dimension in image\nunderstanding, we address the challenging problem of describing textures with\nsemantic attributes. We identify a rich vocabulary of forty-seven texture terms\nand use them to describe a large dataset of patterns collected in the wild.The\nresulting Describable Textures Dataset (DTD) is the basis to seek for the best\ntexture representation for recognizing describable texture attributes in\nimages. We port from object recognition to texture recognition the Improved\nFisher Vector (IFV) and show that, surprisingly, it outperforms specialized\ntexture descriptors not only on our problem, but also in established material\nrecognition datasets. We also show that the describable attributes are\nexcellent texture descriptors, transferring between datasets and tasks; in\nparticular, combined with IFV, they significantly outperform the\nstate-of-the-art by more than 8 percent on both FMD and KTHTIPS-2b benchmarks.\nWe also demonstrate that they produce intuitive descriptions of materials and\nInternet images."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3715v3", 
    "title": "Recognizing Image Style", 
    "arxiv-id": "1311.3715v3", 
    "author": "Holger Winnemoeller", 
    "publish": "2013-11-15T03:37:50Z", 
    "summary": "The style of an image plays a significant role in how it is viewed, but style\nhas received little attention in computer vision research. We describe an\napproach to predicting style of images, and perform a thorough evaluation of\ndifferent image features for these tasks. We find that features learned in a\nmulti-layer network generally perform best -- even when trained with object\nclass (not style) labels. Our large-scale learning methods results in the best\npublished performance on an existing dataset of aesthetic ratings and\nphotographic style annotations. We present two novel datasets: 80K Flickr\nphotographs annotated with 20 curated style labels, and 85K paintings annotated\nwith 25 style/genre labels. Our approach shows excellent classification\nperformance on both datasets. We use the learned classifiers to extend\ntraditional tag-based image search to consider stylistic constraints, and\ndemonstrate cross-dataset understanding of style."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.3808v1", 
    "title": "Periodicity Extraction using Superposition of Distance Matching Function   and One-dimensional Haar Wavelet Transform", 
    "arxiv-id": "1311.3808v1", 
    "author": "P. Nagabhushan", 
    "publish": "2013-11-15T11:02:39Z", 
    "summary": "Periodicity of a texture is one of the important visual characteristics and\nis often used as a measure for textural discrimination at the structural level.\nKnowledge about periodicity of a texture is very essential in the field of\ntexture synthesis and texture compression and also in the design of frieze and\nwall papers. In this paper, we propose a method of periodicity extraction from\nnoisy images based on superposition of distance matching function (DMF) and\nwavelet decomposition without de-noising the test images. Overall DMFs are\nsubjected to single-level Haar wavelet decomposition to obtain approximate and\ndetailed coefficients. Extracted coefficients help in determination of\nperiodicities in row and column directions. We illustrate the usefulness and\nthe effectiveness of the proposed method in a texture synthesis application."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2013.2501", 
    "link": "http://arxiv.org/pdf/1311.4029v2", 
    "title": "Blind Deconvolution with Non-local Sparsity Reweighting", 
    "arxiv-id": "1311.4029v2", 
    "author": "Rob Fergus", 
    "publish": "2013-11-16T07:34:48Z", 
    "summary": "Blind deconvolution has made significant progress in the past decade. Most\nsuccessful algorithms are classified either as Variational or Maximum\na-Posteriori ($MAP$). In spite of the superior theoretical justification of\nvariational techniques, carefully constructed $MAP$ algorithms have proven\nequally effective in practice. In this paper, we show that all successful $MAP$\nand variational algorithms share a common framework, relying on the following\nkey principles: sparsity promotion in the gradient domain, $l_2$ regularization\nfor kernel estimation, and the use of convex (often quadratic) cost functions.\nOur observations lead to a unified understanding of the principles required for\nsuccessful blind deconvolution. We incorporate these principles into a novel\nalgorithm that improves significantly upon the state of the art."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.4033v1", 
    "title": "A Comparative Study of Histogram Equalization Based Image Enhancement   Techniques for Brightness Preservation and Contrast Enhancement", 
    "arxiv-id": "1311.4033v1", 
    "author": "Sanjeev Sharma", 
    "publish": "2013-11-16T08:10:56Z", 
    "summary": "Histogram Equalization is a contrast enhancement technique in the image\nprocessing which uses the histogram of image. However histogram equalization is\nnot the best method for contrast enhancement because the mean brightness of the\noutput image is significantly different from the input image. There are several\nextensions of histogram equalization has been proposed to overcome the\nbrightness preservation challenge. Contrast enhancement using brightness\npreserving bi-histogram equalization (BBHE) and Dualistic sub image histogram\nequalization (DSIHE) which divides the image histogram into two parts based on\nthe input mean and median respectively then equalizes each sub histogram\nindependently. This paper provides review of different popular histogram\nequalization techniques and experimental study based on the absolute mean\nbrightness error (AMBE), peak signal to noise ratio (PSNR), Structure\nsimilarity index (SSI) and Entropy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.4082v3", 
    "title": "Can a biologically-plausible hierarchy effectively replace face   detection, alignment, and recognition pipelines?", 
    "arxiv-id": "1311.4082v3", 
    "author": "Tomaso Poggio", 
    "publish": "2013-11-16T17:49:31Z", 
    "summary": "The standard approach to unconstrained face recognition in natural\nphotographs is via a detection, alignment, recognition pipeline. While that\napproach has achieved impressive results, there are several reasons to be\ndissatisfied with it, among them is its lack of biological plausibility. A\nrecent theory of invariant recognition by feedforward hierarchical networks,\nlike HMAX, other convolutional networks, or possibly the ventral stream,\nimplies an alternative approach to unconstrained face recognition. This\napproach accomplishes detection and alignment implicitly by storing\ntransformations of training images (called templates) rather than explicitly\ndetecting and aligning faces at test time. Here we propose a particular\nlocality-sensitive hashing based voting scheme which we call \"consensus of\ncollisions\" and show that it can be used to approximate the full 3-layer\nhierarchy implied by the theory. The resulting end-to-end system for\nunconstrained face recognition operates on photographs of faces taken under\nnatural conditions, e.g., Labeled Faces in the Wild (LFW), without aligning or\ncropping them, as is normally done. It achieves a drastic improvement in the\nstate of the art on this end-to-end task, reaching the same level of\nperformance as the best systems operating on aligned, closely cropped images\n(no outside training data). It also performs well on two newer datasets,\nsimilar to LFW, but more difficult: LFW-jittered (new here) and SUFR-W."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.4963v2", 
    "title": "Comparative Study Of Image Edge Detection Algorithms", 
    "arxiv-id": "1311.4963v2", 
    "author": "Shraey Bhatia", 
    "publish": "2013-11-20T06:22:53Z", 
    "summary": "Since edge detection is in the forefront of image processing for object\ndetection, it is crucial to have a good understanding of edge detection\nalgorithms. The reason for this is that edges form the outline of an object. An\nedge is the boundary between an object and the background, and indicates the\nboundary between overlapping objects. This means that if the edges in an image\ncan be identified accurately, all of the objects can be located and basic\nproperties such as area, perimeter, and shape can be measured. Since computer\nvision involves the identification and classification of objects in an image,\nedge detection is an essential tool. We tested two edge detectors that use\ndifferent methods for detecting edges and compared their results under a\nvariety of situations to determine which detector was preferable under\ndifferent sets of conditions."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.5590v1", 
    "title": "Adaptive Learning of Region-based pLSA Model for Total Scene Annotation", 
    "arxiv-id": "1311.5590v1", 
    "author": "Honggang Zhang", 
    "publish": "2013-11-21T21:36:23Z", 
    "summary": "In this paper, we present a region-based pLSA model to accomplish the task of\ntotal scene annotation. To be more specific, we not only properly generate a\nlist of tags for each image, but also localizing each region with its\ncorresponding tag. We integrate advantages of different existing region-based\nworks: employ efficient and powerful JSEG algorithm for segmentation so that\neach region can easily express meaningful object information; the introduction\nof pLSA model can help better capturing semantic information behind the\nlow-level features. Moreover, we also propose an adaptive padding mechanism to\nautomatically choose the optimal padding strategy for each region, which\ndirectly increases the overall system performance. Finally we conduct 3\nexperiments to verify our ideas on Corel database and demonstrate the\neffectiveness and accuracy of our system."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.5591v2", 
    "title": "PANDA: Pose Aligned Networks for Deep Attribute Modeling", 
    "arxiv-id": "1311.5591v2", 
    "author": "Lubomir Bourdev", 
    "publish": "2013-11-21T21:43:12Z", 
    "summary": "We propose a method for inferring human attributes (such as gender, hair\nstyle, clothes style, expression, action) from images of people under large\nvariation of viewpoint, pose, appearance, articulation and occlusion.\nConvolutional Neural Nets (CNN) have been shown to perform very well on large\nscale object recognition problems. In the context of attribute classification,\nhowever, the signal is often subtle and it may cover only a small part of the\nimage, while the image is dominated by the effects of pose and viewpoint.\nDiscounting for pose variation would require training on very large labeled\ndatasets which are not presently available. Part-based models, such as poselets\nand DPM have been shown to perform well for this problem but they are limited\nby shallow low-level features. We propose a new method which combines\npart-based models and deep learning by training pose-normalized CNNs. We show\nsubstantial improvement vs. state-of-the-art methods on challenging attribute\nclassification tasks in unconstrained settings. Experiments confirm that our\nmethod outperforms both the best part-based methods on this problem and\nconventional CNNs trained on the full bounding box of the person."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.6007v1", 
    "title": "Dynamic Model of Facial Expression Recognition based on Eigen-face   Approach", 
    "arxiv-id": "1311.6007v1", 
    "author": "S L Happy", 
    "publish": "2013-11-23T15:40:37Z", 
    "summary": "Emotions are best way of communicating information; and sometimes it carry\nmore information than words. Recently, there has been a huge interest in\nautomatic recognition of human emotion because of its wide spread application\nin security, surveillance, marketing, advertisement, and human-computer\ninteraction. To communicate with a computer in a natural way, it will be\ndesirable to use more natural modes of human communication based on voice,\ngestures and facial expressions. In this paper, a holistic approach for facial\nexpression recognition is proposed which captures the variation in facial\nfeatures in temporal domain and classifies the sequence of images in different\nemotions. The proposed method uses Haar-like features to detect face in an\nimage. The dimensionality of the eigenspace is reduced using Principal\nComponent Analysis (PCA). By projecting the subsequent face images into\nprincipal eigen directions, the variation pattern of the obtained weight vector\nis modeled to classify it into different emotions. Owing to the variations of\nexpressions for different people and its intensity, a person specific method\nfor emotion recognition is followed. Using the gray scale images of the frontal\nface, the system is able to classify four basic emotions such as happiness,\nsadness, surprise, and anger."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.6048v1", 
    "title": "On the Design and Analysis of Multiple View Descriptors", 
    "arxiv-id": "1311.6048v1", 
    "author": "Stefano Soatto", 
    "publish": "2013-11-23T20:38:50Z", 
    "summary": "We propose an extension of popular descriptors based on gradient orientation\nhistograms (HOG, computed in a single image) to multiple views. It hinges on\ninterpreting HOG as a conditional density in the space of sampled images, where\nthe effects of nuisance factors such as viewpoint and illumination are\nmarginalized. However, such marginalization is performed with respect to a very\ncoarse approximation of the underlying distribution. Our extension leverages on\nthe fact that multiple views of the same scene allow separating intrinsic from\nnuisance variability, and thus afford better marginalization of the latter. The\nresult is a descriptor that has the same complexity of single-view HOG, and can\nbe compared in the same manner, but exploits multiple views to better trade off\ninsensitivity to nuisance variability with specificity to intrinsic\nvariability. We also introduce a novel multi-view wide-baseline matching\ndataset, consisting of a mixture of real and synthetic objects with ground\ntruthed camera motion and dense three-dimensional geometry."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.6049v1", 
    "title": "Skin Texture Recognition Using Neural Networks", 
    "arxiv-id": "1311.6049v1", 
    "author": "Zaid Abd Alkareem", 
    "publish": "2013-11-23T20:52:05Z", 
    "summary": "Skin recognition is used in many applications ranging from algorithms for\nface detection, hand gesture analysis, and to objectionable image filtering. In\nthis work a skin recognition system was developed and tested. While many skin\nsegmentation algorithms relay on skin color, our work relies on both skin color\nand texture features (features derives from the GLCM) to give a better and more\nefficient recognition accuracy of skin textures. We used feed forward neural\nnetworks to classify input textures images to be skin or non skin textures. The\nsystem gave very encouraging results during the neural network generalization\nface."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.6500v1", 
    "title": "Stitched Panoramas from Toy Airborne Video Cameras", 
    "arxiv-id": "1311.6500v1", 
    "author": "Camille Goudeseune", 
    "publish": "2013-11-11T20:32:50Z", 
    "summary": "Effective panoramic photographs are taken from vantage points that are high.\nHigh vantage points have recently become easier to reach as the cost of\nquadrotor helicopters has dropped to nearly disposable levels. Although cameras\ncarried by such aircraft weigh only a few grams, their low-quality video can be\nconverted into panoramas of high quality and high resolution. Also, the small\nsize of these aircraft vastly reduces the risks inherent to flight."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.6740v1", 
    "title": "Hilditchs Algorithm Based Tamil Character Recognition", 
    "arxiv-id": "1311.6740v1", 
    "author": "V. Karthikeyan", 
    "publish": "2013-11-19T08:38:50Z", 
    "summary": "Character identification plays a vital role in the contemporary world of\nImage processing. It can solve many composite problems and makes humans work\neasier. An instance is Handwritten Character detection. Handwritten recognition\nis not a novel expertise, but it has not gained community notice until Now. The\neventual aim of designing Handwritten Character recognition structure with an\naccurateness rate of 100% is pretty illusionary. Tamil Handwritten Character\nrecognition system uses the Neural Networks to distinguish them. Neural Network\nand structural characteristics are used to instruct and recognize written\ncharacters. After training and testing the exactness rate reached 99%. This\ncorrectness rate is extremely high. In this paper we are exploring image\nprocessing through the Hilditch algorithm foundation and structural\ncharacteristics of a character in the image. And we recognized some character\nof the Tamil language, and we are trying to identify all the character of Tamil\nIn our future works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4502", 
    "link": "http://arxiv.org/pdf/1311.6758v1", 
    "title": "Detection of Partially Visible Objects", 
    "arxiv-id": "1311.6758v1", 
    "author": "Jiri Matas", 
    "publish": "2013-11-24T16:59:19Z", 
    "summary": "An \"elephant in the room\" for most current object detection and localization\nmethods is the lack of explicit modelling of partial visibility due to\nocclusion by other objects or truncation by the image boundary. Based on a\nsliding window approach, we propose a detection method which explicitly models\npartial visibility by treating it as a latent variable. A novel non-maximum\nsuppression scheme is proposed which takes into account the inferred partial\nvisibility of objects while providing a globally optimal solution. The method\ngives more detailed scene interpretations than conventional detectors in that\nwe are able to identify the visible parts of an object. We report improved\naverage precision on the PASCAL VOC 2010 dataset compared to a baseline\ndetector."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2014.2318713", 
    "link": "http://arxiv.org/pdf/1311.6887v2", 
    "title": "Modeling Radiometric Uncertainty for Vision with Tone-mapped Color   Images", 
    "arxiv-id": "1311.6887v2", 
    "author": "Kate Saenko", 
    "publish": "2013-11-27T07:39:27Z", 
    "summary": "To produce images that are suitable for display, tone-mapping is widely used\nin digital cameras to map linear color measurements into narrow gamuts with\nlimited dynamic range. This introduces non-linear distortion that must be\nundone, through a radiometric calibration process, before computer vision\nsystems can analyze such photographs radiometrically. This paper considers the\ninherent uncertainty of undoing the effects of tone-mapping. We observe that\nthis uncertainty varies substantially across color space, making some pixels\nmore reliable than others. We introduce a model for this uncertainty and a\nmethod for fitting it to a given camera or imaging pipeline. Once fit, the\nmodel provides for each pixel in a tone-mapped digital photograph a probability\ndistribution over linear scene colors that could have induced it. We\ndemonstrate how these distributions can be useful for visual inference by\nincorporating them into estimation algorithms for a representative set of\nvision tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2014.2318713", 
    "link": "http://arxiv.org/pdf/1311.6932v1", 
    "title": "A novel framework for image forgery localization", 
    "arxiv-id": "1311.6932v1", 
    "author": "Luisa Verdoliva", 
    "publish": "2013-11-27T11:06:05Z", 
    "summary": "Image forgery localization is a very active and open research field for the\ndifficulty to handle the large variety of manipulations a malicious user can\nperform by means of more and more sophisticated image editing tools. Here, we\npropose a localization framework based on the fusion of three very different\ntools, based, respectively, on sensor noise, patch-matching, and machine\nlearning. The binary masks provided by these tools are finally fused based on\nsome suitable reliability indexes. According to preliminary experiments on the\ntraining set, the proposed framework provides often a very good localization\naccuracy and sometimes valuable clues for visual scrutiny."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2014.2318713", 
    "link": "http://arxiv.org/pdf/1311.6934v1", 
    "title": "Image forgery detection based on the fusion of machine learning and   block-matching methods", 
    "arxiv-id": "1311.6934v1", 
    "author": "Luisa Verdoliva", 
    "publish": "2013-11-27T11:17:55Z", 
    "summary": "Dense local descriptors and machine learning have been used with success in\nseveral applications, like classification of textures, steganalysis, and\nforgery detection. We develop a new image forgery detector building upon some\ndescriptors recently proposed in the steganalysis field suitably merging some\nof such descriptors, and optimizing a SVM classifier on the available training\nset. Despite the very good performance, very small forgeries are hardly ever\ndetected because they contribute very little to the descriptors. Therefore we\nalso develop a simple, but extremely specific, copy-move detector based on\nregion matching and fuse decisions so as to reduce the missing detection rate.\nOverall results appear to be extremely encouraging."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DICTA.2011.15", 
    "link": "http://arxiv.org/pdf/1311.7186v1", 
    "title": "A Novel Illumination-Invariant Loss for Monocular 3D Pose Estimation", 
    "arxiv-id": "1311.7186v1", 
    "author": "Nathan Brewer", 
    "publish": "2013-11-28T01:54:50Z", 
    "summary": "The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision. Our proposed method of\nregistering a 3D model of a known object on a given 2D photo of the object has\nnumerous advantages over existing methods. It does not require prior training,\nknowledge of the camera parameters, explicit point correspondences or matching\nfeatures between the image and model. Unlike techniques that estimate a partial\n3D pose (as in an overhead view of traffic or machine parts on a conveyor\nbelt), our method estimates the complete 3D pose of the object. It works on a\nsingle static image from a given view under varying and unknown lighting\nconditions. For this purpose we derive a novel illumination-invariant distance\nmeasure between the 2D photo and projected 3D model, which is then minimised to\nfind the best pose parameters. Results for vehicle pose detection in real\nphotographs are presented."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DICTA.2011.15", 
    "link": "http://arxiv.org/pdf/1311.7327v1", 
    "title": "Unobtrusive Low Cost Pupil Size Measurements using Web cameras", 
    "arxiv-id": "1311.7327v1", 
    "author": "Costantine D. Spyropoulos", 
    "publish": "2013-11-28T14:25:43Z", 
    "summary": "Unobtrusive every day health monitoring can be of important use for the\nelderly population. In particular, pupil size may be a valuable source of\ninformation, since, apart from pathological cases, it can reveal the emotional\nstate, the fatigue and the ageing. To allow for unobtrusive monitoring to gain\nacceptance, one should seek for efficient methods of monitoring using com- mon\nlow-cost hardware. This paper describes a method for monitoring pupil sizes\nusing a common web camera in real time. Our method works by first detecting the\nface and the eyes area. Subsequently, optimal iris and sclera location and\nradius, modelled as ellipses, are found using efficient filtering. Finally, the\npupil center and radius is estimated by optimal filtering within the area of\nthe iris. Experimental result show both the efficiency and the effectiveness of\nour approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DICTA.2011.15", 
    "link": "http://arxiv.org/pdf/1402.0595v1", 
    "title": "Scene Labeling with Contextual Hierarchical Models", 
    "arxiv-id": "1402.0595v1", 
    "author": "Tolga Tasdizen", 
    "publish": "2014-02-04T02:10:01Z", 
    "summary": "Scene labeling is the problem of assigning an object label to each pixel. It\nunifies the image segmentation and object recognition problems. The importance\nof using contextual information in scene labeling frameworks has been widely\nrealized in the field. We propose a contextual framework, called contextual\nhierarchical model (CHM), which learns contextual information in a hierarchical\nframework for scene labeling. At each level of the hierarchy, a classifier is\ntrained based on downsampled input images and outputs of previous levels. Our\nmodel then incorporates the resulting multi-resolution contextual information\ninto a classifier to segment the input image at original resolution. This\ntraining strategy allows for optimization of a joint posterior probability at\nmultiple resolutions through the hierarchy. Contextual hierarchical model is\npurely based on the input image patches and does not make use of any fragments\nor shape examples. Hence, it is applicable to a variety of problems such as\nobject segmentation and edge detection. We demonstrate that CHM outperforms\nstate-of-the-art on Stanford background and Weizmann horse datasets. It also\noutperforms state-of-the-art edge detection methods on NYU depth dataset and\nachieves state-of-the-art on Berkeley segmentation dataset (BSDS 500)."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DICTA.2011.15", 
    "link": "http://arxiv.org/pdf/1402.0785v1", 
    "title": "Signal to Noise Ratio in Lensless Compressive Imaging", 
    "arxiv-id": "1402.0785v1", 
    "author": "Paul Wilford", 
    "publish": "2014-02-04T16:12:53Z", 
    "summary": "We analyze the signal to noise ratio (SNR) in a lensless compressive imaging\n(LCI) architecture. The architecture consists of a sensor of a single detecting\nelement and an aperture assembly of an array of programmable elements. LCI can\nbe used in conjunction with compressive sensing to capture images in a\ncompressed form of compressive measurements. In this paper, we perform SNR\nanalysis of the LCI and compare it with imaging with a pinhole or a lens. We\nwill show that the SNR in the LCI is independent of the image resolution, while\nthe SNR in either pinhole aperture imaging or lens aperture imaging decreases\nas the image resolution increases. Consequently, the SNR in the LCI is much\nhigher if the image resolution is large enough."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2346029", 
    "link": "http://arxiv.org/pdf/1402.0978v1", 
    "title": "Patchwise Joint Sparse Tracking with Occlusion Detection", 
    "arxiv-id": "1402.0978v1", 
    "author": "Ahmad Khajenezhad", 
    "publish": "2014-02-05T09:08:11Z", 
    "summary": "This paper presents a robust tracking approach to handle challenges such as\nocclusion and appearance change. Here, the target is partitioned into a number\nof patches. Then, the appearance of each patch is modeled using a dictionary\ncomposed of corresponding target patches in previous frames. In each frame, the\ntarget is found among a set of candidates generated by a particle filter, via a\nlikelihood measure that is shown to be proportional to the sum of\npatch-reconstruction errors of each candidate. Since the target's appearance\noften changes slowly in a video sequence, it is assumed that the target in the\ncurrent frame and the best candidates of a small number of previous frames,\nbelong to a common subspace. This is imposed using joint sparse representation\nto enforce the target and previous best candidates to have a common sparsity\npattern. Moreover, an occlusion detection scheme is proposed that uses\npatch-reconstruction errors and a prior probability of occlusion, extracted\nfrom an adaptive Markov chain, to calculate the probability of occlusion per\npatch. In each frame, occluded patches are excluded when updating the\ndictionary. Extensive experimental results on several challenging sequences\nshows that the proposed method outperforms state-of-the-art trackers."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2346029", 
    "link": "http://arxiv.org/pdf/1402.1151v1", 
    "title": "Image Acquisition in an Underwater Vision System with NIR and VIS   Illumination", 
    "arxiv-id": "1402.1151v1", 
    "author": "Andrzej Kasi\u0144ski", 
    "publish": "2014-02-05T20:18:26Z", 
    "summary": "The paper describes the image acquisition system able to capture images in\ntwo separated bands of light, used to underwater autonomous navigation. The\nchannels are: the visible light spectrum and near infrared spectrum. The\ncharacteristics of natural, underwater environment were also described together\nwith the process of the underwater image creation. The results of an experiment\nwith comparison of selected images acquired in these channels are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22312803/IJCTT-V7P144", 
    "link": "http://arxiv.org/pdf/1402.1331v1", 
    "title": "An Estimation Method of Measuring Image Quality for Compressed Images of   Human Face", 
    "arxiv-id": "1402.1331v1", 
    "author": "Tanusree Chatterjee", 
    "publish": "2014-02-06T11:58:42Z", 
    "summary": "Nowadays digital image compression and decompression techniques are very much\nimportant. So our aim is to calculate the quality of face and other regions of\nthe compressed image with respect to the original image. Image segmentation is\ntypically used to locate objects and boundaries (lines, curves etc.)in images.\nAfter segmentation the image is changed into something which is more meaningful\nto analyze. Using Universal Image Quality Index(Q),Structural Similarity\nIndex(SSIM) and Gradient-based Structural Similarity Index(G-SSIM) it can be\nshown that face region is less compressed than any other region of the image."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1348v1", 
    "title": "A Cellular Automata based Optimal Edge Detection Technique using   Twenty-Five Neighborhood Model", 
    "arxiv-id": "1402.1348v1", 
    "author": "Jahangir Mohammed", 
    "publish": "2014-02-06T13:32:39Z", 
    "summary": "Cellular Automata (CA) are common and most simple models of parallel\ncomputations. Edge detection is one of the crucial task in image processing,\nespecially in processing biological and medical images. CA can be successfully\napplied in image processing. This paper presents a new method for edge\ndetection of binary images based on two dimensional twenty five neighborhood\ncellular automata. The method considers only linear rules of CA for extraction\nof edges under null boundary condition. The performance of this approach is\ncompared with some existing edge detection techniques. This comparison shows\nthat the proposed method to be very promising for edge detection of binary\nimages. All the algorithms and results used in this paper are prepared in\nMATLAB."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1359v1", 
    "title": "Real-time Pedestrian Surveillance with Top View Cumulative Grids", 
    "arxiv-id": "1402.1359v1", 
    "author": "Jeyarajan Thiyagalingam", 
    "publish": "2014-02-06T14:09:25Z", 
    "summary": "This manuscript presents an efficient approach to map pedestrian surveillance\nfootage to an aerial view for global assessment of features. The analysis of\nthe footages relies on low level computer vision and enable real-time\nsurveillance. While we neglect object tracking, we introduce cumulative grids\non top view scene flow visualization to highlight situations of interest in the\nfootage. Our approach is tested on multiview footage both from RGB cameras and,\nfor the first time in the field, on RGB-D-sensors."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1371v1", 
    "title": "Quantile Representation for Indirect Immunofluorescence Image   Classification", 
    "arxiv-id": "1402.1371v1", 
    "author": "Marco Loog", 
    "publish": "2014-02-06T14:56:55Z", 
    "summary": "In the diagnosis of autoimmune diseases, an important task is to classify\nimages of slides containing several HEp-2 cells. All cells from one slide share\nthe same label, and by classifying cells from one slide independently, some\ninformation on the global image quality and intensity is lost. Considering one\nwhole slide as a collection (a bag) of feature vectors, however, poses the\nproblem of how to handle this bag. A simple, and surprisingly effective,\napproach is to summarize the bag of feature vectors by a few quantile values\nper feature. This characterizes the full distribution of all instances, thereby\nassuming that all instances in a bag are informative. This representation is\nparticularly useful when each bag contains many feature vectors, which is the\ncase in the classification of the immunofluorescence images. Experiments on the\nclassification of indirect immunofluorescence images show the usefulness of\nthis approach."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1503v1", 
    "title": "Tracking via Motion Estimation with Physically Motivated Inter-Region   Constraints", 
    "arxiv-id": "1402.1503v1", 
    "author": "Anthony Yezzi", 
    "publish": "2014-02-06T21:27:25Z", 
    "summary": "In this paper, we propose a method for tracking structures (e.g., ventricles\nand myocardium) in cardiac images (e.g., magnetic resonance) by propagating\nforward in time a previous estimate of the structures via a new deformation\nestimation scheme that is motivated by physical constraints of fluid motion.\nThe method employs within structure motion estimation (so that differing\nmotions among different structures are not mixed) while simultaneously\nsatisfying the physical constraint in fluid motion that at the interface\nbetween a fluid and a medium, the normal component of the fluid's motion must\nmatch the normal component of the motion of the medium. We show how to estimate\nthe motion according to the previous considerations in a variational framework,\nand in particular, show that these conditions lead to PDEs with boundary\nconditions at the interface that resemble Robin boundary conditions and induce\ncoupling between structures. We illustrate the use of this motion estimation\nscheme in propagating a segmentation across frames and show that it leads to\nmore accurate segmentation than traditional motion estimation that does not\nmake use of physical constraints. Further, the method is naturally suited to\ninteractive segmentation methods, which are prominently used in practice in\ncommercial applications for cardiac analysis, where typically a segmentation\nfrom the previous frame is used to predict a segmentation in the next frame. We\nshow that our propagation scheme reduces the amount of user interaction by\npredicting more accurate segmentations than commonly used and recent\ninteractive commercial techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1879v1", 
    "title": "Sparse Illumination Learning and Transfer for Single-Sample Face   Recognition with Image Corruption and Misalignment", 
    "arxiv-id": "1402.1879v1", 
    "author": "Yi Ma", 
    "publish": "2014-02-08T18:46:28Z", 
    "summary": "Single-sample face recognition is one of the most challenging problems in\nface recognition. We propose a novel algorithm to address this problem based on\na sparse representation based classification (SRC) framework. The new algorithm\nis robust to image misalignment and pixel corruption, and is able to reduce\nrequired gallery images to one sample per class. To compensate for the missing\nillumination information traditionally provided by multiple gallery images, a\nsparse illumination learning and transfer (SILT) technique is introduced. The\nillumination in SILT is learned by fitting illumination examples of auxiliary\nface images from one or more additional subjects with a sparsely-used\nillumination dictionary. By enforcing a sparse representation of the query\nimage in the illumination dictionary, the SILT can effectively recover and\ntransfer the illumination and pose information from the alignment stage to the\nrecognition stage. Our extensive experiments have demonstrated that the new\nalgorithms significantly outperform the state of the art in the single-sample\nregime and with less restrictions. In particular, the single-sample face\nalignment accuracy is comparable to that of the well-known Deformable SRC\nalgorithm using multiple gallery images per class. Furthermore, the face\nrecognition accuracy exceeds those of the SRC and Extended SRC algorithms using\nhand labeled alignment initialization."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.1971v2", 
    "title": "Direct Processing of Run Length Compressed Document Image for   Segmentation and Characterization of a Specified Block", 
    "arxiv-id": "1402.1971v2", 
    "author": "B. B. Chaudhuri", 
    "publish": "2014-02-09T18:01:12Z", 
    "summary": "Extracting a block of interest referred to as segmenting a specified block in\nan image and studying its characteristics is of general research interest, and\ncould be a challenging if such a segmentation task has to be carried out\ndirectly in a compressed image. This is the objective of the present research\nwork. The proposal is to evolve a method which would segment and extract a\nspecified block, and carry out its characterization without decompressing a\ncompressed image, for two major reasons that most of the image archives contain\nimages in compressed format and decompressing an image indents additional\ncomputing time and space. Specifically in this research work, the proposal is\nto work on run-length compressed document images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2013v1", 
    "title": "Foreground segmentation based on multi-resolution and matting", 
    "arxiv-id": "1402.2013v1", 
    "author": "Yisong Chen", 
    "publish": "2014-02-10T01:22:35Z", 
    "summary": "We propose a foreground segmentation algorithm that does foreground\nextraction under different scales and refines the result by matting. First, the\ninput image is filtered and resampled to 5 different resolutions. Then each of\nthem is segmented by adaptive figure-ground classification and the best\nsegmentation is automatically selected by an evaluation score that maximizes\nthe difference between foreground and background. This segmentation is\nupsampled to the original size, and a corresponding trimap is built.\nClosed-form matting is employed to label the boundary region, and the result is\nrefined by a final figure-ground classification. Experiments show the success\nof our method in treating challenging images with cluttered background and\nadapting to loose initial bounding-box."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2016v2", 
    "title": "Leveraging Long-Term Predictions and Online-Learning in Agent-based   Multiple Person Tracking", 
    "arxiv-id": "1402.2016v2", 
    "author": "Dinesh Manocha", 
    "publish": "2014-02-10T02:07:07Z", 
    "summary": "We present a multiple-person tracking algorithm, based on combining particle\nfilters and RVO, an agent-based crowd model that infers collision-free\nvelocities so as to predict pedestrian's motion. In addition to position and\nvelocity, our tracking algorithm can estimate the internal goals (desired\ndestination or desired velocity) of the tracked pedestrian in an online manner,\nthus removing the need to specify this information beforehand. Furthermore, we\nleverage the longer-term predictions of RVO by deriving a higher-order particle\nfilter, which aggregates multiple predictions from different prior time steps.\nThis yields a tracker that can recover from short-term occlusions and spurious\nnoise in the appearance model. Experimental results show that our tracking\nalgorithm is suitable for predicting pedestrians' behaviors online without\nneeding scene priors or hand-annotated goal information, and improves tracking\nin real-world crowded scenes under low frame rates."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2020v1", 
    "title": "Binary Stereo Matching", 
    "arxiv-id": "1402.2020v1", 
    "author": "Shiqiang Yang", 
    "publish": "2014-02-10T02:33:39Z", 
    "summary": "In this paper, we propose a novel binary-based cost computation and\naggregation approach for stereo matching problem. The cost volume is\nconstructed through bitwise operations on a series of binary strings. Then this\napproach is combined with traditional winner-take-all strategy, resulting in a\nnew local stereo matching algorithm called binary stereo matching (BSM). Since\ncore algorithm of BSM is based on binary and integer computations, it has a\nhigher computational efficiency than previous methods. Experimental results on\nMiddlebury benchmark show that BSM has comparable performance with\nstate-of-the-art local stereo methods in terms of both quality and speed.\nFurthermore, experiments on images with radiometric differences demonstrate\nthat BSM is more robust than previous methods under these changes, which is\ncommon under real illumination."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2188v1", 
    "title": "Handwritten Character Recognition In Malayalam Scripts- A Review", 
    "arxiv-id": "1402.2188v1", 
    "author": "P. M Dhanya", 
    "publish": "2014-02-10T15:41:48Z", 
    "summary": "Handwritten character recognition is one of the most challenging and ongoing\nareas of research in the field of pattern recognition. HCR research is matured\nfor foreign languages like Chinese and Japanese but the problem is much more\ncomplex for Indian languages. The problem becomes even more complicated for\nSouth Indian languages due to its large character set and the presence of\nvowels modifiers and compound characters. This paper provides an overview of\nimportant contributions and advances in offline as well as online handwritten\ncharacter recognition of Malayalam scripts."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2426v1", 
    "title": "Imaging with Rays: Microscopy, Medical Imaging, and Computer Vision", 
    "arxiv-id": "1402.2426v1", 
    "author": "Yeshaiahu Fainman", 
    "publish": "2014-02-11T10:26:31Z", 
    "summary": "In this paper we broadly consider techniques which utilize projections on\nrays for data collection, with particular emphasis on optical techniques. We\nformulate a variety of imaging techniques as either special cases or extensions\nof tomographic reconstruction. We then consider how the techniques must be\nextended to describe objects containing occlusion, as with a self-occluding\nopaque object. We formulate the reconstruction problem as a regularized\nnonlinear optimization problem to simultaneously solve for object brightness\nand attenuation, where the attenuation can become infinite. We demonstrate\nvarious simulated examples for imaging opaque objects, including sparse point\nsources, a conventional multiview reconstruction technique, and a\nsuper-resolving technique which exploits occlusion to resolve an image."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2606v1", 
    "title": "A Fast Two Pass Multi-Value Segmentation Algorithm based on Connected   Component Analysis", 
    "arxiv-id": "1402.2606v1", 
    "author": "Dibyendu Mukherjee", 
    "publish": "2014-02-11T19:27:05Z", 
    "summary": "Connected component analysis (CCA) has been heavily used to label binary\nimages and classify segments. However, it has not been well-exploited to\nsegment multi-valued natural images. This work proposes a novel multi-value\nsegmentation algorithm that utilizes CCA to segment color images. A user\ndefined distance measure is incorporated in the proposed modified CCA to\nidentify and segment similar image regions. The raw output of the algorithm\nconsists of distinctly labelled segmented regions. The proposed algorithm has a\nunique design architecture that provides several benefits: 1) it can be used to\nsegment any multi-channel multi-valued image; 2) the distance\nmeasure/segmentation criteria can be application-specific and 3) an absolute\nlinear-time implementation allows easy extension for real-time video\nsegmentation. Experimental demonstrations of the aforesaid benefits are\npresented along with the comparison results on multiple datasets with current\nbenchmark algorithms. A number of possible application areas are also\nidentified and results on real-time video segmentation has been presented to\nshow the promise of the proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2673v1", 
    "title": "Real-Time Hand Shape Classification", 
    "arxiv-id": "1402.2673v1", 
    "author": "Michal Kawulok", 
    "publish": "2014-02-11T21:32:48Z", 
    "summary": "The problem of hand shape classification is challenging since a hand is\ncharacterized by a large number of degrees of freedom. Numerous shape\ndescriptors have been proposed and applied over the years to estimate and\nclassify hand poses in reasonable time. In this paper we discuss our parallel\nframework for real-time hand shape classification applicable in real-time\napplications. We show how the number of gallery images influences the\nclassification accuracy and execution time of the parallel algorithm. We\npresent the speedup and efficiency analyses that prove the efficacy of the\nparallel implementation. Noteworthy, different methods can be used at each step\nof our parallel framework. Here, we combine the shape contexts with the\nappearance-based techniques to enhance the robustness of the algorithm and to\nincrease the classification score. An extensive experimental study proves the\nsuperiority of the proposed approach over existing state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2681v2", 
    "title": "Packing and Padding: Coupled Multi-index for Accurate Image Retrieval", 
    "arxiv-id": "1402.2681v2", 
    "author": "Qi Tian", 
    "publish": "2014-02-11T22:00:31Z", 
    "summary": "In Bag-of-Words (BoW) based image retrieval, the SIFT visual word has a low\ndiscriminative power, so false positive matches occur prevalently. Apart from\nthe information loss during quantization, another cause is that the SIFT\nfeature only describes the local gradient distribution. To address this\nproblem, this paper proposes a coupled Multi-Index (c-MI) framework to perform\nfeature fusion at indexing level. Basically, complementary features are coupled\ninto a multi-dimensional inverted index. Each dimension of c-MI corresponds to\none kind of feature, and the retrieval process votes for images similar in both\nSIFT and other feature spaces. Specifically, we exploit the fusion of local\ncolor feature into c-MI. While the precision of visual match is greatly\nenhanced, we adopt Multiple Assignment to improve recall. The joint cooperation\nof SIFT and color features significantly reduces the impact of false positive\nmatches.\n  Extensive experiments on several benchmark datasets demonstrate that c-MI\nimproves the retrieval accuracy significantly, while consuming only half of the\nquery time compared to the baseline. Importantly, we show that c-MI is well\ncomplementary to many prior techniques. Assembling these methods, we have\nobtained an mAP of 85.8% and N-S score of 3.85 on Holidays and Ukbench\ndatasets, respectively, which compare favorably with the state-of-the-arts."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2720v1", 
    "title": "Noise Analysis for Lensless Compressive Imaging", 
    "arxiv-id": "1402.2720v1", 
    "author": "Paul Wilford", 
    "publish": "2014-02-12T03:12:40Z", 
    "summary": "We analyze the signal to noise ratio (SNR) in a recently proposed lensless\ncompressive imaging architecture. The architecture consists of a sensor of a\nsingle detector element and an aperture assembly of an array of aperture\nelements, each of which has a programmable transmittance. This lensless\ncompressive imaging architecture can be used in conjunction with compressive\nsensing to capture images in a compressed form of compressive measurements. In\nthis paper, we perform noise analysis of this lensless compressive imaging\narchitecture and compare it with pinhole aperture imaging and lens aperture\nimaging. We will show that the SNR in the lensless compressive imaging is\nindependent of the image resolution, while that in either pinhole aperture\nimaging or lens aperture imaging decreases as the image resolution increases.\nConsequently, the SNR in the lensless compressive imaging can be much higher if\nthe image resolution is large enough."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2826v1", 
    "title": "Realtime Multilevel Crowd Tracking using Reciprocal Velocity Obstacles", 
    "arxiv-id": "1402.2826v1", 
    "author": "Dinesh Manocha", 
    "publish": "2014-02-11T15:49:53Z", 
    "summary": "We present a novel, realtime algorithm to compute the trajectory of each\npedestrian in moderately dense crowd scenes. Our formulation is based on an\nadaptive particle filtering scheme that uses a multi-agent motion model based\non velocity-obstacles, and takes into account local interactions as well as\nphysical and personal constraints of each pedestrian. Our method dynamically\nchanges the number of particles allocated to each pedestrian based on different\nconfidence metrics. Additionally, we use a new high-definition crowd video\ndataset, which is used to evaluate the performance of different pedestrian\ntracking algorithms. This dataset consists of videos of indoor and outdoor\nscenes, recorded at different locations with 30-80 pedestrians. We highlight\nthe performance benefits of our algorithm over prior techniques using this\ndataset. In practice, our algorithm can compute trajectories of tens of\npedestrians on a multi-core desktop CPU at interactive rates (27-30 frames per\nsecond). To the best of our knowledge, our approach is 4-5 times faster than\nprior methods, which provide similar accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2941v1", 
    "title": "Multispectral Palmprint Encoding and Recognition", 
    "arxiv-id": "1402.2941v1", 
    "author": "Ajmal Mian", 
    "publish": "2014-02-06T06:35:51Z", 
    "summary": "Palmprints are emerging as a new entity in multi-modal biometrics for human\nidentification and verification. Multispectral palmprint images captured in the\nvisible and infrared spectrum not only contain the wrinkles and ridge structure\nof a palm, but also the underlying pattern of veins; making them a highly\ndiscriminating biometric identifier. In this paper, we propose a feature\nencoding scheme for robust and highly accurate representation and matching of\nmultispectral palmprints. To facilitate compact storage of the feature, we\ndesign a binary hash table structure that allows for efficient matching in\nlarge databases. Comprehensive experiments for both identification and\nverification scenarios are performed on two public datasets -- one captured\nwith a contact-based sensor (PolyU dataset), and the other with a contact-free\nsensor (CASIA dataset). Recognition results in various experimental setups show\nthat the proposed method consistently outperforms existing state-of-the-art\nmethods. Error rates achieved by our method (0.003% on PolyU and 0.2% on CASIA)\nare the lowest reported in literature on both dataset and clearly indicate the\nviability of palmprint as a reliable and promising biometric. All source codes\nare publicly available."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.3557v1", 
    "title": "Improving Streaming Video Segmentation with Early and Mid-Level Visual   Processing", 
    "arxiv-id": "1402.3557v1", 
    "author": "Truong Nguyen", 
    "publish": "2014-02-14T19:37:35Z", 
    "summary": "Despite recent advances in video segmentation, many opportunities remain to\nimprove it using a variety of low and mid-level visual cues. We propose\nimprovements to the leading streaming graph-based hierarchical video\nsegmentation (streamGBH) method based on early and mid level visual processing.\nThe extensive experimental analysis of our approach validates the improvement\nof hierarchical supervoxel representation by incorporating motion and color\nwith effective filtering. We also pose and illuminate some open questions\ntowards intermediate level video analysis as further extension to streamGBH. We\nexploit the supervoxels as an initialization towards estimation of dominant\naffine motion regions, followed by merging of such motion regions in order to\nhierarchically segment a video in a novel motion-segmentation framework which\naims at subsequent applications such as foreground recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.3869v2", 
    "title": "FTVd is beyond Fast Total Variation regularized Deconvolution", 
    "arxiv-id": "1402.3869v2", 
    "author": "Yilun Wang", 
    "publish": "2014-02-17T02:13:30Z", 
    "summary": "In this paper, we revisit the \"FTVd\" algorithm for Fast Total Variation\nRegularized Deconvolution, which has been widely used in the past few years.\nBoth its original version implemented in the MATLAB software FTVd 3.0 and its\nrelated variant implemented in the latter version FTVd 4.0 are considered\n\\cite{Wang08FTVdsoftware}. We propose that the intermediate results during the\niterations are the solutions of a series of combined Tikhonov and total\nvariation regularized image deconvolution models and therefore some of them\noften have even better image quality than the final solution, which is\ncorresponding to the pure total variation regularized model."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.3926v1", 
    "title": "Sparse Coding Approach for Multi-Frame Image Super Resolution", 
    "arxiv-id": "1402.3926v1", 
    "author": "Noboru Murata", 
    "publish": "2014-02-17T08:23:35Z", 
    "summary": "An image super-resolution method from multiple observation of low-resolution\nimages is proposed. The method is based on sub-pixel accuracy block matching\nfor estimating relative displacements of observed images, and sparse signal\nrepresentation for estimating the corresponding high-resolution image. Relative\ndisplacements of small patches of observed low-resolution images are accurately\nestimated by a computationally efficient block matching method. Since the\nestimated displacements are also regarded as a warping component of image\ndegradation process, the matching results are directly utilized to generate\nlow-resolution dictionary for sparse image representation. The matching scores\nof the block matching are used to select a subset of low-resolution patches for\nreconstructing a high-resolution patch, that is, an adaptive selection of\ninformative low-resolution images is realized. When there is only one\nlow-resolution image, the proposed method works as a single-frame\nsuper-resolution method. The proposed method is shown to perform comparable or\nsuperior to conventional single- and multi-frame super-resolution methods\nthrough experiments using various real-world datasets."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4067v1", 
    "title": "Statistical Noise Analysis in SENSE Parallel MRI", 
    "arxiv-id": "1402.4067v1", 
    "author": "Antonio Trsitan-Vega", 
    "publish": "2014-02-17T17:16:21Z", 
    "summary": "A complete first and second order statistical characterization of noise in\nSENSE reconstructed data is proposed. SENSE acquisitions have usually been\nmodeled as Rician distributed, since the data reconstruction takes place into\nthe spatial domain, where Gaussian noise is assumed. However, this model just\nholds for the first order statistics and obviates other effects induced by\ncoils correlations and the reconstruction interpolation. Those effects are\nproperly taken into account in this study, in order to fully justify a final\nSENSE noise model. As a result, some interesting features of the reconstructed\nimage arise: (1) There is a strong correlation between adjacent lines. (2) The\nresulting distribution is non-stationary and therefore the variance of noise\nwill vary from point to point across the image. Closed equations for the\ncalculation of the variance of noise and the correlation coefficient between\nlines are proposed. The proposed model is totally compatible with g-factor\nformulations."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4069v2", 
    "title": "Application of the Ring Theory in the Segmentation of Digital Images", 
    "arxiv-id": "1402.4069v2", 
    "author": "Roberto Rodr\u00edguez", 
    "publish": "2014-02-17T17:16:35Z", 
    "summary": "Ring theory is one of the branches of the abstract algebra that has been\nbroadly used in images. However, ring theory has not been very related with\nimage segmentation. In this paper, we propose a new index of similarity among\nimages using Zn rings and the entropy function. This new index was applied as a\nnew stopping criterion to the Mean Shift Iterative Algorithm with the goal to\nreach a better segmentation. An analysis on the performance of the algorithm\nwith this new stopping criterion is carried out. The obtained results proved\nthat the new index is a suitable tool to compare images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4388v1", 
    "title": "Automatic Detection of Font Size Straight from Run Length Compressed   Text Documents", 
    "arxiv-id": "1402.4388v1", 
    "author": "B. B. Chaudhuri", 
    "publish": "2014-02-18T16:30:59Z", 
    "summary": "Automatic detection of font size finds many applications in the area of\nintelligent OCRing and document image analysis, which has been traditionally\npracticed over uncompressed documents, although in real life the documents\nexist in compressed form for efficient storage and transmission. It would be\nnovel and intelligent if the task of font size detection could be carried out\ndirectly from the compressed data of these documents without decompressing,\nwhich would result in saving of considerable amount of processing time and\nspace. Therefore, in this paper we present a novel idea of learning and\ndetecting font size directly from run-length compressed text documents at line\nlevel using simple line height features, which paves the way for intelligent\nOCRing and document analysis directly from compressed documents. In the\nproposed model, the given mixed-case text documents of different font size are\nsegmented into compressed text lines and the features extracted such as line\nheight and ascender height are used to capture the pattern of font size in the\nform of a regression line, using which the automatic detection of font size is\ndone during the recognition stage. The method is experimented with a dataset of\n50 compressed documents consisting of 780 text lines of single font size and\n375 text lines of mixed font size resulting in an overall accuracy of 99.67%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4936v1", 
    "title": "Enhanced Secure Algorithm for Fingerprint Recognition", 
    "arxiv-id": "1402.4936v1", 
    "author": "Amira Mohammad Abdel-Mawgoud Saleh", 
    "publish": "2014-02-20T09:19:17Z", 
    "summary": "Fingerprint recognition requires a minimal effort from the user, does not\ncapture other information than strictly necessary for the recognition process,\nand provides relatively good performance. A critical step in fingerprint\nidentification system is thinning of the input fingerprint image. The\nperformance of a minutiae extraction algorithm relies heavily on the quality of\nthe thinning algorithm. So, a fast fingerprint thinning algorithm is proposed.\nThe algorithm works directly on the gray-scale image as binarization of\nfingerprint causes many spurious minutiae and also removes many important\nfeatures. The performance of the thinning algorithm is evaluated and\nexperimental results show that the proposed thinning algorithm is both fast and\naccurate. A new minutiae-based fingerprint matching technique is proposed. The\nmain idea is that each fingerprint is represented by a minutiae table of just\ntwo columns in the database. The number of different minutiae types\n(terminations and bifurcations) found in each track of a certain width around\nthe core point of the fingerprint is recorded in this table. Each row in the\ntable represents a certain track, in the first column, the number of\nterminations in each track is recorded, in the second column, the number of\nbifurcations in each track is recorded. The algorithm is rotation and\ntranslation invariant, and needs less storage size. Experimental results show\nthat recognition accuracy is 98%, with Equal Error Rate (EER) of 2%. Finally,\nthe integrity of the data transmission via communication channels must be\nsecure all the way from the scanner to the application. After applying Gaussian\nnoise addition, and JPEG compression with high and moderate quality factors on\nthe watermarked fingerprint images, recognition accuracy decreases slightly to\nreach 96%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4963v4", 
    "title": "Vesselness via Multiple Scale Orientation Scores", 
    "arxiv-id": "1402.4963v4", 
    "author": "Erik Bekkers", 
    "publish": "2014-02-20T11:06:35Z", 
    "summary": "The multi-scale Frangi vesselness filter is an established tool in (retinal)\nvascular imaging. However, it cannot cope with crossings or bifurcations, since\nit only looks for elongated structures. Therefore, we disentangle crossing\nstructures in the image via (multiple scale) invertible orientation scores. The\ndescribed vesselness filter via scale-orientation scores performs considerably\nbetter at enhancing vessels throughout crossings and bifurcations than the\nFrangi version. Both methods are evaluated on a public dataset. Performance is\nmeasured by comparing ground truth data to the segmentation results obtained by\nbasic thresholding and morphological component analysis of the filtered images."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.aeue.2014.10.022", 
    "link": "http://arxiv.org/pdf/1402.5564v3", 
    "title": "Structure Tensor Based Image Interpolation Method", 
    "arxiv-id": "1402.5564v3", 
    "author": "Zeyun Yu", 
    "publish": "2014-02-22T23:58:11Z", 
    "summary": "Feature preserving image interpolation is an active area in image processing\nfield. In this paper a new direct edge directed image super-resolution\nalgorithm based on structure tensors is proposed. Using an isotropic Gaussian\nfilter, the structure tensor at each pixel of the input image is computed and\nthe pixels are classified to three distinct classes; uniform region, corners\nand edges, according to the eigenvalues of the structure tensor. Due to\napplication of the isotropic Gaussian filter, the classification is robust to\nnoise presented in image. Based on the tangent eigenvector of the structure\ntensor, the edge direction is determined and used for interpolation along the\nedges. In comparison to some previous edge directed image interpolation\nmethods, the proposed method achieves higher quality in both subjective and\nobjective aspects. Also the proposed method outperforms previous methods in\ncase of noisy and JPEG compressed images. Furthermore, without the need for\noptimization in the process, the algorithm can achieve higher speed."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.aeue.2014.10.022", 
    "link": "http://arxiv.org/pdf/1402.5619v1", 
    "title": "A Novel Histogram Based Robust Image Registration Technique", 
    "arxiv-id": "1402.5619v1", 
    "author": "V. Karthikeyan", 
    "publish": "2014-02-23T15:24:27Z", 
    "summary": "In this paper, a method for Automatic Image Registration (AIR) through\nhistogram is proposed. Automatic image registration is one of the crucial steps\nin the analysis of remotely sensed data. A new acquired image must be\ntransformed, using image registration techniques, to match the orientation and\nscale of previous related images. This new approach combines several\nsegmentations of the pair of images to be registered. A relaxation parameter on\nthe histogram modes delineation is introduced. It is followed by\ncharacterization of the extracted objects through the objects area, axis ratio,\nand perimeter and fractal dimension. The matched objects are used for rotation\nand translation estimation. It allows for the registration of pairs of images\nwith differences in rotation and translation. This method contributes to\nsubpixel accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.aeue.2014.10.022", 
    "link": "http://arxiv.org/pdf/1402.5623v1", 
    "title": "Localization of License Plate Using Morphological Operations", 
    "arxiv-id": "1402.5623v1", 
    "author": "V. J. Vijayalakshmi", 
    "publish": "2014-02-23T16:08:09Z", 
    "summary": "It is believed that there are currently millions of vehicles on the roads\nworldwide. The over speed of vehicles,theft of vehicles, disobeying traffic\nrules in public, an unauthorized person entering the restricted area are keep\non increasing. In order restrict against these criminal activities, we need an\nautomatic public security system. Each vehicle has their own Vehicle\nIdentification Number (VIN) as their primary identifier. The VIN is actually a\nLicense Number which states a legal license to participate in the public\ntraffic. The proposed paper is to identify the vehicle with the help of\nvehicles License Plate (LP).LPRS is one the most important part of the\nIntelligent Transportation System (ITS) to locate the LP. In this paper certain\nexisting algorithm drawbacks are overcome by the proposed morphological\noperations for LPRS. Morphological operation is chosen due to its higher\nefficiency, noise filter capacity, accuracy, exact localization of LP and\nspeed."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2014.7025077", 
    "link": "http://arxiv.org/pdf/1402.5697v1", 
    "title": "Exemplar-based Linear Discriminant Analysis for Robust Object Tracking", 
    "arxiv-id": "1402.5697v1", 
    "author": "Nong Sang", 
    "publish": "2014-02-24T01:10:09Z", 
    "summary": "Tracking-by-detection has become an attractive tracking technique, which\ntreats tracking as a category detection problem. However, the task in tracking\nis to search for a specific object, rather than an object category as in\ndetection. In this paper, we propose a novel tracking framework based on\nexemplar detector rather than category detector. The proposed tracker is an\nensemble of exemplar-based linear discriminant analysis (ELDA) detectors. Each\ndetector is quite specific and discriminative, because it is trained by a\nsingle object instance and massive negatives. To improve its adaptivity, we\nupdate both object and background models. Experimental results on several\nchallenging video sequences demonstrate the effectiveness and robustness of our\ntracking algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2014.7025077", 
    "link": "http://arxiv.org/pdf/1402.5792v3", 
    "title": "A Novel Scheme for Intelligent Recognition of Pornographic Images", 
    "arxiv-id": "1402.5792v3", 
    "author": "Amer Namazi", 
    "publish": "2014-02-24T11:15:04Z", 
    "summary": "Harmful contents are rising in internet day by day and this motivates the\nessence of more research in fast and reliable obscene and immoral material\nfiltering. Pornographic image recognition is an important component in each\nfiltering system. In this paper, a new approach for detecting pornographic\nimages is introduced. In this approach, two new features are suggested. These\ntwo features in combination with other simple traditional features provide\ndecent difference between porn and non-porn images. In addition, we applied\nfuzzy integral based information fusion to combine MLP (Multi-Layer Perceptron)\nand NF (Neuro-Fuzzy) outputs. To test the proposed method, performance of\nsystem was evaluated over 18354 download images from internet. The attained\nprecision was 93% in TP and 8% in FP on training dataset, and 87% and 5.5% on\ntest dataset. Achieved results verify the performance of proposed system versus\nother related works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4221", 
    "link": "http://arxiv.org/pdf/1402.5805v1", 
    "title": "Automatic Estimation of Live Coffee Leaf Infection based on Image   Processing Techniques", 
    "arxiv-id": "1402.5805v1", 
    "author": "Oubong Gwun", 
    "publish": "2014-02-24T12:06:40Z", 
    "summary": "Image segmentation is the most challenging issue in computer vision\napplications. And most difficulties for crops management in agriculture are the\nlack of appropriate methods for detecting the leaf damage for pests treatment.\nIn this paper we proposed an automatic method for leaf damage detection and\nseverity estimation of coffee leaf by avoiding defoliation. After enhancing the\ncontrast of the original image using LUT based gamma correction, the image is\nprocessed to remove the background, and the output leaf is clustered using\nFuzzy c-means segmentation in V channel of YUV color space to maximize all leaf\ndamage detection, and finally, the severity of leaf is estimated in terms of\nratio for leaf pixel distribution between the normal and the detected leaf\ndamage. The results in each proposed method was compared to the current\nresearches and the accuracy is obvious either in the background removal or\ndamage detection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4221", 
    "link": "http://arxiv.org/pdf/1402.5859v1", 
    "title": "A Novel Face Recognition Method using Nearest Line Projection", 
    "arxiv-id": "1402.5859v1", 
    "author": "Xun Qu", 
    "publish": "2014-02-24T15:36:32Z", 
    "summary": "Face recognition is a popular application of pat- tern recognition methods,\nand it faces challenging problems including illumination, expression, and pose.\nThe most popular way is to learn the subspaces of the face images so that it\ncould be project to another discriminant space where images of different\npersons can be separated. In this paper, a nearest line projection algorithm is\ndeveloped to represent the face images for face recognition. Instead of\nprojecting an image to its nearest image, we try to project it to its nearest\nline spanned by two different face images. The subspaces are learned so that\neach face image to its nearest line is minimized. We evaluated the proposed\nalgorithm on some benchmark face image database, and also compared it to some\nother image projection algorithms. The experiment results showed that the\nproposed algorithm outperforms other ones."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4221", 
    "link": "http://arxiv.org/pdf/1402.5923v1", 
    "title": "A Testbed for Cross-Dataset Analysis", 
    "arxiv-id": "1402.5923v1", 
    "author": "Barbara Caputo", 
    "publish": "2014-02-24T19:25:17Z", 
    "summary": "Since its beginning visual recognition research has tried to capture the huge\nvariability of the visual world in several image collections. The number of\navailable datasets is still progressively growing together with the amount of\nsamples per object category. However, this trend does not correspond directly\nto an increasing in the generalization capabilities of the developed\nrecognition systems. Each collection tends to have its specific characteristics\nand to cover just some aspects of the visual world: these biases often narrow\nthe effect of the methods defined and tested separately over each image set.\nOur work makes a first step towards the analysis of the dataset bias problem on\na large scale. We organize twelve existing databases in a unique corpus and we\npresent the visual community with a useful feature repository for future\nresearch."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6383v1", 
    "title": "Large-margin Learning of Compact Binary Image Encodings", 
    "arxiv-id": "1402.6383v1", 
    "author": "Anton van den Hengel", 
    "publish": "2014-02-26T00:22:50Z", 
    "summary": "The use of high-dimensional features has become a normal practice in many\ncomputer vision applications. The large dimension of these features is a\nlimiting factor upon the number of data points which may be effectively stored\nand processed, however. We address this problem by developing a novel approach\nto learning a compact binary encoding, which exploits both pair-wise proximity\nand class-label information on training data set. Exploiting this extra\ninformation allows the development of encodings which, although compact,\noutperform the original high-dimensional features in terms of final\nclassification or retrieval performance. The method is general, in that it is\napplicable to both non-parametric and parametric learning methods. This\ngenerality means that the embedded features are suitable for a wide variety of\ncomputer vision tasks, such as image classification and content-based image\nretrieval. Experimental results demonstrate that the new compact descriptor\nachieves an accuracy comparable to, and in some cases better than, the visual\ndescriptor in the original space despite being significantly more compact.\nMoreover, any convex loss function and convex regularization penalty (e.g., $\n\\ell_p $ norm with $ p \\ge 1 $) can be incorporated into the framework, which\nprovides future flexibility."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6387v1", 
    "title": "Active spline model: A shape based model-interactive segmentation", 
    "arxiv-id": "1402.6387v1", 
    "author": "U. Rajendra Acharya", 
    "publish": "2014-02-26T01:32:48Z", 
    "summary": "Rarely in literature a method of segmentation cares for the edit after the\nalgorithm delivers. They provide no solution when segmentation goes wrong. We\npropose to formulate point distribution model in terms of\ncentripetal-parameterized Catmull-Rom spline. Such fusion brings interactivity\nto model-based segmentation, so that edit is better handled. When the delivered\nsegment is unsatisfactory, user simply shifts points to vary the curve. We ran\nthe method on three disparate imaging modalities and achieved an average\noverlap of 0.879 for automated lung segmentation on chest radiographs. The edit\nafterward improved the average overlap to 0.945, with a minimum of 0.925. The\nsource code and the demo video are available at http://wp.me/p3vCKy-2S"
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6416v1", 
    "title": "Deconstruction of compound objects from image sets", 
    "arxiv-id": "1402.6416v1", 
    "author": "Lachlan Fleming", 
    "publish": "2014-02-26T05:37:41Z", 
    "summary": "We propose a method to recover the structure of a compound object from\nmultiple silhouettes. Structure is expressed as a collection of 3D primitives\nchosen from a pre-defined library, each with an associated pose. This has\nseveral advantages over a volume or mesh representation both for estimation and\nthe utility of the recovered model. The main challenge in recovering such a\nmodel is the combinatorial number of possible arrangements of parts. We address\nthis issue by exploiting the sparse nature of the problem, and show that our\nmethod scales to objects constructed from large libraries of parts."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6650v1", 
    "title": "A Novel Method for the Recognition of Isolated Handwritten Arabic   Characters", 
    "arxiv-id": "1402.6650v1", 
    "author": "Cheng Suen", 
    "publish": "2014-02-26T19:09:09Z", 
    "summary": "There are many difficulties facing a handwritten Arabic recognition system\nsuch as unlimited variation in human handwriting, similarities of distinct\ncharacter shapes, interconnections of neighbouring characters and their\nposition in the word. The typical Optical Character Recognition (OCR) systems\nare based mainly on three stages, preprocessing, features extraction and\nrecognition. This paper proposes new methods for handwritten Arabic character\nrecognition which is based on novel preprocessing operations including\ndifferent kinds of noise removal also different kind of features like\nstructural, Statistical and Morphological features from the main body of the\ncharacter and also from the secondary components. Evaluation of the accuracy of\nthe selected features is made. The system was trained and tested by back\npropagation neural network with CENPRMI dataset. The proposed algorithm\nobtained promising results as it is able to recognize 88% of our test set\naccurately. In Comparable with other related works we find that our result is\nthe highest among other published works."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6932v1", 
    "title": "Low-Cost Compressive Sensing for Color Video and Depth", 
    "arxiv-id": "1402.6932v1", 
    "author": "Lawrence Carin", 
    "publish": "2014-02-27T15:15:43Z", 
    "summary": "A simple and inexpensive (low-power and low-bandwidth) modification is made\nto a conventional off-the-shelf color video camera, from which we recover\n{multiple} color frames for each of the original measured frames, and each of\nthe recovered frames can be focused at a different depth. The recovery of\nmultiple frames for each measured frame is made possible via high-speed coding,\nmanifested via translation of a single coded aperture; the inexpensive\ntranslation is constituted by mounting the binary code on a piezoelectric\ndevice. To simultaneously recover depth information, a {liquid} lens is\nmodulated at high speed, via a variable voltage. Consequently, during the\naforementioned coding process, the liquid lens allows the camera to sweep the\nfocus through multiple depths. In addition to designing and implementing the\ncamera, fast recovery is achieved by an anytime algorithm exploiting the\ngroup-sparsity of wavelet/DCT coefficients."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1402.7162v1", 
    "title": "Visual Saliency Model using SIFT and Comparison of Learning Approaches", 
    "arxiv-id": "1402.7162v1", 
    "author": "Hamdi Yalin Yalic", 
    "publish": "2014-02-28T08:33:17Z", 
    "summary": "Humans' ability to detect and locate salient objects on images is remarkably\nfast and successful. Performing this process by using eye tracking equipment is\nexpensive and cannot be easily applied, and computer modeling of this human\nbehavior is still a problem to be solved. In our study, one of the largest\npublic eye-tracking databases which has fixation points of 15 observers on 1003\nimages is used. In addition to low, medium and high-level features which have\nbeen used in previous studies, SIFT features extracted from the images are used\nto improve the classification accuracy of the models. A second contribution of\nthis paper is the comparison and statistical analysis of different machine\nlearning methods that can be used to train our model. As a result, a best\nfeature set and learning model to predict where humans look at images, is\ndetermined."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1404.0106v1", 
    "title": "Traffic Monitoring Using M2M Communication", 
    "arxiv-id": "1404.0106v1", 
    "author": "Seong Ro Lee", 
    "publish": "2014-04-01T02:05:55Z", 
    "summary": "This paper presents an intelligent traffic monitoring system using wireless\nvision sensor network that captures and processes the real-time video image to\nobtain the traffic flow rate and vehicle speeds along different urban roadways.\nThis system will display the traffic states on the front roadways that can\nguide the drivers to select the right way and avoid potential traffic\ncongestions. On the other hand, it will also monitor the vehicle speeds and\nstore the vehicle details, for those breaking the roadway speed limits, in its\ndatabase. The real-time traffic data is processed by the Personal Computer (PC)\nat the sub roadway station and the traffic flow rate data is transmitted to the\nmain roadway station Arduino 3G via email, where the data is extracted and\ntraffic flow rate displayed."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1404.0336v2", 
    "title": "A Continuous Max-Flow Approach to General Hierarchical Multi-Labeling   Problems", 
    "arxiv-id": "1404.0336v2", 
    "author": "Terry M. Peters", 
    "publish": "2014-04-01T18:27:52Z", 
    "summary": "Multi-region segmentation algorithms often have the onus of incorporating\ncomplex anatomical knowledge representing spatial or geometric relationships\nbetween objects, and general-purpose methods of addressing this knowledge in an\noptimization-based manner have thus been lacking. This paper presents\nGeneralized Hierarchical Max-Flow (GHMF) segmentation, which captures simple\nanatomical part-whole relationships in the form of an unconstrained hierarchy.\nRegularization can then be applied to both parts and wholes independently,\nallowing for spatial grouping and clustering of labels in a globally optimal\nconvex optimization framework. For the purposes of ready integration into a\nvariety of segmentation tasks, the hierarchies can be presented in run-time,\nallowing for the segmentation problem to be readily specified and alternatives\nexplored without undue programming effort or recompilation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1404.0533v1", 
    "title": "A Comparative Study of Modern Inference Techniques for Structured   Discrete Energy Minimization Problems", 
    "arxiv-id": "1404.0533v1", 
    "author": "Carsten Rother", 
    "publish": "2014-04-02T12:27:27Z", 
    "summary": "Szeliski et al. published an influential study in 2006 on energy minimization\nmethods for Markov Random Fields (MRF). This study provided valuable insights\nin choosing the best optimization technique for certain classes of problems.\nWhile these insights remain generally useful today, the phenomenal success of\nrandom field models means that the kinds of inference problems that have to be\nsolved changed significantly. Specifically, the models today often include\nhigher order interactions, flexible connectivity structures, large\nla\\-bel-spaces of different cardinalities, or learned energy tables. To reflect\nthese changes, we provide a modernized and enlarged study. We present an\nempirical comparison of 32 state-of-the-art optimization techniques on a corpus\nof 2,453 energy minimization instances from diverse applications in computer\nvision. To ensure reproducibility, we evaluate all methods in the OpenGM 2\nframework and report extensive results regarding runtime and solution quality.\nKey insights from our study agree with the results of Szeliski et al. for the\ntypes of models they studied. However, on new and challenging types of models\nour findings disagree and suggest that polyhedral methods and integer\nprogramming solvers are competitive in terms of runtime and solution quality\nover a large range of model types."
},{
    "category": "cs.CV", 
    "doi": "10.4236/am.2014.53049.", 
    "link": "http://arxiv.org/pdf/1404.0566v1", 
    "title": "Weyl group orbit functions in image processing", 
    "arxiv-id": "1404.0566v1", 
    "author": "Ond\u0159ej Kaj\u00ednek", 
    "publish": "2014-02-17T09:42:37Z", 
    "summary": "We deal with the Fourier-like analysis of functions on discrete grids in\ntwo-dimensional simplexes using $C-$ and $E-$ Weyl group orbit functions. For\nthese cases we present the convolution theorem. We provide an example of\napplication of image processing using the $C-$ functions and the convolutions\nfor spatial filtering of the treated image."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cmpb.2014.03.003", 
    "link": "http://arxiv.org/pdf/1404.0600v2", 
    "title": "MBIS: Multivariate Bayesian Image Segmentation Tool", 
    "arxiv-id": "1404.0600v2", 
    "author": "Meritxell Bach-Cuadra", 
    "publish": "2014-04-02T16:10:39Z", 
    "summary": "We present MBIS (Multivariate Bayesian Image Segmentation tool), a clustering\ntool based on the mixture of multivariate normal distributions model. MBIS\nsupports multi-channel bias field correction based on a B-spline model. A\nsecond methodological novelty is the inclusion of graph-cuts optimization for\nthe stationary anisotropic hidden Markov random field model. Along with MBIS,\nwe release an evaluation framework that contains three different experiments on\nmulti-site data. We first validate the accuracy of segmentation and the\nestimated bias field for each channel. MBIS outperforms a widely used\nsegmentation tool in a cross-comparison evaluation. The second experiment\ndemonstrates the robustness of results on atlas-free segmentation of two image\nsets from scan-rescan protocols on 21 healthy subjects. Multivariate\nsegmentation is more replicable than the monospectral counterpart on\nT1-weighted images. Finally, we provide a third experiment to illustrate how\nMBIS can be used in a large-scale study of tissue volume change with increasing\nage in 584 healthy subjects. This last result is meaningful as multivariate\nsegmentation performs robustly without the need for prior knowledge"
},{
    "category": "cs.CV", 
    "doi": "10.1109/ACPR.2013.147", 
    "link": "http://arxiv.org/pdf/1404.0627v1", 
    "title": "Extraction of Projection Profile, Run-Histogram and Entropy Features   Straight from Run-Length Compressed Text-Documents", 
    "arxiv-id": "1404.0627v1", 
    "author": "B. B. Chaudhuri", 
    "publish": "2014-04-02T17:34:13Z", 
    "summary": "Document Image Analysis, like any Digital Image Analysis requires\nidentification and extraction of proper features, which are generally extracted\nfrom uncompressed images, though in reality images are made available in\ncompressed form for the reasons such as transmission and storage efficiency.\nHowever, this implies that the compressed image should be decompressed, which\nindents additional computing resources. This limitation induces the motivation\nto research in extracting features directly from the compressed image. In this\nresearch, we propose to extract essential features such as projection profile,\nrun-histogram and entropy for text document analysis directly from run-length\ncompressed text-documents. The experimentation illustrates that features are\nextracted directly from the compressed image without going through the stage of\ndecompression, because of which the computing time is reduced. The feature\nvalues so extracted are exactly identical to those extracted from uncompressed\nimages."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.1129v2", 
    "title": "An Efficient Two-Stage Sparse Representation Method", 
    "arxiv-id": "1404.1129v2", 
    "author": "Manchor Ko", 
    "publish": "2014-04-04T01:57:25Z", 
    "summary": "There are a large number of methods for solving under-determined linear\ninverse problem. Many of them have very high time complexity for large\ndatasets. We propose a new method called Two-Stage Sparse Representation (TSSR)\nto tackle this problem. We decompose the representing space of signals into two\nparts, the measurement dictionary and the sparsifying basis. The dictionary is\ndesigned to approximate a sub-Gaussian distribution to exploit its\nconcentration property. We apply sparse coding to the signals on the dictionary\nin the first stage, and obtain the training and testing coefficients\nrespectively. Then we design the basis to approach an identity matrix in the\nsecond stage, to acquire the Restricted Isometry Property (RIP) and\nuniversality property. The testing coefficients are encoded over the basis and\nthe final representing coefficients are obtained. We verify that the projection\nof testing coefficients onto the basis is a good approximation of the signal\nonto the representing space. Since the projection is conducted on a much\nsparser space, the runtime is greatly reduced. For concrete realization, we\nprovide an instance for the proposed TSSR. Experiments on four biometrics\ndatabases show that TSSR is effective and efficient, comparing with several\nclassical methods for solving linear inverse problem."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.1151v3", 
    "title": "Recognition of Handwritten MODI Numerals using Hu and Zernike features", 
    "arxiv-id": "1404.1151v3", 
    "author": "Pravin L. Yannawar", 
    "publish": "2014-04-04T04:31:52Z", 
    "summary": "Handwritten automatic character recognition has attracted many researchers\nall over the world to contribute automatic character recognition domain. Shape\nidentification and feature extraction is very important part of any character\nrecognition system and success of method is highly dependent on selection of\nfeatures. However feature extraction is the most important step in defining the\nshape of the character as precisely and as uniquely as possible. This is indeed\nthe most important step and complex task as well and achieved success by using\ninvariance property, irrespective of position and orientation. Zernike moments\ndescribes shape, identify rotation invariant due to its Orthogonality property.\nMODI is an ancient script of India had cursive and complex representation of\ncharacters. The work described in this paper presents efficiency of Zernike\nmoments over Hus moment for automatic recognition of handwritten MODI numerals."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.1682v3", 
    "title": "Pseudo-Zernike Based Multi-Pass Automatic Target Recognition From   Multi-Channel SAR", 
    "arxiv-id": "1404.1682v3", 
    "author": "Alfonso Farina", 
    "publish": "2014-04-07T08:00:59Z", 
    "summary": "The capability to exploit multiple sources of information is of fundamental\nimportance in a battlefield scenario. Information obtained from different\nsources, and separated in space and time, provide the opportunity to exploit\ndiversities in order to mitigate uncertainty. For the specific challenge of\nAutomatic Target Recognition (ATR) from radar platforms, both channel (e.g.\npolarization) and spatial diversity can provide useful information for such a\nspecific and critical task. In this paper the use of pseudo-Zernike moments\napplied to multi-channel multi-pass data is presented exploiting diversities\nand invariant properties leading to high confidence ATR, small computational\ncomplexity and data transfer requirements. The effectiveness of the proposed\napproach, in different configurations and data source availability is\ndemonstrated using real data."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.1777v2", 
    "title": "Neural Codes for Image Retrieval", 
    "arxiv-id": "1404.1777v2", 
    "author": "Victor Lempitsky", 
    "publish": "2014-04-07T13:08:08Z", 
    "summary": "It has been shown that the activations invoked by an image within the top\nlayers of a large convolutional neural network provide a high-level descriptor\nof the visual content of the image. In this paper, we investigate the use of\nsuch descriptors (neural codes) within the image retrieval application. In the\nexperiments with several standard retrieval benchmarks, we establish that\nneural codes perform competitively even when the convolutional neural network\nhas been trained for an unrelated classification task (e.g.\\ Image-Net). We\nalso evaluate the improvement in the retrieval performance of neural codes,\nwhen the network is retrained on a dataset of images that are similar to images\nencountered at test time.\n  We further evaluate the performance of the compressed neural codes and show\nthat a simple PCA compression provides very good short codes that give\nstate-of-the-art accuracy on a number of datasets. In general, neural codes\nturn out to be much more resilient to such compression in comparison other\nstate-of-the-art descriptors. Finally, we show that discriminative\ndimensionality reduction trained on a dataset of pairs of matched photographs\nimproves the performance of PCA-compressed neural codes even further. Overall,\nour quantitative experiments demonstrate the promise of neural codes as visual\ndescriptors for image retrieval."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.1831v1", 
    "title": "Improving Bilayer Product Quantization for Billion-Scale Approximate   Nearest Neighbors in High Dimensions", 
    "arxiv-id": "1404.1831v1", 
    "author": "Victor Lempitsky", 
    "publish": "2014-04-07T16:08:13Z", 
    "summary": "The top-performing systems for billion-scale high-dimensional approximate\nnearest neighbor (ANN) search are all based on two-layer architectures that\ninclude an indexing structure and a compressed datapoints layer. An indexing\nstructure is crucial as it allows to avoid exhaustive search, while the lossy\ndata compression is needed to fit the dataset into RAM. Several of the most\nsuccessful systems use product quantization (PQ) for both the indexing and the\ndataset compression layers. These systems are however limited in the way they\nexploit the interaction of product quantization processes that happen at\ndifferent stages of these systems.\n  Here we introduce and evaluate two approximate nearest neighbor search\nsystems that both exploit the synergy of product quantization processes in a\nmore efficient way. The first system, called Fast Bilayer Product Quantization\n(FBPQ), speeds up the runtime of the baseline system (Multi-D-ADC) by several\ntimes, while achieving the same accuracy. The second system, Hierarchical\nBilayer Product Quantization (HBPQ) provides a significantly better recall for\nthe same runtime at a cost of small memory footprint increase. For the BIGANN\ndataset of billion SIFT descriptors, the 10% increase in Recall@1 and the 17%\nincrease in Recall@10 is observed."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.1869v1", 
    "title": "DenseNet: Implementing Efficient ConvNet Descriptor Pyramids", 
    "arxiv-id": "1404.1869v1", 
    "author": "Kurt Keutzer", 
    "publish": "2014-04-07T18:08:56Z", 
    "summary": "Convolutional Neural Networks (CNNs) can provide accurate object\nclassification. They can be extended to perform object detection by iterating\nover dense or selected proposed object regions. However, the runtime of such\ndetectors scales as the total number and/or area of regions to examine per\nimage, and training such detectors may be prohibitively slow. However, for some\nCNN classifier topologies, it is possible to share significant work among\noverlapping regions to be classified. This paper presents DenseNet, an open\nsource system that computes dense, multiscale features from the convolutional\nlayers of a CNN based object classifier. Future work will involve training\nefficient object detectors with DenseNet feature descriptors."
},{
    "category": "cs.CV", 
    "doi": "10.1142/S0218001416510010", 
    "link": "http://arxiv.org/pdf/1404.2005v1", 
    "title": "Automatic Tracker Selection w.r.t Object Detection Performance", 
    "arxiv-id": "1404.2005v1", 
    "author": "Slawomir Bak", 
    "publish": "2014-04-08T04:09:32Z", 
    "summary": "The tracking algorithm performance depends on video content. This paper\npresents a new multi-object tracking approach which is able to cope with video\ncontent variations. First the object detection is improved using Kanade-\nLucas-Tomasi (KLT) feature tracking. Second, for each mobile object, an\nappropriate tracker is selected among a KLT-based tracker and a discriminative\nappearance-based tracker. This selection is supported by an online tracking\nevaluation. The approach has been experimented on three public video datasets.\nThe experimental results show a better performance of the proposed approach\ncompared to recent state of the art trackers."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIP.2014.51", 
    "link": "http://arxiv.org/pdf/1404.2014v1", 
    "title": "Entropy Computation of Document Images in Run-Length Compressed Domain", 
    "arxiv-id": "1404.2014v1", 
    "author": "B. B. Chaudhuri", 
    "publish": "2014-04-08T05:15:18Z", 
    "summary": "Compression of documents, images, audios and videos have been traditionally\npracticed to increase the efficiency of data storage and transfer. However, in\norder to process or carry out any analytical computations, decompression has\nbecome an unavoidable pre-requisite. In this research work, we have attempted\nto compute the entropy, which is an important document analytic directly from\nthe compressed documents. We use Conventional Entropy Quantifier (CEQ) and\nSpatial Entropy Quantifiers (SEQ) for entropy computations [1]. The entropies\nobtained are useful in applications like establishing equivalence, word\nspotting and document retrieval. Experiments have been performed with all the\ndata sets of [1], at character, word and line levels taking compressed\ndocuments in run-length compressed domain. The algorithms developed are\ncomputational and space efficient, and results obtained match 100% with the\nresults reported in [1]."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2441053", 
    "link": "http://arxiv.org/pdf/1404.2086v2", 
    "title": "Cascades of Regression Tree Fields for Image Restoration", 
    "arxiv-id": "1404.2086v2", 
    "author": "Carsten Rother", 
    "publish": "2014-04-08T10:52:41Z", 
    "summary": "Conditional random fields (CRFs) are popular discriminative models for\ncomputer vision and have been successfully applied in the domain of image\nrestoration, especially to image denoising. For image deblurring, however,\ndiscriminative approaches have been mostly lacking. We posit two reasons for\nthis: First, the blur kernel is often only known at test time, requiring any\ndiscriminative approach to cope with considerable variability. Second, given\nthis variability it is quite difficult to construct suitable features for\ndiscriminative prediction. To address these challenges we first show a\nconnection between common half-quadratic inference for generative image priors\nand Gaussian CRFs. Based on this analysis, we then propose a cascade model for\nimage restoration that consists of a Gaussian CRF at each stage. Each stage of\nour cascade is semi-parametric, i.e. it depends on the instance-specific\nparameters of the restoration problem, such as the blur kernel. We train our\nmodel by loss minimization with synthetically generated training data. Our\nexperiments show that when applied to non-blind image deblurring, the proposed\napproach is efficient and yields state-of-the-art restoration quality on images\ncorrupted with synthetic and real blur. Moreover, we demonstrate its\nsuitability for image denoising, where we achieve competitive results for\ngrayscale and color images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2441053", 
    "link": "http://arxiv.org/pdf/1404.2268v1", 
    "title": "A Compact Linear Programming Relaxation for Binary Sub-modular MRF", 
    "arxiv-id": "1404.2268v1", 
    "author": "Sai-Kit Yeung", 
    "publish": "2014-04-09T16:33:44Z", 
    "summary": "We propose a novel compact linear programming (LP) relaxation for binary\nsub-modular MRF in the context of object segmentation. Our model is obtained by\nlinearizing an $l_1^+$-norm derived from the quadratic programming (QP) form of\nthe MRF energy. The resultant LP model contains significantly fewer variables\nand constraints compared to the conventional LP relaxation of the MRF energy.\nIn addition, unlike QP which can produce ambiguous labels, our model can be\nviewed as a quasi-total-variation minimization problem, and it can therefore\npreserve the discontinuities in the labels. We further establish a relaxation\nbound between our LP model and the conventional LP model. In the experiments,\nwe demonstrate our method for the task of interactive object segmentation. Our\nLP model outperforms QP when converting the continuous labels to binary labels\nusing different threshold values on the entire Oxford interactive segmentation\ndataset. The computational complexity of our LP is of the same order as that of\nthe QP, and it is significantly lower than the conventional LP relaxation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2441053", 
    "link": "http://arxiv.org/pdf/1404.2571v1", 
    "title": "RANCOR: Non-Linear Image Registration with Total Variation   Regularization", 
    "arxiv-id": "1404.2571v1", 
    "author": "Jing Yuan", 
    "publish": "2014-04-09T18:30:38Z", 
    "summary": "Optimization techniques have been widely used in deformable registration,\nallowing for the incorporation of similarity metrics with regularization\nmechanisms. These regularization mechanisms are designed to mitigate the\neffects of trivial solutions to ill-posed registration problems and to\notherwise ensure the resulting deformation fields are well-behaved. This paper\nintroduces a novel deformable registration algorithm, RANCOR, which uses\niterative convexification to address deformable registration problems under\ntotal-variation regularization. Initial comparative results against four\nstate-of-the-art registration algorithms are presented using the Internet Brain\nSegmentation Repository (IBSR) database."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.2999v1", 
    "title": "A Reverse Hierarchy Model for Predicting Eye Fixations", 
    "arxiv-id": "1404.2999v1", 
    "author": "Xiaolin Hu", 
    "publish": "2014-04-11T04:39:21Z", 
    "summary": "A number of psychological and physiological evidences suggest that early\nvisual attention works in a coarse-to-fine way, which lays a basis for the\nreverse hierarchy theory (RHT). This theory states that attention propagates\nfrom the top level of the visual hierarchy that processes gist and abstract\ninformation of input, to the bottom level that processes local details.\nInspired by the theory, we develop a computational model for saliency detection\nin images. First, the original image is downsampled to different scales to\nconstitute a pyramid. Then, saliency on each layer is obtained by image\nsuper-resolution reconstruction from the layer above, which is defined as\nunpredictability from this coarse-to-fine reconstruction. Finally, saliency on\neach layer of the pyramid is fused into stochastic fixations through a\nprobabilistic model, where attention initiates from the top layer and\npropagates downward through the pyramid. Extensive experiments on two standard\neye-tracking datasets show that the proposed method can achieve competitive\nresults with state-of-the-art models."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3312v1", 
    "title": "Shrinkage Optimized Directed Information using Pictorial Structures for   Action Recognition", 
    "arxiv-id": "1404.3312v1", 
    "author": "Silvio Savarese", 
    "publish": "2014-04-12T19:01:36Z", 
    "summary": "In this paper, we propose a novel action recognition framework. The method\nuses pictorial structures and shrinkage optimized directed information\nassessment (SODA) coupled with Markov Random Fields called SODA+MRF to model\nthe directional temporal dependency and bidirectional spatial dependency. As a\nvariant of mutual information, directional information captures the directional\ninformation flow and temporal structure of video sequences across frames.\nMeanwhile, within each frame, Markov random fields are utilized to model the\nspatial relations among different parts of a human body and the body parts of\ndifferent people. The proposed SODA+MRF model is robust to view point\ntransformations and detect complex interactions accurately. We compare the\nproposed method against several baseline methods to highlight the effectiveness\nof the SODA+MRF model. We demonstrate that our algorithm has superior action\nrecognition performance on the UCF action recognition dataset, the Olympic\nsports dataset and the collective activity dataset over several\nstate-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3366v2", 
    "title": "Learning Deep Convolutional Features for MRI Based Alzheimer's Disease   Classification", 
    "arxiv-id": "1404.3366v2", 
    "author": "Chunhua Shen", 
    "publish": "2014-04-13T10:45:38Z", 
    "summary": "Effective and accurate diagnosis of Alzheimer's disease (AD) or mild\ncognitive impairment (MCI) can be critical for early treatment and thus has\nattracted more and more attention nowadays. Since first introduced, machine\nlearning methods have been gaining increasing popularity for AD related\nresearch. Among the various identified biomarkers, magnetic resonance imaging\n(MRI) are widely used for the prediction of AD or MCI. However, before a\nmachine learning algorithm can be applied, image features need to be extracted\nto represent the MRI images. While good representations can be pivotal to the\nclassification performance, almost all the previous studies typically rely on\nhuman labelling to find the regions of interest (ROI) which may be correlated\nto AD, such as hippocampus, amygdala, precuneus, etc. This procedure requires\ndomain knowledge and is costly and tedious.\n  Instead of relying on extraction of ROI features, it is more promising to\nremove manual ROI labelling from the pipeline and directly work on the raw MRI\nimages. In other words, we can let the machine learning methods to figure out\nthese informative and discriminative image structures for AD classification. In\nthis work, we propose to learn deep convolutional image features using\nunsupervised and supervised learning. Deep learning has emerged as a powerful\ntool in the machine learning community and has been successfully applied to\nvarious tasks. We thus propose to exploit deep features of MRI images based on\na pre-trained large convolutional neural network (CNN) for AD and MCI\nclassification, which spares the effort of manual ROI annotation process."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3538v2", 
    "title": "Proceedings of The 38th Annual Workshop of the Austrian Association for   Pattern Recognition (\u00d6AGM), 2014", 
    "arxiv-id": "1404.3538v2", 
    "author": "Rustem Takhanov", 
    "publish": "2014-04-14T11:01:04Z", 
    "summary": "The 38th Annual Workshop of the Austrian Association for Pattern Recognition\n(\\\"OAGM) will be held at IST Austria, on May 22-23, 2014. The workshop provides\na platform for researchers and industry to discuss traditional and new areas of\ncomputer vision. This year the main topic is: Pattern Recognition:\ninterdisciplinary challenges and opportunities."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3543v2", 
    "title": "Recover Canonical-View Faces in the Wild with Deep Neural Networks", 
    "arxiv-id": "1404.3543v2", 
    "author": "Xiaoou Tang", 
    "publish": "2014-04-14T11:32:17Z", 
    "summary": "Face images in the wild undergo large intra-personal variations, such as\nposes, illuminations, occlusions, and low resolutions, which cause great\nchallenges to face-related applications. This paper addresses this challenge by\nproposing a new deep learning framework that can recover the canonical view of\nface images. It dramatically reduces the intra-person variances, while\nmaintaining the inter-person discriminativeness. Unlike the existing face\nreconstruction methods that were either evaluated in controlled 2D environment\nor employed 3D information, our approach directly learns the transformation\nfrom the face images with a complex set of variations to their canonical views.\nAt the training stage, to avoid the costly process of labeling canonical-view\nimages from the training set by hand, we have devised a new measurement to\nautomatically select or synthesize a canonical-view image for each identity. As\nan application, this face recovery approach is used for face verification.\nFacial features are learned from the recovered canonical-view face images by\nusing a facial component-based convolutional neural network. Our approach\nachieves the state-of-the-art performance on the LFW dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3596v7", 
    "title": "Face Detection with a 3D Model", 
    "arxiv-id": "1404.3596v7", 
    "author": "Gary Gramajo", 
    "publish": "2014-04-14T14:31:32Z", 
    "summary": "This paper presents a part-based face detection approach where the spatial\nrelationship between the face parts is represented by a hidden 3D model with\nsix parameters. The computational complexity of the search in the six\ndimensional pose space is addressed by proposing meaningful 3D pose candidates\nby image-based regression from detected face keypoint locations. The 3D pose\ncandidates are evaluated using a parameter sensitive classifier based on\ndifference features relative to the 3D pose. A compatible subset of candidates\nis then obtained by non-maximal suppression. Experiments on two standard face\ndetection datasets show that the proposed 3D model based approach obtains\nresults comparable to or better than state of the art."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3933v1", 
    "title": "Scalable Matting: A Sub-linear Approach", 
    "arxiv-id": "1404.3933v1", 
    "author": "Ying Wu", 
    "publish": "2014-04-15T14:39:20Z", 
    "summary": "Natural image matting, which separates foreground from background, is a very\nimportant intermediate step in recent computer vision algorithms. However, it\nis severely underconstrained and difficult to solve. State-of-the-art\napproaches include matting by graph Laplacian, which significantly improves the\nunderconstrained nature by reducing the solution space. However, matting by\ngraph Laplacian is still very difficult to solve and gets much harder as the\nimage size grows: current iterative methods slow down as $\\mathcal{O}\\left(n^2\n\\right)$ in the resolution $n$. This creates uncomfortable practical limits on\nthe resolution of images that we can matte. Current literature mitigates the\nproblem, but they all remain super-linear in complexity. We expose properties\nof the problem that remain heretofore unexploited, demonstrating that an\noptimization technique originally intended to solve PDEs can be adapted to take\nadvantage of this knowledge to solve the matting problem, not heuristically,\nbut exactly and with sub-linear complexity. This makes ours the most efficient\nmatting solver currently known by a very wide margin and allows matting finally\nto be practical and scalable in the future as consumer photos exceed many\ndozens of megapixels, and also relieves matting from being a bottleneck for\nvision algorithms that depend on it."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.3991v1", 
    "title": "Spiralet Sparse Representation", 
    "arxiv-id": "1404.3991v1", 
    "author": "Mohamed Cheriet", 
    "publish": "2014-04-15T17:12:40Z", 
    "summary": "This is the first report on Working Paper WP-RFM-14-01. The potential and\ncapability of sparse representations is well-known. However, their\n(multivariate variable) vectorial form, which is completely fine in many fields\nand disciplines, results in removal and filtering of important \"spatial\"\nrelations that are implicitly carried by two-dimensional [or multi-dimensional]\nobjects, such as images. In this paper, a new approach, called spiralet sparse\nrepresentation, is proposed in order to develop an augmented representation and\ntherefore a modified sparse representation and theory, which is capable to\npreserve the data associated to the spatial relations."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2014.361", 
    "link": "http://arxiv.org/pdf/1404.4316v1", 
    "title": "Generic Object Detection With Dense Neural Patterns and Regionlets", 
    "arxiv-id": "1404.4316v1", 
    "author": "Yuanqing Lin", 
    "publish": "2014-04-16T17:23:47Z", 
    "summary": "This paper addresses the challenge of establishing a bridge between deep\nconvolutional neural networks and conventional object detection frameworks for\naccurate and efficient generic object detection. We introduce Dense Neural\nPatterns, short for DNPs, which are dense local features derived from\ndiscriminatively trained deep convolutional neural networks. DNPs can be easily\nplugged into conventional detection frameworks in the same way as other dense\nlocal features(like HOG or LBP). The effectiveness of the proposed approach is\ndemonstrated with the Regionlets object detection framework. It achieved 46.1%\nmean average precision on the PASCAL VOC 2007 dataset, and 44.1% on the PASCAL\nVOC 2010 dataset, which dramatically improves the original Regionlets approach\nwithout DNPs."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0093389", 
    "link": "http://arxiv.org/pdf/1404.4467v2", 
    "title": "Cube-Cut: Vertebral Body Segmentation in MRI-Data through Cubic-Shaped   Divergences", 
    "arxiv-id": "1404.4467v2", 
    "author": "Jan Egger", 
    "publish": "2014-04-17T09:58:28Z", 
    "summary": "In this article, we present a graph-based method using a cubic template for\nvolumetric segmentation of vertebrae in magnetic resonance imaging (MRI)\nacquisitions. The user can define the degree of deviation from a regular cube\nvia a smoothness value Delta. The Cube-Cut algorithm generates a directed graph\nwith two terminal nodes (s-t-network), where the nodes of the graph correspond\nto a cubic-shaped subset of the image's voxels. The weightings of the graph's\nterminal edges, which connect every node with a virtual source s or a virtual\nsink t, represent the affinity of a voxel to the vertebra (source) and to the\nbackground (sink). Furthermore, a set of infinite weighted and non-terminal\nedges implements the smoothness term. After graph construction, a minimal\ns-t-cut is calculated within polynomial computation time, which splits the\nnodes into two disjoint units. Subsequently, the segmentation result is\ndetermined out of the source-set. A quantitative evaluation of a C++\nimplementation of the algorithm resulted in an average Dice Similarity\nCoefficient (DSC) of 81.33% and a running time of less than a minute."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0093389", 
    "link": "http://arxiv.org/pdf/1404.4661v1", 
    "title": "Learning Fine-grained Image Similarity with Deep Ranking", 
    "arxiv-id": "1404.4661v1", 
    "author": "Ying Wu", 
    "publish": "2014-04-17T22:09:16Z", 
    "summary": "Learning fine-grained image similarity is a challenging task. It needs to\ncapture between-class and within-class image differences. This paper proposes a\ndeep ranking model that employs deep learning techniques to learn similarity\nmetric directly from images.It has higher learning capability than models based\non hand-crafted features. A novel multiscale network structure has been\ndeveloped to describe the images effectively. An efficient triplet sampling\nalgorithm is proposed to learn the model with distributed asynchronized\nstochastic gradient. Extensive experiments show that the proposed algorithm\noutperforms models based on hand-crafted visual features and deep\nclassification models."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0093389", 
    "link": "http://arxiv.org/pdf/1404.4774v3", 
    "title": "Online Group Feature Selection", 
    "arxiv-id": "1404.4774v3", 
    "author": "Wu Xindong", 
    "publish": "2014-04-18T12:51:24Z", 
    "summary": "Online feature selection with dynamic features has become an active research\narea in recent years. However, in some real-world applications such as image\nanalysis and email spam filtering, features may arrive by groups. Existing\nonline feature selection methods evaluate features individually, while existing\ngroup feature selection methods cannot handle online processing. Motivated by\nthis, we formulate the online group feature selection problem, and propose a\nnovel selection approach for this problem. Our proposed approach consists of\ntwo stages: online intra-group selection and online inter-group selection. In\nthe intra-group selection, we use spectral analysis to select discriminative\nfeatures in each group when it arrives. In the inter-group selection, we use\nLasso to select a globally optimal subset of features. This 2-stage procedure\ncontinues until there are no more features to come or some predefined stopping\nconditions are met. Extensive experiments conducted on benchmark and real-world\ndata sets demonstrate that our proposed approach outperforms other\nstate-of-the-art online feature selection methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCYB.2014.2307067", 
    "link": "http://arxiv.org/pdf/1404.4780v1", 
    "title": "Robust Face Recognition via Adaptive Sparse Representation", 
    "arxiv-id": "1404.4780v1", 
    "author": "Xuegang Hu", 
    "publish": "2014-04-18T13:24:29Z", 
    "summary": "Sparse Representation (or coding) based Classification (SRC) has gained great\nsuccess in face recognition in recent years. However, SRC emphasizes the\nsparsity too much and overlooks the correlation information which has been\ndemonstrated to be critical in real-world face recognition problems. Besides,\nsome work considers the correlation but overlooks the discriminative ability of\nsparsity. Different from these existing techniques, in this paper, we propose a\nframework called Adaptive Sparse Representation based Classification (ASRC) in\nwhich sparsity and correlation are jointly considered. Specifically, when the\nsamples are of low correlation, ASRC selects the most discriminative samples\nfor representation, like SRC; when the training samples are highly correlated,\nASRC selects most of the correlated and discriminative samples for\nrepresentation, rather than choosing some related samples randomly. In general,\nthe representation model is adaptive to the correlation structure, which\nbenefits from both $\\ell_1$-norm and $\\ell_2$-norm.\n  Extensive experiments conducted on publicly available data sets verify the\neffectiveness and robustness of the proposed algorithm by comparing it with\nstate-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCYB.2014.2307067", 
    "link": "http://arxiv.org/pdf/1404.4800v1", 
    "title": "Automatic Annotation of Axoplasmic Reticula in Pursuit of Connectomes", 
    "arxiv-id": "1404.4800v1", 
    "author": "Michael Kazhdan", 
    "publish": "2014-04-16T20:09:37Z", 
    "summary": "In this paper, we present a new pipeline which automatically identifies and\nannotates axoplasmic reticula, which are small subcellular structures present\nonly in axons. We run our algorithm on the Kasthuri11 dataset, which was color\ncorrected using gradient-domain techniques to adjust contrast. We use a\nbilateral filter to smooth out the noise in this data while preserving edges,\nwhich highlights axoplasmic reticula. These axoplasmic reticula are then\nannotated using a morphological region growing algorithm. Additionally, we\nperform Laplacian sharpening on the bilaterally filtered data to enhance edges,\nand repeat the morphological region growing algorithm to annotate more\naxoplasmic reticula. We track our annotations through the slices to improve\nprecision, and to create long objects to aid in segment merging. This method\nannotates axoplasmic reticula with high precision. Our algorithm can easily be\nadapted to annotate axoplasmic reticula in different sets of brain data by\nchanging a few thresholds. The contribution of this work is the introduction of\na straightforward and robust pipeline which annotates axoplasmic reticula with\nhigh precision, contributing towards advancements in automatic feature\nannotations in neural EM data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2358082", 
    "link": "http://arxiv.org/pdf/1404.4923v3", 
    "title": "Unified Structured Learning for Simultaneous Human Pose Estimation and   Garment Attribute Classification", 
    "arxiv-id": "1404.4923v3", 
    "author": "Shuicheng Yan", 
    "publish": "2014-04-19T04:51:06Z", 
    "summary": "In this paper, we utilize structured learning to simultaneously address two\nintertwined problems: human pose estimation (HPE) and garment attribute\nclassification (GAC), which are valuable for a variety of computer vision and\nmultimedia applications. Unlike previous works that usually handle the two\nproblems separately, our approach aims to produce a jointly optimal estimation\nfor both HPE and GAC via a unified inference procedure. To this end, we adopt a\npreprocessing step to detect potential human parts from each image (i.e., a set\nof \"candidates\") that allows us to have a manageable input space. In this way,\nthe simultaneous inference of HPE and GAC is converted to a structured learning\nproblem, where the inputs are the collections of candidate ensembles, the\noutputs are the joint labels of human parts and garment attributes, and the\njoint feature representation involves various cues such as pose-specific\nfeatures, garment-specific features, and cross-task features that encode\ncorrelations between human parts and garment attributes. Furthermore, we\nexplore the \"strong edge\" evidence around the potential human parts so as to\nderive more powerful representations for oriented human parts. Such evidences\ncan be seamlessly integrated into our structured learning model as a kind of\nenergy function, and the learning process could be performed by standard\nstructured Support Vector Machines (SVM) algorithm. However, the joint\nstructure of the two problems is a cyclic graph, which hinders efficient\ninference. To resolve this issue, we compute instead approximate optima by\nusing an iterative procedure, where in each iteration the variables of one\nproblem are fixed. In this way, satisfactory solutions can be efficiently\ncomputed by dynamic programming. Experimental results on two benchmark datasets\nshow the state-of-the-art performance of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2358082", 
    "link": "http://arxiv.org/pdf/1404.4942v1", 
    "title": "Geometric Abstraction from Noisy Image-Based 3D Reconstructions", 
    "arxiv-id": "1404.4942v1", 
    "author": "Horst Bischof", 
    "publish": "2014-04-19T09:55:00Z", 
    "summary": "Creating geometric abstracted models from image-based scene reconstructions\nis difficult due to noise and irregularities in the reconstructed model. In\nthis paper, we present a geometric modeling method for noisy reconstructions\ndominated by planar horizontal and orthogonal vertical structures. We partition\nthe scene into horizontal slices and create an inside/outside labeling\nrepresented by a floor plan for each slice by solving an energy minimization\nproblem. Consecutively, we create an irregular discretization of the volume\naccording to the individual floor plans and again label each cell as\ninside/outside by minimizing an energy function. By adjusting the smoothness\nparameter, we introduce different levels of detail. In our experiments, we show\nresults with varying regularization levels using synthetically generated and\nreal-world data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.5344v3", 
    "title": "A higher-order MRF based variational model for multiplicative noise   reduction", 
    "arxiv-id": "1404.5344v3", 
    "author": "Thomas Pock", 
    "publish": "2014-04-21T22:19:31Z", 
    "summary": "The Fields of Experts (FoE) image prior model, a filter-based higher-order\nMarkov Random Fields (MRF) model, has been shown to be effective for many image\nrestoration problems. Motivated by the successes of FoE-based approaches, in\nthis letter, we propose a novel variational model for multiplicative noise\nreduction based on the FoE image prior model. The resulted model corresponds to\na non-convex minimization problem, which can be solved by a recently published\nnon-convex optimization algorithm. Experimental results based on synthetic\nspeckle noise and real synthetic aperture radar (SAR) images suggest that the\nperformance of our proposed method is on par with the best published\ndespeckling algorithm. Besides, our proposed model comes along with an\nadditional advantage, that the inference is extremely efficient. {Our GPU based\nimplementation takes less than 1s to produce state-of-the-art despeckling\nperformance.}"
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.5351v1", 
    "title": "Fast Approximate Matching of Cell-Phone Videos for Robust Background   Subtraction", 
    "arxiv-id": "1404.5351v1", 
    "author": "Neel Sundaresan", 
    "publish": "2014-04-22T00:02:14Z", 
    "summary": "We identify a novel instance of the background subtraction problem that\nfocuses on extracting near-field foreground objects captured using handheld\ncameras. Given two user-generated videos of a scene, one with and the other\nwithout the foreground object(s), our goal is to efficiently generate an output\nvideo with only the foreground object(s) present in it. We cast this challenge\nas a spatio-temporal frame matching problem, and propose an efficient solution\nfor it that exploits the temporal smoothness of the video sequences. We present\ntheoretical analyses for the error bounds of our approach, and validate our\nfindings using a detailed set of simulation experiments. Finally, we present\nthe results of our approach tested on multiple real videos captured using\nhandheld cameras, and compare them to several alternate foreground extraction\napproaches."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.5588v1", 
    "title": "Large Margin Image Set Representation and Classification", 
    "arxiv-id": "1404.5588v1", 
    "author": "Xin Gao", 
    "publish": "2014-04-22T18:41:42Z", 
    "summary": "In this paper, we propose a novel image set representation and classification\nmethod by maximizing the margin of image sets. The margin of an image set is\ndefined as the difference of the distance to its nearest image set from\ndifferent classes and the distance to its nearest image set of the same class.\nBy modeling the image sets by using both their image samples and their affine\nhull models, and maximizing the margins of the images sets, the image set\nrepresentation parameter learning problem is formulated as an minimization\nproblem, which is further optimized by an expectation -maximization (EM)\nstrategy with accelerated proximal gradient (APG) optimization in an iterative\nalgorithm. To classify a given test image set, we assign it to the class which\ncould provide the largest margin. Experiments on two applications of\nvideo-sequence-based face recognition demonstrate that the proposed method\nsignificantly outperforms state-of-the-art image set classification methods in\nterms of both effectiveness and efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.6031v1", 
    "title": "Maximum Margin Vector Correlation Filter", 
    "arxiv-id": "1404.6031v1", 
    "author": "B. V. K. Vijaya Kumar", 
    "publish": "2014-04-24T05:43:54Z", 
    "summary": "Correlation Filters (CFs) are a class of classifiers which are designed for\naccurate pattern localization. Traditionally CFs have been used with scalar\nfeatures only, which limits their ability to be used with vector feature\nrepresentations like Gabor filter banks, SIFT, HOG, etc. In this paper we\npresent a new CF named Maximum Margin Vector Correlation Filter (MMVCF) which\nextends the traditional CF designs to vector features. MMVCF further combines\nthe generalization capability of large margin based classifiers like Support\nVector Machines (SVMs) and the localization properties of CFs for better\nrobustness to outliers. We demonstrate the efficacy of MMVCF for object\ndetection and landmark localization on a variety of databases and demonstrate\nthat MMVCF consistently shows improved pattern localization capability in\ncomparison to SVMs."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.6055v2", 
    "title": "A General Homogeneous Matrix Formulation to 3D Rotation Geometric   Transformations", 
    "arxiv-id": "1404.6055v2", 
    "author": "Ziqiang Chen", 
    "publish": "2014-04-24T08:49:52Z", 
    "summary": "We present algebraic projective geometry definitions of 3D rotations so as to\nbridge a small gap between the applications and the definitions of 3D rotations\nin homogeneous matrix form. A general homogeneous matrix formulation to 3D\nrotation geometric transformations is proposed which suits for the cases when\nthe rotation axis is unnecessarily through the coordinate system origin given\ntheir rotation axes and rotation angles."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.6351v1", 
    "title": "Improving weather radar by fusion and classification", 
    "arxiv-id": "1404.6351v1", 
    "author": "Karin Hennermann", 
    "publish": "2014-04-25T08:32:51Z", 
    "summary": "In air traffic management (ATM) all necessary operations (tactical planing,\nsector configuration, required staffing, runway configuration, routing of\napproaching aircrafts) rely on accurate measurements and predictions of the\ncurrent weather situation. An essential basis of information is delivered by\nweather radar images (WXR), which, unfortunately, exhibit a vast amount of\ndisturbances. Thus, the improvement of these datasets is the key factor for\nmore accurate predictions of weather phenomena and weather conditions. Image\nprocessing methods based on texture analysis and geometric operators allow to\nidentify regions including artefacts as well as zones of missing information.\nCorrection of these zones is implemented by exploiting multi-spectral satellite\ndata (Meteosat Second Generation). Results prove that the proposed system for\nartefact detection and data correction significantly improves the quality of\nWXR data and, thus, enables more reliable weather now- and forecast leading to\nincreased ATM safety."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.6413v1", 
    "title": "Indoor Activity Detection and Recognition for Sport Games Analysis", 
    "arxiv-id": "1404.6413v1", 
    "author": "Horst Bischof", 
    "publish": "2014-04-25T13:25:09Z", 
    "summary": "Activity recognition in sport is an attractive field for computer vision\nresearch. Game, player and team analysis are of great interest and research\ntopics within this field emerge with the goal of automated analysis. The very\nspecific underlying rules of sports can be used as prior knowledge for the\nrecognition task and present a constrained environment for evaluation. This\npaper describes recognition of single player activities in sport with special\nemphasis on volleyball. Starting from a per-frame player-centered activity\nrecognition, we incorporate geometry and contextual information via an activity\ncontext descriptor that collects information about all player's activities over\na certain timespan relative to the investigated player. The benefit of this\ncontext information on single player activity recognition is evaluated on our\nnew real-life dataset presenting a total amount of almost 36k annotated frames\ncontaining 7 activity classes within 6 videos of professional volleyball games.\nOur incorporation of the contextual information improves the average\nplayer-centered classification performance of 77.56% by up to 18.35% on\nspecific classes, proving that spatio-temporal context is an important clue for\nactivity recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.6736v1", 
    "title": "Robust and Efficient Subspace Segmentation via Least Squares Regression", 
    "arxiv-id": "1404.6736v1", 
    "author": "Shuicheng Yan", 
    "publish": "2014-04-27T11:01:17Z", 
    "summary": "This paper studies the subspace segmentation problem which aims to segment\ndata drawn from a union of multiple linear subspaces. Recent works by using\nsparse representation, low rank representation and their extensions attract\nmuch attention. If the subspaces from which the data drawn are independent or\northogonal, they are able to obtain a block diagonal affinity matrix, which\nusually leads to a correct segmentation. The main differences among them are\ntheir objective functions. We theoretically show that if the objective function\nsatisfies some conditions, and the data are sufficiently drawn from independent\nsubspaces, the obtained affinity matrix is always block diagonal. Furthermore,\nthe data sampling can be insufficient if the subspaces are orthogonal. Some\nexisting methods are all special cases. Then we present the Least Squares\nRegression (LSR) method for subspace segmentation. It takes advantage of data\ncorrelation, which is common in real data. LSR encourages a grouping effect\nwhich tends to group highly correlated data together. Experimental results on\nthe Hopkins 155 database and Extended Yale Database B show that our method\nsignificantly outperforms state-of-the-art methods. Beyond segmentation\naccuracy, all experiments demonstrate that LSR is much more efficient."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.7059v2", 
    "title": "Stereo on a budget", 
    "arxiv-id": "1404.7059v2", 
    "author": "Shai Avidan", 
    "publish": "2014-04-28T17:06:28Z", 
    "summary": "We propose an algorithm for recovering depth using less than two images.\nInstead of having both cameras send their entire image to the host computer,\nthe left camera sends its image to the host while the right camera sends only a\nfraction $\\epsilon$ of its image. The key aspect is that the cameras send the\ninformation without communicating at all. Hence, the required communication\nbandwidth is significantly reduced.\n  While standard image compression techniques can reduce the communication\nbandwidth, this requires additional computational resources on the part of the\nencoder (camera). We aim at designing a light weight encoder that only touches\na fraction of the pixels. The burden of decoding is placed on the decoder\n(host).\n  We show that it is enough for the encoder to transmit a sparse set of pixels.\nUsing only $1+\\epsilon$ images, with $\\epsilon$ as little as 2% of the image,\nthe decoder can compute a depth map. The depth map's accuracy is comparable to\ntraditional stereo matching algorithms that require both images as input. Using\nthe depth map and the left image, the right image can be synthesized. No\ncomputations are required at the encoder, and the decoder's runtime is linear\nin the images' size."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2337274", 
    "link": "http://arxiv.org/pdf/1404.7174v7", 
    "title": "Computer vision-based recognition of liquid surfaces and phase   boundaries in transparent vessels, with emphasis on chemistry applications", 
    "arxiv-id": "1404.7174v7", 
    "author": "Tal Kachman", 
    "publish": "2014-04-28T21:41:30Z", 
    "summary": "The ability to recognize the liquid surface and the liquid level in\ntransparent containers is perhaps the most commonly used evaluation method when\ndealing with fluids. Such recognition is essential in determining the liquid\nvolume, fill level, phase boundaries and phase separation in various fluid\nsystems. The recognition of liquid surfaces is particularly important in\nsolution chemistry, where it is essential to many laboratory techniques (e.g.,\nextraction, distillation, titration). A general method for the recognition of\ninterfaces between liquid and air or between phase-separating liquids could\nhave a wide range of applications and contribute to the understanding of the\nvisual properties of such interfaces. This work examines a computer vision\nmethod for the recognition of liquid surfaces and liquid levels in various\ntransparent containers. The method can be applied to recognition of both\nliquid-air and liquid-liquid surfaces. No prior knowledge of the number of\nphases is required. The method receives the image of the liquid container and\nthe boundaries of the container in the image and scans all possible curves that\ncould correspond to the outlines of liquid surfaces in the image. The method\nthen compares each curve to the image to rate its correspondence with the\noutline of the real liquid surface by examining various image properties in the\narea surrounding each point of the curve. The image properties that were found\nto give the best indication of the liquid surface are the relative intensity\nchange, the edge density change and the gradient direction relative to the\ncurve normal."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2013.6738211", 
    "link": "http://arxiv.org/pdf/1404.7211v1", 
    "title": "Spatially Directional Predictive Coding for Block-based Compressive   Sensing of Natural Images", 
    "arxiv-id": "1404.7211v1", 
    "author": "Feng Jiang", 
    "publish": "2014-04-29T02:10:09Z", 
    "summary": "A novel coding strategy for block-based compressive sens-ing named spatially\ndirectional predictive coding (SDPC) is proposed, which efficiently utilizes\nthe intrinsic spatial cor-relation of natural images. At the encoder, for each\nblock of compressive sensing (CS) measurements, the optimal pre-diction is\nselected from a set of prediction candidates that are generated by four\ndesigned directional predictive modes. Then, the resulting residual is\nprocessed by scalar quantiza-tion (SQ). At the decoder, the same prediction is\nadded onto the de-quantized residuals to produce the quantized CS measurements,\nwhich is exploited for CS reconstruction. Experimental results substantiate\nsignificant improvements achieved by SDPC-plus-SQ in rate distortion\nperformance as compared with SQ alone and DPCM-plus-SQ."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2013.6738211", 
    "link": "http://arxiv.org/pdf/1404.7212v1", 
    "title": "Structural Group Sparse Representation for Image Compressive Sensing   Recovery", 
    "arxiv-id": "1404.7212v1", 
    "author": "Wen Gao", 
    "publish": "2014-04-29T02:15:42Z", 
    "summary": "Compressive Sensing (CS) theory shows that a signal can be decoded from many\nfewer measurements than suggested by the Nyquist sampling theory, when the\nsignal is sparse in some domain. Most of conventional CS recovery approaches,\nhowever, exploited a set of fixed bases (e.g. DCT, wavelet, contourlet and\ngradient domain) for the entirety of a signal, which are irrespective of the\nnonstationarity of natural signals and cannot achieve high enough degree of\nsparsity, thus resulting in poor rate-distortion performance. In this paper, we\npropose a new framework for image compressive sensing recovery via structural\ngroup sparse representation (SGSR) modeling, which enforces image sparsity and\nself-similarity simultaneously under a unified framework in an adaptive group\ndomain, thus greatly confining the CS solution space. In addition, an efficient\niterative shrinkage/thresholding algorithm based technique is developed to\nsolve the above optimization problem. Experimental results demonstrate that the\nnovel CS recovery strategy achieves significant performance improvements over\nthe current state-of-the-art schemes and exhibits nice convergence."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2013.09.025", 
    "link": "http://arxiv.org/pdf/1404.7566v1", 
    "title": "Image Compressive Sensing Recovery Using Adaptively Learned Sparsifying   Basis via L0 Minimization", 
    "arxiv-id": "1404.7566v1", 
    "author": "Wen Gao", 
    "publish": "2014-04-30T00:56:40Z", 
    "summary": "From many fewer acquired measurements than suggested by the Nyquist sampling\ntheory, compressive sensing (CS) theory demonstrates that, a signal can be\nreconstructed with high probability when it exhibits sparsity in some domain.\nMost of the conventional CS recovery approaches, however, exploited a set of\nfixed bases (e.g. DCT, wavelet and gradient domain) for the entirety of a\nsignal, which are irrespective of the non-stationarity of natural signals and\ncannot achieve high enough degree of sparsity, thus resulting in poor CS\nrecovery performance. In this paper, we propose a new framework for image\ncompressive sensing recovery using adaptively learned sparsifying basis via L0\nminimization. The intrinsic sparsity of natural images is enforced\nsubstantially by sparsely representing overlapped image patches using the\nadaptively learned sparsifying basis in the form of L0 norm, greatly reducing\nblocking artifacts and confining the CS solution space. To make our proposed\nscheme tractable and robust, a split Bregman iteration based technique is\ndeveloped to solve the non-convex L0 minimization problem efficiently.\nExperimental results on a wide range of natural images for CS recovery have\nshown that our proposed algorithm achieves significant performance improvements\nover many current state-of-the-art schemes and exhibits good convergence\nproperty."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2014.2345390", 
    "link": "http://arxiv.org/pdf/1404.7584v3", 
    "title": "High-Speed Tracking with Kernelized Correlation Filters", 
    "arxiv-id": "1404.7584v3", 
    "author": "Jorge Batista", 
    "publish": "2014-04-30T04:16:38Z", 
    "summary": "The core component of most modern trackers is a discriminative classifier,\ntasked with distinguishing between the target and the surrounding environment.\nTo cope with natural image changes, this classifier is typically trained with\ntranslated and scaled sample patches. Such sets of samples are riddled with\nredundancies -- any overlapping pixels are constrained to be the same. Based on\nthis simple observation, we propose an analytic model for datasets of thousands\nof translated patches. By showing that the resulting data matrix is circulant,\nwe can diagonalize it with the Discrete Fourier Transform, reducing both\nstorage and computation by several orders of magnitude. Interestingly, for\nlinear regression our formulation is equivalent to a correlation filter, used\nby some of the fastest competitive trackers. For kernel regression, however, we\nderive a new Kernelized Correlation Filter (KCF), that unlike other kernel\nalgorithms has the exact same complexity as its linear counterpart. Building on\nit, we also propose a fast multi-channel extension of linear correlation\nfilters, via a linear kernel, which we call Dual Correlation Filter (DCF). Both\nKCF and DCF outperform top-ranking trackers such as Struck or TLD on a 50\nvideos benchmark, despite running at hundreds of frames-per-second, and being\nimplemented in a few lines of code (Algorithm 1). To encourage further\ndevelopments, our tracking framework was made open-source."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2014.2345390", 
    "link": "http://arxiv.org/pdf/1404.7592v1", 
    "title": "Dynamic Mode Decomposition for Real-Time Background/Foreground   Separation in Video", 
    "arxiv-id": "1404.7592v1", 
    "author": "J. Nathan Kutz", 
    "publish": "2014-04-30T05:21:27Z", 
    "summary": "This paper introduces the method of dynamic mode decomposition (DMD) for\nrobustly separating video frames into background (low-rank) and foreground\n(sparse) components in real-time. The method is a novel application of a\ntechnique used for characterizing nonlinear dynamical systems in an\nequation-free manner by decomposing the state of the system into low-rank terms\nwhose Fourier components in time are known. DMD terms with Fourier frequencies\nnear the origin (zero-modes) are interpreted as background (low-rank) portions\nof the given video frames, and the terms with Fourier frequencies bounded away\nfrom the origin are their sparse counterparts. An approximate low-rank/sparse\nseparation is achieved at the computational cost of just one singular value\ndecomposition and one linear equation solve, thus producing results orders of\nmagnitude faster than a leading separation method, namely robust principal\ncomponent analysis (RPCA). The DMD method that is developed here is\ndemonstrated to work robustly in real-time with personal laptop-class computing\npower and without any parameter tuning, which is a transformative improvement\nin performance that is ideal for video surveillance and recognition\napplications."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2014.2345390", 
    "link": "http://arxiv.org/pdf/1404.7594v1", 
    "title": "Selecting a Small Set of Optimal Gestures from an Extensive Lexicon", 
    "arxiv-id": "1404.7594v1", 
    "author": "J. Nathan Kutz", 
    "publish": "2014-04-30T05:37:44Z", 
    "summary": "Finding the best set of gestures to use for a given computer recognition\nproblem is an essential part of optimizing the recognition performance while\nbeing mindful to those who may articulate the gestures. An objective function,\ncalled the ellipsoidal distance ratio metric (EDRM), for determining the best\ngestures from a larger lexicon library is presented, along with a numerical\nmethod for incorporating subjective preferences. In particular, we demonstrate\nan efficient algorithm that chooses the best $n$ gestures from a lexicon of $m$\ngestures where typically $n \\ll m$ using a weighting of both subjective and\nobjective measures."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2014.05.007", 
    "link": "http://arxiv.org/pdf/1404.7748v1", 
    "title": "A graph-based mathematical morphology reader", 
    "arxiv-id": "1404.7748v1", 
    "author": "Jean Cousty", 
    "publish": "2014-04-30T14:54:19Z", 
    "summary": "This survey paper aims at providing a \"literary\" anthology of mathematical\nmorphology on graphs. It describes in the English language many ideas stemming\nfrom a large number of different papers, hence providing a unified view of an\nactive and diverse field of research."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2014.05.007", 
    "link": "http://arxiv.org/pdf/1406.0023v1", 
    "title": "Circle detection using electro-magnetism optimization", 
    "arxiv-id": "1406.0023v1", 
    "author": "Humberto Sossa", 
    "publish": "2014-05-30T21:58:36Z", 
    "summary": "This paper describes a circle detection method based on Electromagnetism-Like\nOptimization (EMO). Circle detection has received considerable attention over\nthe last years thanks to its relevance for many computer vision tasks. EMO is a\nheuristic method for solving complex optimization problems inspired in\nelectromagnetism principles. This algorithm searches a solution based in the\nattraction and repulsion among prototype candidates. In this paper the\ndetection process is considered to be similar to an optimization problem, the\nalgorithm uses the combination of three edge points (x, y, r) as parameters to\ndetermine circles candidates in the scene. An objective function determines if\nsuch circle candidates are actually present in the image. The EMO algorithm is\nused to find the circle candidate that is better related with the real circle\npresent in the image according to the objective function. The final algorithm\nis a fast circle detector that locates circles with sub-pixel accuracy even\nconsidering complicated conditions and noisy images."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2014.05.007", 
    "link": "http://arxiv.org/pdf/1406.0074v1", 
    "title": "Combined Approach for Image Segmentation", 
    "arxiv-id": "1406.0074v1", 
    "author": "Manoj B. Chandak", 
    "publish": "2014-05-31T12:35:31Z", 
    "summary": "Many image segmentation techniques have been developed over the past two\ndecades for segmenting the images, which help for object recognition, occlusion\nboundary estimation within motion or stereo systems, image compression, image\nediting.\n  In this, there is a combined approach for segmenting the image. By using\nhistogram equalization to the input image, from which it gives contrast\nenhancement output image .After that by applying median filtering,which will\nremove noise from contrast output image . At last I applied fuzzy c-mean\nclustering algorithm to denoising output image, which give segmented output\nimage. In this way it produce better segmented image with less computation\ntime."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2014.05.007", 
    "link": "http://arxiv.org/pdf/1406.0132v1", 
    "title": "Seeing the Big Picture: Deep Embedding with Contextual Evidences", 
    "arxiv-id": "1406.0132v1", 
    "author": "Qi Tian", 
    "publish": "2014-06-01T05:04:28Z", 
    "summary": "In the Bag-of-Words (BoW) model based image retrieval task, the precision of\nvisual matching plays a critical role in improving retrieval performance.\nConventionally, local cues of a keypoint are employed. However, such strategy\ndoes not consider the contextual evidences of a keypoint, a problem which would\nlead to the prevalence of false matches. To address this problem, this paper\ndefines \"true match\" as a pair of keypoints which are similar on three levels,\ni.e., local, regional, and global. Then, a principled probabilistic framework\nis established, which is capable of implicitly integrating discriminative cues\nfrom all these feature levels.\n  Specifically, the Convolutional Neural Network (CNN) is employed to extract\nfeatures from regional and global patches, leading to the so-called \"Deep\nEmbedding\" framework. CNN has been shown to produce excellent performance on a\ndozen computer vision tasks such as image classification and detection, but few\nworks have been done on BoW based image retrieval. In this paper, firstly we\nshow that proper pre-processing techniques are necessary for effective usage of\nCNN feature. Then, in the attempt to fit it into our model, a novel indexing\nstructure called \"Deep Indexing\" is introduced, which dramatically reduces\nmemory usage.\n  Extensive experiments on three benchmark datasets demonstrate that, the\nproposed Deep Embedding method greatly promotes the retrieval accuracy when CNN\nfeature is integrated. We show that our method is efficient in terms of both\nmemory and time cost, and compares favorably with the state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2014.05.007", 
    "link": "http://arxiv.org/pdf/1406.0231v1", 
    "title": "Ambiguous Proximity Distribution", 
    "arxiv-id": "1406.0231v1", 
    "author": "Yongping Li", 
    "publish": "2014-06-02T01:44:50Z", 
    "summary": "Proximity Distribution Kernel is an effective method for bag-of-featues based\nimage representation. In this paper, we investigate the soft assignment of\nvisual words to image features for proximity distribution. Visual word\ncontribution function is proposed to model ambiguous proximity distributions.\nThree ambiguous proximity distributions is developed by three ambiguous\ncontribution functions. The experiments are conducted on both classification\nand retrieval of medical image data sets. The results show that the performance\nof the proposed methods, Proximity Distribution Kernel (PDK), is better or\ncomparable to the state-of-the-art bag-of-features based image representation\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-014-0758-9", 
    "link": "http://arxiv.org/pdf/1406.0288v1", 
    "title": "Continuous Action Recognition Based on Sequence Alignment", 
    "arxiv-id": "1406.0288v1", 
    "author": "Radu Horaud", 
    "publish": "2014-06-02T08:21:27Z", 
    "summary": "Continuous action recognition is more challenging than isolated recognition\nbecause classification and segmentation must be simultaneously carried out. We\nbuild on the well known dynamic time warping (DTW) framework and devise a novel\nvisual alignment technique, namely dynamic frame warping (DFW), which performs\nisolated recognition based on per-frame representation of videos, and on\naligning a test sequence with a model sequence. Moreover, we propose two\nextensions which enable to perform recognition concomitant with segmentation,\nnamely one-pass DFW and two-pass DFW. These two methods have their roots in the\ndomain of continuous recognition of speech and, to the best of our knowledge,\ntheir extension to continuous visual action recognition has been overlooked. We\ntest and illustrate the proposed techniques with a recently released dataset\n(RAVEL) and with two public-domain datasets widely used in action recognition\n(Hollywood-1 and Hollywood-2). We also compare the performances of the proposed\nisolated and continuous recognition algorithms with several recently published\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-014-0758-9", 
    "link": "http://arxiv.org/pdf/1406.0289v1", 
    "title": "The constitution of visual perceptual units in the functional   architecture of V1", 
    "arxiv-id": "1406.0289v1", 
    "author": "Giovanna Citti", 
    "publish": "2014-06-02T08:27:27Z", 
    "summary": "Scope of this paper is to consider a mean field neural model which takes into\naccount the functional neurogeometry of the visual cortex modelled as a group\nof rotations and translations. The model generalizes well known results of\nBressloff and Cowan which, in absence of input, accounts for hallucination\npatterns. The main result of our study consists in showing that in presence of\na visual input, the eigenmodes of the linearized operator which become stable\nrepresent perceptual units present in the image. The result is strictly related\nto dimensionality reduction and clustering problems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-014-0758-9", 
    "link": "http://arxiv.org/pdf/1406.0312v1", 
    "title": "Generalized Max Pooling", 
    "arxiv-id": "1406.0312v1", 
    "author": "Florent Perronnin", 
    "publish": "2014-06-02T10:17:03Z", 
    "summary": "State-of-the-art patch-based image representations involve a pooling\noperation that aggregates statistics computed from local descriptors. Standard\npooling operations include sum- and max-pooling. Sum-pooling lacks\ndiscriminability because the resulting representation is strongly influenced by\nfrequent yet often uninformative descriptors, but only weakly influenced by\nrare yet potentially highly-informative ones. Max-pooling equalizes the\ninfluence of frequent and rare descriptors but is only applicable to\nrepresentations that rely on count statistics, such as the bag-of-visual-words\n(BOV) and its soft- and sparse-coding extensions. We propose a novel pooling\nmechanism that achieves the same effect as max-pooling but is applicable beyond\nthe BOV and especially to the state-of-the-art Fisher Vector -- hence the name\nGeneralized Max Pooling (GMP). It involves equalizing the similarity between\neach patch and the pooled representation, which is shown to be equivalent to\nre-weighting the per-patch statistics. We show on five public image\nclassification benchmarks that the proposed GMP can lead to significant\nperformance gains with respect to heuristic alternatives."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-014-0758-9", 
    "link": "http://arxiv.org/pdf/1406.0588v2", 
    "title": "Image retrieval with hierarchical matching pursuit", 
    "arxiv-id": "1406.0588v2", 
    "author": "Yu-Jin Zhang", 
    "publish": "2014-06-03T06:32:24Z", 
    "summary": "A novel representation of images for image retrieval is introduced in this\npaper, by using a new type of feature with remarkable discriminative power.\nDespite the multi-scale nature of objects, most existing models perform feature\nextraction on a fixed scale, which will inevitably degrade the performance of\nthe whole system. Motivated by this, we introduce a hierarchical sparse coding\narchitecture for image retrieval to explore multi-scale cues. Sparse codes\nextracted on lower layers are transmitted to higher layers recursively. With\nthis mechanism, cues from different scales are fused. Experiments on the\nHolidays dataset show that the proposed method achieves an excellent retrieval\nperformance with a small code length."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-014-0758-9", 
    "link": "http://arxiv.org/pdf/1406.0680v1", 
    "title": "Visual Reranking with Improved Image Graph", 
    "arxiv-id": "1406.0680v1", 
    "author": "Qi Tian", 
    "publish": "2014-06-03T12:07:12Z", 
    "summary": "This paper introduces an improved reranking method for the Bag-of-Words (BoW)\nbased image search. Built on [1], a directed image graph robust to outlier\ndistraction is proposed. In our approach, the relevance among images is encoded\nin the image graph, based on which the initial rank list is refined. Moreover,\nwe show that the rank-level feature fusion can be adopted in this reranking\nmethod as well. Taking advantage of the complementary nature of various\nfeatures, the reranking performance is further enhanced. Particularly, we\nexploit the reranking method combining the BoW and color information.\nExperiments on two benchmark datasets demonstrate that ourmethod yields\nsignificant improvements and the reranking results are competitive to the\nstate-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V7P254", 
    "link": "http://arxiv.org/pdf/1406.0909v1", 
    "title": "Improvement Tracking Dynamic Programming using Replication Function for   Continuous Sign Language Recognition", 
    "arxiv-id": "1406.0909v1", 
    "author": "H. R. Pourreza", 
    "publish": "2014-06-04T00:03:51Z", 
    "summary": "In this paper we used a Replication Function (R. F.)for improvement tracking\nwith dynamic programming. The R. F. transforms values of gray level [0 255] to\n[0 1]. The resulting images of R. F. are more striking and visible in skin\nregions. The R. F. improves Dynamic Programming (D. P.) in overlapping hand and\nface. Results show that Tracking Error Rate 11% and Average Tracked Distance 7%\nreduced"
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V7P254", 
    "link": "http://arxiv.org/pdf/1406.0924v3", 
    "title": "Multiscale Fields of Patterns", 
    "arxiv-id": "1406.0924v3", 
    "author": "John G. Oberlin", 
    "publish": "2014-06-04T02:10:58Z", 
    "summary": "We describe a framework for defining high-order image models that can be used\nin a variety of applications. The approach involves modeling local patterns in\na multiscale representation of an image. Local properties of a coarsened image\nreflect non-local properties of the original image. In the case of binary\nimages local properties are defined by the binary patterns observed over small\nneighborhoods around each pixel. With the multiscale representation we capture\nthe frequency of patterns observed at different scales of resolution. This\nframework leads to expressive priors that depend on a relatively small number\nof parameters. For inference and learning we use an MCMC method for block\nsampling with very large blocks. We evaluate the approach with two example\napplications. One involves contour detection. The other involves binary\nsegmentation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2346232", 
    "link": "http://arxiv.org/pdf/1406.0946v1", 
    "title": "Beyond $\u03c7^2$ Difference: Learning Optimal Metric for Boundary   Detection", 
    "arxiv-id": "1406.0946v1", 
    "author": "Shengjin Wang", 
    "publish": "2014-06-04T05:58:53Z", 
    "summary": "This letter focuses on solving the challenging problem of detecting natural\nimage boundaries. A boundary usually refers to the border between two regions\nwith different semantic meanings. Therefore, a measurement of dissimilarity\nbetween image regions plays a pivotal role in boundary detection of natural\nimages. To improve the performance of boundary detection, a Learning-based\nBoundary Metric (LBM) is proposed to replace $\\chi^2$ difference adopted by the\nclassical algorithm mPb. Compared with $\\chi^2$ difference, LBM is composed of\na single layer neural network and an RBF kernel, and is fine-tuned by\nsupervised learning rather than human-crafted. It is more effective in\ndescribing the dissimilarity between natural image regions while tolerating\nlarge variance of image data. After substituting $\\chi^2$ difference with LBM,\nthe F-measure metric of mPb on the BSDS500 benchmark is increased from 0.69 to\n0.71. Moreover, when image features are computed on a single scale, the\nproposed LBM algorithm still achieves competitive results compared with\n\\emph{mPb}, which makes use of multi-scale image features."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2346232", 
    "link": "http://arxiv.org/pdf/1406.1134v2", 
    "title": "Local Decorrelation For Improved Detection", 
    "arxiv-id": "1406.1134v2", 
    "author": "Joon Hee Han", 
    "publish": "2014-06-04T18:20:38Z", 
    "summary": "Even with the advent of more sophisticated, data-hungry methods, boosted\ndecision trees remain extraordinarily successful for fast rigid object\ndetection, achieving top accuracy on numerous datasets. While effective, most\nboosted detectors use decision trees with orthogonal (single feature) splits,\nand the topology of the resulting decision boundary may not be well matched to\nthe natural topology of the data. Given highly correlated data, decision trees\nwith oblique (multiple feature) splits can be effective. Use of oblique splits,\nhowever, comes at considerable computational expense. Inspired by recent work\non discriminative decorrelation of HOG features, we instead propose an\nefficient feature transform that removes correlations in local neighborhoods.\nThe result is an overcomplete but locally decorrelated representation ideally\nsuited for use with orthogonal decision trees. In fact, orthogonal trees with\nour locally decorrelated features outperform oblique trees trained over the\noriginal features at a fraction of the computational cost. The overall\nimprovement in accuracy is dramatic: on the Caltech Pedestrian Dataset, we\nreduce false positives nearly tenfold over the previous state-of-the-art."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2014.2346232", 
    "link": "http://arxiv.org/pdf/1406.1247v1", 
    "title": "Shared Representation Learning for Heterogeneous Face Recognition", 
    "arxiv-id": "1406.1247v1", 
    "author": "Stan Z. Li", 
    "publish": "2014-06-05T00:23:10Z", 
    "summary": "After intensive research, heterogenous face recognition is still a\nchallenging problem. The main difficulties are owing to the complex\nrelationship between heterogenous face image spaces. The heterogeneity is\nalways tightly coupled with other variations, which makes the relationship of\nheterogenous face images highly nonlinear. Many excellent methods have been\nproposed to model the nonlinear relationship, but they apt to overfit to the\ntraining set, due to limited samples. Inspired by the unsupervised algorithms\nin deep learning, this paper proposes an novel framework for heterogeneous face\nrecognition. We first extract Gabor features at some localized facial points,\nand then use Restricted Boltzmann Machines (RBMs) to learn a shared\nrepresentation locally to remove the heterogeneity around each facial point.\nFinally, the shared representations of local RBMs are connected together and\nprocessed by PCA. Two problems (Sketch-Photo and NIR-VIS) and three databases\nare selected to evaluate the proposed method. For Sketch-Photo problem, we\nobtain perfect results on the CUFS database. For NIR-VIS problem, we produce\nnew state-of-the-art performance on the CASIA HFB and NIR-VIS 2.0 databases."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.1476v5", 
    "title": "A Context-aware Delayed Agglomeration Framework for Electron Microscopy   Segmentation", 
    "arxiv-id": "1406.1476v5", 
    "author": "Lou Scheffer", 
    "publish": "2014-06-05T18:46:38Z", 
    "summary": "Electron Microscopy (EM) image (or volume) segmentation has become\nsignificantly important in recent years as an instrument for connectomics. This\npaper proposes a novel agglomerative framework for EM segmentation. In\nparticular, given an over-segmented image or volume, we propose a novel\nframework for accurately clustering regions of the same neuron. Unlike existing\nagglomerative methods, the proposed context-aware algorithm divides superpixels\n(over-segmented regions) of different biological entities into different\nsubsets and agglomerates them separately. In addition, this paper describes a\n\"delayed\" scheme for agglomerative clustering that postpones some of the merge\ndecisions, pertaining to newly formed bodies, in order to generate a more\nconfident boundary prediction. We report significant improvements attained by\nthe proposed approach in segmentation accuracy over existing standard methods\non 2D and 3D datasets."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.1774v2", 
    "title": "Small Sample Learning of Superpixel Classifiers for EM Segmentation-   Extended Version", 
    "arxiv-id": "1406.1774v2", 
    "author": "Louis Scheffer", 
    "publish": "2014-06-06T18:59:58Z", 
    "summary": "Pixel and superpixel classifiers have become essential tools for EM\nsegmentation algorithms. Training these classifiers remains a major bottleneck\nprimarily due to the requirement of completely annotating the dataset which is\ntedious, error-prone and costly. In this paper, we propose an interactive\nlearning scheme for the superpixel classifier for EM segmentation. Our\nalgorithm is \"active semi-supervised\" because it requests the labels of a small\nnumber of examples from user and applies label propagation technique to\ngenerate these queries. Using only a small set ($<20\\%$) of all datapoints, the\nproposed algorithm consistently generates a classifier almost as accurate as\nthat estimated from a complete groundtruth. We provide segmentation results on\nmultiple datasets to show the strength of these classifiers."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.1881v2", 
    "title": "Fine-grained Activity Recognition with Holistic and Pose based Features", 
    "arxiv-id": "1406.1881v2", 
    "author": "Bernt Schiele", 
    "publish": "2014-06-07T10:07:24Z", 
    "summary": "Holistic methods based on dense trajectories are currently the de facto\nstandard for recognition of human activities in video. Whether holistic\nrepresentations will sustain or will be superseded by higher level video\nencoding in terms of body pose and motion is the subject of an ongoing debate.\nIn this paper we aim to clarify the underlying factors responsible for good\nperformance of holistic and pose-based representations. To that end we build on\nour recent dataset leveraging the existing taxonomy of human activities. This\ndataset includes 24,920 video snippets covering 410 human activities in total.\nOur analysis reveals that holistic and pose-based methods are highly\ncomplementary, and their performance varies significantly depending on the\nactivity. We find that holistic methods are mostly affected by the number and\nspeed of trajectories, whereas pose-based methods are mostly influenced by\nviewpoint of the person. We observe striking performance differences across\nactivities: for certain activities results with pose-based features are more\nthan twice as accurate compared to holistic features, and vice versa. The best\nperforming approach in our comparison is based on the combination of holistic\nand pose-based approaches, which again underlines their complementarity."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.1906v1", 
    "title": "Refinement-Cut: User-Guided Segmentation Algorithm for Translational   Science", 
    "arxiv-id": "1406.1906v1", 
    "author": "Jan Egger", 
    "publish": "2014-06-07T17:11:00Z", 
    "summary": "In this contribution, a semi-automatic segmentation algorithm for (medical)\nimage analysis is presented. More precise, the approach belongs to the category\nof interactive contouring algorithms, which provide real-time feedback of the\nsegmentation result. However, even with interactive real-time contouring\napproaches there are always cases where the user cannot find a satisfying\nsegmentation, e.g. due to homogeneous appearances between the object and the\nbackground, or noise inside the object. For these difficult cases the algorithm\nstill needs additional user support. However, this additional user support\nshould be intuitive and rapid integrated into the segmentation process, without\nbreaking the interactive real-time segmentation feedback. I propose a solution\nwhere the user can support the algorithm by an easy and fast placement of one\nor more seed points to guide the algorithm to a satisfying segmentation result\nalso in difficult cases. These additional seed(s) restrict(s) the calculation\nof the segmentation for the algorithm, but at the same time, still enable to\ncontinue with the interactive real-time feedback segmentation. For a practical\nand genuine application in translational science, the approach has been tested\non medical data from the clinical routine in 2D and 3D."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.1925v1", 
    "title": "Shape-from-intrinsic operator", 
    "arxiv-id": "1406.1925v1", 
    "author": "Michael M. Bronstein", 
    "publish": "2014-06-07T19:33:28Z", 
    "summary": "Shape-from-X is an important class of problems in the fields of geometry\nprocessing, computer graphics, and vision, attempting to recover the structure\nof a shape from some observations. In this paper, we formulate the problem of\nshape-from-operator (SfO), recovering an embedding of a mesh from intrinsic\ndifferential operators defined on the mesh. Particularly interesting instances\nof our SfO problem include synthesis of shape analogies, shape-from-Laplacian\nreconstruction, and shape exaggeration. Numerically, we approach the SfO\nproblem by splitting it into two optimization sub-problems that are applied in\nan alternating scheme: metric-from-operator (reconstruction of the discrete\nmetric from the intrinsic operator) and embedding-from-metric (finding a shape\nembedding that would realize a given metric, a setting of the multidimensional\nscaling problem)."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.1943v1", 
    "title": "Structured Dictionary Learning for Classification", 
    "arxiv-id": "1406.1943v1", 
    "author": "Trac D. Tran", 
    "publish": "2014-06-08T02:51:45Z", 
    "summary": "Sparsity driven signal processing has gained tremendous popularity in the\nlast decade. At its core, the assumption is that the signal of interest is\nsparse with respect to either a fixed transformation or a signal dependent\ndictionary. To better capture the data characteristics, various dictionary\nlearning methods have been proposed for both reconstruction and classification\ntasks. For classification particularly, most approaches proposed so far have\nfocused on designing explicit constraints on the sparse code to improve\nclassification accuracy while simply adopting $l_0$-norm or $l_1$-norm for\nsparsity regularization. Motivated by the success of structured sparsity in the\narea of Compressed Sensing, we propose a structured dictionary learning\nframework (StructDL) that incorporates the structure information on both group\nand task levels in the learning process. Its benefits are two-fold: (i) the\nlabel consistency between dictionary atoms and training data are implicitly\nenforced; and (ii) the classification performance is more robust in the cases\nof a small dictionary size or limited training data than other techniques.\nUsing the subspace model, we derive the conditions for StructDL to guarantee\nthe performance and show theoretically that StructDL is superior to $l_0$-norm\nor $l_1$-norm regularized dictionary learning for classification. Extensive\nexperiments have been performed on both synthetic simulations and real world\napplications, such as face recognition and object classification, to\ndemonstrate the validity of the proposed DL framework."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0125825", 
    "link": "http://arxiv.org/pdf/1406.2031v1", 
    "title": "Detect What You Can: Detecting and Representing Objects using Holistic   Models and Body Parts", 
    "arxiv-id": "1406.2031v1", 
    "author": "Alan Yuille", 
    "publish": "2014-06-08T21:44:18Z", 
    "summary": "Detecting objects becomes difficult when we need to deal with large shape\ndeformation, occlusion and low resolution. We propose a novel approach to i)\nhandle large deformations and partial occlusions in animals (as examples of\nhighly deformable objects), ii) describe them in terms of body parts, and iii)\ndetect them when their body parts are hard to detect (e.g., animals depicted at\nlow resolution). We represent the holistic object and body parts separately and\nuse a fully connected model to arrange templates for the holistic object and\nbody parts. Our model automatically decouples the holistic object or body parts\nfrom the model when they are hard to detect. This enables us to represent a\nlarge number of holistic object and body part combinations to better deal with\ndifferent \"detectability\" patterns caused by deformations, occlusion and/or low\nresolution.\n  We apply our method to the six animal categories in the PASCAL VOC dataset\nand show that our method significantly improves state-of-the-art (by 4.1% AP)\nand provides a richer representation for objects. During training we use\nannotations for body parts (e.g., head, torso, etc), making use of a new\ndataset of fully annotated object parts for PASCAL VOC 2010, which provides a\nmask for each part."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2139v3", 
    "title": "Log-Euclidean Bag of Words for Human Action Recognition", 
    "arxiv-id": "1406.2139v3", 
    "author": "Conrad Sanderson", 
    "publish": "2014-06-09T11:14:03Z", 
    "summary": "Representing videos by densely extracted local space-time features has\nrecently become a popular approach for analysing actions. In this paper, we\ntackle the problem of categorising human actions by devising Bag of Words (BoW)\nmodels based on covariance matrices of spatio-temporal features, with the\nfeatures formed from histograms of optical flow. Since covariance matrices form\na special type of Riemannian manifold, the space of Symmetric Positive Definite\n(SPD) matrices, non-Euclidean geometry should be taken into account while\ndiscriminating between covariance matrices. To this end, we propose to embed\nSPD manifolds to Euclidean spaces via a diffeomorphism and extend the BoW\napproach to its Riemannian version. The proposed BoW approach takes into\naccount the manifold geometry of SPD matrices during the generation of the\ncodebook and histograms. Experiments on challenging human action datasets show\nthat the proposed method obtains notable improvements in discrimination\naccuracy, in comparison to several state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2199v2", 
    "title": "Two-Stream Convolutional Networks for Action Recognition in Videos", 
    "arxiv-id": "1406.2199v2", 
    "author": "Andrew Zisserman", 
    "publish": "2014-06-09T14:44:14Z", 
    "summary": "We investigate architectures of discriminatively trained deep Convolutional\nNetworks (ConvNets) for action recognition in video. The challenge is to\ncapture the complementary information on appearance from still frames and\nmotion between frames. We also aim to generalise the best performing\nhand-crafted features within a data-driven learning framework.\n  Our contribution is three-fold. First, we propose a two-stream ConvNet\narchitecture which incorporates spatial and temporal networks. Second, we\ndemonstrate that a ConvNet trained on multi-frame dense optical flow is able to\nachieve very good performance in spite of limited training data. Finally, we\nshow that multi-task learning, applied to two different action classification\ndatasets, can be used to increase the amount of training data and improve the\nperformance on both.\n  Our architecture is trained and evaluated on the standard video actions\nbenchmarks of UCF-101 and HMDB-51, where it is competitive with the state of\nthe art. It also exceeds by a large margin previous attempts to use deep nets\nfor video classification."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2227v4", 
    "title": "Synthetic Data and Artificial Neural Networks for Natural Scene Text   Recognition", 
    "arxiv-id": "1406.2227v4", 
    "author": "Andrew Zisserman", 
    "publish": "2014-06-09T15:53:33Z", 
    "summary": "In this work we present a framework for the recognition of natural scene\ntext. Our framework does not require any human-labelled data, and performs word\nrecognition on the whole image holistically, departing from the character based\nrecognition systems of the past. The deep neural network models at the centre\nof this framework are trained solely on data produced by a synthetic text\ngeneration engine -- synthetic data that is highly realistic and sufficient to\nreplace real data, giving us infinite amounts of training data. This excess of\ndata exposes new possibilities for word recognition models, and here we\nconsider three models, each one \"reading\" words in a different way: via 90k-way\ndictionary encoding, character sequence encoding, and bag-of-N-grams encoding.\nIn the scenarios of language based and completely unconstrained text\nrecognition we greatly improve upon state-of-the-art performance on standard\ndatasets, using our fast, simple machinery and requiring zero data-acquisition\ncosts."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2282v1", 
    "title": "Robust Estimation of 3D Human Poses from a Single Image", 
    "arxiv-id": "1406.2282v1", 
    "author": "Wen Gao", 
    "publish": "2014-06-09T18:55:31Z", 
    "summary": "Human pose estimation is a key step to action recognition. We propose a\nmethod of estimating 3D human poses from a single image, which works in\nconjunction with an existing 2D pose/joint detector. 3D pose estimation is\nchallenging because multiple 3D poses may correspond to the same 2D pose after\nprojection due to the lack of depth information. Moreover, current 2D pose\nestimators are usually inaccurate which may cause errors in the 3D estimation.\nWe address the challenges in three ways: (i) We represent a 3D pose as a linear\ncombination of a sparse set of bases learned from 3D human skeletons. (ii) We\nenforce limb length constraints to eliminate anthropomorphically implausible\nskeletons. (iii) We estimate a 3D pose by minimizing the $L_1$-norm error\nbetween the projection of the 3D pose and the corresponding 2D detection. The\n$L_1$-norm loss term is robust to inaccurate 2D joint estimations. We use the\nalternating direction method (ADM) to solve the optimization problem\nefficiently. Our approach outperforms the state-of-the-arts on three benchmark\ndatasets."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2283v1", 
    "title": "Depth Map Prediction from a Single Image using a Multi-Scale Deep   Network", 
    "arxiv-id": "1406.2283v1", 
    "author": "Rob Fergus", 
    "publish": "2014-06-09T19:01:18Z", 
    "summary": "Predicting depth is an essential component in understanding the 3D geometry\nof a scene. While for stereo images local correspondence suffices for\nestimation, finding depth relations from a single image is less\nstraightforward, requiring integration of both global and local information\nfrom various cues. Moreover, the task is inherently ambiguous, with a large\nsource of uncertainty coming from the overall scale. In this paper, we present\na new method that addresses this task by employing two deep network stacks: one\nthat makes a coarse global prediction based on the entire image, and another\nthat refines this prediction locally. We also apply a scale-invariant error to\nhelp measure depth relations rather than scale. By leveraging the raw datasets\nas large sources of training data, our method achieves state-of-the-art results\non both NYU Depth and KITTI, and matches detailed depth boundaries without the\nneed for superpixelation."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2375v2", 
    "title": "Parsing Semantic Parts of Cars Using Graphical Models and Segment   Appearance Consistency", 
    "arxiv-id": "1406.2375v2", 
    "author": "Alan Yuille", 
    "publish": "2014-06-09T22:16:57Z", 
    "summary": "This paper addresses the problem of semantic part parsing (segmentation) of\ncars, i.e.assigning every pixel within the car to one of the parts (e.g.body,\nwindow, lights, license plates and wheels). We formulate this as a landmark\nidentification problem, where a set of landmarks specifies the boundaries of\nthe parts. A novel mixture of graphical models is proposed, which dynamically\ncouples the landmarks to a hierarchy of segments. When modeling pairwise\nrelation between landmarks, this coupling enables our model to exploit the\nlocal image contents in addition to spatial deformation, an aspect that most\nexisting graphical models ignore. In particular, our model enforces appearance\nconsistency between segments within the same part. Parsing the car, including\nfinding the optimal coupling between landmarks and segments in the hierarchy,\nis performed by dynamic programming. We evaluate our method on a subset of\nPASCAL VOC 2010 car images and on the car subset of 3D Object Category dataset\n(CAR3D). We show good results and, in particular, quantify the effectiveness of\nusing the segment appearance consistency in terms of accuracy of part\nlocalization and segmentation."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2407v1", 
    "title": "Optimization Methods for Convolutional Sparse Coding", 
    "arxiv-id": "1406.2407v1", 
    "author": "Simon Lucey", 
    "publish": "2014-06-10T02:41:03Z", 
    "summary": "Sparse and convolutional constraints form a natural prior for many\noptimization problems that arise from physical processes. Detecting motifs in\nspeech and musical passages, super-resolving images, compressing videos, and\nreconstructing harmonic motions can all leverage redundancies introduced by\nconvolution. Solving problems involving sparse and convolutional constraints\nremains a difficult computational problem, however. In this paper we present an\noverview of convolutional sparse coding in a consistent framework. The\nobjective involves iteratively optimizing a convolutional least-squares term\nfor the basis functions, followed by an L1-regularized least squares term for\nthe sparse coefficients. We discuss a range of optimization methods for solving\nthe convolutional sparse coding objective, and the properties that make each\nmethod suitable for different applications. In particular, we concentrate on\ncomputational complexity, speed to {\\epsilon} convergence, memory usage, and\nthe effect of implied boundary conditions. We present a broad suite of examples\ncovering different signal and application domains to illustrate the general\napplicability of convolutional sparse coding, and the efficacy of the available\noptimization methods."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2807v2", 
    "title": "The Secrets of Salient Object Segmentation", 
    "arxiv-id": "1406.2807v2", 
    "author": "Alan L. Yuille", 
    "publish": "2014-06-11T07:46:03Z", 
    "summary": "In this paper we provide an extensive evaluation of fixation prediction and\nsalient object segmentation algorithms as well as statistics of major datasets.\nOur analysis identifies serious design flaws of existing salient object\nbenchmarks, called the dataset design bias, by over emphasizing the\nstereotypical concepts of saliency. The dataset design bias does not only\ncreate the discomforting disconnection between fixations and salient object\nsegmentation, but also misleads the algorithm designing. Based on our analysis,\nwe propose a new high quality dataset that offers both fixation and salient\nobject segmentation ground-truth. With fixations and salient object being\npresented simultaneously, we are able to bridge the gap between fixations and\nsalient objects, and propose a novel method for salient object segmentation.\nFinally, we report significant benchmark progress on three existing datasets of\nsegmenting salient objects"
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2952v1", 
    "title": "Bird Species Categorization Using Pose Normalized Deep Convolutional   Nets", 
    "arxiv-id": "1406.2952v1", 
    "author": "Pietro Perona", 
    "publish": "2014-06-11T16:14:42Z", 
    "summary": "We propose an architecture for fine-grained visual categorization that\napproaches expert human performance in the classification of bird species. Our\narchitecture first computes an estimate of the object's pose; this is used to\ncompute local image features which are, in turn, used for classification. The\nfeatures are computed by applying deep convolutional nets to image patches that\nare located and normalized by the pose. We perform an empirical study of a\nnumber of pose normalization schemes, including an investigation of higher\norder geometric warping functions. We propose a novel graph-based clustering\nalgorithm for learning a compact pose normalization space. We perform a\ndetailed investigation of state-of-the-art deep convolutional feature\nimplementations and fine-tuning feature learning for fine-grained\nclassification. We observe that a model that integrates lower-level feature\nlayers with pose-normalized extraction routines and higher-level feature layers\nwith unaligned image features works best. Our experiments advance\nstate-of-the-art performance on bird species recognition, with a large\nimprovement of correct classification rates over previous methods (75% vs.\n55-65%)."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.2984v2", 
    "title": "Joint Training of a Convolutional Network and a Graphical Model for   Human Pose Estimation", 
    "arxiv-id": "1406.2984v2", 
    "author": "Christoph Bregler", 
    "publish": "2014-06-11T18:16:29Z", 
    "summary": "This paper proposes a new hybrid architecture that consists of a deep\nConvolutional Network and a Markov Random Field. We show how this architecture\nis successfully applied to the challenging problem of articulated human pose\nestimation in monocular images. The architecture can exploit structural domain\nconstraints such as geometric relationships between body joint locations. We\nshow that joint training of these two model paradigms improves performance and\nallows us to significantly outperform existing state-of-the-art techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.3418v1", 
    "title": "Fingers' Angle Calculation using Level-Set Method", 
    "arxiv-id": "1406.3418v1", 
    "author": "S. Raheja", 
    "publish": "2014-06-13T04:33:46Z", 
    "summary": "In the current age, use of natural communication in human computer\ninteraction is a known and well installed thought. Hand gesture recognition and\ngesture based applications has gained a significant amount of popularity\namongst people all over the world. It has a number of applications ranging from\nsecurity to entertainment. These applications generally are real time\napplications and need fast, accurate communication with machines. On the other\nend, gesture based communications have few limitations also like bent finger\ninformation is not provided in vision based techniques. In this paper, a novel\nmethod for fingertip detection and for angle calculation of both hands bent\nfingers is discussed. Angle calculation has been done before with sensor based\ngloves/devices. This study has been conducted in the context of natural\ncomputing for calculating angles without using any wired equipment, colors,\nmarker or any device. The pre-processing and segmentation of the region of\ninterest is performed in a HSV color space and a binary format respectively.\nFingertips are detected using level-set method and angles were calculated using\ngeometrical analysis. This technique requires no training for system to perform\nthe task."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-cvi.2014.0018", 
    "link": "http://arxiv.org/pdf/1406.3906v1", 
    "title": "Human-Machine CRFs for Identifying Bottlenecks in Holistic Scene   Understanding", 
    "arxiv-id": "1406.3906v1", 
    "author": "Devi Parikh", 
    "publish": "2014-06-16T05:37:17Z", 
    "summary": "Recent trends in image understanding have pushed for holistic scene\nunderstanding models that jointly reason about various tasks such as object\ndetection, scene recognition, shape analysis, contextual reasoning, and local\nappearance based classifiers. In this work, we are interested in understanding\nthe roles of these different tasks in improved scene understanding, in\nparticular semantic segmentation, object detection and scene recognition.\nTowards this goal, we \"plug-in\" human subjects for each of the various\ncomponents in a state-of-the-art conditional random field model. Comparisons\namong various hybrid human-machine CRFs give us indications of how much \"head\nroom\" there is to improve scene understanding by focusing research efforts on\nvarious individual tasks."
},{
    "category": "cs.CV", 
    "doi": "10.5829/idosi.wasj.2014.31.06.353", 
    "link": "http://arxiv.org/pdf/1406.3949v1", 
    "title": "A Fusion of Labeled-Grid Shape Descriptors with Weighted Ranking   Algorithm for Shapes Recognition", 
    "arxiv-id": "1406.3949v1", 
    "author": "Shoaib Muhammad Khan", 
    "publish": "2014-06-16T09:50:04Z", 
    "summary": "Retrieving similar images from a large dataset based on the image content has\nbeen a very active research area and is a very challenging task. Studies have\nshown that retrieving similar images based on their shape is a very effective\nmethod. For this purpose a large number of methods exist in literature. The\ncombination of more than one feature has also been investigated for this\npurpose and has shown promising results. In this paper a fusion based shapes\nrecognition method has been proposed. A set of local boundary based and region\nbased features are derived from the labeled grid based representation of the\nshape and are combined with a few global shape features to produce a composite\nshape descriptor. This composite shape descriptor is then used in a weighted\nranking algorithm to find similarities among shapes from a large dataset. The\nexperimental analysis has shown that the proposed method is powerful enough to\ndiscriminate the geometrically similar shapes from the non-similar ones."
},{
    "category": "cs.CV", 
    "doi": "10.5829/idosi.wasj.2014.31.06.353", 
    "link": "http://arxiv.org/pdf/1406.4007v1", 
    "title": "Impact of Exponent Parameter Value for the Partition Matrix on the   Performance of Fuzzy C Means Algorithm", 
    "arxiv-id": "1406.4007v1", 
    "author": "Anil Kumar Gupta", 
    "publish": "2014-06-16T13:22:18Z", 
    "summary": "Soft Clustering plays a very important rule on clustering real world data\nwhere a data item contributes to more than one cluster. Fuzzy logic based\nalgorithms are always suitable for performing soft clustering tasks. Fuzzy C\nMeans (FCM) algorithm is a very popular fuzzy logic based algorithm. In case of\nfuzzy logic based algorithm, the parameter like exponent for the partition\nmatrix that we have to fix for the clustering task plays a very important rule\non the performance of the algorithm. In this paper, an experimental analysis is\ndone on FCM algorithm to observe the impact of this parameter on the\nperformance of the algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5829/idosi.wasj.2014.31.06.353", 
    "link": "http://arxiv.org/pdf/1406.4216v2", 
    "title": "Person Re-identification by Local Maximal Occurrence Representation and   Metric Learning", 
    "arxiv-id": "1406.4216v2", 
    "author": "Stan Z. Li", 
    "publish": "2014-06-17T01:53:37Z", 
    "summary": "Person re-identification is an important technique towards automatic search\nof a person's presence in a surveillance video. Two fundamental problems are\ncritical for person re-identification, feature representation and metric\nlearning. An effective feature representation should be robust to illumination\nand viewpoint changes, and a discriminant metric should be learned to match\nvarious person images. In this paper, we propose an effective feature\nrepresentation called Local Maximal Occurrence (LOMO), and a subspace and\nmetric learning method called Cross-view Quadratic Discriminant Analysis\n(XQDA). The LOMO feature analyzes the horizontal occurrence of local features,\nand maximizes the occurrence to make a stable representation against viewpoint\nchanges. Besides, to handle illumination variations, we apply the Retinex\ntransform and a scale invariant texture operator. To learn a discriminant\nmetric, we propose to learn a discriminant low dimensional subspace by\ncross-view quadratic discriminant analysis, and simultaneously, a QDA metric is\nlearned on the derived subspace. We also present a practical computation method\nfor XQDA, as well as its regularization. Experiments on four challenging person\nre-identification databases, VIPeR, QMUL GRID, CUHK Campus, and CUHK03, show\nthat the proposed method improves the state-of-the-art rank-1 identification\nrates by 2.2%, 4.88%, 28.91%, and 31.55% on the four databases, respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5829/idosi.wasj.2014.31.06.353", 
    "link": "http://arxiv.org/pdf/1406.4484v1", 
    "title": "Block matching algorithm based on Harmony Search optimization for motion   estimation", 
    "arxiv-id": "1406.4484v1", 
    "author": "Erik Cuevas", 
    "publish": "2014-06-17T19:13:40Z", 
    "summary": "Motion estimation is one of the major problems in developing video coding\napplications. Among all motion estimation approaches, Block-matching (BM)\nalgorithms are the most popular methods due to their effectiveness and\nsimplicity for both software and hardware implementations. A BM approach\nassumes that the movement of pixels within a defined region of the current\nframe can be modeled as a translation of pixels contained in the previous\nframe. In this procedure, the motion vector is obtained by minimizing a certain\nmatching metric that is produced for the current frame over a determined search\nwindow from the previous frame. Unfortunately, the evaluation of such matching\nmeasurement is computationally expensive and represents the most consuming\noperation in the BM process. Therefore, BM motion estimation can be viewed as\nan optimization problem whose goal is to find the best-matching block within a\nsearch space. The simplest available BM method is the Full Search Algorithm\n(FSA) which finds the most accurate motion vector through an exhaustive\ncomputation of all the elements of the search space. Recently, several fast BM\nalgorithms have been proposed to reduce the search positions by calculating\nonly a fixed subset of motion vectors despite lowering its accuracy. On the\nother hand, the Harmony Search (HS) algorithm is a population-based\noptimization method that is inspired by the music improvisation process in\nwhich a musician searches for harmony and continues to polish the pitches to\nobtain a better harmony. In this paper, a new BM algorithm that combines HS\nwith a fitness approximation model is proposed. The approach uses motion\nvectors belonging to the search window as potential solutions. A fitness\nfunction evaluates the matching quality of each motion vector candidate."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-10578-9_23", 
    "link": "http://arxiv.org/pdf/1406.4729v4", 
    "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual   Recognition", 
    "arxiv-id": "1406.4729v4", 
    "author": "Jian Sun", 
    "publish": "2014-06-18T14:24:17Z", 
    "summary": "Existing deep convolutional neural networks (CNNs) require a fixed-size\n(e.g., 224x224) input image. This requirement is \"artificial\" and may reduce\nthe recognition accuracy for the images or sub-images of an arbitrary\nsize/scale. In this work, we equip the networks with another pooling strategy,\n\"spatial pyramid pooling\", to eliminate the above requirement. The new network\nstructure, called SPP-net, can generate a fixed-length representation\nregardless of image size/scale. Pyramid pooling is also robust to object\ndeformations. With these advantages, SPP-net should in general improve all\nCNN-based image classification methods. On the ImageNet 2012 dataset, we\ndemonstrate that SPP-net boosts the accuracy of a variety of CNN architectures\ndespite their different designs. On the Pascal VOC 2007 and Caltech101\ndatasets, SPP-net achieves state-of-the-art classification results using a\nsingle full-image representation and no fine-tuning.\n  The power of SPP-net is also significant in object detection. Using SPP-net,\nwe compute the feature maps from the entire image only once, and then pool\nfeatures in arbitrary regions (sub-images) to generate fixed-length\nrepresentations for training the detectors. This method avoids repeatedly\ncomputing the convolutional features. In processing test images, our method is\n24-102x faster than the R-CNN method, while achieving better or comparable\naccuracy on Pascal VOC 2007.\n  In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our\nmethods rank #2 in object detection and #3 in image classification among all 38\nteams. This manuscript also introduces the improvement made for this\ncompetition."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-10578-9_23", 
    "link": "http://arxiv.org/pdf/1406.4770v1", 
    "title": "Mass Classification Method in Mammogram Using Fuzzy K-Nearest Neighbour   Equality", 
    "arxiv-id": "1406.4770v1", 
    "author": "K. Thangavel", 
    "publish": "2014-06-18T15:38:46Z", 
    "summary": "Mass classification of objects is an important area of research and\napplication in a variety of fields. In this paper, we present an efficient\ncomputer aided mass classification method in digitized mammograms using Fuzzy\nK-Nearest Neighbor Equality, which performs benign or malignant classification\non region of interest that contains mass. One of the major mammographic\ncharacteristics for mass classification is texture. Fuzzy K-Nearest Neighbor\nEquality exploits this important factor to classify the mass into benign or\nmalignant. The statistical textural features used in characterizing the masses\nare Haralick and Run length features. The main aim of the method is to increase\nthe effectiveness and efficiency of the classification process in an objective\nmanner to reduce the numbers of false positive of malignancies. In this paper\nproposes a novel Fuzzy K-Nearest Neighbor Equality algorithm for classifying\nthe marked regions into benign and malignant and 94.46 sensitivity,96.81\nspecificity and 96.52 accuracy is achieved that is very much promising compare\nto the radiologists' accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-10578-9_23", 
    "link": "http://arxiv.org/pdf/1406.4773v1", 
    "title": "Deep Learning Face Representation by Joint Identification-Verification", 
    "arxiv-id": "1406.4773v1", 
    "author": "Xiaoou Tang", 
    "publish": "2014-06-18T15:42:16Z", 
    "summary": "The key challenge of face recognition is to develop effective feature\nrepresentations for reducing intra-personal variations while enlarging\ninter-personal differences. In this paper, we show that it can be well solved\nwith deep learning and using both face identification and verification signals\nas supervision. The Deep IDentification-verification features (DeepID2) are\nlearned with carefully designed deep convolutional networks. The face\nidentification task increases the inter-personal variations by drawing DeepID2\nextracted from different identities apart, while the face verification task\nreduces the intra-personal variations by pulling DeepID2 extracted from the\nsame identity together, both of which are essential to face recognition. The\nlearned DeepID2 features can be well generalized to new identities unseen in\nthe training data. On the challenging LFW dataset, 99.15% face verification\naccuracy is achieved. Compared with the best deep learning result on LFW, the\nerror rate has been significantly reduced by 67%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-10578-9_23", 
    "link": "http://arxiv.org/pdf/1406.4845v2", 
    "title": "Computer Vision Approach for Low Cost, High Precision Measurement of   Grapevine Trunk Diameter in Outdoor Conditions", 
    "arxiv-id": "1406.4845v2", 
    "author": "Francisco Gonzalez Antivilo", 
    "publish": "2014-05-16T18:44:58Z", 
    "summary": "Trunk diameter is a variable of agricultural interest, used mainly in the\nprediction of fruit trees production. It is correlated with leaf area and\nbiomass of trees, and consequently gives a good estimate of the potential\nproduction of the plants. This work presents a low cost, high precision method\nfor the measurement of trunk diameter of grapevines based on Computer Vision\ntechniques. Several methods based on Computer Vision and other techniques are\nintroduced in the literature. These methods present different advantages for\ncrop management: they are amenable to be operated by unknowledgeable personnel,\nwith lower operational costs; they result in lower stress levels to\nknowledgeable personnel, avoiding the deterioration of the measurement quality\nover time; and they make the measurement process amenable to be embedded in\nlarger autonomous systems, allowing more measurements to be taken with\nequivalent costs. To date, all existing autonomous methods are either of low\nprecision, or have a prohibitive cost for massive agricultural adoption,\nleaving the manual Vernier caliper or tape measure as the only choice in most\nsituations. In this work we present a semi-autonomous measurement method that\nis susceptible to be fully automated, cost effective for mass adoption, and its\nprecision is competitive (with slight improvements) over the caliper manual\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-10578-9_23", 
    "link": "http://arxiv.org/pdf/1406.5035v1", 
    "title": "Why are images smooth?", 
    "arxiv-id": "1406.5035v1", 
    "author": "Uriel Feige", 
    "publish": "2014-06-19T13:25:47Z", 
    "summary": "It is a well observed phenomenon that natural images are smooth, in the sense\nthat nearby pixels tend to have similar values. We describe a mathematical\nmodel of images that makes no assumptions on the nature of the environment that\nimages depict. It only assumes that images can be taken at different scales\n(zoom levels). We provide quantitative bounds on the smoothness of a typical\nimage in our model, as a function of the number of available scales. These\nbounds can serve as a baseline against which to compare the observed smoothness\nof natural images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-10578-9_23", 
    "link": "http://arxiv.org/pdf/1406.5074v1", 
    "title": "Robust Outlier Detection Technique in Data Mining: A Univariate Approach", 
    "arxiv-id": "1406.5074v1", 
    "author": "Pathak Shivani", 
    "publish": "2014-06-19T15:12:49Z", 
    "summary": "Outliers are the points which are different from or inconsistent with the\nrest of the data. They can be novel, new, abnormal, unusual or noisy\ninformation. Outliers are sometimes more interesting than the majority of the\ndata. The main challenges of outlier detection with the increasing complexity,\nsize and variety of datasets, are how to catch similar outliers as a group, and\nhow to evaluate the outliers. This paper describes an approach which uses\nUnivariate outlier detection as a pre-processing step to detect the outlier and\nthen applies K-means algorithm hence to analyse the effects of the outliers on\nthe cluster analysis of dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5095v1", 
    "title": "MRF-based Background Initialisation for Improved Foreground Detection in   Cluttered Surveillance Videos", 
    "arxiv-id": "1406.5095v1", 
    "author": "Brian C. Lovell", 
    "publish": "2014-06-19T16:06:53Z", 
    "summary": "Robust foreground object segmentation via background modelling is a difficult\nproblem in cluttered environments, where obtaining a clear view of the\nbackground to model is almost impossible. In this paper, we propose a method\ncapable of robustly estimating the background and detecting regions of interest\nin such environments. In particular, we propose to extend the background\ninitialisation component of a recent patch-based foreground detection algorithm\nwith an elaborate technique based on Markov Random Fields, where the optimal\nlabelling solution is computed using iterated conditional modes. Rather than\nrelying purely on local temporal statistics, the proposed technique takes into\naccount the spatial continuity of the entire background. Experiments with\nseveral tracking algorithms on the CAVIAR dataset indicate that the proposed\nmethod leads to considerable improvements in object tracking accuracy, when\ncompared to methods based on Gaussian mixture models and feature histograms."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5212v1", 
    "title": "R-CNNs for Pose Estimation and Action Detection", 
    "arxiv-id": "1406.5212v1", 
    "author": "Jitendra Malik", 
    "publish": "2014-06-19T20:56:08Z", 
    "summary": "We present convolutional neural networks for the tasks of keypoint (pose)\nprediction and action classification of people in unconstrained images. Our\napproach involves training an R-CNN detector with loss functions depending on\nthe task being tackled. We evaluate our method on the challenging PASCAL VOC\ndataset and compare it to previous leading approaches. Our method gives\nstate-of-the-art results for keypoint and action prediction. Additionally, we\nintroduce a new dataset for action detection, the task of simultaneously\nlocalizing people and classifying their actions, and present results using our\napproach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5266v2", 
    "title": "Web-Scale Training for Face Identification", 
    "arxiv-id": "1406.5266v2", 
    "author": "Lior Wolf", 
    "publish": "2014-06-20T02:51:31Z", 
    "summary": "Scaling machine learning methods to very large datasets has attracted\nconsiderable attention in recent years, thanks to easy access to ubiquitous\nsensing and data from the web. We study face recognition and show that three\ndistinct properties have surprising effects on the transferability of deep\nconvolutional networks (CNN): (1) The bottleneck of the network serves as an\nimportant transfer learning regularizer, and (2) in contrast to the common\nwisdom, performance saturation may exist in CNN's (as the number of training\nsamples grows); we propose a solution for alleviating this by replacing the\nnaive random subsampling of the training set with a bootstrapping process.\nMoreover, (3) we find a link between the representation norm and the ability to\ndiscriminate in a target domain, which sheds lights on how such networks\nrepresent faces. Based on these discoveries, we are able to improve face\nrecognition accuracy on the widely used LFW benchmark, both in the verification\n(1:1) and identification (1:N) protocols, and directly compare, for the first\ntime, with the state of the art Commercially-Off-The-Shelf system and show a\nsizable leap in performance."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5309v2", 
    "title": "Early Recognition of Human Activities from First-Person Videos Using   Onset Representations", 
    "arxiv-id": "1406.5309v2", 
    "author": "Larry Matthies", 
    "publish": "2014-06-20T08:22:09Z", 
    "summary": "In this paper, we propose a methodology for early recognition of human\nactivities from videos taken with a first-person viewpoint. Early recognition,\nwhich is also known as activity prediction, is an ability to infer an ongoing\nactivity at its early stage. We present an algorithm to perform recognition of\nactivities targeted at the camera from streaming videos, making the system to\npredict intended activities of the interacting person and avoid harmful events\nbefore they actually happen. We introduce the novel concept of 'onset' that\nefficiently summarizes pre-activity observations, and design an approach to\nconsider event history in addition to ongoing video observation for early\nfirst-person recognition of activities. We propose to represent onset using\ncascade histograms of time series gradients, and we describe a novel\nalgorithmic setup to take advantage of onset for early recognition of\nactivities. The experimental results clearly illustrate that the proposed\nconcept of onset enables better/earlier recognition of human activities from\nfirst-person videos."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5472v2", 
    "title": "Predicting Motivations of Actions by Leveraging Text", 
    "arxiv-id": "1406.5472v2", 
    "author": "Antonio Torralba", 
    "publish": "2014-06-20T18:02:02Z", 
    "summary": "Understanding human actions is a key problem in computer vision. However,\nrecognizing actions is only the first step of understanding what a person is\ndoing. In this paper, we introduce the problem of predicting why a person has\nperformed an action in images. This problem has many applications in human\nactivity understanding, such as anticipating or explaining an action. To study\nthis problem, we introduce a new dataset of people performing actions annotated\nwith likely motivations. However, the information in an image alone may not be\nsufficient to automatically solve this task. Since humans can rely on their\nlifetime of experiences to infer motivation, we propose to give computer vision\nsystems access to some of these experiences by using recently developed natural\nlanguage models to mine knowledge stored in massive amounts of text. While we\nare still far away from fully understanding motivation, our results suggest\nthat transferring knowledge from language into vision can help machines\nunderstand why people in images might be performing an action."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5549v2", 
    "title": "Fast Edge Detection Using Structured Forests", 
    "arxiv-id": "1406.5549v2", 
    "author": "C. Lawrence Zitnick", 
    "publish": "2014-06-20T22:28:29Z", 
    "summary": "Edge detection is a critical component of many vision systems, including\nobject detectors and image segmentation algorithms. Patches of edges exhibit\nwell-known forms of local structure, such as straight lines or T-junctions. In\nthis paper we take advantage of the structure present in local image patches to\nlearn both an accurate and computationally efficient edge detector. We\nformulate the problem of predicting local edge masks in a structured learning\nframework applied to random decision forests. Our novel approach to learning\ndecision trees robustly maps the structured labels to a discrete space on which\nstandard information gain measures may be evaluated. The result is an approach\nthat obtains realtime performance that is orders of magnitude faster than many\ncompeting state-of-the-art approaches, while also achieving state-of-the-art\nedge detection results on the BSDS500 Segmentation dataset and NYU Depth\ndataset. Finally, we show the potential of our approach as a general purpose\nedge detector by showing our learned edge models generalize well across\ndatasets."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5653v1", 
    "title": "Interactively Test Driving an Object Detector: Estimating Performance on   Unlabeled Data", 
    "arxiv-id": "1406.5653v1", 
    "author": "Pavan Turaga", 
    "publish": "2014-06-21T21:37:30Z", 
    "summary": "In this paper, we study the problem of `test-driving' a detector, i.e.\nallowing a human user to get a quick sense of how well the detector generalizes\nto their specific requirement. To this end, we present the first system that\nestimates detector performance interactively without extensive ground truthing\nusing a human in the loop. We approach this as a problem of estimating\nproportions and show that it is possible to make accurate inferences on the\nproportion of classes or groups within a large data collection by observing\nonly $5-10\\%$ of samples from the data. In estimating the false detections (for\nprecision), the samples are chosen carefully such that the overall\ncharacteristics of the data collection are preserved. Next, inspired by its use\nin estimating disease propagation we apply pooled testing approaches to\nestimate missed detections (for recall) from the dataset. The estimates thus\nobtained are close to the ones obtained using ground truth, thus reducing the\nneed for extensive labeling which is expensive and time consuming."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-19318-7_43", 
    "link": "http://arxiv.org/pdf/1406.5670v3", 
    "title": "3D ShapeNets: A Deep Representation for Volumetric Shapes", 
    "arxiv-id": "1406.5670v3", 
    "author": "Jianxiong Xiao", 
    "publish": "2014-06-22T03:31:52Z", 
    "summary": "3D shape is a crucial but heavily underutilized cue in today's computer\nvision systems, mostly due to the lack of a good generic shape representation.\nWith the recent availability of inexpensive 2.5D depth sensors (e.g. Microsoft\nKinect), it is becoming increasingly important to have a powerful 3D shape\nrepresentation in the loop. Apart from category recognition, recovering full 3D\nshapes from view-based 2.5D depth maps is also a critical part of visual\nunderstanding. To this end, we propose to represent a geometric 3D shape as a\nprobability distribution of binary variables on a 3D voxel grid, using a\nConvolutional Deep Belief Network. Our model, 3D ShapeNets, learns the\ndistribution of complex 3D shapes across different object categories and\narbitrary poses from raw CAD data, and discovers hierarchical compositional\npart representations automatically. It naturally supports joint object\nrecognition and shape completion from 2.5D depth maps, and it enables active\nobject recognition through view planning. To train our 3D deep learning model,\nwe construct ModelNet -- a large-scale 3D CAD model dataset. Extensive\nexperiments show that our 3D deep representation enables significant\nperformance improvement over the-state-of-the-arts in a variety of tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_9", 
    "link": "http://arxiv.org/pdf/1406.5710v1", 
    "title": "Natural Color Image Enhancement based on Modified Multiscale Retinex   Algorithm and Performance Evaluation usingWavelet Energy", 
    "arxiv-id": "1406.5710v1", 
    "author": "D. R Rameshbabu", 
    "publish": "2014-06-22T11:56:21Z", 
    "summary": "This paper presents a new color image enhancement technique based on modified\nMultiScale Retinex(MSR) algorithm and visual quality of the enhanced images are\nevaluated using a new metric, namely, wavelet energy. The color image\nenhancement is achieved by down sampling the value component of HSV color space\nconverted image into three scales (normal, medium and fine) following the\ncontrast stretching operation. These down sampled value components are enhanced\nusing the MSR algorithm. The value component is reconstructed by averaging each\npixels of the lower scale image with that of the upper scale image subsequent\nto up sampling the lower scale image. This process replaces dark pixel by the\naverage pixels of both the lower scale and upper scale, while retaining the\nbright pixels. The quality of the reconstructed images in the proposed method\nis found to be good and far better then the other researchers method. The\nperformance of the proposed scheme is evaluated using new wavelet domain based\nassessment criterion, referred as wavelet energy. This scheme computes the\nenergy of both original and enhanced image in wavelet domain. The number of\nedge details as well as wavelet energy is less in a poor quality image compared\nwith naturally enhanced image. Experimental results presented confirms that the\nproposed wavelet energy based color image quality assessment technique\nefficiently characterizes both the local and global details of enhanced image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2491929", 
    "link": "http://arxiv.org/pdf/1406.5726v3", 
    "title": "CNN: Single-label to Multi-label", 
    "arxiv-id": "1406.5726v3", 
    "author": "Shuicheng Yan", 
    "publish": "2014-06-22T14:03:07Z", 
    "summary": "Convolutional Neural Network (CNN) has demonstrated promising performance in\nsingle-label image classification tasks. However, how CNN best copes with\nmulti-label images still remains an open problem, mainly due to the complex\nunderlying object layouts and insufficient multi-label training images. In this\nwork, we propose a flexible deep CNN infrastructure, called\nHypotheses-CNN-Pooling (HCP), where an arbitrary number of object segment\nhypotheses are taken as the inputs, then a shared CNN is connected with each\nhypothesis, and finally the CNN output results from different hypotheses are\naggregated with max pooling to produce the ultimate multi-label predictions.\nSome unique characteristics of this flexible deep CNN infrastructure include:\n1) no ground truth bounding box information is required for training; 2) the\nwhole HCP infrastructure is robust to possibly noisy and/or redundant\nhypotheses; 3) no explicit hypothesis label is required; 4) the shared CNN may\nbe well pre-trained with a large-scale single-label image dataset, e.g.\nImageNet; and 5) it may naturally output multi-label prediction results.\nExperimental results on Pascal VOC2007 and VOC2012 multi-label image datasets\nwell demonstrate the superiority of the proposed HCP infrastructure over other\nstate-of-the-arts. In particular, the mAP reaches 84.2% by HCP only and 90.3%\nafter the fusion with our complementary result in [47] based on hand-crafted\nfeatures on the VOC2012 dataset, which significantly outperforms the\nstate-of-the-arts with a large margin of more than 7%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2491929", 
    "link": "http://arxiv.org/pdf/1406.5774v3", 
    "title": "Factors of Transferability for a Generic ConvNet Representation", 
    "arxiv-id": "1406.5774v3", 
    "author": "Stefan Carlsson", 
    "publish": "2014-06-22T21:57:46Z", 
    "summary": "Evidence is mounting that Convolutional Networks (ConvNets) are the most\neffective representation learning method for visual recognition tasks. In the\ncommon scenario, a ConvNet is trained on a large labeled dataset (source) and\nthe feed-forward units activation of the trained network, at a certain layer of\nthe network, is used as a generic representation of an input image for a task\nwith relatively smaller training set (target). Recent studies have shown this\nform of representation transfer to be suitable for a wide range of target\nvisual recognition tasks. This paper introduces and investigates several\nfactors affecting the transferability of such representations. It includes\nparameters for training of the source ConvNet such as its architecture,\ndistribution of the training data, etc. and also the parameters of feature\nextraction such as layer of the trained ConvNet, dimensionality reduction, etc.\nThen, by optimizing these factors, we show that significant improvements can be\nachieved on various (17) visual recognition tasks. We further show that these\nvisual recognition tasks can be categorically ordered based on their distance\nfrom the source task such that a correlation between the performance of tasks\nand their distance from the source task w.r.t. the proposed factors is\nobserved."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2491929", 
    "link": "http://arxiv.org/pdf/1406.6140v4", 
    "title": "Offline Handwritten MODI Character Recognition Using HU, Zernike Moments   and Zoning", 
    "arxiv-id": "1406.6140v4", 
    "author": "Pravin L. Yannawar", 
    "publish": "2014-06-24T05:40:43Z", 
    "summary": "HOCR is abbreviated as Handwritten Optical Character Recognition. HOCR is a\nprocess of recognition of different handwritten characters from a digital image\nof documents. Handwritten automatic character recognition has attracted many\nresearchers all over the world to contribute handwritten character recognition\ndomain. Shape identification and feature extraction is very important part of\nany character recognition system and success of method is highly dependent on\nselection of features. However feature extraction is the most important step in\ndefining the shape of the character as precisely and as uniquely as possible.\nThis is indeed the most important step and complex task as well and achieved\nsuccess by using invariance property, irrespective of position and orientation.\nZernike moments describes shape, identify rotation invariant due to its\nOrthogonality property. MODI is an ancient script of India had cursive and\ncomplex representation of characters. The work described in this paper presents\nefficiency of Zernike moments over Hu 7 moment with zoning for automatic\nrecognition of handwritten MODI characters. Offline approach is used in this\npaper because MODI Script was very popular and widely used for writing purpose\ntill 19th century before Devanagari was officially adopted."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2491929", 
    "link": "http://arxiv.org/pdf/1406.6147v1", 
    "title": "Incorporating Near-Infrared Information into Semantic Image Segmentation", 
    "arxiv-id": "1406.6147v1", 
    "author": "Sabine S\u00fcsstrunk", 
    "publish": "2014-06-24T06:28:50Z", 
    "summary": "Recent progress in computational photography has shown that we can acquire\nnear-infrared (NIR) information in addition to the normal visible (RGB) band,\nwith only slight modifications to standard digital cameras. Due to the\nproximity of the NIR band to visible radiation, NIR images share many\nproperties with visible images. However, as a result of the material dependent\nreflection in the NIR part of the spectrum, such images reveal different\ncharacteristics of the scene. We investigate how to effectively exploit these\ndifferences to improve performance on the semantic image segmentation task.\nBased on a state-of-the-art segmentation framework and a novel manually\nsegmented image database (both indoor and outdoor scenes) that contain\n4-channel images (RGB+NIR), we study how to best incorporate the specific\ncharacteristics of the NIR response. We show that adding NIR leads to improved\nperformance for classes that correspond to a specific type of material in both\noutdoor and indoor scenes. We also discuss the results with respect to the\nphysical properties of the NIR response."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2491929", 
    "link": "http://arxiv.org/pdf/1406.6201v1", 
    "title": "Saccadic Eye Movements and the Generalized Pareto Distribution", 
    "arxiv-id": "1406.6201v1", 
    "author": "Reiner Lenz", 
    "publish": "2014-06-24T10:57:50Z", 
    "summary": "We describe a statistical analysis of the eye tracker measurements in a\ndatabase with 15 observers viewing 1003 images under free-viewing conditions.\nIn contrast to the common approach of investigating the properties of the\nfixation points we analyze the properties of the transition phases between\nfixations. We introduce hyperbolic geometry as a tool to measure the step\nlength between consecutive eye positions. We show that the step lengths,\nmeasured in hyperbolic and euclidean geometry, follow a generalized Pareto\ndistribution. The results based on the hyperbolic distance are more robust than\nthose based on euclidean geometry. We show how the structure of the space of\ngeneralized Pareto distributions can be used to characterize and identify\nindividual observers."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2013.6738439", 
    "link": "http://arxiv.org/pdf/1406.6273v1", 
    "title": "Image Completion for View Synthesis Using Markov Random Fields and   Efficient Belief Propagation", 
    "arxiv-id": "1406.6273v1", 
    "author": "Klaus Diepold", 
    "publish": "2014-06-24T15:12:55Z", 
    "summary": "View synthesis is a process for generating novel views from a scene which has\nbeen recorded with a 3-D camera setup. It has important applications in 3-D\npost-production and 2-D to 3-D conversion. However, a central problem in the\ngeneration of novel views lies in the handling of disocclusions. Background\ncontent, which was occluded in the original view, may become unveiled in the\nsynthesized view. This leads to missing information in the generated view which\nhas to be filled in a visually plausible manner. We present an inpainting\nalgorithm for disocclusion filling in synthesized views based on Markov random\nfields and efficient belief propagation. We compare the result to two\nstate-of-the-art algorithms and demonstrate a significant improvement in image\nquality."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6323v1", 
    "title": "Dense Correspondences Across Scenes and Scales", 
    "arxiv-id": "1406.6323v1", 
    "author": "Tal Hassner", 
    "publish": "2014-06-24T17:49:09Z", 
    "summary": "We seek a practical method for establishing dense correspondences between two\nimages with similar content, but possibly different 3D scenes. One of the\nchallenges in designing such a system is the local scale differences of objects\nappearing in the two images. Previous methods often considered only small\nsubsets of image pixels; matching only pixels for which stable scales may be\nreliably estimated. More recently, others have considered dense\ncorrespondences, but with substantial costs associated with generating, storing\nand matching scale invariant descriptors. Our work here is motivated by the\nobservation that pixels in the image have contexts -- the pixels around them --\nwhich may be exploited in order to estimate local scales reliably and\nrepeatably. Specifically, we make the following contributions. (i) We show that\nscales estimated in sparse interest points may be propagated to neighboring\npixels where this information cannot be reliably determined. Doing so allows\nscale invariant descriptors to be extracted anywhere in the image, not just in\ndetected interest points. (ii) We present three different means for propagating\nthis information: using only the scales at detected interest points, using the\nunderlying image information to guide the propagation of this information\nacross each image, separately, and using both images simultaneously. Finally,\n(iii), we provide extensive results, both qualitative and quantitative,\ndemonstrating that accurate dense correspondences can be obtained even between\nvery different images, with little computational costs beyond those required by\nexisting methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6336v1", 
    "title": "A multilevel thresholding algorithm using Electromagnetism Optimization", 
    "arxiv-id": "1406.6336v1", 
    "author": "Valentin Osuna", 
    "publish": "2014-06-24T19:01:28Z", 
    "summary": "Segmentation is one of the most important tasks in image processing. It\nconsist in classify the pixels into two or more groups depending on their\nintensity levels and a threshold value. The quality of the segmentation depends\non the method applied to select the threshold. The use of the classical\nimplementations for multilevel thresholding is computationally expensive since\nthey exhaustively search the best values to optimize the objective function.\nUnder such conditions, the use of optimization evolutionary approaches has been\nextended. The Electromagnetism Like algorithm (EMO) is an evolutionary method\nwhich mimics the attraction repulsion mechanism among charges to evolve the\nmembers of a population. Different to other algorithms, EMO exhibits\ninteresting search capabilities whereas maintains a low computational overhead.\nIn this paper, a multilevel thresholding (MT) algorithm based on the EMO is\nintroduced. The approach combines the good search capabilities of EMO algorithm\nwith objective functions proposed by the popular MT methods of Otsu and Kapur.\nThe algorithm takes random samples from a feasible search space inside the\nimage histogram. Such samples build each particle in the EMO context whereas\nits quality is evaluated considering the objective that is function employed by\nthe Otsu or Kapur method. Guided by these objective values the set of candidate\nsolutions are evolved through the EMO operators until an optimal solution is\nfound. The approach generates a multilevel segmentation algorithm which can\neffectively identify the threshold values of a digital image in a reduced\nnumber of iterations. Experimental results show performance evidence of the\nimplementation of EMO for digital image segmentation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6425v2", 
    "title": "Compressive Imaging and Characterization of Sparse Light Deflection Maps", 
    "arxiv-id": "1406.6425v2", 
    "author": "Luc Joannes", 
    "publish": "2014-06-25T00:46:10Z", 
    "summary": "Light rays incident on a transparent object of uniform refractive index\nundergo deflections, which uniquely characterize the surface geometry of the\nobject. Associated with each point on the surface is a deflection map (or\nspectrum) which describes the pattern of deflections in various directions.\nThis article presents a novel method to efficiently acquire and reconstruct\nsparse deflection spectra induced by smooth object surfaces. To this end, we\nleverage the framework of Compressed Sensing (CS) in a particular\nimplementation of a schlieren deflectometer, i.e., an optical system providing\nlinear measurements of deflection spectra with programmable spatial light\nmodulation patterns. We design those modulation patterns on the principle of\nspread spectrum CS for reducing the number of observations. The ability of our\ndevice to simultaneously observe the deflection spectra on a dense\ndiscretization of the object surface is related to a Multiple Measurement\nVector (MMV) model. This scheme allows us to estimate both the noise power and\nthe instrumental point spread function.\n  We formulate the spectrum reconstruction task as the solving of a linear\ninverse problem regularized by an analysis sparsity prior using a translation\ninvariant wavelet frame. Our results demonstrate the capability and advantages\nof using a CS based approach for deflectometric imaging both on simulated data\nand experimental deflectometric data.\n  Finally, the paper presents an extension of our method showing how we can\nextract the main deflection direction in each point of the object surface from\na few compressive measurements, without needing any costly reconstruction\nprocedures. This compressive characterization is then confirmed with\nexperimental results on simple plano-convex and multifocal intra-ocular lenses\nstudying the evolution of the main deflection as a function of the object point\nlocation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6538v1", 
    "title": "A Bimodal Co-Sparse Analysis Model for Image Processing", 
    "arxiv-id": "1406.6538v1", 
    "author": "Martin Kleinsteuber", 
    "publish": "2014-06-25T12:28:55Z", 
    "summary": "The success of many computer vision tasks lies in the ability to exploit the\ninterdependency between different image modalities such as intensity and depth.\nFusing corresponding information can be achieved on several levels, and one\npromising approach is the integration at a low level. Moreover, sparse signal\nmodels have successfully been used in many vision applications. Within this\narea of research, the so called co-sparse analysis model has attracted\nconsiderably less attention than its well-known counterpart, the sparse\nsynthesis model, although it has been proven to be very useful in various image\nprocessing applications. In this paper, we propose a co-sparse analysis model\nthat is able to capture the interdependency of two image modalities. It is\nbased on the assumption that a pair of analysis operators exists, so that the\nco-supports of the corresponding bimodal image structures are correlated. We\npropose an algorithm that is able to learn such a coupled pair of operators\nfrom registered and noise-free training data. Furthermore, we explain how this\nmodel can be applied to solve linear inverse problems in image processing and\nhow it can be used for image registration tasks. This paper extends the work of\nsome of the authors by two major contributions. Firstly, a modification of the\nlearning process is proposed that a priori guarantees unit norm and zero-mean\nof the rows of the operator. This accounts for the intuition that contrast in\nimage modalities carries the most information. Secondly, the model is used in a\nnovel bimodal image registration algorithm which estimates the transformation\nparameters of unregistered images of different modalities."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6558v2", 
    "title": "$ N^4 $-Fields: Neural Network Nearest Neighbor Fields for Image   Transforms", 
    "arxiv-id": "1406.6558v2", 
    "author": "Victor Lempitsky", 
    "publish": "2014-06-25T13:10:56Z", 
    "summary": "We propose a new architecture for difficult image processing operations, such\nas natural edge detection or thin object segmentation. The architecture is\nbased on a simple combination of convolutional neural networks with the nearest\nneighbor search.\n  We focus our attention on the situations when the desired image\ntransformation is too hard for a neural network to learn explicitly. We show\nthat in such situations, the use of the nearest neighbor search on top of the\nnetwork output allows to improve the results considerably and to account for\nthe underfitting effect during the neural network training. The approach is\nvalidated on three challenging benchmarks, where the performance of the\nproposed architecture matches or exceeds the state-of-the-art."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6595v2", 
    "title": "3DUNDERWORLD-SLS: An Open-Source Structured-Light Scanning System for   Rapid Geometry Acquisition", 
    "arxiv-id": "1406.6595v2", 
    "author": "Charalambos Poullis", 
    "publish": "2014-06-25T14:51:21Z", 
    "summary": "Recently, there has been an increase in the demand of virtual 3D objects\nrepresenting real-life objects. A plethora of methods and systems have already\nbeen proposed for the acquisition of the geometry of real-life objects ranging\nfrom those which employ active sensor technology, passive sensor technology or\na combination of various techniques.\n  In this paper we present the development of a 3D scanning system which is\nbased on the principle of structured-light, without having particular\nrequirements for specialized equipment. We discuss the intrinsic details and\ninherent difficulties of structured-light scanning techniques and present our\nsolutions. Finally, we introduce our open-source scanning software system\n\"3DUNDERWORLD-SLS\" which implements the proposed techniques both in CPU and\nGPU. We have performed extensive testing with a wide range of models and report\nthe results. Furthermore, we present a comprehensive evaluation of the system\nand a comparison with a high-end commercial 3D scanner."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6811v2", 
    "title": "Face Image Classification by Pooling Raw Features", 
    "arxiv-id": "1406.6811v2", 
    "author": "Heng Tao Shen", 
    "publish": "2014-06-26T08:56:55Z", 
    "summary": "We propose a very simple, efficient yet surprisingly effective feature\nextraction method for face recognition (about 20 lines of Matlab code), which\nis mainly inspired by spatial pyramid pooling in generic image classification.\nWe show that features formed by simply pooling local patches over a multi-level\npyramid, coupled with a linear classifier, can significantly outperform most\nrecent face recognition methods. The simplicity of our feature extraction\nprocedure is demonstrated by the fact that no learning is involved (except PCA\nwhitening). We show that, multi-level spatial pooling and dense extraction of\nmulti-scale patches play critical roles in face image classification. The\nextracted facial features can capture strong structural information of\nindividual faces with no label information being used. We also find that,\npre-processing on local image patches such as contrast normalization can have\nan important impact on the classification accuracy. In particular, on the\nchallenging face recognition datasets of FERET and LFW-a, our method improves\nprevious best results by more than 10% and 20%, respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6818v2", 
    "title": "Face Identification with Second-Order Pooling", 
    "arxiv-id": "1406.6818v2", 
    "author": "Heng Tao Shen", 
    "publish": "2014-06-26T09:21:42Z", 
    "summary": "Automatic face recognition has received significant performance improvement\nby developing specialised facial image representations. On the other hand,\ngeneric object recognition has rarely been applied to the face recognition.\nSpatial pyramid pooling of features encoded by an over-complete dictionary has\nbeen the key component of many state-of-the-art image classification systems.\nInspired by its success, in this work we develop a new face image\nrepresentation method inspired by the second-order pooling in Carreira et al.\n[1], which was originally proposed for image segmentation. The proposed method\ndiffers from the previous methods in that, we encode the densely extracted\nlocal patches by a small-size dictionary; and the facial image signatures are\nobtained by pooling the second-order statistics of the encoded features. We\nshow the importance of pooling on encoded features, which is bypassed by the\noriginal second-order pooling method to avoid the high computational cost.\nEquipped with a simple linear classifier, the proposed method outperforms the\nstate-of-the-art face identification performance by large margins. For example,\non the LFW databases, the proposed method performs better than the previous\nbest by around 13% accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6946v2", 
    "title": "An improved computer vision method for detecting white blood cells", 
    "arxiv-id": "1406.6946v2", 
    "author": "Marco Perez", 
    "publish": "2014-06-26T17:01:32Z", 
    "summary": "The automatic detection of White Blood Cells (WBC) still remains as an\nunsolved issue in medical imaging. The analysis of WBC images has engaged\nresearchers from fields of medicine and computer vision alike. Since WBC can be\napproximated by an ellipsoid form, an ellipse detector algorithm may be\nsuccessfully applied in order to recognize them. This paper presents an\nalgorithm for the automatic detection of WBC embedded into complicated and\ncluttered smear images that considers the complete process as a multi-ellipse\ndetection problem. The approach, based on the Differential Evolution (DE)\nalgorithm, transforms the detection task into an optimization problem where\nindividuals emulate candidate ellipses. An objective function evaluates if such\ncandidate ellipses are really present in the edge image of the smear. Guided by\nthe values of such function, the set of encoded candidate ellipses\n(individuals) are evolved using the DE algorithm so that they can fit into the\nWBC enclosed within the edge-only map of the image. Experimental results from\nwhite blood cell images with a varying range of complexity are included to\nvalidate the efficiency of the proposed technique in terms of accuracy and\nrobustness."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6947v1", 
    "title": "Deep Learning Multi-View Representation for Face Recognition", 
    "arxiv-id": "1406.6947v1", 
    "author": "Xiaoou Tang", 
    "publish": "2014-06-26T17:09:25Z", 
    "summary": "Various factors, such as identities, views (poses), and illuminations, are\ncoupled in face images. Disentangling the identity and view representations is\na major challenge in face recognition. Existing face recognition systems either\nuse handcrafted features or learn features discriminatively to improve\nrecognition accuracy. This is different from the behavior of human brain.\nIntriguingly, even without accessing 3D data, human not only can recognize face\nidentity, but can also imagine face images of a person under different\nviewpoints given a single 2D image, making face perception in the brain robust\nto view changes. In this sense, human brain has learned and encoded 3D face\nmodels from 2D images. To take into account this instinct, this paper proposes\na novel deep neural net, named multi-view perceptron (MVP), which can untangle\nthe identity and view features, and infer a full spectrum of multi-view images\nin the meanwhile, given a single 2D face image. The identity features of MVP\nachieve superior performance on the MultiPIE dataset. MVP is also capable to\ninterpolate and predict images under viewpoints that are unobserved in the\ntraining data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.6962v2", 
    "title": "How good are detection proposals, really?", 
    "arxiv-id": "1406.6962v2", 
    "author": "Bernt Schiele", 
    "publish": "2014-06-26T18:00:56Z", 
    "summary": "Current top performing Pascal VOC object detectors employ detection proposals\nto guide the search for objects thereby avoiding exhaustive sliding window\nsearch across images. Despite the popularity of detection proposals, it is\nunclear which trade-offs are made when using them during object detection. We\nprovide an in depth analysis of ten object proposal methods along with four\nbaselines regarding ground truth annotation recall (on Pascal VOC 2007 and\nImageNet 2013), repeatability, and impact on DPM detector performance. Our\nfindings show common weaknesses of existing methods, and provide insights to\nchoose the most adequate method for different settings."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2015.2474356", 
    "link": "http://arxiv.org/pdf/1406.7062v1", 
    "title": "Adaptive Mesh Representation and Restoration of Biomedical Images", 
    "arxiv-id": "1406.7062v1", 
    "author": "Zeyun Yu", 
    "publish": "2014-06-27T05:06:22Z", 
    "summary": "The triangulation of images has become an active research area in recent\nyears for its compressive representation and ease of image processing and\nvisualization. However, little work has been done on how to faithfully recover\nimage intensities from a triangulated mesh of an image, a process also known as\nimage restoration or decoding from meshes. The existing methods such as linear\ninterpolation, least-square interpolation, or interpolation based on radial\nbasis functions (RBFs) work to some extent, but often yield blurred features\n(edges, corners, etc.). The main reason for this problem is due to the\nisotropically-defined Euclidean distance that is taken into consideration in\nthese methods, without considering the anisotropicity of feature intensities in\nan image. Moreover, most existing methods use intensities defined at mesh nodes\nwhose intensities are often ambiguously defined on or near image edges (or\nfeature boundaries). In the current paper, a new method of restoring an image\nfrom its triangulation representation is proposed, by utilizing anisotropic\nradial basis functions (ARBFs). This method considers not only the geometrical\n(Euclidean) distances but also the local feature orientations (anisotropic\nintensities). Additionally, this method is based on the intensities of mesh\nfaces instead of mesh nodes and thus provides a more robust restoration. The\ntwo strategies together guarantee excellent feature-preserving restoration of\nan image with arbitrary super-resolutions from its triangulation\nrepresentation, as demonstrated by various experiments provided in the paper."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1406.7075v1", 
    "title": "Adaptive texture energy measure method", 
    "arxiv-id": "1406.7075v1", 
    "author": "Omer Faruk Ertugrul", 
    "publish": "2014-06-27T06:00:17Z", 
    "summary": "Recent developments in image quality, data storage, and computational\ncapacity have heightened the need for texture analysis in image process. To\ndate various methods have been developed and introduced for assessing textures\nin images. One of the most popular texture analysis methods is the Texture\nEnergy Measure (TEM) and it has been used for detecting edges, levels, waves,\nspots and ripples by employing predefined TEM masks to images. Despite several\nsuccess- ful studies, TEM has a number of serious weaknesses in use. The major\ndrawback is; the masks are predefined therefore they cannot be adapted to\nimage. A new method, Adaptive Texture Energy Measure Method (aTEM), was offered\nto over- come this disadvantage of TEM by using adaptive masks by adjusting the\ncontrast, sharpening and orientation angle of the mask. To assess the\napplicability of aTEM, it is compared with TEM. The accuracy of the\nclassification of butterfly, flower seed and Brodatz datasets are 0.08, 0.3292\nand 0.3343, respectively by TEM and 0.0053, 0.2417 and 0.3153, respectively by\naTEM. The results of this study indicate that aTEM is a successful method for\ntexture analysis."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1406.7112v1", 
    "title": "3D planar patch extraction from stereo using probabilistic region   growing", 
    "arxiv-id": "1406.7112v1", 
    "author": "Vasileios Zografos", 
    "publish": "2014-06-27T08:52:54Z", 
    "summary": "This article presents a novel 3D planar patch extraction method using a\nprobabilistic region growing algorithm. Our method works by simultaneously\ninitiating multiple planar patches from seed points, the latter determined by\nan intensity-based 2D segmentation algorithm in the stereo-pair images. The\npatches are grown incrementally and in parallel as 3D scene points are\nconsidered for membership, using a probabilistic distance likelihood measure.\nIn addition, we have incorporated prior information based on the noise model in\nthe 2D images and the scene configuration but also include the intensity\ninformation resulting from the initial segmentation. This method works well\nacross many different data-sets, involving real and synthetic examples of both\nregularly and non-regularly sampled data, and is fast enough that may be used\nfor robot navigation tasks of path detection and obstacle avoidance."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1406.7120v1", 
    "title": "Template Matching based Object Detection Using HOG Feature Pyramid", 
    "arxiv-id": "1406.7120v1", 
    "author": "Anish Acharya", 
    "publish": "2014-06-27T09:18:44Z", 
    "summary": "This article provides a step by step development of designing a Object\nDetection scheme using the HOG based Feature Pyramid aligned with the concept\nof Template Matching."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1406.7128v1", 
    "title": "On a new formulation of nonlocal image filters involving the relative   rearrangement", 
    "arxiv-id": "1406.7128v1", 
    "author": "Juli\u00e1n Velasco", 
    "publish": "2014-06-27T09:43:53Z", 
    "summary": "Nonlocal filters are simple and powerful techniques for image denoising. In\nthis paper we study the reformulation of a broad class of nonlocal filters in\nterms of two functional rearrangements: the decreasing and the relative\nrearrangements.\n  Independently of the dimension of the image, we reformulate these filters as\nintegral operators defined in a one-dimensional space corresponding to the\nlevel sets measures.\n  We prove the equivalency between the original and the rearranged versions of\nthe filters and propose a discretization in terms of constant-wise\ninterpolators, which we prove to be convergent to the solution of the\ncontinuous setting.\n  For some particular cases, this new formulation allows us to perform a\ndetailed analysis of the filtering properties. Among others, we prove that the\nfiltered image is a contrast change of the original image, and that the\nfiltering procedure behaves asymptotically as a shock filter combined with a\nborder diffusive term, responsible for the staircaising effect and the loss of\ncontrast."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1406.7360v2", 
    "title": "A framework for improving the performance of verification algorithms   with a low false positive rate requirement and limited training data", 
    "arxiv-id": "1406.7360v2", 
    "author": "Ognjen Arandjelovic", 
    "publish": "2014-06-28T05:43:30Z", 
    "summary": "In this paper we address the problem of matching patterns in the so-called\nverification setting in which a novel, query pattern is verified against a\nsingle training pattern: the decision sought is whether the two match (i.e.\nbelong to the same class) or not. Unlike previous work which has universally\nfocused on the development of more discriminative distance functions between\npatterns, here we consider the equally important and pervasive task of\nselecting a distance threshold which fits a particular operational requirement\n- specifically, the target false positive rate (FPR). First, we argue on\ntheoretical grounds that a data-driven approach is inherently ill-conditioned\nwhen the desired FPR is low, because by the very nature of the challenge only a\nsmall portion of training data affects or is affected by the desired threshold.\nThis leads us to propose a general, statistical model-based method instead. Our\napproach is based on the interpretation of an inter-pattern distance as\nimplicitly defining a pattern embedding which approximately distributes\npatterns according to an isotropic multi-variate normal distribution in some\nspace. This interpretation is then used to show that the distribution of\ntraining inter-pattern distances is the non-central chi2 distribution,\ndifferently parameterized for each class. Thus, to make the class-specific\nthreshold choice we propose a novel analysis-by-synthesis iterative algorithm\nwhich estimates the three free parameters of the model (for each class) using\ntask-specific constraints. The validity of the premises of our work and the\neffectiveness of the proposed method are demonstrated by applying the method to\nthe task of set-based face verification on a large database of pseudo-random\nhead motion videos."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1406.7525v1", 
    "title": "Fusion Based Holistic Road Scene Understanding", 
    "arxiv-id": "1406.7525v1", 
    "author": "Xiaojin Gong", 
    "publish": "2014-06-29T17:11:25Z", 
    "summary": "This paper addresses the problem of holistic road scene understanding based\non the integration of visual and range data. To achieve the grand goal, we\npropose an approach that jointly tackles object-level image segmentation and\nsemantic region labeling within a conditional random field (CRF) framework.\nSpecifically, we first generate semantic object hypotheses by clustering 3D\npoints, learning their prior appearance models, and using a deep learning\nmethod for reasoning their semantic categories. The learned priors, together\nwith spatial and geometric contexts, are incorporated in CRF. With this\nformulation, visual and range data are fused thoroughly, and moreover, the\ncoupled segmentation and semantic labeling problem can be inferred via Graph\nCuts. Our approach is validated on the challenging KITTI dataset that contains\ndiverse complicated road scenarios. Both quantitative and qualitative\nevaluations demonstrate its effectiveness."
},{
    "category": "cs.CV", 
    "doi": "10.11648/j.ijiis.20140302.11", 
    "link": "http://arxiv.org/pdf/1408.0452v1", 
    "title": "Methodology For Detection of QRS Pattern Using Secondary Wavelets", 
    "arxiv-id": "1408.0452v1", 
    "author": "Asharani", 
    "publish": "2014-08-03T03:43:28Z", 
    "summary": "Applications of wavelet transform to the field of health care signals have\npaved the way for implementing revolutionary approaches in detecting the\npresence of certain abnormalities in human health patterns. There were\nextensive studies carried out using primary wavelets in various signals like\nElectrocardiogram (ECG), sonogram etc. with a certain amount of success. On the\nother hand analysis using secondary wavelets which inherits the characteristics\nof a set of variations available in signals like ECG can be a promise to detect\ndiseases with ease. Here a method to create a generalized adapted wavelet is\npresented which contains the information of QRS pattern collected from an\nanomaly sample space. The method has been tested and found to be successful in\nlocating the position of R peak in noise embedded ECG signal."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ChinaSIP.2013.6625344", 
    "link": "http://arxiv.org/pdf/1408.0453v1", 
    "title": "Adaptive Wavelet Based Identification and Extraction of PQRST   Combination in Randomly Stretching ECG Sequence", 
    "arxiv-id": "1408.0453v1", 
    "author": "M. Asharani", 
    "publish": "2014-08-03T03:49:36Z", 
    "summary": "Cardiovascular system study using ECG signals have evolved tremendously in\nthe domain of electronics and signal processing. However, there are certain\nfloating challenges unresolved in the analysis and detection of abnormal\nperformances of cardiovascular system. As the medical field is moving towards\nmore automated and intelligent systems, wrong detection or wrong\ninterpretations of ECG waveform of abnormal conditions can be quite fatal.\nSince the PQRST signals vary their positions randomly, the process of locating,\nidentifying and classifying each feature can be cumbersome and it is prone to\nerrors. Here we present an automated scheme using adaptive wavelet to detect\nprominent R-peak with extreme accuracy and algorithmically tag and mark the\ncoexisting peaks P, Q, S, and T with almost same accuracy. The adaptive wavelet\napproach used in this scheme is capable of detecting R-peak in ECG with 99.99%\naccuracy along with the rest of the waveforms."
},{
    "category": "cs.CV", 
    "doi": "10.5220/0004684504110418", 
    "link": "http://arxiv.org/pdf/1408.0680v1", 
    "title": "A Pattern Recognition System for Detecting Use of Mobile Phones While   Driving", 
    "arxiv-id": "1408.0680v1", 
    "author": "Rangel Arthur", 
    "publish": "2014-08-04T13:35:24Z", 
    "summary": "It is estimated that 80% of crashes and 65% of near collisions involved\ndrivers inattentive to traffic for three seconds before the event. This paper\ndevelops an algorithm for extracting characteristics allowing the cell phones\nidentification used during driving a vehicle. Experiments were performed on\nsets of images with 100 positive images (with phone) and the other 100 negative\nimages (no phone), containing frontal images of the driver. Support Vector\nMachine (SVM) with Polynomial kernel is the most advantageous classification\nsystem to the features provided by the algorithm, obtaining a success rate of\n91.57% for the vision system. Tests done on videos show that it is possible to\nuse the image datasets for training classifiers in real situations. Periods of\n3 seconds were correctly classified at 87.43% of cases."
},{
    "category": "cs.CV", 
    "doi": "10.5220/0004684504110418", 
    "link": "http://arxiv.org/pdf/1408.0814v1", 
    "title": "Object Detection Through Exploration With A Foveated Visual Field", 
    "arxiv-id": "1408.0814v1", 
    "author": "Miguel P. Eckstein", 
    "publish": "2014-08-04T20:49:26Z", 
    "summary": "We present a foveated object detector (FOD) as a biologically-inspired\nalternative to the sliding window (SW) approach which is the dominant method of\nsearch in computer vision object detection. Similar to the human visual system,\nthe FOD has higher resolution at the fovea and lower resolution at the visual\nperiphery. Consequently, more computational resources are allocated at the\nfovea and relatively fewer at the periphery. The FOD processes the entire\nscene, uses retino-specific object detection classifiers to guide eye\nmovements, aligns its fovea with regions of interest in the input image and\nintegrates observations across multiple fixations. Our approach combines modern\nobject detectors from computer vision with a recent model of peripheral pooling\nregions found at the V1 layer of the human visual system. We assessed various\neye movement strategies on the PASCAL VOC 2007 dataset and show that the FOD\nperforms on par with the SW detector while bringing significant computational\ncost savings."
},{
    "category": "cs.CV", 
    "doi": "10.5220/0004684504110418", 
    "link": "http://arxiv.org/pdf/1408.0872v2", 
    "title": "Open-set Person Re-identification", 
    "arxiv-id": "1408.0872v2", 
    "author": "Stan Z. Li", 
    "publish": "2014-08-05T05:55:16Z", 
    "summary": "Person re-identification is becoming a hot research for developing both\nmachine learning algorithms and video surveillance applications. The task of\nperson re-identification is to determine which person in a gallery has the same\nidentity to a probe image. This task basically assumes that the subject of the\nprobe image belongs to the gallery, that is, the gallery contains this person.\nHowever, in practical applications such as searching a suspect in a video, this\nassumption is usually not true. In this paper, we consider the open-set person\nre-identification problem, which includes two sub-tasks, detection and\nidentification. The detection sub-task is to determine the presence of the\nprobe subject in the gallery, and the identification sub-task is to determine\nwhich person in the gallery has the same identity as the accepted probe. We\npresent a database collected from a video surveillance setting of 6 cameras,\nwith 200 persons and 7,413 images segmented. Based on this database, we develop\na benchmark protocol for evaluating the performance under the open-set person\nre-identification scenario. Several popular metric learning algorithms for\nperson re-identification have been evaluated as baselines. From the baseline\nperformance, we observe that the open-set person re-identification problem is\nstill largely unresolved, thus further attention and effort is needed."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-07887-8_100", 
    "link": "http://arxiv.org/pdf/1408.1135v1", 
    "title": "It is hard to see a needle in a haystack: Modeling contrast masking   effect in a numerical observer", 
    "arxiv-id": "1408.1135v1", 
    "author": "Andrew D. A. Maidment", 
    "publish": "2014-08-05T22:23:40Z", 
    "summary": "Within the framework of a virtual clinical trial for breast imaging, we aim\nto develop numerical observers that follow the same detection performance\ntrends as those of a typical human observer. In our prior work, we showed that\nby including spatiotemporal contrast sensitivity function (stCSF) of human\nvisual system (HVS) in a multi-slice channelized Hotelling observer (msCHO), we\ncan correctly predict trends of a typical human observer performance with the\nviewing parameters of browsing speed, viewing distance and contrast. In this\nwork we further improve our numerical observer by modeling contrast masking.\nAfter stCSF, contrast masking is the second most prominent property of HVS and\nit refers to the fact that the presence of one signal affects the visibility\nthreshold for another signal. Our results indicate that the improved numerical\nobserver better predicts changes in detection performance with background\ncomplexity."
},lol]