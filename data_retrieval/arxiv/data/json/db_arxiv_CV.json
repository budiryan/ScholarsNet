[{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/9810003v1", 
    "other_authors": "Andreas Siebert", 
    "title": "A Linear Shift Invariant Multiscale Transform", 
    "arxiv-id": "cs/9810003v1", 
    "author": "Andreas Siebert", 
    "publish": "1998-10-02T03:34:38Z", 
    "summary": "This paper presents a multiscale decomposition algorithm. Unlike standard\nwavelet transforms, the proposed operator is both linear and shift invariant.\nThe central idea is to obtain shift invariance by averaging the aligned wavelet\ntransform projections over all circular shifts of the signal. It is shown how\nthe same transform can be obtained by a linear filter bank."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/9810017v1", 
    "other_authors": "Stephen L. Adler", 
    "title": "General Theory of Image Normalization", 
    "arxiv-id": "cs/9810017v1", 
    "author": "Stephen L. Adler", 
    "publish": "1998-10-19T20:46:16Z", 
    "summary": "We give a systematic, abstract formulation of the image normalization method\nas applied to a general group of image transformations, and then illustrate the\nabstract analysis by applying it to the hierarchy of viewing transformations of\na planar object."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/9908017v1", 
    "other_authors": "Andreas Siebert", 
    "title": "A Differential Invariant for Zooming", 
    "arxiv-id": "cs/9908017v1", 
    "author": "Andreas Siebert", 
    "publish": "1999-08-26T17:18:49Z", 
    "summary": "This paper presents an invariant under scaling and linear brightness change.\nThe invariant is based on differentials and therefore is a local feature.\nRotationally invariant 2-d differential Gaussian operators up to third order\nare proposed for the implementation of the invariant. The performance is\nanalyzed by simulating a camera zoom-out."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-662-48433-3_10", 
    "link": "http://arxiv.org/pdf/cs/0001024v1", 
    "other_authors": "B. R. Schlei, L. Prasad", 
    "title": "A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images", 
    "arxiv-id": "cs/0001024v1", 
    "author": "L. Prasad", 
    "publish": "2000-01-25T16:09:37Z", 
    "summary": "We describe a simple, but efficient algorithm for the generation of dilated\ncontours from bilevel images. The initial part of the contour extraction is\nexplained to be a good candidate for parallel computer code generation. The\nremainder of the algorithm is of linear nature."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0003065v1", 
    "other_authors": "Oleg Kiselyov, Paul Fisher", 
    "title": "Image Compression with Iterated Function Systems, Finite Automata and   Zerotrees: Grand Unification", 
    "arxiv-id": "cs/0003065v1", 
    "author": "Paul Fisher", 
    "publish": "2000-03-15T19:31:51Z", 
    "summary": "Fractal image compression, Culik's image compression and zerotree prediction\ncoding of wavelet image decomposition coefficients succeed only because typical\nimages being compressed possess a significant degree of self-similarity.\nBesides the common concept, these methods turn out to be even more tightly\nrelated, to the point of algorithmical reducibility of one technique to\nanother. The goal of the present paper is to demonstrate these relations.\n  The paper offers a plain-term interpretation of Culik's image compression, in\nregular image processing terms, without resorting to finite state machines and\nsimilar lofty language. The interpretation is shown to be algorithmically\nrelated to an IFS fractal image compression method: an IFS can be exactly\ntransformed into Culik's image code. Using this transformation, we will prove\nthat in a self-similar (part of an) image any zero wavelet coefficient is the\nroot of a zerotree, or its branch.\n  The paper discusses the zerotree coding of (wavelet/projection) coefficients\nas a common predictor/corrector, applied vertically through different layers of\na multiresolutional decomposition, rather than within the same view. This\ninterpretation leads to an insight into the evolution of image compression\ntechniques: from a causal single-layer prediction, to non-causal same-view\npredictions (wavelet decomposition among others) and to a causal cross-layer\nprediction (zero-trees, Culik's method)."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0003079v1", 
    "other_authors": "Andreas Siebert", 
    "title": "Differential Invariants under Gamma Correction", 
    "arxiv-id": "cs/0003079v1", 
    "author": "Andreas Siebert", 
    "publish": "2000-03-26T23:18:43Z", 
    "summary": "This paper presents invariants under gamma correction and similarity\ntransformations. The invariants are local features based on differentials which\nare implemented using derivatives of the Gaussian. The use of the proposed\ninvariant representation is shown to yield improved correlation results in a\ntemplate matching scenario."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0004012v1", 
    "other_authors": "Emmanuel Etievent, Frank Lebourgeois, Jean-Michel Jolion", 
    "title": "Assisted Video Sequences Indexing : Motion Analysis Based on Interest   Points", 
    "arxiv-id": "cs/0004012v1", 
    "author": "Jean-Michel Jolion", 
    "publish": "2000-04-21T17:32:29Z", 
    "summary": "This work deals with content-based video indexing. Our viewpoint is\nsemi-automatic analysis of compressed video. We consider the possible\napplications of motion analysis and moving object detection : assisting moving\nobject indexing, summarising videos, and allowing image and motion queries. We\npropose an approach based on interest points. As first results, we test and\ncompare the stability of different types of interest point detectors in\ncompressed sequences."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0005001v1", 
    "other_authors": "Liang Chen, Naoyuki Tokuda", 
    "title": "Robustness of Regional Matching Scheme over Global Matching Scheme", 
    "arxiv-id": "cs/0005001v1", 
    "author": "Naoyuki Tokuda", 
    "publish": "2000-05-03T08:49:28Z", 
    "summary": "The paper has established and verified the theory prevailing widely among\nimage and pattern recognition specialists that the bottom-up indirect regional\nmatching process is the more stable and the more robust than the global\nmatching process against concentrated types of noise represented by clutter,\noutlier or occlusion in the imagery. We have demonstrated this by analyzing the\neffect of concentrated noise on a typical decision making process of a\nsimplified two candidate voting model where our theorem establishes the lower\nbounds to a critical breakdown point of election (or decision) result by the\nbottom-up matching process are greater than the exact bound of the global\nmatching process implying that the former regional process is capable of\naccommodating a higher level of noise than the latter global process before the\nresult of decision overturns. We present a convincing experimental verification\nsupporting not only the theory by a white-black flag recognition problem in the\npresence of localized noise but also the validity of the conjecture by a facial\nrecognition problem that the theorem remains valid for other decision making\nprocesses involving an important dimension-reducing transform such as principal\ncomponent analysis or a Gabor transform."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0006001v1", 
    "other_authors": "Ninan Sajeeth Philip, K. Babu Joseph", 
    "title": "Boosting the Differences: A fast Bayesian classifier neural network", 
    "arxiv-id": "cs/0006001v1", 
    "author": "K. Babu Joseph", 
    "publish": "2000-05-31T23:37:48Z", 
    "summary": "A Bayesian classifier that up-weights the differences in the attribute values\nis discussed. Using four popular datasets from the UCI repository, some\ninteresting features of the network are illustrated. The network is suitable\nfor classification problems."
},{
    "category": "cs.CV", 
    "doi": "10.1109/DCC.1996.488375", 
    "link": "http://arxiv.org/pdf/cs/0006002v1", 
    "other_authors": "Ninan Sajeeth Philip, K. Babu Joseph", 
    "title": "Distorted English Alphabet Identification : An application of Difference   Boosting Algorithm", 
    "arxiv-id": "cs/0006002v1", 
    "author": "K. Babu Joseph", 
    "publish": "2000-05-31T23:52:31Z", 
    "summary": "The difference-boosting algorithm is used on letters dataset from the UCI\nrepository to classify distorted raster images of English alphabets. In\ncontrast to rather complex networks, the difference-boosting is found to\nproduce comparable or better classification efficiency on this complex problem."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0006047v1", 
    "other_authors": "B. R. Schlei, L. Prasad, A. N. Skourikhine", 
    "title": "Geometric Morphology of Granular Materials", 
    "arxiv-id": "cs/0006047v1", 
    "author": "A. N. Skourikhine", 
    "publish": "2000-06-30T22:17:42Z", 
    "summary": "We present a new method to transform the spectral pixel information of a\nmicrograph into an affine geometric description, which allows us to analyze the\nmorphology of granular materials. We use spectral and pulse-coupled neural\nnetwork based segmentation techniques to generate blobs, and a newly developed\nalgorithm to extract dilated contours. A constrained Delaunay tesselation of\nthe contour points results in a triangular mesh. This mesh is the basic\ningredient of the Chodal Axis Transform, which provides a morphological\ndecomposition of shapes. Such decomposition allows for grain separation and the\nefficient computation of the statistical features of granular materials."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0208005v1", 
    "other_authors": "Ulrich Hillenbrand, Gerd Hirzinger", 
    "title": "Probabilistic Search for Object Segmentation and Recognition", 
    "arxiv-id": "cs/0208005v1", 
    "author": "Gerd Hirzinger", 
    "publish": "2002-08-05T10:57:09Z", 
    "summary": "The problem of searching for a model-based scene interpretation is analyzed\nwithin a probabilistic framework. Object models are formulated as generative\nmodels for range data of the scene. A new statistical criterion, the truncated\nobject probability, is introduced to infer an optimal sequence of object\nhypotheses to be evaluated for their match to the data. The truncated\nprobability is partly determined by prior knowledge of the objects and partly\nlearned from data. Some experiments on sequence quality and object segmentation\nand recognition from stereo data are presented. The article recovers classic\nconcepts from object recognition (grouping, geometric hashing, alignment) from\nthe probabilistic perspective and adds insight into the optimal ordering of\nobject hypotheses for evaluation. Moreover, it introduces point-relation\ndensities, a key component of the truncated probability, as statistical models\nof local surface shape."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0301001v1", 
    "other_authors": "N. Chernov, C. Lesort", 
    "title": "Least squares fitting of circles and lines", 
    "arxiv-id": "cs/0301001v1", 
    "author": "C. Lesort", 
    "publish": "2003-01-01T19:58:03Z", 
    "summary": "We study theoretical and computational aspects of the least squares fit (LSF)\nof circles and circular arcs. First we discuss the existence and uniqueness of\nLSF and various parametrization schemes. Then we evaluate several popular\ncircle fitting algorithms and propose a new one that surpasses the existing\nmethods in reliability. We also discuss and compare direct (algebraic) circle\nfits."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0303015v1", 
    "other_authors": "N. Chernov, C. Lesort", 
    "title": "Statistical efficiency of curve fitting algorithms", 
    "arxiv-id": "cs/0303015v1", 
    "author": "C. Lesort", 
    "publish": "2003-03-18T21:30:36Z", 
    "summary": "We study the problem of fitting parametrized curves to noisy data. Under\ncertain assumptions (known as Cartesian and radial functional models), we\nderive asymptotic expressions for the bias and the covariance matrix of the\nparameter estimates. We also extend Kanatani's version of the Cramer-Rao lower\nbound, which he proved for unbiased estimates only, to more general estimates\nthat include many popular algorithms (most notably, the orthogonal least\nsquares and algebraic fits). We then show that the gradient-weighted algebraic\nfit is statistically efficient and describe all other statistically efficient\nalgebraic fits."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307045v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "Flexible Camera Calibration Using a New Analytical Radial Undistortion   Formula with Application to Mobile Robot Localization", 
    "arxiv-id": "cs/0307045v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-20T02:35:38Z", 
    "summary": "Most algorithms in 3D computer vision rely on the pinhole camera model\nbecause of its simplicity, whereas virtually all imaging devices introduce\ncertain amount of nonlinear distortion, where the radial distortion is the most\nsevere part. Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved. An application of the new radial distortion model is non-iterative\nyellow line alignment with a calibrated camera on ODIS, a robot built in our\nCSOIS."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307046v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "A New Analytical Radial Distortion Model for Camera Calibration", 
    "arxiv-id": "cs/0307046v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-20T05:18:59Z", 
    "summary": "Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307047v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "Rational Radial Distortion Models with Analytical Undistortion Formulae", 
    "arxiv-id": "cs/0307047v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-20T05:54:42Z", 
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nclass of rational radial distortion models with easy analytical undistortion\nformulae. Experimental results are presented to show that with this class of\nrational radial distortion models, satisfactory and comparable accuracy is\nachieved."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307051v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "An Analytical Piecewise Radial Distortion Model for Precision Camera   Calibration", 
    "arxiv-id": "cs/0307051v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-21T16:30:11Z", 
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\npiecewise radial distortion model with easy analytical undistortion formula.\nThe motivation for seeking a piecewise radial distortion model is that, when a\ncamera is resulted in a low quality during manufacturing, the nonlinear radial\ndistortion can be complex. Using low order polynomials to approximate the\nradial distortion might not be precise enough. On the other hand, higher order\npolynomials suffer from the inverse problem. With the new piecewise radial\ndistortion function, more flexibility is obtained and the radial undistortion\ncan be performed analytically. Experimental results are presented to show that\nwith this new piecewise radial distortion model, better performance is achieved\nthan that using the single function. Furthermore, a comparable performance with\nthe conventional polynomial model using 2 coefficients can also be\naccomplished."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0307072v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "Camera Calibration: a USU Implementation", 
    "arxiv-id": "cs/0307072v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-07-31T19:33:48Z", 
    "summary": "The task of camera calibration is to estimate the intrinsic and extrinsic\nparameters of a camera model. Though there are some restricted techniques to\ninfer the 3-D information about the scene from uncalibrated cameras, effective\ncamera calibration procedures will open up the possibility of using a wide\nrange of existing algorithms for 3-D reconstruction and recognition.\n  The applications of camera calibration include vision-based metrology, robust\nvisual platooning and visual docking of mobile robots where the depth\ninformation is important."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0308003v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "A Family of Simplified Geometric Distortion Models for Camera   Calibration", 
    "arxiv-id": "cs/0308003v1", 
    "author": "Kevin L. Moore", 
    "publish": "2003-08-02T01:39:38Z", 
    "summary": "The commonly used radial distortion model for camera calibration is in fact\nan assumption or a restriction. In practice, camera distortion could happen in\na general geometrical manner that is not limited to the radial sense. This\npaper proposes a simplified geometrical distortion modeling method by using two\ndifferent radial distortion functions in the two image axes. A family of\nsimplified geometric distortion models is proposed, which are either simple\npolynomials or the rational functions of polynomials. Analytical geometric\nundistortion is possible using two of the distortion functions discussed in\nthis paper and their performance can be improved by applying a piecewise\nfitting idea. Our experimental results show that the geometrical distortion\nmodels always perform better than their radial distortion counterparts.\nFurthermore, the proposed geometric modeling method is more appropriate for\ncameras whose distortion is not perfectly radially symmetric around the center\nof distortion."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0308034v1", 
    "other_authors": "G. Iovane, P. Giordano, C. Iovane, F. Rotulo", 
    "title": "Fingerprint based bio-starter and bio-access", 
    "arxiv-id": "cs/0308034v1", 
    "author": "F. Rotulo", 
    "publish": "2003-08-21T10:47:27Z", 
    "summary": "In the paper will be presented a safety and security system based on\nfingerprint technology. The results suggest a new scenario where the new cars\ncan use a fingerprint sensor integrated in car handle to allow access and in\nthe dashboard as starter button."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.404821", 
    "link": "http://arxiv.org/pdf/cs/0308035v1", 
    "other_authors": "G. Iovane, F. S. Tortoriello", 
    "title": "IS (Iris Security)", 
    "arxiv-id": "cs/0308035v1", 
    "author": "F. S. Tortoriello", 
    "publish": "2003-08-21T10:52:53Z", 
    "summary": "In the paper will be presented a safety system based on iridology. The\nresults suggest a new scenario where the security problem in supervised and\nunsupervised areas can be treat with the present system and the iris image\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0401017v2", 
    "other_authors": "Nicholas R. Howe, Alexandra Deschamps", 
    "title": "Better Foreground Segmentation Through Graph Cuts", 
    "arxiv-id": "cs/0401017v2", 
    "author": "Alexandra Deschamps", 
    "publish": "2004-01-21T20:06:51Z", 
    "summary": "For many tracking and surveillance applications, background subtraction\nprovides an effective means of segmenting objects moving in front of a static\nbackground. Researchers have traditionally used combinations of morphological\noperations to remove the noise inherent in the background-subtracted result.\nSuch techniques can effectively isolate foreground objects, but tend to lose\nfidelity around the borders of the segmentation, especially for noisy input.\nThis paper explores the use of a minimum graph cut algorithm to segment the\nforeground, resulting in qualitatively and quantitiatively cleaner\nsegmentations. Experiments on both artificial and real data show that the\ngraph-based method reduces the error around segmented foreground objects. A\nMATLAB code implementation is available at\nhttp://www.cs.smith.edu/~nhowe/research/code/#fgseg"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0401018v1", 
    "other_authors": "E. I. Bolotin, G. Sh. Tsitsiashvili, I. V. Golycheva", 
    "title": "Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on   the South of Russian Far East", 
    "arxiv-id": "cs/0401018v1", 
    "author": "I. V. Golycheva", 
    "publish": "2004-01-22T05:53:30Z", 
    "summary": "A method of temporal factor prognosis of TE (tick-borne encephalitis)\ninfection has been developed. The high precision of the prognosis results for a\nnumber of geographical regions of Primorsky Krai has been achieved. The method\ncan be applied not only to epidemiological research but also to others."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0402020v1", 
    "other_authors": "Tin Kam Ho", 
    "title": "Geometrical Complexity of Classification Problems", 
    "arxiv-id": "cs/0402020v1", 
    "author": "Tin Kam Ho", 
    "publish": "2004-02-11T16:34:16Z", 
    "summary": "Despite encouraging recent progresses in ensemble approaches, classification\nmethods seem to have reached a plateau in development. Further advances depend\non a better understanding of geometrical and topological characteristics of\npoint sets in high-dimensional spaces, the preservation of such characteristics\nunder feature transformations and sampling processes, and their interaction\nwith geometrical models used in classifiers. We discuss an attempt to measure\nsuch properties from data sets and relate them to classifier accuracies."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0405093v2", 
    "other_authors": "Vytautas Perlibakas", 
    "title": "Computerized Face Detection and Recognition", 
    "arxiv-id": "cs/0405093v2", 
    "author": "Vytautas Perlibakas", 
    "publish": "2004-05-25T11:36:34Z", 
    "summary": "This publication presents methods for face detection, analysis and\nrecognition: fast normalized cross-correlation (fast correlation coefficient)\nbetween multiple templates based face pre-detection method, method for\ndetection of exact face contour based on snakes and Generalized Gradient Vector\nFlow field, method for combining recognition algorithms based on Cumulative\nMatch Characteristics in order to increase recognition speed and accuracy, and\nface recognition method based on Principal Component Analysis of the Wavelet\nPacket Decomposition allowing to use PCA - based recognition method with large\nnumber of training images. For all the methods are presented experimental\nresults and comparisons of speed and accuracy with large face databases."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0405095v1", 
    "other_authors": "Lili Ma, YangQuan Chen, Kevin L. Moore", 
    "title": "Blind Detection and Compensation of Camera Lens Geometric Distortions", 
    "arxiv-id": "cs/0405095v1", 
    "author": "Kevin L. Moore", 
    "publish": "2004-05-25T22:40:42Z", 
    "summary": "This paper presents a blind detection and compensation technique for camera\nlens geometric distortions. The lens distortion introduces higher-order\ncorrelations in the frequency domain and in turn it can be detected using\nhigher-order spectral analysis tools without assuming any specific calibration\ntarget. The existing blind lens distortion removal method only considered a\nsingle-coefficient radial distortion model. In this paper, two coefficients are\nconsidered to model approximately the geometric distortion. All the models\nconsidered have analytical closed-form inverse formulae."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0406008v1", 
    "other_authors": "Vyacheslav Zavadsky", 
    "title": "Image compression by rectangular wavelet transform", 
    "arxiv-id": "cs/0406008v1", 
    "author": "Vyacheslav Zavadsky", 
    "publish": "2004-06-04T12:28:06Z", 
    "summary": "We study image compression by a separable wavelet basis\n$\\big\\{\\psi(2^{k_1}x-i)\\psi(2^{k_2}y-j),$ $\\phi(x-i)\\psi(2^{k_2}y-j),$\n$\\psi(2^{k_1}(x-i)\\phi(y-j),$ $\\phi(x-i)\\phi(y-i)\\big\\},$ where $k_1, k_2 \\in\n\\mathbb{Z}_+$; $i,j\\in\\mathbb{Z}$; and $\\phi,\\psi$ are elements of a standard\nbiorthogonal wavelet basis in $L_2(\\mathbb{R})$. Because $k_1\\ne k_2$, the\nsupports of the basis elements are rectangles, and the corresponding transform\nis known as the {\\em rectangular wavelet transform}. We prove that if\none-dimensional wavelet basis has $M$ dual vanishing moments then the rate of\napproximation by $N$ coefficients of rectangular wavelet transform is\n$\\mathcal{O}(N^{-M}\\log^C N)$ for functions with mixed derivative of order $M$\nin each direction.\n  The square wavelet transform yields the approximation rate is\n$\\mathcal{O}(N^{-M/2})$ for functions with all derivatives of the total order\n$M$. Thus, the rectangular wavelet transform can outperform the square one if\nan image has a mixed derivative. We provide experimental comparison of image\ncompression which shows that rectangular wavelet transform outperform the\nsquare one."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.eswa.2010.09.137", 
    "link": "http://arxiv.org/pdf/cs/0502095v2", 
    "other_authors": "Gilson A. Giraldi, Leandro S. Marturelli, Paulo S. Rodrigues", 
    "title": "Gradient Vector Flow Models for Boundary Extraction in 2D Images", 
    "arxiv-id": "cs/0502095v2", 
    "author": "Paulo S. Rodrigues", 
    "publish": "2005-02-28T15:09:08Z", 
    "summary": "The Gradient Vector Flow (GVF) is a vector diffusion approach based on\nPartial Differential Equations (PDEs). This method has been applied together\nwith snake models for boundary extraction medical images segmentation. The key\nidea is to use a diffusion-reaction PDE to generate a new external force field\nthat makes snake models less sensitivity to initialization as well as improves\nthe snake's ability to move into boundary concavities. In this paper, we\nfirstly review basic results about convergence and numerical analysis of usual\nGVF schemes. We point out that GVF presents numerical problems due to\ndiscontinuities image intensity. This point is considered from a practical\nviewpoint from which the GVF parameters must follow a relationship in order to\nimprove numerical convergence. Besides, we present an analytical analysis of\nthe GVF dependency from the parameters values. Also, we observe that the method\ncan be used for multiply connected domains by just imposing the suitable\nboundary condition. In the experimental results we verify these theoretical\npoints and demonstrate the utility of GVF on a segmentation approach that we\nhave developed based on snakes."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0505006v1", 
    "other_authors": "Emanuel Diamant", 
    "title": "Searching for image information content, its discovery, extraction, and   representation", 
    "arxiv-id": "cs/0505006v1", 
    "author": "Emanuel Diamant", 
    "publish": "2005-05-02T03:17:02Z", 
    "summary": "Image information content is known to be a complicated and controvercial\nproblem. This paper posits a new image information content definition.\nFollowing the theory of Solomonoff-Kolmogorov-Chaitin's complexity, we define\nimage information content as a set of descriptions of imafe data structures.\nThree levels of such description can be generally distinguished: 1)the global\nlevel, where the coarse structure of the entire scene is initially outlined; 2)\nthe intermediate level, where structures of separate, non-overlapping image\nregions usually associated with individual scene objects are deliniated; and 3)\nthe low-level description, where local image structures observed in a limited\nand restricted field of view are resolved. A technique for creating such image\ninformation content descriptors is developed. Its algorithm is presented and\nelucidated with some examples, which demonstrate the effectiveness of the\nproposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0507058v1", 
    "other_authors": "Emanuel Diamant", 
    "title": "Paving the Way for Image Understanding: A New Kind of Image   Decomposition is Desired", 
    "arxiv-id": "cs/0507058v1", 
    "author": "Emanuel Diamant", 
    "publish": "2005-07-22T12:18:44Z", 
    "summary": "In this paper we present an unconventional image segmentation approach which\nis devised to meet the requirements of image understanding and pattern\nrecognition tasks. Generally image understanding assumes interplay of two\nsub-processes: image information content discovery and image information\ncontent interpretation. Despite of its widespread use, the notion of \"image\ninformation content\" is still ill defined, intuitive, and ambiguous. Most\noften, it is used in the Shannon's sense, which means information content\nassessment averaged over the whole signal ensemble. Humans, however,rarely\nresort to such estimates. They are very effective in decomposing images into\ntheir meaningful constituents and focusing attention to the perceptually\nrelevant image parts. We posit that following the latest findings in human\nattention vision studies and the concepts of Kolmogorov's complexity theory an\nunorthodox segmentation approach can be proposed that provides effective image\ndecomposition to information preserving image fragments well suited for\nsubsequent image interpretation. We provide some illustrative examples,\ndemonstrating effectiveness of this approach."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0509081v1", 
    "other_authors": "Yossi Zana, Roberto M. Cesar-Jr, Regis de A. Barbosa", 
    "title": "Automatic Face Recognition System Based on Local Fourier-Bessel Features", 
    "arxiv-id": "cs/0509081v1", 
    "author": "Regis de A. Barbosa", 
    "publish": "2005-09-27T15:25:36Z", 
    "summary": "We present an automatic face verification system inspired by known properties\nof biological systems. In the proposed algorithm the whole image is converted\nfrom the spatial to polar frequency domain by a Fourier-Bessel Transform (FBT).\nUsing the whole image is compared to the case where only face image regions\n(local analysis) are considered. The resulting representations are embedded in\na dissimilarity space, where each image is represented by its distance to all\nthe other images, and a Pseudo-Fisher discriminator is built. Verification test\nresults on the FERET database showed that the local-based algorithm outperforms\nthe global-FBT version. The local-FBT algorithm performed as state-of-the-art\nmethods under different testing conditions, indicating that the proposed system\nis highly robust for expression, age, and illumination variations. We also\nevaluated the performance of the proposed system under strong occlusion\nconditions and found that it is highly robust for up to 50% of face occlusion.\nFinally, we automated completely the verification system by implementing face\nand eye detection algorithms. Under this condition, the local approach was only\nslightly superior to the global approach."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0509082v1", 
    "other_authors": "Yossi Zana, Roberto M. Cesar-JR", 
    "title": "Face Recognition Based on Polar Frequency Features", 
    "arxiv-id": "cs/0509082v1", 
    "author": "Roberto M. Cesar-JR", 
    "publish": "2005-09-27T15:50:27Z", 
    "summary": "A novel biologically motivated face recognition algorithm based on polar\nfrequency is presented. Polar frequency descriptors are extracted from face\nimages by Fourier-Bessel transform (FBT). Next, the Euclidean distance between\nall images is computed and each image is now represented by its dissimilarity\nto the other images. A Pseudo-Fisher Linear Discriminant was built on this\ndissimilarity space. The performance of Discrete Fourier transform (DFT)\ndescriptors, and a combination of both feature types was also evaluated. The\nalgorithms were tested on a 40- and 1196-subjects face database (ORL and FERET,\nrespectively). With 5 images per subject in the training and test datasets,\nerror rate on the ORL database was 3.8, 1.25 and 0.2% for the FBT, DFT, and the\ncombined classifier, respectively, as compared to 2.6% achieved by the best\nprevious algorithm. The most informative polar frequency features were\nconcentrated at low-to-medium angular frequencies coupled to low radial\nfrequencies. On the FERET database, where an affine normalization\npre-processing was applied, the FBT algorithm outperformed only the PCA in a\nrank recognition test. However, it achieved performance comparable to\nstate-of-the-art methods when evaluated by verification tests. These results\nindicate the high informative value of the polar frequency content of face\nimages in relation to recognition and verification tasks, and that the\nCartesian frequency content can complement information about the subjects'\nidentity, but possibly only when the images are not pre-normalized. Possible\nimplications for human face recognition are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.1867476", 
    "link": "http://arxiv.org/pdf/cs/0509083v1", 
    "other_authors": "Yossi Zana, Roberto M. Cesar-Jr, Rogerio S. Feris, Matthew Turk", 
    "title": "Face Verification in Polar Frequency Domain: a Biologically Motivated   Approach", 
    "arxiv-id": "cs/0509083v1", 
    "author": "Matthew Turk", 
    "publish": "2005-09-27T16:06:22Z", 
    "summary": "We present a novel local-based face verification system whose components are\nanalogous to those of biological systems. In the proposed system, after global\nregistration and normalization, three eye regions are converted from the\nspatial to polar frequency domain by a Fourier-Bessel Transform. The resulting\nrepresentations are embedded in a dissimilarity space, where each image is\nrepresented by its distance to all the other images. In this dissimilarity\nspace a Pseudo-Fisher discriminator is built. ROC and equal error rate\nverification test results on the FERET database showed that the system\nperformed at least as state-of-the-art methods and better than a system based\non polar Fourier features. The local-based system is especially robust to\nfacial expression and age variations, but sensitive to registration errors."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TMI.2006.879967", 
    "link": "http://arxiv.org/pdf/cs/0510001v2", 
    "other_authors": "Jo\u00e3o V. B. Soares, Jorge J. G. Leandro, Roberto M. Cesar Jr., Herbert F. Jelinek, Michael J. Cree", 
    "title": "Retinal Vessel Segmentation Using the 2-D Morlet Wavelet and Supervised   Classification", 
    "arxiv-id": "cs/0510001v2", 
    "author": "Michael J. Cree", 
    "publish": "2005-09-30T22:27:45Z", 
    "summary": "We present a method for automated segmentation of the vasculature in retinal\nimages. The method produces segmentations by classifying each image pixel as\nvessel or non-vessel, based on the pixel's feature vector. Feature vectors are\ncomposed of the pixel's intensity and continuous two-dimensional Morlet wavelet\ntransform responses taken at multiple scales. The Morlet wavelet is capable of\ntuning to specific frequencies, thus allowing noise filtering and vessel\nenhancement in a single step. We use a Bayesian classifier with\nclass-conditional probability density functions (likelihoods) described as\nGaussian mixtures, yielding a fast classification, while being able to model\ncomplex decision surfaces and compare its performance with the linear minimum\nsquared error classifier. The probability distributions are estimated based on\na training set of labeled pixels obtained from manual segmentations. The\nmethod's performance is evaluated on publicly available DRIVE and STARE\ndatabases of manually labeled non-mydriatic images. On the DRIVE database, it\nachieves an area under the receiver operating characteristic (ROC) curve of\n0.9598, being slightly superior than that presented by the method of Staal et\nal."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0510026v1", 
    "other_authors": "Alvaro Enriquez de Luna, Carlos Miravet, Deitze Otaduy, Carlos Dorronsoro", 
    "title": "A decision support system for ship identification based on the curvature   scale space representation", 
    "arxiv-id": "cs/0510026v1", 
    "author": "Carlos Dorronsoro", 
    "publish": "2005-10-11T08:43:04Z", 
    "summary": "In this paper, a decision support system for ship identification is\npresented. The system receives as input a silhouette of the vessel to be\nidentified, previously extracted from a side view of the object. This view\ncould have been acquired with imaging sensors operating at different spectral\nranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and\ncompared to those stored in a database, retrieving a small number of potential\nmatches ranked by their similarity to the target silhouette. This set of\npotential matches is presented to the system operator, who makes the final ship\nidentification. This system makes use of an evolved version of the Curvature\nScale Space (CSS) representation. In the proposed approach, it is curvature\nextrema, instead of zero crossings, that are tracked during silhouette\nevolution, hence improving robustness and enabling to cope successfully with\ncases where the standard CCS representation is found to be unstable. Also, the\nuse of local curvature was replaced with the more robust concept of lobe\nconcavity, with significant additional gains in performance. Experimental\nresults on actual operational imagery prove the excellent performance and\nrobustness of the developed method."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0512084v1", 
    "other_authors": "Nikita Sakhanenko, Hanna Makaruk", 
    "title": "Understanding physics from interconnected data", 
    "arxiv-id": "cs/0512084v1", 
    "author": "Hanna Makaruk", 
    "publish": "2005-12-21T20:23:38Z", 
    "summary": "Metal melting on release after explosion is a physical system far from\nquilibrium. A complete physical model of this system does not exist, because\nmany interrelated effects have to be considered. General methodology needs to\nbe developed so as to describe and understand physical phenomena involved.\n  The high noise of the data, moving blur of images, the high degree of\nuncertainty due to the different types of sensors, and the information\nentangled and hidden inside the noisy images makes reasoning about the physical\nprocesses very difficult. Major problems include proper information extraction\nand the problem of reconstruction, as well as prediction of the missing data.\nIn this paper, several techniques addressing the first problem are given,\nbuilding the basis for tackling the second problem."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0601105v3", 
    "other_authors": "Vassilios S. Vassiliadis", 
    "title": "The Perceptron Algorithm: Image and Signal Decomposition, Compression,   and Analysis by Iterative Gaussian Blurring", 
    "arxiv-id": "cs/0601105v3", 
    "author": "Vassilios S. Vassiliadis", 
    "publish": "2006-01-24T17:23:17Z", 
    "summary": "A novel algorithm for tunable compression to within the precision of\nreproduction targets, or storage, is proposed. The new algorithm is termed the\n`Perceptron Algorithm', which utilises simple existing concepts in a novel way,\nhas multiple immediate commercial application aspects as well as it opens up a\nmultitude of fronts in computational science and technology. The aims of this\npaper are to present the concepts underlying the algorithm, observations by its\napplication to some example cases, and the identification of a multitude of\npotential areas of applications such as: image compression by orders of\nmagnitude, signal compression including sound as well, image analysis in a\nmultilayered detailed analysis, pattern recognition and matching and rapid\ndatabase searching (e.g. face recognition), motion analysis, biomedical\napplications e.g. in MRI and CAT scan image analysis and compression, as well\nas hints on the link of these ideas to the way how biological memory might work\nleading to new points of view in neural computation. Commercial applications of\nimmediate interest are the compression of images at the source (e.g.\nphotographic equipment, scanners, satellite imaging systems), DVD film\ncompression, pay-per-view downloads acceleration and many others identified in\nthe present paper at its conclusion and future work section."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0601106v1", 
    "other_authors": "Vassilios S. Vassiliadis", 
    "title": "The `Face on Mars': a photographic approach for the search of signs of   past civilizations from a macroscopic point of view, factoring long-term   erosion in image reconstruction", 
    "arxiv-id": "cs/0601106v1", 
    "author": "Vassilios S. Vassiliadis", 
    "publish": "2006-01-24T18:12:00Z", 
    "summary": "This short article presents an alternative view of high resolution imaging\nfrom various sources with the aim of the discovery of potential sites of\narchaeological importance, or sites that exhibit `anomalies' such that they may\nmerit closer inspection and analysis. It is conjectured, and to a certain\nextent demonstrated here, that it is possible for advanced civilizations to\nfactor in erosion by natural processes into a large scale design so that main\nfeatures be preserved even with the passage of millions of years. Alternatively\nviewed, even without such intent embedded in a design left for posterity, it is\npossible that a gigantic construction may naturally decay in such a way that\neven cataclysmic (massive) events may leave sufficient information intact with\nthe passage of time, provided one changes the point of view from high\nresolution images to enhanced blurred renderings of the sites in question."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0602044v1", 
    "other_authors": "Siddharth Arora, Jayadev Acharya, Amit Verma, Prasanta K. Panigrahi", 
    "title": "Multilevel Thresholding for Image Segmentation through a Fast   Statistical Recursive Algorithm", 
    "arxiv-id": "cs/0602044v1", 
    "author": "Prasanta K. Panigrahi", 
    "publish": "2006-02-12T18:22:41Z", 
    "summary": "A novel algorithm is proposed for segmenting an image into multiple levels\nusing its mean and variance. Starting from the extreme pixel values at both\nends of the histogram plot, the algorithm is applied recursively on sub-ranges\ncomputed from the previous step, so as to find a threshold level and a new\nsub-range for the next step, until no significant improvement in image quality\ncan be achieved. The method makes use of the fact that a number of\ndistributions tend towards Dirac delta function, peaking at the mean, in the\nlimiting condition of vanishing variance. The procedure naturally provides for\nvariable size segmentation with bigger blocks near the extreme pixel values and\nfiner divisions around the mean or other chosen value for better visualization.\nExperiments on a variety of images show that the new algorithm effectively\nsegments the image in computationally very less time."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0603041v1", 
    "other_authors": "S. Hemachander, Amit Verma, Siddharth Arora, Prasanta K. Panigrahi", 
    "title": "Locally Adaptive Block Thresholding Method with Continuity Constraint", 
    "arxiv-id": "cs/0603041v1", 
    "author": "Prasanta K. Panigrahi", 
    "publish": "2006-03-09T17:14:00Z", 
    "summary": "We present an algorithm that enables one to perform locally adaptive block\nthresholding, while maintaining image continuity. Images are divided into\nsub-images based some standard image attributes and thresholding technique is\nemployed over the sub-images. The present algorithm makes use of the thresholds\nof neighboring sub-images to calculate a range of values. The image continuity\nis taken care by choosing the threshold of the sub-image under consideration to\nlie within the above range. After examining the average range values for\nvarious sub-image sizes of a variety of images, it was found that the range of\nacceptable threshold values is substantially high, justifying our assumption of\nexploiting the freedom of range for bringing out local details."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0603086v1", 
    "other_authors": "Joel Le Roux, Philippe Chaurand, Mickael Urrutia", 
    "title": "Matching Edges in Images ; Application to Face Recognition", 
    "arxiv-id": "cs/0603086v1", 
    "author": "Mickael Urrutia", 
    "publish": "2006-03-22T14:51:53Z", 
    "summary": "This communication describes a representation of images as a set of edges\ncharacterized by their position and orientation. This representation allows the\ncomparison of two images and the computation of their similarity. The first\nstep in this computation of similarity is the seach of a geometrical basis of\nthe two dimensional space where the two images are represented simultaneously\nafter transformation of one of them. Presently, this simultaneous\nrepresentation takes into account a shift and a scaling ; it may be extended to\nrotations or other global geometrical transformations. An elementary\nprobabilistic computation shows that a sufficient but not excessive number of\ntrials (a few tens) ensures that the exhibition of this common basis is\nguaranteed in spite of possible errors in the detection of edges. When this\nfirst step is performed, the search of similarity between the two images\nreduces to counting the coincidence of edges in the two images. The approach\nmay be applied to many problems of pattern matching ; it was checked on face\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0603116v2", 
    "other_authors": "G. A. Giraldi, B. F. Moutinho, D. M. L. de Carvalho, J. C. de Oliveira", 
    "title": "Fourier Analysis and Holographic Representations of 1D and 2D Signals", 
    "arxiv-id": "cs/0603116v2", 
    "author": "J. C. de Oliveira", 
    "publish": "2006-03-29T19:07:52Z", 
    "summary": "In this paper, we focus on Fourier analysis and holographic transforms for\nsignal representation. For instance, in the case of image processing, the\nholographic representation has the property that an arbitrary portion of the\ntransformed image enables reconstruction of the whole image with details\nmissing. We focus on holographic representation defined through the Fourier\nTransforms. Thus, We firstly review some results in Fourier transform and\nFourier series. Next, we review the Discrete Holographic Fourier Transform\n(DHFT) for image representation. Then, we describe the contributions of our\nwork. We show a simple scheme for progressive transmission based on the DHFT.\nNext, we propose the Continuous Holographic Fourier Transform (CHFT) and\ndiscuss some theoretical aspects of it for 1D signals. Finally, some testes are\npresented in the experimental results"
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0604062v1", 
    "other_authors": "Liang Wu", 
    "title": "Biologically Inspired Hierarchical Model for Feature Extraction and   Localization", 
    "arxiv-id": "cs/0604062v1", 
    "author": "Liang Wu", 
    "publish": "2006-04-14T04:40:29Z", 
    "summary": "Feature extraction and matching are among central problems of computer\nvision. It is inefficent to search features over all locations and scales.\nNeurophysiological evidence shows that to locate objects in a digital image the\nhuman visual system employs visual attention to a specific object while\nignoring others. The brain also has a mechanism to search from coarse to fine.\nIn this paper, we present a feature extractor and an associated hierarchical\nsearching model to simulate such processes. With the hierarchical\nrepresentation of the object, coarse scanning is done through the matching of\nthe larger scale and precise localization is conducted through the matching of\nthe smaller scale. Experimental results justify the proposed model in its\neffectiveness and efficiency to localize features."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0605025v1", 
    "other_authors": "Vytautas Perlibakas", 
    "title": "Face Recognition using Principal Component Analysis and Log-Gabor   Filters", 
    "arxiv-id": "cs/0605025v1", 
    "author": "Vytautas Perlibakas", 
    "publish": "2006-05-07T13:30:09Z", 
    "summary": "In this article we propose a novel face recognition method based on Principal\nComponent Analysis (PCA) and Log-Gabor filters. The main advantages of the\nproposed method are its simple implementation, training, and very high\nrecognition accuracy. For recognition experiments we used 5151 face images of\n1311 persons from different sets of the FERET and AR databases that allow to\nanalyze how recognition accuracy is affected by the change of facial\nexpressions, illumination, and aging. Recognition experiments with the FERET\ndatabase (containing photographs of 1196 persons) showed that our method can\nachieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error\nRate. The experiments also showed that the accuracy of our method is less\naffected by eye location errors and used image normalization method than of\ntraditional PCA -based recognition method."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0605027v1", 
    "other_authors": "Vytautas Perlibakas", 
    "title": "Recognition of expression variant faces using masked log-Gabor features   and Principal Component Analysis", 
    "arxiv-id": "cs/0605027v1", 
    "author": "Vytautas Perlibakas", 
    "publish": "2006-05-07T15:02:53Z", 
    "summary": "In this article we propose a method for the recognition of faces with\ndifferent facial expressions. For recognition we extract feature vectors by\nusing log-Gabor filters of multiple orientations and scales. Using sliding\nwindow algorithm and variances -based masking these features are extracted at\nimage regions that are less affected by the changes of facial expressions.\nExtracted features are passed to the Principal Component Analysis (PCA) -based\nrecognition method. The results of face recognition experiments using\nexpression variant faces showed that the proposed method could achieve higher\nrecognition accuracy than many other methods. For development and testing we\nused facial images from the AR and FERET databases. Using facial photographs of\nmore than one thousand persons from the FERET database the proposed method\nachieved 96.6-98.9% first one recognition rate and 0.2-0.6% Equal Error Rate\n(EER)."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0605131v2", 
    "other_authors": "Simon P Morgan", 
    "title": "Notes on Geometric Measure Theory Applications to Image Processing;   De-noising, Segmentation, Pattern, Texture, Lines, Gestalt and Occlusion", 
    "arxiv-id": "cs/0605131v2", 
    "author": "Simon P Morgan", 
    "publish": "2006-05-29T13:27:38Z", 
    "summary": "Regularization functionals that lower level set boundary length when used\nwith L^1 fidelity functionals on signal de-noising on images create artifacts.\nThese are (i) rounding of corners, (ii) shrinking of radii, (iii) shrinking of\ncusps, and (iv) non-smoothing of staircasing. Regularity functionals based upon\ntotal curvature of level set boundaries do not create artifacts (i) and (ii).\nAn adjusted fidelity term based on the flat norm on the current (a\ndistributional graph) representing the density of curvature of level sets\nboundaries can minimize (iii) by weighting the position of a cusp. A regularity\nterm to eliminate staircasing can be based upon the mass of the current\nrepresenting the graph of an image function or its second derivatives.\nDensities on the Grassmann bundle of the Grassmann bundle of the ambient space\nof the graph can be used to identify patterns, textures, occlusion and lines."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609010v1", 
    "other_authors": "Artur Rataj", 
    "title": "An effective edge--directed frequency filter for removal of aliasing in   upsampled images", 
    "arxiv-id": "cs/0609010v1", 
    "author": "Artur Rataj", 
    "publish": "2006-09-04T13:04:57Z", 
    "summary": "Raster images can have a range of various distortions connected to their\nraster structure. Upsampling them might in effect substantially yield the\nraster structure of the original image, known as aliasing. The upsampling\nitself may introduce aliasing into the upsampled image as well. The presented\nmethod attempts to remove the aliasing using frequency filters based on the\ndiscrete fast Fourier transform, and applied directionally in certain regions\nplaced along the edges in the image.\n  As opposed to some anisotropic smoothing methods, the presented algorithm\naims to selectively reduce only the aliasing, preserving the sharpness of image\ndetails.\n  The method can be used as a post--processing filter along with various\nupsampling algorithms. It was experimentally shown that the method can improve\nthe visual quality of the upsampled images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609100v1", 
    "other_authors": "Florent Ranchin, Antonin Chambolle, Fran\u00e7oise Dibos", 
    "title": "Total Variation Minimization and Graph Cuts for Moving Objects   Segmentation", 
    "arxiv-id": "cs/0609100v1", 
    "author": "Fran\u00e7oise Dibos", 
    "publish": "2006-09-18T06:40:44Z", 
    "summary": "In this paper, we are interested in the application to video segmentation of\nthe discrete shape optimization problem involving the shape weighted perimeter\nand an additional term depending on a parameter. Based on recent works and in\nparticular the one of Darbon and Sigelle, we justify the equivalence of the\nshape optimization problem and a weighted total variation regularization. For\nsolving this problem, we adapt the projection algorithm proposed recently for\nsolving the basic TV regularization problem. Another solution to the shape\noptimization investigated here is the graph cut technique. Both methods have\nthe advantage to lead to a global minimum. Since we can distinguish moving\nobjects from static elements of a scene by analyzing norm of the optical flow\nvectors, we choose the optical flow norm as initial data. In order to have the\ncontour as close as possible to an edge in the image, we use a classical edge\ndetector function as the weight of the weighted total variation. This model has\nbeen used in one of our former works. We also apply the same methods to a video\nsegmentation model used by Jehan-Besson, Barlaud and Aubert. In this case, only\nstandard perimeter is incorporated in the shape functional. We also propose\nanother way for finding moving objects by using an a contrario detection of\nobjects on the image obtained by solving the Rudin-Osher-Fatemi Total Variation\nregularization problem.We can notice the segmentation can be associated to a\nlevel set in the former methods."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609164v1", 
    "other_authors": "S. Aogaki, I. Moritani, T. Sugai, F. Takeutchi, F. M. Toyama", 
    "title": "Conditional Expressions for Blind Deconvolution: Multi-point form", 
    "arxiv-id": "cs/0609164v1", 
    "author": "F. M. Toyama", 
    "publish": "2006-09-29T13:48:35Z", 
    "summary": "We present conditional expression (CE) for finding blurs convolved in given\nimages. The CE is given in terms of the zero-values of the blurs evaluated at\nmulti-point. The CE can detect multiple blur all at once. We illustrate the\nmultiple blur-detection by using a test image."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0609165v1", 
    "other_authors": "S. Aogaki, I. Moritani, T. Sugai, F. Takeutchi, F. M. Toyama", 
    "title": "Simple method to eliminate blur based on Lane and Bates algorithm", 
    "arxiv-id": "cs/0609165v1", 
    "author": "F. M. Toyama", 
    "publish": "2006-09-29T13:50:12Z", 
    "summary": "A simple search method for finding a blur convolved in a given image is\npresented. The method can be easily extended to a large blur. The method has\nbeen experimentally tested with a model blurred image."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.630532", 
    "link": "http://arxiv.org/pdf/cs/0610002v1", 
    "other_authors": "S. Aogaki, I. Moritani, T. Sugai, F. Takeutchi, F. M. Toyama", 
    "title": "Conditional Expressions for Blind Deconvolution: Derivative form", 
    "arxiv-id": "cs/0610002v1", 
    "author": "F. M. Toyama", 
    "publish": "2006-09-30T08:05:02Z", 
    "summary": "We developed novel conditional expressions (CEs) for Lane and Bates' blind\ndeconvolution. The CEs are given in term of the derivatives of the zero-values\nof the z-transform of given images. The CEs make it possible to automatically\ndetect multiple blur convolved in the given images all at once without\nperforming any analysis of the zero-sheets of the given images. We illustrate\nthe multiple blur-detection by the CEs for a model image"
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0610059v2", 
    "other_authors": "Claire Jonchery, Fran\u00e7oise Dibos, Georges Koepfler", 
    "title": "Camera motion estimation through planar deformation determination", 
    "arxiv-id": "cs/0610059v2", 
    "author": "Georges Koepfler", 
    "publish": "2006-10-11T09:31:52Z", 
    "summary": "In this paper, we propose a global method for estimating the motion of a\ncamera which films a static scene. Our approach is direct, fast and robust, and\ndeals with adjacent frames of a sequence. It is based on a quadratic\napproximation of the deformation between two images, in the case of a scene\nwith constant depth in the camera coordinate system. This condition is very\nrestrictive but we show that provided translation and depth inverse variations\nare small enough, the error on optical flow involved by the approximation of\ndepths by a constant is small. In this context, we propose a new model of\ncamera motion, that allows to separate the image deformation in a similarity\nand a ``purely'' projective application, due to change of optical axis\ndirection. This model leads to a quadratic approximation of image deformation\nthat we estimate with an M-estimator; we can immediatly deduce camera motion\nparameters."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0611115v1", 
    "other_authors": "Peter Horvath, Ian Jermyn, Zoltan Kato, Josiane Zerubia", 
    "title": "A higher-order active contour model of a `gas of circles' and its   application to tree crown extraction", 
    "arxiv-id": "cs/0611115v1", 
    "author": "Josiane Zerubia", 
    "publish": "2006-11-22T13:44:11Z", 
    "summary": "Many image processing problems involve identifying the region in the image\ndomain occupied by a given entity in the scene. Automatic solution of these\nproblems requires models that incorporate significant prior knowledge about the\nshape of the region. Many methods for including such knowledge run into\ndifficulties when the topology of the region is unknown a priori, for example\nwhen the entity is composed of an unknown number of similar objects.\nHigher-order active contours (HOACs) represent one method for the modelling of\nnon-trivial prior knowledge about shape without necessarily constraining region\ntopology, via the inclusion of non-local interactions between region boundary\npoints in the energy defining the model. The case of an unknown number of\ncircular objects arises in a number of domains, e.g. medical, biological,\nnanotechnological, and remote sensing imagery. Regions composed of an a priori\nunknown number of circles may be referred to as a `gas of circles'. In this\nreport, we present a HOAC model of a `gas of circles'. In order to guarantee\nstable circles, we conduct a stability analysis via a functional Taylor\nexpansion of the HOAC energy around a circular shape. This analysis fixes one\nof the model parameters in terms of the others and constrains the rest. In\nconjunction with a suitable likelihood energy, we apply the model to the\nextraction of tree crowns from aerial imagery, and show that the new model\noutperforms other techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0701150v1", 
    "other_authors": "Luc Brun, Walter G. Kropatsch", 
    "title": "Contains and Inside relationships within combinatorial Pyramids", 
    "arxiv-id": "cs/0701150v1", 
    "author": "Walter G. Kropatsch", 
    "publish": "2007-01-24T15:13:06Z", 
    "summary": "Irregular pyramids are made of a stack of successively reduced graphs\nembedded in the plane. Such pyramids are used within the segmentation framework\nto encode a hierarchy of partitions. The different graph models used within the\nirregular pyramid framework encode different types of relationships between\nregions. This paper compares different graph models used within the irregular\npyramid framework according to a set of relationships between regions. We also\ndefine a new algorithm based on a pyramid of combinatorial maps which allows to\ndetermine if one region contains the other using only local calculus."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-008-0086-1", 
    "link": "http://arxiv.org/pdf/cs/0703053v1", 
    "other_authors": "Guray Erus, Nicolas Lom\u00e9nie", 
    "title": "Extraction of cartographic objects in high resolution satellite images   for object model generation", 
    "arxiv-id": "cs/0703053v1", 
    "author": "Nicolas Lom\u00e9nie", 
    "publish": "2007-03-12T15:57:23Z", 
    "summary": "The aim of this study is to detect man-made cartographic objects in\nhigh-resolution satellite images. New generation satellites offer a sub-metric\nspatial resolution, in which it is possible (and necessary) to develop methods\nat object level rather than at pixel level, and to exploit structural features\nof objects. With this aim, a method to generate structural object models from\nmanually segmented images has been developed. To generate the model from\nnon-segmented images, extraction of the objects from the sample images is\nrequired. A hybrid method of extraction (both in terms of input sources and\nsegmentation algorithms) is proposed: A region based segmentation is applied on\na 10 meter resolution multi-spectral image. The result is used as marker in a\n\"marker-controlled watershed method using edges\" on a 2.5 meter resolution\npanchromatic image. Very promising results have been obtained even on images\nwhere the limits of the target objects are not apparent."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0704.1267v1", 
    "other_authors": "Laurence Likforman-Sulem, Abderrazak Zahour, Bruno Taconet", 
    "title": "Text Line Segmentation of Historical Documents: a Survey", 
    "arxiv-id": "0704.1267v1", 
    "author": "Bruno Taconet", 
    "publish": "2007-04-10T16:26:42Z", 
    "summary": "There is a huge amount of historical documents in libraries and in various\nNational Archives that have not been exploited electronically. Although\nautomatic reading of complete pages remains, in most cases, a long-term\nobjective, tasks such as word spotting, text/image alignment, authentication\nand extraction of specific fields are in use today. For all these tasks, a\nmajor step is document segmentation into text lines. Because of the low quality\nand the complexity of these documents (background noise, artifacts due to\naging, interfering lines),automatic text line segmentation remains an open\nresearch field. The objective of this paper is to present a survey of existing\nmethods, developed during the last decade, and dedicated to documents of\nhistorical interest."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0214v1", 
    "other_authors": "Mourad Zerai, Maher Moakher", 
    "title": "Riemannian level-set methods for tensor-valued data", 
    "arxiv-id": "0705.0214v1", 
    "author": "Maher Moakher", 
    "publish": "2007-05-02T07:32:58Z", 
    "summary": "We present a novel approach for the derivation of PDE modeling\ncurvature-driven flows for matrix-valued data. This approach is based on the\nRiemannian geometry of the manifold of Symmetric Positive Definite Matrices\nPos(n)."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0449v1", 
    "other_authors": "Pierre-Fran\u00e7ois Marteau, Gilbas M\u00e9nier", 
    "title": "Multiresolution Approximation of Polygonal Curves in Linear Complexity", 
    "arxiv-id": "0705.0449v1", 
    "author": "Gilbas M\u00e9nier", 
    "publish": "2007-05-03T12:47:31Z", 
    "summary": "We propose a new algorithm to the problem of polygonal curve approximation\nbased on a multiresolution approach. This algorithm is suboptimal but still\nmaintains some optimality between successive levels of resolution using dynamic\nprogramming. We show theoretically and experimentally that this algorithm has a\nlinear complexity in time and space. We experimentally compare the outcomes of\nour algorithm to the optimal \"full search\" dynamic programming solution and\nfinally to classical merge and split approaches. The experimental evaluations\nconfirm the theoretical derivations and show that the proposed approach\nevaluated on 2D coastal maps either show a lower time complexity or provide\npolygonal approximations closer to the input discrete curves."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0781v1", 
    "other_authors": "Jonathan M. Spiller, T. Marwala", 
    "title": "Medical Image Segmentation and Localization using Deformable Templates", 
    "arxiv-id": "0705.0781v1", 
    "author": "T. Marwala", 
    "publish": "2007-05-06T06:02:46Z", 
    "summary": "This paper presents deformable templates as a tool for segmentation and\nlocalization of biological structures in medical images. Structures are\nrepresented by a prototype template, combined with a parametric warp mapping\nused to deform the original shape. The localization procedure is achieved using\na multi-stage, multi-resolution algorithm de-signed to reduce computational\ncomplexity and time. The algorithm initially identifies regions in the image\nmost likely to contain the desired objects and then examines these regions at\nprogressively increasing resolutions. The final stage of the algorithm involves\nwarping the prototype template to match the localized objects. The algorithm is\npresented along with the results of four example applications using MRI, x-ray\nand ultrasound images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0828v1", 
    "other_authors": "D. L. Falk, D. M. Rubin, T. Marwala", 
    "title": "Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field   Annealing", 
    "arxiv-id": "0705.0828v1", 
    "author": "T. Marwala", 
    "publish": "2007-05-06T23:08:04Z", 
    "summary": "Nuclear medicine (NM) images inherently suffer from large amounts of noise\nand blur. The purpose of this research is to reduce the noise and blur while\nmaintaining image integrity for improved diagnosis. The proposed solution is to\nincrease image quality after the standard pre- and post-processing undertaken\nby a gamma camera system. Mean Field Annealing (MFA) is the image processing\ntechnique used in this research. It is a computational iterative technique that\nmakes use of the Point Spread Function (PSF) and the noise associated with the\nNM image. MFA is applied to NM images with the objective of reducing noise\nwhile not compromising edge integrity. Using a sharpening filter as a\npost-processing technique (after MFA) yields image enhancement of planar NM\nimages."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.0952v1", 
    "other_authors": "Dhiresh R. Surajpal, Tshilidzi Marwala", 
    "title": "An Independent Evaluation of Subspace Face Recognition Algorithms", 
    "arxiv-id": "0705.0952v1", 
    "author": "Tshilidzi Marwala", 
    "publish": "2007-05-07T19:19:55Z", 
    "summary": "This paper explores a comparative study of both the linear and kernel\nimplementations of three of the most popular Appearance-based Face Recognition\nprojection classes, these being the methodologies of Principal Component\nAnalysis, Linear Discriminant Analysis and Independent Component Analysis. The\nexperimental procedure provides a platform of equal working conditions and\nexamines the ten algorithms in the categories of expression, illumination,\nocclusion and temporal delay. The results are then evaluated based on a\nsequential combination of assessment tools that facilitate both intuitive and\nstatistical decisiveness among the intra and interclass comparisons. The best\ncategorical algorithms are then incorporated into a hybrid methodology, where\nthe advantageous effects of fusion strategies are considered."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0705.3593v2", 
    "other_authors": "W. Jacquet, P. de Groen", 
    "title": "MI image registration using prior knowledge", 
    "arxiv-id": "0705.3593v2", 
    "author": "P. de Groen", 
    "publish": "2007-05-24T14:41:11Z", 
    "summary": "Subtraction of aligned images is a means to assess changes in a wide variety\nof clinical applications. In this paper we explore the information theoretical\norigin of Mutual Information (MI), which is based on Shannon's entropy.However,\nthe interpretation of standard MI registration as a communication channel\nsuggests that MI is too restrictive a criterion. In this paper the concept of\nMutual Information (MI) is extended to (Normalized) Focussed Mutual Information\n(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We\nuse this to develop new methodologies to successfully address specific\nregistration problems, the follow-up of dental restorations, cephalometry, and\nthe monitoring of implants."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0706.0300v1", 
    "other_authors": "Simon Scurrell, Tshilidzi Marwala, David Rubin", 
    "title": "Automatic Detection of Pulmonary Embolism using Computational   Intelligence", 
    "arxiv-id": "0706.0300v1", 
    "author": "David Rubin", 
    "publish": "2007-06-03T05:17:38Z", 
    "summary": "This article describes the implementation of a system designed to\nautomatically detect the presence of pulmonary embolism in lung scans. These\nimages are firstly segmented, before alignment and feature extraction using\nPCA. The neural network was trained using the Hybrid Monte Carlo method,\nresulting in a committee of 250 neural networks and good results are obtained."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0709.1771v1", 
    "other_authors": "Heng Lian", 
    "title": "Variational local structure estimation for image super-resolution", 
    "arxiv-id": "0709.1771v1", 
    "author": "Heng Lian", 
    "publish": "2007-09-12T08:41:36Z", 
    "summary": "Super-resolution is an important but difficult problem in image/video\nprocessing. If a video sequence or some training set other than the given\nlow-resolution image is available, this kind of extra information can greatly\naid in the reconstruction of the high-resolution image. The problem is\nsubstantially more difficult with only a single low-resolution image on hand.\nThe image reconstruction methods designed primarily for denoising is\ninsufficient for super-resolution problem in the sense that it tends to\noversmooth images with essentially no noise. We propose a new adaptive linear\ninterpolation method based on variational method and inspired by local linear\nembedding (LLE). The experimental result shows that our method avoids the\nproblem of oversmoothing and preserves image structures well."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0709.1920v2", 
    "other_authors": "Aurelie Bugeau, Patrick P\u00e9rez", 
    "title": "Bandwidth selection for kernel estimation in mixed multi-dimensional   spaces", 
    "arxiv-id": "0709.1920v2", 
    "author": "Patrick P\u00e9rez", 
    "publish": "2007-09-12T16:02:25Z", 
    "summary": "Kernel estimation techniques, such as mean shift, suffer from one major\ndrawback: the kernel bandwidth selection. The bandwidth can be fixed for all\nthe data set or can vary at each points. Automatic bandwidth selection becomes\na real challenge in case of multidimensional heterogeneous features. This paper\npresents a solution to this problem. It is an extension of \\cite{Comaniciu03a}\nwhich was based on the fundamental property of normal distributions regarding\nthe bias of the normalized density gradient. The selection is done iteratively\nfor each type of features, by looking for the stability of local bandwidth\nestimates across a predefined range of bandwidths. A pseudo balloon mean shift\nfiltering and partitioning are introduced. The validity of the method is\ndemonstrated in the context of color image segmentation based on a\n5-dimensional space."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0709.3013v2", 
    "other_authors": "Patrick H\u00e9as, Mihai Datcu", 
    "title": "Supervised learning on graphs of spatio-temporal similarity in satellite   image sequences", 
    "arxiv-id": "0709.3013v2", 
    "author": "Mihai Datcu", 
    "publish": "2007-09-19T13:18:18Z", 
    "summary": "High resolution satellite image sequences are multidimensional signals\ncomposed of spatio-temporal patterns associated to numerous and various\nphenomena. Bayesian methods have been previously proposed in (Heas and Datcu,\n2005) to code the information contained in satellite image sequences in a graph\nrepresentation using Bayesian methods. Based on such a representation, this\npaper further presents a supervised learning methodology of semantics\nassociated to spatio-temporal patterns occurring in satellite image sequences.\nIt enables the recognition and the probabilistic retrieval of similar events.\nIndeed, graphs are attached to statistical models for spatio-temporal\nprocesses, which at their turn describe physical changes in the observed scene.\nTherefore, we adjust a parametric model evaluating similarity types between\ngraph patterns in order to represent user-specific semantics attached to\nspatio-temporal phenomena. The learning step is performed by the incremental\ndefinition of similarity types via user-provided spatio-temporal pattern\nexamples attached to positive or/and negative semantics. From these examples,\nprobabilities are inferred using a Bayesian network and a Dirichlet model. This\nenables to links user interest to a specific similarity model between graph\npatterns. According to the current state of learning, semantic posterior\nprobabilities are updated for all possible graph patterns so that similar\nspatio-temporal phenomena can be recognized and retrieved from the image\nsequence. Few experiments performed on a multi-spectral SPOT image sequence\nillustrate the proposed spatio-temporal recognition method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.0043v2", 
    "other_authors": "Julian J. McAuley, Tiberio S. Caetano, Marconi S. Barbosa", 
    "title": "Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching", 
    "arxiv-id": "0710.0043v2", 
    "author": "Marconi S. Barbosa", 
    "publish": "2007-09-29T06:19:09Z", 
    "summary": "A recent paper \\cite{CaeCaeSchBar06} proposed a provably optimal, polynomial\ntime method for performing near-isometric point pattern matching by means of\nexact probabilistic inference in a chordal graphical model. Their fundamental\nresult is that the chordal graph in question is shown to be globally rigid,\nimplying that exact inference provides the same matching solution as exact\ninference in a complete graphical model. This implies that the algorithm is\noptimal when there is no noise in the point patterns. In this paper, we present\na new graph which is also globally rigid but has an advantage over the graph\nproposed in \\cite{CaeCaeSchBar06}: its maximal clique size is smaller,\nrendering inference significantly more efficient. However, our graph is not\nchordal and thus standard Junction Tree algorithms cannot be directly applied.\nNevertheless, we show that loopy belief propagation in such a graph converges\nto the optimal solution. This allows us to retain the optimality guarantee in\nthe noiseless case, while substantially reducing both memory requirements and\nprocessing time. Our experimental results show that the accuracy of the\nproposed solution is indistinguishable from that of \\cite{CaeCaeSchBar06} when\nthere is noise in the point patterns."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.0243v1", 
    "other_authors": "Julian John McAuley, Tiberio S. Caetano", 
    "title": "High-Order Nonparametric Belief-Propagation for Fast Image Inpainting", 
    "arxiv-id": "0710.0243v1", 
    "author": "Tiberio S. Caetano", 
    "publish": "2007-10-01T09:18:36Z", 
    "summary": "In this paper, we use belief-propagation techniques to develop fast\nalgorithms for image inpainting. Unlike traditional gradient-based approaches,\nwhich may require many iterations to converge, our techniques achieve\ncompetitive results after only a few iterations. On the other hand, while\nbelief-propagation techniques are often unable to deal with high-order models\ndue to the explosion in the size of messages, we avoid this problem by\napproximating our high-order prior model using a Gaussian mixture. By using\nsuch an approximation, we are able to inpaint images quickly while at the same\ntime retaining good visual results."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.2037v2", 
    "other_authors": "Wu Jiang, Fei Ding, Qiao-liang Xiang", 
    "title": "An Affinity Propagation Based method for Vector Quantization Codebook   Design", 
    "arxiv-id": "0710.2037v2", 
    "author": "Qiao-liang Xiang", 
    "publish": "2007-10-10T15:12:20Z", 
    "summary": "In this paper, we firstly modify a parameter in affinity propagation (AP) to\nimprove its convergence ability, and then, we apply it to vector quantization\n(VQ) codebook design problem. In order to improve the quality of the resulted\ncodebook, we combine the improved AP (IAP) with the conventional LBG algorithm\nto generate an effective algorithm call IAP-LBG. According to the experimental\nresults, the proposed method not only enhances the convergence abilities but\nalso is capable of providing higher-quality codebooks than conventional LBG\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0710.2231v1", 
    "other_authors": "Daniel Keysers", 
    "title": "Comparison and Combination of State-of-the-art Techniques for   Handwritten Character Recognition: Topping the MNIST Benchmark", 
    "arxiv-id": "0710.2231v1", 
    "author": "Daniel Keysers", 
    "publish": "2007-10-11T12:22:27Z", 
    "summary": "Although the recognition of isolated handwritten digits has been a research\ntopic for many years, it continues to be of interest for the research community\nand for commercial applications. We show that despite the maturity of the\nfield, different approaches still deliver results that vary enough to allow\nimprovements by using their combination. We do so by choosing four\nwell-motivated state-of-the-art recognition systems for which results on the\nstandard MNIST benchmark are available. When comparing the errors made, we\nobserve that the errors made differ between all four systems, suggesting the\nuse of classifier combination. We then determine the error rate of a\nhypothetical system that combines the output of the four systems. The result\nobtained in this manner is an error rate of 0.35% on the MNIST data, the best\nresult published so far. We furthermore discuss the statistical significance of\nthe combined result and of the results of the individual classifiers."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.0131v1", 
    "other_authors": "Thomas M. Breuel", 
    "title": "Learning Similarity for Character Recognition and 3D Object Recognition", 
    "arxiv-id": "0712.0131v1", 
    "author": "Thomas M. Breuel", 
    "publish": "2007-12-02T10:02:01Z", 
    "summary": "I describe an approach to similarity motivated by Bayesian methods. This\nyields a similarity function that is learnable using a standard Bayesian\nmethods. The relationship of the approach to variable kernel and variable\nmetric methods is discussed. The approach is related to variable kernel\nExperimental results on character recognition and 3D object recognition are\npresented.."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.0136v1", 
    "other_authors": "Thomas M. Breuel", 
    "title": "Learning View Generalization Functions", 
    "arxiv-id": "0712.0136v1", 
    "author": "Thomas M. Breuel", 
    "publish": "2007-12-02T10:54:40Z", 
    "summary": "Learning object models from views in 3D visual object recognition is usually\nformulated either as a function approximation problem of a function describing\nthe view-manifold of an object, or as that of learning a class-conditional\ndensity. This paper describes an alternative framework for learning in visual\nobject recognition, that of learning the view-generalization function. Using\nthe view-generalization function, an observer can perform Bayes-optimal 3D\nobject recognition given one or more 2D training views directly, without the\nneed for a separate model acquisition step. The paper shows that view\ngeneralization functions can be computationally practical by restating two\nwidely-used methods, the eigenspace and linear combination of views approaches,\nin a view generalization framework. The paper relates the approach to recent\nmethods for object recognition based on non-uniform blurring. The paper\npresents results both on simulated 3D ``paperclip'' objects and real-world\nimages from the COIL-100 database showing that useful view-generalization\nfunctions can be realistically be learned from a comparatively small number of\ntraining examples."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.0137v1", 
    "other_authors": "Thomas M. Breuel", 
    "title": "View Based Methods can achieve Bayes-Optimal 3D Recognition", 
    "arxiv-id": "0712.0137v1", 
    "author": "Thomas M. Breuel", 
    "publish": "2007-12-02T11:02:37Z", 
    "summary": "This paper proves that visual object recognition systems using only 2D\nEuclidean similarity measurements to compare object views against previously\nseen views can achieve the same recognition performance as observers having\naccess to all coordinate information and able of using arbitrary 3D models\ninternally. Furthermore, it demonstrates that such systems do not require more\ntraining views than Bayes-optimal 3D model-based systems. For building computer\nvision systems, these results imply that using view-based or appearance-based\ntechniques with carefully constructed combination of evidence mechanisms may\nnot be at a disadvantage relative to 3D model-based systems. For computational\napproaches to human vision, they show that it is impossible to distinguish\nview-based and 3D model-based techniques for 3D object recognition solely by\ncomparing the performance achievable by human and 3D model-based systems.}"
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.1878v1", 
    "other_authors": "Jean Hugues Pruvot, Luc Brun", 
    "title": "Hierarchy construction schemes within the Scale set framework", 
    "arxiv-id": "0712.1878v1", 
    "author": "Luc Brun", 
    "publish": "2007-12-12T07:45:08Z", 
    "summary": "Segmentation algorithms based on an energy minimisation framework often\ndepend on a scale parameter which balances a fit to data and a regularising\nterm. Irregular pyramids are defined as a stack of graphs successively reduced.\nWithin this framework, the scale is often defined implicitly as the height in\nthe pyramid. However, each level of an irregular pyramid can not usually be\nreadily associated to the global optimum of an energy or a global criterion on\nthe base level graph. This last drawback is addressed by the scale set\nframework designed by Guigues. The methods designed by this author allow to\nbuild a hierarchy and to design cuts within this hierarchy which globally\nminimise an energy. This paper studies the influence of the construction scheme\nof the initial hierarchy on the resulting optimal cuts. We propose one\nsequential and one parallel method with two variations within both. Our\nsequential methods provide partitions near the global optima while parallel\nmethods require less execution times than the sequential method of Guigues even\non sequential machines."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.2923v1", 
    "other_authors": "Roumen Anguelov, Inger Plaskitt", 
    "title": "A Class of LULU Operators on Multi-Dimensional Arrays", 
    "arxiv-id": "0712.2923v1", 
    "author": "Inger Plaskitt", 
    "publish": "2007-12-18T10:43:23Z", 
    "summary": "The LULU operators for sequences are extended to multi-dimensional arrays via\nthe morphological concept of connection in a way which preserves their\nessential properties, e.g. they are separators and form a four element fully\nordered semi-group. The power of the operators is demonstrated by deriving a\ntotal variation preserving discrete pulse decomposition of images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0712.4015v1", 
    "other_authors": "Sreechakra Goparaju, Jayadev Acharya, Ajoy K. Ray, Jaideva C. Goswami", 
    "title": "A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased   Estimators", 
    "arxiv-id": "0712.4015v1", 
    "author": "Jaideva C. Goswami", 
    "publish": "2007-12-24T17:11:56Z", 
    "summary": "This paper proposes a novel method for segmentation of images by hierarchical\nmultilevel thresholding. The method is global, agglomerative in nature and\ndisregards pixel locations. It involves the optimization of the ratio of the\nunbiased estimators of within class to between class variances. We obtain a\nrecursive relation at each step for the variances which expedites the process.\nThe efficacy of the method is shown in a comparison with some well-known\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0801.4807v1", 
    "other_authors": "Syed Ali Raza Jafri, Mireille Boutin, Edward J. Delp", 
    "title": "Automatic Text Area Segmentation in Natural Images", 
    "arxiv-id": "0801.4807v1", 
    "author": "Edward J. Delp", 
    "publish": "2008-01-31T01:46:32Z", 
    "summary": "We present a hierarchical method for segmenting text areas in natural images.\nThe method assumes that the text is written with a contrasting color on a more\nor less uniform background. But no assumption is made regarding the language or\ncharacter set used to write the text. In particular, the text can contain\nsimple graphics or symbols. The key feature of our approach is that we first\nconcentrate on finding the background of the text, before testing whether there\nis actually text on the background. Since uniform areas are easy to find in\nnatural images, and since text backgrounds define areas which contain \"holes\"\n(where the text is written) we thus look for uniform areas containing \"holes\"\nand label them as text backgrounds candidates. Each candidate area is then\nfurther tested for the presence of text within its convex hull. We tested our\nmethod on a database of 65 images including English and Urdu text. The method\ncorrectly segmented all the text areas in 63 of these images, and in only 4 of\nthese were areas that do not contain text also segmented."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0802.3528v1", 
    "other_authors": "Fionn Murtagh, Jean-Luc Starck", 
    "title": "Wavelet and Curvelet Moments for Image Classification: Application to   Aggregate Mixture Grading", 
    "arxiv-id": "0802.3528v1", 
    "author": "Jean-Luc Starck", 
    "publish": "2008-02-24T18:25:51Z", 
    "summary": "We show the potential for classifying images of mixtures of aggregate, based\nthemselves on varying, albeit well-defined, sizes and shapes, in order to\nprovide a far more effective approach compared to the classification of\nindividual sizes and shapes. While a dominant (additive, stationary) Gaussian\nnoise component in image data will ensure that wavelet coefficients are of\nGaussian distribution, long tailed distributions (symptomatic, for example, of\nextreme values) may well hold in practice for wavelet coefficients. Energy (2nd\norder moment) has often been used for image characterization for image\ncontent-based retrieval, and higher order moments may be important also, not\nleast for capturing long tailed distributional behavior. In this work, we\nassess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet\nand curvelet transform -- coefficients as features. As analysis methodology,\ntaking account of image types, multiresolution transforms, and moments of\ncoefficients in the scales or bands, we use correspondence analysis as well as\nk-nearest neighbors supervised classification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0804.1982v2", 
    "other_authors": "Li Chen, Yongwu Rong", 
    "title": "Linear Time Recognition Algorithms for Topological Invariants in 3D", 
    "arxiv-id": "0804.1982v2", 
    "author": "Yongwu Rong", 
    "publish": "2008-04-12T03:13:33Z", 
    "summary": "In this paper, we design linear time algorithms to recognize and determine\ntopological invariants such as the genus and homology groups in 3D. These\nproperties can be used to identify patterns in 3D image recognition. This has\ntremendous amount of applications in 3D medical image analysis. Our method is\nbased on cubical images with direct adjacency, also called (6,26)-connectivity\nimages in discrete geometry. According to the fact that there are only six\ntypes of local surface points in 3D and a discrete version of the well-known\nGauss-Bonnett Theorem in differential geometry, we first determine the genus of\na closed 2D-connected component (a closed digital surface). Then, we use\nAlexander duality to obtain the homology groups of a 3D object in 3D space."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.1854v2", 
    "other_authors": "Alexandre Noma, Ana B. V. Graciano, Luis Augusto Consularo, Roberto M. Cesar-Jr, Isabelle Bloch", 
    "title": "A New Algorithm for Interactive Structural Image Segmentation", 
    "arxiv-id": "0805.1854v2", 
    "author": "Isabelle Bloch", 
    "publish": "2008-05-13T13:39:19Z", 
    "summary": "This paper proposes a novel algorithm for the problem of structural image\nsegmentation through an interactive model-based approach. Interaction is\nexpressed in the model creation, which is done according to user traces drawn\nover a given input image. Both model and input are then represented by means of\nattributed relational graphs derived on the fly. Appearance features are taken\ninto account as object attributes and structural properties are expressed as\nrelational attributes. To cope with possible topological differences between\nboth graphs, a new structure called the deformation graph is introduced. The\nsegmentation process corresponds to finding a labelling of the input graph that\nminimizes the deformations introduced in the model when it is updated with\ninput information. This approach has shown to be faster than other segmentation\nmethods, with competitive output quality. Therefore, the method solves the\nproblem of multiple label segmentation in an efficient way. Encouraging results\non both natural and target-specific color images, as well as examples showing\nthe reusability of the model, are presented and discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.2324v1", 
    "other_authors": "Zhang Yu, Shi Zhong-ke, Wang Run-quan", 
    "title": "A multilateral filtering method applied to airplane runway image", 
    "arxiv-id": "0805.2324v1", 
    "author": "Wang Run-quan", 
    "publish": "2008-05-15T13:15:08Z", 
    "summary": "By considering the features of the airport runway image filtering, an\nimproved bilateral filtering method was proposed which can remove noise with\nedge preserving. Firstly the steerable filtering decomposition is used to\ncalculate the sub-band parameters of 4 orients, and the texture feature matrix\nis then obtained from the sub-band local median energy. The texture similar,\nthe spatial closer and the color similar functions are used to filter the\nimage.The effect of the weighting function parameters is qualitatively analyzed\nalso. In contrast with the standard bilateral filter and the simulation results\nfor the real airport runway image show that the multilateral filtering is more\neffective than the standard bilateral filtering."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.2690v1", 
    "other_authors": "M. V. Konnik, E. A. Manykin, S. N. Starikov", 
    "title": "Increasing Linear Dynamic Range of Commercial Digital Photocamera Used   in Imaging Systems with Optical Coding", 
    "arxiv-id": "0805.2690v1", 
    "author": "S. N. Starikov", 
    "publish": "2008-05-17T17:15:26Z", 
    "summary": "Methods of increasing linear optical dynamic range of commercial photocamera\nfor optical-digital imaging systems are described. Use of such methods allows\nto use commercial photocameras for optical measurements. Experimental results\nare reported."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.3217v1", 
    "other_authors": "Fran\u00e7ois Lecellier, St\u00e9phanie Jehan-Besson, Jalal Fadili, Gilles Aubert, Marinette Revenu", 
    "title": "Statistical region-based active contours with exponential family   observations", 
    "arxiv-id": "0805.3217v1", 
    "author": "Marinette Revenu", 
    "publish": "2008-05-21T07:54:07Z", 
    "summary": "In this paper, we focus on statistical region-based active contour models\nwhere image features (e.g. intensity) are random variables whose distribution\nbelongs to some parametric family (e.g. exponential) rather than confining\nourselves to the special Gaussian case. Using shape derivation tools, our\neffort focuses on constructing a general expression for the derivative of the\nenergy (with respect to a domain) and derive the corresponding evolution speed.\nA general result is stated within the framework of multi-parameter exponential\nfamily. More particularly, when using Maximum Likelihood estimators, the\nevolution speed has a closed-form expression that depends simply on the\nprobability density function, while complicating additive terms appear when\nusing other estimators, e.g. moments method. Experimental results on both\nsynthesized and real images demonstrate the applicability of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10032-006-0023-z", 
    "link": "http://arxiv.org/pdf/0805.3218v1", 
    "other_authors": "Fran\u00e7ois Lecellier, St\u00e9phanie Jehan-Besson, Jalal Fadili, Gilles Aubert, Marinette Revenu, Eric Saloux", 
    "title": "Region-based active contour with noise and shape priors", 
    "arxiv-id": "0805.3218v1", 
    "author": "Eric Saloux", 
    "publish": "2008-05-21T08:06:01Z", 
    "summary": "In this paper, we propose to combine formally noise and shape priors in\nregion-based active contours. On the one hand, we use the general framework of\nexponential family as a prior model for noise. On the other hand, translation\nand scale invariant Legendre moments are considered to incorporate the shape\nprior (e.g. fidelity to a reference shape). The combination of the two prior\nterms in the active contour functional yields the final evolution equation\nwhose evolution speed is rigorously derived using shape derivative tools.\nExperimental results on both synthetic images and real life cardiac echography\ndata clearly demonstrate the robustness to initialization and noise,\nflexibility and large potential applicability of our segmentation algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0805.3964v2", 
    "other_authors": "Fabricio Martins Lopes, David Correa Martins-Jr, Roberto M. Cesar-Jr", 
    "title": "DimReduction - Interactive Graphic Environment for Dimensionality   Reduction", 
    "arxiv-id": "0805.3964v2", 
    "author": "Roberto M. Cesar-Jr", 
    "publish": "2008-05-26T14:16:06Z", 
    "summary": "Feature selection is a pattern recognition approach to choose important\nvariables according to some criteria to distinguish or explain certain\nphenomena. There are many genomic and proteomic applications which rely on\nfeature selection to answer questions such as: selecting signature genes which\nare informative about some biological state, e.g. normal tissues and several\ntypes of cancer; or defining a network of prediction or inference among\nelements such as genes, proteins, external stimuli and other elements of\ninterest. In these applications, a recurrent problem is the lack of samples to\nperform an adequate estimate of the joint probabilities between element states.\nA myriad of feature selection algorithms and criterion functions are proposed,\nalthough it is difficult to point the best solution in general. The intent of\nthis work is to provide an open-source multiplataform graphical environment to\napply, test and compare many feature selection approaches suitable to be used\nin bioinformatics problems."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0808.2227v1", 
    "other_authors": "C Bhattacharya", 
    "title": "Higher Order Moments Generation by Mellin Transform for Compound Models   of Clutter", 
    "arxiv-id": "0808.2227v1", 
    "author": "C Bhattacharya", 
    "publish": "2008-08-16T01:34:48Z", 
    "summary": "The compound models of clutter statistics are found suitable to describe the\nnonstationary nature of radar backscattering from high-resolution observations.\nIn this letter, we show that the properties of Mellin transform can be utilized\nto generate higher order moments of simple and compound models of clutter\nstatistics in a compact manner."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0809.1802v1", 
    "other_authors": "William Brouwer, Saurabh Kataria, Sujatha Das, Prasenjit Mitra, C. L. Giles", 
    "title": "Automatic Identification and Data Extraction from 2-Dimensional Plots in   Digital Documents", 
    "arxiv-id": "0809.1802v1", 
    "author": "C. L. Giles", 
    "publish": "2008-09-10T14:43:37Z", 
    "summary": "Most search engines index the textual content of documents in digital\nlibraries. However, scholarly articles frequently report important findings in\nfigures for visual impact and the contents of these figures are not indexed.\nThese contents are often invaluable to the researcher in various fields, for\nthe purposes of direct comparison with their own work. Therefore, searching for\nfigures and extracting figure data are important problems. To the best of our\nknowledge, there exists no tool to automatically extract data from figures in\ndigital documents. If we can extract data from these images automatically and\nstore them in a database, an end-user can query and combine data from multiple\ndigital documents simultaneously and efficiently. We propose a framework based\non image analysis and machine learning to extract information from 2-D plot\nimages and store them in a database. The proposed algorithm identifies a 2-D\nplot and extracts the axis labels, legend and the data points from the 2-D\nplot. We also segregate overlapping shapes that correspond to different data\npoints. We demonstrate performance of individual algorithms, using a\ncombination of generated and real-life images."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0809.3083v1", 
    "other_authors": "Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro, Andrew Zisserman", 
    "title": "Supervised Dictionary Learning", 
    "arxiv-id": "0809.3083v1", 
    "author": "Andrew Zisserman", 
    "publish": "2008-09-18T07:16:34Z", 
    "summary": "It is now well established that sparse signal models are well suited to\nrestoration tasks and can effectively be learned from audio, image, and video\ndata. Recent research has been aimed at learning discriminative sparse models\ninstead of purely reconstructive ones. This paper proposes a new step in that\ndirection, with a novel sparse representation for signals belonging to\ndifferent classes in terms of a shared dictionary and multiple class-decision\nfunctions. The linear variant of the proposed model admits a simple\nprobabilistic interpretation, while its most general variant admits an\ninterpretation in terms of kernels. An optimization framework for learning all\nthe components of the proposed model is presented, along with experimental\nresults on standard handwritten digit and texture classification tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0809.3690v1", 
    "other_authors": "Steffen K\u00fchn, Clemens G\u00fchmann", 
    "title": "Modeling and Control with Local Linearizing Nadaraya Watson Regression", 
    "arxiv-id": "0809.3690v1", 
    "author": "Clemens G\u00fchmann", 
    "publish": "2008-09-22T12:08:24Z", 
    "summary": "Black box models of technical systems are purely descriptive. They do not\nexplain why a system works the way it does. Thus, black box models are\ninsufficient for some problems. But there are numerous applications, for\nexample, in control engineering, for which a black box model is absolutely\nsufficient. In this article, we describe a general stochastic framework with\nwhich such models can be built easily and fully automated by observation.\nFurthermore, we give a practical example and show how this framework can be\nused to model and control a motorcar powertrain."
},{
    "category": "cs.CV", 
    "doi": "10.1186/1471-2105-9-451", 
    "link": "http://arxiv.org/pdf/0810.3579v1", 
    "other_authors": "Fran\u00e7ois-Xavier Dup\u00e9, Luc Brun", 
    "title": "Hierarchical Bag of Paths for Kernel Based Shape Classification", 
    "arxiv-id": "0810.3579v1", 
    "author": "Luc Brun", 
    "publish": "2008-10-20T15:13:18Z", 
    "summary": "Graph kernels methods are based on an implicit embedding of graphs within a\nvector space of large dimension. This implicit embedding allows to apply to\ngraphs methods which where until recently solely reserved to numerical data.\nWithin the shape classification framework, graphs are often produced by a\nskeletonization step which is sensitive to noise. We propose in this paper to\nintegrate the robustness to structural noise by using a kernel based on a bag\nof path where each path is associated to a hierarchy encoding successive\nsimplifications of the path. Several experiments prove the robustness and the\nflexibility of our approach compared to alternative shape classification\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0810.4426v2", 
    "other_authors": "Edward Rosten, Rohan Loveland", 
    "title": "Camera distortion self-calibration using the plumb-line constraint and   minimal Hough entropy", 
    "arxiv-id": "0810.4426v2", 
    "author": "Rohan Loveland", 
    "publish": "2008-10-24T10:50:59Z", 
    "summary": "In this paper we present a simple and robust method for self-correction of\ncamera distortion using single images of scenes which contain straight lines.\nSince the most common distortion can be modelled as radial distortion, we\nillustrate the method using the Harris radial distortion model, but the method\nis applicable to any distortion model. The method is based on transforming the\nedgels of the distorted image to a 1-D angular Hough space, and optimizing the\ndistortion correction parameters which minimize the entropy of the\ncorresponding normalized histogram. Properly corrected imagery will have fewer\ncurved lines, and therefore less spread in Hough space. Since the method does\nnot rely on any image structure beyond the existence of edgels sharing some\ncommon orientations and does not use edge fitting, it is applicable to a wide\nvariety of image types. For instance, it can be applied equally well to images\nof texture with weak but dominant orientations, or images with strong vanishing\npoints. Finally, the method is performed on both synthetic and real data\nrevealing that it is particularly robust to noise."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0810.4617v2", 
    "other_authors": "Effrosyni Kokiopoulou, Pascal Frossard", 
    "title": "Graph-based classification of multiple observation sets", 
    "arxiv-id": "0810.4617v2", 
    "author": "Pascal Frossard", 
    "publish": "2008-10-25T16:02:32Z", 
    "summary": "We consider the problem of classification of an object given multiple\nobservations that possibly include different transformations. The possible\ntransformations of the object generally span a low-dimensional manifold in the\noriginal signal space. We propose to take advantage of this manifold structure\nfor the effective classification of the object represented by the observation\nset. In particular, we design a low complexity solution that is able to exploit\nthe properties of the data manifolds with a graph-based algorithm. Hence, we\nformulate the computation of the unknown label matrix as a smoothing process on\nthe manifold under the constraint that all observations represent an object of\none single class. It results into a discrete optimization problem, which can be\nsolved by an efficient and low complexity algorithm. We demonstrate the\nperformance of the proposed graph-based algorithm in the classification of sets\nof multiple images. Moreover, we show its high potential in video-based face\nrecognition, where it outperforms state-of-the-art solutions that fall short of\nexploiting the manifold structure of the face image data sets."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0810.5325v1", 
    "other_authors": "R. Sala Llonch, E. Kokiopoulou, I. Tosic, P. Frossard", 
    "title": "3D Face Recognition with Sparse Spherical Representations", 
    "arxiv-id": "0810.5325v1", 
    "author": "P. Frossard", 
    "publish": "2008-10-29T17:43:54Z", 
    "summary": "This paper addresses the problem of 3D face recognition using simultaneous\nsparse approximations on the sphere. The 3D face point clouds are first aligned\nwith a novel and fully automated registration process. They are then\nrepresented as signals on the 2D sphere in order to preserve depth and geometry\ninformation. Next, we implement a dimensionality reduction process with\nsimultaneous sparse approximations and subspace projection. It permits to\nrepresent each 3D face by only a few spherical functions that are able to\ncapture the salient facial characteristics, and hence to preserve the\ndiscriminant facial information. We eventually perform recognition by effective\nmatching in the reduced space, where Linear Discriminant Analysis can be\nfurther activated for improved recognition performance. The 3D face recognition\nalgorithm is evaluated on the FRGC v.1.0 data set, where it is shown to\noutperform classical state-of-the-art solutions that work with depth images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0811.4699v2", 
    "other_authors": "A. Sparavigna, R. Marazzato", 
    "title": "Mapping Images with the Coherence Length Diagrams", 
    "arxiv-id": "0811.4699v2", 
    "author": "R. Marazzato", 
    "publish": "2008-11-28T12:11:21Z", 
    "summary": "Statistical pattern recognition methods based on the Coherence Length Diagram\n(CLD) have been proposed for medical image analyses, such as quantitative\ncharacterisation of human skin textures, and for polarized light microscopy of\nliquid crystal textures. Further investigations are made on image maps\noriginated from such diagram and some examples related to irregularity of\nmicrostructures are shown."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0812.1340v2", 
    "other_authors": "B. Baykant Alagoz", 
    "title": "Obtaining Depth Maps From Color Images By Region Based Stereo Matching   Algorithms", 
    "arxiv-id": "0812.1340v2", 
    "author": "B. Baykant Alagoz", 
    "publish": "2008-12-07T11:42:41Z", 
    "summary": "In the paper, region based stereo matching algorithms are developed for\nextraction depth information from two color stereo image pair. A filter\neliminating unreliable disparity estimation was used for increasing reliability\nof the disparity map. Obtained results by algorithms were represented and\ncompared."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0812.2892v1", 
    "other_authors": "Hadi. Zayyani, Seyyedmajid Valiollahzadeh, Massoud. Babaie-Zadeh", 
    "title": "Sparse Component Analysis (SCA) in Random-valued and Salt and Pepper   Noise Removal", 
    "arxiv-id": "0812.2892v1", 
    "author": "Massoud. Babaie-Zadeh", 
    "publish": "2008-12-15T19:24:45Z", 
    "summary": "In this paper, we propose a new method for impulse noise removal from images.\nIt uses the sparsity of images in the Discrete Cosine Transform (DCT) domain.\nThe zeros in this domain give us the exact mathematical equation to reconstruct\nthe pixels that are corrupted by random-value impulse noises. The proposed\nmethod can also detect and correct the corrupted pixels. Moreover, in a simpler\ncase that salt and pepper noise is the brightest and darkest pixels in the\nimage, we propose a simpler version of our method. In addition to the proposed\nmethod, we suggest a combination of the traditional median filter method with\nour method to yield better results when the percentage of the corrupted samples\nis high."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0901.4953v1", 
    "other_authors": "Marcelo Hashimoto, Roberto M. Cesar Jr", 
    "title": "A Keygraph Classification Framework for Real-Time Object Detection", 
    "arxiv-id": "0901.4953v1", 
    "author": "Roberto M. Cesar Jr", 
    "publish": "2009-01-30T19:38:44Z", 
    "summary": "In this paper, we propose a new approach for keypoint-based object detection.\nTraditional keypoint-based methods consist in classifying individual points and\nusing pose estimation to discard misclassifications. Since a single point\ncarries no relational features, such methods inherently restrict the usage of\nstructural information to the pose estimation phase. Therefore, the classifier\nconsiders purely appearance-based feature vectors, thus requiring\ncomputationally expensive feature extraction or complex probabilistic modelling\nto achieve satisfactory robustness. In contrast, our approach consists in\nclassifying graphs of keypoints, which incorporates structural information\nduring the classification phase and allows the extraction of simpler feature\nvectors that are naturally robust. In the present work, 3-vertices graphs have\nbeen considered, though the methodology is general and larger order graphs may\nbe adopted. Successful experimental results obtained for real-time object\ndetection in video sequences are reported."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0902.2788v2", 
    "other_authors": "Ali Pourmohammad, Seyed Mohammad Ahadi", 
    "title": "Using SLP Neural Network to Persian Handwritten Digits Recognition", 
    "arxiv-id": "0902.2788v2", 
    "author": "Seyed Mohammad Ahadi", 
    "publish": "2009-02-16T21:13:35Z", 
    "summary": "This paper has been withdrawn by the author ali pourmohammad."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0902.4073v1", 
    "other_authors": "Amelia Sparavigna", 
    "title": "Dipole and Quadrupole Moments in Image Processing", 
    "arxiv-id": "0902.4073v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-02-24T20:34:43Z", 
    "summary": "This paper proposes an algorithm for image processing, obtained by adapting\nto image maps the definitions of two well-known physical quantities. These\nquantities are the dipole and quadrupole moments of a charge distribution. We\nwill see how it is possible to define dipole and quadrupole moments for the\ngray-tone maps and apply them in the development of algorithms for edge\ndetection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0902.4663v1", 
    "other_authors": "Amelia Sparavigna", 
    "title": "Dipole Vectors in Images Processing", 
    "arxiv-id": "0902.4663v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-02-26T18:42:30Z", 
    "summary": "Instead of evaluating the gradient field of the brightness map of an image,\nwe propose the use of dipole vectors. This approach is obtained by adapting to\nthe image gray-tone distribution the definition of the dipole moment of charge\ndistributions. We will show how to evaluate the dipoles and obtain a vector\nfield, which can be a good alternative to the gradient field in pattern\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0904.0962v1", 
    "other_authors": "Amelia Sparavigna", 
    "title": "Color Dipole Moments for Edge Detection", 
    "arxiv-id": "0904.0962v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-04-06T16:25:08Z", 
    "summary": "Dipole and higher moments are physical quantities used to describe a charge\ndistribution. In analogy with electromagnetism, it is possible to define the\ndipole moments for a gray-scale image, according to the single aspect of a\ngray-tone map. In this paper we define the color dipole moments for color\nimages. For color maps in fact, we have three aspects, the three primary\ncolors, to consider. Associating three color charges to each pixel, color\ndipole moments can be easily defined and used for edge detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s00138-009-0196-9", 
    "link": "http://arxiv.org/pdf/0904.1613v1", 
    "other_authors": "Andriy Myronenko, Xubo Song", 
    "title": "On the closed-form solution of the rotation matrix arising in computer   vision problems", 
    "arxiv-id": "0904.1613v1", 
    "author": "Xubo Song", 
    "publish": "2009-04-09T22:15:25Z", 
    "summary": "We show the closed-form solution to the maximization of trace(A'R), where A\nis given and R is unknown rotation matrix. This problem occurs in many computer\nvision tasks involving optimal rotation matrix estimation. The solution has\nbeen continuously reinvented in different fields as part of specific problems.\nWe summarize the historical evolution of the problem and present the general\nproof of the solution. We contribute to the proof by considering the degenerate\ncases of A and discuss the uniqueness of R."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.46", 
    "link": "http://arxiv.org/pdf/0905.2635v1", 
    "other_authors": "Andriy Myronenko, Xubo Song", 
    "title": "Point-Set Registration: Coherent Point Drift", 
    "arxiv-id": "0905.2635v1", 
    "author": "Xubo Song", 
    "publish": "2009-05-15T22:28:00Z", 
    "summary": "Point set registration is a key component in many computer vision tasks. The\ngoal of point set registration is to assign correspondences between two sets of\npoints and to recover the transformation that maps one point set to the other.\nMultiple factors, including an unknown non-rigid spatial transformation, large\ndimensionality of point set, noise and outliers, make the point set\nregistration a challenging problem. We introduce a probabilistic method, called\nthe Coherent Point Drift (CPD) algorithm, for both rigid and non-rigid point\nset registration. We consider the alignment of two point sets as a probability\ndensity estimation problem. We fit the GMM centroids (representing the first\npoint set) to the data (the second point set) by maximizing the likelihood. We\nforce the GMM centroids to move coherently as a group to preserve the\ntopological structure of the point sets. In the rigid case, we impose the\ncoherence constraint by re-parametrization of GMM centroid locations with rigid\nparameters and derive a closed form solution of the maximization step of the EM\nalgorithm in arbitrary dimensions. In the non-rigid case, we impose the\ncoherence constraint by regularizing the displacement field and using the\nvariational calculus to derive the optimal transformation. We also introduce a\nfast algorithm that reduces the method computation complexity to linear. We\ntest the CPD algorithm for both rigid and non-rigid transformations in the\npresence of noise, outliers and missing points, where CPD shows accurate\nresults and outperforms current state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.46", 
    "link": "http://arxiv.org/pdf/0905.2924v1", 
    "other_authors": "Nassir Mohammad, Alexander Balinsky", 
    "title": "Colorization of Natural Images via L1 Optimization", 
    "arxiv-id": "0905.2924v1", 
    "author": "Alexander Balinsky", 
    "publish": "2009-05-18T16:07:52Z", 
    "summary": "Natural images in the colour space YUV have been observed to have a\nnon-Gaussian, heavy tailed distribution (called 'sparse') when the filter\nG(U)(r) = U(r) - sum_{s \\in N(r)} w{(Y)_{rs}} U(s), is applied to the\nchromacity channel U (and equivalently to V), where w is a weighting function\nconstructed from the intensity component Y [1]. In this paper we develop\nBayesian analysis of the colorization problem using the filter response as a\nregularization term to arrive at a non-convex optimization problem. This\nproblem is convexified using L1 optimization which often gives the same results\nfor sparse signals [2]. It is observed that L1 optimization, in many cases,\nover-performs the famous colorization algorithm by Levin et al [3]."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.46", 
    "link": "http://arxiv.org/pdf/0905.2958v3", 
    "other_authors": "J. H. Oaknin", 
    "title": "A statistical learning approach to color demosaicing", 
    "arxiv-id": "0905.2958v3", 
    "author": "J. H. Oaknin", 
    "publish": "2009-05-18T19:44:58Z", 
    "summary": "A statistical learning/inference framework for color demosaicing is\npresented. We start with simplistic assumptions about color constancy, and\nrecast color demosaicing as a blind linear inverse problem: color parameterizes\nthe unknown kernel, while brightness takes on the role of a latent variable. An\nexpectation-maximization algorithm naturally suggests itself for the estimation\nof them both. Then, as we gradually broaden the family of hypothesis where\ncolor is learned, we let our demosaicing behave adaptively, in a manner that\nreflects our prior knowledge about the statistics of color images. We show that\nwe can incorporate realistic, learned priors without essentially changing the\ncomplexity of the simple expectation-maximization algorithm we started with."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0905.3964v1", 
    "other_authors": "Mahzad Kalantari, Amir Hashemi, Franck Jung, JeanPierre Guedon", 
    "title": "A New Solution to the Relative Orientation Problem using only 3 Points   and the Vertical Direction", 
    "arxiv-id": "0905.3964v1", 
    "author": "JeanPierre Guedon", 
    "publish": "2009-05-25T08:29:01Z", 
    "summary": "This paper presents a new method to recover the relative pose between two\nimages, using three points and the vertical direction information. The vertical\ndirection can be determined in two ways: 1- using direct physical measurement\nlike IMU (inertial measurement unit), 2- using vertical vanishing point. This\nknowledge of the vertical direction solves 2 unknowns among the 3 parameters of\nthe relative rotation, so that only 3 homologous points are requested to\nposition a couple of images. Rewriting the coplanarity equations leads to a\nsimpler solution. The remaining unknowns resolution is performed by an\nalgebraic method using Grobner bases. The elements necessary to build a\nspecific algebraic solver are given in this paper, allowing for a real-time\nimplementation. The results on real and synthetic data show the efficiency of\nthis method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.1763v2", 
    "other_authors": "Behnood Gholami, Allen R. Tannenbaum, Wassim M. Haddad", 
    "title": "Segmentation of Facial Expressions Using Semi-Definite Programming and   Generalized Principal Component Analysis", 
    "arxiv-id": "0906.1763v2", 
    "author": "Wassim M. Haddad", 
    "publish": "2009-06-09T19:50:10Z", 
    "summary": "In this paper, we use semi-definite programming and generalized principal\ncomponent analysis (GPCA) to distinguish between two or more different facial\nexpressions. In the first step, semi-definite programming is used to reduce the\ndimension of the image data and \"unfold\" the manifold which the data points\n(corresponding to facial expressions) reside on. Next, GPCA is used to fit a\nseries of subspaces to the data points and associate each data point with a\nsubspace. Data points that belong to the same subspace are claimed to belong to\nthe same facial expression category. An example is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.2770v1", 
    "other_authors": "Martin Braure De Calignon, Luc Brun, Jacques-Olivier Lachaud", 
    "title": "Combinatorial pyramids and discrete geometry for energy-minimizing   segmentation", 
    "arxiv-id": "0906.2770v1", 
    "author": "Jacques-Olivier Lachaud", 
    "publish": "2009-06-15T19:33:21Z", 
    "summary": "This paper defines the basis of a new hierarchical framework for segmentation\nalgorithms based on energy minimization schemes. This new framework is based on\ntwo formal tools. First, a combinatorial pyramid encode efficiently a hierarchy\nof partitions. Secondly, discrete geometric estimators measure precisely some\nimportant geometric parameters of the regions. These measures combined with\nphotometrical and topological features of the partition allows to design energy\nterms based on discrete measures. Our segmentation framework exploits these\nenergies to build a pyramid of image partitions with a minimization scheme.\nSome experiments illustrating our framework are shown and discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.3068v1", 
    "other_authors": "Jacques-Olivier Lachaud, Benjamin Taton", 
    "title": "Deformable Model with a Complexity Independent from Image Resolution", 
    "arxiv-id": "0906.3068v1", 
    "author": "Benjamin Taton", 
    "publish": "2009-06-17T04:42:39Z", 
    "summary": "We present a parametric deformable model which recovers image components with\na complexity independent from the resolution of input images. The proposed\nmodel also automatically changes its topology and remains fully compatible with\nthe general framework of deformable models. More precisely, the image space is\nequipped with a metric that expands salient image details according to their\nstrength and their curvature. During the whole evolution of the model, the\nsampling of the contour is kept regular with respect to this metric. By this\nway, the vertex density is reduced along most parts of the curve while a high\nquality of shape representation is preserved. The complexity of the deformable\nmodel is thus improved and is no longer influenced by feature-preserving\nchanges in the resolution of input images. Building the metric requires a prior\nestimation of contour curvature. It is obtained using a robust estimator which\ninvestigates the local variations in the orientation of image gradient.\nExperimental results on both computer generated and biomedical images are\npresented to illustrate the advantages of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.3323v1", 
    "other_authors": "Andriy Myronenko, Xubo Song", 
    "title": "Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid   Image Registration", 
    "arxiv-id": "0906.3323v1", 
    "author": "Xubo Song", 
    "publish": "2009-06-17T23:24:38Z", 
    "summary": "We introduce an adaptive regularization approach. In contrast to conventional\nTikhonov regularization, which specifies a fixed regularization operator, we\nestimate it simultaneously with parameters. From a Bayesian perspective we\nestimate the prior distribution on parameters assuming that it is close to some\ngiven model distribution. We constrain the prior distribution to be a\nGauss-Markov random field (GMRF), which allows us to solve for the prior\ndistribution analytically and provides a fast optimization algorithm. We apply\nour approach to non-rigid image registration to estimate the spatial\ntransformation between two images. Our evaluation shows that the adaptive\nregularization approach significantly outperforms standard variational methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.3770v1", 
    "other_authors": "G. M. Atiqur Rahaman, Md. Mobarak Hossain", 
    "title": "Automatic Defect Detection and Classification Technique from Image: A   Special Case Using Ceramic Tiles", 
    "arxiv-id": "0906.3770v1", 
    "author": "Md. Mobarak Hossain", 
    "publish": "2009-06-20T03:00:37Z", 
    "summary": "Quality control is an important issue in the ceramic tile industry. On the\nother hand maintaining the rate of production with respect to time is also a\nmajor issue in ceramic tile manufacturing. Again, price of ceramic tiles also\ndepends on purity of texture, accuracy of color, shape etc. Considering this\ncriteria, an automated defect detection and classification technique has been\nproposed in this report that can have ensured the better quality of tiles in\nmanufacturing process as well as production rate. Our proposed method plays an\nimportant role in ceramic tiles industries to detect the defects and to control\nthe quality of ceramic tiles. This automated classification method helps us to\nacquire knowledge about the pattern of defect within a very short period of\ntime and also to decide about the recovery process so that the defected tiles\nmay not be mixed with the fresh tiles."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.4131v2", 
    "other_authors": "Josna Rao, Ghassan Hamarneh, Rafeef Abugharbieh", 
    "title": "Automatic Spatially-Adaptive Balancing of Energy Terms for Image   Segmentation", 
    "arxiv-id": "0906.4131v2", 
    "author": "Rafeef Abugharbieh", 
    "publish": "2009-06-22T21:10:46Z", 
    "summary": "Image segmentation techniques are predominately based on parameter-laden\noptimization. The objective function typically involves weights for balancing\ncompeting image fidelity and segmentation regularization cost terms. Setting\nthese weights suitably has been a painstaking, empirical process. Even if such\nideal weights are found for a novel image, most current approaches fix the\nweight across the whole image domain, ignoring the spatially-varying properties\nof object shape and image appearance. We propose a novel technique that\nautonomously balances these terms in a spatially-adaptive manner through the\nincorporation of image reliability in a graph-based segmentation framework. We\nvalidate on synthetic data achieving a reduction in mean error of 47% (p-value\n<< 0.05) when compared to the best fixed parameter segmentation. We also\npresent results on medical images (including segmentations of the corpus\ncallosum and brain tissue in MRI data) and on natural images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.4789v1", 
    "other_authors": "Amir Azizi, Hamid Reza Pourreza", 
    "title": "Efficient IRIS Recognition through Improvement of Feature Extraction and   subset Selection", 
    "arxiv-id": "0906.4789v1", 
    "author": "Hamid Reza Pourreza", 
    "publish": "2009-06-25T20:14:42Z", 
    "summary": "The selection of the optimal feature subset and the classification has become\nan important issue in the field of iris recognition. In this paper we propose\nseveral methods for iris feature subset selection and vector creation. The\ndeterministic feature sequence is extracted from the iris image by using the\ncontourlet transform technique. Contourlet transform captures the intrinsic\ngeometrical structures of iris image. It decomposes the iris image into a set\nof directional sub-bands with texture details captured in different\norientations at various scales so for reducing the feature vector dimensions we\nuse the method for extract only significant bit and information from normalized\niris images. In this method we ignore fragile bits. And finally we use SVM\n(Support Vector Machine) classifier for approximating the amount of people\nidentification in our proposed system. Experimental result show that most\nproposed method reduces processing time and increase the classification\naccuracy and also the iris feature vector length is much smaller versus the\nother methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0906.5039v1", 
    "other_authors": "Ahmed Ben Jmaa, Walid Mahdi, Yousra Ben Jemaa, Abdelmajid Ben Hamadou", 
    "title": "A new approach for digit recognition based on hand gesture analysis", 
    "arxiv-id": "0906.5039v1", 
    "author": "Abdelmajid Ben Hamadou", 
    "publish": "2009-06-27T04:46:23Z", 
    "summary": "We present in this paper a new approach for hand gesture analysis that allows\ndigit recognition. The analysis is based on extracting a set of features from a\nhand image and then combining them by using an induction graph. The most\nimportant features we extract from each image are the fingers locations, their\nheights and the distance between each pair of fingers. Our approach consists of\nthree steps: (i) Hand detection and localization, (ii) fingers extraction and\n(iii) features identification and combination to digit recognition. Each input\nimage is assumed to contain only one person, thus we apply a fuzzy classifier\nto identify the skin pixels. In the finger extraction step, we attempt to\nremove all the hand components except the fingers, this process is based on the\nhand anatomy properties. The final step consists on representing histogram of\nthe detected fingers in order to extract features that will be used for digit\nrecognition. The approach is invariant to scale, rotation and translation of\nthe hand. Some experiments have been undertaken to show the effectiveness of\nthe proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.0204v1", 
    "other_authors": "Ghassan Hamarneh", 
    "title": "Multi-Label MRF Optimization via Least Squares s-t Cuts", 
    "arxiv-id": "0907.0204v1", 
    "author": "Ghassan Hamarneh", 
    "publish": "2009-07-01T17:18:46Z", 
    "summary": "There are many applications of graph cuts in computer vision, e.g.\nsegmentation. We present a novel method to reformulate the NP-hard, k-way graph\npartitioning problem as an approximate minimal s-t graph cut problem, for which\na globally optimal solution is found in polynomial time. Each non-terminal\nvertex in the original graph is replaced by a set of ceil(log_2(k)) new\nvertices. The original graph edges are replaced by new edges connecting the new\nvertices to each other and to only two, source s and sink t, terminal nodes.\nThe weights of the new edges are obtained using a novel least squares solution\napproximating the constraints of the initial k-way setup. The minimal s-t cut\nlabels each new vertex with a binary (s vs t) \"Gray\" encoding, which is then\ndecoded into a decimal label number that assigns each of the original vertices\nto one of k classes. We analyze the properties of the approximation and present\nquantitative as well as qualitative segmentation results."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.0288v1", 
    "other_authors": "Simant Dube", 
    "title": "An Iterative Fingerprint Enhancement Algorithm Based on Accurate   Determination of Orientation Flow", 
    "arxiv-id": "0907.0288v1", 
    "author": "Simant Dube", 
    "publish": "2009-07-02T04:57:32Z", 
    "summary": "We describe an algorithm to enhance and binarize a fingerprint image. The\nalgorithm is based on accurate determination of orientation flow of the ridges\nof the fingerprint image by computing variance of the neighborhood pixels\naround a pixel in different directions. We show that an iterative algorithm\nwhich captures the mutual interdependence of orientation flow computation,\nenhancement and binarization gives very good results on poor quality images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.0418v1", 
    "other_authors": "Andrew Kae, Gary B. Huang, Erik Learned-Miller", 
    "title": "Bounding the Probability of Error for High Precision Recognition", 
    "arxiv-id": "0907.0418v1", 
    "author": "Erik Learned-Miller", 
    "publish": "2009-07-02T16:09:47Z", 
    "summary": "We consider models for which it is important, early in processing, to\nestimate some variables with high precision, but perhaps at relatively low\nrates of recall. If some variables can be identified with near certainty, then\nthey can be conditioned upon, allowing further inference to be done\nefficiently. Specifically, we consider optical character recognition (OCR)\nsystems that can be bootstrapped by identifying a subset of correctly\ntranslated document words with very high precision. This \"clean set\" is\nsubsequently used as document-specific training data. While many current OCR\nsystems produce measures of confidence for the identity of each letter or word,\nthresholding these confidence values, even at very high values, still produces\nsome errors.\n  We introduce a novel technique for identifying a set of correct words with\nvery high precision. Rather than estimating posterior probabilities, we bound\nthe probability that any given word is incorrect under very general\nassumptions, using an approximate worst case analysis. As a result, the\nparameters of the model are nearly irrelevant, and we are able to identify a\nsubset of words, even in noisy documents, of which we are highly confident. On\nour set of 10 documents, we are able to identify about 6% of the words on\naverage without making a single error. This ability to produce word lists with\nvery high precision allows us to use a family of models which depends upon such\nclean word lists."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.1545v1", 
    "other_authors": "Se Baek Oh, George Barbastathis, Ramesh Raskar", 
    "title": "Augmenting Light Field to model Wave Optics effects", 
    "arxiv-id": "0907.1545v1", 
    "author": "Ramesh Raskar", 
    "publish": "2009-07-09T13:43:12Z", 
    "summary": "The ray-based 4D light field representation cannot be directly used to\nanalyze diffractive or phase--sensitive optical elements. In this paper, we\nexploit tools from wave optics and extend the light field representation via a\nnovel \"light field transform\". We introduce a key modification to the\nray--based model to support the transform. We insert a \"virtual light source\",\nwith potentially negative valued radiance for certain emitted rays. We create a\nlook-up table of light field transformers of canonical optical elements. The\ntwo key conclusions are that (i) in free space, the 4D light field completely\nrepresents wavefront propagation via rays with real (positive as well as\nnegative) valued radiance and (ii) at occluders, a light field composed of\nlight field transformers plus insertion of (ray--based) virtual light sources\nrepresents resultant phase and amplitude of wavefronts. For free--space\npropagation, we analyze different wavefronts and coherence possibilities. For\noccluders, we show that the light field transform is simply based on a\nconvolution followed by a multiplication operation. This formulation brings\npowerful concepts from wave optics to computer vision and graphics. We show\napplications in cubic-phase plate imaging and holographic displays."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-010-0234-2", 
    "link": "http://arxiv.org/pdf/0907.2075v1", 
    "other_authors": "Ulas Bagci, Li Bai", 
    "title": "Multiresolution Elastic Medical Image Registration in Standard Intensity   Scale", 
    "arxiv-id": "0907.2075v1", 
    "author": "Li Bai", 
    "publish": "2009-07-12T22:39:34Z", 
    "summary": "Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.3209v1", 
    "other_authors": "Ulas Bagci, Li Bai", 
    "title": "Registration of Standardized Histological Images in Feature Space", 
    "arxiv-id": "0907.3209v1", 
    "author": "Li Bai", 
    "publish": "2009-07-18T11:28:41Z", 
    "summary": "In this paper, we propose three novel and important methods for the\nregistration of histological images for 3D reconstruction. First, possible\nintensity variations and nonstandardness in images are corrected by an\nintensity standardization process which maps the image scale into a standard\nscale where the similar intensities correspond to similar tissues meaning.\nSecond, 2D histological images are mapped into a feature space where continuous\nvariables are used as high confidence image features for accurate registration.\nThird, we propose an automatic best reference slice selection algorithm that\nimproves reconstruction quality based on both image entropy and mean square\nerror of the registration process. We demonstrate that the choice of reference\nslice has a significant impact on registration error, standardization, feature\nspace and entropy information. After 2D histological slices are registered\nthrough an affine transformation with respect to an automatically chosen\nreference, the 3D volume is reconstructed by co-registering 2D slices\nelastically."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.3215v1", 
    "other_authors": "Ulas Bagci, Li Bai", 
    "title": "Fully Automatic 3D Reconstruction of Histological Images", 
    "arxiv-id": "0907.3215v1", 
    "author": "Li Bai", 
    "publish": "2009-07-18T12:32:27Z", 
    "summary": "In this paper, we propose a computational framework for 3D volume\nreconstruction from 2D histological slices using registration algorithms in\nfeature space. To improve the quality of reconstructed 3D volume, first,\nintensity variations in images are corrected by an intensity standardization\nprocess which maps image intensity scale to a standard scale where similar\nintensities correspond to similar tissues. Second, a subvolume approach is\nproposed for 3D reconstruction by dividing standardized slices into groups.\nThird, in order to improve the quality of the reconstruction process, an\nautomatic best reference slice selection algorithm is developed based on an\niterative assessment of image entropy and mean square error of the registration\nprocess. Finally, we demonstrate that the choice of the reference slice has a\nsignificant impact on registration quality and subsequent 3D reconstruction."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.3218v1", 
    "other_authors": "Ulas Bagci, Li Bai", 
    "title": "Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face   Recognition", 
    "arxiv-id": "0907.3218v1", 
    "author": "Li Bai", 
    "publish": "2009-07-18T13:03:19Z", 
    "summary": "In this paper, the problem of automatic Gabor wavelet selection for face\nrecognition is tackled by introducing an automatic algorithm based on Parallel\nAdaBoosting method. Incorporating mutual information into the algorithm leads\nto the selection procedure not only based on classification accuracy but also\non efficiency. Effective image features are selected by using properly chosen\nGabor wavelets optimised with Parallel AdaBoost method and mutual information\nto get high recognition rates with low computational cost. Experiments are\nconducted using the well-known FERET face database. In proposed framework,\nmemory and computation costs are reduced significantly and high classification\naccuracy is obtained."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.4354v1", 
    "other_authors": "Damian Eads, Edward Rosten, David Helmbold", 
    "title": "Learning Object Location Predictors with Boosting and Grammar-Guided   Feature Extraction", 
    "arxiv-id": "0907.4354v1", 
    "author": "David Helmbold", 
    "publish": "2009-07-24T18:01:08Z", 
    "summary": "We present BEAMER: a new spatially exploitative approach to learning object\ndetectors which shows excellent results when applied to the task of detecting\nobjects in greyscale aerial imagery in the presence of ambiguous and noisy\ndata. There are four main contributions used to produce these results. First,\nwe introduce a grammar-guided feature extraction system, enabling the\nexploration of a richer feature space while constraining the features to a\nuseful subset. This is specified with a rule-based generative grammar crafted\nby a human expert. Second, we learn a classifier on this data using a newly\nproposed variant of AdaBoost which takes into account the spatially correlated\nnature of the data. Third, we perform another round of training to optimize the\nmethod of converting the pixel classifications generated by boosting into a\nhigh quality set of (x, y) locations. Lastly, we carefully define three common\nproblems in object detection and define two evaluation criteria that are\ntightly matched to these problems. Major strengths of this approach are: (1) a\nway of randomly searching a broad feature space, (2) its performance when\nevaluated on well-matched evaluation criteria, and (3) its use of the location\nprediction domain to learn object detectors as well as to generate detections\nthat perform well on several tasks: object counting, tracking, and target\ndetection. We demonstrate the efficacy of BEAMER with a comprehensive\nexperimental evaluation on a challenging data set."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.770219", 
    "link": "http://arxiv.org/pdf/0907.4984v1", 
    "other_authors": "Yousra Ben Jemaa, Sana Khanfir", 
    "title": "Automatic local Gabor Features extraction for face recognition", 
    "arxiv-id": "0907.4984v1", 
    "author": "Sana Khanfir", 
    "publish": "2009-07-28T20:02:15Z", 
    "summary": "We present in this paper a biometric system of face detection and recognition\nin color images. The face detection technique is based on skin color\ninformation and fuzzy classification. A new algorithm is proposed in order to\ndetect automatically face features (eyes, mouth and nose) and extract their\ncorrespondent geometrical points. These fiducial points are described by sets\nof wavelet components which are used for recognition. To achieve the face\nrecognition, we use neural networks and we study its performances for different\ninputs. We compare the two types of features used for recognition: geometric\ndistances and Gabor coefficients which can be used either independently or\njointly. This comparison shows that Gabor coefficients are more powerful than\ngeometric distances. We show with experimental results how the importance\nrecognition ratio makes our system an effective tool for automatic face\ndetection and recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0907.5321v2", 
    "other_authors": "Tomoya Sakai", 
    "title": "Multiple pattern classification by sparse subspace decomposition", 
    "arxiv-id": "0907.5321v2", 
    "author": "Tomoya Sakai", 
    "publish": "2009-07-30T12:23:25Z", 
    "summary": "A robust classification method is developed on the basis of sparse subspace\ndecomposition. This method tries to decompose a mixture of subspaces of\nunlabeled data (queries) into class subspaces as few as possible. Each query is\nclassified into the class whose subspace significantly contributes to the\ndecomposed subspace. Multiple queries from different classes can be\nsimultaneously classified into their respective classes. A practical greedy\nalgorithm of the sparse subspace decomposition is designed for the\nclassification. The present method achieves high recognition rate and robust\nperformance exploiting joint sparsity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0908.1369v1", 
    "other_authors": "Meijun Zhu, Pengfei Zhang", 
    "title": "Segmentation for radar images based on active contour", 
    "arxiv-id": "0908.1369v1", 
    "author": "Pengfei Zhang", 
    "publish": "2009-08-10T18:33:51Z", 
    "summary": "We exam various geometric active contour methods for radar image\nsegmentation. Due to special properties of radar images, we propose our new\nmodel based on modified Chan-Vese functional. Our method is efficient in\nseparating non-meteorological noises from meteorological images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0908.1919v3", 
    "other_authors": "Patrick Erik Bradley", 
    "title": "A dyadic solution of relative pose problems", 
    "arxiv-id": "0908.1919v3", 
    "author": "Patrick Erik Bradley", 
    "publish": "2009-08-13T15:41:44Z", 
    "summary": "A hierarchical interval subdivision is shown to lead to a $p$-adic encoding\nof image data. This allows in the case of the relative pose problem in computer\nvision and photogrammetry to derive equations having 2-adic numbers as\ncoefficients, and to use Hensel's lifting method to their solution. This method\nis applied to the linear and non-linear equations coming from eight, seven or\nfive point correspondences. An inherent property of the method is its\nrobustness."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0908.4386v1", 
    "other_authors": "Reza Gharoie Ahangar, Mohammad Farajpoor Ahangar", 
    "title": "Handwritten Farsi Character Recognition using Artificial Neural Network", 
    "arxiv-id": "0908.4386v1", 
    "author": "Mohammad Farajpoor Ahangar", 
    "publish": "2009-08-30T11:55:48Z", 
    "summary": "Neural Networks are being used for character recognition from last many years\nbut most of the work was confined to English character recognition. Till date,\na very little work has been reported for Handwritten Farsi Character\nrecognition. In this paper, we have made an attempt to recognize handwritten\nFarsi characters by using a multilayer perceptron with one hidden layer. The\nerror backpropagation algorithm has been used to train the MLP network. In\naddition, an analysis has been carried out to determine the number of hidden\nnodes to achieve high performance of backpropagation network in the recognition\nof handwritten Farsi characters. The system has been trained using several\ndifferent forms of handwriting provided by both male and female participants of\ndifferent age groups. Finally, this rigorous training results an automatic HCR\nsystem using MLP network. In this work, the experiments were carried out on two\nhundred fifty samples of five writers. The results showed that the MLP networks\ntrained by the error backpropagation algorithm are superior in recognition\naccuracy and memory usage. The result indicates that the backpropagation\nnetwork provides good recognition accuracy of more than 80% of handwritten\nFarsi characters."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0910.1295v1", 
    "other_authors": "Fabien Moutarde, Alexandre Bargeton, Anne Herbin, Lowik Chanussot", 
    "title": "Modular Traffic Sign Recognition applied to on-vehicle real-time visual   detection of American and European speed limit signs", 
    "arxiv-id": "0910.1295v1", 
    "author": "Lowik Chanussot", 
    "publish": "2009-10-07T15:43:01Z", 
    "summary": "We present a new modular traffic signs recognition system, successfully\napplied to both American and European speed limit signs. Our sign detection\nstep is based only on shape-detection (rectangles or circles). This enables it\nto work on grayscale images, contrary to most European competitors, which eases\nrobustness to illumination conditions (notably night operation). Speed sign\ncandidates are classified (or rejected) by segmenting potential digits inside\nthem (which is rather original and has several advantages), and then applying a\nneural digit recognition. The global detection rate is ~90% for both (standard)\nU.S. and E.U. speed signs, with a misclassification rate <1%, and no validated\nfalse alarm in >150 minutes of video. The system processes in real-time ~20\nframes/s on a standard high-end laptop."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0910.1844v1", 
    "other_authors": "Pascal Fallavollita", 
    "title": "3D/2D Registration of Mapping Catheter Images for Arrhythmia   Interventional Assistance", 
    "arxiv-id": "0910.1844v1", 
    "author": "Pascal Fallavollita", 
    "publish": "2009-10-09T20:07:11Z", 
    "summary": "Radiofrequency (RF) catheter ablation has transformed treatment for\ntachyarrhythmias and has become first-line therapy for some tachycardias. The\nprecise localization of the arrhythmogenic site and the positioning of the RF\ncatheter over that site are problematic: they can impair the efficiency of the\nprocedure and are time consuming (several hours). Electroanatomic mapping\ntechnologies are available that enable the display of the cardiac chambers and\nthe relative position of ablation lesions. However, these are expensive and use\ncustom-made catheters. The proposed methodology makes use of standard catheters\nand inexpensive technology in order to create a 3D volume of the heart chamber\naffected by the arrhythmia. Further, we propose a novel method that uses a\npriori 3D information of the mapping catheter in order to estimate the 3D\nlocations of multiple electrodes across single view C-arm images. The monoplane\nalgorithm is tested for feasibility on computer simulations and initial canine\ndata."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0910.1849v1", 
    "other_authors": "Sanjay Silakari, Mahesh Motwani, Manish Maheshwari", 
    "title": "Color Image Clustering using Block Truncation Algorithm", 
    "arxiv-id": "0910.1849v1", 
    "author": "Manish Maheshwari", 
    "publish": "2009-10-09T20:21:23Z", 
    "summary": "With the advancement in image capturing device, the image data been generated\nat high volume. If images are analyzed properly, they can reveal useful\ninformation to the human users. Content based image retrieval address the\nproblem of retrieving images relevant to the user needs from image databases on\nthe basis of low-level visual features that can be derived from the images.\nGrouping images into meaningful categories to reveal useful information is a\nchallenging and important problem. Clustering is a data mining technique to\ngroup a set of unsupervised data based on the conceptual clustering principal:\nmaximizing the intraclass similarity and minimizing the interclass similarity.\nProposed framework focuses on color as feature. Color Moment and Block\nTruncation Coding (BTC) are used to extract features for image dataset.\nExperimental study using K-Means clustering algorithm is conducted to group the\nimage dataset into various clusters."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0910.2381v4", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "Fractional differentiation based image processing", 
    "arxiv-id": "0910.2381v4", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2009-10-13T12:37:32Z", 
    "summary": "There are many resources useful for processing images, most of them freely\navailable and quite friendly to use. In spite of this abundance of tools, a\nstudy of the processing methods is still worthy of efforts. Here, we want to\ndiscuss the possibilities arising from the use of fractional differential\ncalculus. This calculus evolved in the research field of pure mathematics until\n1920, when applied science started to use it. Only recently, fractional\ncalculus was involved in image processing methods. As we shall see, the\nfractional calculation is able to enhance the quality of images, with\ninteresting possibilities in edge detection and image restoration. We suggest\nalso the fractional differentiation as a tool to reveal faint objects in\nastronomical images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457702", 
    "link": "http://arxiv.org/pdf/0910.2917v1", 
    "other_authors": "P. M. Jodoin, V. Saligrama, J. Konrad", 
    "title": "Behavior Subtraction", 
    "arxiv-id": "0910.2917v1", 
    "author": "J. Konrad", 
    "publish": "2009-10-15T16:09:18Z", 
    "summary": "Background subtraction has been a driving engine for many computer vision and\nvideo analytics tasks. Although its many variants exist, they all share the\nunderlying assumption that photometric scene properties are either static or\nexhibit temporal stationarity. While this works in some applications, the model\nfails when one is interested in discovering {\\it changes in scene dynamics}\nrather than those in a static background; detection of unusual pedestrian and\nmotor traffic patterns is but one example. We propose a new model and\ncomputational framework that address this failure by considering stationary\nscene dynamics as a ``background'' with which observed scene dynamics are\ncompared. Central to our approach is the concept of an {\\it event}, that we\ndefine as short-term scene dynamics captured over a time window at a specific\nspatial location in the camera field of view. We compute events by\ntime-aggregating motion labels, obtained by background subtraction, as well as\nobject descriptors (e.g., object size). Subsequently, we characterize events\nprobabilistically, but use a low-memory, low-complexity surrogates in practical\nimplementation. Using these surrogates amounts to {\\it behavior subtraction}, a\nnew algorithm with some surprising properties. As demonstrated here, behavior\nsubtraction is an effective tool in anomaly detection and localization. It is\nresilient to spurious background motion, such as one due to camera jitter, and\nis content-blind, i.e., it works equally well on humans, cars, animals, and\nother objects in both uncluttered and highly-cluttered scenes. Clearly,\ntreating video as a collection of events rather than colored pixels opens new\npossibilities for video analytics."
},{
    "category": "cs.CV", 
    "doi": "10.1134/S2070046610010048", 
    "link": "http://arxiv.org/pdf/0910.4839v2", 
    "other_authors": "Patrick Erik Bradley", 
    "title": "A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting", 
    "arxiv-id": "0910.4839v2", 
    "author": "Patrick Erik Bradley", 
    "publish": "2009-10-26T09:34:29Z", 
    "summary": "A $p$-adic variation of the Ran(dom) Sa(mple) C(onsensus) method for solving\nthe relative pose problem in stereo vision is developped. From two 2-adically\nencoded images a random sample of five pairs of corresponding points is taken,\nand the equations for the essential matrix are solved by lifting solutions\nmodulo 2 to the 2-adic integers. A recently devised $p$-adic hierarchical\nclassification algorithm imitating the known LBG quantisation method classifies\nthe solutions for all the samples after having determined the number of\nclusters using the known intra-inter validity of clusterings. In the successful\ncase, a cluster ranking will determine the cluster containing a 2-adic\napproximation to the \"true\" solution of the problem."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0910.5002v1", 
    "other_authors": "Oleg Michailovich", 
    "title": "An Iterative Shrinkage Approach to Total-Variation Image Restoration", 
    "arxiv-id": "0910.5002v1", 
    "author": "Oleg Michailovich", 
    "publish": "2009-10-26T22:50:18Z", 
    "summary": "The problem of restoration of digital images from their degraded measurements\nplays a central role in a multitude of practically important applications. A\nparticularly challenging instance of this problem occurs in the case when the\ndegradation phenomenon is modeled by an ill-conditioned operator. In such a\ncase, the presence of noise makes it impossible to recover a valuable\napproximation of the image of interest without using some a priori information\nabout its properties. Such a priori information is essential for image\nrestoration, rendering it stable and robust to noise. Particularly, if the\noriginal image is known to be a piecewise smooth function, one of the standard\npriors used in this case is defined by the Rudin-Osher-Fatemi model, which\nresults in total variation (TV) based image restoration. The current arsenal of\nalgorithms for TV-based image restoration is vast. In the present paper, a\ndifferent approach to the solution of the problem is proposed based on the\nmethod of iterative shrinkage (aka iterated thresholding). In the proposed\nmethod, the TV-based image restoration is performed through a recursive\napplication of two simple procedures, viz. linear filtering and soft\nthresholding. Therefore, the method can be identified as belonging to the group\nof first-order algorithms which are efficient in dealing with images of\nrelatively large sizes. Another valuable feature of the proposed method\nconsists in its working directly with the TV functional, rather then with its\nsmoothed versions. Moreover, the method provides a single solution for both\nisotropic and anisotropic definitions of the TV functional, thereby\nestablishing a useful connection between the two formulae."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0911.0481v1", 
    "other_authors": "M. Krishnaveni, Suresh Kumar Thakur, P. Subashini", 
    "title": "An Optimal Method For Wake Detection In SAR Images Using Radon   Transformation Combined With Wavelet Filters", 
    "arxiv-id": "0911.0481v1", 
    "author": "P. Subashini", 
    "publish": "2009-11-03T03:37:03Z", 
    "summary": "A new fangled method for ship wake detection in synthetic aperture radar\n(SAR) images is explored here. Most of the detection procedure applies the\nRadon transform as its properties outfit more than any other transformation for\nthe detection purpose. But still it holds problems when the transform is\napplied to an image with a high level of noise. Here this paper articulates the\ncombination between the radon transformation and the shrinkage methods which\nincrease the mode of wake detection process. The latter shrinkage method with\nRT maximize the signal to noise ratio hence it leads to most optimal detection\nof lines in the SAR images. The originality mainly works on the denoising\nsegment of the proposed algorithm. Experimental work outs are carried over both\nin simulated and real SAR images. The detection process is more adequate with\nthe proposed method and improves better than the conventional methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0911.0490v1", 
    "other_authors": "Y. Ireaneus Anna Rejani, S. Thamarai Selvi", 
    "title": "Breast Cancer Detection Using Multilevel Thresholding", 
    "arxiv-id": "0911.0490v1", 
    "author": "S. Thamarai Selvi", 
    "publish": "2009-11-03T04:33:55Z", 
    "summary": "This paper presents an algorithm which aims to assist the radiologist in\nidentifying breast cancer at its earlier stages. It combines several image\nprocessing techniques like image negative, thresholding and segmentation\ntechniques for detection of tumor in mammograms. The algorithm is verified by\nusing mammograms from Mammographic Image Analysis Society. The results obtained\nby applying these techniques are described."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2090532", 
    "link": "http://arxiv.org/pdf/0911.4874v2", 
    "other_authors": "Amelia Carolina Sparavigna, Roberto Marazzato", 
    "title": "Non-photorealistic image processing: an Impressionist rendering", 
    "arxiv-id": "0911.4874v2", 
    "author": "Roberto Marazzato", 
    "publish": "2009-11-25T15:16:53Z", 
    "summary": "The paper describes an image processing for a non-photorealistic rendering.\nThe algorithm is based on a random choice of a set of pixels from those ot the\noriginal image and substitution of them with colour spots. An iterative\nprocedure is applied to cover, at a desired level, the canvas. The resulting\neffect mimics the impressionist painting and Pointillism."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0911.5462v1", 
    "other_authors": "Mahdi S. Hosseini, Babak N. Araabi, Hamid Soltanian-Zadeh", 
    "title": "Pigment Melanin: Pattern for Iris Recognition", 
    "arxiv-id": "0911.5462v1", 
    "author": "Hamid Soltanian-Zadeh", 
    "publish": "2009-11-29T07:07:54Z", 
    "summary": "Recognition of iris based on Visible Light (VL) imaging is a difficult\nproblem because of the light reflection from the cornea. Nonetheless, pigment\nmelanin provides a rich feature source in VL, unavailable in Near-Infrared\n(NIR) imaging. This is due to biological spectroscopy of eumelanin, a chemical\nnot stimulated in NIR. In this case, a plausible solution to observe such\npatterns may be provided by an adaptive procedure using a variational technique\non the image histogram. To describe the patterns, a shape analysis method is\nused to derive feature-code for each subject. An important question is how much\nthe melanin patterns, extracted from VL, are independent of iris texture in\nNIR. With this question in mind, the present investigation proposes fusion of\nfeatures extracted from NIR and VL to boost the recognition performance. We\nhave collected our own database (UTIRIS) consisting of both NIR and VL images\nof 158 eyes of 79 individuals. This investigation demonstrates that the\nproposed algorithm is highly sensitive to the patterns of cromophores and\nimproves the iris recognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.0600v1", 
    "other_authors": "Alireza Ghahari, Reza Aghaeizadeh Zoroofi", 
    "title": "Sequential Clustering based Facial Feature Extraction Method for   Automatic Creation of Facial Models from Orthogonal Views", 
    "arxiv-id": "0912.0600v1", 
    "author": "Reza Aghaeizadeh Zoroofi", 
    "publish": "2009-12-03T08:54:24Z", 
    "summary": "Multiview 3D face modeling has attracted increasing attention recently and\nhas become one of the potential avenues in future video systems. We aim to make\nmore reliable and robust automatic feature extraction and natural 3D feature\nconstruction from 2D features detected on a pair of frontal and profile view\nface images. We propose several heuristic algorithms to minimize possible\nerrors introduced by prevalent nonperfect orthogonal condition and noncoherent\nluminance. In our approach, we first extract the 2D features that are visible\nto both cameras in both views. Then, we estimate the coordinates of the\nfeatures in the hidden profile view based on the visible features extracted in\nthe two orthogonal views. Finally, based on the coordinates of the extracted\nfeatures, we deform a 3D generic model to perform the desired 3D clone\nmodeling. Present study proves the scope of resulted facial models for\npractical applications like face recognition and facial animation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.1310v1", 
    "other_authors": "Edward Rosten, Rohan Loveland, Mark Hickman", 
    "title": "Automatic creation of urban velocity fields from aerial video", 
    "arxiv-id": "0912.1310v1", 
    "author": "Mark Hickman", 
    "publish": "2009-12-07T19:04:41Z", 
    "summary": "In this paper, we present a system for modelling vehicle motion in an urban\nscene from low frame-rate aerial video. In particular, the scene is modelled as\na probability distribution over velocities at every pixel in the image.\n  We describe the complete system for acquiring this model. The video is\ncaptured from a helicopter and stabilized by warping the images to match an\northorectified image of the area. A pixel classifier is applied to the\nstabilized images, and the response is segmented to determine car locations and\norientations. The results are fed in to a tracking scheme which tracks cars for\nthree frames, creating tracklets. This allows the tracker to use a combination\nof velocity, direction, appearance, and acceleration cues to keep only tracks\nlikely to be correct. Each tracklet provides a measurement of the car velocity\nat every point along the tracklet's length, and these are then aggregated to\ncreate a histogram of vehicle velocities at every pixel in the image.\n  The results demonstrate that the velocity probability distribution prior can\nbe used to infer a variety of information about road lane directions, speed\nlimits, vehicle speeds and common trajectories, and traffic bottlenecks, as\nwell as providing a means of describing environmental knowledge about traffic\nrules that can be used in tracking."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.3589v1", 
    "other_authors": "Marcus Hutter, Nathan Brewer", 
    "title": "Matching 2-D Ellipses to 3-D Circles with Application to Vehicle Pose   Estimation", 
    "arxiv-id": "0912.3589v1", 
    "author": "Nathan Brewer", 
    "publish": "2009-12-18T05:58:54Z", 
    "summary": "Finding the three-dimensional representation of all or a part of a scene from\na single two dimensional image is a challenging task. In this paper we propose\na method for identifying the pose and location of objects with circular\nprotrusions in three dimensions from a single image and a 3d representation or\nmodel of the object of interest. To do this, we present a method for\nidentifying ellipses and their properties quickly and reliably with a novel\ntechnique that exploits intensity differences between objects and a geometric\ntechnique for matching an ellipse in 2d to a circle in 3d.\n  We apply these techniques to the specific problem of determining the pose and\nlocation of vehicles, particularly cars, from a single image. We have achieved\nexcellent pose recovery performance on artificially generated car images and\nshow promising results on real vehicle images. We also make use of the ellipse\ndetection method to identify car wheels from images, with a very high\nsuccessful match rate."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIM.2009.2037996", 
    "link": "http://arxiv.org/pdf/0912.3973v2", 
    "other_authors": "Angkoon Phinyomark, Chusak Limsakul, Pornchai Phukpattaranont", 
    "title": "A Novel Feature Extraction for Robust EMG Pattern Recognition", 
    "arxiv-id": "0912.3973v2", 
    "author": "Pornchai Phukpattaranont", 
    "publish": "2009-12-20T03:49:21Z", 
    "summary": "Varieties of noises are major problem in recognition of Electromyography\n(EMG) signal. Hence, methods to remove noise become most significant in EMG\nsignal analysis. White Gaussian noise (WGN) is used to represent interference\nin this paper. Generally, WGN is difficult to be removed using typical\nfiltering and solutions to remove WGN are limited. In addition, noise removal\nis an important step before performing feature extraction, which is used in\nEMG-based recognition. This research is aimed to present a novel feature that\ntolerate with WGN. As a result, noise removal algorithm is not needed. Two\nnovel mean and median frequencies (MMNF and MMDF) are presented for robust\nfeature extraction. Sixteen existing features and two novelties are evaluated\nin a noisy environment. WGN with various signal-to-noise ratios (SNRs), i.e.\n20-0 dB, was added to the original EMG signal. The results showed that MMNF\nperformed very well especially in weak EMG signal compared with others. The\nerror of MMNF in weak EMG signal with very high noise, 0 dB SNR, is about 5-10\npercent and closed by MMDF and Histogram, whereas the error of other features\nis more than 20 percent. While in strong EMG signal, the error of MMNF is\nbetter than those from other features. Moreover, the combination of MMNF,\nHistrogram of EMG and Willison amplitude is used as feature vector in\nclassification task. The experimental result shows the better recognition\nresult in noisy environment than other success feature candidates. From the\nabove results demonstrate that MMNF can be used for new robust feature\nextraction."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/0912.5502v1", 
    "other_authors": "Serguei A. Mokhov, Miao Song, Ching Y. Suen", 
    "title": "Writer Identification Using Inexpensive Signal Processing Techniques", 
    "arxiv-id": "0912.5502v1", 
    "author": "Ching Y. Suen", 
    "publish": "2009-12-30T18:19:53Z", 
    "summary": "We propose to use novel and classical audio and text signal-processing and\notherwise techniques for \"inexpensive\" fast writer identification tasks of\nscanned hand-written documents \"visually\". The \"inexpensive\" refers to the\nefficiency of the identification process in terms of CPU cycles while\npreserving decent accuracy for preliminary identification. This is a\ncomparative study of multiple algorithm combinations in a pattern recognition\npipeline implemented in Java around an open-source Modular Audio Recognition\nFramework (MARF) that can do a lot more beyond audio. We present our\npreliminary experimental findings in such an identification task. We simulate\n\"visual\" identification by \"looking\" at the hand-written document as a whole\nrather than trying to extract fine-grained features out of it prior\nclassification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.0927v1", 
    "other_authors": "Brijnesh J. Jain, Klaus Obermayer", 
    "title": "Accelerating Competitive Learning Graph Quantization", 
    "arxiv-id": "1001.0927v1", 
    "author": "Klaus Obermayer", 
    "publish": "2010-01-06T16:05:25Z", 
    "summary": "Vector quantization(VQ) is a lossy data compression technique from signal\nprocessing for which simple competitive learning is one standard method to\nquantize patterns from the input space. Extending competitive learning VQ to\nthe domain of graphs results in competitive learning for quantizing input\ngraphs. In this contribution, we propose an accelerated version of competitive\nlearning graph quantization (GQ) without trading computational time against\nsolution quality. For this, we lift graphs locally to vectors in order to avoid\nunnecessary calculations of intractable graph distances. In doing so, the\naccelerated version of competitive learning GQ gradually turns locally into a\ncompetitive learning VQ with increasing number of iterations. Empirical results\nshow a significant speedup by maintaining a comparable solution quality."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.1221v1", 
    "other_authors": "Paolo Piro, Richard Nock, Frank Nielsen, Michel Barlaud", 
    "title": "Boosting k-NN for categorization of natural scenes", 
    "arxiv-id": "1001.1221v1", 
    "author": "Michel Barlaud", 
    "publish": "2010-01-08T08:30:51Z", 
    "summary": "The k-nearest neighbors (k-NN) classification rule has proven extremely\nsuccessful in countless many computer vision applications. For example, image\ncategorization often relies on uniform voting among the nearest prototypes in\nthe space of descriptors. In spite of its good properties, the classic k-NN\nrule suffers from high variance when dealing with sparse prototype datasets in\nhigh dimensions. A few techniques have been proposed to improve k-NN\nclassification, which rely on either deforming the nearest neighborhood\nrelationship or modifying the input space. In this paper, we propose a novel\nboosting algorithm, called UNN (Universal Nearest Neighbors), which induces\nleveraged k-NN, thus generalizing the classic k-NN rule. We redefine the voting\nrule as a strong classifier that linearly combines predictions from the k\nclosest prototypes. Weak classifiers are learned by UNN so as to minimize a\nsurrogate risk. A major feature of UNN is the ability to learn which prototypes\nare the most relevant for a given class, thus allowing one for effective data\nreduction. Experimental results on the synthetic two-class dataset of Ripley\nshow that such a filtering strategy is able to reject \"noisy\" prototypes. We\ncarried out image categorization experiments on a database containing eight\nclasses of natural scenes. We show that our method outperforms significantly\nthe classic k-NN classification, while enabling significant reduction of the\ncomputational cost by means of data filtering."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.1968v1", 
    "other_authors": "M. Krishnaveni, Dr. V. Radha", 
    "title": "A Topological derivative based image segmentation for sign language   recognition system using isotropic filter", 
    "arxiv-id": "1001.1968v1", 
    "author": "Dr. V. Radha", 
    "publish": "2010-01-12T18:18:10Z", 
    "summary": "The need of sign language is increasing radically especially to hearing\nimpaired community. Only few research groups try to automatically recognize\nsign language from video, colored gloves and etc. Their approach requires a\nvalid segmentation of the data that is used for training and of the data that\nis used to be recognized. Recognition of a sign language image sequence is\nchallenging because of the variety of hand shapes and hand motions. Here, this\npaper proposes to apply a combination of image segmentation with restoration\nusing topological derivatives for achieving high recognition accuracy. Image\nquality measures are conceded here to differentiate the methods both\nsubjectively as well as objectively. Experiments show that the additional use\nof the restoration before segmenting the postures significantly improves the\ncorrect rate of hand detection, and that the discrete derivatives yields a high\nrate of discrimination between different static hand postures as well as\nbetween hand postures and the scene background. Eventually, the research is to\ncontribute to the implementation of automated sign language recognition system\nmainly established for the welfare purpose."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3487v1", 
    "other_authors": "Chow Kok Kent, Naomie Salim", 
    "title": "Features Based Text Similarity Detection", 
    "arxiv-id": "1001.3487v1", 
    "author": "Naomie Salim", 
    "publish": "2010-01-20T07:46:23Z", 
    "summary": "As the Internet help us cross cultural border by providing different\ninformation, plagiarism issue is bound to arise. As a result, plagiarism\ndetection becomes more demanding in overcoming this issue. Different plagiarism\ndetection tools have been developed based on various detection techniques.\nNowadays, fingerprint matching technique plays an important role in those\ndetection tools. However, in handling some large content articles, there are\nsome weaknesses in fingerprint matching technique especially in space and time\nconsumption issue. In this paper, we propose a new approach to detect\nplagiarism which integrates the use of fingerprint matching technique with four\nkey features to assist in the detection process. These proposed features are\ncapable to choose the main point or key sentence in the articles to be\ncompared. Those selected sentence will be undergo the fingerprint matching\nprocess in order to detect the similarity between the sentences. Hence, time\nand space usage for the comparison process is reduced without affecting the\neffectiveness of the plagiarism detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3502v1", 
    "other_authors": "Hamdan. O. Alanazi, B. B Zaidan, A. A Zaidan", 
    "title": "3D Skull Recognition Using 3D Matching Technique", 
    "arxiv-id": "1001.3502v1", 
    "author": "A. A Zaidan", 
    "publish": "2010-01-20T08:17:26Z", 
    "summary": "Biometrics has become a \"hot\" area. Governments are funding research programs\nfocused on biometrics. In this paper the problem of person recognition and\nverification based on a different biometric application has been addressed. The\nsystem is based on the 3DSkull recognition using 3D matching technique, in fact\nthis paper present several bio-metric approaches in order of assign the weak\npoint in term of used the biometric from the authorize person and insure the\nperson who access the data is the real person. The feature of the simulate\nsystem shows the capability of using 3D matching system as an efficient way to\nidentify the person through his or her skull by match it with database, this\ntechnique grantee fast processing with optimizing the false positive and\nnegative as well ."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3503v1", 
    "other_authors": "P. Rajendran, M. Madheswaran", 
    "title": "Hybrid Medical Image Classification Using Association Rule Mining with   Decision Tree Algorithm", 
    "arxiv-id": "1001.3503v1", 
    "author": "M. Madheswaran", 
    "publish": "2010-01-20T08:19:48Z", 
    "summary": "The main focus of image mining in the proposed method is concerned with the\nclassification of brain tumor in the CT scan brain images. The major steps\ninvolved in the system are: pre-processing, feature extraction, association\nrule mining and hybrid classifier. The pre-processing step has been done using\nthe median filtering process and edge features have been extracted using canny\nedge detection technique. The two image mining approaches with a hybrid manner\nhave been proposed in this paper. The frequent patterns from the CT scan images\nare generated by frequent pattern tree (FP-Tree) algorithm that mines the\nassociation rules. The decision tree method has been used to classify the\nmedical images for diagnosis. This system enhances the classification process\nto be more accurate. The hybrid method improves the efficiency of the proposed\nmethod than the traditional image mining methods. The experimental result on\nprediagnosed database of brain images showed 97% sensitivity and 95% accuracy\nrespectively. The physicians can make use of this accurate decision tree\nclassification phase for classifying the brain images into normal, benign and\nmalignant for effective medical diagnosis."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.3735v1", 
    "other_authors": "G. N. Harikrishna Rai, T. R. Gopalakrishnan Nair", 
    "title": "Gradient Based Seeded Region Grow method for CT Angiographic Image   Segmentation", 
    "arxiv-id": "1001.3735v1", 
    "author": "T. R. Gopalakrishnan Nair", 
    "publish": "2010-01-21T07:15:29Z", 
    "summary": "Segmentation of medical images using seeded region growing technique is\nincreasingly becoming a popular method because of its ability to involve\nhigh-level knowledge of anatomical structures in seed selection process. Region\nbased segmentation of medical images are widely used in varied clinical\napplications like visualization, bone detection, tumor detection and\nunsupervised image retrieval in clinical databases. As medical images are\nmostly fuzzy in nature, segmenting regions based intensity is the most\nchallenging task. In this paper, we discuss about popular seeded region grow\nmethodology used for segmenting anatomical structures in CT Angiography images.\nWe have proposed a gradient based homogeneity criteria to control the region\ngrow process while segmenting CTA images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.4189v1", 
    "other_authors": "H. B. Kekre, Tanuja K. Sarode, Saylee M. Gharge", 
    "title": "Detection and Demarcation of Tumor using Vector Quantization in MRI   images", 
    "arxiv-id": "1001.4189v1", 
    "author": "Saylee M. Gharge", 
    "publish": "2010-01-23T19:00:44Z", 
    "summary": "Segmenting a MRI images into homogeneous texture regions representing\ndisparate tissue types is often a useful preprocessing step in the\ncomputer-assisted detection of breast cancer. That is why we proposed new\nalgorithm to detect cancer in mammogram breast cancer images. In this paper we\nproposed segmentation using vector quantization technique. Here we used Linde\nBuzo-Gray algorithm (LBG) for segmentation of MRI images. Initially a codebook\nof size 128 was generated for MRI images. These code vectors were further\nclustered in 8 clusters using same LBG algorithm. These 8 images were displayed\nas a result. This approach does not leads to over segmentation or under\nsegmentation. For the comparison purpose we displayed results of watershed\nsegmentation and Entropy using Gray Level Co-occurrence Matrix along with this\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.4297v1", 
    "other_authors": "Andrew D. Straw, Kristin Branson, Titus R. Neumann, Michael H. Dickinson", 
    "title": "Multi-camera Realtime 3D Tracking of Multiple Flying Animals", 
    "arxiv-id": "1001.4297v1", 
    "author": "Michael H. Dickinson", 
    "publish": "2010-01-25T01:40:40Z", 
    "summary": "Automated tracking of animal movement allows analyses that would not\notherwise be possible by providing great quantities of data. The additional\ncapability of tracking in realtime - with minimal latency - opens up the\nexperimental possibility of manipulating sensory feedback, thus allowing\ndetailed explorations of the neural basis for control of behavior. Here we\ndescribe a new system capable of tracking the position and body orientation of\nanimals such as flies and birds. The system operates with less than 40 msec\nlatency and can track multiple animals simultaneously. To achieve these\nresults, a multi target tracking algorithm was developed based on the Extended\nKalman Filter and the Nearest Neighbor Standard Filter data association\nalgorithm. In one implementation, an eleven camera system is capable of\ntracking three flies simultaneously at 60 frames per second using a gigabit\nnetwork of nine standard Intel Pentium 4 and Core 2 Duo computers. This\nmanuscript presents the rationale and details of the algorithms employed and\nshows three implementations of the system. An experiment was performed using\nthe tracking system to measure the effect of visual contrast on the flight\nspeed of Drosophila melanogaster. At low contrasts, speed is more variable and\nfaster on average than at high contrasts. Thus, the system is already a useful\ntool to study the neurobiology and behavior of freely flying animals. If\ncombined with other techniques, such as `virtual reality'-type computer\ngraphics or genetic manipulation, the tracking system would offer a powerful\nnew way to investigate the biology of flying animals."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.5352v1", 
    "other_authors": "K. Indira, S. Sethu Selvi", 
    "title": "Kannada Character Recognition System A Review", 
    "arxiv-id": "1001.5352v1", 
    "author": "S. Sethu Selvi", 
    "publish": "2010-01-29T08:29:57Z", 
    "summary": "Intensive research has been done on optical character recognition ocr and a\nlarge number of articles have been published on this topic during the last few\ndecades. Many commercial OCR systems are now available in the market, but most\nof these systems work for Roman, Chinese, Japanese and Arabic characters. There\nare no sufficient number of works on Indian language character recognition\nespecially Kannada script among 12 major scripts in India. This paper presents\na review of existing work on printed Kannada script and their results. The\ncharacteristics of Kannada script and Kannada Character Recognition System kcr\nare discussed in detail. Finally fusion at the classifier level is proposed to\nincrease the recognition accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1001.5359v1", 
    "other_authors": "S. Rathinavel, S. Arumugam", 
    "title": "Threshold Based Indexing of Commercial Shoe Print to Create Reference   and Recovery Images", 
    "arxiv-id": "1001.5359v1", 
    "author": "S. Arumugam", 
    "publish": "2010-01-29T09:03:48Z", 
    "summary": "One of the important evidence in a crime scene that is normally overlooked\nbut very important evidence is shoe print as the criminal is normally unaware\nof the mask for this. In this paper we use image processing technique to\nprocess reference shoe images to make it index-able for a search from the\ndatabase the shoe print impressions available in the commercial market. This is\nachieved first by converting the commercially available image through the\nprocess of converting them to gray scale then apply image enhancement and\nrestoration techniques and finally do image segmentation to store the segmented\nparameter as index in the database storage. We use histogram method for image\nenhancement, inverse filtering for image restoration and threshold method for\nindexing. We use global threshold as index of the shoe print. The paper\ndescribes this method and simulation results are included to validate the\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-90-481-9112-3_74", 
    "link": "http://arxiv.org/pdf/1002.1148v1", 
    "other_authors": "Salem Saleh Al-amri, N. V. Kalyankar, S. D. Khamitkar", 
    "title": "A Comparative Study of Removal Noise from Remote Sensing Image", 
    "arxiv-id": "1002.1148v1", 
    "author": "S. D. Khamitkar", 
    "publish": "2010-02-05T08:34:39Z", 
    "summary": "This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.843969", 
    "link": "http://arxiv.org/pdf/1002.1285v1", 
    "other_authors": "Ulas Bagci, Jayaram K. Udupa, Li Bai", 
    "title": "The Influence of Intensity Standardization on Medical Image Registration", 
    "arxiv-id": "1002.1285v1", 
    "author": "Li Bai", 
    "publish": "2010-02-05T17:35:49Z", 
    "summary": "Acquisition-to-acquisition signal intensity variations (non-standardness) are\ninherent in MR images. Standardization is a post processing method for\ncorrecting inter-subject intensity variations through transforming all images\nfrom the given image gray scale into a standard gray scale wherein similar\nintensities achieve similar tissue meanings. The lack of a standard image\nintensity scale in MRI leads to many difficulties in tissue characterizability,\nimage display, and analysis, including image segmentation. This phenomenon has\nbeen documented well; however, effects of standardization on medical image\nregistration have not been studied yet. In this paper, we investigate the\ninfluence of intensity standardization in registration tasks with systematic\nand analytic evaluations involving clinical MR images. We conducted nearly\n20,000 clinical MR image registration experiments and evaluated the quality of\nregistrations both quantitatively and qualitatively. The evaluations show that\nintensity variations between images degrades the accuracy of registration\nperformance. The results imply that the accuracy of image registration not only\ndepends on spatial and geometric similarity but also on the similarity of the\nintensity values for the same tissues in different images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.1288v1", 
    "other_authors": "Ulas Bagci, Jayaram K. Udupa, Xinjian Chen", 
    "title": "Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical   Images", 
    "arxiv-id": "1002.1288v1", 
    "author": "Xinjian Chen", 
    "publish": "2010-02-05T17:54:36Z", 
    "summary": "This paper investigates, using prior shape models and the concept of ball\nscale (b-scale), ways of automatically recognizing objects in 3D images without\nperforming elaborate searches or optimization. That is, the goal is to place\nthe model in a single shot close to the right pose (position, orientation, and\nscale) in a given image so that the model boundaries fall in the close vicinity\nof object boundaries in the image. This is achieved via the following set of\nkey ideas: (a) A semi-automatic way of constructing a multi-object shape model\nassembly. (b) A novel strategy of encoding, via b-scale, the pose relationship\nbetween objects in the training images and their intensity patterns captured in\nb-scale images. (c) A hierarchical mechanism of positioning the model, in a\none-shot way, in a given image from a knowledge of the learnt pose relationship\nand the b-scale image of the given image to be segmented. The evaluation\nresults on a set of 20 routine clinical abdominal female and male CT data sets\nindicate the following: (1) Incorporating a large number of objects improves\nthe recognition accuracy dramatically. (2) The recognition algorithm can be\nthought as a hierarchical framework such that quick replacement of the model\nassembly is defined as coarse recognition and delineation itself is known as\nfinest recognition. (3) Scale yields useful information about the relationship\nbetween the model assembly and any given image such that the recognition\nresults in a placement of the model close to the actual pose without doing any\nelaborate searches or optimization. (4) Effective object recognition can make\ndelineation most accurate."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.2182v1", 
    "other_authors": "T. Balakumaran, I. L. A. Vennila, C. Gowri Shankar", 
    "title": "Detection of Microcalcification in Mammograms Using Wavelet Transform   and Fuzzy Shell Clustering", 
    "arxiv-id": "1002.2182v1", 
    "author": "C. Gowri Shankar", 
    "publish": "2010-02-10T19:22:25Z", 
    "summary": "Microcalcifications in mammogram have been mainly targeted as a reliable\nearliest sign of breast cancer and their early detection is vital to improve\nits prognosis. Since their size is very small and may be easily overlooked by\nthe examining radiologist, computer-based detection output can assist the\nradiologist to improve the diagnostic accuracy. In this paper, we have proposed\nan algorithm for detecting microcalcification in mammogram. The proposed\nmicrocalcification detection algorithm involves mammogram quality enhancement\nusing multirresolution analysis based on the dyadic wavelet transform and\nmicrocalcification detection by fuzzy shell clustering. It may be possible to\ndetect nodular components such as microcalcification accurately by introducing\nshape information. The effectiveness of the proposed algorithm for\nmicrocalcification detection is confirmed by experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.2408v1", 
    "other_authors": "D. Jayanthi, N. Devi, S. SwarnaParvathi", 
    "title": "Automatic diagnosis of retinal diseases from color retinal images", 
    "arxiv-id": "1002.2408v1", 
    "author": "S. SwarnaParvathi", 
    "publish": "2010-02-11T19:54:08Z", 
    "summary": "Teleophthalmology holds a great potential to improve the quality, access, and\naffordability in health care. For patients, it can reduce the need for travel\nand provide the access to a superspecialist. Ophthalmology lends itself easily\nto telemedicine as it is a largely image based diagnosis. The main goal of the\nproposed system is to diagnose the type of disease in the retina and to\nautomatically detect and segment retinal diseases without human supervision or\ninteraction. The proposed system will diagnose the disease present in the\nretina using a neural network based classifier.The extent of the disease spread\nin the retina can be identified by extracting the textural features of the\nretina. This system will diagnose the following type of diseases: Diabetic\nRetinopathy and Drusen."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.2418v1", 
    "other_authors": "S. M. Ramesh, A. Shanmugam", 
    "title": "Medical Image Compression using Wavelet Decomposition for Prediction   Method", 
    "arxiv-id": "1002.2418v1", 
    "author": "A. Shanmugam", 
    "publish": "2010-02-11T20:16:33Z", 
    "summary": "In this paper offers a simple and lossless compression method for compression\nof medical images. Method is based on wavelet decomposition of the medical\nimages followed by the correlation analysis of coefficients. The correlation\nanalyses are the basis of prediction equation for each sub band. Predictor\nvariable selection is performed through coefficient graphic method to avoid\nmulticollinearity problem and to achieve high prediction accuracy and\ncompression rate. The method is applied on MRI and CT images. Results show that\nthe proposed approach gives a high compression rate for MRI and CT images\ncomparing with state of the art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1002.3985v1", 
    "other_authors": "Md. Imran Hossain, Syed Golam Rajib", 
    "title": "Supervised Learning of Digital image restoration based on Quantization   Nearest Neighbor algorithm", 
    "arxiv-id": "1002.3985v1", 
    "author": "Syed Golam Rajib", 
    "publish": "2010-02-21T18:34:10Z", 
    "summary": "In this paper, an algorithm is proposed for Image Restoration. Such algorithm\nis different from the traditional approaches in this area, by utilizing priors\nthat are learned from similar images. Original images and their degraded\nversions by the known degradation operators are utilized for designing the\nQuantization. The code vectors are designed using the blurred images. For each\nsuch vector, the high frequency information obtained from the original images\nis also available. During restoration, the high frequency information of a\ngiven degraded image is estimated from its low frequency information based on\nthe artificial noise. For the restoration problem, a number of techniques are\ndesigned corresponding to various versions of the blurring function. Given a\nnoisy and blurred image, one of the techniques is chosen based on a similarity\nmeasure, therefore providing the identification of the blur. To make the\nrestoration process computationally efficient, the Quantization Nearest\nNeighborhood approaches are utilized."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0487v1", 
    "other_authors": "Chunhua Shen, Junae Kim, Lei Wang", 
    "title": "Scalable Large-Margin Mahalanobis Distance Metric Learning", 
    "arxiv-id": "1003.0487v1", 
    "author": "Lei Wang", 
    "publish": "2010-03-02T01:12:34Z", 
    "summary": "For many machine learning algorithms such as $k$-Nearest Neighbor ($k$-NN)\nclassifiers and $ k $-means clustering, often their success heavily depends on\nthe metric used to calculate distances between different data points.\n  An effective solution for defining such a metric is to learn it from a set of\nlabeled training samples. In this work, we propose a fast and scalable\nalgorithm to learn a Mahalanobis distance metric. By employing the principle of\nmargin maximization to achieve better generalization performances, this\nalgorithm formulates the metric learning as a convex optimization problem and a\npositive semidefinite (psd) matrix is the unknown variable. a specialized\ngradient descent method is proposed. our algorithm is much more efficient and\nhas a better performance in scalability compared with existing methods.\nExperiments on benchmark data sets suggest that, compared with state-of-the-art\nmetric learning algorithms, our algorithm can achieve a comparable\nclassification accuracy with reduced computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0642v2", 
    "other_authors": "Ayatullah Faruk Mollah, Subhadip Basu, Nibaran Das, Ram Sarkar, Mita Nasipuri, Mahantapas Kundu", 
    "title": "Text Region Extraction from Business Card Images for Mobile Devices", 
    "arxiv-id": "1003.0642v2", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-03-02T17:45:26Z", 
    "summary": "Designing a Business Card Reader (BCR) for mobile devices is a challenge to\nthe researchers because of huge deformation in acquired images, multiplicity in\nnature of the business cards and most importantly the computational constraints\nof the mobile devices. This paper presents a text extraction method designed in\nour work towards developing a BCR for mobile devices. At first, the background\nof a camera captured image is eliminated at a coarse level. Then, various rule\nbased techniques are applied on the Connected Components (CC) to filter out the\nnoises and picture regions. The CCs identified as text are then binarized using\nan adaptive but light-weight binarization technique. Experiments show that the\ntext extraction accuracy is around 98% for a wide range of resolutions with\nvarying computation time and memory requirements. The optimum performance is\nachieved for the images of resolution 1024x768 pixels with text extraction\naccuracy of 98.54% and, space and time requirements as 1.1 MB and 0.16 seconds\nrespectively."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0645v2", 
    "other_authors": "Ayatullah Faruk Mollah, Subhadip Basu, Nibaran Das, Ram Sarkar, Mita Nasipuri, Mahantapas Kundu", 
    "title": "Binarizing Business Card Images for Mobile Devices", 
    "arxiv-id": "1003.0645v2", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-03-02T18:02:40Z", 
    "summary": "Business card images are of multiple natures as these often contain graphics,\npictures and texts of various fonts and sizes both in background and\nforeground. So, the conventional binarization techniques designed for document\nimages can not be directly applied on mobile devices. In this paper, we have\npresented a fast binarization technique for camera captured business card\nimages. A card image is split into small blocks. Some of these blocks are\nclassified as part of the background based on intensity variance. Then the\nnon-text regions are eliminated and the text ones are skew corrected and\nbinarized using a simple yet adaptive technique. Experiment shows that the\ntechnique is fast, efficient and applicable for the mobile devices."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.0776v1", 
    "other_authors": "Roumen Anguelov, Inger Fabris-Rotelli", 
    "title": "Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays", 
    "arxiv-id": "1003.0776v1", 
    "author": "Inger Fabris-Rotelli", 
    "publish": "2010-03-03T10:58:20Z", 
    "summary": "This report presents properties of the Discrete Pulse Transform on\nmulti-dimensional arrays introduced by the authors two or so years ago. The\nmain result given here in Lemma 2.1 is also formulated in a paper to appear in\nIEEE Transactions on Image Processing. However, the proof, being too technical,\nwas omitted there and hence it appears in full in this publication."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1072v2", 
    "other_authors": "Satadal Saha, Subhadip Basu, Mita Nasipuri, Dipak Kumar Basu", 
    "title": "An Offline Technique for Localization of License Plates for Indian   Commercial Vehicles", 
    "arxiv-id": "1003.1072v2", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-03-04T15:57:41Z", 
    "summary": "Automatic License Plate Recognition (ALPR) is a challenging area of research\ndue to its importance to variety of commercial applications. The overall\nproblem may be subdivided into two key modules, firstly, localization of\nlicense plates from vehicle images, and secondly, optical character recognition\nof extracted license plates. In the current work, we have concentrated on the\nfirst part of the problem, i.e., localization of license plate regions from\nIndian commercial vehicles as a significant step towards development of a\ncomplete ALPR system for Indian vehicles. The technique is based on color based\nsegmentation of vehicle images and identification of potential license plate\nregions. True license plates are finally localized based on four spatial and\nhorizontal contrast features. The technique successfully localizes the actual\nlicense plates in 73.4% images."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1511v1", 
    "other_authors": "Rohit Katiyar, Dr. Vinay Kumar Pathak", 
    "title": "Clinical gait data analysis based on Spatio-Temporal features", 
    "arxiv-id": "1003.1511v1", 
    "author": "Dr. Vinay Kumar Pathak", 
    "publish": "2010-03-07T18:46:12Z", 
    "summary": "Analysing human gait has found considerable interest in recent computer\nvision research. So far, however, contributions to this topic exclusively dealt\nwith the tasks of person identification or activity recognition. In this paper,\nwe consider a different application for gait analysis and examine its use as a\nmeans of deducing the physical well-being of people. The proposed method is\nbased on transforming the joint motion trajectories using wavelets to extract\nspatio-temporal features which are then fed as input to a vector quantiser; a\nself-organising map for classification of walking patterns of individuals with\nand without pathology. We show that our proposed algorithm is successful in\nextracting features that successfully discriminate between individuals with and\nwithout locomotion impairment."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1803v1", 
    "other_authors": "T. K. Thivakaran, RM. Chandrasekaran", 
    "title": "Nonlinear Filter Based Image Denoising Using AMF Approach", 
    "arxiv-id": "1003.1803v1", 
    "author": "RM. Chandrasekaran", 
    "publish": "2010-03-09T07:05:47Z", 
    "summary": "This paper proposes a new technique based on nonlinear Adaptive Median filter\n(AMF) for image restoration. Image denoising is a common procedure in digital\nimage processing aiming at the removal of noise, which may corrupt an image\nduring its acquisition or transmission, while retaining its quality. This\nprocedure is traditionally performed in the spatial or frequency domain by\nfiltering. The aim of image enhancement is to reconstruct the true image from\nthe corrupted image. The process of image acquisition frequently leads to\ndegradation and the quality of the digitized image becomes inferior to the\noriginal image. Filtering is a technique for enhancing the image. Linear filter\nis the filtering in which the value of an output pixel is a linear combination\nof neighborhood values, which can produce blur in the image. Thus a variety of\nsmoothing techniques have been developed that are non linear. Median filter is\nthe one of the most popular non-linear filter. When considering a small\nneighborhood it is highly efficient but for large window and in case of high\nnoise it gives rise to more blurring to image. The Centre Weighted Median (CWM)\nfilter has got a better average performance over the median filter [8]. However\nthe original pixel corrupted and noise reduction is substantial under high\nnoise condition. Hence this technique has also blurring affect on the image. To\nillustrate the superiority of the proposed approach by overcoming the existing\nproblem, the proposed new scheme (AMF) Adaptive Median Filter has been\nsimulated along with the standard ones and various performance measures have\nbeen compared."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1819v1", 
    "other_authors": "Supriya Kapoor, Shruti Khanna, Rahul Bhatia", 
    "title": "Facial Gesture Recognition Using Correlation And Mahalanobis Distance", 
    "arxiv-id": "1003.1819v1", 
    "author": "Rahul Bhatia", 
    "publish": "2010-03-09T07:39:03Z", 
    "summary": "Augmenting human computer interaction with automated analysis and synthesis\nof facial expressions is a goal towards which much research effort has been\ndevoted recently. Facial gesture recognition is one of the important component\nof natural human-machine interfaces; it may also be used in behavioural\nscience, security systems and in clinical practice. Although humans recognise\nfacial expressions virtually without effort or delay, reliable expression\nrecognition by machine is still a challenge. The face expression recognition\nproblem is challenging because different individuals display the same\nexpression differently. This paper presents an overview of gesture recognition\nin real time using the concepts of correlation and Mahalanobis distance.We\nconsider the six universal emotional categories namely joy, anger, fear,\ndisgust, sadness and surprise."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1826v1", 
    "other_authors": "Syed Amjad Ali, Srinivasan Vathsal, K. Lal kishore", 
    "title": "A GA based Window Selection Methodology to Enhance Window based Multi   wavelet transformation and thresholding aided CT image denoising technique", 
    "arxiv-id": "1003.1826v1", 
    "author": "K. Lal kishore", 
    "publish": "2010-03-09T08:09:02Z", 
    "summary": "Image denoising is getting more significance, especially in Computed\nTomography (CT), which is an important and most common modality in medical\nimaging. This is mainly due to that the effectiveness of clinical diagnosis\nusing CT image lies on the image quality. The denoising technique for CT images\nusing window-based Multi-wavelet transformation and thresholding shows the\neffectiveness in denoising, however, a drawback exists in selecting the closer\nwindows in the process of window-based multi-wavelet transformation and\nthresholding. Generally, the windows of the duplicate noisy image that are\ncloser to each window of original noisy image are obtained by the checking them\nsequentially. This leads to the possibility of missing out very closer windows\nand so enhancement is required in the aforesaid process of the denoising\ntechnique. In this paper, we propose a GA-based window selection methodology to\ninclude the denoising technique. With the aid of the GA-based window selection\nmethodology, the windows of the duplicate noisy image that are very closer to\nevery window of the original noisy image are extracted in an effective manner.\nBy incorporating the proposed GA-based window selection methodology, the\ndenoising the CT image is performed effectively. Eventually, a comparison is\nmade between the denoising technique with and without the proposed GA-based\nwindow selection methodology."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1827v1", 
    "other_authors": "Vidhi Rawat, Alok jain, Vibhakar shrimali", 
    "title": "Investigation and Assessment of Disorder of Ultrasound B-mode Images", 
    "arxiv-id": "1003.1827v1", 
    "author": "Vibhakar shrimali", 
    "publish": "2010-03-09T08:13:37Z", 
    "summary": "Digital image plays a vital role in the early detection of cancers, such as\nprostate cancer, breast cancer, lungs cancer, cervical cancer. Ultrasound\nimaging method is also suitable for early detection of the abnormality of\nfetus. The accurate detection of region of interest in ultrasound image is\ncrucial. Since the result of reflection, refraction and deflection of\nultrasound waves from different types of tissues with different acoustic\nimpedance. Usually, the contrast in ultrasound image is very low and weak edges\nmake the image difficult to identify the fetus region in the ultrasound image.\nSo the analysis of ultrasound image is more challenging one. We try to develop\na new algorithmic approach to solve the problem of non clarity and find\ndisorder of it. Generally there is no common enhancement approach for noise\nreduction. This paper proposes different filtering techniques based on\nstatistical methods for the removal of various noise. The quality of the\nenhanced images is measured by the statistical quantity measures:\nSignal-to-Noise Ratio (SNR), Peak Signal-to-Noise Ratio (PSNR), and Root Mean\nSquare Error (RMSE)."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1891v1", 
    "other_authors": "Nibaran Das, Ayatullah Faruk Mollah, Sudip Saha, Syed Sahidul Haque", 
    "title": "Handwritten Arabic Numeral Recognition using a Multi Layer Perceptron", 
    "arxiv-id": "1003.1891v1", 
    "author": "Syed Sahidul Haque", 
    "publish": "2010-03-09T14:56:00Z", 
    "summary": "Handwritten numeral recognition is in general a benchmark problem of Pattern\nRecognition and Artificial Intelligence. Compared to the problem of printed\nnumeral recognition, the problem of handwritten numeral recognition is\ncompounded due to variations in shapes and sizes of handwritten characters.\nConsidering all these, the problem of handwritten numeral recognition is\naddressed under the present work in respect to handwritten Arabic numerals.\nArabic is spoken throughout the Arab World and the fifth most popular language\nin the world slightly before Portuguese and Bengali. For the present work, we\nhave developed a feature set of 88 features is designed to represent samples of\nhandwritten Arabic numerals for this work. It includes 72 shadow and 16 octant\nfeatures. A Multi Layer Perceptron (MLP) based classifier is used here for\nrecognition handwritten Arabic digits represented with the said feature set. On\nexperimentation with a database of 3000 samples, the technique yields an\naverage recognition rate of 94.93% evaluated after three-fold cross validation\nof results. It is useful for applications related to OCR of handwritten Arabic\nDigit and can also be extended to include OCR of handwritten characters of\nArabic alphabet."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.1894v1", 
    "other_authors": "Nibaran Das, Ayatullah Faruk Mollah, Ram Sarkar, Subhadip Basu", 
    "title": "A comparative study of different feature sets for recognition of   handwritten Arabic numerals using a Multi Layer Perceptron", 
    "arxiv-id": "1003.1894v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-09T15:05:37Z", 
    "summary": "The work presents a comparative assessment of seven different feature sets\nfor recognition of handwritten Arabic numerals using a Multi Layer Perceptron\n(MLP) based classifier. The seven feature sets employed here consist of shadow\nfeatures, octant centroids, longest runs, angular distances, effective spans,\ndynamic centers of gravity, and some of their combinations. On experimentation\nwith a database of 3000 samples, the maximum recognition rate of 95.80% is\nobserved with both of two separate combinations of features. One of these\ncombinations consists of shadow and centriod features, i. e. 88 features in\nall, and the other shadow, centroid and longest run features, i. e. 124\nfeatures in all. Out of these two, the former combination having a smaller\nnumber of features is finally considered effective for applications related to\nOptical Character Recognition (OCR) of handwritten Arabic numerals. The work\ncan also be extended to include OCR of handwritten characters of Arabic\nalphabet."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.3266v1", 
    "other_authors": "Olga Sofina, Yuriy Bunyak, Roman Kvetnyy", 
    "title": "Pattern recognition using inverse resonance filtration", 
    "arxiv-id": "1003.3266v1", 
    "author": "Roman Kvetnyy", 
    "publish": "2010-03-16T22:30:12Z", 
    "summary": "An approach to textures pattern recognition based on inverse resonance\nfiltration (IRF) is considered. A set of principal resonance harmonics of\ntextured image signal fluctuations eigen harmonic decomposition (EHD) is used\nfor the IRF design. It was shown that EHD is invariant to textured image linear\nshift. The recognition of texture is made by transfer of its signal into\nunstructured signal which simple statistical parameters can be used for texture\npattern recognition. Anomalous variations of this signal point on foreign\nobjects. Two methods of 2D EHD parameters estimation are considered with the\naccount of texture signal breaks presence. The first method is based on the\nlinear symmetry model that is not sensitive to signal phase jumps. The\ncondition of characteristic polynomial symmetry provides the model stationarity\nand periodicity. Second method is based on the eigenvalues problem of matrices\npencil projection into principal vectors space of singular values decomposition\n(SVD) of 2D correlation matrix. Two methods of classification of retrieval from\ntextured image foreign objects are offered."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.3654v1", 
    "other_authors": "Chitrakala Gopalan, D. Manjula", 
    "title": "Sliding window approach based Text Binarisation from Complex Textual   images", 
    "arxiv-id": "1003.3654v1", 
    "author": "D. Manjula", 
    "publish": "2010-03-18T19:01:56Z", 
    "summary": "Text binarisation process classifies individual pixels as text or background\nin the textual images. Binarization is necessary to bridge the gap between\nlocalization and recognition by OCR. This paper presents Sliding window method\nto binarise text from textual images with textured background. Suitable\npreprocessing techniques are applied first to increase the contrast of the\nimage and blur the background noises due to textured background. Then Edges are\ndetected by iterative thresholding. Subsequently formed edge boxes are analyzed\nto remove unwanted edges due to complex background and binarised by sliding\nwindow approach based character size uniformity check algorithm. The proposed\nmethod has been applied on localized region from heterogeneous textual images\nand compared with Otsu, Niblack methods and shown encouraging performance of\nthe proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.4021v1", 
    "other_authors": "Vitaly Pimenov", 
    "title": "System-theoretic approach to image interest point detection", 
    "arxiv-id": "1003.4021v1", 
    "author": "Vitaly Pimenov", 
    "publish": "2010-03-21T20:21:09Z", 
    "summary": "Interest point detection is a common task in various computer vision\napplications. Although a big variety of detector are developed so far\ncomputational efficiency of interest point based image analysis remains to be\nthe problem. Current paper proposes a system-theoretic approach to interest\npoint detection. Starting from the analysis of interdependency between detector\nand descriptor it is shown that given a descriptor it is possible to introduce\nto notion of detector redundancy. Furthermore for each detector it is possible\nto construct its irredundant and equivalent modification. Modified detector\npossesses lower computational complexity and is preferable. It is also shown\nthat several known approaches to reduce computational complexity of image\nregistration can be generalized in terms of proposed theory."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.4053v1", 
    "other_authors": "Raman Maini, Himanshu Aggarwal", 
    "title": "A Comprehensive Review of Image Enhancement Techniques", 
    "arxiv-id": "1003.4053v1", 
    "author": "Himanshu Aggarwal", 
    "publish": "2010-03-22T03:39:46Z", 
    "summary": "Principle objective of Image enhancement is to process an image so that\nresult is more suitable than original image for specific application. Digital\nimage enhancement techniques provide a multitude of choices for improving the\nvisual quality of images. Appropriate choice of such techniques is greatly\ninfluenced by the imaging modality, task at hand and viewing conditions. This\npaper will provide an overview of underlying concepts, along with algorithms\ncommonly used for image enhancement. The paper focuses on spatial domain\ntechniques for image enhancement, with particular reference to point processing\nmethods and histogram processing."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.839920", 
    "link": "http://arxiv.org/pdf/1003.4087v1", 
    "other_authors": "Ratika Pradhan, Mohan P. Pradhan, Ashish Bhusan, Ronak K. Pradhan, M. K. Ghose", 
    "title": "Land-cover Classification and Mapping for Eastern Himalayan State Sikkim", 
    "arxiv-id": "1003.4087v1", 
    "author": "M. K. Ghose", 
    "publish": "2010-03-22T06:49:30Z", 
    "summary": "Area of classifying satellite imagery has become a challenging task in\ncurrent era where there is tremendous growth in settlement i.e. construction of\nbuildings, roads, bridges, dam etc. This paper suggests an improvised k-means\nand Artificial Neural Network (ANN) classifier for land-cover mapping of\nEastern Himalayan state Sikkim. The improvised k-means algorithm shows\nsatisfactory results compared to existing methods that includes k-Nearest\nNeighbor and maximum likelihood classifier. The strength of the Artificial\nNeural Network (ANN) classifier lies in the fact that they are fast and have\ngood recognition rate and it's capability of self-learning compared to other\nclassification algorithms has made it widely accepted. Classifier based on ANN\nshows satisfactory and accurate result in comparison with the classical method."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5249v1", 
    "other_authors": "Raphael Sznitman, Bruno Jedynak", 
    "title": "Active Testing for Face Detection and Localization", 
    "arxiv-id": "1003.5249v1", 
    "author": "Bruno Jedynak", 
    "publish": "2010-03-27T00:17:19Z", 
    "summary": "We provide a novel search technique, which uses a hierarchical model and a\nmutual information gain heuristic to efficiently prune the search space when\nlocalizing faces in images. We show exponential gains in computation over\ntraditional sliding window approaches, while keeping similar performance\nlevels."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5320v1", 
    "other_authors": "Alexander M. Bronstein, Michael M. Bronstein, Ron Kimmel", 
    "title": "The Video Genome", 
    "arxiv-id": "1003.5320v1", 
    "author": "Ron Kimmel", 
    "publish": "2010-03-27T20:57:47Z", 
    "summary": "Fast evolution of Internet technologies has led to an explosive growth of\nvideo data available in the public domain and created unprecedented challenges\nin the analysis, organization, management, and control of such content. The\nproblems encountered in video analysis such as identifying a video in a large\ndatabase (e.g. detecting pirated content in YouTube), putting together video\nfragments, finding similarities and common ancestry between different versions\nof a video, have analogous counterpart problems in genetic research and\nanalysis of DNA and protein sequences. In this paper, we exploit the analogy\nbetween genetic sequences and videos and propose an approach to video analysis\nmotivated by genomic research. Representing video information as video DNA\nsequences and applying bioinformatic algorithms allows to search, match, and\ncompare videos in large-scale databases. We show an application for\ncontent-based metadata mapping between versions of annotated video."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5821v1", 
    "other_authors": "Roberto Marazzato, Amelia Carolina Sparavigna", 
    "title": "Tuning CLD Maps", 
    "arxiv-id": "1003.5821v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2010-03-30T13:58:08Z", 
    "summary": "The Coherence Length Diagram and the related maps have been shown to\nrepresent a useful tool for image analysis. Setting threshold parameters is one\nof the most important issues when dealing with such applications, as they\naffect both the computability, which is outlined by the support map, and the\nappearance of the coherence length diagram itself and of defect maps. A coupled\noptimization analysis, returning a range for the basic (saturation) threshold,\nand a histogram based method, yielding suitable values for a desired map\nappearance, are proposed for an effective control of the analysis process."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5861v1", 
    "other_authors": "Dakshina Ranjan Kisku, Hunny Mehrotra, Phalguni Gupta, Jamuna Kanta Sing", 
    "title": "Robust multi-camera view face recognition", 
    "arxiv-id": "1003.5861v1", 
    "author": "Jamuna Kanta Sing", 
    "publish": "2010-03-30T16:26:39Z", 
    "summary": "This paper presents multi-appearance fusion of Principal Component Analysis\n(PCA) and generalization of Linear Discriminant Analysis (LDA) for multi-camera\nview offline face recognition (verification) system. The generalization of LDA\nhas been extended to establish correlations between the face classes in the\ntransformed representation and this is called canonical covariate. The proposed\nsystem uses Gabor filter banks for characterization of facial features by\nspatial frequency, spatial locality and orientation to make compensate to the\nvariations of face instances occurred due to illumination, pose and facial\nexpression changes. Convolution of Gabor filter bank to face images produces\nGabor face representations with high dimensional feature vectors. PCA and\ncanonical covariate are then applied on the Gabor face representations to\nreduce the high dimensional feature spaces into low dimensional Gabor\neigenfaces and Gabor canonical faces. Reduced eigenface vector and canonical\nface vector are fused together using weighted mean fusion rule. Finally,\nsupport vector machines (SVM) have trained with augmented fused set of features\nand perform the recognition task. The system has been evaluated with UMIST face\ndatabase consisting of multiview faces. The experimental results demonstrate\nthe efficiency and robustness of the proposed system for multi-view face images\nwith high recognition rates. Complexity analysis of the proposed system is also\npresented at the end of the experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5886v1", 
    "other_authors": "Sandip Rakshit, Subhadip Basu", 
    "title": "Development of a multi-user handwriting recognition system using   Tesseract open source OCR engine", 
    "arxiv-id": "1003.5886v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:22:44Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of lower case\nRoman script using Tesseract open source Optical Character Recognition (OCR)\nengine under Apache License 2.0. Handwritten data samples containing isolated\nand free-flow text were collected from different users. Tesseract is trained\nwith user-specific data samples of both the categories of document pages to\ngenerate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated and free-flow handwritten test samples\ncollected from the designated user. On a three user model, the system is\ntrained with 1844, 1535 and 1113 isolated handwritten character samples\ncollected from three different users and the performance is tested on 1133,\n1186 and 1204 character samples, collected form the test sets of the three\nusers respectively. The user specific character level accuracies were obtained\nas 87.92%, 81.53% and 65.71% respectively. The overall character-level accuracy\nof the system is observed as 78.39%. The system fails to segment 10.96%\ncharacters and erroneously classifies 10.65% characters on the overall dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5891v1", 
    "other_authors": "Sandip Rakshit, Subhadip Basu", 
    "title": "Recognition of Handwritten Roman Script Using Tesseract Open source OCR   Engine", 
    "arxiv-id": "1003.5891v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:35:37Z", 
    "summary": "In the present work, we have used Tesseract 2.01 open source Optical\nCharacter Recognition (OCR) Engine under Apache License 2.0 for recognition of\nhandwriting samples of lower case Roman script. Handwritten isolated and\nfree-flow text samples were collected from multiple users. Tesseract is trained\nto recognize user-specific handwriting samples of both the categories of\ndocument pages. On a single user model, the system is trained with 1844\nisolated handwritten characters and the performance is tested on 1133\ncharacters, taken form the test set. The overall character-level accuracy of\nthe system is observed as 83.5%. The system fails to segment 5.56% characters\nand erroneously classifies 10.94% characters."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5893v1", 
    "other_authors": "Sandip Rakshit, Subhadip Basu, Hisashi Ikeda", 
    "title": "Recognition of Handwritten Textual Annotations using Tesseract Open   Source OCR Engine for information Just In Time (iJIT)", 
    "arxiv-id": "1003.5893v1", 
    "author": "Hisashi Ikeda", 
    "publish": "2010-03-30T18:48:47Z", 
    "summary": "Objective of the current work is to develop an Optical Character Recognition\n(OCR) engine for information Just In Time (iJIT) system that can be used for\nrecognition of handwritten textual annotations of lower case Roman script.\nTesseract open source OCR engine under Apache License 2.0 is used to develop\nuser-specific handwriting recognition models, viz., the language sets, for the\nsaid system, where each user is identified by a unique identification tag\nassociated with the digital pen. To generate the language set for any user,\nTesseract is trained with labeled handwritten data samples of isolated and\nfree-flow texts of Roman script, collected exclusively from that user. The\ndesigned system is tested on five different language sets with free- flow\nhandwritten annotations as test samples. The system could successfully segment\nand subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80%\nhandwritten characters in the test samples of five different users."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5897v1", 
    "other_authors": "Sandip Rakshit, Debkumar Ghosal, Tanmoy Das, Subhrajit Dutta, Subhadip Basu", 
    "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla   Basic Characters and Digits", 
    "arxiv-id": "1003.5897v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:54:57Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.5898v1", 
    "other_authors": "Sandip Rakshit, Amitava Kundu, Mrinmoy Maity, Subhajit Mandal, Satwika Sarkar, Subhadip Basu", 
    "title": "Recognition of handwritten Roman Numerals using Tesseract open source   OCR engine", 
    "arxiv-id": "1003.5898v1", 
    "author": "Subhadip Basu", 
    "publish": "2010-03-30T18:59:49Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of Roman\nnumerals using Tesseract open source Optical Character Recognition (OCR)\nengine. Tesseract is trained with data samples of different persons to generate\none user-independent language model, representing the handwritten Roman\ndigit-set. The system is trained with 1226 digit samples collected form the\ndifferent users. The performance is tested on two different datasets, one\nconsisting of samples collected from the known users (those who prepared the\ntraining data samples) and the other consisting of handwritten data samples of\nunknown users. The overall recognition accuracy is obtained as 92.1% and 86.59%\non these test datasets respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.6052v2", 
    "other_authors": "Satadal Saha, Subhadip Basu, Mita Nasipuri, Dipak Kumar Basu", 
    "title": "Development of an automated Red Light Violation Detection System (RLVDS)   for Indian vehicles", 
    "arxiv-id": "1003.6052v2", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-03-31T13:44:29Z", 
    "summary": "Integrated Traffic Management Systems (ITMS) are now implemented in different\ncities in India to primarily address the concerns of road-safety and security.\nAn automated Red Light Violation Detection System (RLVDS) is an integral part\nof the ITMS. In our present work we have designed and developed a complete\nsystem for generating the list of all stop-line violating vehicle images\nautomatically from video snapshots of road-side surveillance cameras. The\nsystem first generates adaptive background images for each camera view,\nsubtracts captured images from the corresponding background images and analyses\npotential occlusions over the stop-line in a traffic signal. Considering\nround-the-clock operations in a real-life test environment, the developed\nsystem could successfully track 92% images of vehicles with violations on the\nstop-line in a \"Red\" traffic signal."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1003.6059v2", 
    "other_authors": "Satadal Saha, Subhadip Basu, Mita Nasipuri, Dipak Kumar Basu", 
    "title": "A novel scheme for binarization of vehicle images using hierarchical   histogram equalization technique", 
    "arxiv-id": "1003.6059v2", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-03-31T14:00:16Z", 
    "summary": "Automatic License Plate Recognition system is a challenging area of research\nnow-a-days and binarization is an integral and most important part of it. In\ncase of a real life scenario, most of existing methods fail to properly\nbinarize the image of a vehicle in a congested road, captured through a CCD\ncamera. In the current work we have applied histogram equalization technique\nover the complete image and also over different hierarchy of image\npartitioning. A novel scheme is formulated for giving the membership value to\neach pixel for each hierarchy of histogram equalization. Then the image is\nbinarized depending on the net membership value of each pixel. The technique is\nexhaustively evaluated on the vehicle image dataset as well as the license\nplate dataset, giving satisfactory performances."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.0512v1", 
    "other_authors": "Mahmoud Khademi, Mohammad Hadi Kiapour, Mohammad T. Manzuri-Shalmani, Ali A. Kiaei", 
    "title": "Analysis, Interpretation, and Recognition of Facial Action Units and   Expressions Using Neuro-Fuzzy Modeling", 
    "arxiv-id": "1004.0512v1", 
    "author": "Ali A. Kiaei", 
    "publish": "2010-04-04T15:20:27Z", 
    "summary": "In this paper an accurate real-time sequence-based system for representation,\nrecognition, interpretation, and analysis of the facial action units (AUs) and\nexpressions is presented. Our system has the following characteristics: 1)\nemploying adaptive-network-based fuzzy inference systems (ANFIS) and temporal\ninformation, we developed a classification scheme based on neuro-fuzzy modeling\nof the AU intensity, which is robust to intensity variations, 2) using both\ngeometric and appearance-based features, and applying efficient dimension\nreduction techniques, our system is robust to illumination changes and it can\nrepresent the subtle changes as well as temporal information involved in\nformation of the facial expressions, and 3) by continuous values of intensity\nand employing top-down hierarchical rule-based classifiers, we can develop\naccurate human-interpretable AU-to-expression converters. Extensive experiments\non Cohn-Kanade database show the superiority of the proposed method, in\ncomparison with support vector machines, hidden Markov models, and neural\nnetwork classifiers. Keywords: biased discriminant analysis (BDA), classifier\ndesign and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy\nmodeling."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1215v1", 
    "other_authors": "Elad Shaked, Oleg Michailovich", 
    "title": "Regularized Richardson-Lucy Algorithm for Sparse Reconstruction of   Poissonian Images", 
    "arxiv-id": "1004.1215v1", 
    "author": "Oleg Michailovich", 
    "publish": "2010-04-08T01:08:30Z", 
    "summary": "Restoration of digital images from their degraded measurements has always\nbeen a problem of great theoretical and practical importance in numerous\napplications of imaging sciences. A specific solution to the problem of image\nrestoration is generally determined by the nature of degradation phenomenon as\nwell as by the statistical properties of measurement noises. The present study\nis concerned with the case in which the images of interest are corrupted by\nconvolutional blurs and Poisson noises. To deal with such problems, there\nexists a range of solution methods which are based on the principles\noriginating from the fixed-point algorithm of Richardson and Lucy (RL). In this\npaper, we provide conceptual and experimental proof that such methods tend to\nconverge to sparse solutions, which makes them applicable only to those images\nwhich can be represented by a relatively small number of non-zero samples in\nthe spatial domain. Unfortunately, the set of such images is relatively small,\nwhich restricts the applicability of RL-type methods. On the other hand,\nvirtually all practical images admit sparse representations in the domain of a\nproperly designed linear transform. To take advantage of this fact, it is\ntherefore tempting to modify the RL algorithm so as to make it recover\nrepresentation coefficients, rather than the values of their associated image.\nSuch modification is introduced in this paper. Apart from the generality of its\nassumptions, the proposed method is also superior to many established\nreconstruction approaches in terms of estimation accuracy and computational\ncomplexity. This and other conclusions of this study are validated through a\nseries of numerical experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1227v1", 
    "other_authors": "Ismail A. Ismail, Mohammed A. Ramadan, Talaat S. El danaf, Ahmed H. Samak", 
    "title": "Signature Recognition using Multi Scale Fourier Descriptor And Wavelet   Transform", 
    "arxiv-id": "1004.1227v1", 
    "author": "Ahmed H. Samak", 
    "publish": "2010-04-08T02:39:49Z", 
    "summary": "This paper present a novel off-line signature recognition method based on\nmulti scale Fourier Descriptor and wavelet transform . The main steps of\nconstructing a signature recognition system are discussed and experiments on\nreal data sets show that the average error rate can reach 1%. Finally we\ncompare 8 distance measures between feature vectors with respect to the\nrecognition performance.\n  Key words: signature recognition; Fourier Descriptor; Wavelet transform;\npersonal verification"
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1679v1", 
    "other_authors": "S. Zulaikha Beevi, M. Mohammed Sathik, K. Senthamaraikannan", 
    "title": "A Robust Fuzzy Clustering Technique with Spatial Neighborhood   Information for Effective Medical Image Segmentation", 
    "arxiv-id": "1004.1679v1", 
    "author": "K. Senthamaraikannan", 
    "publish": "2010-04-10T04:04:12Z", 
    "summary": "Medical image segmentation demands an efficient and robust segmentation\nalgorithm against noise. The conventional fuzzy c-means algorithm is an\nefficient clustering algorithm that is used in medical image segmentation. But\nFCM is highly vulnerable to noise since it uses only intensity values for\nclustering the images. This paper aims to develop a novel and efficient fuzzy\nspatial c-means clustering algorithm which is robust to noise. The proposed\nclustering algorithm uses fuzzy spatial information to calculate membership\nvalue. The input image is clustered using proposed ISFCM algorithm. A\ncomparative study has been made between the conventional FCM and proposed\nISFCM. The proposed approach is found to be outperforming the conventional FCM."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1768v1", 
    "other_authors": "M. Gomathi, P. Thangaraj", 
    "title": "A New Approach to Lung Image Segmentation using Fuzzy Possibilistic   C-Means Algorithm", 
    "arxiv-id": "1004.1768v1", 
    "author": "P. Thangaraj", 
    "publish": "2010-04-11T08:01:08Z", 
    "summary": "Image segmentation is a vital part of image processing. Segmentation has its\napplication widespread in the field of medical images in order to diagnose\ncurious diseases. The same medical images can be segmented manually. But the\naccuracy of image segmentation using the segmentation algorithms is more when\ncompared with the manual segmentation. In the field of medical diagnosis an\nextensive diversity of imaging techniques is presently available, such as\nradiography, computed tomography (CT) and magnetic resonance imaging (MRI).\nMedical image segmentation is an essential step for most consequent image\nanalysis tasks. Although the original FCM algorithm yields good results for\nsegmenting noise free images, it fails to segment images corrupted by noise,\noutliers and other imaging artifact. This paper presents an image segmentation\napproach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic\nc-means algorithm (FPCM). This approach is a generalized version of standard\nFuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM\ntechnique is eliminated in modifying the standard technique. The Modified FCM\nalgorithm is formulated by modifying the distance measurement of the standard\nFCM algorithm to permit the labeling of a pixel to be influenced by other\npixels and to restrain the noise effect during segmentation. Instead of having\none term in the objective function, a second term is included, forcing the\nmembership to be as high as possible without a maximum limit constraint of one.\nExperiments are conducted on real images to investigate the performance of the\nproposed modified FCM technique in segmenting the medical images. Standard FCM,\nModified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to\nexplore the accuracy of our proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2010.106", 
    "link": "http://arxiv.org/pdf/1004.1886v1", 
    "other_authors": "Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing", 
    "title": "Feature Level Fusion of Face and Palmprint Biometrics by Isomorphic   Graph-based Improved K-Medoids Partitioning", 
    "arxiv-id": "1004.1886v1", 
    "author": "Jamuna Kanta Sing", 
    "publish": "2010-04-12T07:34:39Z", 
    "summary": "This paper presents a feature level fusion approach which uses the improved\nK-medoids clustering algorithm and isomorphic graph for face and palmprint\nbiometrics. Partitioning around medoids (PAM) algorithm is used to partition\nthe set of n invariant feature points of the face and palmprint images into k\nclusters. By partitioning the face and palmprint images with scale invariant\nfeatures SIFT points, a number of clusters is formed on both the images. Then\non each cluster, an isomorphic graph is drawn. In the next step, the most\nprobable pair of graphs is searched using iterative relaxation algorithm from\nall possible isomorphic graphs for a pair of corresponding face and palmprint\nimages. Finally, graphs are fused by pairing the isomorphic graphs into\naugmented groups in terms of addition of invariant SIFT points and in terms of\ncombining pair of keypoint descriptors by concatenation rule. Experimental\nresults obtained from the extensive evaluation show that the proposed feature\nlevel fusion with the improved K-medoids partitioning algorithm increases the\nperformance of the system with utmost level of accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.1887v1", 
    "other_authors": "Phalguni Gupta, Dakshina Ranjan Kisku, Jamuna Kanta Sing, Massimo Tistarelli", 
    "title": "Maximized Posteriori Attributes Selection from Facial Salient Landmarks   for Face Recognition", 
    "arxiv-id": "1004.1887v1", 
    "author": "Massimo Tistarelli", 
    "publish": "2010-04-12T07:42:09Z", 
    "summary": "This paper presents a robust and dynamic face recognition technique based on\nthe extraction and matching of devised probabilistic graphs drawn on SIFT\nfeatures related to independent face areas. The face matching strategy is based\non matching individual salient facial graph characterized by SIFT features as\nconnected to facial landmarks such as the eyes and the mouth. In order to\nreduce the face matching errors, the Dempster-Shafer decision theory is applied\nto fuse the individual matching scores obtained from each pair of salient\nfacial features. The proposed algorithm is evaluated with the ORL and the IITK\nface databases. The experimental results demonstrate the effectiveness and\npotential of the proposed face recognition technique also in case of partially\noccluded faces."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3257v1", 
    "other_authors": "Rahul Kala, Harsh Vazirani, Anupam Shukla, Ritu Tiwari", 
    "title": "Offline Handwriting Recognition using Genetic Algorithm", 
    "arxiv-id": "1004.3257v1", 
    "author": "Ritu Tiwari", 
    "publish": "2010-04-19T17:49:28Z", 
    "summary": "Handwriting Recognition enables a person to scribble something on a piece of\npaper and then convert it into text. If we look into the practical reality\nthere are enumerable styles in which a character may be written. These styles\ncan be self combined to generate more styles. Even if a small child knows the\nbasic styles a character can be written, he would be able to recognize\ncharacters written in styles intermediate between them or formed by their\nmixture. This motivates the use of Genetic Algorithms for the problem. In order\nto prove this, we made a pool of images of characters. We converted them to\ngraphs. The graph of every character was intermixed to generate styles\nintermediate between the styles of parent character. Character recognition\ninvolved the matching of the graph generated from the unknown character image\nwith the graphs generated by mixing. Using this method we received an accuracy\nof 98.44%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3276v1", 
    "other_authors": "G. K. Kharate, V. H. Patil", 
    "title": "Color Image Compression Based On Wavelet Packet Best Tree", 
    "arxiv-id": "1004.3276v1", 
    "author": "V. H. Patil", 
    "publish": "2010-04-19T18:28:46Z", 
    "summary": "In Image Compression, the researchers' aim is to reduce the number of bits\nrequired to represent an image by removing the spatial and spectral\nredundancies. Recently discrete wavelet transform and wavelet packet has\nemerged as popular techniques for image compression. The wavelet transform is\none of the major processing components of image compression. The result of the\ncompression changes as per the basis and tap of the wavelet used. It is\nproposed that proper selection of mother wavelet on the basis of nature of\nimages, improve the quality as well as compression ratio remarkably. We suggest\nthe novel technique, which is based on wavelet packet best tree based on\nThreshold Entropy with enhanced run-length encoding. This method reduces the\ntime complexity of wavelet packets decomposition as complete tree is not\ndecomposed. Our algorithm selects the sub-bands, which include significant\ninformation based on threshold entropy. The enhanced run length encoding\ntechnique is suggested provides better results than RLE. The result when\ncompared with JPEG-2000 proves to be better."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3549v1", 
    "other_authors": "Bassam Al-Mahadeen, Mokhled S. AlTarawneh, Islam H. AlTarawneh", 
    "title": "Signature Region of Interest using Auto cropping", 
    "arxiv-id": "1004.3549v1", 
    "author": "Islam H. AlTarawneh", 
    "publish": "2010-04-20T20:04:17Z", 
    "summary": "A new approach for signature region of interest pre-processing was presented.\nIt used new auto cropping preparation on the basis of the image content, where\nthe intensity value of pixel is the source of cropping. This approach provides\nboth the possibility of improving the performance of security systems based on\nsignature images, and also the ability to use only the region of interest of\nthe used image to suit layout design of biometric systems. Underlying the\napproach is a novel segmentation method which identifies the exact region of\nforeground of signature for feature extraction usage. Evaluation results of\nthis approach shows encouraging prospects by eliminating the need for false\nregion isolating, reduces the time cost associated with signature false points\ndetection, and addresses enhancement issues. A further contribution of this\npaper is an automated cropping stage in bio-secure based systems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3629v1", 
    "other_authors": "Yuya Inagaki, Jun-ichi Inoue", 
    "title": "Simultaneous Bayesian inference of motion velocity fields and   probabilistic models in successive video-frames described by spatio-temporal   MRFs", 
    "arxiv-id": "1004.3629v1", 
    "author": "Jun-ichi Inoue", 
    "publish": "2010-04-21T06:27:47Z", 
    "summary": "We numerically investigate a mean-field Bayesian approach with the assistance\nof the Markov chain Monte Carlo method to estimate motion velocity fields and\nprobabilistic models simultaneously in consecutive digital images described by\nspatio-temporal Markov random fields. Preliminary to construction of our\nprocedure, we find that mean-field variables in the iteration diverge due to\nimproper normalization factor of regularization terms appearing in the\nposterior. To avoid this difficulty, we rescale the regularization term by\nintroducing a scaling factor and optimizing it by means of minimization of the\nmean-square error. We confirm that the optimal scaling factor stabilizes the\nmean-field iterative process of the motion velocity estimation. We next attempt\nto estimate the optimal values of hyper-parameters including the regularization\nterm, which define our probabilistic model macroscopically, by using the\nBoltzmann-machine type learning algorithm based on gradient descent of marginal\nlikelihood (type-II likelihood) with respect to the hyper-parameters. In our\nframework, one can estimate both the probabilistic model (hyper-parameters) and\nmotion velocity fields simultaneously. We find that our motion estimation is\nmuch better than the result obtained by Zhang and Hanouer (1995) in which the\nhyper-parameters are set to some ad-hoc values without any theoretical\njustification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.3980v1", 
    "other_authors": "Mithun Das Gupta", 
    "title": "Hashing Image Patches for Zooming", 
    "arxiv-id": "1004.3980v1", 
    "author": "Mithun Das Gupta", 
    "publish": "2010-04-22T18:42:03Z", 
    "summary": "In this paper we present a Bayesian image zooming/super-resolution algorithm\nbased on a patch based representation. We work on a patch based model with\noverlap and employ a Locally Linear Embedding (LLE) based approach as our data\nfidelity term in the Bayesian inference. The image prior imposes continuity\nconstraints across the overlapping patches. We apply an error back-projection\ntechnique, with an approximate cross bilateral filter. The problem of nearest\nneighbor search is handled by a variant of the locality sensitive hashing (LSH)\nscheme. The novelty of our work lies in the speed up achieved by the hashing\nscheme and the robustness and inherent modularity and parallel structure\nachieved by the LLE setup. The ill-posedness of the image reconstruction\nproblem is handled by the introduction of regularization priors which encode\nthe knowledge present in vast collections of natural images. We present\ncomparative results for both run-time as well as visual image quality based\nmeasurements."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4373v1", 
    "other_authors": "Joseph Shtok, Michael Zibulevsky, Michael Elad", 
    "title": "Spatially-Adaptive Reconstruction in Computed Tomography Based on   Statistical Learning", 
    "arxiv-id": "1004.4373v1", 
    "author": "Michael Elad", 
    "publish": "2010-04-25T19:10:26Z", 
    "summary": "We propose a direct reconstruction algorithm for Computed Tomography, based\non a local fusion of a few preliminary image estimates by means of a non-linear\nfusion rule. One such rule is based on a signal denoising technique which is\nspatially adaptive to the unknown local smoothness. Another, more powerful\nfusion rule, is based on a neural network trained off-line with a high-quality\ntraining set of images. Two types of linear reconstruction algorithms for the\npreliminary images are employed for two different reconstruction tasks. For an\nentire image reconstruction from full projection data, the proposed scheme uses\na sequence of Filtered Back-Projection algorithms with a gradually growing\ncut-off frequency. To recover a Region Of Interest only from local projections,\nstatistically-trained linear reconstruction algorithms are employed. Numerical\nexperiments display the improvement in reconstruction quality when compared to\nlinear reconstruction algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4448v1", 
    "other_authors": "Salem Saleh Al-amri, N. V. Kalyankar, Khamitkar S. D", 
    "title": "Deblured Gaussian Blurred Images", 
    "arxiv-id": "1004.4448v1", 
    "author": "Khamitkar S. D", 
    "publish": "2010-04-26T09:32:28Z", 
    "summary": "This paper attempts to undertake the study of Restored Gaussian Blurred\nImages. by using four types of techniques of deblurring image as Wiener filter,\nRegularized filter, Lucy Richardson deconvlutin algorithm and Blind\ndeconvlution algorithm with an information of the Point Spread Function (PSF)\ncorrupted blurred image with Different values of Size and Alfa and then\ncorrupted by Gaussian noise. The same is applied to the remote sensing image\nand they are compared with one another, So as to choose the base technique for\nrestored or deblurring image.This paper also attempts to undertake the study of\nrestored Gaussian blurred image with no any information about the Point Spread\nFunction (PSF) by using same four techniques after execute the guess of the\nPSF, the number of iterations and the weight threshold of it. To choose the\nbase guesses for restored or deblurring image of this techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4467v1", 
    "other_authors": "Er. Deepak Aggarwal, Er. Sandeep Kaur, Er. Anantdeep", 
    "title": "An Efficient Watermarking Algorithm to Improve Payload and Robustness   without Affecting Image Perceptual Quality", 
    "arxiv-id": "1004.4467v1", 
    "author": "Er. Anantdeep", 
    "publish": "2010-04-26T10:17:53Z", 
    "summary": "Capacity, Robustness, & Perceptual quality of watermark data are very\nimportant issues to be considered. A lot of research is going on to increase\nthese parameters for watermarking of the digital images, as there is always a\ntradeoff among them. . In this paper an efficient watermarking algorithm to\nimprove payload and robustness without affecting perceptual quality of image\ndata based on DWT is discussed. The aim of the paper is to employ the nested\nwatermarks in wavelet domain which increases the capacity and ultimately the\nrobustness against attacks and selection of different scaling factor values for\nLL & HH bands and during embedding not to create the visible artifacts in the\noriginal image and therefore the original and watermarked image is similar."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-13365-7_1", 
    "link": "http://arxiv.org/pdf/1004.4793v1", 
    "other_authors": "R. K. Fedorov", 
    "title": "Logical methods of object recognition on satellite images using spatial   constraints", 
    "arxiv-id": "1004.4793v1", 
    "author": "R. K. Fedorov", 
    "publish": "2010-04-27T13:22:36Z", 
    "summary": "A logical approach to object recognition on image is proposed. The main idea\nof the approach is to perform the object recognition as a logical inference on\na set of rules describing an object shape."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.1187v1", 
    "other_authors": "S. V. Sheela, K. R. Radhika", 
    "title": "Biometric Authentication using Nonparametric Methods", 
    "arxiv-id": "1006.1187v1", 
    "author": "K. R. Radhika", 
    "publish": "2010-06-07T07:15:37Z", 
    "summary": "The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy kmeans classifiers. The best performance was obtained for MMU\ndatabase consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.2700v1", 
    "other_authors": "Robert Sheng Xu, Oleg Michailovich, Magdy Salama", 
    "title": "Image Segmentation Using Weak Shape Priors", 
    "arxiv-id": "1006.2700v1", 
    "author": "Magdy Salama", 
    "publish": "2010-06-14T12:43:37Z", 
    "summary": "The problem of image segmentation is known to become particularly challenging\nin the case of partial occlusion of the object(s) of interest, background\nclutter, and the presence of strong noise. To overcome this problem, the\npresent paper introduces a novel approach segmentation through the use of\n\"weak\" shape priors. Specifically, in the proposed method, an segmenting active\ncontour is constrained to converge to a configuration at which its geometric\nparameters attain their empirical probability densities closely matching the\ncorresponding model densities that are learned based on training samples. It is\nshown through numerical experiments that the proposed shape modeling can be\nregarded as \"weak\" in the sense that it minimally influences the segmentation,\nwhich is allowed to be dominated by data-related forces. On the other hand, the\npriors provide sufficient constraints to regularize the convergence of\nsegmentation, while requiring substantially smaller training sets to yield less\nbiased results as compared to the case of PCA-based regularization methods. The\nmain advantages of the proposed technique over some existing alternatives is\ndemonstrated in a series of experiments."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.2734v1", 
    "other_authors": "Ariel E. Baya, Pablo M. Granitto", 
    "title": "Penalized K-Nearest-Neighbor-Graph Based Metrics for Clustering", 
    "arxiv-id": "1006.2734v1", 
    "author": "Pablo M. Granitto", 
    "publish": "2010-06-14T15:07:45Z", 
    "summary": "A difficult problem in clustering is how to handle data with a manifold\nstructure, i.e. data that is not shaped in the form of compact clouds of\npoints, forming arbitrary shapes or paths embedded in a high-dimensional space.\nIn this work we introduce the Penalized k-Nearest-Neighbor-Graph (PKNNG) based\nmetric, a new tool for evaluating distances in such cases. The new metric can\nbe used in combination with most clustering algorithms. The PKNNG metric is\nbased on a two-step procedure: first it constructs the k-Nearest-Neighbor-Graph\nof the dataset of interest using a low k-value and then it adds edges with an\nexponentially penalized weight for connecting the sub-graphs produced by the\nfirst step. We discuss several possible schemes for connecting the different\nsub-graphs. We use three artificial datasets in four different embedding\nsituations to evaluate the behavior of the new metric, including a comparison\namong different clustering methods. We also evaluate the new metric in a real\nworld application, clustering the MNIST digits dataset. In all cases the PKNNG\nmetric shows promising clustering results."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.2804v1", 
    "other_authors": "Minakshi Gogoi, D K Bhattacharyya", 
    "title": "An Effective Fingerprint Verification Technique", 
    "arxiv-id": "1006.2804v1", 
    "author": "D K Bhattacharyya", 
    "publish": "2010-06-14T18:57:35Z", 
    "summary": "This paper presents an effective method for fingerprint verification based on\na data mining technique called minutiae clustering and a graph-theoretic\napproach to analyze the process of fingerprint comparison to give a feature\nspace representation of minutiae and to produce a lower bound on the number of\ndetectably distinct fingerprints. The method also proving the invariance of\neach individual fingerprint by using both the topological behavior of the\nminutiae graph and also using a distance measure called Hausdorff distance.The\nmethod provides a graph based index generation mechanism of fingerprint\nbiometric data. The self-organizing map neural network is also used for\nclassifying the fingerprints."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.3056v1", 
    "other_authors": "Guoshen Yu, Guillermo Sapiro, St\u00e9phane Mallat", 
    "title": "Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian   Mixture Models to Structured Sparsity", 
    "arxiv-id": "1006.3056v1", 
    "author": "St\u00e9phane Mallat", 
    "publish": "2010-06-15T19:29:08Z", 
    "summary": "A general framework for solving image inverse problems is introduced in this\npaper. The approach is based on Gaussian mixture models, estimated via a\ncomputationally efficient MAP-EM algorithm. A dual mathematical interpretation\nof the proposed framework with structured sparse estimation is described, which\nshows that the resulting piecewise linear estimate stabilizes the estimation\nwhen compared to traditional sparse inverse problem techniques. This\ninterpretation also suggests an effective dictionary motivated initialization\nfor the MAP-EM algorithm. We demonstrate that in a number of image inverse\nproblems, including inpainting, zooming, and deblurring, the same algorithm\nproduces either equal, often significantly better, or very small margin worse\nresults than the best published ones, at a lower computational cost."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.3506v1", 
    "other_authors": "Ana Paula Brand\u00e3o Lopes, Eduardo Alves do Valle Jr., Jussara Marques de Almeida, Arnaldo Albuquerque de Ara\u00fajo", 
    "title": "Action Recognition in Videos: from Motion Capture Labs to the Web", 
    "arxiv-id": "1006.3506v1", 
    "author": "Arnaldo Albuquerque de Ara\u00fajo", 
    "publish": "2010-06-17T16:27:35Z", 
    "summary": "This paper presents a survey of human action recognition approaches based on\nvisual data recorded from a single video camera. We propose an organizing\nframework which puts in evidence the evolution of the area, with techniques\nmoving from heavily constrained motion capture scenarios towards more\nchallenging, realistic, \"in the wild\" videos. The proposed organization is\nbased on the representation used as input for the recognition task, emphasizing\nthe hypothesis assumed and thus, the constraints imposed on the type of video\nthat each technique is able to address. Expliciting the hypothesis and\nconstraints makes the framework particularly useful to select a method, given\nan application. Another advantage of the proposed organization is that it\nallows categorizing newest approaches seamlessly with traditional ones, while\nproviding an insightful perspective of the evolution of the action recognition\ntask up to now. That perspective is the basis for the discussion in the end of\nthe paper, where we also present the main open issues in the area."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.4175v1", 
    "other_authors": "Noha El-Zehiry, Leo Grady", 
    "title": "Optimization of Weighted Curvature for Image Segmentation", 
    "arxiv-id": "1006.4175v1", 
    "author": "Leo Grady", 
    "publish": "2010-06-21T20:59:43Z", 
    "summary": "Minimization of boundary curvature is a classic regularization technique for\nimage segmentation in the presence of noisy image data. Techniques for\nminimizing curvature have historically been derived from descent methods which\ncould be trapped in a local minimum and therefore required a good\ninitialization. Recently, combinatorial optimization techniques have been\napplied to the optimization of curvature which provide a solution that achieves\nnearly a global optimum. However, when applied to image segmentation these\nmethods required a meaningful data term. Unfortunately, for many images,\nparticularly medical images, it is difficult to find a meaningful data term.\nTherefore, we propose to remove the data term completely and instead weight the\ncurvature locally, while still achieving a global optimum."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.4588v1", 
    "other_authors": "S. Sadek, A. Al-Hamadi, B. Michaelis, U. Sayed", 
    "title": "Efficient Region-Based Image Querying", 
    "arxiv-id": "1006.4588v1", 
    "author": "U. Sayed", 
    "publish": "2010-06-23T16:52:26Z", 
    "summary": "Retrieving images from large and varied repositories using visual contents\nhas been one of major research items, but a challenging task in the image\nmanagement community. In this paper we present an efficient approach for\nregion-based image classification and retrieval using a fast multi-level neural\nnetwork model. The advantages of this neural model in image classification and\nretrieval domain will be highlighted. The proposed approach accomplishes its\ngoal in three main steps. First, with the help of a mean-shift based\nsegmentation algorithm, significant regions of the image are isolated.\nSecondly, color and texture features of each region are extracted by using\ncolor moments and 2D wavelets decomposition technique. Thirdly the multi-level\nneural classifier is trained in order to classify each region in a given image\ninto one of five predefined categories, i.e., \"Sky\", \"Building\", \"SandnRock\",\n\"Grass\" and \"Water\". Simulation results show that the proposed method is\npromising in terms of classification and retrieval accuracy results. These\nresults compare favorably with the best published results obtained by other\nstate-of-the-art image retrieval techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.4910v2", 
    "other_authors": "Burak Bayramli", 
    "title": "3D Visual Tracking with Particle and Kalman Filters", 
    "arxiv-id": "1006.4910v2", 
    "author": "Burak Bayramli", 
    "publish": "2010-06-25T04:51:32Z", 
    "summary": "One of the most visually demonstrable and straightforward uses of filtering\nis in the field of Computer Vision. In this document we will try to outline the\nissues encountered while designing and implementing a particle and kalman\nfilter based tracking system."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5902v1", 
    "other_authors": "Sandhya Arora, Debotosh Bhattacharjee, Mita Nasipuri, L. Malik, M. Kundu, D. K. Basu", 
    "title": "Performance Comparison of SVM and ANN for Handwritten Devnagari   Character Recognition", 
    "arxiv-id": "1006.5902v1", 
    "author": "D. K. Basu", 
    "publish": "2010-06-30T16:16:43Z", 
    "summary": "Classification methods based on learning from examples have been widely\napplied to character recognition from the 1990s and have brought forth\nsignificant improvements of recognition accuracies. This class of methods\nincludes statistical methods, artificial neural networks, support vector\nmachines (SVM), multiple classifier combination, etc. In this paper, we discuss\nthe characteristics of the some classification methods that have been\nsuccessfully applied to handwritten Devnagari character recognition and results\nof SVM and ANNs classification method, applied on Handwritten Devnagari\ncharacters. After preprocessing the character image, we extracted shadow\nfeatures, chain code histogram features, view based features and longest run\nfeatures. These features are then fed to Neural classifier and in support\nvector machine for classification. In neural classifier, we explored three ways\nof combining decisions of four MLP's designed for four different features."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5908v1", 
    "other_authors": "Sandhya Arora, Debotosh Bhattacharjee, Mita Nasipuri, D. K. Basu, M. Kundu", 
    "title": "Recognition of Non-Compound Handwritten Devnagari Characters using a   Combination of MLP and Minimum Edit Distance", 
    "arxiv-id": "1006.5908v1", 
    "author": "M. Kundu", 
    "publish": "2010-06-30T16:25:21Z", 
    "summary": "This paper deals with a new method for recognition of offline Handwritten\nnon-compound Devnagari Characters in two stages. It uses two well known and\nestablished pattern recognition techniques: one using neural networks and the\nother one using minimum edit distance. Each of these techniques is applied on\ndifferent sets of characters for recognition. In the first stage, two sets of\nfeatures are computed and two classifiers are applied to get higher recognition\naccuracy. Two MLP's are used separately to recognize the characters. For one of\nthe MLP's the characters are represented with their shadow features and for the\nother chain code histogram feature is used. The decision of both MLP's is\ncombined using weighted majority scheme. Top three results produced by combined\nMLP's in the first stage are used to calculate the relative difference values.\nIn the second stage, based on these relative differences character set is\ndivided into two. First set consists of the characters with distinct shapes and\nsecond set consists of confused characters, which appear very similar in\nshapes. Characters of distinct shapes of first set are classified using MLP.\nConfused characters in second set are classified using minimum edit distance\nmethod. Method of minimum edit distance makes use of corner detected in a\ncharacter image using modified Harris corner detection technique. Experiment on\nthis method is carried out on a database of 7154 samples. The overall\nrecognition is found to be 90.74%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5911v1", 
    "other_authors": "S. Arora, Debotosh Bhattacharjee, M. Nasipuri, D. K. Basu, M. Kundu", 
    "title": "Application of Statistical Features in Handwritten Devnagari Character   Recognition", 
    "arxiv-id": "1006.5911v1", 
    "author": "M. Kundu", 
    "publish": "2010-06-30T16:33:01Z", 
    "summary": "In this paper a scheme for offline Handwritten Devnagari Character\nRecognition is proposed, which uses different feature extraction methodologies\nand recognition algorithms. The proposed system assumes no constraints in\nwriting style or size. First the character is preprocessed and features namely\n: Chain code histogram and moment invariant features are extracted and fed to\nMultilayer Perceptrons as a preliminary recognition step. Finally the results\nof both MLP's are combined using weighted majority scheme. The proposed system\nis tested on 1500 handwritten devnagari character database collected from\ndifferent people. It is observed that the proposed system achieves recognition\nrates 98.03% for top 5 results and 89.46% for top 1 result."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5913v1", 
    "other_authors": "Sandhya Arora, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Multiple Classifier Combination for Off-line Handwritten Devnagari   Character Recognition", 
    "arxiv-id": "1006.5913v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-06-30T16:38:02Z", 
    "summary": "This work presents the application of weighted majority voting technique for\ncombination of classification decision obtained from three Multi_Layer\nPerceptron(MLP) based classifiers for Recognition of Handwritten Devnagari\ncharacters using three different feature sets. The features used are\nintersection, shadow feature and chain code histogram features. Shadow features\nare computed globally for character image while intersection features and chain\ncode histogram features are computed by dividing the character image into\ndifferent segments. On experimentation with a dataset of 4900 samples the\noverall recognition rate observed is 92.16% as we considered top five choices\nresults. This method is compared with other recent methods for Handwritten\nDevnagari Character Recognition and it has been observed that this approach has\nbetter success rate than other methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5920v1", 
    "other_authors": "Sandhya Arora, Debotosh Bhattacharjee, Mita Nasipuri, Latesh Malik", 
    "title": "A Two Stage Classification Approach for Handwritten Devanagari   Characters", 
    "arxiv-id": "1006.5920v1", 
    "author": "Latesh Malik", 
    "publish": "2010-06-30T16:54:43Z", 
    "summary": "The paper presents a two stage classification approach for handwritten\ndevanagari characters The first stage is using structural properties like\nshirorekha, spine in character and second stage exploits some intersection\nfeatures of characters which are fed to a feedforward neural network. Simple\nhistogram based method does not work for finding shirorekha, vertical bar\n(Spine) in handwritten devnagari characters. So we designed a differential\ndistance based technique to find a near straight line for shirorekha and spine.\nThis approach has been tested for 50000 samples and we got 89.12% success"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5924v1", 
    "other_authors": "Sandhya Arora, Latesh Malik, Debotosh Bhattacharjee, Mita Nasipuri", 
    "title": "A novel approach for handwritten Devnagari character recognition", 
    "arxiv-id": "1006.5924v1", 
    "author": "Mita Nasipuri", 
    "publish": "2010-06-30T17:09:39Z", 
    "summary": "In this paper a method for recognition of handwritten devanagari characters\nis described. Here, feature vector is constituted by accumulated directional\ngradient changes in different segments, number of intersections points for the\ncharacter, type of spine present and type of shirorekha present in the\ncharacter. One Multi-layer Perceptron with conjugate-gradient training is used\nto classify these feature vectors. This method is applied to a database with\n1000 sample characters and the recognition rate obtained is 88.12%"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5927v1", 
    "other_authors": "Sandhya Arora, Latesh Malik, Debotosh Bhattacharjee, Mita Nasipuri", 
    "title": "Classification Of Gradient Change Features Using MLP For Handwritten   Character Recognition", 
    "arxiv-id": "1006.5927v1", 
    "author": "Mita Nasipuri", 
    "publish": "2010-06-30T17:14:40Z", 
    "summary": "A novel, generic scheme for off-line handwritten English alphabets character\nimages is proposed. The advantage of the technique is that it can be applied in\na generic manner to different applications and is expected to perform better in\nuncertain and noisy environments. The recognition scheme is using a multilayer\nperceptron(MLP) neural networks. The system was trained and tested on a\ndatabase of 300 samples of handwritten characters. For improved generalization\nand to avoid overtraining, the whole available dataset has been divided into\ntwo subsets: training set and test set. We achieved 99.10% and 94.15% correct\nrecognition rates on training and test sets respectively. The purposed scheme\nis robust with respect to various writing styles and size as well as presence\nof considerable noise."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5942v1", 
    "other_authors": "Santanu Halder, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "FPGA Based Assembling of Facial Components for Human Face Construction", 
    "arxiv-id": "1006.5942v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-06-30T18:01:47Z", 
    "summary": "This paper aims at VLSI realization for generation of a new face from textual\ndescription. The FASY (FAce SYnthesis) System is a Face Database Retrieval and\nnew Face generation System that is under development. One of its main features\nis the generation of the requested face when it is not found in the existing\ndatabase. The new face generation system works in three steps - searching\nphase, assembling phase and tuning phase. In this paper the tuning phase using\nhardware description language and its implementation in a Field Programmable\nGate Array (FPGA) device is presented."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1006.5945v2", 
    "other_authors": "S. Halder, Debotosh Bhattacharjee, M. Nasipuri, D. K. Basu, M. Kundu", 
    "title": "Fuzzy Classification of Facial Component Parameters", 
    "arxiv-id": "1006.5945v2", 
    "author": "M. Kundu", 
    "publish": "2010-06-30T18:07:35Z", 
    "summary": "This paper presents a novel type-2 Fuzzy logic System to define the Shape of\na facial component with the crisp output. This work is the part of our main\nresearch effort to design a system (called FASY) which offers a novel face\nconstruction approach based on the textual description and also extracts and\nanalyzes the facial components from a face image by an efficient technique. The\nFuzzy model, designed in this paper, takes crisp value of width and height of a\nfacial component and produces the crisp value of Shape for different facial\ncomponents. This method is designed using Matlab 6.5 and Visual Basic 6.0 and\ntested with the facial components extracted from 200 male and female face\nimages of different ages from different face databases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1009.0623v2", 
    "other_authors": "S. Sakthivel, R. Lakshmipathi", 
    "title": "Weighted Attribute Fusion Model for Face Recognition", 
    "arxiv-id": "1009.0623v2", 
    "author": "R. Lakshmipathi", 
    "publish": "2010-09-03T10:05:20Z", 
    "summary": "Recognizing a face based on its attributes is an easy task for a human to\nperform as it is a cognitive process. In recent years, Face Recognition is\nachieved with different kinds of facial features which were used separately or\nin a combined manner. Currently, Feature fusion methods and parallel methods\nare the facial features used and performed by integrating multiple feature sets\nat different levels. However, this integration and the combinational methods do\nnot guarantee better result. Hence to achieve better results, the feature\nfusion model with multiple weighted facial attribute set is selected. For this\nfeature model, face images from predefined data set has been taken from\nOlivetti Research Laboratory (ORL) and applied on different methods like\nPrincipal Component Analysis (PCA) based Eigen feature extraction technique,\nDiscrete Cosine Transformation (DCT) based feature extraction technique,\nHistogram Based Feature Extraction technique and Simple Intensity based\nfeatures. The extracted feature set obtained from these methods were compared\nand tested for accuracy. In this work we have developed a model which will use\nthe above set of feature extraction techniques with different levels of weights\nto attain better accuracy. The results show that the selection of optimum\nweight for a particular feature will lead to improvement in recognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr.2008.0172", 
    "link": "http://arxiv.org/pdf/1009.0854v1", 
    "other_authors": "M. Emre Celebi, Hassan Kingravi, Fatih Celiker", 
    "title": "Fast Color Space Transformations Using Minimax Approximations", 
    "arxiv-id": "1009.0854v1", 
    "author": "Fatih Celiker", 
    "publish": "2010-09-04T17:44:06Z", 
    "summary": "Color space transformations are frequently used in image processing,\ngraphics, and visualization applications. In many cases, these transformations\nare complex nonlinear functions, which prohibits their use in time-critical\napplications. In this paper, we present a new approach called Minimax\nApproximations for Color-space Transformations (MACT).We demonstrate MACT on\nthree commonly used color space transformations. Extensive experiments on a\nlarge and diverse image set and comparisons with well-known multidimensional\nlookup table interpolation methods show that MACT achieves an excellent balance\namong four criteria: ease of implementation, memory usage, accuracy, and\ncomputational speed."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr.2008.0172", 
    "link": "http://arxiv.org/pdf/1009.0892v2", 
    "other_authors": "Yongbin Zheng, Chunhua Shen, Richard Hartley, Xinsheng Huang", 
    "title": "Effective Pedestrian Detection Using Center-symmetric Local   Binary/Trinary Patterns", 
    "arxiv-id": "1009.0892v2", 
    "author": "Xinsheng Huang", 
    "publish": "2010-09-05T05:16:11Z", 
    "summary": "Accurately detecting pedestrians in images plays a critically important role\nin many computer vision applications. Extraction of effective features is the\nkey to this task. Promising features should be discriminative, robust to\nvarious variations and easy to compute. In this work, we present novel\nfeatures, termed dense center-symmetric local binary patterns (CS-LBP) and\npyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for\npedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4}\nmainly captures the texture information. The proposed CS-LBP feature, in\ncontrast, captures the gradient information and some texture information.\nMoreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to\nimplement and computationally efficient, which is desirable for real-time\napplications. Experiments on the INRIA pedestrian dataset show that the dense\nCS-LBP feature with linear supporct vector machines (SVMs) is comparable with\nthe histograms of oriented gradients (HOG) feature with linear SVMs, and the\npyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and\nthe start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection\nkernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP\nfeature and the PHOG feature could significantly improve the detection\nperformance-producing state-of-the-art accuracy on the INRIA pedestrian\ndataset."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr.2009.0056", 
    "link": "http://arxiv.org/pdf/1009.0957v1", 
    "other_authors": "M. Emre Celebi", 
    "title": "Distance Measures for Reduced Ordering Based Vector Filters", 
    "arxiv-id": "1009.0957v1", 
    "author": "M. Emre Celebi", 
    "publish": "2010-09-05T23:49:38Z", 
    "summary": "Reduced ordering based vector filters have proved successful in removing\nlong-tailed noise from color images while preserving edges and fine image\ndetails. These filters commonly utilize variants of the Minkowski distance to\norder the color vectors with the aim of distinguishing between noisy and\nnoise-free vectors. In this paper, we review various alternative distance\nmeasures and evaluate their performance on a large and diverse set of images\nusing several effectiveness and efficiency criteria. The results demonstrate\nthat there are in fact strong alternatives to the popular Minkowski metrics."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-ipr:20080080", 
    "link": "http://arxiv.org/pdf/1009.0958v1", 
    "other_authors": "M. Emre Celebi", 
    "title": "Real-Time Implementation of Order-Statistics Based Directional Filters", 
    "arxiv-id": "1009.0958v1", 
    "author": "M. Emre Celebi", 
    "publish": "2010-09-05T23:53:27Z", 
    "summary": "Vector filters based on order-statistics have proved successful in removing\nimpulsive noise from color images while preserving edges and fine image\ndetails. Among these filters, the ones that involve the cosine distance\nfunction (directional filters) have particularly high computational\nrequirements, which limits their use in time critical applications. In this\npaper, we introduce two methods to speed up these filters. Experiments on a\ndiverse set of color images show that the proposed methods provide substantial\ncomputational gains without significant loss of accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.26.001518", 
    "link": "http://arxiv.org/pdf/1009.0959v1", 
    "other_authors": "M. Emre Celebi, Hassan A. Kingravi, Rastislav Lukac, Fatih Celiker", 
    "title": "Cost-Effective Implementation of Order-Statistics Based Vector Filters   Using Minimax Approximations", 
    "arxiv-id": "1009.0959v1", 
    "author": "Fatih Celiker", 
    "publish": "2010-09-06T00:02:35Z", 
    "summary": "Vector operators based on robust order statistics have proved successful in\ndigital multichannel imaging applications, particularly color image filtering\nand enhancement, in dealing with impulsive noise while preserving edges and\nfine image details. These operators often have very high computational\nrequirements which limits their use in time-critical applications. This paper\nintroduces techniques to speed up vector filters using the minimax\napproximation theory. Extensive experiments on a large and diverse set of color\nimages show that proposed approximations achieve an excellent balance among\nease of implementation, accuracy, and computational speed."
},{
    "category": "cs.CV", 
    "doi": "10.2352/J.ImagingSci.Technol.(2007)51:2(155)", 
    "link": "http://arxiv.org/pdf/1009.0961v1", 
    "other_authors": "M. Emre Celebi, Hassan A. Kingravi, Bakhtiyar Uddin, Y. Alp Aslandogan", 
    "title": "A Fast Switching Filter for Impulsive Noise Removal from Color Images", 
    "arxiv-id": "1009.0961v1", 
    "author": "Y. Alp Aslandogan", 
    "publish": "2010-09-06T00:13:25Z", 
    "summary": "In this paper, we present a fast switching filter for impulsive noise removal\nfrom color images. The filter exploits the HSL color space, and is based on the\npeer group concept, which allows for the fast detection of noise in a\nneighborhood without resorting to pairwise distance computations between each\npixel. Experiments on large set of diverse images demonstrate that the proposed\napproach is not only extremely fast, but also gives excellent results in\ncomparison to various state-of-the-art filters."
},{
    "category": "cs.CV", 
    "doi": "10.1117/1.2772639", 
    "link": "http://arxiv.org/pdf/1009.0962v1", 
    "other_authors": "M. Emre Celebi, Hassan A. Kingravi, Y. Alp Aslandogan", 
    "title": "Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images", 
    "arxiv-id": "1009.0962v1", 
    "author": "Y. Alp Aslandogan", 
    "publish": "2010-09-06T00:22:58Z", 
    "summary": "In this paper, a comprehensive survey of 48 filters for impulsive noise\nremoval from color images is presented. The filters are formulated using a\nuniform notation and categorized into 8 families. The performance of these\nfilters is compared on a large set of images that cover a variety of domains\nusing three effectiveness and one efficiency criteria. In order to ensure a\nfair efficiency comparison, a fast and accurate approximation for the inverse\ncosine function is introduced. In addition, commonly used distance measures\n(Minkowski, angular, and directional-distance) are analyzed and evaluated.\nFinally, suggestions are provided on how to choose a filter given certain\nrequirements."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.08.003", 
    "link": "http://arxiv.org/pdf/1009.1013v1", 
    "other_authors": "M. Emre Celebi, Hitoshi Iyatomi, William V. Stoecker, Randy H. Moss, Harold S. Rabinovitz, Giuseppe Argenziano, H. Peter Soyer", 
    "title": "Automatic Detection of Blue-White Veil and Related Structures in   Dermoscopy Images", 
    "arxiv-id": "1009.1013v1", 
    "author": "H. Peter Soyer", 
    "publish": "2010-09-06T10:29:18Z", 
    "summary": "Dermoscopy is a non-invasive skin imaging technique, which permits\nvisualization of features of pigmented melanocytic neoplasms that are not\ndiscernable by examination with the naked eye. One of the most important\nfeatures for the diagnosis of melanoma in dermoscopy images is the blue-white\nveil (irregular, structureless areas of confluent blue pigmentation with an\noverlying white \"ground-glass\" film). In this article, we present a machine\nlearning approach to the detection of blue-white veil and related structures in\ndermoscopy images. The method involves contextual pixel classification using a\ndecision tree classifier. The percentage of blue-white areas detected in a\nlesion combined with a simple shape descriptor yielded a sensitivity of 69.35%\nand a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity\nrises to 78.20% for detection of blue veil in those cases where it is a primary\nfeature for melanoma recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00387.x", 
    "link": "http://arxiv.org/pdf/1009.1020v1", 
    "other_authors": "M. Emre Celebi, Gerald Schaefer, Hitoshi Iyatomi, William V. Stoecker, Joseph M. Malters, James M. Grichnik", 
    "title": "An Improved Objective Evaluation Measure for Border Detection in   Dermoscopy Images", 
    "arxiv-id": "1009.1020v1", 
    "author": "James M. Grichnik", 
    "publish": "2010-09-06T10:53:21Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, dermoscopy image analysis has become\nan important research area. One of the most important steps in dermoscopy image\nanalysis is the automated detection of lesion borders. Although numerous\nmethods have been developed for the detection of lesion borders, very few\nstudies were comprehensive in the evaluation of their results. Methods: In this\npaper, we evaluate five recent border detection methods on a set of 90\ndermoscopy images using three sets of dermatologist-drawn borders as the\nground-truth. In contrast to previous work, we utilize an objective measure,\nthe Normalized Probabilistic Rand Index, which takes into account the\nvariations in the ground-truth images. Conclusion: The results demonstrate that\nthe differences between four of the evaluated border detection methods are in\nfact smaller than those predicted by the commonly used XOR measure."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.1362v1", 
    "other_authors": "M. Emre Celebi, Hitoshi Iyatomi, Gerald Schaefer, William V. Stoecker", 
    "title": "Approximate Lesion Localization in Dermoscopy Images", 
    "arxiv-id": "1009.1362v1", 
    "author": "William V. Stoecker", 
    "publish": "2010-09-06T11:01:53Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, automated analysis of dermoscopy\nimages has become an important research area. Border detection is often the\nfirst step in this analysis. Methods: In this article, we present an\napproximate lesion localization method that serves as a preprocessing step for\ndetecting borders in dermoscopy images. In this method, first the black frame\naround the image is removed using an iterative algorithm. The approximate\nlocation of the lesion is then determined using an ensemble of thresholding\nalgorithms. Results: The method is tested on a set of 428 dermoscopy images.\nThe localization error is quantified by a metric that uses dermatologist\ndetermined borders as the ground truth. Conclusion: The results demonstrate\nthat the method presented here achieves both fast and accurate localization of\nlesions in dermoscopy images."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.1983v1", 
    "other_authors": "P. Geetha, Vasumathi Narayanan", 
    "title": "Evolutionary Computational Method of Facial Expression Analysis for   Content-based Video Retrieval using 2-Dimensional Cellular Automata", 
    "arxiv-id": "1009.1983v1", 
    "author": "Vasumathi Narayanan", 
    "publish": "2010-09-10T11:25:17Z", 
    "summary": "In this paper, Deterministic Cellular Automata (DCA) based video shot\nclassification and retrieval is proposed. The deterministic 2D Cellular\nautomata model captures the human facial expressions, both spontaneous and\nposed. The determinism stems from the fact that the facial muscle actions are\nstandardized by the encodings of Facial Action Coding System (FACS) and Action\nUnits (AUs). Based on these encodings, we generate the set of evolutionary\nupdate rules of the DCA for each facial expression. We consider a\nPerson-Independent Facial Expression Space (PIFES) to analyze the facial\nexpressions based on Partitioned 2D-Cellular Automata which capture the\ndynamics of facial expressions and classify the shots based on it. Target video\nshot is retrieved by comparing the similar expression is obtained for the query\nframe's face with respect to the key faces expressions in the database video.\nConsecutive key face expressions in the database that are highly similar to the\nquery frame's face, then the key faces are used to generate the set of\nretrieved video shots from the database. A concrete example of its application\nwhich realizes an affective interaction between the computer and the user is\nproposed. In the affective interaction, the computer can recognize the facial\nexpression of any given video shot. This interaction endows the computer with\ncertain ability to adapt to the user's feedback."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.3029v1", 
    "other_authors": "Maxime Taquet, Laurent Jacques, Christophe De Vleeschouwer, Benoit Macq", 
    "title": "Invariant Spectral Hashing of Image Saliency Graph", 
    "arxiv-id": "1009.3029v1", 
    "author": "Benoit Macq", 
    "publish": "2010-09-15T20:11:11Z", 
    "summary": "Image hashing is the process of associating a short vector of bits to an\nimage. The resulting summaries are useful in many applications including image\nindexing, image authentication and pattern recognition. These hashes need to be\ninvariant under transformations of the image that result in similar visual\ncontent, but should drastically differ for conceptually distinct contents. This\npaper proposes an image hashing method that is invariant under rotation,\nscaling and translation of the image. The gist of our approach relies on the\ngeometric characterization of salient point distribution in the image. This is\nachieved by the definition of a \"saliency graph\" connecting these points\njointly with an image intensity function on the graph nodes. An invariant hash\nis then obtained by considering the spectrum of this function in the\neigenvector basis of the Laplacian graph, that is, its graph Fourier transform.\nInterestingly, this spectrum is invariant under any relabeling of the graph\nnodes. The graph reveals geometric information of the image, making the hash\nrobust to image transformation, yet distinct for different visual content. The\nefficiency of the proposed method is assessed on a set of MRI 2-D slices and on\na database of faces."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.3078v1", 
    "other_authors": "Peng Wang, Chunhua Shen, Nick Barnes, Hong Zheng, Zhang Ren", 
    "title": "Asymmetric Totally-corrective Boosting for Real-time Object Detection", 
    "arxiv-id": "1009.3078v1", 
    "author": "Zhang Ren", 
    "publish": "2010-09-16T02:45:59Z", 
    "summary": "Real-time object detection is one of the core problems in computer vision.\nThe cascade boosting framework proposed by Viola and Jones has become the\nstandard for this problem. In this framework, the learning goal for each node\nis asymmetric, which is required to achieve a high detection rate and a\nmoderate false positive rate. We develop new boosting algorithms to address\nthis asymmetric learning problem. We show that our methods explicitly optimize\nasymmetric loss objectives in a totally corrective fashion. The methods are\ntotally corrective in the sense that the coefficients of all selected weak\nclassifiers are updated at each iteration. In contract, conventional boosting\nlike AdaBoost is stage-wise in that only the current weak classifier's\ncoefficient is updated. At the heart of the totally corrective boosting is the\ncolumn generation technique. Experiments on face detection show that our\nmethods outperform the state-of-the-art asymmetric boosting methods."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4581v1", 
    "other_authors": "Mohammed EL Hassouni, Driss Aboutajdine", 
    "title": "3D-Mesh denoising using an improved vertex based anisotropic diffusion", 
    "arxiv-id": "1009.4581v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2010-09-23T11:26:37Z", 
    "summary": "This paper deals with an improvement of vertex based nonlinear diffusion for\nmesh denoising. This method directly filters the position of the vertices using\nLaplace, reduced centered Gaussian and Rayleigh probability density functions\nas diffusivities. The use of these PDFs improves the performance of a\nvertex-based diffusion method which are adapted to the underlying mesh\nstructure. We also compare the proposed method to other mesh denoising methods\nsuch as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To\nevaluate these methods of filtering, we use two error metrics. The first is\nbased on the vertices and the second is based on the normals. Experimental\nresults demonstrate the effectiveness of our proposed method in comparison with\nthe existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4739v1", 
    "other_authors": "Romain Tavenard, Laurent Amsaleg, Herv\u00e9 J\u00e9gou", 
    "title": "Balancing clusters to reduce response time variability in large scale   image search", 
    "arxiv-id": "1009.4739v1", 
    "author": "Herv\u00e9 J\u00e9gou", 
    "publish": "2010-09-21T11:31:02Z", 
    "summary": "Many algorithms for approximate nearest neighbor search in high-dimensional\nspaces partition the data into clusters. At query time, in order to avoid\nexhaustive search, an index selects the few (or a single) clusters nearest to\nthe query point. Clusters are often produced by the well-known $k$-means\napproach since it has several desirable properties. On the downside, it tends\nto produce clusters having quite different cardinalities. Imbalanced clusters\nnegatively impact both the variance and the expectation of query response\ntimes. This paper proposes to modify $k$-means centroids to produce clusters\nwith more comparable sizes without sacrificing the desirable properties.\nExperiments with a large scale collection of image descriptors show that our\nalgorithm significantly reduces the variance of response times without\nseriously impacting the search quality."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4757v3", 
    "other_authors": "Vikram Dhillon", 
    "title": "Modeling Instantaneous Changes In Natural Scenes", 
    "arxiv-id": "1009.4757v3", 
    "author": "Vikram Dhillon", 
    "publish": "2010-09-24T03:32:28Z", 
    "summary": "This project aims to create 3d model of the natural world and model changes\nin it instantaneously. A framework for modeling instantaneous changes natural\nscenes in real time using Lagrangian Particle Framework and a fluid-particle\ngrid approach is presented. This project is presented in the form of a\nproof-based system where we show that the design is very much possible but\ncurrently we only have selective scripts that accomplish the given job, a\ncomplete software however is still under work. This research can be divided\ninto 3 distinct sections: the first one discusses a multi-camera rig that can\nmeasure ego-motion accurately up to 88%, how this device becomes the backbone\nof our framework, and some improvements devised to optimize a know framework\nfor depth maps and 3d structure estimation from a single still image called\nmake3d. The second part discusses the fluid-particle framework to model natural\nscenes, presents some algorithms that we are using to accomplish this task and\nwe show how an application of our framework can extend make3d to model natural\nscenes in real time. This part of the research constructs a bridge between\ncomputer vision and computer graphics so that now ideas, answers and intuitions\nthat arose in the domain of computer graphics can now be applied to computer\nvision and natural modeling. The final part of this research improves upon what\nmight become the first general purpose vision system using deep belief\narchitectures and provides another framework to improve the lower bound on\ntraining images for boosting by using a variation of Restricted Boltzmann\nmachines (RBM). We also discuss other applications that might arise from our\nwork in these areas."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4823v1", 
    "other_authors": "Joao Carreira, Adrian Ion, Cristian Sminchisescu", 
    "title": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques", 
    "arxiv-id": "1009.4823v1", 
    "author": "Cristian Sminchisescu", 
    "publish": "2010-09-24T12:32:02Z", 
    "summary": "We propose a mid-level image segmentation framework that combines multiple\nfigure-ground hypothesis (FG) constrained at different locations and scales,\ninto interpretations that tile the entire image. The problem is cast as\noptimization over sets of maximal cliques sampled from the graph connecting\nnon-overlapping, putative figure-ground segment hypotheses. Potential functions\nover cliques combine unary Gestalt-based figure quality scores and pairwise\ncompatibilities among spatially neighboring segments, constrained by\nT-junctions and the boundary interface statistics resulting from projections of\nreal 3d scenes. Learning the model parameters is formulated as rank\noptimization, alternating between sampling image tilings and optimizing their\npotential function parameters. State of the art results are reported on both\nthe Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was\nachieved."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.4974v1", 
    "other_authors": "S. M. Kamruzzaman, Firoz Ahmed Siddiqi, Md. Saiful Islam, Md. Emdadul Haque, Mohammad Shamsul Alam", 
    "title": "Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis   Function Networks", 
    "arxiv-id": "1009.4974v1", 
    "author": "Mohammad Shamsul Alam", 
    "publish": "2010-09-25T05:46:31Z", 
    "summary": "This paper introduces a novel method for human face detection with its\norientation by using wavelet, principle component analysis (PCA) and redial\nbasis networks. The input image is analyzed by two-dimensional wavelet and a\ntwo-dimensional stationary wavelet. The common goals concern are the image\nclearance and simplification, which are parts of de-noising or compression. We\napplied an effective procedure to reduce the dimension of the input vectors\nusing PCA. Radial Basis Function (RBF) neural network is then used as a\nfunction approximation network to detect where either the input image is\ncontained a face or not and if there is a face exists then tell about its\norientation. We will show how RBF can perform well then back-propagation\nalgorithm and give some solution for better regularization of the RBF (GRNN)\nnetwork. Compared with traditional RBF networks, the proposed network\ndemonstrates better capability of approximation to underlying functions, faster\nlearning speed, better size of network, and high robustness to outliers."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1009.5758v1", 
    "other_authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Jian Zhang", 
    "title": "Face Detection with Effective Feature Extraction", 
    "arxiv-id": "1009.5758v1", 
    "author": "Jian Zhang", 
    "publish": "2010-09-29T03:13:09Z", 
    "summary": "There is an abundant literature on face detection due to its important role\nin many vision applications. Since Viola and Jones proposed the first real-time\nAdaBoost based face detector, Haar-like features have been adopted as the\nmethod of choice for frontal face detection. In this work, we show that simple\nfeatures other than Haar-like features can also be applied for training an\neffective face detector. Since, single feature is not discriminative enough to\nseparate faces from difficult non-faces, we further improve the generalization\nperformance of our simple features by introducing feature co-occurrences. We\ndemonstrate that our proposed features yield a performance improvement compared\nto Haar-like features. In addition, our findings indicate that features play a\ncrucial role in the ability of the system to generalize."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.0417v1", 
    "other_authors": "Yu Su, Margaret H. Dunham", 
    "title": "Visual-hint Boundary to Segment Algorithm for Image Segmentation", 
    "arxiv-id": "1010.0417v1", 
    "author": "Margaret H. Dunham", 
    "publish": "2010-10-03T15:27:56Z", 
    "summary": "Image segmentation has been a very active research topic in image analysis\narea. Currently, most of the image segmentation algorithms are designed based\non the idea that images are partitioned into a set of regions preserving\nhomogeneous intra-regions and inhomogeneous inter-regions. However, human\nvisual intuition does not always follow this pattern. A new image segmentation\nmethod named Visual-Hint Boundary to Segment (VHBS) is introduced, which is\nmore consistent with human perceptions. VHBS abides by two visual hint rules\nbased on human perceptions: (i) the global scale boundaries tend to be the real\nboundaries of the objects; (ii) two adjacent regions with quite different\ncolors or textures tend to result in the real boundaries between them. It has\nbeen demonstrated by experiments that, compared with traditional image\nsegmentation method, VHBS has better performance and also preserves higher\ncomputational efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.0422v1", 
    "other_authors": "Arthur Szlam, Koray Kavukcuoglu, Yann LeCun", 
    "title": "Convolutional Matching Pursuit and Dictionary Training", 
    "arxiv-id": "1010.0422v1", 
    "author": "Yann LeCun", 
    "publish": "2010-10-03T16:55:56Z", 
    "summary": "Matching pursuit and K-SVD is demonstrated in the translation invariant\nsetting"
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.3867v1", 
    "other_authors": "Alexandre Bargeton, Fabien Moutarde, Fawzi Nashashibi, Anne-Sophie Puthon", 
    "title": "Joint interpretation of on-board vision and static GPS cartography for   determination of correct speed limit", 
    "arxiv-id": "1010.3867v1", 
    "author": "Anne-Sophie Puthon", 
    "publish": "2010-10-19T12:03:16Z", 
    "summary": "We present here a first prototype of a \"Speed Limit Support\" Advance Driving\nAssistance System (ADAS) producing permanent reliable information on the\ncurrent speed limit applicable to the vehicle. Such a module can be used either\nfor information of the driver, or could even serve for automatic setting of the\nmaximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on\na joint interpretation of cartographic information (for static reference\ninformation) with on-board vision, used for traffic sign detection and\nrecognition (including supplementary sub-signs) and visual road lines\nlocalization (for detection of lane changes). The visual traffic sign detection\npart is quite robust (90% global correct detection and recognition for main\nspeed signs, and 80% for exit-lane sub-signs detection). Our approach for joint\ninterpretation with cartography is original, and logic-based rather than\nprobability-based, which allows correct behaviour even in cases, which do\nhappen, when both vision and cartography may provide the same erroneous\ninformation."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.3935v1", 
    "other_authors": "Pedro M. Q. Aguiar, Rui F. C. Guerreiro, Bruno B. Gon\u00e7alves", 
    "title": "3-D Rigid Models from Partial Views - Global Factorization", 
    "arxiv-id": "1010.3935v1", 
    "author": "Bruno B. Gon\u00e7alves", 
    "publish": "2010-10-19T14:45:55Z", 
    "summary": "The so-called factorization methods recover 3-D rigid structure from motion\nby factorizing an observation matrix that collects 2-D projections of features.\nThese methods became popular due to their robustness - they use a large number\nof views, which constrains adequately the solution - and computational\nsimplicity - the large number of unknowns is computed through an SVD, avoiding\nnon-linear optimization. However, they require that all the entries of the\nobservation matrix are known. This is unlikely to happen in practice, due to\nself-occlusion and limited field of view. Also, when processing long videos,\nregions that become occluded often appear again later. Current factorization\nmethods process these as new regions, leading to less accurate estimates of 3-D\nstructure. In this paper, we propose a global factorization method that infers\ncomplete 3-D models directly from the 2-D projections in the entire set of\navailable video frames. Our method decides whether a region that has become\nvisible is a region that was seen before, or a previously unseen region, in a\nglobal way, i.e., by seeking the simplest rigid object that describes well the\nentire set of observations. This global approach increases significantly the\naccuracy of the estimates of the 3-D shape of the scene and the 3-D motion of\nthe camera. Experiments with artificial and real videos illustrate the good\nperformance of our method."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.3947v1", 
    "other_authors": "Bernardo Esteves Pires, Pedro M. Q. Aguiar", 
    "title": "Maximum Likelihood Mosaics", 
    "arxiv-id": "1010.3947v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2010-10-19T15:13:40Z", 
    "summary": "The majority of the approaches to the automatic recovery of a panoramic image\nfrom a set of partial views are suboptimal in the sense that the input images\nare aligned, or registered, pair by pair, e.g., consecutive frames of a video\nclip. These approaches lead to propagation errors that may be very severe,\nparticularly when dealing with videos that show the same region at disjoint\ntime intervals. Although some authors have proposed a post-processing step to\nreduce the registration errors in these situations, there have not been\nattempts to compute the optimal solution, i.e., the registrations leading to\nthe panorama that best matches the entire set of partial views}. This is our\ngoal. In this paper, we use a generative model for the partial views of the\npanorama and develop an algorithm to compute in an efficient way the Maximum\nLikelihood estimate of all the unknowns involved: the parameters describing the\nalignment of all the images and the panorama itself."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00357.x", 
    "link": "http://arxiv.org/pdf/1010.4021v1", 
    "other_authors": "Jos\u00e9 J. Rodrigues, Jo\u00e3o M. F. Xavier, Pedro M. Q. Aguiar", 
    "title": "ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of   Unlabeled Points)", 
    "arxiv-id": "1010.4021v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2010-10-19T19:48:41Z", 
    "summary": "In image analysis, many tasks require representing two-dimensional (2D)\nshape, often specified by a set of 2D points, for comparison purposes. The\nchallenge of the representation is that it must not only capture the\ncharacteristics of the shape but also be invariant to relevant transformations.\nInvariance to geometric transformations, such as translation, rotation, and\nscale, has received attention in the past, usually under the assumption that\nthe points are previously labeled, i.e., that the shape is characterized by an\nordered set of landmarks. However, in many practical scenarios, the points\ndescribing the shape are obtained from automatic processes, e.g., edge or\ncorner detection, thus without labels or natural ordering. Obviously, the\ncombinatorial problem of computing the correspondences between the points of\ntwo shapes in the presence of the aforementioned geometrical distortions\nbecomes a quagmire when the number of points is large. We circumvent this\nproblem by representing shapes in a way that is invariant to the permutation of\nthe landmarks, i.e., we represent bags of unlabeled 2D points. Within our\nframework, a shape is mapped to an analytic function on the complex plane,\nleading to what we call its analytic signature (ANSIG). To store an ANSIG, it\nsuffices to sample it along a closed contour in the complex plane. We show that\nthe ANSIG is a maximal invariant with respect to the permutation group, i.e.,\nthat different shapes have different ANSIGs and shapes that differ by a\npermutation (or re-labeling) of the landmarks have the same ANSIG. We further\nshow how easy it is to factor out geometric transformations when comparing\nshapes using the ANSIG representation. Finally, we illustrate these\ncapabilities with shape-based image classification experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.4203v1", 
    "other_authors": "Jo\u00e3o B. F. P. Crespo, Pedro M. Q. Aguiar", 
    "title": "Revisiting Complex Moments For 2D Shape Representation and Image   Normalization", 
    "arxiv-id": "1010.4203v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2010-10-18T20:12:29Z", 
    "summary": "When comparing 2D shapes, a key issue is their normalization. Translation and\nscale are easily taken care of by removing the mean and normalizing the energy.\nHowever, defining and computing the orientation of a 2D shape is not so simple.\nIn fact, although for elongated shapes the principal axis can be used to define\none of two possible orientations, there is no such tool for general shapes. As\nwe show in the paper, previous approaches fail to compute the orientation of\neven noiseless observations of simple shapes. We address this problem. In the\npaper, we show how to uniquely define the orientation of an arbitrary 2D shape,\nin terms of what we call its Principal Moments. We show that a small subset of\nthese moments suffice to represent the underlying 2D shape and propose a new\nmethod to efficiently compute the shape orientation: Principal Moment Analysis.\nFinally, we discuss how this method can further be applied to normalize\ngrey-level images. Besides the theoretical proof of correctness, we describe\nexperiments demonstrating robustness to noise and illustrating the method with\nreal images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.4314v1", 
    "other_authors": "Guoshen Yu, Guillermo Sapiro", 
    "title": "Statistical Compressive Sensing of Gaussian Mixture Models", 
    "arxiv-id": "1010.4314v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2010-10-20T20:22:26Z", 
    "summary": "A new framework of compressive sensing (CS), namely statistical compressive\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution and achieving accurate reconstruction on\naverage, is introduced. For signals following a Gaussian distribution, with\nGaussian or Bernoulli sensing matrices of O(k) measurements, considerably\nsmaller than the O(k log(N/k)) required by conventional CS, where N is the\nsignal dimension, and with an optimal decoder implemented with linear\nfiltering, significantly faster than the pursuit decoders applied in\nconventional CS, the error of SCS is shown tightly upper bounded by a constant\ntimes the k-best term approximation error, with overwhelming probability. The\nfailure probability is also significantly smaller than that of conventional CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the k-best term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For signals following Gaussian mixture models, SCS with a piecewise\nlinear decoder is introduced and shown to produce for real images better\nresults than conventional CS based on sparse models."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.4893v1", 
    "other_authors": "Pablo Sprechmann, Ignacio Ramirez, Pablo Cancela, Guillermo Sapiro", 
    "title": "Collaborative Sources Identification in Mixed Signals via Hierarchical   Sparse Modeling", 
    "arxiv-id": "1010.4893v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2010-10-23T16:47:16Z", 
    "summary": "A collaborative framework for detecting the different sources in mixed\nsignals is presented in this paper. The approach is based on C-HiLasso, a\nconvex collaborative hierarchical sparse model, and proceeds as follows. First,\nwe build a structured dictionary for mixed signals by concatenating a set of\nsub-dictionaries, each one of them learned to sparsely model one of a set of\npossible classes. Then, the coding of the mixed signal is performed by\nefficiently solving a convex optimization problem that combines standard\nsparsity with group and collaborative sparsity. The present sources are\nidentified by looking at the sub-dictionaries automatically selected in the\ncoding. The collaborative filtering in C-HiLasso takes advantage of the\ntemporal/spatial redundancy in the mixed signals, letting collections of\nsamples collaborate in identifying the classes, while allowing individual\nsamples to have different internal sparse representations. This collaboration\nis critical to further stabilize the sparse representation of signals, in\nparticular the class/sub-dictionary selection. The internal sparsity inside the\nsub-dictionaries, as naturally incorporated by the hierarchical aspects of\nC-HiLasso, is critical to make the model consistent with the essence of the\nsub-dictionaries that have been trained for sparse representation of each\nindividual class. We present applications from speaker and instrument\nidentification and texture separation. In the case of audio signals, we use\nsparse modeling to describe the short-term power spectrum envelopes of harmonic\nsounds. The proposed pitch independent method automatically detects the number\nof sources on a recording."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1010.5610v1", 
    "other_authors": "Ju Sun, Qiang Chen, Shuicheng Yan, Loong-Fah Cheong", 
    "title": "Selective Image Super-Resolution", 
    "arxiv-id": "1010.5610v1", 
    "author": "Loong-Fah Cheong", 
    "publish": "2010-10-27T08:58:48Z", 
    "summary": "In this paper we propose a vision system that performs image Super Resolution\n(SR) with selectivity. Conventional SR techniques, either by multi-image fusion\nor example-based construction, have failed to capitalize on the intrinsic\nstructural and semantic context in the image, and performed \"blind\" resolution\nrecovery to the entire image area. By comparison, we advocate example-based\nselective SR whereby selectivity is exemplified in three aspects: region\nselectivity (SR only at object regions), source selectivity (object SR with\ntrained object dictionaries), and refinement selectivity (object boundaries\nrefinement using matting). The proposed system takes over-segmented\nlow-resolution images as inputs, assimilates recent learning techniques of\nsparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to\na framework for joint figure-ground separation and interest object SR. The\nefficiency of our framework is manifested in our experiments with subsets of\nthe VOC2009 and MSRC datasets. We also demonstrate several interesting vision\napplications that can build on our system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2146264", 
    "link": "http://arxiv.org/pdf/1011.0596v1", 
    "other_authors": "Ayan Chaudhury, Abhishek Gupta, Sumita Manna, Subhadeep Mukherjee, Amlan Chakrabarti", 
    "title": "Multiple View Reconstruction of Calibrated Images using Singular Value   Decomposition", 
    "arxiv-id": "1011.0596v1", 
    "author": "Amlan Chakrabarti", 
    "publish": "2010-11-02T12:25:04Z", 
    "summary": "Calibration in a multi camera network has widely been studied for over\nseveral years starting from the earlier days of photogrammetry. Many authors\nhave presented several calibration algorithms with their relative advantages\nand disadvantages. In a stereovision system, multiple view reconstruction is a\nchallenging task. However, the total computational procedure in detail has not\nbeen presented before. Here in this work, we are dealing with the problem that,\nwhen a world coordinate point is fixed in space, image coordinates of that 3D\npoint vary for different camera positions and orientations. In computer vision\naspect, this situation is undesirable. That is, the system has to be designed\nin such a way that image coordinate of the world coordinate point will be fixed\nirrespective of the position & orientation of the cameras. We have done it in\nan elegant fashion. Firstly, camera parameters are calculated in its local\ncoordinate system. Then, we use global coordinate data to transfer all local\ncoordinate data of stereo cameras into same global coordinate system, so that\nwe can register everything into this global coordinate system. After all the\ntransformations, when the image coordinate of the world coordinate point is\ncalculated, it gives same coordinate value for all camera positions &\norientations. That is, the whole system is calibrated."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.0640v1", 
    "other_authors": "M. Emre Celebi, Hitoshi Iyatomi, Gerald Schaefer, William V. Stoecker", 
    "title": "Lesion Border Detection in Dermoscopy Images", 
    "arxiv-id": "1011.0640v1", 
    "author": "William V. Stoecker", 
    "publish": "2010-10-30T17:17:02Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, computerized analysis of dermoscopy\nimages has become an important research area. One of the most important steps\nin dermoscopy image analysis is the automated detection of lesion borders.\nMethods: In this article, we present a systematic overview of the recent border\ndetection methods in the literature paying particular attention to\ncomputational issues and evaluation aspects. Conclusion: Common problems with\nthe existing approaches include the acquisition, size, and diagnostic\ndistribution of the test image set, the evaluation of the results, and the\ninadequate description of the employed methods. Border determination by\ndermatologists appears to depend upon higher-level knowledge, therefore it is\nlikely that the incorporation of domain knowledge in automated methods will\nenable them to perform better, especially in sets of images with a variety of\ndiagnoses."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.1035v1", 
    "other_authors": "Srimal Jayawardena, Marcus Hutter, Nathan Brewer", 
    "title": "Featureless 2D-3D Pose Estimation by Minimising an   Illumination-Invariant Loss", 
    "arxiv-id": "1011.1035v1", 
    "author": "Nathan Brewer", 
    "publish": "2010-11-03T23:44:46Z", 
    "summary": "The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision ranging from robotic vision\nto image analysis. Our proposed method of registering a 3D model of a known\nobject on a given 2D photo of the object has numerous advantages over existing\nmethods: It does neither require prior training nor learning, nor knowledge of\nthe camera parameters, nor explicit point correspondences or matching features\nbetween image and model. Unlike techniques that estimate a partial 3D pose (as\nin an overhead view of traffic or machine parts on a conveyor belt), our method\nestimates the complete 3D pose of the object, and works on a single static\nimage from a given view, and under varying and unknown lighting conditions. For\nthis purpose we derive a novel illumination-invariant distance measure between\n2D photo and projected 3D model, which is then minimised to find the best pose\nparameters. Results for vehicle pose detection are presented."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.2272v1", 
    "other_authors": "A. P. Reji, Thomas Tessamma", 
    "title": "Single Frame Image super Resolution using Learned Directionlets", 
    "arxiv-id": "1011.2272v1", 
    "author": "Thomas Tessamma", 
    "publish": "2010-11-10T04:43:44Z", 
    "summary": "In this paper, a new directionally adaptive, learning based, single image\nsuper resolution method using multiple direction wavelet transform, called\nDirectionlets is presented. This method uses directionlets to effectively\ncapture directional features and to extract edge information along different\ndirections of a set of available high resolution images .This information is\nused as the training set for super resolving a low resolution input image and\nthe Directionlet coefficients at finer scales of its high-resolution image are\nlearned locally from this training set and the inverse Directionlet transform\nrecovers the super-resolved high resolution image. The simulation results\nshowed that the proposed approach outperforms standard interpolation techniques\nlike Cubic spline interpolation as well as standard Wavelet-based learning,\nboth visually and in terms of the mean squared error (mse) values. This method\ngives good result with aliased images also."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.3019v1", 
    "other_authors": "Shriprakash Sinha, Gert J. ter Horst", 
    "title": "Bounded Multivariate Surfaces On Monovariate Internal Functions", 
    "arxiv-id": "1011.3019v1", 
    "author": "Gert J. ter Horst", 
    "publish": "2010-11-12T19:48:13Z", 
    "summary": "Combining the properties of monovariate internal functions as proposed in\nKolmogorov superimposition theorem, in tandem with the bounds wielded by the\nmultivariate formulation of Chebyshev inequality, a hybrid model is presented,\nthat decomposes images into homogeneous probabilistically bounded multivariate\nsurfaces. Given an image, the model shows a novel way of working on reduced\nimage representation while processing and capturing the interaction among the\nmultidimensional information that describes the content of the same. Further,\nit tackles the practical issues of preventing leakage by bounding the growth of\nsurface and reducing the problem sample size. The model if used, also sheds\nlight on how the Chebyshev parameter relates to the number of pixels and the\ndimensionality of the feature space that associates with a pixel. Initial\nsegmentation results on the Berkeley image segmentation benchmark indicate the\neffectiveness of the proposed decomposition algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.3023v4", 
    "other_authors": "Joan Bruna, St\u00e9phane Mallat", 
    "title": "Classification with Scattering Operators", 
    "arxiv-id": "1011.3023v4", 
    "author": "St\u00e9phane Mallat", 
    "publish": "2010-11-12T20:15:25Z", 
    "summary": "A scattering vector is a local descriptor including multiscale and\nmulti-direction co-occurrence information. It is computed with a cascade of\nwavelet decompositions and complex modulus. This scattering representation is\nlocally translation invariant and linearizes deformations. A supervised\nclassification algorithm is computed with a PCA model selection on scattering\nvectors. State of the art results are obtained for handwritten digit\nrecognition and texture classification."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.3177v3", 
    "other_authors": "Ricardo Sousa, Jaime S. Cardoso", 
    "title": "The Data Replication Method for the Classification with Reject Option", 
    "arxiv-id": "1011.3177v3", 
    "author": "Jaime S. Cardoso", 
    "publish": "2010-11-14T02:48:02Z", 
    "summary": "Classification is one of the most important tasks of machine learning.\nAlthough the most well studied model is the two-class problem, in many\nscenarios there is the opportunity to label critical items for manual revision,\ninstead of trying to automatically classify every item. In this paper we adapt\na paradigm initially proposed for the classification of ordinal data to address\nthe classification problem with reject option. The technique reduces the\nproblem of classifying with reject option to the standard two-class problem.\nThe introduced method is then mapped into support vector machines and neural\nnetworks. Finally, the framework is extended to multiclass ordinal data with\nreject option. An experimental study with synthetic and real data sets,\nverifies the usefulness of the proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.compmedimag.2008.11.002", 
    "link": "http://arxiv.org/pdf/1011.4321v1", 
    "other_authors": "M. H. Fazel Zarandi, Zahra S. Razaee", 
    "title": "A Fuzzy Clustering Model for Fuzzy Data with Outliers", 
    "arxiv-id": "1011.4321v1", 
    "author": "Zahra S. Razaee", 
    "publish": "2010-11-18T22:20:45Z", 
    "summary": "In this paper a fuzzy clustering model for fuzzy data with outliers is\nproposed. The model is based on Wasserstein distance between interval valued\ndata which is generalized to fuzzy data. In addition, Keller's approach is used\nto identify outliers and reduce their influences. We have also defined a\ntransformation to change our distance to the Euclidean distance. With the help\nof this approach, the problem of fuzzy clustering of fuzzy data is reduced to\nfuzzy clustering of crisp data. In order to show the performance of the\nproposed clustering algorithm, two simulation experiments are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2011.2158428", 
    "link": "http://arxiv.org/pdf/1011.4615v2", 
    "other_authors": "Idan Ram, Michael Elad, Israel Cohen", 
    "title": "Generalized Tree-Based Wavelet Transform", 
    "arxiv-id": "1011.4615v2", 
    "author": "Israel Cohen", 
    "publish": "2010-11-20T21:32:36Z", 
    "summary": "In this paper we propose a new wavelet transform applicable to functions\ndefined on graphs, high dimensional data and networks. The proposed method\ngeneralizes the Haar-like transform proposed in [1], and it is defined via a\nhierarchical tree, which is assumed to capture the geometry and structure of\nthe input data. It is applied to the data using a modified version of the\ncommon one-dimensional (1D) wavelet filtering and decimation scheme, which can\nemploy different wavelet filters. In each level of this wavelet decomposition\nscheme, a permutation derived from the tree is applied to the approximation\ncoefficients, before they are filtered. We propose a tree construction method\nthat results in an efficient representation of the input function in the\ntransform domain. We show that the proposed transform is more efficient than\nboth the 1D and two-dimensional (2D) separable wavelet transforms in\nrepresenting images. We also explore the application of the proposed transform\nto image denoising, and show that combined with a subimage averaging scheme, it\nachieves denoising results which are similar to those obtained with the K-SVD\nalgorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2011.2158428", 
    "link": "http://arxiv.org/pdf/1011.5962v1", 
    "other_authors": "Pantelis Bouboulis, Sergios Theodoridis", 
    "title": "Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces", 
    "arxiv-id": "1011.5962v1", 
    "author": "Sergios Theodoridis", 
    "publish": "2010-11-27T10:24:12Z", 
    "summary": "The goal of this paper is the development of a novel approach for the problem\nof Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces\n(RKHS). The problem is cast as an optimization task in a RKHS, by taking\nadvantage of the celebrated semiparametric Representer Theorem. Examples verify\nthat in the presence of gaussian noise the proposed method performs relatively\nwell compared to wavelet based technics and outperforms them significantly in\nthe presence of impulse or mixed noise.\n  A more detailed version of this work has been published in the IEEE Trans.\nIm. Proc. : P. Bouboulis, K. Slavakis and S. Theodoridis, Adaptive Kernel-based\nImage Denoising employing Semi-Parametric Regularization, IEEE Transactions on\nImage Processing, vol 19(6), 2010, 1465 - 1479."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1011.6656v2", 
    "other_authors": "Ivana Tosic, Bruno A. Olshausen, Benjamin J. Culpepper", 
    "title": "Learning sparse representations of depth", 
    "arxiv-id": "1011.6656v2", 
    "author": "Benjamin J. Culpepper", 
    "publish": "2010-11-30T19:55:21Z", 
    "summary": "This paper introduces a new method for learning and inferring sparse\nrepresentations of depth (disparity) maps. The proposed algorithm relaxes the\nusual assumption of the stationary noise model in sparse coding. This enables\nlearning from data corrupted with spatially varying noise or uncertainty,\ntypically obtained by laser range scanners or structured light depth cameras.\nSparse representations are learned from the Middlebury database disparity maps\nand then exploited in a two-layer graphical model for inferring depth from\nstereo, by including a sparsity prior on the learned features. Since they\ncapture higher-order dependencies in the depth structure, these priors can\ncomplement smoothness priors commonly used in depth inference based on Markov\nRandom Field (MRF) models. Inference on the proposed graph is achieved using an\nalternating iterative optimization technique, where the first layer is solved\nusing an existing MRF-based stereo matching algorithm, then held fixed as the\nsecond layer is solved using the proposed non-stationary sparse coding\nalgorithm. This leads to a general method for improving solutions of state of\nthe art MRF-based depth estimation algorithms. Our experimental results first\nshow that depth inference using learned representations leads to state of the\nart denoising of depth maps obtained from laser range scanners and a time of\nflight camera. Furthermore, we show that adding sparse priors improves the\nresults of two depth estimation methods: the classical graph cut algorithm by\nBoykov et al. and the more recent algorithm of Woodford et al."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.0237v1", 
    "other_authors": "E. R. Gast, Michael S. Lew", 
    "title": "A Framework for Real-Time Face and Facial Feature Tracking using Optical   Flow Pre-estimation and Template Tracking", 
    "arxiv-id": "1101.0237v1", 
    "author": "Michael S. Lew", 
    "publish": "2010-12-31T12:16:29Z", 
    "summary": "This work presents a framework for tracking head movements and capturing the\nmovements of the mouth and both the eyebrows in real-time. We present a head\ntracker which is a combination of a optical flow and a template based tracker.\nThe estimation of the optical flow head tracker is used as starting point for\nthe template tracker which fine-tunes the head estimation. This approach\ntogether with re-updating the optical flow points prevents the head tracker\nfrom drifting. This combination together with our switching scheme, makes our\ntracker very robust against fast movement and motion-blur. We also propose a\nway to reduce the influence of partial occlusion of the head. In both the\noptical flow and the template based tracker we identify and exclude occluded\npoints."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.0242v1", 
    "other_authors": "Xiaojing Chen, Michael S. Lew", 
    "title": "Binary and nonbinary description of hypointensity in human brain MR   images", 
    "arxiv-id": "1101.0242v1", 
    "author": "Michael S. Lew", 
    "publish": "2010-12-31T12:26:04Z", 
    "summary": "Accumulating evidence has shown that iron is involved in the mechanism\nunderlying many neurodegenerative diseases, such as Alzheimer's disease,\nParkinson's disease and Huntington's disease. Abnormal (higher) iron\naccumulation has been detected in the brains of most neurodegenerative\npatients, especially in the basal ganglia region. Presence of iron leads to\nchanges in MR signal in both magnitude and phase. Accordingly, tissues with\nhigh iron concentration appear hypo-intense (darker than usual) in MR\ncontrasts. In this report, we proposed an improved binary hypointensity\ndescription and a novel nonbinary hypointensity description based on principle\ncomponents analysis. Moreover, Kendall's rank correlation coefficient was used\nto compare the complementary and redundant information provided by the two\nmethods in order to better understand the individual descriptions of iron\naccumulation in the brain."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.0384v1", 
    "other_authors": "Chelsia Amy Doukim, Jamal Ahmad Dargham, Ali Chekima, Sigeru Omatu", 
    "title": "Combining Neural Networks for Skin Detection", 
    "arxiv-id": "1101.0384v1", 
    "author": "Sigeru Omatu", 
    "publish": "2011-01-02T04:53:22Z", 
    "summary": "Two types of combining strategies were evaluated namely combining skin\nfeatures and combining skin classifiers. Several combining rules were applied\nwhere the outputs of the skin classifiers are combined using binary operators\nsuch as the AND and the OR operators, \"Voting\", \"Sum of Weights\" and a new\nneural network. Three chrominance components from the YCbCr colour space that\ngave the highest correct detection on their single feature MLP were selected as\nthe combining parameters. A major issue in designing a MLP neural network is to\ndetermine the optimal number of hidden units given a set of training patterns.\nTherefore, a \"coarse to fine search\" method to find the number of neurons in\nthe hidden layer is proposed. The strategy of combining Cb/Cr and Cr features\nimproved the correct detection by 3.01% compared to the best single feature MLP\ngiven by Cb-Cr. The strategy of combining the outputs of three skin classifiers\nusing the \"Sum of Weights\" rule further improved the correct detection by 4.38%\ncompared to the best single feature MLP."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.0457v1", 
    "other_authors": "Ayatullah Faruk Mollah, Subhadip Basu, Mita Nasipuri", 
    "title": "Segmentation of Camera Captured Business Card Images for Mobile Devices", 
    "arxiv-id": "1101.0457v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-01-03T06:15:08Z", 
    "summary": "Due to huge deformation in the camera captured images, variety in nature of\nthe business cards and the computational constraints of the mobile devices,\ndesign of an efficient Business Card Reader (BCR) is challenging to the\nresearchers. Extraction of text regions and segmenting them into characters is\none of such challenges. In this paper, we have presented an efficient character\nsegmentation technique for business card images captured by a cell-phone\ncamera, designed in our present work towards developing an efficient BCR. At\nfirst, text regions are extracted from the card images and then the skewed ones\nare corrected using a computationally efficient skew correction technique. At\nlast, these skew corrected text regions are segmented into lines and characters\nbased on horizontal and vertical histogram. Experiments show that the present\ntechnique is efficient and applicable for mobile devices, and the mean\nsegmentation accuracy of 97.48% is achieved with 3 mega-pixel (500-600 dpi)\nimages. It takes only 1.1 seconds for segmentation including all the\npreprocessing steps on a moderately powerful notebook (DualCore T2370, 1.73\nGHz, 1GB RAM, 1MB L2 Cache)."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.1602v1", 
    "other_authors": "Nor Amizam Jusoh, Jasni Mohamad Zain", 
    "title": "Application of Freeman Chain Codes: An Alternative Recognition Technique   for Malaysian Car Plates", 
    "arxiv-id": "1101.1602v1", 
    "author": "Jasni Mohamad Zain", 
    "publish": "2011-01-08T16:22:20Z", 
    "summary": "Various applications of car plate recognition systems have been developed\nusing various kinds of methods and techniques by researchers all over the\nworld. The applications developed were only suitable for specific country due\nto its standard specification endorsed by the transport department of\nparticular countries. The Road Transport Department of Malaysia also has\nendorsed a specification for car plates that includes the font and size of\ncharacters that must be followed by car owners. However, there are cases where\nthis specification is not followed. Several applications have been developed in\nMalaysia to overcome this problem. However, there is still problem in achieving\n100% recognition accuracy. This paper is mainly focused on conducting an\nexperiment using chain codes technique to perform recognition for different\ntypes of fonts used in Malaysian car plates."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.2243v1", 
    "other_authors": "Chenguang Lu", 
    "title": "Illustrating Color Evolution and Color Blindness by the Decoding Model   of Color Vision", 
    "arxiv-id": "1101.2243v1", 
    "author": "Chenguang Lu", 
    "publish": "2010-12-12T20:49:00Z", 
    "summary": "A symmetrical model of color vision, the decoding model as a new version of\nzone model, was introduced. The model adopts new continuous-valued logic and\nworks in a way very similar to the way a 3-8 decoder in a numerical circuit\nworks. By the decoding model, Young and Helmholtz's tri-pigment theory and\nHering's opponent theory are unified more naturally; opponent process, color\nevolution, and color blindness are illustrated more concisely. According to the\ndecoding model, we can obtain a transform from RGB system to HSV system, which\nis formally identical to the popular transform for computer graphics provided\nby Smith (1978). Advantages, problems, and physiological tests of the decoding\nmodel are also discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.2312v1", 
    "other_authors": "Jan Urban", 
    "title": "Automatic segmentation of HeLa cell images", 
    "arxiv-id": "1101.2312v1", 
    "author": "Jan Urban", 
    "publish": "2011-01-12T10:16:11Z", 
    "summary": "In this work, the possibilities for segmentation of cells from their\nbackground and each other in digital image were tested, combined and improoved.\nLot of images with young, adult and mixture cells were able to prove the\nquality of described algorithms. Proper segmentation is one of the main task of\nimage analysis and steps order differ from work to work, depending on input\nimages. Reply for biologicaly given question was looking for in this work,\nincluding filtration, details emphasizing, segmentation and sphericity\ncomputing. Order of algorithms and way to searching for them was also\ndescribed. Some questions and ideas for further work were mentioned in the\nconclusion part."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.2491v1", 
    "other_authors": "V J Dongre, V H Mankar", 
    "title": "A Review of Research on Devnagari Character Recognition", 
    "arxiv-id": "1101.2491v1", 
    "author": "V H Mankar", 
    "publish": "2011-01-13T04:00:30Z", 
    "summary": "English Character Recognition (CR) has been extensively studied in the last\nhalf century and progressed to a level, sufficient to produce technology driven\napplications. But same is not the case for Indian languages which are\ncomplicated in terms of structure and computations. Rapidly growing\ncomputational power may enable the implementation of Indic CR methodologies.\nDigital document processing is gaining popularity for application to office and\nlibrary automation, bank and postal services, publishing houses and\ncommunication technology. Devnagari being the national language of India,\nspoken by more than 500 million people, should be given special attention so\nthat document retrieval and analysis of rich ancient and modern Indian\nliterature can be effectively done. This article is intended to serve as a\nguide and update for the readers, working in the Devnagari Optical Character\nRecognition (DOCR) area. An overview of DOCR systems is presented and the\navailable DOCR techniques are reviewed. The current status of DOCR is discussed\nand directions for future research are suggested."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JSTSP.2011.2158063", 
    "link": "http://arxiv.org/pdf/1101.4301v1", 
    "other_authors": "Artiom Kovnatsky, Michael M. Bronstein, Alexander M. Bronstein, Ron Kimmel", 
    "title": "Diffusion framework for geometric and photometric data fusion in   non-rigid shape analysis", 
    "arxiv-id": "1101.4301v1", 
    "author": "Ron Kimmel", 
    "publish": "2011-01-22T16:41:20Z", 
    "summary": "In this paper, we explore the use of the diffusion geometry framework for the\nfusion of geometric and photometric information in local and global shape\ndescriptors. Our construction is based on the definition of a diffusion process\non the shape manifold embedded into a high-dimensional space where the\nembedding coordinates represent the photometric information. Experimental\nresults show that such data fusion is useful in coping with different\nchallenges of shape analysis where pure geometric and pure photometric methods\nfail."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1101.5320v2", 
    "other_authors": "Laurent Jacques, Laurent Duval, Caroline Chaux, Gabriel Peyr\u00e9", 
    "title": "A Panorama on Multiscale Geometric Representations, Intertwining   Spatial, Directional and Frequency Selectivity", 
    "arxiv-id": "1101.5320v2", 
    "author": "Gabriel Peyr\u00e9", 
    "publish": "2011-01-27T15:53:30Z", 
    "summary": "The richness of natural images makes the quest for optimal representations in\nimage processing and computer vision challenging. The latter observation has\nnot prevented the design of image representations, which trade off between\nefficiency and complexity, while achieving accurate rendering of smooth regions\nas well as reproducing faithful contours and textures. The most recent ones,\nproposed in the past decade, share an hybrid heritage highlighting the\nmultiscale and oriented nature of edges and patterns in images. This paper\npresents a panorama of the aforementioned literature on decompositions in\nmultiscale, multi-orientation bases or dictionaries. They typically exhibit\nredundancy to improve sparsity in the transformed domain and sometimes its\ninvariance with respect to simple geometric deformations (translation,\nrotation). Oriented multiscale dictionaries extend traditional wavelet\nprocessing and may offer rotation invariance. Highly redundant dictionaries\nrequire specific algorithms to simplify the search for an efficient (sparse)\nrepresentation. We also discuss the extension of multiscale geometric\ndecompositions to non-Euclidean domains such as the sphere or arbitrary meshed\nsurfaces. The etymology of panorama suggests an overview, based on a choice of\npartially overlapping \"pictures\". We hope that this paper will contribute to\nthe appreciation and apprehension of a stream of current research directions in\nimage understanding."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.1292v1", 
    "other_authors": "Bernard Ghanem, Narendra Ahuja", 
    "title": "Modeling Dynamic Swarms", 
    "arxiv-id": "1102.1292v1", 
    "author": "Narendra Ahuja", 
    "publish": "2011-02-07T12:29:30Z", 
    "summary": "This paper proposes the problem of modeling video sequences of dynamic swarms\n(DS). We define DS as a large layout of stochastically repetitive spatial\nconfigurations of dynamic objects (swarm elements) whose motions exhibit local\nspatiotemporal interdependency and stationarity, i.e., the motions are similar\nin any small spatiotemporal neighborhood. Examples of DS abound in nature,\ne.g., herds of animals and flocks of birds. To capture the local spatiotemporal\nproperties of the DS, we present a probabilistic model that learns both the\nspatial layout of swarm elements and their joint dynamics that are modeled as\nlinear transformations. To this end, a spatiotemporal neighborhood is\nassociated with each swarm element, in which local stationarity is enforced\nboth spatially and temporally. We assume that the prior on the swarm dynamics\nis distributed according to an MRF in both space and time. Embedding this model\nin a MAP framework, we iterate between learning the spatial layout of the swarm\nand its dynamics. We learn the swarm transformations using ICM, which iterates\nbetween estimating these transformations and updating their distribution in the\nspatiotemporal neighborhoods. We demonstrate the validity of our method by\nconducting experiments on real video sequences. Real sequences of birds, geese,\nrobot swarms, and pedestrians evaluate the applicability of our model to real\nworld data."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.2743v2", 
    "other_authors": "Yixiong Liang, Lei Wang, Shenghui Liao, Beiji Zou", 
    "title": "Feature selection via simultaneous sparse approximation for person   specific face verification", 
    "arxiv-id": "1102.2743v2", 
    "author": "Beiji Zou", 
    "publish": "2011-02-14T11:51:35Z", 
    "summary": "There is an increasing use of some imperceivable and redundant local features\nfor face recognition. While only a relatively small fraction of them is\nrelevant to the final recognition task, the feature selection is a crucial and\nnecessary step to select the most discriminant ones to obtain a compact face\nrepresentation. In this paper, we investigate the sparsity-enforced\nregularization-based feature selection methods and propose a multi-task feature\nselection method for building person specific models for face verification. We\nassume that the person specific models share a common subset of features and\nnovelly reformulated the common subset selection problem as a simultaneous\nsparse approximation problem. To the best of our knowledge, it is the first\ntime to apply the sparsity-enforced regularization methods for person specific\nface verification. The effectiveness of the proposed methods is verified with\nthe challenging LFW face databases."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.4258v1", 
    "other_authors": "E. Boyer, A. M. Bronstein, M. M. Bronstein, B. Bustos, T. Darom, R. Horaud, I. Hotz, Y. Keller, J. Keustermans, A. Kovnatsky, R. Litman, J. Reininghaus, I. Sipiran, D. Smeets, P. Suetens, D. Vandermeulen, A. Zaharescu, V. Zobel", 
    "title": "SHREC 2011: robust feature detection and description benchmark", 
    "arxiv-id": "1102.4258v1", 
    "author": "V. Zobel", 
    "publish": "2011-02-21T15:43:19Z", 
    "summary": "Feature-based approaches have recently become very popular in computer vision\nand image analysis applications, and are becoming a promising direction in\nshape retrieval. SHREC'11 robust feature detection and description benchmark\nsimulates the feature detection and description stages of feature-based shape\nretrieval algorithms. The benchmark tests the performance of shape feature\ndetectors and descriptors under a wide variety of transformations. The\nbenchmark allows evaluating how algorithms cope with certain classes of\ntransformations and strength of the transformations that can be dealt with. The\npresent paper is a report of the SHREC'11 robust feature detection and\ndescription benchmark results."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1102.5688v1", 
    "other_authors": "Liyakathunisa, C. N . Ravi Kumar", 
    "title": "A novel super resolution reconstruction of low reoslution images   progressively using dct and zonal filter based denoising", 
    "arxiv-id": "1102.5688v1", 
    "author": "C. N . Ravi Kumar", 
    "publish": "2011-02-28T15:24:06Z", 
    "summary": "Due to the factors like processing power limitations and channel capabilities\nimages are often down sampled and transmitted at low bit rates resulting in a\nlow resolution compressed image. High resolution images can be reconstructed\nfrom several blurred, noisy and down sampled low resolution images using a\ncomputational process know as super resolution reconstruction. Super-resolution\nis the process of combining multiple aliased low-quality images to produce a\nhigh resolution, high-quality image. The problem of recovering a high\nresolution image progressively from a sequence of low resolution compressed\nimages is considered. In this paper we propose a novel DCT based progressive\nimage display algorithm by stressing on the encoding and decoding process. At\nthe encoder we consider a set of low resolution images which are corrupted by\nadditive white Gaussian noise and motion blur. The low resolution images are\ncompressed using 8 by 8 blocks DCT and noise is filtered using our proposed\nnovel zonal filter. Multiframe fusion is performed in order to obtain a single\nnoise free image. At the decoder the image is reconstructed progressively by\ntransmitting the coarser image first followed by the detail image. And finally\na super resolution image is reconstructed by applying our proposed novel\nadaptive interpolation technique. We have performed both objective and\nsubjective analysis of the reconstructed image, and the resultant image has\nbetter super resolution factor, and a higher ISNR and PSNR. A comparative study\ndone with Iterative Back Projection (IBP) and Projection on to Convex Sets\n(POCS),Papoulis Grechberg, FFT based Super resolution Reconstruction shows that\nour method has out performed the previous contributions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.0120v2", 
    "other_authors": "Srimanta Kundu, Nibaran Das, Mita Nasipuri", 
    "title": "Automatic Detection of Ringworm using Local Binary Pattern (LBP)", 
    "arxiv-id": "1103.0120v2", 
    "author": "Mita Nasipuri", 
    "publish": "2011-03-01T10:06:31Z", 
    "summary": "In this paper we present a novel approach for automatic recognition of ring\nworm skin disease based on LBP (Local Binary Pattern) feature extracted from\nthe affected skin images. The proposed method is evaluated by extensive\nexperiments on the skin images collected from internet. The dataset is tested\nusing three different classifiers i.e. Bayesian, MLP and SVM. Experimental\nresults show that the proposed methodology efficiently discriminates between a\nring worm skin and a normal skin. It is a low cost technique and does not\nrequire any special imaging devices."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.1475v1", 
    "other_authors": "Miriam H. A. Bauer, Jan Egger, Daniela Kuhnt, Sebastiano Barbieri, Jan Klein, Horst K. Hahn, Bernd Freisleben, Christopher Nimsky", 
    "title": "A Semi-Automatic Graph-Based Approach for Determining the Boundary of   Eloquent Fiber Bundles in the Human Brain", 
    "arxiv-id": "1103.1475v1", 
    "author": "Christopher Nimsky", 
    "publish": "2011-03-08T09:39:21Z", 
    "summary": "Diffusion Tensor Imaging (DTI) allows estimating the position, orientation\nand dimension of bundles of nerve pathways. This non-invasive imaging technique\ntakes advantage of the diffusion of water molecules and determines the\ndiffusion coefficients for every voxel of the data set. The identification of\nthe diffusion coefficients and the derivation of information about fiber\nbundles is of major interest for planning and performing neurosurgical\ninterventions. To minimize the risk of neural deficits during brain surgery as\ntumor resection (e.g. glioma), the segmentation and integration of the results\nin the operating room is of prime importance. In this contribution, a robust\nand efficient graph-based approach for segmentating tubular fiber bundles in\nthe human brain is presented. To define a cost function, the fractional\nanisotropy (FA) is used, derived from the DTI data, but this value may differ\nfrom patient to patient. Besides manually definining seed regions describing\nthe structure of interest, additionally a manual definition of the cost\nfunction by the user is necessary. To improve the approach the contribution\nintroduces a solution for automatically determining the cost function by using\ndifferent 3D masks for each individual data set."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.1587v2", 
    "other_authors": "Xin Li", 
    "title": "All Roads Lead To Rome", 
    "arxiv-id": "1103.1587v2", 
    "author": "Xin Li", 
    "publish": "2011-03-08T17:50:56Z", 
    "summary": "This short article presents a class of projection-based solution algorithms\nto the problem considered in the pioneering work on compressed sensing -\nperfect reconstruction of a phantom image from 22 radial lines in the frequency\ndomain. Under the framework of projection-based image reconstruction, we will\nshow experimentally that several old and new tools of nonlinear filtering\n(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant\nthresholding and SA-DCT thresholding) all lead to perfect reconstruction of the\nphantom image."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.1952v1", 
    "other_authors": "Miriam H. A. Bauer, Jan Egger, Daniela Kuhnt, Sebastiano Barbieri, Jan Klein, Horst K. Hahn, Bernd Freisleben, Christopher Nimsky", 
    "title": "Ray-Based and Graph-Based Methods for Fiber Bundle Boundary Estimation", 
    "arxiv-id": "1103.1952v1", 
    "author": "Christopher Nimsky", 
    "publish": "2011-03-10T07:19:23Z", 
    "summary": "Diffusion Tensor Imaging (DTI) provides the possibility of estimating the\nlocation and course of eloquent structures in the human brain. Knowledge about\nthis is of high importance for preoperative planning of neurosurgical\ninterventions and for intraoperative guidance by neuronavigation in order to\nminimize postoperative neurological deficits. Therefore, the segmentation of\nthese structures as closed, three-dimensional object is necessary. In this\ncontribution, two methods for fiber bundle segmentation between two defined\nregions are compared using software phantoms (abstract model and anatomical\nphantom modeling the right corticospinal tract). One method uses evaluation\npoints from sampled rays as candidates for boundary points, the other method\nsets up a directed and weighted (depending on a scalar measure) graph and\nperforms a min-cut for optimal segmentation results. Comparison is done by\nusing the Dice Similarity Coefficient (DSC), a measure for spatial overlap of\ndifferent segmentation results."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.3440v1", 
    "other_authors": "M. S. Shirdhonkar, Manesh Kokare", 
    "title": "Off-Line Handwritten Signature Identification Using Rotated Complex   Wavelet Filters", 
    "arxiv-id": "1103.3440v1", 
    "author": "Manesh Kokare", 
    "publish": "2011-03-17T15:52:15Z", 
    "summary": "In this paper, a new method for handwritten signature identification based on\nrotated complex wavelet filters is proposed. We have proposed to use the\nrotated complex wavelet filters (RCWF) and dual tree complex wavelet\ntransform(DTCWT) together to derive signature feature extraction, which\ncaptures information in twelve different directions. In identification phase,\nCanberra distance measure is used. The proposed method is compared with\ndiscrete wavelet transform (DWT). From experimental results it is found that\nsignature identification rate of proposed method is superior over DWT"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.4723v3", 
    "other_authors": "B. G. Kodge, P. S. Hiremath", 
    "title": "Automatic Extraction of Open Space Area from High Resolution Urban   Satellite Imagery", 
    "arxiv-id": "1103.4723v3", 
    "author": "P. S. Hiremath", 
    "publish": "2011-03-24T10:40:00Z", 
    "summary": "In the 21st century, Aerial and satellite images are information rich. They\nare also complex to analyze. For GIS systems, many features require fast and\nreliable extraction of open space area from high resolution satellite imagery.\nIn this paper we will study efficient and reliable automatic extraction\nalgorithm to find out the open space area from the high resolution urban\nsatellite imagery. This automatic extraction algorithm uses some filters and\nsegmentations and grouping is applying on satellite images. And the result\nimages may use to calculate the total available open space area and the built\nup area. It may also use to compare the difference between present and past\nopen space area using historical urban satellite images of that same projection"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.sigpro.2011.04.025", 
    "link": "http://arxiv.org/pdf/1103.4913v1", 
    "other_authors": "B. G. Kodge, P. S. Hiremath", 
    "title": "Automatic Open Space Area Extraction and Change Detection from High   Resolution Urban Satellite Images", 
    "arxiv-id": "1103.4913v1", 
    "author": "P. S. Hiremath", 
    "publish": "2011-03-25T07:02:09Z", 
    "summary": "In this paper, we study efficient and reliable automatic extraction algorithm\nto find out the open space area from the high resolution urban satellite\nimagery, and to detect changes from the extracted open space area during the\nperiod 2003, 2006 and 2008. This automatic extraction and change detection\nalgorithm uses some filters, segmentation and grouping that are applied on\nsatellite images. The resultant images may be used to calculate the total\navailable open space area and the built up area. It may also be used to compare\nthe difference between present and past open space area using historical urban\nsatellite images of that same projection, which is an important geo spatial\ndata management application."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2206", 
    "link": "http://arxiv.org/pdf/1103.5621v1", 
    "other_authors": "Hafizan Mat Som, Jasni Mohamad Zain, Amzari Jihadi Ghazali", 
    "title": "Application of Threshold Techniques for Readability Improvement of Jawi   Historical Manuscript Images", 
    "arxiv-id": "1103.5621v1", 
    "author": "Amzari Jihadi Ghazali", 
    "publish": "2011-03-29T12:34:53Z", 
    "summary": "Historical documents such as old books and manuscripts have a high aesthetic\nvalue and highly appreciated. Unfortunately, there are some documents cannot be\nread due to quality problems like faded paper, ink expand, uneven colour tone,\ntorn paper and other elements disruption such as the existence of small spots.\nThe study aims to produce a copy of manuscript that shows clear wordings so\nthey can easily be read and the copy can also be displayed for visitors. 16\nsamples of Jawi historical manuscript with different quality problems were\nobtained from The Royal Museum of Pahang, Malaysia. We applied three\nbinarization techniques; Otsu's method represents global threshold technique;\nSauvola and Niblack method which are categorized as local threshold techniques.\nWe compared the binarized images with the original manuscript to be visually\ninspected by the museum's curator. The unclear features were marked and\nanalyzed. Most of the examined images show that with optimal parameters and\neffective pre processing technique, local thresholding methods are work well\ncompare with the other one. Niblack's and Sauvola's techniques seem to be the\nsuitable approaches for these types of images. Most of binarized images with\nthese two methods show improvement for readability and character recognition.\nFor this research, even the differences of image result were hard to be\ndistinguished by human capabilities, after comparing the time cost and overall\nachievement rate of recognized symbols, Niblack's method is performing better\nthan Sauvola's. We could improve the post processing step by adding edge\ndetection techniques and further enhanced by an innovative image refinement\ntechnique and a formulation of a class proper method."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2206", 
    "link": "http://arxiv.org/pdf/1103.5808v1", 
    "other_authors": "Stuart B. Heinrich, Wesley E. Snyder", 
    "title": "Improved Edge Awareness in Discontinuity Preserving Smoothing", 
    "arxiv-id": "1103.5808v1", 
    "author": "Wesley E. Snyder", 
    "publish": "2011-03-30T01:57:09Z", 
    "summary": "Discontinuity preserving smoothing is a fundamentally important procedure\nthat is useful in a wide variety of image processing contexts. It is directly\nuseful for noise reduction, and frequently used as an intermediate step in\nhigher level algorithms. For example, it can be particularly useful in edge\ndetection and segmentation. Three well known algorithms for discontinuity\npreserving smoothing are nonlinear anisotropic diffusion, bilateral filtering,\nand mean shift filtering. Although slight differences make them each better\nsuited to different tasks, all are designed to preserve discontinuities while\nsmoothing. However, none of them satisfy this goal perfectly: they each have\nexception cases in which smoothing may occur across hard edges. The principal\ncontribution of this paper is the identification of a property we call edge\nawareness that should be satisfied by any discontinuity preserving smoothing\nalgorithm. This constraint can be incorporated into existing algorithms to\nimprove quality, and usually has negligible changes in runtime performance\nand/or complexity. We present modifications necessary to augment diffusion and\nmean shift, as well as a new formulation of the bilateral filter that unifies\nthe spatial and range spaces to achieve edge awareness."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2206", 
    "link": "http://arxiv.org/pdf/1103.6052v1", 
    "other_authors": "Stuart B. Heinrich, Wesley E. Snyder", 
    "title": "Internal Constraints of the Trifocal Tensor", 
    "arxiv-id": "1103.6052v1", 
    "author": "Wesley E. Snyder", 
    "publish": "2011-03-30T21:47:41Z", 
    "summary": "The fundamental matrix and trifocal tensor are convenient algebraic\nrepresentations of the epipolar geometry of two and three view configurations,\nrespectively. The estimation of these entities is central to most\nreconstruction algorithms, and a solid understanding of their properties and\nconstraints is therefore very important. The fundamental matrix has 1 internal\nconstraint which is well understood, whereas the trifocal tensor has 8\nindependent algebraic constraints. The internal tensor constraints can be\nrepresented in many ways, although there is only one minimal and sufficient set\nof 8 constraints known. In this paper, we derive a second set of minimal and\nsufficient constraints that is simpler. We also show how this can be used in a\nnew parameterization of the trifocal tensor. We hope that this increased\nunderstanding of the internal constraints may lead to improved algorithms for\nestimating the trifocal tensor, although the primary contribution is an\nimproved theoretical understanding."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3218", 
    "link": "http://arxiv.org/pdf/1105.0079v1", 
    "other_authors": "Azrulhizam Shapi'i, Riza Sulaiman, Mohammad Khatim Hasan, Abdul Yazid Mohd Kassim", 
    "title": "An Automated Size Recognition Technique for Acetabular Implant in Total   Hip Replacement", 
    "arxiv-id": "1105.0079v1", 
    "author": "Abdul Yazid Mohd Kassim", 
    "publish": "2011-04-30T12:07:11Z", 
    "summary": "Preoperative templating in Total Hip Replacement (THR) is a method to\nestimate the optimal size and position of the implant. Today, observational\n(manual) size recognition techniques are still used to find a suitable implant\nfor the patient. Therefore, a digital and automated technique should be\ndeveloped so that the implant size recognition process can be effectively\nimplemented. For this purpose, we have introduced the new technique for\nacetabular implant size recognition in THR preoperative planning based on the\ndiameter of acetabulum size. This technique enables the surgeon to recognise a\ndigital acetabular implant size automatically. Ten randomly selected X-rays of\nunidentified patients were used to test the accuracy and utility of an\nautomated implant size recognition technique. Based on the testing result, the\nnew technique yielded very close results to those obtained by the observational\nmethod in nine studies (90%)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3218", 
    "link": "http://arxiv.org/pdf/1105.0821v1", 
    "other_authors": "Radu Arsinte, Ciprian Ilioaei", 
    "title": "Considerations and Results in Multimedia and DVB Application Development   on Philips Nexperia Platform", 
    "arxiv-id": "1105.0821v1", 
    "author": "Ciprian Ilioaei", 
    "publish": "2011-05-04T13:40:16Z", 
    "summary": "This paper presents some experiments regarding applications development on\nhigh performance media processors included in Philips Nexperia Family. The\nPNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded\nto overcome these limitations and to make possible a general-purpose use of\nthis kit. For exemplification two typical applications, important both for\nmultimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio\ndecoding. These original implementations are compared (in speed, memory\nrequirements and costs) with Philips Nexperia Library."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3218", 
    "link": "http://arxiv.org/pdf/1105.2491v2", 
    "other_authors": "Riccardo Satta, Giorgio Fumera, Fabio Roli, Marco Cristani, Vittorio Murino", 
    "title": "A Multiple Component Matching Framework for Person Re-Identification", 
    "arxiv-id": "1105.2491v2", 
    "author": "Vittorio Murino", 
    "publish": "2011-05-12T14:46:01Z", 
    "summary": "Person re-identification consists in recognizing an individual that has\nalready been observed over a network of cameras. It is a novel and challenging\nresearch topic in computer vision, for which no reference framework exists yet.\nDespite this, previous works share similar representations of human body based\non part decomposition and the implicit concept of multiple instances. Building\non these similarities, we propose a Multiple Component Matching (MCM) framework\nfor the person re-identification problem, which is inspired by Multiple\nComponent Learning, a framework recently proposed for object detection. We show\nthat previous techniques for person re-identification can be considered\nparticular implementations of our MCM framework. We then present a novel person\nre-identification technique as a direct, simple implementation of our\nframework, focused in particular on robustness to varying lighting conditions,\nand show that it can attain state of the art performances."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.540754", 
    "link": "http://arxiv.org/pdf/1105.2797v1", 
    "other_authors": "Afzal Godil, Sandy Ressler, Patrick Grother", 
    "title": "Face Recognition using 3D Facial Shape and Color Map Information:   Comparison and Combination", 
    "arxiv-id": "1105.2797v1", 
    "author": "Patrick Grother", 
    "publish": "2011-05-13T18:25:28Z", 
    "summary": "In this paper, we investigate the use of 3D surface geometry for face\nrecognition and compare it to one based on color map information. The 3D\nsurface and color map data are from the CAESAR anthropometric database. We find\nthat the recognition performance is not very different between 3D surface and\ncolor map information using a principal component analysis algorithm. We also\ndiscuss the different techniques for the combination of the 3D surface and\ncolor map information for multi-modal recognition by using different fusion\napproaches and show that there is significant improvement in results. The\neffectiveness of various techniques is compared and evaluated on a dataset with\n200 subjects in two different positions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2010.12.009", 
    "link": "http://arxiv.org/pdf/1105.3559v4", 
    "other_authors": "Rocio Gonzalez-Diaz, Adrian Ion, Mabel Iglesias-Ham, Walter G. Kropatsch", 
    "title": "Invariant Representative Cocycles of Cohomology Generators using   Irregular Graph Pyramids", 
    "arxiv-id": "1105.3559v4", 
    "author": "Walter G. Kropatsch", 
    "publish": "2011-05-18T08:18:42Z", 
    "summary": "Structural pattern recognition describes and classifies data based on the\nrelationships of features and parts. Topological invariants, like the Euler\nnumber, characterize the structure of objects of any dimension. Cohomology can\nprovide more refined algebraic invariants to a topological space than does\nhomology. It assigns `quantities' to the chains used in homology to\ncharacterize holes of any dimension. Graph pyramids can be used to describe\nsubdivisions of the same object at multiple levels of detail. This paper\npresents cohomology in the context of structural pattern recognition and\nintroduces an algorithm to efficiently compute representative cocycles (the\nbasic elements of cohomology) in 2D using a graph pyramid. An extension to\nobtain scanning and rotation invariant cocycles is given."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2010.12.009", 
    "link": "http://arxiv.org/pdf/1105.3828v2", 
    "other_authors": "Evgeniy Martyushev", 
    "title": "An Algorithmic Solution to the Five-Point Pose Problem Based on the   Cayley Representation of Rotations", 
    "arxiv-id": "1105.3828v2", 
    "author": "Evgeniy Martyushev", 
    "publish": "2011-05-19T09:50:01Z", 
    "summary": "We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2010.12.009", 
    "link": "http://arxiv.org/pdf/1105.3834v1", 
    "other_authors": "Andrea Spadaccini, Vanni Rizzo", 
    "title": "A Multiple-Choice Test Recognition System based on the Gamera Framework", 
    "arxiv-id": "1105.3834v1", 
    "author": "Vanni Rizzo", 
    "publish": "2011-05-19T10:09:44Z", 
    "summary": "This article describes JECT-OMR, a system that analyzes digital images\nrepresenting scans of multiple-choice tests compiled by students. The system\nperforms a structural analysis of the document in order to get the chosen\nanswer for each question, and it also contains a bar-code decoder, used for the\nidentification of additional information encoded in the document. JECT-OMR was\nimplemented using the Python programming language, and leverages the power of\nthe Gamera framework in order to accomplish its task. The system exhibits an\naccuracy of over 99% in the recognition of marked and non-marked squares\nrepresenting answers, thus making it suitable for real world applications"
},{
    "category": "cs.CV", 
    "doi": "10.1002/ima.20271", 
    "link": "http://arxiv.org/pdf/1105.4183v1", 
    "other_authors": "Rocio Gonzalez-Diaz, Maria Jose Jimenez, Belen Medrano", 
    "title": "Cubical Cohomology Ring of 3D Photographs", 
    "arxiv-id": "1105.4183v1", 
    "author": "Belen Medrano", 
    "publish": "2011-05-20T22:12:41Z", 
    "summary": "Cohomology and cohomology ring of three-dimensional (3D) objects are\ntopological invariants that characterize holes and their relations. Cohomology\nring has been traditionally computed on simplicial complexes. Nevertheless,\ncubical complexes deal directly with the voxels in 3D images, no additional\ntriangulation is necessary, facilitating efficient algorithms for the\ncomputation of topological invariants in the image context. In this paper, we\npresent formulas to directly compute the cohomology ring of 3D cubical\ncomplexes without making use of any additional triangulation. Starting from a\ncubical complex $Q$ that represents a 3D binary-valued digital picture whose\nforeground has one connected component, we compute first the cohomological\ninformation on the boundary of the object, $\\partial Q$ by an incremental\ntechnique; then, using a face reduction algorithm, we compute it on the whole\nobject; finally, applying the mentioned formulas, the cohomology ring is\ncomputed from such information."
},{
    "category": "cs.CV", 
    "doi": "10.1109/IV.2011.89", 
    "link": "http://arxiv.org/pdf/1105.4354v2", 
    "other_authors": "Abhishek Das, Avijit Kar, Debasis Bhattacharyya", 
    "title": "Preprocessing for Automating Early Detection of Cervical Cancer", 
    "arxiv-id": "1105.4354v2", 
    "author": "Debasis Bhattacharyya", 
    "publish": "2011-05-22T17:06:59Z", 
    "summary": "Uterine Cervical Cancer is one of the most common forms of cancer in women\nworldwide. Most cases of cervical cancer can be prevented through screening\nprograms aimed at detecting precancerous lesions. During Digital Colposcopy,\ncolposcopic images or cervigrams are acquired in raw form. They contain\nspecular reflections which appear as bright spots heavily saturated with white\nlight and occur due to the presence of moisture on the uneven cervix surface\nand. The cervix region occupies about half of the raw cervigram image. Other\nparts of the image contain irrelevant information, such as equipment, frames,\ntext and non-cervix tissues. This irrelevant information can confuse automatic\nidentification of the tissues within the cervix. Therefore we focus on the\ncervical borders, so that we have a geometric boundary on the relevant image\narea. Our novel technique eliminates the SR, identifies the region of interest\nand makes the cervigram ready for segmentation algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.dam.2004.09.014", 
    "link": "http://arxiv.org/pdf/1105.4477v1", 
    "other_authors": "Rocio Gonzalez-Diaz, Pedro Real", 
    "title": "On the Cohomology of 3D Digital Images", 
    "arxiv-id": "1105.4477v1", 
    "author": "Pedro Real", 
    "publish": "2011-05-23T12:06:18Z", 
    "summary": "We propose a method for computing the cohomology ring of three--dimensional\n(3D) digital binary-valued pictures. We obtain the cohomology ring of a 3D\ndigital binary--valued picture $I$, via a simplicial complex K(I)topologically\nrepresenting (up to isomorphisms of pictures) the picture I. The usefulness of\na simplicial description of the \"digital\" cohomology ring of 3D digital\nbinary-valued pictures is tested by means of a small program visualizing the\ndifferent steps of the method. Some examples concerning topological thinning,\nthe visualization of representative (co)cycles of (co)homology generators and\nthe computation of the cup product on the cohomology of simple pictures are\nshowed."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.4480v1", 
    "other_authors": "Rocio Gonzalez-Diaz, Maria Jose Jimenez, Belen Medrano, Pedro Real", 
    "title": "A Tool for Integer Homology Computation: Lambda-At Model", 
    "arxiv-id": "1105.4480v1", 
    "author": "Pedro Real", 
    "publish": "2011-05-23T12:40:06Z", 
    "summary": "In this paper, we formalize the notion of lambda-AT-model (where $\\lambda$ is\na non-null integer) for a given chain complex, which allows the computation of\nhomological information in the integer domain avoiding using the Smith Normal\nForm of the boundary matrices. We present an algorithm for computing such a\nmodel, obtaining Betti numbers, the prime numbers p involved in the invariant\nfactors of the torsion subgroup of homology, the amount of invariant factors\nthat are a power of p and a set of representative cycles of generators of\nhomology mod p, for each p. Moreover, we establish the minimum valid lambda for\nsuch a construction, what cuts down the computational costs related to the\ntorsion subgroup. The tools described here are useful to determine topological\ninformation of nD structured objects such as simplicial, cubical or simploidal\ncomplexes and are applicable to extract such an information from digital\npictures."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.4712v1", 
    "other_authors": "H. R. Chennamma, Lalitha Rangarajan", 
    "title": "Image Splicing Detection Using Inherent Lens Radial Distortion", 
    "arxiv-id": "1105.4712v1", 
    "author": "Lalitha Rangarajan", 
    "publish": "2011-05-24T09:05:04Z", 
    "summary": "Image splicing is a common form of image forgery. Such alterations may leave\nno visual clues of tampering. In recent works camera characteristics\nconsistency across the image has been used to establish the authenticity and\nintegrity of digital images. Such constant camera characteristic properties are\ninherent from camera manufacturing processes and are unique. The majority of\ndigital cameras are equipped with spherical lens and this introduces radial\ndistortions on images. This aberration is often disturbed and fails to be\nconsistent across the image, when an image is spliced. This paper describes the\ndetection of splicing operation on images by estimating radial distortion from\ndifferent portions of the image using line-based calibration. For the first\ntime, the detection of image splicing through the verification of consistency\nof lens radial distortion has been explored in this paper. The conducted\nexperiments demonstrate the efficacy of our proposed approach for the detection\nof image splicing on both synthetic and real images."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.6014v1", 
    "other_authors": "Yafei Sun", 
    "title": "Neural Networks for Emotion Classification", 
    "arxiv-id": "1105.6014v1", 
    "author": "Yafei Sun", 
    "publish": "2011-05-30T15:19:55Z", 
    "summary": "It is argued that for the computer to be able to interact with humans, it\nneeds to have the communication skills of humans. One of these skills is the\nability to understand the emotional state of the person. This thesis describes\na neural network-based approach for emotion classification. We learn a\nclassifier that can recognize six basic emotions with an average accuracy of\n77% over the Cohn-Kanade database. The novelty of this work is that instead of\nempirically selecting the parameters of the neural network, i.e. the learning\nrate, activation function parameter, momentum number, the number of nodes in\none layer, etc. we developed a strategy that can automatically select\ncomparatively better combination of these parameters. We also introduce another\nway to perform back propagation. Instead of using the partial differential of\nthe error function, we use optimal algorithm; namely Powell's direction set to\nminimize the error function. We were also interested in construction an\nauthentic emotion databases. This is a very important task because nowadays\nthere is no such database available. Finally, we perform several experiments\nand show that our neural network approach can be successfully used for emotion\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.6060v1", 
    "other_authors": "Feiyang Yu, Ard Oerlemans, Erwin M. Bakker", 
    "title": "Alignment of Microtubule Imagery", 
    "arxiv-id": "1105.6060v1", 
    "author": "Erwin M. Bakker", 
    "publish": "2011-05-30T18:30:51Z", 
    "summary": "This work discusses preliminary work aimed at simulating and visualizing the\ngrowth process of a tiny structure inside the cell---the microtubule.\nDifficulty of recording the process lies in the fact that the tissue\npreparation method for electronic microscopes is highly destructive to live\ncells. Here in this paper, our approach is to take pictures of microtubules at\ndifferent time slots and then appropriately combine these images into a\ncoherent video. Experimental results are given on real data."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1105.6277v1", 
    "other_authors": "Hoi Sim Wong, Tat-Jun Chin, Jin Yu, David Suter", 
    "title": "Incremental Top-k List Comparison Approach to Robust Multi-Structure   Model Fitting", 
    "arxiv-id": "1105.6277v1", 
    "author": "David Suter", 
    "publish": "2011-05-31T13:45:46Z", 
    "summary": "Random hypothesis sampling lies at the core of many popular robust fitting\ntechniques such as RANSAC. In this paper, we propose a novel hypothesis\nsampling scheme based on incremental computation of distances between partial\nrankings (top-$k$ lists) derived from residual sorting information. Our method\nsimultaneously (1) guides the sampling such that hypotheses corresponding to\nall true structures can be quickly retrieved and (2) filters the hypotheses\nsuch that only a small but very promising subset remain. This permits the usage\nof simple agglomerative clustering on the surviving hypotheses for accurate\nmodel selection. The outcome is a highly efficient multi-structure robust\nestimation technique. Experiments on synthetic and real data show the superior\nperformance of our approach over previous methods."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1108.1122v1", 
    "other_authors": "Yaniv Taigman, Lior Wolf", 
    "title": "Leveraging Billions of Faces to Overcome Performance Barriers in   Unconstrained Face Recognition", 
    "arxiv-id": "1108.1122v1", 
    "author": "Lior Wolf", 
    "publish": "2011-08-04T15:51:19Z", 
    "summary": "We employ the face recognition technology developed in house at face.com to a\nwell accepted benchmark and show that without any tuning we are able to\nconsiderably surpass state of the art results. Much of the improvement is\nconcentrated in the high-valued performance point of zero false positive\nmatches, where the obtained recall rate almost doubles the best reported result\nto date. We discuss the various components and innovations of our system that\nenable this significant performance gap. These components include extensive\nutilization of an accurate 3D reconstructed shape model dealing with challenges\narising from pose and illumination. In addition, discriminative models based on\nbillions of faces are used in order to overcome aging and facial expression as\nwell as low light and overexposure. Finally, we identify a challenging set of\nidentification queries that might provide useful focus for future research."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1108.1169v1", 
    "other_authors": "Karol Gregor, Yann LeCun", 
    "title": "Learning Representations by Maximizing Compression", 
    "arxiv-id": "1108.1169v1", 
    "author": "Yann LeCun", 
    "publish": "2011-08-04T19:00:14Z", 
    "summary": "We give an algorithm that learns a representation of data through\ncompression. The algorithm 1) predicts bits sequentially from those previously\nseen and 2) has a structure and a number of computations similar to an\nautoencoder. The likelihood under the model can be calculated exactly, and\narithmetic coding can be used directly for compression. When training on digits\nthe algorithm learns filters similar to those of restricted boltzman machines\nand denoising autoencoders. Independent samples can be drawn from the model by\na single sweep through the pixels. The algorithm has a good compression\nperformance when compared to other methods that work under random ordering of\npixels."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.imavis.2008.10.001", 
    "link": "http://arxiv.org/pdf/1108.1353v1", 
    "other_authors": "K. Susheel Kumar, Vijay Bhaskar Semwal, R C Tripathi", 
    "title": "Real time face recognition using adaboost improved fast PCA algorithm", 
    "arxiv-id": "1108.1353v1", 
    "author": "R C Tripathi", 
    "publish": "2011-08-05T15:41:31Z", 
    "summary": "This paper presents an automated system for human face recognition in a real\ntime background world for a large homemade dataset of persons face. The task is\nvery difficult as the real time background subtraction in an image is still a\nchallenge. Addition to this there is a huge variation in human face image in\nterms of size, pose and expression. The system proposed collapses most of this\nvariance. To detect real time human face AdaBoost with Haar cascade is used and\na simple fast PCA and LDA is used to recognize the faces detected. The matched\nface is then used to mark attendance in the laboratory, in our case. This\nbiometric system is a real time attendance system based on the human face\nrecognition with a simple and fast algorithms and gaining a high accuracy\nrate.."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2191780", 
    "link": "http://arxiv.org/pdf/1108.2632v1", 
    "other_authors": "Subhojit Som, Philip Schniter", 
    "title": "Compressive Imaging using Approximate Message Passing and a Markov-Tree   Prior", 
    "arxiv-id": "1108.2632v1", 
    "author": "Philip Schniter", 
    "publish": "2011-08-12T14:41:49Z", 
    "summary": "We propose a novel algorithm for compressive imaging that exploits both the\nsparsity and persistence across scales found in the 2D wavelet transform\ncoefficients of natural images. Like other recent works, we model wavelet\nstructure using a hidden Markov tree (HMT) but, unlike other works, ours is\nbased on loopy belief propagation (LBP). For LBP, we adopt a recently proposed\n\"turbo\" message passing schedule that alternates between exploitation of HMT\nstructure and exploitation of compressive-measurement structure. For the\nlatter, we leverage Donoho, Maleki, and Montanari's recently proposed\napproximate message passing (AMP) algorithm. Experiments with a large image\ndatabase suggest that, relative to existing schemes, our turbo LBP approach\nyields state-of-the-art reconstruction performance with substantial reduction\nin complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2191780", 
    "link": "http://arxiv.org/pdf/1108.3250v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zaky", 
    "title": "The Statistical methods of Pixel-Based Image Fusion Techniques", 
    "arxiv-id": "1108.3250v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2011-08-12T16:51:21Z", 
    "summary": "There are many image fusion methods that can be used to produce\nhigh-resolution mutlispectral images from a high-resolution panchromatic (PAN)\nimage and low-resolution multispectral (MS) of remote sensed images. This paper\nattempts to undertake the study of image fusion techniques with different\nStatistical techniques for image fusion as Local Mean Matching (LMM), Local\nMean and Variance Matching (LMVM), Regression variable substitution (RVS),\nLocal Correlation Modeling (LCM) and they are compared with one another so as\nto choose the best technique, that can be applied on multi-resolution satellite\nimages. This paper also devotes to concentrate on the analytical techniques for\nevaluating the quality of image fusion (F) by using various methods including\nStandard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to\nNoise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation\nIndex (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2191780", 
    "link": "http://arxiv.org/pdf/1108.3251v1", 
    "other_authors": "Artem Migukin, Vladimir Katkovnik, Jaakko Astola", 
    "title": "Advanced phase retrieval: maximum likelihood technique with sparse   regularization of phase and amplitude", 
    "arxiv-id": "1108.3251v1", 
    "author": "Jaakko Astola", 
    "publish": "2011-08-15T09:37:15Z", 
    "summary": "Sparse modeling is one of the efficient techniques for imaging that allows\nrecovering lost information. In this paper, we present a novel iterative\nphase-retrieval algorithm using a sparse representation of the object amplitude\nand phase. The algorithm is derived in terms of a constrained maximum\nlikelihood, where the wave field reconstruction is performed using a number of\nnoisy intensity-only observations with a zero-mean additive Gaussian noise. The\ndeveloped algorithm enables the optimal solution for the object wave field\nreconstruction. Our goal is an improvement of the reconstruction quality with\nrespect to the conventional algorithms. Sparse regularization results in\nadvanced reconstruction accuracy, and numerical simulations demonstrate\nsignificant enhancement of imaging."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2012.262", 
    "link": "http://arxiv.org/pdf/1108.3605v2", 
    "other_authors": "Adrian Barbu", 
    "title": "Hierarchical Object Parsing from Structured Noisy Point Clouds", 
    "arxiv-id": "1108.3605v2", 
    "author": "Adrian Barbu", 
    "publish": "2011-08-18T02:11:34Z", 
    "summary": "Object parsing and segmentation from point clouds are challenging tasks\nbecause the relevant data is available only as thin structures along object\nboundaries or other features, and is corrupted by large amounts of noise. To\nhandle this kind of data, flexible shape models are desired that can accurately\nfollow the object boundaries. Popular models such as Active Shape and Active\nAppearance models lack the necessary flexibility for this task, while recent\napproaches such as the Recursive Compositional Models make model\nsimplifications in order to obtain computational guarantees. This paper\ninvestigates a hierarchical Bayesian model of shape and appearance in a\ngenerative setting. The input data is explained by an object parsing layer,\nwhich is a deformation of a hidden PCA shape model with Gaussian prior. The\npaper also introduces a novel efficient inference algorithm that uses informed\ndata-driven proposals to initialize local searches for the hidden variables.\nApplied to the problem of object parsing from structured point clouds such as\nedge detection images, the proposed approach obtains state of the art parsing\nerrors on two standard datasets without using any intensity information."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2012.262", 
    "link": "http://arxiv.org/pdf/1108.4098v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zaky", 
    "title": "Multisensor Images Fusion Based on Feature-Level", 
    "arxiv-id": "1108.4098v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2011-08-20T07:43:46Z", 
    "summary": "Until now, of highest relevance for remote sensing data processing and\nanalysis have been techniques for pixel level image fusion. So, This paper\nattempts to undertake the study of Feature-Level based image fusion. For this\npurpose, feature based fusion techniques, which are usually based on empirical\nor heuristic rules, are employed. Hence, in this paper we consider feature\nextraction (FE) for fusion. It aims at finding a transformation of the original\nspace that would produce such new features, which preserve or improve as much\nas possible. This study introduces three different types of Image fusion\ntechniques including Principal Component Analysis based Feature Fusion (PCA),\nSegment Fusion (SF) and Edge fusion (EF). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including (SD), (En), (CC), (SNR), (NRMSE)\nand (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.1179/1743131X11Y.0000000013", 
    "link": "http://arxiv.org/pdf/1108.4315v1", 
    "other_authors": "Won Yeol Lee, Young Woo Kim, Se Yun Kim, Jae Young Lim, Dong Hoon Lim", 
    "title": "Edge detection based on morphological amoebas", 
    "arxiv-id": "1108.4315v1", 
    "author": "Dong Hoon Lim", 
    "publish": "2011-08-22T13:49:57Z", 
    "summary": "Detecting the edges of objects within images is critical for quality image\nprocessing. We present an edge-detecting technique that uses morphological\namoebas that adjust their shape based on variation in image contours. We\nevaluate the method both quantitatively and qualitatively for edge detection of\nimages, and compare it to classic morphological methods. Our amoeba-based\nedge-detection system performed better than the classic edge detectors."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1108.6294v1", 
    "other_authors": "L. R Sudha, Dr. R Bhavani", 
    "title": "Biometric Authorization System using Gait Biometry", 
    "arxiv-id": "1108.6294v1", 
    "author": "Dr. R Bhavani", 
    "publish": "2011-08-31T17:22:51Z", 
    "summary": "Human gait, which is a new biometric aimed to recognize individuals by the\nway they walk have come to play an increasingly important role in visual\nsurveillance applications. In this paper a novel hybrid holistic approach is\nproposed to show how behavioural walking characteristics can be used to\nrecognize unauthorized and suspicious persons when they enter a surveillance\narea. Initially background is modelled from the input video captured from\ncameras deployed for security and the foreground moving object in the\nindividual frames are segmented using the background subtraction algorithm.\nThen gait representing spatial, temporal and wavelet components are extracted\nand fused for training and testing multi class support vector machine models\n(SVM). The proposed system is evaluated using side view videos of NLPR\ndatabase. The experimental results demonstrate that the proposed system\nachieves a pleasing recognition rate and also the results indicate that the\nclassification ability of SVM with Radial Basis Function (RBF) is better than\nwith other kernel functions."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.0264v1", 
    "other_authors": "Hanxi Li, Chunhua Shen, Yongsheng Gao", 
    "title": "Face Recognition using Optimal Representation Ensemble", 
    "arxiv-id": "1110.0264v1", 
    "author": "Yongsheng Gao", 
    "publish": "2011-10-03T04:44:47Z", 
    "summary": "Recently, the face recognizers based on linear representations have been\nshown to deliver state-of-the-art performance. In real-world applications,\nhowever, face images usually suffer from expressions, disguises and random\nocclusions. The problematic facial parts undermine the validity of the\nlinear-subspace assumption and thus the recognition performance deteriorates\nsignificantly. In this work, we address the problem in a\nlearning-inference-mixed fashion. By observing that the linear-subspace\nassumption is more reliable on certain face patches rather than on the holistic\nface, some Bayesian Patch Representations (BPRs) are randomly generated and\ninterpreted according to the Bayes' theory. We then train an ensemble model\nover the patch-representations by minimizing the empirical risk w.r.t the\n\"leave-one-out margins\". The obtained model is termed Optimal Representation\nEnsemble (ORE), since it guarantees the optimality from the perspective of\nEmpirical Risk Minimization. To handle the unknown patterns in test faces, a\nrobust version of BPR is proposed by taking the non-face category into\nconsideration. Equipped with the Robust-BPRs, the inference ability of ORE is\nincreased dramatically and several record-breaking accuracies (99.9% on Yale-B\nand 99.5% on AR) and desirable efficiencies (below 20 ms per face in Matlab)\nare achieved. It also overwhelms other modular heuristics on the faces with\nrandom occlusions, extreme expressions and disguises. Furthermore, to\naccommodate immense BPRs sets, a boosting-like algorithm is also derived. The\nboosted model, a.k.a Boosted-ORE, obtains similar performance to its prototype.\nBesides the empirical superiorities, two desirable features of the proposed\nmethods, namely, the training-determined model-selection and the\ndata-weight-free boosting procedure, are also theoretically verified."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.0585v1", 
    "other_authors": "Jacob Whitehill, Javier Movellan", 
    "title": "Discriminately Decreasing Discriminability with Learned Image Filters", 
    "arxiv-id": "1110.0585v1", 
    "author": "Javier Movellan", 
    "publish": "2011-10-04T06:48:29Z", 
    "summary": "In machine learning and computer vision, input images are often filtered to\nincrease data discriminability. In some situations, however, one may wish to\npurposely decrease discriminability of one classification task (a \"distractor\"\ntask), while simultaneously preserving information relevant to another (the\ntask-of-interest): For example, it may be important to mask the identity of\npersons contained in face images before submitting them to a crowdsourcing site\n(e.g., Mechanical Turk) when labeling them for certain facial attributes.\nAnother example is inter-dataset generalization: when training on a dataset\nwith a particular covariance structure among multiple attributes, it may be\nuseful to suppress one attribute while preserving another so that a trained\nclassifier does not learn spurious correlations between attributes. In this\npaper we present an algorithm that finds optimal filters to give high\ndiscriminability to one task while simultaneously giving low discriminability\nto a distractor task. We present results showing the effectiveness of the\nproposed technique on both simulated data and natural face images."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.0872v1", 
    "other_authors": "Toshiro Kubota", 
    "title": "Non-Gaussian Scale Space Filtering with 2 by 2 Matrix of Linear Filters", 
    "arxiv-id": "1110.0872v1", 
    "author": "Toshiro Kubota", 
    "publish": "2011-10-04T23:58:55Z", 
    "summary": "Construction of a scale space with a convolution filter has been studied\nextensively in the past. It has been proven that the only convolution kernel\nthat satisfies the scale space requirements is a Gaussian type. In this paper,\nwe consider a matrix of convolution filters introduced in [1] as a building\nkernel for a scale space, and shows that we can construct a non-Gaussian scale\nspace with a $2\\times 2$ matrix of filters. The paper derives sufficient\nconditions for the matrix of filters for being a scale space kernel, and\npresent some numerical demonstrations."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1401", 
    "link": "http://arxiv.org/pdf/1110.1485v1", 
    "other_authors": "Hafiz Imtiaz, Shaikh Anowarul Fattah", 
    "title": "A Face Recognition Scheme using Wavelet Based Dominant Features", 
    "arxiv-id": "1110.1485v1", 
    "author": "Shaikh Anowarul Fattah", 
    "publish": "2011-10-07T11:16:17Z", 
    "summary": "In this paper, a multi-resolution feature extraction algorithm for face\nrecognition is proposed based on two-dimensional discrete wavelet transform\n(2D-DWT), which efficiently exploits the local spatial variations in a face\nimage. For the purpose of feature extraction, instead of considering the entire\nface image, an entropy-based local band selection criterion is developed, which\nselects high-informative horizontal segments from the face image. In order to\ncapture the local spatial variations within these highinformative horizontal\nbands precisely, the horizontal band is segmented into several small spatial\nmodules. Dominant wavelet coefficients corresponding to each local region\nresiding inside those horizontal bands are selected as features. In the\nselection of the dominant coefficients, a threshold criterion is proposed,\nwhich not only drastically reduces the feature dimension but also provides high\nwithin-class compactness and high between-class separability. A principal\ncomponent analysis is performed to further reduce the dimensionality of the\nfeature space. Extensive experimentation is carried out upon standard face\ndatabases and a very high degree of recognition accuracy is achieved by the\nproposed method in comparison to those obtained by some of the existing\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3318", 
    "link": "http://arxiv.org/pdf/1110.1509v1", 
    "other_authors": "A. Kadir, L. E. Nugroho, A. Susanto, P. I. Santosa", 
    "title": "A Comparative Experiment of Several Shape Methods in Recognizing Plants", 
    "arxiv-id": "1110.1509v1", 
    "author": "P. I. Santosa", 
    "publish": "2011-10-07T12:43:38Z", 
    "summary": "Shape is an important aspects in recognizing plants. Several approaches have\nbeen introduced to identify objects, including plants. Combination of geometric\nfeatures such as aspect ratio, compactness, and dispersion, or moments such as\nmoment invariants were usually used toidentify plants. In this research, a\ncomparative experiment of 4 methods to identify plants using shape features was\naccomplished. Two approaches have never been used in plants identification yet,\nZernike moments and Polar Fourier Transform (PFT), were incorporated. The\nexperimental comparison was done on 52 kinds of plants with various shapes. The\nresult, PFT gave best performance with 64% in accuracy and outperformed the\nother methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2301", 
    "link": "http://arxiv.org/pdf/1110.1513v1", 
    "other_authors": "Abdul Kadir, Lukito Edi Nugroho, Adhi Susanto, Paulus Insap Santosa", 
    "title": "Foliage Plant Retrieval using Polar Fourier Transform, Color Moments and   Vein Features", 
    "arxiv-id": "1110.1513v1", 
    "author": "Paulus Insap Santosa", 
    "publish": "2011-10-07T13:00:03Z", 
    "summary": "This paper proposed a method that combines Polar Fourier Transform, color\nmoments, and vein features to retrieve leaf images based on a leaf image. The\nmethod is very useful to help people in recognizing foliage plants. Foliage\nplants are plants that have various colors and unique patterns in the leaf.\nTherefore, the colors and its patterns are information that should be counted\non in the processing of plant identification. To compare the performance of\nretrieving system to other result, the experiments used Flavia dataset, which\nis very popular in recognizing plants. The result shows that the method gave\nbetter performance than PNN, SVM, and Fourier Transform. The method was also\ntested using foliage plants with various colors. The accuracy was 90.80% for 50\nkinds of plants."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2301", 
    "link": "http://arxiv.org/pdf/1110.2053v3", 
    "other_authors": "Stefano Soatto", 
    "title": "Steps Towards a Theory of Visual Information: Active Perception,   Signal-to-Symbol Conversion and the Interplay Between Sensing and Control", 
    "arxiv-id": "1110.2053v3", 
    "author": "Stefano Soatto", 
    "publish": "2011-10-10T14:28:41Z", 
    "summary": "This manuscript describes the elements of a theory of information tailored to\ncontrol and decision tasks and specifically to visual data. The concept of\nActionable Information is described, that relates to a notion of information\nchampioned by J. Gibson, and a notion of \"complete information\" that relates to\nthe minimal sufficient statistics of a complete representation. It is shown\nthat the \"actionable information gap\" between the two can be reduced by\nexercising control on the sensing process. Thus, senging, control and\ninformation are inextricably tied. This has consequences in the so-called\n\"signal-to-symbol barrier\" problem, as well as in the analysis and design of\nactive sensing systems. It has ramifications in vision-based control,\nnavigation, 3-D reconstruction and rendering, as well as detection,\nlocalization, recognition and categorization of objects and scenes in live\nvideo.\n  This manuscript has been developed from a set of lecture notes for a summer\ncourse at the First International Computer Vision Summer School (ICVSS) in\nScicli, Italy, in July of 2008. They were later expanded and amended for\nsubsequent lectures in the same School in July 2009. Starting on November 1,\n2009, they were further expanded for a special topics course, CS269, taught at\nUCLA in the Spring term of 2010."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.2210v1", 
    "other_authors": "S. R. Jodogne, J. H. Piater", 
    "title": "Closed-Loop Learning of Visual Control Policies", 
    "arxiv-id": "1110.2210v1", 
    "author": "J. H. Piater", 
    "publish": "2011-10-10T21:56:36Z", 
    "summary": "In this paper we present a general, flexible framework for learning mappings\nfrom images to actions by interacting with the environment. The basic idea is\nto introduce a feature-based image classifier in front of a reinforcement\nlearning algorithm. The classifier partitions the visual space according to the\npresence or absence of few highly informative local descriptors that are\nincrementally selected in a sequence of attempts to remove perceptual aliasing.\nWe also address the problem of fighting overfitting in such a greedy algorithm.\nFinally, we show how high-level visual features can be generated when the power\nof local descriptors is insufficient for completely disambiguating the aliased\nstates. This is done by building a hierarchy of composite features that consist\nof recursive spatial combinations of visual features. We demonstrate the\nefficacy of our algorithms by solving three visual navigation tasks and a\nvisual version of the classical Car on the Hill control problem."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.3194v1", 
    "other_authors": "Qiyu Jin, Ion Grama, Quansheng Liu", 
    "title": "Controlled Total Variation regularization for inverse problems", 
    "arxiv-id": "1110.3194v1", 
    "author": "Quansheng Liu", 
    "publish": "2011-10-14T13:02:36Z", 
    "summary": "This paper provides a new algorithm for solving inverse problems, based on\nthe minimization of the $L^2$ norm and on the control of the Total Variation.\nIt consists in relaxing the role of the Total Variation in the classical Total\nVariation minimization approach, which permits us to get better approximation\nto the inverse problems. The numerical results on the deconvolution problem\nshow that our method outperforms some previous ones."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.4970v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zaky", 
    "title": "Studying Satellite Image Quality Based on the Fusion Techniques", 
    "arxiv-id": "1110.4970v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2011-10-22T13:26:00Z", 
    "summary": "Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. However,\nthe jury is still out on the benefits of a fused image compared to its original\nimages. There is also a lack of measures for assessing the objective quality of\nthe spatial resolution for the fusion methods. Therefore, an objective quality\nof the spatial resolution assessment for fusion images is required. So, this\nstudy attempts to develop a new qualitative assessment to evaluate the spatial\nquality of the pan sharpened images by many spatial quality metrics. Also, this\npaper deals with a comparison of various image fusion techniques based on pixel\nand feature fusion techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.5404v1", 
    "other_authors": "Thai Hoang Le, Len Bui", 
    "title": "Face Recognition Based on SVM and 2DPCA", 
    "arxiv-id": "1110.5404v1", 
    "author": "Len Bui", 
    "publish": "2011-10-25T03:54:51Z", 
    "summary": "The paper will present a novel approach for solving face recognition problem.\nOur method combines 2D Principal Component Analysis (2DPCA), one of the\nprominent methods for extracting feature vectors, and Support Vector Machine\n(SVM), the most powerful discriminative method for classification. Experiments\nbased on proposed method have been conducted on two public data sets FERET and\nAT&T; the results show that the proposed method could improve the\nclassification rates."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.5450v1", 
    "other_authors": "Roberto Cespi, Andreas Kolb, Marvin Lindner", 
    "title": "Hand Tracking based on Hierarchical Clustering of Range Data", 
    "arxiv-id": "1110.5450v1", 
    "author": "Marvin Lindner", 
    "publish": "2011-10-25T09:24:25Z", 
    "summary": "Fast and robust hand segmentation and tracking is an essential basis for\ngesture recognition and thus an important component for contact-less\nhuman-computer interaction (HCI). Hand gesture recognition based on 2D video\ndata has been intensively investigated. However, in practical scenarios purely\nintensity based approaches suffer from uncontrollable environmental conditions\nlike cluttered background colors. In this paper we present a real-time hand\nsegmentation and tracking algorithm using Time-of-Flight (ToF) range cameras\nand intensity data. The intensity and range information is fused into one pixel\nvalue, representing its combined intensity-depth homogeneity. The scene is\nhierarchically clustered using a GPU based parallel merging algorithm, allowing\na robust identification of both hands even for inhomogeneous backgrounds. After\nthe detection, both hands are tracked on the CPU. Our tracking algorithm can\ncope with the situation that one hand is temporarily covered by the other hand."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1110.5945v1", 
    "other_authors": "Sudipto Dolui, Alan Kuurstra, Iv\u00e1n C. Salgado Patarroyo, Oleg V. Michailovich", 
    "title": "A New Similarity Measure for Non-Local Means Filtering of MRI Images", 
    "arxiv-id": "1110.5945v1", 
    "author": "Oleg V. Michailovich", 
    "publish": "2011-10-26T23:14:57Z", 
    "summary": "The acquisition of MRI images offers a trade-off in terms of acquisition\ntime, spatial/temporal resolution and signal-to-noise ratio (SNR). Thus, for\ninstance, increasing the time efficiency of MRI often comes at the expense of\nreduced SNR. This, in turn, necessitates the use of post-processing tools for\nnoise rejection, which makes image de-noising an indispensable component of\ncomputer assistance diagnosis. In the field of MRI, a multitude of image\nde-noising methods have been proposed hitherto. In this paper, the application\nof a particular class of de-noising algorithms - known as non-local mean (NLM)\nfilters - is investigated. Such filters have been recently applied for MRI data\nenhancement and they have been shown to provide more accurate results as\ncompared to many alternative de-noising algorithms. Unfortunately, virtually\nall existing methods for NLM filtering have been derived under the assumption\nof additive white Gaussian (AWG) noise contamination. Since this assumption is\nknown to fail at low values of SNR, an alternative formulation of NLM filtering\nis required, which would take into consideration the correct Rician statistics\nof MRI noise. Accordingly, the contribution of the present paper is two-fold.\nFirst, it points out some principal disadvantages of the earlier methods of NLM\nfiltering of MRI images and suggests means to rectify them. Second, the paper\nintroduces a new similarity measure for NLM filtering of MRI Images, which is\nderived under bona fide statistical assumptions and results in more accurate\nreconstruction of MR scans as compared to alternative NLM approaches. Finally,\nthe utility and viability of the proposed method is demonstrated through a\nseries of numerical experiments using both in silico and in vivo MRI data."
},{
    "category": "cs.CV", 
    "doi": "10.1613/jair.2110", 
    "link": "http://arxiv.org/pdf/1112.0059v1", 
    "other_authors": "Sancho McCann, David G. Lowe", 
    "title": "Local Naive Bayes Nearest Neighbor for Image Classification", 
    "arxiv-id": "1112.0059v1", 
    "author": "David G. Lowe", 
    "publish": "2011-12-01T01:19:08Z", 
    "summary": "We present Local Naive Bayes Nearest Neighbor, an improvement to the NBNN\nimage classification algorithm that increases classification accuracy and\nimproves its ability to scale to large numbers of object classes. The key\nobservation is that only the classes represented in the local neighborhood of a\ndescriptor contribute significantly and reliably to their posterior probability\nestimates. Instead of maintaining a separate search structure for each class,\nwe merge all of the reference data together into one search structure, allowing\nquick identification of a descriptor's local neighborhood. We show an increase\nin classification accuracy when we ignore adjustments to the more distant\nclasses and show that the run time grows with the log of the number of classes\nrather than linearly in the number of classes as did the original. This gives a\n100 times speed-up over the original method on the Caltech 256 dataset. We also\nprovide the first head-to-head comparison of NBNN against spatial pyramid\nmethods using a common set of input features. We show that local NBNN\noutperforms all previous NBNN based methods and the original spatial pyramid\nmodel. However, we find that local NBNN, while competitive with, does not beat\nstate-of-the-art spatial pyramid methods that use local soft assignment and\nmax-pooling."
},{
    "category": "cs.CV", 
    "doi": "10.1103/PhysRevE.85.041918", 
    "link": "http://arxiv.org/pdf/1112.0655v1", 
    "other_authors": "Andras Gelencser, Themistoklis Prodromakis, Christofer Toumazou, Tamas Roska", 
    "title": "A Biomimetic Model of the Outer Plexiform Layer by Incorporating   Memristive Devices", 
    "arxiv-id": "1112.0655v1", 
    "author": "Tamas Roska", 
    "publish": "2011-12-03T13:53:54Z", 
    "summary": "In this paper we present a biorealistic model for the first part of the early\nvision processing by incorporating memristive nanodevices. The architecture of\nthe proposed network is based on the organisation and functioning of the outer\nplexiform layer (OPL) in the vertebrate retina. We demonstrate that memristive\ndevices are indeed a valuable building block for neuromorphic architectures, as\ntheir highly non-linear and adaptive response could be exploited for\nestablishing ultra-dense networks with similar dynamics to their biological\ncounterparts. We particularly show that hexagonal memristive grids can be\nemployed for faithfully emulating the smoothing-effect occurring at the OPL for\nenhancing the dynamic range of the system. In addition, we employ a\nmemristor-based thresholding scheme for detecting the edges of grayscale\nimages, while the proposed system is also evaluated for its adaptation and\nfault tolerance capacity against different light or noise conditions as well as\ndistinct device yields."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1187v1", 
    "other_authors": "Neus Sabater, Andr\u00e9s Almansa, Jean-Michel Morel", 
    "title": "Meaningful Matches in Stereovision", 
    "arxiv-id": "1112.1187v1", 
    "author": "Jean-Michel Morel", 
    "publish": "2011-12-06T08:06:45Z", 
    "summary": "This paper introduces a statistical method to decide whether two blocks in a\npair of of images match reliably. The method ensures that the selected block\nmatches are unlikely to have occurred \"just by chance.\" The new approach is\nbased on the definition of a simple but faithful statistical \"background model\"\nfor image blocks learned from the image itself. A theorem guarantees that under\nthis model not more than a fixed number of wrong matches occurs (on average)\nfor the whole image. This fixed number (the number of false alarms) is the only\nmethod parameter. Furthermore, the number of false alarms associated with each\nmatch measures its reliability. This \"a contrario\" block-matching method,\nhowever, cannot rule out false matches due to the presence of periodic objects\nin the images. But it is successfully complemented by a parameterless\n\"self-similarity threshold.\" Experimental evidence shows that the proposed\nmethod also detects occlusions and incoherent motions due to vehicles and\npedestrians in non simultaneous stereo."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1200v1", 
    "other_authors": "Duc Phu Chau, Fran\u00e7ois Bremond, Monique Thonnat", 
    "title": "A multi-feature tracking algorithm enabling adaptation to context   variations", 
    "arxiv-id": "1112.1200v1", 
    "author": "Monique Thonnat", 
    "publish": "2011-12-06T09:19:17Z", 
    "summary": "We propose in this paper a tracking algorithm which is able to adapt itself\nto different scene contexts. A feature pool is used to compute the matching\nscore between two detected objects. This feature pool includes 2D, 3D\ndisplacement distances, 2D sizes, color histogram, histogram of oriented\ngradient (HOG), color covariance and dominant color. An offline learning\nprocess is proposed to search for useful features and to estimate their weights\nfor each context. In the online tracking process, a temporal window is defined\nto establish the links between the detected objects. This enables to find the\nobject trajectories even if the objects are misdetected in some frames. A\ntrajectory filter is proposed to remove noisy trajectories. Experimentation on\ndifferent contexts is shown. The proposed tracker has been tested in videos\nbelonging to three public datasets and to the Caretaker European project. The\nexperimental results prove the effect of the proposed feature weight learning,\nand the robustness of the proposed tracker compared to some methods in the\nstate of the art. The contributions of our approach over the state of the art\ntrackers are: (i) a robust tracking algorithm based on a feature pool, (ii) a\nsupervised learning scheme to learn feature weights for each context, (iii) a\nnew method to quantify the reliability of HOG descriptor, (iv) a combination of\ncolor covariance and dominant color features with spatial pyramid distance to\nmanage the case of object occlusion."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1484v1", 
    "other_authors": "S. S. Panda, M. S. R. S Prasad, G. Jena", 
    "title": "POCS Based Super-Resolution Image Reconstruction Using an Adaptive   Regularization Parameter", 
    "arxiv-id": "1112.1484v1", 
    "author": "G. Jena", 
    "publish": "2011-12-07T06:29:07Z", 
    "summary": "Crucial information barely visible to the human eye is often embedded in a\nseries of low-resolution images taken of the same scene. Super-resolution\nenables the extraction of this information by reconstructing a single image, at\na high resolution than is present in any of the individual images. This is\nparticularly useful in forensic imaging, where the extraction of minute details\nin an image can help to solve a crime. Super-resolution image restoration has\nbeen one of the most important research areas in recent years which goals to\nobtain a high resolution (HR) image from several low resolutions (LR) blurred,\nnoisy, under sampled and displaced images. Relation of the HR image and LR\nimages can be modeled by a linear system using a transformation matrix and\nadditive noise. However, a unique solution may not be available because of the\nsingularity of transformation matrix. To overcome this problem, POCS method has\nbeen used. However, their performance is not good because the effect of noise\nenergy has been ignored. In this paper, we propose an adaptive regularization\napproach based on the fact that the regularization parameter should be a linear\nfunction of noise variance. The performance of the proposed approach has been\ntested on several images and the obtained results demonstrate the superiority\nof our approach compared with existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TPAMI.2011.207", 
    "link": "http://arxiv.org/pdf/1112.1496v3", 
    "other_authors": "Kaihua Zhang, Lei Zhang, Huihui Song, David Zhang", 
    "title": "Re-initialization Free Level Set Evolution via Reaction Diffusion", 
    "arxiv-id": "1112.1496v3", 
    "author": "David Zhang", 
    "publish": "2011-12-07T08:16:48Z", 
    "summary": "This paper presents a novel reaction-diffusion (RD) method for implicit\nactive contours, which is completely free of the costly re-initialization\nprocedure in level set evolution (LSE). A diffusion term is introduced into\nLSE, resulting in a RD-LSE equation, to which a piecewise constant solution can\nbe derived. In order to have a stable numerical solution of the RD based LSE,\nwe propose a two-step splitting method (TSSM) to iteratively solve the RD-LSE\nequation: first iterating the LSE equation, and then solving the diffusion\nequation. The second step regularizes the level set function obtained in the\nfirst step to ensure stability, and thus the complex and costly\nre-initialization procedure is completely eliminated from LSE. By successfully\napplying diffusion to LSE, the RD-LSE model is stable by means of the simple\nfinite difference method, which is very easy to implement. The proposed RD\nmethod can be generalized to solve the LSE for both variational level set\nmethod and PDE-based level set method. The RD-LSE method shows very good\nperformance on boundary anti-leakage, and it can be readily extended to high\ndimensional level set method. The extensive and promising experimental results\non synthetic and real images validate the effectiveness of the proposed RD-LSE\napproach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijist.2011.1303", 
    "link": "http://arxiv.org/pdf/1112.2386v1", 
    "other_authors": "'Omid Pakdelazar', 'Gholamali Rezai-rad'", 
    "title": "Improvement of BM3D Algorithm and Employment to Satellite and CFA Images   Denoising", 
    "arxiv-id": "1112.2386v1", 
    "author": "'Gholamali Rezai-rad'", 
    "publish": "2011-12-11T18:57:10Z", 
    "summary": "This paper proposes a new procedure in order to improve the performance of\nblock matching and 3-D filtering (BM3D) image denoising algorithm. It is\ndemonstrated that it is possible to achieve a better performance than that of\nBM3D algorithm in a variety of noise levels. This method changes BM3D algorithm\nparameter values according to noise level, removes prefiltering, which is used\nin high noise level; therefore Peak Signal-to-Noise Ratio (PSNR) and visual\nquality get improved, and BM3D complexities and processing time are reduced.\nThis improved BM3D algorithm is extended and used to denoise satellite and\ncolor filter array (CFA) images. Output results show that the performance has\nupgraded in comparison with current methods of denoising satellite and CFA\nimages. In this regard this algorithm is compared with Adaptive PCA algorithm,\nthat has led to superior performance for denoising CFA images, on the subject\nof PSNR and visual quality. Also the processing time has decreased\nsignificantly."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijist.2011.1303", 
    "link": "http://arxiv.org/pdf/1112.2903v1", 
    "other_authors": "Shai Bagon, Meirav Galun", 
    "title": "Large Scale Correlation Clustering Optimization", 
    "arxiv-id": "1112.2903v1", 
    "author": "Meirav Galun", 
    "publish": "2011-12-13T14:28:12Z", 
    "summary": "Clustering is a fundamental task in unsupervised learning. The focus of this\npaper is the Correlation Clustering functional which combines positive and\nnegative affinities between the data points. The contribution of this paper is\ntwo fold: (i) Provide a theoretic analysis of the functional. (ii) New\noptimization algorithms which can cope with large scale problems (>100K\nvariables) that are infeasible using existing methods. Our theoretic analysis\nprovides a probabilistic generative interpretation for the functional, and\njustifies its intrinsic \"model-selection\" capability. Furthermore, we draw an\nanalogy between optimizing this functional and the well known Potts energy\nminimization. This analogy allows us to suggest several new optimization\nalgorithms, which exploit the intrinsic \"model-selection\" capability of the\nfunctional to automatically recover the underlying number of clusters. We\ncompare our algorithms to existing methods on both synthetic and real data. In\naddition we suggest two new applications that are made possible by our\nalgorithms: unsupervised face identification and interactive multi-object\nsegmentation by rough boundary delineation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijist.2011.1303", 
    "link": "http://arxiv.org/pdf/1112.2988v2", 
    "other_authors": "Tsvi Achler", 
    "title": "Supervised Generative Reconstruction: An Efficient Way To Flexibly Store   and Recognize Patterns", 
    "arxiv-id": "1112.2988v2", 
    "author": "Tsvi Achler", 
    "publish": "2011-12-13T18:10:11Z", 
    "summary": "Matching animal-like flexibility in recognition and the ability to quickly\nincorporate new information remains difficult. Limits are yet to be adequately\naddressed in neural models and recognition algorithms. This work proposes a\nconfiguration for recognition that maintains the same function of conventional\nalgorithms but avoids combinatorial problems. Feedforward recognition\nalgorithms such as classical artificial neural networks and machine learning\nalgorithms are known to be subject to catastrophic interference and forgetting.\nModifying or learning new information (associations between patterns and\nlabels) causes loss of previously learned information. I demonstrate using\nmathematical analysis how supervised generative models, with feedforward and\nfeedback connections, can emulate feedforward algorithms yet avoid catastrophic\ninterference and forgetting. Learned information in generative models is stored\nin a more intuitive form that represents the fixed points or solutions of the\nnetwork and moreover displays similar difficulties as cognitive phenomena.\nBrain-like capabilities and limits associated with generative models suggest\nthe brain may perform recognition and store information using a similar\napproach. Because of the central role of recognition, progress understanding\nthe underlying principles may reveal significant insight on how to better study\nand integrate with the brain."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0038897", 
    "link": "http://arxiv.org/pdf/1112.3697v1", 
    "other_authors": "Alexander Binder, Shinichi Nakajima, Marius Kloft, Christina M\u00fcller, Wojciech Samek, Ulf Brefeld, Klaus-Robert M\u00fcller, Motoaki Kawanabe", 
    "title": "Insights from Classifying Visual Concepts with Multiple Kernel Learning", 
    "arxiv-id": "1112.3697v1", 
    "author": "Motoaki Kawanabe", 
    "publish": "2011-12-16T01:06:47Z", 
    "summary": "Combining information from various image features has become a standard\ntechnique in concept recognition tasks. However, the optimal way of fusing the\nresulting kernel functions is usually unknown in practical applications.\nMultiple kernel learning (MKL) techniques allow to determine an optimal linear\ncombination of such similarity matrices. Classical approaches to MKL promote\nsparse mixtures. Unfortunately, so-called 1-norm MKL variants are often\nobserved to be outperformed by an unweighted sum kernel. The contribution of\nthis paper is twofold: We apply a recently developed non-sparse MKL variant to\nstate-of-the-art concept recognition tasks within computer vision. We provide\ninsights on benefits and limits of non-sparse MKL and compare it against its\ndirect competitors, the sum kernel SVM and the sparse MKL. We report empirical\nresults for the PASCAL VOC 2009 Classification and ImageCLEF2010 Photo\nAnnotation challenge data sets. About to be submitted to PLoS ONE."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-15907-7_26", 
    "link": "http://arxiv.org/pdf/1112.4060v1", 
    "other_authors": "Bart\u0142omiej P\u0142aczek", 
    "title": "A real time vehicles detection algorithm for vision based sensors", 
    "arxiv-id": "1112.4060v1", 
    "author": "Bart\u0142omiej P\u0142aczek", 
    "publish": "2011-12-17T14:50:50Z", 
    "summary": "A vehicle detection plays an important role in the traffic control at\nsignalised intersections. This paper introduces a vision-based algorithm for\nvehicles presence recognition in detection zones. The algorithm uses linguistic\nvariables to evaluate local attributes of an input image. The image attributes\nare categorised as vehicle, background or unknown features. Experimental\nresults on complex traffic scenes show that the proposed algorithm is effective\nfor a real-time vehicles detection."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.4064v1", 
    "other_authors": "Bart\u0142omiej P\u0142aczek", 
    "title": "Vehicles Recognition Using Fuzzy Descriptors of Image Segments", 
    "arxiv-id": "1112.4064v1", 
    "author": "Bart\u0142omiej P\u0142aczek", 
    "publish": "2011-12-17T15:21:22Z", 
    "summary": "In this paper a vision-based vehicles recognition method is presented.\nProposed method uses fuzzy description of image segments for automatic\nrecognition of vehicles recorded in image data. The description takes into\naccount selected geometrical properties and shape coefficients determined for\nsegments of reference image (vehicle model). The proposed method was\nimplemented using reasoning system with fuzzy rules. A vehicles recognition\nalgorithm was developed based on the fuzzy rules describing shape and\narrangement of the image segments that correspond to visible parts of a\nvehicle. An extension of the algorithm with set of fuzzy rules defined for\ndifferent reference images (and various vehicle shapes) enables vehicles\nclassification in traffic scenes. The devised method is suitable for\napplication in video sensors for road traffic control and surveillance systems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.4135v1", 
    "other_authors": "Abdelkaher Ait Abdelouahad, Mohammed El Hassouni, Hocine Cherifi, Driss Aboutajdine", 
    "title": "A Reduced Reference Image Quality Measure Using Bessel K Forms Model for   Tetrolet Coefficients", 
    "arxiv-id": "1112.4135v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2011-12-18T08:11:59Z", 
    "summary": "In this paper, we introduce a Reduced Reference Image Quality Assessment\n(RRIQA) measure based on the natural image statistic approach. A new adaptive\ntransform called \"Tetrolet\" is applied to both reference and distorted images.\nTo model the marginal distribution of tetrolet coefficients Bessel K Forms\n(BKF) density is proposed. Estimating the parameters of this distribution\nallows to summarize the reference image with a small amount of side\ninformation. Five distortion measures based on the BKF parameters of the\noriginal and processed image are used to predict quality scores. A comparison\nbetween these measures is presented showing a good consistency with human\njudgment."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.4164v5", 
    "other_authors": "Shervin Minaee, Mehran Fotouhi, Babak Hossein Khalaj", 
    "title": "A Geometric Approach For Fully Automatic Chromosome Segmentation", 
    "arxiv-id": "1112.4164v5", 
    "author": "Babak Hossein Khalaj", 
    "publish": "2011-12-18T15:46:18Z", 
    "summary": "A fundamental task in human chromosome analysis is chromosome segmentation.\nSegmentation plays an important role in chromosome karyotyping. The first step\nin segmentation is to remove intrusive objects such as stain debris and other\nnoises. The next step is detection of touching and overlapping chromosomes, and\nthe final step is separation of such chromosomes. Common methods for separation\nbetween touching chromosomes are interactive and require human intervention for\ncorrect separation between touching and overlapping chromosomes. In this paper,\na geometric-based method is used for automatic detection of touching and\noverlapping chromosomes and separating them. The proposed scheme performs\nsegmentation in two phases. In the first phase, chromosome clusters are\ndetected using three geometric criteria, and in the second phase, chromosome\nclusters are separated using a cut-line. Most of earlier methods did not work\nproperly in case of chromosome clusters that contained more than two\nchromosomes. Our method, on the other hand, is quite efficient in separation of\nsuch chromosome clusters. At each step, one separation will be performed and\nthis algorithm is repeated until all individual chromosomes are separated.\nAnother important point about the proposed method is that it uses the geometric\nfeatures of chromosomes which are independent of the type of images and it can\neasily be applied to any type of images such as binary images and does not\nrequire multispectral images as well. We have applied our method to a database\ncontaining 62 touching and partially overlapping chromosomes and a success rate\nof 91.9% is achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-540-93905-4_10", 
    "link": "http://arxiv.org/pdf/1112.5298v1", 
    "other_authors": "Tomas Werner", 
    "title": "Zero-Temperature Limit of a Convergent Algorithm to Minimize the Bethe   Free Energy", 
    "arxiv-id": "1112.5298v1", 
    "author": "Tomas Werner", 
    "publish": "2011-12-22T13:10:05Z", 
    "summary": "After the discovery that fixed points of loopy belief propagation coincide\nwith stationary points of the Bethe free energy, several researchers proposed\nprovably convergent algorithms to directly minimize the Bethe free energy.\nThese algorithms were formulated only for non-zero temperature (thus finding\nfixed points of the sum-product algorithm) and their possible extension to zero\ntemperature is not obvious. We present the zero-temperature limit of the\ndouble-loop algorithm by Heskes, which converges a max-product fixed point. The\ninner loop of this algorithm is max-sum diffusion. Under certain conditions,\nthe algorithm combines the complementary advantages of the max-product belief\npropagation and max-sum diffusion (LP relaxation): it yields good approximation\nof both ground states and max-marginals."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2155077", 
    "link": "http://arxiv.org/pdf/1112.5638v1", 
    "other_authors": "Elif Vural, Pascal Frossard", 
    "title": "Discretization of Parametrizable Signal Manifolds", 
    "arxiv-id": "1112.5638v1", 
    "author": "Pascal Frossard", 
    "publish": "2011-12-23T19:08:10Z", 
    "summary": "Transformation-invariant analysis of signals often requires the computation\nof the distance from a test pattern to a transformation manifold. In\nparticular, the estimation of the distances between a transformed query signal\nand several transformation manifolds representing different classes provides\nessential information for the classification of the signal. In many\napplications the computation of the exact distance to the manifold is costly,\nwhereas an efficient practical solution is the approximation of the manifold\ndistance with the aid of a manifold grid. In this paper, we consider a setting\nwith transformation manifolds of known parameterization. We first present an\nalgorithm for the selection of samples from a single manifold that permits to\nminimize the average error in the manifold distance estimation. Then we propose\na method for the joint discretization of multiple manifolds that represent\ndifferent signal classes, where we optimize the transformation-invariant\nclassification accuracy yielded by the discrete manifold representation.\nExperimental results show that sampling each manifold individually by\nminimizing the manifold distance estimation error outperforms baseline sampling\nsolutions with respect to registration and classification accuracy. Performing\nan additional joint optimization on all samples improves the classification\nperformance further. Moreover, given a fixed total number of samples to be\nselected from all manifolds, an asymmetric distribution of samples to different\nmanifolds depending on their geometric structures may also increase the\nclassification accuracy in comparison with the equal distribution of samples."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.5640v5", 
    "other_authors": "Elif Vural, Pascal Frossard", 
    "title": "Learning Smooth Pattern Transformation Manifolds", 
    "arxiv-id": "1112.5640v5", 
    "author": "Pascal Frossard", 
    "publish": "2011-12-23T19:13:31Z", 
    "summary": "Manifold models provide low-dimensional representations that are useful for\nprocessing and analyzing data in a transformation-invariant way. In this paper,\nwe study the problem of learning smooth pattern transformation manifolds from\nimage sets that represent observations of geometrically transformed signals. In\norder to construct a manifold, we build a representative pattern whose\ntransformations accurately fit various input images. We examine two objectives\nof the manifold building problem, namely, approximation and classification. For\nthe approximation problem, we propose a greedy method that constructs a\nrepresentative pattern by selecting analytic atoms from a continuous dictionary\nmanifold. We present a DC (Difference-of-Convex) optimization scheme that is\napplicable to a wide range of transformation and dictionary models, and\ndemonstrate its application to transformation manifolds generated by rotation,\ntranslation and anisotropic scaling of a reference pattern. Then, we generalize\nthis approach to a setting with multiple transformation manifolds, where each\nmanifold represents a different class of signals. We present an iterative\nmultiple manifold building algorithm such that the classification accuracy is\npromoted in the learning of the representative patterns. Experimental results\nsuggest that the proposed methods yield high accuracy in the approximation and\nclassification of data compared to some reference methods, while the invariance\nto geometric transformations is achieved due to the transformation manifold\nmodel."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.5895v1", 
    "other_authors": "Julio Duarte-Carvajalino, Guillermo Sapiro, Guoshen Yu, Lawrence Carin", 
    "title": "Online Adaptive Statistical Compressed Sensing of Gaussian Mixture   Models", 
    "arxiv-id": "1112.5895v1", 
    "author": "Lawrence Carin", 
    "publish": "2011-12-26T21:42:22Z", 
    "summary": "A framework of online adaptive statistical compressed sensing is introduced\nfor signals following a mixture model. The scheme first uses non-adaptive\nmeasurements, from which an online decoding scheme estimates the model\nselection. As soon as a candidate model has been selected, an optimal sensing\nscheme for the selected model continues to apply. The final signal\nreconstruction is calculated from the ensemble of both the non-adaptive and the\nadaptive measurements. For signals generated from a Gaussian mixture model, the\nonline adaptive sensing algorithm is given and its performance is analyzed. On\nboth synthetic and real image data, the proposed adaptive scheme considerably\nreduces the average reconstruction error with respect to standard statistical\ncompressed sensing that uses fully random measurements, at a marginally\nincreased computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.5997v3", 
    "other_authors": "Sina Akbari Mistani, Shervin Minaee, Emad Fatemizadeh", 
    "title": "Multispectral Palmprint Recognition Using a Hybrid Feature", 
    "arxiv-id": "1112.5997v3", 
    "author": "Emad Fatemizadeh", 
    "publish": "2011-12-27T18:19:04Z", 
    "summary": "Personal identification problem has been a major field of research in recent\nyears. Biometrics-based technologies that exploit fingerprints, iris, face,\nvoice and palmprints, have been in the center of attention to solve this\nproblem. Palmprints can be used instead of fingerprints that have been of the\nearliest of these biometrics technologies. A palm is covered with the same skin\nas the fingertips but has a larger surface, giving us more information than the\nfingertips. The major features of the palm are palm-lines, including principal\nlines, wrinkles and ridges. Using these lines is one of the most popular\napproaches towards solving the palmprint recognition problem. Another robust\nfeature is the wavelet energy of palms. In this paper we used a hybrid feature\nwhich combines both of these features. %Moreover, multispectral analysis is\napplied to improve the performance of the system. At the end, minimum distance\nclassifier is used to match test images with one of the training samples. The\nproposed algorithm has been tested on a well-known multispectral palmprint\ndataset and achieved an average accuracy of 98.8\\%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1112.6269v1", 
    "other_authors": "Dhananjay D. M., C. V. Guru Rao, I. V. Muralikrishna", 
    "title": "Automated PolyU Palmprint sample Registration and Coarse Classification", 
    "arxiv-id": "1112.6269v1", 
    "author": "I. V. Muralikrishna", 
    "publish": "2011-12-29T10:35:01Z", 
    "summary": "Biometric based authentication for secured access to resources has gained\nimportance, due to their reliable, invariant and discriminating features.\nPalmprint is one such biometric entity. Prior to classification and\nidentification registering a sample palmprint is an important activity. In this\npaper we propose a computationally effective method for automated registration\nof samples from PlolyU palmprint database. In our approach we preprocess the\nsample and trace the border to find the nearest point from center of sample.\nAngle between vector representing the nearest point and vector passing through\nthe center is used for automated palm sample registration. The angle of\ninclination between start and end point of heart line and life line is used for\nbasic classification of palmprint samples in left class and right class."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.0566v2", 
    "other_authors": "Ivana Tosic, Sarah Drewes", 
    "title": "Learning joint intensity-depth sparse representations", 
    "arxiv-id": "1201.0566v2", 
    "author": "Sarah Drewes", 
    "publish": "2012-01-03T03:47:09Z", 
    "summary": "This paper presents a method for learning overcomplete dictionaries composed\nof two modalities that describe a 3D scene: image intensity and scene depth. We\npropose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse\nfeatures in two modalities using conic programming and integrate it into a\ntwo-step dictionary learning algorithm. JBP differs from related convex\nalgorithms because it finds joint sparsity models with different atoms and\ndifferent coefficient values for intensity and depth. This is crucial for\nrecovering generative models where the same sparse underlying causes (3D\nfeatures) give rise to different signals (intensity and depth). We give a\ntheoretical bound for the sparse coefficient recovery error obtained by JBP,\nand show experimentally that JBP is far superior to the state of the art Group\nLasso algorithm. When applied to the Middlebury depth-intensity database, our\nlearning algorithm converges to a set of related features, such as pairs of\ndepth and intensity edges or image textures and depth slants. Finally, we show\nthat the learned dictionary and JBP achieve the state of the art depth\ninpainting performance on time-of-flight 3D data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.1417v1", 
    "other_authors": "Hesam Ekhtiyar, Mahdi Sheida, Mahmood Amintoosi", 
    "title": "Picture Collage with Genetic Algorithm and Stereo vision", 
    "arxiv-id": "1201.1417v1", 
    "author": "Mahmood Amintoosi", 
    "publish": "2011-11-29T06:24:33Z", 
    "summary": "In this paper, a salient region extraction method for creating picture\ncollage based on stereo vision is proposed. Picture collage is a kind of visual\nimage summary to arrange all input images on a given canvas, allowing overlay,\nto maximize visible visual information. The salient regions of each image are\nfirstly extracted and represented as a depth map. The output picture collage\nshows as many visible salient regions (without being overlaid by others) from\nall images as possible. A very efficient Genetic algorithm is used here for the\noptimization. The experimental results showed the superior performance of the\nproposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.1571v3", 
    "other_authors": "Hongyu Lu, Yutian Wang, Shanglian Bao", 
    "title": "A United Image Force for Deformable Models and Direct Transforming   Geometric Active Contorus to Snakes by Level Sets", 
    "arxiv-id": "1201.1571v3", 
    "author": "Shanglian Bao", 
    "publish": "2012-01-07T15:58:18Z", 
    "summary": "A uniform distribution of the image force field around the object fasts the\nconvergence speed of the segmentation process. However, to achieve this aim, it\ncauses the force constructed from the heat diffusion model unable to indicate\nthe object boundaries accurately. The image force based on electrostatic field\nmodel can perform an exact shape recovery. First, this study introduces a\nfusion scheme of these two image forces, which is capable of extracting the\nobject boundary with high precision and fast speed. Until now, there is no\nsatisfied analysis about the relationship between Snakes and Geometric Active\nContours (GAC). The second contribution of this study addresses that the GAC\nmodel can be deduced directly from Snakes model. It proves that each term in\nGAC and Snakes is correspondent and has similar function. However, the two\nmodels are expressed using different mathematics. Further, since losing the\nability of rotating the contour, adoption of level sets can limits the usage of\nGAC in some circumstances."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2050v1", 
    "other_authors": "Tina Gebreyohannes, Dong-Yoon Kim", 
    "title": "Adaptive Noise Reduction Scheme for Salt and Pepper", 
    "arxiv-id": "1201.2050v1", 
    "author": "Dong-Yoon Kim", 
    "publish": "2012-01-10T13:41:56Z", 
    "summary": "In this paper, a new adaptive noise reduction scheme for images corrupted by\nimpulse noise is presented. The proposed scheme efficiently identifies and\nreduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify\npixels which are most likely corrupted by salt and pepper noise that are\ncandidates for further median based noise reduction processing. Directional\nfiltering is then applied after noise reduction to achieve a good tradeoff\nbetween detail preservation and noise removal. The proposed scheme can remove\nsalt and pepper noise with noise density as high as 90% and produce better\nresult in terms of qualitative and quantitative measures of images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2843v1", 
    "other_authors": "Mahmoud Ramezani Mayiami, Babak Seyfe", 
    "title": "Nonparametric Sparse Representation", 
    "arxiv-id": "1201.2843v1", 
    "author": "Babak Seyfe", 
    "publish": "2012-01-13T14:05:59Z", 
    "summary": "This paper suggests a nonparametric scheme to find the sparse solution of the\nunderdetermined system of linear equations in the presence of unknown impulsive\nor non-Gaussian noise. This approach is robust against any variations of the\nnoise model and its parameters. It is based on minimization of rank pseudo norm\nof the residual signal and l_1-norm of the signal of interest, simultaneously.\nWe use the steepest descent method to find the sparse solution via an iterative\nalgorithm. Simulation results show that our proposed method outperforms the\nexistence methods like OMP, BP, Lasso, and BCS whenever the observation vector\nis contaminated with measurement or environmental non-Gaussian noise with\nunknown parameters. Furthermore, for low SNR condition, the proposed method has\nbetter performance in the presence of Gaussian noise."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2905v2", 
    "other_authors": "Zhao Qiyang", 
    "title": "NegCut: Automatic Image Segmentation based on MRF-MAP", 
    "arxiv-id": "1201.2905v2", 
    "author": "Zhao Qiyang", 
    "publish": "2012-01-13T18:18:03Z", 
    "summary": "Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a\nprevailing method in recent interactive image segmentation tools. Although\nmathematically explicit in its computational targets, and impressive for the\nsegmentation quality, MRF-MAP is hard to accomplish without the interactive\ninformation from users. So it is rarely adopted in the automatic style up to\ntoday. In this paper, we present an automatic image segmentation algorithm,\nNegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is\nNP-hard when the probabilistic models are unknown, and then present an\napproximation function in the form of minimum cuts on graphs with negative\nweights. Finally, the binary segmentation is taken from the largest eigenvector\nof the target matrix, with a tuned version of the Lanczos eigensolver. It is\nshown competitive at the segmentation quality in our experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.2995v1", 
    "other_authors": "B. Rajathilagam, Murali Rangarajan, K. P. Soman", 
    "title": "G-Lets: Signal Processing Using Transformation Groups", 
    "arxiv-id": "1201.2995v1", 
    "author": "K. P. Soman", 
    "publish": "2012-01-14T07:18:06Z", 
    "summary": "We present an algorithm using transformation groups and their irreducible\nrepresentations to generate an orthogonal basis for a signal in the vector\nspace of the signal. It is shown that multiresolution analysis can be done with\namplitudes using a transformation group. G-lets is thus not a single transform,\nbut a group of linear transformations related by group theory. The algorithm\nalso specifies that a multiresolution and multiscale analysis for each\nresolution is possible in terms of frequencies. Separation of low and high\nfrequency components of each amplitude resolution is facilitated by G-lets.\nUsing conjugacy classes of the transformation group, more than one set of basis\nmay be generated, giving a different perspective of the signal through each\nbasis. Applications for this algorithm include edge detection, feature\nextraction, denoising, face recognition, compression, and more. We analyze this\nalgorithm using dihedral groups as an example. We demonstrate the results with\nan ECG signal and the standard `Lena' image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3109v1", 
    "other_authors": "Wesley Nunes Gon\u00e7alves, Odemir Martinez Bruno", 
    "title": "Automatic system for counting cells with elliptical shape", 
    "arxiv-id": "1201.3109v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-15T17:42:07Z", 
    "summary": "This paper presents a new method for automatic quantification of ellipse-like\ncells in images, an important and challenging problem that has been studied by\nthe computer vision community. The proposed method can be described by two main\nsteps. Initially, image segmentation based on the k-means algorithm is\nperformed to separate different types of cells from the background. Then, a\nrobust and efficient strategy is performed on the blob contour for touching\ncells splitting. Due to the contour processing, the method achieves excellent\nresults of detection compared to manual detection performed by specialists."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3153v1", 
    "other_authors": "Andr\u00e9 Ricardo Backes, Odemir Martinez Bruno", 
    "title": "Fractal and Multi-Scale Fractal Dimension analysis: a comparative study   of Bouligand-Minkowski method", 
    "arxiv-id": "1201.3153v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-16T03:18:22Z", 
    "summary": "Shape is one of the most important visual attributes to characterize objects,\nplaying a important role in pattern recognition. There are various approaches\nto extract relevant information of a shape. An approach widely used in shape\nanalysis is the complexity, and Fractal Dimension and Multi-Scale Fractal\nDimension are both well-known methodologies to estimate it. This papers\npresents a comparative study between Fractal Dimension and Multi-Scale Fractal\nDimension in a shape analysis context. Through experimental comparison using a\nshape database previously classified, both methods are compared. Different\nparameters configuration of each method are considered and a discussion about\nthe results of each method is also presented."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3233v2", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "Variations of images to increase their visibility", 
    "arxiv-id": "1201.3233v2", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2012-01-16T12:31:27Z", 
    "summary": "The calculus of variations applied to the image processing requires some\nnumerical models able to perform the variations of images and the extremization\nof appropriate actions. To produce the variations of images, there are several\npossibilities based on the brightness maps. Before a numerical model, I propose\nan experimental approach, based on a tool of Gimp, GNU Image Manipulation\nProgram, in order to visualize how the image variations can be. After the\ndiscussion of this tool, which is able to strongly increase the visibility of\nimages, the variations and a possible functional for the visibility are\nproposed in the framework of a numerical model. The visibility functional is\nanalogous to the fringe visibility of the optical interference."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3612v1", 
    "other_authors": "Wesley Nunes Gon\u00e7alves, Bruno Brandoli Machado, Odemir Martinez Bruno", 
    "title": "Spatiotemporal Gabor filters: a new method for dynamic texture   recognition", 
    "arxiv-id": "1201.3612v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-17T20:26:04Z", 
    "summary": "This paper presents a new method for dynamic texture recognition based on\nspatiotemporal Gabor filters. Dynamic textures have emerged as a new field of\ninvestigation that extends the concept of self-similarity of texture image to\nthe spatiotemporal domain. To model a dynamic texture, we convolve the sequence\nof images to a bank of spatiotemporal Gabor filters. For each response, a\nfeature vector is built by calculating the energy statistic. As far as the\nauthors know, this paper is the first to report an effective method for dynamic\ntexture recognition using spatiotemporal Gabor filters. We evaluate the\nproposed method on two challenging databases and the experimental results\nindicate that the proposed method is a robust approach for dynamic texture\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3720v1", 
    "other_authors": "Aamir Khan, Muhammad Farhan, Aasim Khurshid, Adeel Akram", 
    "title": "A Multimodal Biometric System Using Linear Discriminant Analysis For   Improved Performance", 
    "arxiv-id": "1201.3720v1", 
    "author": "Adeel Akram", 
    "publish": "2012-01-18T08:20:00Z", 
    "summary": "Essentially a biometric system is a pattern recognition system which\nrecognizes a user by determining the authenticity of a specific anatomical or\nbehavioral characteristic possessed by the user. With the ever increasing\nintegration of computers and Internet into daily life style, it has become\nnecessary to protect sensitive and personal data. This paper proposes a\nmultimodal biometric system which incorporates more than one biometric trait to\nattain higher security and to handle failure to enroll situations for some\nusers. This paper is aimed at investigating a multimodal biometric identity\nsystem using Linear Discriminant Analysis as backbone to both facial and speech\nrecognition and implementing such system in real-time using SignalWAVE."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3803v1", 
    "other_authors": "Manoj K. Vairalkar, Sonali. Nimbhorkar", 
    "title": "Image Labeling and Segmentation using Hierarchical Conditional Random   Field Model", 
    "arxiv-id": "1201.3803v1", 
    "author": "Sonali. Nimbhorkar", 
    "publish": "2012-01-16T07:33:56Z", 
    "summary": "The use of hierarchical Conditional Random Field model deal with the problem\nof labeling images . At the time of labeling a new image, selection of the\nnearest cluster and using the related CRF model to label this image. When one\ngive input image, one first use the CRF model to get initial pixel labels then\nfinding the cluster with most similar images. Then at last relabeling the input\nimage by the CRF model associated with this cluster. This paper presents a\napproach to label and segment specific image having correct information."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3821v1", 
    "other_authors": "Carlos Miravet, Francisco B. Rodr\u00edguez", 
    "title": "A PCA-Based Super-Resolution Algorithm for Short Image Sequences", 
    "arxiv-id": "1201.3821v1", 
    "author": "Francisco B. Rodr\u00edguez", 
    "publish": "2012-01-18T15:19:03Z", 
    "summary": "In this paper, we present a novel, learning-based, two-step super-resolution\n(SR) algorithm well suited to solve the specially demanding problem of\nobtaining SR estimates from short image sequences. The first step, devoted to\nincrease the sampling rate of the incoming images, is performed by fitting\nlinear combinations of functions generated from principal components (PC) to\nreproduce locally the sparse projected image data, and using these models to\nestimate image values at nodes of the high-resolution grid. PCs were obtained\nfrom local image patches sampled at sub-pixel level, which were generated in\nturn from a database of high-resolution images by application of a physically\nrealistic observation model. Continuity between local image models is enforced\nby minimizing an adequate functional in the space of model coefficients. The\nsecond step, dealing with restoration, is performed by a linear filter with\ncoefficients learned to restore residual interpolation artifacts in addition to\nlow-resolution blurring, providing an effective coupling between both steps of\nthe method. Results on a demanding five-image scanned sequence of graphics and\ntext are presented, showing the excellent performance of the proposed method\ncompared to several state-of-the-art two-step and Bayesian Maximum a Posteriori\nSR algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.3972v1", 
    "other_authors": "Kapil Kumar Gupta, Rizwan Beg, Jitendra Kumar Niranjan", 
    "title": "A Novel Approach to Fast Image Filtering Algorithm of Infrared Images   based on Intro Sort Algorithm", 
    "arxiv-id": "1201.3972v1", 
    "author": "Jitendra Kumar Niranjan", 
    "publish": "2012-01-19T04:57:36Z", 
    "summary": "In this study we investigate the fast image filtering algorithm based on\nIntro sort algorithm and fast noise reduction of infrared images. Main feature\nof the proposed approach is that no prior knowledge of noise required. It is\ndeveloped based on Stefan- Boltzmann law and the Fourier law. We also\ninvestigate the fast noise reduction approach that has advantage of less\ncomputation load. In addition, it can retain edges, details, text information\neven if the size of the window increases. Intro sort algorithm begins with\nQuick sort and switches to heap sort when the recursion depth exceeds a level\nbased on the number of elements being sorted. This approach has the advantage\nof fast noise reduction by reducing the comparison time. It also significantly\nspeed up the noise reduction process and can apply to real-time image\nprocessing. This approach will extend the Infrared images applications for\nmedicine and video conferencing."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.4139v1", 
    "other_authors": "Bruno Brandoli Machado, Wesley Nunes Gon\u00e7alves, Odemir Martinez Bruno", 
    "title": "Image decomposition with anisotropic diffusion applied to leaf-texture   analysis", 
    "arxiv-id": "1201.4139v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-01-19T18:39:41Z", 
    "summary": "Texture analysis is an important field of investigation that has received a\ngreat deal of interest from computer vision community. In this paper, we\npropose a novel approach for texture modeling based on partial differential\nequation (PDE). Each image $f$ is decomposed into a family of derived\nsub-images. $f$ is split into the $u$ component, obtained with anisotropic\ndiffusion, and the $v$ component which is calculated by the difference between\nthe original image and the $u$ component. After enhancing the texture attribute\n$v$ of the image, Gabor features are computed as descriptors. We validate the\nproposed approach on two texture datasets with high variability. We also\nevaluate our approach on an important real-world application: leaf-texture\nanalysis. Experimental results indicate that our approach can be used to\nproduce higher classification rates and can be successfully employed for\ndifferent texture applications."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.4895v2", 
    "other_authors": "Aswin C Sankaranarayanan, Pavan K Turaga, Rama Chellappa, Richard G Baraniuk", 
    "title": "Compressive Acquisition of Dynamic Scenes", 
    "arxiv-id": "1201.4895v2", 
    "author": "Richard G Baraniuk", 
    "publish": "2012-01-23T23:19:59Z", 
    "summary": "Compressive sensing (CS) is a new approach for the acquisition and recovery\nof sparse signals and images that enables sampling rates significantly below\nthe classical Nyquist rate. Despite significant progress in the theory and\nmethods of CS, little headway has been made in compressive video acquisition\nand recovery. Video CS is complicated by the ephemeral nature of dynamic\nevents, which makes direct extensions of standard CS imaging architectures and\nsignal models difficult. In this paper, we develop a new framework for video CS\nfor dynamic textured scenes that models the evolution of the scene as a linear\ndynamical system (LDS). This reduces the video recovery problem to first\nestimating the model parameters of the LDS from compressive measurements, and\nthen reconstructing the image frames. We exploit the low-dimensional dynamic\nparameters (the state sequence) and high-dimensional static parameters (the\nobservation matrix) of the LDS to devise a novel compressive measurement\nstrategy that measures only the dynamic part of the scene at each instant and\naccumulates measurements over time to estimate the static parameters. This\nenables us to lower the compressive measurement rate considerably. We validate\nour approach with a range of experiments involving both video recovery, sensing\nhyper-spectral data, and classification of dynamic scenes from compressive\ndata. Together, these applications demonstrate the effectiveness of the\napproach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2227768", 
    "link": "http://arxiv.org/pdf/1201.5227v1", 
    "other_authors": "T. Romen Singh, Sudipta Roy, O. Imocha Singh, Tejmani Sinam, Kh. Manglem Singh", 
    "title": "A New Local Adaptive Thresholding Technique in Binarization", 
    "arxiv-id": "1201.5227v1", 
    "author": "Kh. Manglem Singh", 
    "publish": "2012-01-25T10:17:30Z", 
    "summary": "Image binarization is the process of separation of pixel values into two\ngroups, white as background and black as foreground. Thresholding plays a major\nin binarization of images. Thresholding can be categorized into global\nthresholding and local thresholding. In images with uniform contrast\ndistribution of background and foreground like document images, global\nthresholding is more appropriate. In degraded document images, where\nconsiderable background noise or variation in contrast and illumination exists,\nthere exists many pixels that cannot be easily classified as foreground or\nbackground. In such cases, binarization with local thresholding is more\nappropriate. This paper describes a locally adaptive thresholding technique\nthat removes background by using local mean and mean deviation. Normally the\nlocal mean computational time depends on the window size. Our technique uses\nintegral sum image as a prior processing to calculate local mean. It does not\ninvolve calculations of standard deviations as in other local adaptive\ntechniques. This along with the fact that calculations of mean is independent\nof window size speed up the process as compared to other local thresholding\ntechniques."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1201.5404v1", 
    "other_authors": "Julio M. Duarte-Carvajalino, Guoshen Yu, Lawrence Carin, Guillermo Sapiro", 
    "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture   Models", 
    "arxiv-id": "1201.5404v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2012-01-25T22:25:27Z", 
    "summary": "A framework for adaptive and non-adaptive statistical compressive sensing is\ndeveloped, where a statistical model replaces the standard sparsity model of\nclassical compressive sensing. We propose within this framework optimal\ntask-specific sensing protocols specifically and jointly designed for\nclassification and reconstruction. A two-step adaptive sensing paradigm is\ndeveloped, where online sensing is applied to detect the signal class in the\nfirst step, followed by a reconstruction step adapted to the detected class and\nthe observed samples. The approach is based on information theory, here\ntailored for Gaussian mixture models (GMMs), where an information-theoretic\nobjective relationship between the sensed signals and a representation of the\nspecific task of interest is maximized. Experimental results using synthetic\nsignals, Landsat satellite attributes, and natural images of different sizes\nand with different noise levels show the improvements achieved using the\nproposed framework when compared to more standard sensing protocols. The\nunderlying formulation can be applied beyond GMMs, at the price of higher\nmathematical and computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1201.5938v1", 
    "other_authors": "Hajar Moradmand, Saeed Setayeshi, Hossein Khazaei Targhi", 
    "title": "Comparing Methods for segmentation of Microcalcification Clusters in   Digitized Mammograms", 
    "arxiv-id": "1201.5938v1", 
    "author": "Hossein Khazaei Targhi", 
    "publish": "2012-01-28T09:51:23Z", 
    "summary": "The appearance of microcalcifications in mammograms is one of the early signs\nof breast cancer. So, early detection of microcalcification clusters (MCCs) in\nmammograms can be helpful for cancer diagnosis and better treatment of breast\ncancer. In this paper a computer method has been proposed to support\nradiologists in detection MCCs in digital mammography. First, in order to\nfacilitate and improve the detection step, mammogram images have been enhanced\nwith wavelet transformation and morphology operation. Then for segmentation of\nsuspicious MCCs, two methods have been investigated. The considered methods\nare: adaptive threshold and watershed segmentation. Finally, the detected MCCs\nareas in different algorithms will be compared to find out which segmentation\nmethod is more appropriate for extracting MCCs in mammograms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1203.0076v1", 
    "other_authors": "Luis Quesada", 
    "title": "Using Barriers to Reduce the Sensitivity to Edge Miscalculations of   Casting-Based Object Projection Feature Estimation", 
    "arxiv-id": "1203.0076v1", 
    "author": "Luis Quesada", 
    "publish": "2012-03-01T02:32:28Z", 
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting reliable object projection feature estimation techniques are based on\nray-casting or grid-filling from the inner point. These techniques assume the\nedge image to be accurate. However, in real case scenarios, edge\nmiscalculations may arise from low contrast between the target object and its\nsurroundings or motion blur caused by low frame rates or fast moving target\nobjects. In this paper, we propose a barrier extension to casting-based\ntechniques that mitigates the effect of edge miscalculations."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1203.0265v1", 
    "other_authors": "S. Chitra, J. B. Bhattacharjee, B. Thilakavathi", 
    "title": "Image Fusion and Re-Modified SPIHT for Fused Image", 
    "arxiv-id": "1203.0265v1", 
    "author": "B. Thilakavathi", 
    "publish": "2012-02-29T17:57:12Z", 
    "summary": "This paper presents the Discrete Wavelet based fusion techniques for\ncombining perceptually important image features. SPIHT (Set Partitioning in\nHierarchical Trees) algorithm is an efficient method for lossy and lossless\ncoding of fused image. This paper presents some modifications on the SPIHT\nalgorithm. It is based on the idea of insignificant correlation of wavelet\ncoefficient among the medium and high frequency sub bands. In RE-MSPIHT\nalgorithm, wavelet coefficients are scaled prior to SPIHT coding based on the\nsub band importance, with the goal of minimizing the MSE."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1203.0744v1", 
    "other_authors": "Shu Kong, Donghui Wang", 
    "title": "A Report on Multilinear PCA Plus Multilinear LDA to Deal with Tensorial   Data: Visual Classification as An Example", 
    "arxiv-id": "1203.0744v1", 
    "author": "Donghui Wang", 
    "publish": "2012-03-04T15:00:16Z", 
    "summary": "In practical applications, we often have to deal with high order data, such\nas a grayscale image and a video sequence are intrinsically 2nd-order tensor\nand 3rd-order tensor, respectively. For doing clustering or classification of\nthese high order data, it is a conventional way to vectorize these data before\nhand, as PCA or FDA does, which often induce the curse of dimensionality\nproblem. For this reason, experts have developed many methods to deal with the\ntensorial data, such as multilinear PCA, multilinear LDA, and so on. In this\npaper, we still address the problem of high order data representation and\nrecognition, and propose to study the result of merging multilinear PCA and\nmultilinear LDA into one scenario, we name it \\textbf{GDA} for the abbreviation\nof Generalized Discriminant Analysis. To evaluate GDA, we perform a series of\nexperiments, and the experimental results demonstrate our GDA outperforms a\nselection of competing methods such (2D)$^2$PCA, (2D)$^2$LDA, and MDA."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1203.0781v3", 
    "other_authors": "Takayuki Katsuki, Masato Inoue", 
    "title": "Posterior Mean Super-Resolution with a Compound Gaussian Markov Random   Field Prior", 
    "arxiv-id": "1203.0781v3", 
    "author": "Masato Inoue", 
    "publish": "2012-03-04T22:12:54Z", 
    "summary": "This manuscript proposes a posterior mean (PM) super-resolution (SR) method\nwith a compound Gaussian Markov random field (MRF) prior. SR is a technique to\nestimate a spatially high-resolution image from observed multiple\nlow-resolution images. A compound Gaussian MRF model provides a preferable\nprior for natural images that preserves edges. PM is the optimal estimator for\nthe objective function of peak signal-to-noise ratio (PSNR). This estimator is\nnumerically determined by using variational Bayes (VB). We then solve the\nconjugate prior problem on VB and the exponential-order calculation cost\nproblem of a compound Gaussian MRF prior with simple Taylor approximations. In\nexperiments, the proposed method roughly overcomes existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TSP.2012.2225054", 
    "link": "http://arxiv.org/pdf/1203.0856v1", 
    "other_authors": "Shu Kong, Donghui Wang", 
    "title": "Online Discriminative Dictionary Learning for Image Classification Based   on Block-Coordinate Descent Method", 
    "arxiv-id": "1203.0856v1", 
    "author": "Donghui Wang", 
    "publish": "2012-03-05T10:43:15Z", 
    "summary": "Previous researches have demonstrated that the framework of dictionary\nlearning with sparse coding, in which signals are decomposed as linear\ncombinations of a few atoms of a learned dictionary, is well adept to\nreconstruction issues. This framework has also been used for discrimination\ntasks such as image classification. To achieve better performances of\nclassification, experts develop several methods to learn a discriminative\ndictionary in a supervised manner. However, another issue is that when the data\nbecome extremely large in scale, these methods will be no longer effective as\nthey are all batch-oriented approaches. For this reason, we propose a novel\nonline algorithm for discriminative dictionary learning, dubbed \\textbf{ODDL}\nin this paper. First, we introduce a linear classifier into the conventional\ndictionary learning formulation and derive a discriminative dictionary learning\nproblem. Then, we exploit an online algorithm to solve the derived problem.\nUnlike the most existing approaches which update dictionary and classifier\nalternately via iteratively solving sub-problems, our approach directly\nexplores them jointly. Meanwhile, it can largely shorten the runtime for\ntraining and is also particularly suitable for large-scale classification\nissues. To evaluate the performance of the proposed ODDL approach in image\nrecognition, we conduct some experiments on three well-known benchmarks, and\nthe experimental results demonstrate ODDL is fairly promising for image\nclassification tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0492-5", 
    "link": "http://arxiv.org/pdf/1203.0905v2", 
    "other_authors": "Jos\u00e9 I. Ronda, Antonio Vald\u00e9s, Guillermo Gallego", 
    "title": "Autocalibration with the Minimum Number of Cameras with Known Pixel   Shape", 
    "arxiv-id": "1203.0905v2", 
    "author": "Guillermo Gallego", 
    "publish": "2012-03-05T13:18:44Z", 
    "summary": "In 3D reconstruction, the recovery of the calibration parameters of the\ncameras is paramount since it provides metric information about the observed\nscene, e.g., measures of angles and ratios of distances. Autocalibration\nenables the estimation of the camera parameters without using a calibration\ndevice, but by enforcing simple constraints on the camera parameters. In the\nabsence of information about the internal camera parameters such as the focal\nlength and the principal point, the knowledge of the camera pixel shape is\nusually the only available constraint. Given a projective reconstruction of a\nrigid scene, we address the problem of the autocalibration of a minimal set of\ncameras with known pixel shape and otherwise arbitrarily varying intrinsic and\nextrinsic parameters. We propose an algorithm that only requires 5 cameras (the\ntheoretical minimum), thus halving the number of cameras required by previous\nalgorithms based on the same constraint. To this purpose, we introduce as our\nbasic geometric tool the six-line conic variety (SLCV), consisting in the set\nof planes intersecting six given lines of 3D space in points of a conic. We\nshow that the set of solutions of the Euclidean upgrading problem for three\ncameras with known pixel shape can be parameterized in a computationally\nefficient way. This parameterization is then used to solve autocalibration from\nfive or more cameras, reducing the three-dimensional search space to a\ntwo-dimensional one. We provide experiments with real images showing the good\nperformance of the technique."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0492-5", 
    "link": "http://arxiv.org/pdf/1203.1513v2", 
    "other_authors": "Joan Bruna, St\u00e9phane Mallat", 
    "title": "Invariant Scattering Convolution Networks", 
    "arxiv-id": "1203.1513v2", 
    "author": "St\u00e9phane Mallat", 
    "publish": "2012-03-05T17:12:42Z", 
    "summary": "A wavelet scattering network computes a translation invariant image\nrepresentation, which is stable to deformations and preserves high frequency\ninformation for classification. It cascades wavelet transform convolutions with\nnon-linear modulus and averaging operators. The first network layer outputs\nSIFT-type descriptors whereas the next layers provide complementary invariant\ninformation which improves classification. The mathematical analysis of wavelet\nscattering networks explains important properties of deep convolution networks\nfor classification.\n  A scattering representation of stationary processes incorporates higher order\nmoments and can thus discriminate textures having the same Fourier power\nspectrum. State of the art classification results are obtained for handwritten\ndigits and texture discrimination, using a Gaussian kernel SVM and a generative\nPCA classifier."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3102", 
    "link": "http://arxiv.org/pdf/1203.1765v1", 
    "other_authors": "Guillaume Kom, Alain Tiedeu, Martin Kom, John Ngundam", 
    "title": "A comparative evaluation of two algorithms of detection of masses on   mammograms", 
    "arxiv-id": "1203.1765v1", 
    "author": "John Ngundam", 
    "publish": "2012-03-08T12:07:27Z", 
    "summary": "In this paper, we implement and carry out the comparison of two methods of\ncomputer-aided-detection of masses on mammograms. The two algorithms basically\nconsist of 3 steps each: segmentation, binarization and noise suppression using\ndifferent techniques for each step. A database of 60 images was used to compare\nthe performance of the two algorithms in terms of general detection efficiency,\nconservation of size and shape of detected masses."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3102", 
    "link": "http://arxiv.org/pdf/1203.1985v1", 
    "other_authors": "Zhaowen Wang, Jinjun Wang, Jing Xiao, Kai-Hsiang Lin, Thomas Huang", 
    "title": "Substructure and Boundary Modeling for Continuous Action Recognition", 
    "arxiv-id": "1203.1985v1", 
    "author": "Thomas Huang", 
    "publish": "2012-03-09T04:16:33Z", 
    "summary": "This paper introduces a probabilistic graphical model for continuous action\nrecognition with two novel components: substructure transition model and\ndiscriminative boundary model. The first component encodes the sparse and\nglobal temporal transition prior between action primitives in state-space model\nto handle the large spatial-temporal variations within an action class. The\nsecond component enforces the action duration constraint in a discriminative\nway to locate the transition boundaries between actions more accurately. The\ntwo components are integrated into a unified graphical structure to enable\neffective training and inference. Our comprehensive experimental results on\nboth public and in-house datasets show that, with the capability to incorporate\nadditional information that had not been explicitly or efficiently modeled by\nprevious methods, our proposed algorithm achieved significantly improved\nperformance for continuous action recognition."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3102", 
    "link": "http://arxiv.org/pdf/1203.2404v1", 
    "other_authors": "Nobert Thomas Pallath, Tessamma Thomas", 
    "title": "Video Object Tracking and Analysis for Computer Assisted Surgery", 
    "arxiv-id": "1203.2404v1", 
    "author": "Tessamma Thomas", 
    "publish": "2012-03-12T05:39:34Z", 
    "summary": "Pedicle screw insertion technique has made revolution in the surgical\ntreatment of spinal fractures and spinal disorders. Although X- ray fluoroscopy\nbased navigation is popular, there is risk of prolonged exposure to X- ray\nradiation. Systems that have lower radiation risk are generally quite\nexpensive. The position and orientation of the drill is clinically very\nimportant in pedicle screw fixation. In this paper, the position and\norientation of the marker on the drill is determined using pattern recognition\nbased methods, using geometric features, obtained from the input video sequence\ntaken from CCD camera. A search is then performed on the video frames after\npreprocessing, to obtain the exact position and orientation of the drill.\nAnimated graphics, showing the instantaneous position and orientation of the\ndrill is then overlaid on the processed video for real time drill control and\nnavigation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2012.4103", 
    "link": "http://arxiv.org/pdf/1203.2514v1", 
    "other_authors": "K. Sreedhar, B. Panlal", 
    "title": "Enhancement of Images using Morphological Transformation", 
    "arxiv-id": "1203.2514v1", 
    "author": "B. Panlal", 
    "publish": "2012-03-09T13:22:25Z", 
    "summary": "This paper deals with enhancement of images with poor contrast and detection\nof background. Proposes a frame work which is used to detect the background in\nimages characterized by poor contrast. Image enhancement has been carried out\nby the two methods based on the Weber's law notion. The first method employs\ninformation from image background analysis by blocks, while the second\ntransformation method utilizes the opening operation, closing operation, which\nis employed to define the multi-background gray scale images. The complete\nimage processing is done using MATLAB simulation model. Finally, this paper is\norganized as follows as Morphological transformation and Weber's law. Image\nbackground approximation to the background by means of block analysis in\nconjunction with transformations that enhance images with poor lighting. The\nmultibackground notion is introduced by means of the opening by reconstruction\nshows a comparison among several techniques to improve contrast in images.\nFinally, conclusions are presented."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.2839v1", 
    "other_authors": "Jan Egger, Tina Kapur, Thomas Dukatz, Malgorzata Kolodziej, Dzenan Zukic, Bernd Freisleben, Christopher Nimsky", 
    "title": "Square-Cut: A Segmentation Algorithm on the Basis of a Rectangle Shape", 
    "arxiv-id": "1203.2839v1", 
    "author": "Christopher Nimsky", 
    "publish": "2012-03-13T15:41:14Z", 
    "summary": "We present a rectangle-based segmentation algorithm that sets up a graph and\nperforms a graph cut to separate an object from the background. However,\ngraph-based algorithms distribute the graph's nodes uniformly and equidistantly\non the image. Then, a smoothness term is added to force the cut to prefer a\nparticular shape. This strategy does not allow the cut to prefer a certain\nstructure, especially when areas of the object are indistinguishable from the\nbackground. We solve this problem by referring to a rectangle shape of the\nobject when sampling the graph nodes, i.e., the nodes are distributed\nnonuniformly and non-equidistantly on the image. This strategy can be useful,\nwhen areas of the object are indistinguishable from the background. For\nevaluation, we focus on vertebrae images from Magnetic Resonance Imaging (MRI)\ndatasets to support the time consuming manual slice-by-slice segmentation\nperformed by physicians. The ground truth of the vertebrae boundaries were\nmanually extracted by two clinical experts (neurological surgeons) with several\nyears of experience in spine surgery and afterwards compared with the automatic\nsegmentation results of the proposed scheme yielding an average Dice Similarity\nCoefficient (DSC) of 90.97\\pm62.2%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3114v1", 
    "other_authors": "Maria-Luisa Sosas, Miguel-Octavio Arias", 
    "title": "Integrated three-dimensional reconstruction using reflectance fields", 
    "arxiv-id": "1203.3114v1", 
    "author": "Miguel-Octavio Arias", 
    "publish": "2012-03-14T15:31:16Z", 
    "summary": "A method to obtain three-dimensional data of real-world objects by\nintegrating their material properties is presented. The material properties are\ndefined by capturing the Reflectance Fields of the real-world objects. It is\nshown, unlike conventional reconstruction methods, the method is able to use\nthe reflectance information to recover surface depth for objects having a\nnon-Lambertian surface reflectance. It is, for recovering 3D data of objects\nexhibiting an anisotropic BRDF with an error less than 0.3%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3170v1", 
    "other_authors": "Shampa Sengupta, Asit Kr. Das", 
    "title": "Single Reduct Generation Based on Relative Indiscernibility of Rough Set   Theory", 
    "arxiv-id": "1203.3170v1", 
    "author": "Asit Kr. Das", 
    "publish": "2012-03-14T18:34:05Z", 
    "summary": "In real world everything is an object which represents particular classes.\nEvery object can be fully described by its attributes. Any real world dataset\ncontains large number of attributes and objects. Classifiers give poor\nperformance when these huge datasets are given as input to it for proper\nclassification. So from these huge dataset most useful attributes need to be\nextracted that contribute the maximum to the decision. In the paper, attribute\nset is reduced by generating reducts using the indiscernibility relation of\nRough Set Theory (RST). The method measures similarity among the attributes\nusing relative indiscernibility relation and computes attribute similarity set.\nThen the set is minimized and an attribute similarity table is constructed from\nwhich attribute similar to maximum number of attributes is selected so that the\nresultant minimum set of selected attributes (called reduct) cover all\nattributes of the attribute similarity table. The method has been applied on\nglass dataset collected from the UCI repository and the classification accuracy\nis calculated by various classifiers. The result shows the efficiency of the\nproposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3230v1", 
    "other_authors": "Andrea Masiero, Angelo Cenedese", 
    "title": "Reconstruction error in a motion capture system", 
    "arxiv-id": "1203.3230v1", 
    "author": "Angelo Cenedese", 
    "publish": "2012-03-14T22:46:29Z", 
    "summary": "Marker-based motion capture (MoCap) systems can be composed by several dozens\nof cameras with the purpose of reconstructing the trajectories of hundreds of\ntargets. With a large amount of cameras it becomes interesting to determine the\noptimal reconstruction strategy. For such aim it is of fundamental importance\nto understand the information provided by different camera measurements and how\nthey are combined, i.e. how the reconstruction error changes by considering\ndifferent cameras. In this work, first, an approximation of the reconstruction\nerror variance is derived. The results obtained in some simulations suggest\nthat the proposed strategy allows to obtain a good approximation of the real\nerror variance with significant reduction of the computational time."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.3270v1", 
    "other_authors": "Sushil Kumar Paul, Mohammad Shorif Uddin, Saida Bouakaz", 
    "title": "Extraction of Facial Feature Points Using Cumulative Histogram", 
    "arxiv-id": "1203.3270v1", 
    "author": "Saida Bouakaz", 
    "publish": "2012-03-15T05:20:27Z", 
    "summary": "This paper proposes a novel adaptive algorithm to extract facial feature\npoints automatically such as eyebrows corners, eyes corners, nostrils, nose\ntip, and mouth corners in frontal view faces, which is based on cumulative\nhistogram approach by varying different threshold values. At first, the method\nadopts the Viola-Jones face detector to detect the location of face and also\ncrops the face region in an image. From the concept of the human face\nstructure, the six relevant regions such as right eyebrow, left eyebrow, right\neye, left eye, nose, and mouth areas are cropped in a face image. Then the\nhistogram of each cropped relevant region is computed and its cumulative\nhistogram value is employed by varying different threshold values to create a\nnew filtering image in an adaptive way. The connected component of interested\narea for each relevant filtering image is indicated our respective feature\nregion. A simple linear search algorithm for eyebrows, eyes and mouth filtering\nimages and contour algorithm for nose filtering image are applied to extract\nour desired corner points automatically. The method was tested on a large BioID\nfrontal face database in different illuminations, expressions and lighting\nconditions and the experimental results have achieved average success rates of\n95.27%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.4204v1", 
    "other_authors": "Amir Daneshgar, Ramin Javadi, Basir Shariat Razavi", 
    "title": "Clustering Using Isoperimetric Number of Trees", 
    "arxiv-id": "1203.4204v1", 
    "author": "Basir Shariat Razavi", 
    "publish": "2012-03-19T19:15:25Z", 
    "summary": "In this paper we propose a graph-based data clustering algorithm which is\nbased on exact clustering of a minimum spanning tree in terms of a minimum\nisoperimetry criteria. We show that our basic clustering algorithm runs in $O(n\n\\log n)$ and with post-processing in $O(n^2)$ (worst case) time where $n$ is\nthe size of the data set. We also show that our generalized graph model which\nalso allows the use of potentials at vertices can be used to extract a more\ndetailed pack of information as the {\\it outlier profile} of the data set. In\nthis direction we show that our approach can be used to define the concept of\nan outlier-set in a precise way and we propose approximation algorithms for\nfinding such sets. We also provide a comparative performance analysis of our\nalgorithm with other related ones and we show that the new clustering algorithm\n(without the outlier extraction procedure) behaves quite effectively even on\nhard benchmarks and handmade examples."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.4874v1", 
    "other_authors": "Christopher Thorpe, Feng Li, Zijia Li, Zhan Yu, David Saunders, Jingyi Yu", 
    "title": "A Co-Prime Blur Scheme for Data Security in Video Surveillance", 
    "arxiv-id": "1203.4874v1", 
    "author": "Jingyi Yu", 
    "publish": "2012-03-22T02:57:53Z", 
    "summary": "This paper presents a novel Coprime Blurred Pair (CBP) model for visual\ndata-hiding for security in camera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream, we introduce a spatial\nencryption scheme by blurring the image/video contents to create a CBP. Our\ngoal is to obscure detail in public video streams by blurring while allowing\nbehavior to be recognized and to quickly deblur the stream so that details are\navailable if behavior is recognized as suspicious. We create a CBP by blurring\nthe same latent image with two unknown kernels. The two kernels are coprime\nwhen mapped to bivariate polynomials in the z domain. To deblur the CBP we\nfirst use the coprime constraint to approximate the kernels and sample the\nbivariate CBP polynomials in one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose the results into a 2D\nkernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of\nthe kernel matrices to recover the coprime kernels and then the latent video\nstream. It is therefore only possible to deblur the video stream if a user has\naccess to both streams. To improve the practicability of our algorithm, we\nimplement our algorithm using a graphics processing unit (GPU) to decrypt the\nblurred video streams in real-time, and extensive experimental results\ndemonstrate that our new scheme can effectively protect sensitive identity\ninformation in surveillance videos and faithfully reconstruct the unblurred\nvideo stream when two blurred sequences are available."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.5078v1", 
    "other_authors": "Tranos Zuva, Oludayo O. Olugbara, Sunday O. Ojo, Seleman M. Ngwira", 
    "title": "Kernel Density Feature Points Estimator for Content-Based Image   Retrieval", 
    "arxiv-id": "1203.5078v1", 
    "author": "Seleman M. Ngwira", 
    "publish": "2012-03-22T18:47:57Z", 
    "summary": "Research is taking place to find effective algorithms for content-based image\nrepresentation and description. There is a substantial amount of algorithms\navailable that use visual features (color, shape, texture). Shape feature has\nattracted much attention from researchers that there are many shape\nrepresentation and description algorithms in literature. These shape image\nrepresentation and description algorithms are usually not application\nindependent or robust, making them undesirable for generic shape description.\nThis paper presents an object shape representation using Kernel Density Feature\nPoints Estimator (KDFPE). In this method, the density of feature points within\ndefined rings around the centroid of the image is obtained. The KDFPE is then\napplied to the vector of the image. KDFPE is invariant to translation, scale\nand rotation. This method of image representation shows improved retrieval rate\nwhen compared to Density Histogram Feature Points (DHFP) method. Analytic\nanalysis is done to justify our method, which was compared with the DHFP to\nprove its robustness."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.6329v2", 
    "other_authors": "Arnav Bhavsar", 
    "title": "Analysis of Magnification in Depth from Defocus", 
    "arxiv-id": "1203.6329v2", 
    "author": "Arnav Bhavsar", 
    "publish": "2012-03-28T18:16:46Z", 
    "summary": "In depth from defocus (DFD), when images are captured with different camera\nparameters, a relative magnification is induced between them. Image warping is\na simpler solution to account for magnification than seemingly more accurate\noptical approaches. This work is an investigation into the effects of\nmagnification on the accuracy of DFD. We comment on issues regarding scaling\neffect on relative blur computation. We statistically analyze accountability of\nscale factor, commenting on the bias and efficiency of the estimator that does\nnot consider scale. We also discuss the effect of interpolation errors on blur\nestimation in a warping based solution to handle magnification and carry out\nexperimental analysis to comment on the blur estimation accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1203.6722v1", 
    "other_authors": "Vinay Bettadapura", 
    "title": "Face Expression Recognition and Analysis: The State of the Art", 
    "arxiv-id": "1203.6722v1", 
    "author": "Vinay Bettadapura", 
    "publish": "2012-03-30T05:47:59Z", 
    "summary": "The automatic recognition of facial expressions has been an active research\ntopic since the early nineties. There have been several advances in the past\nfew years in terms of face detection and tracking, feature extraction\nmechanisms and the techniques used for expression classification. This paper\nsurveys some of the published work since 2001 till date. The paper presents a\ntime-line view of the advances made in this field, the applications of\nautomatic face expression recognizers, the characteristics of an ideal system,\nthe databases that have been used and the advances made in terms of their\nstandardization and a detailed summary of the state of the art. The paper also\ndiscusses facial parameterization using FACS Action Units (AUs) and MPEG-4\nFacial Animation Parameters (FAPs) and the recent advances in face detection,\ntracking and feature extraction methods. Notes have also been presented on\nemotions, expressions and facial features, discussion on the six prototypic\nexpressions and the recent studies on expression classifiers. The paper ends\nwith a note on the challenges and the future work. This paper has been written\nin a tutorial style with the intention of helping students and researchers who\nare new to this field."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.0446v1", 
    "other_authors": "Mingli Song, Dachent Tao, Stephen J. Maybank", 
    "title": "Sparse Camera Network for Visual Surveillance -- A Comprehensive Survey", 
    "arxiv-id": "1302.0446v1", 
    "author": "Stephen J. Maybank", 
    "publish": "2013-02-03T02:40:29Z", 
    "summary": "Technological advances in sensor manufacture, communication, and computing\nare stimulating the development of new applications that are transforming\ntraditional vision systems into pervasive intelligent camera networks. The\nanalysis of visual cues in multi-camera networks enables a wide range of\napplications, from smart home and office automation to large area surveillance\nand traffic surveillance. While dense camera networks - in which most cameras\nhave large overlapping fields of view - are well studied, we are mainly\nconcerned with sparse camera networks. A sparse camera network undertakes large\narea surveillance using as few cameras as possible, and most cameras have\nnon-overlapping fields of view with one another. The task is challenging due to\nthe lack of knowledge about the topological structure of the network,\nvariations in the appearance and motion of specific tracking targets in\ndifferent views, and the difficulties of understanding composite events in the\nnetwork. In this review paper, we present a comprehensive survey of recent\nresearch results to address the problems of intra-camera tracking, topological\nstructure learning, target appearance modeling, and global activity\nunderstanding in sparse camera networks. A number of current open research\nissues are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.0494v4", 
    "other_authors": "Binjie Qin, Zhuangming Shen, Zien Zhou, Jiawei Zhou, Jiuai Sun, Hui Zhang, Mingxing Hu, Yisong Lv", 
    "title": "Local Structure Matching Driven by Joint-Saliency-Structure Adaptive   Kernel Regression", 
    "arxiv-id": "1302.0494v4", 
    "author": "Yisong Lv", 
    "publish": "2013-02-03T14:14:27Z", 
    "summary": "For nonrigid image registration, matching the particular structures (or the\noutliers) that have missing correspondence and/or local large deformations, can\nbe more difficult than matching the common structures with small deformations\nin the two images. Most existing works depend heavily on the outlier\nsegmentation to remove the outlier effect in the registration. Moreover, these\nworks do not handle simultaneously the missing correspondences and local large\ndeformations. In this paper, we defined the nonrigid image registration as a\nlocal adaptive kernel regression which locally reconstruct the moving image's\ndense deformation vectors from the sparse deformation vectors in the\nmulti-resolution block matching. The kernel function of the kernel regression\nadapts its shape and orientation to the reference image's structure to gather\nmore deformation vector samples of the same structure for the iterative\nregression computation, whereby the moving image's local deformations could be\ncompliant with the reference image's local structures. To estimate the local\ndeformations around the outliers, we use joint saliency map that highlights the\ncorresponding saliency structures (called Joint Saliency Structures, JSSs) in\nthe two images to guide the dense deformation reconstruction by emphasizing\nthose JSSs' sparse deformation vectors in the kernel regression. The\nexperimental results demonstrate that by using local JSS adaptive kernel\nregression, the proposed method achieves almost the best performance in\nalignment of all challenging image pairs with outlier structures compared with\nother five state-of-the-art nonrigid registration algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.0689v1", 
    "other_authors": "Anh Cat Le Ngo, Li-Minn Ang, Guoping Qiu, Kah-Phooi Seng", 
    "title": "Multi-scale Visual Attention & Saliency Modelling with Decision Theory", 
    "arxiv-id": "1302.0689v1", 
    "author": "Kah-Phooi Seng", 
    "publish": "2013-02-04T14:00:52Z", 
    "summary": "Bottom-up saliency, an early human visual processing, behaves like binary\nclassification of interest and null hypothesis. Its discriminant power, mutual\ninformation of image features and class distribution, is closely related to\nsaliency value by the well-known centre-surround theory. As classification\naccuracy very much depends on window sizes, the discriminant saliency (power)\nvaries according to sampling scales. Discriminating power estimation in\nmulti-scales framework needs integrating with wavelet transformation and then\nestimating statistical discrepancy of two consecutive scales (centre-surround\nwindows) by Hidden Markov Tree (HMT) model. Finally, multi-scale discriminant\nsaliency (MDIS) maps are combined by the maximum information rule to synthesize\na final saliency map. All MDIS maps are evaluated with standard quantitative\ntools (NSS,LCC,AUC) on N.Bruce's database with ground truth data as\neye-tracking locations ; as well assessed qualitatively by visual examination\nof individual cases. For evaluating MDIS against well-known AIM saliency\nmethod, simulations are needed and described in details with several\ninteresting conclusions, drawn for further research directions."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.1007v1", 
    "other_authors": "Firas Ajil Jassim", 
    "title": "Image Denoising Using Interquartile Range Filter with Local Averaging", 
    "arxiv-id": "1302.1007v1", 
    "author": "Firas Ajil Jassim", 
    "publish": "2013-02-05T12:02:53Z", 
    "summary": "Image denoising is one of the fundamental problems in image processing. In\nthis paper, a novel approach to suppress noise from the image is conducted by\napplying the interquartile range (IQR) which is one of the statistical methods\nused to detect outlier effect from a dataset. A window of size kXk was\nimplemented to support IQR filter. Each pixel outside the IQR range of the kXk\nwindow is treated as noisy pixel. The estimation of the noisy pixels was\nobtained by local averaging. The essential advantage of applying IQR filter is\nto preserve edge sharpness better of the original image. A variety of test\nimages have been used to support the proposed filter and PSNR was calculated\nand compared with median filter. The experimental results on standard test\nimages demonstrate this filter is simpler and better performing than median\nfilter."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.1294v1", 
    "other_authors": "Firas Ajil Jassim, Fawzi Hasan Altaany", 
    "title": "Image Interpolation Using Kriging Technique for Spatial Data", 
    "arxiv-id": "1302.1294v1", 
    "author": "Fawzi Hasan Altaany", 
    "publish": "2013-02-06T09:22:58Z", 
    "summary": "Image interpolation has been used spaciously by customary interpolation\ntechniques. Recently, Kriging technique has been widely implemented in\nsimulation area and geostatistics for prediction. In this article, Kriging\ntechnique was used instead of the classical interpolation methods to predict\nthe unknown points in the digital image array. The efficiency of the proposed\ntechnique was proven using the PSNR and compared with the traditional\ninterpolation techniques. The results showed that Kriging technique is almost\naccurate as cubic interpolation and in some images Kriging has higher accuracy.\nA miscellaneous test images have been used to consolidate the proposed\ntechnique."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.1296v1", 
    "other_authors": "Firas Ajil Jassim", 
    "title": "Hybrid Image Segmentation using Discerner Cluster in FCM and Histogram   Thresholding", 
    "arxiv-id": "1302.1296v1", 
    "author": "Firas Ajil Jassim", 
    "publish": "2013-02-06T09:31:59Z", 
    "summary": "Image thresholding has played an important role in image segmentation. This\npaper presents a hybrid approach for image segmentation based on the\nthresholding by fuzzy c-means (THFCM) algorithm for image segmentation. The\ngoal of the proposed approach is to find a discerner cluster able to find an\nautomatic threshold. The algorithm is formulated by applying the standard FCM\nclustering algorithm to the frequencies (y-values) on the smoothed histogram.\nHence, the frequencies of an image can be used instead of the conventional\nwhole data of image. The cluster that has the highest peak which represents the\nmaximum frequency in the image histogram will play as an excellent role in\ndetermining a discerner cluster to the grey level image. Then, the pixels\nbelong to the discerner cluster represent an object in the gray level histogram\nwhile the other clusters represent a background. Experimental results with\nstandard test images have been obtained through the proposed approach (THFCM)."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.1300v1", 
    "other_authors": "Firas Ajil Jassim", 
    "title": "Kriging Interpolation Filter to Reduce High Density Salt and Pepper   Noise", 
    "arxiv-id": "1302.1300v1", 
    "author": "Firas Ajil Jassim", 
    "publish": "2013-02-06T09:45:18Z", 
    "summary": "Image denoising is a critical issue in the field of digital image processing.\nThis paper proposes a novel Salt & Pepper noise suppression by developing a\nKriging Interpolation Filter (KIF) for image denoising. Gray-level images\ndegraded with Salt & Pepper noise have been considered. A sequential search for\nnoise detection was made using kXk window size to determine non-noisy pixels\nonly. The non-noisy pixels are passed into Kriging interpolation method to\npredict their absent neighbor pixels that were noisy pixels at the first phase.\nThe utilization of Kriging interpolation filter proves that it is very\nimpressive to suppress high noise density. It has been found that Kriging\nInterpolation filter achieves noise reduction without loss of edges and\ndetailed information. Comparisons with existing algorithms are done using\nquality metrics like PSNR and MSE to assess the proposed filter."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.1690v1", 
    "other_authors": "Jonathan Masci, Alessandro Giusti, Dan Cire\u015fan, Gabriel Fricout, J\u00fcrgen Schmidhuber", 
    "title": "A Fast Learning Algorithm for Image Segmentation with Max-Pooling   Convolutional Networks", 
    "arxiv-id": "1302.1690v1", 
    "author": "J\u00fcrgen Schmidhuber", 
    "publish": "2013-02-07T10:17:07Z", 
    "summary": "We present a fast algorithm for training MaxPooling Convolutional Networks to\nsegment images. This type of network yields record-breaking performance in a\nvariety of tasks, but is normally trained on a computationally expensive\npatch-by-patch basis. Our new method processes each training image in a single\npass, which is vastly more efficient.\n  We validate the approach in different scenarios and report a 1500-fold\nspeed-up. In an application to automated steel defect detection and\nsegmentation, we obtain excellent performance with short training times."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.2073v2", 
    "other_authors": "Florian Seidel, Clemens Hage, Martin Kleinsteuber", 
    "title": "pROST : A Smoothed Lp-norm Robust Online Subspace Tracking Method for   Realtime Background Subtraction in Video", 
    "arxiv-id": "1302.2073v2", 
    "author": "Martin Kleinsteuber", 
    "publish": "2013-02-08T16:14:14Z", 
    "summary": "An increasing number of methods for background subtraction use Robust PCA to\nidentify sparse foreground objects. While many algorithms use the L1-norm as a\nconvex relaxation of the ideal sparsifying function, we approach the problem\nwith a smoothed Lp-norm and present pROST, a method for robust online subspace\ntracking. The algorithm is based on alternating minimization on manifolds.\nImplemented on a graphics processing unit it achieves realtime performance.\nExperimental results on a state-of-the-art benchmark for background subtraction\non real-world video data indicate that the method succeeds at a broad variety\nof background subtraction scenarios, and it outperforms competing approaches\nwhen video quality is deteriorated by camera jitter."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0031064", 
    "link": "http://arxiv.org/pdf/1302.3155v1", 
    "other_authors": "Anirban Mukhopadhyay, Zhen Qian, Suchendra M. Bhandarkar, Tianming Liu, Sarah Rinehart, Szilard Voros", 
    "title": "Morphological Analusis Of The Left Ventricular Eendocardial Surface   Using A Bag-Of-Features Descriptor", 
    "arxiv-id": "1302.3155v1", 
    "author": "Szilard Voros", 
    "publish": "2013-02-13T16:25:19Z", 
    "summary": "The limitations of conventional imaging techniques have hitherto precluded a\nthorough and formal investigation of the complex morphology of the left\nventricular (LV) endocardial surface and its relation to the severity of\nCoronary Artery Disease (CAD). Recent developments in high-resolution\nMultirow-Detector Computed Tomography (MDCT) scanner technology have enabled\nthe imaging of LV endocardial surface morphology in a single heart beat.\nAnalysis of high-resolution Computed Tomography (CT) images from a 320-MDCT\nscanner allows the study of the relationship between percent Diameter Stenosis\n(DS) of the major coronary arteries and localization of the cardiac segments\naffected by coronary arterial stenosis. In this paper a novel approach for the\nanalysis using a combination of rigid transformation-invariant shape\ndescriptors and a more generalized isometry-invariant Bag-of-Features (BoF)\ndescriptor, is proposed and implemented. The proposed approach is shown to be\nsuccessful in identifying, localizing and quantifying the incidence and extent\nof CAD and thus, is seen to have a potentially significant clinical impact.\nSpecifically, the association between the incidence and extent of CAD,\ndetermined via the percent DS measurements of the major coronary arteries, and\nthe alterations in the endocardial surface morphology is formally quantified. A\nmultivariate regression test performed on a strict leave-one-out basis are\nshown to exhibit a distinct pattern in terms of the correlation coefficient\nwithin the cardiac segments where the incidence of coronary arterial stenosis\nis localized."
},{
    "category": "cs.CV", 
    "doi": "10.1137/130909858", 
    "link": "http://arxiv.org/pdf/1302.3785v2", 
    "other_authors": "Elif Vural, Pascal Frossard", 
    "title": "Analysis of Descent-Based Image Registration", 
    "arxiv-id": "1302.3785v2", 
    "author": "Pascal Frossard", 
    "publish": "2013-02-15T15:45:32Z", 
    "summary": "We present a performance analysis for image registration with gradient\ndescent methods. We consider a typical multiscale registration setting where\nthe global 2-D translation between a pair of images is estimated by smoothing\nthe images and minimizing the distance between them with gradient descent. Our\nstudy particularly concentrates on the effect of noise and low-pass filtering\non the alignment accuracy. We adopt an analytic representation for images and\nanalyze the well-behavedness of the image distance function by estimating the\nneighborhood of translations for which it is free of undesired local minima.\nThis corresponds to the neighborhood of translation vectors that are correctly\ncomputable with a simple gradient descent minimization. We show that the area\nof this neighborhood increases at least quadratically with the smoothing filter\nsize, which justifies the use of a smoothing step in image registration with\nlocal optimizers such as gradient descent. We then examine the effect of noise\non the alignment accuracy and derive an upper bound for the alignment error in\nterms of the noise properties and filter size. Our main finding is that the\nerror increases at a rate that is at least linear with respect to the filter\nsize. Therefore, smoothing improves the well-behavedness of the distance\nfunction; however, this comes at the cost of amplifying the alignment error in\nnoisy settings. Our results provide a mathematical insight about why\nhierarchical techniques are effective in image registration, suggesting that\nthe multiscale coarse-to-fine alignment strategy of these techniques is very\nsuitable from the perspective of the trade-off between the well-behavedness of\nthe objective function and the registration accuracy. To the best of our\nknowledge, this is the first such study for descent-based image registration."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2005.846030", 
    "link": "http://arxiv.org/pdf/1302.3900v1", 
    "other_authors": "Franz Graf, Hans-Peter Kriegel, Michael Weiler", 
    "title": "Robust Image Segmentation in Low Depth Of Field Images", 
    "arxiv-id": "1302.3900v1", 
    "author": "Michael Weiler", 
    "publish": "2013-02-15T21:49:26Z", 
    "summary": "In photography, low depth of field (DOF) is an important technique to\nemphasize the object of interest (OOI) within an image. Thus, low DOF images\nare widely used in the application area of macro, portrait or sports\nphotography. When viewing a low DOF image, the viewer implicitly concentrates\non the regions that are sharper regions of the image and thus segments the\nimage into regions of interest and non regions of interest which has a major\nimpact on the perception of the image. Thus, a robust algorithm for the fully\nautomatic detection of the OOI in low DOF images provides valuable information\nfor subsequent image processing and image retrieval. In this paper we propose a\nrobust and parameterless algorithm for the fully automatic segmentation of low\nDOF images. We compare our method with three similar methods and show the\nsuperior robustness even though our algorithm does not require any parameters\nto be set by hand. The experiments are conducted on a real world data set with\nhigh and low DOF images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.4043v1", 
    "other_authors": "Belhassen Akrout, Imen Khanfir Kallel, Chokri Ben Amar", 
    "title": "A new scheme of signature extraction for iris authentication", 
    "arxiv-id": "1302.4043v1", 
    "author": "Chokri Ben Amar", 
    "publish": "2013-02-17T08:11:58Z", 
    "summary": "Iris recognition, a relatively new biometric technology, has great\nadvantages, such as variability, stability and security, thus is the most\npromising for high security environment. Iris recognition is proposed in this\nreport. We describe some methods, the first one is based on grey level\nhistogram to extract the pupil, the second is based on elliptic and parabolic\nHOUGH transformation to determinate the edge of iris, upper and lower eyelids,\nthe third we used 2D Gabor Wavelets to encode the iris and finally we used the\nHamming distance for authentication."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.4673v1", 
    "other_authors": "Walter J. Scheirer, Michael J. Wilber, Michael Eckmann, Terrance E. Boult", 
    "title": "Good Recognition is Non-Metric", 
    "arxiv-id": "1302.4673v1", 
    "author": "Terrance E. Boult", 
    "publish": "2013-02-19T17:02:34Z", 
    "summary": "Recognition is the fundamental task of visual cognition, yet how to formalize\nthe general recognition problem for computer vision remains an open issue. The\nproblem is sometimes reduced to the simplest case of recognizing matching\npairs, often structured to allow for metric constraints. However, visual\nrecognition is broader than just pair matching -- especially when we consider\nmulti-class training data and large sets of features in a learning context.\nWhat we learn and how we learn it has important implications for effective\nalgorithms. In this paper, we reconsider the assumption of recognition as a\npair matching test, and introduce a new formal definition that captures the\nbroader context of the problem. Through a meta-analysis and an experimental\nassessment of the top algorithms on popular data sets, we gain a sense of how\noften metric properties are violated by good recognition algorithms. By\nstudying these violations, useful insights come to light: we make the case that\nlocally metric algorithms should leverage outside information to solve the\ngeneral recognition problem."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5189v1", 
    "other_authors": "Dilip K. Prasad", 
    "title": "Object Detection in Real Images", 
    "arxiv-id": "1302.5189v1", 
    "author": "Dilip K. Prasad", 
    "publish": "2013-02-21T06:06:47Z", 
    "summary": "Object detection and recognition are important problems in computer vision.\nSince these problems are meta-heuristic, despite a lot of research, practically\nusable, intelligent, real-time, and dynamic object detection/recognition\nmethods are still unavailable. We propose a new object detection/recognition\nmethod, which improves over the existing methods in every stage of the object\ndetection/recognition process. In addition to the usual features, we propose to\nuse geometric shapes, like linear cues, ellipses and quadrangles, as additional\nfeatures. The full potential of geometric cues is exploited by using them to\nextract other features in a robust, computationally efficient, and less\nmeta-heuristic manner. We also propose a new hierarchical codebook, which\nprovides good generalization and discriminative properties. The codebook\nenables fast multi-path inference mechanisms based on propagation of\nconditional likelihoods, that make it robust to occlusion and noise. It has the\ncapability of dynamic learning. We also propose a new learning method that has\ngenerative and discriminative learning capabilities, does not need large and\nfully supervised training dataset, and is capable of online learning. The\npreliminary work of detecting geometric shapes in real images has been\ncompleted. This preliminary work is the focus of this report. Future path for\nrealizing the proposed object detection/recognition method is also discussed in\nbrief."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5894v1", 
    "other_authors": "Sonya Eini, Abdolah Chalechale", 
    "title": "Four Side Distance: A New Fourier Shape Signature", 
    "arxiv-id": "1302.5894v1", 
    "author": "Abdolah Chalechale", 
    "publish": "2013-02-24T10:49:39Z", 
    "summary": "Shape is one of the main features in content based image retrieval (CBIR).\nThis paper proposes a new shape signature. In this technique, features of each\nshape are extracted based on four sides of the rectangle that covers the shape.\nThe proposed technique is Fourier based and it is invariant to translation,\nscaling and rotation. The retrieval performance between some commonly used\nFourier based signatures and the proposed four sides distance (FSD) signature\nhas been tested using MPEG-7 database. Experimental results are shown that the\nFSD signature has better performance compared with those signatures."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5957v1", 
    "other_authors": "Xavier Descombes, Serguei Komech", 
    "title": "Shape Characterization via Boundary Distortion", 
    "arxiv-id": "1302.5957v1", 
    "author": "Serguei Komech", 
    "publish": "2013-02-24T21:38:20Z", 
    "summary": "In this paper, we derive new shape descriptors based on a directional\ncharacterization. The main idea is to study the behavior of the shape\nneighborhood under family of transformations. We obtain a description invariant\nwith respect to rotation, reflection, translation and scaling. A well-defined\nmetric is then proposed on the associated feature space. We show the continuity\nof this metric. Some results on shape retrieval are provided on two databases\nto show the accuracy of the proposed shape metric."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.5985v1", 
    "other_authors": "Xiaodi Hou, Alan Yuille, Christof Koch", 
    "title": "A Meta-Theory of Boundary Detection Benchmarks", 
    "arxiv-id": "1302.5985v1", 
    "author": "Christof Koch", 
    "publish": "2013-02-25T03:12:12Z", 
    "summary": "Human labeled datasets, along with their corresponding evaluation algorithms,\nplay an important role in boundary detection. We here present a psychophysical\nexperiment that addresses the reliability of such benchmarks. To find better\nremedies to evaluate the performance of any boundary detection algorithm, we\npropose a computational framework to remove inappropriate human labels and\nestimate the intrinsic properties of boundaries."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.6379v1", 
    "other_authors": "Faizan Ahmad, Aaima Najam, Zeeshan Ahmed", 
    "title": "Image-based Face Detection and Recognition: \"State of the Art\"", 
    "arxiv-id": "1302.6379v1", 
    "author": "Zeeshan Ahmed", 
    "publish": "2013-02-26T10:12:30Z", 
    "summary": "Face recognition from image or video is a popular topic in biometrics\nresearch. Many public places usually have surveillance cameras for video\ncapture and these cameras have their significant value for security purpose. It\nis widely acknowledged that the face recognition have played an important role\nin surveillance system as it doesn't need the object's cooperation. The actual\nadvantages of face based identification over other biometrics are uniqueness\nand acceptance. As human face is a dynamic object having high degree of\nvariability in its appearance, that makes face detection a difficult problem in\ncomputer vision. In this field, accuracy and speed of identification is a main\nissue.\n  The goal of this paper is to evaluate various face detection and recognition\nmethods, provide complete solution for image based face detection and\nrecognition with higher accuracy, better response rate as an initial step for\nvideo surveillance. Solution is proposed based on performed tests on various\nface rich databases in terms of subjects, pose, emotions, race and light."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.6957v1", 
    "other_authors": "Karthikeyan Natesan Ramamurthy, Jayaraman J. Thiagarajan, Prasanna Sattigeri, Andreas Spanias", 
    "title": "Ensemble Sparse Models for Image Analysis", 
    "arxiv-id": "1302.6957v1", 
    "author": "Andreas Spanias", 
    "publish": "2013-02-27T18:58:36Z", 
    "summary": "Sparse representations with learned dictionaries have been successful in\nseveral image analysis applications. In this paper, we propose and analyze the\nframework of ensemble sparse models, and demonstrate their utility in image\nrestoration and unsupervised clustering. The proposed ensemble model\napproximates the data as a linear combination of approximations from multiple\n\\textit{weak} sparse models. Theoretical analysis of the ensemble model reveals\nthat even in the worst-case, the ensemble can perform better than any of its\nconstituent individual models. The dictionaries corresponding to the individual\nsparse models are obtained using either random example selection or boosted\napproaches. Boosted approaches learn one dictionary per round such that the\ndictionary learned in a particular round is optimized for the training examples\nhaving high reconstruction error in the previous round. Results with compressed\nrecovery show that the ensemble representations lead to a better performance\ncompared to using a single dictionary obtained with the conventional\nalternating minimization approach. The proposed ensemble models are also used\nfor single image superresolution, and we show that they perform comparably to\nthe recent approaches. In unsupervised clustering, experiments show that the\nproposed model performs better than baseline approaches in several standard\ndatasets."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1302.7180v1", 
    "other_authors": "Dong Yi, Zhen Lei, Yang Hu, Stan Z. Li", 
    "title": "Fast Matching by 2 Lines of Code for Large Scale Face Recognition   Systems", 
    "arxiv-id": "1302.7180v1", 
    "author": "Stan Z. Li", 
    "publish": "2013-02-28T12:59:41Z", 
    "summary": "In this paper, we propose a method to apply the popular cascade classifier\ninto face recognition to improve the computational efficiency while keeping\nhigh recognition rate. In large scale face recognition systems, because the\nprobability of feature templates coming from different subjects is very high,\nmost of the matching pairs will be rejected by the early stages of the cascade.\nTherefore, the cascade can improve the matching speed significantly. On the\nother hand, using the nested structure of the cascade, we could drop some\nstages at the end of feature to reduce the memory and bandwidth usage in some\nresources intensive system while not sacrificing the performance too much. The\ncascade is learned by two steps. Firstly, some kind of prepared features are\ngrouped into several nested stages. And then, the threshold of each stage is\nlearned to achieve user defined verification rate (VR). In the paper, we take a\nlandmark based Gabor+LDA face recognition system as baseline to illustrate the\nprocess and advantages of the proposed method. However, the use of this method\nis very generic and not limited in face recognition, which can be easily\ngeneralized to other biometrics as a post-processing module. Experiments on the\nFERET database show the good performance of our baseline and an experiment on a\nself-collected large scale database illustrates that the cascade can improve\nthe matching speed significantly."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SSD.2009.4956749", 
    "link": "http://arxiv.org/pdf/1303.0479v2", 
    "other_authors": "Zhuangming Shen, Jiuai Sun, Hui Zhang, Binjie Qin", 
    "title": "Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for   Nonrigid Image Registration", 
    "arxiv-id": "1303.0479v2", 
    "author": "Binjie Qin", 
    "publish": "2013-03-03T09:15:25Z", 
    "summary": "Joint saliency map (JSM) [1] was developed to assign high joint saliency\nvalues to the corresponding saliency structures (called Joint Saliency\nStructures, JSSs) but zero or low joint saliency values to the outliers (or\nmismatches) that are introduced by missing correspondence or local large\ndeformations between the reference and moving images to be registered. JSM\nguides the local structure matching in nonrigid registration by emphasizing\nthese JSSs' sparse deformation vectors in adaptive kernel regression of\nhierarchical sparse deformation vectors for iterative dense deformation\nreconstruction. By designing an effective superpixel-based local structure\nscale estimator to compute the reference structure's structure scale, we\nfurther propose to determine the scale (the width) of kernels in the adaptive\nkernel regression through combining the structure scales to JSM-based scales of\nmismatch between the local saliency structures. Therefore, we can adaptively\nselect the sample size of sparse deformation vectors to reconstruct the dense\ndeformation vectors for accurately matching the every local structures in the\ntwo images. The experimental results demonstrate better accuracy of our method\nin aligning two images with missing correspondence and local large deformation\nthan the state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0582v2", 
    "other_authors": "Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy, Andreas Spanias", 
    "title": "Multiple Kernel Sparse Representations for Supervised and Unsupervised   Learning", 
    "arxiv-id": "1303.0582v2", 
    "author": "Andreas Spanias", 
    "publish": "2013-03-03T23:41:34Z", 
    "summary": "In complex visual recognition tasks it is typical to adopt multiple\ndescriptors, that describe different aspects of the images, for obtaining an\nimproved recognition performance. Descriptors that have diverse forms can be\nfused into a unified feature space in a principled manner using kernel methods.\nSparse models that generalize well to the test data can be learned in the\nunified kernel space, and appropriate constraints can be incorporated for\napplication in supervised and unsupervised learning. In this paper, we propose\nto perform sparse coding and dictionary learning in the multiple kernel space,\nwhere the weights of the ensemble kernel are tuned based on graph-embedding\nprinciples such that class discrimination is maximized. In our proposed\nalgorithm, dictionaries are inferred using multiple levels of 1-D subspace\nclustering in the kernel space, and the sparse codes are obtained using a\nsimple levelwise pursuit scheme. Empirical results for object recognition and\nimage clustering show that our algorithm outperforms existing sparse coding\nbased approaches, and compares favorably to other state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0633v1", 
    "other_authors": "Subra Mukherjee, Karen Das", 
    "title": "Omega Model for Human Detection and Counting for application in Smart   Surveillance System", 
    "arxiv-id": "1303.0633v1", 
    "author": "Karen Das", 
    "publish": "2013-03-04T08:01:36Z", 
    "summary": "Driven by the significant advancements in technology and social issues such\nas security management, there is a strong need for Smart Surveillance System in\nour society today. One of the key features of a Smart Surveillance System is\nefficient human detection and counting such that the system can decide and\nlabel events on its own. In this paper we propose a new, novel and robust\nmodel, The Omega Model, for detecting and counting human beings present in the\nscene. The proposed model employs a set of four distinct descriptors for\nidentifying the unique features of the head, neck and shoulder regions of a\nperson. This unique head neck shoulder signature given by the Omega Model\nexploits the challenges such as inter person variations in size and shape of\npeoples head, neck and shoulder regions to achieve robust detection of human\nbeings even under partial occlusion, dynamically changing background and\nvarying illumination conditions. After experimentation we observe and analyze\nthe influences of each of the four descriptors on the system performance and\ncomputation speed and conclude that a weight based decision making system\nproduces the best results. Evaluation results on a number of images indicate\nthe validation of our method in actual situation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0634v1", 
    "other_authors": "Joyeeta Singha, Karen Das", 
    "title": "Indian Sign Language Recognition Using Eigen Value Weighted Euclidean   Distance Based Classification Technique", 
    "arxiv-id": "1303.0634v1", 
    "author": "Karen Das", 
    "publish": "2013-03-04T08:06:07Z", 
    "summary": "Sign Language Recognition is one of the most growing fields of research\ntoday. Many new techniques have been developed recently in these fields. Here\nin this paper, we have proposed a system using Eigen value weighted Euclidean\ndistance as a classification technique for recognition of various Sign\nLanguages of India. The system comprises of four parts: Skin Filtering, Hand\nCropping, Feature Extraction and Classification. Twenty four signs were\nconsidered in this paper, each having ten samples, thus a total of two hundred\nforty images was considered for which recognition rate obtained was 97 percent."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0635v1", 
    "other_authors": "Jeemoni Kalita, Karen Das", 
    "title": "Recognition of Facial Expression Using Eigenvector Based Distributed   Features and Euclidean Distance Based Decision Making Technique", 
    "arxiv-id": "1303.0635v1", 
    "author": "Karen Das", 
    "publish": "2013-03-04T08:09:22Z", 
    "summary": "In this paper, an Eigenvector based system has been presented to recognize\nfacial expressions from digital facial images. In the approach, firstly the\nimages were acquired and cropping of five significant portions from the image\nwas performed to extract and store the Eigenvectors specific to the\nexpressions. The Eigenvectors for the test images were also computed, and\nfinally the input facial image was recognized when similarity was obtained by\ncalculating the minimum Euclidean distance between the test image and the\ndifferent expressions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0644v1", 
    "other_authors": "A. Meena, K. Raja", 
    "title": "Automatic symmetry based cluster approach for anomalous brain   identification in PET scan image : An Analysis", 
    "arxiv-id": "1303.0644v1", 
    "author": "K. Raja", 
    "publish": "2013-03-04T08:52:45Z", 
    "summary": "Medical image segmentation is referred to the segmentation of known anatomic\nstructures from different medical images. Normally, the medical data researches\nare more complicated and an exclusive structures. This computer aided diagnosis\nis used for assisting doctors in evaluating medical imagery or in recognizing\nabnormal findings in a medical image. To integrate the specialized knowledge\nfor medical data processing is helpful to form a real useful healthcare\ndecision making system. This paper studies the different symmetry based\ndistances applied in clustering algorithms and analyzes symmetry approach for\nPositron Emission Tomography (PET) scan image segmentation. Unlike CT and MRI,\nthe PET scan identifies the structure of blood flow to and from organs. PET\nscan also helps in early diagnosis of cancer and heart, brain and gastro\nintestinal ailments and to detect the progress of treatment. In this paper, the\nscope diagnostic task expands for PET image in various brain functions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0645v1", 
    "other_authors": "A. Meena, R. Raja", 
    "title": "Symmetry Based Cluster Approach for Automatic Recognition of the   Epileptic Focus in Brain Using PET Scan Image : An Analysis", 
    "arxiv-id": "1303.0645v1", 
    "author": "R. Raja", 
    "publish": "2013-03-04T09:00:23Z", 
    "summary": "Recognition of epileptic focal point is the important diagnosis when\nscreening the epilepsy patients for latent surgical cures. The accurate\nlocalization is challenging one because of the low spatial resolution images\nwith more noisy data. Positron Emission Tomography (PET) has now replaced the\nissues and caring a high resolution. This paper focuses the research of\nautomated localization of epileptic seizures in brain functional images using\nsymmetry based cluster approach. This approach presents a fully automated\nsymmetry based brain abnormality detection method for PET sequences. PET images\nare spatially normalized to Digital Imaging and Communications in Medicine\n(DICOM) standard and then it has been trained using symmetry based cluster\napproach using Medical Image Processing, Analysis & Visualization (MIPAV) tool.\nThe performance evolution is considered by the metric like accuracy of\ndiagnosis. The obtained result is surely assists the surgeon for the automated\nidentification of seizures focus."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2322938", 
    "link": "http://arxiv.org/pdf/1303.0647v1", 
    "other_authors": "A. Meena, R. Raja", 
    "title": "Spatial Fuzzy C Means PET Image Segmentation of Neurodegenerative   Disorder", 
    "arxiv-id": "1303.0647v1", 
    "author": "R. Raja", 
    "publish": "2013-03-04T09:08:34Z", 
    "summary": "Nuclear image has emerged as a promising research work in medical field.\nImages from different modality meet its own challenge. Positron Emission\nTomography (PET) image may help to precisely localize disease to assist in\nplanning the right treatment for each case and saving valuable time. In this\npaper, a novel approach of Spatial Fuzzy C Means (PET SFCM) clustering\nalgorithm is introduced on PET scan image datasets. The proposed algorithm is\nincorporated the spatial neighborhood information with traditional FCM and\nupdating the objective function of each cluster. This algorithm is implemented\nand tested on huge data collection of patients with brain neuro degenerative\ndisorder such as Alzheimers disease. It has demonstrated its effectiveness by\ntesting it for real world patient data sets. Experimental results are compared\nwith conventional FCM and K Means clustering algorithm. The performance of the\nPET SFCM provides satisfactory results compared with other two algorithms"
},{
    "category": "cs.CV", 
    "doi": "10.1038/srep01364", 
    "link": "http://arxiv.org/pdf/1303.0964v1", 
    "other_authors": "Jan Egger, Tina Kapur, Andriy Fedorov, Steve Pieper, James V. Miller, Harini Veeraraghavan, Bernd Freisleben, Alexandra Golby, Christopher Nimsky, Ron Kikinis", 
    "title": "GBM Volumetry using the 3D Slicer Medical Image Computing Platform", 
    "arxiv-id": "1303.0964v1", 
    "author": "Ron Kikinis", 
    "publish": "2013-03-05T09:40:46Z", 
    "summary": "Volumetric change in glioblastoma multiforme (GBM) over time is a critical\nfactor in treatment decisions. Typically, the tumor volume is computed on a\nslice-by-slice basis using MRI scans obtained at regular intervals. (3D)Slicer\n- a free platform for biomedical research - provides an alternative to this\nmanual slice-by-slice segmentation process, which is significantly faster and\nrequires less user interaction. In this study, 4 physicians segmented GBMs in\n10 patients, once using the competitive region-growing based GrowCut\nsegmentation module of Slicer, and once purely by drawing boundaries completely\nmanually on a slice-by-slice basis. Furthermore, we provide a variability\nanalysis for three physicians for 12 GBMs. The time required for GrowCut\nsegmentation was on an average 61% of the time required for a pure manual\nsegmentation. A comparison of Slicer-based segmentation with manual\nslice-by-slice segmentation resulted in a Dice Similarity Coefficient of 88.43\n+/- 5.23% and a Hausdorff Distance of 2.32 +/- 5.23 mm."
},{
    "category": "cs.CV", 
    "doi": "10.1049/iet-bmt.2013.0033", 
    "link": "http://arxiv.org/pdf/1303.1624v1", 
    "other_authors": "Yongkang Wong, Mehrtash T. Harandi, Conrad Sanderson", 
    "title": "On Robust Face Recognition via Sparse Encoding: the Good, the Bad, and   the Ugly", 
    "arxiv-id": "1303.1624v1", 
    "author": "Conrad Sanderson", 
    "publish": "2013-03-07T09:30:10Z", 
    "summary": "In the field of face recognition, Sparse Representation (SR) has received\nconsiderable attention during the past few years. Most of the relevant\nliterature focuses on holistic descriptors in closed-set identification\napplications. The underlying assumption in SR-based methods is that each class\nin the gallery has sufficient samples and the query lies on the subspace\nspanned by the gallery of the same class. Unfortunately, such assumption is\neasily violated in the more challenging face verification scenario, where an\nalgorithm is required to determine if two faces (where one or both have not\nbeen seen before) belong to the same person. In this paper, we first discuss\nwhy previous attempts with SR might not be applicable to verification problems.\nWe then propose an alternative approach to face verification via SR.\nSpecifically, we propose to use explicit SR encoding on local image patches\nrather than the entire face. The obtained sparse signals are pooled via\naveraging to form multiple region descriptors, which are then concatenated to\nform an overall face descriptor. Due to the deliberate loss spatial relations\nwithin each region (caused by averaging), the resulting descriptor is robust to\nmisalignment & various image deformations. Within the proposed framework, we\nevaluate several SR encoding techniques: l1-minimisation, Sparse Autoencoder\nNeural Network (SANN), and an implicit probabilistic technique based on\nGaussian Mixture Models. Thorough experiments on AR, FERET, exYaleB, BANCA and\nChokePoint datasets show that the proposed local SR approach obtains\nconsiderably better and more robust performance than several previous\nstate-of-the-art holistic SR methods, in both verification and closed-set\nidentification problems. The experiments also show that l1-minimisation based\nencoding has a considerably higher computational than the other techniques, but\nleads to higher recognition rates."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1667v1", 
    "other_authors": "Francisco Assis da Silva, Almir Olivette Artero, Maria Stela Veludo de Paiva, Ricardo Luis Barbosa", 
    "title": "ALPRS - A New Approach for License Plate Recognition using the Sift   Algorithm", 
    "arxiv-id": "1303.1667v1", 
    "author": "Ricardo Luis Barbosa", 
    "publish": "2013-03-07T12:49:49Z", 
    "summary": "This paper presents a new approach for the automatic license plate\nrecognition, which includes the SIFT algorithm in step to locate the plate in\nthe input image. In this new approach, besides the comparison of the features\nobtained with the SIFT algorithm, the correspondence between the spatial\norientations and the positioning associated with the keypoints is also\nobserved. Afterwards, an algorithm is used for the character recognition of the\nplates, very fast, which makes it possible its application in real time. The\nresults obtained with the proposed approach presented very good success rates,\nso much for locating the characters in the input image, as for their\nrecognition."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1749v2", 
    "other_authors": "Carl Olsson, Johannes Ulen, Yuri Boykov, Vladimir Kolmogorov", 
    "title": "Simplifying Energy Optimization using Partial Enumeration", 
    "arxiv-id": "1303.1749v2", 
    "author": "Vladimir Kolmogorov", 
    "publish": "2013-03-07T16:59:11Z", 
    "summary": "Energies with high-order non-submodular interactions have been shown to be\nvery useful in vision due to their high modeling power. Optimization of such\nenergies, however, is generally NP-hard. A naive approach that works for small\nproblem instances is exhaustive search, that is, enumeration of all possible\nlabelings of the underlying graph. We propose a general minimization approach\nfor large graphs based on enumeration of labelings of certain small patches.\nThis partial enumeration technique reduces complex high-order energy\nformulations to pairwise Constraint Satisfaction Problems with unary costs\n(uCSP), which can be efficiently solved using standard methods like TRW-S. Our\napproach outperforms a number of existing state-of-the-art algorithms on well\nknown difficult problems (e.g. curvature regularization, stereo,\ndeconvolution); it gives near global minimum and better speed.\n  Our main application of interest is curvature regularization. In the context\nof segmentation, our partial enumeration technique allows to evaluate curvature\ndirectly on small patches using a novel integral geometry approach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1761v1", 
    "other_authors": "Mayank Bhargava, Tim Polzehl", 
    "title": "Improving Automatic Emotion Recognition from speech using Rhythm and   Temporal feature", 
    "arxiv-id": "1303.1761v1", 
    "author": "Tim Polzehl", 
    "publish": "2013-03-07T17:33:06Z", 
    "summary": "This paper is devoted to improve automatic emotion recognition from speech by\nincorporating rhythm and temporal features. Research on automatic emotion\nrecognition so far has mostly been based on applying features like MFCCs, pitch\nand energy or intensity. The idea focuses on borrowing rhythm features from\nlinguistic and phonetic analysis and applying them to the speech signal on the\nbasis of acoustic knowledge only. In addition to this we exploit a set of\ntemporal and loudness features. A segmentation unit is employed in starting to\nseparate the voiced/unvoiced and silence parts and features are explored on\ndifferent segments. Thereafter different classifiers are used for\nclassification. After selecting the top features using an IGR filter we are\nable to achieve a recognition rate of 80.60 % on the Berlin Emotion Database\nfor the speaker dependent framework."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.1829v1", 
    "other_authors": "Fernand Meyer", 
    "title": "Watersheds on edge or node weighted graphs \"par l'exemple\"", 
    "arxiv-id": "1303.1829v1", 
    "author": "Fernand Meyer", 
    "publish": "2013-03-07T21:15:29Z", 
    "summary": "Watersheds have been defined both for node and edge weighted graphs. We show\nthat they are identical: for each edge (resp.\\ node) weighted graph exists a\nnode (resp. edge) weighted graph with the same minima and catchment basin."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.2437v1", 
    "other_authors": "Joseph Suresh Paul, Uma Krishna Swamy Pillai, Nyjin Thomas", 
    "title": "Least-Squares FIR Models of Low-Resolution MR data for Efficient   Phase-Error Compensation with Simultaneous Artefact Removal", 
    "arxiv-id": "1303.2437v1", 
    "author": "Nyjin Thomas", 
    "publish": "2013-03-11T06:40:02Z", 
    "summary": "Signal space models in both phase-encode, and frequency-encode directions are\npresented for extrapolation of 2D partial kspace. Using the boxcar\nrepresentation of low-resolution spatial data, and a geometrical representation\nof signal space vectors in both positive and negative phase-encode directions,\na robust predictor is constructed using a series of signal space projections.\nCompared to some of the existing phase-correction methods that require\nacquisition of a pre-determined set of fractional kspace lines, the proposed\npredictor is found to be more efficient, due to its capability of exhibiting an\nequivalent degree of performance using only half the number of fractional\nlines. Robust filtering of noisy data is achieved using a second signal space\nmodel in the frequency-encode direction, bypassing the requirement of a prior\nhighpass filtering operation. The signal space is constructed from Fourier\nTransformed samples of each row in the low-resolution image. A set of FIR\nfilters are estimated by fitting a least squares model to this signal space.\nPartial kspace extrapolation using the FIR filters is shown to result in\nartifact-free reconstruction, particularly in respect of Gibbs ringing and\nstreaking type artifacts."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4102", 
    "link": "http://arxiv.org/pdf/1303.2439v1", 
    "other_authors": "Joseph Suresh Paul, Joshin John Mathew, Souparnika Kandoth Naroth, Chandrasekar Kesavadas", 
    "title": "Voxel-wise Weighted MR Image Enhancement using an Extended Neighborhood   Filter", 
    "arxiv-id": "1303.2439v1", 
    "author": "Chandrasekar Kesavadas", 
    "publish": "2013-03-11T06:54:26Z", 
    "summary": "We present an edge preserving and denoising filter for enhancing the features\nin images, which contain an ROI having a narrow spatial extent. Typical\nexamples include angiograms, or ROI spatially distributed in multiple locations\nand contained within an outlying region, such as in multiple-sclerosis. The\nfiltering involves determination of multiplicative weights in the spatial\ndomain using an extended set of neighborhood directions. Equivalently, the\nfiltering operation may be interpreted as a combination of directional filters\nin the frequency domain, with selective weighting for spatial frequencies\ncontained within each direction. The advantages of the proposed filter in\ncomparison to specialized non-linear filters, which operate on diffusion\nprinciple, are illustrated using numerical phantom data. The performance\nevaluation is carried out on simulated images from BrainWeb database for\nmultiple-sclerosis, acute ischemic stroke using clinically acquired FLAIR\nimages and MR angiograms."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2465v1", 
    "other_authors": "Vikas Reddy, Conrad Sanderson, Brian C. Lovell", 
    "title": "A Low-Complexity Algorithm for Static Background Estimation from   Cluttered Image Sequences in Surveillance Contexts", 
    "arxiv-id": "1303.2465v1", 
    "author": "Brian C. Lovell", 
    "publish": "2013-03-11T09:57:49Z", 
    "summary": "For the purposes of foreground estimation, the true background model is\nunavailable in many practical circumstances and needs to be estimated from\ncluttered image sequences. We propose a sequential technique for static\nbackground estimation in such conditions, with low computational and memory\nrequirements. Image sequences are analysed on a block-by-block basis. For each\nblock location a representative set is maintained which contains distinct\nblocks obtained along its temporal line. The background estimation is carried\nout in a Markov Random Field framework, where the optimal labelling solution is\ncomputed using iterated conditional modes. The clique potentials are computed\nbased on the combined frequency response of the candidate block and its\nneighbourhood. It is assumed that the most appropriate block results in the\nsmoothest response, indirectly enforcing the spatial continuity of structures\nwithin a scene. Experiments on real-life surveillance videos demonstrate that\nthe proposed method obtains considerably better background estimates (both\nqualitatively and quantitatively) than median filtering and the recently\nproposed \"intervals of stable intensity\" method. Further experiments on the\nWallflower dataset suggest that the combination of the proposed method with a\nforeground segmentation algorithm results in improved foreground segmentation."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2607v2", 
    "other_authors": "Hossam Isack, Yuri Boykov", 
    "title": "Joint optimization of fitting & matching in multi-view reconstruction", 
    "arxiv-id": "1303.2607v2", 
    "author": "Yuri Boykov", 
    "publish": "2013-03-11T18:14:42Z", 
    "summary": "Many standard approaches for geometric model fitting are based on pre-matched\nimage features. Typically, such pre-matching uses only feature appearances\n(e.g. SIFT) and a large number of non-unique features must be discarded in\norder to control the false positive rate. In contrast, we solve feature\nmatching and multi-model fitting problems in a joint optimization framework.\nThis paper proposes several fit-&-match energy formulations based on a\ngeneralization of the assignment problem. We developed an efficient solver\nbased on min-cost-max-flow algorithm that finds near optimal solutions. Our\napproach significantly increases the number of detected matches. In practice,\nenergy-based joint fitting & matching allows to increase the distance between\nview-points previously restricted by robustness of local SIFT-matching and to\nimprove the model fitting accuracy when compared to state-of-the-art\nmulti-model fitting techniques."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2610v1", 
    "other_authors": "Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy, Deepta Rajan, Anup Puri, David Frakes, Andreas Spanias", 
    "title": "Kernel Sparse Models for Automated Tumor Segmentation", 
    "arxiv-id": "1303.2610v1", 
    "author": "Andreas Spanias", 
    "publish": "2013-03-11T18:33:01Z", 
    "summary": "In this paper, we propose sparse coding-based approaches for segmentation of\ntumor regions from MR images. Sparse coding with data-adapted dictionaries has\nbeen successfully employed in several image recovery and vision problems. The\nproposed approaches obtain sparse codes for each pixel in brain magnetic\nresonance images considering their intensity values and location information.\nSince it is trivial to obtain pixel-wise sparse codes, and combining multiple\nfeatures in the sparse coding setup is not straightforward, we propose to\nperform sparse coding in a high-dimensional feature space where non-linear\nsimilarities can be effectively modeled. We use the training data from\nexpert-segmented images to obtain kernel dictionaries with the kernel K-lines\nclustering procedure. For a test image, sparse codes are computed with these\nkernel dictionaries, and they are used to identify the tumor regions. This\napproach is completely automated, and does not require user intervention to\ninitialize the tumor regions in a test image. Furthermore, a low complexity\nsegmentation approach based on kernel sparse codes, which allows the user to\ninitialize the tumor region, is also presented. Results obtained with both the\nproposed approaches are validated against manual segmentation by an expert\nradiologist, and the proposed methods lead to accurate tumor identification."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2685v1", 
    "other_authors": "Akshay Gadde, Sunil K Narang, Antonio Ortega", 
    "title": "Bilateral Filter: Graph Spectral Interpretation and Extensions", 
    "arxiv-id": "1303.2685v1", 
    "author": "Antonio Ortega", 
    "publish": "2013-03-11T20:52:57Z", 
    "summary": "In this paper we study the bilateral filter proposed by Tomasi and Manduchi,\nas a spectral domain transform defined on a weighted graph. The nodes of this\ngraph represent the pixels in the image and a graph signal defined on the nodes\nrepresents the intensity values. Edge weights in the graph correspond to the\nbilateral filter coefficients and hence are data adaptive. Spectrum of a graph\nis defined in terms of the eigenvalues and eigenvectors of the graph Laplacian\nmatrix. We use this spectral interpretation to generalize the bilateral filter\nand propose more flexible and application specific spectral designs of\nbilateral-like filters. We show that these spectral filters can be implemented\nwith k-iterative bilateral filtering operations and do not require expensive\ndiagonalization of the Laplacian matrix."
},{
    "category": "cs.CV", 
    "doi": "10.1155/2011/164956", 
    "link": "http://arxiv.org/pdf/1303.2751v1", 
    "other_authors": "Mallikarjun Hangarge", 
    "title": "Gaussian Mixture Model for Handwritten Script Identification", 
    "arxiv-id": "1303.2751v1", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2013-03-12T02:32:02Z", 
    "summary": "This paper presents a Gaussian Mixture Model (GMM) to identify the script of\nhandwritten words of Roman, Devanagari, Kannada and Telugu scripts. It\nemphasizes the significance of directional energies for identification of\nscript of the word. It is robust to varied image sizes and different styles of\nwriting. A GMM is modeled using a set of six novel features derived from\ndirectional energy distributions of the underlying image. The standard\ndeviation of directional energy distributions are computed by decomposing an\nimage matrix into right and left diagonals. Furthermore, deviation of\nhorizontal and vertical distributions of energies is also built-in to GMM. A\ndataset of 400 images out of 800 (200 of each script) are used for training GMM\nand the remaining is for testing. An exhaustive experimentation is carried out\nat bi-script, tri-script and multi-script level and achieved script\nidentification accuracies in percentage as 98.7, 98.16 and 96.91 respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.23", 
    "link": "http://arxiv.org/pdf/1303.2783v1", 
    "other_authors": "Conrad Sanderson, Mehrtash T. Harandi, Yongkang Wong, Brian C. Lovell", 
    "title": "Combined Learning of Salient Local Descriptors and Distance Metrics for   Image Set Face Verification", 
    "arxiv-id": "1303.2783v1", 
    "author": "Brian C. Lovell", 
    "publish": "2013-03-12T06:12:59Z", 
    "summary": "In contrast to comparing faces via single exemplars, matching sets of face\nimages increases robustness and discrimination performance. Recent image set\nmatching approaches typically measure similarities between subspaces or\nmanifolds, while representing faces in a rigid and holistic manner. Such\nrepresentations are easily affected by variations in terms of alignment,\nillumination, pose and expression. While local feature based representations\nare considerably more robust to such variations, they have received little\nattention within the image set matching area. We propose a novel image set\nmatching technique, comprised of three aspects: (i) robust descriptors of face\nregions based on local features, partly inspired by the hierarchy in the human\nvisual system, (ii) use of several subspace and exemplar metrics to compare\ncorresponding face regions, (iii) jointly learning which regions are the most\ndiscriminative while finding the optimal mixing weights for combining metrics.\nFace recognition experiments on LFW, PIE and MOBIO face datasets show that the\nproposed algorithm obtains considerably better performance than several recent\nstate-of-the-art techniques, such as Local Principal Angle and the Kernel\nAffine Hull Method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-1-4471-5195-1_21", 
    "link": "http://arxiv.org/pdf/1303.2844v1", 
    "other_authors": "Pedro F. Felzenszwalb", 
    "title": "A Stochastic Grammar for Natural Shapes", 
    "arxiv-id": "1303.2844v1", 
    "author": "Pedro F. Felzenszwalb", 
    "publish": "2013-03-12T11:23:47Z", 
    "summary": "We consider object detection using a generic model for natural shapes. A\ncommon approach for object recognition involves matching object models directly\nto images. Another approach involves building intermediate representations via\na generic grouping processes. We argue that these two processes (model-based\nrecognition and grouping) may use similar computational mechanisms. By defining\na generic model for shapes we can use model-based techniques to implement a\nmid-level vision grouping process."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-1-4471-5195-1_21", 
    "link": "http://arxiv.org/pdf/1303.3087v1", 
    "other_authors": "Mallikarjun Hangarge, K. C. Santosh, Srikanth Doddamani, Rajmohan Pardeshi", 
    "title": "Statistical Texture Features based Handwritten and Printed Text   Classification in South Indian Documents", 
    "arxiv-id": "1303.3087v1", 
    "author": "Rajmohan Pardeshi", 
    "publish": "2013-03-13T04:51:22Z", 
    "summary": "In this paper, we use statistical texture features for handwritten and\nprinted text classification. We primarily aim for word level classification in\nsouth Indian scripts. Words are first extracted from the scanned document. For\neach extracted word, statistical texture features are computed such as mean,\nstandard deviation, smoothness, moment, uniformity, entropy and local range\nincluding local entropy. These feature vectors are then used to classify words\nvia k-NN classifier. We have validated the approach over several different\ndatasets. Scripts like Kannada, Telugu, Malayalam and Hindi i.e., Devanagari\nare primarily employed where an average classification rate of 99.26% is\nachieved. In addition, to provide an extensibility of the approach, we address\nRoman script by using publicly available dataset and interesting results are\nreported."
},{
    "category": "cs.CV", 
    "doi": "10.1088/1742-6596/410/1/012163", 
    "link": "http://arxiv.org/pdf/1303.3152v1", 
    "other_authors": "Bruno Brandoli Machado, Wesley Nunes Gon\u00e7alves, Odemir Martinez Bruno", 
    "title": "Material quality assessment of silk nanofibers based on swarm   intelligence", 
    "arxiv-id": "1303.3152v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2013-03-13T13:23:21Z", 
    "summary": "In this paper, we propose a novel approach for texture analysis based on\nartificial crawler model. Our method assumes that each agent can interact with\nthe environment and each other. The evolution process converges to an\nequilibrium state according to the set of rules. For each textured image, the\nfeature vector is composed by signatures of the live agents curve at each time.\nExperimental results revealed that combining the minimum and maximum signatures\ninto one increase the classification rate. In addition, we pioneer the use of\nautonomous agents for characterizing silk fibroin scaffolds. The results\nstrongly suggest that our approach can be successfully employed for texture\nanalysis."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4160v1", 
    "other_authors": "Vikas Reddy, Conrad Sanderson, Brian C. Lovell", 
    "title": "Improved Foreground Detection via Block-based Classifier Cascade with   Probabilistic Decision Integration", 
    "arxiv-id": "1303.4160v1", 
    "author": "Brian C. Lovell", 
    "publish": "2013-03-18T05:48:40Z", 
    "summary": "Background subtraction is a fundamental low-level processing task in numerous\ncomputer vision applications. The vast majority of algorithms process images on\na pixel-by-pixel basis, where an independent decision is made for each pixel. A\ngeneral limitation of such processing is that rich contextual information is\nnot taken into account. We propose a block-based method capable of dealing with\nnoise, illumination variations and dynamic backgrounds, while still obtaining\nsmooth contours of foreground objects. Specifically, image sequences are\nanalysed on an overlapping block-by-block basis. A low-dimensional texture\ndescriptor obtained from each block is passed through an adaptive classifier\ncascade, where each stage handles a distinct problem. A probabilistic\nforeground mask generation approach then exploits block overlaps to integrate\ninterim block-level decisions into final pixel-level foreground segmentation.\nUnlike many pixel-based methods, ad-hoc post-processing of foreground masks is\nnot required. Experiments on the difficult Wallflower and I2R datasets show\nthat the proposed approach obtains on average better results (both\nqualitatively and quantitatively) than several prominent methods. We\nfurthermore propose the use of tracking performance as an unbiased approach for\nassessing the practical usefulness of foreground segmentation methods, and show\nthat the proposed approach leads to considerable improvements in tracking\naccuracy on the CAVIAR dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4614v1", 
    "other_authors": "Abdel Bela\u00efd, K. C. Santosh, Vincent Poulain D'Andecy", 
    "title": "Handwritten and Printed Text Separation in Real Document", 
    "arxiv-id": "1303.4614v1", 
    "author": "Vincent Poulain D'Andecy", 
    "publish": "2013-03-19T14:23:24Z", 
    "summary": "The aim of the paper is to separate handwritten and printed text from a real\ndocument embedded with noise, graphics including annotations. Relying on\nrun-length smoothing algorithm (RLSA), the extracted pseudo-lines and\npseudo-words are used as basic blocks for classification. To handle this, a\nmulti-class support vector machine (SVM) with Gaussian kernel performs a first\nlabelling of each pseudo-word including the study of local neighbourhood. It\nthen propagates the context between neighbours so that we can correct possible\nlabelling errors. Considering running time complexity issue, we propose linear\ncomplexity methods where we use k-NN with constraint. When using a kd-tree, it\nis almost linearly proportional to the number of pseudo-words. The performance\nof our system is close to 90%, even when very small learning dataset where\nsamples are basically composed of complex administrative documents."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4803v1", 
    "other_authors": "Xi Li, Weiming Hu, Chunhua Shen, Zhongfei Zhang, Anthony Dick, Anton van den Hengel", 
    "title": "A Survey of Appearance Models in Visual Object Tracking", 
    "arxiv-id": "1303.4803v1", 
    "author": "Anton van den Hengel", 
    "publish": "2013-03-20T01:08:33Z", 
    "summary": "Visual object tracking is a significant computer vision task which can be\napplied to many domains such as visual surveillance, human computer\ninteraction, and video compression. In the literature, researchers have\nproposed a variety of 2D appearance models. To help readers swiftly learn the\nrecent advances in 2D appearance models for visual object tracking, we\ncontribute this survey, which provides a detailed review of the existing 2D\nappearance models. In particular, this survey takes a module-based architecture\nthat enables readers to easily grasp the key points of visual object tracking.\nIn this survey, we first decompose the problem of appearance modeling into two\ndifferent processing stages: visual representation and statistical modeling.\nThen, different 2D appearance models are categorized and discussed with respect\nto their composition modules. Finally, we address several issues of interest as\nwell as the remaining challenges for future research on this topic. The\ncontributions of this survey are four-fold. First, we review the literature of\nvisual representations according to their feature-construction mechanisms\n(i.e., local and global). Second, the existing statistical modeling schemes for\ntracking-by-detection are reviewed according to their model-construction\nmechanisms: generative, discriminative, and hybrid generative-discriminative.\nThird, each type of visual representations or statistical modeling techniques\nis analyzed and discussed from a theoretical or practical viewpoint. Fourth,\nthe existing benchmark resources (e.g., source code and video datasets) are\nexamined in this survey."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4839v1", 
    "other_authors": "Dr. Firoj Parwej", 
    "title": "The State of the Art Recognize in Arabic Script through Combination of   Online and Offline", 
    "arxiv-id": "1303.4839v1", 
    "author": "Dr. Firoj Parwej", 
    "publish": "2013-03-20T04:54:44Z", 
    "summary": "Handwriting recognition refers to the identification of written characters.\nHandwriting recognition has become an acute research area in recent years for\nthe ease of access of computer science. In this paper primarily discussed\nOn-line and Off-line handwriting recognition methods for Arabic words which are\noften used among then across the Middle East and North Africa People. Arabic\nword online handwriting recognition is a very challenging task due to its\ncursive nature. Because of the characteristic of the whole body of the Arabic\nscript, namely connectivity between the characters, thereby the segmentation of\nAn Arabic script is very difficult. In this paper we introduced an Arabic\nscript multiple classifier system for recognizing notes written on a Starboard.\nThis Arabic script multiple classifier system combines one off-line and on-line\nhandwriting recognition systems. The Arabic script recognizers are all based on\nHidden Markov Models but vary in the way of preprocessing and normalization. To\ncombine the Arabic script output sequences of the recognizers, we incrementally\nalign the word sequences using a norm string matching algorithm. The Arabic\nscript combination we could increase the system performance over the excellent\ncharacter recognizer by about 3%. The proposed technique is also the necessary\nstep towards character recognition, person identification, personality\ndetermination where input data is processed from all perspectives."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4840v1", 
    "other_authors": "Igor Polkovnikov", 
    "title": "Asynchronous Cellular Operations on Gray Images Extracting Topographic   Shape Features and Their Relations", 
    "arxiv-id": "1303.4840v1", 
    "author": "Igor Polkovnikov", 
    "publish": "2013-03-20T04:59:08Z", 
    "summary": "A variety of operations of cellular automata on gray images is presented. All\noperations are of a wave-front nature finishing in a stable state. They are\nused to extract shape descripting gray objects robust to a variety of pattern\ndistortions. Topographic terms are used: \"lakes\", \"dales\", \"dales of dales\". It\nis shown how mutual object relations like \"above\" can be presented in terms of\ngray image analysis and how it can be used for character classification and for\ngray pattern decomposition. Algorithms can be realized with a parallel\nasynchronous architecture. Keywords: Pattern Recognition, Mathematical\nMorphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis,\nTopographical Shape Descriptors, Asynchronous Parallel Processors, Holes,\nCavities, Concavities, Graphs."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TCSVT.2012.2203199", 
    "link": "http://arxiv.org/pdf/1303.4845v2", 
    "other_authors": "Myong-Song Ho, Gwang-Hui Ju, Yong-Bom O, Gwang-Ho Jong", 
    "title": "On Constructing the Value Function for Optimal Trajectory Problem and   its Application to Image Processing", 
    "arxiv-id": "1303.4845v2", 
    "author": "Gwang-Ho Jong", 
    "publish": "2013-03-20T06:16:55Z", 
    "summary": "We proposed an algorithm for solving Hamilton-Jacobi equation associated to\nan optimal trajectory problem for a vehicle moving inside the pre-specified\ndomain with the speed depending upon the direction of the motion and current\nposition of the vehicle. The dynamics of the vehicle is defined by an ordinary\ndifferential equation, the right hand of which is given by product of control(a\ntime dependent fuction) and a function dependent on trajectory and control. At\nsome unspecified terminal time, the vehicle reaches the boundary of the\npre-specified domain and incurs a terminal cost. We also associate the\ntraveling cost with a type of integral to the trajectory followed by vehicle.\nWe are interested in a numerical method for finding a trajectory that minimizes\nthe sum of the traveling cost and terminal cost. We developed an algorithm\nsolving the value function for general trajectory optimization problem. Our\nalgorithm is closely related to the Tsitsiklis's Fast Marching Method and J. A.\nSethian's OUM and SLF-LLL[1-4] and is a generalization of them. On the basis of\nthese results, We applied our algorithm to the image processing such as\nfingerprint verification."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.4866v1", 
    "other_authors": "Ankit R. Chadha, Neha S. Satam", 
    "title": "A Robust Rapid Approach to Image Segmentation with Optimal Thresholding   and Watershed Transform", 
    "arxiv-id": "1303.4866v1", 
    "author": "Neha S. Satam", 
    "publish": "2013-03-20T08:15:07Z", 
    "summary": "This paper describes a novel method for partitioning image into meaningful\nsegments. The proposed method employs watershed transform, a well-known image\nsegmentation technique. Along with that, it uses various auxiliary schemes such\nas Binary Gradient Masking, dilation which segment the image in proper way. The\nalgorithm proposed in this paper considers all these methods in effective way\nand takes little time. It is organized in such a manner so that it operates on\ninput image adaptively. Its robustness and efficiency makes it more convenient\nand suitable for all types of images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.5691v1", 
    "other_authors": "Benjamin Berkels, Ivan Cabrilo, Sven Haller, Martin Rumpf, Carlo Schaller", 
    "title": "Cortical Surface Co-Registration based on MRI Images and Photos", 
    "arxiv-id": "1303.5691v1", 
    "author": "Carlo Schaller", 
    "publish": "2013-03-22T19:07:13Z", 
    "summary": "Brain shift, i.e. the change in configuration of the brain after opening the\ndura mater, is a key problem in neuronavigation. We present an approach to\nco-register intra-operative microscope images with pre-operative MRI to adapt\nand optimize intra-operative neuronavigation. The tools are a robust\nclassification of sulci on MRI extracted cortical surfaces, guided user marking\nof most prominent sulci on a microscope image, and the actual variational\nregistration method with a fidelity energy for 3D deformations of the cortical\nsurface combined with a higher order, linear elastica type prior energy.\nFurthermore, the actual registration is validated on an artificial testbed with\nknown ground truth deformation and on real data of a neuro clinical patient."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6066v2", 
    "other_authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel", 
    "title": "Asymmetric Pruning for Learning Cascade Detectors", 
    "arxiv-id": "1303.6066v2", 
    "author": "Anton van den Hengel", 
    "publish": "2013-03-25T10:01:19Z", 
    "summary": "Cascade classifiers are one of the most important contributions to real-time\nobject detection. Nonetheless, there are many challenging problems arising in\ntraining cascade detectors. One common issue is that the node classifier is\ntrained with a symmetric classifier. Having a low misclassification error rate\ndoes not guarantee an optimal node learning goal in cascade classifiers, i.e.,\nan extremely high detection rate with a moderate false positive rate. In this\nwork, we present a new approach to train an effective node classifier in a\ncascade detector. The algorithm is based on two key observations: 1) Redundant\nweak classifiers can be safely discarded; 2) The final detector should satisfy\nthe asymmetric learning objective of the cascade architecture. To achieve this,\nwe separate the classifier training into two steps: finding a pool of\ndiscriminative weak classifiers/features and training the final classifier by\npruning weak classifiers which contribute little to the asymmetric learning\ncriterion (asymmetric classifier construction). Our model reduction approach\nhelps accelerate the learning time while achieving the pre-determined learning\nobjective. Experimental results on both face and car data sets verify the\neffectiveness of the proposed algorithm. On the FDDB face data sets, our\napproach achieves the state-of-the-art performance, which demonstrates the\nadvantage of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6455v1", 
    "other_authors": "Shaode Yu, Qingsong Zhu, Shibin Wu, Yaoqin Xie", 
    "title": "Performance Evaluation of Edge-Directed Interpolation Methods for Images", 
    "arxiv-id": "1303.6455v1", 
    "author": "Yaoqin Xie", 
    "publish": "2013-03-26T12:35:46Z", 
    "summary": "Many interpolation methods have been developed for high visual quality, but\nfail for inability to preserve image structures. Edges carry heavy structural\ninformation for detection, determination and classification. Edge-adaptive\ninterpolation approaches become a center of focus. In this paper, performance\nof four edge-directed interpolation methods comparing with two traditional\nmethods is evaluated on two groups of images. These methods include new\nedge-directed interpolation (NEDI), edge-guided image interpolation (EGII),\niterative curvature-based interpolation (ICBI), directional cubic convolution\ninterpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic.\nMeanwhile, no parameters are mentioned to measure edge-preserving ability of\nedge-adaptive interpolation approaches and we proposed two. One evaluates\naccuracy and the other measures robustness of edge-preservation ability.\nPerformance evaluation is based on six parameters. Objective assessment and\nvisual analysis are illustrated and conclusions are drawn from theoretical\nbackgrounds and practical results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6619v1", 
    "other_authors": "Arun p V, S. K. Katiyar", 
    "title": "An N-dimensional approach towards object based classification of   remotely sensed imagery", 
    "arxiv-id": "1303.6619v1", 
    "author": "S. K. Katiyar", 
    "publish": "2013-03-26T19:39:20Z", 
    "summary": "Remote sensing techniques are widely used for land cover classification and\nurban analysis. The availability of high resolution remote sensing imagery\nlimits the level of classification accuracy attainable from pixel-based\napproach. In this paper object-based classification scheme based on a\nhierarchical support vector machine is introduced. By combining spatial and\nspectral information, the amount of overlap between classes can be decreased;\nthereby yielding higher classification accuracy and more accurate land cover\nmaps. We have adopted certain automatic approaches based on the advanced\ntechniques as Cellular automata and Genetic Algorithm for kernel and tuning\nparameter selection. Performance evaluation of the proposed methodology in\ncomparison with the existing approaches is performed with reference to the\nBhopal city study area."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6711v1", 
    "other_authors": "P. V. Arun, S. K. Katiyar", 
    "title": "An intelligent approach towards automatic shape modeling and object   extraction from satellite images using cellular automata based algorithm", 
    "arxiv-id": "1303.6711v1", 
    "author": "S. K. Katiyar", 
    "publish": "2013-03-27T00:33:52Z", 
    "summary": "Automatic feature extraction domain has witnessed the application of many\nintelligent methodologies over past decade; however detection accuracy of these\napproaches were limited as object geometry and contextual knowledge were not\ngiven enough consideration. In this paper, we propose a frame work for accurate\ndetection of features along with automatic interpolation, and interpretation by\nmodeling feature shape as well as contextual knowledge using advanced\ntechniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed\nmethodology has been compared with contemporary methods using different\nstatistical measures. Investigations over various satellite images revealed\nthat considerable success was achieved with the CNN approach. CNN has been\neffective in modeling different complex features effectively and complexity of\nthe approach has been considerably reduced using corset optimization. The\nsystem has dynamically used spectral and spatial information for representing\ncontextual knowledge using CNN-prolog approach. System has been also proved to\nbe effective in providing intelligent interpolation and interpretation of\nrandom features."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6926v1", 
    "other_authors": "Dr. S. K. Katiyar, Arun P. V.", 
    "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing", 
    "arxiv-id": "1303.6926v1", 
    "author": "Arun P. V.", 
    "publish": "2013-03-27T18:57:12Z", 
    "summary": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.6927v1", 
    "other_authors": "Arun P. V., Dr. S. K. Katiyar", 
    "title": "An investigation towards wavelet based optimization of automatic image   registration techniques", 
    "arxiv-id": "1303.6927v1", 
    "author": "Dr. S. K. Katiyar", 
    "publish": "2013-03-27T19:02:02Z", 
    "summary": "Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1303.7390v2", 
    "other_authors": "Aasa Feragen, Jens Petersen, Dominik Grimm, Asger Dirksen, Jesper Holst Pedersen, Karsten Borgwardt, Marleen de Bruijne", 
    "title": "Geometric tree kernels: Classification of COPD from airway tree geometry", 
    "arxiv-id": "1303.7390v2", 
    "author": "Marleen de Bruijne", 
    "publish": "2013-03-29T13:25:17Z", 
    "summary": "Methodological contributions: This paper introduces a family of kernels for\nanalyzing (anatomical) trees endowed with vector valued measurements made along\nthe tree. While state-of-the-art graph and tree kernels use combinatorial\ntree/graph structure with discrete node and edge labels, the kernels presented\nin this paper can include geometric information such as branch shape, branch\nradius or other vector valued properties. In addition to being flexible in\ntheir ability to model different types of attributes, the presented kernels are\ncomputationally efficient and some of them can easily be computed for large\ndatasets (N of the order 10.000) of trees with 30-600 branches. Combining the\nkernels with standard machine learning tools enables us to analyze the relation\nbetween disease and anatomical tree structure and geometry. Experimental\nresults: The kernels are used to compare airway trees segmented from low-dose\nCT, endowed with branch shape descriptors and airway wall area percentage\nmeasurements made along the tree. Using kernelized hypothesis testing we show\nthat the geometric airway trees are significantly differently distributed in\npatients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy\nindividuals. The geometric tree kernels also give a significant increase in the\nclassification accuracy of COPD from geometric tree structure endowed with\nairway wall thickness measurements in comparison with state-of-the-art methods,\ngiving further insight into the relationship between airway wall thickness and\nCOPD. Software: Software for computing kernels and statistical tests is\navailable at http://image.diku.dk/aasa/software.php."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0271v2", 
    "other_authors": "Qiang Qiu, Rama Chellappa", 
    "title": "Compositional Dictionaries for Domain Adaptive Face Recognition", 
    "arxiv-id": "1308.0271v2", 
    "author": "Rama Chellappa", 
    "publish": "2013-08-01T17:27:31Z", 
    "summary": "We present a dictionary learning approach to compensate for the\ntransformation of faces due to changes in view point, illumination, resolution,\netc. The key idea of our approach is to force domain-invariant sparse coding,\ni.e., design a consistent sparse representation of the same face in different\ndomains. In this way, classifiers trained on the sparse codes in the source\ndomain consisting of frontal faces for example can be applied to the target\ndomain (consisting of faces in different poses, illumination conditions, etc)\nwithout much loss in recognition accuracy. The approach is to first learn a\ndomain base dictionary, and then describe each domain shift (identity, pose,\nillumination) using a sparse representation over the base dictionary. The\ndictionary adapted to each domain is expressed as sparse linear combinations of\nthe base dictionary. In the context of face recognition, with the proposed\ncompositional dictionary approach, a face image can be decomposed into sparse\nrepresentations for a given subject, pose and illumination respectively. This\napproach has three advantages: first, the extracted sparse representation for a\nsubject is consistent across domains and enables pose and illumination\ninsensitive face recognition. Second, sparse representations for pose and\nillumination can subsequently be used to estimate the pose and illumination\ncondition of a face image. Finally, by composing sparse representations for\nsubject and the different domains, we can also perform pose alignment and\nillumination normalization. Extensive experiments using two public face\ndatasets are presented to demonstrate the effectiveness of our approach for\nface recognition."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0273v1", 
    "other_authors": "Qiang Qiu, Guillermo Sapiro", 
    "title": "Learning Robust Subspace Clustering", 
    "arxiv-id": "1308.0273v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2013-08-01T17:31:37Z", 
    "summary": "We propose a low-rank transformation-learning framework to robustify subspace\nclustering. Many high-dimensional data, such as face images and motion\nsequences, lie in a union of low-dimensional subspaces. The subspace clustering\nproblem has been extensively studied in the literature to partition such\nhigh-dimensional data into clusters corresponding to their underlying\nlow-dimensional subspaces. However, low-dimensional intrinsic structures are\noften violated for real-world observations, as they can be corrupted by errors\nor deviate from ideal models. We propose to address this by learning a linear\ntransformation on subspaces using matrix rank, via its convex surrogate nuclear\nnorm, as the optimization criteria. The learned linear transformation restores\na low-rank structure for data from the same subspace, and, at the same time,\nforces a high-rank structure for data from different subspaces. In this way, we\nreduce variations within the subspaces, and increase separations between the\nsubspaces for more accurate subspace clustering. This proposed learned robust\nsubspace clustering framework significantly enhances the performance of\nexisting subspace clustering methods. To exploit the low-rank structures of the\ntransformed subspaces, we further introduce a subspace clustering technique,\ncalled Robust Sparse Subspace Clustering, which efficiently combines robust PCA\nwith sparse modeling. We also discuss the online learning of the\ntransformation, and learning of the transformation while simultaneously\nreducing the data dimensionality. Extensive experiments using public datasets\nare presented, showing that the proposed approach significantly outperforms\nstate-of-the-art subspace clustering methods."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0275v1", 
    "other_authors": "Qiang Qiu, Guillermo Sapiro, Ching-Hui Chen", 
    "title": "Domain-invariant Face Recognition using Learned Low-rank Transformation", 
    "arxiv-id": "1308.0275v1", 
    "author": "Ching-Hui Chen", 
    "publish": "2013-08-01T17:34:36Z", 
    "summary": "We present a low-rank transformation approach to compensate for face\nvariations due to changes in visual domains, such as pose and illumination. The\nkey idea is to learn discriminative linear transformations for face images\nusing matrix rank as the optimization criteria. The learned linear\ntransformations restore a shared low-rank structure for faces from the same\nsubject, and, at the same time, force a high-rank structure for faces from\ndifferent subjects. In this way, among the transformed faces, we reduce\nvariations caused by domain changes within the classes, and increase\nseparations between the classes for better face recognition across domains.\nExtensive experiments using public datasets are presented to demonstrate the\neffectiveness of our approach for face recognition across domains. The\npotential of the approach for feature extraction in generic object recognition\nand coded aperture design are discussed as well."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0290v1", 
    "other_authors": "Qiang Qiu, Zhuolin Jiang, Rama Chellappa", 
    "title": "Sparse Dictionary-based Attributes for Action Recognition and   Summarization", 
    "arxiv-id": "1308.0290v1", 
    "author": "Rama Chellappa", 
    "publish": "2013-08-01T18:25:16Z", 
    "summary": "We present an approach for dictionary learning of action attributes via\ninformation maximization. We unify the class distribution and appearance\ninformation into an objective function for learning a sparse dictionary of\naction attributes. The objective function maximizes the mutual information\nbetween what has been learned and what remains to be learned in terms of\nappearance information and class distribution for each dictionary atom. We\npropose a Gaussian Process (GP) model for sparse representation to optimize the\ndictionary objective function. The sparse coding property allows a kernel with\ncompact support in GP to realize a very efficient dictionary learning process.\nHence we can describe an action video by a set of compact and discriminative\naction attributes. More importantly, we can recognize modeled action categories\nin a sparse feature space, which can be generalized to unseen and unmodeled\naction categories. Experimental results demonstrate the effectiveness of our\napproach in action recognition and summarization."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0365v1", 
    "other_authors": "Emanuel Aldea, Khurom H. Kiyani", 
    "title": "Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes", 
    "arxiv-id": "1308.0365v1", 
    "author": "Khurom H. Kiyani", 
    "publish": "2013-08-01T21:58:33Z", 
    "summary": "In this paper we address the problem of multiple camera calibration in the\npresence of a homogeneous scene, and without the possibility of employing\ncalibration object based methods. The proposed solution exploits salient\nfeatures present in a larger field of view, but instead of employing active\nvision we replace the cameras with stereo rigs featuring a long focal analysis\ncamera, as well as a short focal registration camera. Thus, we are able to\npropose an accurate solution which does not require intrinsic variation models\nas in the case of zooming cameras. Moreover, the availability of the two views\nsimultaneously in each rig allows for pose re-estimation between rigs as often\nas necessary. The algorithm has been successfully validated in an indoor\nsetting, as well as on a difficult scene featuring a highly dense pilgrim crowd\nin Makkah."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.0890v1", 
    "other_authors": "Parimita Saikia, Karen Das", 
    "title": "Head Gesture Recognition using Optical Flow based Classification with   Reinforcement of GMM based Background Subtraction", 
    "arxiv-id": "1308.0890v1", 
    "author": "Karen Das", 
    "publish": "2013-08-05T05:17:26Z", 
    "summary": "This paper describes a technique of real time head gesture recognition\nsystem. The method includes Gaussian mixture model (GMM) accompanied by optical\nflow algorithm which provided us the required information regarding head\nmovement. The proposed model can be implemented in various control system. We\nare also presenting the result and implementation of both mentioned method."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.1126v1", 
    "other_authors": "H. Lakshman, W. -Q Lim, H. Schwarz, D. Marpe, G. Kutyniok, T. Wiegand", 
    "title": "Image interpolation using Shearlet based iterative refinement", 
    "arxiv-id": "1308.1126v1", 
    "author": "T. Wiegand", 
    "publish": "2013-08-05T21:33:06Z", 
    "summary": "This paper proposes an image interpolation algorithm exploiting sparse\nrepresentation for natural images. It involves three main steps: (a) obtaining\nan initial estimate of the high resolution image using linear methods like FIR\nfiltering, (b) promoting sparsity in a selected dictionary through iterative\nthresholding, and (c) extracting high frequency information from the\napproximation to refine the initial estimate. For the sparse modeling, a\nshearlet dictionary is chosen to yield a multiscale directional representation.\nThe proposed algorithm is compared to several state-of-the-art methods to\nassess its objective as well as subjective performance. Compared to the cubic\nspline interpolation method, an average PSNR gain of around 0.8 dB is observed\nover a dataset of 200 images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.1374v1", 
    "other_authors": "Hyuntaek Oh", 
    "title": "Bayesian ensemble learning for image denoising", 
    "arxiv-id": "1308.1374v1", 
    "author": "Hyuntaek Oh", 
    "publish": "2013-08-06T18:46:18Z", 
    "summary": "Natural images are often affected by random noise and image denoising has\nlong been a central topic in Computer Vision. Many algorithms have been\nintroduced to remove the noise from the natural images, such as Gaussian,\nWiener filtering and wavelet thresholding. However, many of these algorithms\nremove the fine edges and make them blur. Recently, many promising denoising\nalgorithms have been introduced such as Non-local Means, Fields of Experts, and\nBM3D. In this paper, we explore Bayesian method of ensemble learning for image\ndenoising. Ensemble methods seek to combine multiple different algorithms to\nretain the strengths of all methods and the weaknesses of none. Bayesian\nensemble models are Non-local Means and Fields of Experts, the very successful\nrecent algorithms. The Non-local Means presumes that the image contains an\nextensive amount of self-similarity. The approach of the Fields of Experts\nmodel extends traditional Markov Random Field model by learning potential\nfunctions over extended pixel neighborhoods. The two models are implemented and\nimage denoising is performed on natural images. The experimental results\nobtained are used to compare with the single algorithm and discuss the ensemble\nlearning and their approaches. Comparing to the results of Non-local Means and\nFields of Experts, Ensemble learning showed improvement nearly 1dB."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.1981v3", 
    "other_authors": "Kaushik Mitra, Oliver Cossairt, Ashok Veeraraghavan", 
    "title": "A Framework for the Analysis of Computational Imaging Systems with   Practical Applications", 
    "arxiv-id": "1308.1981v3", 
    "author": "Ashok Veeraraghavan", 
    "publish": "2013-08-08T21:21:54Z", 
    "summary": "Over the last decade, a number of Computational Imaging (CI) systems have\nbeen proposed for tasks such as motion deblurring, defocus deblurring and\nmultispectral imaging. These techniques increase the amount of light reaching\nthe sensor via multiplexing and then undo the deleterious effects of\nmultiplexing by appropriate reconstruction algorithms. Given the widespread\nappeal and the considerable enthusiasm generated by these techniques, a\ndetailed performance analysis of the benefits conferred by this approach is\nimportant.\n  Unfortunately, a detailed analysis of CI has proven to be a challenging\nproblem because performance depends equally on three components: (1) the\noptical multiplexing, (2) the noise characteristics of the sensor, and (3) the\nreconstruction algorithm. A few recent papers have performed analysis taking\nmultiplexing and noise characteristics into account. However, analysis of CI\nsystems under state-of-the-art reconstruction algorithms, most of which exploit\nsignal prior models, has proven to be unwieldy. In this paper, we present a\ncomprehensive analysis framework incorporating all three components.\n  In order to perform this analysis, we model the signal priors using a\nGaussian Mixture Model (GMM). A GMM prior confers two unique characteristics.\nFirstly, GMM satisfies the universal approximation property which says that any\nprior density function can be approximated to any fidelity using a GMM with\nappropriate number of mixtures. Secondly, a GMM prior lends itself to\nanalytical tractability allowing us to derive simple expressions for the\n`minimum mean square error' (MMSE), which we use as a metric to characterize\nthe performance of CI systems. We use our framework to analyze several\npreviously proposed CI techniques, giving conclusive answer to the question:\n`How much performance gain is due to use of a signal prior and how much is due\nto multiplexing?"
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.2654v1", 
    "other_authors": "Jos\u00e9 M. Celaya-Padilla, Juan Rodriguez-Rojas, Victor Trevino, Jos\u00e9 G. Gerardo Tamez-Pena", 
    "title": "Local image registration a comparison for bilateral registration   mammography", 
    "arxiv-id": "1308.2654v1", 
    "author": "Jos\u00e9 G. Gerardo Tamez-Pena", 
    "publish": "2013-08-12T19:29:49Z", 
    "summary": "Early tumor detection is key in reducing the number of breast cancer death\nand screening mammography is one of the most widely available and reliable\nmethod for early detection. However, it is difficult for the radiologist to\nprocess with the same attention each case, due the large amount of images to be\nread. Computer aided detection (CADe) systems improve tumor detection rate; but\nthe current efficiency of these systems is not yet adequate and the correct\ninterpretation of CADe outputs requires expert human intervention. Computer\naided diagnosis systems (CADx) are being designed to improve cancer diagnosis\naccuracy, but they have not been efficiently applied in breast cancer. CADx\nefficiency can be enhanced by considering the natural mirror symmetry between\nthe right and left breast. The objective of this work is to evaluate\nco-registration algorithms for the accurate alignment of the left to right\nbreast for CADx enhancement. A set of mammograms were artificially altered to\ncreate a ground truth set to evaluate the registration efficiency of DEMONs,\nand SPLINE deformable registration algorithms. The registration accuracy was\nevaluated using mean square errors, mutual information and correlation. The\nresults on the 132 images proved that the SPLINE deformable registration\nover-perform the DEMONS on mammography images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.3052v2", 
    "other_authors": "Wufeng Xue, Lei Zhang, Xuanqin Mou, Alan C. Bovik", 
    "title": "Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual   Image Quality Index", 
    "arxiv-id": "1308.3052v2", 
    "author": "Alan C. Bovik", 
    "publish": "2013-08-14T07:25:10Z", 
    "summary": "It is an important task to faithfully evaluate the perceptual quality of\noutput images in many applications such as image compression, image restoration\nand multimedia streaming. A good image quality assessment (IQA) model should\nnot only deliver high quality prediction accuracy but also be computationally\nefficient. The efficiency of IQA metrics is becoming particularly important due\nto the increasing proliferation of high-volume visual data in high-speed\nnetworks. We present a new effective and efficient IQA model, called gradient\nmagnitude similarity deviation (GMSD). The image gradients are sensitive to\nimage distortions, while different local structures in a distorted image suffer\ndifferent degrees of degradations. This motivates us to explore the use of\nglobal variation of gradient based local quality map for overall image quality\nprediction. We find that the pixel-wise gradient magnitude similarity (GMS)\nbetween the reference and distorted images combined with a novel pooling\nstrategy the standard deviation of the GMS map can predict accurately\nperceptual image quality. The resulting GMSD algorithm is much faster than most\nstate-of-the-art IQA methods, and delivers highly competitive prediction\naccuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.4440v1", 
    "other_authors": "AL-Wassai Firouz, N. V. Kalyankar", 
    "title": "Influences Combination of Multi-Sensor Images on Classification Accuracy", 
    "arxiv-id": "1308.4440v1", 
    "author": "N. V. Kalyankar", 
    "publish": "2013-08-20T21:34:47Z", 
    "summary": "This paper focuses on two main issues; first one is the impact of combination\nof multi-sensor images on the supervised learning classification accuracy using\nsegment Fusion (SF). The second issue attempts to undertake the study of\nsupervised machine learning classification technique of remote sensing images\nby using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD),\nMaximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their\naccuracies have been evaluated on their respected classification to choose the\nbest technique for classification of remote sensing images. QuickBird\nmultispectral data (MS) and panchromatic data (PAN) have been used in this\nstudy to demonstrate the enhancement and accuracy assessment of fused image\nover the original images using ALwassaiProcess software. According to\nexperimental result of this study, is that the test results indicate the\nsupervised classification results of fusion image, which generated better than\nthe MS did. As well as the result with Euclidean classifier is robust and\nprovides better results than the other classifiers do, despite of the popular\nbelief that the maximum-likelihood classifier is the most accurate classifier."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.4902v1", 
    "other_authors": "Aini Najwa Azmi, Dewi Nasien, Siti Mariyam Shamsuddin", 
    "title": "A review on handwritten character and numeral recognition for Roman,   Arabic, Chinese and Indian scripts", 
    "arxiv-id": "1308.4902v1", 
    "author": "Siti Mariyam Shamsuddin", 
    "publish": "2013-08-22T15:38:15Z", 
    "summary": "There are a lot of intensive researches on handwritten character recognition\n(HCR) for almost past four decades. The research has been done on some of\npopular scripts such as Roman, Arabic, Chinese and Indian. In this paper we\npresent a review on HCR work on the four popular scripts. We have summarized\nmost of the published paper from 2005 to recent and also analyzed the various\nmethods in creating a robust HCR system. We also added some future direction of\nresearch on HCR."
},{
    "category": "cs.CV", 
    "doi": "10.5120/10949-5908", 
    "link": "http://arxiv.org/pdf/1308.5063v1", 
    "other_authors": "Panqu Wang, Yan Zhang", 
    "title": "Suspicious Object Recognition Method in Video Stream Based on Visual   Attention", 
    "arxiv-id": "1308.5063v1", 
    "author": "Yan Zhang", 
    "publish": "2013-08-23T07:26:56Z", 
    "summary": "We propose a state of the art method for intelligent object recognition and\nvideo surveillance based on human visual attention. Bottom up and top down\nattention are applied respectively in the process of acquiring interested\nobject(saliency map) and object recognition. The revision of 4 channel PFT\nmethod is proposed for bottom up attention and enhances the speed and accuracy.\nInhibit of return (IOR) is applied in judging the sequence of saliency object\npop out. Euclidean distance of color distribution, object center coordinates\nand speed are considered in judging whether the target is match and suspicious.\nThe extensive tests on videos and images show that our method in video analysis\nhas high accuracy and fast speed compared with traditional method. The method\ncan be applied into many fields such as video surveillance and security."
},{
    "category": "cs.CV", 
    "doi": "10.18483/ijSci.251", 
    "link": "http://arxiv.org/pdf/1308.5315v1", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "Edge-detection applied to moving sand dunes on Mars", 
    "arxiv-id": "1308.5315v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2013-08-24T11:07:05Z", 
    "summary": "Here we discuss the application of an edge detection filter, the Sobel filter\nof GIMP, to the recently discovered motion of some sand dunes on Mars. The\nfilter allows a good comparison of an image HiRISE of 2007 and an image of 1999\nrecorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,\nmeasuring therefore the motion of the dunes on a longer period of time than\nthat previously investigated."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2283510", 
    "link": "http://arxiv.org/pdf/1308.5876v1", 
    "other_authors": "Laura Rebollo-Neira, Ryszard Maciol, Shabnam Bibi", 
    "title": "Hierarchized block wise image approximation by greedy pursuit strategies", 
    "arxiv-id": "1308.5876v1", 
    "author": "Shabnam Bibi", 
    "publish": "2013-08-27T13:57:16Z", 
    "summary": "An approach for effective implementation of greedy selection methodologies,\nto approximate an image partitioned into blocks, is proposed. The method is\nspecially designed for approximating partitions on a transformed image. It\nevolves by selecting, at each iteration step, i) the elements for approximating\neach of the blocks partitioning the image and ii) the hierarchized sequence in\nwhich the blocks are approximated to reach the required global condition on\nsparsity."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6056v1", 
    "other_authors": "Juan C. Moreno, V. B. S. Prasath, Hugo Proenca, K. Palaniappan", 
    "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active   Contours", 
    "arxiv-id": "1308.6056v1", 
    "author": "K. Palaniappan", 
    "publish": "2013-08-28T04:48:00Z", 
    "summary": "Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6309v1", 
    "other_authors": "Nizar Zaghden, Badreddine Khelifi, Adel M. Alimi, Remy Mullot", 
    "title": "Text recognition in both ancient and cartographic documents", 
    "arxiv-id": "1308.6309v1", 
    "author": "Remy Mullot", 
    "publish": "2013-08-28T20:59:55Z", 
    "summary": "This paper deals with the recognition and matching of text in both\ncartographic maps and ancient documents. The purpose of this work is to find\nsimilar text regions based on statistical and global features. A phase of\nnormalization is done first, in object to well categorize the same quantity of\ninformation. A phase of wordspotting is done next by combining local and global\nfeatures. We make different experiments by combining the different techniques\nof extracting features in order to obtain better results in recognition phase.\nWe applied fontspotting on both ancient documents and cartographic ones. We\nalso applied the wordspotting in which we adopted a new technique which tries\nto compare the images of character and not the entire images words. We present\nthe precision and recall values obtained with three methods for the new method\nof wordspotting applied on characters only."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6311v1", 
    "other_authors": "Nizar Zaghden, Remy Mullot, Mohamed Adel Alimi", 
    "title": "Categorizing ancient documents", 
    "arxiv-id": "1308.6311v1", 
    "author": "Mohamed Adel Alimi", 
    "publish": "2013-08-28T21:09:35Z", 
    "summary": "The analysis of historical documents is still a topical issue given the\nimportance of information that can be extracted and also the importance given\nby the institutions to preserve their heritage. The main idea in order to\ncharacterize the content of the images of ancient documents after attempting to\nclean the image is segmented blocks texts from the same image and tries to find\nsimilar blocks in either the same image or the entire image database. Most\napproaches of offline handwriting recognition proceed by segmenting words into\nsmaller pieces (usually characters) which are recognized separately.\nRecognition of a word then requires the recognition of all characters (OCR)\nthat compose it. Our work focuses mainly on the characterization of classes in\nimages of old documents. We use Som toolbox for finding classes in documents.\nWe applied also fractal dimensions and points of interest to categorize and\nmatch ancient documents."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6319v1", 
    "other_authors": "Nizar Zaghden, Remy Mullot, Mohamed Adel Alimi", 
    "title": "A proposition of a robust system for historical document images   indexation", 
    "arxiv-id": "1308.6319v1", 
    "author": "Mohamed Adel Alimi", 
    "publish": "2013-08-28T21:37:08Z", 
    "summary": "Characterizing noisy or ancient documents is a challenging problem up to now.\nMany techniques have been done in order to effectuate feature extraction and\nimage indexation for such documents. Global approaches are in general less\nrobust and exact than local approaches. That's why, we propose in this paper, a\nhybrid system based on global approach(fractal dimension), and a local one\nbased on SIFT descriptor. The Scale Invariant Feature Transform seems to do\nwell with our application since it's rotation invariant and relatively robust\nto changing illumination.In the first step the calculation of fractal dimension\nis applied to images in order to eliminate images which have distant features\nthan image request characteristics. Next, the SIFT is applied to show which\nimages match well the request. However the average matching time using the\nhybrid approach is better than \"fractal dimension\" and \"SIFT descriptor\" if\nthey are used alone."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cviu.2014.04.010", 
    "link": "http://arxiv.org/pdf/1308.6388v1", 
    "other_authors": "Zhi-Yong Liu, Hong Qiao", 
    "title": "GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure", 
    "arxiv-id": "1308.6388v1", 
    "author": "Hong Qiao", 
    "publish": "2013-08-29T08:00:20Z", 
    "summary": "In this paper we propose the Graduated NonConvexity and Graduated Concavity\nProcedure (GNCGCP) as a general optimization framework to approximately solve\nthe combinatorial optimization problems on the set of partial permutation\nmatrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC)\nwhich realizes a convex relaxation and graduated concavity (GC) which realizes\na concave relaxation. It is proved that GNCGCP realizes exactly a type of\nconvex-concave relaxation procedure (CCRP), but with a much simpler formulation\nwithout needing convex or concave relaxation in an explicit way. Actually,\nGNCGCP involves only the gradient of the objective function and is therefore\nvery easy to use in practical applications. Two typical NP-hard problems,\n(sub)graph matching and quadratic assignment problem (QAP), are employed to\ndemonstrate its simplicity and state-of-the-art performance."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1308.6401v1", 
    "other_authors": "Karim Hammoudi, Fadi Dornaika, Bahman Soheilian, Bruno Vallet, John McDonald, Nicolas Paparoditis", 
    "title": "A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of   Urban Facades from Heterogeneous Cartographic Data", 
    "arxiv-id": "1308.6401v1", 
    "author": "Nicolas Paparoditis", 
    "publish": "2013-08-29T08:47:09Z", 
    "summary": "In this paper we present a practical approach for generating an\nocclusion-free textured 3D map of urban facades by the synergistic use of\nterrestrial images, 3D point clouds and area-based information. Particularly in\ndense urban environments, the high presence of urban objects in front of the\nfacades causes significant difficulties for several stages in computational\nbuilding modeling. Major challenges lie on the one hand in extracting complete\n3D facade quadrilateral delimitations and on the other hand in generating\nocclusion-free facade textures. For these reasons, we describe a\nstraightforward approach for completing and recovering facade geometry and\ntextures by exploiting the data complementarity of terrestrial multi-source\nimagery and area-based information."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1308.6687v1", 
    "other_authors": "Pengfei Zhu, Wangmeng Zuo, Lei Zhang, Simon C. K. Shiu, David Zhang", 
    "title": "Image Set based Collaborative Representation for Face Recognition", 
    "arxiv-id": "1308.6687v1", 
    "author": "David Zhang", 
    "publish": "2013-08-30T09:08:56Z", 
    "summary": "With the rapid development of digital imaging and communication technologies,\nimage set based face recognition (ISFR) is becoming increasingly important. One\nkey issue of ISFR is how to effectively and efficiently represent the query\nface image set by using the gallery face image sets. The set-to-set distance\nbased methods ignore the relationship between gallery sets, while representing\nthe query set images individually over the gallery sets ignores the correlation\nbetween query set images. In this paper, we propose a novel image set based\ncollaborative representation and classification method for ISFR. By modeling\nthe query set as a convex or regularized hull, we represent this hull\ncollaboratively over all the gallery sets. With the resolved representation\ncoefficients, the distance between the query set and each gallery set can then\nbe calculated for classification. The proposed model naturally and effectively\nextends the image based collaborative representation to an image set based one,\nand our extensive experiments on benchmark ISFR databases show the superiority\nof the proposed method to state-of-the-art ISFR methods under different set\nsizes in terms of both recognition rate and efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1402.0595v1", 
    "other_authors": "Mojtaba Seyedhosseini, Tolga Tasdizen", 
    "title": "Scene Labeling with Contextual Hierarchical Models", 
    "arxiv-id": "1402.0595v1", 
    "author": "Tolga Tasdizen", 
    "publish": "2014-02-04T02:10:01Z", 
    "summary": "Scene labeling is the problem of assigning an object label to each pixel. It\nunifies the image segmentation and object recognition problems. The importance\nof using contextual information in scene labeling frameworks has been widely\nrealized in the field. We propose a contextual framework, called contextual\nhierarchical model (CHM), which learns contextual information in a hierarchical\nframework for scene labeling. At each level of the hierarchy, a classifier is\ntrained based on downsampled input images and outputs of previous levels. Our\nmodel then incorporates the resulting multi-resolution contextual information\ninto a classifier to segment the input image at original resolution. This\ntraining strategy allows for optimization of a joint posterior probability at\nmultiple resolutions through the hierarchy. Contextual hierarchical model is\npurely based on the input image patches and does not make use of any fragments\nor shape examples. Hence, it is applicable to a variety of problems such as\nobject segmentation and edge detection. We demonstrate that CHM outperforms\nstate-of-the-art on Stanford background and Weizmann horse datasets. It also\noutperforms state-of-the-art edge detection methods on NYU depth dataset and\nachieves state-of-the-art on Berkeley segmentation dataset (BSDS 500)."
},{
    "category": "cs.CV", 
    "doi": "10.5772/56570", 
    "link": "http://arxiv.org/pdf/1402.0785v1", 
    "other_authors": "Hong Jiang, Gang Huang, Paul Wilford", 
    "title": "Signal to Noise Ratio in Lensless Compressive Imaging", 
    "arxiv-id": "1402.0785v1", 
    "author": "Paul Wilford", 
    "publish": "2014-02-04T16:12:53Z", 
    "summary": "We analyze the signal to noise ratio (SNR) in a lensless compressive imaging\n(LCI) architecture. The architecture consists of a sensor of a single detecting\nelement and an aperture assembly of an array of programmable elements. LCI can\nbe used in conjunction with compressive sensing to capture images in a\ncompressed form of compressive measurements. In this paper, we perform SNR\nanalysis of the LCI and compare it with imaging with a pinhole or a lens. We\nwill show that the SNR in the LCI is independent of the image resolution, while\nthe SNR in either pinhole aperture imaging or lens aperture imaging decreases\nas the image resolution increases. Consequently, the SNR in the LCI is much\nhigher if the image resolution is large enough."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2346029", 
    "link": "http://arxiv.org/pdf/1402.0978v1", 
    "other_authors": "Ali Zarezade, Hamid R. Rabiee, Ali Soltani-Farani, Ahmad Khajenezhad", 
    "title": "Patchwise Joint Sparse Tracking with Occlusion Detection", 
    "arxiv-id": "1402.0978v1", 
    "author": "Ahmad Khajenezhad", 
    "publish": "2014-02-05T09:08:11Z", 
    "summary": "This paper presents a robust tracking approach to handle challenges such as\nocclusion and appearance change. Here, the target is partitioned into a number\nof patches. Then, the appearance of each patch is modeled using a dictionary\ncomposed of corresponding target patches in previous frames. In each frame, the\ntarget is found among a set of candidates generated by a particle filter, via a\nlikelihood measure that is shown to be proportional to the sum of\npatch-reconstruction errors of each candidate. Since the target's appearance\noften changes slowly in a video sequence, it is assumed that the target in the\ncurrent frame and the best candidates of a small number of previous frames,\nbelong to a common subspace. This is imposed using joint sparse representation\nto enforce the target and previous best candidates to have a common sparsity\npattern. Moreover, an occlusion detection scheme is proposed that uses\npatch-reconstruction errors and a prior probability of occlusion, extracted\nfrom an adaptive Markov chain, to calculate the probability of occlusion per\npatch. In each frame, occluded patches are excluded when updating the\ndictionary. Extensive experimental results on several challenging sequences\nshows that the proposed method outperforms state-of-the-art trackers."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2346029", 
    "link": "http://arxiv.org/pdf/1402.1151v1", 
    "other_authors": "Wojciech Biega\u0144ski, Andrzej Kasi\u0144ski", 
    "title": "Image Acquisition in an Underwater Vision System with NIR and VIS   Illumination", 
    "arxiv-id": "1402.1151v1", 
    "author": "Andrzej Kasi\u0144ski", 
    "publish": "2014-02-05T20:18:26Z", 
    "summary": "The paper describes the image acquisition system able to capture images in\ntwo separated bands of light, used to underwater autonomous navigation. The\nchannels are: the visible light spectrum and near infrared spectrum. The\ncharacteristics of natural, underwater environment were also described together\nwith the process of the underwater image creation. The results of an experiment\nwith comparison of selected images acquired in these channels are discussed."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22312803/IJCTT-V7P144", 
    "link": "http://arxiv.org/pdf/1402.1331v1", 
    "other_authors": "Abhishek Bhattacharya, Tanusree Chatterjee", 
    "title": "An Estimation Method of Measuring Image Quality for Compressed Images of   Human Face", 
    "arxiv-id": "1402.1331v1", 
    "author": "Tanusree Chatterjee", 
    "publish": "2014-02-06T11:58:42Z", 
    "summary": "Nowadays digital image compression and decompression techniques are very much\nimportant. So our aim is to calculate the quality of face and other regions of\nthe compressed image with respect to the original image. Image segmentation is\ntypically used to locate objects and boundaries (lines, curves etc.)in images.\nAfter segmentation the image is changed into something which is more meaningful\nto analyze. Using Universal Image Quality Index(Q),Structural Similarity\nIndex(SSIM) and Gradient-based Structural Similarity Index(G-SSIM) it can be\nshown that face region is less compressed than any other region of the image."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1348v1", 
    "other_authors": "Deepak Ranjan Nayak, Sumit Kumar Sahu, Jahangir Mohammed", 
    "title": "A Cellular Automata based Optimal Edge Detection Technique using   Twenty-Five Neighborhood Model", 
    "arxiv-id": "1402.1348v1", 
    "author": "Jahangir Mohammed", 
    "publish": "2014-02-06T13:32:39Z", 
    "summary": "Cellular Automata (CA) are common and most simple models of parallel\ncomputations. Edge detection is one of the crucial task in image processing,\nespecially in processing biological and medical images. CA can be successfully\napplied in image processing. This paper presents a new method for edge\ndetection of binary images based on two dimensional twenty five neighborhood\ncellular automata. The method considers only linear rules of CA for extraction\nof edges under null boundary condition. The performance of this approach is\ncompared with some existing edge detection techniques. This comparison shows\nthat the proposed method to be very promising for edge detection of binary\nimages. All the algorithms and results used in this paper are prepared in\nMATLAB."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1359v1", 
    "other_authors": "Kai Berger, Jeyarajan Thiyagalingam", 
    "title": "Real-time Pedestrian Surveillance with Top View Cumulative Grids", 
    "arxiv-id": "1402.1359v1", 
    "author": "Jeyarajan Thiyagalingam", 
    "publish": "2014-02-06T14:09:25Z", 
    "summary": "This manuscript presents an efficient approach to map pedestrian surveillance\nfootage to an aerial view for global assessment of features. The analysis of\nthe footages relies on low level computer vision and enable real-time\nsurveillance. While we neglect object tracking, we introduce cumulative grids\non top view scene flow visualization to highlight situations of interest in the\nfootage. Our approach is tested on multiview footage both from RGB cameras and,\nfor the first time in the field, on RGB-D-sensors."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1371v1", 
    "other_authors": "David M. J. Tax, Veronika Cheplygina, Marco Loog", 
    "title": "Quantile Representation for Indirect Immunofluorescence Image   Classification", 
    "arxiv-id": "1402.1371v1", 
    "author": "Marco Loog", 
    "publish": "2014-02-06T14:56:55Z", 
    "summary": "In the diagnosis of autoimmune diseases, an important task is to classify\nimages of slides containing several HEp-2 cells. All cells from one slide share\nthe same label, and by classifying cells from one slide independently, some\ninformation on the global image quality and intensity is lost. Considering one\nwhole slide as a collection (a bag) of feature vectors, however, poses the\nproblem of how to handle this bag. A simple, and surprisingly effective,\napproach is to summarize the bag of feature vectors by a few quantile values\nper feature. This characterizes the full distribution of all instances, thereby\nassuming that all instances in a bag are informative. This representation is\nparticularly useful when each bag contains many feature vectors, which is the\ncase in the classification of the immunofluorescence images. Experiments on the\nclassification of indirect immunofluorescence images show the usefulness of\nthis approach."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1503v1", 
    "other_authors": "Omar Arif, Ganesh Sundaramoorthi, Byung-Woo Hong, Anthony Yezzi", 
    "title": "Tracking via Motion Estimation with Physically Motivated Inter-Region   Constraints", 
    "arxiv-id": "1402.1503v1", 
    "author": "Anthony Yezzi", 
    "publish": "2014-02-06T21:27:25Z", 
    "summary": "In this paper, we propose a method for tracking structures (e.g., ventricles\nand myocardium) in cardiac images (e.g., magnetic resonance) by propagating\nforward in time a previous estimate of the structures via a new deformation\nestimation scheme that is motivated by physical constraints of fluid motion.\nThe method employs within structure motion estimation (so that differing\nmotions among different structures are not mixed) while simultaneously\nsatisfying the physical constraint in fluid motion that at the interface\nbetween a fluid and a medium, the normal component of the fluid's motion must\nmatch the normal component of the motion of the medium. We show how to estimate\nthe motion according to the previous considerations in a variational framework,\nand in particular, show that these conditions lead to PDEs with boundary\nconditions at the interface that resemble Robin boundary conditions and induce\ncoupling between structures. We illustrate the use of this motion estimation\nscheme in propagating a segmentation across frames and show that it leads to\nmore accurate segmentation than traditional motion estimation that does not\nmake use of physical constraints. Further, the method is naturally suited to\ninteractive segmentation methods, which are prominently used in practice in\ncommercial applications for cardiac analysis, where typically a segmentation\nfrom the previous frame is used to predict a segmentation in the next frame. We\nshow that our propagation scheme reduces the amount of user interaction by\npredicting more accurate segmentations than commonly used and recent\ninteractive commercial techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14614-2869", 
    "link": "http://arxiv.org/pdf/1402.1879v1", 
    "other_authors": "Liansheng Zhuang, Tsung-Han Chan, Allen Y. Yang, S. Shankar Sastry, Yi Ma", 
    "title": "Sparse Illumination Learning and Transfer for Single-Sample Face   Recognition with Image Corruption and Misalignment", 
    "arxiv-id": "1402.1879v1", 
    "author": "Yi Ma", 
    "publish": "2014-02-08T18:46:28Z", 
    "summary": "Single-sample face recognition is one of the most challenging problems in\nface recognition. We propose a novel algorithm to address this problem based on\na sparse representation based classification (SRC) framework. The new algorithm\nis robust to image misalignment and pixel corruption, and is able to reduce\nrequired gallery images to one sample per class. To compensate for the missing\nillumination information traditionally provided by multiple gallery images, a\nsparse illumination learning and transfer (SILT) technique is introduced. The\nillumination in SILT is learned by fitting illumination examples of auxiliary\nface images from one or more additional subjects with a sparsely-used\nillumination dictionary. By enforcing a sparse representation of the query\nimage in the illumination dictionary, the SILT can effectively recover and\ntransfer the illumination and pose information from the alignment stage to the\nrecognition stage. Our extensive experiments have demonstrated that the new\nalgorithms significantly outperform the state of the art in the single-sample\nregime and with less restrictions. In particular, the single-sample face\nalignment accuracy is comparable to that of the well-known Deformable SRC\nalgorithm using multiple gallery images per class. Furthermore, the face\nrecognition accuracy exceeds those of the SRC and Extended SRC algorithms using\nhand labeled alignment initialization."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.1971v2", 
    "other_authors": "Mohammed Javed, P. Nagabhushan, B. B. Chaudhuri", 
    "title": "Direct Processing of Run Length Compressed Document Image for   Segmentation and Characterization of a Specified Block", 
    "arxiv-id": "1402.1971v2", 
    "author": "B. B. Chaudhuri", 
    "publish": "2014-02-09T18:01:12Z", 
    "summary": "Extracting a block of interest referred to as segmenting a specified block in\nan image and studying its characteristics is of general research interest, and\ncould be a challenging if such a segmentation task has to be carried out\ndirectly in a compressed image. This is the objective of the present research\nwork. The proposal is to evolve a method which would segment and extract a\nspecified block, and carry out its characterization without decompressing a\ncompressed image, for two major reasons that most of the image archives contain\nimages in compressed format and decompressing an image indents additional\ncomputing time and space. Specifically in this research work, the proposal is\nto work on run-length compressed document images."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2013v1", 
    "other_authors": "Xintong Yu, Xiaohan Liu, Yisong Chen", 
    "title": "Foreground segmentation based on multi-resolution and matting", 
    "arxiv-id": "1402.2013v1", 
    "author": "Yisong Chen", 
    "publish": "2014-02-10T01:22:35Z", 
    "summary": "We propose a foreground segmentation algorithm that does foreground\nextraction under different scales and refines the result by matting. First, the\ninput image is filtered and resampled to 5 different resolutions. Then each of\nthem is segmented by adaptive figure-ground classification and the best\nsegmentation is automatically selected by an evaluation score that maximizes\nthe difference between foreground and background. This segmentation is\nupsampled to the original size, and a corresponding trimap is built.\nClosed-form matting is employed to label the boundary region, and the result is\nrefined by a final figure-ground classification. Experiments show the success\nof our method in treating challenging images with cluttered background and\nadapting to loose initial bounding-box."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2016v2", 
    "other_authors": "Wenxi Liu, Antoni B. Chan, Rynson W. H. Lau, Dinesh Manocha", 
    "title": "Leveraging Long-Term Predictions and Online-Learning in Agent-based   Multiple Person Tracking", 
    "arxiv-id": "1402.2016v2", 
    "author": "Dinesh Manocha", 
    "publish": "2014-02-10T02:07:07Z", 
    "summary": "We present a multiple-person tracking algorithm, based on combining particle\nfilters and RVO, an agent-based crowd model that infers collision-free\nvelocities so as to predict pedestrian's motion. In addition to position and\nvelocity, our tracking algorithm can estimate the internal goals (desired\ndestination or desired velocity) of the tracked pedestrian in an online manner,\nthus removing the need to specify this information beforehand. Furthermore, we\nleverage the longer-term predictions of RVO by deriving a higher-order particle\nfilter, which aggregates multiple predictions from different prior time steps.\nThis yields a tracker that can recover from short-term occlusions and spurious\nnoise in the appearance model. Experimental results show that our tracking\nalgorithm is suitable for predicting pedestrians' behaviors online without\nneeding scene priors or hand-annotated goal information, and improves tracking\nin real-world crowded scenes under low frame rates."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2020v1", 
    "other_authors": "Kang Zhang, Jiyang Li, Yijing Li, Weidong Hu, Lifeng Sun, Shiqiang Yang", 
    "title": "Binary Stereo Matching", 
    "arxiv-id": "1402.2020v1", 
    "author": "Shiqiang Yang", 
    "publish": "2014-02-10T02:33:39Z", 
    "summary": "In this paper, we propose a novel binary-based cost computation and\naggregation approach for stereo matching problem. The cost volume is\nconstructed through bitwise operations on a series of binary strings. Then this\napproach is combined with traditional winner-take-all strategy, resulting in a\nnew local stereo matching algorithm called binary stereo matching (BSM). Since\ncore algorithm of BSM is based on binary and integer computations, it has a\nhigher computational efficiency than previous methods. Experimental results on\nMiddlebury benchmark show that BSM has comparable performance with\nstate-of-the-art local stereo methods in terms of both quality and speed.\nFurthermore, experiments on images with radiometric differences demonstrate\nthat BSM is more robust than previous methods under these changes, which is\ncommon under real illumination."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2188v1", 
    "other_authors": "Anitha Mary M. O. Chacko, P. M Dhanya", 
    "title": "Handwritten Character Recognition In Malayalam Scripts- A Review", 
    "arxiv-id": "1402.2188v1", 
    "author": "P. M Dhanya", 
    "publish": "2014-02-10T15:41:48Z", 
    "summary": "Handwritten character recognition is one of the most challenging and ongoing\nareas of research in the field of pattern recognition. HCR research is matured\nfor foreign languages like Chinese and Japanese but the problem is much more\ncomplex for Indian languages. The problem becomes even more complicated for\nSouth Indian languages due to its large character set and the presence of\nvowels modifiers and compound characters. This paper provides an overview of\nimportant contributions and advances in offline as well as online handwritten\ncharacter recognition of Malayalam scripts."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2426v1", 
    "other_authors": "Keith Dillon, Yeshaiahu Fainman", 
    "title": "Imaging with Rays: Microscopy, Medical Imaging, and Computer Vision", 
    "arxiv-id": "1402.2426v1", 
    "author": "Yeshaiahu Fainman", 
    "publish": "2014-02-11T10:26:31Z", 
    "summary": "In this paper we broadly consider techniques which utilize projections on\nrays for data collection, with particular emphasis on optical techniques. We\nformulate a variety of imaging techniques as either special cases or extensions\nof tomographic reconstruction. We then consider how the techniques must be\nextended to describe objects containing occlusion, as with a self-occluding\nopaque object. We formulate the reconstruction problem as a regularized\nnonlinear optimization problem to simultaneously solve for object brightness\nand attenuation, where the attenuation can become infinite. We demonstrate\nvarious simulated examples for imaging opaque objects, including sparse point\nsources, a conventional multiview reconstruction technique, and a\nsuper-resolving technique which exploits occlusion to resolve an image."
},{
    "category": "cs.CV", 
    "doi": "10.5120/14521-2926", 
    "link": "http://arxiv.org/pdf/1402.2606v1", 
    "other_authors": "Dibyendu Mukherjee", 
    "title": "A Fast Two Pass Multi-Value Segmentation Algorithm based on Connected   Component Analysis", 
    "arxiv-id": "1402.2606v1", 
    "author": "Dibyendu Mukherjee", 
    "publish": "2014-02-11T19:27:05Z", 
    "summary": "Connected component analysis (CCA) has been heavily used to label binary\nimages and classify segments. However, it has not been well-exploited to\nsegment multi-valued natural images. This work proposes a novel multi-value\nsegmentation algorithm that utilizes CCA to segment color images. A user\ndefined distance measure is incorporated in the proposed modified CCA to\nidentify and segment similar image regions. The raw output of the algorithm\nconsists of distinctly labelled segmented regions. The proposed algorithm has a\nunique design architecture that provides several benefits: 1) it can be used to\nsegment any multi-channel multi-valued image; 2) the distance\nmeasure/segmentation criteria can be application-specific and 3) an absolute\nlinear-time implementation allows easy extension for real-time video\nsegmentation. Experimental demonstrations of the aforesaid benefits are\npresented along with the comparison results on multiple datasets with current\nbenchmark algorithms. A number of possible application areas are also\nidentified and results on real-time video segmentation has been presented to\nshow the promise of the proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2673v1", 
    "other_authors": "Jakub Nalepa, Michal Kawulok", 
    "title": "Real-Time Hand Shape Classification", 
    "arxiv-id": "1402.2673v1", 
    "author": "Michal Kawulok", 
    "publish": "2014-02-11T21:32:48Z", 
    "summary": "The problem of hand shape classification is challenging since a hand is\ncharacterized by a large number of degrees of freedom. Numerous shape\ndescriptors have been proposed and applied over the years to estimate and\nclassify hand poses in reasonable time. In this paper we discuss our parallel\nframework for real-time hand shape classification applicable in real-time\napplications. We show how the number of gallery images influences the\nclassification accuracy and execution time of the parallel algorithm. We\npresent the speedup and efficiency analyses that prove the efficacy of the\nparallel implementation. Noteworthy, different methods can be used at each step\nof our parallel framework. Here, we combine the shape contexts with the\nappearance-based techniques to enhance the robustness of the algorithm and to\nincrease the classification score. An extensive experimental study proves the\nsuperiority of the proposed approach over existing state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2681v2", 
    "other_authors": "Liang Zheng, Shengjin Wang, Ziqiong Liu, Qi Tian", 
    "title": "Packing and Padding: Coupled Multi-index for Accurate Image Retrieval", 
    "arxiv-id": "1402.2681v2", 
    "author": "Qi Tian", 
    "publish": "2014-02-11T22:00:31Z", 
    "summary": "In Bag-of-Words (BoW) based image retrieval, the SIFT visual word has a low\ndiscriminative power, so false positive matches occur prevalently. Apart from\nthe information loss during quantization, another cause is that the SIFT\nfeature only describes the local gradient distribution. To address this\nproblem, this paper proposes a coupled Multi-Index (c-MI) framework to perform\nfeature fusion at indexing level. Basically, complementary features are coupled\ninto a multi-dimensional inverted index. Each dimension of c-MI corresponds to\none kind of feature, and the retrieval process votes for images similar in both\nSIFT and other feature spaces. Specifically, we exploit the fusion of local\ncolor feature into c-MI. While the precision of visual match is greatly\nenhanced, we adopt Multiple Assignment to improve recall. The joint cooperation\nof SIFT and color features significantly reduces the impact of false positive\nmatches.\n  Extensive experiments on several benchmark datasets demonstrate that c-MI\nimproves the retrieval accuracy significantly, while consuming only half of the\nquery time compared to the baseline. Importantly, we show that c-MI is well\ncomplementary to many prior techniques. Assembling these methods, we have\nobtained an mAP of 85.8% and N-S score of 3.85 on Holidays and Ukbench\ndatasets, respectively, which compare favorably with the state-of-the-arts."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2720v1", 
    "other_authors": "Hong Jiang, Gang Huang, Paul Wilford", 
    "title": "Noise Analysis for Lensless Compressive Imaging", 
    "arxiv-id": "1402.2720v1", 
    "author": "Paul Wilford", 
    "publish": "2014-02-12T03:12:40Z", 
    "summary": "We analyze the signal to noise ratio (SNR) in a recently proposed lensless\ncompressive imaging architecture. The architecture consists of a sensor of a\nsingle detector element and an aperture assembly of an array of aperture\nelements, each of which has a programmable transmittance. This lensless\ncompressive imaging architecture can be used in conjunction with compressive\nsensing to capture images in a compressed form of compressive measurements. In\nthis paper, we perform noise analysis of this lensless compressive imaging\narchitecture and compare it with pinhole aperture imaging and lens aperture\nimaging. We will show that the SNR in the lensless compressive imaging is\nindependent of the image resolution, while that in either pinhole aperture\nimaging or lens aperture imaging decreases as the image resolution increases.\nConsequently, the SNR in the lensless compressive imaging can be much higher if\nthe image resolution is large enough."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2826v1", 
    "other_authors": "Aniket Bera, Dinesh Manocha", 
    "title": "Realtime Multilevel Crowd Tracking using Reciprocal Velocity Obstacles", 
    "arxiv-id": "1402.2826v1", 
    "author": "Dinesh Manocha", 
    "publish": "2014-02-11T15:49:53Z", 
    "summary": "We present a novel, realtime algorithm to compute the trajectory of each\npedestrian in moderately dense crowd scenes. Our formulation is based on an\nadaptive particle filtering scheme that uses a multi-agent motion model based\non velocity-obstacles, and takes into account local interactions as well as\nphysical and personal constraints of each pedestrian. Our method dynamically\nchanges the number of particles allocated to each pedestrian based on different\nconfidence metrics. Additionally, we use a new high-definition crowd video\ndataset, which is used to evaluate the performance of different pedestrian\ntracking algorithms. This dataset consists of videos of indoor and outdoor\nscenes, recorded at different locations with 30-80 pedestrians. We highlight\nthe performance benefits of our algorithm over prior techniques using this\ndataset. In practice, our algorithm can compute trajectories of tens of\npedestrians on a multi-core desktop CPU at interactive rates (27-30 frames per\nsecond). To the best of our knowledge, our approach is 4-5 times faster than\nprior methods, which provide similar accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.2941v1", 
    "other_authors": "Zohaib Khan, Faisal Shafait, Yiqun Hu, Ajmal Mian", 
    "title": "Multispectral Palmprint Encoding and Recognition", 
    "arxiv-id": "1402.2941v1", 
    "author": "Ajmal Mian", 
    "publish": "2014-02-06T06:35:51Z", 
    "summary": "Palmprints are emerging as a new entity in multi-modal biometrics for human\nidentification and verification. Multispectral palmprint images captured in the\nvisible and infrared spectrum not only contain the wrinkles and ridge structure\nof a palm, but also the underlying pattern of veins; making them a highly\ndiscriminating biometric identifier. In this paper, we propose a feature\nencoding scheme for robust and highly accurate representation and matching of\nmultispectral palmprints. To facilitate compact storage of the feature, we\ndesign a binary hash table structure that allows for efficient matching in\nlarge databases. Comprehensive experiments for both identification and\nverification scenarios are performed on two public datasets -- one captured\nwith a contact-based sensor (PolyU dataset), and the other with a contact-free\nsensor (CASIA dataset). Recognition results in various experimental setups show\nthat the proposed method consistently outperforms existing state-of-the-art\nmethods. Error rates achieved by our method (0.003% on PolyU and 0.2% on CASIA)\nare the lowest reported in literature on both dataset and clearly indicate the\nviability of palmprint as a reliable and promising biometric. All source codes\nare publicly available."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.3557v1", 
    "other_authors": "Subarna Tripathi, Youngbae Hwang, Serge Belongie, Truong Nguyen", 
    "title": "Improving Streaming Video Segmentation with Early and Mid-Level Visual   Processing", 
    "arxiv-id": "1402.3557v1", 
    "author": "Truong Nguyen", 
    "publish": "2014-02-14T19:37:35Z", 
    "summary": "Despite recent advances in video segmentation, many opportunities remain to\nimprove it using a variety of low and mid-level visual cues. We propose\nimprovements to the leading streaming graph-based hierarchical video\nsegmentation (streamGBH) method based on early and mid level visual processing.\nThe extensive experimental analysis of our approach validates the improvement\nof hierarchical supervoxel representation by incorporating motion and color\nwith effective filtering. We also pose and illuminate some open questions\ntowards intermediate level video analysis as further extension to streamGBH. We\nexploit the supervoxels as an initialization towards estimation of dominant\naffine motion regions, followed by merging of such motion regions in order to\nhierarchically segment a video in a novel motion-segmentation framework which\naims at subsequent applications such as foreground recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.3869v2", 
    "other_authors": "Yilun Wang", 
    "title": "FTVd is beyond Fast Total Variation regularized Deconvolution", 
    "arxiv-id": "1402.3869v2", 
    "author": "Yilun Wang", 
    "publish": "2014-02-17T02:13:30Z", 
    "summary": "In this paper, we revisit the \"FTVd\" algorithm for Fast Total Variation\nRegularized Deconvolution, which has been widely used in the past few years.\nBoth its original version implemented in the MATLAB software FTVd 3.0 and its\nrelated variant implemented in the latter version FTVd 4.0 are considered\n\\cite{Wang08FTVdsoftware}. We propose that the intermediate results during the\niterations are the solutions of a series of combined Tikhonov and total\nvariation regularized image deconvolution models and therefore some of them\noften have even better image quality than the final solution, which is\ncorresponding to the pure total variation regularized model."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.3926v1", 
    "other_authors": "Toshiyuki Kato, Hideitsu Hino, Noboru Murata", 
    "title": "Sparse Coding Approach for Multi-Frame Image Super Resolution", 
    "arxiv-id": "1402.3926v1", 
    "author": "Noboru Murata", 
    "publish": "2014-02-17T08:23:35Z", 
    "summary": "An image super-resolution method from multiple observation of low-resolution\nimages is proposed. The method is based on sub-pixel accuracy block matching\nfor estimating relative displacements of observed images, and sparse signal\nrepresentation for estimating the corresponding high-resolution image. Relative\ndisplacements of small patches of observed low-resolution images are accurately\nestimated by a computationally efficient block matching method. Since the\nestimated displacements are also regarded as a warping component of image\ndegradation process, the matching results are directly utilized to generate\nlow-resolution dictionary for sparse image representation. The matching scores\nof the block matching are used to select a subset of low-resolution patches for\nreconstructing a high-resolution patch, that is, an adaptive selection of\ninformative low-resolution images is realized. When there is only one\nlow-resolution image, the proposed method works as a single-frame\nsuper-resolution method. The proposed method is shown to perform comparable or\nsuperior to conventional single- and multi-frame super-resolution methods\nthrough experiments using various real-world datasets."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4067v1", 
    "other_authors": "Santiago Aja-Fernandez, Gonzalo Vegas-Sanchez-Ferrero, Antonio Trsitan-Vega", 
    "title": "Statistical Noise Analysis in SENSE Parallel MRI", 
    "arxiv-id": "1402.4067v1", 
    "author": "Antonio Trsitan-Vega", 
    "publish": "2014-02-17T17:16:21Z", 
    "summary": "A complete first and second order statistical characterization of noise in\nSENSE reconstructed data is proposed. SENSE acquisitions have usually been\nmodeled as Rician distributed, since the data reconstruction takes place into\nthe spatial domain, where Gaussian noise is assumed. However, this model just\nholds for the first order statistics and obviates other effects induced by\ncoils correlations and the reconstruction interpolation. Those effects are\nproperly taken into account in this study, in order to fully justify a final\nSENSE noise model. As a result, some interesting features of the reconstructed\nimage arise: (1) There is a strong correlation between adjacent lines. (2) The\nresulting distribution is non-stationary and therefore the variance of noise\nwill vary from point to point across the image. Closed equations for the\ncalculation of the variance of noise and the correlation coefficient between\nlines are proposed. The proposed model is totally compatible with g-factor\nformulations."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4069v2", 
    "other_authors": "Yasel Garc\u00e9s, Esley Torres, Osvaldo Pereira, Roberto Rodr\u00edguez", 
    "title": "Application of the Ring Theory in the Segmentation of Digital Images", 
    "arxiv-id": "1402.4069v2", 
    "author": "Roberto Rodr\u00edguez", 
    "publish": "2014-02-17T17:16:35Z", 
    "summary": "Ring theory is one of the branches of the abstract algebra that has been\nbroadly used in images. However, ring theory has not been very related with\nimage segmentation. In this paper, we propose a new index of similarity among\nimages using Zn rings and the entropy function. This new index was applied as a\nnew stopping criterion to the Mean Shift Iterative Algorithm with the goal to\nreach a better segmentation. An analysis on the performance of the algorithm\nwith this new stopping criterion is carried out. The obtained results proved\nthat the new index is a suitable tool to compare images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4388v1", 
    "other_authors": "Mohammed Javed, P. Nagabhushan, B. B. Chaudhuri", 
    "title": "Automatic Detection of Font Size Straight from Run Length Compressed   Text Documents", 
    "arxiv-id": "1402.4388v1", 
    "author": "B. B. Chaudhuri", 
    "publish": "2014-02-18T16:30:59Z", 
    "summary": "Automatic detection of font size finds many applications in the area of\nintelligent OCRing and document image analysis, which has been traditionally\npracticed over uncompressed documents, although in real life the documents\nexist in compressed form for efficient storage and transmission. It would be\nnovel and intelligent if the task of font size detection could be carried out\ndirectly from the compressed data of these documents without decompressing,\nwhich would result in saving of considerable amount of processing time and\nspace. Therefore, in this paper we present a novel idea of learning and\ndetecting font size directly from run-length compressed text documents at line\nlevel using simple line height features, which paves the way for intelligent\nOCRing and document analysis directly from compressed documents. In the\nproposed model, the given mixed-case text documents of different font size are\nsegmented into compressed text lines and the features extracted such as line\nheight and ascender height are used to capture the pattern of font size in the\nform of a regression line, using which the automatic detection of font size is\ndone during the recognition stage. The method is experimented with a dataset of\n50 compressed documents consisting of 780 text lines of single font size and\n375 text lines of mixed font size resulting in an overall accuracy of 99.67%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4936v1", 
    "other_authors": "Amira Mohammad Abdel-Mawgoud Saleh", 
    "title": "Enhanced Secure Algorithm for Fingerprint Recognition", 
    "arxiv-id": "1402.4936v1", 
    "author": "Amira Mohammad Abdel-Mawgoud Saleh", 
    "publish": "2014-02-20T09:19:17Z", 
    "summary": "Fingerprint recognition requires a minimal effort from the user, does not\ncapture other information than strictly necessary for the recognition process,\nand provides relatively good performance. A critical step in fingerprint\nidentification system is thinning of the input fingerprint image. The\nperformance of a minutiae extraction algorithm relies heavily on the quality of\nthe thinning algorithm. So, a fast fingerprint thinning algorithm is proposed.\nThe algorithm works directly on the gray-scale image as binarization of\nfingerprint causes many spurious minutiae and also removes many important\nfeatures. The performance of the thinning algorithm is evaluated and\nexperimental results show that the proposed thinning algorithm is both fast and\naccurate. A new minutiae-based fingerprint matching technique is proposed. The\nmain idea is that each fingerprint is represented by a minutiae table of just\ntwo columns in the database. The number of different minutiae types\n(terminations and bifurcations) found in each track of a certain width around\nthe core point of the fingerprint is recorded in this table. Each row in the\ntable represents a certain track, in the first column, the number of\nterminations in each track is recorded, in the second column, the number of\nbifurcations in each track is recorded. The algorithm is rotation and\ntranslation invariant, and needs less storage size. Experimental results show\nthat recognition accuracy is 98%, with Equal Error Rate (EER) of 2%. Finally,\nthe integrity of the data transmission via communication channels must be\nsecure all the way from the scanner to the application. After applying Gaussian\nnoise addition, and JPEG compression with high and moderate quality factors on\nthe watermarked fingerprint images, recognition accuracy decreases slightly to\nreach 96%."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-06932-6_35", 
    "link": "http://arxiv.org/pdf/1402.4963v4", 
    "other_authors": "Julius Hannink, Remco Duits, Erik Bekkers", 
    "title": "Vesselness via Multiple Scale Orientation Scores", 
    "arxiv-id": "1402.4963v4", 
    "author": "Erik Bekkers", 
    "publish": "2014-02-20T11:06:35Z", 
    "summary": "The multi-scale Frangi vesselness filter is an established tool in (retinal)\nvascular imaging. However, it cannot cope with crossings or bifurcations, since\nit only looks for elongated structures. Therefore, we disentangle crossing\nstructures in the image via (multiple scale) invertible orientation scores. The\ndescribed vesselness filter via scale-orientation scores performs considerably\nbetter at enhancing vessels throughout crossings and bifurcations than the\nFrangi version. Both methods are evaluated on a public dataset. Performance is\nmeasured by comparing ground truth data to the segmentation results obtained by\nbasic thresholding and morphological component analysis of the filtered images."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.aeue.2014.10.022", 
    "link": "http://arxiv.org/pdf/1402.5564v3", 
    "other_authors": "Ahmadreza Baghaie, Zeyun Yu", 
    "title": "Structure Tensor Based Image Interpolation Method", 
    "arxiv-id": "1402.5564v3", 
    "author": "Zeyun Yu", 
    "publish": "2014-02-22T23:58:11Z", 
    "summary": "Feature preserving image interpolation is an active area in image processing\nfield. In this paper a new direct edge directed image super-resolution\nalgorithm based on structure tensors is proposed. Using an isotropic Gaussian\nfilter, the structure tensor at each pixel of the input image is computed and\nthe pixels are classified to three distinct classes; uniform region, corners\nand edges, according to the eigenvalues of the structure tensor. Due to\napplication of the isotropic Gaussian filter, the classification is robust to\nnoise presented in image. Based on the tangent eigenvector of the structure\ntensor, the edge direction is determined and used for interpolation along the\nedges. In comparison to some previous edge directed image interpolation\nmethods, the proposed method achieves higher quality in both subjective and\nobjective aspects. Also the proposed method outperforms previous methods in\ncase of noisy and JPEG compressed images. Furthermore, without the need for\noptimization in the process, the algorithm can achieve higher speed."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.aeue.2014.10.022", 
    "link": "http://arxiv.org/pdf/1402.5619v1", 
    "other_authors": "V. Karthikeyan", 
    "title": "A Novel Histogram Based Robust Image Registration Technique", 
    "arxiv-id": "1402.5619v1", 
    "author": "V. Karthikeyan", 
    "publish": "2014-02-23T15:24:27Z", 
    "summary": "In this paper, a method for Automatic Image Registration (AIR) through\nhistogram is proposed. Automatic image registration is one of the crucial steps\nin the analysis of remotely sensed data. A new acquired image must be\ntransformed, using image registration techniques, to match the orientation and\nscale of previous related images. This new approach combines several\nsegmentations of the pair of images to be registered. A relaxation parameter on\nthe histogram modes delineation is introduced. It is followed by\ncharacterization of the extracted objects through the objects area, axis ratio,\nand perimeter and fractal dimension. The matched objects are used for rotation\nand translation estimation. It allows for the registration of pairs of images\nwith differences in rotation and translation. This method contributes to\nsubpixel accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.aeue.2014.10.022", 
    "link": "http://arxiv.org/pdf/1402.5623v1", 
    "other_authors": "V. Karthikeyan, V. J. Vijayalakshmi", 
    "title": "Localization of License Plate Using Morphological Operations", 
    "arxiv-id": "1402.5623v1", 
    "author": "V. J. Vijayalakshmi", 
    "publish": "2014-02-23T16:08:09Z", 
    "summary": "It is believed that there are currently millions of vehicles on the roads\nworldwide. The over speed of vehicles,theft of vehicles, disobeying traffic\nrules in public, an unauthorized person entering the restricted area are keep\non increasing. In order restrict against these criminal activities, we need an\nautomatic public security system. Each vehicle has their own Vehicle\nIdentification Number (VIN) as their primary identifier. The VIN is actually a\nLicense Number which states a legal license to participate in the public\ntraffic. The proposed paper is to identify the vehicle with the help of\nvehicles License Plate (LP).LPRS is one the most important part of the\nIntelligent Transportation System (ITS) to locate the LP. In this paper certain\nexisting algorithm drawbacks are overcome by the proposed morphological\noperations for LPRS. Morphological operation is chosen due to its higher\nefficiency, noise filter capacity, accuracy, exact localization of LP and\nspeed."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2014.7025077", 
    "link": "http://arxiv.org/pdf/1402.5697v1", 
    "other_authors": "Changxin Gao, Feifei Chen, Jin-Gang Yu, Rui Huang, Nong Sang", 
    "title": "Exemplar-based Linear Discriminant Analysis for Robust Object Tracking", 
    "arxiv-id": "1402.5697v1", 
    "author": "Nong Sang", 
    "publish": "2014-02-24T01:10:09Z", 
    "summary": "Tracking-by-detection has become an attractive tracking technique, which\ntreats tracking as a category detection problem. However, the task in tracking\nis to search for a specific object, rather than an object category as in\ndetection. In this paper, we propose a novel tracking framework based on\nexemplar detector rather than category detector. The proposed tracker is an\nensemble of exemplar-based linear discriminant analysis (ELDA) detectors. Each\ndetector is quite specific and discriminative, because it is trained by a\nsingle object instance and massive negatives. To improve its adaptivity, we\nupdate both object and background models. Experimental results on several\nchallenging video sequences demonstrate the effectiveness and robustness of our\ntracking algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICIP.2014.7025077", 
    "link": "http://arxiv.org/pdf/1402.5792v3", 
    "other_authors": "Seyed Mostafa Kia, Hossein Rahmani, Reza Mortezaei, Mohsen Ebrahimi Moghaddam, Amer Namazi", 
    "title": "A Novel Scheme for Intelligent Recognition of Pornographic Images", 
    "arxiv-id": "1402.5792v3", 
    "author": "Amer Namazi", 
    "publish": "2014-02-24T11:15:04Z", 
    "summary": "Harmful contents are rising in internet day by day and this motivates the\nessence of more research in fast and reliable obscene and immoral material\nfiltering. Pornographic image recognition is an important component in each\nfiltering system. In this paper, a new approach for detecting pornographic\nimages is introduced. In this approach, two new features are suggested. These\ntwo features in combination with other simple traditional features provide\ndecent difference between porn and non-porn images. In addition, we applied\nfuzzy integral based information fusion to combine MLP (Multi-Layer Perceptron)\nand NF (Neuro-Fuzzy) outputs. To test the proposed method, performance of\nsystem was evaluated over 18354 download images from internet. The attained\nprecision was 93% in TP and 8% in FP on training dataset, and 87% and 5.5% on\ntest dataset. Achieved results verify the performance of proposed system versus\nother related works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4221", 
    "link": "http://arxiv.org/pdf/1402.5805v1", 
    "other_authors": "Eric Hitimana, Oubong Gwun", 
    "title": "Automatic Estimation of Live Coffee Leaf Infection based on Image   Processing Techniques", 
    "arxiv-id": "1402.5805v1", 
    "author": "Oubong Gwun", 
    "publish": "2014-02-24T12:06:40Z", 
    "summary": "Image segmentation is the most challenging issue in computer vision\napplications. And most difficulties for crops management in agriculture are the\nlack of appropriate methods for detecting the leaf damage for pests treatment.\nIn this paper we proposed an automatic method for leaf damage detection and\nseverity estimation of coffee leaf by avoiding defoliation. After enhancing the\ncontrast of the original image using LUT based gamma correction, the image is\nprocessed to remove the background, and the output leaf is clustered using\nFuzzy c-means segmentation in V channel of YUV color space to maximize all leaf\ndamage detection, and finally, the severity of leaf is estimated in terms of\nratio for leaf pixel distribution between the normal and the detected leaf\ndamage. The results in each proposed method was compared to the current\nresearches and the accuracy is obvious either in the background removal or\ndamage detection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4221", 
    "link": "http://arxiv.org/pdf/1402.5859v1", 
    "other_authors": "Huanguo Zhang, Sha Lv, Wei Li, Xun Qu", 
    "title": "A Novel Face Recognition Method using Nearest Line Projection", 
    "arxiv-id": "1402.5859v1", 
    "author": "Xun Qu", 
    "publish": "2014-02-24T15:36:32Z", 
    "summary": "Face recognition is a popular application of pat- tern recognition methods,\nand it faces challenging problems including illumination, expression, and pose.\nThe most popular way is to learn the subspaces of the face images so that it\ncould be project to another discriminant space where images of different\npersons can be separated. In this paper, a nearest line projection algorithm is\ndeveloped to represent the face images for face recognition. Instead of\nprojecting an image to its nearest image, we try to project it to its nearest\nline spanned by two different face images. The subspaces are learned so that\neach face image to its nearest line is minimized. We evaluated the proposed\nalgorithm on some benchmark face image database, and also compared it to some\nother image projection algorithms. The experiment results showed that the\nproposed algorithm outperforms other ones."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4221", 
    "link": "http://arxiv.org/pdf/1402.5923v1", 
    "other_authors": "Tatiana Tommasi, Tinne Tuytelaars, Barbara Caputo", 
    "title": "A Testbed for Cross-Dataset Analysis", 
    "arxiv-id": "1402.5923v1", 
    "author": "Barbara Caputo", 
    "publish": "2014-02-24T19:25:17Z", 
    "summary": "Since its beginning visual recognition research has tried to capture the huge\nvariability of the visual world in several image collections. The number of\navailable datasets is still progressively growing together with the amount of\nsamples per object category. However, this trend does not correspond directly\nto an increasing in the generalization capabilities of the developed\nrecognition systems. Each collection tends to have its specific characteristics\nand to cover just some aspects of the visual world: these biases often narrow\nthe effect of the methods defined and tested separately over each image set.\nOur work makes a first step towards the analysis of the dataset bias problem on\na large scale. We organize twelve existing databases in a unique corpus and we\npresent the visual community with a useful feature repository for future\nresearch."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6383v1", 
    "other_authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel", 
    "title": "Large-margin Learning of Compact Binary Image Encodings", 
    "arxiv-id": "1402.6383v1", 
    "author": "Anton van den Hengel", 
    "publish": "2014-02-26T00:22:50Z", 
    "summary": "The use of high-dimensional features has become a normal practice in many\ncomputer vision applications. The large dimension of these features is a\nlimiting factor upon the number of data points which may be effectively stored\nand processed, however. We address this problem by developing a novel approach\nto learning a compact binary encoding, which exploits both pair-wise proximity\nand class-label information on training data set. Exploiting this extra\ninformation allows the development of encodings which, although compact,\noutperform the original high-dimensional features in terms of final\nclassification or retrieval performance. The method is general, in that it is\napplicable to both non-parametric and parametric learning methods. This\ngenerality means that the embedded features are suitable for a wide variety of\ncomputer vision tasks, such as image classification and content-based image\nretrieval. Experimental results demonstrate that the new compact descriptor\nachieves an accuracy comparable to, and in some cases better than, the visual\ndescriptor in the original space despite being significantly more compact.\nMoreover, any convex loss function and convex regularization penalty (e.g., $\n\\ell_p $ norm with $ p \\ge 1 $) can be incorporated into the framework, which\nprovides future flexibility."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6387v1", 
    "other_authors": "Jen Hong Tan, U. Rajendra Acharya", 
    "title": "Active spline model: A shape based model-interactive segmentation", 
    "arxiv-id": "1402.6387v1", 
    "author": "U. Rajendra Acharya", 
    "publish": "2014-02-26T01:32:48Z", 
    "summary": "Rarely in literature a method of segmentation cares for the edit after the\nalgorithm delivers. They provide no solution when segmentation goes wrong. We\npropose to formulate point distribution model in terms of\ncentripetal-parameterized Catmull-Rom spline. Such fusion brings interactivity\nto model-based segmentation, so that edit is better handled. When the delivered\nsegment is unsatisfactory, user simply shifts points to vary the curve. We ran\nthe method on three disparate imaging modalities and achieved an average\noverlap of 0.879 for automated lung segmentation on chest radiographs. The edit\nafterward improved the average overlap to 0.945, with a minimum of 0.925. The\nsource code and the demo video are available at http://wp.me/p3vCKy-2S"
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6416v1", 
    "other_authors": "Anton van den Hengel, John Bastian, Anthony Dick, Lachlan Fleming", 
    "title": "Deconstruction of compound objects from image sets", 
    "arxiv-id": "1402.6416v1", 
    "author": "Lachlan Fleming", 
    "publish": "2014-02-26T05:37:41Z", 
    "summary": "We propose a method to recover the structure of a compound object from\nmultiple silhouettes. Structure is expressed as a collection of 3D primitives\nchosen from a pre-defined library, each with an associated pose. This has\nseveral advantages over a volume or mesh representation both for estimation and\nthe utility of the recovered model. The main challenge in recovering such a\nmodel is the combinatorial number of possible arrangements of parts. We address\nthis issue by exploiting the sparse nature of the problem, and show that our\nmethod scales to objects constructed from large libraries of parts."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6650v1", 
    "other_authors": "Ahmed Sahlol, Cheng Suen", 
    "title": "A Novel Method for the Recognition of Isolated Handwritten Arabic   Characters", 
    "arxiv-id": "1402.6650v1", 
    "author": "Cheng Suen", 
    "publish": "2014-02-26T19:09:09Z", 
    "summary": "There are many difficulties facing a handwritten Arabic recognition system\nsuch as unlimited variation in human handwriting, similarities of distinct\ncharacter shapes, interconnections of neighbouring characters and their\nposition in the word. The typical Optical Character Recognition (OCR) systems\nare based mainly on three stages, preprocessing, features extraction and\nrecognition. This paper proposes new methods for handwritten Arabic character\nrecognition which is based on novel preprocessing operations including\ndifferent kinds of noise removal also different kind of features like\nstructural, Statistical and Morphological features from the main body of the\ncharacter and also from the secondary components. Evaluation of the accuracy of\nthe selected features is made. The system was trained and tested by back\npropagation neural network with CENPRMI dataset. The proposed algorithm\nobtained promising results as it is able to recognize 88% of our test set\naccurately. In Comparable with other related works we find that our result is\nthe highest among other published works."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2014.2337759", 
    "link": "http://arxiv.org/pdf/1402.6932v1", 
    "other_authors": "Xin Yuan, Patrick Llull, Xuejun Liao, Jianbo Yang, Guillermo Sapiro, David J. Brady, Lawrence Carin", 
    "title": "Low-Cost Compressive Sensing for Color Video and Depth", 
    "arxiv-id": "1402.6932v1", 
    "author": "Lawrence Carin", 
    "publish": "2014-02-27T15:15:43Z", 
    "summary": "A simple and inexpensive (low-power and low-bandwidth) modification is made\nto a conventional off-the-shelf color video camera, from which we recover\n{multiple} color frames for each of the original measured frames, and each of\nthe recovered frames can be focused at a different depth. The recovery of\nmultiple frames for each measured frame is made possible via high-speed coding,\nmanifested via translation of a single coded aperture; the inexpensive\ntranslation is constituted by mounting the binary code on a piezoelectric\ndevice. To simultaneously recover depth information, a {liquid} lens is\nmodulated at high speed, via a variable voltage. Consequently, during the\naforementioned coding process, the liquid lens allows the camera to sweep the\nfocus through multiple depths. In addition to designing and implementing the\ncamera, fast recovery is achieved by an anytime algorithm exploiting the\ngroup-sparsity of wavelet/DCT coefficients."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1402.7162v1", 
    "other_authors": "Hamdi Yalin Yalic", 
    "title": "Visual Saliency Model using SIFT and Comparison of Learning Approaches", 
    "arxiv-id": "1402.7162v1", 
    "author": "Hamdi Yalin Yalic", 
    "publish": "2014-02-28T08:33:17Z", 
    "summary": "Humans' ability to detect and locate salient objects on images is remarkably\nfast and successful. Performing this process by using eye tracking equipment is\nexpensive and cannot be easily applied, and computer modeling of this human\nbehavior is still a problem to be solved. In our study, one of the largest\npublic eye-tracking databases which has fixation points of 15 observers on 1003\nimages is used. In addition to low, medium and high-level features which have\nbeen used in previous studies, SIFT features extracted from the images are used\nto improve the classification accuracy of the models. A second contribution of\nthis paper is the comparison and statistical analysis of different machine\nlearning methods that can be used to train our model. As a result, a best\nfeature set and learning model to predict where humans look at images, is\ndetermined."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0085v1", 
    "other_authors": "Nitin Bhatia, Vandana", 
    "title": "Survey of Nearest Neighbor Techniques", 
    "arxiv-id": "1007.0085v1", 
    "author": "Vandana", 
    "publish": "2010-07-01T06:53:50Z", 
    "summary": "The nearest neighbor (NN) technique is very simple, highly efficient and\neffective in the field of pattern recognition, text categorization, object\nrecognition etc. Its simplicity is its main advantage, but the disadvantages\ncan't be ignored even. The memory requirement and computation complexity also\nmatter. Many techniques are developed to overcome these limitations. NN\ntechniques are broadly classified into structure less and structure based\ntechniques. In this paper, we present the survey of such techniques. Weighted\nkNN, Model based kNN, Condensed NN, Reduced NN, Generalized NN are structure\nless techniques whereas k-d tree, ball tree, Principal Axis Tree, Nearest\nFeature Line, Tunable NN, Orthogonal Search Tree are structure based algorithms\ndeveloped on the basis of kNN. The structure less method overcome memory\nlimitation and structure based techniques reduce the computational complexity."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0313v1", 
    "other_authors": "Duc Phu Chau, Francois Bremond, Etienne Corvee, Monique Thonnat", 
    "title": "Repairing People Trajectories Based on Point Clustering", 
    "arxiv-id": "1007.0313v1", 
    "author": "Monique Thonnat", 
    "publish": "2010-07-02T07:50:03Z", 
    "summary": "This paper presents a method for improving any object tracking algorithm\nbased on machine learning. During the training phase, important trajectory\nfeatures are extracted which are then used to calculate a confidence value of\ntrajectory. The positions at which objects are usually lost and found are\nclustered in order to construct the set of 'lost zones' and 'found zones' in\nthe scene. Using these zones, we construct a triplet set of zones i.e. three\nzones: In/Out zone (zone where an object can enter or exit the scene), 'lost\nzone' and 'found zone'. Thanks to these triplets, during the testing phase, we\ncan repair the erroneous trajectories according to which triplet they are most\nlikely to belong to. The advantage of our approach over the existing state of\nthe art approaches is that (i) this method does not depend on a predefined\ncontextual scene, (ii) we exploit the semantic of the scene and (iii) we have\nproposed a method to filter out noisy trajectories based on their confidence\nvalue."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0547v1", 
    "other_authors": "Chandan Singh, Nitin Bhatia", 
    "title": "A Fast Decision Technique for Hierarchical Hough Transform for Line   Detection", 
    "arxiv-id": "1007.0547v1", 
    "author": "Nitin Bhatia", 
    "publish": "2010-07-04T12:19:16Z", 
    "summary": "Many techniques have been proposed to speedup the performance of classic\nHough Transform. These techniques are primarily based on converting the voting\nprocedure to a hierarchy based voting method. These methods use approximate\ndecision-making process. In this paper, we propose a fast decision making\nprocess that enhances the speed and reduces the space requirements.\nExperimental results demonstrate that the proposed algorithm is much faster\nthan a similar Fast Hough Transform."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0618v1", 
    "other_authors": "Santanu Halder, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Face Synthesis (FASY) System for Determining the Characteristics of a   Face Image", 
    "arxiv-id": "1007.0618v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-07-05T05:24:30Z", 
    "summary": "This paper aims at determining the characteristics of a face image by\nextracting its components. The FASY (FAce SYnthesis) System is a Face Database\nRetrieval and new Face generation System that is under development. One of its\nmain features is the generation of the requested face when it is not found in\nthe existing database, which allows a continuous growing of the database also.\nTo generate the new face image, we need to store the face components in the\ndatabase. So we have designed a new technique to extract the face components by\na sophisticated method. After extraction of the facial feature points we have\nanalyzed the components to determine their characteristics. After extraction\nand analysis we have stored the components along with their characteristics\ninto the face database for later use during the face construction."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0620v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Quotient Based Multiresolution Image Fusion of Thermal and Visual Images   Using Daubechies Wavelet Transform for Human Face Recognition", 
    "arxiv-id": "1007.0620v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-07-05T05:56:44Z", 
    "summary": "This paper investigates the multiresolution level-1 and level-2 Quotient\nbased Fusion of thermal and visual images. In the proposed system, the method-1\nnamely \"Decompose then Quotient Fuse Level-1\" and the method-2 namely\n\"Decompose-Reconstruct then Quotient Fuse Level-2\" both work on wavelet\ntransformations of the visual and thermal face images. The wavelet transform is\nwell-suited to manage different image resolution and allows the image\ndecomposition in different kinds of coefficients, while preserving the image\ninformation without any loss. This approach is based on a definition of an\nillumination invariant signature image which enables an analytic generation of\nthe image space with varying illumination. The quotient fused images are passed\nthrough Principal Component Analysis (PCA) for dimension reduction and then\nthose images are classified using a multi-layer perceptron (MLP). The\nperformances of both the methods have been evaluated using OTCBVS and IRIS\ndatabases. All the different classes have been tested separately, among them\nthe maximum recognition result is 100%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0621v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Fusion of Daubechies Wavelet Coefficients for Human Face Recognition", 
    "arxiv-id": "1007.0621v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-07-05T06:04:43Z", 
    "summary": "In this paper fusion of visual and thermal images in wavelet transformed\ndomain has been presented. Here, Daubechies wavelet transform, called as D2,\ncoefficients from visual and corresponding coefficients computed in the same\nmanner from thermal images are combined to get fused coefficients. After\ndecomposition up to fifth level (Level 5) fusion of coefficients is done.\nInverse Daubechies wavelet transform of those coefficients gives us fused face\nimages. The main advantage of using wavelet transform is that it is well-suited\nto manage different image resolution and allows the image decomposition in\ndifferent kinds of coefficients, while preserving the image information. Fused\nimages thus found are passed through Principal Component Analysis (PCA) for\nreduction of dimensions and then those reduced fused images are classified\nusing a multi-layer perceptron. For experiments IRIS Thermal/Visual Face\nDatabase was used. Experimental results show that the performance of the\napproach presented here achieves maximum success rate of 100% in many cases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0626v1", 
    "other_authors": "M. K. Bhowmik, Debotosh Bhattacharjee, M. Nasipuri, D. K. Basu, M. Kundu", 
    "title": "Fusion of Wavelet Coefficients from Visual and Thermal Face Images for   Human Face Recognition - A Comparative Study", 
    "arxiv-id": "1007.0626v1", 
    "author": "M. Kundu", 
    "publish": "2010-07-05T07:33:45Z", 
    "summary": "In this paper we present a comparative study on fusion of visual and thermal\nimages using different wavelet transformations. Here, coefficients of discrete\nwavelet transforms from both visual and thermal images are computed separately\nand combined. Next, inverse discrete wavelet transformation is taken in order\nto obtain fused face image. Both Haar and Daubechies (db2) wavelet transforms\nhave been used to compare recognition results. For experiments IRIS\nThermal/Visual Face Database was used. Experimental results using Haar and\nDaubechies wavelets show that the performance of the approach presented here\nachieves maximum success rate of 100% in many cases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0627v1", 
    "other_authors": "M. K. Bhowmik, Debotosh Bhattacharjee, M. Nasipuri, D. K. Basu, M. Kundu", 
    "title": "A Parallel Framework for Multilayer Perceptron for Human Face   Recognition", 
    "arxiv-id": "1007.0627v1", 
    "author": "M. Kundu", 
    "publish": "2010-07-05T07:40:56Z", 
    "summary": "Artificial neural networks have already shown their success in face\nrecognition and similar complex pattern recognition tasks. However, a major\ndisadvantage of the technique is that it is extremely slow during training for\nlarger classes and hence not suitable for real-time complex problems such as\npattern recognition. This is an attempt to develop a parallel framework for the\ntraining algorithm of a perceptron. In this paper, two general architectures\nfor a Multilayer Perceptron (MLP) have been demonstrated. The first\narchitecture is All-Class-in-One-Network (ACON) where all the classes are\nplaced in a single network and the second one is One-Class-in-One-Network\n(OCON) where an individual single network is responsible for each and every\nclass. Capabilities of these two architectures were compared and verified in\nsolving human face recognition, which is a complex pattern recognition task\nwhere several factors affect the recognition performance like pose variations,\nfacial expression changes, occlusions, and most importantly illumination\nchanges. Both the structures were implemented and tested for face recognition\npurpose and experimental results show that the OCON structure performs better\nthan the generally used ACON ones in term of training convergence speed of the\nnetwork. Unlike the conventional sequential approach of training the neural\nnetworks, the OCON technique may be implemented by training all the classes of\nthe face images simultaneously."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0628v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Image Pixel Fusion for Human Face Recognition", 
    "arxiv-id": "1007.0628v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-07-05T07:45:48Z", 
    "summary": "In this paper we present a technique for fusion of optical and thermal face\nimages based on image pixel fusion approach. Out of several factors, which\naffect face recognition performance in case of visual images, illumination\nchanges are a significant factor that needs to be addressed. Thermal images are\nbetter in handling illumination conditions but not very consistent in capturing\ntexture details of the faces. Other factors like sunglasses, beard, moustache\netc also play active role in adding complicacies to the recognition process.\nFusion of thermal and visual images is a solution to overcome the drawbacks\npresent in the individual thermal and visual face images. Here fused images are\nprojected into an eigenspace and the projected images are classified using a\nradial basis function (RBF) neural network and also by a multi-layer perceptron\n(MLP). In the experiments Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database benchmark for thermal and visual face images have\nbeen used. Comparison of experimental results show that the proposed approach\nperforms significantly well in recognizing face images with a success rate of\n96% and 95.07% for RBF Neural Network and MLP respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0631v1", 
    "other_authors": "M. K. Bhowmik, Debotosh Bhattacharjee, M. Nasipuri, D. K. Basu, M. Kundu", 
    "title": "Classification of Fused Images using Radial Basis Function Neural   Network for Human Face Recognition", 
    "arxiv-id": "1007.0631v1", 
    "author": "M. Kundu", 
    "publish": "2010-07-05T07:57:42Z", 
    "summary": "Here an efficient fusion technique for automatic face recognition has been\npresented. Fusion of visual and thermal images has been done to take the\nadvantages of thermal images as well as visual images. By employing fusion a\nnew image can be obtained, which provides the most detailed, reliable, and\ndiscriminating information. In this method fused images are generated using\nvisual and thermal face images in the first step. In the second step, fused\nimages are projected into eigenspace and finally classified using a radial\nbasis function neural network. In the experiments Object Tracking and\nClassification Beyond Visible Spectrum (OTCBVS) database benchmark for thermal\nand visual face images have been used. Experimental results show that the\nproposed approach performs well in recognizing unknown individuals with a\nmaximum success rate of 96%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0633v1", 
    "other_authors": "Debotosh Bhattacharjee, Mrinal Kanti Bhowmik, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Classification of fused face images using multilayer perceptron neural   network", 
    "arxiv-id": "1007.0633v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-07-05T08:01:11Z", 
    "summary": "This paper presents a concept of image pixel fusion of visual and thermal\nfaces, which can significantly improve the overall performance of a face\nrecognition system. Several factors affect face recognition performance\nincluding pose variations, facial expression changes, occlusions, and most\nimportantly illumination changes. So, image pixel fusion of thermal and visual\nimages is a solution to overcome the drawbacks present in the individual\nthermal and visual face images. Fused images are projected into eigenspace and\nfinally classified using a multi-layer perceptron. In the experiments we have\nused Object Tracking and Classification Beyond Visible Spectrum (OTCBVS)\ndatabase benchmark thermal and visual face images. Experimental results show\nthat the proposed approach significantly improves the verification and\nidentification performance and the success rate is 95.07%. The main objective\nof employing fusion is to produce a fused image that provides the most detailed\nand reliable information. Fusion of multiple images together produces a more\nefficient representation of the image."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0636v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Mahantapas Kundu, Dipak Kumar Basu", 
    "title": "Classification of Log-Polar-Visual Eigenfaces using Multilayer   Perceptron", 
    "arxiv-id": "1007.0636v1", 
    "author": "Dipak Kumar Basu", 
    "publish": "2010-07-05T08:05:14Z", 
    "summary": "In this paper we present a simple novel approach to tackle the challenges of\nscaling and rotation of face images in face recognition. The proposed approach\nregisters the training and testing visual face images by log-polar\ntransformation, which is capable to handle complicacies introduced by scaling\nand rotation. Log-polar images are projected into eigenspace and finally\nclassified using an improved multi-layer perceptron. In the experiments we have\nused ORL face database and Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database for visual face images. Experimental results show\nthat the proposed approach significantly improves the recognition performances\nfrom visual to log-polar-visual face images. In case of ORL face database,\nrecognition rate for visual face images is 89.5% and that is increased to 97.5%\nfor log-polar-visual face images whereas for OTCBVS face database recognition\nrate for visual images is 87.84% and 96.36% for log-polar-visual face images."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.0638v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Human Face Recognition using Line Features", 
    "arxiv-id": "1007.0638v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-07-05T08:10:30Z", 
    "summary": "In this work we investigate a novel approach to handle the challenges of face\nrecognition, which includes rotation, scale, occlusion, illumination etc. Here,\nwe have used thermal face images as those are capable to minimize the affect of\nillumination changes and occlusion due to moustache, beards, adornments etc.\nThe proposed approach registers the training and testing thermal face images in\npolar coordinate, which is capable to handle complicacies introduced by scaling\nand rotation. Line features are extracted from thermal polar images and feature\nvectors are constructed using these line. Feature vectors thus obtained passes\nthrough principal component analysis (PCA) for the dimensionality reduction of\nfeature vectors. Finally, the images projected into eigenspace are classified\nusing a multi-layer perceptron. In the experiments we have used Object Tracking\nand Classification Beyond Visible Spectrum (OTCBVS) database. Experimental\nresults show that the proposed approach significantly improves the verification\nand identification performance and the success rate is 99.25%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2014.4223", 
    "link": "http://arxiv.org/pdf/1007.1016v1", 
    "other_authors": "Oleg S. Pianykh", 
    "title": "Bilateral filters: what they can and cannot do", 
    "arxiv-id": "1007.1016v1", 
    "author": "Oleg S. Pianykh", 
    "publish": "2010-07-06T23:25:39Z", 
    "summary": "Nonlinear bilateral filters (BF) deliver a fine blend of computational\nsimplicity and blur-free denoising. However, little is known about their\nnature, noise-suppressing properties, and optimal choices of filter parameters.\nOur study is meant to fill this gap-explaining the underlying mechanism of\nbilateral filtering and providing the methodology for optimal filter selection.\nPractical application to CT image denoising is discussed to illustrate our\nresults."
},{
    "category": "cs.CV", 
    "doi": "10.5120/1745-2053", 
    "link": "http://arxiv.org/pdf/1007.1048v1", 
    "other_authors": "D. Sasikala, R. Neelaveni", 
    "title": "Registration of Brain Images using Fast Walsh Hadamard Transform", 
    "arxiv-id": "1007.1048v1", 
    "author": "R. Neelaveni", 
    "publish": "2010-07-07T04:49:16Z", 
    "summary": "A lot of image registration techniques have been developed with great\nsignificance for data analysis in medicine, astrophotography, satellite imaging\nand few other areas. This work proposes a method for medical image registration\nusing Fast Walsh Hadamard transform. This algorithm registers images of the\nsame or different modalities. Each image bit is lengthened in terms of Fast\nWalsh Hadamard basis functions. Each basis function is a notion of determining\nvarious aspects of local structure, e.g., horizontal edge, corner, etc. These\ncoefficients are normalized and used as numerals in a chosen number system\nwhich allows one to form a unique number for each type of local structure. The\nexperimental results show that Fast Walsh Hadamard transform accomplished\nbetter results than the conventional Walsh transform in the time domain. Also\nFast Walsh Hadamard transform is more reliable in medical image registration\nconsuming less time."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0011631", 
    "link": "http://arxiv.org/pdf/1007.1398v1", 
    "other_authors": "Raphael Sznitman, Manaswi Gupta, Gregory D. Hager, Paulo E. Arratia, Josue Sznitman", 
    "title": "Multi-environment model estimation for motility analysis of   Caenorhabditis Elegans", 
    "arxiv-id": "1007.1398v1", 
    "author": "Josue Sznitman", 
    "publish": "2010-07-08T15:10:05Z", 
    "summary": "The nematode Caenorhabditis elegans is a well-known model organism used to\ninvestigate fundamental questions in biology. Motility assays of this small\nroundworm are designed to study the relationships between genes and behavior.\nCommonly, motility analysis is used to classify nematode movements and\ncharacterize them quantitatively. Over the past years, C. elegans' motility has\nbeen studied across a wide range of environments, including crawling on\nsubstrates, swimming in fluids, and locomoting through microfluidic substrates.\nHowever, each environment often requires customized image processing tools\nrelying on heuristic parameter tuning. In the present study, we propose a novel\nMulti-Environment Model Estimation (MEME) framework for automated image\nsegmentation that is versatile across various environments. The MEME platform\nis constructed around the concept of Mixture of Gaussian (MOG) models, where\nstatistical models for both the background environment and the nematode\nappearance are explicitly learned and used to accurately segment a target\nnematode. Our method is designed to simplify the burden often imposed on users;\nhere, only a single image which includes a nematode in its environment must be\nprovided for model learning. In addition, our platform enables the extraction\nof nematode `skeletons' for straightforward motility quantification. We test\nour algorithm on various locomotive environments and compare performances with\nan intensity-based thresholding method. Overall, MEME outperforms the\nthreshold-based approach for the overwhelming majority of cases examined.\nUltimately, MEME provides researchers with an attractive platform for C.\nelegans' segmentation and `skeletonizing' across a wide range of motility\nassays."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0011631", 
    "link": "http://arxiv.org/pdf/1007.1432v1", 
    "other_authors": "Edward Rosten, Gerhard Reitmayr, Tom Drummond", 
    "title": "Improved RANSAC performance using simple, iterative minimal-set solvers", 
    "arxiv-id": "1007.1432v1", 
    "author": "Tom Drummond", 
    "publish": "2010-07-08T18:12:49Z", 
    "summary": "RANSAC is a popular technique for estimating model parameters in the presence\nof outliers. The best speed is achieved when the minimum possible number of\npoints is used to estimate hypotheses for the model. Many useful problems can\nbe represented using polynomial constraints (for instance, the determinant of a\nfundamental matrix must be zero) and so have a number of solutions which are\nconsistent with a minimal set. A considerable amount of effort has been\nexpended on finding the constraints of such problems, and these often require\nthe solution of systems of polynomial equations. We show that better\nperformance can be achieved by using a simple optimization based approach on\nminimal sets. For a given minimal set, the optimization approach is not\nguaranteed to converge to the correct solution. However, when used within\nRANSAC the greater speed and numerical stability results in better performance\noverall, and much simpler algorithms. We also show that by selecting more than\nthe minimal number of points and using robust optimization can yield better\nresults for very noisy by reducing the number of trials required. The increased\nspeed of our method demonstrated with experiments on essential matrix\nestimation."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0011631", 
    "link": "http://arxiv.org/pdf/1007.1708v1", 
    "other_authors": "Lim Huey Charn, Liyana Nuraini Rasid, Shahrel A. Suandi", 
    "title": "A Study on the Effectiveness of Different Patch Size and Shape for Eyes   and Mouth Detection", 
    "arxiv-id": "1007.1708v1", 
    "author": "Shahrel A. Suandi", 
    "publish": "2010-07-10T09:01:48Z", 
    "summary": "Template matching is one of the simplest methods used for eyes and mouth\ndetection. However, it can be modified and extended to become a powerful tool.\nSince the patch itself plays a significant role in optimizing detection\nperformance, a study on the influence of patch size and shape is carried out.\nThe optimum patch size and shape is determined using the proposed method.\nUsually, template matching is also combined with other methods in order to\nimprove detection accuracy. Thus, in this paper, the effectiveness of two image\nprocessing methods i.e. grayscale and Haar wavelet transform, when used with\ntemplate matching are analyzed."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0011631", 
    "link": "http://arxiv.org/pdf/1007.2442v1", 
    "other_authors": "Kyle Johnson, Clayton Chang, Hod Lipson", 
    "title": "Neural Network Based Reconstruction of a 3D Object from a 2D Wireframe", 
    "arxiv-id": "1007.2442v1", 
    "author": "Hod Lipson", 
    "publish": "2010-07-14T22:01:26Z", 
    "summary": "We propose a new approach for constructing a 3D representation from a 2D\nwireframe drawing. A drawing is simply a parallel projection of a 3D object\nonto a 2D surface; humans are able to recreate mental 3D models from 2D\nrepresentations very easily, yet the process is very difficult to emulate\ncomputationally. We hypothesize that our ability to perform this construction\nrelies on the angles in the 2D scene, among other geometric properties. Being\nable to reproduce this reconstruction process automatically would allow for\nefficient and robust 3D sketch interfaces. Our research focuses on the\nrelationship between 2D geometry observable in the sketch and 3D geometry\nderived from a potential 3D construction. We present a fully automated system\nthat constructs 3D representations from 2D wireframes using a neural network in\nconjunction with a genetic search algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0011631", 
    "link": "http://arxiv.org/pdf/1007.3772v1", 
    "other_authors": "Stephen O'Hara", 
    "title": "Video Event Recognition for Surveillance Applications (VERSA)", 
    "arxiv-id": "1007.3772v1", 
    "author": "Stephen O'Hara", 
    "publish": "2010-07-21T22:47:00Z", 
    "summary": "VERSA provides a general-purpose framework for defining and recognizing\nevents in live or recorded surveillance video streams. The approach for event\nrecognition in VERSA is using a declarative logic language to define the\nspatial and temporal relationships that characterize a given event or activity.\nDoing so requires the definition of certain fundamental spatial and temporal\nrelationships and a high-level syntax for specifying frame templates and query\nparameters. Although the handling of uncertainty in the current VERSA\nimplementation is simplistic, the language and architecture is amenable to\nextending using Fuzzy Logic or similar approaches. VERSA's high-level\narchitecture is designed to work in XML-based, services- oriented environments.\nVERSA can be thought of as subscribing to the XML annotations streamed by a\nlower-level video analytics service that provides basic entity detection,\nlabeling, and tracking. One or many VERSA Event Monitors could thus analyze\nvideo streams and provide alerts when certain events are detected."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0011631", 
    "link": "http://arxiv.org/pdf/1007.3926v1", 
    "other_authors": "Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing", 
    "title": "Ear Identification by Fusion of Segmented Slice Regions using Invariant   Features: An Experimental Manifold with Dual Fusion Approach", 
    "arxiv-id": "1007.3926v1", 
    "author": "Jamuna Kanta Sing", 
    "publish": "2010-07-21T14:09:33Z", 
    "summary": "This paper proposes a robust ear identification system which is developed by\nfusing SIFT features of color segmented slice regions of an ear. The proposed\near identification method makes use of Gaussian mixture model (GMM) to build\near model with mixture of Gaussian using vector quantization algorithm and K-L\ndivergence is applied to the GMM framework for recording the color similarity\nin the specified ranges by comparing color similarity between a pair of\nreference ear and probe ear. SIFT features are then detected and extracted from\neach color slice region as a part of invariant feature extraction. The\nextracted keypoints are then fused separately by the two fusion approaches,\nnamely concatenation and the Dempster-Shafer theory. Finally, the fusion\napproaches generate two independent augmented feature vectors which are used\nfor identification of individuals separately. The proposed identification\ntechnique is tested on IIT Kanpur ear database of 400 individuals and is found\nto achieve 98.25% accuracy for identification while top 5 matched criteria is\nset for each subject."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1007.5129v1", 
    "other_authors": "Mohammed J. Islam, Majid Ahmadi, Maher A. Sid-Ahmed", 
    "title": "An Efficient Automatic Mass Classification Method In Digitized   Mammograms Using Artificial Neural Network", 
    "arxiv-id": "1007.5129v1", 
    "author": "Maher A. Sid-Ahmed", 
    "publish": "2010-07-29T07:19:58Z", 
    "summary": "In this paper we present an efficient computer aided mass classification\nmethod in digitized mammograms using Artificial Neural Network (ANN), which\nperforms benign-malignant classification on region of interest (ROI) that\ncontains mass. One of the major mammographic characteristics for mass\nclassification is texture. ANN exploits this important factor to classify the\nmass into benign or malignant. The statistical textural features used in\ncharacterizing the masses are mean, standard deviation, entropy, skewness,\nkurtosis and uniformity. The main aim of the method is to increase the\neffectiveness and efficiency of the classification process in an objective\nmanner to reduce the numbers of false-positive of malignancies. Three layers\nartificial neural network (ANN) with seven features was proposed for\nclassifying the marked regions into benign and malignant and 90.91% sensitivity\nand 83.87% specificity is achieved that is very much promising compare to the\nradiologist's sensitivity 75%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.0579v1", 
    "other_authors": "Ye Ji", 
    "title": "Image Retrieval Method Using Top-surf Descriptor", 
    "arxiv-id": "1104.0579v1", 
    "author": "Ye Ji", 
    "publish": "2011-04-04T14:14:47Z", 
    "summary": "This report presents the results and details of a content-based image\nretrieval project using the Top-surf descriptor. The experimental results are\npreliminary, however, it shows the capability of deducing objects from parts of\nthe objects or from the objects that are similar. This paper uses a dataset\nconsisting of 1200 images of which 800 images are equally divided into 8\ncategories, namely airplane, beach, motorbike, forest, elephants, horses, bus\nand building, while the other 400 images are randomly picked from the Internet.\nThe best results achieved are from building category."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.0582v1", 
    "other_authors": "Ran Tao", 
    "title": "Visual Concept Detection and Real Time Object Detection", 
    "arxiv-id": "1104.0582v1", 
    "author": "Ran Tao", 
    "publish": "2011-04-04T14:18:51Z", 
    "summary": "Bag-of-words model is implemented and tried on 10-class visual concept\ndetection problem. The experimental results show that \"DURF+ERT+SVM\"\noutperforms \"SIFT+ERT+SVM\" both in detection performance and computation\nefficiency. Besides, combining DURF and SIFT results in even better detection\nperformance. Real-time object detection using SIFT and RANSAC is also tried on\nsimple objects, e.g. drink can, and good result is achieved."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.1237v1", 
    "other_authors": "Soumen Bag, Soumen Barik, Prithwiraj Sen, Gautam Sanyal", 
    "title": "A Statistical Nonparametric Approach of Face Recognition: Combination of   Eigenface & Modified k-Means Clustering", 
    "arxiv-id": "1104.1237v1", 
    "author": "Gautam Sanyal", 
    "publish": "2011-04-07T03:17:08Z", 
    "summary": "Facial expressions convey non-verbal cues, which play an important role in\ninterpersonal relations. Automatic recognition of human face based on facial\nexpression can be an important component of natural human-machine interface. It\nmay also be used in behavioural science. Although human can recognize the face\npractically without any effort, but reliable face recognition by machine is a\nchallenge. This paper presents a new approach for recognizing the face of a\nperson considering the expressions of the same human face at different\ninstances of time. This methodology is developed combining Eigenface method for\nfeature extraction and modified k-Means clustering for identification of the\nhuman face. This method endowed the face recognition without using the\nconventional distance measure classifiers. Simulation results show that\nproposed face recognition using perception of k-Means clustering is useful for\nface images with different facial expressions."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.1472v1", 
    "other_authors": "Xiaopeng Xu, Xiaochun Zhang", 
    "title": "Gaussian Affine Feature Detector", 
    "arxiv-id": "1104.1472v1", 
    "author": "Xiaochun Zhang", 
    "publish": "2011-04-08T03:15:43Z", 
    "summary": "A new method is proposed to get image features' geometric information. Using\nGaussian as an input signal, a theoretical optimal solution to calculate\nfeature's affine shape is proposed. Based on analytic result of a feature\nmodel, the method is different from conventional iterative approaches. From the\nmodel, feature's parameters such as position, orientation, background\nluminance, contrast, area and aspect ratio can be extracted. Tested with\nsynthesized and benchmark data, the method achieves or outperforms existing\napproaches in term of accuracy, speed and stability. The method can detect\nsmall, long or thin objects precisely, and works well under general conditions,\nsuch as for low contrast, blurred or noisy images."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.1485v1", 
    "other_authors": "Arijit Laha, J. Das", 
    "title": "Fuzzy Rules and Evidence Theory for Satellite Image Analysis", 
    "arxiv-id": "1104.1485v1", 
    "author": "J. Das", 
    "publish": "2011-04-08T05:18:15Z", 
    "summary": "Design of a fuzzy rule based classifier is proposed. The performance of the\nclassifier for multispectral satellite image classification is improved using\nDempster- Shafer theory of evidence that exploits information of the\nneighboring pixels. The classifiers are tested rigorously with two known images\nand their performance are found to be better than the results available in the\nliterature. We also demonstrate the improvement of performance while using D-S\ntheory along with fuzzy rule based classifiers over the basic fuzzy rule based\nclassifiers for all the test cases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.1556v3", 
    "other_authors": "Jan Klein, Sebastiano Barbieri, Miriam H. A. Bauer, Christopher Nimsky, Horst K. Hahn", 
    "title": "Benchmarking the Quality of Diffusion-Weighted Images", 
    "arxiv-id": "1104.1556v3", 
    "author": "Horst K. Hahn", 
    "publish": "2011-04-08T12:03:16Z", 
    "summary": "We present a novel method that allows for measuring the quality of\ndiffusion-weighted MR images dependent on the image resolution and the image\nnoise. For this purpose, we introduce a new thresholding technique so that\nnoise and the signal can automatically be estimated from a single data set.\nThus, no user interaction as well as no double acquisition technique, which\nrequires a time-consuming proper geometrical registration, is needed. As a\ncoarser image resolution or slice thickness leads to a higher signal-to-noise\nratio (SNR), our benchmark determines a resolution-independent quality measure\nso that images with different resolutions can be adequately compared. To\nevaluate our method, a set of diffusion-weighted images from different vendors\nis used. It is shown that the quality can efficiently be determined and that\nthe automatically computed SNR is comparable to the SNR which is measured\nmanually in a manually selected region of interest."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.1945v1", 
    "other_authors": "M. S. Shirdhonkar, Manesh B. Kokare", 
    "title": "Off-Line Handwritten Signature Retrieval using Curvelet Transforms", 
    "arxiv-id": "1104.1945v1", 
    "author": "Manesh B. Kokare", 
    "publish": "2011-04-11T13:37:08Z", 
    "summary": "In this paper, a new method for offline handwritten signature retrieval is\nbased on curvelet transform is proposed. Many applications in image processing\nrequire similarity retrieval of an image from a large collection of images. In\nsuch cases, image indexing becomes important for efficient organization and\nretrieval of images. This paper addresses this issue in the context of a\ndatabase of handwritten signature images and describes a system for similarity\nretrieval. The proposed system uses a curvelet based texture features\nextraction. The performance of the system has been tested with an image\ndatabase of 180 signatures. The results obtained indicate that the proposed\nsystem is able to identify signatures with great with accuracy even when a part\nof a signature is missing."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.2059v1", 
    "other_authors": "Kwie Min Wong", 
    "title": "Template-based matching using weight maps", 
    "arxiv-id": "1104.2059v1", 
    "author": "Kwie Min Wong", 
    "publish": "2011-04-11T20:32:54Z", 
    "summary": "Template matching is one of the most prevalent pattern recognition methods\nworldwide. It has found uses in most visual concept detection fields. In this\nwork, we investigate methods for improving template matching by adjusting the\nweights of different regions of the template. We compare several weight maps\nand test the methods using the FERET face test set in the context of human eye\ndetection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.2069v1", 
    "other_authors": "Alwin de Rooij", 
    "title": "GEOMIR2K9 - A Similar Scene Finder", 
    "arxiv-id": "1104.2069v1", 
    "author": "Alwin de Rooij", 
    "publish": "2011-04-11T21:17:28Z", 
    "summary": "The main goal of the GEOMIR2K9 project is to create a software program that\nis able to find similar scenic images clustered by geographical location and\nsorted by similarity based only on their visual content. The user should be\nable to input a query image, based on this given query image the program should\nfind relevant visual content and present this to the user in a meaningful way.\nTechnically the goal for the GEOMIR2K9 project is twofold. The first of these\ntwo goals is to create a basic low level visual information retrieval system.\nThis includes feature extraction, post processing of the feature data and\nclassification/ clustering based on similarity with a strong focus on scenic\nimages. The second goal of this project is to provide the user with a novel and\nsuitable interface and visualization method so that the user may interact with\nthe retrieved images in a natural and meaningful way."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.2171v1", 
    "other_authors": "Sibel Tari, Murat Genctav", 
    "title": "From a Modified Ambrosio-Tortorelli to a Randomized Part Hierarchy Tree", 
    "arxiv-id": "1104.2171v1", 
    "author": "Murat Genctav", 
    "publish": "2011-04-12T11:20:06Z", 
    "summary": "We demonstrate the possibility of coding parts, features that are higher\nlevel than boundaries, using a modified AT field after augmenting the\ninteraction term of the AT energy with a non-local term and weakening the\nseparation into boundary/not-boundary phases. The iteratively extracted parts\nusing the level curves with double point singularities are organized as a\nproper binary tree. Inconsistencies due to non-generic configurations for level\ncurves as well as due to visual changes such as occlusion are successfully\nhandled once the tree is endowed with a probabilistic structure. The work is a\nstep in establishing the AT function as a bridge between low and high level\nvisual processing."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.2175v1", 
    "other_authors": "Sibel Tari", 
    "title": "Extracting Parts of 2D Shapes Using Local and Global Interactions   Simultaneously", 
    "arxiv-id": "1104.2175v1", 
    "author": "Sibel Tari", 
    "publish": "2011-04-12T11:33:20Z", 
    "summary": "Perception research provides strong evidence in favor of part based\nrepresentation of shapes in human visual system. Despite considerable\ndifferences among different theories in terms of how part boundaries are found,\nthere is substantial agreement on that the process depends on many local and\nglobal geometric factors. This poses an important challenge from the\ncomputational point of view. In the first part of the chapter, I present a\nnovel decomposition method by taking both local and global interactions within\nthe shape domain into account. At the top of the partitioning hierarchy, the\nshape gets split into two parts capturing, respectively, the gross structure\nand the peripheral structure. The gross structure may be conceived as the least\ndeformable part of the shape which remains stable under visual transformations.\nThe peripheral structure includes limbs, protrusions, and boundary texture.\nSuch a separation is in accord with the behavior of the artists who start with\na gross shape and enrich it with details. The method is particularly\ninteresting from the computational point of view as it does not resort to any\ngeometric notions (e.g. curvature, convexity) explicitly. In the second part of\nthe chapter, I relate the new method to PDE based shape representation schemes."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.2745v1", 
    "other_authors": "Cagri Aslan, Sibel Tari", 
    "title": "An Axis-Based Representation for Recognition", 
    "arxiv-id": "1104.2745v1", 
    "author": "Sibel Tari", 
    "publish": "2011-04-14T12:52:40Z", 
    "summary": "This paper presents a new axis-based shape representation scheme along with a\nmatching framework to address the problem of generic shape recognition. The\nmain idea is to define the relative spatial arrangement of local symmetry axes\nand their metric properties in a shape centered coordinate frame. The resulting\ndescriptions are invariant to scale, rotation, small changes in viewpoint and\narticulations. Symmetry points are extracted from a surface whose level curves\nroughly mimic the motion by curvature. By increasing the amount of smoothing on\nthe evolving curve, only those symmetry axes that correspond to the most\nprominent parts of a shape are extracted. The representation does not suffer\nfrom the common instability problems of the traditional connected skeletons. It\ncaptures the perceptual qualities of shapes well. Therefore finding the\nsimilarities and the differences among shapes becomes easier. The matching\nprocess gives highly successful results on a diverse database of 2D shapes."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.2751v1", 
    "other_authors": "C. Aslan, A. Erdem, E. Erdem, S. Tari", 
    "title": "Disconnected Skeleton: Shape at its Absolute Scale", 
    "arxiv-id": "1104.2751v1", 
    "author": "S. Tari", 
    "publish": "2011-04-14T13:02:43Z", 
    "summary": "We present a new skeletal representation along with a matching framework to\naddress the deformable shape recognition problem. The disconnectedness arises\nas a result of excessive regularization that we use to describe a shape at an\nattainably coarse scale. Our motivation is to rely on the stable properties of\nthe shape instead of inaccurately measured secondary details. The new\nrepresentation does not suffer from the common instability problems of\ntraditional connected skeletons, and the matching process gives quite\nsuccessful results on a diverse database of 2D shapes. An important difference\nof our approach from the conventional use of the skeleton is that we replace\nthe local coordinate frame with a global Euclidean frame supported by\nadditional mechanisms to handle articulations and local boundary deformations.\nAs a result, we can produce descriptions that are sensitive to any combination\nof changes in scale, position, orientation and articulation, as well as\ninvariant ones."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.3742v1", 
    "other_authors": "Fillipe Souza, Eduardo Valle, Guillermo Ch\u00e1vez, Arnaldo Ara\u00fajo", 
    "title": "Hue Histograms to Spatiotemporal Local Features for Action Recognition", 
    "arxiv-id": "1104.3742v1", 
    "author": "Arnaldo Ara\u00fajo", 
    "publish": "2011-04-19T13:36:15Z", 
    "summary": "Despite the recent developments in spatiotemporal local features for action\nrecognition in video sequences, local color information has so far been\nignored. However, color has been proved an important element to the success of\nautomated recognition of objects and scenes. In this paper we extend the\nspace-time interest point descriptor STIP to take into account the color\ninformation on the features' neighborhood. We compare the performance of our\ncolor-aware version of STIP (which we have called HueSTIP) with the original\none."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2010.1301", 
    "link": "http://arxiv.org/pdf/1104.4168v1", 
    "other_authors": "Wei Liu, Eraldo Ribeiro", 
    "title": "A Meshless Method for Variational Nonrigid 2-D Shape Registration", 
    "arxiv-id": "1104.4168v1", 
    "author": "Eraldo Ribeiro", 
    "publish": "2011-04-21T04:48:41Z", 
    "summary": "We present a method for nonrigid registration of 2-D geometric shapes. Our\ncontribution is twofold. First, we extend the classic chamfer-matching energy\nto a variational functional. Secondly, we introduce a meshless deformation\nmodel that can handle significant high-curvature deformations. We represent 2-D\nshapes implicitly using distance transforms, and registration error is defined\nbased on the shape contours' mutual distances. In addition, we model global\nshape deformation as an approximation blended from local deformation fields\nusing partition-of-unity. The global deformation field is regularized by\npenalizing inconsistencies between local fields. The representation can be made\nadaptive to shape's contour, leading to registration that is both flexible and\nefficient. Finally, registration is achieved by minimizing a variational\nchamfer-energy functional combined with the consistency regularizer. We\ndemonstrate the effectiveness of our method on a number of experiments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2170696", 
    "link": "http://arxiv.org/pdf/1104.4298v2", 
    "other_authors": "Carsten Gottschlich", 
    "title": "Curved Gabor Filters for Fingerprint Image Enhancement", 
    "arxiv-id": "1104.4298v2", 
    "author": "Carsten Gottschlich", 
    "publish": "2011-04-21T15:52:39Z", 
    "summary": "Gabor filters play an important role in many application areas for the\nenhancement of various types of images and the extraction of Gabor features.\nFor the purpose of enhancing curved structures in noisy images, we introduce\ncurved Gabor filters which locally adapt their shape to the direction of flow.\nThese curved Gabor filters enable the choice of filter parameters which\nincrease the smoothing power without creating artifacts in the enhanced image.\nIn this paper, curved Gabor filters are applied to the curved ridge and valley\nstructure of low-quality fingerprint images. First, we combine two orientation\nfield estimation methods in order to obtain a more robust estimation for very\nnoisy images. Next, curved regions are constructed by following the respective\nlocal orientation and they are used for estimating the local ridge frequency.\nLastly, curved Gabor filters are defined based on curved regions and they are\napplied for the enhancement of low-quality fingerprint images. Experimental\nresults on the FVC2004 databases show improvements of this approach in\ncomparison to state-of-the-art enhancement methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2170696", 
    "link": "http://arxiv.org/pdf/1104.4704v2", 
    "other_authors": "Chunhua Shen, Junae Kim, Lei Wang, Anton van den Hengel", 
    "title": "Positive Semidefinite Metric Learning Using Boosting-like Algorithms", 
    "arxiv-id": "1104.4704v2", 
    "author": "Anton van den Hengel", 
    "publish": "2011-04-25T10:38:03Z", 
    "summary": "The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2011.2170696", 
    "link": "http://arxiv.org/pdf/1104.4989v6", 
    "other_authors": "Abhishek Das, Avijit Kar, Debasis Bhattacharyya", 
    "title": "Preprocessing: A Step in Automating Early Detection of Cervical Cancer", 
    "arxiv-id": "1104.4989v6", 
    "author": "Debasis Bhattacharyya", 
    "publish": "2011-04-26T18:38:01Z", 
    "summary": "This paper has been withdrawn"
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1104.5304v1", 
    "other_authors": "Vincent Michel, Alexandre Gramfort, Ga\u00ebl Varoquaux, Evelyn Eger, Christine Keribin, Bertrand Thirion", 
    "title": "A supervised clustering approach for fMRI-based inference of brain   states", 
    "arxiv-id": "1104.5304v1", 
    "author": "Bertrand Thirion", 
    "publish": "2011-04-28T06:12:45Z", 
    "summary": "We propose a method that combines signals from many brain regions observed in\nfunctional Magnetic Resonance Imaging (fMRI) to predict the subject's behavior\nduring a scanning session. Such predictions suffer from the huge number of\nbrain regions sampled on the voxel grid of standard fMRI data sets: the curse\nof dimensionality. Dimensionality reduction is thus needed, but it is often\nperformed using a univariate feature selection procedure, that handles neither\nthe spatial structure of the images, nor the multivariate nature of the signal.\nBy introducing a hierarchical clustering of the brain volume that incorporates\nconnectivity constraints, we reduce the span of the possible spatial\nconfigurations to a single tree of nested regions tailored to the signal. We\nthen prune the tree in a supervised setting, hence the name supervised\nclustering, in order to extract a parcellation (division of the volume) such\nthat parcel-based signal averages best predict the target information.\nDimensionality reduction is thus achieved by feature agglomeration, and the\nconstructed features now provide a multi-scale representation of the signal.\nComparisons with reference methods on both simulated and real data show that\nour approach yields higher prediction accuracy than standard voxel-based\napproaches. Moreover, the method infers an explicit weighting of the regions\ninvolved in the regression or classification task."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.0767v2", 
    "other_authors": "Vini Katyal, Deepesh Srivastava", 
    "title": "Efficient Fruit Defect Detection and Glare removal Algorithm by   anisotropic diffusion and 2D Gabor filter", 
    "arxiv-id": "1204.0767v2", 
    "author": "Deepesh Srivastava", 
    "publish": "2012-04-03T19:02:54Z", 
    "summary": "This paper focuses on fruit defect detection and glare removal using\nmorphological operations, Glare removal can be considered as an important\npreprocessing step as uneven lighting may introduce it in images, which hamper\nthe results produced through segmentation by Gabor filters .The problem of\nglare in images is very pronounced sometimes due to the unusual reflectance\nfrom the camera sensor or stray light entering, this method counteracts this\nproblem and makes the defect detection much more pronounced. Anisotropic\ndiffusion is used for further smoothening of the images and removing the high\nenergy regions in an image for better defect detection and makes the defects\nmore retrievable. Our algorithm is robust and scalable the employability of a\nparticular mask for glare removal has been checked and proved useful for\ncounteracting.this problem, anisotropic diffusion further enhances the defects\nwith its use further Optimal Gabor filter at various orientations is used for\ndefect detection."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1177v1", 
    "other_authors": "Aamir Khan, Hasan Farooq", 
    "title": "Principal Component Analysis-Linear Discriminant Analysis Feature   Extractor for Pattern Recognition", 
    "arxiv-id": "1204.1177v1", 
    "author": "Hasan Farooq", 
    "publish": "2012-04-05T10:48:09Z", 
    "summary": "Robustness of embedded biometric systems is of prime importance with the\nemergence of fourth generation communication devices and advancement in\nsecurity systems This paper presents the realization of such technologies which\ndemands reliable and error-free biometric identity verification systems. High\ndimensional patterns are not permitted due to eigen-decomposition in high\ndimensional image space and degeneration of scattering matrices in small size\nsample. Generalization, dimensionality reduction and maximizing the margins are\ncontrolled by minimizing weight vectors. Results show good pattern by\nmultimodal biometric system proposed in this paper. This paper is aimed at\ninvestigating a biometric identity system using Principal Component Analysis\nand Lindear Discriminant Analysis with K-Nearest Neighbor and implementing such\nsystem in real-time using SignalWAVE."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1198v1", 
    "other_authors": "Farjana Yeasmin Omee, Shiam Shabbir Himel, Md. Abu Naser Bikas", 
    "title": "A Complete Workflow for Development of Bangla OCR", 
    "arxiv-id": "1204.1198v1", 
    "author": "Md. Abu Naser Bikas", 
    "publish": "2012-04-05T12:28:11Z", 
    "summary": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1393v1", 
    "other_authors": "Koichiro Yamaguchi, Tamir Hazan, David McAllester, Raquel Urtasun", 
    "title": "Continuous Markov Random Fields for Robust Stereo Estimation", 
    "arxiv-id": "1204.1393v1", 
    "author": "Raquel Urtasun", 
    "publish": "2012-04-06T01:40:21Z", 
    "summary": "In this paper we present a novel slanted-plane MRF model which reasons\njointly about occlusion boundaries as well as depth. We formulate the problem\nas the one of inference in a hybrid MRF composed of both continuous (i.e.,\nslanted 3D planes) and discrete (i.e., occlusion boundaries) random variables.\nThis allows us to define potentials encoding the ownership of the pixels that\ncompose the boundary between segments, as well as potentials encoding which\njunctions are physically possible. Our approach outperforms the\nstate-of-the-art on Middlebury high resolution imagery as well as in the more\nchallenging KITTI dataset, while being more efficient than existing slanted\nplane MRF-based methods, taking on average 2 minutes to perform inference on\nhigh resolution imagery."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1611v1", 
    "other_authors": "Choon Boon Ng, Yong Haur Tay, Bok Min Goi", 
    "title": "Vision-based Human Gender Recognition: A Survey", 
    "arxiv-id": "1204.1611v1", 
    "author": "Bok Min Goi", 
    "publish": "2012-04-07T08:17:40Z", 
    "summary": "Gender is an important demographic attribute of people. This paper provides a\nsurvey of human gender recognition in computer vision. A review of approaches\nexploiting information from face and whole body (either from a still image or\ngait sequence) is presented. We highlight the challenges faced and survey the\nrepresentative methods of these approaches. Based on the results, good\nperformance have been achieved for datasets captured under controlled\nenvironments, but there is still much work that can be done to improve the\nrobustness of gender recognition under real-life environments."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1629v1", 
    "other_authors": "Mohamed Ali Mahjoub, karim kalti", 
    "title": "Image segmentation by adaptive distance based on EM algorithm", 
    "arxiv-id": "1204.1629v1", 
    "author": "karim kalti", 
    "publish": "2012-04-07T13:04:24Z", 
    "summary": "This paper introduces a Bayesian image segmentation algorithm based on finite\nmixtures. An EM algorithm is developed to estimate parameters of the Gaussian\nmixtures. The finite mixture is a flexible and powerful probabilistic modeling\ntool. It can be used to provide a model-based clustering in the field of\npattern recognition. However, the application of finite mixtures to image\nsegmentation presents some difficulties; especially it's sensible to noise. In\nthis paper we propose a variant of this method which aims to resolve this\nproblem. Our approach proceeds by the characterization of pixels by two\nfeatures: the first one describes the intrinsic properties of the pixel and the\nsecond characterizes the neighborhood of pixel. Then the classification is made\non the base on adaptive distance which privileges the one or the other features\naccording to the spatial position of the pixel in the image. The obtained\nresults have shown a significant improvement of our approach compared to the\nstandard version of EM algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1634v1", 
    "other_authors": "Oussema zayane, besma jouini, Mohamed Ali Mahjoub", 
    "title": "Automatic liver segmentation method in CT images", 
    "arxiv-id": "1204.1634v1", 
    "author": "Mohamed Ali Mahjoub", 
    "publish": "2012-04-07T13:46:24Z", 
    "summary": "The aim of this work is to develop a method for automatic segmentation of the\nliver based on a priori knowledge of the image, such as location and shape of\nthe liver."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1678v1", 
    "other_authors": "Moncef Charfi, Monji Kherallah, Abdelkarim El Baati, Adel M. Alimi", 
    "title": "A New Approach for Arabic Handwritten Postal Addresses Recognition", 
    "arxiv-id": "1204.1678v1", 
    "author": "Adel M. Alimi", 
    "publish": "2012-04-07T20:45:06Z", 
    "summary": "In this paper, we propose an automatic analysis system for the Arabic\nhandwriting postal addresses recognition, by using the beta elliptical model.\nOur system is divided into different steps: analysis, pre-processing and\nclassification. The first operation is the filtering of image. In the second,\nwe remove the border print, stamps and graphics. After locating the address on\nthe envelope, the address segmentation allows the extraction of postal code and\ncity name separately. The pre-processing system and the modeling approach are\nbased on two basic steps. The first step is the extraction of the temporal\norder in the image of the handwritten trajectory. The second step is based on\nthe use of Beta-Elliptical model for the representation of handwritten script.\nThe recognition system is based on Graph-matching algorithm. Our modeling and\nrecognition approaches were validated by using the postal code and city names\nextracted from the Tunisian postal envelopes data. The recognition rate\nobtained is about 98%."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.1704v1", 
    "other_authors": "K. Somasundaram, S. Vimala", 
    "title": "Multi-Level Coding Efficiency with Improved Quality for Image   Compression based on AMBTC", 
    "arxiv-id": "1204.1704v1", 
    "author": "S. Vimala", 
    "publish": "2012-04-08T03:44:13Z", 
    "summary": "In this paper, we have proposed an extended version of Absolute Moment Block\nTruncation Coding (AMBTC) to compress images. Generally the elements of a\nbitplane used in the variants of Block Truncation Coding (BTC) are of size 1\nbit. But it has been extended to two bits in the proposed method. Number of\nstatistical moments preserved to reconstruct the compressed has also been\nraised from 2 to 4. Hence, the quality of the reconstructed images has been\nimproved significantly from 33.62 to 38.12 with the increase in bpp by 1. The\nincreased bpp (3) is further reduced to 1.75in multiple levels: in one level,\nby dropping 4 elements of the bitplane in such a away that the pixel values of\nthe dropped elements can easily be interpolated with out much of loss in the\nquality, in level two, eight elements are dropped and reconstructed later and\nin level three, the size of the statistical moments is reduced. The experiments\nwere carried over standard images of varying intensities. In all the cases, the\nproposed method outperforms the existing AMBTC technique in terms of both PSNR\nand bpp."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2062v1", 
    "other_authors": "Babasaheb G. Patil, Shaila Subbaraman", 
    "title": "SVD-EBP Algorithm for Iris Pattern Recognition", 
    "arxiv-id": "1204.2062v1", 
    "author": "Shaila Subbaraman", 
    "publish": "2012-04-10T07:10:06Z", 
    "summary": "This paper proposes a neural network approach based on Error Back Propagation\n(EBP) for classification of different eye images. To reduce the complexity of\nlayered neural network the dimensions of input vectors are optimized using\nSingular Value Decomposition (SVD). The main of this work is to provide for\nbest method for feature extraction and classification. The details of this\ncombined system named as SVD-EBP system, and results thereof are presented in\nthis paper.\n  Keywords- Singular value decomposition(SVD), Error back Propagation(EBP)."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2073v1", 
    "other_authors": "S. P. Khandait, R. C. Thool, P. D. Khandait", 
    "title": "Automatic facial feature extraction and expression recognition based on   neural network", 
    "arxiv-id": "1204.2073v1", 
    "author": "P. D. Khandait", 
    "publish": "2012-04-10T07:57:53Z", 
    "summary": "In this paper, an approach to the problem of automatic facial feature\nextraction from a still frontal posed image and classification and recognition\nof facial expression and hence emotion and mood of a person is presented. Feed\nforward back propagation neural network is used as a classifier for classifying\nthe expressions of supplied face into seven basic categories like surprise,\nneutral, sad, disgust, fear, happy and angry. For face portion segmentation and\nlocalization, morphological image processing operations are used. Permanent\nfacial features like eyebrows, eyes, mouth and nose are extracted using SUSAN\nedge detection operator, facial geometry, edge projection analysis. Experiments\nare carried out on JAFFE facial expression database and gives better\nperformance in terms of 100% accuracy for training set and 95.26% accuracy for\ntest set."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2114v1", 
    "other_authors": "Jun Yee Ng, Yong Haur Tay", 
    "title": "Image-based Vehicle Classification System", 
    "arxiv-id": "1204.2114v1", 
    "author": "Yong Haur Tay", 
    "publish": "2012-04-10T11:59:10Z", 
    "summary": "Electronic toll collection (ETC) system has been a common trend used for toll\ncollection on toll road nowadays. The implementation of electronic toll\ncollection allows vehicles to travel at low or full speed during the toll\npayment, which help to avoid the traffic delay at toll road. One of the major\ncomponents of an electronic toll collection is the automatic vehicle detection\nand classification (AVDC) system which is important to classify the vehicle so\nthat the toll is charged according to the vehicle classes. Vision-based vehicle\nclassification system is one type of vehicle classification system which adopt\ncamera as the input sensing device for the system. This type of system has\nadvantage over the rest for it is cost efficient as low cost camera is used.\nThe implementation of vision-based vehicle classification system requires lower\ninitial investment cost and very suitable for the toll collection trend\nmigration in Malaysia from single ETC system to full-scale multi-lane free flow\n(MLFF). This project includes the development of an image-based vehicle\nclassification system as an effort to seek for a robust vision-based vehicle\nclassification system. The techniques used in the system include\nscale-invariant feature transform (SIFT) technique, Canny's edge detector,\nK-means clustering as well as Euclidean distance matching. In this project, a\nunique way to image description as matching medium is proposed. This\ndistinctiveness of method is analogous to the human DNA concept which is highly\nunique. The system is evaluated on open datasets and return promising results."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2134v1", 
    "other_authors": "Fernand Meyer", 
    "title": "The steepest watershed: from graphs to images", 
    "arxiv-id": "1204.2134v1", 
    "author": "Fernand Meyer", 
    "publish": "2012-04-10T13:08:34Z", 
    "summary": "The watershed is a powerful tool for segmenting objects whose contours appear\nas crest lines on a gradient image. The watershed transform associates to a\ntopographic surface a partition into catchment basins, defined as attraction\nzones of a drop of water falling on the relief and following a line of steepest\ndescent. Unfortunately, catchment basins may overlap and do not form a\npartition. Moreover, current watershed algorithms, being shortsighted, do not\ncorrectly estimate the steepness of the downwards trajectories and overestimate\nthe overlapping zones of catchment basins. An arbitrary division of these zones\nbetween adjacent catchment basin results in a poor localization of the\ncontours. We propose an algorithm without myopia, which considers the total\nlength of a trajectory for estimating its steepness. We first consider\ntopographic surfaces defined on node weighted graphs. The graphs are pruned in\norder to eliminate all downwards trajectories which are not the steepest. An\niterative algorithm with simple neighborhood operations performs the pruning\nand constructs the catchment basins. The algorithm is then adapted to gray tone\nimages. The graph structure itself is encoded as an image thanks to the fixed\nneighborhood structure of grids. A pair of adaptative erosions and dilations\nprune the graph and extend the catchment basins. As a result one obtains a\nprecise detection of the catchment basins and a graph of the steepest\ntrajectories. A last iterative algorithm allows to follow selected downwards\ntrajectories in order to detect particular structures such as rivers or thalweg\nlines of the topographic surface."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2294v1", 
    "other_authors": "Wan Mohd Yaakob Wan Bejuri, Mohd Murtadha Mohamad, Maimunah Sapri, Mohd Adly Rosly", 
    "title": "Ubiquitous WLAN/Camera Positioning using Inverse Intensity Chromaticity   Space-based Feature Detection and Matching: A Preliminary Result", 
    "arxiv-id": "1204.2294v1", 
    "author": "Mohd Adly Rosly", 
    "publish": "2012-04-10T22:05:34Z", 
    "summary": "This paper present our new intensity chromaticity space-based feature\ndetection and matching algorithm. This approach utilizes hybridization of\nwireless local area network and camera internal sensor which to receive signal\nstrength from a access point and the same time retrieve interest point\ninformation from hallways. This information is combined by model fitting\napproach in order to find the absolute of user target position. No conventional\nsearching algorithm is required, thus it is expected reducing the computational\ncomplexity. Finally we present pre-experimental results to illustrate the\nperformance of the localization system for an indoor environment set-up."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2336v1", 
    "other_authors": "R. Venkata Ramana Chary, D. Rajya Lakshmi, K. V. N. Sunitha", 
    "title": "Feature Extraction Methods for Color Image Similarity", 
    "arxiv-id": "1204.2336v1", 
    "author": "K. V. N. Sunitha", 
    "publish": "2012-04-11T04:45:51Z", 
    "summary": "Many User interactive systems are proposed all methods are trying to\nimplement as a user friendly and various approaches proposed but most of the\nsystems not reached to the use specifications like user friendly systems with\nuser interest, all proposed method implemented basic techniques some are\nimproved methods also propose but not reaching to the user specifications. In\nthis proposed paper we concentrated on image retrieval system with in early\ndays many user interactive systems performed with basic concepts but such\nsystems are not reaching to the user specifications and not attracted to the\nuser so a lot of research interest in recent years with new specifications,\nrecent approaches have user is interested in friendly interacted methods are\nexpecting, many are concentrated for improvement in all methods. In this\nproposed system we focus on the retrieval of images within a large image\ncollection based on color projections and different mathematical approaches are\nintroduced and applied for retrieval of images. before Appling proposed methods\nimages are sub grouping using threshold values, in this paper R G B color\ncombinations considered for retrieval of images, in proposed methods are\nimplemented and results are included, through results it is observed that we\nobtaining efficient results comparatively previous and existing."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2358v2", 
    "other_authors": "Lei Zhang, Meng Yang, Xiangchu Feng, Yi Ma, David Zhang", 
    "title": "Collaborative Representation based Classification for Face Recognition", 
    "arxiv-id": "1204.2358v2", 
    "author": "David Zhang", 
    "publish": "2012-04-11T07:13:20Z", 
    "summary": "By coding a query sample as a sparse linear combination of all training\nsamples and then classifying it by evaluating which class leads to the minimal\ncoding residual, sparse representation based classification (SRC) leads to\ninteresting results for robust face recognition. It is widely believed that the\nl1- norm sparsity constraint on coding coefficients plays a key role in the\nsuccess of SRC, while its use of all training samples to collaboratively\nrepresent the query sample is rather ignored. In this paper we discuss how SRC\nworks, and show that the collaborative representation mechanism used in SRC is\nmuch more crucial to its success of face classification. The SRC is a special\ncase of collaborative representation based classification (CRC), which has\nvarious instantiations by applying different norms to the coding residual and\ncoding coefficient. More specifically, the l1 or l2 norm characterization of\ncoding residual is related to the robustness of CRC to outlier facial pixels,\nwhile the l1 or l2 norm characterization of coding coefficient is related to\nthe degree of discrimination of facial features. Extensive experiments were\nconducted to verify the face recognition accuracy and efficiency of CRC with\ndifferent instantiations."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.2912v1", 
    "other_authors": "Xi Li, Chunhua Shen, Qinfeng Shi, Anthony Dick, Anton van den Hengel", 
    "title": "Non-sparse Linear Representations for Visual Tracking with Online   Reservoir Metric Learning", 
    "arxiv-id": "1204.2912v1", 
    "author": "Anton van den Hengel", 
    "publish": "2012-04-13T08:16:41Z", 
    "summary": "Most sparse linear representation-based trackers need to solve a\ncomputationally expensive L1-regularized optimization problem. To address this\nproblem, we propose a visual tracker based on non-sparse linear\nrepresentations, which admit an efficient closed-form solution without\nsacrificing accuracy. Moreover, in order to capture the correlation information\nbetween different feature dimensions, we learn a Mahalanobis distance metric in\nan online fashion and incorporate the learned metric into the optimization\nproblem for obtaining the linear representation. We show that online metric\nlearning using proximity comparison significantly improves the robustness of\nthe tracking, especially on those sequences exhibiting drastic appearance\nchanges. Furthermore, in order to prevent the unbounded growth in the number of\ntraining samples for the metric learning, we design a time-weighted reservoir\nsampling method to maintain and update limited-sized foreground and background\nsample buffers for balancing sample diversity and adaptability. Experimental\nresults on challenging videos demonstrate the effectiveness and robustness of\nthe proposed tracker."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.4257v1", 
    "other_authors": "Aamir Khan, Muhammad Farhan, Asar Ali", 
    "title": "Speech Recognition: Increasing Efficiency of Support Vector Machines", 
    "arxiv-id": "1204.4257v1", 
    "author": "Asar Ali", 
    "publish": "2012-04-19T06:10:02Z", 
    "summary": "With the advancement of communication and security technologies, it has\nbecome crucial to have robustness of embedded biometric systems. This paper\npresents the realization of such technologies which demands reliable and\nerror-free biometric identity verification systems. High dimensional patterns\nare not permitted due to eigen-decomposition in high dimensional feature space\nand degeneration of scattering matrices in small size sample. Generalization,\ndimensionality reduction and maximizing the margins are controlled by\nminimizing weight vectors. Results show good pattern by multimodal biometric\nsystem proposed in this paper. This paper is aimed at investigating a biometric\nidentity system using Support Vector Machines(SVMs) and Lindear Discriminant\nAnalysis(LDA) with MFCCs and implementing such system in real-time using\nSignalWAVE."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.5416v1", 
    "other_authors": "Manoj Kumar, Vikas Kaushik, Pradeep Singla", 
    "title": "A New Approach of Improving CFA Image for Digital Camera's", 
    "arxiv-id": "1204.5416v1", 
    "author": "Pradeep Singla", 
    "publish": "2012-04-24T15:45:37Z", 
    "summary": "This paper work directly towards the improving the quality of the image for\nthe digital cameras and other visual capturing products. In this Paper, the\nauthors clearly defines the problems occurs in the CFA image. A different\nmethodology for removing the noise is discuses in the paper for color\ncorrection and color balancing of the image. At the same time, the authors also\nproposed a new methodology of providing denoisiing process before the\ndemosaickingfor the improving the image quality of CFA which is much efficient\nthen the other previous defined. The demosaicking process for producing the\ncolors in the image in a best way is also discuss."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.5431v2", 
    "other_authors": "Mohammad Tofighi, Hashem Kalbkhani, Mahrokh G. Shayesteh, Mehdi Ghasemzadeh", 
    "title": "Robust Head Pose Estimation Using Contourlet Transform", 
    "arxiv-id": "1204.5431v2", 
    "author": "Mehdi Ghasemzadeh", 
    "publish": "2012-04-24T17:08:04Z", 
    "summary": "Estimating pose of the head is an important preprocessing step in many\npattern recognition and computer vision systems such as face recognition. Since\nthe performance of the face recognition systems is greatly affected by the\nposes of the face, how to estimate the accurate pose of the face in human face\nimage is still a challenging problem. In this paper, we represent a novel\nmethod for head pose estimation. To enhance the efficiency of the estimation we\nuse contourlet transform for feature extraction. Contourlet transform is\nmulti-resolution, multi-direction transform. In order to reduce the feature\nspace dimension and obtain appropriate features we use LDA (Linear Discriminant\nAnalysis) and PCA (Principal Component Analysis) to remove ineffcient features.\nThen, we apply different classifiers such as k-nearest neighborhood (knn) and\nminimum distance. We use the public available FERET database to evaluate the\nperformance of proposed method. Simulation results indicate the superior\nrobustness of the proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.6326v2", 
    "other_authors": "Jean-Philippe Jodoin, Guillaume-Alexandre Bilodeau, Nicolas Saunier", 
    "title": "Background subtraction based on Local Shape", 
    "arxiv-id": "1204.6326v2", 
    "author": "Nicolas Saunier", 
    "publish": "2012-04-27T20:26:34Z", 
    "summary": "We present a novel approach to background subtraction that is based on the\nlocal shape of small image regions. In our approach, an image region centered\non a pixel is mod-eled using the local self-similarity descriptor. We aim at\nobtaining a reliable change detection based on local shape change in an image\nwhen foreground objects are moving. The method first builds a background model\nand compares the local self-similarities between the background model and the\nsubsequent frames to distinguish background and foreground objects.\nPost-processing is then used to refine the boundaries of moving objects.\nResults show that this approach is promising as the foregrounds obtained are\ncom-plete, although they often include shadows."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.6458v1", 
    "other_authors": "Junyan Wang, Kap Luk Chan", 
    "title": "Active Contour with A Tangential Component", 
    "arxiv-id": "1204.6458v1", 
    "author": "Kap Luk Chan", 
    "publish": "2012-04-29T07:17:28Z", 
    "summary": "Conventional edge-based active contours often require the normal component of\nan edge indicator function on the optimal contours to approximate zero, while\nthe tangential component can still be significant. In real images, the full\ngradients of the edge indicator function along the object boundaries are often\nsmall. Hence, the curve evolution of edge-based active contours can terminate\nearly before converging to the object boundaries with a careless contour\ninitialization. We propose a novel Geodesic Snakes (GeoSnakes) active contour\nthat requires the full gradients of the edge indicator to vanish at the optimal\nsolution. Besides, the conventional curve evolution approach for minimizing\nactive contour energy cannot fully solve the Euler-Lagrange (EL) equation of\nour GeoSnakes active contour, causing a Pseudo Stationary Phenomenon (PSP). To\naddress the PSP problem, we propose an auxiliary curve evolution equation,\nnamed the equilibrium flow (EF) equation. Based on the EF and the conventional\ncurve evolution, we obtain a solution to the full EL equation of GeoSnakes\nactive contour. Experimental results validate the proposed geometrical\ninterpretation of the early termination problem, and they also show that the\nproposed method overcomes the problem."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2011.04.006", 
    "link": "http://arxiv.org/pdf/1204.6563v2", 
    "other_authors": "Prabhu Kaliamoorthi, Ramakrishna Kakarala", 
    "title": "Parametric annealing: a stochastic search method for human pose tracking", 
    "arxiv-id": "1204.6563v2", 
    "author": "Ramakrishna Kakarala", 
    "publish": "2012-04-30T07:04:08Z", 
    "summary": "Model based methods to marker-free motion capture have a very high\ncomputational overhead that make them unattractive. In this paper we describe a\nmethod that improves on existing global optimization techniques to tracking\narticulated objects. Our method improves on the state-of-the-art Annealed\nParticle Filter (APF) by reusing samples across annealing layers and by using\nan adaptive parametric density for diffusion. We compare the proposed method\nwith APF on a scalable problem and study how the two methods scale with the\ndimensionality, multi-modality and the range of search. Then we perform\nsensitivity analysis on the parameters of our algorithm and show that it\ntolerates a wide range of parameter settings. We also show results on tracking\nhuman pose from the widely-used Human Eva I dataset. Our results show that the\nproposed method reduces the tracking error despite using less than 50% of the\ncomputational resources as APF. The tracked output also shows a significant\nqualitative improvement over APF as demonstrated through image and video\nresults."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6215-8919", 
    "link": "http://arxiv.org/pdf/1204.6653v1", 
    "other_authors": "Vini Katyal, Aviral, Deepesh Srivastava", 
    "title": "Elimination of Glass Artifacts and Object Segmentation", 
    "arxiv-id": "1204.6653v1", 
    "author": "Deepesh Srivastava", 
    "publish": "2012-04-30T14:47:45Z", 
    "summary": "Many images nowadays are captured from behind the glasses and may have\ncertain stains discrepancy because of glass and must be processed to make\ndifferentiation between the glass and objects behind it. This research paper\nproposes an algorithm to remove the damaged or corrupted part of the image and\nmake it consistent with other part of the image and to segment objects behind\nthe glass. The damaged part is removed using total variation inpainting method\nand segmentation is done using kmeans clustering, anisotropic diffusion and\nwatershed transformation. The final output is obtained by interpolation. This\nalgorithm can be useful to applications in which some part of the images are\ncorrupted due to data transmission or needs to segment objects from an image\nfor further processing."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6215-8919", 
    "link": "http://arxiv.org/pdf/1207.0805v3", 
    "other_authors": "G. Geethu Lakshmi", 
    "title": "Anatomical Structure Segmentation in Liver MRI Images", 
    "arxiv-id": "1207.0805v3", 
    "author": "G. Geethu Lakshmi", 
    "publish": "2012-07-03T14:32:20Z", 
    "summary": "Segmentation of medical images is a challenging task owing to their\ncomplexity. A standard segmentation problem within Magnetic Resonance Imaging\n(MRI) is the task of labeling voxels according to their tissue type. Image\nsegmentation provides volumetric quantification of liver area and thus helps in\nthe diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice,\nHemochromatosis etc.This work deals with comparison of segmentation by applying\nLevel Set Method,Fuzzy Level Information C-Means Clustering Algorithm and\nGradient Vector Flow Snake Algorithm.The results are compared using the\nparameters such as Number of pixels correctly classified, and percentage of\narea segmented."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6215-8919", 
    "link": "http://arxiv.org/pdf/1207.1114v3", 
    "other_authors": "Yao Lu, Kaizhu Huang, Cheng-Lin Liu", 
    "title": "A Fast Projected Fixed-Point Algorithm for Large Graph Matching", 
    "arxiv-id": "1207.1114v3", 
    "author": "Cheng-Lin Liu", 
    "publish": "2012-07-03T18:20:25Z", 
    "summary": "We propose a fast approximate algorithm for large graph matching. A new\nprojected fixed-point method is defined and a new doubly stochastic projection\nis adopted to derive the algorithm. Previous graph matching algorithms suffer\nfrom high computational complexity and therefore do not have good scalability\nwith respect to graph size. For matching two weighted graphs of $n$ nodes, our\nalgorithm has time complexity only $O(n^3)$ per iteration and space complexity\n$O(n^2)$. In addition to its scalability, our algorithm is easy to implement,\nrobust, and able to match undirected weighted attributed graphs of different\nsizes. While the convergence rate of previous iterative graph matching\nalgorithms is unknown, our algorithm is theoretically guaranteed to converge at\na linear rate. Extensive experiments on large synthetic and real graphs (more\nthan 1,000 nodes) were conducted to evaluate the performance of various\nalgorithms. Results show that in most cases our proposed algorithm achieves\nbetter performance than previous state-of-the-art algorithms in terms of both\nspeed and accuracy in large graph matching. In particular, with high accuracy,\nour algorithm takes only a few seconds (in a PC) to match two graphs of 1,000\nnodes."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.1551v1", 
    "other_authors": "Shervan Fekri-Ershad, Mohammad Saberi, Farshad Tajeripour", 
    "title": "An Innovative Skin Detection Approach Using Color Based Image Retrieval   Technique", 
    "arxiv-id": "1207.1551v1", 
    "author": "Farshad Tajeripour", 
    "publish": "2012-07-06T08:04:38Z", 
    "summary": "From The late 90th, \"Skin Detection\" becomes one of the major problems in\nimage processing. If \"Skin Detection\" will be done in high accuracy, it can be\nused in many cases as face recognition, Human Tracking and etc. Until now so\nmany methods were presented for solving this problem. In most of these methods,\ncolor space was used to extract feature vector for classifying pixels, but the\nmost of them have not good accuracy in detecting types of skin. The proposed\napproach in this paper is based on \"Color based image retrieval\" (CBIR)\ntechnique. In this method, first by means of CBIR method and image tiling and\nconsidering the relation between pixel and its neighbors, a feature vector\nwould be defined and then with using a training step, detecting the skin in the\ntest stage. The result shows that the presenting approach, in addition to its\nhigh accuracy in detecting type of skin, has no sensitivity to illumination\nintensity and moving face orientation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.1649v1", 
    "other_authors": "N\u00fabia Rosa da Silva, Odemir Martinez Bruno", 
    "title": "Analysis of Multi-Scale Fractal Dimension to Classify Human Motion", 
    "arxiv-id": "1207.1649v1", 
    "author": "Odemir Martinez Bruno", 
    "publish": "2012-07-06T15:10:49Z", 
    "summary": "In recent years there has been considerable interest in human action\nrecognition. Several approaches have been developed in order to enhance the\nautomatic video analysis. Although some developments have been achieved by the\ncomputer vision community, the properly classification of human motion is still\na hard and challenging task. The objective of this study is to investigate the\nuse of 3D multi-scale fractal dimension to recognize motion patterns in videos.\nIn order to develop a robust strategy for human motion classification, we\nproposed a method where the Fourier transform is used to calculate the\nderivative in which all data points are deemed. Our results shown that\ndifferent accuracy rates can be found for different databases. We believe that\nin specific applications our results are the first step to develop an automatic\nmonitoring system, which can be applied in security systems, traffic\nmonitoring, biology, physical therapy, cardiovascular disease among many\nothers."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.1922v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zaky", 
    "title": "Spatial And Spectral Quality Evaluation Based On Edges Regions Of   Satellite Image Fusion", 
    "arxiv-id": "1207.1922v1", 
    "author": "Ali A. Al-Zaky", 
    "publish": "2012-07-08T23:06:38Z", 
    "summary": "The Quality of image fusion is an essential determinant of the value of\nprocessing images fusion for many applications. Spatial and spectral qualities\nare the two important indexes that used to evaluate the quality of any fused\nimage. However, the jury is still out of fused image's benefits if it compared\nwith its original images. In addition, there is a lack of measures for\nassessing the objective quality of the spatial resolution for the fusion\nmethods. Therefore, an objective quality of the spatial resolution assessment\nfor fusion images is required. Most important details of the image are in edges\nregions, but most standards of image estimation do not depend upon specifying\nthe edges in the image and measuring their edges. However, they depend upon the\ngeneral estimation or estimating the uniform region, so this study deals with\nnew method proposed to estimate the spatial resolution by Contrast Statistical\nAnalysis (CSA) depending upon calculating the contrast of the edge, non edge\nregions and the rate for the edges regions. Specifying the edges in the image\nis made by using Soble operator with different threshold values. In addition,\nestimating the color distortion added by image fusion based on Histogram\nAnalysis of the edge brightness values of all RGB-color bands and Lcomponent."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.2346v3", 
    "other_authors": "Rocio Gonalez-Diaz, Javier Lamar, Ronald Umble", 
    "title": "Cups Products in Z2-Cohomology of 3D Polyhedral Complexes", 
    "arxiv-id": "1207.2346v3", 
    "author": "Ronald Umble", 
    "publish": "2012-07-10T13:40:40Z", 
    "summary": "Let $I=(\\mathbb{Z}^3,26,6,B)$ be a 3D digital image, let $Q(I)$ be the\nassociated cubical complex and let $\\partial Q(I)$ be the subcomplex of $Q(I)$\nwhose maximal cells are the quadrangles of $Q(I)$ shared by a voxel of $B$ in\nthe foreground -- the object under study -- and by a voxel of\n$\\mathbb{Z}^3\\smallsetminus B$ in the background -- the ambient space. We show\nhow to simplify the combinatorial structure of $\\partial Q(I)$ and obtain a 3D\npolyhedral complex $P(I)$ homeomorphic to $\\partial Q(I)$ but with fewer cells.\nWe introduce an algorithm that computes cup products on\n$H^*(P(I);\\mathbb{Z}_2)$ directly from the combinatorics. The computational\nmethod introduced here can be effectively applied to any polyhedral complex\nembedded in $\\mathbb{R}^3$."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.2426v1", 
    "other_authors": "Issam Qaffou, Mohammed Sadgal, Abdelaziz Elfazziki", 
    "title": "A Multi-Agents Architecture to Learn Vision Operators and their   Parameters", 
    "arxiv-id": "1207.2426v1", 
    "author": "Abdelaziz Elfazziki", 
    "publish": "2012-07-10T17:56:00Z", 
    "summary": "In a vision system, every task needs that the operators to apply should be\n{\\guillemotleft} well chosen {\\guillemotright} and their parameters should be\nalso {\\guillemotleft} well adjusted {\\guillemotright}. The diversity of\noperators and the multitude of their parameters constitute a big challenge for\nusers. As it is very difficult to make the {\\guillemotleft} right\n{\\guillemotright} choice, lack of a specific rule, many disadvantages appear\nand affect the computation time and especially the quality of results. In this\npaper we present a multi-agent architecture to learn the best operators to\napply and their best parameters for a class of images. Our architecture\nconsists of three types of agents: User Agent, Operator Agent and Parameter\nAgent. The User Agent determines the phases of treatment, a library of\noperators and the possible values of their parameters. The Operator Agent\nconstructs all possible combinations of operators and the Parameter Agent, the\ncore of the architecture, adjusts the parameters of each combination by\ntreating a large number of images. Through the reinforcement learning\nmechanism, our architecture does not consider only the system opportunities but\nalso the user preferences."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.2537v1", 
    "other_authors": "Sambhunath Biswas, Amrita Biswas", 
    "title": "Face Recognition Algorithms based on Transformed Shape Features", 
    "arxiv-id": "1207.2537v1", 
    "author": "Amrita Biswas", 
    "publish": "2012-07-11T03:45:18Z", 
    "summary": "Human face recognition is, indeed, a challenging task, especially under the\nillumination and pose variations. We examine in the present paper effectiveness\nof two simple algorithms using coiflet packet and Radon transforms to recognize\nhuman faces from some databases of still gray level images, under the\nenvironment of illumination and pose variations. Both the algorithms convert\n2-D gray level training face images into their respective depth maps or\nphysical shape which are subsequently transformed by Coiflet packet and Radon\ntransforms to compute energy for feature extraction. Experiments show that such\ntransformed shape features are robust to illumination and pose variations. With\nthe features extracted, training classes are optimally separated through linear\ndiscriminant analysis (LDA), while classification for test face images is made\nthrough a k-NN classifier, based on L1 norm and Mahalanobis distance measures.\nProposed algorithms are then tested on face images that differ in\nillumination,expression or pose separately, obtained from three\ndatabases,namely, ORL, Yale and Essex-Grimace databases. Results, so obtained,\nare compared with two different existing algorithms.Performance using\nDaubechies wavelets is also examined. It is seen that the proposed Coiflet\npacket and Radon transform based algorithms have significant performance,\nespecially under different illumination conditions and pose variation.\nComparison shows the proposed algorithms are superior."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.2602v1", 
    "other_authors": "Seyed Amir Mohammadi, Mohammad Reza Mahzoun", 
    "title": "A Novel Approach Coloured Object Tracker with Adaptive Model and   Bandwidth using Mean Shift Algorithm", 
    "arxiv-id": "1207.2602v1", 
    "author": "Mohammad Reza Mahzoun", 
    "publish": "2012-07-11T11:29:36Z", 
    "summary": "The traditional color-based mean-shift tracking algorithm is popular among\ntracking methods due to its simple and efficient procedure, however, the lack\nof dynamism in its target model makes it unsuitable for tracking objects which\nhave changes in their sizes and shapes. In this paper, we propose a fast novel\nthreephase colored object tracker algorithm based on mean shift idea while\nutilizing adaptive model. The proposed method can improve the mentioned\nweaknesses of the original mean-shift algorithm. The experimental results show\nthat the new method is feasible, robust and has acceptable speed in comparison\nwith other algorithms.15 page,"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.2641v2", 
    "other_authors": "Teun Baar, Wiger van Houten, Zeno Geradts", 
    "title": "Camera identification by grouping images from database, based on shared   noise patterns", 
    "arxiv-id": "1207.2641v2", 
    "author": "Zeno Geradts", 
    "publish": "2012-07-11T13:58:35Z", 
    "summary": "Previous research showed that camera specific noise patterns, so-called\nPRNU-patterns, are extracted from images and related images could be found. In\nthis particular research the focus is on grouping images from a database, based\non a shared noise pattern as an identification method for cameras. Using the\nmethod as described in this article, groups of images, created using the same\ncamera, could be linked from a large database of images. Using MATLAB\nprogramming, relevant image noise patterns are extracted from images much\nquicker than common methods by the use of faster noise extraction filters and\nimprovements to reduce the calculation costs. Relating noise patterns, with a\ncorrelation above a certain threshold value, can quickly be matched. Hereby,\nfrom a database of images, groups of relating images could be linked and the\nmethod could be used to scan a large number of images for suspect noise\npatterns."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.3127v1", 
    "other_authors": "Quan Wang, Yan Ou, A. Agung Julius, Kim L. Boyer, Min Jun Kim", 
    "title": "Tracking Tetrahymena Pyriformis Cells using Decision Trees", 
    "arxiv-id": "1207.3127v1", 
    "author": "Min Jun Kim", 
    "publish": "2012-07-13T01:22:04Z", 
    "summary": "Matching cells over time has long been the most difficult step in cell\ntracking. In this paper, we approach this problem by recasting it as a\nclassification problem. We construct a feature set for each cell, and compute a\nfeature difference vector between a cell in the current frame and a cell in a\nprevious frame. Then we determine whether the two cells represent the same cell\nover time by training decision trees as our binary classifiers. With the output\nof decision trees, we are able to formulate an assignment problem for our cell\nassociation task and solve it using a modified version of the Hungarian\nalgorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2012.4305", 
    "link": "http://arxiv.org/pdf/1207.3142v2", 
    "other_authors": "Bing Li, Weihua Xiong, Weiming Hu", 
    "title": "Color Constancy based on Image Similarity via Bilayer Sparse Coding", 
    "arxiv-id": "1207.3142v2", 
    "author": "Weiming Hu", 
    "publish": "2012-07-13T04:46:19Z", 
    "summary": "Computational color constancy is a very important topic in computer vision\nand has attracted many researchers' attention. Recently, lots of research has\nshown the effects of high level visual content information for illumination\nestimation. However, all of these existing methods are essentially\ncombinational strategies in which image's content analysis is only used to\nguide the combination or selection from a variety of individual illumination\nestimation methods. In this paper, we propose a novel bilayer sparse coding\nmodel for illumination estimation that considers image similarity in terms of\nboth low level color distribution and high level image scene content\nsimultaneously. For the purpose, the image's scene content information is\nintegrated with its color distribution to obtain optimal illumination\nestimation model. The experimental results on two real-world image sets show\nthat our algorithm is superior to other prevailing illumination estimation\nmethods, even better than combinational methods."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.ultras.2012.03.011", 
    "link": "http://arxiv.org/pdf/1207.3370v1", 
    "other_authors": "Talita Perciano, Matthew Urban, Nelson D. A. Mascarenhas, Mostafa Fatemi, Alejandro C. Frery, Glauber T. Silva", 
    "title": "Deconvolution of vibroacoustic images using a simulation model based on   a three dimensional point spread function", 
    "arxiv-id": "1207.3370v1", 
    "author": "Glauber T. Silva", 
    "publish": "2012-07-13T21:37:04Z", 
    "summary": "Vibro-acoustography (VA) is a medical imaging method based on the\ndifference-frequency generation produced by the mixture of two focused\nultrasound beams. VA has been applied to different problems in medical imaging\nsuch as imaging bones, microcalcifications in the breast, mass lesions, and\ncalcified arteries. The obtained images may have a resolution of 0.7--0.8 mm.\nCurrent VA systems based on confocal or linear array transducers generate\nC-scan images at the beam focal plane. Images on the axial plane are also\npossible, however the system resolution along depth worsens when compared to\nthe lateral one. Typical axial resolution is about 1.0 cm. Furthermore, the\nelevation resolution of linear array systems is larger than that in lateral\ndirection. This asymmetry degrades C-scan images obtained using linear arrays.\nThe purpose of this article is to study VA image restoration based on a 3D\npoint spread function (PSF) using classical deconvolution algorithms: Wiener,\nconstrained least-squares (CLSs), and geometric mean filters. To assess the\nfilters' performance, we use an image quality index that accounts for\ncorrelation loss, luminance and contrast distortion. Results for simulated VA\nimages show that the quality index achieved with the Wiener filter is 0.9 (1\nindicates perfect restoration). This filter yielded the best result in\ncomparison with the other ones. Moreover, the deconvolution algorithms were\napplied to an experimental VA image of a phantom composed of three stretched\n0.5 mm wires. Experiments were performed using transducer driven at two\nfrequencies, 3075 kHz and 3125 kHz, which resulted in the difference-frequency\nof 50 kHz. Restorations with the theoretical line spread function (LSF) did not\nrecover sufficient information to identify the wires in the images. However,\nusing an estimated LSF the obtained results displayed enough information to\nspot the wires in the images."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.ultras.2012.03.011", 
    "link": "http://arxiv.org/pdf/1207.3510v2", 
    "other_authors": "Quan Wang", 
    "title": "HMRF-EM-image: Implementation of the Hidden Markov Random Field Model   and its Expectation-Maximization Algorithm", 
    "arxiv-id": "1207.3510v2", 
    "author": "Quan Wang", 
    "publish": "2012-07-15T14:50:17Z", 
    "summary": "In this project, we study the hidden Markov random field (HMRF) model and its\nexpectation-maximization (EM) algorithm. We implement a MATLAB toolbox named\nHMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This\ntoolbox also implements edge-prior-preserving image segmentation, and can be\neasily reconfigured for other problems, such as 3D image segmentation."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.ultras.2012.03.011", 
    "link": "http://arxiv.org/pdf/1207.3538v3", 
    "other_authors": "Quan Wang", 
    "title": "Kernel Principal Component Analysis and its Applications in Face   Recognition and Active Shape Models", 
    "arxiv-id": "1207.3538v3", 
    "author": "Quan Wang", 
    "publish": "2012-07-15T20:28:26Z", 
    "summary": "Principal component analysis (PCA) is a popular tool for linear\ndimensionality reduction and feature extraction. Kernel PCA is the nonlinear\nform of PCA, which better exploits the complicated spatial structure of\nhigh-dimensional features. In this paper, we first review the basic ideas of\nPCA and kernel PCA. Then we focus on the reconstruction of pre-images for\nkernel PCA. We also give an introduction on how PCA is used in active shape\nmodels (ASMs), and discuss how kernel PCA can be applied to improve traditional\nASMs. Then we show some experimental results to compare the performance of\nkernel PCA and standard PCA for classification problems. We also implement the\nkernel PCA-based ASMs, and use it to construct human face models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2012.2316", 
    "link": "http://arxiv.org/pdf/1207.3576v2", 
    "other_authors": "S. Padmavathi, N. Archana, K. P. Soman", 
    "title": "Hierarchical Approach for Total Variation Digital Image Inpainting", 
    "arxiv-id": "1207.3576v2", 
    "author": "K. P. Soman", 
    "publish": "2012-07-16T04:51:07Z", 
    "summary": "The art of recovering an image from damage in an undetectable form is known\nas inpainting. The manual work of inpainting is most often a very time\nconsuming process. Due to digitalization of this technique, it is automatic and\nfaster. In this paper, after the user selects the regions to be reconstructed,\nthe algorithm automatically reconstruct the lost regions with the help of the\ninformation surrounding them. The existing methods perform very well when the\nregion to be reconstructed is very small, but fails in proper reconstruction as\nthe area increases. This paper describes a Hierarchical method by which the\narea to be inpainted is reduced in multiple levels and Total Variation(TV)\nmethod is used to inpaint in each level. This algorithm gives better\nperformance when compared with other existing algorithms such as nearest\nneighbor interpolation, Inpainting through Blurring and Sobolev Inpainting."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2012.2316", 
    "link": "http://arxiv.org/pdf/1207.4129v1", 
    "other_authors": "Dragomir Anguelov, Daphne Koller, Hoi-Cheung Pang, Praveen Srinivasan, Sebastian Thrun", 
    "title": "Recovering Articulated Object Models from 3D Range Data", 
    "arxiv-id": "1207.4129v1", 
    "author": "Sebastian Thrun", 
    "publish": "2012-07-11T14:48:13Z", 
    "summary": "We address the problem of unsupervised learning of complex articulated object\nmodels from 3D range data. We describe an algorithm whose input is a set of\nmeshes corresponding to different configurations of an articulated object. The\nalgorithm automatically recovers a decomposition of the object into\napproximately rigid parts, the location of the parts in the different object\ninstances, and the articulated object skeleton linking the parts. Our algorithm\nfirst registers allthe meshes using an unsupervised non-rigid technique\ndescribed in a companion paper. It then segments the meshes using a graphical\nmodel that captures the spatial contiguity of parts. The segmentation is done\nusing the EM algorithm, iterating between finding a decomposition of the object\ninto rigid parts, and finding the location of the parts in the object\ninstances. Although the graphical model is densely connected, the object\ndecomposition step can be performed optimally and efficiently, allowing us to\nidentify a large number of object parts while avoiding local maxima. We\ndemonstrate the algorithm on real world datasets, recovering a 15-part\narticulated model of a human puppet from just 7 different puppet\nconfigurations, as well as a 4 part model of a fiexing arm where significant\nnon-rigid deformation was present."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2012.2316", 
    "link": "http://arxiv.org/pdf/1207.4179v1", 
    "other_authors": "Nebojsa Jojic, Yaron Caspi, Manuel Reyes-Gomez", 
    "title": "Probabilistic index maps for modeling natural signals", 
    "arxiv-id": "1207.4179v1", 
    "author": "Manuel Reyes-Gomez", 
    "publish": "2012-07-12T19:47:14Z", 
    "summary": "One of the major problems in modeling natural signals is that signals with\nvery similar structure may locally have completely different measurements,\ne.g., images taken under different illumination conditions, or the speech\nsignal captured in different environments. While there have been many\nsuccessful attempts to address these problems in application-specific settings,\nwe believe that underlying a large set of problems in signal representation is\na representational deficiency of intensity-derived local measurements that are\nthe basis of most efficient models. We argue that interesting structure in\nsignals is better captured when the signal is de- fined as a matrix whose\nentries are discrete indices to a separate palette of possible measurements. In\norder to model the variability in signal structure, we define a signal class\nnot by a single index map, but by a probability distribution over the index\nmaps, which can be estimated from the data, and which we call probabilistic\nindex maps. The existing algorithm can be adapted to work with this\nrepresentation. Furthermore, the probabilistic index map representation leads\nto algorithms with computational costs proportional to either the size of the\npalette or the log of the size of the palette, making the cost of significantly\nincreased invariance to non-structural changes quite bearable. We illustrate\nthe benefits of the probabilistic index map representation in several\napplications in computer vision and speech processing."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-25085-9_10", 
    "link": "http://arxiv.org/pdf/1207.4308v1", 
    "other_authors": "Maria E. Buemi, Marta Mejail, Julio Jacobo, Alejandro C. Frery, Heitor S. Ramos", 
    "title": "Assessment of SAR Image Filtering using Adaptive Stack Filters", 
    "arxiv-id": "1207.4308v1", 
    "author": "Heitor S. Ramos", 
    "publish": "2012-07-18T09:16:07Z", 
    "summary": "Stack filters are a special case of non-linear filters. They have a good\nperformance for filtering images with different types of noise while preserving\nedges and details. A stack filter decomposes an input image into several binary\nimages according to a set of thresholds. Each binary image is then filtered by\na Boolean function, which characterizes the filter. Adaptive stack filters can\nbe designed to be optimal; they are computed from a pair of images consisting\nof an ideal noiseless image and its noisy version. In this work we study the\nperformance of adaptive stack filters when they are applied to Synthetic\nAperture Radar (SAR) images. This is done by evaluating the quality of the\nfiltered images through the use of suitable image quality indexes and by\nmeasuring the classification accuracy of the resulting images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-25085-9_10", 
    "link": "http://arxiv.org/pdf/1207.5007v1", 
    "other_authors": "Madhur Srivastava, Yashwant Yashu, Satish K. Singh, Prasanta K. Panigrahi", 
    "title": "Multisegmentation through wavelets: Comparing the efficacy of Daubechies   vs Coiflets", 
    "arxiv-id": "1207.5007v1", 
    "author": "Prasanta K. Panigrahi", 
    "publish": "2012-07-20T17:37:27Z", 
    "summary": "In this paper, we carry out a comparative study of the efficacy of wavelets\nbelonging to Daubechies and Coiflet family in achieving image segmentation\nthrough a fast statistical algorithm.The fact that wavelets belonging to\nDaubechies family optimally capture the polynomial trends and those of Coiflet\nfamily satisfy mini-max condition, makes this comparison interesting. In the\ncontext of the present algorithm, it is found that the performance of Coiflet\nwavelets is better, as compared to Daubechies wavelet."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2012.2347", 
    "link": "http://arxiv.org/pdf/1207.5064v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, Dr. N. V. Kalyankar", 
    "title": "A Novel Metric Approach Evaluation For The Spatial Enhancement Of   Pan-Sharpened Images", 
    "arxiv-id": "1207.5064v1", 
    "author": "Dr. N. V. Kalyankar", 
    "publish": "2012-07-20T21:30:35Z", 
    "summary": "Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. The\nQuality of image fusion is an essential determinant of the value of processing\nimages fusion for many applications. Spatial and spectral qualities are the two\nimportant indexes that used to evaluate the quality of any fused image.\nHowever, the jury is still out of fused image's benefits if it compared with\nits original images. In addition, there is a lack of measures for assessing the\nobjective quality of the spatial resolution for the fusion methods. So, an\nobjective quality of the spatial resolution assessment for fusion images is\nrequired. Therefore, this paper describes a new approach proposed to estimate\nthe spatial resolution improve by High Past Division Index (HPDI) upon\ncalculating the spatial-frequency of the edge regions of the image and it deals\nwith a comparison of various analytical techniques for evaluating the Spatial\nquality, and estimating the colour distortion added by image fusion including:\nMG, SG, FCC, SD, En, SNR, CC and NRMSE. In addition, this paper devotes to\nconcentrate on the comparison of various image fusion techniques based on pixel\nand feature fusion technique."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2274385", 
    "link": "http://arxiv.org/pdf/1207.5113v1", 
    "other_authors": "Junyan Wang, Kap Luk Chan", 
    "title": "Piecewise Linear Patch Reconstruction for Segmentation and Description   of Non-smooth Image Structures", 
    "arxiv-id": "1207.5113v1", 
    "author": "Kap Luk Chan", 
    "publish": "2012-07-21T09:38:45Z", 
    "summary": "In this paper, we propose a unified energy minimization model for the\nsegmentation of non-smooth image structures. The energy of piecewise linear\npatch reconstruction is considered as an objective measure of the quality of\nthe segmentation of non-smooth structures. The segmentation is achieved by\nminimizing the single energy without any separate process of feature\nextraction. We also prove that the error of segmentation is bounded by the\nproposed energy functional, meaning that minimizing the proposed energy leads\nto reducing the error of segmentation. As a by-product, our method produces a\ndictionary of optimized orthonormal descriptors for each segmented region. The\nunique feature of our method is that it achieves the simultaneous segmentation\nand description for non-smooth image structures under the same optimization\nframework. The experiments validate our theoretical claims and show the clear\nsuperior performance of our methods over other related methods for segmentation\nof various image textures. We show that our model can be coupled with the\npiecewise smooth model to handle both smooth and non-smooth structures, and we\ndemonstrate that the proposed model is capable of coping with multiple\ndifferent regions through the one-against-all strategy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2274385", 
    "link": "http://arxiv.org/pdf/1207.6774v1", 
    "other_authors": "A. R. Revathi, Dhananjay Kumar", 
    "title": "A Survey Of Activity Recognition And Understanding The Behavior In Video   Survelliance", 
    "arxiv-id": "1207.6774v1", 
    "author": "Dhananjay Kumar", 
    "publish": "2012-07-29T13:07:09Z", 
    "summary": "This paper presents a review of human activity recognition and behaviour\nunderstanding in video sequence. The key objective of this paper is to provide\na general review on the overall process of a surveillance system used in the\ncurrent trend. Visual surveillance system is directed on automatic\nidentification of events of interest, especially on tracking and classification\nof moving objects. The processing step of the video surveillance system\nincludes the following stages: Surrounding model, object representation, object\ntracking, activity recognition and behaviour understanding. It describes\ntechniques that use to define a general set of activities that are applicable\nto a wide range of scenes and environments in video sequence."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2274385", 
    "link": "http://arxiv.org/pdf/1207.7244v1", 
    "other_authors": "Liujuan Cao", 
    "title": "Visual Vocabulary Learning and Its Application to 3D and Mobile Visual   Search", 
    "arxiv-id": "1207.7244v1", 
    "author": "Liujuan Cao", 
    "publish": "2012-06-29T15:07:26Z", 
    "summary": "In this technical report, we review related works and recent trends in visual\nvocabulary based web image search, object recognition, mobile visual search,\nand 3D object retrieval. Especial focuses would be also given for the recent\ntrends in supervised/unsupervised vocabulary optimization, compact descriptor\nfor visual search, as well as in multi-view based 3D object representation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2274385", 
    "link": "http://arxiv.org/pdf/1307.0129v1", 
    "other_authors": "Roozbeh Rajabi, Hassan Ghassemian", 
    "title": "Hyperspectral Data Unmixing Using GNMF Method and Sparseness Constraint", 
    "arxiv-id": "1307.0129v1", 
    "author": "Hassan Ghassemian", 
    "publish": "2013-06-29T16:57:44Z", 
    "summary": "Hyperspectral images contain mixed pixels due to low spatial resolution of\nhyperspectral sensors. Mixed pixels are pixels containing more than one\ndistinct material called endmembers. The presence percentages of endmembers in\nmixed pixels are called abundance fractions. Spectral unmixing problem refers\nto decomposing these pixels into a set of endmembers and abundance fractions.\nDue to nonnegativity constraint on abundance fractions, nonnegative matrix\nfactorization methods (NMF) have been widely used for solving spectral unmixing\nproblem. In this paper we have used graph regularized (GNMF) method with\nsparseness constraint to unmix hyperspectral data. This method applied on\nsimulated data using AVIRIS Indian Pines dataset and USGS library and results\nare quantified based on AAD and SAD measures. Results in comparison with other\nmethods show that the proposed method can unmix data more effectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2274385", 
    "link": "http://arxiv.org/pdf/1307.0277v1", 
    "other_authors": "Sourav Samantaa, Nilanjan Dey, Poulami Das, Suvojit Acharjee, Sheli Sinha Chaudhuri", 
    "title": "Multilevel Threshold Based Gray Scale Image Segmentation using Cuckoo   Search", 
    "arxiv-id": "1307.0277v1", 
    "author": "Sheli Sinha Chaudhuri", 
    "publish": "2013-07-01T06:50:23Z", 
    "summary": "Image Segmentation is a technique of partitioning the original image into\nsome distinct classes. Many possible solutions may be available for segmenting\nan image into a certain number of classes, each one having different quality of\nsegmentation. In our proposed method, multilevel thresholding technique has\nbeen used for image segmentation. A new approach of Cuckoo Search (CS) is used\nfor selection of optimal threshold value. In other words, the algorithm is used\nto achieve the best solution from the initial random threshold values or\nsolutions and to evaluate the quality of a solution correlation function is\nused. Finally, MSE and PSNR are measured to understand the segmentation\nquality."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.0776v1", 
    "other_authors": "Jian Cheng, Tianzi Jiang, Rachid Deriche, Dinggang Shen, Pew-Thian Yap", 
    "title": "Regularized Spherical Polar Fourier Diffusion MRI with Optimal   Dictionary Learning", 
    "arxiv-id": "1307.0776v1", 
    "author": "Pew-Thian Yap", 
    "publish": "2013-07-02T17:47:32Z", 
    "summary": "Compressed Sensing (CS) takes advantage of signal sparsity or compressibility\nand allows superb signal reconstruction from relatively few measurements. Based\non CS theory, a suitable dictionary for sparse representation of the signal is\nrequired. In diffusion MRI (dMRI), CS methods were proposed to reconstruct\ndiffusion-weighted signal and the Ensemble Average Propagator (EAP), and there\nare two kinds of Dictionary Learning (DL) methods: 1) Discrete Representation\nDL (DR-DL), and 2) Continuous Representation DL (CR-DL). DR-DL is susceptible\nto numerical inaccuracy owing to interpolation and regridding errors in a\ndiscretized q-space. In this paper, we propose a novel CR-DL approach, called\nDictionary Learning - Spherical Polar Fourier Imaging (DL-SPFI) for effective\ncompressed-sensing reconstruction of the q-space diffusion-weighted signal and\nthe EAP. In DL-SPFI, an dictionary that sparsifies the signal is learned from\nthe space of continuous Gaussian diffusion signals. The learned dictionary is\nthen adaptively applied to different voxels using a weighted LASSO framework\nfor robust signal reconstruction. The adaptive dictionary is proved to be\noptimal. Compared with the start-of-the-art CR-DL and DR-DL methods proposed by\nMerlet et al. and Bilgic et al., espectively, our work offers the following\nadvantages. First, the learned dictionary is proved to be optimal for Gaussian\ndiffusion signals. Second, to our knowledge, this is the first work to learn a\nvoxel-adaptive dictionary. The importance of the adaptive dictionary in EAP\nreconstruction will be demonstrated theoretically and empirically. Third,\noptimization in DL-SPFI is only performed in a small subspace resided by the\nSPF coefficients, as opposed to the q-space approach utilized by Merlet et al.\nThe experiment results demonstrate the advantages of DL-SPFI over the original\nSPF basis and Bilgic et al.'s method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.0937v1", 
    "other_authors": "Mouhamed Gaith Ayadi, Riadh Bouslimi, Jalel Akaichi", 
    "title": "Extending UML for Conceptual Modeling of Annotation of Medical Images", 
    "arxiv-id": "1307.0937v1", 
    "author": "Jalel Akaichi", 
    "publish": "2013-07-03T08:45:37Z", 
    "summary": "Imaging has occupied a huge role in the management of patients, whether\nhospitalized or not. Depending on the patients clinical problem, a variety of\nimaging modalities were available for use. This gave birth of the annotation of\nmedical image process. The annotation is intended to image analysis and solve\nthe problem of semantic gap. The reason for image annotation is due to increase\nin acquisition of images. Physicians and radiologists feel better while using\nannotation techniques for faster remedy in surgery and medicine due to the\nfollowing reasons: giving details to the patients, searching the present and\npast records from the larger databases, and giving solutions to them in a\nfaster and more accurate way. However, classical conceptual modeling does not\nincorporate the specificity of medical domain specially the annotation of\nmedical image. The design phase is the most important activity in the\nsuccessful building of annotation process. For this reason, we focus in this\npaper on presenting the conceptual modeling of the annotation of medical image\nby defining a new profile using the StarUML extensibility mechanism."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.0998v3", 
    "other_authors": "F. Lu, Z. Chen", 
    "title": "A Unified Framework of Elementary Geometric Transformation   Representation", 
    "arxiv-id": "1307.0998v3", 
    "author": "Z. Chen", 
    "publish": "2013-07-03T12:59:53Z", 
    "summary": "As an extension of projective homology, stereohomology is proposed via an\nextension of Desargues theorem and the extended Desargues configuration.\nGeometric transformations such as reflection, translation, central symmetry,\ncentral projection, parallel projection, shearing, central dilation, scaling,\nand so on are all included in stereohomology and represented as\nHouseholder-Chen elementary matrices. Hence all these geometric transformations\nare called elementary. This makes it possible to represent these elementary\ngeometric transformations in homogeneous square matrices independent of a\nparticular choice of coordinate system."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.1303v1", 
    "other_authors": "Toufiq Parag", 
    "title": "Submodularity of a Set Label Disagreement Function", 
    "arxiv-id": "1307.1303v1", 
    "author": "Toufiq Parag", 
    "publish": "2013-07-02T15:25:09Z", 
    "summary": "A set label disagreement function is defined over the number of variables\nthat deviates from the dominant label. The dominant label is the value assumed\nby the largest number of variables within a set of binary variables. The\nsubmodularity of a certain family of set label disagreement function is\ndiscussed in this manuscript. Such disagreement function could be utilized as a\ncost function in combinatorial optimization approaches for problems defined\nover hypergraphs."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.1437v1", 
    "other_authors": "Yuqian Zhang, Cun Mu, Han-wen Kuo, John Wright", 
    "title": "Toward Guaranteed Illumination Models for Non-Convex Objects", 
    "arxiv-id": "1307.1437v1", 
    "author": "John Wright", 
    "publish": "2013-07-04T18:08:19Z", 
    "summary": "Illumination variation remains a central challenge in object detection and\nrecognition. Existing analyses of illumination variation typically pertain to\nconvex, Lambertian objects, and guarantee quality of approximation in an\naverage case sense. We show that it is possible to build V(vertex)-description\nconvex cone models with worst-case performance guarantees, for non-convex\nLambertian objects. Namely, a natural verification test based on the angle to\nthe constructed cone guarantees to accept any image which is sufficiently\nwell-approximated by an image of the object under some admissible lighting\ncondition, and guarantees to reject any image that does not have a sufficiently\ngood approximation. The cone models are generated by sampling point\nilluminations with sufficient density, which follows from a new perturbation\nbound for point images in the Lambertian model. As the number of point images\nrequired for guaranteed verification may be large, we introduce a new\nformulation for cone preserving dimensionality reduction, which leverages tools\nfrom sparse and low-rank decomposition to reduce the complexity, while\ncontrolling the approximation error with respect to the original cone."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.2434v1", 
    "other_authors": "Firouz A. Al-Wassai, N. V. Kalyankar", 
    "title": "Major Limitations of Satellite images", 
    "arxiv-id": "1307.2434v1", 
    "author": "N. V. Kalyankar", 
    "publish": "2013-07-09T13:01:46Z", 
    "summary": "Remote sensing has proven to be a powerful tool for the monitoring of the\nEarth surface to improve our perception of our surroundings has led to\nunprecedented developments in sensor and information technologies. However,\ntechnologies for effective use of the data and for extracting useful\ninformation from the data of Remote sensing are still very limited since no\nsingle sensor combines the optimal spectral, spatial and temporal resolution.\nThis paper briefly reviews the limitations of satellite remote sensing. Also,\nreviews on the problems of image fusion techniques. The conclusion of this,\nAccording to literature, the remote sensing is still the lack of software tools\nfor effective information extraction from remote sensing data. The trade-off in\nspectral and spatial resolution will remain and new advanced data fusion\napproaches are needed to make optimal use of remote sensors for extract the\nmost useful information."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-40811-3_80", 
    "link": "http://arxiv.org/pdf/1307.2440v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar", 
    "title": "Image Fusion Technologies In Commercial Remote Sensing Packages", 
    "arxiv-id": "1307.2440v1", 
    "author": "N. V. Kalyankar", 
    "publish": "2013-07-09T13:14:11Z", 
    "summary": "Several remote sensing software packages are used to the explicit purpose of\nanalyzing and visualizing remotely sensed data, with the developing of remote\nsensing sensor technologies from last ten years. Accord-ing to literature, the\nremote sensing is still the lack of software tools for effective information\nextraction from remote sensing data. So, this paper provides a state-of-art of\nmulti-sensor image fusion technologies as well as review on the quality\nevaluation of the single image or fused images in the commercial remote sensing\npack-ages. It also introduces program (ALwassaiProcess) developed for image\nfusion and classification."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-05530-5_11", 
    "link": "http://arxiv.org/pdf/1307.2965v2", 
    "other_authors": "Quan Wang, Dijia Wu, Le Lu, Meizhu Liu, Kim L. Boyer, Shaohua Kevin Zhou", 
    "title": "Semantic Context Forests for Learning-Based Knee Cartilage Segmentation   in 3D MR Images", 
    "arxiv-id": "1307.2965v2", 
    "author": "Shaohua Kevin Zhou", 
    "publish": "2013-07-11T03:29:51Z", 
    "summary": "The automatic segmentation of human knee cartilage from 3D MR images is a\nuseful yet challenging task due to the thin sheet structure of the cartilage\nwith diffuse boundaries and inhomogeneous intensities. In this paper, we\npresent an iterative multi-class learning method to segment the femoral, tibial\nand patellar cartilage simultaneously, which effectively exploits the spatial\ncontextual constraints between bone and cartilage, and also between different\ncartilages. First, based on the fact that the cartilage grows in only certain\narea of the corresponding bone surface, we extract the distance features of not\nonly to the surface of the bone, but more informatively, to the densely\nregistered anatomical landmarks on the bone surface. Second, we introduce a set\nof iterative discriminative classifiers that at each iteration, probability\ncomparison features are constructed from the class confidence maps derived by\npreviously learned classifiers. These features automatically embed the semantic\ncontext information between different cartilages of interest. Validated on a\ntotal of 176 volumes from the Osteoarthritis Initiative (OAI) dataset, the\nproposed approach demonstrates high robustness and accuracy of segmentation in\ncomparison with existing state-of-the-art MR cartilage segmentation methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2013.3303", 
    "link": "http://arxiv.org/pdf/1307.2997v1", 
    "other_authors": "S. Padmavathi, Manojna K. S. S, S. Sphoorthy Reddy, D. Meenakshy", 
    "title": "Conversion of Braille to Text in English, Hindi and Tamil Languages", 
    "arxiv-id": "1307.2997v1", 
    "author": "D. Meenakshy", 
    "publish": "2013-07-11T07:24:16Z", 
    "summary": "The Braille system has been used by the visually impaired for reading and\nwriting. Due to limited availability of the Braille text books an efficient\nusage of the books becomes a necessity. This paper proposes a method to convert\na scanned Braille document to text which can be read out to many through the\ncomputer. The Braille documents are pre processed to enhance the dots and\nreduce the noise. The Braille cells are segmented and the dots from each cell\nis extracted and converted in to a number sequence. These are mapped to the\nappropriate alphabets of the language. The converted text is spoken out through\na speech synthesizer. The paper also provides a mechanism to type the Braille\ncharacters through the number pad of the keyboard. The typed Braille character\nis mapped to the alphabet and spoken out. The Braille cell has a standard\nrepresentation but the mapping differs for each language. In this paper mapping\nof English, Hindi and Tamil are considered."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2013.3303", 
    "link": "http://arxiv.org/pdf/1307.3043v2", 
    "other_authors": "Sergey Kosov, Pushmeet Kohli, Franz Rottensteiner, Christian Heipke", 
    "title": "A two-layer Conditional Random Field for the classification of partially   occluded objects", 
    "arxiv-id": "1307.3043v2", 
    "author": "Christian Heipke", 
    "publish": "2013-07-11T10:07:19Z", 
    "summary": "Conditional Random Fields (CRF) are among the most popular techniques for\nimage labelling because of their flexibility in modelling dependencies between\nthe labels and the image features. This paper proposes a novel CRF-framework\nfor image labeling problems which is capable to classify partially occluded\nobjects. Our approach is evaluated on aerial near-vertical images as well as on\nurban street-view images and compared with another methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4308", 
    "link": "http://arxiv.org/pdf/1307.3054v1", 
    "other_authors": "Sayali Nimkar, Sanal Varghese, Sucheta Shrivastava", 
    "title": "Contrast Enhancement And Brightness Preservation Using Multi-   Decomposition Histogram Equalization", 
    "arxiv-id": "1307.3054v1", 
    "author": "Sucheta Shrivastava", 
    "publish": "2013-07-11T11:02:57Z", 
    "summary": "Histogram Equalization (HE) has been an essential addition to the Image\nEnhancement world. Enhancement techniques like Classical Histogram Equalization\n(CHE), Adaptive Histogram Equalization (ADHE), Bi-Histogram Equalization (BHE)\nand Recursive Mean Separate Histogram Equalization (RMSHE) methods enhance\ncontrast, however, brightness is not well preserved with these methods, which\ngives an unpleasant look to the final image obtained. Thus, we introduce a\nnovel technique Multi-Decomposition Histogram Equalization (MDHE) to eliminate\nthe drawbacks of the earlier methods. In MDHE, we have decomposed the input\nsixty-four parts, applied CHE in each of the sub-images and then finally\ninterpolated them in correct order. The final image after MDHE results in\ncontrast enhanced and brightness preserved image compared to all other\ntechniques mentioned above. We have calculated the various parameters like\nPSNR, SNR, RMSE, MSE, etc. for every technique. Our results are well supported\nby bar graphs, histograms and the parameter calculations at the end."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2013.4308", 
    "link": "http://arxiv.org/pdf/1307.3271v1", 
    "other_authors": "Thomas Schultz, Anna Vilanova, Ralph Brecheisen, Gordon Kindlmann", 
    "title": "Fuzzy Fibers: Uncertainty in dMRI Tractography", 
    "arxiv-id": "1307.3271v1", 
    "author": "Gordon Kindlmann", 
    "publish": "2013-07-11T21:01:23Z", 
    "summary": "Fiber tracking based on diffusion weighted Magnetic Resonance Imaging (dMRI)\nallows for noninvasive reconstruction of fiber bundles in the human brain. In\nthis chapter, we discuss sources of error and uncertainty in this technique,\nand review strategies that afford a more reliable interpretation of the\nresults. This includes methods for computing and rendering probabilistic\ntractograms, which estimate precision in the face of measurement noise and\nartifacts. However, we also address aspects that have received less attention\nso far, such as model selection, partial voluming, and the impact of\nparameters, both in preprocessing and in fiber tracking itself. We conclude by\ngiving impulses for future research."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5302", 
    "link": "http://arxiv.org/pdf/1307.3439v1", 
    "other_authors": "Y. Jayanta Singh, Shalu Gupta", 
    "title": "Speedy Object Detection based on Shape", 
    "arxiv-id": "1307.3439v1", 
    "author": "Shalu Gupta", 
    "publish": "2013-07-12T12:37:06Z", 
    "summary": "This study is a part of design of an audio system for in-house object\ndetection system for visually impaired, low vision personnel by birth or by an\naccident or due to old age. The input of the system will be scene and output as\naudio. Alert facility is provided based on severity levels of the objects\n(snake, broke glass etc) and also during difficulties. The study proposed\ntechniques to provide speedy detection of objects based on shapes and its\nscale. Features are extraction to have minimum spaces using dynamic scaling.\nFrom a scene, clusters of objects are formed based on the scale and shape.\nSearching is performed among the clusters initially based on the shape, scale,\nmean cluster value and index of object(s). The minimum operation to detect the\npossible shape of the object is performed. In case the object does not have a\nlikely matching shape, scale etc, then the several operations required for an\nobject detection will not perform; instead, it will declared as a new object.\nIn such way, this study finds a speedy way of detecting objects."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5302", 
    "link": "http://arxiv.org/pdf/1307.3759v1", 
    "other_authors": "Evgeniy Martyushev", 
    "title": "A Minimal Six-Point Auto-Calibration Algorithm", 
    "arxiv-id": "1307.3759v1", 
    "author": "Evgeniy Martyushev", 
    "publish": "2013-07-14T17:37:36Z", 
    "summary": "A non-iterative auto-calibration algorithm is presented. It deals with a\nminimal set of six scene points in three views taken by a camera with fixed but\nunknown intrinsic parameters. Calibration is based on the image correspondences\nonly. The algorithm is implemented and validated on synthetic image data."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5302", 
    "link": "http://arxiv.org/pdf/1307.4516v1", 
    "other_authors": "I. Laurence Aroquiaraj, K. Thangavel", 
    "title": "Mammogram Edge Detection Using Hybrid Soft Computing Methods", 
    "arxiv-id": "1307.4516v1", 
    "author": "K. Thangavel", 
    "publish": "2013-07-17T06:45:23Z", 
    "summary": "Image segmentation is a crucial step in a wide range of method image\nprocessing systems. It is useful in visualization of the different objects\npresent in the image. In spite of the several methods available in the\nliterature, image segmentation still a challenging problem in most of image\nprocessing applications. The challenge comes from the fuzziness of image\nobjects and the overlapping of the different regions. Detection of edges in an\nimage is a very important step towards understanding image features. There are\nlarge numbers of edge detection operators available, each designed to be\nsensitive to certain types of edges. The Quality of edge detection can be\nmeasured from several criteria objectively. Some criteria are proposed in terms\nof mathematical measurement, some of them are based on application and\nimplementation requirements. Since edges often occur at image locations\nrepresenting object boundaries, edge detection is extensively used in image\nsegmentation when images are divided into areas corresponding to different\nobjects. This can be used specifically for enhancing the tumor area in\nmammographic images. Different methods are available for edge detection like\nRoberts, Sobel, Prewitt, Canny, Log edge operators. In this paper a novel\nalgorithms for edge detection has been proposed for mammographic images. Breast\nboundary, pectoral region and tumor location can be seen clearly by using this\nmethod. For comparison purpose Roberts, Sobel, Prewitt, Canny, Log edge\noperators are used and their results are displayed. Experimental results\ndemonstrate the effectiveness of the proposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5302", 
    "link": "http://arxiv.org/pdf/1307.4717v1", 
    "other_authors": "T. Dharani, I. Laurence Aroquiaraj", 
    "title": "Content Based Image Retrieval System using Feature Classification with   Modified KNN Algorithm", 
    "arxiv-id": "1307.4717v1", 
    "author": "I. Laurence Aroquiaraj", 
    "publish": "2013-07-17T18:22:24Z", 
    "summary": "Feature means countenance, remote sensing scene objects with similar\ncharacteristics, associated to interesting scene elements in the image\nformation process. They are classified into three types in image processing,\nthat is low, middle and high. Low level features are color, texture and middle\nlevel feature is shape and high level feature is semantic gap of objects. An\nimage retrieval system is a computer system for browsing, searching and\nretrieving images from a large image database. Content Based Image Retrieval is\na technique which uses visual features of image such as color, shape, texture\nto search user required image from large image database according to user\nrequests in the form of a query. MKNN is an enhancing method of KNN. The\nproposed KNN classification is called MKNN. MKNN contains two parts for\nprocessing, they are validity of the train samples and applying weighted KNN.\nThe validity of each point is computed according to its neighbors. In our\nproposal, Modified K-Nearest Neighbor can be considered a kind of weighted KNN\nso that the query label is approximated by weighting the neighbors of the\nquery."
},{
    "category": "cs.CV", 
    "doi": "10.1117/12.2036077", 
    "link": "http://arxiv.org/pdf/1307.4990v2", 
    "other_authors": "Purnendu Banerjee, B. B. Chaudhuri", 
    "title": "Video Text Localization using Wavelet and Shearlet Transforms", 
    "arxiv-id": "1307.4990v2", 
    "author": "B. B. Chaudhuri", 
    "publish": "2013-07-18T15:58:19Z", 
    "summary": "Text in video is useful and important in indexing and retrieving the video\ndocuments efficiently and accurately. In this paper, we present a new method of\ntext detection using a combined dictionary consisting of wavelets and a\nrecently introduced transform called shearlets. Wavelets provide optimally\nsparse expansion for point-like structures and shearlets provide optimally\nsparse expansions for curve-like structures. By combining these two features we\nhave computed a high frequency sub-band to brighten the text part. Then K-means\nclustering is used for obtaining text pixels from the Standard Deviation (SD)\nof combined coefficient of wavelets and shearlets as well as the union of\nwavelets and shearlets features. Text parts are obtained by grouping\nneighboring regions based on geometric properties of the classified output\nframe of unsupervised K-means classification. The proposed method tested on a\nstandard as well as newly collected database shows to be superior to some\nexisting methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TUFFC.2013.2854", 
    "link": "http://arxiv.org/pdf/1307.5102v1", 
    "other_authors": "Stefano Gonella, Jarvis D. Haupt", 
    "title": "Automated Defect Localization via Low Rank Plus Outlier Modeling of   Propagating Wavefield Data", 
    "arxiv-id": "1307.5102v1", 
    "author": "Jarvis D. Haupt", 
    "publish": "2013-07-19T00:06:59Z", 
    "summary": "This work proposes an agnostic inference strategy for material diagnostics,\nconceived within the context of laser-based non-destructive evaluation methods,\nwhich extract information about structural anomalies from the analysis of\nacoustic wavefields measured on the structure's surface by means of a scanning\nlaser interferometer. The proposed approach couples spatiotemporal windowing\nwith low rank plus outlier modeling, to identify a priori unknown deviations in\nthe propagating wavefields caused by material inhomogeneities or defects, using\nvirtually no knowledge of the structural and material properties of the medium.\nThis characteristic makes the approach particularly suitable for diagnostics\nscenarios where the mechanical and material models are complex, unknown, or\nunreliable. We demonstrate our approach in a simulated environment using\nbenchmark point and line defect localization problems based on propagating\nflexural waves in a thin plate."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5591v1", 
    "other_authors": "Subra Mukherjee, Karen Das", 
    "title": "A Novel Equation based Classifier for Detecting Human in Images", 
    "arxiv-id": "1307.5591v1", 
    "author": "Karen Das", 
    "publish": "2013-07-22T05:13:03Z", 
    "summary": "Shape based classification is one of the most challenging tasks in the field\nof computer vision. Shapes play a vital role in object recognition. The basic\nshapes in an image can occur in varying scale, position and orientation. And\nspecially when detecting human, the task becomes more challenging owing to the\nlargely varying size, shape, posture and clothing of human. So, in our work we\ndetect human, based on the head-shoulder shape as it is the most unvarying part\nof human body. Here, firstly a new and a novel equation named as the Omega\nEquation that describes the shape of human head-shoulder is developed and based\non this equation, a classifier is designed particularly for detecting human\npresence in a scene. The classifier detects human by analyzing some of the\ndiscriminative features of the values of the parameters obtained from the Omega\nequation. The proposed method has been tested on a variety of shape dataset\ntaking into consideration the complexities of human head-shoulder shape. In all\nthe experiments the proposed method demonstrated satisfactory results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5653v1", 
    "other_authors": "Duc Phu Chau, Julien Badie, Fran\u00e7ois Bremond, Monique Thonnat", 
    "title": "Online Tracking Parameter Adaptation based on Evaluation", 
    "arxiv-id": "1307.5653v1", 
    "author": "Monique Thonnat", 
    "publish": "2013-07-22T11:09:33Z", 
    "summary": "Parameter tuning is a common issue for many tracking algorithms. In order to\nsolve this problem, this paper proposes an online parameter tuning to adapt a\ntracking algorithm to various scene contexts. In an offline training phase,\nthis approach learns how to tune the tracker parameters to cope with different\ncontexts. In the online control phase, once the tracking quality is evaluated\nas not good enough, the proposed approach computes the current context and\ntunes the tracking parameters using the learned values. The experimental\nresults show that the proposed approach improves the performance of the\ntracking algorithm and outperforms recent state of the art trackers. This paper\nbrings two contributions: (1) an online tracking evaluation, and (2) a method\nto adapt online tracking parameters to scene contexts."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5691v1", 
    "other_authors": "Nicolas Riche, Matthieu Duvinage, Matei Mancas, Bernard Gosselin, Thierry Dutoit", 
    "title": "A study of parameters affecting visual saliency assessment", 
    "arxiv-id": "1307.5691v1", 
    "author": "Thierry Dutoit", 
    "publish": "2013-07-22T13:01:36Z", 
    "summary": "Since the early 2000s, computational visual saliency has been a very active\nresearch area. Each year, more and more new models are published in the main\ncomputer vision conferences. Nowadays, one of the big challenges is to find a\nway to fairly evaluate all of these models. In this paper, a new framework is\nproposed to assess models of visual saliency. This evaluation is divided into\nthree experiments leading to the proposition of a new evaluation framework.\nEach experiment is based on a basic question: 1) there are two ground truths\nfor saliency evaluation: what are the differences between eye fixations and\nmanually segmented salient regions?, 2) the properties of the salient regions:\nfor example, do large, medium and small salient regions present different\ndifficulties for saliency models? and 3) the metrics used to assess saliency\nmodels: what advantages would there be to mix them with PCA? Statistical\nanalysis is used here to answer each of these three questions."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5693v1", 
    "other_authors": "Yasin Kavak, Erkut Erdem, Aykut Erdem", 
    "title": "Visual saliency estimation by integrating features using multiple kernel   learning", 
    "arxiv-id": "1307.5693v1", 
    "author": "Aykut Erdem", 
    "publish": "2013-07-22T13:09:12Z", 
    "summary": "In the last few decades, significant achievements have been attained in\npredicting where humans look at images through different computational models.\nHowever, how to determine contributions of different visual features to overall\nsaliency still remains an open problem. To overcome this issue, a recent class\nof models formulates saliency estimation as a supervised learning problem and\naccordingly apply machine learning techniques. In this paper, we also address\nthis challenging problem and propose to use multiple kernel learning (MKL) to\ncombine information coming from different feature dimensions and to perform\nintegration at an intermediate level. Besides, we suggest to use responses of a\nrecently proposed filterbank of object detectors, known as Object-Bank, as\nadditional semantic high-level features. Here we show that our MKL-based\nframework together with the proposed object-specific features provide\nstate-of-the-art performance as compared to SVM or AdaBoost-based saliency\nmodels."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5702v1", 
    "other_authors": "Samuel F. Dodge, Lina J. Karam", 
    "title": "Is Bottom-Up Attention Useful for Scene Recognition?", 
    "arxiv-id": "1307.5702v1", 
    "author": "Lina J. Karam", 
    "publish": "2013-07-22T13:38:16Z", 
    "summary": "The human visual system employs a selective attention mechanism to understand\nthe visual world in an eficient manner. In this paper, we show how\ncomputational models of this mechanism can be exploited for the computer vision\napplication of scene recognition. First, we consider saliency weighting and\nsaliency pruning, and provide a comparison of the performance of different\nattention models in these approaches in terms of classification accuracy.\nPruning can achieve a high degree of computational savings without\nsignificantly sacrificing classification accuracy. In saliency weighting,\nhowever, we found that classification performance does not improve. In\naddition, we present a new method to incorporate salient and non-salient\nregions for improved classification accuracy. We treat the salient and\nnon-salient regions separately and combine them using Multiple Kernel Learning.\nWe evaluate our approach using the UIUC sports dataset and find that with a\nsmall training size, our method improves upon the classification accuracy of\nthe baseline bag of features approach."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5710v1", 
    "other_authors": "Jan T\u007f\u00fcnnermann, Dieter Enns, B\u007f\u00e4rbel Mertsching", 
    "title": "Saliency-Guided Perceptual Grouping Using Motion Cues in Region-Based   Artificial Visual Attention", 
    "arxiv-id": "1307.5710v1", 
    "author": "B\u007f\u00e4rbel Mertsching", 
    "publish": "2013-07-22T13:48:13Z", 
    "summary": "Region-based artificial attention constitutes a framework for bio-inspired\nattentional processes on an intermediate abstraction level for the use in\ncomputer vision and mobile robotics. Segmentation algorithms produce regions of\ncoherently colored pixels. These serve as proto-objects on which the\nattentional processes determine image portions of relevance. A single\nregion---which not necessarily represents a full object---constitutes the focus\nof attention. For many post-attentional tasks, however, such as identifying or\ntracking objects, single segments are not sufficient. Here, we present a\nsaliency-guided approach that groups regions that potentially belong to the\nsame object based on proximity and similarity of motion. We compare our results\nto object selection by thresholding saliency maps and a further\nattention-guided strategy."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5748v1", 
    "other_authors": "Riccardo Satta", 
    "title": "Appearance Descriptors for Person Re-identification: a Comprehensive   Review", 
    "arxiv-id": "1307.5748v1", 
    "author": "Riccardo Satta", 
    "publish": "2013-07-22T15:41:57Z", 
    "summary": "In video-surveillance, person re-identification is the task of recognising\nwhether an individual has already been observed over a network of cameras.\nTypically, this is achieved by exploiting the clothing appearance, as classical\nbiometric traits like the face are impractical in real-world video surveillance\nscenarios. Clothing appearance is represented by means of low-level\n\\textit{local} and/or \\textit{global} features of the image, usually extracted\naccording to some part-based body model to treat different body parts (e.g.\ntorso and legs) independently. This paper provides a comprehensive review of\ncurrent approaches to build appearance descriptors for person\nre-identification. The most relevant techniques are described in detail, and\ncategorised according to the body models and features used. The aim of this\nwork is to provide a structured body of knowledge and a starting point for\nresearchers willing to conduct novel investigations on this challenging topic."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.5800v1", 
    "other_authors": "Subra Mukherjee, Karen Das", 
    "title": "An Adaptive GMM Approach to Background Subtraction for Application in   Real Time Surveillance", 
    "arxiv-id": "1307.5800v1", 
    "author": "Karen Das", 
    "publish": "2013-07-22T17:59:28Z", 
    "summary": "Efficient security management has become an important parameter in todays\nworld. As the problem is growing, there is an urgent need for the introduction\nof advanced technology and equipment to improve the state-of art of\nsurveillance. In this paper we propose a model for real time background\nsubtraction using AGMM. The proposed model is robust and adaptable to dynamic\nbackground, fast illumination changes, repetitive motion. Also we have\nincorporated a method for detecting shadows using the Horpresert color model.\nThe proposed model can be employed for monitoring areas where movement or entry\nis highly restricted. So on detection of any unexpected events in the scene an\nalarm can be triggered and hence we can achieve real time surveillance even in\nthe absence of constant human monitoring."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.6170v2", 
    "other_authors": "Lucas Paletta, Laurent Itti, Bj\u00f6rn Schuller, Fang Fang", 
    "title": "6th International Symposium on Attention in Cognitive Systems 2013", 
    "arxiv-id": "1307.6170v2", 
    "author": "Fang Fang", 
    "publish": "2013-07-22T12:27:26Z", 
    "summary": "This volume contains the papers accepted at the 6th International Symposium\non Attention in Cognitive Systems (ISACS 2013), held in Beijing, August 5,\n2013. The aim of this symposium is to highlight the central role of attention\non various kinds of performance in cognitive systems processing. It brings\ntogether researchers and developers from both academia and industry, from\ncomputer vision, robotics, perception psychology, psychophysics and\nneuroscience, in order to provide an interdisciplinary forum to present and\ncommunicate on computational models of attention, with the focus on\ninterdependencies with visual cognition. Furthermore, it intends to investigate\nrelevant objectives for performance comparison, to document and to investigate\npromising application domains, and to discuss visual attention with reference\nto other aspects of AI enabled systems."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.6303v1", 
    "other_authors": "Junyan Wang, Kap Luk Chan", 
    "title": "Matching-Constrained Active Contours", 
    "arxiv-id": "1307.6303v1", 
    "author": "Kap Luk Chan", 
    "publish": "2013-07-24T06:18:44Z", 
    "summary": "In object segmentation by active contours, the initial contour is often\nrequired. Conventionally, the initial contour is provided by the user. This\npaper extends the conventional active contour model by incorporating feature\nmatching in the formulation, which gives rise to a novel matching-constrained\nactive contour. The numerical solution to the new optimization model provides\nan automated framework of object segmentation without user intervention. The\nmain idea is to incorporate feature point matching as a constraint in active\ncontour models. To this effect, we obtain a mathematical model of interior\npoints to boundary contour such that matching of interior feature points gives\ncontour alignment, and we formulate the matching score as a constraint to\nactive contour model such that the feature matching of maximum score that gives\nthe contour alignment provides the initial feasible solution to the constrained\noptimization model of segmentation. The constraint also ensures that the\noptimal contour does not deviate too much from the initial contour.\nProjected-gradient descent equations are derived to solve the constrained\noptimization. In the experiments, we show that our method is capable of\nachieving the automatic object segmentation, and it outperforms the related\nmethods."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.6542v1", 
    "other_authors": "Shofwatul 'Uyun, Sri Hartati, Agus Harjoko, Subanar", 
    "title": "Selection Mammogram Texture Descriptors Based on Statistics Properties   Backpropagation Structure", 
    "arxiv-id": "1307.6542v1", 
    "author": "Subanar", 
    "publish": "2013-07-10T02:42:29Z", 
    "summary": "Computer Aided Diagnosis (CAD) system has been developed for the early\ndetection of breast cancer, one of the most deadly cancer for women. The benign\nof mammogram has different texture from malignant. There are fifty mammogram\nimages used in this work which are divided for training and testing. Therefore,\nthe selection of the right texture to determine the level of accuracy of CAD\nsystem is important. The first and second order statistics are the texture\nfeature extraction methods which can be used on a mammogram. This work\nclassifies texture descriptor into nine groups where the extraction of features\nis classified using backpropagation learning with two types of multi-layer\nperceptron (MLP). The best texture descriptor as selected when the value of\nregression 1 appears in both the MLP-1 and the MLP-2 with the number of epoches\nless than 1000. The results of testing show that the best selected texture\ndescriptor is the second order (combination) using all direction (0, 45, 90 and\n135) that have twenty four descriptors."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.6544v1", 
    "other_authors": "M. A. El-Dosuky", 
    "title": "Veni Vidi Vici, A Three-Phase Scenario For Parameter Space Analysis in   Image Analysis and Visualization", 
    "arxiv-id": "1307.6544v1", 
    "author": "M. A. El-Dosuky", 
    "publish": "2013-07-17T04:49:24Z", 
    "summary": "Automatic analysis of the enormous sets of images is a critical task in life\nsciences. This faces many challenges such as: algorithms are highly\nparameterized, significant human input is intertwined, and lacking a standard\nmeta-visualization approach. This paper proposes an alternative iterative\napproach for optimizing input parameters, saving time by minimizing the user\ninvolvement, and allowing for understanding the workflow of algorithms and\ndiscovering new ones. The main focus is on developing an interactive\nvisualization technique that enables users to analyze the relationships between\nsampled input parameters and corresponding output. This technique is\nimplemented as a prototype called Veni Vidi Vici, or \"I came, I saw, I\nconquered.\" This strategy is inspired by the mathematical formulas of numbering\ncomputable functions and is developed atop ImageJ, a scientific image\nprocessing program. A case study is presented to investigate the proposed\nframework. Finally, the paper explores some potential future issues in the\napplication of the proposed approach in parameter space analysis in\nvisualization."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.7474v1", 
    "other_authors": "R. Subash Chandra Boss, K. Thangavel, D. Arul Pon Daniel", 
    "title": "Automatic Mammogram image Breast Region Extraction and Removal of   Pectoral Muscle", 
    "arxiv-id": "1307.7474v1", 
    "author": "D. Arul Pon Daniel", 
    "publish": "2013-07-29T06:42:25Z", 
    "summary": "Currently Mammography is a most effective imaging modality used by\nradiologists for the screening of breast cancer. Finding an accurate, robust\nand efficient breast region segmentation technique still remains a challenging\nproblem in digital mammography. Extraction of the breast profile region and the\nremoval of pectoral muscle are essential pre-processing steps in Computer Aided\nDiagnosis (CAD) system for the diagnosis of breast cancer. Primarily it allows\nthe search for abnormalities to be limited to the region of the breast tissue\nwithout undue influence from the background of the mammogram. The presence of\npectoral muscle in mammograms biases detection procedures, which recommends\nremoving the pectoral muscle during mammogram image pre-processing. The\npresence of pectoral muscle in mammograms may disturb or influence the\ndetection of breast cancer as the pectoral muscle and mammographic parenchymas\nappear similar. The goal of breast region extraction is reducing the image size\nwithout losing anatomic information, it improve the accuracy of the overall CAD\nsystem. The main objective of this study is to propose an automated method to\nidentify the pectoral muscle in Medio-Lateral Oblique (MLO) view mammograms. In\nthis paper, we proposed histogram based 8-neighborhood connected component\nlabelling method for breast region extraction and removal of pectoral muscle.\nThe proposed method is evaluated by using the mean values of accuracy and\nerror. The comparative analysis shows that the proposed method identifies the\nbreast region more accurately."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.7800v1", 
    "other_authors": "Yongsub Lim, Kyomin Jung, Pushmeet Kohli", 
    "title": "Efficient Energy Minimization for Enforcing Statistics", 
    "arxiv-id": "1307.7800v1", 
    "author": "Pushmeet Kohli", 
    "publish": "2013-07-30T03:46:38Z", 
    "summary": "Energy minimization algorithms, such as graph cuts, enable the computation of\nthe MAP solution under certain probabilistic models such as Markov random\nfields. However, for many computer vision problems, the MAP solution under the\nmodel is not the ground truth solution. In many problem scenarios, the system\nhas access to certain statistics of the ground truth. For instance, in image\nsegmentation, the area and boundary length of the object may be known. In these\ncases, we want to estimate the most probable solution that is consistent with\nsuch statistics, i.e., satisfies certain equality or inequality constraints.\n  The above constrained energy minimization problem is NP-hard in general, and\nis usually solved using Linear Programming formulations, which relax the\nintegrality constraints. This paper proposes a novel method that finds the\ndiscrete optimal solution of such problems by maximizing the corresponding\nLagrangian dual. This method can be applied to any constrained energy\nminimization problem whose unconstrained version is polynomial time solvable,\nand can handle multiple, equality or inequality, and linear or non-linear\nconstraints. We demonstrate the efficacy of our method on the\nforeground/background image segmentation problem, and show that it produces\nimpressive segmentation results with less error, and runs more than 20 times\nfaster than the state-of-the-art LP relaxation based approaches."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.7848v1", 
    "other_authors": "Lucas Paletta, Katrin Santner, Gerald Fritz", 
    "title": "An Integrated System for 3D Gaze Recovery and Semantic Analysis of Human   Attention", 
    "arxiv-id": "1307.7848v1", 
    "author": "Gerald Fritz", 
    "publish": "2013-07-30T07:18:20Z", 
    "summary": "This work describes a computer vision system that enables pervasive mapping\nand monitoring of human attention. The key contribution is that our methodology\nenables full 3D recovery of the gaze pointer, human view frustum and associated\nhuman centered measurements directly into an automatically computed 3D model in\nreal-time. We apply RGB-D SLAM and descriptor matching methodologies for the 3D\nmodeling, localization and fully automated annotation of ROIs (regions of\ninterest) within the acquired 3D model. This innovative methodology will open\nnew avenues for attention studies in real world environments, bringing new\npotential into automated processing for human factors technologies."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.7851v1", 
    "other_authors": "Jingdong Wang, Hao Xu, Xian-Sheng Hua, Shipeng Li", 
    "title": "Hybrid Affinity Propagation", 
    "arxiv-id": "1307.7851v1", 
    "author": "Shipeng Li", 
    "publish": "2013-07-30T07:30:46Z", 
    "summary": "In this paper, we address a problem of managing tagged images with hybrid\nsummarization. We formulate this problem as finding a few image exemplars to\nrepresent the image set semantically and visually, and solve it in a hybrid way\nby exploiting both visual and textual information associated with images. We\npropose a novel approach, called homogeneous and heterogeneous message\npropagation ($\\text{H}^\\text{2}\\text{MP}$). Similar to the affinity propagation\n(AP) approach, $\\text{H}^\\text{2}\\text{MP}$ reduce the conventional\n\\emph{vector} message propagation to \\emph{scalar} message propagation to make\nthe algorithm more efficient. Beyond AP that can only handle homogeneous data,\n$\\text{H}^\\text{2}\\text{MP}$ generalizes it to exploit extra heterogeneous\nrelations and the generalization is non-trivial as the reduction to scalar\nmessages from vector messages is more challenging. The main advantages of our\napproach lie in 1) that $\\text{H}^\\text{2}\\text{MP}$ exploits visual similarity\nand in addition the useful information from the associated tags, including the\nassociations relation between images and tags and the relations within tags,\nand 2) that the summary is both visually and semantically satisfactory. In\naddition, our approach can also present a textual summary to a tagged image\ncollection, which can be used to automatically generate a textual description.\nThe experimental results demonstrate the effectiveness and efficiency of the\nroposed approach."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.8233v1", 
    "other_authors": "Jan T\u007f\u00fcnnermann, Markus Hennig, Michael Silbernagel, B\u007f\u00e4rbel Mertsching", 
    "title": "A Prototyping Environment for Integrated Artificial Attention Systems", 
    "arxiv-id": "1307.8233v1", 
    "author": "B\u007f\u00e4rbel Mertsching", 
    "publish": "2013-07-31T06:24:28Z", 
    "summary": "Artificial visual attention systems aim to support technical systems in\nvisual tasks by applying the concepts of selective attention observed in humans\nand other animals. Such systems are typically evaluated against ground truth\nobtained from human gaze-data or manually annotated test images. When applied\nto robotics, the systems are required to be adaptable to the target system.\nHere, we describe a flexible environment based on a robotic middleware layer\nallowing the development and testing of attention-guided vision systems. In\nsuch a framework, the systems can be tested with input from various sources,\ndifferent attention algorithms at the core, and diverse subsequent tasks."
},{
    "category": "cs.CV", 
    "doi": "10.5120/12496-7272", 
    "link": "http://arxiv.org/pdf/1307.8405v1", 
    "other_authors": "Zixuan Wang, Jinyun Yan", 
    "title": "Who and Where: People and Location Co-Clustering", 
    "arxiv-id": "1307.8405v1", 
    "author": "Jinyun Yan", 
    "publish": "2013-07-31T17:53:10Z", 
    "summary": "In this paper, we consider the clustering problem on images where each image\ncontains patches in people and location domains. We exploit the correlation\nbetween people and location domains, and proposed a semi-supervised\nco-clustering algorithm to cluster images. Our algorithm updates the\ncorrelation links at the runtime, and produces clustering in both domains\nsimultaneously. We conduct experiments in a manually collected dataset and a\nFlickr dataset. The result shows that the such correlation improves the\nclustering performance."
},{
    "category": "cs.CV", 
    "doi": "10.1364/OE.23.002220", 
    "link": "http://arxiv.org/pdf/1407.0010v2", 
    "other_authors": "Liangqiong Qu, Jiandong Tian, Zhi Han, Yandong Tang", 
    "title": "Pixel-wise Orthogonal Decomposition for Color Illumination Invariant and   Shadow-free Image", 
    "arxiv-id": "1407.0010v2", 
    "author": "Yandong Tang", 
    "publish": "2014-06-30T07:55:27Z", 
    "summary": "In this paper, we propose a novel, effective and fast method to obtain a\ncolor illumination invariant and shadow-free image from a single outdoor image.\nDifferent from state-of-the-art methods for shadow-free image that either need\nshadow detection or statistical learning, we set up a linear equation set for\neach pixel value vector based on physically-based shadow invariants, deduce a\npixel-wise orthogonal decomposition for its solutions, and then get an\nillumination invariant vector for each pixel value vector on an image. The\nillumination invariant vector is the unique particular solution of the linear\nequation set, which is orthogonal to its free solutions. With this illumination\ninvariant vector and Lab color space, we propose an algorithm to generate a\nshadow-free image which well preserves the texture and color information of the\noriginal image. A series of experiments on a diverse set of outdoor images and\nthe comparisons with the state-of-the-art methods validate our method."
},{
    "category": "cs.CV", 
    "doi": "10.1364/OE.23.002220", 
    "link": "http://arxiv.org/pdf/1407.0717v1", 
    "other_authors": "Lubomir Bourdev, Fei Yang, Rob Fergus", 
    "title": "Deep Poselets for Human Detection", 
    "arxiv-id": "1407.0717v1", 
    "author": "Rob Fergus", 
    "publish": "2014-07-02T20:28:22Z", 
    "summary": "We address the problem of detecting people in natural scenes using a part\napproach based on poselets. We propose a bootstrapping method that allows us to\ncollect millions of weakly labeled examples for each poselet type. We use these\nexamples to train a Convolutional Neural Net to discriminate different poselet\ntypes and separate them from the background class. We then use the trained CNN\nas a way to represent poselet patches with a Pose Discriminative Feature (PDF)\nvector -- a compact 256-dimensional feature vector that is effective at\ndiscriminating pose from appearance. We train the poselet model on top of PDF\nfeatures and combine them with object-level CNNs for detection and bounding box\nprediction. The resulting model leads to state-of-the-art performance for human\ndetection on the PASCAL datasets."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6944561", 
    "link": "http://arxiv.org/pdf/1407.0765v1", 
    "other_authors": "Awais Mansoor, Valery Patsekin, Dale Scherl, J. Paul Robinson, Bartlomiej Rajwa", 
    "title": "BiofilmQuant: A Computer-Assisted Tool for Dental Biofilm Quantification", 
    "arxiv-id": "1407.0765v1", 
    "author": "Bartlomiej Rajwa", 
    "publish": "2014-07-03T02:40:13Z", 
    "summary": "Dental biofilm is the deposition of microbial material over a tooth\nsubstratum. Several methods have recently been reported in the literature for\nbiofilm quantification; however, at best they provide a barely automated\nsolution requiring significant input needed from the human expert. On the\ncontrary, state-of-the-art automatic biofilm methods fail to make their way\ninto clinical practice because of the lack of effective mechanism to\nincorporate human input to handle praxis or misclassified regions. Manual\ndelineation, the current gold standard, is time consuming and subject to expert\nbias. In this paper, we introduce a new semi-automated software tool,\nBiofilmQuant, for dental biofilm quantification in quantitative light-induced\nfluorescence (QLF) images. The software uses a robust statistical modeling\napproach to automatically segment the QLF image into three classes (background,\nbiofilm, and tooth substratum) based on the training data. This initial\nsegmentation has shown a high degree of consistency and precision on more than\n200 test QLF dental scans. Further, the proposed software provides the\nclinicians full control to fix any misclassified areas using a single click. In\naddition, BiofilmQuant also provides a complete solution for the longitudinal\nquantitative analysis of biofilm of the full set of teeth, providing greater\nease of usability."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6944561", 
    "link": "http://arxiv.org/pdf/1407.0786v1", 
    "other_authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel", 
    "title": "Strengthening the Effectiveness of Pedestrian Detection with Spatially   Pooled Features", 
    "arxiv-id": "1407.0786v1", 
    "author": "Anton van den Hengel", 
    "publish": "2014-07-03T05:39:30Z", 
    "summary": "We propose a simple yet effective approach to the problem of pedestrian\ndetection which outperforms the current state-of-the-art. Our new features are\nbuilt on the basis of low-level visual features and spatial pooling.\nIncorporating spatial pooling improves the translational invariance and thus\nthe robustness of the detection process. We then directly optimise the partial\narea under the ROC curve (\\pAUC) measure, which concentrates detection\nperformance in the range of most practical importance. The combination of these\nfactors leads to a pedestrian detector which outperforms all competitors on all\nof the standard benchmark datasets. We advance state-of-the-art results by\nlowering the average miss rate from $13\\%$ to $11\\%$ on the INRIA benchmark,\n$41\\%$ to $37\\%$ on the ETH benchmark, $51\\%$ to $42\\%$ on the TUD-Brussels\nbenchmark and $36\\%$ to $29\\%$ on the Caltech-USA benchmark."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.0935v1", 
    "other_authors": "M. T Gopalakrishna, M. Ravishankar, D. R Rameshbabu", 
    "title": "Multiple Moving Object Recognitions in video based on Log Gabor-PCA   Approach", 
    "arxiv-id": "1407.0935v1", 
    "author": "D. R Rameshbabu", 
    "publish": "2014-07-03T14:52:56Z", 
    "summary": "Object recognition in the video sequence or images is one of the sub-field of\ncomputer vision. Moving object recognition from a video sequence is an\nappealing topic with applications in various areas such as airport safety,\nintrusion surveillance, video monitoring, intelligent highway, etc. Moving\nobject recognition is the most challenging task in intelligent video\nsurveillance system. In this regard, many techniques have been proposed based\non different methods. Despite of its importance, moving object recognition in\ncomplex environments is still far from being completely solved for low\nresolution videos, foggy videos, and also dim video sequences. All in all,\nthese make it necessary to develop exceedingly robust techniques. This paper\nintroduces multiple moving object recognition in the video sequence based on\nLoG Gabor-PCA approach and Angle based distance Similarity measures techniques\nused to recognize the object as a human, vehicle etc. Number of experiments are\nconducted for indoor and outdoor video sequences of standard datasets and also\nour own collection of video sequences comprising of partial night vision video\nsequences. Experimental results show that our proposed approach achieves an\nexcellent recognition rate. Results obtained are satisfactory and competent."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1120v2", 
    "other_authors": "Mehrtash T. Harandi, Mathieu Salzmann, Richard Hartley", 
    "title": "From Manifold to Manifold: Geometry-Aware Dimensionality Reduction for   SPD Matrices", 
    "arxiv-id": "1407.1120v2", 
    "author": "Richard Hartley", 
    "publish": "2014-07-04T05:10:43Z", 
    "summary": "Representing images and videos with Symmetric Positive Definite (SPD)\nmatrices and considering the Riemannian geometry of the resulting space has\nproven beneficial for many recognition tasks. Unfortunately, computation on the\nRiemannian manifold of SPD matrices --especially of high-dimensional ones--\ncomes at a high cost that limits the applicability of existing techniques. In\nthis paper we introduce an approach that lets us handle high-dimensional SPD\nmatrices by constructing a lower-dimensional, more discriminative SPD manifold.\nTo this end, we model the mapping from the high-dimensional SPD manifold to the\nlow-dimensional one with an orthonormal projection. In particular, we search\nfor a projection that yields a low-dimensional manifold with maximum\ndiscriminative power encoded via an affinity-weighted similarity measure based\non metrics on the manifold. Learning can then be expressed as an optimization\nproblem on a Grassmann manifold. Our evaluation on several classification tasks\nshows that our approach leads to a significant accuracy gain over\nstate-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1267v1", 
    "other_authors": "Qiang Fu, Quan Quan, Kai-Yuan Cai", 
    "title": "Calibration of Multiple Fish-Eye Cameras Using a Wand", 
    "arxiv-id": "1407.1267v1", 
    "author": "Kai-Yuan Cai", 
    "publish": "2014-07-04T15:58:23Z", 
    "summary": "Fish-eye cameras are becoming increasingly popular in computer vision, but\ntheir use for 3D measurement is limited partly due to the lack of an accurate,\nefficient and user-friendly calibration procedure. For such a purpose, we\npropose a method to calibrate the intrinsic and extrinsic parameters (including\nradial distortion parameters) of two/multiple fish-eye cameras simultaneously\nby using a wand under general motions. Thanks to the generic camera model used,\nthe proposed calibration method is also suitable for two/multiple conventional\ncameras and mixed cameras (e.g. two conventional cameras and a fish-eye\ncamera). Simulation and real experiments demonstrate the effectiveness of the\nproposed method. Moreover, we develop the camera calibration toolbox, which is\navailable online."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1352v1", 
    "other_authors": "Deli Zhao, Xiaoou Tang", 
    "title": "Homophilic Clustering by Locally Asymmetric Geometry", 
    "arxiv-id": "1407.1352v1", 
    "author": "Xiaoou Tang", 
    "publish": "2014-07-05T01:58:13Z", 
    "summary": "Clustering is indispensable for data analysis in many scientific disciplines.\nDetecting clusters from heavy noise remains challenging, particularly for\nhigh-dimensional sparse data. Based on graph-theoretic framework, the present\npaper proposes a novel algorithm to address this issue. The locally asymmetric\ngeometries of neighborhoods between data points result in a directed similarity\ngraph to model the structural connectivity of data points. Performing\nsimilarity propagation on this directed graph simply by its adjacency matrix\npowers leads to an interesting discovery, in the sense that if the in-degrees\nare ordered by the corresponding sorted out-degrees, they will be\nself-organized to be homophilic layers according to the different distributions\nof cluster densities, which is dubbed the Homophilic In-degree figure (the HI\nfigure). With the HI figure, we can easily single out all cores of clusters,\nidentify the boundary between cluster and noise, and visualize the intrinsic\nstructures of clusters. Based on the in-degree homophily, we also develop a\nsimple efficient algorithm of linear space complexity to cluster noisy data.\nExtensive experiments on toy and real-world scientific data validate the\neffectiveness of our algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1490v1", 
    "other_authors": "Jianguo Li, Yurong Chen", 
    "title": "Large-scale Supervised Hierarchical Feature Learning for Face   Recognition", 
    "arxiv-id": "1407.1490v1", 
    "author": "Yurong Chen", 
    "publish": "2014-07-06T12:45:23Z", 
    "summary": "This paper proposes a novel face recognition algorithm based on large-scale\nsupervised hierarchical feature learning. The approach consists of two parts:\nhierarchical feature learning and large-scale model learning. The hierarchical\nfeature learning searches feature in three levels of granularity in a\nsupervised way. First, face images are modeled by receptive field theory, and\nthe representation is an image with many channels of Gaussian receptive maps.\nWe activate a few most distinguish channels by supervised learning. Second, the\nface image is further represented by patches of picked channels, and we search\nfrom the over-complete patch pool to activate only those most discriminant\npatches. Third, the feature descriptor of each patch is further projected to\nlower dimension subspace with discriminant subspace analysis.\n  Learned feature of activated patches are concatenated to get a full face\nrepresentation.A linear classifier is learned to separate face pairs from same\nsubjects and different subjects. As the number of face pairs are extremely\nlarge, we introduce ADMM (alternative direction method of multipliers) to train\nthe linear classifier on a computing cluster. Experiments show that more\ntraining samples will bring notable accuracy improvement.\n  We conduct experiments on FRGC and LFW. Results show that the proposed\napproach outperforms existing algorithms under the same protocol notably.\nBesides, the proposed approach is small in memory footprint, and low in\ncomputing cost, which makes it suitable for embedded applications."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1785v2", 
    "other_authors": "Zemin Zhang, Gregory Ely, Shuchin Aeron, Ning Hao, Misha Kilmer", 
    "title": "Novel methods for multilinear data completion and de-noising based on   tensor-SVD", 
    "arxiv-id": "1407.1785v2", 
    "author": "Misha Kilmer", 
    "publish": "2014-07-07T17:47:54Z", 
    "summary": "In this paper we propose novel methods for completion (from limited samples)\nand de-noising of multilinear (tensor) data and as an application consider 3-D\nand 4- D (color) video data completion and de-noising. We exploit the recently\nproposed tensor-Singular Value Decomposition (t-SVD)[11]. Based on t-SVD, the\nnotion of multilinear rank and a related tensor nuclear norm was proposed in\n[11] to characterize informational and structural complexity of multilinear\ndata. We first show that videos with linear camera motion can be represented\nmore efficiently using t-SVD compared to the approaches based on vectorizing or\nflattening of the tensors. Since efficiency in representation implies\nefficiency in recovery, we outline a tensor nuclear norm penalized algorithm\nfor video completion from missing entries. Application of the proposed\nalgorithm for video recovery from missing entries is shown to yield a superior\nperformance over existing methods. We also consider the problem of tensor\nrobust Principal Component Analysis (PCA) for de-noising 3-D video data from\nsparse random corruptions. We show superior performance of our method compared\nto the matrix robust PCA adapted to this setting as proposed in [4]."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1808v1", 
    "other_authors": "Bharath Hariharan, Pablo Arbel\u00e1ez, Ross Girshick, Jitendra Malik", 
    "title": "Simultaneous Detection and Segmentation", 
    "arxiv-id": "1407.1808v1", 
    "author": "Jitendra Malik", 
    "publish": "2014-07-07T18:59:11Z", 
    "summary": "We aim to detect all instances of a category in an image and, for each\ninstance, mark the pixels that belong to it. We call this task Simultaneous\nDetection and Segmentation (SDS). Unlike classical bounding box detection, SDS\nrequires a segmentation and not just a box. Unlike classical semantic\nsegmentation, we require individual object instances. We build on recent work\nthat uses convolutional neural networks to classify category-independent region\nproposals (R-CNN [16]), introducing a novel architecture tailored for SDS. We\nthen use category-specific, top- down figure-ground predictions to refine our\nbottom-up proposals. We show a 7 point boost (16% relative) over our baselines\non SDS, a 5 point boost (10% relative) over state-of-the-art on semantic\nsegmentation, and state-of-the-art performance in object detection. Finally, we\nprovide diagnostic tools that unpack performance and provide directions for\nfuture work."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1957v1", 
    "other_authors": "Hilton Bristow, Simon Lucey", 
    "title": "Regression-Based Image Alignment for General Object Categories", 
    "arxiv-id": "1407.1957v1", 
    "author": "Simon Lucey", 
    "publish": "2014-07-08T05:43:47Z", 
    "summary": "Gradient-descent methods have exhibited fast and reliable performance for\nimage alignment in the facial domain, but have largely been ignored by the\nbroader vision community. They require the image function be smooth and\n(numerically) differentiable -- properties that hold for pixel-based\nrepresentations obeying natural image statistics, but not for more general\nclasses of non-linear feature transforms. We show that transforms such as Dense\nSIFT can be incorporated into a Lucas Kanade alignment framework by predicting\ndescent directions via regression. This enables robust matching of instances\nfrom general object categories whilst maintaining desirable properties of Lucas\nKanade such as the capacity to handle high-dimensional warp parametrizations\nand a fast rate of convergence. We present alignment results on a number of\nobjects from ImageNet, and an extension of the method to unsupervised joint\nalignment of objects from a corpus of images."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.1974v3", 
    "other_authors": "Jianjia Zhang, Lei Wang, Luping Zhou, Wanqing Li", 
    "title": "Learning Discriminative Stein Kernel for SPD Matrices and Its   Applications", 
    "arxiv-id": "1407.1974v3", 
    "author": "Wanqing Li", 
    "publish": "2014-07-08T07:07:12Z", 
    "summary": "Stein kernel has recently shown promising performance on classifying images\nrepresented by symmetric positive definite (SPD) matrices. It evaluates the\nsimilarity between two SPD matrices through their eigenvalues. In this paper,\nwe argue that directly using the original eigenvalues may be problematic\nbecause: i) Eigenvalue estimation becomes biased when the number of samples is\ninadequate, which may lead to unreliable kernel evaluation; ii) More\nimportantly, eigenvalues only reflect the property of an individual SPD matrix.\nThey are not necessarily optimal for computing Stein kernel when the goal is to\ndiscriminate different sets of SPD matrices. To address the two issues in one\nshot, we propose a discriminative Stein kernel, in which an extra parameter\nvector is defined to adjust the eigenvalues of the input SPD matrices. The\noptimal parameter values are sought by optimizing a proxy of classification\nperformance. To show the generality of the proposed method, three different\nkernel learning criteria that are commonly used in the literature are employed\nrespectively as a proxy. A comprehensive experimental study is conducted on a\nvariety of image classification tasks to compare our proposed discriminative\nStein kernel with the original Stein kernel and other commonly used methods for\nevaluating the similarity between SPD matrices. The experimental results\ndemonstrate that, the discriminative Stein kernel can attain greater\ndiscrimination and better align with classification tasks by altering the\neigenvalues. This makes it produce higher classification performance than the\noriginal Stein kernel and other commonly used methods."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.2170v2", 
    "other_authors": "Giorgos Tolias, Teddy Furon, Herv\u00e9 J\u00e9gou", 
    "title": "Orientation covariant aggregation of local descriptors with embeddings", 
    "arxiv-id": "1407.2170v2", 
    "author": "Herv\u00e9 J\u00e9gou", 
    "publish": "2014-07-08T16:55:36Z", 
    "summary": "Image search systems based on local descriptors typically achieve orientation\ninvariance by aligning the patches on their dominant orientations. Albeit\nsuccessful, this choice introduces too much invariance because it does not\nguarantee that the patches are rotated consistently. This paper introduces an\naggregation strategy of local descriptors that achieves this covariance\nproperty by jointly encoding the angle in the aggregation stage in a continuous\nmanner. It is combined with an efficient monomial embedding to provide a\ncodebook-free method to aggregate local descriptors into a single vector\nrepresentation. Our strategy is also compatible and employed with several\npopular encoding methods, in particular bag-of-words, VLAD and the Fisher\nvector. Our geometric-aware aggregation strategy is effective for image search,\nas shown by experiments performed on standard benchmarks for image and\nparticular object retrieval, namely Holidays and Oxford buildings."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.2343v1", 
    "other_authors": "Kunal Narayan Chaudhury", 
    "title": "PatchLift: Fast and Exact Computation of Patch Distances using Lifting,   with Applications to Non-Local Means", 
    "arxiv-id": "1407.2343v1", 
    "author": "Kunal Narayan Chaudhury", 
    "publish": "2014-07-09T03:15:37Z", 
    "summary": "In this paper, we propose a fast algorithm called PatchLift for computing\ndistances between patches extracted from a one-dimensional signal. PatchLift is\nbased on the observation that the patch distances can be expressed in terms of\nsimple moving sums of an image, which is derived from the one-dimensional\nsignal via lifting. We apply PatchLift to develop a separable extension of the\nclassical Non-Local Means (NLM) algorithm which is at least 100 times faster\nthan NLM for standard parameter settings. The PSNR obtained using the proposed\nextension is typically close to (and often larger than) the PSNRs obtained\nusing the original NLM. We provide some simulations results to demonstrate the\nacceleration achieved using separability and PatchLift."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-319-01778-5_10", 
    "link": "http://arxiv.org/pdf/1407.2390v1", 
    "other_authors": "SRM Prasanna, Rituparna Devi, Deepjoy Das, Subhankar Ghosh, Krishna Naik", 
    "title": "Online Stroke and Akshara Recognition GUI in Assamese Language Using   Hidden Markov Model", 
    "arxiv-id": "1407.2390v1", 
    "author": "Krishna Naik", 
    "publish": "2014-07-09T08:48:41Z", 
    "summary": "The work describes the development of Online Assamese Stroke & Akshara\nRecognizer based on a set of language rules. In handwriting literature strokes\nare composed of two coordinate trace in between pen down and pen up labels. The\nAssamese aksharas are combination of a number of strokes, the maximum number of\nstrokes taken to make a combination being eight. Based on these combinations\neight language rule models have been made which are used to test if a set of\nstrokes form a valid akshara. A Hidden Markov Model is used to train 181\ndifferent stroke patterns which generates a model used during stroke level\ntesting. Akshara level testing is performed by integrating a GUI (provided by\nCDAC-Pune) with the Binaries of HTK toolkit classifier, HMM train model and the\nlanguage rules using a dynamic linked library (dll). We have got a stroke level\nperformance of 94.14% and akshara level performance of 84.2%."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijci.2014.3301", 
    "link": "http://arxiv.org/pdf/1407.2572v2", 
    "other_authors": "Reza Azad, Babak Azad, Iraj Mogharreb, Shahram Jamali", 
    "title": "Classifiers fusion method to recognize handwritten persian numerals", 
    "arxiv-id": "1407.2572v2", 
    "author": "Shahram Jamali", 
    "publish": "2014-07-09T17:49:11Z", 
    "summary": "Recognition of Persian handwritten characters has been considered as a\nsignificant field of research for the last few years under pattern analysing\ntechnique. In this paper, a new approach for robust handwritten Persian\nnumerals recognition using strong feature set and a classifier fusion method is\nscrutinized to increase the recognition percentage. For implementing the\nclassifier fusion technique, we have considered k nearest neighbour (KNN),\nlinear classifier (LC) and support vector machine (SVM) classifiers. The\ninnovation of this tactic is to attain better precision with few features using\nclassifier fusion method. For evaluation of the proposed method we considered a\nPersian numerals database with 20,000 handwritten samples. Spending 15,000\nsamples for training stage, we verified our technique on other 5,000 samples,\nand the correct recognition ratio achieved approximately 99.90%. Additional, we\ngot 99.97% exactness using four-fold cross validation procedure on 20,000\ndatabases."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JBHI.2014.2310204", 
    "link": "http://arxiv.org/pdf/1407.2630v1", 
    "other_authors": "Awais Mansoor, Valery Patsekin, Dale Scherl, J. Paul Robinson, Bartlomiej Rajwa", 
    "title": "A Statistical Modeling Approach to Computer-Aided Quantification of   Dental Biofilm", 
    "arxiv-id": "1407.2630v1", 
    "author": "Bartlomiej Rajwa", 
    "publish": "2014-07-09T20:32:32Z", 
    "summary": "Biofilm is a formation of microbial material on tooth substrata. Several\nmethods to quantify dental biofilm coverage have recently been reported in the\nliterature, but at best they provide a semi-automated approach to\nquantification with significant input from a human grader that comes with the\ngraders bias of what are foreground, background, biofilm, and tooth.\nAdditionally, human assessment indices limit the resolution of the\nquantification scale; most commercial scales use five levels of quantification\nfor biofilm coverage (0%, 25%, 50%, 75%, and 100%). On the other hand, current\nstate-of-the-art techniques in automatic plaque quantification fail to make\ntheir way into practical applications owing to their inability to incorporate\nhuman input to handle misclassifications. This paper proposes a new interactive\nmethod for biofilm quantification in Quantitative light-induced fluorescence\n(QLF) images of canine teeth that is independent of the perceptual bias of the\ngrader. The method partitions a QLF image into segments of uniform texture and\nintensity called superpixels; every superpixel is statistically modeled as a\nrealization of a single 2D Gaussian Markov random field (GMRF) whose parameters\nare estimated; the superpixel is then assigned to one of three classes\n(background, biofilm, tooth substratum) based on the training set of data. The\nquantification results show a high degree of consistency and precision. At the\nsame time, the proposed method gives pathologists full control to post-process\nthe automatic quantification by flipping misclassified superpixels to a\ndifferent state (background, tooth, biofilm) with a single click, providing\ngreater usability than simply marking the boundaries of biofilm and tooth as\ndone by current state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JBHI.2014.2310204", 
    "link": "http://arxiv.org/pdf/1407.2649v1", 
    "other_authors": "Alican Bozkurt, Pinar Duygulu, A. Enis Cetin", 
    "title": "Classifying Fonts and Calligraphy Styles Using Complex Wavelet Transform", 
    "arxiv-id": "1407.2649v1", 
    "author": "A. Enis Cetin", 
    "publish": "2014-07-09T22:25:32Z", 
    "summary": "Recognizing fonts has become an important task in document analysis, due to\nthe increasing number of available digital documents in different fonts and\nemphases. A generic font-recognition system independent of language, script and\ncontent is desirable for processing various types of documents. At the same\ntime, categorizing calligraphy styles in handwritten manuscripts is important\nfor palaeographic analysis, but has not been studied sufficiently in the\nliterature. We address the font-recognition problem as analysis and\ncategorization of textures. We extract features using complex wavelet transform\nand use support vector machines for classification. Extensive experimental\nevaluations on different datasets in four languages and comparisons with\nstate-of-the-art studies show that our proposed method achieves higher\nrecognition accuracy while being computationally simpler. Furthermore, on a new\ndataset generated from Ottoman manuscripts, we show that the proposed method\ncan also be used for categorizing Ottoman calligraphy with high accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JBHI.2014.2310204", 
    "link": "http://arxiv.org/pdf/1407.2700v1", 
    "other_authors": "Ghazali Sulong, Anwar Yahy Ebrahim, Muhammad Jehanzeb", 
    "title": "Offline handwritten signature identification using adaptive window   positioning techniques", 
    "arxiv-id": "1407.2700v1", 
    "author": "Muhammad Jehanzeb", 
    "publish": "2014-07-10T06:03:00Z", 
    "summary": "The paper presents to address this challenge, we have proposed the use of\nAdaptive Window Positioning technique which focuses on not just the meaning of\nthe handwritten signature but also on the individuality of the writer. This\ninnovative technique divides the handwritten signature into 13 small windows of\nsize nxn(13x13).This size should be large enough to contain ample information\nabout the style of the author and small enough to ensure a good identification\nperformance.The process was tested with a GPDS data set containing 4870\nsignature samples from 90 different writers by comparing the robust features of\nthe test signature with that of the user signature using an appropriate\nclassifier. Experimental results reveal that adaptive window positioning\ntechnique proved to be the efficient and reliable method for accurate signature\nfeature extraction for the identification of offline handwritten signatures.The\ncontribution of this technique can be used to detect signatures signed under\nemotional duress."
},{
    "category": "cs.CV", 
    "doi": "10.1109/JBHI.2014.2310204", 
    "link": "http://arxiv.org/pdf/1407.2721v2", 
    "other_authors": "Bj\u00f6rn Barz, Erik Rodner, Joachim Denzler", 
    "title": "ARTOS -- Adaptive Real-Time Object Detection System", 
    "arxiv-id": "1407.2721v2", 
    "author": "Joachim Denzler", 
    "publish": "2014-07-10T08:02:23Z", 
    "summary": "ARTOS is all about creating, tuning, and applying object detection models\nwith just a few clicks. In particular, ARTOS facilitates learning of models for\nvisual object detection by eliminating the burden of having to collect and\nannotate a large set of positive and negative samples manually and in addition\nit implements a fast learning technique to reduce the time needed for the\nlearning step.\n  A clean and friendly GUI guides the user through the process of model\ncreation, adaptation of learned models to different domains using in-situ\nimages, and object detection on both offline images and images from a video\nstream. A library written in C++ provides the main functionality of ARTOS with\na C-style procedural interface, so that it can be easily integrated with any\nother project."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2013.05.004", 
    "link": "http://arxiv.org/pdf/1407.2961v1", 
    "other_authors": "Youness Aliyari Ghassabeh", 
    "title": "On the Convergence of the Mean Shift Algorithm in the One-Dimensional   Space", 
    "arxiv-id": "1407.2961v1", 
    "author": "Youness Aliyari Ghassabeh", 
    "publish": "2014-07-10T20:55:25Z", 
    "summary": "The mean shift algorithm is a non-parametric and iterative technique that has\nbeen used for finding modes of an estimated probability density function. It\nhas been successfully employed in many applications in specific areas of\nmachine vision, pattern recognition, and image processing. Although the mean\nshift algorithm has been used in many applications, a rigorous proof of its\nconvergence is still missing in the literature. In this paper we address the\nconvergence of the mean shift algorithm in the one-dimensional space and prove\nthat the sequence generated by the mean shift algorithm is a monotone and\nconvergent sequence."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6943783", 
    "link": "http://arxiv.org/pdf/1407.3176v1", 
    "other_authors": "Awais Mansoor, Ulas Bagci, Brent Foster, Ziyue Xu, Deborah Douglas, Jeffrey M. Solomon, Jayaram K. Udupa, Daniel J. Mollura", 
    "title": "CIDI-Lung-Seg: A Single-Click Annotation Tool for Automatic Delineation   of Lungs from CT Scans", 
    "arxiv-id": "1407.3176v1", 
    "author": "Daniel J. Mollura", 
    "publish": "2014-07-11T14:41:27Z", 
    "summary": "Accurate and fast extraction of lung volumes from computed tomography (CT)\nscans remains in a great demand in the clinical environment because the\navailable methods fail to provide a generic solution due to wide anatomical\nvariations of lungs and existence of pathologies. Manual annotation, current\ngold standard, is time consuming and often subject to human bias. On the other\nhand, current state-of-the-art fully automated lung segmentation methods fail\nto make their way into the clinical practice due to their inability to\nefficiently incorporate human input for handling misclassifications and praxis.\nThis paper presents a lung annotation tool for CT images that is interactive,\nefficient, and robust. The proposed annotation tool produces an \"as accurate as\npossible\" initial annotation based on the fuzzy-connectedness image\nsegmentation, followed by efficient manual fixation of the initial extraction\nif deemed necessary by the practitioner. To provide maximum flexibility to the\nusers, our annotation tool is supported in three major operating systems\n(Windows, Linux, and the Mac OS X). The quantitative results comparing our free\nsoftware with commercially available lung segmentation tools show higher degree\nof consistency and precision of our software with a considerable potential to\nenhance the performance of routine clinical tasks."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3179v1", 
    "other_authors": "Awais Mansoor, Ulas Bagci, Daniel J. Mollura", 
    "title": "Near-optimal Keypoint Sampling for Fast Pathological Lung Segmentation", 
    "arxiv-id": "1407.3179v1", 
    "author": "Daniel J. Mollura", 
    "publish": "2014-07-11T14:53:26Z", 
    "summary": "Accurate delineation of pathological lungs from computed tomography (CT)\nimages remains mostly unsolved because available methods fail to provide a\nreliable generic solution due to high variability of abnormality appearance.\nLocal descriptor-based classification methods have shown to work well in\nannotating pathologies; however, these methods are usually computationally\nintensive which restricts their widespread use in real-time or near-real-time\nclinical applications. In this paper, we present a novel approach for fast,\naccurate, reliable segmentation of pathological lungs from CT scans by\ncombining region-based segmentation method with local descriptor classification\nthat is performed on an optimized sampling grid. Our method works in two\nstages; during stage one, we adapted the fuzzy connectedness (FC) image\nsegmentation algorithm to perform initial lung parenchyma extraction. In the\nsecond stage, texture-based local descriptors are utilized to segment abnormal\nimaging patterns using a near optimal keypoint analysis by employing centroid\nof supervoxel as grid points. The quantitative results show that our\npathological lung segmentation method is fast, robust, and improves on current\nstandards and has potential to enhance the performance of routine clinical\ntasks."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3193v1", 
    "other_authors": "Awais Mansoor, Ulas Bagci, Daniel J. Mollura", 
    "title": "Optimally Stabilized PET Image Denoising Using Trilateral Filtering", 
    "arxiv-id": "1407.3193v1", 
    "author": "Daniel J. Mollura", 
    "publish": "2014-07-11T15:08:18Z", 
    "summary": "Low-resolution and signal-dependent noise distribution in positron emission\ntomography (PET) images makes denoising process an inevitable step prior to\nqualitative and quantitative image analysis tasks. Conventional PET denoising\nmethods either over-smooth small-sized structures due to resolution limitation\nor make incorrect assumptions about the noise characteristics. Therefore,\nclinically important quantitative information may be corrupted. To address\nthese challenges, we introduced a novel approach to remove signal-dependent\nnoise in the PET images where the noise distribution was considered as\nPoisson-Gaussian mixed. Meanwhile, the generalized Anscombe's transformation\n(GAT) was used to stabilize varying nature of the PET noise. Other than noise\nstabilization, it is also desirable for the noise removal filter to preserve\nthe boundaries of the structures while smoothing the noisy regions. Indeed, it\nis important to avoid significant loss of quantitative information such as\nstandard uptake value (SUV)-based metrics as well as metabolic lesion volume.\nTo satisfy all these properties, we extended bilateral filtering method into\ntrilateral filtering through multiscaling and optimal Gaussianization process.\nThe proposed method was tested on more than 50 PET-CT images from various\npatients having different cancers and achieved the superior performance\ncompared to the widely used denoising techniques in the literature."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3399v2", 
    "other_authors": "Xianjie Chen, Alan Yuille", 
    "title": "Articulated Pose Estimation by a Graphical Model with Image Dependent   Pairwise Relations", 
    "arxiv-id": "1407.3399v2", 
    "author": "Alan Yuille", 
    "publish": "2014-07-12T17:04:21Z", 
    "summary": "We present a method for estimating articulated human pose from a single\nstatic image based on a graphical model with novel pairwise relations that make\nadaptive use of local image measurements. More precisely, we specify a\ngraphical model for human pose which exploits the fact the local image\nmeasurements can be used both to detect parts (or joints) and also to predict\nthe spatial relationships between them (Image Dependent Pairwise Relations).\nThese spatial relationships are represented by a mixture model. We use Deep\nConvolutional Neural Networks (DCNNs) to learn conditional probabilities for\nthe presence of parts and their spatial relationships within image patches.\nHence our model combines the representational flexibility of graphical models\nwith the efficiency and statistical power of DCNNs. Our method significantly\noutperforms the state of the art methods on the LSP and FLIC datasets and also\nperforms very well on the Buffy dataset without any training."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3535v2", 
    "other_authors": "Arif Mahmood, Ajmal Mian, Robyn Owens", 
    "title": "Optimizing Auto-correlation for Fast Target Search in Large Search Space", 
    "arxiv-id": "1407.3535v2", 
    "author": "Robyn Owens", 
    "publish": "2014-07-14T03:57:57Z", 
    "summary": "In remote sensing image-blurring is induced by many sources such as\natmospheric scatter, optical aberration, spatial and temporal sensor\nintegration. The natural blurring can be exploited to speed up target search by\nfast template matching. In this paper, we synthetically induce additional\nnon-uniform blurring to further increase the speed of the matching process. To\navoid loss of accuracy, the amount of synthetic blurring is varied spatially\nover the image according to the underlying content. We extend transitive\nalgorithm for fast template matching by incorporating controlled image blur. To\nthis end we propose an Efficient Group Size (EGS) algorithm which minimizes the\nnumber of similarity computations for a particular search image. A larger\nefficient group size guarantees less computations and more speedup. EGS\nalgorithm is used as a component in our proposed Optimizing auto-correlation\n(OptA) algorithm. In OptA a search image is iteratively non-uniformly blurred\nwhile ensuring no accuracy degradation at any image location. In each iteration\nefficient group size and overall computations are estimated by using the\nproposed EGS algorithm. The OptA algorithm stops when the number of\ncomputations cannot be further decreased without accuracy degradation. The\nproposed algorithm is compared with six existing state of the art exhaustive\naccuracy techniques using correlation coefficient as the similarity measure.\nExperiments on satellite and aerial image datasets demonstrate the\neffectiveness of the proposed algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3540v1", 
    "other_authors": "Tarek El-Gaaly, Joshua Gluckman", 
    "title": "Measuring Atmospheric Scattering from Digital Images of Urban Scenery   using Temporal Polarization-Based Vision", 
    "arxiv-id": "1407.3540v1", 
    "author": "Joshua Gluckman", 
    "publish": "2014-07-14T04:36:31Z", 
    "summary": "Particulate Matter (PM) is a form of air pollution that visually degrades\nurban scenery and is hazardous to human health and the environment. Current\nmonitoring devices are limited in measuring average PM over large areas.\nQuantifying the visual effects of haze in digital images of urban scenery and\ncorrelating these effects to PM levels is a vital step in more practically\nmonitoring our environment. Current image haze extraction algorithms remove\nhaze from the scene for the sole purpose of enhancing vision. We present two\nalgorithms which bridge the gap between image haze extraction and environmental\nmonitoring. We provide a means of measuring atmospheric scattering from images\nof urban scenery by incorporating temporal knowledge. In doing so, we also\npresent a method of recovering an accurate depthmap of the scene and recovering\nthe scene without the visual effects of haze. We compare our algorithm to three\nknown haze removal methods. The algorithms are composed of an optimization over\na model of haze formation in images and an optimization using a constraint of\nconstant depth over a sequence of images taken over time. These algorithms not\nonly measure atmospheric scattering, but also recover a more accurate depthmap\nand dehazed image. The measurements of atmospheric scattering this research\nproduces, can be directly correlated to PM levels and therefore pave the way to\nmonitoring the health of the environment by visual means. Accurate atmospheric\nsensing from digital images is a challenging and under-researched problem. This\nwork provides an important step towards a more practical and accurate visual\nmeans of measuring PM from digital images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3664v1", 
    "other_authors": "Mohammed M. Abdelsamea", 
    "title": "An Enhancement Neighborhood connected Segmentation for 2D-Cellular Image", 
    "arxiv-id": "1407.3664v1", 
    "author": "Mohammed M. Abdelsamea", 
    "publish": "2014-07-14T14:21:38Z", 
    "summary": "A good segmentation result depends on a set of \"correct\" choice for the\nseeds. When the input images are noisy, the seeds may fall on atypical pixels\nthat are not representative of the region statistics. This can lead to\nerroneous segmentation results. In this paper, an automatic seeded region\ngrowing algorithm is proposed for cellular image segmentation. First, the\nregions of interest (ROIs) extracted from the preprocessed image. Second, the\ninitial seeds are automatically selected based on ROIs extracted from the\nimage. Third, the most reprehensive seeds are selected using a machine learning\nalgorithm. Finally, the cellular image is segmented into regions where each\nregion corresponds to a seed. The aim of the proposed is to automatically\nextract the Region of Interests (ROI) from in the cellular images in terms of\novercoming the explosion, under segmentation and over segmentation problems.\nExperimental results show that the proposed algorithm can improve the segmented\nimage and the segmented results are less noisy as compared to some existing\nalgorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/EMBC.2014.6945004", 
    "link": "http://arxiv.org/pdf/1407.3673v2", 
    "other_authors": "Isha Tyagi, Ashish Nautiyal, Vishwanath Bijalwan, Meenu Balodhi", 
    "title": "Enhanced EZW Technique for Compression of Image by Setting Detail   Retaining Pass Number", 
    "arxiv-id": "1407.3673v2", 
    "author": "Meenu Balodhi", 
    "publish": "2014-07-03T10:55:52Z", 
    "summary": "This submission has been withdrawn by arXiv administrators because it\ncontains excessive and unattributed reuse of content from other authors."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P289", 
    "link": "http://arxiv.org/pdf/1407.3675v1", 
    "other_authors": "Archana Vijayan, Vincy Salam", 
    "title": "A New Approach for Super resolution by Using Web Images and FFT Based   Image Registration", 
    "arxiv-id": "1407.3675v1", 
    "author": "Vincy Salam", 
    "publish": "2014-07-05T13:10:01Z", 
    "summary": "Preserving accuracy is a challenging issue in super resolution images. In\nthis paper, we propose a new FFT based image registration algorithm and a\nsparse based super resolution algorithm to improve the accuracy of super\nresolution image. Given a low resolution image, our approach initially extracts\nthe local descriptors from the input and then the local descriptors from the\nwhole correlated images using the SIFT algorithm. Once this is completed, it\nwill compare the local descriptors on the basis of a threshold value. The\nretrieved images could be having different focal length, illumination,\ninclination and size. To overcome the above differences of the retrieved\nimages, we propose a new FFT based image registration algorithm. After the\nregistration stage, we apply a sparse based super resolution on the images for\nrecreating images with better resolution compared to the input. Based on the\nPSSNR calculation and SSIM comparison, we can see that the new methodology\ncreates a better image than the traditional methods."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P289", 
    "link": "http://arxiv.org/pdf/1407.3686v1", 
    "other_authors": "Alejandro Gonz\u00e1lez, Sebastian Ramos, David V\u00e1zquez, Antonio M. L\u00f3pez, Jaume Amores", 
    "title": "Spatiotemporal Stacked Sequential Learning for Pedestrian Detection", 
    "arxiv-id": "1407.3686v1", 
    "author": "Jaume Amores", 
    "publish": "2014-07-14T15:03:01Z", 
    "summary": "Pedestrian classifiers decide which image windows contain a pedestrian. In\npractice, such classifiers provide a relatively high response at neighbor\nwindows overlapping a pedestrian, while the responses around potential false\npositives are expected to be lower. An analogous reasoning applies for image\nsequences. If there is a pedestrian located within a frame, the same pedestrian\nis expected to appear close to the same location in neighbor frames. Therefore,\nsuch a location has chances of receiving high classification scores during\nseveral frames, while false positives are expected to be more spurious. In this\npaper we propose to exploit such correlations for improving the accuracy of\nbase pedestrian classifiers. In particular, we propose to use two-stage\nclassifiers which not only rely on the image descriptors required by the base\nclassifiers but also on the response of such base classifiers in a given\nspatiotemporal neighborhood. More specifically, we train pedestrian classifiers\nusing a stacked sequential learning (SSL) paradigm. We use a new pedestrian\ndataset we have acquired from a car to evaluate our proposal at different frame\nrates. We also test on a well known dataset: Caltech. The obtained results show\nthat our SSL proposal boosts detection accuracy significantly with a minimal\nimpact on the computational cost. Interestingly, SSL improves more the accuracy\nat the most dangerous situations, i.e. when a pedestrian is close to the\ncamera."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P289", 
    "link": "http://arxiv.org/pdf/1407.3695v1", 
    "other_authors": "Isidora Stankovi\u0107", 
    "title": "Recovery of Images with Missing Pixels using a Gradient Compressive   Sensing Algorithm", 
    "arxiv-id": "1407.3695v1", 
    "author": "Isidora Stankovi\u0107", 
    "publish": "2014-06-22T20:18:32Z", 
    "summary": "This paper investigates the possibility of reconstruction of images\nconsidering that they are sparse in the DCT transformation domain. Two\napproaches are considered. One when the image is pre-processed in the DCT\ndomain, using 8x8 blocks. The image is made sparse by setting the smallest DCT\ncoefficients to zero. In the other case the original image is considered\nwithout pre-processing, assuming the sparsity as intrinsic property of the\nanalyzed image. A gradient based algorithm is used to recover a large number of\nmissing pixels in the image. The case of a salt-and-paper noise affecting a\nlarge number of pixels is easily reduced to the case of missing pixels and\nconsidered within the same framework. The reconstruction of images affected\nwith salt-and-paper impulsive is compared with the images filtered using a\nmedian filter. The same algorithm can be used considering transformation of the\nwhole image. Reconstructions of black and white and colour images are\nconsidered."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P289", 
    "link": "http://arxiv.org/pdf/1407.3840v4", 
    "other_authors": "Lee-Kang Liu, Stanley H. Chan, Truong Q. Nguyen", 
    "title": "Depth Reconstruction from Sparse Samples: Representation, Algorithm, and   Sampling", 
    "arxiv-id": "1407.3840v4", 
    "author": "Truong Q. Nguyen", 
    "publish": "2014-07-14T22:52:05Z", 
    "summary": "The rapid development of 3D technology and computer vision applications have\nmotivated a thrust of methodologies for depth acquisition and estimation.\nHowever, most existing hardware and software methods have limited performance\ndue to poor depth precision, low resolution and high computational cost. In\nthis paper, we present a computationally efficient method to recover dense\ndepth maps from sparse measurements. We make three contributions. First, we\nprovide empirical evidence that depth maps can be encoded much more sparsely\nthan natural images by using common dictionaries such as wavelets and\ncontourlets. We also show that a combined wavelet-contourlet dictionary\nachieves better performance than using either dictionary alone. Second, we\npropose an alternating direction method of multipliers (ADMM) to achieve fast\nreconstruction. A multi-scale warm start procedure is proposed to speed up the\nconvergence. Third, we propose a two-stage randomized sampling scheme to\noptimally choose the sampling locations, thus maximizing the reconstruction\nperformance for any given sampling budget. Experimental results show that the\nproposed method produces high quality dense depth estimates, and is robust to\nnoisy measurements. Applications to real data in stereo matching are\ndemonstrated."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P289", 
    "link": "http://arxiv.org/pdf/1407.3867v1", 
    "other_authors": "Ning Zhang, Jeff Donahue, Ross Girshick, Trevor Darrell", 
    "title": "Part-based R-CNNs for Fine-grained Category Detection", 
    "arxiv-id": "1407.3867v1", 
    "author": "Trevor Darrell", 
    "publish": "2014-07-15T02:32:16Z", 
    "summary": "Semantic part localization can facilitate fine-grained categorization by\nexplicitly isolating subtle appearance differences associated with specific\nobject parts. Methods for pose-normalized representations have been proposed,\nbut generally presume bounding box annotations at test time due to the\ndifficulty of object detection. We propose a model for fine-grained\ncategorization that overcomes these limitations by leveraging deep\nconvolutional features computed on bottom-up region proposals. Our method\nlearns whole-object and part detectors, enforces learned geometric constraints\nbetween them, and predicts a fine-grained category from a pose-normalized\nrepresentation. Experiments on the Caltech-UCSD bird dataset confirm that our\nmethod outperforms state-of-the-art fine-grained categorization methods in an\nend-to-end evaluation without requiring a bounding box at test time."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0546-8", 
    "link": "http://arxiv.org/pdf/1407.3956v2", 
    "other_authors": "Bernhard Schmitzer, Christoph Schn\u00f6rr", 
    "title": "Globally Optimal Joint Image Segmentation and Shape Matching Based on   Wasserstein Modes", 
    "arxiv-id": "1407.3956v2", 
    "author": "Christoph Schn\u00f6rr", 
    "publish": "2014-07-15T12:12:54Z", 
    "summary": "A functional for joint variational object segmentation and shape matching is\ndeveloped. The formulation is based on optimal transport w.r.t. geometric\ndistance and local feature similarity. Geometric invariance and modelling of\nobject-typical statistical variations is achieved by introducing degrees of\nfreedom that describe transformations and deformations of the shape template.\nThe shape model is mathematically equivalent to contour-based approaches but\ninference can be performed without conversion between the contour and region\nrepresentations, allowing combination with other convex segmentation approaches\nand simplifying optimization. While the overall functional is non-convex,\nnon-convexity is confined to a low-dimensional variable. We propose a locally\noptimal alternating optimization scheme and a globally optimal branch and bound\nscheme, based on adaptive convex relaxation. Combining both methods allows to\neliminate the delicate initialization problem inherent to many contour based\napproaches while remaining computationally practical. The properties of the\nfunctional, its ability to adapt to a wide range of input data structures and\nthe different optimization schemes are illustrated and compared by numerical\nexperiments."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-014-0546-8", 
    "link": "http://arxiv.org/pdf/1407.3969v1", 
    "other_authors": "Giorgio Ricca, Mauro C. Beltrametti, Anna Maria Massone", 
    "title": "An iterative approach to Hough transform without re-voting", 
    "arxiv-id": "1407.3969v1", 
    "author": "Anna Maria Massone", 
    "publish": "2014-07-15T12:56:35Z", 
    "summary": "Many bone shapes in the human skeleton are characterized by profiles that can\nbe associated to equations of algebraic curves. Fixing the parameters in the\ncurve equation, by means of a classical pattern recognition procedure like the\nHough transform technique, it is then possible to associate an equation to a\nspecific bone profile. However, most skeleton districts are more accurately\ndescribed by piecewise defined curves. This paper utilizes an iterative\napproach of the Hough transform without re-voting, to provide an efficient\nprocedure for describing the profile of a bone in the human skeleton as a\ncollection of different but continuously attached curves."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.3986v1", 
    "other_authors": "Haritha Raveendran, Deepa Thomas", 
    "title": "Image Fusion Using LEP Filtering and Bilinear Interpolation", 
    "arxiv-id": "1407.3986v1", 
    "author": "Deepa Thomas", 
    "publish": "2014-07-05T13:12:39Z", 
    "summary": "Image Fusion is the process in which core information from a set of component\nimages is merged to form a single image, which is more informative and complete\nthan the component input images in quality and appearance. This paper presents\na fast and effective image fusion method for creating high quality fused images\nby merging component images. In the proposed method, the input image is broken\ndown to a two-scale image representation with a base layer having large scale\nvariations in intensity, and a detail layer containing small scale details.\nHere fusion of the base and detail layers is implemented by means of a Local\nEdge preserving filtering based technique. The proposed method is an efficient\nimage fusion technique in which the noise component is very low and quality of\nthe resultant image is high so that it can be used for applications like\nmedical image processing, requiring very accurate edge preserved images.\nPerformance is tested by calculating PSNR and SSIM of images. The benefit of\nthe proposed method is that it removes noise without altering the underlying\nstructures of the image. This paper also presents an image zooming technique\nusing bilinear interpolation in which a portion of the input image is cropped\nand bilinear interpolation is applied. Experimental results showed that the\nwhen PSNR value is calculated, the noise is found to be very low for the\nresultant image portion."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.4023v2", 
    "other_authors": "Bin Yang, Junjie Yan, Zhen Lei, Stan Z. Li", 
    "title": "Aggregate channel features for multi-view face detection", 
    "arxiv-id": "1407.4023v2", 
    "author": "Stan Z. Li", 
    "publish": "2014-07-15T15:31:39Z", 
    "summary": "Face detection has drawn much attention in recent decades since the seminal\nwork by Viola and Jones. While many subsequences have improved the work with\nmore powerful learning algorithms, the feature representation used for face\ndetection still can't meet the demand for effectively and efficiently handling\nfaces with large appearance variance in the wild. To solve this bottleneck, we\nborrow the concept of channel features to the face detection domain, which\nextends the image channel to diverse types like gradient magnitude and oriented\ngradient histograms and therefore encodes rich information in a simple form. We\nadopt a novel variant called aggregate channel features, make a full\nexploration of feature design, and discover a multi-scale version of features\nwith better performance. To deal with poses of faces in the wild, we propose a\nmulti-view detection approach featuring score re-ranking and detection\nadjustment. Following the learning pipelines in Viola-Jones framework, the\nmulti-view face detector using aggregate channel features shows competitive\nperformance against state-of-the-art algorithms on AFW and FDDB testsets, while\nruns at 42 FPS on VGA images."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.4206v1", 
    "other_authors": "Yichao Xu, Kazuki Maeno, Hajime Nagahara, Rin-ichiro Taniguchi", 
    "title": "Mobile Camera Array Calibration for Light Field Acquisition", 
    "arxiv-id": "1407.4206v1", 
    "author": "Rin-ichiro Taniguchi", 
    "publish": "2014-07-16T06:38:24Z", 
    "summary": "The light field camera is useful for computer graphics and vision\napplications. Calibration is an essential step for these applications. After\ncalibration, we can rectify the captured image by using the calibrated camera\nparameters. However, the large camera array calibration method, which assumes\nthat all cameras are on the same plane, ignores the orientation and intrinsic\nparameters. The multi-camera calibration technique usually assumes that the\nworking volume and viewpoints are fixed. In this paper, we describe a\ncalibration algorithm suitable for a mobile camera array based light field\nacquisition system. The algorithm performs in Zhang's style by moving a\ncheckerboard, and computes the initial parameters in closed form. Global\noptimization is then applied to refine all the parameters simultaneously. Our\nimplementation is rather flexible in that users can assign the number of\nviewpoints and refinement of intrinsic parameters is optional. Experiments on\nboth simulated data and real data acquired by a commercial product show that\nour method yields good results. Digital refocusing application shows the\ncalibrated light field can well focus to the target object we desired."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.4867v2", 
    "other_authors": "Jay Prakash Gupta, Pushkar Dixit, Nishant Singh, Vijay Bhaskar Semwal", 
    "title": "Analysis of Gait Pattern to Recognize the Human Activities", 
    "arxiv-id": "1407.4867v2", 
    "author": "Vijay Bhaskar Semwal", 
    "publish": "2014-07-18T01:45:17Z", 
    "summary": "Human activity recognition based on the computer vision is the process of\nlabelling image sequences with action labels. Accurate systems for this problem\nare applied in areas such as visual surveillance, human computer interaction\nand video retrieval."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.4874v1", 
    "other_authors": "Zhenhua Wang, Bin Fan, Fuchao Wu", 
    "title": "Affine Subspace Representation for Feature Description", 
    "arxiv-id": "1407.4874v1", 
    "author": "Fuchao Wu", 
    "publish": "2014-07-18T02:33:56Z", 
    "summary": "This paper proposes a novel Affine Subspace Representation (ASR) descriptor\nto deal with affine distortions induced by viewpoint changes. Unlike the\ntraditional local descriptors such as SIFT, ASR inherently encodes local\ninformation of multi-view patches, making it robust to affine distortions while\nmaintaining a high discriminative ability. To this end, PCA is used to\nrepresent affine-warped patches as PCA-patch vectors for its compactness and\nefficiency. Then according to the subspace assumption, which implies that the\nPCA-patch vectors of various affine-warped patches of the same keypoint can be\nrepresented by a low-dimensional linear subspace, the ASR descriptor is\nobtained by using a simple subspace-to-point mapping. Such a linear subspace\nrepresentation could accurately capture the underlying information of a\nkeypoint (local structure) under multiple views without sacrificing its\ndistinctiveness. To accelerate the computation of ASR descriptor, a fast\napproximate algorithm is proposed by moving the most computational part (ie,\nwarp patch under various affine transformations) to an offline training stage.\nExperimental results show that ASR is not only better than the state-of-the-art\ndescriptors under various image transformations, but also performs well without\na dedicated affine invariant detector when dealing with viewpoint changes."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.4898v1", 
    "other_authors": "Ghassem Tofighi, Nasser Ali Afarin, Kamraan Raahemifar, Anastasios N. Venetsanopoulos", 
    "title": "Hand Pointing Detection Using Live Histogram Template of Forehead Skin", 
    "arxiv-id": "1407.4898v1", 
    "author": "Anastasios N. Venetsanopoulos", 
    "publish": "2014-07-18T07:10:03Z", 
    "summary": "Hand pointing detection has multiple applications in many fields such as\nvirtual reality and control devices in smart homes. In this paper, we proposed\na novel approach to detect pointing vector in 2D space of a room. After\nbackground subtraction, face and forehead is detected. In the second step,\nforehead skin H-S plane histograms in HSV space is calculated. By using these\nhistogram templates of users skin, and back projection method, skin areas are\ndetected. The contours of hand are extracted using Freeman chain code\nalgorithm. Next step is finding fingertips. Points in hand contour which are\ncandidates for the fingertip can be found in convex defects of convex hull and\ncontour. We introduced a novel method for finding the fingertip based on the\nspecial points on the contour and their relationships. Our approach detects\nhand-pointing vectors in live video from a common webcam with 94%TP and 85%TN."
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.5035v3", 
    "other_authors": "Judy Hoffman, Sergio Guadarrama, Eric Tzeng, Ronghang Hu, Jeff Donahue, Ross Girshick, Trevor Darrell, Kate Saenko", 
    "title": "LSDA: Large Scale Detection Through Adaptation", 
    "arxiv-id": "1407.5035v3", 
    "author": "Kate Saenko", 
    "publish": "2014-07-18T17:08:02Z", 
    "summary": "A major challenge in scaling object detection is the difficulty of obtaining\nlabeled images for large numbers of categories. Recently, deep convolutional\nneural networks (CNNs) have emerged as clear winners on object classification\nbenchmarks, in part due to training with 1.2M+ labeled classification images.\nUnfortunately, only a small fraction of those labels are available for the\ndetection task. It is much cheaper and easier to collect large quantities of\nimage-level labels from search engines than it is to collect detection data and\nlabel it with precise bounding boxes. In this paper, we propose Large Scale\nDetection through Adaptation (LSDA), an algorithm which learns the difference\nbetween the two tasks and transfers this knowledge to classifiers for\ncategories without bounding box annotated data, turning them into detectors.\nOur method has the potential to enable detection for the tens of thousands of\ncategories that lack bounding box annotations, yet have plenty of\nclassification data. Evaluation on the ImageNet LSVRC-2013 detection challenge\ndemonstrates the efficacy of our approach. This algorithm enables us to produce\na >7.6K detector by using available classification data from leaf nodes in the\nImageNet tree. We additionally demonstrate how to modify our architecture to\nproduce a fast detector (running at 2fps for the 7.6K detector). Models and\nsoftware are available at"
},{
    "category": "cs.CV", 
    "doi": "10.14445/22315381/IJETT-V12P282", 
    "link": "http://arxiv.org/pdf/1407.5242v1", 
    "other_authors": "Ziming Zhang, Philip H. S. Torr", 
    "title": "Object Proposal Generation using Two-Stage Cascade SVMs", 
    "arxiv-id": "1407.5242v1", 
    "author": "Philip H. S. Torr", 
    "publish": "2014-07-20T03:53:21Z", 
    "summary": "Object proposal algorithms have shown great promise as a first step for\nobject recognition and detection. Good object proposal generation algorithms\nrequire high object recall rate as well as low computational cost, because\ngenerating object proposals is usually utilized as a preprocessing step. The\nproblem of how to accelerate the object proposal generation and evaluation\nprocess without decreasing recall is thus of great interest. In this paper, we\npropose a new object proposal generation method using two-stage cascade SVMs,\nwhere in the first stage linear filters are learned for predefined quantized\nscales/aspect-ratios independently, and in the second stage a global linear\nclassifier is learned across all the quantized scales/aspect-ratios for\ncalibration, so that all the proposals can be compared properly. The proposals\nwith highest scores are our final output. Specifically, we explain our\nscale/aspect-ratio quantization scheme, and investigate the effects of\ncombinations of $\\ell_1$ and $\\ell_2$ regularizers in cascade SVMs with/without\nranking constraints in learning. Comprehensive experiments on VOC2007 dataset\nare conducted, and our results achieve the state-of-the-art performance with\nhigh object recall rate and high computational efficiency. Besides, our method\nhas been demonstrated to be suitable for not only class-specific but also\ngeneric object proposal generation."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.41.2014.077", 
    "link": "http://arxiv.org/pdf/1407.5324v1", 
    "other_authors": "Reza Azad, Babak Azad, Iman Tavakoli Kazerooni", 
    "title": "Optimized Method for Iranian Road Signs Detection and recognition system", 
    "arxiv-id": "1407.5324v1", 
    "author": "Iman Tavakoli Kazerooni", 
    "publish": "2014-07-20T18:53:20Z", 
    "summary": "Road sign recognition is one of the core technologies in Intelligent\nTransport Systems. In the current study, a robust and real-time method is\npresented to identify and detect the roads speed signs in road image in\ndifferent situations. In our proposed method, first, the connected components\nare created in the main image using the edge detection and mathematical\nmorphology and the location of the road signs extracted by the geometric and\ncolor data; then the letters are segmented and recognized by Multiclass Support\nVector Machine (SVMs) classifiers. Regarding that the geometric and color\nfeatures ate properly used in detection the location of the road signs, so it\nis not sensitive to the distance and noise and has higher speed and efficiency.\nIn the result part, the proposed approach is applied on Iranian road speed sign\ndatabase and the detection and recognition accuracy rate achieved 98.66% and\n100% respectively."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.41.2014.077", 
    "link": "http://arxiv.org/pdf/1407.5759v1", 
    "other_authors": "Denis Fortun, Patrick Bouthemy, Charles Kervrann", 
    "title": "Aggregation of local parametric candidates with exemplar-based occlusion   handling for optical flow", 
    "arxiv-id": "1407.5759v1", 
    "author": "Charles Kervrann", 
    "publish": "2014-07-22T06:50:40Z", 
    "summary": "Handling all together large displacements, motion details and occlusions\nremains an open issue for reliable computation of optical flow in a video\nsequence. We propose a two-step aggregation paradigm to address this problem.\nThe idea is to supply local motion candidates at every pixel in a first step,\nand then to combine them to determine the global optical flow field in a second\nstep. We exploit local parametric estimations combined with patch\ncorrespondences and we experimentally demonstrate that they are sufficient to\nproduce highly accurate motion candidates. The aggregation step is designed as\nthe discrete optimization of a global regularized energy. The occlusion map is\nestimated jointly with the flow field throughout the two steps. We propose a\ngeneric exemplar-based approach for occlusion filling with motion vectors. We\nachieve state-of-the-art results in computer vision benchmarks, with\nparticularly significant improvements in the case of large displacements and\nocclusions."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.41.2014.077", 
    "link": "http://arxiv.org/pdf/1407.5976v1", 
    "other_authors": "Holger R. Roth, Jianhua Yao, Le Lu, James Stieger, Joseph E. Burns, Ronald M. Summers", 
    "title": "Detection of Sclerotic Spine Metastases via Random Aggregation of Deep   Convolutional Neural Network Classifications", 
    "arxiv-id": "1407.5976v1", 
    "author": "Ronald M. Summers", 
    "publish": "2014-07-22T19:06:50Z", 
    "summary": "Automated detection of sclerotic metastases (bone lesions) in Computed\nTomography (CT) images has potential to be an important tool in clinical\npractice and research. State-of-the-art methods show performance of 79%\nsensitivity or true-positive (TP) rate, at 10 false-positives (FP) per volume.\nWe design a two-tiered coarse-to-fine cascade framework to first operate a\nhighly sensitive candidate generation system at a maximum sensitivity of ~92%\nbut with high FP level (~50 per patient). Regions of interest (ROI) for lesion\ncandidates are generated in this step and function as input for the second\ntier. In the second tier we generate N 2D views, via scale, random\ntranslations, and rotations with respect to each ROI centroid coordinates.\nThese random views are used to train a deep Convolutional Neural Network (CNN)\nclassifier. In testing, the CNN is employed to assign individual probabilities\nfor a new set of N random views that are averaged at each ROI to compute a\nfinal per-candidate classification probability. This second tier behaves as a\nhighly selective process to reject difficult false positives while preserving\nhigh sensitivities. We validate the approach on CT images of 59 patients (49\nwith sclerotic metastases and 10 normal controls). The proposed method reduces\nthe number of FP/vol. from 4 to 1.2, 7 to 3, and 12 to 9.5 when comparing a\nsensitivity rates of 60%, 70%, and 80% respectively in testing. The\nArea-Under-the-Curve (AUC) is 0.834. The results show marked improvement upon\nprevious work."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.41.2014.077", 
    "link": "http://arxiv.org/pdf/1407.6082v1", 
    "other_authors": "Igor Milevskiy, Yuri Boykov", 
    "title": "Joint Energy-based Detection and Classificationon of Multilingual Text   Lines", 
    "arxiv-id": "1407.6082v1", 
    "author": "Yuri Boykov", 
    "publish": "2014-07-23T01:14:01Z", 
    "summary": "This paper proposes a new hierarchical MDL-based model for a joint detection\nand classification of multilingual text lines in im- ages taken by hand-held\ncameras. The majority of related text detec- tion methods assume alphabet-based\nwriting in a single language, e.g. in Latin. They use simple clustering\nheuristics specific to such texts: prox- imity between letters within one line,\nlarger distance between separate lines, etc. We are interested in a\nsignificantly more ambiguous problem where images combine alphabet and\nlogographic characters from multiple languages and typographic rules vary a lot\n(e.g. English, Korean, and Chinese). Complexity of detecting and classifying\ntext lines in multiple languages calls for a more principled approach based on\ninformation- theoretic principles. Our new MDL model includes data costs\ncombining geometric errors with classification likelihoods and a hierarchical\nsparsity term based on label costs. This energy model can be efficiently\nminimized by fusion moves. We demonstrate robustness of the proposed algorithm\non a large new database of multilingual text images collected in the pub- lic\ntransit system of Seoul."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.41.2014.077", 
    "link": "http://arxiv.org/pdf/1407.6174v1", 
    "other_authors": "Fatih Cakir, Stan Sclaroff", 
    "title": "Visual Word Selection without Re-Coding and Re-Pooling", 
    "arxiv-id": "1407.6174v1", 
    "author": "Stan Sclaroff", 
    "publish": "2014-07-23T11:10:39Z", 
    "summary": "The Bag-of-Words (BoW) representation is widely used in computer vision. The\nsize of the codebook impacts the time and space complexity of the applications\nthat use BoW. Thus, given a training set for a particular computer vision task,\na key problem is pruning a large codebook to select only a subset of visual\nwords. Evaluating possible selections of words to be included in the pruned\ncodebook can be computationally prohibitive; in a brute-force scheme,\nevaluating each pruned codebook requires re-coding of all features extracted\nfrom training images to words in the candidate codebook and then re-pooling the\nwords to obtain a representation of each image, e.g., histogram of visual word\nfrequencies. In this paper, a method is proposed that selects and evaluates a\nsubset of words from an initially large codebook, without the need for\nre-coding or re-pooling. Formulations are proposed for two commonly-used\nschemes: hard and soft (kernel) coding of visual words with average-pooling.\nThe effectiveness of these formulations is evaluated on the 15 Scenes and\nCaltech 10 benchmarks."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.41.2014.077", 
    "link": "http://arxiv.org/pdf/1407.6251v2", 
    "other_authors": "Philip Lenz, Andreas Geiger, Raquel Urtasun", 
    "title": "FollowMe: Efficient Online Min-Cost Flow Tracking with Bounded Memory   and Computation", 
    "arxiv-id": "1407.6251v2", 
    "author": "Raquel Urtasun", 
    "publish": "2014-07-23T15:07:12Z", 
    "summary": "One of the most popular approaches to multi-target tracking is\ntracking-by-detection. Current min-cost flow algorithms which solve the data\nassociation problem optimally have three main drawbacks: they are\ncomputationally expensive, they assume that the whole video is given as a\nbatch, and they scale badly in memory and computation with the length of the\nvideo sequence. In this paper, we address each of these issues, resulting in a\ncomputationally and memory-bounded solution. First, we introduce a dynamic\nversion of the successive shortest-path algorithm which solves the data\nassociation problem optimally while reusing computation, resulting in\nsignificantly faster inference than standard solvers. Second, we address the\noptimal solution to the data association problem when dealing with an incoming\nstream of data (i.e., online setting). Finally, we present our main\ncontribution which is an approximate online solution with bounded memory and\ncomputation which is capable of handling videos of arbitrarily length while\nperforming tracking in real time. We demonstrate the effectiveness of our\nalgorithms on the KITTI and PETS2009 benchmarks and show state-of-the-art\nperformance, while being significantly faster than existing solvers."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6318v1", 
    "other_authors": "Reza Azad, Fatemeh Davami", 
    "title": "A robust and adaptable method for face detection based on Color   Probabilistic Estimation Technique", 
    "arxiv-id": "1407.6318v1", 
    "author": "Fatemeh Davami", 
    "publish": "2014-07-23T18:12:08Z", 
    "summary": "Human face perception is currently an active research area in the computer\nvision community. Skin detection is one of the most important and primary\nstages for this purpose. So far, many approaches are proposed to done this\ncase. Near all of these methods have tried to find best match intensity\ndistribution with skin pixels based on popular color spaces such as RGB, HSI or\nYCBCR. Results show that these methods cannot provide an accurate approach for\nevery kind of skin. In this paper, an approach is proposed to solve this\nproblem using a color probabilistic estimation technique. This approach is\nincluding two stages. In the first one, the skin intensity distribution is\nestimated using some train photos of pure skin, and at the second stage, the\nskin pixels are detected using Gaussian model and optimal threshold tuning.\nThen from the skin region facial features have been extracted to get the face\nfrom the skin region. In the results section, the proposed approach is applied\non FEI database and the accuracy rate reached 99.25%. The proposed approach can\nbe used for all kinds of skin using train stage which is the main advantage\namong the other advantages, such as Low noise sensitivity and low computational\ncomplexity."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6321v1", 
    "other_authors": "Reza Azad, Majid Nazari", 
    "title": "Novel and Automatic Parking Inventory System Based on Pattern   Recognition and Directional Chain Code", 
    "arxiv-id": "1407.6321v1", 
    "author": "Majid Nazari", 
    "publish": "2014-07-23T18:20:56Z", 
    "summary": "The objective of this paper is to design an efficient vehicle license plate\nrecognition System and to implement it for automatic parking inventory system.\nThe system detects the vehicle first and then captures the image of the front\nview of the vehicle. Vehicle license plate is localized and characters are\nsegmented. For finding the place of plate, a novel and real time method is\nexpressed. A new and robust technique based on directional chain code is used\nfor character recognition. The resulting vehicle number is then compared with\nthe available database of all the vehicles so as to come up with information\nabout the vehicle type and to charge entrance cost accordingly. The system is\nthen allowed to open parking barrier for the vehicle and generate entrance cost\nreceipt. The vehicle information (such as entrance time, date, and cost amount)\nis also stored in the database to maintain the record. The hardware and\nsoftware integrated system is implemented and a working prototype model is\ndeveloped. Under the available database, the average accuracy of locating\nvehicle license plate obtained 100%. Using 70% samples of character for\ntraining, we tested our scheme on whole samples and obtained 100% correct\nrecognition rate. Further we tested our character recognition stage on Persian\nvehicle data set and we achieved 99% correct recognition."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6423v1", 
    "other_authors": "Jiasong Wu, Longyu Jiang, Xu Han, Lotfi Senhadji, Huazhong Shu", 
    "title": "Performance evaluation of wavelet scattering network in image texture   classification in various color spaces", 
    "arxiv-id": "1407.6423v1", 
    "author": "Huazhong Shu", 
    "publish": "2014-07-24T01:39:33Z", 
    "summary": "Texture plays an important role in many image analysis applications. In this\npaper, we give a performance evaluation of color texture classification by\nperforming wavelet scattering network in various color spaces. Experimental\nresults on the KTH_TIPS_COL database show that opponent RGB based wavelet\nscattering network outperforms other color spaces. Therefore, when dealing with\nthe problem of color texture classification, opponent RGB based wavelet\nscattering network is recommended."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6492v2", 
    "other_authors": "Reza Azad, Fatemeh Davami, Hamid Reza Shayegh", 
    "title": "Recognition of Handwritten Persian/Arabic Numerals Based on Robust   Feature Set and K-NN Classifier", 
    "arxiv-id": "1407.6492v2", 
    "author": "Hamid Reza Shayegh", 
    "publish": "2014-07-24T08:53:00Z", 
    "summary": "This paper has been withdrawn by the author due to a crucial sign error in\nequation 2 and some mistake in Table 1 information. please let me for changing\nthis information and updating this paper."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6496v2", 
    "other_authors": "Reza Azad, Mohammad Baghdadi", 
    "title": "Novel and Fast Algorithm for Extracting License Plate Location Based on   Edge Analysis", 
    "arxiv-id": "1407.6496v2", 
    "author": "Mohammad Baghdadi", 
    "publish": "2014-07-24T09:01:36Z", 
    "summary": "Nowadays in developing or developed countries, the Intelligent Transportation\nSystem (ITS) technology has attracted so much attention to itself. License\nPlate Recognition (LPR) systems have many applications in ITSs, such as the\npayment of parking fee, controlling the traffic volume, traffic data\ncollection, etc. This paper presents a new and fast method for license plate\nextraction based on edge analysis. our proposed method consist of four stage,\nwhich are edge detection, non-useable edge and noise removing, edge analysis\nand morphology-based license plate extraction. In the result part, the proposed\nalgorithm is applied on vehicle database and the accuracy rate reached 98%.\nFrom the experimental results it is shown that the proposed method gives fairly\nacceptable level of accuracy for practical license plate recognition system."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6498v1", 
    "other_authors": "Reza Azad, Babak Azad, Hamid Reza Shayegh", 
    "title": "Real-Time and Efficient Method for Accuracy Enhancement of Edge Based   License Plate Recognition System", 
    "arxiv-id": "1407.6498v1", 
    "author": "Hamid Reza Shayegh", 
    "publish": "2014-07-24T09:02:16Z", 
    "summary": "License Plate Recognition plays an important role on the traffic monitoring\nand parking management. Administration and restriction of those transportation\ntools for their better service becomes very essential. In this paper, a fast\nand real time method has an appropriate application to find plates that the\nplat has tilt and the picture quality is poor. In the proposed method, at the\nbeginning, the image is converted into binary mode with use of adaptive\nthreshold. And with use of edge detection and morphology operation, plate\nnumber location has been specified and if the plat has tilt; its tilt is\nremoved away. Then its characters are distinguished using image processing\ntechniques. Finally, K Nearest Neighbour (KNN) classifier was used for\ncharacter recognition. This method has been tested on available data set that\nhas different images of the background, considering distance, and angel of view\nso that the correct extraction rate of plate reached at 98% and character\nrecognition rate achieved at 99.12%. Further we tested our character\nrecognition stage on Persian vehicle data set and we achieved 99% correct\nrecognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.7815/ijorcs.36.2013.072", 
    "link": "http://arxiv.org/pdf/1407.6506v1", 
    "other_authors": "Reza Azad, Hamid Reza Shayegh", 
    "title": "Novel and Tuneable Method for Skin Detection Based on Hybrid Color Space   and Color Statistical Features", 
    "arxiv-id": "1407.6506v1", 
    "author": "Hamid Reza Shayegh", 
    "publish": "2014-07-24T09:31:13Z", 
    "summary": "Skin detection is one of the most important and primary stages in some of\nimage processing applications such as face detection and human tracking. So\nfar, many approaches are proposed to done this case. Near all of these methods\nhave tried to find best match intensity distribution with skin pixels based on\npopular color spaces such as RGB, CMYK or YCbCr. Results show these methods\ncannot provide an accurate approach for every kinds of skin. In this paper, an\napproach is proposed to solve this problem using statistical features\ntechnique. This approach is including two stages. In the first one, from pure\nskin statistical features were extracted and at the second stage, the skin\npixels are detected using HSV and YCbCr color spaces. In the result part, the\nproposed approach is applied on FEI database and the accuracy rate reached\n99.25 + 0.2. Further proposed method is applied on complex background database\nand accuracy rate obtained 95.40+0.31%. The proposed approach can be used for\nall kinds of skin using train stage which is the main advantages of it. Low\nnoise sensitivity and low computational complexity are some of other\nadvantages."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.6510v1", 
    "other_authors": "Reza Azad, Hamid Reza Shayegh", 
    "title": "New Method for Optimization of License Plate Recognition system with Use   of Edge Detection and Connected Component", 
    "arxiv-id": "1407.6510v1", 
    "author": "Hamid Reza Shayegh", 
    "publish": "2014-07-24T09:52:47Z", 
    "summary": "License Plate recognition plays an important role on the traffic monitoring\nand parking management systems. In this paper, a fast and real time method has\nbeen proposed which has an appropriate application to find tilt and poor\nquality plates. In the proposed method, at the beginning, the image is\nconverted into binary mode using adaptive threshold. Then, by using some edge\ndetection and morphology operations, plate number location has been specified.\nFinally, if the plat has tilt, its tilt is removed away. This method has been\ntested on another paper data set that has different images of the background,\nconsidering distance, and angel of view so that the correct extraction rate of\nplate reached at 98.66%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.6705v2", 
    "other_authors": "Reza Azad, Hamid Reza Shayegh, Hamed Amiri", 
    "title": "A Robust and Efficient Method for Improving Accuracy of License Plate   Characters Recognition", 
    "arxiv-id": "1407.6705v2", 
    "author": "Hamed Amiri", 
    "publish": "2014-07-24T09:26:01Z", 
    "summary": "License Plate Recognition (LPR) plays an important role on the traffic\nmonitoring and parking management. A robust and efficient method for enhancing\naccuracy of license plate characters recognition based on K Nearest Neighbours\n(K-NN) classifier is presented in this paper. The system first prepares a\ncontour form of the extracted character, then the angle and distance feature\ninformation about the character is extracted and finally K-NN classifier is\nused to character recognition. Angle and distance features of a character have\nbeen computed based on distribution of points on the bitmap image of character.\nIn K-NN method, the Euclidean distance between testing point and reference\npoints is calculated in order to find the k-nearest neighbours. We evaluated\nour method on the available dataset that contain 1200 sample. Using 70% samples\nfor training, we tested our method on whole samples and obtained 99% correct\nrecognition rate.Further, we achieved average 99.41% accuracy using\nthree/strategy validation technique on 1200 dataset."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.6748v1", 
    "other_authors": "Ayodeji S. Makinde, Yaw Nkansah-Gyekye, Loserian S. Laizer", 
    "title": "Enhancing the Accuracy of Biometric Feature Extraction Fusion Using   Gabor Filter and Mahalanobis Distance Algorithm", 
    "arxiv-id": "1407.6748v1", 
    "author": "Loserian S. Laizer", 
    "publish": "2014-07-24T22:24:01Z", 
    "summary": "Biometric recognition systems have advanced significantly in the last decade\nand their use in specific applications will increase in the near future. The\nability to conduct meaningful comparisons and assessments will be crucial to\nsuccessful deployment and increasing biometric adoption. The best modality used\nas unimodal biometric systems are unable to fully address the problem of higher\nrecognition rate. Multimodal biometric systems are able to mitigate some of the\nlimitations encountered in unimodal biometric systems, such as\nnon-universality, distinctiveness, non-acceptability, noisy sensor data, spoof\nattacks, and performance. More reliable recognition accuracy and performance\nare achievable as different modalities were being combined together and\ndifferent algorithms or techniques were being used. The work presented in this\npaper focuses on a bimodal biometric system using face and fingerprint. An\nimage enhancement technique (histogram equalization) is used to enhance the\nface and fingerprint images. Salient features of the face and fingerprint were\nextracted using the Gabor filter technique. A dimensionality reduction\ntechnique was carried out on both images extracted features using a principal\ncomponent analysis technique. A feature level fusion algorithm (Mahalanobis\ndistance technique) is used to combine each unimodal feature together. The\nperformance of the proposed approach is validated and is effective."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.7317v1", 
    "other_authors": "Reza Shoja Ghiass, Ognjen Arandjelovic, Hakim Bendada, Xavier Maldague", 
    "title": "A unified framework for thermal face recognition", 
    "arxiv-id": "1407.7317v1", 
    "author": "Xavier Maldague", 
    "publish": "2014-07-28T04:20:24Z", 
    "summary": "The reduction of the cost of infrared (IR) cameras in recent years has made\nIR imaging a highly viable modality for face recognition in practice. A\nparticularly attractive advantage of IR-based over conventional, visible\nspectrum-based face recognition stems from its invariance to visible\nillumination. In this paper we argue that the main limitation of previous work\non face recognition using IR lies in its ad hoc approach to treating different\nnuisance factors which affect appearance, prohibiting a unified approach that\nis capable of handling concurrent changes in multiple (or indeed all) major\nextrinsic sources of variability, which is needed in practice. We describe the\nfirst approach that attempts to achieve this - the framework we propose\nachieves outstanding recognition performance in the presence of variable (i)\npose, (ii) facial expression, (iii) physiological state, (iv) partial occlusion\ndue to eye-wear, and (v) quasi-occlusion due to facial hair growth."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.7390v3", 
    "other_authors": "Jos\u00e9 Ram\u00f3n Padilla-L\u00f3pez, Alexandros Andr\u00e9 Chaaraoui, Francisco Fl\u00f3rez-Revuelta", 
    "title": "A discussion on the validation tests employed to compare human action   recognition methods using the MSR Action3D dataset", 
    "arxiv-id": "1407.7390v3", 
    "author": "Francisco Fl\u00f3rez-Revuelta", 
    "publish": "2014-07-28T11:59:30Z", 
    "summary": "This paper aims to determine which is the best human action recognition\nmethod based on features extracted from RGB-D devices, such as the Microsoft\nKinect. A review of all the papers that make reference to MSR Action3D, the\nmost used dataset that includes depth information acquired from a RGB-D device,\nhas been performed. We found that the validation method used by each work\ndiffers from the others. So, a direct comparison among works cannot be made.\nHowever, almost all the works present their results comparing them without\ntaking into account this issue. Therefore, we present different rankings\naccording to the methodology used for the validation in orden to clarify the\nexisting confusion."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.7504v1", 
    "other_authors": "Lluis Gomez, Dimosthenis Karatzas", 
    "title": "A Fast Hierarchical Method for Multi-script and Arbitrary Oriented Scene   Text Extraction", 
    "arxiv-id": "1407.7504v1", 
    "author": "Dimosthenis Karatzas", 
    "publish": "2014-07-28T19:21:53Z", 
    "summary": "Typography and layout lead to the hierarchical organisation of text in words,\ntext lines, paragraphs. This inherent structure is a key property of text in\nany script and language, which has nonetheless been minimally leveraged by\nexisting text detection methods. This paper addresses the problem of text\nsegmentation in natural scenes from a hierarchical perspective. Contrary to\nexisting methods, we make explicit use of text structure, aiming directly to\nthe detection of region groupings corresponding to text within a hierarchy\nproduced by an agglomerative similarity clustering process over individual\nregions. We propose an optimal way to construct such an hierarchy introducing a\nfeature space designed to produce text group hypotheses with high recall and a\nnovel stopping rule combining a discriminative classifier and a probabilistic\nmeasure of group meaningfulness based in perceptual organization. Results\nobtained over four standard datasets, covering text in variable orientations\nand different languages, demonstrate that our algorithm, while being trained in\na single mixed dataset, outperforms state of the art methods in unconstrained\nscenarios."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.7626v1", 
    "other_authors": "Deepak Ranjan Nayak, Prashanta Kumar Patra, Amitav Mahapatra", 
    "title": "A Survey on Two Dimensional Cellular Automata and Its Application in   Image Processing", 
    "arxiv-id": "1407.7626v1", 
    "author": "Amitav Mahapatra", 
    "publish": "2014-07-29T04:09:09Z", 
    "summary": "Parallel algorithms for solving any image processing task is a highly\ndemanded approach in the modern world. Cellular Automata (CA) are the most\ncommon and simple models of parallel computation. So, CA has been successfully\nused in the domain of image processing for the last couple of years. This paper\nprovides a survey of available literatures of some methodologies employed by\ndifferent researchers to utilize the cellular automata for solving some\nimportant problems of image processing. The survey includes some important\nimage processing tasks such as rotation, zooming, translation, segmentation,\nedge detection, compression and noise reduction of images. Finally, the\nexperimental results of some methodologies are presented."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.7686v1", 
    "other_authors": "Zohaib Khan", 
    "title": "Hyperspectral Imaging and Analysis for Sparse Reconstruction and   Recognition", 
    "arxiv-id": "1407.7686v1", 
    "author": "Zohaib Khan", 
    "publish": "2014-07-29T10:29:28Z", 
    "summary": "This thesis proposes spatio-spectral techniques for hyperspectral image\nanalysis. Adaptive spatio-spectral support and variable exposure hyperspectral\nimaging is demonstrated to improve spectral reflectance recovery from\nhyperspectral images. Novel spectral dimensionality reduction techniques have\nbeen proposed from the perspective of spectral only and spatio-spectral\ninformation preservation. It was found that the joint sparse and joint group\nsparse hyperspectral image models achieve lower reconstruction error and higher\nrecognition accuracy using only a small subset of bands. Hyperspectral image\ndatabases have been developed and made publicly available for further research\nin compressed hyperspectral imaging, forensic document analysis and spectral\nreflectance recovery."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.8121v1", 
    "other_authors": "Dibya Jyoti Bora, Anil Kumar Gupta", 
    "title": "Clustering Approach Towards Image Segmentation: An Analytical Study", 
    "arxiv-id": "1407.8121v1", 
    "author": "Anil Kumar Gupta", 
    "publish": "2014-07-30T16:45:00Z", 
    "summary": "Image processing is an important research area in computer vision. Image\nsegmentation plays the vital rule in image processing research. There exist so\nmany methods for image segmentation. Clustering is an unsupervised study.\nClustering can also be used for image segmentation. In this paper, an in-depth\nstudy is done on different clustering techniques that can be used for image\nsegmentation with their pros and cons. An experiment for color image\nsegmentation based on clustering with K-Means algorithm is performed to observe\nthe accuracy of clustering technique for the segmentation purpose."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCKE.2013.6682800", 
    "link": "http://arxiv.org/pdf/1407.8123v1", 
    "other_authors": "T. R. Gopalakrishnan Nair, Richa Sharma", 
    "title": "Merging and Shifting of Images with Prominence Coefficient for   Predictive Analysis using Combined Image", 
    "arxiv-id": "1407.8123v1", 
    "author": "Richa Sharma", 
    "publish": "2014-07-30T16:54:54Z", 
    "summary": "Shifting of objects in an image and merging many images after appropriate\nshifting is being used in several engineering and scientific applications which\nrequire complex perception development. A method has been presented here which\ncould be used in precision engineering and biological applications where more\nprecise prediction is required of a combined phenomenon with varying prominence\nof each phenomenon. Accurate merging of intended pixels can be achieved in high\nquality using frequency domain techniques even though initial properties of the\noriginal pixels are lost in this process. This paper introduces a technique to\nshift and merge various images with varying prominence of each image. A\ncoefficient named prominence coefficient has been introduced which is capable\nof making some of the images transparent and highlighting the rest as per\nrequirement of merging process which can be used as a simple but effective\ntechnique for overlapped view of a set of images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/1407.8176v1", 
    "other_authors": "T. R. Gopalakrishnan Nair, Richa Sharma", 
    "title": "Accurate merging of images for predictive analysis using combined image", 
    "arxiv-id": "1407.8176v1", 
    "author": "Richa Sharma", 
    "publish": "2014-07-30T07:08:31Z", 
    "summary": "Several Scientific and engineering applications require merging of sampled\nimages for complex perception development. In most cases, for such\nrequirements, images are merged at intensity level. Even though it gives fairly\ngood perception of combined scenario of objects and scenes, it is found that\nthey are not sufficient enough to analyze certain engineering cases. The main\nproblem is incoherent modulation of intensity arising out of phase properties\nbeing lost. In order to compensate these losses, combined phase and amplitude\nmerge is demanded. We present here a method which could be used in precision\nengineering and biological applications where more precise prediction is\nrequired of a combined phenomenon. When pixels are added, its original property\nis lost but accurate merging of intended pixels can be achieved in high quality\nusing frequency domain properties of an image. This paper introduces a\ntechnique to merge various images which can be used as a simple but effective\ntechnique for overlapped view of a set of images and producing reduced dataset\nfor review purposes."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/1407.8497v1", 
    "other_authors": "Amal Farag, Le Lu, Evrim Turkbey, Jiamin Liu, Ronald M. Summers", 
    "title": "A Bottom-Up Approach for Automatic Pancreas Segmentation in Abdominal CT   Scans", 
    "arxiv-id": "1407.8497v1", 
    "author": "Ronald M. Summers", 
    "publish": "2014-07-31T17:51:03Z", 
    "summary": "Organ segmentation is a prerequisite for a computer-aided diagnosis (CAD)\nsystem to detect pathologies and perform quantitative analysis. For\nanatomically high-variability abdominal organs such as the pancreas, previous\nsegmentation works report low accuracies when comparing to organs like the\nheart or liver. In this paper, a fully-automated bottom-up method is presented\nfor pancreas segmentation, using abdominal computed tomography (CT) scans. The\nmethod is based on a hierarchical two-tiered information propagation by\nclassifying image patches. It labels superpixels as pancreas or not via pooling\npatch-level confidences on 2D CT slices over-segmented by the Simple Linear\nIterative Clustering approach. A supervised random forest (RF) classifier is\ntrained on the patch level and a two-level cascade of RFs is applied at the\nsuperpixel level, coupled with multi-channel feature extraction, respectively.\nOn six-fold cross-validation using 80 patient CT volumes, we achieved 68.8%\nDice coefficient and 57.2% Jaccard Index, comparable to or slightly better than\npublished state-of-the-art methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0803.1586v1", 
    "other_authors": "Jarrad Springett, Jeroen Vendrig", 
    "title": "Spatio-activity based object detection", 
    "arxiv-id": "0803.1586v1", 
    "author": "Jeroen Vendrig", 
    "publish": "2008-03-11T13:40:42Z", 
    "summary": "We present the SAMMI lightweight object detection method which has a high\nlevel of accuracy and robustness, and which is able to operate in an\nenvironment with a large number of cameras. Background modeling is based on DCT\ncoefficients provided by cameras. Foreground detection uses similarity in\ntemporal characteristics of adjacent blocks of pixels, which is a\ncomputationally inexpensive way to make use of object coherence. Scene model\nupdating uses the approximated median method for improved performance.\nEvaluation at pixel level and application level shows that SAMMI object\ndetection performs better and faster than the conventional Mixture of Gaussians\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0803.2812v2", 
    "other_authors": "Mikhail V. Konnik", 
    "title": "Using Spatially Varying Pixels Exposures and Bayer-covered Photosensors   for High Dynamic Range Imaging", 
    "arxiv-id": "0803.2812v2", 
    "author": "Mikhail V. Konnik", 
    "publish": "2008-03-19T14:55:15Z", 
    "summary": "The method of a linear high dynamic range imaging using solid-state\nphotosensors with Bayer colour filters array is provided in this paper. Using\ninformation from neighbour pixels, it is possible to reconstruct linear images\nwith wide dynamic range from the oversaturated images. Bayer colour filters\narray is considered as an array of neutral filters in a quasimonochromatic\nlight. If the camera's response function to the desirable light source is known\nthen one can calculate correction coefficients to reconstruct oversaturated\nimages. Reconstructed images are linearized in order to provide a linear high\ndynamic range images for optical-digital imaging systems. The calibration\nprocedure for obtaining the camera's response function to the desired light\nsource is described. Experimental results of the reconstruction of the images\nfrom the oversaturated images are presented for red, green, and blue\nquasimonochromatic light sources. Quantitative analysis of the accuracy of the\nreconstructed images is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.0689v1", 
    "other_authors": "Hongjun Jia, Li Zhang", 
    "title": "Directional Cross Diamond Search Algorithm for Fast Block Motion   Estimation", 
    "arxiv-id": "0806.0689v1", 
    "author": "Li Zhang", 
    "publish": "2008-06-04T05:05:19Z", 
    "summary": "In block-matching motion estimation (BMME), the search patterns have a\nsignificant impact on the algorithm's performance, both the search speed and\nthe search quality. The search pattern should be designed to fit the motion\nvector probability (MVP) distribution characteristics of the real-world\nsequences. In this paper, we build a directional model of MVP distribution to\ndescribe the directional-center-biased characteristic of the MVP distribution\nand the directional characteristics of the conditional MVP distribution more\nexactly based on the detailed statistical data of motion vectors of eighteen\npopular sequences. Three directional search patterns are firstly designed by\nutilizing the directional characteristics and they are the smallest search\npatterns among the popular ones. A new algorithm is proposed using the\nhorizontal cross search pattern as the initial step and the horizontal/vertical\ndiamond search pattern as the subsequent step for the fast BMME, which is\ncalled the directional cross diamond search (DCDS) algorithm. The DCDS\nalgorithm can obtain the motion vector with fewer search points than CDS, DS or\nHEXBS while maintaining the similar or even better search quality. The gain on\nspeedup of DCDS over CDS or DS can be up to 54.9%. The simulation results show\nthat DCDS is efficient, effective and robust, and it can always give the faster\nsearch speed on different sequences than other fast block-matching algorithm in\ncommon use."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.1446v1", 
    "other_authors": "Guoshen Yu, Jean-Jacques Slotine", 
    "title": "Fast Wavelet-Based Visual Classification", 
    "arxiv-id": "0806.1446v1", 
    "author": "Jean-Jacques Slotine", 
    "publish": "2008-06-08T10:15:04Z", 
    "summary": "We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.1984v1", 
    "other_authors": "S. Feng, I. A. Kogan, H. Krim", 
    "title": "Classification of curves in 2D and 3D via affine integral signatures", 
    "arxiv-id": "0806.1984v1", 
    "author": "H. Krim", 
    "publish": "2008-06-12T01:12:25Z", 
    "summary": "We propose a robust classification algorithm for curves in 2D and 3D, under\nthe special and full groups of affine transformations. To each plane or spatial\ncurve we assign a plane signature curve. Curves, equivalent under an affine\ntransformation, have the same signature. The signatures introduced in this\npaper are based on integral invariants, which behave much better on noisy\nimages than classically known differential invariants. The comparison with\nother types of invariants is given in the introduction. Though the integral\ninvariants for planar curves were known before, the affine integral invariants\nfor spatial curves are proposed here for the first time. Using the inductive\nvariation of the moving frame method we compute affine invariants in terms of\nEuclidean invariants. We present two types of signatures, the global signature\nand the local signature. Both signatures are independent of parameterization\n(curve sampling). The global signature depends on the choice of the initial\npoint and does not allow us to compare fragments of curves, and is therefore\nsensitive to occlusions. The local signature, although is slightly more\nsensitive to noise, is independent of the choice of the initial point and is\nnot sensitive to occlusions in an image. It helps establish local equivalence\nof curves. The robustness of these invariants and signatures in their\napplication to the problem of classification of noisy spatial curves extracted\nfrom a 3D object is analyzed."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.3885v1", 
    "other_authors": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   1: the framework", 
    "arxiv-id": "0806.3885v1", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T13:43:06Z", 
    "summary": "Adams and Bishop have proposed in 1994 a novel region growing algorithm\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\nintroduces a framework to implement an algorithm using SRGPA. This framework is\nbuilt around two concepts: localization and organization of applied action.\nThis conceptualization gives a quick implementation of algorithms, a direct\ntranslation between the mathematical idea and the numerical implementation, and\nan improvement of algorithms efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.3887v1", 
    "other_authors": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   2: how to localize a final partition invariant about the seeded region   initialisation order", 
    "arxiv-id": "0806.3887v1", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T13:34:15Z", 
    "summary": "In the previous paper, we have conceptualized the localization and the\norganization of seeded region growing by pixels aggregation (SRGPA) but we do\nnot give the issue when there is a collision between two distinct regions\nduring the growing process. In this paper, we propose two implementations to\nmanage two classical growing processes: one without a boundary region region to\ndivide the other regions and another with. Unfortunately, as noticed by Mehnert\nand Jakway (1997), this partition depends on the seeded region initialisation\norder (SRIO). We propose a growing process, invariant about SRIO such as the\nboundary region is the set of ambiguous pixels."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.3928v1", 
    "other_authors": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   3: a wide range of algorithms", 
    "arxiv-id": "0806.3928v1", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T17:02:47Z", 
    "summary": "In the two previous papers of this serie, we have created a library, called\nPopulation, dedicated to seeded region growing by pixels aggregation and we\nhave proposed different growing processes to get a partition with or without a\nboundary region to divide the other regions or to get a partition invariant\nabout the seeded region initialisation order. Using this work, we implement\nsome algorithms belonging to the field of SRGPA using this library and these\ngrowing processes."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0806.3939v2", 
    "other_authors": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   4: Simple, generic and robust extraction of grains in granular materials   obtained by X-ray tomography", 
    "arxiv-id": "0806.3939v2", 
    "author": "Vincent Tariel", 
    "publish": "2008-06-24T17:40:25Z", 
    "summary": "This paper proposes a simple, generic and robust method to extract the grains\nfrom experimental tridimensionnal images of granular materials obtained by\nX-ray tomography. This extraction has two steps: segmentation and splitting.\nFor the segmentation step, if there is a sufficient contrast between the\ndifferent components, a classical threshold procedure followed by a succession\nof morphological filters can be applied. If not, and if the boundary needs to\nbe localized precisely, a watershed transformation controlled by labels is\napplied. The basement of this transformation is to localize a label included in\nthe component and another label in the component complementary. A \"soft\"\nthreshold following by an opening is applied on the initial image to localize a\nlabel in a component. For any segmentation procedure, the visualisation shows a\nproblem: some groups of two grains, close one to each other, become connected.\nSo if a classical cluster procedure is applied on the segmented binary image,\nthese numerical connected grains are considered as a single grain. To overcome\nthis problem, we applied a procedure introduced by L. Vincent in 1993. This\ngrains extraction is tested for various complexes porous media and granular\nmaterial, to predict various properties (diffusion, electrical conductivity,\ndeformation field) in a good agreement with experiment data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICSIPR.2013.6497980", 
    "link": "http://arxiv.org/pdf/0807.2047v3", 
    "other_authors": "Mahzad Kalantari, Franck Jung, JeanPierre Guedon, Nicolas Paparoditis", 
    "title": "The Five Points Pose Problem : A New and Accurate Solution Adapted to   any Geometric Configuration", 
    "arxiv-id": "0807.2047v3", 
    "author": "Nicolas Paparoditis", 
    "publish": "2008-07-13T18:37:06Z", 
    "summary": "The goal of this paper is to estimate directly the rotation and translation\nbetween two stereoscopic images with the help of five homologous points. The\nmethodology presented does not mix the rotation and translation parameters,\nwhich is comparably an important advantage over the methods using the\nwell-known essential matrix. This results in correct behavior and accuracy for\nsituations otherwise known as quite unfavorable, such as planar scenes, or\npanoramic sets of images (with a null base length), while providing quite\ncomparable results for more \"standard\" cases. The resolution of the algebraic\npolynomials resulting from the modeling of the coplanarity constraint is made\nwith the help of powerful algebraic solver tools (the Groebner bases and the\nRational Univariate Representation)."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0807.4701v1", 
    "other_authors": "A. Sparavigna, R. Marazzato", 
    "title": "An image processing analysis of skin textures", 
    "arxiv-id": "0807.4701v1", 
    "author": "R. Marazzato", 
    "publish": "2008-07-29T16:28:44Z", 
    "summary": "Colour and coarseness of skin are visually different. When image processing\nis involved in the skin analysis, it is important to quantitatively evaluate\nsuch differences using texture features. In this paper, we discuss a texture\nanalysis and measurements based on a statistical approach to the pattern\nrecognition. Grain size and anisotropy are evaluated with proper diagrams. The\npossibility to determine the presence of pattern defects is also discussed."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0903.0134v2", 
    "other_authors": "Ahmad Reza Eskandari, Ali Pourmohammad", 
    "title": "Recognition of Regular Shapes in Satelite Images", 
    "arxiv-id": "0903.0134v2", 
    "author": "Ali Pourmohammad", 
    "publish": "2009-03-01T11:10:27Z", 
    "summary": "This paper has been withdrawn by the author ali pourmohammad."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0903.0538v1", 
    "other_authors": "Dan Laurentiu Lacrama, Florin Alexa, Adriana Balta", 
    "title": "Real-time Texture Error Detection", 
    "arxiv-id": "0903.0538v1", 
    "author": "Adriana Balta", 
    "publish": "2009-03-03T14:08:24Z", 
    "summary": "This paper advocates an improved solution for real-time error detection of\ntexture errors that occurs in the production process in textile industry. The\nresearch is focused on the mono-color products with 3D texture model (Jaquard\nfabrics). This is a more difficult task than, for example, 2D multicolor\ntextures."
},{
    "category": "cs.CV", 
    "doi": "10.1111/j.1600-0846.2009.00413.x", 
    "link": "http://arxiv.org/pdf/0903.5045v1", 
    "other_authors": "Amelia Sparavigna", 
    "title": "Digital Restoration of Ancient Papyri", 
    "arxiv-id": "0903.5045v1", 
    "author": "Amelia Sparavigna", 
    "publish": "2009-03-30T06:00:15Z", 
    "summary": "Image processing can be used for digital restoration of ancient papyri, that\nis, for a restoration performed on their digital images. The digital\nmanipulation allows reducing the background signals and enhancing the\nreadability of texts. In the case of very old and damaged documents, this is\nfundamental for identification of the patterns of letters. Some examples of\nrestoration, obtained with an image processing which uses edges detection and\nFourier filtering, are shown. One of them concerns 7Q5 fragment of the Dead Sea\nScrolls."
},{
    "category": "cs.CV", 
    "doi": "10.3390/e11030513", 
    "link": "http://arxiv.org/pdf/0909.0481v1", 
    "other_authors": "Fionn Murtagh, Pedro Contreras, Jean-Luc Starck", 
    "title": "Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models   in Image Segmentation", 
    "arxiv-id": "0909.0481v1", 
    "author": "Jean-Luc Starck", 
    "publish": "2009-09-02T17:46:08Z", 
    "summary": "By a \"covering\" we mean a Gaussian mixture model fit to observed data.\nApproximations of the Bayes factor can be availed of to judge model fit to the\ndata within a given Gaussian mixture model. Between families of Gaussian\nmixture models, we propose the R\\'enyi quadratic entropy as an excellent and\ntractable model comparison framework. We exemplify this using the segmentation\nof an MRI image volume, based (1) on a direct Gaussian mixture model applied to\nthe marginal distribution function, and (2) Gaussian model fit through k-means\napplied to the 4D multivalued image volume furnished by the wavelet transform.\nVisual preference for one model over another is not immediate. The R\\'enyi\nquadratic entropy allows us to show clearly that one of these modelings is\nsuperior to the other."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457627", 
    "link": "http://arxiv.org/pdf/0909.1605v1", 
    "other_authors": "G. Chen, S. Atev, G. Lerman", 
    "title": "Kernel Spectral Curvature Clustering (KSCC)", 
    "arxiv-id": "0909.1605v1", 
    "author": "G. Lerman", 
    "publish": "2009-09-09T01:58:23Z", 
    "summary": "Multi-manifold modeling is increasingly used in segmentation and data\nrepresentation tasks in computer vision and related fields. While the general\nproblem, modeling data by mixtures of manifolds, is very challenging, several\napproaches exist for modeling data by mixtures of affine subspaces (which is\noften referred to as hybrid linear modeling). We translate some important\ninstances of multi-manifold modeling to hybrid linear modeling in embedded\nspaces, without explicitly performing the embedding but applying the kernel\ntrick. The resulting algorithm, Kernel Spectral Curvature Clustering, uses\nkernels at two levels - both as an implicit embedding method to linearize\nnonflat manifolds and as a principled method to convert a multiway affinity\nproblem into a spectral clustering one. We demonstrate the effectiveness of the\nmethod by comparing it with other state-of-the-art methods on both synthetic\ndata and a real-world problem of segmenting multiple motions from two\nperspective camera views."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.1608v1", 
    "other_authors": "G. Chen, G. Lerman", 
    "title": "Motion Segmentation by SCC on the Hopkins 155 Database", 
    "arxiv-id": "0909.1608v1", 
    "author": "G. Lerman", 
    "publish": "2009-09-09T02:12:22Z", 
    "summary": "We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark\ndatabase of 155 motion sequences, and show that it outperforms all other\nstate-of-the-art methods. The average misclassification rate by SCC is 1.41%\nfor sequences having two motions and 4.85% for three motions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.3911v1", 
    "other_authors": "Yon Ping Chen, Tien Der Yeh", 
    "title": "A Method for Extraction and Recognition of Isolated License Plate   Characters", 
    "arxiv-id": "0909.3911v1", 
    "author": "Tien Der Yeh", 
    "publish": "2009-09-22T05:38:32Z", 
    "summary": "A method to extract and recognize isolated characters in license plates is\nproposed. In extraction stage, the proposed method detects isolated characters\nby using Difference-of-Gaussian (DOG) function, The DOG function, similar to\nLaplacian of Gaussian function, was proven to produce the most stable image\nfeatures compared to a range of other possible image functions. The candidate\ncharacters are extracted by doing connected component analysis on different\nscale DOG images. In recognition stage, a novel feature vector named\naccumulated gradient projection vector (AGPV) is used to compare the candidate\ncharacter with the standard ones. The AGPV is calculated by first projecting\npixels of similar gradient orientations onto specific axes, and then\naccumulates the projected gradient magnitudes by each axis. In the experiments,\nthe AGPVs are proven to be invariant from image scaling and rotation, and\nrobust to noise and illumination change."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.5458v1", 
    "other_authors": "Robert Sheng Xu, Oleg Michailovich, Magdy Salama", 
    "title": "Information tracking approach to segmentation of ultrasound imagery of   prostate", 
    "arxiv-id": "0909.5458v1", 
    "author": "Magdy Salama", 
    "publish": "2009-09-29T22:39:19Z", 
    "summary": "The size and geometry of the prostate are known to be pivotal quantities used\nby clinicians to assess the condition of the gland during prostate cancer\nscreening. As an alternative to palpation, an increasing number of methods for\nestimation of the above-mentioned quantities are based on using imagery data of\nprostate. The necessity to process large volumes of such data creates a need\nfor automatic segmentation tools which would allow the estimation to be carried\nout with maximum accuracy and efficiency. In particular, the use of transrectal\nultrasound (TRUS) imaging in prostate cancer screening seems to be becoming a\nstandard clinical practice due to the high benefit-to-cost ratio of this\nimaging modality. Unfortunately, the segmentation of TRUS images is still\nhampered by relatively low contrast and reduced SNR of the images, thereby\nrequiring the segmentation algorithms to incorporate prior knowledge about the\ngeometry of the gland. In this paper, a novel approach to the problem of\nsegmenting the TRUS images is described. The proposed approach is based on the\nconcept of distribution tracking, which provides a unified framework for\nmodeling and fusing image-related and morphological features of the prostate.\nMoreover, the same framework allows the segmentation to be regularized via\nusing a new type of \"weak\" shape priors, which minimally bias the estimation\nprocedure, while rendering the latter stable and robust."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICCVW.2009.5457626", 
    "link": "http://arxiv.org/pdf/0909.5460v2", 
    "other_authors": "E. Shaked, O. Michailovich", 
    "title": "Iterative Shrinkage Approach to Restoration of Optical Imagery", 
    "arxiv-id": "0909.5460v2", 
    "author": "O. Michailovich", 
    "publish": "2009-09-29T22:33:10Z", 
    "summary": "The problem of reconstruction of digital images from their degraded\nmeasurements is regarded as a problem of central importance in various fields\nof engineering and imaging sciences. In such cases, the degradation is\ntypically caused by the resolution limitations of an imaging device in use\nand/or by the destructive influence of measurement noise. Specifically, when\nthe noise obeys a Poisson probability law, standard approaches to the problem\nof image reconstruction are based on using fixed-point algorithms which follow\nthe methodology first proposed by Richardson and Lucy. The practice of using\nthese methods, however, shows that their convergence properties tend to\ndeteriorate at relatively high noise levels. Accordingly, in the present paper,\na novel method for de-noising and/or de-blurring of digital images corrupted by\nPoisson noise is introduced. The proposed method is derived under the\nassumption that the image of interest can be sparsely represented in the domain\nof a linear transform. Consequently, a shrinkage-based iterative procedure is\nproposed, which guarantees the solution to converge to the global maximizer of\nan associated maximum-a-posteriori criterion. It is shown in a series of both\ncomputer-simulated and real-life experiments that the proposed method\noutperforms a number of existing alternatives in terms of stability, precision,\nand computational efficiency."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2010.5539866", 
    "link": "http://arxiv.org/pdf/1005.0858v1", 
    "other_authors": "Teng Zhang, Arthur Szlam, Yi Wang, Gilad Lerman", 
    "title": "Randomized hybrid linear modeling by local best-fit flats", 
    "arxiv-id": "1005.0858v1", 
    "author": "Gilad Lerman", 
    "publish": "2010-05-05T21:46:13Z", 
    "summary": "The hybrid linear modeling problem is to identify a set of d-dimensional\naffine sets in a D-dimensional Euclidean space. It arises, for example, in\nobject tracking and structure from motion. The hybrid linear model can be\nconsidered as the second simplest (behind linear) manifold model of data. In\nthis paper we will present a very simple geometric method for hybrid linear\nmodeling based on selecting a set of local best fit flats that minimize a\nglobal l1 error measure. The size of the local neighborhoods is determined\nautomatically by the Jones' l2 beta numbers; it is proven under certain\ngeometric conditions that good local neighborhoods exist and are found by our\nmethod. We also demonstrate how to use this algorithm for fast determination of\nthe number of affine subspaces. We give extensive experimental evidence\ndemonstrating the state of the art accuracy and speed of the algorithm on\nsynthetic and real hybrid linear data."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CVPR.2010.5539866", 
    "link": "http://arxiv.org/pdf/1005.0907v1", 
    "other_authors": "Yasser M. Alginaih, Abdul Ahad Siddiqi", 
    "title": "Multistage Hybrid Arabic/Indian Numeral OCR System", 
    "arxiv-id": "1005.0907v1", 
    "author": "Abdul Ahad Siddiqi", 
    "publish": "2010-05-06T07:25:23Z", 
    "summary": "The use of OCR in postal services is not yet universal and there are still\nmany countries that process mail sorting manually. Automated Arabic/Indian\nnumeral Optical Character Recognition (OCR) systems for Postal services are\nbeing used in some countries, but still there are errors during the mail\nsorting process, thus causing a reduction in efficiency. The need to\ninvestigate fast and efficient recognition algorithms/systems is important so\nas to correctly read the postal codes from mail addresses and to eliminate any\nerrors during the mail sorting stage. The objective of this study is to\nrecognize printed numerical postal codes from mail addresses. The proposed\nsystem is a multistage hybrid system which consists of three different feature\nextraction methods, i.e., binary, zoning, and fuzzy features, and three\ndifferent classifiers, i.e., Hamming Nets, Euclidean Distance, and Fuzzy Neural\nNetwork Classifiers. The proposed system, systematically compares the\nperformance of each of these methods, and ensures that the numerals are\nrecognized correctly. Comprehensive results provide a very high recognition\nrate, outperforming the other known developed methods in literature."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.0945v1", 
    "other_authors": "Mohit Soni, Sandesh Gupta, M. S. Rao, Phalguni Gupta", 
    "title": "An Efficient Vein Pattern-based Recognition System", 
    "arxiv-id": "1005.0945v1", 
    "author": "Phalguni Gupta", 
    "publish": "2010-05-06T09:34:21Z", 
    "summary": "This paper presents an efficient human recognition system based on vein\npattern from the palma dorsa. A new absorption based technique has been\nproposed to collect good quality images with the help of a low cost camera and\nlight source. The system automatically detects the region of interest from the\nimage and does the necessary preprocessing to extract features. A Euclidean\nDistance based matching technique has been used for making the decision. It has\nbeen tested on a data set of 1750 image samples collected from 341 individuals.\nThe accuracy of the verification system is found to be 99.26% with false\nrejection rate (FRR) of 0.03%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.1471v1", 
    "other_authors": "Karin Schnass, Pierre Vandergheynst", 
    "title": "Classification via Incoherent Subspaces", 
    "arxiv-id": "1005.1471v1", 
    "author": "Pierre Vandergheynst", 
    "publish": "2010-05-10T08:49:56Z", 
    "summary": "This article presents a new classification framework that can extract\nindividual features per class. The scheme is based on a model of incoherent\nsubspaces, each one associated to one class, and a model on how the elements in\na class are represented in this subspace. After the theoretical analysis an\nalternate projection algorithm to find such a collection is developed. The\nclassification performance and speed of the proposed method is tested on the AR\nand YaleB databases and compared to that of Fisher's LDA and a recent approach\nbased on on $\\ell_1$ minimisation. Finally connections of the presented scheme\nto already existing work are discussed and possible ways of extensions are\npointed out."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.2715v1", 
    "other_authors": "Georgios Tzimiropoulos, Stefanos Zafeiriou", 
    "title": "On the Subspace of Image Gradient Orientations", 
    "arxiv-id": "1005.2715v1", 
    "author": "Stefanos Zafeiriou", 
    "publish": "2010-05-16T00:31:19Z", 
    "summary": "We introduce the notion of Principal Component Analysis (PCA) of image\ngradient orientations. As image data is typically noisy, but noise is\nsubstantially different from Gaussian, traditional PCA of pixel intensities\nvery often fails to estimate reliably the low-dimensional subspace of a given\ndata population. We show that replacing intensities with gradient orientations\nand the $\\ell_2$ norm with a cosine-based distance measure offers, to some\nextend, a remedy to this problem. Our scheme requires the eigen-decomposition\nof a covariance matrix and is as computationally efficient as standard $\\ell_2$\nPCA. We demonstrate some of its favorable properties on robust subspace\nestimation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4020v1", 
    "other_authors": "Salem Saleh Al-amri, N. V. Kalyankar, Khamitkar S. D.", 
    "title": "Image Segmentation by Using Threshold Techniques", 
    "arxiv-id": "1005.4020v1", 
    "author": "Khamitkar S. D.", 
    "publish": "2010-05-21T17:30:08Z", 
    "summary": "This paper attempts to undertake the study of segmentation image techniques\nby using five threshold methods as Mean method, P-tile method, Histogram\nDependent Technique (HDT), Edge Maximization Technique (EMT) and visual\nTechnique and they are compared with one another so as to choose the best\ntechnique for threshold segmentation techniques image. These techniques applied\non three satellite images to choose base guesses for threshold segmentation\nimage."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4034v1", 
    "other_authors": "Santanu Halder, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Face Synthesis (FASY) System for Generation of a Face Image from Human   Description", 
    "arxiv-id": "1005.4034v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-05-21T18:03:44Z", 
    "summary": "This paper aims at generating a new face based on the human like description\nusing a new concept. The FASY (FAce SYnthesis) System is a Face Database\nRetrieval and new Face generation System that is under development. One of its\nmain features is the generation of the requested face when it is not found in\nthe existing database, which allows a continuous growing of the database also."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4035v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Mita Nasipuri, Dipak Kumar Basu, Mahantapas Kundu", 
    "title": "Classification of Polar-Thermal Eigenfaces using Multilayer Perceptron   for Human Face Recognition", 
    "arxiv-id": "1005.4035v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2010-05-21T18:07:42Z", 
    "summary": "This paper presents a novel approach to handle the challenges of face\nrecognition. In this work thermal face images are considered, which minimizes\nthe affect of illumination changes and occlusion due to moustache, beards,\nadornments etc. The proposed approach registers the training and testing\nthermal face images in polar coordinate, which is capable to handle\ncomplicacies introduced by scaling and rotation. Polar images are projected\ninto eigenspace and finally classified using a multi-layer perceptron. In the\nexperiments we have used Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database benchmark thermal face images. Experimental results\nshow that the proposed approach significantly improves the verification and\nidentification performance and the success rate is 97.05%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4044v1", 
    "other_authors": "Debotosh Bhattacharjee, Dipak Kumar Basu, Mita Nasipuri, M. Kundu", 
    "title": "Reduction of Feature Vectors Using Rough Set Theory for Human Face   Recognition", 
    "arxiv-id": "1005.4044v1", 
    "author": "M. Kundu", 
    "publish": "2010-05-21T19:13:39Z", 
    "summary": "In this paper we describe a procedure to reduce the size of the input feature\nvector. A complex pattern recognition problem like face recognition involves\nhuge dimension of input feature vector. To reduce that dimension here we have\nused eigenspace projection (also called as Principal Component Analysis), which\nis basically transformation of space. To reduce further we have applied feature\nselection method to select indispensable features, which will remain in the\nfinal feature vectors. Features those are not selected are removed from the\nfinal feature vector considering them as redundant or superfluous. For\nselection of features we have used the concept of reduct and core from rough\nset theory. This method has shown very good performance. It is worth to mention\nthat in some cases the recognition rate increases with the decrease in the\nfeature vector dimension."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SECURWARE.2010.45", 
    "link": "http://arxiv.org/pdf/1005.4103v1", 
    "other_authors": "Chunhua Shen, Peng Wang, Hanxi Li", 
    "title": "LACBoost and FisherBoost: Optimally Building Cascade Classifiers", 
    "arxiv-id": "1005.4103v1", 
    "author": "Hanxi Li", 
    "publish": "2010-05-22T04:22:57Z", 
    "summary": "Object detection is one of the key tasks in computer vision. The cascade\nframework of Viola and Jones has become the de facto standard. A classifier in\neach node of the cascade is required to achieve extremely high detection rates,\ninstead of low overall classification error. Although there are a few reported\nmethods addressing this requirement in the context of object detection, there\nis no a principled feature selection method that explicitly takes into account\nthis asymmetric node learning objective. We provide such a boosting algorithm\nin this work. It is inspired by the linear asymmetric classifier (LAC) of Wu et\nal. in that our boosting algorithm optimizes a similar cost function. The new\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on face detection\nsuggest that our proposed boosting algorithms can improve the state-of-the-art\nmethods in detection performance."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.4118v1", 
    "other_authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Jian Zhang", 
    "title": "Incremental Training of a Detector Using Online Sparse   Eigen-decomposition", 
    "arxiv-id": "1005.4118v1", 
    "author": "Jian Zhang", 
    "publish": "2010-05-22T11:05:58Z", 
    "summary": "The ability to efficiently and accurately detect objects plays a very crucial\nrole for many computer vision tasks. Recently, offline object detectors have\nshown a tremendous success. However, one major drawback of offline techniques\nis that a complete set of training data has to be collected beforehand. In\naddition, once learned, an offline detector can not make use of newly arriving\ndata. To alleviate these drawbacks, online learning has been adopted with the\nfollowing objectives: (1) the technique should be computationally and storage\nefficient; (2) the updated classifier must maintain its high classification\naccuracy. In this paper, we propose an effective and efficient framework for\nlearning an adaptive online greedy sparse linear discriminant analysis (GSLDA)\nmodel. Unlike many existing online boosting detectors, which usually apply\nexponential or logistic loss, our online algorithm makes use of LDA's learning\ncriterion that not only aims to maximize the class-separation criterion but\nalso incorporates the asymmetrical property of training data distributions. We\nprovide a better alternative for online boosting algorithms in the context of\ntraining a visual object detector. We demonstrate the robustness and efficiency\nof our methods on handwriting digit and face data sets. Our results confirm\nthat object detection tasks benefit significantly when trained in an online\nmanner."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.4216v1", 
    "other_authors": "Y. Babykalpana, K. ThanushKodi", 
    "title": "Classification of LULC Change Detection using Remotely Sensed Data for   Coimbatore City, Tamilnadu, India", 
    "arxiv-id": "1005.4216v1", 
    "author": "K. ThanushKodi", 
    "publish": "2010-05-23T18:16:49Z", 
    "summary": "Maps are used to describe far-off places . It is an aid for navigation and\nmilitary strategies. Mapping of the lands are important and the mapping work is\nbased on (i). Natural resource management & development (ii). Information\ntechnology ,(iii). Environmental development ,(iv). Facility management and\n(v). e-governance. The Landuse / Landcover system espoused by almost all\nOrganisations and scientists, engineers and remote sensing community who are\ninvolved in mapping of earth surface features, is a system which is derived\nfrom the united States Geological Survey (USGS) LULC classification system. The\napplication of RS and GIS involves influential of homogeneous zones, drift\nanalysis of land use integration of new area changes or change detection\netc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a\ngeneralized LULC classification system respect to the Indian conditions based\non the various categories of Earth surface features , resolution of available\nsatellite data, capabilities of sensors and present and future applications.\nThe profusion information of the earth surface offered by the high resolution\nsatellite images for remote sensing applications. Using change detection\nmethodologies to extract the target changes in the areas from high resolution\nimages and rapidly updates geodatabase information processing.Traditionally,\nclassification approaches have focused on per-pixel technologies. Pixels within\nareas assumed to be automatically homogeneous are analyzed independently."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.4292v1", 
    "other_authors": "Mrigank Rajya, Sonal Rewri, Swati Sheoran", 
    "title": "Application Of Fuzzy System In Segmentation Of MRI Brain Tumor", 
    "arxiv-id": "1005.4292v1", 
    "author": "Swati Sheoran", 
    "publish": "2010-05-24T09:59:08Z", 
    "summary": "Segmentation of images holds an important position in the area of image\nprocessing. It becomes more important whi le typically dealing with medical\nimages where presurgery and post surgery decisions are required for the purpose\nof initiating and speeding up the recovery process. Segmentation of 3-D tumor\nstructures from magnetic resonance images (MRI) is a very challenging problem\ndue to the variability of tumor geometry and intensity patterns. Level set\nevolution combining global smoothness with the flexibility of topology changes\noffers significant advantages over the conventional statistical classification\nfollowed by mathematical morphology. Level set evolution with constant\npropagation needs to be initialized either completely inside or outside the\ntumor and can leak through weak or missing boundary parts. Replacing the\nconstant propagation term by a statistical force overcomes these limitations\nand results in a convergence to a stable solution. Using MR images presenting\ntumors, probabilities for background and tumor regions are calculated from a\npre- and post-contrast difference image and mixture modeling fit of the\nhistogram. The whole image is used for initialization of the level set\nevolution to segment the tumor boundaries."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2010.2053548", 
    "link": "http://arxiv.org/pdf/1005.5181v1", 
    "other_authors": "Daniel Burfoot", 
    "title": "Compression Rate Method for Empirical Science and Application to   Computer Vision", 
    "arxiv-id": "1005.5181v1", 
    "author": "Daniel Burfoot", 
    "publish": "2010-05-27T21:27:43Z", 
    "summary": "This philosophical paper proposes a modified version of the scientific\nmethod, in which large databases are used instead of experimental observations\nas the necessary empirical ingredient. This change in the source of the\nempirical data allows the scientific method to be applied to several aspects of\nphysical reality that previously resisted systematic interrogation. Under the\nnew method, scientific theories are compared by instantiating them as\ncompression programs, and examining the codelengths they achieve on a database\nof measurements related to a phenomenon of interest. Because of the\nimpossibility of compressing random data, \"real world\" data can only be\ncompressed by discovering and exploiting the empirical structure it exhibits.\nThe method also provides a new way of thinking about two longstanding issues in\nthe philosophy of science: the problem of induction and the problem of\ndemarcation.\n  The second part of the paper proposes to reformulate computer vision as an\nempirical science of visual reality, by applying the new method to large\ndatabases of natural images. The immediate goal of the proposed reformulation\nis to repair the chronic difficulties in evaluation experienced by the field of\ncomputer vision. The reformulation should bring a wide range of benefits,\nincluding a substantially increased degree of methodological rigor, the ability\nto justify complex theories without overfitting, a scalable evaluation\nparadigm, and the potential to make systematic progress. A crucial argument is\nthat the change is not especially drastic, because most computer vision tasks\ncan be reformulated as specialized image compression techniques. Finally, a\nconcrete proposal is discussed in which a database is produced by recording\nfrom a roadside video camera, and compression is achieved by developing a\ncomputational understanding of the appearance of moving cars."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2010.2206", 
    "link": "http://arxiv.org/pdf/1005.5437v1", 
    "other_authors": "Ch. Srinivasa Rao, S. Srinivas Kumar, B. Chandra Mohan", 
    "title": "Content Based Image Retrieval Using Exact Legendre Moments and Support   Vector Machine", 
    "arxiv-id": "1005.5437v1", 
    "author": "B. Chandra Mohan", 
    "publish": "2010-05-29T08:12:16Z", 
    "summary": "Content Based Image Retrieval (CBIR) systems based on shape using invariant\nimage moments, viz., Moment Invariants (MI) and Zernike Moments (ZM) are\navailable in the literature. MI and ZM are good at representing the shape\nfeatures of an image. However, non-orthogonality of MI and poor reconstruction\nof ZM restrict their application in CBIR. Therefore, an efficient and\northogonal moment based CBIR system is needed. Legendre Moments (LM) are\northogonal, computationally faster, and can represent image shape features\ncompactly. CBIR system using Exact Legendre Moments (ELM) for gray scale images\nis proposed in this work. Superiority of the proposed CBIR system is observed\nover other moment based methods, viz., MI and ZM in terms of retrieval\nefficiency and retrieval time. Further, the classification efficiency is\nimproved by employing Support Vector Machine (SVM) classifier. Improved\nretrieval results are obtained over existing CBIR algorithm based on Stacked\nEuler Vector (SERVE) combined with Modified Moment Invariants (MMI)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2010.2201", 
    "link": "http://arxiv.org/pdf/1005.5439v1", 
    "other_authors": "Amer A. Al-Rahayfeh, Abdelshakour A. Abuzneid", 
    "title": "Detection of Bleeding in Wireless Capsule Endoscopy Images Using Range   Ratio Color", 
    "arxiv-id": "1005.5439v1", 
    "author": "Abdelshakour A. Abuzneid", 
    "publish": "2010-05-29T08:25:50Z", 
    "summary": "Wireless Capsule Endoscopy (WCE) is device to detect abnormalities in\ncolon,esophagus,small intestinal and stomach, to distinguish bleeding in WCE\nimages from non bleeding is a hard job by human reviewing and very time\nconsuming. Consequently, automation for classifying bleeding frames not only\nwill expedite the process but will reduce the burden on the doctors. Using the\npurity of the red color we can detect the Bleeding areas in WCE images. But, we\ncould find various intensity of red color values in different parts of the\nsmall intestinal,so it is not enough to depend on the red color feature alone.\nWe select RGB(Red,Green,Blue) because it takes raw level values and it is easy\nto use. In this paper we will put range ratio color for each of R,G,and B.\nTherefore, we divide each image into multiple pixels and apply the range ratio\ncolor condition for each pixel. Then we count the number of the pixels that\nachieved our condition. If the number of pixels grater than zero, then the\nframe is classified as a bleeding type. Otherwise, it is a non-bleeding. Our\nexperimental results show that this method could achieve a very high accuracy\nin detecting bleeding images for the different parts of the small intestinal"
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1008.1695v1", 
    "other_authors": "S. V. Sheela, K. R. Radhika", 
    "title": "Biometric Authentication using Nonparametric Methods", 
    "arxiv-id": "1008.1695v1", 
    "author": "K. R. Radhika", 
    "publish": "2010-08-10T11:38:29Z", 
    "summary": "The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy k-means classifiers. The best performance was obtained for\nMMU database consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1008.3346v1", 
    "other_authors": "Md. Saiful Islam, Md. Haider Ali", 
    "title": "A Miniature-Based Image Retrieval System", 
    "arxiv-id": "1008.3346v1", 
    "author": "Md. Haider Ali", 
    "publish": "2010-08-19T16:38:35Z", 
    "summary": "Due to the rapid development of World Wide Web (WWW) and imaging technology,\nmore and more images are available in the Internet and stored in databases.\nSearching the related images by the querying image is becoming tedious and\ndifficult. Most of the images on the web are compressed by methods based on\ndiscrete cosine transform (DCT) including Joint Photographic Experts\nGroup(JPEG) and H.261. This paper presents an efficient content-based image\nindexing technique for searching similar images using discrete cosine transform\nfeatures. Experimental results demonstrate its superiority with the existing\ntechniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2010.2309", 
    "link": "http://arxiv.org/pdf/1008.3742v1", 
    "other_authors": "Chunhua Shen, Peng Wang, Anton van den Hengel", 
    "title": "Optimally Training a Cascade Classifier", 
    "arxiv-id": "1008.3742v1", 
    "author": "Anton van den Hengel", 
    "publish": "2010-08-23T03:06:34Z", 
    "summary": "Cascade classifiers are widely used in real-time object detection. Different\nfrom conventional classifiers that are designed for a low overall\nclassification error rate, a classifier in each node of the cascade is required\nto achieve an extremely high detection rate and moderate false positive rate.\nAlthough there are a few reported methods addressing this requirement in the\ncontext of object detection, there is no a principled feature selection method\nthat explicitly takes into account this asymmetric node learning objective. We\nprovide such an algorithm here. We show a special case of the biased minimax\nprobability machine has the same formulation as the linear asymmetric\nclassifier (LAC) of \\cite{wu2005linear}. We then design a new boosting\nalgorithm that directly optimizes the cost function of LAC. The resulting\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on object detection\nverify the effectiveness of the proposed boosting algorithm as a node\nclassifier in cascade object detection, and show performance better than that\nof the current state-of-the-art."
},{
    "category": "cs.CV", 
    "doi": "10.2147/PLMI.S11116", 
    "link": "http://arxiv.org/pdf/1008.3798v1", 
    "other_authors": "Thomas W Kelsey, Benedicta Caserta, Luis Castillo, W Hamish B Wallace, Francisco C\u00f3ppola Gonz\u00e1lvez", 
    "title": "Proliferating cell nuclear antigen (PCNA) allows the automatic   identification of follicles in microscopic images of human ovarian tissue", 
    "arxiv-id": "1008.3798v1", 
    "author": "Francisco C\u00f3ppola Gonz\u00e1lvez", 
    "publish": "2010-08-23T11:37:43Z", 
    "summary": "Human ovarian reserve is defined by the population of nongrowing follicles\n(NGFs) in the ovary. Direct estimation of ovarian reserve involves the\nidentification of NGFs in prepared ovarian tissue. Previous studies involving\nhuman tissue have used hematoxylin and eosin (HE) stain, with NGF populations\nestimated by human examination either of tissue under a microscope, or of\nimages taken of this tissue. In this study we replaced HE with proliferating\ncell nuclear antigen (PCNA), and automated the identification and enumeration\nof NGFs that appear in the resulting microscopic images. We compared the\nautomated estimates to those obtained by human experts, with the \"gold\nstandard\" taken to be the average of the conservative and liberal estimates by\nthree human experts. The automated estimates were within 10% of the \"gold\nstandard\", for images at both 100x and 200x magnifications. Automated analysis\ntook longer than human analysis for several hundred images, not allowing for\nbreaks from analysis needed by humans. Our results both replicate and improve\non those of previous studies involving rodent ovaries, and demonstrate the\nviability of large-scale studies of human ovarian reserve using a combination\nof immunohistochemistry and computational image analysis techniques."
},{
    "category": "cs.CV", 
    "doi": "10.3923/itj.2010.811.817", 
    "link": "http://arxiv.org/pdf/1008.4206v1", 
    "other_authors": "Mirza Rehenuma Tabassum, Alim Ul Gias, Md. Mostafa Kamal, Hossain Muhammad Muctadir, Muhammad Ibrahim, Asif Khan Shakir, Asif Imran, Saiful Islamm, Md. Golam Rabbani, Shah Mostafa Khaled, Md. Saiful Islam, Zerina Begum", 
    "title": "Comparative Study of Statistical Skin Detection Algorithms for   Sub-Continental Human Images", 
    "arxiv-id": "1008.4206v1", 
    "author": "Zerina Begum", 
    "publish": "2010-08-25T05:33:04Z", 
    "summary": "Object detection has been a focus of research in human-computer interaction.\nSkin area detection has been a key to different recognitions like face\nrecognition, human motion detection, pornographic and nude image prediction,\netc. Most of the research done in the fields of skin detection has been trained\nand tested on human images of African, Mongolian and Anglo-Saxon ethnic\norigins. Although there are several intensity invariant approaches to skin\ndetection, the skin color of Indian sub-continentals have not been focused\nseparately. The approach of this research is to make a comparative study\nbetween three image segmentation approaches using Indian sub-continental human\nimages, to optimize the detection criteria, and to find some efficient\nparameters to detect the skin area from these images. The experiments observed\nthat HSV color model based approach to Indian sub-continental skin detection is\nmore suitable with considerable success rate of 91.1% true positives and 88.1%\ntrue negatives."
},{
    "category": "cs.CV", 
    "doi": "10.3923/itj.2010.811.817", 
    "link": "http://arxiv.org/pdf/1012.2138v2", 
    "other_authors": "Vasileios Zografos, Klas Nordberg, Liam Ellis", 
    "title": "Sparse motion segmentation using multiple six-point consistencies", 
    "arxiv-id": "1012.2138v2", 
    "author": "Liam Ellis", 
    "publish": "2010-12-09T22:56:02Z", 
    "summary": "We present a method for segmenting an arbitrary number of moving objects in\nimage sequences using the geometry of 6 points in 2D to infer motion\nconsistency. The method has been evaluated on the Hopkins 155 database and\nsurpasses current state-of-the-art methods such as SSC, both in terms of\noverall performance on two and three motions but also in terms of maximum\nerrors. The method works by finding initial clusters in the spatial domain, and\nthen classifying each remaining point as belonging to the cluster that\nminimizes a motion consistency score. In contrast to most other motion\nsegmentation methods that are based on an affine camera model, the proposed\nmethod is fully projective."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.2491v1", 
    "other_authors": "Vasileios Zografos, Bernard Buxton", 
    "title": "Affine Invariant, Model-Based Object Recognition Using Robust Metrics   and Bayesian Statistics", 
    "arxiv-id": "1012.2491v1", 
    "author": "Bernard Buxton", 
    "publish": "2010-12-11T21:48:51Z", 
    "summary": "We revisit the problem of model-based object recognition for intensity images\nand attempt to address some of the shortcomings of existing Bayesian methods,\nsuch as unsuitable priors and the treatment of residuals with a non-robust\nerror norm. We do so by using a refor- mulation of the Huber metric and\ncarefully chosen prior distributions. Our proposed method is invariant to\n2-dimensional affine transforma- tions and, because it is relatively easy to\ntrain and use, it is suited for general object matching problems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.2603v1", 
    "other_authors": "Hanxi Li, Chunhua Shen, Qinfeng Shi", 
    "title": "Real-time Visual Tracking Using Sparse Representation", 
    "arxiv-id": "1012.2603v1", 
    "author": "Qinfeng Shi", 
    "publish": "2010-12-12T23:41:56Z", 
    "summary": "The $\\ell_1$ tracker obtains robustness by seeking a sparse representation of\nthe tracking object via $\\ell_1$ norm minimization \\cite{Xue_ICCV_09_Track}.\nHowever, the high computational complexity involved in the $ \\ell_1 $ tracker\nrestricts its further applications in real time processing scenario. Hence we\npropose a Real Time Compressed Sensing Tracking (RTCST) by exploiting the\nsignal recovery power of Compressed Sensing (CS). Dimensionality reduction and\na customized Orthogonal Matching Pursuit (OMP) algorithm are adopted to\naccelerate the CS tracking. As a result, our algorithm achieves a real-time\nspeed that is up to $6,000$ times faster than that of the $\\ell_1$ tracker.\nMeanwhile, RTCST still produces competitive (sometimes even superior) tracking\naccuracy comparing to the existing $\\ell_1$ tracker. Furthermore, for a\nstationary camera, a further refined tracker is designed by integrating a\nCS-based background model (CSBM). This CSBM-equipped tracker coined as RTCST-B,\noutperforms most state-of-the-arts with respect to both accuracy and\nrobustness. Finally, our experimental results on various video sequences, which\nare verified by a new metric---Tracking Success Probability (TSP), show the\nexcellence of the proposed algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.3216v1", 
    "other_authors": "Zhengdong Zhang, Arvind Ganesh, Xiao Liang, Yi Ma", 
    "title": "TILT: Transform Invariant Low-rank Textures", 
    "arxiv-id": "1012.3216v1", 
    "author": "Yi Ma", 
    "publish": "2010-12-15T02:55:25Z", 
    "summary": "In this paper, we show how to efficiently and effectively extract a class of\n\"low-rank textures\" in a 3D scene from 2D images despite significant\ncorruptions and warping. The low-rank textures capture geometrically meaningful\nstructures in an image, which encompass conventional local features such as\nedges and corners as well as all kinds of regular, symmetric patterns\nubiquitous in urban environments and man-made objects. Our approach to finding\nthese low-rank textures leverages the recent breakthroughs in convex\noptimization that enable robust recovery of a high-dimensional low-rank matrix\ndespite gross sparse errors. In the case of planar regions with significant\naffine or projective deformation, our method can accurately recover both the\nintrinsic low-rank texture and the precise domain transformation, and hence the\n3D geometry and appearance of the planar regions. Extensive experimental\nresults demonstrate that this new technique works effectively for many regular\nand near-regular patterns or objects that are approximately low-rank, such as\nsymmetrical patterns, building facades, printed texts, and human faces."
},{
    "category": "cs.CV", 
    "doi": "10.1007/11559573_51", 
    "link": "http://arxiv.org/pdf/1012.3802v1", 
    "other_authors": "Lin Wu, Yang Wang", 
    "title": "Detecting Image Forgeries using Geometric Cues", 
    "arxiv-id": "1012.3802v1", 
    "author": "Yang Wang", 
    "publish": "2010-12-17T03:27:54Z", 
    "summary": "This chapter presents a framework for detecting fake regions by using various\nmethods including watermarking technique and blind approaches. In particular,\nwe describe current categories on blind approaches which can be divided into\nfive: pixel-based techniques, format-based techniques, camera-based techniques,\nphysically-based techniques and geometric-based techniques. Then we take a\nsecond look on the geometric-based techniques and further categorize them in\ndetail. In the following section, the state-of-the-art methods involved in the\ngeometric technique are elaborated."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1012.3951v1", 
    "other_authors": "Roee Litman, Alex M. Bronstein, Michael M. Bronstein", 
    "title": "Diffusion-geometric maximally stable component detection in deformable   shapes", 
    "arxiv-id": "1012.3951v1", 
    "author": "Michael M. Bronstein", 
    "publish": "2010-12-17T18:23:35Z", 
    "summary": "Maximally stable component detection is a very popular method for feature\nanalysis in images, mainly due to its low computation cost and high\nrepeatability. With the recent advance of feature-based methods in geometric\nshape analysis, there is significant interest in finding analogous approaches\nin the 3D world. In this paper, we formulate a diffusion-geometric framework\nfor stable component detection in non-rigid 3D shapes, which can be used for\ngeometric feature detection and description. A quantitative evaluation of our\nmethod on the SHREC'10 feature detection benchmark shows its potential as a\nsource of high-quality features."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1012.5933v1", 
    "other_authors": "Dan Raviv, Alexander M. Bronstein, Michael M. Bronstein, Ron Kimmel, Nir Sochen", 
    "title": "Affine-invariant diffusion geometry for the analysis of deformable 3D   shapes", 
    "arxiv-id": "1012.5933v1", 
    "author": "Nir Sochen", 
    "publish": "2010-12-29T13:11:41Z", 
    "summary": "We introduce an (equi-)affine invariant diffusion geometry by which surfaces\nthat go through squeeze and shear transformations can still be properly\nanalyzed. The definition of an affine invariant metric enables us to construct\nan invariant Laplacian from which local and global geometric structures are\nextracted. Applications of the proposed framework demonstrate its power in\ngeneralizing and enriching the existing set of tools for shape analysis."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.cag.2011.03.011", 
    "link": "http://arxiv.org/pdf/1012.5936v1", 
    "other_authors": "Dan Raviv, Alexander M. Bronstein, Michael M. Bronstein, Ron Kimmel, Nir Sochen", 
    "title": "Affine-invariant geodesic geometry of deformable 3D shapes", 
    "arxiv-id": "1012.5936v1", 
    "author": "Nir Sochen", 
    "publish": "2010-12-29T13:33:01Z", 
    "summary": "Natural objects can be subject to various transformations yet still preserve\nproperties that we refer to as invariants. Here, we use definitions of affine\ninvariant arclength for surfaces in R^3 in order to extend the set of existing\nnon-rigid shape analysis tools. In fact, we show that by re-defining the\nsurface metric as its equi-affine version, the surface with its modified metric\ntensor can be treated as a canonical Euclidean object on which most classical\nEuclidean processing and analysis tools can be applied. The new definition of a\nmetric is used to extend the fast marching method technique for computing\ngeodesic distances on surfaces, where now, the distances are defined with\nrespect to an affine invariant arclength. Applications of the proposed\nframework demonstrate its invariance, efficiency, and accuracy in shape\nanalysis."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2301", 
    "link": "http://arxiv.org/pdf/1106.0371v1", 
    "other_authors": "Ashraf A. Aly, Safaai Bin Deris, Nazar Zaki", 
    "title": "A Novel Image Segmentation Enhancement Technique based on Active Contour   and Topological Alignments", 
    "arxiv-id": "1106.0371v1", 
    "author": "Nazar Zaki", 
    "publish": "2011-06-02T06:31:13Z", 
    "summary": "Topological alignments and snakes are used in image processing, particularly\nin locating object boundaries. Both of them have their own advantages and\nlimitations. To improve the overall image boundary detection system, we focused\non developing a novel algorithm for image processing. The algorithm we propose\nto develop will based on the active contour method in conjunction with\ntopological alignments method to enhance the image detection approach. The\nalgorithm presents novel technique to incorporate the advantages of both\nTopological Alignments and snakes. Where the initial segmentation by\nTopological Alignments is firstly transformed into the input of the snake model\nand begins its evolvement to the interested object boundary. The results show\nthat the algorithm can deal with low contrast images and shape cells,\ndemonstrate the segmentation accuracy under weak image boundaries, which\nresponsible for lacking accuracy in image detecting techniques. We have\nachieved better segmentation and boundary detecting for the image, also the\nability of the system to improve the low contrast and deal with over and under\nsegmentation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/acij.2011.2301", 
    "link": "http://arxiv.org/pdf/1106.0962v1", 
    "other_authors": "K. Chattopadhyay, J. Basu, A. Konar", 
    "title": "An efficient circle detection scheme in digital images using ant system   algorithm", 
    "arxiv-id": "1106.0962v1", 
    "author": "A. Konar", 
    "publish": "2011-06-06T05:52:09Z", 
    "summary": "Detection of geometric features in digital images is an important exercise in\nimage analysis and computer vision. The Hough Transform techniques for\ndetection of circles require a huge memory space for data processing hence\nrequiring a lot of time in computing the locations of the data space, writing\nto and searching through the memory space. In this paper we propose a novel and\nefficient scheme for detecting circles in edge-detected grayscale digital\nimages. We use Ant-system algorithm for this purpose which has not yet found\nmuch application in this field. The main feature of this scheme is that it can\ndetect both intersecting as well as non-intersecting circles with a time\nefficiency that makes it useful in real time applications. We build up an ant\nsystem of new type which finds out closed loops in the image and then tests\nthem for circles."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SOFA.2010.5565599", 
    "link": "http://arxiv.org/pdf/1106.2357v1", 
    "other_authors": "Nicolaie Popescu-Bodorin, Valentina E. Balas", 
    "title": "Comparing Haar-Hilbert and Log-Gabor Based Iris Encoders on Bath Iris   Image Database", 
    "arxiv-id": "1106.2357v1", 
    "author": "Valentina E. Balas", 
    "publish": "2011-06-12T23:14:05Z", 
    "summary": "This papers introduces a new family of iris encoders which use 2-dimensional\nHaar Wavelet Transform for noise attenuation, and Hilbert Transform to encode\nthe iris texture. In order to prove the usefulness of the newly proposed iris\nencoding approach, the recognition results obtained by using these new encoders\nare compared to those obtained using the classical Log- Gabor iris encoder.\nTwelve tests involving single/multienrollment and conducted on Bath Iris Image\nDatabase are presented here. One of these tests achieves an Equal Error Rate\ncomparable to the lowest value reported so far for this database. New Matlab\ntools for iris image processing are also released together with this paper: a\nsecond version of the Circular Fuzzy Iris Segmentator (CFIS2), a fast Log-Gabor\nencoder and two Haar-Hilbert based encoders."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SOFA.2010.5565599", 
    "link": "http://arxiv.org/pdf/1106.2695v1", 
    "other_authors": "Duc Phu Chau, Fran\u00e7ois Bremond, Monique Thonnat, Etienne Corvee", 
    "title": "Robust Mobile Object Tracking Based on Multiple Feature Similarity and   Trajectory Filtering", 
    "arxiv-id": "1106.2695v1", 
    "author": "Etienne Corvee", 
    "publish": "2011-06-14T12:45:05Z", 
    "summary": "This paper presents a new algorithm to track mobile objects in different\nscene conditions. The main idea of the proposed tracker includes estimation,\nmulti-features similarity measures and trajectory filtering. A feature set\n(distance, area, shape ratio, color histogram) is defined for each tracked\nobject to search for the best matching object. Its best matching object and its\nstate estimated by the Kalman filter are combined to update position and size\nof the tracked object. However, the mobile object trajectories are usually\nfragmented because of occlusions and misdetections. Therefore, we also propose\na trajectory filtering, named global tracker, aims at removing the noisy\ntrajectories and fusing the fragmented trajectories belonging to a same mobile\nobject. The method has been tested with five videos of different scene\nconditions. Three of them are provided by the ETISEO benchmarking project\n(http://www-sop.inria.fr/orion/ETISEO) in which the proposed tracker\nperformance has been compared with other seven tracking algorithms. The\nadvantages of our approach over the existing state of the art ones are: (i) no\nprior knowledge information is required (e.g. no calibration and no contextual\nmodels are needed), (ii) the tracker is more reliable by combining multiple\nfeature similarities, (iii) the tracker can perform in different scene\nconditions: single/several mobile objects, weak/strong illumination,\nindoor/outdoor scenes, (iv) a trajectory filtering is defined and applied to\nimprove the tracker performance, (v) the tracker performance outperforms many\nalgorithms of the state of the art."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3464v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Debotosh Bhattacharjee, Dipak Kumar Basu, Mita Nasipuri", 
    "title": "Polar Fusion Technique Analysis for Evaluating the Performances of Image   Fusion of Thermal and Visual Images for Human Face Recognition", 
    "arxiv-id": "1106.3464v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-06-17T12:25:30Z", 
    "summary": "This paper presents a comparative study of two different methods, which are\nbased on fusion and polar transformation of visual and thermal images. Here,\ninvestigation is done to handle the challenges of face recognition, which\ninclude pose variations, changes in facial expression, partial occlusions,\nvariations in illumination, rotation through different angles, change in scale\netc. To overcome these obstacles we have implemented and thoroughly examined\ntwo different fusion techniques through rigorous experimentation. In the first\nmethod log-polar transformation is applied to the fused images obtained after\nfusion of visual and thermal images whereas in second method fusion is applied\non log-polar transformed individual visual and thermal images. After this step,\nwhich is thus obtained in one form or another, Principal Component Analysis\n(PCA) is applied to reduce dimension of the fused images. Log-polar transformed\nimages are capable of handling complicacies introduced by scaling and rotation.\nThe main objective of employing fusion is to produce a fused image that\nprovides more detailed and reliable information, which is capable to overcome\nthe drawbacks present in the individual visual and thermal face images.\nFinally, those reduced fused images are classified using a multilayer\nperceptron neural network. The database used for the experiments conducted here\nis Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database\nbenchmark thermal and visual face images. The second method has shown better\nperformance, which is 95.71% (maximum) and on an average 93.81% as correct\nrecognition rate."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3466v1", 
    "other_authors": "Mrinal Kanti Bhowmik, Gautam Majumdar, Debotosh Bhattacharjee, Dipak Kumar Basu, Mita Nasipuri", 
    "title": "Next Level of Data Fusion for Human Face Recognition", 
    "arxiv-id": "1106.3466v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-06-17T12:31:30Z", 
    "summary": "This paper demonstrates two different fusion techniques at two different\nlevels of a human face recognition process. The first one is called data fusion\nat lower level and the second one is the decision fusion towards the end of the\nrecognition process. At first a data fusion is applied on visual and\ncorresponding thermal images to generate fused image. Data fusion is\nimplemented in the wavelet domain after decomposing the images through\nDaubechies wavelet coefficients (db2). During the data fusion maximum of\napproximate and other three details coefficients are merged together. After\nthat Principle Component Analysis (PCA) is applied over the fused coefficients\nand finally two different artificial neural networks namely Multilayer\nPerceptron(MLP) and Radial Basis Function(RBF) networks have been used\nseparately to classify the images. After that, for decision fusion based\ndecisions from both the classifiers are combined together using Bayesian\nformulation. For experiments, IRIS thermal/visible Face Database has been used.\nExperimental results show that the performance of multiple classifier system\nalong with decision fusion works well over the single classifier system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3467v1", 
    "other_authors": "Arindam Kar, Debotosh Bhattacharjee, Dipak Kumar Basu, Mita Nasipuri, Mahantapas Kundu", 
    "title": "High Performance Human Face Recognition using Independent High Intensity   Gabor Wavelet Responses: A Statistical Approach", 
    "arxiv-id": "1106.3467v1", 
    "author": "Mahantapas Kundu", 
    "publish": "2011-06-17T12:42:26Z", 
    "summary": "In this paper, we present a technique by which high-intensity feature vectors\nextracted from the Gabor wavelet transformation of frontal face images, is\ncombined together with Independent Component Analysis (ICA) for enhanced face\nrecognition. Firstly, the high-intensity feature vectors are automatically\nextracted using the local characteristics of each individual face from the\nGabor transformed images. Then ICA is applied on these locally extracted\nhigh-intensity feature vectors of the facial images to obtain the independent\nhigh intensity feature (IHIF) vectors. These IHIF forms the basis of the work.\nFinally, the image classification is done using these IHIF vectors, which are\nconsidered as representatives of the images. The importance behind implementing\nICA along with the high-intensity features of Gabor wavelet transformation is\ntwofold. On the one hand, selecting peaks of the Gabor transformed face images\nexhibit strong characteristics of spatial locality, scale, and orientation\nselectivity. Thus these images produce salient local features that are most\nsuitable for face recognition. On the other hand, as the ICA employs locally\nsalient features from the high informative facial parts, it reduces redundancy\nand represents independent features explicitly. These independent features are\nmost useful for subsequent facial discrimination and associative recall. The\nefficiency of IHIF method is demonstrated by the experiment on frontal facial\nimages dataset, selected from the FERET, FRAV2D, and the ORL database."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.3517v1", 
    "other_authors": "Shashi Kumar D. R., K. B. Raja, R. K. Chhootaray, Sabyasachi Pattanaik", 
    "title": "DWT Based Fingerprint Recognition using Non Minutiae Features", 
    "arxiv-id": "1106.3517v1", 
    "author": "Sabyasachi Pattanaik", 
    "publish": "2011-06-17T15:52:56Z", 
    "summary": "Forensic applications like criminal investigations, terrorist identification\nand National security issues require a strong fingerprint data base and\nefficient identification system. In this paper we propose DWT based Fingerprint\nRecognition using Non Minutiae (DWTFR) algorithm. Fingerprint image is\ndecomposed into multi resolution sub bands of LL, LH, HL and HH by applying 3\nlevel DWT. The Dominant local orientation angle {\\theta} and Coherence are\ncomputed on LL band only. The Centre Area Features and Edge Parameters are\ndetermined on each DWT level by considering all four sub bands. The comparison\nof test fingerprint with database fingerprint is decided based on the Euclidean\nDistance of all the features. It is observed that the values of FAR, FRR and\nTSR are improved compared to the existing algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.4907v1", 
    "other_authors": "H. R. Chennamma, Lalitha Rangarajan, Veerabhadrappa", 
    "title": "Face Identification from Manipulated Facial Images using SIFT", 
    "arxiv-id": "1106.4907v1", 
    "author": "Veerabhadrappa", 
    "publish": "2011-06-24T08:30:15Z", 
    "summary": "Editing on digital images is ubiquitous. Identification of deliberately\nmodified facial images is a new challenge for face identification system. In\nthis paper, we address the problem of identification of a face or person from\nheavily altered facial images. In this face identification problem, the input\nto the system is a manipulated or transformed face image and the system reports\nback the determined identity from a database of known individuals. Such a\nsystem can be useful in mugshot identification in which mugshot database\ncontains two views (frontal and profile) of each criminal. We considered only\nfrontal view from the available database for face identification and the query\nimage is a manipulated face generated by face transformation software tool\navailable online. We propose SIFT features for efficient face identification in\nthis scenario. Further comparative analysis has been given with well known\neigenface approach. Experiments have been conducted with real case images to\nevaluate the performance of both methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5156v2", 
    "other_authors": "B. V. Dhandra, Mallikarjun Hangarge", 
    "title": "Morphological Reconstruction for Word Level Script Identification", 
    "arxiv-id": "1106.5156v2", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2011-06-25T18:16:59Z", 
    "summary": "A line of a bilingual document page may contain text words in regional\nlanguage and numerals in English. For Optical Character Recognition (OCR) of\nsuch a document page, it is necessary to identify different script forms before\nrunning an individual OCR system. In this paper, we have identified a tool of\nmorphological opening by reconstruction of an image in different directions and\nregional descriptors for script identification at word level, based on the\nobservation that every text has a distinct visual appearance. The proposed\nsystem is developed for three Indian major bilingual documents, Kannada, Telugu\nand Devnagari containing English numerals. The nearest neighbour and k-nearest\nneighbour algorithms are applied to classify new word images. The proposed\nalgorithm is tested on 2625 words with various font styles and sizes. The\nresults obtained are quite encouraging"
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5186v1", 
    "other_authors": "Ulas Bagci, Jianhua Yao, Jesus Caban, Anthony F. Suffredini, Tara N. Palmore, Daniel J. Mollura", 
    "title": "Learning Shape and Texture Characteristics of CT Tree-in-Bud Opacities   for CAD Systems", 
    "arxiv-id": "1106.5186v1", 
    "author": "Daniel J. Mollura", 
    "publish": "2011-06-26T03:35:08Z", 
    "summary": "Although radiologists can employ CAD systems to characterize malignancies,\npulmonary fibrosis and other chronic diseases; the design of imaging techniques\nto quantify infectious diseases continue to lag behind. There exists a need to\ncreate more CAD systems capable of detecting and quantifying characteristic\npatterns often seen in respiratory tract infections such as influenza,\nbacterial pneumonia, or tuborculosis. One of such patterns is Tree-in-bud (TIB)\nwhich presents \\textit{thickened} bronchial structures surrounding by clusters\nof \\textit{micro-nodules}. Automatic detection of TIB patterns is a challenging\ntask because of their weak boundary, noisy appearance, and small lesion size.\nIn this paper, we present two novel methods for automatically detecting TIB\npatterns: (1) a fast localization of candidate patterns using information from\nlocal scale of the images, and (2) a M\\\"{o}bius invariant feature extraction\nmethod based on learned local shape and texture properties. A comparative\nevaluation of the proposed methods is presented with a dataset of 39 laboratory\nconfirmed viral bronchiolitis human parainfluenza (HPIV) CTs and 21 normal lung\nCTs. Experimental results demonstrate that the proposed CAD system can achieve\nhigh detection rate with an overall accuracy of 90.96%."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5460v1", 
    "other_authors": "Jeremiah Wala, Sergei Fotin, Jaesung Lee, Artit Jirapatnakul, Alberto Biancardi, Anthony Reeves", 
    "title": "Automated segmentation of the pulmonary arteries in low-dose CT by   vessel tracking", 
    "arxiv-id": "1106.5460v1", 
    "author": "Anthony Reeves", 
    "publish": "2011-06-27T17:47:23Z", 
    "summary": "We present a fully automated method for top-down segmentation of the\npulmonary arterial tree in low-dose thoracic CT images. The main basal\npulmonary arteries are identified near the lung hilum by searching for\ncandidate vessels adjacent to known airways, identified by our previously\nreported airway segmentation method. Model cylinders are iteratively fit to the\nvessels to track them into the lungs. Vessel bifurcations are detected by\nmeasuring the rate of change of vessel radii, and child vessels are segmented\nby initiating new trackers at bifurcation points. Validation is accomplished\nusing our novel sparse surface (SS) evaluation metric. The SS metric was\ndesigned to quantify the magnitude of the segmentation error per vessel while\nsignificantly decreasing the manual marking burden for the human user. A total\nof 210 arteries and 205 veins were manually marked across seven test cases.\n134/210 arteries were correctly segmented, with a specificity for arteries of\n90%, and average segmentation error of 0.15 mm. This fully-automated\nsegmentation is a promising method for improving lung nodule detection in\nlow-dose CT screening scans, by separating vessels from surrounding\niso-intensity objects."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5569v1", 
    "other_authors": "David Prochazka, Tomas Koubek", 
    "title": "Augmented Reality Implementation Methods in Mainstream Applications", 
    "arxiv-id": "1106.5569v1", 
    "author": "Tomas Koubek", 
    "publish": "2011-06-28T05:57:37Z", 
    "summary": "Augmented reality has became an useful tool in many areas from space\nexploration to military applications. Although used theoretical principles are\nwell known for almost a decade, the augmented reality is almost exclusively\nused in high budget solutions with a special hardware. However, in last few\nyears we could see rising popularity of many projects focused on deployment of\nthe augmented reality on different mobile devices. Our article is aimed on\ndevelopers who consider development of an augmented reality application for the\nmainstream market. Such developers will be forced to keep the application\nprice, therefore also the development price, at reasonable level. Usage of\nexisting image processing software library could bring a significant cut-down\nof the development costs. In the theoretical part of the article is presented\nan overview of the augmented reality application structure. Further, an\napproach for selection appropriate library as well as the review of the\nexisting software libraries focused in this area is described. The last part of\nthe article outlines our implementation of key parts of the augmented reality\napplication using the OpenCV library."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5571v1", 
    "other_authors": "David Prochazka, Michael Stencl, Ondrej Popelka, Jiri Stastny", 
    "title": "Mobile Augmented Reality Applications", 
    "arxiv-id": "1106.5571v1", 
    "author": "Jiri Stastny", 
    "publish": "2011-06-28T06:08:38Z", 
    "summary": "Augmented reality have undergone considerable improvement in past years. Many\nspecial techniques and hardware devices were developed, but the crucial\nbreakthrough came with the spread of intelligent mobile phones. This enabled\nmass spread of augmented reality applications. However mobile devices have\nlimited hardware capabilities, which narrows down the methods usable for scene\nanalysis. In this article we propose an augmented reality application which is\nusing cloud computing to enable using of more complex computational methods\nsuch as neural networks. Our goal is to create an affordable augmented reality\napplication suitable which will help car designers in by 'virtualizing' car\nmodifications."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5737v1", 
    "other_authors": "D. Bennet, Dr. S. Arumuga Perumal", 
    "title": "Fingerprint: DWT, SVD Based Enhancement and Significant Contrast for   Ridges and Valleys Using Fuzzy Measures", 
    "arxiv-id": "1106.5737v1", 
    "author": "Dr. S. Arumuga Perumal", 
    "publish": "2011-06-23T16:25:22Z", 
    "summary": "The performance of the Fingerprint recognition system will be more accurate\nwith respect of enhancement for the fingerprint images. In this paper we\ndevelop a novel method for Fingerprint image contrast enhancement technique\nbased on the discrete wavelet transform (DWT) and singular value decomposition\n(SVD) has been proposed. This technique is compared with conventional image\nequalization techniques such as standard general histogram equalization and\nlocal histogram equalization. An automatic histogram threshold approach based\non a fuzziness measure is presented. Then, using an index of fuzziness, a\nsimilarity process is started to find the threshold point. A significant\ncontrast between ridges and valleys of the best, medium and poor finger image\nfeatures to extract from finger images and get maximum recognition rate using\nfuzzy measures. The experimental results show the recognition of superiority of\nthe proposed method to get maximum performance up gradation to the\nimplementation of this approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1106.5928v1", 
    "other_authors": "Salvador Gabarda, Gabriel Cristobal", 
    "title": "Image denoising assessment using anisotropic stack filtering", 
    "arxiv-id": "1106.5928v1", 
    "author": "Gabriel Cristobal", 
    "publish": "2011-06-29T13:12:56Z", 
    "summary": "In this paper we propose a measure of anisotropy as a quality parameter to\nestimate the amount of noise in noisy images. The anisotropy of an image can be\ndetermined through a directional measure, using an appropriate statistical\ndistribution of the information contained in the image. This new measure is\nachieved through a stack filtering paradigm. First, we define a local\ndirectional entropy, based on the distribution of 0's and 1's in the\nneigborhood of every pixel location of each stack level. Then the entropy\nvariation of this directional entropy is used to define an anisotropic measure.\nThe empirical results have shown that this measure can be regarded as an\nexcellent image noise indicator, which is particularly relevant for quality\nassessment of denoising algorithms. The method has been evaluated with\nartificial and real-world degraded images."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.0845v4", 
    "other_authors": "Suprijadi, Thomas Muliawan, Sparisoma Viridi", 
    "title": "Automatic Road Lighting System (ARLS) Model Based on Image Processing of   Moving Object", 
    "arxiv-id": "1107.0845v4", 
    "author": "Sparisoma Viridi", 
    "publish": "2011-07-05T11:06:04Z", 
    "summary": "Using a vehicle toy (in next future called vehicle) as a moving object an\nautomatic road lighting system (ARLS) model is constructed. A digital video\ncamera with 25 fps is used to capture the vehicle motion as it moves in the\ntest segment of the road. Captured images are then processed to calculate\nvehicle speed. This information of the speed together with position of vehicle\nis then used to control the lighting system along the path that passes by the\nvehicle. Length of the road test segment is 1 m, the video camera is positioned\nabout 1.1 m above the test segment, and the vehicle toy dimension is 13 cm\n\\times 9.3 cm. In this model, the maximum speed that ARLS can handle is about\n1.32 m/s, and the highest performance is obtained about 91% at speed 0.93 m/s."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.1058v1", 
    "other_authors": "Ranch Y. Q. Lai", 
    "title": "Online Vehicle Detection For Estimating Traffic Status", 
    "arxiv-id": "1107.1058v1", 
    "author": "Ranch Y. Q. Lai", 
    "publish": "2011-07-06T08:43:38Z", 
    "summary": "We propose a traffic congestion estimation system based on unsupervised\non-line learning algorithm. The system does not rely on background extraction\nor motion detection. It extracts local features inside detection regions of\nvariable size which are drawn on lanes in advance. The extracted features are\nthen clustered into two classes using K-means and Gaussian Mixture Models(GMM).\nA Bayes classifier is used to detect vehicles according to the previous cluster\ninformation which keeps updated whenever system is running by on-line EM\nalgorithm. Experimental result shows that our system can be adapted to various\ntraffic scenes for estimating traffic status."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.1081v1", 
    "other_authors": "B. V. Dhandra, Mallikarjun Hangarge, Gururaj Mukarambi", 
    "title": "Spatial Features for Multi-Font/Multi-Size Kannada Numerals and Vowels   Recognition", 
    "arxiv-id": "1107.1081v1", 
    "author": "Gururaj Mukarambi", 
    "publish": "2011-07-06T10:02:42Z", 
    "summary": "This paper presents multi-font/multi-size Kannada numerals and vowels\nrecognition based on spatial features. Directional spatial features viz stroke\ndensity, stroke length and the number of stokes in an image are employed as\npotential features to characterize the printed Kannada numerals and vowels.\nBased on these features 1100 numerals and 1400 vowels are classified with\nMulti-class Support Vector Machines (SVM). The proposed system achieves the\nrecognition accuracy as 98.45% and 90.64% for numerals and vowels respectively."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.1561v1", 
    "other_authors": "Wei Siming, Lin Zhouchen", 
    "title": "Analysis and Improvement of Low Rank Representation for Subspace   segmentation", 
    "arxiv-id": "1107.1561v1", 
    "author": "Lin Zhouchen", 
    "publish": "2011-07-08T05:44:57Z", 
    "summary": "We analyze and improve low rank representation (LRR), the state-of-the-art\nalgorithm for subspace segmentation of data. We prove that for the noiseless\ncase, the optimization model of LRR has a unique solution, which is the shape\ninteraction matrix (SIM) of the data matrix. So in essence LRR is equivalent to\nfactorization methods. We also prove that the minimum value of the optimization\nmodel of LRR is equal to the rank of the data matrix. For the noisy case, we\nshow that LRR can be approximated as a factorization method that combines noise\nremoval by column sparse robust PCA. We further propose an improved version of\nLRR, called Robust Shape Interaction (RSI), which uses the corrected data as\nthe dictionary instead of the noisy data. RSI is more robust than LRR when the\ncorruption in data is heavy. Experiments on both synthetic and real data\ntestify to the improved robustness of RSI."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2085v1", 
    "other_authors": "Oleg Chertov, Taras Slipets", 
    "title": "Kunchenko's Polynomials for Template Matching", 
    "arxiv-id": "1107.2085v1", 
    "author": "Taras Slipets", 
    "publish": "2011-07-11T18:44:17Z", 
    "summary": "This paper reviews Kunchenko's polynomials using as template matching method\nto recognize template in one-dimensional input signal. Kunchenko's polynomials\nmethod is compared with classical methods - cross-correlation and sum of\nsquared differences according to numerical statistical example."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2336v1", 
    "other_authors": "N. S. Nikolaidis, I. N. Nikolaidis, C. C. Tsouros", 
    "title": "A Variation of the Box-Counting Algorithm Applied to Colour Images", 
    "arxiv-id": "1107.2336v1", 
    "author": "C. C. Tsouros", 
    "publish": "2011-07-12T16:21:06Z", 
    "summary": "The box counting method for fractal dimension estimation had not been applied\nto large or colour images thus far due to the processing time required. In this\nletter we present a fast, easy to implement and very easily expandable to any\nnumber of dimensions variation, the box merging method. It is applied here in\nRGB images which are considered as sets in 5-D space."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2553v1", 
    "other_authors": "Toufiq Parag, Vladimir Pavlovic, Ahmed Elgammal", 
    "title": "Learning Hypergraph Labeling for Feature Matching", 
    "arxiv-id": "1107.2553v1", 
    "author": "Ahmed Elgammal", 
    "publish": "2011-07-13T14:01:50Z", 
    "summary": "This study poses the feature correspondence problem as a hypergraph node\nlabeling problem. Candidate feature matches and their subsets (usually of size\nlarger than two) are considered to be the nodes and hyperedges of a hypergraph.\nA hypergraph labeling algorithm, which models the subset-wise interaction by an\nundirected graphical model, is applied to label the nodes (feature\ncorrespondences) as correct or incorrect. We describe a method to learn the\ncost function of this labeling algorithm from labeled examples using a\ngraphical model training algorithm. The proposed feature matching algorithm is\ndifferent from the most of the existing learning point matching methods in\nterms of the form of the objective function, the cost function to be learned\nand the optimization method applied to minimize it. The results on standard\ndatasets demonstrate how learning over a hypergraph improves the matching\nperformance over existing algorithms, notably one that also uses higher order\ninformation without learning."
},{
    "category": "cs.CV", 
    "doi": "10.1109/CIBIM.2011.5949220", 
    "link": "http://arxiv.org/pdf/1107.2693v1", 
    "other_authors": "Nicolaie Popescu-Bodorin", 
    "title": "A Fuzzy View on k-Means Based Signal Quantization with Application in   Iris Segmentation", 
    "arxiv-id": "1107.2693v1", 
    "author": "Nicolaie Popescu-Bodorin", 
    "publish": "2011-07-13T22:46:58Z", 
    "summary": "This paper shows that the k-means quantization of a signal can be interpreted\nboth as a crisp indicator function and as a fuzzy membership assignment\ndescribing fuzzy clusters and fuzzy boundaries. Combined crisp and fuzzy\nindicator functions are defined here as natural generalizations of the ordinary\ncrisp and fuzzy indicator functions, respectively. An application to iris\nsegmentation is presented together with a demo program."
},{
    "category": "cs.CV", 
    "doi": "10.1109/SYNASC.2009.45", 
    "link": "http://arxiv.org/pdf/1107.2696v1", 
    "other_authors": "Nicolaie Popescu-Bodorin", 
    "title": "Exploring New Directions in Iris Recognition", 
    "arxiv-id": "1107.2696v1", 
    "author": "Nicolaie Popescu-Bodorin", 
    "publish": "2011-07-13T23:18:57Z", 
    "summary": "A new approach in iris recognition based on Circular Fuzzy Iris Segmentation\n(CFIS) and Gabor Analytic Iris Texture Binary Encoder (GAITBE) is proposed and\ntested here. CFIS procedure is designed to guarantee that similar iris segments\nwill be obtained for similar eye images, despite the fact that the degree of\nocclusion may vary from one image to another. Its result is a circular iris\nring (concentric with the pupil) which approximates the actual iris. GAITBE\nproves better encoding of statistical independence between the iris codes\nextracted from different irides using Hilbert Transform. Irides from University\nof Bath Iris Database are binary encoded on two different lengths (768 / 192\nbytes) and tested in both single-enrollment and multi-enrollment identification\nscenarios. All cases illustrate the capacity of the newly proposed methodology\nto narrow down the distribution of inter-class matching scores, and\nconsequently, to guarantee a steeper descent of the False Accept Rate."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.2723v1", 
    "other_authors": "Soumen Bag, Gaurav Harit", 
    "title": "Topographic Feature Extraction for Bengali and Hindi Character Images", 
    "arxiv-id": "1107.2723v1", 
    "author": "Gaurav Harit", 
    "publish": "2011-07-14T04:05:23Z", 
    "summary": "Feature selection and extraction plays an important role in different\nclassification based problems such as face recognition, signature verification,\noptical character recognition (OCR) etc. The performance of OCR highly depends\non the proper selection and extraction of feature set. In this paper, we\npresent novel features based on the topography of a character as visible from\ndifferent viewing directions on a 2D plane. By topography of a character we\nmean the structural features of the strokes and their spatial relations. In\nthis work we develop topographic features of strokes visible with respect to\nviews from different directions (e.g. North, South, East, and West). We\nconsider three types of topographic features: closed region, convexity of\nstrokes, and straight line strokes. These features are represented as a\nshape-based graph which acts as an invariant feature set for discriminating\nvery similar type characters efficiently. We have tested the proposed method on\nprinted and handwritten Bengali and Hindi character images. Initial results\ndemonstrate the efficacy of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.2781v1", 
    "other_authors": "Rami Cohen", 
    "title": "Face Recognition using Curvelet Transform", 
    "arxiv-id": "1107.2781v1", 
    "author": "Rami Cohen", 
    "publish": "2011-07-14T10:44:01Z", 
    "summary": "Face recognition has been studied extensively for more than 20 years now.\nSince the beginning of 90s the subject has became a major issue. This\ntechnology is used in many important real-world applications, such as video\nsurveillance, smart cards, database security, internet and intranet access.\nThis report reviews recent two algorithms for face recognition which take\nadvantage of a relatively new multiscale geometric analysis tool - Curvelet\ntransform, for facial processing and feature extraction. This transform proves\nto be efficient especially due to its good ability to detect curves and lines,\nwhich characterize the human's face. An algorithm which is based on the two\nalgorithms mentioned above is proposed, and its performance is evaluated on\nthree data bases of faces: AT&T (ORL), Essex Grimace and Georgia-Tech.\nk-nearest neighbour (k-NN) and Support vector machine (SVM) classifiers are\nused, along with Principal Component Analysis (PCA) for dimensionality\nreduction. This algorithm shows good results, and it even outperforms other\nalgorithms in some cases."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.3194v1", 
    "other_authors": "Le Hoang Thai, Ha Nhat Tam", 
    "title": "Fingerprint recognition using standardized fingerprint model", 
    "arxiv-id": "1107.3194v1", 
    "author": "Ha Nhat Tam", 
    "publish": "2011-07-16T03:04:22Z", 
    "summary": "Fingerprint recognition is one of most popular and accuracy Biometric\ntechnologies. Nowadays, it is used in many real applications. However,\nrecognizing fingerprints in poor quality images is still a very complex\nproblem. In recent years, many algorithms, models...are given to improve the\naccuracy of recognition system. This paper discusses on the standardized\nfingerprint model which is used to synthesize the template of fingerprints. In\nthis model, after pre-processing step, we find the transformation between\ntemplates, adjust parameters, synthesize fingerprint, and reduce noises. Then,\nwe use the final fingerprint to match with others in FVC2004 fingerprint\ndatabase (DB4) to show the capability of the model."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.3195v1", 
    "other_authors": "Thai Le, Phat Tat, Hai Tran", 
    "title": "Facial Expression Classification Based on Multi Artificial Neural   Network and Two Dimensional Principal Component Analysis", 
    "arxiv-id": "1107.3195v1", 
    "author": "Hai Tran", 
    "publish": "2011-07-16T03:15:40Z", 
    "summary": "Facial expression classification is a kind of image classification and it has\nreceived much attention, in recent years. There are many approaches to solve\nthese problems with aiming to increase efficient classification. One of famous\nsuggestions is described as first step, project image to different spaces;\nsecond step, in each of these spaces, images are classified into responsive\nclass and the last step, combine the above classified results into the final\nresult. The advantages of this approach are to reflect fulfill and multiform of\nimage classified. In this paper, we use 2D-PCA and its variants to project the\npattern or image into different spaces with different grouping strategies. Then\nwe develop a model which combines many Neural Networks applied for the last\nstep. This model evaluates the reliability of each space and gives the final\nclassification conclusion. Our model links many Neural Networks together, so we\ncall it Multi Artificial Neural Network (MANN). We apply our proposal model for\n6 basic facial expressions on JAFFE database consisting 213 images posed by 10\nJapanese female models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.3348v2", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zuky", 
    "title": "Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion   Techniques", 
    "arxiv-id": "1107.3348v2", 
    "author": "Ali A. Al-Zuky", 
    "publish": "2011-07-18T01:41:37Z", 
    "summary": "In remote sensing, image fusion technique is a useful tool used to fuse high\nspatial resolution panchromatic images (PAN) with lower spatial resolution\nmultispectral images (MS) to create a high spatial resolution multispectral of\nimage fusion (F) while preserving the spectral information in the multispectral\nimage (MS).There are many PAN sharpening techniques or Pixel-Based image fusion\ntechniques that have been developed to try to enhance the spatial resolution\nand the spectral property preservation of the MS. This paper attempts to\nundertake the study of image fusion, by using two types of pixel-based image\nfusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods\nof Pixel-Based Image Fusion Techniques. The first type includes Brovey\nTransform (BT), Color Normalized Transformation (CN) and Multiplicative Method\n(MLT). The second type include High-Pass Filter Additive Method (HPFA),\nHigh-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and\nThe Wavelet transform-based fusion method (WT). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including Standard Deviation (SD),\nEntropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR),\nNormalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to\nestimate the quality and degree of information improvement of a fused image\nquantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4396v2", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zuky", 
    "title": "The IHS Transformations Based Image Fusion", 
    "arxiv-id": "1107.4396v2", 
    "author": "Ali A. Al-Zuky", 
    "publish": "2011-07-19T06:18:56Z", 
    "summary": "The IHS sharpening technique is one of the most commonly used techniques for\nsharpening. Different transformations have been developed to transfer a color\nimage from the RGB space to the IHS space. Through literature, it appears that,\nvarious scientists proposed alternative IHS transformations and many papers\nhave reported good results whereas others show bad ones as will as not those\nobtained which the formula of IHS transformation were used. In addition to\nthat, many papers show different formulas of transformation matrix such as IHS\ntransformation. This leads to confusion what is the exact formula of the IHS\ntransformation?. Therefore, the main purpose of this work is to explore\ndifferent IHS transformation techniques and experiment it as IHS based image\nfusion. The image fusion performance was evaluated, in this study, using\nvarious methods to estimate the quality and degree of information improvement\nof a fused image quantitatively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4667v2", 
    "other_authors": "Vijayaraghavan Thirumalai, Pascal Frossard", 
    "title": "Correlation Estimation from Compressed Images", 
    "arxiv-id": "1107.4667v2", 
    "author": "Pascal Frossard", 
    "publish": "2011-07-23T08:51:17Z", 
    "summary": "This paper addresses the problem of correlation estimation in sets of\ncompressed images. We consider a framework where images are represented under\nthe form of linear measurements due to low complexity sensing or security\nrequirements. We assume that the images are correlated through the displacement\nof visual objects due to motion or viewpoint change and the correlation is\neffectively represented by optical flow or motion field models. The correlation\nis estimated in the compressed domain by jointly processing the linear\nmeasurements. We first show that the correlated images can be efficiently\nrelated using a linear operator. Using this linear relationship we then\ndescribe the dependencies between images in the compressed domain. We further\ncast a regularized optimization problem where the correlation is estimated in\norder to satisfy both data consistency and motion smoothness objectives with a\nGraph Cut algorithm. We analyze in detail the correlation estimation\nperformance and quantify the penalty due to image compression. Extensive\nexperiments in stereo and video imaging applications show that our novel\nsolution stays competitive with methods that implement complex image\nreconstruction steps prior to correlation estimation. We finally use the\nestimated correlation in a novel joint image reconstruction scheme that is\nbased on an optimization problem with sparsity priors on the reconstructed\nimages. Additional experiments show that our correlation estimation algorithm\nleads to an effective reconstruction of pairs of images in distributed image\ncoding schemes that outperform independent reconstruction algorithms by 2 to 4\ndB."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4763v1", 
    "other_authors": "Jia Du, Alvina Goh, Anqi Qiu", 
    "title": "Diffeomorphic Metric Mapping of High Angular Resolution Diffusion   Imaging based on Riemannian Structure of Orientation Distribution Functions", 
    "arxiv-id": "1107.4763v1", 
    "author": "Anqi Qiu", 
    "publish": "2011-07-24T15:34:27Z", 
    "summary": "In this paper, we propose a novel large deformation diffeomorphic\nregistration algorithm to align high angular resolution diffusion images\n(HARDI) characterized by orientation distribution functions (ODFs). Our\nproposed algorithm seeks an optimal diffeomorphism of large deformation between\ntwo ODF fields in a spatial volume domain and at the same time, locally\nreorients an ODF in a manner such that it remains consistent with the\nsurrounding anatomical structure. To this end, we first review the Riemannian\nmanifold of ODFs. We then define the reorientation of an ODF when an affine\ntransformation is applied and subsequently, define the diffeomorphic group\naction to be applied on the ODF based on this reorientation. We incorporate the\nRiemannian metric of ODFs for quantifying the similarity of two HARDI images\ninto a variational problem defined under the large deformation diffeomorphic\nmetric mapping (LDDMM) framework. We finally derive the gradient of the cost\nfunction in both Riemannian spaces of diffeomorphisms and the ODFs, and present\nits numerical implementation. Both synthetic and real brain HARDI data are used\nto illustrate the performance of our registration algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.4958v1", 
    "other_authors": "Elhanan Elboher, Michael Werman", 
    "title": "Efficient and Accurate Gaussian Image Filtering Using Running Sums", 
    "arxiv-id": "1107.4958v1", 
    "author": "Michael Werman", 
    "publish": "2011-07-25T14:20:34Z", 
    "summary": "This paper presents a simple and efficient method to convolve an image with a\nGaussian kernel. The computation is performed in a constant number of\noperations per pixel using running sums along the image rows and columns. We\ninvestigate the error function used for kernel approximation and its relation\nto the properties of the input signal. Based on natural image statistics we\npropose a quadratic form kernel error function so that the output image l2\nerror is minimized. We apply the proposed approach to approximate the Gaussian\nkernel by linear combination of constant functions. This results in very\nefficient Gaussian filtering method. Our experiments show that the proposed\ntechnique is faster than state of the art methods while preserving a similar\naccuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2011.2215", 
    "link": "http://arxiv.org/pdf/1107.5850v2", 
    "other_authors": "Ibrahim Saygin Topkaya, Hakan Erdogan", 
    "title": "Confidence-Based Dynamic Classifier Combination For Mean-Shift Tracking", 
    "arxiv-id": "1107.5850v2", 
    "author": "Hakan Erdogan", 
    "publish": "2011-07-29T01:08:52Z", 
    "summary": "We introduce a novel tracking technique which uses dynamic confidence-based\nfusion of two different information sources for robust and efficient tracking\nof visual objects. Mean-shift tracking is a popular and well known method used\nin object tracking problems. Originally, the algorithm uses a similarity\nmeasure which is optimized by shifting a search area to the center of a\ngenerated weight image to track objects. Recent improvements on the original\nmean-shift algorithm involves using a classifier that differentiates the object\nfrom its surroundings. We adopt this classifier-based approach and propose an\napplication of a classifier fusion technique within this classifier-based\ncontext in this work. We use two different classifiers, where one comes from a\nbackground modeling method, to generate the weight image and we calculate\ncontributions of the classifiers dynamically using their confidences to\ngenerate a final weight image to be used in tracking. The contributions of the\nclassifiers are calculated by using correlations between histograms of their\nweight images and histogram of a defined ideal weight image in the previous\nframe. We show with experiments that our dynamic combination scheme selects\ngood contributions for classifiers for different cases and improves tracking\naccuracy significantly."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1407", 
    "link": "http://arxiv.org/pdf/1109.0090v1", 
    "other_authors": "Arup Kumar Pal, Anup Sar", 
    "title": "An Efficient Codebook Initialization Approach for LBG Algorithm", 
    "arxiv-id": "1109.0090v1", 
    "author": "Anup Sar", 
    "publish": "2011-09-01T04:47:08Z", 
    "summary": "In VQ based image compression technique has three major steps namely (i)\nCodebook Design, (ii) VQ Encoding Process and (iii) VQ Decoding Process. The\nperformance of VQ based image compression technique depends upon the\nconstructed codebook. A widely used technique for VQ codebook design is the\nLinde-Buzo-Gray (LBG) algorithm. However the performance of the standard LBG\nalgorithm is highly dependent on the choice of the initial codebook. In this\npaper, we have proposed a simple and very effective approach for codebook\ninitialization for LBG algorithm. The simulation results show that the proposed\nscheme is computationally efficient and gives expected performance as compared\nto the standard LBG algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1407", 
    "link": "http://arxiv.org/pdf/1109.0138v1", 
    "other_authors": "Atef Boujelben, Hedi Tmar, Jameleddine Mnif, Mohamed Abid", 
    "title": "Automatic Application Level Set Approach in Detection Calcifications in   Mammographic Image", 
    "arxiv-id": "1109.0138v1", 
    "author": "Mohamed Abid", 
    "publish": "2011-09-01T09:51:42Z", 
    "summary": "Breast cancer is considered as one of a major health problem that constitutes\nthe strongest cause behind mortality among women in the world. So, in this\ndecade, breast cancer is the second most common type of cancer, in term of\nappearance frequency, and the fifth most common cause of cancer related death.\nIn order to reduce the workload on radiologists, a variety of CAD systems;\nComputer-Aided Diagnosis (CADi) and Computer-Aided Detection (CADe) have been\nproposed. In this paper, we interested on CADe tool to help radiologist to\ndetect cancer. The proposed CADe is based on a three-step work flow; namely,\ndetection, analysis and classification. This paper deals with the problem of\nautomatic detection of Region Of Interest (ROI) based on Level Set approach\ndepended on edge and region criteria. This approach gives good visual\ninformation from the radiologist. After that, the features extraction using\ntextures characteristics and the vector classification using Multilayer\nPerception (MLP) and k-Nearest Neighbours (KNN) are adopted to distinguish\ndifferent ACR (American College of Radiology) classification. Moreover, we use\nthe Digital Database for Screening Mammography (DDSM) for experiments and these\nresults in term of accuracy varied between 60 % and 70% are acceptable and must\nbe ameliorated to aid radiologist."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1407", 
    "link": "http://arxiv.org/pdf/1109.0882v2", 
    "other_authors": "Xiaowei Zhou, Can Yang, Weichuan Yu", 
    "title": "Moving Object Detection by Detecting Contiguous Outliers in the Low-Rank   Representation", 
    "arxiv-id": "1109.0882v2", 
    "author": "Weichuan Yu", 
    "publish": "2011-09-05T13:08:24Z", 
    "summary": "Object detection is a fundamental step for automated video analysis in many\nvision applications. Object detection in a video is usually performed by object\ndetectors or background subtraction techniques. Often, an object detector\nrequires manually labeled examples to train a binary classifier, while\nbackground subtraction needs a training sequence that contains no objects to\nbuild a background model. To automate the analysis, object detection without a\nseparate training phase becomes a critical task. People have tried to tackle\nthis task by using motion information. But existing motion-based methods are\nusually limited when coping with complex scenarios such as nonrigid motion and\ndynamic background. In this paper, we show that above challenges can be\naddressed in a unified framework named DEtecting Contiguous Outliers in the\nLOw-rank Representation (DECOLOR). This formulation integrates object detection\nand background learning into a single process of optimization, which can be\nsolved by an alternating algorithm efficiently. We explain the relations\nbetween DECOLOR and other sparsity-based methods. Experiments on both simulated\ndata and real sequences demonstrate that DECOLOR outperforms the\nstate-of-the-art approaches and it can work effectively on a wide range of\ncomplex scenarios."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1407", 
    "link": "http://arxiv.org/pdf/1109.1057v1", 
    "other_authors": "Risheng Liu, Zhouchen Lin, Wei Zhang, Kewei Tang, Zhixun Su", 
    "title": "Toward Designing Intelligent PDEs for Computer Vision: An Optimal   Control Approach", 
    "arxiv-id": "1109.1057v1", 
    "author": "Zhixun Su", 
    "publish": "2011-09-06T04:26:44Z", 
    "summary": "Many computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually\nrequires high mathematical skills and good insight into the problems. In this\npaper, we consider designing PDEs for various problems arising in computer\nvision and image processing in a lazy manner: \\emph{learning PDEs from real\ndata via data-based optimal control}. We first propose a general intelligent\nPDE system which holds the basic translational and rotational invariance rule\nfor most vision problems. By introducing a PDE-constrained optimal control\nframework, it is possible to use the training data resulting from multiple ways\n(ground truth, results from other methods, and manual results from humans) to\nlearn PDEs for different computer vision tasks. The proposed optimal control\nbased training framework aims at learning a PDE-based regressor to approximate\nthe unknown (and usually nonlinear) mapping of different vision tasks. The\nexperimental results show that the learnt PDEs can solve different vision\nproblems reasonably well. In particular, we can obtain PDEs not only for\nproblems that traditional PDEs work well but also for problems that PDE-based\nmethods have never been tried before, due to the difficulty in describing those\nproblems in a mathematical way."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1407", 
    "link": "http://arxiv.org/pdf/1109.1067v1", 
    "other_authors": "A. Padma, Dr. R. Sukanesh", 
    "title": "Automatic Diagnosis of Abnormal Tumor Region from Brain Computed   Tomography Images Using Wavelet Based Statistical Texture Features", 
    "arxiv-id": "1109.1067v1", 
    "author": "Dr. R. Sukanesh", 
    "publish": "2011-09-06T05:31:26Z", 
    "summary": "The research work presented in this paper is to achieve the tissue\nclassification and automatically diagnosis the abnormal tumor region present in\nComputed Tomography (CT) images using the wavelet based statistical texture\nanalysis method. Comparative studies of texture analysis method are performed\nfor the proposed wavelet based texture analysis method and Spatial Gray Level\nDependence Method (SGLDM). Our proposed system consists of four phases i)\nDiscrete Wavelet Decomposition (ii) Feature extraction (iii) Feature selection\n(iv) Analysis of extracted texture features by classifier. A wavelet based\nstatistical texture feature set is derived from normal and tumor regions.\nGenetic Algorithm (GA) is used to select the optimal texture features from the\nset of extracted texture features. We construct the Support Vector Machine\n(SVM) based classifier and evaluate the performance of classifier by comparing\nthe classification results of the SVM based classifier with the Back\nPropagation Neural network classifier(BPN). The results of Support Vector\nMachine (SVM), BPN classifiers for the texture analysis methods are evaluated\nusing Receiver Operating Characteristic (ROC) analysis. Experimental results\nshow that the classification accuracy of SVM is 96% for 10 fold cross\nvalidation method. The system has been tested with a number of real Computed\nTomography brain images and has achieved satisfactory results."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsea.2011.1412", 
    "link": "http://arxiv.org/pdf/1109.1068v1", 
    "other_authors": "K. Karteeka Pavan, Allam Appa Rao, A. V. Dattatreya Rao", 
    "title": "An Automatic Clustering Technique for Optimal Clusters", 
    "arxiv-id": "1109.1068v1", 
    "author": "A. V. Dattatreya Rao", 
    "publish": "2011-09-06T05:34:28Z", 
    "summary": "This paper proposes a simple, automatic and efficient clustering algorithm,\nnamely, Automatic Merging for Optimal Clusters (AMOC) which aims to generate\nnearly optimal clusters for the given datasets automatically. The AMOC is an\nextension to standard k-means with a two phase iterative procedure combining\ncertain validation techniques in order to find optimal clusters with automation\nof merging of clusters. Experiments on both synthetic and real data have proved\nthat the proposed algorithm finds nearly optimal clustering structures in terms\nof number of clusters, compactness and separation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2011.1305", 
    "link": "http://arxiv.org/pdf/1109.1247v1", 
    "other_authors": "Vikas J Dongre, Vijay H Mankar", 
    "title": "Devnagari document segmentation using histogram approach", 
    "arxiv-id": "1109.1247v1", 
    "author": "Vijay H Mankar", 
    "publish": "2011-09-06T17:56:58Z", 
    "summary": "Document segmentation is one of the critical phases in machine recognition of\nany language. Correct segmentation of individual symbols decides the accuracy\nof character recognition technique. It is used to decompose image of a sequence\nof characters into sub images of individual symbols by segmenting lines and\nwords. Devnagari is the most popular script in India. It is used for writing\nHindi, Marathi, Sanskrit and Nepali languages. Moreover, Hindi is the third\nmost popular language in the world. Devnagari documents consist of vowels,\nconsonants and various modifiers. Hence proper segmentation of Devnagari word\nis challenging. A simple histogram based approach to segment Devnagari\ndocuments is proposed in this paper. Various challenges in segmentation of\nDevnagari script are also discussed."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2011.1305", 
    "link": "http://arxiv.org/pdf/1109.1480v1", 
    "other_authors": "Alexander Shekhovtsov, Pushmeet Kohli, Carsten Rother", 
    "title": "Curvature Prior for MRF-based Segmentation and Shape Inpainting", 
    "arxiv-id": "1109.1480v1", 
    "author": "Carsten Rother", 
    "publish": "2011-09-07T14:53:51Z", 
    "summary": "Most image labeling problems such as segmentation and image reconstruction\nare fundamentally ill-posed and suffer from ambiguities and noise. Higher order\nimage priors encode high level structural dependencies between pixels and are\nkey to overcoming these problems. However, these priors in general lead to\ncomputationally intractable models. This paper addresses the problem of\ndiscovering compact representations of higher order priors which allow\nefficient inference. We propose a framework for solving this problem which uses\na recently proposed representation of higher order functions where they are\nencoded as lower envelopes of linear functions. Maximum a Posterior inference\non our learned models reduces to minimizing a pairwise function of discrete\nvariables, which can be done approximately using standard methods. Although\nthis is a primarily theoretical paper, we also demonstrate the practical\neffectiveness of our framework on the problem of learning a shape prior for\nimage segmentation and reconstruction. We show that our framework can learn a\ncompact representation that approximates a prior that encourages low curvature\nshapes. We evaluate the approximation accuracy, discuss properties of the\ntrained model, and show various results for shape inpainting and image\nsegmentation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2011.1305", 
    "link": "http://arxiv.org/pdf/1109.1865v1", 
    "other_authors": "Rohit Pandharkar, Ashok Veeraraghavan, Ramesh Raskar", 
    "title": "Progressive versus Random Projections for Compressive Capture of Images,   Lightfields and Higher Dimensional Visual Signals", 
    "arxiv-id": "1109.1865v1", 
    "author": "Ramesh Raskar", 
    "publish": "2011-09-09T00:33:10Z", 
    "summary": "Computational photography involves sophisticated capture methods. A new trend\nis to capture projection of higher dimensional visual signals such as videos,\nmulti-spectral data and lightfields on lower dimensional sensors. Carefully\ndesigned capture methods exploit the sparsity of the underlying signal in a\ntransformed domain to reduce the number of measurements and use an appropriate\nreconstruction method. Traditional progressive methods may capture successively\nmore detail using a sequence of simple projection basis, such as DCT or\nwavelets and employ straightforward backprojection for reconstruction.\nRandomized projection methods do not use any specific sequence and use L0\nminimization for reconstruction. In this paper, we analyze the statistical\nproperties of natural images, videos, multi-spectral data and light-fields and\ncompare the effectiveness of progressive and random projections. We define\neffectiveness by plotting reconstruction SNR against compression factor. The\nkey idea is a procedure to measure best-case effectiveness that is fast,\nindependent of specific hardware and independent of the reconstruction\nprocedure. We believe this is the first empirical study to compare different\nlossy capture strategies without the complication of hardware or reconstruction\nambiguity. The scope is limited to linear non-adaptive sensing. The results\nshow that random projections produce significant advantages over other\nprojections only for higher dimensional signals, and suggest more research to\nnascent adaptive and non-linear projection methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2011.1305", 
    "link": "http://arxiv.org/pdf/1109.2449v4", 
    "other_authors": "Jan Funke, Bj\u00f6rn Andres, Fred Hamprecht, Albert Cardona, Matthew Cook", 
    "title": "Multi-Hypothesis CRF-Segmentation of Neural Tissue in Anisotropic EM   Volumes", 
    "arxiv-id": "1109.2449v4", 
    "author": "Matthew Cook", 
    "publish": "2011-09-12T12:57:25Z", 
    "summary": "We present an approach for the joint segmentation and grouping of similar\ncomponents in anisotropic 3D image data and use it to segment neural tissue in\nserial sections electron microscopy (EM) images.\n  We first construct a nested set of neuron segmentation hypotheses for each\nslice. A conditional random field (CRF) then allows us to evaluate both the\ncompatibility of a specific segmentation and a specific inter-slice assignment\nof neuron candidates with the underlying observations. The model is solved\noptimally for an entire image stack simultaneously using integer linear\nprogramming (ILP), which yields the maximum a posteriori solution in amortized\nlinear time in the number of slices.\n  We evaluate the performance of our approach on an annotated sample of the\nDrosophila larva neuropil and show that the consideration of different\nsegmentation hypotheses in each slice leads to a significant improvement in the\nsegmentation and assignment accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2011.1305", 
    "link": "http://arxiv.org/pdf/1109.3126v1", 
    "other_authors": "Evgeniy Martyushev", 
    "title": "A Non-Iterative Solution to the Four-Point Three-Views Pose Problem in   Case of Collinear Cameras", 
    "arxiv-id": "1109.3126v1", 
    "author": "Evgeniy Martyushev", 
    "publish": "2011-09-14T16:24:26Z", 
    "summary": "We give a non-iterative solution to a particular case of the four-point\nthree-views pose problem when three camera centers are collinear. Using the\nwell-known Cayley representation of orthogonal matrices, we derive from the\nepipolar constraints a system of three polynomial equations in three variables.\nThe eliminant of that system is a multiple of a 36th degree univariate\npolynomial. The true (unique) solution to the problem can be expressed in terms\nof one of real roots of that polynomial. Experiments on synthetic data confirm\nthat our method is robust enough even in case of planar configurations."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2011.1305", 
    "link": "http://arxiv.org/pdf/1109.3317v1", 
    "other_authors": "Ayatullah Faruk Mollah, Nabamita Majumder, Subhadip Basu, Mita Nasipuri", 
    "title": "Design of an Optical Character Recognition System for Camera-based   Handheld Devices", 
    "arxiv-id": "1109.3317v1", 
    "author": "Mita Nasipuri", 
    "publish": "2011-09-15T11:24:41Z", 
    "summary": "This paper presents a complete Optical Character Recognition (OCR) system for\ncamera captured image/graphics embedded textual documents for handheld devices.\nAt first, text regions are extracted and skew corrected. Then, these regions\nare binarized and segmented into lines and characters. Characters are passed\ninto the recognition module. Experimenting with a set of 100 business card\nimages, captured by cell phone camera, we have achieved a maximum recognition\naccuracy of 92.74%. Compared to Tesseract, an open source desktop-based\npowerful OCR engine, present recognition accuracy is worth contributing.\nMoreover, the developed technique is computationally efficient and consumes low\nmemory so as to be applicable on handheld devices."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2202673", 
    "link": "http://arxiv.org/pdf/1109.3637v1", 
    "other_authors": "Rui F. C. Guerreiro, Pedro M. Q. Aguiar", 
    "title": "Connectivity-Enforcing Hough Transform for the Robust Extraction of Line   Segments", 
    "arxiv-id": "1109.3637v1", 
    "author": "Pedro M. Q. Aguiar", 
    "publish": "2011-09-16T14:56:25Z", 
    "summary": "Global voting schemes based on the Hough transform (HT) have been widely used\nto robustly detect lines in images. However, since the votes do not take line\nconnectivity into account, these methods do not deal well with cluttered\nimages. In opposition, the so-called local methods enforce connectivity but\nlack robustness to deal with challenging situations that occur in many\nrealistic scenarios, e.g., when line segments cross or when long segments are\ncorrupted. In this paper, we address the critical limitations of the HT as a\nline segment extractor by incorporating connectivity in the voting process.\nThis is done by only accounting for the contributions of edge points lying in\nincreasingly larger neighborhoods and whose position and directional content\nagree with potential line segments. As a result, our method, which we call\nSTRAIGHT (Segment exTRAction by connectivity-enforcInG HT), extracts the\nlongest connected segments in each location of the image, thus also integrating\ninto the HT voting process the usually separate step of individual segment\nextraction. The usage of the Hough space mapping and a corresponding\nhierarchical implementation make our approach computationally feasible. We\npresent experiments that illustrate, with synthetic and real images, how\nSTRAIGHT succeeds in extracting complete segments in several situations where\ncurrent methods fail."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2202673", 
    "link": "http://arxiv.org/pdf/1109.3767v1", 
    "other_authors": "Othman Ahmad", 
    "title": "Generalised Object Detection and Semantic Analysis: Casino Example using   Matlab", 
    "arxiv-id": "1109.3767v1", 
    "author": "Othman Ahmad", 
    "publish": "2011-09-17T10:09:02Z", 
    "summary": "Matlab version 7.1 had been used to detect playing cards on a Casino table\nand the suits and ranks of these cards had been identified. The process gives\nan example of an application of computer vision to a problem where rectangular\nobjects are to be detected and the information content of the objects are\nextracted out. In the case of playing cards, it is the suit and rank of each\ncard. The image processing system is done in two passes. Pass 1 detects\nrectangular shapes and template matched with a template of the left and right\nedges of the cards. Pass 2 extracts the suit and rank of the cards by matching\nthe top left portion of the card that contains both rank and suit information,\nwith stored templates of ranks and suits of the playing cards using a series of\nif-then statements."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2202673", 
    "link": "http://arxiv.org/pdf/1109.3850v1", 
    "other_authors": "Dae-Woong Lee", 
    "title": "On the digital homology groups of digital images", 
    "arxiv-id": "1109.3850v1", 
    "author": "Dae-Woong Lee", 
    "publish": "2011-09-18T07:48:36Z", 
    "summary": "In this article we study the digital homology groups of digital images which\nare based on the singular homology groups of topological spaces in algebraic\ntopology. Specifically, we define a digitally standard $n$-simplex, a digitally\nsingular $n$-simplex, and the digital homology groups of digital images with\n$k$-adjacency relations. We then construct a covariant functor from a category\nof digital images and digitally continuous functions to the one of abelian\ngroups and group homomorphisms, and investigate some fundamental and\ninteresting properties of digital homology groups of digital images, such as\nthe digital version of the dimension axiom which is one of the\nEilenberg-Steenrod axioms."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2202673", 
    "link": "http://arxiv.org/pdf/1109.4683v1", 
    "other_authors": "Alper Ayvaci, Stefano Soatto", 
    "title": "Detachable Object Detection: Segmentation and Depth Ordering From   Short-Baseline Video", 
    "arxiv-id": "1109.4683v1", 
    "author": "Stefano Soatto", 
    "publish": "2011-09-22T00:55:32Z", 
    "summary": "We describe an approach for segmenting an image into regions that correspond\nto surfaces in the scene that are partially surrounded by the medium. It\nintegrates both appearance and motion statistics into a cost functional, that\nis seeded with occluded regions and minimized efficiently by solving a linear\nprogramming problem. Where a short observation time is insufficient to\ndetermine whether the object is detachable, the results of the minimization can\nbe used to seed a more costly optimization based on a longer sequence of video\ndata. The result is an entirely unsupervised scheme to detect and segment an\narbitrary and unknown number of objects. We test our scheme to highlight the\npotential, as well as limitations, of our approach."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2202673", 
    "link": "http://arxiv.org/pdf/1109.4744v1", 
    "other_authors": "S. Deepak Srinivasan, Klaus Obermayer", 
    "title": "Probabilistic prototype models for attributed graphs", 
    "arxiv-id": "1109.4744v1", 
    "author": "Klaus Obermayer", 
    "publish": "2011-09-22T09:26:23Z", 
    "summary": "This contribution proposes a new approach towards developing a class of\nprobabilistic methods for classifying attributed graphs. The key concept is\nrandom attributed graph, which is defined as an attributed graph whose nodes\nand edges are annotated by random variables. Every node/edge has two random\nprocesses associated with it- occurence probability and the probability\ndistribution over the attribute values. These are estimated within the maximum\nlikelihood framework. The likelihood of a random attributed graph to generate\nan outcome graph is used as a feature for classification. The proposed approach\nis fast and robust to noise."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2202673", 
    "link": "http://arxiv.org/pdf/1109.4909v1", 
    "other_authors": "Chris Slaughter, Allen Y. Yang, Justin Bagwell, Costa Checkles, Luis Sentis, Sriram Vishwanath", 
    "title": "Sparse Online Low-Rank Projection and Outlier Rejection (SOLO) for 3-D   Rigid-Body Motion Registration", 
    "arxiv-id": "1109.4909v1", 
    "author": "Sriram Vishwanath", 
    "publish": "2011-09-22T18:41:00Z", 
    "summary": "Motivated by an emerging theory of robust low-rank matrix representation, in\nthis paper, we introduce a novel solution for online rigid-body motion\nregistration. The goal is to develop algorithmic techniques that enable a\nrobust, real-time motion registration solution suitable for low-cost, portable\n3-D camera devices. Assuming 3-D image features are tracked via a standard\ntracker, the algorithm first utilizes Robust PCA to initialize a low-rank shape\nrepresentation of the rigid body. Robust PCA finds the global optimal solution\nof the initialization, while its complexity is comparable to singular value\ndecomposition. In the online update stage, we propose a more efficient\nalgorithm for sparse subspace projection to sequentially project new feature\nobservations onto the shape subspace. The lightweight update stage guarantees\nthe real-time performance of the solution while maintaining good registration\neven when the image sequence is contaminated by noise, gross data corruption,\noutlying features, and missing data. The state-of-the-art accuracy of the\nsolution is validated through extensive simulation and a real-world experiment,\nwhile the system enjoys one to two orders of magnitude speed-up compared to\nwell-established RANSAC solutions. The new algorithm will be released online to\naid peer evaluation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2198222", 
    "link": "http://arxiv.org/pdf/1109.5114v3", 
    "other_authors": "Kunal N. Chaudhury, Sebanti Sanyal", 
    "title": "Improvements on \"Fast space-variant elliptical filtering using box   splines\"", 
    "arxiv-id": "1109.5114v3", 
    "author": "Sebanti Sanyal", 
    "publish": "2011-09-23T15:43:21Z", 
    "summary": "It is well-known that box filters can be efficiently computed using\npre-integrations and local finite-differences\n[Crow1984,Heckbert1986,Viola2001]. By generalizing this idea and by combining\nit with a non-standard variant of the Central Limit Theorem, a constant-time or\nO(1) algorithm was proposed in [Chaudhury2010] that allowed one to perform\nspace-variant filtering using Gaussian-like kernels. The algorithm was based on\nthe observation that both isotropic and anisotropic Gaussians could be\napproximated using certain bivariate splines called box splines. The attractive\nfeature of the algorithm was that it allowed one to continuously control the\nshape and size (covariance) of the filter, and that it had a fixed\ncomputational cost per pixel, irrespective of the size of the filter. The\nalgorithm, however, offered a limited control on the covariance and accuracy of\nthe Gaussian approximation. In this work, we propose some improvements by\nappropriately modifying the algorithm in [Chaudhury2010]."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2189578", 
    "link": "http://arxiv.org/pdf/1109.5453v4", 
    "other_authors": "Takayuki Katsuki, Akira Torii, Masato Inoue", 
    "title": "Posterior Mean Super-resolution with a Causal Gaussian Markov Random   Field Prior", 
    "arxiv-id": "1109.5453v4", 
    "author": "Masato Inoue", 
    "publish": "2011-09-26T06:23:09Z", 
    "summary": "We propose a Bayesian image super-resolution (SR) method with a causal\nGaussian Markov random field (MRF) prior. SR is a technique to estimate a\nspatially high-resolution image from given multiple low-resolution images. An\nMRF model with the line process supplies a preferable prior for natural images\nwith edges. We improve the existing image transformation model, the compound\nMRF model, and its hyperparameter prior model. We also derive the optimal\nestimator -- not the joint maximum a posteriori (MAP) or marginalized maximum\nlikelihood (ML), but the posterior mean (PM) -- from the objective function of\nthe L2-norm (mean square error) -based peak signal-to-noise ratio (PSNR). Point\nestimates such as MAP and ML are generally not stable in ill-posed\nhigh-dimensional problems because of overfitting, while PM is a stable\nestimator because all the parameters in the model are evaluated as\ndistributions. The estimator is numerically determined by using variational\nBayes. Variational Bayes is a widely used method that approximately determines\na complicated posterior distribution, but it is generally hard to use because\nit needs the conjugate prior. We solve this problem with simple Taylor\napproximations. Experimental results have shown that the proposed method is\nmore accurate or comparable to existing methods."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2189578", 
    "link": "http://arxiv.org/pdf/1109.6442v2", 
    "other_authors": "Ankit Chaudhary, Jagdish L. Raheja", 
    "title": "ABHIVYAKTI: A Vision Based Intelligent System for Elder and Sick Persons", 
    "arxiv-id": "1109.6442v2", 
    "author": "Jagdish L. Raheja", 
    "publish": "2011-09-29T08:59:29Z", 
    "summary": "This paper describes an intelligent system ABHIVYAKTI, which would be\npervasive in nature and based on the Computer Vision. It would be very easy in\nuse and deployment. Elder and sick people who are not able to talk or walk,\nthey are dependent on other human beings and need continuous monitoring, while\nour system provides flexibility to the sick or elder person to announce his or\nher need to their caretaker by just showing a particular gesture with the\ndeveloped system, if the caretaker is not nearby. This system will use\nfingertip detection techniques for acquiring gesture and Artificial Neural\nNetworks (ANNs) will be used for gesture recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2189578", 
    "link": "http://arxiv.org/pdf/1109.6840v1", 
    "other_authors": "Sumita Mishra", 
    "title": "A Novel comprehensive method for real time Video Motion Detection   Surveillance", 
    "arxiv-id": "1109.6840v1", 
    "author": "Sumita Mishra", 
    "publish": "2011-09-30T14:48:51Z", 
    "summary": "This article describes a comprehensive system for surveillance and monitoring\napplications. The development of an efficient real time video motion detection\nsystem is motivated by their potential for deployment in the areas where\nsecurity is the main concern. The paper presents a platform for real time video\nmotion detection and subsequent generation of an alarm condition as set by the\nparameters of the control system. The prototype consists of a mobile platform\nmounted with RF camera which provides continuous feedback of the environment.\nThe received visual information is then analyzed by user for appropriate\ncontrol action, thus enabling the user to operate the system from a remote\nlocation. The system is also equipped with the ability to process the image of\nan object and generate control signals which are automatically transmitted to\nthe mobile platform to track the object."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2189578", 
    "link": "http://arxiv.org/pdf/1111.0885v1", 
    "other_authors": "Roozbeh Rajabi, Mahdi Khodadadzadeh, Hassan Ghassemian", 
    "title": "Graph Regularized Nonnegative Matrix Factorization for Hyperspectral   Data Unmixing", 
    "arxiv-id": "1111.0885v1", 
    "author": "Hassan Ghassemian", 
    "publish": "2011-11-03T15:46:47Z", 
    "summary": "Spectral unmixing is an important tool in hyperspectral data analysis for\nestimating endmembers and abundance fractions in a mixed pixel. This paper\nexamines the applicability of a recently developed algorithm called graph\nregularized nonnegative matrix factorization (GNMF) for this aim. The proposed\napproach exploits the intrinsic geometrical structure of the data besides\nconsidering positivity and full additivity constraints. Simulated data based on\nthe measured spectral signatures, is used for evaluating the proposed\nalgorithm. Results in terms of abundance angle distance (AAD) and spectral\nangle distance (SAD) show that this method can effectively unmix hyperspectral\ndata."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2189578", 
    "link": "http://arxiv.org/pdf/1111.1014v1", 
    "other_authors": "John Wright, Arvind Ganesh, Allen Yang, Zihan Zhou, Yi Ma", 
    "title": "Sparsity and Robustness in Face Recognition", 
    "arxiv-id": "1111.1014v1", 
    "author": "Yi Ma", 
    "publish": "2011-11-03T23:50:36Z", 
    "summary": "This report concerns the use of techniques for sparse signal representation\nand sparse error correction for automatic face recognition. Much of the recent\ninterest in these techniques comes from the paper \"Robust Face Recognition via\nSparse Representation\" by Wright et al. (2009), which showed how, under certain\ntechnical conditions, one could cast the face recognition problem as one of\nseeking a sparse representation of a given input face image in terms of a\n\"dictionary\" of training images and images of individual pixels. In this\nreport, we have attempted to clarify some frequently encountered questions\nabout this work and particularly, on the validity of using sparse\nrepresentation techniques for face recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2189578", 
    "link": "http://arxiv.org/pdf/1111.1090v1", 
    "other_authors": "Divya Jyoti, Aman Chadha, Pallavi Vaidya, M. Mani Roja", 
    "title": "A robust, low-cost approach to Face Detection and Face Recognition", 
    "arxiv-id": "1111.1090v1", 
    "author": "M. Mani Roja", 
    "publish": "2011-11-04T10:36:43Z", 
    "summary": "In the domain of Biometrics, recognition systems based on iris, fingerprint\nor palm print scans etc. are often considered more dependable due to extremely\nlow variance in the properties of these entities with respect to time. However,\nover the last decade data processing capability of computers has increased\nmanifold, which has made real-time video content analysis possible. This shows\nthat the need of the hour is a robust and highly automated Face Detection and\nRecognition algorithm with credible accuracy rate. The proposed Face Detection\nand Recognition system using Discrete Wavelet Transform (DWT) accepts face\nframes as input from a database containing images from low cost devices such as\nVGA cameras, webcams or even CCTV's, where image quality is inferior. Face\nregion is then detected using properties of L*a*b* color space and only Frontal\nFace is extracted such that all additional background is eliminated. Further,\nthis extracted image is converted to grayscale and its dimensions are resized\nto 128 x 128 pixels. DWT is then applied to entire image to obtain the\ncoefficients. Recognition is carried out by comparison of the DWT coefficients\nbelonging to the test image with those of the registered reference image. On\ncomparison, Euclidean distance classifier is deployed to validate the test\nimage from the database. Accuracy for various levels of DWT Decomposition is\nobtained and hence, compared."
},{
    "category": "cs.CV", 
    "doi": "10.2478/s13540-012-0024-1", 
    "link": "http://arxiv.org/pdf/1111.1311v1", 
    "other_authors": "Richard Herrmann", 
    "title": "Covariant fractional extension of the modified Laplace-operator used in   3D-shape recovery", 
    "arxiv-id": "1111.1311v1", 
    "author": "Richard Herrmann", 
    "publish": "2011-11-05T14:09:05Z", 
    "summary": "Extending the Liouville-Caputo definition of a fractional derivative to a\nnonlocal covariant generalization of arbitrary bound operators acting on\nmultidimensional Riemannian spaces an appropriate approach for the 3D shape\nrecovery of aperture afflicted 2D slide sequences is proposed. We demonstrate,\nthat the step from a local to a nonlocal algorithm yields an order of magnitude\nin accuracy and by using the specific fractional approach an additional factor\n2 in accuracy of the derived results."
},{
    "category": "cs.CV", 
    "doi": "10.2478/s13540-012-0024-1", 
    "link": "http://arxiv.org/pdf/1111.1461v1", 
    "other_authors": "Michael M. Bronstein", 
    "title": "Multimodal diff-hash", 
    "arxiv-id": "1111.1461v1", 
    "author": "Michael M. Bronstein", 
    "publish": "2011-11-07T00:28:37Z", 
    "summary": "Many applications require comparing multimodal data with different structure\nand dimensionality that cannot be compared directly. Recently, there has been\nincreasing interest in methods for learning and efficiently representing such\nmultimodal similarity. In this paper, we present a simple algorithm for\nmultimodal similarity-preserving hashing, trying to map multimodal data into\nthe Hamming space while preserving the intra- and inter-modal similarities. We\nshow that our method significantly outperforms the state-of-the-art method in\nthe field."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3506", 
    "link": "http://arxiv.org/pdf/1111.1562v1", 
    "other_authors": "M. Y. Shams, M. Z. Rashad, O. Nomir, R. M. El-Awady", 
    "title": "Iris Recognition Based on LBP and Combined LVQ Classifier", 
    "arxiv-id": "1111.1562v1", 
    "author": "R. M. El-Awady", 
    "publish": "2011-11-07T12:35:29Z", 
    "summary": "Iris recognition is considered as one of the best biometric methods used for\nhuman identification and verification, this is because of its unique features\nthat differ from one person to another, and its importance in the security\nfield. This paper proposes an algorithm for iris recognition and classification\nusing a system based on Local Binary Pattern and histogram properties as a\nstatistical approaches for feature extraction, and Combined Learning Vector\nQuantization Classifier as Neural Network approach for classification, in order\nto build a hybrid model depends on both features. The localization and\nsegmentation techniques are presented using both Canny edge detection and Hough\nCircular Transform in order to isolate an iris from the whole eye image and for\nnoise detection .Feature vectors results from LBP is applied to a Combined LVQ\nclassifier with different classes to determine the minimum acceptable\nperformance, and the result is based on majority voting among several LVQ\nclassifier. Different iris datasets CASIA, MMU1, MMU2, and LEI with different\nextensions and size are presented. Since LBP is working on a grayscale level so\ncolored iris images should be transformed into a grayscale level. The proposed\nsystem gives a high recognition rate 99.87 % on different iris datasets\ncompared with other methods."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3506", 
    "link": "http://arxiv.org/pdf/1111.1599v1", 
    "other_authors": "Colin S. Lea, Jason J. Corso", 
    "title": "Efficient Hierarchical Markov Random Fields for Object Detection on a   Mobile Robot", 
    "arxiv-id": "1111.1599v1", 
    "author": "Jason J. Corso", 
    "publish": "2011-11-07T14:46:16Z", 
    "summary": "Object detection and classification using video is necessary for intelligent\nplanning and navigation on a mobile robot. However, current methods can be too\nslow or not sufficient for distinguishing multiple classes. Techniques that\nrely on binary (foreground/background) labels incorrectly identify areas with\nmultiple overlapping objects as single segment. We propose two Hierarchical\nMarkov Random Field models in efforts to distinguish connected objects using\ntiered, binary label sets. Near-realtime performance has been achieved using\nefficient optimization methods which runs up to 11 frames per second on a dual\ncore 2.2 Ghz processor. Evaluation of both models is done using footage taken\nfrom a robot obstacle course at the 2010 Intelligent Ground Vehicle\nCompetition."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.1752v1", 
    "other_authors": "Abdelghni Lakehal, Omar El Beqqali", 
    "title": "New Method for 3D Shape Retrieval", 
    "arxiv-id": "1111.1752v1", 
    "author": "Omar El Beqqali", 
    "publish": "2011-11-07T21:24:36Z", 
    "summary": "The recent technological progress in acquisition, modeling and processing of\n3D data leads to the proliferation of a large number of 3D objects databases.\nConsequently, the techniques used for content based 3D retrieval has become\nnecessary. In this paper, we introduce a new method for 3D objects recognition\nand retrieval by using a set of binary images CLI (Characteristic level\nimages). We propose a 3D indexing and search approach based on the similarity\nbetween characteristic level images using Hu moments for it indexing. To\nmeasure the similarity between 3D objects we compute the Hausdorff distance\nbetween a vectors descriptor. The performance of this new approach is evaluated\nat set of 3D object of well known database, is NTU (National Taiwan University)\ndatabase."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.1947v1", 
    "other_authors": "Yi Chen, Umamahesh Srinivas, Thong T. Do, Vishal Monga, Trac D. Tran", 
    "title": "Discriminative Local Sparse Representations for Robust Face Recognition", 
    "arxiv-id": "1111.1947v1", 
    "author": "Trac D. Tran", 
    "publish": "2011-11-08T16:04:58Z", 
    "summary": "A key recent advance in face recognition models a test face image as a sparse\nlinear combination of a set of training face images. The resulting sparse\nrepresentations have been shown to possess robustness against a variety of\ndistortions like random pixel corruption, occlusion and disguise. This approach\nhowever makes the restrictive (in many scenarios) assumption that test faces\nmust be perfectly aligned (or registered) to the training data prior to\nclassification. In this paper, we propose a simple yet robust local block-based\nsparsity model, using adaptively-constructed dictionaries from local features\nin the training data, to overcome this misalignment problem. Our approach is\ninspired by human perception: we analyze a series of local discriminative\nfeatures and combine them to arrive at the final classification decision. We\npropose a probabilistic graphical model framework to explicitly mine the\nconditional dependencies between these distinct sparse local features. In\nparticular, we learn discriminative graphs on sparse representations obtained\nfrom distinct local slices of a face. Conditional correlations between these\nsparse features are first discovered (in the training phase), and subsequently\nexploited to bring about significant improvements in recognition rates.\nExperimental results obtained on benchmark face databases demonstrate the\neffectiveness of the proposed algorithms in the presence of multiple\nregistration errors (such as translation, rotation, and scaling) as well as\nunder variations of pose and illumination."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.2391v1", 
    "other_authors": "B. Vijayalakshmi, V. Subbiah Bharathi", 
    "title": "A Novel Approach to Texture classification using statistical feature", 
    "arxiv-id": "1111.2391v1", 
    "author": "V. Subbiah Bharathi", 
    "publish": "2011-11-10T04:28:08Z", 
    "summary": "Texture is an important spatial feature which plays a vital role in content\nbased image retrieval. The enormous growth of the internet and the wide use of\ndigital data have increased the need for both efficient image database creation\nand retrieval procedure. This paper describes a new approach for texture\nclassification by combining statistical texture features of Local Binary\nPattern and Texture spectrum. Since most significant information of a texture\noften appears in the high frequency channels, the features are extracted by the\ncomputation of LBP and Texture Spectrum and Legendre Moments. Euclidean\ndistance is used for similarity measurement. The experimental result shows that\n97.77% classification accuracy is obtained by the proposed method."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.3818v1", 
    "other_authors": "Martin H\u00fcnniger", 
    "title": "Good Pairs of Adjacency Relations in Arbitrary Dimensions", 
    "arxiv-id": "1111.3818v1", 
    "author": "Martin H\u00fcnniger", 
    "publish": "2011-11-16T14:37:07Z", 
    "summary": "In this text we show, that the notion of a \"good pair\" that was introduced in\nthe paper \"Digital Manifolds and the Theorem of Jordan-Brouwer\" has actually\nknown models. We will show, how to choose cubical adjacencies, the\ngeneralizations of the well known 4- and 8-neighborhood to arbitrary\ndimensions, in order to find good pairs. Furthermore, we give another proof for\nthe well known fact that the Khalimsky-topology implies good pairs. The outcome\nis consistent with the known theory as presented by T.Y. Kong, A. Rosenfeld,\nG.T. Herman and M. Khachan et.al and gives new insights in higher dimensions."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.4052v1", 
    "other_authors": "Le Hoang Thai, Nguyen Do Thai Nguyen, Tran Son Hai", 
    "title": "A Facial Expression Classification System Integrating Canny, Principal   Component Analysis and Artificial Neural Network", 
    "arxiv-id": "1111.4052v1", 
    "author": "Tran Son Hai", 
    "publish": "2011-11-17T10:43:08Z", 
    "summary": "Facial Expression Classification is an interesting research problem in recent\nyears. There are a lot of methods to solve this problem. In this research, we\npropose a novel approach using Canny, Principal Component Analysis (PCA) and\nArtificial Neural Network. Firstly, in preprocessing phase, we use Canny for\nlocal region detection of facial images. Then each of local region's features\nwill be presented based on Principal Component Analysis (PCA). Finally, using\nArtificial Neural Network (ANN)applies for Facial Expression Classification. We\napply our proposal method (Canny_PCA_ANN) for recognition of six basic facial\nexpressions on JAFFE database consisting 213 images posed by 10 Japanese female\nmodels. The experimental result shows the feasibility of our proposal method."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.4290v1", 
    "other_authors": "B. V. Dhandra, R. G. Benne, Mallikarjun Hangarge", 
    "title": "A Single Euler Number Feature for Multi-font Multi-size Kannada Numeral   Recognition", 
    "arxiv-id": "1111.4290v1", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2011-11-18T06:34:07Z", 
    "summary": "In this paper a novel approach is proposed based on single Euler number\nfeature which is free from thinning and size normalization for multi-font and\nmulti-size Kannada numeral recognition system. A nearest neighbor\nclassification is used for classification of Kannada numerals by considering\nthe Euclidian distance. A total 1500 numeral images with different font sizes\nbetween (10..84) are tested for algorithm efficiency and the overall the\nclassification accuracy is found to be 99.00% .The said method is thinning\nfree, fast, and showed encouraging results on varying font styles and sizes of\nKannada numerals."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcsit.2011.3508", 
    "link": "http://arxiv.org/pdf/1111.4291v1", 
    "other_authors": "B. V. Dhandra, R. G. Benne, Mallikarjun Hangarge", 
    "title": "Multi-font Multi-size Kannada Numeral Recognition Based on Structural   Features", 
    "arxiv-id": "1111.4291v1", 
    "author": "Mallikarjun Hangarge", 
    "publish": "2011-11-18T06:59:35Z", 
    "summary": "In this paper a fast and novel method is proposed for multi-font multi-size\nKannada numeral recognition which is thinning free and without size\nnormalization approach. The different structural feature are used for numeral\nrecognition namely, directional density of pixels in four directions, water\nreservoirs, maximum profile distances, and fill hole density are used for the\nrecognition of Kannada numerals. A Euclidian minimum distance criterion is used\nto find minimum distances and K-nearest neighbor classifier is used to classify\nthe Kannada numerals by varying the size of numeral image from 16 to 50 font\nsizes for the 20 different font styles from NUDI and BARAHA popular word\nprocessing Kannada software. The total 1150 numeral images are tested and the\noverall accuracy of classification is found to be 100%. The average time taken\nby this method is 0.1476 seconds."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.4619v1", 
    "other_authors": "Idan Ram, Michael Elad, Israel Cohen", 
    "title": "Redundant Wavelets on Graphs and High Dimensional Data Clouds", 
    "arxiv-id": "1111.4619v1", 
    "author": "Israel Cohen", 
    "publish": "2011-11-20T08:58:45Z", 
    "summary": "In this paper, we propose a new redundant wavelet transform applicable to\nscalar functions defined on high dimensional coordinates, weighted graphs and\nnetworks. The proposed transform utilizes the distances between the given data\npoints. We modify the filter-bank decomposition scheme of the redundant wavelet\ntransform by adding in each decomposition level linear operators that reorder\nthe approximation coefficients. These reordering operators are derived by\norganizing the tree-node features so as to shorten the path that passes through\nthese points. We explore the use of the proposed transform to image denoising,\nand show that it achieves denoising results that are close to those obtained\nwith the BM3D algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.4654v1", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "A self-portrait of young Leonardo", 
    "arxiv-id": "1111.4654v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2011-11-20T17:41:01Z", 
    "summary": "One of the most famous drawings by Leonardo da Vinci is a self-portrait in\nred chalk, where he looks quite old. In fact, there is a sketch in one of his\nnotebooks, partially covered by written notes, that can be a self-portrait of\nthe artist when he was young. The use of image processing, to remove the\nhandwritten text and improve the image, allows a comparison of the two\nportraits."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.4676v1", 
    "other_authors": "Andrew Pickin", 
    "title": "Facial Asymmetry and Emotional Expression", 
    "arxiv-id": "1111.4676v1", 
    "author": "Andrew Pickin", 
    "publish": "2011-11-20T20:55:07Z", 
    "summary": "This report is about facial asymmetry, its connection to emotional\nexpression, and methods of measuring facial asymmetry in videos of faces. The\nresearch was motivated by two factors: firstly, there was a real opportunity to\ndevelop a novel measure of asymmetry that required minimal human involvement\nand that improved on earlier measures in the literature; and secondly, the\nstudy of the relationship between facial asymmetry and emotional expression is\nboth interesting in its own right, and important because it can inform\nneuropsychological theory and answer open questions concerning emotional\nprocessing in the brain. The two aims of the research were: first, to develop\nan automatic frame-by-frame measure of facial asymmetry in videos of faces that\nimproved on previous measures; and second, to use the measure to analyse the\nrelationship between facial asymmetry and emotional expression, and connect our\nfindings with previous research of the relationship."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.5108v1", 
    "other_authors": "Sriram Nagaraj, Aswin C. Sankaranarayanan, Richard G. Baraniuk", 
    "title": "A Theory for Optical flow-based Transport on Image Manifolds", 
    "arxiv-id": "1111.5108v1", 
    "author": "Richard G. Baraniuk", 
    "publish": "2011-11-22T05:55:25Z", 
    "summary": "An image articulation manifold (IAM) is the collection of images formed when\nan object is articulated in front of a camera. IAMs arise in a variety of image\nprocessing and computer vision applications, where they provide a natural\nlow-dimensional embedding of the collection of high-dimensional images. To date\nIAMs have been studied as embedded submanifolds of Euclidean spaces.\nUnfortunately, their promise has not been realized in practice, because real\nworld imagery typically contains sharp edges that render an IAM\nnon-differentiable and hence non-isometric to the low-dimensional parameter\nspace under the Euclidean metric. As a result, the standard tools from\ndifferential geometry, in particular using linear tangent spaces to transport\nalong the IAM, have limited utility. In this paper, we explore a nonlinear\ntransport operator for IAMs based on the optical flow between images and\ndevelop new analytical tools reminiscent of those from differential geometry\nusing the idea of optical flow manifolds (OFMs). We define a new metric for\nIAMs that satisfies certain local isometry conditions, and we show how to use\nthis metric to develop a new tools such as flow fields on IAMs, parallel flow\nfields, parallel transport, as well as a intuitive notion of curvature. The\nspace of optical flow fields along a path of constant curvature has a natural\nmulti-scale structure via a monoid structure on the space of all flow fields\nalong a path. We also develop lower bounds on approximation errors while\napproximating non-parallel flow fields by parallel flow fields."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.6030v2", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "An image processing of a Raphael's portrait of Leonardo", 
    "arxiv-id": "1111.6030v2", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2011-11-25T15:46:37Z", 
    "summary": "In one of his paintings, the School of Athens, Raphael is depicting Leonardo\nda Vinci as the philosopher Plato. Some image processing tools can help us in\ncomparing this portrait with two Leonardo's portraits, considered as\nself-portraits."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1111.7271v1", 
    "other_authors": "Rodrigo Nava, Gabriel Crist\u00f3bal, Boris Escalante-Ram\u00edrez", 
    "title": "Invariant texture analysis through Local Binary Patterns", 
    "arxiv-id": "1111.7271v1", 
    "author": "Boris Escalante-Ram\u00edrez", 
    "publish": "2011-11-30T18:58:53Z", 
    "summary": "In many image processing applications, such as segmentation and\nclassification, the selection of robust features descriptors is crucial to\nimprove the discrimination capabilities in real world scenarios. In particular,\nit is well known that image textures constitute power visual cues for feature\nextraction and classification. In the past few years the local binary pattern\n(LBP) approach, a texture descriptor method proposed by Ojala et al., has\ngained increased acceptance due to its computational simplicity and more\nimportantly for encoding a powerful signature for describing textures. However,\nthe original algorithm presents some limitations such as noise sensitivity and\nits lack of rotational invariance which have led to many proposals or\nextensions in order to overcome such limitations. In this paper we performed a\nquantitative study of the Ojala's original LBP proposal together with other\nrecently proposed LBP extensions in the presence of rotational, illumination\nand noisy changes. In the experiments we have considered two different\ndatabases: Brodatz and CUReT for different sizes of LBP masks. Experimental\nresults demonstrated the effectiveness and robustness of the described texture\ndescriptors for images that are subjected to geometric or radiometric changes."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.0216v1", 
    "other_authors": "Fernand Meyer", 
    "title": "The watershed concept and its use in segmentation : a brief history", 
    "arxiv-id": "1202.0216v1", 
    "author": "Fernand Meyer", 
    "publish": "2012-02-01T17:00:45Z", 
    "summary": "The watershed is one of the most used tools in image segmentation. We present\nhow its concept is born and developed over time. Its implementation as an\nalgorithm or a hardwired device evolved together with the technology which\nallowed it. We present also how it is used in practice, first together with\nmarkers, and later introduced in a multiscale framework, in order to produce\nnot a unique partition but a complete hierarchy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.0492v3", 
    "other_authors": "Peter Abeles", 
    "title": "Resolving Implementation Ambiguity and Improving SURF", 
    "arxiv-id": "1202.0492v3", 
    "author": "Peter Abeles", 
    "publish": "2012-02-02T17:10:56Z", 
    "summary": "Speeded Up Robust Features (SURF) has emerged as one of the more popular\nfeature descriptors and detectors in recent years. Performance and algorithmic\ndetails vary widely between implementations due to SURF's complexity and\nambiguities found in its description. To resolve these ambiguities, a set of\ngeneral techniques for feature stability is defined based on the smoothness\nrule. Additional improvements to SURF are proposed for speed and stability. To\nillustrate the importance of these implementation details, a performance study\nof popular SURF implementations is done. By utilizing all the suggested\nimprovements, it is possible to create a SURF implementation that is several\ntimes faster and more stable."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.0549v1", 
    "other_authors": "Gautam S. Thakur, Mohsen Ali, Pan Hui, Ahmed Helmy", 
    "title": "Comparing Background Subtraction Algorithms and Method of Car Counting", 
    "arxiv-id": "1202.0549v1", 
    "author": "Ahmed Helmy", 
    "publish": "2012-01-29T19:19:33Z", 
    "summary": "In this paper, we compare various image background subtraction algorithms\nwith the ground truth of cars counted. We have given a sample of thousand\nimages, which are the snap shots of current traffic as records at various\nintersections and highways. We have also counted an approximate number of cars\nthat are visible in these images. In order to ascertain the accuracy of\nalgorithms to be used for the processing of million images, we compare them on\nmany metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.0609v1", 
    "other_authors": "Roberto Henry Herrera, Rub\u00e9n Orozco, Manuel Rodr\u00edguez", 
    "title": "Wavelet-based deconvolution of ultrasonic signals in nondestructive   evaluation", 
    "arxiv-id": "1202.0609v1", 
    "author": "Manuel Rodr\u00edguez", 
    "publish": "2012-02-03T05:43:46Z", 
    "summary": "In this paper, the inverse problem of reconstructing reflectivity function of\na medium is examined within a blind deconvolution framework. The ultrasound\npulse is estimated using higher-order statistics, and Wiener filter is used to\nobtain the ultrasonic reflectivity function through wavelet-based models. A new\napproach to the parameter estimation of the inverse filtering step is proposed\nin the nondestructive evaluation field, which is based on the theory of\nFourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be\nviewed as a solution to the open problem of adaptation of the ForWaRD framework\nto perform the convolution kernel estimation and deconvolution\ninterdependently. The results indicate stable solutions of the estimated pulse\nand an improvement in the radio-frequency (RF) signal taking into account its\nsignal-to-noise ratio (SNR) and axial resolution. Simulations and experiments\nshowed that the proposed approach can provide robust and optimal estimates of\nthe reflectivity function."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.1587v1", 
    "other_authors": "K. Karteeka Pavan, Allam Appa Rao, A. V. Dattatreya Rao", 
    "title": "Automatic Clustering with Single Optimal Solution", 
    "arxiv-id": "1202.1587v1", 
    "author": "A. V. Dattatreya Rao", 
    "publish": "2012-02-08T03:26:01Z", 
    "summary": "Determining optimal number of clusters in a dataset is a challenging task.\nThough some methods are available, there is no algorithm that produces unique\nclustering solution. The paper proposes an Automatic Merging for Single Optimal\nSolution (AMSOS) which aims to generate unique and nearly optimal clusters for\nthe given datasets automatically. The AMSOS is iteratively merges the closest\nclusters automatically by validating with cluster validity measure to find\nsingle and nearly optimal clusters for the given data set. Experiments on both\nsynthetic and real data have proved that the proposed algorithm finds single\nand nearly optimal clustering structure in terms of number of clusters,\ncompactness and separation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.1685v1", 
    "other_authors": "Valentina E. Balas, Iulia M. Motoc, Alina Barbulescu", 
    "title": "Combined Haar-Hilbert and Log-Gabor Based Iris Encoders", 
    "arxiv-id": "1202.1685v1", 
    "author": "Alina Barbulescu", 
    "publish": "2012-02-08T13:07:10Z", 
    "summary": "This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris\nrecognition performance leading to a less ambiguous biometric decision\nlandscape in which the overlap between the experimental intra- and interclass\nscore distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and\ncombined Haar-Hilbert and Log-Gabor encoders are tested here both for single\nand dual iris approach. The experimental results confirm that the best\nperformance is obtained for the dual iris approach when the iris code is\ngenerated using the combined Haar-Hilbert and Log-Gabor encoder, and when the\nmatching score fuses the information from both Haar-Hilbert and Log-Gabor\nchannels of the combined encoder."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.1943v1", 
    "other_authors": "Srimal Jayawardena, Di Yang, Marcus Hutter", 
    "title": "3D Model Assisted Image Segmentation", 
    "arxiv-id": "1202.1943v1", 
    "author": "Marcus Hutter", 
    "publish": "2012-02-09T10:53:11Z", 
    "summary": "The problem of segmenting a given image into coherent regions is important in\nComputer Vision and many industrial applications require segmenting a known\nobject into its components. Examples include identifying individual parts of a\ncomponent for process control work in a manufacturing plant and identifying\nparts of a car from a photo for automatic damage detection. Unfortunately most\nof an object's parts of interest in such applications share the same pixel\ncharacteristics, having similar colour and texture. This makes segmenting the\nobject into its components a non-trivial task for conventional image\nsegmentation algorithms. In this paper, we propose a \"Model Assisted\nSegmentation\" method to tackle this problem. A 3D model of the object is\nregistered over the given image by optimising a novel gradient based loss\nfunction. This registration obtains the full 3D pose from an image of the\nobject. The image can have an arbitrary view of the object and is not limited\nto a particular set of views. The segmentation is subsequently performed using\na level-set based method, using the projected contours of the registered 3D\nmodel as initialisation curves. The method is fully automatic and requires no\nuser interaction. Also, the system does not require any prior training. We\npresent our results on photographs of a real car."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.1990v1", 
    "other_authors": "Upendra Kumar, Tapobrata Lahiri, Manoj Kumar Pal", 
    "title": "Non-parametric convolution based image-segmentation of ill-posed objects   applying context window approach", 
    "arxiv-id": "1202.1990v1", 
    "author": "Manoj Kumar Pal", 
    "publish": "2012-02-09T14:02:26Z", 
    "summary": "Context-dependence in human cognition process is a well-established fact.\nFollowing this, we introduced the image segmentation method that can use\ncontext to classify a pixel on the basis of its membership to a particular\nobject-class of the concerned image. In the broad methodological steps, each\npixel was defined by its context window (CW) surrounding it the size of which\nwas fixed heuristically. CW texture defined by the intensities of its pixels\nwas convoluted with weights optimized through a non-parametric function\nsupported by a backpropagation network. Result of convolution was used to\nclassify them. The training data points (i.e., pixels) were carefully chosen to\ninclude all variety of contexts of types, i) points within the object, ii)\npoints near the edge but inside the objects, iii) points at the border of the\nobjects, iv) points near the edge but outside the objects, v) points near or at\nthe edge of the image frame. Moreover the training data points were selected\nfrom all the images within image-dataset. CW texture information for 1000\npixels from face area and background area of images were captured, out of which\n700 CWs were used as training input data, and remaining 300 for testing. Our\nwork gives the first time foundation of quantitative enumeration of efficiency\nof image-segmentation which is extendable to segment out more than 2 objects\nwithin an image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2190983", 
    "link": "http://arxiv.org/pdf/1202.2528v1", 
    "other_authors": "Kevin Mader, Gil Reese", 
    "title": "Using Covariance Matrices as Feature Descriptors for Vehicle Detection   from a Fixed Camera", 
    "arxiv-id": "1202.2528v1", 
    "author": "Gil Reese", 
    "publish": "2012-02-12T13:40:11Z", 
    "summary": "A method is developed to distinguish between cars and trucks present in a\nvideo feed of a highway. The method builds upon previously done work using\ncovariance matrices as an accurate descriptor for regions. Background\nsubtraction and other similar proven image processing techniques are used to\nidentify the regions where the vehicles are most likely to be, and a distance\nmetric comparing the vehicle inside the region to a fixed library of vehicles\nis used to determine the class of vehicle."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.3021v1", 
    "other_authors": "Salvador Gabarda, Gabriel Cristobal", 
    "title": "No-reference image quality assessment through the von Mises distribution", 
    "arxiv-id": "1202.3021v1", 
    "author": "Gabriel Cristobal", 
    "publish": "2012-02-14T12:50:35Z", 
    "summary": "An innovative way of calculating the von Mises distribution (VMD) of image\nentropy is introduced in this paper. The VMD's concentration parameter and some\nfitness parameter that will be later defined, have been analyzed in the\nexperimental part for determining their suitability as a image quality\nassessment measure in some particular distortions such as Gaussian blur or\nadditive Gaussian noise. To achieve such measure, the local R\\'{e}nyi entropy\nis calculated in four equally spaced orientations and used to determine the\nparameters of the von Mises distribution of the image entropy. Considering\ncontextual images, experimental results after applying this model show that the\nbest-in-focus noise-free images are associated with the highest values for the\nvon Mises distribution concentration parameter and the highest approximation of\nimage data to the von Mises distribution model. Our defined von Misses fitness\nparameter experimentally appears also as a suitable no-reference image quality\nassessment indicator for no-contextual images."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.3684v1", 
    "other_authors": "Marius Leordeanu, Rahul Sukthankar, Cristian Sminchisescu", 
    "title": "Generalized Boundaries from Multiple Image Interpretations", 
    "arxiv-id": "1202.3684v1", 
    "author": "Cristian Sminchisescu", 
    "publish": "2012-02-16T20:08:11Z", 
    "summary": "Boundary detection is essential for a variety of computer vision tasks such\nas segmentation and recognition. In this paper we propose a unified formulation\nand a novel algorithm that are applicable to the detection of different types\nof boundaries, such as intensity edges, occlusion boundaries or object category\nspecific boundaries. Our formulation leads to a simple method with\nstate-of-the-art performance and significantly lower computational cost than\nexisting methods. We evaluate our algorithm on different types of boundaries,\nfrom low-level boundaries extracted in natural images, to occlusion boundaries\nobtained using motion cues and RGB-D cameras, to boundaries from\nsoft-segmentation. We also propose a novel method for figure/ground\nsoft-segmentation that can be used in conjunction with our boundary detection\nmethod and improve its accuracy at almost no extra computational cost."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.3884v1", 
    "other_authors": "Dinesh Dileep Gaurav, Renu Ramesh", 
    "title": "A feature extraction technique based on character geometry for character   recognition", 
    "arxiv-id": "1202.3884v1", 
    "author": "Renu Ramesh", 
    "publish": "2012-02-17T11:41:28Z", 
    "summary": "This paper describes a geometry based technique for feature extraction\napplicable to segmentation-based word recognition systems. The proposed system\nextracts the geometric features of the character contour. This features are\nbased on the basic line types that forms the character skeleton. The system\ngives a feature vector as its output. The feature vectors so generated from a\ntraining set, were then used to train a pattern recognition engine based on\nNeural Networks so that the system can be benchmarked."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.29.002058", 
    "link": "http://arxiv.org/pdf/1202.4107v1", 
    "other_authors": "Scott A. Hale", 
    "title": "Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin   Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition   of Whale Images on a Network)", 
    "arxiv-id": "1202.4107v1", 
    "author": "Scott A. Hale", 
    "publish": "2012-02-18T21:42:24Z", 
    "summary": "At least two software packages---DARWIN, Eckerd College, and FinScan, Texas\nA&M---exist to facilitate the identification of cetaceans---whales, dolphins,\nporpoises---based upon the naturally occurring features along the edges of\ntheir dorsal fins. Such identification is useful for biological studies of\npopulation, social interaction, migration, etc. The process whereby fin\noutlines are extracted in current fin-recognition software packages is manually\nintensive and represents a major user input bottleneck: it is both time\nconsuming and visually fatiguing. This research aims to develop automated\nmethods (employing unsupervised thresholding and morphological processing\ntechniques) to extract cetacean dorsal fin outlines from digital photographs\nthereby reducing manual user input. Ideally, automatic outline generation will\nimprove the overall user experience and improve the ability of the software to\ncorrectly identify cetaceans. Various transformations from color to gray space\nwere examined to determine which produced a grayscale image in which a suitable\nthreshold could be easily identified. To assist with unsupervised thresholding,\na new metric was developed to evaluate the jaggedness of figures (\"pixelarity\")\nin an image after thresholding. The metric indicates how cleanly a threshold\nsegments background and foreground elements and hence provides a good measure\nof the quality of a given threshold. This research results in successful\nextractions in roughly 93% of images, and significantly reduces user-input\ntime."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2235849", 
    "link": "http://arxiv.org/pdf/1202.4207v2", 
    "other_authors": "Meng Yang, Lei Zhang, Jian Yang, David Zhang", 
    "title": "Regularized Robust Coding for Face Recognition", 
    "arxiv-id": "1202.4207v2", 
    "author": "David Zhang", 
    "publish": "2012-02-20T02:02:26Z", 
    "summary": "Recently the sparse representation based classification (SRC) has been\nproposed for robust face recognition (FR). In SRC, the testing image is coded\nas a sparse linear combination of the training samples, and the representation\nfidelity is measured by the l2-norm or l1-norm of the coding residual. Such a\nsparse coding model assumes that the coding residual follows Gaussian or\nLaplacian distribution, which may not be effective enough to describe the\ncoding residual in practical FR systems. Meanwhile, the sparsity constraint on\nthe coding coefficients makes SRC's computational cost very high. In this\npaper, we propose a new face coding model, namely regularized robust coding\n(RRC), which could robustly regress a given signal with regularized regression\ncoefficients. By assuming that the coding residual and the coding coefficient\nare respectively independent and identically distributed, the RRC seeks for a\nmaximum a posterior solution of the coding problem. An iteratively reweighted\nregularized robust coding (IR3C) algorithm is proposed to solve the RRC model\nefficiently. Extensive experiments on representative face databases demonstrate\nthat the RRC is much more effective and efficient than state-of-the-art sparse\nrepresentation based methods in dealing with face occlusion, corruption,\nlighting and expression changes, etc."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2012.2235849", 
    "link": "http://arxiv.org/pdf/1202.4237v1", 
    "other_authors": "Qiyang Zhao", 
    "title": "A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP", 
    "arxiv-id": "1202.4237v1", 
    "author": "Qiyang Zhao", 
    "publish": "2012-02-20T06:56:26Z", 
    "summary": "Color image segmentation is an important topic in the image processing field.\nMRF-MAP is often adopted in the unsupervised segmentation methods, but their\nperformance are far behind recent interactive segmentation tools supervised by\nuser inputs. Furthermore, the existing related unsupervised methods also suffer\nfrom the low efficiency, and high risk of being trapped in the local optima,\nbecause MRF-MAP is currently solved by iterative frameworks with inaccurate\ninitial color distribution models. To address these problems, the letter\ndesigns an efficient method to calculate the energy functions approximately in\nthe non-iteration style, and proposes a new binary segmentation algorithm based\non the slightly tuned Lanczos eigensolver. The experiments demonstrate that the\nnew algorithm achieves competitive performance compared with two state-of-art\nsegmentation methods."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1202.4495v1", 
    "other_authors": "V. Canals, A. Morro, J. L. Rossell\u00f3", 
    "title": "Stochastic-Based Pattern Recognition Analysis", 
    "arxiv-id": "1202.4495v1", 
    "author": "J. L. Rossell\u00f3", 
    "publish": "2012-02-20T23:48:38Z", 
    "summary": "In this work we review the basic principles of stochastic logic and propose\nits application to probabilistic-based pattern-recognition analysis. The\nproposed technique is intrinsically a parallel comparison of input data to\nvarious pre-stored categories using Bayesian techniques. We design smart\npulse-based stochastic-logic blocks to provide an efficient pattern recognition\nanalysis. The proposed rchitecture is applied to a specific navigation problem.\nThe resulting system is orders of magnitude faster than processor-based\nsolutions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1202.6384v1", 
    "other_authors": "Arthur Szlam, Karol Gregor, Yann LeCun", 
    "title": "Fast approximations to structured sparse coding and applications to   object classification", 
    "arxiv-id": "1202.6384v1", 
    "author": "Yann LeCun", 
    "publish": "2012-02-28T21:27:14Z", 
    "summary": "We describe a method for fast approximation of sparse coding. The input space\nis subdivided by a binary decision tree, and we simultaneously learn a\ndictionary and assignment of allowed dictionary elements for each leaf of the\ntree. We store a lookup table with the assignments and the pseudoinverses for\neach node, allowing for very fast inference. We give an algorithm for learning\nthe tree, the dictionary and the dictionary element assignment, and In the\nprocess of describing this algorithm, we discuss the more general problem of\nlearning the groups in group structured sparse modelling. We show that our\nmethod creates good sparse representations by using it in the object\nrecognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own\nfast version of the SIFT descriptor the whole system runs at 20 frames per\nsecond on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while\nsacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patrec.2010.07.008", 
    "link": "http://arxiv.org/pdf/1202.6586v1", 
    "other_authors": "Luis Quesada, Alejandro J. Le\u00f3n", 
    "title": "Filling-Based Techniques Applied to Object Projection Feature Estimation", 
    "arxiv-id": "1202.6586v1", 
    "author": "Alejandro J. Le\u00f3n", 
    "publish": "2012-02-29T16:10:10Z", 
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting object projection feature estimation techniques are based on\nray-casting from the inner point. These techniques present three main\ndrawbacks: when the inner point is surrounded by edges, rays may not reach\nother relevant areas; as a consequence of that issue, the estimated features\nmay greatly vary depending on the position of the inner point relative to the\nobject projection; and finally, increasing the number of rays being casted and\nthe ray-casting iterations (which would make the results more accurate and\nstable) increases the processing time to the point the tracking cannot be\nperformed on the fly. In this paper, we analyze an intuitive filling-based\nobject projection feature estimation technique that solves the aforementioned\nproblems but is too sensitive to edge miscalculations. Then, we propose a less\ncomputing-intensive modification to that technique that would not be affected\nby the existing techniques issues and would be no more sensitive to edge\nmiscalculations than ray-casting-based techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3208", 
    "link": "http://arxiv.org/pdf/1205.1644v1", 
    "other_authors": "H S Jagadeesh, K Suresh Babu, K B Raja", 
    "title": "DBC based Face Recognition using DWT", 
    "arxiv-id": "1205.1644v1", 
    "author": "K B Raja", 
    "publish": "2012-05-08T09:44:03Z", 
    "summary": "The applications using face biometric has proved its reliability in last\ndecade. In this paper, we propose DBC based Face Recognition using DWT (DBC-\nFR) model. The Poly-U Near Infra Red (NIR) database images are scanned and\ncropped to get only the face part in pre-processing. The face part is resized\nto 100*100 and DWT is applied to derive LL, LH, HL and HH subbands. The LL\nsubband of size 50*50 is converted into 100 cells with 5*5 dimention of each\ncell. The Directional Binary Code (DBC) is applied on each 5*5 cell to derive\n100 features. The Euclidian distance measure is used to compare the features of\ntest image and database images. The proposed algorithm render better percentage\nrecognition rate compared to the existing algorithm."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.2031v1", 
    "other_authors": "K. S. Sreejini, A. Lijiya, V. K. Govindan", 
    "title": "M-FISH Karyotyping - A New Approach Based on Watershed Transform", 
    "arxiv-id": "1205.2031v1", 
    "author": "V. K. Govindan", 
    "publish": "2012-05-09T16:52:23Z", 
    "summary": "Karyotyping is a process in which chromosomes in a dividing cell are properly\nstained, identified and displayed in a standard format, which helps geneticist\nto study and diagnose genetic factors behind various genetic diseases and for\nstudying cancer. M-FISH (Multiplex Fluorescent In-Situ Hybridization) provides\ncolor karyotyping. In this paper, an automated method for M-FISH chromosome\nsegmentation based on watershed transform followed by naive Bayes\nclassification of each region using the features, mean and standard deviation,\nis presented. Also, a post processing step is added to re-classify the small\nchromosome segments to the neighboring larger segment for reducing the chances\nof misclassification. The approach provided improved accuracy when compared to\nthe pixel-by-pixel approach. The approach was tested on 40 images from the\ndataset and achieved an accuracy of 84.21 %."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.2164v1", 
    "other_authors": "Ankit Kumar, Tushar Patnaik, Vivek Kr Verma", 
    "title": "Discrimination of English to other Indian languages (Kannada and Hindi)   for OCR system", 
    "arxiv-id": "1205.2164v1", 
    "author": "Vivek Kr Verma", 
    "publish": "2012-05-10T06:14:51Z", 
    "summary": "India is a multilingual multi-script country. In every state of India there\nare two languages one is state local language and the other is English. For\nexample in Andhra Pradesh, a state in India, the document may contain text\nwords in English and Telugu script. For Optical Character Recognition (OCR) of\nsuch a bilingual document, it is necessary to identify the script before\nfeeding the text words to the OCRs of individual scripts. In this paper, we are\nintroducing a simple and efficient technique of script identification for\nKannada, English and Hindi text words of a printed document. The proposed\napproach is based on the horizontal and vertical projection profile for the\ndiscrimination of the three scripts. The feature extraction is done based on\nthe horizontal projection profile of each text words. We analysed 700 different\nwords of Kannada, English and Hindi in order to extract the discrimination\nfeatures and for the development of knowledge base. We use the horizontal\nprojection profile of each text word and based on the horizontal projection\nprofile we extract the appropriate features. The proposed system is tested on\n100 different document images containing more than 1000 text words of each\nscript and a classification rate of 98.25%, 99.25% and 98.87% is achieved for\nKannada, English and Hindi respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.2663v1", 
    "other_authors": "Otavio A. B. Penatti, Eduardo Valle, Ricardo da S. Torres", 
    "title": "Are visual dictionaries generalizable?", 
    "arxiv-id": "1205.2663v1", 
    "author": "Ricardo da S. Torres", 
    "publish": "2012-05-11T18:54:12Z", 
    "summary": "Mid-level features based on visual dictionaries are today a cornerstone of\nsystems for classification and retrieval of images. Those state-of-the-art\nrepresentations depend crucially on the choice of a codebook (visual\ndictionary), which is usually derived from the dataset. In general-purpose,\ndynamic image collections (e.g., the Web), one cannot have the entire\ncollection in order to extract a representative dictionary. However, based on\nthe hypothesis that the dictionary reflects only the diversity of low-level\nappearances and does not capture semantics, we argue that a dictionary based on\na small subset of the data, or even on an entirely different dataset, is able\nto produce a good representation, provided that the chosen images span a\ndiverse enough portion of the low-level feature space. Our experiments confirm\nthat hypothesis, opening the opportunity to greatly alleviate the burden in\ngenerating the codebook, and confirming the feasibility of employing visual\ndictionaries in large-scale dynamic environments."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.3766v1", 
    "other_authors": "Jason Chang, John W. Fisher III", 
    "title": "Efficient Topology-Controlled Sampling of Implicit Shapes", 
    "arxiv-id": "1205.3766v1", 
    "author": "John W. Fisher III", 
    "publish": "2012-05-16T19:11:51Z", 
    "summary": "Sampling from distributions of implicitly defined shapes enables analysis of\nvarious energy functionals used for image segmentation. Recent work describes a\ncomputationally efficient Metropolis-Hastings method for accomplishing this\ntask. Here, we extend that framework so that samples are accepted at every\niteration of the sampler, achieving an order of magnitude speed up in\nconvergence. Additionally, we show how to incorporate topological constraints."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.3999v1", 
    "other_authors": "Qiyu Jin, Ion Grama, Quansheng Liu", 
    "title": "Optimal Weights Mixed Filter for Removing Mixture of Gaussian and   Impulse Noises", 
    "arxiv-id": "1205.3999v1", 
    "author": "Quansheng Liu", 
    "publish": "2012-05-17T18:15:45Z", 
    "summary": "According to the character of Gaussian, we modify the Rank-Ordered Absolute\nDifferences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian\nand impulse noises (ROADG). It will be more effective to detect impulse noise\nwhen the impulse is mixed with Gaussian noise. Combining rightly the ROADG with\nOptimal Weights Filter (OWF), we obtain a new method to deal with the mixed\nnoise, called Optimal Weights Mixed Filter (OWMF). The simulation results show\nthat the method is effective to remove the mixed noise."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.4336v2", 
    "other_authors": "K. Thangavel, R. Roselin", 
    "title": "Fuzzy - Rough Feature Selection With \u03a0- Membership Function For   Mammogram Classification", 
    "arxiv-id": "1205.4336v2", 
    "author": "R. Roselin", 
    "publish": "2012-05-19T15:19:38Z", 
    "summary": "Breast cancer is the second leading cause for death among women and it is\ndiagnosed with the help of mammograms. Oncologists are miserably failed in\nidentifying the micro calcification at the early stage with the help of the\nmammogram visually. In order to improve the performance of the breast cancer\nscreening, most of the researchers have proposed Computer Aided Diagnosis using\nimage processing. In this study mammograms are preprocessed and features are\nextracted, then the abnormality is identified through the classification. If\nall the extracted features are used, most of the cases are misidentified. Hence\nfeature selection procedure is sought. In this paper, Fuzzy-Rough feature\nselection with {\\pi} membership function is proposed. The selected features are\nused to classify the abnormalities with help of Ant-Miner and Weka tools. The\nexperimental analysis shows that the proposed method improves the mammograms\nclassification accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.4450v3", 
    "other_authors": "Chengxi Ye, Yuxu Lin, Mingli Song, Chun Chen, David W. Jacobs", 
    "title": "Spectral Graph Cut from a Filtering Point of View", 
    "arxiv-id": "1205.4450v3", 
    "author": "David W. Jacobs", 
    "publish": "2012-05-20T19:30:26Z", 
    "summary": "Spectral graph theory is well known and widely used in computer vision. In\nthis paper, we analyze image segmentation algorithms that are based on spectral\ngraph theory, e.g., normalized cut, and show that there is a natural connection\nbetween spectural graph theory based image segmentationand and edge preserving\nfiltering. Based on this connection we show that the normalized cut algorithm\nis equivalent to repeated iterations of bilateral filtering. Then, using this\nequivalence we present and implement a fast normalized cut algorithm for image\nsegmentation. Experiments show that our implementation can solve the original\noptimization problem in the normalized cut algorithm 10 to 100 times faster.\nFurthermore, we present a new algorithm called conditioned normalized cut for\nimage segmentation that can easily incorporate color image patches and\ndemonstrate how this segmentation problem can be solved with edge preserving\nfiltering."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.4831v1", 
    "other_authors": "Bino Sebastian V, A. Unnikrishnan, Kannan Balakrishnan", 
    "title": "Gray Level Co-Occurrence Matrices: Generalisation and Some New Features", 
    "arxiv-id": "1205.4831v1", 
    "author": "Kannan Balakrishnan", 
    "publish": "2012-05-22T08:00:45Z", 
    "summary": "Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques\nused for image texture analysis. In this paper we defined a new feature called\ntrace extracted from the GLCM and its implications in texture analysis are\ndiscussed in the context of Content Based Image Retrieval (CBIR). The\ntheoretical extension of GLCM to n-dimensional gray scale images are also\ndiscussed. The results indicate that trace features outperform Haralick\nfeatures when applied to CBIR."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijcseit.2012.2210", 
    "link": "http://arxiv.org/pdf/1205.5097v1", 
    "other_authors": "Vijayalaxmi, P. Sudhakara Rao, S. Sreehari", 
    "title": "Neural Network Approach for Eye Detection", 
    "arxiv-id": "1205.5097v1", 
    "author": "S. Sreehari", 
    "publish": "2012-05-23T05:14:20Z", 
    "summary": "Driving support systems, such as car navigation systems are becoming common\nand they support driver in several aspects. Non-intrusive method of detecting\nFatigue and drowsiness based on eye-blink count and eye directed instruction\ncontrolhelps the driver to prevent from collision caused by drowsy driving. Eye\ndetection and tracking under various conditions such as illumination,\nbackground, face alignment and facial expression makes the problem\ncomplex.Neural Network based algorithm is proposed in this paper to detect the\neyes efficiently. In the proposed algorithm, first the neural Network is\ntrained to reject the non-eye regionbased on images with features of eyes and\nthe images with features of non-eye using Gabor filter and Support Vector\nMachines to reduce the dimension and classify efficiently. In the algorithm,\nfirst the face is segmented using L*a*btransform color space, then eyes are\ndetected using HSV and Neural Network approach. The algorithm is tested on\nnearly 100 images of different persons under different conditions and the\nresults are satisfactory with success rate of 98%.The Neural Network is trained\nwith 50 non-eye images and 50 eye images with different angles using Gabor\nfilter. This paper is a part of research work on \"Development of Non-Intrusive\nsystem for real-time Monitoring and Prediction of Driver Fatigue and\ndrowsiness\" project sponsored by Department of Science & Technology, Govt. of\nIndia, New Delhi at Vignan Institute of Technology and Sciences, Vignan Hills,\nHyderabad."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.5351v2", 
    "other_authors": "Xiang Ren, Zhouchen Lin", 
    "title": "Linearized Alternating Direction Method with Adaptive Penalty and Warm   Starts for Fast Solving Transform Invariant Low-Rank Textures", 
    "arxiv-id": "1205.5351v2", 
    "author": "Zhouchen Lin", 
    "publish": "2012-05-24T07:16:14Z", 
    "summary": "Transform Invariant Low-rank Textures (TILT) is a novel and powerful tool\nthat can effectively rectify a rich class of low-rank textures in 3D scenes\nfrom 2D images despite significant deformation and corruption. The existing\nalgorithm for solving TILT is based on the alternating direction method (ADM).\nIt suffers from high computational cost and is not theoretically guaranteed to\nconverge to a correct solution. In this paper, we propose a novel algorithm to\nspeed up solving TILT, with guaranteed convergence. Our method is based on the\nrecently proposed linearized alternating direction method with adaptive penalty\n(LADMAP). To further reduce computation, warm starts are also introduced to\ninitialize the variables better and cut the cost on singular value\ndecomposition. Extensive experimental results on both synthetic and real data\ndemonstrate that this new algorithm works much more efficiently and robustly\nthan the existing algorithm. It could be at least five times faster than the\nprevious method."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.5425v1", 
    "other_authors": "Sune Darkner, Jon Sporring", 
    "title": "Locally Orderless Registration", 
    "arxiv-id": "1205.5425v1", 
    "author": "Jon Sporring", 
    "publish": "2012-05-24T12:56:45Z", 
    "summary": "Image registration is an important tool for medical image analysis and is\nused to bring images into the same reference frame by warping the coordinate\nfield of one image, such that some similarity measure is minimized. We study\nsimilarity in image registration in the context of Locally Orderless Images\n(LOI), which is the natural way to study density estimates and reveals the 3\nfundamental scales: the measurement scale, the intensity scale, and the\nintegration scale.\n  This paper has three main contributions: Firstly, we rephrase a large set of\npopular similarity measures into a common framework, which we refer to as\nLocally Orderless Registration, and which makes full use of the features of\nlocal histograms. Secondly, we extend the theoretical understanding of the\nlocal histograms. Thirdly, we use our framework to compare two state-of-the-art\nintensity density estimators for image registration: The Parzen Window (PW) and\nthe Generalized Partial Volume (GPV), and we demonstrate their differences on a\npopular similarity measure, Normalized Mutual Information (NMI).\n  We conclude, that complicated similarity measures such as NMI may be\nevaluated almost as fast as simple measures such as Sum of Squared Distances\n(SSD) regardless of the choice of PW and GPV. Also, GPV is an asymmetric\nmeasure, and PW is our preferred choice."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6352v4", 
    "other_authors": "Vladimir Kolmogorov, Thomas Schoenemann", 
    "title": "Generalized sequential tree-reweighted message passing", 
    "arxiv-id": "1205.6352v4", 
    "author": "Thomas Schoenemann", 
    "publish": "2012-05-29T13:06:58Z", 
    "summary": "This paper addresses the problem of approximate MAP-MRF inference in general\ngraphical models. Following [36], we consider a family of linear programming\nrelaxations of the problem where each relaxation is specified by a set of\nnested pairs of factors for which the marginalization constraint needs to be\nenforced. We develop a generalization of the TRW-S algorithm [9] for this\nproblem, where we use a decomposition into junction chains, monotonic w.r.t.\nsome ordering on the nodes. This generalizes the monotonic chains in [9] in a\nnatural way. We also show how to deal with nested factors in an efficient way.\nExperiments show an improvement over min-sum diffusion, MPLP and subgradient\nascent algorithms on a number of computer vision and natural language\nprocessing problems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6391v2", 
    "other_authors": "Kong Shu, Wang Donghui", 
    "title": "A Brief Summary of Dictionary Learning Based Approach for Classification", 
    "arxiv-id": "1205.6391v2", 
    "author": "Wang Donghui", 
    "publish": "2012-05-29T15:28:54Z", 
    "summary": "This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6572v1", 
    "other_authors": "Amiya Halder, Soumajit Pramanik", 
    "title": "An Unsupervised Dynamic Image Segmentation using Fuzzy Hopfield Neural   Network based Genetic Algorithm", 
    "arxiv-id": "1205.6572v1", 
    "author": "Soumajit Pramanik", 
    "publish": "2012-05-30T08:10:59Z", 
    "summary": "This paper proposes a Genetic Algorithm based segmentation method that can\nautomatically segment gray-scale images. The proposed method mainly consists of\nspatial unsupervised grayscale image segmentation that divides an image into\nregions. The aim of this algorithm is to produce precise segmentation of images\nusing intensity information along with neighborhood relationships. In this\npaper, Fuzzy Hopfield Neural Network (FHNN) clustering helps in generating the\npopulation of Genetic algorithm which there by automatically segments the\nimage. This technique is a powerful method for image segmentation and works for\nboth single and multiple-feature data with spatial information. Validity index\nhas been utilized for introducing a robust technique for finding the optimum\nnumber of components in an image. Experimental results shown that the algorithm\ngenerates good quality segmented image."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6605v1", 
    "other_authors": "Jan Egger, Bernd Freisleben, Christopher Nimsky, Tina Kapur", 
    "title": "Template-Cut: A Pattern-Based Segmentation Paradigm", 
    "arxiv-id": "1205.6605v1", 
    "author": "Tina Kapur", 
    "publish": "2012-05-30T09:44:43Z", 
    "summary": "We present a scale-invariant, template-based segmentation paradigm that sets\nup a graph and performs a graph cut to separate an object from the background.\nTypically graph-based schemes distribute the nodes of the graph uniformly and\nequidistantly on the image, and use a regularizer to bias the cut towards a\nparticular shape. The strategy of uniform and equidistant nodes does not allow\nthe cut to prefer more complex structures, especially when areas of the object\nare indistinguishable from the background. We propose a solution by introducing\nthe concept of a \"template shape\" of the target object in which the nodes are\nsampled non-uniformly and non-equidistantly on the image. We evaluate it on\n2D-images where the object's textures and backgrounds are similar, and large\nareas of the object have the same gray level appearance as the background. We\nalso evaluate it in 3D on 60 brain tumor datasets for neurosurgical planning\npurposes."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1205.6745v1", 
    "other_authors": "P Gnanasivam, Dr. S Muttan", 
    "title": "Fingerprint Gender Classification using Wavelet Transform and Singular   Value Decomposition", 
    "arxiv-id": "1205.6745v1", 
    "author": "Dr. S Muttan", 
    "publish": "2012-05-30T16:26:23Z", 
    "summary": "A novel method of gender Classification from fingerprint is proposed based on\ndiscrete wavelet transform (DWT) and singular value decomposition (SVD). The\nclassification is achieved by extracting the energy computed from all the\nsub-bands of DWT combined with the spatial features of non-zero singular values\nobtained from the SVD of fingerprint images. K nearest neighbor (KNN) used as a\nclassifier. This method is experimented with the internal database of 3570\nfingerprints finger prints in which 1980 were male fingerprints and 1590 were\nfemale fingerprints. Finger-wise gender classification is achieved which is\n94.32% for the left hand little fingers of female persons and 95.46% for the\nleft hand index finger of male persons. Gender classification for any finger of\nmale persons tested is attained as 91.67% and 84.69% for female persons\nrespectively. Overall classification rate is 88.28% has been achieved."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11263-013-0611-6", 
    "link": "http://arxiv.org/pdf/1206.0238v1", 
    "other_authors": "M. Zahid Hossain, M. Ashraful Amin, Hong Yan", 
    "title": "Rapid Feature Extraction for Optical Character Recognition", 
    "arxiv-id": "1206.0238v1", 
    "author": "Hong Yan", 
    "publish": "2012-06-01T16:20:41Z", 
    "summary": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2012.3203", 
    "link": "http://arxiv.org/pdf/1206.1515v1", 
    "other_authors": "Manal Abdullah, Majda Wazzan, Sahar Bo-saeed", 
    "title": "Optimizing Face Recognition Using PCA", 
    "arxiv-id": "1206.1515v1", 
    "author": "Sahar Bo-saeed", 
    "publish": "2012-06-07T14:51:54Z", 
    "summary": "Principle Component Analysis PCA is a classical feature extraction and data\nrepresentation technique widely used in pattern recognition. It is one of the\nmost successful techniques in face recognition. But it has drawback of high\ncomputational especially for big size database. This paper conducts a study to\noptimize the time complexity of PCA (eigenfaces) that does not affects the\nrecognition performance. The authors minimize the participated eigenvectors\nwhich consequently decreases the computational time. A comparison is done to\ncompare the differences between the recognition time in the original algorithm\nand in the enhanced algorithm. The performance of the original and the enhanced\nproposed algorithm is tested on face94 face database. Experimental results show\nthat the recognition time is reduced by 35% by applying our proposed enhanced\nalgorithm. DET Curves are used to illustrate the experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2012.3203", 
    "link": "http://arxiv.org/pdf/1206.1518v1", 
    "other_authors": "Manal A. Abdullah, Lulwah M. Al-Harigy, Hanadi H. Al-Fraidi", 
    "title": "Off-Line Arabic Handwriting Character Recognition Using Word   Segmentation", 
    "arxiv-id": "1206.1518v1", 
    "author": "Hanadi H. Al-Fraidi", 
    "publish": "2012-06-07T15:07:08Z", 
    "summary": "The ultimate aim of handwriting recognition is to make computers able to read\nand/or authenticate human written texts, with a performance comparable to or\neven better than that of humans. Reading means that the computer is given a\npiece of handwriting and it provides the electronic transcription of that (e.g.\nin ASCII format). Two types of handwriting: on-line and offline. The most\nimportant purpose of off-line handwriting recognition is in protection systems\nand authentication. Arabic Handwriting scripts are much more complicated in\ncomparison to Latin scripts. This paper introduces a simple and novel\nmethodology to authenticate Arabic handwriting characters. Reaching our aim, we\nbuilt our own character database. The research methodology depends on two\nstages: The first is character extraction where preprocessing the word and then\napply segmentation process to obtain the character. The second is the character\nrecognition by matching the characters comprising the word with the letters in\nthe database. Our results ensure character recognition with 81%. We eliminate\nFAR by using similarity percent between 45-55%. Our research is coded using\nMATLAB."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijaia.2012.3203", 
    "link": "http://arxiv.org/pdf/1206.1552v1", 
    "other_authors": "K. Vasanth, V. Jawahar Senthil Kumar", 
    "title": "Performance Analysis of Unsymmetrical trimmed median as detector on   image noises and its Fpga implementation", 
    "arxiv-id": "1206.1552v1", 
    "author": "V. Jawahar Senthil Kumar", 
    "publish": "2012-06-07T16:49:36Z", 
    "summary": "This Paper Analyze the performance of Unsymmetrical trimmed median, which is\nused as detector for the detection of impulse noise, Gaussian noise and mixed\nnoise is proposed. The proposed algorithm uses a fixed 3x3 window for the\nincreasing noise densities. The pixels in the current window are arranged in\nsorting order using a improved snake like sorting algorithm with reduced\ncomparator. The processed pixel is checked for the occurrence of outliers, if\nthe absolute difference between processed pixels is greater than fixed\nthreshold. Under high noise densities the processed pixel is also noisy hence\nthe median is checked using the above procedure. if found true then the pixel\nis considered as noisy hence the corrupted pixel is replaced by the median of\nthe current processing window. If median is also noisy then replace the\ncorrupted pixel with unsymmetrical trimmed median else if the pixel is termed\nuncorrupted and left unaltered. The proposed algorithm (PA) is tested on\nvarying detail images for various noises. The proposed algorithm effectively\nremoves the high density fixed value impulse noise, low density random valued\nimpulse noise, low density Gaussian noise and lower proportion of mixed noise.\nThe proposed algorithm is targeted on Xc3e5000-5fg900 FPGA using Xilinx 7.1\ncompiler version which requires less number of slices, optimum speed and low\npower when compared to the other median finding architectures."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.2437v1", 
    "other_authors": "Md. Sahidullah, Goutam Saha", 
    "title": "A Novel Windowing Technique for Efficient Computation of MFCC for   Speaker Recognition", 
    "arxiv-id": "1206.2437v1", 
    "author": "Goutam Saha", 
    "publish": "2012-06-12T04:23:38Z", 
    "summary": "In this paper, we propose a novel family of windowing technique to compute\nMel Frequency Cepstral Coefficient (MFCC) for automatic speaker recognition\nfrom speech. The proposed method is based on fundamental property of discrete\ntime Fourier transform (DTFT) related to differentiation in frequency domain.\nClassical windowing scheme such as Hamming window is modified to obtain\nderivatives of discrete time Fourier transform coefficients. It has been\nmathematically shown that the slope and phase of power spectrum are inherently\nincorporated in newly computed cepstrum. Speaker recognition systems based on\nour proposed family of window functions are shown to attain substantial and\nconsistent performance improvement over baseline single tapered Hamming window\nas well as recently proposed multitaper windowing technique."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.2627v2", 
    "other_authors": "Tanaya Guha, Rabab K. Ward", 
    "title": "Image Similarity Using Sparse Representation and Compression Distance", 
    "arxiv-id": "1206.2627v2", 
    "author": "Rabab K. Ward", 
    "publish": "2012-06-12T19:30:57Z", 
    "summary": "A new line of research uses compression methods to measure the similarity\nbetween signals. Two signals are considered similar if one can be compressed\nsignificantly when the information of the other is known. The existing\ncompression-based similarity methods, although successful in the discrete one\ndimensional domain, do not work well in the context of images. This paper\nproposes a sparse representation-based approach to encode the information\ncontent of an image using information from the other image, and uses the\ncompactness (sparsity) of the representation as a measure of its\ncompressibility (how much can the image be compressed) with respect to the\nother image. The more sparse the representation of an image, the better it can\nbe compressed and the more it is similar to the other image. The efficacy of\nthe proposed measure is demonstrated through the high accuracies achieved in\nimage clustering, retrieval and classification."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.2807v1", 
    "other_authors": "Silvio Jamil F. Guimar\u00e3es, Jean Cousty, Yukiko Kenmochi, Laurent Najman", 
    "title": "An efficient hierarchical graph based image segmentation", 
    "arxiv-id": "1206.2807v1", 
    "author": "Laurent Najman", 
    "publish": "2012-06-13T13:49:23Z", 
    "summary": "Hierarchical image segmentation provides region-oriented scalespace, i.e., a\nset of image segmentations at different detail levels in which the\nsegmentations at finer levels are nested with respect to those at coarser\nlevels. Most image segmentation algorithms, such as region merging algorithms,\nrely on a criterion for merging that does not lead to a hierarchy, and for\nwhich the tuning of the parameters can be difficult. In this work, we propose a\nhierarchical graph based image segmentation relying on a criterion popularized\nby Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic\nimages, showing efficiency, ease of use, and robustness of our method."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.3559v1", 
    "other_authors": "Saumil Srivastava", 
    "title": "Real time facial expression recognition using a novel method", 
    "arxiv-id": "1206.3559v1", 
    "author": "Saumil Srivastava", 
    "publish": "2012-05-08T06:54:41Z", 
    "summary": "This paper discusses a novel method for Facial Expression Recognition System\nwhich performs facial expression analysis in a near real time from a live web\ncam feed. Primary objectives were to get results in a near real time with light\ninvariant, person independent and pose invariant way. The system is composed of\ntwo different entities trainer and evaluator. Each frame of video feed is\npassed through a series of steps including haar classifiers, skin detection,\nfeature extraction, feature points tracking, creating a learned Support Vector\nMachine model to classify emotions to achieve a tradeoff between accuracy and\nresult rate. A processing time of 100-120 ms per 10 frames was achieved with\naccuracy of around 60%. We measure our accuracy in terms of variety of\ninteraction and classification scenarios. We conclude by discussing relevance\nof our work to human computer interaction and exploring further measures that\ncan be taken."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.3594v1", 
    "other_authors": "Yu. A. Bunyak, O. Yu. Sofina, R. N. Kvetnyy", 
    "title": "Blind PSF estimation and methods of deconvolution optimization", 
    "arxiv-id": "1206.3594v1", 
    "author": "R. N. Kvetnyy", 
    "publish": "2012-06-15T20:51:39Z", 
    "summary": "We have shown that the left side null space of the autoregression (AR) matrix\noperator is the lexicographical presentation of the point spread function (PSF)\non condition the AR parameters are common for original and blurred images. The\nmethod of inverse PSF evaluation with regularization functional as the function\nof surface area is offered. The inverse PSF was used for primary image\nestimation. Two methods of original image estimate optimization were designed\nbasing on maximum entropy generalization of sought and blurred images\nconditional probability density and regularization. The first method uses\nbalanced variations of convolution and deconvolution transforms to obtaining\niterative schema of image optimization. The variations balance was defined by\ndynamic regularization basing on condition of iteration process convergence.\nThe regularization has dynamic character because depends on current and\nprevious image estimate variations. The second method implements the\nregularization of deconvolution optimization in curved space with metric\ndefined on image estimate surface. It is basing on target functional invariance\nto fluctuations of optimal argument value. The given iterative schemas have\nfaster convergence in comparison with known ones, so they can be used for\nreconstruction of high resolution images series in real time."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2012.2235067", 
    "link": "http://arxiv.org/pdf/1206.4866v1", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "Portraits of Julius Caesar: a proposal for 3D analysis", 
    "arxiv-id": "1206.4866v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2012-06-21T13:14:59Z", 
    "summary": "Here I suggest the use of a 3D scanning and rendering to create some virtual\ncopies of ancient artifacts to study and compare them. In particular, this\napproach could be interesting for some roman marble busts, two of which are\nportraits of Julius Caesar, and the third is a realistic portrait of a man\nrecently found at Arles, France. The comparison of some images indicates that a\nthree-dimensional visualization is necessary."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1206.5065v1", 
    "other_authors": "Sofia Zaidenberg, Bernard Boulay, Fran\u00e7ois Bremond", 
    "title": "A generic framework for video understanding applied to group behavior   recognition", 
    "arxiv-id": "1206.5065v1", 
    "author": "Fran\u00e7ois Bremond", 
    "publish": "2012-06-22T06:24:30Z", 
    "summary": "This paper presents an approach to detect and track groups of people in\nvideo-surveillance applications, and to automatically recognize their behavior.\nThis method keeps track of individuals moving together by maintaining a spacial\nand temporal group coherence. First, people are individually detected and\ntracked. Second, their trajectories are analyzed over a temporal window and\nclustered using the Mean-Shift algorithm. A coherence value describes how well\na set of people can be described as a group. Furthermore, we propose a formal\nevent description language. The group events recognition approach is\nsuccessfully validated on 4 camera views from 3 datasets: an airport, a subway,\na shopping center corridor and an entrance hall."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1206.6878v1", 
    "other_authors": "Monika Schaeffer, Ron Parr", 
    "title": "Efficient Selection of Disambiguating Actions for Stereo Vision", 
    "arxiv-id": "1206.6878v1", 
    "author": "Ron Parr", 
    "publish": "2012-06-27T16:31:21Z", 
    "summary": "In many domains that involve the use of sensors, such as robotics or sensor\nnetworks, there are opportunities to use some form of active sensing to\ndisambiguate data from noisy or unreliable sensors. These disambiguating\nactions typically take time and expend energy. One way to choose the next\ndisambiguating action is to select the action with the greatest expected\nentropy reduction, or information gain. In this work, we consider active\nsensing in aid of stereo vision for robotics. Stereo vision is a powerful\nsensing technique for mobile robots, but it can fail in scenes that lack strong\ntexture. In such cases, a structured light source, such as vertical laser line\ncan be used for disambiguation. By treating the stereo matching problem as a\nspecially structured HMM-like graphical model, we demonstrate that for a scan\nline with n columns and maximum stereo disparity d, the entropy minimizing aim\npoint for the laser can be selected in O(nd) time - cost no greater than the\nstereo algorithm itself. In contrast, a typical HMM formulation would suggest\nat least O(nd^2) time for the entropy calculation alone."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.0967v1", 
    "other_authors": "Hema Swetha Koppula, Rudhir Gupta, Ashutosh Saxena", 
    "title": "Human Activity Learning using Object Affordances from RGB-D Videos", 
    "arxiv-id": "1208.0967v1", 
    "author": "Ashutosh Saxena", 
    "publish": "2012-08-04T23:44:07Z", 
    "summary": "Human activities comprise several sub-activities performed in a sequence and\ninvolve interactions with various objects. This makes reasoning about the\nobject affordances a central task for activity recognition. In this work, we\nconsider the problem of jointly labeling the object affordances and human\nactivities from RGB-D videos. We frame the problem as a Markov Random Field\nwhere the nodes represent objects and sub-activities, and the edges represent\nthe relationships between object affordances, their relations with\nsub-activities, and their evolution over time. We formulate the learning\nproblem using a structural SVM approach, where labeling over various alternate\ntemporal segmentations are considered as latent variables. We tested our method\non a dataset comprising 120 activity videos collected from four subjects, and\nobtained an end-to-end precision of 81.8% and recall of 80.0% for labeling the\nactivities."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.1670v1", 
    "other_authors": "Josphineleela Ramakrishnan, Ramakrishnan Malaisamy", 
    "title": "Performance Measurement and Method Analysis (PMMA) for Fingerprint   Reconstruction", 
    "arxiv-id": "1208.1670v1", 
    "author": "Ramakrishnan Malaisamy", 
    "publish": "2012-08-08T14:15:38Z", 
    "summary": "Fingerprint reconstruction is one of the most well-known and publicized\nbiometrics. Because of their uniqueness and consistency over time, fingerprints\nhave been used for identification over a century, more recently becoming\nautomated due to advancements in computed capabilities. Fingerprint\nreconstruction is popular because of the inherent ease of acquisition, the\nnumerous sources (e.g. ten fingers) available for collection, and their\nestablished use and collections by law enforcement and immigration.\nFingerprints have always been the most practical and positive means of\nidentification. Offenders, being well aware of this, have been coming up with\nways to escape identification by that means. Erasing left over fingerprints,\nusing gloves, fingerprint forgery; are certain examples of methods tried by\nthem, over the years. Failing to prevent themselves, they moved to an extent of\nmutilating their finger skin pattern, to remain unidentified. This article is\nbased upon obliteration of finger ridge patterns and discusses some known cases\nin relation to the same, in chronological order; highlighting the reasons why\noffenders go to an extent of performing such act. The paper gives an overview\nof different methods and performance measurement of the fingerprint\nreconstruction."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.1672v1", 
    "other_authors": "Josphineleela Ramakrishnan, M. Ramakrishnan", 
    "title": "An Efficient Automatic Attendance System Using Fingerprint   Reconstruction Technique", 
    "arxiv-id": "1208.1672v1", 
    "author": "M. Ramakrishnan", 
    "publish": "2012-08-08T14:23:50Z", 
    "summary": "Biometric time and attendance system is one of the most successful\napplications of biometric technology. One of the main advantage of a biometric\ntime and attendance system is it avoids \"buddy-punching\". Buddy punching was a\nmajor loophole which will be exploiting in the traditional time attendance\nsystems. Fingerprint recognition is an established field today, but still\nidentifying individual from a set of enrolled fingerprints is a time taking\nprocess. Most fingerprint-based biometric systems store the minutiae template\nof a user in the database. It has been traditionally assumed that the minutiae\ntemplate of a user does not reveal any information about the original\nfingerprint. This belief has now been shown to be false; several algorithms\nhave been proposed that can reconstruct fingerprint images from minutiae\ntemplates. In this paper, a novel fingerprint reconstruction algorithm is\nproposed to reconstruct the phase image, which is then converted into the\ngrayscale image. The proposed reconstruction algorithm reconstructs the phase\nimage from minutiae. The proposed reconstruction algorithm is used to automate\nthe whole process of taking attendance, manually which is a laborious and\ntroublesome work and waste a lot of time, with its managing and maintaining the\nrecords for a period of time is also a burdensome task. The proposed\nreconstruction algorithm has been evaluated with respect to the success rates\nof type-I attack (match the reconstructed fingerprint against the original\nfingerprint) and type-II attack (match the reconstructed fingerprint against\ndifferent impressions of the original fingerprint) using a commercial\nfingerprint recognition system. Given the reconstructed image from our\nalgorithm, we show that both types of attacks can be effectively launched\nagainst a fingerprint recognition system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.2655v1", 
    "other_authors": "M. Kharinov", 
    "title": "Stable Segmentation of Digital Image", 
    "arxiv-id": "1208.2655v1", 
    "author": "M. Kharinov", 
    "publish": "2012-08-13T18:21:05Z", 
    "summary": "In the paper the optimal image segmentation by means of piecewise constant\napproximations is considered. The optimality is defined by a minimum value of\nthe total squared error or by equivalent value of standard deviation of the\napproximation from the image. The optimal approximations are defined\nindependently on the method of their obtaining and might be generated in\ndifferent algorithms. We investigate the computation of the optimal\napproximation on the grounds of stability with respect to a given set of\nmodifications. To obtain the optimal approximation the Mumford-Shuh model is\ngeneralized and developed, which in the computational part is combined with the\nOtsu method in multi-thresholding version. The proposed solution is proved\nanalytically and experimentally on the example of the standard image."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.3133v1", 
    "other_authors": "Walaa M. Abd-Elhafiez, Wajeb Gharibi", 
    "title": "Color Image Compression Algorithm Based on the DCT Blocks", 
    "arxiv-id": "1208.3133v1", 
    "author": "Wajeb Gharibi", 
    "publish": "2012-08-15T14:51:45Z", 
    "summary": "This paper presents the performance of different blockbased discrete cosine\ntransform (DCT) algorithms for compressing color image. In this RGB component\nof color image are converted to YCbCr before DCT transform is applied. Y is\nluminance component;Cb and Cr are chrominance components of the image. The\nmodification of the image data is done based on the classification of image\nblocks to edge blocks and non-edge blocks, then the edge block of the image is\ncompressed with low compression and the nonedge blocks is compressed with high\ncompression. The analysis results have indicated that the performance of the\nsuggested method is much better, where the constructed images are less\ndistorted and compressed with higher factor."
},{
    "category": "cs.CV", 
    "doi": "10.1109/AVSS.2012.1", 
    "link": "http://arxiv.org/pdf/1208.3512v1", 
    "other_authors": "Toshiro Kubota", 
    "title": "Contour Completion Around a Fixation Point", 
    "arxiv-id": "1208.3512v1", 
    "author": "Toshiro Kubota", 
    "publish": "2012-08-16T23:22:50Z", 
    "summary": "The paper presents two edge grouping algorithms for finding a closed contour\nstarting from a particular edge point and enclosing a fixation point. Both\nalgorithms search a shortest simple cycle in \\textit{an angularly ordered\ngraph} derived from an edge image where a vertex is an end point of a contour\nfragment and an undirected arc is drawn between a pair of end-points whose\nvisual angle from the fixation point is less than a threshold value, which is\nset to $\\pi/2$ in our experiments. The first algorithm restricts the search\nspace by disregarding arcs that cross the line extending from the fixation\npoint to the starting point. The second algorithm improves the solution of the\nfirst algorithm in a greedy manner. The algorithms were tested with a large\nnumber of natural images with manually placed fixation and starting points. The\nresults are promising."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIFS.2012.2218597", 
    "link": "http://arxiv.org/pdf/1208.3665v2", 
    "other_authors": "Vincent Christlein, Christian Riess, Johannes Jordan, Corinna Riess, Elli Angelopoulou", 
    "title": "An Evaluation of Popular Copy-Move Forgery Detection Approaches", 
    "arxiv-id": "1208.3665v2", 
    "author": "Elli Angelopoulou", 
    "publish": "2012-08-17T19:41:23Z", 
    "summary": "A copy-move forgery is created by copying and pasting content within the same\nimage, and potentially post-processing it. In recent years, the detection of\ncopy-move forgeries has become one of the most actively researched topics in\nblind image forensics. A considerable number of different algorithms have been\nproposed focusing on different types of postprocessed copies. In this paper, we\naim to answer which copy-move forgery detection algorithms and processing steps\n(e.g., matching, filtering, outlier detection, affine transformation\nestimation) perform best in various postprocessing scenarios. The focus of our\nanalysis is to evaluate the performance of previously proposed feature sets. We\nachieve this by casting existing algorithms in a common pipeline. In this\npaper, we examined the 15 most prominent feature sets. We analyzed the\ndetection performance on a per-image basis and on a per-pixel basis. We created\na challenging real-world copy-move dataset, and a software framework for\nsystematic image manipulation. Experiments show, that the keypoint-based\nfeatures SIFT and SURF, as well as the block-based DCT, DWT, KPCA, PCA and\nZernike features perform very well. These feature sets exhibit the best\nrobustness against various noise sources and downsampling, while reliably\nidentifying the copied regions."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIFS.2012.2218597", 
    "link": "http://arxiv.org/pdf/1208.3670v1", 
    "other_authors": "Qiong Liu", 
    "title": "A Survey of Recent View-based 3D Model Retrieval Methods", 
    "arxiv-id": "1208.3670v1", 
    "author": "Qiong Liu", 
    "publish": "2012-08-08T04:45:42Z", 
    "summary": "Extensive research efforts have been dedicated to 3D model retrieval in\nrecent decades. Recently, view-based methods have attracted much research\nattention due to the high discriminative property of multi-views for 3D object\nrepresentation. In this report, we summarize the view-based 3D model methods\nand provide the further research trends. This paper focuses on the scheme for\nmatching between multiple views of 3D models and the application of\nbag-of-visual-words method in 3D model retrieval. For matching between multiple\nviews, the many-to-many matching, probabilistic matching and semisupervised\nlearning methods are introduced. For bag-of-visual-words application in 3D\nmodel retrieval, we first briefly review the bag-of-visual-words works on\nmultimedia and computer vision tasks, where the visual dictionary has been\ndetailed introduced. Then a series of 3D model retrieval methods by using\nbag-of-visual-words description are surveyed in this paper. At last, we\nsummarize the further research content in view-based 3D model retrieval."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIFS.2012.2218597", 
    "link": "http://arxiv.org/pdf/1208.3716v2", 
    "other_authors": "Jian Zhang, Shaohui Liu, Debin Zhao, Ruiqin Xiong, Siwei Ma", 
    "title": "Improved Total Variation based Image Compressive Sensing Recovery by   Nonlocal Regularization", 
    "arxiv-id": "1208.3716v2", 
    "author": "Siwei Ma", 
    "publish": "2012-08-18T01:48:05Z", 
    "summary": "Recently, total variation (TV) based minimization algorithms have achieved\ngreat success in compressive sensing (CS) recovery for natural images due to\nits virtue of preserving edges. However, the use of TV is not able to recover\nthe fine details and textures, and often suffers from undesirable staircase\nartifact. To reduce these effects, this letter presents an improved TV based\nimage CS recovery algorithm by introducing a new nonlocal regularization\nconstraint into CS optimization problem. The nonlocal regularization is built\non the well known nonlocal means (NLM) filtering and takes advantage of\nself-similarity in images, which helps to suppress the staircase effect and\nrestore the fine details. Furthermore, an efficient augmented Lagrangian based\nalgorithm is developed to solve the above combined TV and nonlocal\nregularization constrained problem. Experimental results demonstrate that the\nproposed algorithm achieves significant performance improvements over the\nstate-of-the-art TV based algorithm in both PSNR and visual perception."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.3723v1", 
    "other_authors": "Jian Zhang, Chen Zhao, Ruiqin Xiong, Siwei Ma, Debin Zhao", 
    "title": "Image Super-Resolution via Dual-Dictionary Learning And Sparse   Representation", 
    "arxiv-id": "1208.3723v1", 
    "author": "Debin Zhao", 
    "publish": "2012-08-18T03:00:03Z", 
    "summary": "Learning-based image super-resolution aims to reconstruct high-frequency (HF)\ndetails from the prior model trained by a set of high- and low-resolution image\npatches. In this paper, HF to be estimated is considered as a combination of\ntwo components: main high-frequency (MHF) and residual high-frequency (RHF),\nand we propose a novel image super-resolution method via dual-dictionary\nlearning and sparse representation, which consists of the main dictionary\nlearning and the residual dictionary learning, to recover MHF and RHF\nrespectively. Extensive experimental results on test images validate that by\nemploying the proposed two-layer progressive scheme, more image details can be\nrecovered and much better results can be achieved than the state-of-the-art\nalgorithms in terms of both PSNR and visual perception."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.3901v2", 
    "other_authors": "Igor G. Olaizola, Marco Quartulli, Julian Florez, Basilio Sierra", 
    "title": "Trace transform based method for color image domain identification", 
    "arxiv-id": "1208.3901v2", 
    "author": "Basilio Sierra", 
    "publish": "2012-08-19T22:21:19Z", 
    "summary": "Context categorization is a fundamental pre-requisite for multi-domain\nmultimedia content analysis applications in order to manage contextual\ninformation in an efficient manner. In this paper, we introduce a new color\nimage context categorization method (DITEC) based on the trace transform. The\nproblem of dimensionality reduction of the obtained trace transform signal is\naddressed through statistical descriptors that keep the underlying information.\nThese extracted features offer a highly discriminant behavior for content\ncategorization. The theoretical properties of the method are analyzed and\nvalidated experimentally through two different datasets."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.4316v1", 
    "other_authors": "Sreeraj. M, Sumam Mary Idicula", 
    "title": "An Online Character Recognition System to Convert Grantha Script to   Malayalam", 
    "arxiv-id": "1208.4316v1", 
    "author": "Sumam Mary Idicula", 
    "publish": "2012-08-21T17:40:15Z", 
    "summary": "This paper presents a novel approach to recognize Grantha, an ancient script\nin South India and converting it to Malayalam, a prevalent language in South\nIndia using online character recognition mechanism. The motivation behind this\nwork owes its credit to (i) developing a mechanism to recognize Grantha script\nin this modern world and (ii) affirming the strong connection among Grantha and\nMalayalam. A framework for the recognition of Grantha script using online\ncharacter recognition is designed and implemented. The features extracted from\nthe Grantha script comprises mainly of time-domain features based on writing\ndirection and curvature. The recognized characters are mapped to corresponding\nMalayalam characters. The framework was tested on a bed of medium length\nmanuscripts containing 9-12 sample lines and printed pages of a book titled\nSoundarya Lahari writtenin Grantha by Sri Adi Shankara to recognize the words\nand sentences. The manuscript recognition rates with the system are for Grantha\nas 92.11%, Old Malayalam 90.82% and for new Malayalam script 89.56%. The\nrecognition rates of pages of the printed book are for Grantha as 96.16%, Old\nMalayalam script 95.22% and new Malayalam script as 92.32% respectively. These\nresults show the efficiency of the developed system."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.4842v1", 
    "other_authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar", 
    "title": "The Segmentation Fusion Method On10 Multi-Sensors", 
    "arxiv-id": "1208.4842v1", 
    "author": "N. V. Kalyankar", 
    "publish": "2012-08-23T14:55:30Z", 
    "summary": "The most significant problem may be undesirable effects for the spectral\nsignatures of fused images as well as the benefits of using fused images mostly\ncompared to their source images were acquired at the same time by one sensor.\nThey may or may not be suitable for the fusion of other images. It becomes\ntherefore increasingly important to investigate techniques that allow\nmulti-sensor, multi-date image fusion to make final conclusions can be drawn on\nthe most suitable method of fusion. So, In this study we present a new method\nSegmentation Fusion method (SF) for remotely sensed images is presented by\nconsidering the physical characteristics of sensors, which uses a feature level\nprocessing paradigm. In a particularly, attempts to test the proposed method\nperformance on 10 multi-sensor images and comparing it with different fusion\ntechniques for estimating the quality and degree of information improvement\nquantitatively by using various spatial and spectral metrics."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.5016v1", 
    "other_authors": "Ender Konukoglu, Ben Glocker, Antonio Criminisi, Kilian M. Pohl", 
    "title": "WESD - Weighted Spectral Distance for Measuring Shape Dissimilarity", 
    "arxiv-id": "1208.5016v1", 
    "author": "Kilian M. Pohl", 
    "publish": "2012-08-24T17:38:46Z", 
    "summary": "This article presents a new distance for measuring shape dissimilarity\nbetween objects. Recent publications introduced the use of eigenvalues of the\nLaplace operator as compact shape descriptors. Here, we revisit the eigenvalues\nto define a proper distance, called Weighted Spectral Distance (WESD), for\nquantifying shape dissimilarity. The definition of WESD is derived through\nanalysing the heat-trace. This analysis provides the proposed distance an\nintuitive meaning and mathematically links it to the intrinsic geometry of\nobjects. We analyse the resulting distance definition, present and prove its\nimportant theoretical properties. Some of these properties include: i) WESD is\ndefined over the entire sequence of eigenvalues yet it is guaranteed to\nconverge, ii) it is a pseudometric, iii) it is accurately approximated with a\nfinite number of eigenvalues, and iv) it can be mapped to the [0,1) interval.\nLastly, experiments conducted on synthetic and real objects are presented.\nThese experiments highlight the practical benefits of WESD for applications in\nvision and medical image analysis."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.5451v1", 
    "other_authors": "Zhongwei Tang, Alexey Castrodad, Mariano Tepper, Guillermo Sapiro", 
    "title": "Are You Imitating Me? Unsupervised Sparse Modeling for Group Activity   Analysis from a Single Video", 
    "arxiv-id": "1208.5451v1", 
    "author": "Guillermo Sapiro", 
    "publish": "2012-08-27T17:21:39Z", 
    "summary": "A framework for unsupervised group activity analysis from a single video is\nhere presented. Our working hypothesis is that human actions lie on a union of\nlow-dimensional subspaces, and thus can be efficiently modeled as sparse linear\ncombinations of atoms from a learned dictionary representing the action's\nprimitives. Contrary to prior art, and with the primary goal of spatio-temporal\naction grouping, in this work only one single video segment is available for\nboth unsupervised learning and analysis without any prior training information.\nAfter extracting simple features at a single spatio-temporal scale, we learn a\ndictionary for each individual in the video during each short time lapse. These\ndictionaries allow us to compare the individuals' actions by producing an\naffinity matrix which contains sufficient discriminative information about the\nactions in the scene leading to grouping with simple and efficient tools. With\ndiverse publicly available real videos, we demonstrate the effectiveness of the\nproposed framework and its robustness to cluttered backgrounds, changes of\nhuman appearance, and action variability."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ISCAS.2012.6271583", 
    "link": "http://arxiv.org/pdf/1208.6137v1", 
    "other_authors": "Deepak Kumar, M N Anil Prasad, A G Ramakrishnan", 
    "title": "Benchmarking recognition results on word image datasets", 
    "arxiv-id": "1208.6137v1", 
    "author": "A G Ramakrishnan", 
    "publish": "2012-08-30T11:24:44Z", 
    "summary": "We have benchmarked the maximum obtainable recognition accuracy on various\nword image datasets using manual segmentation and a currently available\ncommercial OCR. We have developed a Matlab program, with graphical user\ninterface, for semi-automated pixel level segmentation of word images. We\ndiscuss the advantages of pixel level annotation. We have covered five\ndatabases adding up to over 3600 word images. These word images have been\ncropped from camera captured scene, born-digital and street view images. We\nrecognize the segmented word image using the trial version of Nuance Omnipage\nOCR. We also discuss, how the degradations introduced during acquisition or\ninaccuracies introduced during creation of word images affect the recognition\nof the word present in the image. Word images for different kinds of\ndegradations and correction for slant and curvy nature of words are also\ndiscussed. The word recognition rates obtained on ICDAR 2003, Sign evaluation,\nStreet view, Born-digital and ICDAR 2011 datasets are 83.9%, 89.3%, 79.6%,\n88.5% and 86.7% respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1208.6335v1", 
    "other_authors": "Aman Chadha, Sushmit Mallik, Ravdeep Johar", 
    "title": "Comparative Study and Optimization of Feature-Extraction Techniques for   Content based Image Retrieval", 
    "arxiv-id": "1208.6335v1", 
    "author": "Ravdeep Johar", 
    "publish": "2012-08-30T23:50:06Z", 
    "summary": "The aim of a Content-Based Image Retrieval (CBIR) system, also known as Query\nby Image Content (QBIC), is to help users to retrieve relevant images based on\ntheir contents. CBIR technologies provide a method to find images in large\ndatabases by using unique descriptors from a trained image. The image\ndescriptors include texture, color, intensity and shape of the object inside an\nimage. Several feature-extraction techniques viz., Average RGB, Color Moments,\nCo-occurrence, Local Color Histogram, Global Color Histogram and Geometric\nMoment have been critically compared in this paper. However, individually these\ntechniques result in poor performance. So, combinations of these techniques\nhave also been evaluated and results for the most efficient combination of\ntechniques have been presented and optimized for each class of image query. We\nalso propose an improvement in image retrieval performance by introducing the\nidea of Query modification through image cropping. It enables the user to\nidentify a region of interest and modify the initial query to refine and\npersonalize the image retrieval results."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1181v1", 
    "other_authors": "Nilanjan Dey, Anamitra Bardhan Roy, Moumita Pal, Achintya Das", 
    "title": "FCM Based Blood Vessel Segmentation Method for Retinal Images", 
    "arxiv-id": "1209.1181v1", 
    "author": "Achintya Das", 
    "publish": "2012-09-06T05:12:53Z", 
    "summary": "Segmentation of blood vessels in retinal images provides early diagnosis of\ndiseases like glaucoma, diabetic retinopathy and macular degeneration. Among\nthese diseases occurrence of Glaucoma is most frequent and has serious ocular\nconsequences that can even lead to blindness, if it is not detected early. The\nclinical criteria for the diagnosis of glaucoma include intraocular pressure\nmeasurement, optic nerve head evaluation, retinal nerve fiber layer and visual\nfield defects. This form of blood vessel segmentation helps in early detection\nfor ophthalmic diseases, and potentially reduces the risk of blindness. The\nlow-contrast images at the retina owing to narrow blood vessels of the retina\nare difficult to extract. These low contrast images are, however useful in\nrevealing certain systemic diseases. Motivated by the goals of improving\ndetection of such vessels, this present work proposes an algorithm for\nsegmentation of blood vessels and compares the results between expert\nophthalmologist hand-drawn ground-truths and segmented image(i.e. the output of\nthe present work).Sensitivity, specificity, positive predictive value (PPV),\npositive likelihood ratio (PLR) and accuracy are used to evaluate overall\nperformance.It is found that this work segments blood vessels successfully with\nsensitivity, specificity, PPV, PLR and accuracy of 99.62%, 54.66%, 95.08%,\n219.72 and 95.03%, respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1224v1", 
    "other_authors": "Nilanjan Dey, Achintya Das, Sheli Sinha Chaudhuri", 
    "title": "Wavelet Based Normal and Abnormal Heart Sound Identification using   Spectrogram Analysis", 
    "arxiv-id": "1209.1224v1", 
    "author": "Sheli Sinha Chaudhuri", 
    "publish": "2012-09-06T08:37:44Z", 
    "summary": "The present work proposes a computer-aided normal and abnormal heart sound\nidentification based on Discrete Wavelet Transform (DWT), it being useful for\ntele-diagnosis of heart diseases. Due to the presence of Cumulative Frequency\ncomponents in the spectrogram, DWT is applied on the spectro-gram up to n level\nto extract the features from the individual approximation components. One\ndimensional feature vector is obtained by evaluating the Row Mean of the\napproximation components of these spectrograms. For this present approach, the\nset of spectrograms has been considered as the database, rather than raw sound\nsamples. Minimum Euclidean distance is computed between feature vector of the\ntest sample and the feature vectors of the stored samples to identify the heart\nsound. By applying this algorithm, almost 82% of accuracy was achieved."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1558v1", 
    "other_authors": "Nilanjan Dey, Pradipti Nandi, Nilanjana Barman, Debolina Das, Subhabrata Chakraborty", 
    "title": "A Comparative Study between Moravec and Harris Corner Detection of Noisy   Images Using Adaptive Wavelet Thresholding Technique", 
    "arxiv-id": "1209.1558v1", 
    "author": "Subhabrata Chakraborty", 
    "publish": "2012-09-07T14:52:02Z", 
    "summary": "In this paper a comparative study between Moravec and Harris Corner Detection\nhas been done for obtaining features required to track and recognize objects\nwithin a noisy image. Corner detection of noisy images is a challenging task in\nimage processing. Natural images often get corrupted by noise during\nacquisition and transmission. As Corner detection of these noisy images does\nnot provide desired results, hence de-noising is required. Adaptive wavelet\nthresholding approach is applied for the same."
},{
    "category": "cs.CV", 
    "doi": "10.5120/8320-1959", 
    "link": "http://arxiv.org/pdf/1209.1563v1", 
    "other_authors": "Sayantan Mukhopadhyay, Shouvik Biswas, Anamitra Bardhan Roy, Nilanjan Dey", 
    "title": "Wavelet Based QRS Complex Detection of ECG Signal", 
    "arxiv-id": "1209.1563v1", 
    "author": "Nilanjan Dey", 
    "publish": "2012-09-07T15:05:57Z", 
    "summary": "The Electrocardiogram (ECG) is a sensitive diagnostic tool that is used to\ndetect various cardiovascular diseases by measuring and recording the\nelectrical activity of the heart in exquisite detail. A wide range of heart\ncondition is determined by thorough examination of the features of the ECG\nreport. Automatic extraction of time plane features is important for\nidentification of vital cardiac diseases. This paper presents a\nmulti-resolution wavelet transform based system for detection 'P', 'Q', 'R',\n'S', 'T' peaks complex from original ECG signal. 'R-R' time lapse is an\nimportant minutia of the ECG signal that corresponds to the heartbeat of the\nconcerned person. Abrupt increase in height of the 'R' wave or changes in the\nmeasurement of the 'R-R' denote various anomalies of human heart. Similarly\n'P-P', 'Q-Q', 'S-S', 'T-T' also corresponds to different anomalies of heart and\ntheir peak amplitude also envisages other cardiac diseases. In this proposed\nmethod the 'PQRST' peaks are marked and stored over the entire signal and the\ntime interval between two consecutive 'R' peaks and other peaks interval are\nmeasured to detect anomalies in behavior of heart, if any. The peaks are\nachieved by the composition of Daubeheissub bands wavelet of original ECG\nsignal. The accuracy of the 'PQRST' complex detection and interval measurement\nis achieved up to 100% with high exactitude by processing and thresholding the\noriginal ECG signal."
},{
    "category": "cs.CV", 
    "doi": "10.1109/3DIMPVT.2012.12", 
    "link": "http://arxiv.org/pdf/1209.1759v1", 
    "other_authors": "Yani Ioannou, Babak Taati, Robin Harrap, Michael Greenspan", 
    "title": "Difference of Normals as a Multi-Scale Operator in Unorganized Point   Clouds", 
    "arxiv-id": "1209.1759v1", 
    "author": "Michael Greenspan", 
    "publish": "2012-09-08T22:43:28Z", 
    "summary": "A novel multi-scale operator for unorganized 3D point clouds is introduced.\nThe Difference of Normals (DoN) provides a computationally efficient,\nmulti-scale approach to processing large unorganized 3D point clouds. The\napplication of DoN in the multi-scale filtering of two different real-world\noutdoor urban LIDAR scene datasets is quantitatively and qualitatively\ndemonstrated. In both datasets the DoN operator is shown to segment large 3D\npoint clouds into scale-salient clusters, such as cars, people, and lamp posts\ntowards applications in semi-automatic annotation, and as a pre-processing step\nin automatic object recognition. The application of the operator to\nsegmentation is evaluated on a large public dataset of outdoor LIDAR scenes\nwith ground truth annotations."
},{
    "category": "cs.CV", 
    "doi": "10.1109/3DIMPVT.2012.12", 
    "link": "http://arxiv.org/pdf/1209.1788v1", 
    "other_authors": "Elsa E. Moschetti, M. Gabriela Palacio, Mery Picco, Oscar H. Bustos, Alejandro C. Frery", 
    "title": "On the Use of Lee's Protocol for Speckle-Reducing Techniques", 
    "arxiv-id": "1209.1788v1", 
    "author": "Alejandro C. Frery", 
    "publish": "2012-09-09T10:30:08Z", 
    "summary": "This paper presents two new MAP (Maximum a Posteriori) filters for speckle\nnoise reduction and a Monte Carlo procedure for the assessment of their\nperformance. In order to quantitatively evaluate the results obtained using\nthese new filters, with respect to classical ones, a Monte Carlo extension of\nLee's protocol is proposed. This extension of the protocol shows that its\noriginal version leads to inconsistencies that hamper its use as a general\nprocedure for filter assessment. Some solutions for these inconsistencies are\nproposed, and a consistent comparison of speckle-reducing filters is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1109/3DIMPVT.2012.12", 
    "link": "http://arxiv.org/pdf/1209.2082v3", 
    "other_authors": "Guangcan Liu, Shiyu Chang, Yi Ma", 
    "title": "Blind Image Deblurring by Spectral Properties of Convolution Operators", 
    "arxiv-id": "1209.2082v3", 
    "author": "Yi Ma", 
    "publish": "2012-09-10T18:19:36Z", 
    "summary": "In this paper, we study the problem of recovering a sharp version of a given\nblurry image when the blur kernel is unknown. Previous methods often introduce\nan image-independent regularizer (such as Gaussian or sparse priors) on the\ndesired blur kernel. We shall show that the blurry image itself encodes rich\ninformation about the blur kernel. Such information can be found through\nanalyzing and comparing how the spectrum of an image as a convolution operator\nchanges before and after blurring. Our analysis leads to an effective convex\nregularizer on the blur kernel which depends only on the given blurry image. We\nshow that the minimizer of this regularizer guarantees to give good\napproximation to the blur kernel if the original image is sharp enough. By\ncombining this powerful regularizer with conventional image deblurring\ntechniques, we show how we could significantly improve the deblurring results\nthrough simulations and experiments on real images. In addition, our analysis\nand experiments help explaining a widely accepted doctrine; that is, the edges\nare good features for deblurring."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3308", 
    "link": "http://arxiv.org/pdf/1209.2515v1", 
    "other_authors": "V. J. Rehna, M. K. Jeya Kumar", 
    "title": "Wavelet Based Image Coding Schemes : A Recent Survey", 
    "arxiv-id": "1209.2515v1", 
    "author": "M. K. Jeya Kumar", 
    "publish": "2012-09-12T08:08:50Z", 
    "summary": "A variety of new and powerful algorithms have been developed for image\ncompression over the years. Among them the wavelet-based image compression\nschemes have gained much popularity due to their overlapping nature which\nreduces the blocking artifacts that are common phenomena in JPEG compression\nand multiresolution character which leads to superior energy compaction with\nhigh quality reconstructed images. This paper provides a detailed survey on\nsome of the popular wavelet coding techniques such as the Embedded Zerotree\nWavelet (EZW) coding, Set Partitioning in Hierarchical Tree (SPIHT) coding, the\nSet Partitioned Embedded Block (SPECK) Coder, and the Embedded Block Coding\nwith Optimized Truncation (EBCOT) algorithm. Other wavelet-based coding\ntechniques like the Wavelet Difference Reduction (WDR) and the Adaptive Scanned\nWavelet Difference Reduction (ASWDR) algorithms, the Space Frequency\nQuantization (SFQ) algorithm, the Embedded Predictive Wavelet Image Coder\n(EPWIC), Compression with Reversible Embedded Wavelet (CREW), the Stack-Run\n(SR) coding and the recent Geometric Wavelet (GW) coding are also discussed.\nBased on the review, recommendations and discussions are presented for\nalgorithm development and implementation."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3308", 
    "link": "http://arxiv.org/pdf/1209.2816v1", 
    "other_authors": "S. Padmavathi, B. Priyalakshmi. Dr. K. P. Soman", 
    "title": "Hirarchical Digital Image Inpainting Using Wavelets", 
    "arxiv-id": "1209.2816v1", 
    "author": "B. Priyalakshmi. Dr. K. P. Soman", 
    "publish": "2012-09-13T08:40:17Z", 
    "summary": "Inpainting is the technique of reconstructing unknown or damaged portions of\nan image in a visually plausible way. Inpainting algorithm automatically fills\nthe damaged region in an image using the information available in undamaged\nregion. Propagation of structure and texture information becomes a challenge as\nthe size of damaged area increases. In this paper, a hierarchical inpainting\nalgorithm using wavelets is proposed. The hierarchical method tries to keep the\nmask size smaller while wavelets help in handling the high pass structure\ninformation and low pass texture information separately. The performance of the\nproposed algorithm is tested using different factors. The results of our\nalgorithm are compared with existing methods such as interpolation, diffusion\nand exemplar techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijsc.2012.3308", 
    "link": "http://arxiv.org/pdf/1209.2903v1", 
    "other_authors": "Nilanjan Dey, Pradipti Nandi, Nilanjana Barman", 
    "title": "A Novel Approach of Harris Corner Detection of Noisy Images using   Adaptive Wavelet Thresholding Technique", 
    "arxiv-id": "1209.2903v1", 
    "author": "Nilanjana Barman", 
    "publish": "2012-09-13T14:15:16Z", 
    "summary": "In this paper we propose a method of corner detection for obtaining features\nwhich is required to track and recognize objects within a noisy image. Corner\ndetection of noisy images is a challenging task in image processing. Natural\nimages often get corrupted by noise during acquisition and transmission. Though\nCorner detection of these noisy images does not provide desired results, hence\nde-noising is required. Adaptive wavelet thresholding approach is applied for\nthe same."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.3113v1", 
    "other_authors": "Baran Tander, Atilla \u00d6zmen, Murat Ba\u015fkan", 
    "title": "Detection and Classification of Viewer Age Range Smart Signs at TV   Broadcast", 
    "arxiv-id": "1209.3113v1", 
    "author": "Murat Ba\u015fkan", 
    "publish": "2012-09-14T07:52:09Z", 
    "summary": "In this paper, the identification and classification of Viewer Age Range\nSmart Signs, designed by the Radio and Television Supreme Council of Turkey, to\ngive age range information for the TV viewers, are realized. Therefore, the\nautomatic detection at the broadcast will be possible, enabling the\nmanufacturing of TV receivers which are sensible to these signs. The most\nimportant step at this process is the pattern recognition. Since the symbols\nthat must be identified are circular, various circle detection techniques can\nbe employed. In our study, first, two different circle segmentation methods for\nstill images are analyzed, their advantages and drawbacks are discussed. A\npopular neural network structure called Multilayer Perceptron is employed for\nthe classification. Afterwards, the same procedures are carried out for\nstreaming video. All of the steps depicted above are realized on a standard PC."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.4317v1", 
    "other_authors": "Haichao Zhang, David Wipf, Yanning Zhang", 
    "title": "Image Super-Resolution via Sparse Bayesian Modeling of Natural Images", 
    "arxiv-id": "1209.4317v1", 
    "author": "Yanning Zhang", 
    "publish": "2012-09-19T18:02:41Z", 
    "summary": "Image super-resolution (SR) is one of the long-standing and active topics in\nimage processing community. A large body of works for image super resolution\nformulate the problem with Bayesian modeling techniques and then obtain its\nMaximum-A-Posteriori (MAP) solution, which actually boils down to a regularized\nregression task over separable regularization term. Although straightforward,\nthis approach cannot exploit the full potential offered by the probabilistic\nmodeling, as only the posterior mode is sought. Also, the separable property of\nthe regularization term can not capture any correlations between the sparse\ncoefficients, which sacrifices much on its modeling accuracy. We propose a\nBayesian image SR algorithm via sparse modeling of natural images. The sparsity\nproperty of the latent high resolution image is exploited by introducing latent\nvariables into the high-order Markov Random Field (MRF) which capture the\ncontent adaptive variance by pixel-wise adaptation. The high-resolution image\nis estimated via Empirical Bayesian estimation scheme, which is substantially\nfaster than our previous approach based on Markov Chain Monte Carlo sampling\n[1]. It is shown that the actual cost function for the proposed approach\nactually incorporates a non-factorial regularization term over the sparse\ncoefficients. Experimental results indicate that the proposed method can\ngenerate competitive or better results than \\emph{state-of-the-art} SR\nalgorithms."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.4419v1", 
    "other_authors": "Chao Wang", 
    "title": "Head Frontal-View Identification Using Extended LLE", 
    "arxiv-id": "1209.4419v1", 
    "author": "Chao Wang", 
    "publish": "2012-09-20T04:15:39Z", 
    "summary": "Automatic head frontal-view identification is challenging due to appearance\nvariations caused by pose changes, especially without any training samples. In\nthis paper, we present an unsupervised algorithm for identifying frontal view\namong multiple facial images under various yaw poses (derived from the same\nperson). Our approach is based on Locally Linear Embedding (LLE), with the\nassumption that with yaw pose being the only variable, the facial images should\nlie in a smooth and low dimensional manifold. We horizontally flip the facial\nimages and present two K-nearest neighbor protocols for the original images and\nthe flipped images, respectively. In the proposed extended LLE, for any facial\nimage (original or flipped one), we search (1) the Ko nearest neighbors among\nthe original facial images and (2) the Kf nearest neighbors among the flipped\nfacial images to construct the same neighborhood graph. The extended LLE\neliminates the differences (because of background, face position and scale in\nthe whole image and some asymmetry of left-right face) between the original\nfacial image and the flipped facial image at the same yaw pose so that the\nflipped facial images can be used effectively. Our approach does not need any\ntraining samples as prior information. The experimental results show that the\nfrontal view of head can be identified reliably around the lowest point of the\npose manifold for multiple facial images, especially the cropped facial images\n(little background and centered face)."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.4420v1", 
    "other_authors": "Lan-Ting LI", 
    "title": "An Efficient Color Face Verification Based on 2-Directional   2-Dimensional Feature Extraction", 
    "arxiv-id": "1209.4420v1", 
    "author": "Lan-Ting LI", 
    "publish": "2012-09-20T04:20:40Z", 
    "summary": "A novel and uniform framework for face verification is presented in this\npaper. First of all, a 2-directional 2-dimensional feature extraction method is\nadopted to extract client-specific template - 2D discrimant projection matrix.\nThen the face skin color information is utilized as an additive feature to\nenhance decision making strategy that makes use of not only 2D grey feature but\nalso 2D skin color feature. A fusion decision of both is applied to experiment\nthe performance on the XM2VTS database according to Lausanne protocol.\nExperimental results show that the framework achieves high verification\naccuracy and verification speed."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5039v1", 
    "other_authors": "Jaswinder Singh Dilawari, Ravinder Khanna", 
    "title": "Creation of Digital Test Form for Prepress Department", 
    "arxiv-id": "1209.5039v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-23T07:52:01Z", 
    "summary": "The main problem in colour management in prepress department is lack of\navailability of literature on colour management and knowledge gap between\nprepress department and press department. So a digital test from has been\ncreated by Adobe Photoshop to analyse the ICC profile and to create a new\nprofile and this analysed data is used to study about various grey scale of RGB\nand CMYK images. That helps in conversion of image from RGB to CMYK in prepress\ndepartment."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5040v1", 
    "other_authors": "Jaswinder Singh Dilawari, Ravinder Khanna", 
    "title": "Image Classification and Optimized Image Reproduction", 
    "arxiv-id": "1209.5040v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-23T08:11:27Z", 
    "summary": "By taking into account the properties and limitations of the human visual\nsystem, images can be more efficiently compressed, colors more accurately\nreproduced, prints better rendered. To show all these advantages in this paper\nnew adapted color charts have been created based on technical and visual image\ncategory analysis. A number of tests have been carried out using extreme images\nwith their key information strictly in dark and light areas. It was shown that\nthe image categorization using the adapted color charts improves the analysis\nof relevant image information with regard to both the image gradation and the\ndetail reproduction. The images with key information in hi-key areas were also\ntest printed using the adapted color charts."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5041v1", 
    "other_authors": "Jaswinder Singh Dilawari, Ravinder Khanna", 
    "title": "An Implementation of Computer Graphics as Prepress Image Enhancement   Process", 
    "arxiv-id": "1209.5041v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-23T09:15:20Z", 
    "summary": "The production of a printed product involves three stages: prepress, the\nprinting process (press) itself, and finishing (post press). There are various\ntypes of equipments (printers, scanners) and various qualities image are\npresent in the market. These give different color rendering each time during\nreproduction. So, a color key tool has been developed keeping Color Management\nScheme (CMS) in mind so that during reproduction no color rendering takes place\nirrespective of use of any device and resolution level has also been improved."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5417v1", 
    "other_authors": "Hesam Ekhtiyar, Mehdi Sheida, Somaye Sobati Moghadam", 
    "title": "Model based neuro-fuzzy ASR on Texas processor", 
    "arxiv-id": "1209.5417v1", 
    "author": "Somaye Sobati Moghadam", 
    "publish": "2012-09-24T20:47:27Z", 
    "summary": "In this paper an algorithm for recognizing speech has been proposed. The\nrecognized speech is used to execute related commands which use the MFCC and\ntwo kind of classifiers, first one uses MLP and second one uses fuzzy inference\nsystem as a classifier. The experimental results demonstrate the high gain and\nefficiency of the proposed algorithm. We have implemented this system based on\ngraphical design and tested on a fix point digital signal processor (DSP) of\n600 MHz, with reference DM6437-EVM of Texas instrument."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5494v1", 
    "other_authors": "Nafiza Saidin, Harsa Amylia Mat Sakim, Umi Kalthum Ngah, Ibrahim Lutfi Shuaib", 
    "title": "Segmentation of Breast Regions in Mammogram Based on Density: A Review", 
    "arxiv-id": "1209.5494v1", 
    "author": "Ibrahim Lutfi Shuaib", 
    "publish": "2012-09-25T04:58:55Z", 
    "summary": "The focus of this paper is to review approaches for segmentation of breast\nregions in mammograms according to breast density. Studies based on density\nhave been undertaken because of the relationship between breast cancer and\ndensity. Breast cancer usually occurs in the fibroglandular area of breast\ntissue, which appears bright on mammograms and is described as breast density.\nMost of the studies are focused on the classification methods for glandular\ntissue detection. Others highlighted on the segmentation methods for\nfibroglandular tissue, while few researchers performed segmentation of the\nbreast anatomical regions based on density. There have also been works on the\nsegmentation of other specific parts of breast regions such as either detection\nof nipple position, skin-air interface or pectoral muscles. The problems on the\nevaluation performance of the segmentation results in relation to ground truth\nare also discussed in this paper."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.5756v1", 
    "other_authors": "Sameh Souli, Zied Lachiri", 
    "title": "Environmental Sounds Spectrogram Classification using Log-Gabor Filters   and Multiclass Support Vector Machines", 
    "arxiv-id": "1209.5756v1", 
    "author": "Zied Lachiri", 
    "publish": "2012-09-25T20:11:23Z", 
    "summary": "This paper presents novel approaches for efficient feature extraction using\nenvironmental sound magnitude spectrogram. We propose approach based on the\nvisual domain. This approach included three methods. The first method is based\non extraction for each spectrogram a single log-Gabor filter followed by mutual\ninformation procedure. In the second method, the spectrogram is passed by the\nsame steps of the first method but with an averaged bank of 12 log-Gabor\nfilter. The third method consists of spectrogram segmentation into three\npatches, and after that for each spectrogram patch we applied the second\nmethod. The classification results prove that the second method is the most\nefficient in our environmental sound classification system."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6037v1", 
    "other_authors": "Jaswinder Singh Dilawari, Ravinder Khanna", 
    "title": "Reproduction of Images by Gamut Mapping and Creation of New Test Charts   in Prepress Process", 
    "arxiv-id": "1209.6037v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-09-26T19:25:56Z", 
    "summary": "With the advent of digital images the problem of keeping picture\nvisualization uniformity arises because each printing or scanning device has\nits own color chart. So, universal color profiles are made by ICC to bring\nuniformity in various types of devices. Keeping that color profile in mind\nvarious new color charts are created and calibrated with the help of standard\nIT8 test charts available in the market. The main objective to color\nreproduction is to produce the identical picture at device output. For that\nprinciples for gamut mapping has been designed"
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6151v1", 
    "other_authors": "Thai Hoang Le, Truong Nhat Vo", 
    "title": "Face Alignment Using Active Shape Model And Support Vector Machine", 
    "arxiv-id": "1209.6151v1", 
    "author": "Truong Nhat Vo", 
    "publish": "2012-09-27T07:58:10Z", 
    "summary": "The Active Shape Model (ASM) is one of the most popular local texture models\nfor face alignment. It applies in many fields such as locating facial features\nin the image, face synthesis, etc. However, the experimental results show that\nthe accuracy of the classical ASM for some applications is not high. This paper\nsuggests some improvements on the classical ASM to increase the performance of\nthe model in the application: face alignment. Four of our major improvements\ninclude: i) building a model combining Sobel filter and the 2-D profile in\nsearching face in image; ii) applying Canny algorithm for the enhancement edge\non image; iii) Support Vector Machine (SVM) is used to classify landmarks on\nface, in order to determine exactly location of these landmarks support for\nASM; iv)automatically adjust 2-D profile in the multi-level model based on the\nsize of the input image. The experimental results on Caltech face database and\nTechnical University of Denmark database (imm_face) show that our proposed\nimprovement leads to far better performance."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6189v1", 
    "other_authors": "Nicolaie Popescu-Bodorin, Valentina E. Balas, Iulia M. Motoc", 
    "title": "The Biometric Menagerie - A Fuzzy and Inconsistent Concept", 
    "arxiv-id": "1209.6189v1", 
    "author": "Iulia M. Motoc", 
    "publish": "2012-09-27T11:24:28Z", 
    "summary": "This paper proves that in iris recognition, the concepts of sheep, goats,\nlambs and wolves - as proposed by Doddington and Yager in the so-called\nBiometric Menagerie, are at most fuzzy and at least not quite well defined.\nThey depend not only on the users or on their biometric templates, but also on\nthe parameters that calibrate the iris recognition system. This paper shows\nthat, in the case of iris recognition, the extensions of these concepts have\nvery unsharp and unstable (non-stationary) boundaries. The membership of a user\nto these categories is more often expressed as a degree (as a fuzzy value)\nrather than as a crisp value. Moreover, they are defined by fuzzy Sugeno rules\ninstead of classical (crisp) definitions. For these reasons, we said that the\nBiometric Menagerie proposed by Doddington and Yager could be at most a fuzzy\nconcept of biometry, but even this status is conditioned by improving its\ndefinition. All of these facts are confirmed experimentally in a series of 12\nexhaustive iris recognition tests undertaken for University of Bath Iris Image\nDatabase while using three different iris code dimensions (256x16, 128x8 and\n64x4), two different iris texture encoders (Log-Gabor and Haar-Hilbert) and two\ndifferent types of safety models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1209.6190v1", 
    "other_authors": "Iulia M. Motoc, Cristina M. Noaica, Robert Badea, Claudiu G. Ghica", 
    "title": "Noise Influence on the Fuzzy-Linguistic Partitioning of Iris Code Space", 
    "arxiv-id": "1209.6190v1", 
    "author": "Claudiu G. Ghica", 
    "publish": "2012-09-27T11:31:25Z", 
    "summary": "This paper analyses the set of iris codes stored or used in an iris\nrecognition system as an f-granular space. The f-granulation is given by\nidentifying in the iris code space the extensions of the fuzzy concepts wolves,\ngoats, lambs and sheep (previously introduced by Doddington as 'animals' of the\nbiometric menagerie) - which together form a partitioning of the iris code\nspace. The main question here is how objective (stable / stationary) this\npartitioning is when the iris segments are subject to noisy acquisition. In\norder to prove that the f-granulation of iris code space with respect to the\nfuzzy concepts that define the biometric menagerie is unstable in noisy\nconditions (is sensitive to noise), three types of noise (localvar, motion\nblur, salt and pepper) have been alternatively added to the iris segments\nextracted from University of Bath Iris Image Database. The results of 180\nexhaustive (all-to-all) iris recognition tests are presented and commented\nhere."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0052v1", 
    "other_authors": "ELkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine", 
    "title": "Dimensionality Reduction and Classification feature using Mutual   Information applied to Hyperspectral Images : A Filter strategy based   algorithm", 
    "arxiv-id": "1210.0052v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-09-28T23:03:00Z", 
    "summary": "Hyperspectral images (HIS) classification is a high technical remote sensing\ntool. The goal is to reproduce a thematic map that will be compared with a\nreference ground truth map (GT), constructed by expecting the region. The HIS\ncontains more than a hundred bidirectional measures, called bands (or simply\nimages), of the same region. They are taken at juxtaposed frequencies.\nUnfortunately, some bands contain redundant information, others are affected by\nthe noise, and the high dimensionality of features made the accuracy of\nclassification lower. The problematic is how to find the good bands to classify\nthe pixels of regions. Some methods use Mutual Information (MI) and threshold,\nto select relevant bands, without treatment of redundancy. Others control and\neliminate redundancy by selecting the band top ranking the MI, and if its\nneighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll accept the useful redundancy.\nA band contains useful redundancy if it contributes to produce an estimated\nreference map that has higher MI with the GT.nTo control redundancy, we\nintroduce a complementary threshold added to last value of MI. This process is\na Filter strategy; it gets a better performance of classification accuracy and\nnot expensive, but less preferment than Wrapper strategy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0115v2", 
    "other_authors": "Guangling Sun", 
    "title": "Demosaicing and Superresolution for Color Filter Array via Residual   Image Reconstruction and Sparse Representation", 
    "arxiv-id": "1210.0115v2", 
    "author": "Guangling Sun", 
    "publish": "2012-09-29T15:24:37Z", 
    "summary": "A framework of demosaicing and superresolution for color filter array (CFA)\nvia residual image reconstruction and sparse representation is presented.Given\nthe intermediate image produced by certain demosaicing and interpolation\ntechnique, a residual image between the final reconstruction image and the\nintermediate image is reconstructed using sparse representation.The final\nreconstruction image has richer edges and details than that of the intermediate\nimage. Specifically, a generic dictionary is learned from a large set of\ncomposite training data composed of intermediate data and residual data. The\nlearned dictionary implies a mapping between the two data. A specific\ndictionary adaptive to the input CFA is learned thereafter. Using the adaptive\ndictionary, the sparse coefficients of intermediate data are computed and\ntransformed to predict residual image. The residual image is added back into\nthe intermediate image to obtain the final reconstruction image. Experimental\nresults demonstrate the state-of-the-art performance in terms of PSNR and\nsubjective visual perception."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0310v2", 
    "other_authors": "Raheleh Kafieh, Hossein Rabbani, Michael D. Abramoff, Milan Sonka", 
    "title": "Intra-Retinal Layer Segmentation of 3D Optical Coherence Tomography   Using Coarse Grained Diffusion Map", 
    "arxiv-id": "1210.0310v2", 
    "author": "Milan Sonka", 
    "publish": "2012-10-01T08:52:29Z", 
    "summary": "Optical coherence tomography (OCT) is a powerful and noninvasive method for\nretinal imaging. In this paper, we introduce a fast segmentation method based\non a new variant of spectral graph theory named diffusion maps. The research is\nperformed on spectral domain (SD) OCT images depicting macular and optic nerve\nhead appearance. The presented approach does not require edge-based image\ninformation and relies on regional image texture. Consequently, the proposed\nmethod demonstrates robustness in situations of low image contrast or poor\nlayer-to-layer image gradients. Diffusion mapping is applied to 2D and 3D OCT\ndatasets composed of two steps, one for partitioning the data into important\nand less important sections, and another one for localization of internal\nlayers.In the first step, the pixels/voxels are grouped in rectangular/cubic\nsets to form a graph node.The weights of a graph are calculated based on\ngeometric distances between pixels/voxels and differences of their mean\nintensity.The first diffusion map clusters the data into three parts, the\nsecond of which is the area of interest. The other two sections are eliminated\nfrom the remaining calculations. In the second step, the remaining area is\nsubjected to another diffusion map assessment and the internal layers are\nlocalized based on their textural similarities.The proposed method was tested\non 23 datasets from two patient groups (glaucoma and normals). The mean\nunsigned border positioning errors(mean - SD) was 8.52 - 3.13 and 7.56 - 2.95\nmicrometer for the 2D and 3D methods, respectively."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0347v1", 
    "other_authors": "D. Sasirekha, E. Chandra", 
    "title": "Enhanced Techniques for PDF Image Segmentation and Text Extraction", 
    "arxiv-id": "1210.0347v1", 
    "author": "E. Chandra", 
    "publish": "2012-10-01T10:38:08Z", 
    "summary": "Extracting text objects from the PDF images is a challenging problem. The\ntext data present in the PDF images contain certain useful information for\nautomatic annotation, indexing etc. However variations of the text due to\ndifferences in text style, font, size, orientation, alignment as well as\ncomplex structure make the problem of automatic text extraction extremely\ndifficult and challenging job. This paper presents two techniques under\nblock-based classification. After a brief introduction of the classification\nmethods, two methods were enhanced and results were evaluated. The performance\nmetrics for segmentation and time consumption are tested for both the models."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0386v3", 
    "other_authors": "Junlin Hu, Ping Guo", 
    "title": "Combined Descriptors in Spatial Pyramid Domain for Image Classification", 
    "arxiv-id": "1210.0386v3", 
    "author": "Ping Guo", 
    "publish": "2012-10-01T13:05:20Z", 
    "summary": "Recently spatial pyramid matching (SPM) with scale invariant feature\ntransform (SIFT) descriptor has been successfully used in image classification.\nUnfortunately, the codebook generation and feature quantization procedures\nusing SIFT feature have the high complexity both in time and space. To address\nthis problem, in this paper, we propose an approach which combines local binary\npatterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid\ndomain. The proposed method does not need to learn the codebook and feature\nquantization processing, hence it becomes very efficient. Experiments on two\npopular benchmark datasets demonstrate that the proposed method always\nsignificantly outperforms the very popular SPM based SIFT descriptor method\nboth in time and classification accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0528v1", 
    "other_authors": "Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine", 
    "title": "Band Selection and Classification of Hyperspectral Images using Mutual   Information: An algorithm based on minimizing the error probability using the   inequality of Fano", 
    "arxiv-id": "1210.0528v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-09-28T23:36:26Z", 
    "summary": "Hyperspectral image is a substitution of more than a hundred images, called\nbands, of the same region. They are taken at juxtaposed frequencies. The\nreference image of the region is called Ground Truth map (GT). the problematic\nis how to find the good bands to classify the pixels of regions; because the\nbands can be not only redundant, but a source of confusion, and decreasing so\nthe accuracy of classification. Some methods use Mutual Information (MI) and\nthreshold, to select relevant bands. Recently there's an algorithm selection\nbased on mutual information, using bandwidth rejection and a threshold to\ncontrol and eliminate redundancy. The band top ranking the MI is selected, and\nif its neighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll make difference between\nuseful and useless redundancy. A band contains useful redundancy if it\ncontributes to decreasing error probability. According to this scheme, we\nintroduce new algorithm using also mutual information, but it retains only the\nbands minimizing the error probability of classification. To control\nredundancy, we introduce a complementary threshold. So the good band candidate\nmust contribute to decrease the last error probability augmented by the\nthreshold. This process is a wrapper strategy; it gets high performance of\nclassification accuracy but it is expensive than filter strategy."
},{
    "category": "cs.CV", 
    "doi": "10.5121/sipij.2012.3410", 
    "link": "http://arxiv.org/pdf/1210.0818v1", 
    "other_authors": "Harbi AlMahafzah, Mohammad Imran, H. S. Sheshadri", 
    "title": "Multibiometric: Feature Level Fusion Using FKP Multi-Instance biometric", 
    "arxiv-id": "1210.0818v1", 
    "author": "H. S. Sheshadri", 
    "publish": "2012-10-02T16:03:58Z", 
    "summary": "This paper proposed the use of multi-instance feature level fusion as a means\nto improve the performance of Finger Knuckle Print (FKP) verification. A\nlog-Gabor filter has been used to extract the image local orientation\ninformation, and represent the FKP features. Experiments are performed using\nthe FKP database, which consists of 7,920 images. Results indicate that the\nmulti-instance verification approach outperforms higher performance than using\nany single instance. The influence on biometric performance using feature level\nfusion under different fusion rules have been demonstrated in this paper."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6182-8612", 
    "link": "http://arxiv.org/pdf/1210.0829v1", 
    "other_authors": "Harbi AlMahafzah, Maen Zaid AlRwashdeh", 
    "title": "A Survey of Multibiometric Systems", 
    "arxiv-id": "1210.0829v1", 
    "author": "Maen Zaid AlRwashdeh", 
    "publish": "2012-10-02T16:26:39Z", 
    "summary": "Most biometric systems deployed in real-world applications are unimodal.\nUsing unimodal biometric systems have to contend with a variety of problems\nsuch as: Noise in sensed data; Intra-class variations; Inter-class\nsimilarities; Non-universality; Spoof attacks. These problems have addressed by\nusing multibiometric systems, which expected to be more reliable due to the\npresence of multiple, independent pieces of evidence."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5101", 
    "link": "http://arxiv.org/pdf/1210.1029v1", 
    "other_authors": "Guangling Sun, Guoqing Li, Jie Yin", 
    "title": "Blurred Image Classification based on Adaptive Dictionary", 
    "arxiv-id": "1210.1029v1", 
    "author": "Jie Yin", 
    "publish": "2012-10-03T08:54:01Z", 
    "summary": "Two types of framework for blurred image classification based on adaptive\ndictionary are proposed. Given a blurred image, instead of image deblurring,\nthe semantic category of the image is determined by blur insensitive sparse\ncoefficients calculated depending on an adaptive dictionary. The dictionary is\nadaptive to the Point Spread Function (PSF) estimated from input blurred image.\nThe PSF is assumed to be space invariant and inferred separately in one\nframework or updated combining with sparse coefficients calculation in an\nalternative and iterative algorithm in the other framework. The experiment has\nevaluated three types of blur, naming defocus blur, simple motion blur and\ncamera shake blur. The experiment results confirm the effectiveness of the\nproposed frameworks."
},{
    "category": "cs.CV", 
    "doi": "10.5121/ijma.2013.5101", 
    "link": "http://arxiv.org/pdf/1210.1033v1", 
    "other_authors": "Guangling Sun, Guoqing Li, Xinpeng Zhang", 
    "title": "Robust Degraded Face Recognition Using Enhanced Local Frequency   Descriptor and Multi-scale Competition", 
    "arxiv-id": "1210.1033v1", 
    "author": "Xinpeng Zhang", 
    "publish": "2012-10-03T09:02:51Z", 
    "summary": "Recognizing degraded faces from low resolution and blurred images are common\nyet challenging task. Local Frequency Descriptor (LFD) has been proved to be\neffective for this task yet it is extracted from a spatial neighborhood of a\npixel of a frequency plane independently regardless of correlations between\nfrequencies. In addition, it uses a fixed window size named single scale of\nshort-term Frequency transform (STFT). To explore the frequency correlations\nand preserve low resolution and blur insensitive simultaneously, we propose\nEnhanced LFD in which information in space and frequency is jointly utilized so\nas to be more descriptive and discriminative than LFD. The multi-scale\ncompetition strategy that extracts multiple descriptors corresponding to\nmultiple window sizes of STFT and take one corresponding to maximum confidence\nas the final recognition result. The experiments conducted on Yale and FERET\ndatabases demonstrate that promising results have been achieved by the proposed\nEnhanced LFD and multi-scale competition strategy."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2014.03.013", 
    "link": "http://arxiv.org/pdf/1210.1316v2", 
    "other_authors": "Xi Peng, Lei Zhang, Zhang Yi, Kok Kiong Tan", 
    "title": "Learning Locality-Constrained Collaborative Representation for Face   Recognition", 
    "arxiv-id": "1210.1316v2", 
    "author": "Kok Kiong Tan", 
    "publish": "2012-10-04T07:12:49Z", 
    "summary": "The model of low-dimensional manifold and sparse representation are two\nwell-known concise models that suggest each data can be described by a few\ncharacteristics. Manifold learning is usually investigated for dimension\nreduction by preserving some expected local geometric structures from the\noriginal space to a low-dimensional one. The structures are generally\ndetermined by using pairwise distance, e.g., Euclidean distance. Alternatively,\nsparse representation denotes a data point as a linear combination of the\npoints from the same subspace. In practical applications, however, the nearby\npoints in terms of pairwise distance may not belong to the same subspace, and\nvice versa. Consequently, it is interesting and important to explore how to get\na better representation by integrating these two models together. To this end,\nthis paper proposes a novel coding algorithm, called Locality-Constrained\nCollaborative Representation (LCCR), which improves the robustness and\ndiscrimination of data representation by introducing a kind of local\nconsistency. The locality term derives from a biologic observation that the\nsimilar inputs have similar code. The objective function of LCCR has an\nanalytical solution, and it does not involve local minima. The empirical\nstudies based on four public facial databases, ORL, AR, Extended Yale B, and\nMultiple PIE, show that LCCR is promising in recognizing human faces from\nfrontal views with varying expression and illumination, as well as various\ncorruptions and occlusions."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2014.03.013", 
    "link": "http://arxiv.org/pdf/1210.1916v1", 
    "other_authors": "Meftah Ur Rahman", 
    "title": "A comparative study on face recognition techniques and neural network", 
    "arxiv-id": "1210.1916v1", 
    "author": "Meftah Ur Rahman", 
    "publish": "2012-10-06T06:37:51Z", 
    "summary": "In modern times, face recognition has become one of the key aspects of\ncomputer vision. There are at least two reasons for this trend; the first is\nthe commercial and law enforcement applications, and the second is the\navailability of feasible technologies after years of research. Due to the very\nnature of the problem, computer scientists, neuro-scientists and psychologists\nall share a keen interest in this field. In plain words, it is a computer\napplication for automatically identifying a person from a still image or video\nframe. One of the ways to accomplish this is by comparing selected features\nfrom the image and a facial database. There are hundreds if not thousand\nfactors associated with this. In this paper some of the most common techniques\navailable including applications of neural network in facial recognition are\nstudied and compared with respect to their performance."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.patcog.2014.03.013", 
    "link": "http://arxiv.org/pdf/1210.3165v1", 
    "other_authors": "Ayatullah Faruk Mollah, Subhadip Basu, Mita Nasipuri", 
    "title": "Computationally Efficient Implementation of Convolution-based Locally   Adaptive Binarization Techniques", 
    "arxiv-id": "1210.3165v1", 
    "author": "Mita Nasipuri", 
    "publish": "2012-10-11T10:04:44Z", 
    "summary": "One of the most important steps of document image processing is binarization.\nThe computational requirements of locally adaptive binarization techniques make\nthem unsuitable for devices with limited computing facilities. In this paper,\nwe have presented a computationally efficient implementation of convolution\nbased locally adaptive binarization techniques keeping the performance\ncomparable to the original implementation. The computational complexity has\nbeen reduced from O(W2N2) to O(WN2) where WxW is the window size and NxN is the\nimage size. Experiments over benchmark datasets show that the computation time\nhas been reduced by 5 to 15 times depending on the window size while memory\nconsumption remains the same with respect to the state-of-the-art algorithmic\nimplementation."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2253484", 
    "link": "http://arxiv.org/pdf/1210.3350v1", 
    "other_authors": "Virginia Estellers, Jean-Philippe Thiran, Xavier Bresson", 
    "title": "Enhanced Compressed Sensing Recovery with Level Set Normals", 
    "arxiv-id": "1210.3350v1", 
    "author": "Xavier Bresson", 
    "publish": "2012-10-11T19:53:44Z", 
    "summary": "We propose a compressive sensing algorithm that exploits geometric properties\nof images to recover images of high quality from few measurements. The image\nreconstruction is done by iterating the two following steps: 1) estimation of\nnormal vectors of the image level curves and 2) reconstruction of an image\nfitting the normal vectors, the compressed sensing measurements and the\nsparsity constraint. The proposed technique can naturally extend to non local\noperators and graphs to exploit the repetitive nature of textured images in\norder to recover fine detail structures. In both cases, the problem is reduced\nto a series of convex minimization problems that can be efficiently solved with\na combination of variable splitting and augmented Lagrangian methods, leading\nto fast and easy-to-code algorithms. Extended experiments show a clear\nimprovement over related state-of-the-art algorithms in the quality of the\nreconstructed images and the robustness of the proposed method to noise,\ndifferent kind of images and reduced measurements."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2253484", 
    "link": "http://arxiv.org/pdf/1210.3404v2", 
    "other_authors": "St\u00e9fan J. van der Walt, B. M. Herbst", 
    "title": "A polygon-based interpolation operator for super-resolution imaging", 
    "arxiv-id": "1210.3404v2", 
    "author": "B. M. Herbst", 
    "publish": "2012-10-12T00:31:46Z", 
    "summary": "We outline the super-resolution reconstruction problem posed as a\nmaximization of probability. We then introduce an interpolation method based on\npolygonal pixel overlap, express it as a linear operator, and use it to improve\nreconstruction. Polygon interpolation outperforms the simpler bilinear\ninterpolation operator and, unlike Gaussian modeling of pixels, requires no\nparameter estimation. A free software implementation that reproduces the\nresults shown is provided."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.3832v1", 
    "other_authors": "Idan Ram, Michael Elad, Israel Cohen", 
    "title": "Image Processing using Smooth Ordering of its Patches", 
    "arxiv-id": "1210.3832v1", 
    "author": "Israel Cohen", 
    "publish": "2012-10-14T20:17:33Z", 
    "summary": "We propose an image processing scheme based on reordering of its patches. For\na given corrupted image, we extract all patches with overlaps, refer to these\nas coordinates in high-dimensional space, and order them such that they are\nchained in the \"shortest possible path\", essentially solving the traveling\nsalesman problem. The obtained ordering applied to the corrupted image, implies\na permutation of the image pixels to what should be a regular signal. This\nenables us to obtain good recovery of the clean image by applying relatively\nsimple 1D smoothing operations (such as filtering or interpolation) to the\nreordered set of pixels. We explore the use of the proposed approach to image\ndenoising and inpainting, and show promising results in both cases."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.4863v1", 
    "other_authors": "Severine Dubuisson, Christophe Gonzales, Xuan Son NGuyen", 
    "title": "DBN-Based Combinatorial Resampling for Articulated Object Tracking", 
    "arxiv-id": "1210.4863v1", 
    "author": "Xuan Son NGuyen", 
    "publish": "2012-10-16T17:38:55Z", 
    "summary": "Particle Filter is an effective solution to track objects in video sequences\nin complex situations. Its key idea is to estimate the density over the\npossible states of the object using a weighted sample whose elements are called\nparticles. One of its crucial step is a resampling step in which particles are\nresampled to avoid some degeneracy problem. In this paper, we introduce a new\nresampling method called Combinatorial Resampling that exploits some features\nof articulated objects to resample over an implicitly created sample of an\nexponential size better representing the density to estimate. We prove that it\nis sound and, through experimentations both on challenging synthetic and real\nvideo sequences, we show that it outperforms all classical resampling methods\nboth in terms of the quality of its results and in terms of response times."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.5653v1", 
    "other_authors": "Prof. Samir K. Bandyopadhyay, Biswajita Datta, Sudipta Roy", 
    "title": "Identifications of concealed weapon in a Human Body", 
    "arxiv-id": "1210.5653v1", 
    "author": "Sudipta Roy", 
    "publish": "2012-10-20T20:37:22Z", 
    "summary": "The detection of weapons concealed underneath a person cloths is very much\nimportant to the improvement of the security of the public as well as the\nsafety of public assets like airports, buildings and railway stations etc."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.5732v1", 
    "other_authors": "Jaswinder Singh Dilawari, Ravinder Khanna", 
    "title": "Developing ICC Profile Using Gray Level Control In Offset Printing   Process", 
    "arxiv-id": "1210.5732v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-10-21T14:49:30Z", 
    "summary": "In prepress department RGB image has to be converted to CMYK image. To\ncontrol that amount of black, cyan, magenta and yellow has to be controlled by\nusing color separation method. Graycolor separation method is selected to\ncontrol the amounts of these colors because it increase the quality of printing\nalso. A single printer used for printing the same image on different paper also\nresults in different printed images. To remove this problem a different ICC\nprofile based on gray level control is developedand a sheet offset printer is\ncalibrated using that profile and a subjective evaluation shows satisfactory\nresults for different quality papers."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.6157v1", 
    "other_authors": "Vibekananda Dutta, Dr Nishtha Kesswani, Deepti Gahalot", 
    "title": "Novel Architecture for 3D model in virtual communities from detected   face", 
    "arxiv-id": "1210.6157v1", 
    "author": "Deepti Gahalot", 
    "publish": "2012-10-23T07:57:24Z", 
    "summary": "In this research paper we suggest how to extract a face from an image, modify\nit, characterize it in terms of high-level properties, and apply it to the\ncreation of a personalized avatar. In this research work we tested, we\nimplemented the algorithm on several hundred facial images, including many\ntaken under uncontrolled acquisition conditions, and found to exhibit\nsatisfactory performance for immediate practical use."
},{
    "category": "cs.CV", 
    "doi": "10.1109/TIP.2013.2257813", 
    "link": "http://arxiv.org/pdf/1210.7014v2", 
    "other_authors": "Jordan Hashemi, Thiago Vallin Spina, Mariano Tepper, Amy Esler, Vassilios Morellas, Nikolaos Papanikolopoulos, Guillermo Sapiro", 
    "title": "Computer vision tools for the non-invasive assessment of autism-related   behavioral markers", 
    "arxiv-id": "1210.7014v2", 
    "author": "Guillermo Sapiro", 
    "publish": "2012-10-25T22:30:40Z", 
    "summary": "The early detection of developmental disorders is key to child outcome,\nallowing interventions to be initiated that promote development and improve\nprognosis. Research on autism spectrum disorder (ASD) suggests behavioral\nmarkers can be observed late in the first year of life. Many of these studies\ninvolved extensive frame-by-frame video observation and analysis of a child's\nnatural behavior. Although non-intrusive, these methods are extremely\ntime-intensive and require a high level of observer training; thus, they are\nimpractical for clinical and large population research purposes. Diagnostic\nmeasures for ASD are available for infants but are only accurate when used by\nspecialists experienced in early diagnosis. This work is a first milestone in a\nlong-term multidisciplinary project that aims at helping clinicians and general\npractitioners accomplish this early detection/measurement task automatically.\nWe focus on providing computer vision tools to measure and identify ASD\nbehavioral markers based on components of the Autism Observation Scale for\nInfants (AOSI). In particular, we develop algorithms to measure three critical\nAOSI activities that assess visual attention. We augment these AOSI activities\nwith an additional test that analyzes asymmetrical patterns in unsupported\ngait. The first set of algorithms involves assessing head motion by tracking\nfacial features, while the gait analysis relies on joint foreground\nsegmentation and 2D body pose estimation in video. We show results that provide\ninsightful knowledge to augment the clinician's behavioral observations\nobtained from real in-clinic assessments."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICRTIT.2011.5972443", 
    "link": "http://arxiv.org/pdf/1210.7102v1", 
    "other_authors": "B. H. Shekar, N. Harivinod, M. Sharmila Kumari, K. Raghurama Holla", 
    "title": "3D Face Recognition using Significant Point based SULD Descriptor", 
    "arxiv-id": "1210.7102v1", 
    "author": "K. Raghurama Holla", 
    "publish": "2012-10-26T11:27:33Z", 
    "summary": "In this work, we present a new 3D face recognition method based on Speeded-Up\nLocal Descriptor (SULD) of significant points extracted from the range images\nof faces. The proposed model consists of a method for extracting distinctive\ninvariant features from range images of faces that can be used to perform\nreliable matching between different poses of range images of faces. For a given\n3D face scan, range images are computed and the potential interest points are\nidentified by searching at all scales. Based on the stability of the interest\npoint, significant points are extracted. For each significant point we compute\nthe SULD descriptor which consists of vector made of values from the convolved\nHaar wavelet responses located on concentric circles centred on the significant\npoint, and where the amount of Gaussian smoothing is proportional to the radii\nof the circles. Experimental results show that the newly proposed method\nprovides higher recognition rate compared to other existing contemporary models\ndeveloped for 3D face recognition."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICRTIT.2011.5972443", 
    "link": "http://arxiv.org/pdf/1210.7403v1", 
    "other_authors": "Arnav Bhavsar", 
    "title": "Resolution Enhancement of Range Images via Color-Image Segmentation", 
    "arxiv-id": "1210.7403v1", 
    "author": "Arnav Bhavsar", 
    "publish": "2012-10-28T05:27:55Z", 
    "summary": "We report a method for super-resolution of range images. Our approach\nleverages the interpretation of LR image as sparse samples on the HR grid.\nBased on this interpretation, we demonstrate that our recently reported\napproach, which reconstructs dense range images from sparse range data by\nexploiting a registered colour image, can be applied for the task of resolution\nenhancement of range images. Our method only uses a single colour image in\naddition to the range observation in the super-resolution process. Using the\nproposed approach, we demonstrate super-resolution results for large factors\n(e.g. 4) with good localization accuracy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICRTIT.2011.5972443", 
    "link": "http://arxiv.org/pdf/1210.7631v1", 
    "other_authors": "Amelia Carolina Sparavigna", 
    "title": "The fortresses of Ejin: an example of outlining a site from satellite   images", 
    "arxiv-id": "1210.7631v1", 
    "author": "Amelia Carolina Sparavigna", 
    "publish": "2012-10-29T11:53:35Z", 
    "summary": "From 1960's to 1970's, the Chinese Army built some fortified artificial\nhills. Some of them are located in the Inner Mongolia, Western China. These\nlarge fortresses are surrounded by moats. For some of them it is still possible\nto see earthworks, trenches and ditches, the planning of which could have a\nsymbolic meaning. We can argue this result form their digital outlining,\nobtained after an image processing of satellite images, based on edge\ndetection."
},{
    "category": "cs.CV", 
    "doi": "10.5121/csit.2012.2434", 
    "link": "http://arxiv.org/pdf/1210.7669v1", 
    "other_authors": "Pooja Maknikar", 
    "title": "Performance Evaluation of Different Techniques for texture   Classification", 
    "arxiv-id": "1210.7669v1", 
    "author": "Pooja Maknikar", 
    "publish": "2012-10-29T14:05:27Z", 
    "summary": "Texture is the term used to characterize the surface of a given object or\nphenomenon and is an important feature used in image processing and pattern\nrecognition. Our aim is to compare various Texture analyzing methods and\ncompare the results based on time complexity and accuracy of classification.\nThe project describes texture classification using Wavelet Transform and Co\noccurrence Matrix. Comparison of features of a sample texture with database of\ndifferent textures is performed. In wavelet transform we use the Haar, Symlets\nand Daubechies wavelets. We find that, thee Haar wavelet proves to be the most\nefficient method in terms of performance assessment parameters mentioned above.\nComparison of Haar wavelet and Co-occurrence matrix method of classification\nalso goes in the favor of Haar. Though the time requirement is high in the\nlater method, it gives excellent results for classification accuracy except if\nthe image is rotated."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1210.8262v1", 
    "other_authors": "Nicola Rebagliati, Albert Sol\u00e9-Ribalta, Marcello Pelillo, Francesc Serratosa", 
    "title": "On the Relation Between the Common Labelling and the Median Graph", 
    "arxiv-id": "1210.8262v1", 
    "author": "Francesc Serratosa", 
    "publish": "2012-10-31T08:29:58Z", 
    "summary": "In structural pattern recognition, given a set of graphs, the computation of\na Generalized Median Graph is a well known problem. Some methods approach the\nproblem by assuming a relation between the Generalized Median Graph and the\nCommon Labelling problem. However, this relation has still not been formally\nproved. In this paper, we analyse such relation between both problems. The main\nresult proves that the cost of the common labelling upper-bounds the cost of\nthe median with respect to the given set. In addition, we show that the two\nproblems are equivalent in some cases."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0055v1", 
    "other_authors": "Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine", 
    "title": "Dimensionality Reduction and Classification Feature Using Mutual   Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm   Based on Minimizing the Error Probability Using the Inequality of Fano", 
    "arxiv-id": "1211.0055v1", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-10-31T23:30:59Z", 
    "summary": "In the feature classification domain, the choice of data affects widely the\nresults. For the Hyperspectral image, the bands dont all contain the\ninformation; some bands are irrelevant like those affected by various\natmospheric effects, see Figure.4, and decrease the classification accuracy.\nAnd there exist redundant bands to complicate the learning system and product\nincorrect prediction [14]. Even the bands contain enough information about the\nscene they may can't predict the classes correctly if the dimension of space\nimages, see Figure.3, is so large that needs many cases to detect the\nrelationship between the bands and the scene (Hughes phenomenon) [10]. We can\nreduce the dimensionality of hyperspectral images by selecting only the\nrelevant bands (feature selection or subset selection methodology), or\nextracting, from the original bands, new bands containing the maximal\ninformation about the classes, using any functions, logical or numerical\n(feature extraction methodology) [11][9]. Here we focus on the feature\nselection using mutual information. Hyperspectral images have three advantages\nregarding the multispectral images [6],"
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0191v1", 
    "other_authors": "Branko Ristic, Jamie Sherrah, \u00c1ngel F. Garc\u00eda-Fern\u00e1ndez", 
    "title": "Performance Evaluation of Random Set Based Pedestrian Tracking   Algorithms", 
    "arxiv-id": "1211.0191v1", 
    "author": "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez", 
    "publish": "2012-10-25T23:21:46Z", 
    "summary": "The paper evaluates the error performance of three random finite set based\nmulti-object trackers in the context of pedestrian video tracking. The\nevaluation is carried out using a publicly available video dataset of 4500\nframes (town centre street) for which the ground truth is available. The input\nto all pedestrian tracking algorithms is an identical set of head and body\ndetections, obtained using the Histogram of Oriented Gradients (HOG) detector.\nThe tracking error is measured using the recently proposed OSPA metric for\ntracks, adopted as the only known mathematically rigorous metric for measuring\nthe distance between two sets of tracks. A comparative analysis is presented\nunder various conditions."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0602v1", 
    "other_authors": "Jie Zhao, Wei Zheng, Li Zhang, Hua Tian", 
    "title": "Segmentation of ultrasound images of thyroid nodule for assisting fine   needle aspiration cytology", 
    "arxiv-id": "1211.0602v1", 
    "author": "Hua Tian", 
    "publish": "2012-11-03T06:55:03Z", 
    "summary": "The incidence of thyroid nodule is very high and generally increases with the\nage. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\nnodule can be completely cured if detected early. Fine needle aspiration\ncytology is a recognized early diagnosis method of thyroid nodule. There are\nstill some limitations in the fine needle aspiration cytology, and the\nultrasound diagnosis of thyroid nodule has become the first choice for\nauxiliary examination of thyroid nodular disease. If we could combine medical\nimaging technology and fine needle aspiration cytology, the diagnostic rate of\nthyroid nodule would be improved significantly. The properties of ultrasound\nwill degrade the image quality, which makes it difficult to recognize the edges\nfor physicians. Image segmentation technique based on graph theory has become a\nresearch hotspot at present. Normalized cut (Ncut) is a representative one,\nwhich is suitable for segmentation of feature parts of medical image. However,\nhow to solve the normalized cut has become a problem, which needs large memory\ncapacity and heavy calculation of weight matrix. It always generates over\nsegmentation or less segmentation which leads to inaccurate in the\nsegmentation. The speckle noise in B ultrasound image of thyroid tumor makes\nthe quality of the image deteriorate. In the light of this characteristic, we\ncombine the anisotropic diffusion model with the normalized cut in this paper.\nAfter the enhancement of anisotropic diffusion model, it removes the noise in\nthe B ultrasound image while preserves the important edges and local details.\nThis reduces the amount of computation in constructing the weight matrix of the\nimproved normalized cut and improves the accuracy of the final segmentation\nresults. The feasibility of the method is proved by the experimental results."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.0613v2", 
    "other_authors": "ELkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine", 
    "title": "Application of Symmetric Uncertainty and Mutual Information to   Dimensionality Reduction and Classification of Hyperspectral Images", 
    "arxiv-id": "1211.0613v2", 
    "author": "Driss Aboutajdine", 
    "publish": "2012-11-03T14:01:29Z", 
    "summary": "Remote sensing is a technology to acquire data for disatant substances,\nnecessary to construct a model knowledge for applications as classification.\nRecently Hyperspectral Images (HSI) becomes a high technical tool that the main\ngoal is to classify the point of a region. The HIS is more than a hundred\nbidirectional measures, called bands (or simply images), of the same region\ncalled Ground Truth Map (GT). But some bands are not relevant because they are\naffected by different atmospheric effects; others contain redundant\ninformation; and high dimensionality of HSI features make the accuracy of\nclassification lower. All these bands can be important for some applications;\nbut for the classification a small subset of these is relevant. The problematic\nrelated to HSI is the dimensionality reduction. Many studies use mutual\ninformation (MI) to select the relevant bands. Others studies use the MI\nnormalized forms, like Symmetric Uncertainty, in medical imagery applications.\nIn this paper we introduce an algorithm based also on MI to select relevant\nbands and it apply the Symmetric Uncertainty coefficient to control redundancy\nand increase the accuracy of classification. This algorithm is feature\nselection tool and a Filter strategy. We establish this study on HSI AVIRIS\n92AV3C. This is an effectiveness, and fast scheme to control redundancy."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.1252v1", 
    "other_authors": "Md. Ali Hossain, Ahsan-Ul-Ambia, Md. Aktaruzzaman, Md. Ahaduzzaman Khan", 
    "title": "Implementation of Radon Transformation for Electrical Impedance   Tomography (EIT)", 
    "arxiv-id": "1211.1252v1", 
    "author": "Md. Ahaduzzaman Khan", 
    "publish": "2012-10-16T09:46:12Z", 
    "summary": "Radon Transformation is generally used to construct optical image (like CT\nimage) from the projection data in biomedical imaging. In this paper, the\nconcept of Radon Transformation is implemented to reconstruct Electrical\nImpedance Topographic Image (conductivity or resistivity distribution) of a\ncircular subject. A parallel resistance model of a subject is proposed for\nElectrical Impedance Topography(EIT) or Magnetic Induction Tomography(MIT). A\ncircular subject with embedded circular objects is segmented into equal width\nslices from different angles. For each angle, Conductance and Conductivity of\neach slice is calculated and stored in an array. A back projection method is\nused to generate a two-dimensional image from one-dimensional projections. As a\nback projection method, Inverse Radon Transformation is applied on the\ncalculated conductance and conductivity to reconstruct two dimensional images.\nThese images are compared to the target image. In the time of image\nreconstruction, different filters are used and these images are compared with\neach other and target image."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.1482v4", 
    "other_authors": "Sajid Ali", 
    "title": "Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier   Curve and Statistical Techniques", 
    "arxiv-id": "1211.1482v4", 
    "author": "Sajid Ali", 
    "publish": "2012-11-07T08:19:04Z", 
    "summary": "Motion capture is the process of recording the movement of objects or people.\nIt is used in military, entertainment, sports, and medical applications, and\nfor validation of computer vision[2] and robotics. In filmmaking and video game\ndevelopment, it refers to recording actions of human actors, and using that\ninformation to animate digital character models in 2D or 3D computer animation.\nWhen it includes face and fingers or captures subtle"
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-34166-31_2", 
    "link": "http://arxiv.org/pdf/1211.1650v1", 
    "other_authors": "Jaswinder Singh Dilawari, Ravinder Khanna", 
    "title": "Different Operating Systems Compatible for Image Prepress Process in   Color Management: Analysis and Performance Testing", 
    "arxiv-id": "1211.1650v1", 
    "author": "Ravinder Khanna", 
    "publish": "2012-11-07T19:52:50Z", 
    "summary": "Image computing has become a real catchphrase over the past few years and the\ninterpretations of the meaning of the term vary greatly. The Imagecomputing\nmarket is currently rapidly evolving with high growth prospects and almost\ndaily announcements of new devices and application platforms, which results in\nan increasing diversification of devices, operating system and development\nplatforms. Compared to more traditional information technology markets like the\none of desktop computing, mobile computing is much less consolidated and\nneither standards nor even industry standards have yet been established. There\nare various platforms and interfaces which may be used to perform the desired\ntasks through the device. We have tried to compare the various mobile operating\nsystems and their trade-offs."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2247755", 
    "link": "http://arxiv.org/pdf/1211.1656v1", 
    "other_authors": "Yue Wu, Brian Tracey, Joseph P. Noonan", 
    "title": "James-Stein Type Center Pixel Weights for Non-Local Means Image   Denoising", 
    "arxiv-id": "1211.1656v1", 
    "author": "Joseph P. Noonan", 
    "publish": "2012-11-07T20:10:24Z", 
    "summary": "Non-Local Means (NLM) and variants have been proven to be effective and\nrobust in many image denoising tasks. In this letter, we study the parameter\nselection problem of center pixel weights (CPW) in NLM. Our key contributions\nare: 1) we give a novel formulation of the CPW problem from the statistical\nshrinkage perspective; 2) we introduce the James-Stein type CPWs for NLM; and\n3) we propose a new adaptive CPW that is locally tuned for each image pixel.\nOur experimental results showed that compared to existing CPW solutions, the\nnew proposed CPWs are more robust and effective under various noise levels. In\nparticular, the NLM with the James-Stein type CPWs attain higher means with\nsmaller variances in terms of the peak signal and noise ratio, implying they\nimprove the NLM robustness and make it less sensitive to parameter selection."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2247755", 
    "link": "http://arxiv.org/pdf/1211.1752v1", 
    "other_authors": "Abhishek Anand, Sherwin Li", 
    "title": "3D Scene Grammar for Parsing RGB-D Pointclouds", 
    "arxiv-id": "1211.1752v1", 
    "author": "Sherwin Li", 
    "publish": "2012-11-08T03:11:53Z", 
    "summary": "We pose 3D scene-understanding as a problem of parsing in a grammar. A\ngrammar helps us capture the compositional structure of real-word objects,\ne.g., a chair is composed of a seat, a back-rest and some legs. Having multiple\nrules for an object helps us capture structural variations in objects, e.g., a\nchair can optionally also have arm-rests. Finally, having rules to capture\ncomposition at different levels helps us formulate the entire scene-processing\npipeline as a single problem of finding most likely parse-tree---small segments\ncombine to form parts of objects, parts to objects and objects to a scene. We\nattach a generative probability model to our grammar by having a\nfeature-dependent probability function for every rule. We evaluated it by\nextracting labels for every segment and comparing the results with the\nstate-of-the-art segment-labeling algorithm. Our algorithm was outperformed by\nthe state-or-the-art method. But, Our model can be trained very efficiently\n(within seconds), and it scales only linearly in with the number of rules in\nthe grammar. Also, we think that this is an important problem for the 3D vision\ncommunity. So, we are releasing our dataset and related code."
},{
    "category": "cs.CV", 
    "doi": "10.1109/LSP.2013.2247755", 
    "link": "http://arxiv.org/pdf/1211.1800v1", 
    "other_authors": "Hamdi Hassen, Maher khemakhem", 
    "title": "A Comparative study of Arabic handwritten characters invariant feature", 
    "arxiv-id": "1211.1800v1", 
    "author": "Maher khemakhem", 
    "publish": "2012-11-08T09:24:21Z", 
    "summary": "This paper is practically interested in the unchangeable feature of Arabic\nhandwritten character. It presents results of comparative study achieved on\ncertain features extraction techniques of handwritten character, based on Hough\ntransform, Fourier transform, Wavelet transform and Gabor Filter. Obtained\nresults show that Hough Transform and Gabor filter are insensible to the\nrotation and translation, Fourier Transform is sensible to the rotation but\ninsensible to the translation, in contrast to Hough Transform and Gabor filter,\nWavelets Transform is sensitive to the rotation as well as to the translation."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.1968v2", 
    "other_authors": "Zhizhen Zhao, Amit Singer", 
    "title": "Fourier-Bessel rotational invariant eigenimages", 
    "arxiv-id": "1211.1968v2", 
    "author": "Amit Singer", 
    "publish": "2012-11-08T20:59:49Z", 
    "summary": "We present an efficient and accurate algorithm for principal component\nanalysis (PCA) of a large set of two dimensional images, and, for each image,\nthe set of its uniform rotations in the plane and its reflection. The algorithm\nstarts by expanding each image, originally given on a Cartesian grid, in the\nFourier-Bessel basis for the disk. Because the images are bandlimited in the\nFourier domain, we use a sampling criterion to truncate the Fourier-Bessel\nexpansion such that the maximum amount of information is preserved without the\neffect of aliasing. The constructed covariance matrix is invariant to rotation\nand reflection and has a special block diagonal structure. PCA is efficiently\ndone for each block separately. This Fourier-Bessel based PCA detects more\nmeaningful eigenimages and has improved denoising capability compared to\ntraditional PCA for a finite number of noisy images."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2007v1", 
    "other_authors": "Ridha Ejbali, Mourad Zaied, Chokri Ben Amar", 
    "title": "Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic   Units for Speech Recognition", 
    "arxiv-id": "1211.2007v1", 
    "author": "Chokri Ben Amar", 
    "publish": "2012-11-08T22:23:54Z", 
    "summary": "In this paper, we propose a novel architecture of wavelet network called\nMulti-input Multi-output Wavelet Network MIMOWN as a generalization of the old\narchitecture of wavelet network. This newel prototype was applied to speech\nrecognition application especially to model acoustic unit of speech. The\noriginality of our work is the proposal of MIMOWN to model acoustic unit of\nspeech. This approach was proposed to overcome limitation of old wavelet\nnetwork model. The use of the multi-input multi-output architecture will allows\ntraining wavelet network on various examples of acoustic units."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2037v1", 
    "other_authors": "Rehna V. J., M. K. Jeyakumar", 
    "title": "Time Complexity Analysis of Binary Space Partitioning Scheme for Image   Compression", 
    "arxiv-id": "1211.2037v1", 
    "author": "M. K. Jeyakumar", 
    "publish": "2012-11-09T03:59:48Z", 
    "summary": "Segmentation-based image coding methods provide high compression ratios when\ncompared with traditional image coding approaches like the transform and sub\nband coding for low bit-rate compression applications. In this paper, a\nsegmentation-based image coding method, namely the Binary Space Partition\nscheme, that divides the desired image using a recursive procedure for coding\nis presented. The BSP approach partitions the desired image recursively by\nusing bisecting lines, selected from a collection of discrete optional lines,\nin a hierarchical manner. This partitioning procedure generates a binary tree,\nwhich is referred to as the BSP-tree representation of the desired image. The\nalgorithm is extremely complex in computation and has high execution time. The\ntime complexity of the BSP scheme is explored in this work."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2082v1", 
    "other_authors": "C. J. Prabhakar, P. U. Praveen Kumar", 
    "title": "3D Surface Reconstruction of Underwater Objects", 
    "arxiv-id": "1211.2082v1", 
    "author": "P. U. Praveen Kumar", 
    "publish": "2012-11-09T09:17:26Z", 
    "summary": "In this paper, we propose a novel technique to reconstruct 3D surface of an\nunderwater object using stereo images. Reconstructing the 3D surface of an\nunderwater object is really a challenging task due to degraded quality of\nunderwater images. There are various reason of quality degradation of\nunderwater images i.e., non-uniform illumination of light on the surface of\nobjects, scattering and absorption effects. Floating particles present in\nunderwater produces Gaussian noise on the captured underwater images which\ndegrades the quality of images. The degraded underwater images are preprocessed\nby applying homomorphic, wavelet denoising and anisotropic filtering\nsequentially. The uncalibrated rectification technique is applied to\npreprocessed images to rectify the left and right images. The rectified left\nand right image lies on a common plane. To find the correspondence points in a\nleft and right images, we have applied dense stereo matching technique i.e.,\ngraph cut method. Finally, we estimate the depth of images using triangulation\ntechnique. The experimental result shows that the proposed method reconstruct\n3D surface of underwater objects accurately using captured underwater stereo\nimages."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2116v1", 
    "other_authors": "S Arunkumar, Pallab Kumar Sahu, Sudeep Gorai, Kalyan Ghosh", 
    "title": "Localisation of Numerical Date Field in an Indian Handwritten Document", 
    "arxiv-id": "1211.2116v1", 
    "author": "Kalyan Ghosh", 
    "publish": "2012-11-09T12:59:11Z", 
    "summary": "This paper describes a method to localise all those areas which may\nconstitute the date field in an Indian handwritten document. Spatial patterns\nof the date field are studied from various handwritten documents and an\nalgorithm is developed through statistical analysis to identify those sets of\nconnected components which may constitute the date. Common date patterns\nfollowed in India are considered to classify the date formats in different\nclasses. Reported results demonstrate promising performance of the proposed\napproach"
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2150v1", 
    "other_authors": "Mohamed Ben Halima, Hichem karray, Adel. M. Alimi, Ana Fern\u00e1ndez Vila", 
    "title": "NF-SAVO: Neuro-Fuzzy system for Arabic Video OCR", 
    "arxiv-id": "1211.2150v1", 
    "author": "Ana Fern\u00e1ndez Vila", 
    "publish": "2012-11-09T14:57:53Z", 
    "summary": "In this paper we propose a robust approach for text extraction and\nrecognition from video clips which is called Neuro-Fuzzy system for Arabic\nVideo OCR. In Arabic video text recognition, a number of noise components\nprovide the text relatively more complicated to separate from the background.\nFurther, the characters can be moving or presented in a diversity of colors,\nsizes and fonts that are not uniform. Added to this, is the fact that the\nbackground is usually moving making text extraction a more intricate process.\nVideo include two kinds of text, scene text and artificial text. Scene text is\nusually text that becomes part of the scene itself as it is recorded at the\ntime of filming the scene. But artificial text is produced separately and away\nfrom the scene and is laid over it at a later stage or during the post\nprocessing time. The emergence of artificial text is consequently vigilantly\ndirected. This type of text carries with it important information that helps in\nvideo referencing, indexing and retrieval."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2500v1", 
    "other_authors": "Mohamed A. El-Sayed", 
    "title": "A New Algorithm Based Entropic Threshold for Edge Detection in Images", 
    "arxiv-id": "1211.2500v1", 
    "author": "Mohamed A. El-Sayed", 
    "publish": "2012-11-12T02:56:08Z", 
    "summary": "Edge detection is one of the most critical tasks in automatic image analysis.\nThere exists no universal edge detection method which works well under all\nconditions. This paper shows the new approach based on the one of the most\nefficient techniques for edge detection, which is entropy-based thresholding.\nThe main advantages of the proposed method are its robustness and its\nflexibility. We present experimental results for this method, and compare\nresults of the algorithm against several leading edge detection methods, such\nas Canny, LOG, and Sobel. Experimental results demonstrate that the proposed\nmethod achieves better result than some classic methods and the quality of the\nedge detector of the output images is robust and decrease the computation time."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2502v1", 
    "other_authors": "Mohamed A. El-Sayed, Tarek Abd-El Hafeez", 
    "title": "New Edge Detection Technique based on the Shannon Entropy in Gray Level   Images", 
    "arxiv-id": "1211.2502v1", 
    "author": "Tarek Abd-El Hafeez", 
    "publish": "2012-11-12T03:06:18Z", 
    "summary": "Edge detection is an important field in image processing. Edges characterize\nobject boundaries and are therefore useful for segmentation, registration,\nfeature extraction, and identification of objects in a scene. In this paper, an\napproach utilizing an improvement of Baljit and Amar method which uses Shannon\nentropy other than the evaluation of derivatives of the image in detecting\nedges in gray level images has been proposed. The proposed method can reduce\nthe CPU time required for the edge detection process and the quality of the\nedge detector of the output images is robust. A standard test images, the\nreal-world and synthetic images are used to compare the results of the proposed\nedge detector with the Baljit and Amar edge detector method. In order to\nvalidate the results, the run time of the proposed method and the pervious\nmethod are presented. It has been observed that the proposed edge detector\nworks effectively for different gray scale digital images. The performance\nevaluation of the proposed technique in terms of the measured CPU time and the\nquality of edge detector method are presented. Experimental results demonstrate\nthat the proposed method achieve better result than the relevant classic\nmethod."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.2863v1", 
    "other_authors": "Alon Schclar", 
    "title": "Multi-Sensor Fusion via Reduction of Dimensionality", 
    "arxiv-id": "1211.2863v1", 
    "author": "Alon Schclar", 
    "publish": "2012-11-13T01:05:42Z", 
    "summary": "Large high-dimensional datasets are becoming more and more popular in an\nincreasing number of research areas. Processing the high dimensional data\nincurs a high computational cost and is inherently inefficient since many of\nthe values that describe a data object are redundant due to noise and inner\ncorrelations. Consequently, the dimensionality, i.e. the number of values that\nare used to describe a data object, needs to be reduced prior to any other\nprocessing of the data. The dimensionality reduction removes, in most cases,\nnoise from the data and reduces substantially the computational cost of\nalgorithms that are applied to the data.\n  In this thesis, a novel coherent integrated methodology is introduced\n(theory, algorithm and applications) to reduce the dimensionality of\nhigh-dimensional datasets. The method constructs a diffusion process among the\ndata coordinates via a random walk. The dimensionality reduction is obtained\nbased on the eigen-decomposition of the Markov matrix that is associated with\nthe random walk. The proposed method is utilized for: (a) segmentation and\ndetection of anomalies in hyper-spectral images; (b) segmentation of\nmulti-contrast MRI images; and (c) segmentation of video sequences.\n  We also present algorithms for: (a) the characterization of materials using\ntheir spectral signatures to enable their identification; (b) detection of\nvehicles according to their acoustic signatures; and (c) classification of\nvascular vessels recordings to detect hyper-tension and cardio-vascular\ndiseases.\n  The proposed methodology and algorithms produce excellent results that\nsuccessfully compete with current state-of-the-art algorithms."
},{
    "category": "cs.CV", 
    "doi": "10.1364/JOSAA.30.000871", 
    "link": "http://arxiv.org/pdf/1211.3901v1", 
    "other_authors": "Saad Akram, Jonas Beskow, Hedvig Kjellstrom", 
    "title": "Visual Recognition of Isolated Swedish Sign Language Signs", 
    "arxiv-id": "1211.3901v1", 
    "author": "Hedvig Kjellstrom", 
    "publish": "2012-11-16T14:29:31Z", 
    "summary": "We present a method for recognition of isolated Swedish Sign Language signs.\nThe method will be used in a game intended to help children training signing at\nhome, as a complement to training with a teacher. The target group is not\nprimarily deaf children, but children with language disorders. Using sign\nlanguage as a support in conversation has been shown to greatly stimulate the\nspeech development of such children. The signer is captured with an RGB-D\n(Kinect) sensor, which has three advantages over a regular RGB camera. Firstly,\nit allows complex backgrounds to be removed easily. We segment the hands and\nface based on skin color and depth information. Secondly, it helps with the\nresolution of hand over face occlusion. Thirdly, signs take place in 3D; some\naspects of the signs are defined by hand motion vertically to the image plane.\nThis motion can be estimated if the depth is observable. The 3D motion of the\nhands relative to the torso are used as a cue together with the hand shape, and\nHMMs trained with this input are used for classification. To obtain higher\nrobustness towards differences across signers, Fisher Linear Discriminant\nAnalysis is used to find the combinations of features that are most descriptive\nfor each sign, regardless of signer. Experiments show that the system can\ndistinguish signs from a challenging 94 word vocabulary with a precision of up\nto 94% in the signer dependent case and up to 47% in the signer independent\ncase."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4264v1", 
    "other_authors": "Kunal N. Chaudhury, Amit Singer", 
    "title": "Non-Local Patch Regression: Robust Image Denoising in Patch Space", 
    "arxiv-id": "1211.4264v1", 
    "author": "Amit Singer", 
    "publish": "2012-11-18T22:36:43Z", 
    "summary": "It was recently demonstrated in [Chaudhury et al.,Non-Local Euclidean\nMedians,2012] that the denoising performance of Non-Local Means (NLM) can be\nimproved at large noise levels by replacing the mean by the robust Euclidean\nmedian. Numerical experiments on synthetic and natural images showed that the\nlatter consistently performed better than NLM beyond a certain noise level, and\nsignificantly so for images with sharp edges. The Euclidean mean and median can\nbe put into a common regression (on the patch space) framework, in which the\nl_2 norm of the residuals is considered in the former, while the l_1 norm is\nconsidered in the latter. The natural question then is what happens if we\nconsider l_p (0<p<1) regression? We investigate this possibility in this paper."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4307v1", 
    "other_authors": "Han Li, Kun Gai, Pinghua Gong, Changshui Zhang", 
    "title": "Efficient Superimposition Recovering Algorithm", 
    "arxiv-id": "1211.4307v1", 
    "author": "Changshui Zhang", 
    "publish": "2012-11-19T05:44:24Z", 
    "summary": "In this article, we address the issue of recovering latent transparent layers\nfrom superimposition images. Here, we assume we have the estimated\ntransformations and extracted gradients of latent layers. To rapidly recover\nhigh-quality image layers, we propose an Efficient Superimposition Recovering\nAlgorithm (ESRA) by extending the framework of accelerated gradient method. In\naddition, a key building block (in each iteration) in our proposed method is\nthe proximal operator calculating. Here we propose to employ a dual approach\nand present our Parallel Algorithm with Constrained Total Variation (PACTV)\nmethod. Our recovering method not only reconstructs high-quality layers without\ncolor-bias problem, but also theoretically guarantees good convergence\nperformance."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4499v1", 
    "other_authors": "Boshra Rajaei, Thomas Maugey, Hamid-Reza Pourreza, Pascal Frossard", 
    "title": "Rate-Distortion Analysis of Multiview Coding in a DIBR Framework", 
    "arxiv-id": "1211.4499v1", 
    "author": "Pascal Frossard", 
    "publish": "2012-11-19T17:09:56Z", 
    "summary": "Depth image based rendering techniques for multiview applications have been\nrecently introduced for efficient view generation at arbitrary camera\npositions. Encoding rate control has thus to consider both texture and depth\ndata. Due to different structures of depth and texture images and their\ndifferent roles on the rendered views, distributing the available bit budget\nbetween them however requires a careful analysis. Information loss due to\ntexture coding affects the value of pixels in synthesized views while errors in\ndepth information lead to shift in objects or unexpected patterns at their\nboundaries. In this paper, we address the problem of efficient bit allocation\nbetween textures and depth data of multiview video sequences. We adopt a\nrate-distortion framework based on a simplified model of depth and texture\nimages. Our model preserves the main features of depth and texture images.\nUnlike most recent solutions, our method permits to avoid rendering at encoding\ntime for distortion estimation so that the encoding complexity is not\naugmented. In addition to this, our model is independent of the underlying\ninpainting method that is used at decoder. Experiments confirm our theoretical\nresults and the efficiency of our rate allocation strategy."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.4771v1", 
    "other_authors": "Ganesh Sundaramoorthi, Yanchao Yang", 
    "title": "Matching Through Features and Features Through Matching", 
    "arxiv-id": "1211.4771v1", 
    "author": "Yanchao Yang", 
    "publish": "2012-11-20T15:15:56Z", 
    "summary": "This paper addresses how to construct features for the problem of image\ncorrespondence, in particular, the paper addresses how to construct features so\nas to maintain the right level of invariance versus discriminability. We show\nthat without additional prior knowledge of the 3D scene, the right tradeoff\ncannot be established in a pre-processing step of the images as is typically\ndone in most feature-based matching methods. However, given knowledge of the\nsecond image to match, the tradeoff between invariance and discriminability of\nfeatures in the first image is less ambiguous. This suggests to setup the\nproblem of feature extraction and matching as a joint estimation problem. We\ndevelop a possible mathematical framework, a possible computational algorithm,\nand we give example demonstration on finding correspondence on images related\nby a scene that undergoes large 3D deformation of non-planar objects and camera\nviewpoint change."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICASSP.2013.6637870", 
    "link": "http://arxiv.org/pdf/1211.5355v1", 
    "other_authors": "Raka Kundu, Amlan Chakrabarti, Prasanna K. Lenka", 
    "title": "Cobb Angle Measurement of Scoliosis with Reduced Variability", 
    "arxiv-id": "1211.5355v1", 
    "author": "Prasanna K. Lenka", 
    "publish": "2012-11-22T19:09:29Z", 
    "summary": "Cobb angle, which is a measure of spinal curvature is the standard method for\nquantifying the magnitude of Scoliosis related to spinal deformity in\northopedics. Determining the Cobb angle through manual process is subject to\nhuman errors. In this work, we propose a methodology to measure the magnitude\nof Cobb angle, which appreciably reduces the variability related to its\nmeasurement compared to the related works. The proposed methodology is\nfacilitated by using a suitable new improved version of Non-Local Means for\nimage denoisation and Otsus automatic threshold selection for Canny edge\ndetection. We have selected NLM for preprocessing of the image as it is one of\nthe fine states of art for image denoisation and helps in retaining the image\nquality. Trimmedmean, median are more robust to outliners than mean and\nfollowing this concept we observed that NLM denoising quality performance can\nbe enhanced by using Euclidean trimmed-mean replacing the mean. To prove the\nbetter performance of the Non-Local Euclidean Trimmed-mean denoising filter, we\nhave provided some comparative study results of the proposed denoising\ntechnique with traditional NLM and NonLocal Euclidean Medians. The experimental\nresults for Cobb angle measurement over intra observer and inter observer\nexperimental data reveals the better performance and superiority of the\nproposed approach compared to the related works. MATLAB2009b image processing\ntoolbox was used for the purpose of simulation and verification of the proposed\nmethodology."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1211.5712v1", 
    "other_authors": "Jacek Tabor, Krzysztof Misztal", 
    "title": "Detection of elliptical shapes via cross-entropy clustering", 
    "arxiv-id": "1211.5712v1", 
    "author": "Krzysztof Misztal", 
    "publish": "2012-11-24T23:08:15Z", 
    "summary": "The problem of finding elliptical shapes in an image will be considered. We\ndiscuss the solution which uses cross-entropy clustering. The proposed method\nallows the search for ellipses with predefined sizes and position in the space.\nMoreover, it works well for search of ellipsoids in higher dimensions."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1212.0030v1", 
    "other_authors": "Osama Khalil, Andrew Habib", 
    "title": "Viewpoint Invariant Object Detector", 
    "arxiv-id": "1212.0030v1", 
    "author": "Andrew Habib", 
    "publish": "2012-11-30T22:35:19Z", 
    "summary": "Object Detection is the task of identifying the existence of an object class\ninstance and locating it within an image. Difficulties in handling high\nintra-class variations constitute major obstacles to achieving high performance\non standard benchmark datasets (scale, viewpoint, lighting conditions and\norientation variations provide good examples). Suggested model aims at\nproviding more robustness to detecting objects suffering severe distortion due\nto < 60{\\deg} viewpoint changes. In addition, several model computational\nbottlenecks have been resolved leading to a significant increase in the model\nperformance (speed and space) without compromising the resulting accuracy.\nFinally, we produced two illustrative applications showing the potential of the\nobject detection technology being deployed in real life applications; namely\ncontent-based image search and content-based video search."
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1212.0134v1", 
    "other_authors": "J. L. Raheja, Karen Das, Ankit Chaudhary", 
    "title": "Fingertip Detection: A Fast Method with Natural Hand", 
    "arxiv-id": "1212.0134v1", 
    "author": "Ankit Chaudhary", 
    "publish": "2012-12-01T16:59:07Z", 
    "summary": "Many vision based applications have used fingertips to track or manipulate\ngestures in their applications. Gesture identification is a natural way to pass\nthe signals to the machine, as the human express its feelings most of the time\nwith hand expressions. Here a novel time efficient algorithm has been described\nfor fingertip detection. This method is invariant to hand direction and in\npreprocessing it cuts only hand part from the full image, hence further\ncomputation would be much faster than processing full image. Binary silhouette\nof the input image is generated using HSV color space based skin filter and\nhand cropping done based on intensity histogram of the hand image"
},{
    "category": "cs.CV", 
    "doi": "10.1007/978-3-642-38628-2_78", 
    "link": "http://arxiv.org/pdf/1212.0291v1", 
    "other_authors": "C. J. Prabhakar, P. U. Praveen Kumar", 
    "title": "An Image Based Technique for Enhancement of Underwater Images", 
    "arxiv-id": "1212.0291v1", 
    "author": "P. U. Praveen Kumar", 
    "publish": "2012-12-03T05:57:46Z", 
    "summary": "The underwater images usually suffers from non-uniform lighting, low\ncontrast, blur and diminished colors. In this paper, we proposed an image based\npreprocessing technique to enhance the quality of the underwater images. The\nproposed technique comprises a combination of four filters such as homomorphic\nfiltering, wavelet denoising, bilateral filter and contrast equalization. These\nfilters are applied sequentially on degraded underwater images. The literature\nsurvey reveals that image based preprocessing algorithms uses standard filter\ntechniques with various combinations. For smoothing the image, the image based\npreprocessing algorithms uses the anisotropic filter. The main drawback of the\nanisotropic filter is that iterative in nature and computation time is high\ncompared to bilateral filter. In the proposed technique, in addition to other\nthree filters, we employ a bilateral filter for smoothing the image. The\nexperimentation is carried out in two stages. In the first stage, we have\nconducted various experiments on captured images and estimated optimal\nparameters for bilateral filter. Similarly, optimal filter bank and optimal\nwavelet shrinkage function are estimated for wavelet denoising. In the second\nstage, we conducted the experiments using estimated optimal parameters, optimal\nfilter bank and optimal wavelet shrinkage function for evaluating the proposed\ntechnique. We evaluated the technique using quantitative based criteria such as\na gradient magnitude histogram and Peak Signal to Noise Ratio (PSNR). Further,\nthe results are qualitatively evaluated based on edge detection results. The\nproposed technique enhances the quality of the underwater images and can be\nemployed prior to apply computer vision techniques."
},{
    "category": "cs.CV", 
    "doi": "10.5120/6222-8800", 
    "link": "http://arxiv.org/pdf/1212.0318v1", 
    "other_authors": "D. Srinivasa Rao, M. Seetha, M. H. M. Krishna Prasad", 
    "title": "Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its   Applications", 
    "arxiv-id": "1212.0318v1", 
    "author": "M. H. M. Krishna Prasad", 
    "publish": "2012-12-03T08:55:52Z", 
    "summary": "Image fusion is the process of integrating multiple images of the same scene\ninto a single fused image to reduce uncertainty and minimizing redundancy while\nextracting all the useful information from the source images. Image fusion\nprocess is required for different applications like medical imaging, remote\nsensing, medical imaging, machine vision, biometrics and military applications\nwhere quality and critical information is required. In this paper, image fusion\nusing fuzzy and neuro fuzzy logic approaches utilized to fuse images from\ndifferent sensors, in order to enhance visualization. The proposed work further\nexplores comparison between fuzzy based image fusion and neuro fuzzy fusion\ntechnique along with quality evaluation indices for image fusion like image\nquality index, mutual information measure, fusion factor, fusion symmetry,\nfusion index, root mean square error, peak signal to noise ratio, entropy,\ncorrelation coefficient and spatial frequency. Experimental results obtained\nfrom fusion process prove that the use of the neuro fuzzy based image fusion\napproach shows better performance in first two test cases while in the third\ntest case fuzzy based image fusion technique gives better results."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0383v1", 
    "other_authors": "V. Asha, N. U. Bhajantri, P. Nagabhushan", 
    "title": "GLCM-based chi-square histogram distance for automatic detection of   defects on patterned textures", 
    "arxiv-id": "1212.0383v1", 
    "author": "P. Nagabhushan", 
    "publish": "2012-12-03T13:40:41Z", 
    "summary": "Chi-square histogram distance is one of the distance measures that can be\nused to find dissimilarity between two histograms. Motivated by the fact that\ntexture discrimination by human vision system is based on second-order\nstatistics, we make use of histogram of gray-level co-occurrence matrix (GLCM)\nthat is based on second-order statistics and propose a new machine vision\nalgorithm for automatic defect detection on patterned textures. Input defective\nimages are split into several periodic blocks and GLCMs are computed after\nquantizing the gray levels from 0-255 to 0-63 to keep the size of GLCM compact\nand to reduce computation time. Dissimilarity matrix derived from chi-square\ndistances of the GLCMs is subjected to hierarchical clustering to automatically\nidentify defective and defect-free blocks. Effectiveness of the proposed method\nis demonstrated through experiments on defective real-fabric images of 2 major\nwallpaper groups (pmm and p4m groups)."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0402v1", 
    "other_authors": "Khurram Soomro, Amir Roshan Zamir, Mubarak Shah", 
    "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild", 
    "arxiv-id": "1212.0402v1", 
    "author": "Mubarak Shah", 
    "publish": "2012-12-03T14:45:31Z", 
    "summary": "We introduce UCF101 which is currently the largest dataset of human actions.\nIt consists of 101 action classes, over 13k clips and 27 hours of video data.\nThe database consists of realistic user uploaded videos containing camera\nmotion and cluttered background. Additionally, we provide baseline action\nrecognition results on this new dataset using standard bag of words approach\nwith overall performance of 44.5%. To the best of our knowledge, UCF101 is\ncurrently the most challenging dataset of actions due to its large number of\nclasses, large number of clips and also unconstrained nature of such clips."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0433v1", 
    "other_authors": "Prasad Sudhakar, Laurent Jacques, Xavier Dubois, Philippe Antoine, Luc Joannes", 
    "title": "Compressive Schlieren Deflectometry", 
    "arxiv-id": "1212.0433v1", 
    "author": "Luc Joannes", 
    "publish": "2012-12-03T16:21:07Z", 
    "summary": "Schlieren deflectometry aims at characterizing the deflections undergone by\nrefracted incident light rays at any surface point of a transparent object. For\nsmooth surfaces, each surface location is actually associated with a sparse\ndeflection map (or spectrum). This paper presents a novel method to\ncompressively acquire and reconstruct such spectra. This is achieved by\naltering the way deflection information is captured in a common Schlieren\nDeflectometer, i.e., the deflection spectra are indirectly observed by the\nprinciple of spread spectrum compressed sensing. These observations are\nrealized optically using a 2-D Spatial Light Modulator (SLM) adjusted to the\ncorresponding sensing basis and whose modulations encode the light deviation\nsubsequently recorded by a CCD camera. The efficiency of this approach is\ndemonstrated experimentally on the observation of few test objects. Further,\nusing a simple parametrization of the deflection spectra we show that relevant\nkey parameters can be directly computed using the measurements, avoiding full\nreconstruction."
},{
    "category": "cs.CV", 
    "doi": "10.1504/IJCVR.2011.045267", 
    "link": "http://arxiv.org/pdf/1212.0888v1", 
    "other_authors": "Roozbeh Rajabi, Hassan Ghassemian", 
    "title": "Unmixing of Hyperspectral Data Using Robust Statistics-based NMF", 
    "arxiv-id": "1212.0888v1", 
    "author": "Hassan Ghassemian", 
    "publish": "2012-12-04T21:59:35Z", 
    "summary": "Mixed pixels are presented in hyperspectral images due to low spatial\nresolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels\nspectra into endmembers spectra and abundance fractions. In this paper using of\nrobust statistics-based nonnegative matrix factorization (RNMF) for spectral\nunmixing of hyperspectral data is investigated. RNMF uses a robust cost\nfunction and iterative updating procedure, so is not sensitive to outliers.\nThis method has been applied to simulated data using USGS spectral library,\nAVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF\nmethod based on SAD and AAD measures. Results demonstrate that this method can\nbe used efficiently for hyperspectral unmixing purposes."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.image.2013.05.001", 
    "link": "http://arxiv.org/pdf/1212.1073v2", 
    "other_authors": "Jinshan Pan, Risheng Liu, Zhixun Su, Xianfeng Gu", 
    "title": "Kernel Estimation from Salient Structure for Robust Motion Deblurring", 
    "arxiv-id": "1212.1073v2", 
    "author": "Xianfeng Gu", 
    "publish": "2012-12-05T16:02:43Z", 
    "summary": "Blind image deblurring algorithms have been improving steadily in the past\nyears. Most state-of-the-art algorithms, however, still cannot perform\nperfectly in challenging cases, especially in large blur setting. In this\npaper, we focus on how to estimate a good kernel estimate from a single blurred\nimage based on the image structure. We found that image details caused by\nblurring could adversely affect the kernel estimation, especially when the blur\nkernel is large. One effective way to eliminate these details is to apply image\ndenoising model based on the Total Variation (TV). First, we developed a novel\nmethod for computing image structures based on TV model, such that the\nstructures undermining the kernel estimation will be removed. Second, to\nmitigate the possible adverse effect of salient edges and improve the\nrobustness of kernel estimation, we applied a gradient selection method. Third,\nwe proposed a novel kernel estimation method, which is capable of preserving\nthe continuity and sparsity of the kernel and reducing the noises. Finally, we\ndeveloped an adaptive weighted spatial prior, for the purpose of preserving\nsharp edges in latent image restoration. The effectiveness of our method is\ndemonstrated by experiments on various kinds of challenging examples."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.image.2013.05.001", 
    "link": "http://arxiv.org/pdf/1212.1329v1", 
    "other_authors": "V. Asha, N. U. Bhajantri, P. Nagabhushan", 
    "title": "Automatic Detection of Texture Defects Using Texture-Periodicity and   Gabor Wavelets", 
    "arxiv-id": "1212.1329v1", 
    "author": "P. Nagabhushan", 
    "publish": "2012-12-06T14:17:21Z", 
    "summary": "In this paper, we propose a machine vision algorithm for automatically\ndetecting defects in textures belonging to 16 out of 17 wallpaper groups using\ntexture-periodicity and a family of Gabor wavelets. Input defective images are\nsubjected to Gabor wavelet transformation in multi-scales and\nmulti-orientations and a resultant image is obtained in L2 norm. The resultant\nimage is split into several periodic blocks and energy of each block is used as\na feature space to automatically identify defective and defect-free blocks\nusing Ward's hierarchical clustering. Experiments on defective fabric images of\nthree major wallpaper groups, namely, pmm, p2 and p4m, show that the proposed\nmethod is robust in finding fabric defects without human intervention and can\nbe used for automatic defect detection in fabric industries."
},{
    "category": "cs.CV", 
    "doi": "10.1016/j.image.2013.05.001", 
    "link": "http://arxiv.org/pdf/1212.1819v2", 
    "other_authors": "Edwin Carlinet, Thierry G\u00e9raud", 
    "title": "A fair comparison of many max-tree computation algorithms (Extended   version of the paper submitted to ISMM 2013", 
    "arxiv-id": "1212.1819v2", 
    "author": "Thierry G\u00e9raud", 
    "publish": "2012-12-08T17:38:40Z", 
    "summary": "With the development of connected filters for the last decade, many\nalgorithms have been proposed to compute the max-tree. Max-tree allows to\ncompute the most advanced connected operators in a simple way. However, no fair\ncomparison of algorithms has been proposed yet and the choice of an algorithm\nover an other depends on many parameters. Since the need of fast algorithms is\nobvious for production code, we present an in depth comparison of five\nalgorithms and some variations of them in a unique framework. Finally, a\ndecision tree will be proposed to help user in choosing the right algorithm\nwith respect to their data."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2245v1", 
    "other_authors": "Martin Welk, Patrik Raudaschl, Thomas Schwarzbauer, Martin Erler, Martin L\u00e4uter", 
    "title": "Fast and Robust Linear Motion Deblurring", 
    "arxiv-id": "1212.2245v1", 
    "author": "Martin L\u00e4uter", 
    "publish": "2012-12-10T23:00:10Z", 
    "summary": "We investigate efficient algorithmic realisations for robust deconvolution of\ngrey-value images with known space-invariant point-spread function, with\nemphasis on 1D motion blur scenarios. The goal is to make deconvolution\nsuitable as preprocessing step in automated image processing environments with\ntight time constraints. Candidate deconvolution methods are selected for their\nrestoration quality, robustness and efficiency. Evaluation of restoration\nquality and robustness on synthetic and real-world test images leads us to\nfocus on a combination of Wiener filtering with few iterations of robust and\nregularised Richardson-Lucy deconvolution. We discuss algorithmic optimisations\nfor specific scenarios. In the case of uniform linear motion blur in coordinate\ndirection, it is possible to achieve real-time performance (less than 50 ms) in\nsingle-threaded CPU computation on images of $256\\times256$ pixels. For more\ngeneral space-invariant blur settings, still favourable computation times are\nobtained. Exemplary parallel implementations demonstrate that the proposed\nmethod also achieves real-time performance for general 1D motion blurs in a\nmulti-threaded CPU setting, and for general 2D blurs on a GPU."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2278v2", 
    "other_authors": "Carl Vondrick, Aditya Khosla, Tomasz Malisiewicz, Antonio Torralba", 
    "title": "Inverting and Visualizing Features for Object Detection", 
    "arxiv-id": "1212.2278v2", 
    "author": "Antonio Torralba", 
    "publish": "2012-12-11T01:59:51Z", 
    "summary": "We introduce algorithms to visualize feature spaces used by object detectors.\nThe tools in this paper allow a human to put on `HOG goggles' and perceive the\nvisual world as a HOG based object detector sees it. We found that these\nvisualizations allow us to analyze object detection systems in new ways and\ngain new insight into the detector's failures. For example, when we visualize\nthe features for high scoring false alarms, we discovered that, although they\nare clearly wrong in image space, they do look deceptively similar to true\npositives in feature space. This result suggests that many of these false\nalarms are caused by our choice of feature space, and indicates that creating a\nbetter learning algorithm or building bigger datasets is unlikely to correct\nthese errors. By visualizing feature spaces, we can gain a more intuitive\nunderstanding of our detection systems."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2546v1", 
    "other_authors": "Jonathan Masci, Jes\u00fas Angulo, J\u00fcrgen Schmidhuber", 
    "title": "A Learning Framework for Morphological Operators using Counter-Harmonic   Mean", 
    "arxiv-id": "1212.2546v1", 
    "author": "J\u00fcrgen Schmidhuber", 
    "publish": "2012-12-11T17:29:04Z", 
    "summary": "We present a novel framework for learning morphological operators using\ncounter-harmonic mean. It combines concepts from morphology and convolutional\nneural networks. A thorough experimental validation analyzes basic\nmorphological operators dilation and erosion, opening and closing, as well as\nthe much more complex top-hat transform, for which we report a real-world\napplication from the steel industry. Using online learning and stochastic\ngradient descent, our system learns both the structuring element and the\ncomposition of operators. It scales well to large datasets and online settings."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2692v1", 
    "other_authors": "Ghazali Osman, Muhammad Suzuri Hitam, Mohd Nasir Ismail", 
    "title": "Enhanced skin colour classifier using RGB Ratio model", 
    "arxiv-id": "1212.2692v1", 
    "author": "Mohd Nasir Ismail", 
    "publish": "2012-12-12T03:01:00Z", 
    "summary": "Skin colour detection is frequently been used for searching people, face\ndetection, pornographic filtering and hand tracking. The presence of skin or\nnon-skin in digital image can be determined by manipulating pixels colour or\npixels texture. The main problem in skin colour detection is to represent the\nskin colour distribution model that is invariant or least sensitive to changes\nin illumination condition. Another problem comes from the fact that many\nobjects in the real world may possess almost similar skin-tone colour such as\nwood, leather, skin-coloured clothing, hair and sand. Moreover, skin colour is\ndifferent between races and can be different from a person to another, even\nwith people of the same ethnicity. Finally, skin colour will appear a little\ndifferent when different types of camera are used to capture the object or\nscene. The objective in this study is to develop a skin colour classifier based\non pixel-based using RGB ratio model. The RGB ratio model is a newly proposed\nmethod that belongs under the category of an explicitly defined skin region\nmodel. This skin classifier was tested with SIdb dataset and two benchmark\ndatasets; UChile and TDSD datasets to measure classifier performance. The\nperformance of skin classifier was measured based on true positive (TF) and\nfalse positive (FP) indicator. This newly proposed model was compared with\nKovac, Saleh and Swift models. The experimental results showed that the RGB\nratio model outperformed all the other models in term of detection rate. The\nRGB ratio model is able to reduce FP detection that caused by reddish objects\ncolour as well as be able to detect darkened skin and skin covered by shadow."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s11760-013-0563-x", 
    "link": "http://arxiv.org/pdf/1212.2823v1", 
    "other_authors": "Shuran Song, Jianxiong Xiao", 
    "title": "Tracking Revisited using RGBD Camera: Baseline and Benchmark", 
    "arxiv-id": "1212.2823v1", 
    "author": "Jianxiong Xiao", 
    "publish": "2012-12-12T14:02:41Z", 
    "summary": "Although there has been significant progress in the past decade,tracking is\nstill a very challenging computer vision task, due to problems such as\nocclusion and model drift.Recently, the increased popularity of depth sensors\ne.g. Microsoft Kinect has made it easy to obtain depth data at low cost.This\nmay be a game changer for tracking, since depth information can be used to\nprevent model drift and handle occlusion.In this paper, we construct a\nbenchmark dataset of 100 RGBD videos with high diversity, including deformable\nobjects, various occlusion conditions and moving cameras. We propose a very\nsimple but strong baseline model for RGBD tracking, and present a quantitative\ncomparison of several state-of-the-art tracking algorithms.Experimental results\nshow that including depth information and reasoning about occlusion\nsignificantly improves tracking performance. The datasets, evaluation details,\nsource code for the baseline algorithm, and instructions for submitting new\nmodels will be made available online after acceptance."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0051788", 
    "link": "http://arxiv.org/pdf/1212.2860v1", 
    "other_authors": "Jan Egger, Tina Kapur, Christopher Nimsky, Ron Kikinis", 
    "title": "Pituitary Adenoma Volumetry with 3D Slicer", 
    "arxiv-id": "1212.2860v1", 
    "author": "Ron Kikinis", 
    "publish": "2012-12-12T16:12:32Z", 
    "summary": "In this study, we present pituitary adenoma volumetry using the free and open\nsource medical image computing platform for biomedical research: (3D) Slicer.\nVolumetric changes in cerebral pathologies like pituitary adenomas are a\ncritical factor in treatment decisions by physicians and in general the volume\nis acquired manually. Therefore, manual slice-by-slice segmentations in\nmagnetic resonance imaging (MRI) data, which have been obtained at regular\nintervals, are performed. In contrast to this manual time consuming\nslice-by-slice segmentation process Slicer is an alternative which can be\nsignificantly faster and less user intensive. In this contribution, we compare\npure manual segmentations of ten pituitary adenomas with semi-automatic\nsegmentations under Slicer. Thus, physicians drew the boundaries completely\nmanually on a slice-by-slice basis and performed a Slicer-enhanced segmentation\nusing the competitive region-growing based module of Slicer named GrowCut.\nResults showed that the time and user effort required for GrowCut-based\nsegmentations were on average about thirty percent less than the pure manual\nsegmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC)\nbetween the manual and the Slicer-based segmentations to proof that the two are\ncomparable yielding an average DSC of 81.97\\pm3.39%."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0051788", 
    "link": "http://arxiv.org/pdf/1212.3268v3", 
    "other_authors": "Gilles Puy, Pierre Vandergheynst", 
    "title": "Robust image reconstruction from multi-view measurements", 
    "arxiv-id": "1212.3268v3", 
    "author": "Pierre Vandergheynst", 
    "publish": "2012-12-13T19:00:17Z", 
    "summary": "We propose a novel method to accurately reconstruct a set of images\nrepresenting a single scene from few linear multi-view measurements. Each\nobserved image is modeled as the sum of a background image and a foreground\none. The background image is common to all observed images but undergoes\ngeometric transformations, as the scene is observed from different viewpoints.\nIn this paper, we assume that these geometric transformations are represented\nby a few parameters, e.g., translations, rotations, affine transformations,\netc.. The foreground images differ from one observed image to another, and are\nused to model possible occlusions of the scene. The proposed reconstruction\nalgorithm estimates jointly the images and the transformation parameters from\nthe available multi-view measurements. The ideal solution of this multi-view\nimaging problem minimizes a non-convex functional, and the reconstruction\ntechnique is an alternating descent method built to minimize this functional.\nThe convergence of the proposed algorithm is studied, and conditions under\nwhich the sequence of estimated images and parameters converges to a critical\npoint of the non-convex functional are provided. Finally, the efficiency of the\nalgorithm is demonstrated using numerical simulations for applications such as\ncompressed sensing or super-resolution."
},{
    "category": "cs.CV", 
    "doi": "10.1371/journal.pone.0051788", 
    "link": "http://arxiv.org/pdf/1212.3373v1", 
    "other_authors": "J. K. Mandal, Somnath Mukhopadhyay", 
    "title": "A Novel Directional Weighted Minimum Deviation (DWMD) Based Filter for   Removal of Random Valued Impulse Noise", 
    "arxiv-id": "1212.3373v1", 
    "author": "Somnath Mukhopadhyay", 
    "publish": "2012-12-14T00:13:11Z", 
    "summary": "The most median-based de noising methods works fine for restoring the images\ncorrupted by Randomn Valued Impulse Noise with low noise level but very poor\nwith highly corrupted images. In this paper a directional weighted minimum\ndeviation (DWMD) based filter has been proposed for removal of high random\nvalued impulse noise (RVIN). The proposed approach based on Standard Deviation\n(SD) works in two phases. The first phase detects the contaminated pixels by\ndifferencing between the test pixel and its neighbor pixels aligned with four\nmain directions. The second phase filters only those pixels keeping others\nintact. The filtering scheme is based on minimum standard deviation of the four\ndirectional pixels. Extensive simulations show that the proposed filter not\nonly provide better performance of de noising RVIN but can preserve more\ndetails features even thin lines or dots. This technique shows better\nperformance in terms of PSNR, Image Fidelity and Computational Cost compared to\nthe existing filters."
},{
    "category": "cs.CV", 
    "doi": "10.1007/s10851-013-0488-6", 
    "link": "http://arxiv.org/pdf/1212.3530v5", 
    "other_authors": "Erik Bekkers, Remco Duits, Tos Berendschot, Bart ter Haar Romeny", 
    "title": "A Multi-Orientation Analysis Approach to Retinal Vessel Tracking", 
    "arxiv-id": "1212.3530v5", 
    "author": "Bart ter Haar Romeny", 
    "publish": "2012-12-14T17:04:03Z", 
    "summary": "This paper presents a method for retinal vasculature extraction based on\nbiologically inspired multi-orientation analysis. We apply multi-orientation\nanalysis via so-called invertible orientation scores, modeling the cortical\ncolumns in the visual system of higher mammals. This allows us to generically\ndeal with many hitherto complex problems inherent to vessel tracking, such as\ncrossings, bifurcations, parallel vessels, vessels of varying widths and\nvessels with high curvature. Our approach applies tracking in invertible\norientation scores via a novel geometrical principle for curve optimization in\nthe Euclidean motion group SE(2). The method runs fully automatically and\nprovides a detailed model of the retinal vasculature, which is crucial as a\nsound basis for further quantitative analysis of the retina, especially in\nscreening applications."
}]