[{
    "category": "cs.CV", 
    "author": "Andreas Siebert", 
    "title": "A Linear Shift Invariant Multiscale Transform", 
    "publish": "1998-10-02T03:34:38Z", 
    "summary": "This paper presents a multiscale decomposition algorithm. Unlike standard\nwavelet transforms, the proposed operator is both linear and shift invariant.\nThe central idea is to obtain shift invariance by averaging the aligned wavelet\ntransform projections over all circular shifts of the signal. It is shown how\nthe same transform can be obtained by a linear filter bank.", 
    "link": "http://arxiv.org/pdf/cs/9810003v1", 
    "arxiv-id": "cs/9810003v1"
},{
    "category": "cs.CV", 
    "author": "Stephen L. Adler", 
    "title": "General Theory of Image Normalization", 
    "publish": "1998-10-19T20:46:16Z", 
    "summary": "We give a systematic, abstract formulation of the image normalization method\nas applied to a general group of image transformations, and then illustrate the\nabstract analysis by applying it to the hierarchy of viewing transformations of\na planar object.", 
    "link": "http://arxiv.org/pdf/cs/9810017v1", 
    "arxiv-id": "cs/9810017v1"
},{
    "category": "cs.CV", 
    "author": "Andreas Siebert", 
    "title": "A Differential Invariant for Zooming", 
    "publish": "1999-08-26T17:18:49Z", 
    "summary": "This paper presents an invariant under scaling and linear brightness change.\nThe invariant is based on differentials and therefore is a local feature.\nRotationally invariant 2-d differential Gaussian operators up to third order\nare proposed for the implementation of the invariant. The performance is\nanalyzed by simulating a camera zoom-out.", 
    "link": "http://arxiv.org/pdf/cs/9908017v1", 
    "arxiv-id": "cs/9908017v1"
},{
    "category": "cs.CV", 
    "author": "L. Prasad", 
    "title": "A Parallel Algorithm for Dilated Contour Extraction from Bilevel Images", 
    "publish": "2000-01-25T16:09:37Z", 
    "summary": "We describe a simple, but efficient algorithm for the generation of dilated\ncontours from bilevel images. The initial part of the contour extraction is\nexplained to be a good candidate for parallel computer code generation. The\nremainder of the algorithm is of linear nature.", 
    "link": "http://arxiv.org/pdf/cs/0001024v1", 
    "arxiv-id": "cs/0001024v1"
},{
    "category": "cs.CV", 
    "author": "Paul Fisher", 
    "title": "Image Compression with Iterated Function Systems, Finite Automata and   Zerotrees: Grand Unification", 
    "publish": "2000-03-15T19:31:51Z", 
    "summary": "Fractal image compression, Culik's image compression and zerotree prediction\ncoding of wavelet image decomposition coefficients succeed only because typical\nimages being compressed possess a significant degree of self-similarity.\nBesides the common concept, these methods turn out to be even more tightly\nrelated, to the point of algorithmical reducibility of one technique to\nanother. The goal of the present paper is to demonstrate these relations.\n  The paper offers a plain-term interpretation of Culik's image compression, in\nregular image processing terms, without resorting to finite state machines and\nsimilar lofty language. The interpretation is shown to be algorithmically\nrelated to an IFS fractal image compression method: an IFS can be exactly\ntransformed into Culik's image code. Using this transformation, we will prove\nthat in a self-similar (part of an) image any zero wavelet coefficient is the\nroot of a zerotree, or its branch.\n  The paper discusses the zerotree coding of (wavelet/projection) coefficients\nas a common predictor/corrector, applied vertically through different layers of\na multiresolutional decomposition, rather than within the same view. This\ninterpretation leads to an insight into the evolution of image compression\ntechniques: from a causal single-layer prediction, to non-causal same-view\npredictions (wavelet decomposition among others) and to a causal cross-layer\nprediction (zero-trees, Culik's method).", 
    "link": "http://arxiv.org/pdf/cs/0003065v1", 
    "arxiv-id": "cs/0003065v1"
},{
    "category": "cs.CV", 
    "author": "Andreas Siebert", 
    "title": "Differential Invariants under Gamma Correction", 
    "publish": "2000-03-26T23:18:43Z", 
    "summary": "This paper presents invariants under gamma correction and similarity\ntransformations. The invariants are local features based on differentials which\nare implemented using derivatives of the Gaussian. The use of the proposed\ninvariant representation is shown to yield improved correlation results in a\ntemplate matching scenario.", 
    "link": "http://arxiv.org/pdf/cs/0003079v1", 
    "arxiv-id": "cs/0003079v1"
},{
    "category": "cs.CV", 
    "author": "Jean-Michel Jolion", 
    "title": "Assisted Video Sequences Indexing : Motion Analysis Based on Interest   Points", 
    "publish": "2000-04-21T17:32:29Z", 
    "summary": "This work deals with content-based video indexing. Our viewpoint is\nsemi-automatic analysis of compressed video. We consider the possible\napplications of motion analysis and moving object detection : assisting moving\nobject indexing, summarising videos, and allowing image and motion queries. We\npropose an approach based on interest points. As first results, we test and\ncompare the stability of different types of interest point detectors in\ncompressed sequences.", 
    "link": "http://arxiv.org/pdf/cs/0004012v1", 
    "arxiv-id": "cs/0004012v1"
},{
    "category": "cs.CV", 
    "author": "Naoyuki Tokuda", 
    "title": "Robustness of Regional Matching Scheme over Global Matching Scheme", 
    "publish": "2000-05-03T08:49:28Z", 
    "summary": "The paper has established and verified the theory prevailing widely among\nimage and pattern recognition specialists that the bottom-up indirect regional\nmatching process is the more stable and the more robust than the global\nmatching process against concentrated types of noise represented by clutter,\noutlier or occlusion in the imagery. We have demonstrated this by analyzing the\neffect of concentrated noise on a typical decision making process of a\nsimplified two candidate voting model where our theorem establishes the lower\nbounds to a critical breakdown point of election (or decision) result by the\nbottom-up matching process are greater than the exact bound of the global\nmatching process implying that the former regional process is capable of\naccommodating a higher level of noise than the latter global process before the\nresult of decision overturns. We present a convincing experimental verification\nsupporting not only the theory by a white-black flag recognition problem in the\npresence of localized noise but also the validity of the conjecture by a facial\nrecognition problem that the theorem remains valid for other decision making\nprocesses involving an important dimension-reducing transform such as principal\ncomponent analysis or a Gabor transform.", 
    "link": "http://arxiv.org/pdf/cs/0005001v1", 
    "arxiv-id": "cs/0005001v1"
},{
    "category": "cs.CV", 
    "author": "K. Babu Joseph", 
    "title": "Boosting the Differences: A fast Bayesian classifier neural network", 
    "publish": "2000-05-31T23:37:48Z", 
    "summary": "A Bayesian classifier that up-weights the differences in the attribute values\nis discussed. Using four popular datasets from the UCI repository, some\ninteresting features of the network are illustrated. The network is suitable\nfor classification problems.", 
    "link": "http://arxiv.org/pdf/cs/0006001v1", 
    "arxiv-id": "cs/0006001v1"
},{
    "category": "cs.CV", 
    "author": "K. Babu Joseph", 
    "title": "Distorted English Alphabet Identification : An application of Difference   Boosting Algorithm", 
    "publish": "2000-05-31T23:52:31Z", 
    "summary": "The difference-boosting algorithm is used on letters dataset from the UCI\nrepository to classify distorted raster images of English alphabets. In\ncontrast to rather complex networks, the difference-boosting is found to\nproduce comparable or better classification efficiency on this complex problem.", 
    "link": "http://arxiv.org/pdf/cs/0006002v1", 
    "arxiv-id": "cs/0006002v1"
},{
    "category": "cs.CV", 
    "author": "A. N. Skourikhine", 
    "title": "Geometric Morphology of Granular Materials", 
    "publish": "2000-06-30T22:17:42Z", 
    "summary": "We present a new method to transform the spectral pixel information of a\nmicrograph into an affine geometric description, which allows us to analyze the\nmorphology of granular materials. We use spectral and pulse-coupled neural\nnetwork based segmentation techniques to generate blobs, and a newly developed\nalgorithm to extract dilated contours. A constrained Delaunay tesselation of\nthe contour points results in a triangular mesh. This mesh is the basic\ningredient of the Chodal Axis Transform, which provides a morphological\ndecomposition of shapes. Such decomposition allows for grain separation and the\nefficient computation of the statistical features of granular materials.", 
    "link": "http://arxiv.org/pdf/cs/0006047v1", 
    "arxiv-id": "cs/0006047v1"
},{
    "category": "cs.CV", 
    "author": "Gerd Hirzinger", 
    "title": "Probabilistic Search for Object Segmentation and Recognition", 
    "publish": "2002-08-05T10:57:09Z", 
    "summary": "The problem of searching for a model-based scene interpretation is analyzed\nwithin a probabilistic framework. Object models are formulated as generative\nmodels for range data of the scene. A new statistical criterion, the truncated\nobject probability, is introduced to infer an optimal sequence of object\nhypotheses to be evaluated for their match to the data. The truncated\nprobability is partly determined by prior knowledge of the objects and partly\nlearned from data. Some experiments on sequence quality and object segmentation\nand recognition from stereo data are presented. The article recovers classic\nconcepts from object recognition (grouping, geometric hashing, alignment) from\nthe probabilistic perspective and adds insight into the optimal ordering of\nobject hypotheses for evaluation. Moreover, it introduces point-relation\ndensities, a key component of the truncated probability, as statistical models\nof local surface shape.", 
    "link": "http://arxiv.org/pdf/cs/0208005v1", 
    "arxiv-id": "cs/0208005v1"
},{
    "category": "cs.CV", 
    "author": "C. Lesort", 
    "title": "Least squares fitting of circles and lines", 
    "publish": "2003-01-01T19:58:03Z", 
    "summary": "We study theoretical and computational aspects of the least squares fit (LSF)\nof circles and circular arcs. First we discuss the existence and uniqueness of\nLSF and various parametrization schemes. Then we evaluate several popular\ncircle fitting algorithms and propose a new one that surpasses the existing\nmethods in reliability. We also discuss and compare direct (algebraic) circle\nfits.", 
    "link": "http://arxiv.org/pdf/cs/0301001v1", 
    "arxiv-id": "cs/0301001v1"
},{
    "category": "cs.CV", 
    "author": "C. Lesort", 
    "title": "Statistical efficiency of curve fitting algorithms", 
    "publish": "2003-03-18T21:30:36Z", 
    "summary": "We study the problem of fitting parametrized curves to noisy data. Under\ncertain assumptions (known as Cartesian and radial functional models), we\nderive asymptotic expressions for the bias and the covariance matrix of the\nparameter estimates. We also extend Kanatani's version of the Cramer-Rao lower\nbound, which he proved for unbiased estimates only, to more general estimates\nthat include many popular algorithms (most notably, the orthogonal least\nsquares and algebraic fits). We then show that the gradient-weighted algebraic\nfit is statistically efficient and describe all other statistically efficient\nalgebraic fits.", 
    "link": "http://arxiv.org/pdf/cs/0303015v1", 
    "arxiv-id": "cs/0303015v1"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "Flexible Camera Calibration Using a New Analytical Radial Undistortion   Formula with Application to Mobile Robot Localization", 
    "publish": "2003-07-20T02:35:38Z", 
    "summary": "Most algorithms in 3D computer vision rely on the pinhole camera model\nbecause of its simplicity, whereas virtually all imaging devices introduce\ncertain amount of nonlinear distortion, where the radial distortion is the most\nsevere part. Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved. An application of the new radial distortion model is non-iterative\nyellow line alignment with a calibrated camera on ODIS, a robot built in our\nCSOIS.", 
    "link": "http://arxiv.org/pdf/cs/0307045v1", 
    "arxiv-id": "cs/0307045v1"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "A New Analytical Radial Distortion Model for Camera Calibration", 
    "publish": "2003-07-20T05:18:59Z", 
    "summary": "Common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nradial distortion model with an easy analytical undistortion formula, which\nalso belongs to the polynomial approximation category. Experimental results are\npresented to show that with this radial distortion model, satisfactory accuracy\nis achieved.", 
    "link": "http://arxiv.org/pdf/cs/0307046v1", 
    "arxiv-id": "cs/0307046v1"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "Rational Radial Distortion Models with Analytical Undistortion Formulae", 
    "publish": "2003-07-20T05:54:42Z", 
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\nclass of rational radial distortion models with easy analytical undistortion\nformulae. Experimental results are presented to show that with this class of\nrational radial distortion models, satisfactory and comparable accuracy is\nachieved.", 
    "link": "http://arxiv.org/pdf/cs/0307047v1", 
    "arxiv-id": "cs/0307047v1"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "An Analytical Piecewise Radial Distortion Model for Precision Camera   Calibration", 
    "publish": "2003-07-21T16:30:11Z", 
    "summary": "The common approach to radial distortion is by the means of polynomial\napproximation, which introduces distortion-specific parameters into the camera\nmodel and requires estimation of these distortion parameters. The task of\nestimating radial distortion is to find a radial distortion model that allows\neasy undistortion as well as satisfactory accuracy. This paper presents a new\npiecewise radial distortion model with easy analytical undistortion formula.\nThe motivation for seeking a piecewise radial distortion model is that, when a\ncamera is resulted in a low quality during manufacturing, the nonlinear radial\ndistortion can be complex. Using low order polynomials to approximate the\nradial distortion might not be precise enough. On the other hand, higher order\npolynomials suffer from the inverse problem. With the new piecewise radial\ndistortion function, more flexibility is obtained and the radial undistortion\ncan be performed analytically. Experimental results are presented to show that\nwith this new piecewise radial distortion model, better performance is achieved\nthan that using the single function. Furthermore, a comparable performance with\nthe conventional polynomial model using 2 coefficients can also be\naccomplished.", 
    "link": "http://arxiv.org/pdf/cs/0307051v1", 
    "arxiv-id": "cs/0307051v1"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "Camera Calibration: a USU Implementation", 
    "publish": "2003-07-31T19:33:48Z", 
    "summary": "The task of camera calibration is to estimate the intrinsic and extrinsic\nparameters of a camera model. Though there are some restricted techniques to\ninfer the 3-D information about the scene from uncalibrated cameras, effective\ncamera calibration procedures will open up the possibility of using a wide\nrange of existing algorithms for 3-D reconstruction and recognition.\n  The applications of camera calibration include vision-based metrology, robust\nvisual platooning and visual docking of mobile robots where the depth\ninformation is important.", 
    "link": "http://arxiv.org/pdf/cs/0307072v1", 
    "arxiv-id": "cs/0307072v1"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "A Family of Simplified Geometric Distortion Models for Camera   Calibration", 
    "publish": "2003-08-02T01:39:38Z", 
    "summary": "The commonly used radial distortion model for camera calibration is in fact\nan assumption or a restriction. In practice, camera distortion could happen in\na general geometrical manner that is not limited to the radial sense. This\npaper proposes a simplified geometrical distortion modeling method by using two\ndifferent radial distortion functions in the two image axes. A family of\nsimplified geometric distortion models is proposed, which are either simple\npolynomials or the rational functions of polynomials. Analytical geometric\nundistortion is possible using two of the distortion functions discussed in\nthis paper and their performance can be improved by applying a piecewise\nfitting idea. Our experimental results show that the geometrical distortion\nmodels always perform better than their radial distortion counterparts.\nFurthermore, the proposed geometric modeling method is more appropriate for\ncameras whose distortion is not perfectly radially symmetric around the center\nof distortion.", 
    "link": "http://arxiv.org/pdf/cs/0308003v1", 
    "arxiv-id": "cs/0308003v1"
},{
    "category": "cs.CV", 
    "author": "F. Rotulo", 
    "title": "Fingerprint based bio-starter and bio-access", 
    "publish": "2003-08-21T10:47:27Z", 
    "summary": "In the paper will be presented a safety and security system based on\nfingerprint technology. The results suggest a new scenario where the new cars\ncan use a fingerprint sensor integrated in car handle to allow access and in\nthe dashboard as starter button.", 
    "link": "http://arxiv.org/pdf/cs/0308034v1", 
    "arxiv-id": "cs/0308034v1"
},{
    "category": "cs.CV", 
    "author": "F. S. Tortoriello", 
    "title": "IS (Iris Security)", 
    "publish": "2003-08-21T10:52:53Z", 
    "summary": "In the paper will be presented a safety system based on iridology. The\nresults suggest a new scenario where the security problem in supervised and\nunsupervised areas can be treat with the present system and the iris image\nrecognition.", 
    "link": "http://arxiv.org/pdf/cs/0308035v1", 
    "arxiv-id": "cs/0308035v1"
},{
    "category": "cs.CV", 
    "author": "Alexandra Deschamps", 
    "title": "Better Foreground Segmentation Through Graph Cuts", 
    "publish": "2004-01-21T20:06:51Z", 
    "summary": "For many tracking and surveillance applications, background subtraction\nprovides an effective means of segmenting objects moving in front of a static\nbackground. Researchers have traditionally used combinations of morphological\noperations to remove the noise inherent in the background-subtracted result.\nSuch techniques can effectively isolate foreground objects, but tend to lose\nfidelity around the borders of the segmentation, especially for noisy input.\nThis paper explores the use of a minimum graph cut algorithm to segment the\nforeground, resulting in qualitatively and quantitiatively cleaner\nsegmentations. Experiments on both artificial and real data show that the\ngraph-based method reduces the error around segmented foreground objects. A\nMATLAB code implementation is available at\nhttp://www.cs.smith.edu/~nhowe/research/code/#fgseg", 
    "link": "http://arxiv.org/pdf/cs/0401017v2", 
    "arxiv-id": "cs/0401017v2"
},{
    "category": "cs.CV", 
    "author": "I. V. Golycheva", 
    "title": "Factor Temporal Prognosis of Tick-Borne Encephalitis Foci Functioning on   the South of Russian Far East", 
    "publish": "2004-01-22T05:53:30Z", 
    "summary": "A method of temporal factor prognosis of TE (tick-borne encephalitis)\ninfection has been developed. The high precision of the prognosis results for a\nnumber of geographical regions of Primorsky Krai has been achieved. The method\ncan be applied not only to epidemiological research but also to others.", 
    "link": "http://arxiv.org/pdf/cs/0401018v1", 
    "arxiv-id": "cs/0401018v1"
},{
    "category": "cs.CV", 
    "author": "Tin Kam Ho", 
    "title": "Geometrical Complexity of Classification Problems", 
    "publish": "2004-02-11T16:34:16Z", 
    "summary": "Despite encouraging recent progresses in ensemble approaches, classification\nmethods seem to have reached a plateau in development. Further advances depend\non a better understanding of geometrical and topological characteristics of\npoint sets in high-dimensional spaces, the preservation of such characteristics\nunder feature transformations and sampling processes, and their interaction\nwith geometrical models used in classifiers. We discuss an attempt to measure\nsuch properties from data sets and relate them to classifier accuracies.", 
    "link": "http://arxiv.org/pdf/cs/0402020v1", 
    "arxiv-id": "cs/0402020v1"
},{
    "category": "cs.CV", 
    "author": "Vytautas Perlibakas", 
    "title": "Computerized Face Detection and Recognition", 
    "publish": "2004-05-25T11:36:34Z", 
    "summary": "This publication presents methods for face detection, analysis and\nrecognition: fast normalized cross-correlation (fast correlation coefficient)\nbetween multiple templates based face pre-detection method, method for\ndetection of exact face contour based on snakes and Generalized Gradient Vector\nFlow field, method for combining recognition algorithms based on Cumulative\nMatch Characteristics in order to increase recognition speed and accuracy, and\nface recognition method based on Principal Component Analysis of the Wavelet\nPacket Decomposition allowing to use PCA - based recognition method with large\nnumber of training images. For all the methods are presented experimental\nresults and comparisons of speed and accuracy with large face databases.", 
    "link": "http://arxiv.org/pdf/cs/0405093v2", 
    "arxiv-id": "cs/0405093v2"
},{
    "category": "cs.CV", 
    "author": "Kevin L. Moore", 
    "title": "Blind Detection and Compensation of Camera Lens Geometric Distortions", 
    "publish": "2004-05-25T22:40:42Z", 
    "summary": "This paper presents a blind detection and compensation technique for camera\nlens geometric distortions. The lens distortion introduces higher-order\ncorrelations in the frequency domain and in turn it can be detected using\nhigher-order spectral analysis tools without assuming any specific calibration\ntarget. The existing blind lens distortion removal method only considered a\nsingle-coefficient radial distortion model. In this paper, two coefficients are\nconsidered to model approximately the geometric distortion. All the models\nconsidered have analytical closed-form inverse formulae.", 
    "link": "http://arxiv.org/pdf/cs/0405095v1", 
    "arxiv-id": "cs/0405095v1"
},{
    "category": "cs.CV", 
    "author": "Vyacheslav Zavadsky", 
    "title": "Image compression by rectangular wavelet transform", 
    "publish": "2004-06-04T12:28:06Z", 
    "summary": "We study image compression by a separable wavelet basis\n$\\big\\{\\psi(2^{k_1}x-i)\\psi(2^{k_2}y-j),$ $\\phi(x-i)\\psi(2^{k_2}y-j),$\n$\\psi(2^{k_1}(x-i)\\phi(y-j),$ $\\phi(x-i)\\phi(y-i)\\big\\},$ where $k_1, k_2 \\in\n\\mathbb{Z}_+$; $i,j\\in\\mathbb{Z}$; and $\\phi,\\psi$ are elements of a standard\nbiorthogonal wavelet basis in $L_2(\\mathbb{R})$. Because $k_1\\ne k_2$, the\nsupports of the basis elements are rectangles, and the corresponding transform\nis known as the {\\em rectangular wavelet transform}. We prove that if\none-dimensional wavelet basis has $M$ dual vanishing moments then the rate of\napproximation by $N$ coefficients of rectangular wavelet transform is\n$\\mathcal{O}(N^{-M}\\log^C N)$ for functions with mixed derivative of order $M$\nin each direction.\n  The square wavelet transform yields the approximation rate is\n$\\mathcal{O}(N^{-M/2})$ for functions with all derivatives of the total order\n$M$. Thus, the rectangular wavelet transform can outperform the square one if\nan image has a mixed derivative. We provide experimental comparison of image\ncompression which shows that rectangular wavelet transform outperform the\nsquare one.", 
    "link": "http://arxiv.org/pdf/cs/0406008v1", 
    "arxiv-id": "cs/0406008v1"
},{
    "category": "cs.CV", 
    "author": "Paulo S. Rodrigues", 
    "title": "Gradient Vector Flow Models for Boundary Extraction in 2D Images", 
    "publish": "2005-02-28T15:09:08Z", 
    "summary": "The Gradient Vector Flow (GVF) is a vector diffusion approach based on\nPartial Differential Equations (PDEs). This method has been applied together\nwith snake models for boundary extraction medical images segmentation. The key\nidea is to use a diffusion-reaction PDE to generate a new external force field\nthat makes snake models less sensitivity to initialization as well as improves\nthe snake's ability to move into boundary concavities. In this paper, we\nfirstly review basic results about convergence and numerical analysis of usual\nGVF schemes. We point out that GVF presents numerical problems due to\ndiscontinuities image intensity. This point is considered from a practical\nviewpoint from which the GVF parameters must follow a relationship in order to\nimprove numerical convergence. Besides, we present an analytical analysis of\nthe GVF dependency from the parameters values. Also, we observe that the method\ncan be used for multiply connected domains by just imposing the suitable\nboundary condition. In the experimental results we verify these theoretical\npoints and demonstrate the utility of GVF on a segmentation approach that we\nhave developed based on snakes.", 
    "link": "http://arxiv.org/pdf/cs/0502095v2", 
    "arxiv-id": "cs/0502095v2"
},{
    "category": "cs.CV", 
    "author": "Emanuel Diamant", 
    "title": "Searching for image information content, its discovery, extraction, and   representation", 
    "publish": "2005-05-02T03:17:02Z", 
    "summary": "Image information content is known to be a complicated and controvercial\nproblem. This paper posits a new image information content definition.\nFollowing the theory of Solomonoff-Kolmogorov-Chaitin's complexity, we define\nimage information content as a set of descriptions of imafe data structures.\nThree levels of such description can be generally distinguished: 1)the global\nlevel, where the coarse structure of the entire scene is initially outlined; 2)\nthe intermediate level, where structures of separate, non-overlapping image\nregions usually associated with individual scene objects are deliniated; and 3)\nthe low-level description, where local image structures observed in a limited\nand restricted field of view are resolved. A technique for creating such image\ninformation content descriptors is developed. Its algorithm is presented and\nelucidated with some examples, which demonstrate the effectiveness of the\nproposed approach.", 
    "link": "http://arxiv.org/pdf/cs/0505006v1", 
    "arxiv-id": "cs/0505006v1"
},{
    "category": "cs.CV", 
    "author": "Emanuel Diamant", 
    "title": "Paving the Way for Image Understanding: A New Kind of Image   Decomposition is Desired", 
    "publish": "2005-07-22T12:18:44Z", 
    "summary": "In this paper we present an unconventional image segmentation approach which\nis devised to meet the requirements of image understanding and pattern\nrecognition tasks. Generally image understanding assumes interplay of two\nsub-processes: image information content discovery and image information\ncontent interpretation. Despite of its widespread use, the notion of \"image\ninformation content\" is still ill defined, intuitive, and ambiguous. Most\noften, it is used in the Shannon's sense, which means information content\nassessment averaged over the whole signal ensemble. Humans, however,rarely\nresort to such estimates. They are very effective in decomposing images into\ntheir meaningful constituents and focusing attention to the perceptually\nrelevant image parts. We posit that following the latest findings in human\nattention vision studies and the concepts of Kolmogorov's complexity theory an\nunorthodox segmentation approach can be proposed that provides effective image\ndecomposition to information preserving image fragments well suited for\nsubsequent image interpretation. We provide some illustrative examples,\ndemonstrating effectiveness of this approach.", 
    "link": "http://arxiv.org/pdf/cs/0507058v1", 
    "arxiv-id": "cs/0507058v1"
},{
    "category": "cs.CV", 
    "author": "Regis de A. Barbosa", 
    "title": "Automatic Face Recognition System Based on Local Fourier-Bessel Features", 
    "publish": "2005-09-27T15:25:36Z", 
    "summary": "We present an automatic face verification system inspired by known properties\nof biological systems. In the proposed algorithm the whole image is converted\nfrom the spatial to polar frequency domain by a Fourier-Bessel Transform (FBT).\nUsing the whole image is compared to the case where only face image regions\n(local analysis) are considered. The resulting representations are embedded in\na dissimilarity space, where each image is represented by its distance to all\nthe other images, and a Pseudo-Fisher discriminator is built. Verification test\nresults on the FERET database showed that the local-based algorithm outperforms\nthe global-FBT version. The local-FBT algorithm performed as state-of-the-art\nmethods under different testing conditions, indicating that the proposed system\nis highly robust for expression, age, and illumination variations. We also\nevaluated the performance of the proposed system under strong occlusion\nconditions and found that it is highly robust for up to 50% of face occlusion.\nFinally, we automated completely the verification system by implementing face\nand eye detection algorithms. Under this condition, the local approach was only\nslightly superior to the global approach.", 
    "link": "http://arxiv.org/pdf/cs/0509081v1", 
    "arxiv-id": "cs/0509081v1"
},{
    "category": "cs.CV", 
    "author": "Roberto M. Cesar-JR", 
    "title": "Face Recognition Based on Polar Frequency Features", 
    "publish": "2005-09-27T15:50:27Z", 
    "summary": "A novel biologically motivated face recognition algorithm based on polar\nfrequency is presented. Polar frequency descriptors are extracted from face\nimages by Fourier-Bessel transform (FBT). Next, the Euclidean distance between\nall images is computed and each image is now represented by its dissimilarity\nto the other images. A Pseudo-Fisher Linear Discriminant was built on this\ndissimilarity space. The performance of Discrete Fourier transform (DFT)\ndescriptors, and a combination of both feature types was also evaluated. The\nalgorithms were tested on a 40- and 1196-subjects face database (ORL and FERET,\nrespectively). With 5 images per subject in the training and test datasets,\nerror rate on the ORL database was 3.8, 1.25 and 0.2% for the FBT, DFT, and the\ncombined classifier, respectively, as compared to 2.6% achieved by the best\nprevious algorithm. The most informative polar frequency features were\nconcentrated at low-to-medium angular frequencies coupled to low radial\nfrequencies. On the FERET database, where an affine normalization\npre-processing was applied, the FBT algorithm outperformed only the PCA in a\nrank recognition test. However, it achieved performance comparable to\nstate-of-the-art methods when evaluated by verification tests. These results\nindicate the high informative value of the polar frequency content of face\nimages in relation to recognition and verification tasks, and that the\nCartesian frequency content can complement information about the subjects'\nidentity, but possibly only when the images are not pre-normalized. Possible\nimplications for human face recognition are discussed.", 
    "link": "http://arxiv.org/pdf/cs/0509082v1", 
    "arxiv-id": "cs/0509082v1"
},{
    "category": "cs.CV", 
    "author": "Matthew Turk", 
    "title": "Face Verification in Polar Frequency Domain: a Biologically Motivated   Approach", 
    "publish": "2005-09-27T16:06:22Z", 
    "summary": "We present a novel local-based face verification system whose components are\nanalogous to those of biological systems. In the proposed system, after global\nregistration and normalization, three eye regions are converted from the\nspatial to polar frequency domain by a Fourier-Bessel Transform. The resulting\nrepresentations are embedded in a dissimilarity space, where each image is\nrepresented by its distance to all the other images. In this dissimilarity\nspace a Pseudo-Fisher discriminator is built. ROC and equal error rate\nverification test results on the FERET database showed that the system\nperformed at least as state-of-the-art methods and better than a system based\non polar Fourier features. The local-based system is especially robust to\nfacial expression and age variations, but sensitive to registration errors.", 
    "link": "http://arxiv.org/pdf/cs/0509083v1", 
    "arxiv-id": "cs/0509083v1"
},{
    "category": "cs.CV", 
    "author": "Michael J. Cree", 
    "title": "Retinal Vessel Segmentation Using the 2-D Morlet Wavelet and Supervised   Classification", 
    "publish": "2005-09-30T22:27:45Z", 
    "summary": "We present a method for automated segmentation of the vasculature in retinal\nimages. The method produces segmentations by classifying each image pixel as\nvessel or non-vessel, based on the pixel's feature vector. Feature vectors are\ncomposed of the pixel's intensity and continuous two-dimensional Morlet wavelet\ntransform responses taken at multiple scales. The Morlet wavelet is capable of\ntuning to specific frequencies, thus allowing noise filtering and vessel\nenhancement in a single step. We use a Bayesian classifier with\nclass-conditional probability density functions (likelihoods) described as\nGaussian mixtures, yielding a fast classification, while being able to model\ncomplex decision surfaces and compare its performance with the linear minimum\nsquared error classifier. The probability distributions are estimated based on\na training set of labeled pixels obtained from manual segmentations. The\nmethod's performance is evaluated on publicly available DRIVE and STARE\ndatabases of manually labeled non-mydriatic images. On the DRIVE database, it\nachieves an area under the receiver operating characteristic (ROC) curve of\n0.9598, being slightly superior than that presented by the method of Staal et\nal.", 
    "link": "http://arxiv.org/pdf/cs/0510001v2", 
    "arxiv-id": "cs/0510001v2"
},{
    "category": "cs.CV", 
    "author": "Carlos Dorronsoro", 
    "title": "A decision support system for ship identification based on the curvature   scale space representation", 
    "publish": "2005-10-11T08:43:04Z", 
    "summary": "In this paper, a decision support system for ship identification is\npresented. The system receives as input a silhouette of the vessel to be\nidentified, previously extracted from a side view of the object. This view\ncould have been acquired with imaging sensors operating at different spectral\nranges (CCD, FLIR, image intensifier). The input silhouette is preprocessed and\ncompared to those stored in a database, retrieving a small number of potential\nmatches ranked by their similarity to the target silhouette. This set of\npotential matches is presented to the system operator, who makes the final ship\nidentification. This system makes use of an evolved version of the Curvature\nScale Space (CSS) representation. In the proposed approach, it is curvature\nextrema, instead of zero crossings, that are tracked during silhouette\nevolution, hence improving robustness and enabling to cope successfully with\ncases where the standard CCS representation is found to be unstable. Also, the\nuse of local curvature was replaced with the more robust concept of lobe\nconcavity, with significant additional gains in performance. Experimental\nresults on actual operational imagery prove the excellent performance and\nrobustness of the developed method.", 
    "link": "http://arxiv.org/pdf/cs/0510026v1", 
    "arxiv-id": "cs/0510026v1"
},{
    "category": "cs.CV", 
    "author": "Hanna Makaruk", 
    "title": "Understanding physics from interconnected data", 
    "publish": "2005-12-21T20:23:38Z", 
    "summary": "Metal melting on release after explosion is a physical system far from\nquilibrium. A complete physical model of this system does not exist, because\nmany interrelated effects have to be considered. General methodology needs to\nbe developed so as to describe and understand physical phenomena involved.\n  The high noise of the data, moving blur of images, the high degree of\nuncertainty due to the different types of sensors, and the information\nentangled and hidden inside the noisy images makes reasoning about the physical\nprocesses very difficult. Major problems include proper information extraction\nand the problem of reconstruction, as well as prediction of the missing data.\nIn this paper, several techniques addressing the first problem are given,\nbuilding the basis for tackling the second problem.", 
    "link": "http://arxiv.org/pdf/cs/0512084v1", 
    "arxiv-id": "cs/0512084v1"
},{
    "category": "cs.CV", 
    "author": "Vassilios S. Vassiliadis", 
    "title": "The Perceptron Algorithm: Image and Signal Decomposition, Compression,   and Analysis by Iterative Gaussian Blurring", 
    "publish": "2006-01-24T17:23:17Z", 
    "summary": "A novel algorithm for tunable compression to within the precision of\nreproduction targets, or storage, is proposed. The new algorithm is termed the\n`Perceptron Algorithm', which utilises simple existing concepts in a novel way,\nhas multiple immediate commercial application aspects as well as it opens up a\nmultitude of fronts in computational science and technology. The aims of this\npaper are to present the concepts underlying the algorithm, observations by its\napplication to some example cases, and the identification of a multitude of\npotential areas of applications such as: image compression by orders of\nmagnitude, signal compression including sound as well, image analysis in a\nmultilayered detailed analysis, pattern recognition and matching and rapid\ndatabase searching (e.g. face recognition), motion analysis, biomedical\napplications e.g. in MRI and CAT scan image analysis and compression, as well\nas hints on the link of these ideas to the way how biological memory might work\nleading to new points of view in neural computation. Commercial applications of\nimmediate interest are the compression of images at the source (e.g.\nphotographic equipment, scanners, satellite imaging systems), DVD film\ncompression, pay-per-view downloads acceleration and many others identified in\nthe present paper at its conclusion and future work section.", 
    "link": "http://arxiv.org/pdf/cs/0601105v3", 
    "arxiv-id": "cs/0601105v3"
},{
    "category": "cs.CV", 
    "author": "Vassilios S. Vassiliadis", 
    "title": "The `Face on Mars': a photographic approach for the search of signs of   past civilizations from a macroscopic point of view, factoring long-term   erosion in image reconstruction", 
    "publish": "2006-01-24T18:12:00Z", 
    "summary": "This short article presents an alternative view of high resolution imaging\nfrom various sources with the aim of the discovery of potential sites of\narchaeological importance, or sites that exhibit `anomalies' such that they may\nmerit closer inspection and analysis. It is conjectured, and to a certain\nextent demonstrated here, that it is possible for advanced civilizations to\nfactor in erosion by natural processes into a large scale design so that main\nfeatures be preserved even with the passage of millions of years. Alternatively\nviewed, even without such intent embedded in a design left for posterity, it is\npossible that a gigantic construction may naturally decay in such a way that\neven cataclysmic (massive) events may leave sufficient information intact with\nthe passage of time, provided one changes the point of view from high\nresolution images to enhanced blurred renderings of the sites in question.", 
    "link": "http://arxiv.org/pdf/cs/0601106v1", 
    "arxiv-id": "cs/0601106v1"
},{
    "category": "cs.CV", 
    "author": "Prasanta K. Panigrahi", 
    "title": "Multilevel Thresholding for Image Segmentation through a Fast   Statistical Recursive Algorithm", 
    "publish": "2006-02-12T18:22:41Z", 
    "summary": "A novel algorithm is proposed for segmenting an image into multiple levels\nusing its mean and variance. Starting from the extreme pixel values at both\nends of the histogram plot, the algorithm is applied recursively on sub-ranges\ncomputed from the previous step, so as to find a threshold level and a new\nsub-range for the next step, until no significant improvement in image quality\ncan be achieved. The method makes use of the fact that a number of\ndistributions tend towards Dirac delta function, peaking at the mean, in the\nlimiting condition of vanishing variance. The procedure naturally provides for\nvariable size segmentation with bigger blocks near the extreme pixel values and\nfiner divisions around the mean or other chosen value for better visualization.\nExperiments on a variety of images show that the new algorithm effectively\nsegments the image in computationally very less time.", 
    "link": "http://arxiv.org/pdf/cs/0602044v1", 
    "arxiv-id": "cs/0602044v1"
},{
    "category": "cs.CV", 
    "author": "Prasanta K. Panigrahi", 
    "title": "Locally Adaptive Block Thresholding Method with Continuity Constraint", 
    "publish": "2006-03-09T17:14:00Z", 
    "summary": "We present an algorithm that enables one to perform locally adaptive block\nthresholding, while maintaining image continuity. Images are divided into\nsub-images based some standard image attributes and thresholding technique is\nemployed over the sub-images. The present algorithm makes use of the thresholds\nof neighboring sub-images to calculate a range of values. The image continuity\nis taken care by choosing the threshold of the sub-image under consideration to\nlie within the above range. After examining the average range values for\nvarious sub-image sizes of a variety of images, it was found that the range of\nacceptable threshold values is substantially high, justifying our assumption of\nexploiting the freedom of range for bringing out local details.", 
    "link": "http://arxiv.org/pdf/cs/0603041v1", 
    "arxiv-id": "cs/0603041v1"
},{
    "category": "cs.CV", 
    "author": "Mickael Urrutia", 
    "title": "Matching Edges in Images ; Application to Face Recognition", 
    "publish": "2006-03-22T14:51:53Z", 
    "summary": "This communication describes a representation of images as a set of edges\ncharacterized by their position and orientation. This representation allows the\ncomparison of two images and the computation of their similarity. The first\nstep in this computation of similarity is the seach of a geometrical basis of\nthe two dimensional space where the two images are represented simultaneously\nafter transformation of one of them. Presently, this simultaneous\nrepresentation takes into account a shift and a scaling ; it may be extended to\nrotations or other global geometrical transformations. An elementary\nprobabilistic computation shows that a sufficient but not excessive number of\ntrials (a few tens) ensures that the exhibition of this common basis is\nguaranteed in spite of possible errors in the detection of edges. When this\nfirst step is performed, the search of similarity between the two images\nreduces to counting the coincidence of edges in the two images. The approach\nmay be applied to many problems of pattern matching ; it was checked on face\nrecognition.", 
    "link": "http://arxiv.org/pdf/cs/0603086v1", 
    "arxiv-id": "cs/0603086v1"
},{
    "category": "cs.CV", 
    "author": "J. C. de Oliveira", 
    "title": "Fourier Analysis and Holographic Representations of 1D and 2D Signals", 
    "publish": "2006-03-29T19:07:52Z", 
    "summary": "In this paper, we focus on Fourier analysis and holographic transforms for\nsignal representation. For instance, in the case of image processing, the\nholographic representation has the property that an arbitrary portion of the\ntransformed image enables reconstruction of the whole image with details\nmissing. We focus on holographic representation defined through the Fourier\nTransforms. Thus, We firstly review some results in Fourier transform and\nFourier series. Next, we review the Discrete Holographic Fourier Transform\n(DHFT) for image representation. Then, we describe the contributions of our\nwork. We show a simple scheme for progressive transmission based on the DHFT.\nNext, we propose the Continuous Holographic Fourier Transform (CHFT) and\ndiscuss some theoretical aspects of it for 1D signals. Finally, some testes are\npresented in the experimental results", 
    "link": "http://arxiv.org/pdf/cs/0603116v2", 
    "arxiv-id": "cs/0603116v2"
},{
    "category": "cs.CV", 
    "author": "Liang Wu", 
    "title": "Biologically Inspired Hierarchical Model for Feature Extraction and   Localization", 
    "publish": "2006-04-14T04:40:29Z", 
    "summary": "Feature extraction and matching are among central problems of computer\nvision. It is inefficent to search features over all locations and scales.\nNeurophysiological evidence shows that to locate objects in a digital image the\nhuman visual system employs visual attention to a specific object while\nignoring others. The brain also has a mechanism to search from coarse to fine.\nIn this paper, we present a feature extractor and an associated hierarchical\nsearching model to simulate such processes. With the hierarchical\nrepresentation of the object, coarse scanning is done through the matching of\nthe larger scale and precise localization is conducted through the matching of\nthe smaller scale. Experimental results justify the proposed model in its\neffectiveness and efficiency to localize features.", 
    "link": "http://arxiv.org/pdf/cs/0604062v1", 
    "arxiv-id": "cs/0604062v1"
},{
    "category": "cs.CV", 
    "author": "Vytautas Perlibakas", 
    "title": "Face Recognition using Principal Component Analysis and Log-Gabor   Filters", 
    "publish": "2006-05-07T13:30:09Z", 
    "summary": "In this article we propose a novel face recognition method based on Principal\nComponent Analysis (PCA) and Log-Gabor filters. The main advantages of the\nproposed method are its simple implementation, training, and very high\nrecognition accuracy. For recognition experiments we used 5151 face images of\n1311 persons from different sets of the FERET and AR databases that allow to\nanalyze how recognition accuracy is affected by the change of facial\nexpressions, illumination, and aging. Recognition experiments with the FERET\ndatabase (containing photographs of 1196 persons) showed that our method can\nachieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error\nRate. The experiments also showed that the accuracy of our method is less\naffected by eye location errors and used image normalization method than of\ntraditional PCA -based recognition method.", 
    "link": "http://arxiv.org/pdf/cs/0605025v1", 
    "arxiv-id": "cs/0605025v1"
},{
    "category": "cs.CV", 
    "author": "Vytautas Perlibakas", 
    "title": "Recognition of expression variant faces using masked log-Gabor features   and Principal Component Analysis", 
    "publish": "2006-05-07T15:02:53Z", 
    "summary": "In this article we propose a method for the recognition of faces with\ndifferent facial expressions. For recognition we extract feature vectors by\nusing log-Gabor filters of multiple orientations and scales. Using sliding\nwindow algorithm and variances -based masking these features are extracted at\nimage regions that are less affected by the changes of facial expressions.\nExtracted features are passed to the Principal Component Analysis (PCA) -based\nrecognition method. The results of face recognition experiments using\nexpression variant faces showed that the proposed method could achieve higher\nrecognition accuracy than many other methods. For development and testing we\nused facial images from the AR and FERET databases. Using facial photographs of\nmore than one thousand persons from the FERET database the proposed method\nachieved 96.6-98.9% first one recognition rate and 0.2-0.6% Equal Error Rate\n(EER).", 
    "link": "http://arxiv.org/pdf/cs/0605027v1", 
    "arxiv-id": "cs/0605027v1"
},{
    "category": "cs.CV", 
    "author": "Simon P Morgan", 
    "title": "Notes on Geometric Measure Theory Applications to Image Processing;   De-noising, Segmentation, Pattern, Texture, Lines, Gestalt and Occlusion", 
    "publish": "2006-05-29T13:27:38Z", 
    "summary": "Regularization functionals that lower level set boundary length when used\nwith L^1 fidelity functionals on signal de-noising on images create artifacts.\nThese are (i) rounding of corners, (ii) shrinking of radii, (iii) shrinking of\ncusps, and (iv) non-smoothing of staircasing. Regularity functionals based upon\ntotal curvature of level set boundaries do not create artifacts (i) and (ii).\nAn adjusted fidelity term based on the flat norm on the current (a\ndistributional graph) representing the density of curvature of level sets\nboundaries can minimize (iii) by weighting the position of a cusp. A regularity\nterm to eliminate staircasing can be based upon the mass of the current\nrepresenting the graph of an image function or its second derivatives.\nDensities on the Grassmann bundle of the Grassmann bundle of the ambient space\nof the graph can be used to identify patterns, textures, occlusion and lines.", 
    "link": "http://arxiv.org/pdf/cs/0605131v2", 
    "arxiv-id": "cs/0605131v2"
},{
    "category": "cs.CV", 
    "author": "Artur Rataj", 
    "title": "An effective edge--directed frequency filter for removal of aliasing in   upsampled images", 
    "publish": "2006-09-04T13:04:57Z", 
    "summary": "Raster images can have a range of various distortions connected to their\nraster structure. Upsampling them might in effect substantially yield the\nraster structure of the original image, known as aliasing. The upsampling\nitself may introduce aliasing into the upsampled image as well. The presented\nmethod attempts to remove the aliasing using frequency filters based on the\ndiscrete fast Fourier transform, and applied directionally in certain regions\nplaced along the edges in the image.\n  As opposed to some anisotropic smoothing methods, the presented algorithm\naims to selectively reduce only the aliasing, preserving the sharpness of image\ndetails.\n  The method can be used as a post--processing filter along with various\nupsampling algorithms. It was experimentally shown that the method can improve\nthe visual quality of the upsampled images.", 
    "link": "http://arxiv.org/pdf/cs/0609010v1", 
    "arxiv-id": "cs/0609010v1"
},{
    "category": "cs.CV", 
    "author": "Fran\u00e7oise Dibos", 
    "title": "Total Variation Minimization and Graph Cuts for Moving Objects   Segmentation", 
    "publish": "2006-09-18T06:40:44Z", 
    "summary": "In this paper, we are interested in the application to video segmentation of\nthe discrete shape optimization problem involving the shape weighted perimeter\nand an additional term depending on a parameter. Based on recent works and in\nparticular the one of Darbon and Sigelle, we justify the equivalence of the\nshape optimization problem and a weighted total variation regularization. For\nsolving this problem, we adapt the projection algorithm proposed recently for\nsolving the basic TV regularization problem. Another solution to the shape\noptimization investigated here is the graph cut technique. Both methods have\nthe advantage to lead to a global minimum. Since we can distinguish moving\nobjects from static elements of a scene by analyzing norm of the optical flow\nvectors, we choose the optical flow norm as initial data. In order to have the\ncontour as close as possible to an edge in the image, we use a classical edge\ndetector function as the weight of the weighted total variation. This model has\nbeen used in one of our former works. We also apply the same methods to a video\nsegmentation model used by Jehan-Besson, Barlaud and Aubert. In this case, only\nstandard perimeter is incorporated in the shape functional. We also propose\nanother way for finding moving objects by using an a contrario detection of\nobjects on the image obtained by solving the Rudin-Osher-Fatemi Total Variation\nregularization problem.We can notice the segmentation can be associated to a\nlevel set in the former methods.", 
    "link": "http://arxiv.org/pdf/cs/0609100v1", 
    "arxiv-id": "cs/0609100v1"
},{
    "category": "cs.CV", 
    "author": "F. M. Toyama", 
    "title": "Conditional Expressions for Blind Deconvolution: Multi-point form", 
    "publish": "2006-09-29T13:48:35Z", 
    "summary": "We present conditional expression (CE) for finding blurs convolved in given\nimages. The CE is given in terms of the zero-values of the blurs evaluated at\nmulti-point. The CE can detect multiple blur all at once. We illustrate the\nmultiple blur-detection by using a test image.", 
    "link": "http://arxiv.org/pdf/cs/0609164v1", 
    "arxiv-id": "cs/0609164v1"
},{
    "category": "cs.CV", 
    "author": "F. M. Toyama", 
    "title": "Simple method to eliminate blur based on Lane and Bates algorithm", 
    "publish": "2006-09-29T13:50:12Z", 
    "summary": "A simple search method for finding a blur convolved in a given image is\npresented. The method can be easily extended to a large blur. The method has\nbeen experimentally tested with a model blurred image.", 
    "link": "http://arxiv.org/pdf/cs/0609165v1", 
    "arxiv-id": "cs/0609165v1"
},{
    "category": "cs.CV", 
    "author": "F. M. Toyama", 
    "title": "Conditional Expressions for Blind Deconvolution: Derivative form", 
    "publish": "2006-09-30T08:05:02Z", 
    "summary": "We developed novel conditional expressions (CEs) for Lane and Bates' blind\ndeconvolution. The CEs are given in term of the derivatives of the zero-values\nof the z-transform of given images. The CEs make it possible to automatically\ndetect multiple blur convolved in the given images all at once without\nperforming any analysis of the zero-sheets of the given images. We illustrate\nthe multiple blur-detection by the CEs for a model image", 
    "link": "http://arxiv.org/pdf/cs/0610002v1", 
    "arxiv-id": "cs/0610002v1"
},{
    "category": "cs.CV", 
    "author": "Georges Koepfler", 
    "title": "Camera motion estimation through planar deformation determination", 
    "publish": "2006-10-11T09:31:52Z", 
    "summary": "In this paper, we propose a global method for estimating the motion of a\ncamera which films a static scene. Our approach is direct, fast and robust, and\ndeals with adjacent frames of a sequence. It is based on a quadratic\napproximation of the deformation between two images, in the case of a scene\nwith constant depth in the camera coordinate system. This condition is very\nrestrictive but we show that provided translation and depth inverse variations\nare small enough, the error on optical flow involved by the approximation of\ndepths by a constant is small. In this context, we propose a new model of\ncamera motion, that allows to separate the image deformation in a similarity\nand a ``purely'' projective application, due to change of optical axis\ndirection. This model leads to a quadratic approximation of image deformation\nthat we estimate with an M-estimator; we can immediatly deduce camera motion\nparameters.", 
    "link": "http://arxiv.org/pdf/cs/0610059v2", 
    "arxiv-id": "cs/0610059v2"
},{
    "category": "cs.CV", 
    "author": "Josiane Zerubia", 
    "title": "A higher-order active contour model of a `gas of circles' and its   application to tree crown extraction", 
    "publish": "2006-11-22T13:44:11Z", 
    "summary": "Many image processing problems involve identifying the region in the image\ndomain occupied by a given entity in the scene. Automatic solution of these\nproblems requires models that incorporate significant prior knowledge about the\nshape of the region. Many methods for including such knowledge run into\ndifficulties when the topology of the region is unknown a priori, for example\nwhen the entity is composed of an unknown number of similar objects.\nHigher-order active contours (HOACs) represent one method for the modelling of\nnon-trivial prior knowledge about shape without necessarily constraining region\ntopology, via the inclusion of non-local interactions between region boundary\npoints in the energy defining the model. The case of an unknown number of\ncircular objects arises in a number of domains, e.g. medical, biological,\nnanotechnological, and remote sensing imagery. Regions composed of an a priori\nunknown number of circles may be referred to as a `gas of circles'. In this\nreport, we present a HOAC model of a `gas of circles'. In order to guarantee\nstable circles, we conduct a stability analysis via a functional Taylor\nexpansion of the HOAC energy around a circular shape. This analysis fixes one\nof the model parameters in terms of the others and constrains the rest. In\nconjunction with a suitable likelihood energy, we apply the model to the\nextraction of tree crowns from aerial imagery, and show that the new model\noutperforms other techniques.", 
    "link": "http://arxiv.org/pdf/cs/0611115v1", 
    "arxiv-id": "cs/0611115v1"
},{
    "category": "cs.CV", 
    "author": "Walter G. Kropatsch", 
    "title": "Contains and Inside relationships within combinatorial Pyramids", 
    "publish": "2007-01-24T15:13:06Z", 
    "summary": "Irregular pyramids are made of a stack of successively reduced graphs\nembedded in the plane. Such pyramids are used within the segmentation framework\nto encode a hierarchy of partitions. The different graph models used within the\nirregular pyramid framework encode different types of relationships between\nregions. This paper compares different graph models used within the irregular\npyramid framework according to a set of relationships between regions. We also\ndefine a new algorithm based on a pyramid of combinatorial maps which allows to\ndetermine if one region contains the other using only local calculus.", 
    "link": "http://arxiv.org/pdf/cs/0701150v1", 
    "arxiv-id": "cs/0701150v1"
},{
    "category": "cs.CV", 
    "author": "Nicolas Lom\u00e9nie", 
    "title": "Extraction of cartographic objects in high resolution satellite images   for object model generation", 
    "publish": "2007-03-12T15:57:23Z", 
    "summary": "The aim of this study is to detect man-made cartographic objects in\nhigh-resolution satellite images. New generation satellites offer a sub-metric\nspatial resolution, in which it is possible (and necessary) to develop methods\nat object level rather than at pixel level, and to exploit structural features\nof objects. With this aim, a method to generate structural object models from\nmanually segmented images has been developed. To generate the model from\nnon-segmented images, extraction of the objects from the sample images is\nrequired. A hybrid method of extraction (both in terms of input sources and\nsegmentation algorithms) is proposed: A region based segmentation is applied on\na 10 meter resolution multi-spectral image. The result is used as marker in a\n\"marker-controlled watershed method using edges\" on a 2.5 meter resolution\npanchromatic image. Very promising results have been obtained even on images\nwhere the limits of the target objects are not apparent.", 
    "link": "http://arxiv.org/pdf/cs/0703053v1", 
    "arxiv-id": "cs/0703053v1"
},{
    "category": "cs.CV", 
    "author": "Bruno Taconet", 
    "title": "Text Line Segmentation of Historical Documents: a Survey", 
    "publish": "2007-04-10T16:26:42Z", 
    "summary": "There is a huge amount of historical documents in libraries and in various\nNational Archives that have not been exploited electronically. Although\nautomatic reading of complete pages remains, in most cases, a long-term\nobjective, tasks such as word spotting, text/image alignment, authentication\nand extraction of specific fields are in use today. For all these tasks, a\nmajor step is document segmentation into text lines. Because of the low quality\nand the complexity of these documents (background noise, artifacts due to\naging, interfering lines),automatic text line segmentation remains an open\nresearch field. The objective of this paper is to present a survey of existing\nmethods, developed during the last decade, and dedicated to documents of\nhistorical interest.", 
    "link": "http://arxiv.org/pdf/0704.1267v1", 
    "arxiv-id": "0704.1267v1"
},{
    "category": "cs.CV", 
    "author": "Maher Moakher", 
    "title": "Riemannian level-set methods for tensor-valued data", 
    "publish": "2007-05-02T07:32:58Z", 
    "summary": "We present a novel approach for the derivation of PDE modeling\ncurvature-driven flows for matrix-valued data. This approach is based on the\nRiemannian geometry of the manifold of Symmetric Positive Definite Matrices\nPos(n).", 
    "link": "http://arxiv.org/pdf/0705.0214v1", 
    "arxiv-id": "0705.0214v1"
},{
    "category": "cs.CV", 
    "author": "Gilbas M\u00e9nier", 
    "title": "Multiresolution Approximation of Polygonal Curves in Linear Complexity", 
    "publish": "2007-05-03T12:47:31Z", 
    "summary": "We propose a new algorithm to the problem of polygonal curve approximation\nbased on a multiresolution approach. This algorithm is suboptimal but still\nmaintains some optimality between successive levels of resolution using dynamic\nprogramming. We show theoretically and experimentally that this algorithm has a\nlinear complexity in time and space. We experimentally compare the outcomes of\nour algorithm to the optimal \"full search\" dynamic programming solution and\nfinally to classical merge and split approaches. The experimental evaluations\nconfirm the theoretical derivations and show that the proposed approach\nevaluated on 2D coastal maps either show a lower time complexity or provide\npolygonal approximations closer to the input discrete curves.", 
    "link": "http://arxiv.org/pdf/0705.0449v1", 
    "arxiv-id": "0705.0449v1"
},{
    "category": "cs.CV", 
    "author": "T. Marwala", 
    "title": "Medical Image Segmentation and Localization using Deformable Templates", 
    "publish": "2007-05-06T06:02:46Z", 
    "summary": "This paper presents deformable templates as a tool for segmentation and\nlocalization of biological structures in medical images. Structures are\nrepresented by a prototype template, combined with a parametric warp mapping\nused to deform the original shape. The localization procedure is achieved using\na multi-stage, multi-resolution algorithm de-signed to reduce computational\ncomplexity and time. The algorithm initially identifies regions in the image\nmost likely to contain the desired objects and then examines these regions at\nprogressively increasing resolutions. The final stage of the algorithm involves\nwarping the prototype template to match the localized objects. The algorithm is\npresented along with the results of four example applications using MRI, x-ray\nand ultrasound images.", 
    "link": "http://arxiv.org/pdf/0705.0781v1", 
    "arxiv-id": "0705.0781v1"
},{
    "category": "cs.CV", 
    "author": "T. Marwala", 
    "title": "Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field   Annealing", 
    "publish": "2007-05-06T23:08:04Z", 
    "summary": "Nuclear medicine (NM) images inherently suffer from large amounts of noise\nand blur. The purpose of this research is to reduce the noise and blur while\nmaintaining image integrity for improved diagnosis. The proposed solution is to\nincrease image quality after the standard pre- and post-processing undertaken\nby a gamma camera system. Mean Field Annealing (MFA) is the image processing\ntechnique used in this research. It is a computational iterative technique that\nmakes use of the Point Spread Function (PSF) and the noise associated with the\nNM image. MFA is applied to NM images with the objective of reducing noise\nwhile not compromising edge integrity. Using a sharpening filter as a\npost-processing technique (after MFA) yields image enhancement of planar NM\nimages.", 
    "link": "http://arxiv.org/pdf/0705.0828v1", 
    "arxiv-id": "0705.0828v1"
},{
    "category": "cs.CV", 
    "author": "Tshilidzi Marwala", 
    "title": "An Independent Evaluation of Subspace Face Recognition Algorithms", 
    "publish": "2007-05-07T19:19:55Z", 
    "summary": "This paper explores a comparative study of both the linear and kernel\nimplementations of three of the most popular Appearance-based Face Recognition\nprojection classes, these being the methodologies of Principal Component\nAnalysis, Linear Discriminant Analysis and Independent Component Analysis. The\nexperimental procedure provides a platform of equal working conditions and\nexamines the ten algorithms in the categories of expression, illumination,\nocclusion and temporal delay. The results are then evaluated based on a\nsequential combination of assessment tools that facilitate both intuitive and\nstatistical decisiveness among the intra and interclass comparisons. The best\ncategorical algorithms are then incorporated into a hybrid methodology, where\nthe advantageous effects of fusion strategies are considered.", 
    "link": "http://arxiv.org/pdf/0705.0952v1", 
    "arxiv-id": "0705.0952v1"
},{
    "category": "cs.CV", 
    "author": "P. de Groen", 
    "title": "MI image registration using prior knowledge", 
    "publish": "2007-05-24T14:41:11Z", 
    "summary": "Subtraction of aligned images is a means to assess changes in a wide variety\nof clinical applications. In this paper we explore the information theoretical\norigin of Mutual Information (MI), which is based on Shannon's entropy.However,\nthe interpretation of standard MI registration as a communication channel\nsuggests that MI is too restrictive a criterion. In this paper the concept of\nMutual Information (MI) is extended to (Normalized) Focussed Mutual Information\n(FMI) to incorporate prior knowledge to overcome some shortcomings of MI. We\nuse this to develop new methodologies to successfully address specific\nregistration problems, the follow-up of dental restorations, cephalometry, and\nthe monitoring of implants.", 
    "link": "http://arxiv.org/pdf/0705.3593v2", 
    "arxiv-id": "0705.3593v2"
},{
    "category": "cs.CV", 
    "author": "David Rubin", 
    "title": "Automatic Detection of Pulmonary Embolism using Computational   Intelligence", 
    "publish": "2007-06-03T05:17:38Z", 
    "summary": "This article describes the implementation of a system designed to\nautomatically detect the presence of pulmonary embolism in lung scans. These\nimages are firstly segmented, before alignment and feature extraction using\nPCA. The neural network was trained using the Hybrid Monte Carlo method,\nresulting in a committee of 250 neural networks and good results are obtained.", 
    "link": "http://arxiv.org/pdf/0706.0300v1", 
    "arxiv-id": "0706.0300v1"
},{
    "category": "cs.CV", 
    "author": "Heng Lian", 
    "title": "Variational local structure estimation for image super-resolution", 
    "publish": "2007-09-12T08:41:36Z", 
    "summary": "Super-resolution is an important but difficult problem in image/video\nprocessing. If a video sequence or some training set other than the given\nlow-resolution image is available, this kind of extra information can greatly\naid in the reconstruction of the high-resolution image. The problem is\nsubstantially more difficult with only a single low-resolution image on hand.\nThe image reconstruction methods designed primarily for denoising is\ninsufficient for super-resolution problem in the sense that it tends to\noversmooth images with essentially no noise. We propose a new adaptive linear\ninterpolation method based on variational method and inspired by local linear\nembedding (LLE). The experimental result shows that our method avoids the\nproblem of oversmoothing and preserves image structures well.", 
    "link": "http://arxiv.org/pdf/0709.1771v1", 
    "arxiv-id": "0709.1771v1"
},{
    "category": "cs.CV", 
    "author": "Patrick P\u00e9rez", 
    "title": "Bandwidth selection for kernel estimation in mixed multi-dimensional   spaces", 
    "publish": "2007-09-12T16:02:25Z", 
    "summary": "Kernel estimation techniques, such as mean shift, suffer from one major\ndrawback: the kernel bandwidth selection. The bandwidth can be fixed for all\nthe data set or can vary at each points. Automatic bandwidth selection becomes\na real challenge in case of multidimensional heterogeneous features. This paper\npresents a solution to this problem. It is an extension of \\cite{Comaniciu03a}\nwhich was based on the fundamental property of normal distributions regarding\nthe bias of the normalized density gradient. The selection is done iteratively\nfor each type of features, by looking for the stability of local bandwidth\nestimates across a predefined range of bandwidths. A pseudo balloon mean shift\nfiltering and partitioning are introduced. The validity of the method is\ndemonstrated in the context of color image segmentation based on a\n5-dimensional space.", 
    "link": "http://arxiv.org/pdf/0709.1920v2", 
    "arxiv-id": "0709.1920v2"
},{
    "category": "cs.CV", 
    "author": "Mihai Datcu", 
    "title": "Supervised learning on graphs of spatio-temporal similarity in satellite   image sequences", 
    "publish": "2007-09-19T13:18:18Z", 
    "summary": "High resolution satellite image sequences are multidimensional signals\ncomposed of spatio-temporal patterns associated to numerous and various\nphenomena. Bayesian methods have been previously proposed in (Heas and Datcu,\n2005) to code the information contained in satellite image sequences in a graph\nrepresentation using Bayesian methods. Based on such a representation, this\npaper further presents a supervised learning methodology of semantics\nassociated to spatio-temporal patterns occurring in satellite image sequences.\nIt enables the recognition and the probabilistic retrieval of similar events.\nIndeed, graphs are attached to statistical models for spatio-temporal\nprocesses, which at their turn describe physical changes in the observed scene.\nTherefore, we adjust a parametric model evaluating similarity types between\ngraph patterns in order to represent user-specific semantics attached to\nspatio-temporal phenomena. The learning step is performed by the incremental\ndefinition of similarity types via user-provided spatio-temporal pattern\nexamples attached to positive or/and negative semantics. From these examples,\nprobabilities are inferred using a Bayesian network and a Dirichlet model. This\nenables to links user interest to a specific similarity model between graph\npatterns. According to the current state of learning, semantic posterior\nprobabilities are updated for all possible graph patterns so that similar\nspatio-temporal phenomena can be recognized and retrieved from the image\nsequence. Few experiments performed on a multi-spectral SPOT image sequence\nillustrate the proposed spatio-temporal recognition method.", 
    "link": "http://arxiv.org/pdf/0709.3013v2", 
    "arxiv-id": "0709.3013v2"
},{
    "category": "cs.CV", 
    "author": "Marconi S. Barbosa", 
    "title": "Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching", 
    "publish": "2007-09-29T06:19:09Z", 
    "summary": "A recent paper \\cite{CaeCaeSchBar06} proposed a provably optimal, polynomial\ntime method for performing near-isometric point pattern matching by means of\nexact probabilistic inference in a chordal graphical model. Their fundamental\nresult is that the chordal graph in question is shown to be globally rigid,\nimplying that exact inference provides the same matching solution as exact\ninference in a complete graphical model. This implies that the algorithm is\noptimal when there is no noise in the point patterns. In this paper, we present\na new graph which is also globally rigid but has an advantage over the graph\nproposed in \\cite{CaeCaeSchBar06}: its maximal clique size is smaller,\nrendering inference significantly more efficient. However, our graph is not\nchordal and thus standard Junction Tree algorithms cannot be directly applied.\nNevertheless, we show that loopy belief propagation in such a graph converges\nto the optimal solution. This allows us to retain the optimality guarantee in\nthe noiseless case, while substantially reducing both memory requirements and\nprocessing time. Our experimental results show that the accuracy of the\nproposed solution is indistinguishable from that of \\cite{CaeCaeSchBar06} when\nthere is noise in the point patterns.", 
    "link": "http://arxiv.org/pdf/0710.0043v2", 
    "arxiv-id": "0710.0043v2"
},{
    "category": "cs.CV", 
    "author": "Tiberio S. Caetano", 
    "title": "High-Order Nonparametric Belief-Propagation for Fast Image Inpainting", 
    "publish": "2007-10-01T09:18:36Z", 
    "summary": "In this paper, we use belief-propagation techniques to develop fast\nalgorithms for image inpainting. Unlike traditional gradient-based approaches,\nwhich may require many iterations to converge, our techniques achieve\ncompetitive results after only a few iterations. On the other hand, while\nbelief-propagation techniques are often unable to deal with high-order models\ndue to the explosion in the size of messages, we avoid this problem by\napproximating our high-order prior model using a Gaussian mixture. By using\nsuch an approximation, we are able to inpaint images quickly while at the same\ntime retaining good visual results.", 
    "link": "http://arxiv.org/pdf/0710.0243v1", 
    "arxiv-id": "0710.0243v1"
},{
    "category": "cs.CV", 
    "author": "Qiao-liang Xiang", 
    "title": "An Affinity Propagation Based method for Vector Quantization Codebook   Design", 
    "publish": "2007-10-10T15:12:20Z", 
    "summary": "In this paper, we firstly modify a parameter in affinity propagation (AP) to\nimprove its convergence ability, and then, we apply it to vector quantization\n(VQ) codebook design problem. In order to improve the quality of the resulted\ncodebook, we combine the improved AP (IAP) with the conventional LBG algorithm\nto generate an effective algorithm call IAP-LBG. According to the experimental\nresults, the proposed method not only enhances the convergence abilities but\nalso is capable of providing higher-quality codebooks than conventional LBG\nmethod.", 
    "link": "http://arxiv.org/pdf/0710.2037v2", 
    "arxiv-id": "0710.2037v2"
},{
    "category": "cs.CV", 
    "author": "Daniel Keysers", 
    "title": "Comparison and Combination of State-of-the-art Techniques for   Handwritten Character Recognition: Topping the MNIST Benchmark", 
    "publish": "2007-10-11T12:22:27Z", 
    "summary": "Although the recognition of isolated handwritten digits has been a research\ntopic for many years, it continues to be of interest for the research community\nand for commercial applications. We show that despite the maturity of the\nfield, different approaches still deliver results that vary enough to allow\nimprovements by using their combination. We do so by choosing four\nwell-motivated state-of-the-art recognition systems for which results on the\nstandard MNIST benchmark are available. When comparing the errors made, we\nobserve that the errors made differ between all four systems, suggesting the\nuse of classifier combination. We then determine the error rate of a\nhypothetical system that combines the output of the four systems. The result\nobtained in this manner is an error rate of 0.35% on the MNIST data, the best\nresult published so far. We furthermore discuss the statistical significance of\nthe combined result and of the results of the individual classifiers.", 
    "link": "http://arxiv.org/pdf/0710.2231v1", 
    "arxiv-id": "0710.2231v1"
},{
    "category": "cs.CV", 
    "author": "Thomas M. Breuel", 
    "title": "Learning Similarity for Character Recognition and 3D Object Recognition", 
    "publish": "2007-12-02T10:02:01Z", 
    "summary": "I describe an approach to similarity motivated by Bayesian methods. This\nyields a similarity function that is learnable using a standard Bayesian\nmethods. The relationship of the approach to variable kernel and variable\nmetric methods is discussed. The approach is related to variable kernel\nExperimental results on character recognition and 3D object recognition are\npresented..", 
    "link": "http://arxiv.org/pdf/0712.0131v1", 
    "arxiv-id": "0712.0131v1"
},{
    "category": "cs.CV", 
    "author": "Thomas M. Breuel", 
    "title": "Learning View Generalization Functions", 
    "publish": "2007-12-02T10:54:40Z", 
    "summary": "Learning object models from views in 3D visual object recognition is usually\nformulated either as a function approximation problem of a function describing\nthe view-manifold of an object, or as that of learning a class-conditional\ndensity. This paper describes an alternative framework for learning in visual\nobject recognition, that of learning the view-generalization function. Using\nthe view-generalization function, an observer can perform Bayes-optimal 3D\nobject recognition given one or more 2D training views directly, without the\nneed for a separate model acquisition step. The paper shows that view\ngeneralization functions can be computationally practical by restating two\nwidely-used methods, the eigenspace and linear combination of views approaches,\nin a view generalization framework. The paper relates the approach to recent\nmethods for object recognition based on non-uniform blurring. The paper\npresents results both on simulated 3D ``paperclip'' objects and real-world\nimages from the COIL-100 database showing that useful view-generalization\nfunctions can be realistically be learned from a comparatively small number of\ntraining examples.", 
    "link": "http://arxiv.org/pdf/0712.0136v1", 
    "arxiv-id": "0712.0136v1"
},{
    "category": "cs.CV", 
    "author": "Thomas M. Breuel", 
    "title": "View Based Methods can achieve Bayes-Optimal 3D Recognition", 
    "publish": "2007-12-02T11:02:37Z", 
    "summary": "This paper proves that visual object recognition systems using only 2D\nEuclidean similarity measurements to compare object views against previously\nseen views can achieve the same recognition performance as observers having\naccess to all coordinate information and able of using arbitrary 3D models\ninternally. Furthermore, it demonstrates that such systems do not require more\ntraining views than Bayes-optimal 3D model-based systems. For building computer\nvision systems, these results imply that using view-based or appearance-based\ntechniques with carefully constructed combination of evidence mechanisms may\nnot be at a disadvantage relative to 3D model-based systems. For computational\napproaches to human vision, they show that it is impossible to distinguish\nview-based and 3D model-based techniques for 3D object recognition solely by\ncomparing the performance achievable by human and 3D model-based systems.}", 
    "link": "http://arxiv.org/pdf/0712.0137v1", 
    "arxiv-id": "0712.0137v1"
},{
    "category": "cs.CV", 
    "author": "Luc Brun", 
    "title": "Hierarchy construction schemes within the Scale set framework", 
    "publish": "2007-12-12T07:45:08Z", 
    "summary": "Segmentation algorithms based on an energy minimisation framework often\ndepend on a scale parameter which balances a fit to data and a regularising\nterm. Irregular pyramids are defined as a stack of graphs successively reduced.\nWithin this framework, the scale is often defined implicitly as the height in\nthe pyramid. However, each level of an irregular pyramid can not usually be\nreadily associated to the global optimum of an energy or a global criterion on\nthe base level graph. This last drawback is addressed by the scale set\nframework designed by Guigues. The methods designed by this author allow to\nbuild a hierarchy and to design cuts within this hierarchy which globally\nminimise an energy. This paper studies the influence of the construction scheme\nof the initial hierarchy on the resulting optimal cuts. We propose one\nsequential and one parallel method with two variations within both. Our\nsequential methods provide partitions near the global optima while parallel\nmethods require less execution times than the sequential method of Guigues even\non sequential machines.", 
    "link": "http://arxiv.org/pdf/0712.1878v1", 
    "arxiv-id": "0712.1878v1"
},{
    "category": "cs.CV", 
    "author": "Inger Plaskitt", 
    "title": "A Class of LULU Operators on Multi-Dimensional Arrays", 
    "publish": "2007-12-18T10:43:23Z", 
    "summary": "The LULU operators for sequences are extended to multi-dimensional arrays via\nthe morphological concept of connection in a way which preserves their\nessential properties, e.g. they are separators and form a four element fully\nordered semi-group. The power of the operators is demonstrated by deriving a\ntotal variation preserving discrete pulse decomposition of images.", 
    "link": "http://arxiv.org/pdf/0712.2923v1", 
    "arxiv-id": "0712.2923v1"
},{
    "category": "cs.CV", 
    "author": "Jaideva C. Goswami", 
    "title": "A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased   Estimators", 
    "publish": "2007-12-24T17:11:56Z", 
    "summary": "This paper proposes a novel method for segmentation of images by hierarchical\nmultilevel thresholding. The method is global, agglomerative in nature and\ndisregards pixel locations. It involves the optimization of the ratio of the\nunbiased estimators of within class to between class variances. We obtain a\nrecursive relation at each step for the variances which expedites the process.\nThe efficacy of the method is shown in a comparison with some well-known\nmethods.", 
    "link": "http://arxiv.org/pdf/0712.4015v1", 
    "arxiv-id": "0712.4015v1"
},{
    "category": "cs.CV", 
    "author": "Edward J. Delp", 
    "title": "Automatic Text Area Segmentation in Natural Images", 
    "publish": "2008-01-31T01:46:32Z", 
    "summary": "We present a hierarchical method for segmenting text areas in natural images.\nThe method assumes that the text is written with a contrasting color on a more\nor less uniform background. But no assumption is made regarding the language or\ncharacter set used to write the text. In particular, the text can contain\nsimple graphics or symbols. The key feature of our approach is that we first\nconcentrate on finding the background of the text, before testing whether there\nis actually text on the background. Since uniform areas are easy to find in\nnatural images, and since text backgrounds define areas which contain \"holes\"\n(where the text is written) we thus look for uniform areas containing \"holes\"\nand label them as text backgrounds candidates. Each candidate area is then\nfurther tested for the presence of text within its convex hull. We tested our\nmethod on a database of 65 images including English and Urdu text. The method\ncorrectly segmented all the text areas in 63 of these images, and in only 4 of\nthese were areas that do not contain text also segmented.", 
    "link": "http://arxiv.org/pdf/0801.4807v1", 
    "arxiv-id": "0801.4807v1"
},{
    "category": "cs.CV", 
    "author": "Jean-Luc Starck", 
    "title": "Wavelet and Curvelet Moments for Image Classification: Application to   Aggregate Mixture Grading", 
    "publish": "2008-02-24T18:25:51Z", 
    "summary": "We show the potential for classifying images of mixtures of aggregate, based\nthemselves on varying, albeit well-defined, sizes and shapes, in order to\nprovide a far more effective approach compared to the classification of\nindividual sizes and shapes. While a dominant (additive, stationary) Gaussian\nnoise component in image data will ensure that wavelet coefficients are of\nGaussian distribution, long tailed distributions (symptomatic, for example, of\nextreme values) may well hold in practice for wavelet coefficients. Energy (2nd\norder moment) has often been used for image characterization for image\ncontent-based retrieval, and higher order moments may be important also, not\nleast for capturing long tailed distributional behavior. In this work, we\nassess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet\nand curvelet transform -- coefficients as features. As analysis methodology,\ntaking account of image types, multiresolution transforms, and moments of\ncoefficients in the scales or bands, we use correspondence analysis as well as\nk-nearest neighbors supervised classification.", 
    "link": "http://arxiv.org/pdf/0802.3528v1", 
    "arxiv-id": "0802.3528v1"
},{
    "category": "cs.CV", 
    "author": "Jeroen Vendrig", 
    "title": "Spatio-activity based object detection", 
    "publish": "2008-03-11T13:40:42Z", 
    "summary": "We present the SAMMI lightweight object detection method which has a high\nlevel of accuracy and robustness, and which is able to operate in an\nenvironment with a large number of cameras. Background modeling is based on DCT\ncoefficients provided by cameras. Foreground detection uses similarity in\ntemporal characteristics of adjacent blocks of pixels, which is a\ncomputationally inexpensive way to make use of object coherence. Scene model\nupdating uses the approximated median method for improved performance.\nEvaluation at pixel level and application level shows that SAMMI object\ndetection performs better and faster than the conventional Mixture of Gaussians\nmethod.", 
    "link": "http://arxiv.org/pdf/0803.1586v1", 
    "arxiv-id": "0803.1586v1"
},{
    "category": "cs.CV", 
    "author": "Mikhail V. Konnik", 
    "title": "Using Spatially Varying Pixels Exposures and Bayer-covered Photosensors   for High Dynamic Range Imaging", 
    "publish": "2008-03-19T14:55:15Z", 
    "summary": "The method of a linear high dynamic range imaging using solid-state\nphotosensors with Bayer colour filters array is provided in this paper. Using\ninformation from neighbour pixels, it is possible to reconstruct linear images\nwith wide dynamic range from the oversaturated images. Bayer colour filters\narray is considered as an array of neutral filters in a quasimonochromatic\nlight. If the camera's response function to the desirable light source is known\nthen one can calculate correction coefficients to reconstruct oversaturated\nimages. Reconstructed images are linearized in order to provide a linear high\ndynamic range images for optical-digital imaging systems. The calibration\nprocedure for obtaining the camera's response function to the desired light\nsource is described. Experimental results of the reconstruction of the images\nfrom the oversaturated images are presented for red, green, and blue\nquasimonochromatic light sources. Quantitative analysis of the accuracy of the\nreconstructed images is provided.", 
    "link": "http://arxiv.org/pdf/0803.2812v2", 
    "arxiv-id": "0803.2812v2"
},{
    "category": "cs.CV", 
    "author": "Yongwu Rong", 
    "title": "Linear Time Recognition Algorithms for Topological Invariants in 3D", 
    "publish": "2008-04-12T03:13:33Z", 
    "summary": "In this paper, we design linear time algorithms to recognize and determine\ntopological invariants such as the genus and homology groups in 3D. These\nproperties can be used to identify patterns in 3D image recognition. This has\ntremendous amount of applications in 3D medical image analysis. Our method is\nbased on cubical images with direct adjacency, also called (6,26)-connectivity\nimages in discrete geometry. According to the fact that there are only six\ntypes of local surface points in 3D and a discrete version of the well-known\nGauss-Bonnett Theorem in differential geometry, we first determine the genus of\na closed 2D-connected component (a closed digital surface). Then, we use\nAlexander duality to obtain the homology groups of a 3D object in 3D space.", 
    "link": "http://arxiv.org/pdf/0804.1982v2", 
    "arxiv-id": "0804.1982v2"
},{
    "category": "cs.CV", 
    "author": "Isabelle Bloch", 
    "title": "A New Algorithm for Interactive Structural Image Segmentation", 
    "publish": "2008-05-13T13:39:19Z", 
    "summary": "This paper proposes a novel algorithm for the problem of structural image\nsegmentation through an interactive model-based approach. Interaction is\nexpressed in the model creation, which is done according to user traces drawn\nover a given input image. Both model and input are then represented by means of\nattributed relational graphs derived on the fly. Appearance features are taken\ninto account as object attributes and structural properties are expressed as\nrelational attributes. To cope with possible topological differences between\nboth graphs, a new structure called the deformation graph is introduced. The\nsegmentation process corresponds to finding a labelling of the input graph that\nminimizes the deformations introduced in the model when it is updated with\ninput information. This approach has shown to be faster than other segmentation\nmethods, with competitive output quality. Therefore, the method solves the\nproblem of multiple label segmentation in an efficient way. Encouraging results\non both natural and target-specific color images, as well as examples showing\nthe reusability of the model, are presented and discussed.", 
    "link": "http://arxiv.org/pdf/0805.1854v2", 
    "arxiv-id": "0805.1854v2"
},{
    "category": "cs.CV", 
    "author": "Wang Run-quan", 
    "title": "A multilateral filtering method applied to airplane runway image", 
    "publish": "2008-05-15T13:15:08Z", 
    "summary": "By considering the features of the airport runway image filtering, an\nimproved bilateral filtering method was proposed which can remove noise with\nedge preserving. Firstly the steerable filtering decomposition is used to\ncalculate the sub-band parameters of 4 orients, and the texture feature matrix\nis then obtained from the sub-band local median energy. The texture similar,\nthe spatial closer and the color similar functions are used to filter the\nimage.The effect of the weighting function parameters is qualitatively analyzed\nalso. In contrast with the standard bilateral filter and the simulation results\nfor the real airport runway image show that the multilateral filtering is more\neffective than the standard bilateral filtering.", 
    "link": "http://arxiv.org/pdf/0805.2324v1", 
    "arxiv-id": "0805.2324v1"
},{
    "category": "cs.CV", 
    "author": "S. N. Starikov", 
    "title": "Increasing Linear Dynamic Range of Commercial Digital Photocamera Used   in Imaging Systems with Optical Coding", 
    "publish": "2008-05-17T17:15:26Z", 
    "summary": "Methods of increasing linear optical dynamic range of commercial photocamera\nfor optical-digital imaging systems are described. Use of such methods allows\nto use commercial photocameras for optical measurements. Experimental results\nare reported.", 
    "link": "http://arxiv.org/pdf/0805.2690v1", 
    "arxiv-id": "0805.2690v1"
},{
    "category": "cs.CV", 
    "author": "Marinette Revenu", 
    "title": "Statistical region-based active contours with exponential family   observations", 
    "publish": "2008-05-21T07:54:07Z", 
    "summary": "In this paper, we focus on statistical region-based active contour models\nwhere image features (e.g. intensity) are random variables whose distribution\nbelongs to some parametric family (e.g. exponential) rather than confining\nourselves to the special Gaussian case. Using shape derivation tools, our\neffort focuses on constructing a general expression for the derivative of the\nenergy (with respect to a domain) and derive the corresponding evolution speed.\nA general result is stated within the framework of multi-parameter exponential\nfamily. More particularly, when using Maximum Likelihood estimators, the\nevolution speed has a closed-form expression that depends simply on the\nprobability density function, while complicating additive terms appear when\nusing other estimators, e.g. moments method. Experimental results on both\nsynthesized and real images demonstrate the applicability of our approach.", 
    "link": "http://arxiv.org/pdf/0805.3217v1", 
    "arxiv-id": "0805.3217v1"
},{
    "category": "cs.CV", 
    "author": "Eric Saloux", 
    "title": "Region-based active contour with noise and shape priors", 
    "publish": "2008-05-21T08:06:01Z", 
    "summary": "In this paper, we propose to combine formally noise and shape priors in\nregion-based active contours. On the one hand, we use the general framework of\nexponential family as a prior model for noise. On the other hand, translation\nand scale invariant Legendre moments are considered to incorporate the shape\nprior (e.g. fidelity to a reference shape). The combination of the two prior\nterms in the active contour functional yields the final evolution equation\nwhose evolution speed is rigorously derived using shape derivative tools.\nExperimental results on both synthetic images and real life cardiac echography\ndata clearly demonstrate the robustness to initialization and noise,\nflexibility and large potential applicability of our segmentation algorithm.", 
    "link": "http://arxiv.org/pdf/0805.3218v1", 
    "arxiv-id": "0805.3218v1"
},{
    "category": "cs.CV", 
    "author": "Roberto M. Cesar-Jr", 
    "title": "DimReduction - Interactive Graphic Environment for Dimensionality   Reduction", 
    "publish": "2008-05-26T14:16:06Z", 
    "summary": "Feature selection is a pattern recognition approach to choose important\nvariables according to some criteria to distinguish or explain certain\nphenomena. There are many genomic and proteomic applications which rely on\nfeature selection to answer questions such as: selecting signature genes which\nare informative about some biological state, e.g. normal tissues and several\ntypes of cancer; or defining a network of prediction or inference among\nelements such as genes, proteins, external stimuli and other elements of\ninterest. In these applications, a recurrent problem is the lack of samples to\nperform an adequate estimate of the joint probabilities between element states.\nA myriad of feature selection algorithms and criterion functions are proposed,\nalthough it is difficult to point the best solution in general. The intent of\nthis work is to provide an open-source multiplataform graphical environment to\napply, test and compare many feature selection approaches suitable to be used\nin bioinformatics problems.", 
    "link": "http://arxiv.org/pdf/0805.3964v2", 
    "arxiv-id": "0805.3964v2"
},{
    "category": "cs.CV", 
    "author": "Li Zhang", 
    "title": "Directional Cross Diamond Search Algorithm for Fast Block Motion   Estimation", 
    "publish": "2008-06-04T05:05:19Z", 
    "summary": "In block-matching motion estimation (BMME), the search patterns have a\nsignificant impact on the algorithm's performance, both the search speed and\nthe search quality. The search pattern should be designed to fit the motion\nvector probability (MVP) distribution characteristics of the real-world\nsequences. In this paper, we build a directional model of MVP distribution to\ndescribe the directional-center-biased characteristic of the MVP distribution\nand the directional characteristics of the conditional MVP distribution more\nexactly based on the detailed statistical data of motion vectors of eighteen\npopular sequences. Three directional search patterns are firstly designed by\nutilizing the directional characteristics and they are the smallest search\npatterns among the popular ones. A new algorithm is proposed using the\nhorizontal cross search pattern as the initial step and the horizontal/vertical\ndiamond search pattern as the subsequent step for the fast BMME, which is\ncalled the directional cross diamond search (DCDS) algorithm. The DCDS\nalgorithm can obtain the motion vector with fewer search points than CDS, DS or\nHEXBS while maintaining the similar or even better search quality. The gain on\nspeedup of DCDS over CDS or DS can be up to 54.9%. The simulation results show\nthat DCDS is efficient, effective and robust, and it can always give the faster\nsearch speed on different sequences than other fast block-matching algorithm in\ncommon use.", 
    "link": "http://arxiv.org/pdf/0806.0689v1", 
    "arxiv-id": "0806.0689v1"
},{
    "category": "cs.CV", 
    "author": "Jean-Jacques Slotine", 
    "title": "Fast Wavelet-Based Visual Classification", 
    "publish": "2008-06-08T10:15:04Z", 
    "summary": "We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification.", 
    "link": "http://arxiv.org/pdf/0806.1446v1", 
    "arxiv-id": "0806.1446v1"
},{
    "category": "cs.CV", 
    "author": "H. Krim", 
    "title": "Classification of curves in 2D and 3D via affine integral signatures", 
    "publish": "2008-06-12T01:12:25Z", 
    "summary": "We propose a robust classification algorithm for curves in 2D and 3D, under\nthe special and full groups of affine transformations. To each plane or spatial\ncurve we assign a plane signature curve. Curves, equivalent under an affine\ntransformation, have the same signature. The signatures introduced in this\npaper are based on integral invariants, which behave much better on noisy\nimages than classically known differential invariants. The comparison with\nother types of invariants is given in the introduction. Though the integral\ninvariants for planar curves were known before, the affine integral invariants\nfor spatial curves are proposed here for the first time. Using the inductive\nvariation of the moving frame method we compute affine invariants in terms of\nEuclidean invariants. We present two types of signatures, the global signature\nand the local signature. Both signatures are independent of parameterization\n(curve sampling). The global signature depends on the choice of the initial\npoint and does not allow us to compare fragments of curves, and is therefore\nsensitive to occlusions. The local signature, although is slightly more\nsensitive to noise, is independent of the choice of the initial point and is\nnot sensitive to occlusions in an image. It helps establish local equivalence\nof curves. The robustness of these invariants and signatures in their\napplication to the problem of classification of noisy spatial curves extracted\nfrom a 3D object is analyzed.", 
    "link": "http://arxiv.org/pdf/0806.1984v1", 
    "arxiv-id": "0806.1984v1"
},{
    "category": "cs.CV", 
    "author": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   1: the framework", 
    "publish": "2008-06-24T13:43:06Z", 
    "summary": "Adams and Bishop have proposed in 1994 a novel region growing algorithm\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\nintroduces a framework to implement an algorithm using SRGPA. This framework is\nbuilt around two concepts: localization and organization of applied action.\nThis conceptualization gives a quick implementation of algorithms, a direct\ntranslation between the mathematical idea and the numerical implementation, and\nan improvement of algorithms efficiency.", 
    "link": "http://arxiv.org/pdf/0806.3885v1", 
    "arxiv-id": "0806.3885v1"
},{
    "category": "cs.CV", 
    "author": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   2: how to localize a final partition invariant about the seeded region   initialisation order", 
    "publish": "2008-06-24T13:34:15Z", 
    "summary": "In the previous paper, we have conceptualized the localization and the\norganization of seeded region growing by pixels aggregation (SRGPA) but we do\nnot give the issue when there is a collision between two distinct regions\nduring the growing process. In this paper, we propose two implementations to\nmanage two classical growing processes: one without a boundary region region to\ndivide the other regions and another with. Unfortunately, as noticed by Mehnert\nand Jakway (1997), this partition depends on the seeded region initialisation\norder (SRIO). We propose a growing process, invariant about SRIO such as the\nboundary region is the set of ambiguous pixels.", 
    "link": "http://arxiv.org/pdf/0806.3887v1", 
    "arxiv-id": "0806.3887v1"
},{
    "category": "cs.CV", 
    "author": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   3: a wide range of algorithms", 
    "publish": "2008-06-24T17:02:47Z", 
    "summary": "In the two previous papers of this serie, we have created a library, called\nPopulation, dedicated to seeded region growing by pixels aggregation and we\nhave proposed different growing processes to get a partition with or without a\nboundary region to divide the other regions or to get a partition invariant\nabout the seeded region initialisation order. Using this work, we implement\nsome algorithms belonging to the field of SRGPA using this library and these\ngrowing processes.", 
    "link": "http://arxiv.org/pdf/0806.3928v1", 
    "arxiv-id": "0806.3928v1"
},{
    "category": "cs.CV", 
    "author": "Vincent Tariel", 
    "title": "Conceptualization of seeded region growing by pixels aggregation. Part   4: Simple, generic and robust extraction of grains in granular materials   obtained by X-ray tomography", 
    "publish": "2008-06-24T17:40:25Z", 
    "summary": "This paper proposes a simple, generic and robust method to extract the grains\nfrom experimental tridimensionnal images of granular materials obtained by\nX-ray tomography. This extraction has two steps: segmentation and splitting.\nFor the segmentation step, if there is a sufficient contrast between the\ndifferent components, a classical threshold procedure followed by a succession\nof morphological filters can be applied. If not, and if the boundary needs to\nbe localized precisely, a watershed transformation controlled by labels is\napplied. The basement of this transformation is to localize a label included in\nthe component and another label in the component complementary. A \"soft\"\nthreshold following by an opening is applied on the initial image to localize a\nlabel in a component. For any segmentation procedure, the visualisation shows a\nproblem: some groups of two grains, close one to each other, become connected.\nSo if a classical cluster procedure is applied on the segmented binary image,\nthese numerical connected grains are considered as a single grain. To overcome\nthis problem, we applied a procedure introduced by L. Vincent in 1993. This\ngrains extraction is tested for various complexes porous media and granular\nmaterial, to predict various properties (diffusion, electrical conductivity,\ndeformation field) in a good agreement with experiment data.", 
    "link": "http://arxiv.org/pdf/0806.3939v2", 
    "arxiv-id": "0806.3939v2"
},{
    "category": "cs.CV", 
    "author": "Nicolas Paparoditis", 
    "title": "The Five Points Pose Problem : A New and Accurate Solution Adapted to   any Geometric Configuration", 
    "publish": "2008-07-13T18:37:06Z", 
    "summary": "The goal of this paper is to estimate directly the rotation and translation\nbetween two stereoscopic images with the help of five homologous points. The\nmethodology presented does not mix the rotation and translation parameters,\nwhich is comparably an important advantage over the methods using the\nwell-known essential matrix. This results in correct behavior and accuracy for\nsituations otherwise known as quite unfavorable, such as planar scenes, or\npanoramic sets of images (with a null base length), while providing quite\ncomparable results for more \"standard\" cases. The resolution of the algebraic\npolynomials resulting from the modeling of the coplanarity constraint is made\nwith the help of powerful algebraic solver tools (the Groebner bases and the\nRational Univariate Representation).", 
    "link": "http://arxiv.org/pdf/0807.2047v3", 
    "arxiv-id": "0807.2047v3"
},{
    "category": "cs.CV", 
    "author": "R. Marazzato", 
    "title": "An image processing analysis of skin textures", 
    "publish": "2008-07-29T16:28:44Z", 
    "summary": "Colour and coarseness of skin are visually different. When image processing\nis involved in the skin analysis, it is important to quantitatively evaluate\nsuch differences using texture features. In this paper, we discuss a texture\nanalysis and measurements based on a statistical approach to the pattern\nrecognition. Grain size and anisotropy are evaluated with proper diagrams. The\npossibility to determine the presence of pattern defects is also discussed.", 
    "link": "http://arxiv.org/pdf/0807.4701v1", 
    "arxiv-id": "0807.4701v1"
},{
    "category": "cs.CV", 
    "author": "C Bhattacharya", 
    "title": "Higher Order Moments Generation by Mellin Transform for Compound Models   of Clutter", 
    "publish": "2008-08-16T01:34:48Z", 
    "summary": "The compound models of clutter statistics are found suitable to describe the\nnonstationary nature of radar backscattering from high-resolution observations.\nIn this letter, we show that the properties of Mellin transform can be utilized\nto generate higher order moments of simple and compound models of clutter\nstatistics in a compact manner.", 
    "link": "http://arxiv.org/pdf/0808.2227v1", 
    "arxiv-id": "0808.2227v1"
},{
    "category": "cs.CV", 
    "author": "C. L. Giles", 
    "title": "Automatic Identification and Data Extraction from 2-Dimensional Plots in   Digital Documents", 
    "publish": "2008-09-10T14:43:37Z", 
    "summary": "Most search engines index the textual content of documents in digital\nlibraries. However, scholarly articles frequently report important findings in\nfigures for visual impact and the contents of these figures are not indexed.\nThese contents are often invaluable to the researcher in various fields, for\nthe purposes of direct comparison with their own work. Therefore, searching for\nfigures and extracting figure data are important problems. To the best of our\nknowledge, there exists no tool to automatically extract data from figures in\ndigital documents. If we can extract data from these images automatically and\nstore them in a database, an end-user can query and combine data from multiple\ndigital documents simultaneously and efficiently. We propose a framework based\non image analysis and machine learning to extract information from 2-D plot\nimages and store them in a database. The proposed algorithm identifies a 2-D\nplot and extracts the axis labels, legend and the data points from the 2-D\nplot. We also segregate overlapping shapes that correspond to different data\npoints. We demonstrate performance of individual algorithms, using a\ncombination of generated and real-life images.", 
    "link": "http://arxiv.org/pdf/0809.1802v1", 
    "arxiv-id": "0809.1802v1"
},{
    "category": "cs.CV", 
    "author": "Andrew Zisserman", 
    "title": "Supervised Dictionary Learning", 
    "publish": "2008-09-18T07:16:34Z", 
    "summary": "It is now well established that sparse signal models are well suited to\nrestoration tasks and can effectively be learned from audio, image, and video\ndata. Recent research has been aimed at learning discriminative sparse models\ninstead of purely reconstructive ones. This paper proposes a new step in that\ndirection, with a novel sparse representation for signals belonging to\ndifferent classes in terms of a shared dictionary and multiple class-decision\nfunctions. The linear variant of the proposed model admits a simple\nprobabilistic interpretation, while its most general variant admits an\ninterpretation in terms of kernels. An optimization framework for learning all\nthe components of the proposed model is presented, along with experimental\nresults on standard handwritten digit and texture classification tasks.", 
    "link": "http://arxiv.org/pdf/0809.3083v1", 
    "arxiv-id": "0809.3083v1"
},{
    "category": "cs.CV", 
    "author": "Clemens G\u00fchmann", 
    "title": "Modeling and Control with Local Linearizing Nadaraya Watson Regression", 
    "publish": "2008-09-22T12:08:24Z", 
    "summary": "Black box models of technical systems are purely descriptive. They do not\nexplain why a system works the way it does. Thus, black box models are\ninsufficient for some problems. But there are numerous applications, for\nexample, in control engineering, for which a black box model is absolutely\nsufficient. In this article, we describe a general stochastic framework with\nwhich such models can be built easily and fully automated by observation.\nFurthermore, we give a practical example and show how this framework can be\nused to model and control a motorcar powertrain.", 
    "link": "http://arxiv.org/pdf/0809.3690v1", 
    "arxiv-id": "0809.3690v1"
},{
    "category": "cs.CV", 
    "author": "Luc Brun", 
    "title": "Hierarchical Bag of Paths for Kernel Based Shape Classification", 
    "publish": "2008-10-20T15:13:18Z", 
    "summary": "Graph kernels methods are based on an implicit embedding of graphs within a\nvector space of large dimension. This implicit embedding allows to apply to\ngraphs methods which where until recently solely reserved to numerical data.\nWithin the shape classification framework, graphs are often produced by a\nskeletonization step which is sensitive to noise. We propose in this paper to\nintegrate the robustness to structural noise by using a kernel based on a bag\nof path where each path is associated to a hierarchy encoding successive\nsimplifications of the path. Several experiments prove the robustness and the\nflexibility of our approach compared to alternative shape classification\nmethods.", 
    "link": "http://arxiv.org/pdf/0810.3579v1", 
    "arxiv-id": "0810.3579v1"
},{
    "category": "cs.CV", 
    "author": "Rohan Loveland", 
    "title": "Camera distortion self-calibration using the plumb-line constraint and   minimal Hough entropy", 
    "publish": "2008-10-24T10:50:59Z", 
    "summary": "In this paper we present a simple and robust method for self-correction of\ncamera distortion using single images of scenes which contain straight lines.\nSince the most common distortion can be modelled as radial distortion, we\nillustrate the method using the Harris radial distortion model, but the method\nis applicable to any distortion model. The method is based on transforming the\nedgels of the distorted image to a 1-D angular Hough space, and optimizing the\ndistortion correction parameters which minimize the entropy of the\ncorresponding normalized histogram. Properly corrected imagery will have fewer\ncurved lines, and therefore less spread in Hough space. Since the method does\nnot rely on any image structure beyond the existence of edgels sharing some\ncommon orientations and does not use edge fitting, it is applicable to a wide\nvariety of image types. For instance, it can be applied equally well to images\nof texture with weak but dominant orientations, or images with strong vanishing\npoints. Finally, the method is performed on both synthetic and real data\nrevealing that it is particularly robust to noise.", 
    "link": "http://arxiv.org/pdf/0810.4426v2", 
    "arxiv-id": "0810.4426v2"
},{
    "category": "cs.CV", 
    "author": "Pascal Frossard", 
    "title": "Graph-based classification of multiple observation sets", 
    "publish": "2008-10-25T16:02:32Z", 
    "summary": "We consider the problem of classification of an object given multiple\nobservations that possibly include different transformations. The possible\ntransformations of the object generally span a low-dimensional manifold in the\noriginal signal space. We propose to take advantage of this manifold structure\nfor the effective classification of the object represented by the observation\nset. In particular, we design a low complexity solution that is able to exploit\nthe properties of the data manifolds with a graph-based algorithm. Hence, we\nformulate the computation of the unknown label matrix as a smoothing process on\nthe manifold under the constraint that all observations represent an object of\none single class. It results into a discrete optimization problem, which can be\nsolved by an efficient and low complexity algorithm. We demonstrate the\nperformance of the proposed graph-based algorithm in the classification of sets\nof multiple images. Moreover, we show its high potential in video-based face\nrecognition, where it outperforms state-of-the-art solutions that fall short of\nexploiting the manifold structure of the face image data sets.", 
    "link": "http://arxiv.org/pdf/0810.4617v2", 
    "arxiv-id": "0810.4617v2"
},{
    "category": "cs.CV", 
    "author": "P. Frossard", 
    "title": "3D Face Recognition with Sparse Spherical Representations", 
    "publish": "2008-10-29T17:43:54Z", 
    "summary": "This paper addresses the problem of 3D face recognition using simultaneous\nsparse approximations on the sphere. The 3D face point clouds are first aligned\nwith a novel and fully automated registration process. They are then\nrepresented as signals on the 2D sphere in order to preserve depth and geometry\ninformation. Next, we implement a dimensionality reduction process with\nsimultaneous sparse approximations and subspace projection. It permits to\nrepresent each 3D face by only a few spherical functions that are able to\ncapture the salient facial characteristics, and hence to preserve the\ndiscriminant facial information. We eventually perform recognition by effective\nmatching in the reduced space, where Linear Discriminant Analysis can be\nfurther activated for improved recognition performance. The 3D face recognition\nalgorithm is evaluated on the FRGC v.1.0 data set, where it is shown to\noutperform classical state-of-the-art solutions that work with depth images.", 
    "link": "http://arxiv.org/pdf/0810.5325v1", 
    "arxiv-id": "0810.5325v1"
},{
    "category": "cs.CV", 
    "author": "R. Marazzato", 
    "title": "Mapping Images with the Coherence Length Diagrams", 
    "publish": "2008-11-28T12:11:21Z", 
    "summary": "Statistical pattern recognition methods based on the Coherence Length Diagram\n(CLD) have been proposed for medical image analyses, such as quantitative\ncharacterisation of human skin textures, and for polarized light microscopy of\nliquid crystal textures. Further investigations are made on image maps\noriginated from such diagram and some examples related to irregularity of\nmicrostructures are shown.", 
    "link": "http://arxiv.org/pdf/0811.4699v2", 
    "arxiv-id": "0811.4699v2"
},{
    "category": "cs.CV", 
    "author": "B. Baykant Alagoz", 
    "title": "Obtaining Depth Maps From Color Images By Region Based Stereo Matching   Algorithms", 
    "publish": "2008-12-07T11:42:41Z", 
    "summary": "In the paper, region based stereo matching algorithms are developed for\nextraction depth information from two color stereo image pair. A filter\neliminating unreliable disparity estimation was used for increasing reliability\nof the disparity map. Obtained results by algorithms were represented and\ncompared.", 
    "link": "http://arxiv.org/pdf/0812.1340v2", 
    "arxiv-id": "0812.1340v2"
},{
    "category": "cs.CV", 
    "author": "Massoud. Babaie-Zadeh", 
    "title": "Sparse Component Analysis (SCA) in Random-valued and Salt and Pepper   Noise Removal", 
    "publish": "2008-12-15T19:24:45Z", 
    "summary": "In this paper, we propose a new method for impulse noise removal from images.\nIt uses the sparsity of images in the Discrete Cosine Transform (DCT) domain.\nThe zeros in this domain give us the exact mathematical equation to reconstruct\nthe pixels that are corrupted by random-value impulse noises. The proposed\nmethod can also detect and correct the corrupted pixels. Moreover, in a simpler\ncase that salt and pepper noise is the brightest and darkest pixels in the\nimage, we propose a simpler version of our method. In addition to the proposed\nmethod, we suggest a combination of the traditional median filter method with\nour method to yield better results when the percentage of the corrupted samples\nis high.", 
    "link": "http://arxiv.org/pdf/0812.2892v1", 
    "arxiv-id": "0812.2892v1"
},{
    "category": "cs.CV", 
    "author": "Seyed Mohammad Ahadi", 
    "title": "Using SLP Neural Network to Persian Handwritten Digits Recognition", 
    "publish": "2009-02-16T21:13:35Z", 
    "summary": "This paper has been withdrawn by the author ali pourmohammad.", 
    "link": "http://arxiv.org/pdf/0902.2788v2", 
    "arxiv-id": "0902.2788v2"
},{
    "category": "cs.CV", 
    "author": "Amelia Sparavigna", 
    "title": "Dipole and Quadrupole Moments in Image Processing", 
    "publish": "2009-02-24T20:34:43Z", 
    "summary": "This paper proposes an algorithm for image processing, obtained by adapting\nto image maps the definitions of two well-known physical quantities. These\nquantities are the dipole and quadrupole moments of a charge distribution. We\nwill see how it is possible to define dipole and quadrupole moments for the\ngray-tone maps and apply them in the development of algorithms for edge\ndetection.", 
    "link": "http://arxiv.org/pdf/0902.4073v1", 
    "arxiv-id": "0902.4073v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Sparavigna", 
    "title": "Dipole Vectors in Images Processing", 
    "publish": "2009-02-26T18:42:30Z", 
    "summary": "Instead of evaluating the gradient field of the brightness map of an image,\nwe propose the use of dipole vectors. This approach is obtained by adapting to\nthe image gray-tone distribution the definition of the dipole moment of charge\ndistributions. We will show how to evaluate the dipoles and obtain a vector\nfield, which can be a good alternative to the gradient field in pattern\nrecognition.", 
    "link": "http://arxiv.org/pdf/0902.4663v1", 
    "arxiv-id": "0902.4663v1"
},{
    "category": "cs.CV", 
    "author": "Ali Pourmohammad", 
    "title": "Recognition of Regular Shapes in Satelite Images", 
    "publish": "2009-03-01T11:10:27Z", 
    "summary": "This paper has been withdrawn by the author ali pourmohammad.", 
    "link": "http://arxiv.org/pdf/0903.0134v2", 
    "arxiv-id": "0903.0134v2"
},{
    "category": "cs.CV", 
    "author": "Adriana Balta", 
    "title": "Real-time Texture Error Detection", 
    "publish": "2009-03-03T14:08:24Z", 
    "summary": "This paper advocates an improved solution for real-time error detection of\ntexture errors that occurs in the production process in textile industry. The\nresearch is focused on the mono-color products with 3D texture model (Jaquard\nfabrics). This is a more difficult task than, for example, 2D multicolor\ntextures.", 
    "link": "http://arxiv.org/pdf/0903.0538v1", 
    "arxiv-id": "0903.0538v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Sparavigna", 
    "title": "Digital Restoration of Ancient Papyri", 
    "publish": "2009-03-30T06:00:15Z", 
    "summary": "Image processing can be used for digital restoration of ancient papyri, that\nis, for a restoration performed on their digital images. The digital\nmanipulation allows reducing the background signals and enhancing the\nreadability of texts. In the case of very old and damaged documents, this is\nfundamental for identification of the patterns of letters. Some examples of\nrestoration, obtained with an image processing which uses edges detection and\nFourier filtering, are shown. One of them concerns 7Q5 fragment of the Dead Sea\nScrolls.", 
    "link": "http://arxiv.org/pdf/0903.5045v1", 
    "arxiv-id": "0903.5045v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Sparavigna", 
    "title": "Color Dipole Moments for Edge Detection", 
    "publish": "2009-04-06T16:25:08Z", 
    "summary": "Dipole and higher moments are physical quantities used to describe a charge\ndistribution. In analogy with electromagnetism, it is possible to define the\ndipole moments for a gray-scale image, according to the single aspect of a\ngray-tone map. In this paper we define the color dipole moments for color\nimages. For color maps in fact, we have three aspects, the three primary\ncolors, to consider. Associating three color charges to each pixel, color\ndipole moments can be easily defined and used for edge detection.", 
    "link": "http://arxiv.org/pdf/0904.0962v1", 
    "arxiv-id": "0904.0962v1"
},{
    "category": "cs.CV", 
    "author": "Xubo Song", 
    "title": "On the closed-form solution of the rotation matrix arising in computer   vision problems", 
    "publish": "2009-04-09T22:15:25Z", 
    "summary": "We show the closed-form solution to the maximization of trace(A'R), where A\nis given and R is unknown rotation matrix. This problem occurs in many computer\nvision tasks involving optimal rotation matrix estimation. The solution has\nbeen continuously reinvented in different fields as part of specific problems.\nWe summarize the historical evolution of the problem and present the general\nproof of the solution. We contribute to the proof by considering the degenerate\ncases of A and discuss the uniqueness of R.", 
    "link": "http://arxiv.org/pdf/0904.1613v1", 
    "arxiv-id": "0904.1613v1"
},{
    "category": "cs.CV", 
    "author": "Xubo Song", 
    "title": "Point-Set Registration: Coherent Point Drift", 
    "publish": "2009-05-15T22:28:00Z", 
    "summary": "Point set registration is a key component in many computer vision tasks. The\ngoal of point set registration is to assign correspondences between two sets of\npoints and to recover the transformation that maps one point set to the other.\nMultiple factors, including an unknown non-rigid spatial transformation, large\ndimensionality of point set, noise and outliers, make the point set\nregistration a challenging problem. We introduce a probabilistic method, called\nthe Coherent Point Drift (CPD) algorithm, for both rigid and non-rigid point\nset registration. We consider the alignment of two point sets as a probability\ndensity estimation problem. We fit the GMM centroids (representing the first\npoint set) to the data (the second point set) by maximizing the likelihood. We\nforce the GMM centroids to move coherently as a group to preserve the\ntopological structure of the point sets. In the rigid case, we impose the\ncoherence constraint by re-parametrization of GMM centroid locations with rigid\nparameters and derive a closed form solution of the maximization step of the EM\nalgorithm in arbitrary dimensions. In the non-rigid case, we impose the\ncoherence constraint by regularizing the displacement field and using the\nvariational calculus to derive the optimal transformation. We also introduce a\nfast algorithm that reduces the method computation complexity to linear. We\ntest the CPD algorithm for both rigid and non-rigid transformations in the\npresence of noise, outliers and missing points, where CPD shows accurate\nresults and outperforms current state-of-the-art methods.", 
    "link": "http://arxiv.org/pdf/0905.2635v1", 
    "arxiv-id": "0905.2635v1"
},{
    "category": "cs.CV", 
    "author": "Alexander Balinsky", 
    "title": "Colorization of Natural Images via L1 Optimization", 
    "publish": "2009-05-18T16:07:52Z", 
    "summary": "Natural images in the colour space YUV have been observed to have a\nnon-Gaussian, heavy tailed distribution (called 'sparse') when the filter\nG(U)(r) = U(r) - sum_{s \\in N(r)} w{(Y)_{rs}} U(s), is applied to the\nchromacity channel U (and equivalently to V), where w is a weighting function\nconstructed from the intensity component Y [1]. In this paper we develop\nBayesian analysis of the colorization problem using the filter response as a\nregularization term to arrive at a non-convex optimization problem. This\nproblem is convexified using L1 optimization which often gives the same results\nfor sparse signals [2]. It is observed that L1 optimization, in many cases,\nover-performs the famous colorization algorithm by Levin et al [3].", 
    "link": "http://arxiv.org/pdf/0905.2924v1", 
    "arxiv-id": "0905.2924v1"
},{
    "category": "cs.CV", 
    "author": "J. H. Oaknin", 
    "title": "A statistical learning approach to color demosaicing", 
    "publish": "2009-05-18T19:44:58Z", 
    "summary": "A statistical learning/inference framework for color demosaicing is\npresented. We start with simplistic assumptions about color constancy, and\nrecast color demosaicing as a blind linear inverse problem: color parameterizes\nthe unknown kernel, while brightness takes on the role of a latent variable. An\nexpectation-maximization algorithm naturally suggests itself for the estimation\nof them both. Then, as we gradually broaden the family of hypothesis where\ncolor is learned, we let our demosaicing behave adaptively, in a manner that\nreflects our prior knowledge about the statistics of color images. We show that\nwe can incorporate realistic, learned priors without essentially changing the\ncomplexity of the simple expectation-maximization algorithm we started with.", 
    "link": "http://arxiv.org/pdf/0905.2958v3", 
    "arxiv-id": "0905.2958v3"
},{
    "category": "cs.CV", 
    "author": "JeanPierre Guedon", 
    "title": "A New Solution to the Relative Orientation Problem using only 3 Points   and the Vertical Direction", 
    "publish": "2009-05-25T08:29:01Z", 
    "summary": "This paper presents a new method to recover the relative pose between two\nimages, using three points and the vertical direction information. The vertical\ndirection can be determined in two ways: 1- using direct physical measurement\nlike IMU (inertial measurement unit), 2- using vertical vanishing point. This\nknowledge of the vertical direction solves 2 unknowns among the 3 parameters of\nthe relative rotation, so that only 3 homologous points are requested to\nposition a couple of images. Rewriting the coplanarity equations leads to a\nsimpler solution. The remaining unknowns resolution is performed by an\nalgebraic method using Grobner bases. The elements necessary to build a\nspecific algebraic solver are given in this paper, allowing for a real-time\nimplementation. The results on real and synthetic data show the efficiency of\nthis method.", 
    "link": "http://arxiv.org/pdf/0905.3964v1", 
    "arxiv-id": "0905.3964v1"
},{
    "category": "cs.CV", 
    "author": "Wassim M. Haddad", 
    "title": "Segmentation of Facial Expressions Using Semi-Definite Programming and   Generalized Principal Component Analysis", 
    "publish": "2009-06-09T19:50:10Z", 
    "summary": "In this paper, we use semi-definite programming and generalized principal\ncomponent analysis (GPCA) to distinguish between two or more different facial\nexpressions. In the first step, semi-definite programming is used to reduce the\ndimension of the image data and \"unfold\" the manifold which the data points\n(corresponding to facial expressions) reside on. Next, GPCA is used to fit a\nseries of subspaces to the data points and associate each data point with a\nsubspace. Data points that belong to the same subspace are claimed to belong to\nthe same facial expression category. An example is provided.", 
    "link": "http://arxiv.org/pdf/0906.1763v2", 
    "arxiv-id": "0906.1763v2"
},{
    "category": "cs.CV", 
    "author": "Jacques-Olivier Lachaud", 
    "title": "Combinatorial pyramids and discrete geometry for energy-minimizing   segmentation", 
    "publish": "2009-06-15T19:33:21Z", 
    "summary": "This paper defines the basis of a new hierarchical framework for segmentation\nalgorithms based on energy minimization schemes. This new framework is based on\ntwo formal tools. First, a combinatorial pyramid encode efficiently a hierarchy\nof partitions. Secondly, discrete geometric estimators measure precisely some\nimportant geometric parameters of the regions. These measures combined with\nphotometrical and topological features of the partition allows to design energy\nterms based on discrete measures. Our segmentation framework exploits these\nenergies to build a pyramid of image partitions with a minimization scheme.\nSome experiments illustrating our framework are shown and discussed.", 
    "link": "http://arxiv.org/pdf/0906.2770v1", 
    "arxiv-id": "0906.2770v1"
},{
    "category": "cs.CV", 
    "author": "Benjamin Taton", 
    "title": "Deformable Model with a Complexity Independent from Image Resolution", 
    "publish": "2009-06-17T04:42:39Z", 
    "summary": "We present a parametric deformable model which recovers image components with\na complexity independent from the resolution of input images. The proposed\nmodel also automatically changes its topology and remains fully compatible with\nthe general framework of deformable models. More precisely, the image space is\nequipped with a metric that expands salient image details according to their\nstrength and their curvature. During the whole evolution of the model, the\nsampling of the contour is kept regular with respect to this metric. By this\nway, the vertex density is reduced along most parts of the curve while a high\nquality of shape representation is preserved. The complexity of the deformable\nmodel is thus improved and is no longer influenced by feature-preserving\nchanges in the resolution of input images. Building the metric requires a prior\nestimation of contour curvature. It is obtained using a robust estimator which\ninvestigates the local variations in the orientation of image gradient.\nExperimental results on both computer generated and biomedical images are\npresented to illustrate the advantages of our approach.", 
    "link": "http://arxiv.org/pdf/0906.3068v1", 
    "arxiv-id": "0906.3068v1"
},{
    "category": "cs.CV", 
    "author": "Xubo Song", 
    "title": "Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid   Image Registration", 
    "publish": "2009-06-17T23:24:38Z", 
    "summary": "We introduce an adaptive regularization approach. In contrast to conventional\nTikhonov regularization, which specifies a fixed regularization operator, we\nestimate it simultaneously with parameters. From a Bayesian perspective we\nestimate the prior distribution on parameters assuming that it is close to some\ngiven model distribution. We constrain the prior distribution to be a\nGauss-Markov random field (GMRF), which allows us to solve for the prior\ndistribution analytically and provides a fast optimization algorithm. We apply\nour approach to non-rigid image registration to estimate the spatial\ntransformation between two images. Our evaluation shows that the adaptive\nregularization approach significantly outperforms standard variational methods.", 
    "link": "http://arxiv.org/pdf/0906.3323v1", 
    "arxiv-id": "0906.3323v1"
},{
    "category": "cs.CV", 
    "author": "Md. Mobarak Hossain", 
    "title": "Automatic Defect Detection and Classification Technique from Image: A   Special Case Using Ceramic Tiles", 
    "publish": "2009-06-20T03:00:37Z", 
    "summary": "Quality control is an important issue in the ceramic tile industry. On the\nother hand maintaining the rate of production with respect to time is also a\nmajor issue in ceramic tile manufacturing. Again, price of ceramic tiles also\ndepends on purity of texture, accuracy of color, shape etc. Considering this\ncriteria, an automated defect detection and classification technique has been\nproposed in this report that can have ensured the better quality of tiles in\nmanufacturing process as well as production rate. Our proposed method plays an\nimportant role in ceramic tiles industries to detect the defects and to control\nthe quality of ceramic tiles. This automated classification method helps us to\nacquire knowledge about the pattern of defect within a very short period of\ntime and also to decide about the recovery process so that the defected tiles\nmay not be mixed with the fresh tiles.", 
    "link": "http://arxiv.org/pdf/0906.3770v1", 
    "arxiv-id": "0906.3770v1"
},{
    "category": "cs.CV", 
    "author": "Rafeef Abugharbieh", 
    "title": "Automatic Spatially-Adaptive Balancing of Energy Terms for Image   Segmentation", 
    "publish": "2009-06-22T21:10:46Z", 
    "summary": "Image segmentation techniques are predominately based on parameter-laden\noptimization. The objective function typically involves weights for balancing\ncompeting image fidelity and segmentation regularization cost terms. Setting\nthese weights suitably has been a painstaking, empirical process. Even if such\nideal weights are found for a novel image, most current approaches fix the\nweight across the whole image domain, ignoring the spatially-varying properties\nof object shape and image appearance. We propose a novel technique that\nautonomously balances these terms in a spatially-adaptive manner through the\nincorporation of image reliability in a graph-based segmentation framework. We\nvalidate on synthetic data achieving a reduction in mean error of 47% (p-value\n<< 0.05) when compared to the best fixed parameter segmentation. We also\npresent results on medical images (including segmentations of the corpus\ncallosum and brain tissue in MRI data) and on natural images.", 
    "link": "http://arxiv.org/pdf/0906.4131v2", 
    "arxiv-id": "0906.4131v2"
},{
    "category": "cs.CV", 
    "author": "Hamid Reza Pourreza", 
    "title": "Efficient IRIS Recognition through Improvement of Feature Extraction and   subset Selection", 
    "publish": "2009-06-25T20:14:42Z", 
    "summary": "The selection of the optimal feature subset and the classification has become\nan important issue in the field of iris recognition. In this paper we propose\nseveral methods for iris feature subset selection and vector creation. The\ndeterministic feature sequence is extracted from the iris image by using the\ncontourlet transform technique. Contourlet transform captures the intrinsic\ngeometrical structures of iris image. It decomposes the iris image into a set\nof directional sub-bands with texture details captured in different\norientations at various scales so for reducing the feature vector dimensions we\nuse the method for extract only significant bit and information from normalized\niris images. In this method we ignore fragile bits. And finally we use SVM\n(Support Vector Machine) classifier for approximating the amount of people\nidentification in our proposed system. Experimental result show that most\nproposed method reduces processing time and increase the classification\naccuracy and also the iris feature vector length is much smaller versus the\nother methods.", 
    "link": "http://arxiv.org/pdf/0906.4789v1", 
    "arxiv-id": "0906.4789v1"
},{
    "category": "cs.CV", 
    "author": "Abdelmajid Ben Hamadou", 
    "title": "A new approach for digit recognition based on hand gesture analysis", 
    "publish": "2009-06-27T04:46:23Z", 
    "summary": "We present in this paper a new approach for hand gesture analysis that allows\ndigit recognition. The analysis is based on extracting a set of features from a\nhand image and then combining them by using an induction graph. The most\nimportant features we extract from each image are the fingers locations, their\nheights and the distance between each pair of fingers. Our approach consists of\nthree steps: (i) Hand detection and localization, (ii) fingers extraction and\n(iii) features identification and combination to digit recognition. Each input\nimage is assumed to contain only one person, thus we apply a fuzzy classifier\nto identify the skin pixels. In the finger extraction step, we attempt to\nremove all the hand components except the fingers, this process is based on the\nhand anatomy properties. The final step consists on representing histogram of\nthe detected fingers in order to extract features that will be used for digit\nrecognition. The approach is invariant to scale, rotation and translation of\nthe hand. Some experiments have been undertaken to show the effectiveness of\nthe proposed approach.", 
    "link": "http://arxiv.org/pdf/0906.5039v1", 
    "arxiv-id": "0906.5039v1"
},{
    "category": "cs.CV", 
    "author": "Ghassan Hamarneh", 
    "title": "Multi-Label MRF Optimization via Least Squares s-t Cuts", 
    "publish": "2009-07-01T17:18:46Z", 
    "summary": "There are many applications of graph cuts in computer vision, e.g.\nsegmentation. We present a novel method to reformulate the NP-hard, k-way graph\npartitioning problem as an approximate minimal s-t graph cut problem, for which\na globally optimal solution is found in polynomial time. Each non-terminal\nvertex in the original graph is replaced by a set of ceil(log_2(k)) new\nvertices. The original graph edges are replaced by new edges connecting the new\nvertices to each other and to only two, source s and sink t, terminal nodes.\nThe weights of the new edges are obtained using a novel least squares solution\napproximating the constraints of the initial k-way setup. The minimal s-t cut\nlabels each new vertex with a binary (s vs t) \"Gray\" encoding, which is then\ndecoded into a decimal label number that assigns each of the original vertices\nto one of k classes. We analyze the properties of the approximation and present\nquantitative as well as qualitative segmentation results.", 
    "link": "http://arxiv.org/pdf/0907.0204v1", 
    "arxiv-id": "0907.0204v1"
},{
    "category": "cs.CV", 
    "author": "Simant Dube", 
    "title": "An Iterative Fingerprint Enhancement Algorithm Based on Accurate   Determination of Orientation Flow", 
    "publish": "2009-07-02T04:57:32Z", 
    "summary": "We describe an algorithm to enhance and binarize a fingerprint image. The\nalgorithm is based on accurate determination of orientation flow of the ridges\nof the fingerprint image by computing variance of the neighborhood pixels\naround a pixel in different directions. We show that an iterative algorithm\nwhich captures the mutual interdependence of orientation flow computation,\nenhancement and binarization gives very good results on poor quality images.", 
    "link": "http://arxiv.org/pdf/0907.0288v1", 
    "arxiv-id": "0907.0288v1"
},{
    "category": "cs.CV", 
    "author": "Erik Learned-Miller", 
    "title": "Bounding the Probability of Error for High Precision Recognition", 
    "publish": "2009-07-02T16:09:47Z", 
    "summary": "We consider models for which it is important, early in processing, to\nestimate some variables with high precision, but perhaps at relatively low\nrates of recall. If some variables can be identified with near certainty, then\nthey can be conditioned upon, allowing further inference to be done\nefficiently. Specifically, we consider optical character recognition (OCR)\nsystems that can be bootstrapped by identifying a subset of correctly\ntranslated document words with very high precision. This \"clean set\" is\nsubsequently used as document-specific training data. While many current OCR\nsystems produce measures of confidence for the identity of each letter or word,\nthresholding these confidence values, even at very high values, still produces\nsome errors.\n  We introduce a novel technique for identifying a set of correct words with\nvery high precision. Rather than estimating posterior probabilities, we bound\nthe probability that any given word is incorrect under very general\nassumptions, using an approximate worst case analysis. As a result, the\nparameters of the model are nearly irrelevant, and we are able to identify a\nsubset of words, even in noisy documents, of which we are highly confident. On\nour set of 10 documents, we are able to identify about 6% of the words on\naverage without making a single error. This ability to produce word lists with\nvery high precision allows us to use a family of models which depends upon such\nclean word lists.", 
    "link": "http://arxiv.org/pdf/0907.0418v1", 
    "arxiv-id": "0907.0418v1"
},{
    "category": "cs.CV", 
    "author": "Ramesh Raskar", 
    "title": "Augmenting Light Field to model Wave Optics effects", 
    "publish": "2009-07-09T13:43:12Z", 
    "summary": "The ray-based 4D light field representation cannot be directly used to\nanalyze diffractive or phase--sensitive optical elements. In this paper, we\nexploit tools from wave optics and extend the light field representation via a\nnovel \"light field transform\". We introduce a key modification to the\nray--based model to support the transform. We insert a \"virtual light source\",\nwith potentially negative valued radiance for certain emitted rays. We create a\nlook-up table of light field transformers of canonical optical elements. The\ntwo key conclusions are that (i) in free space, the 4D light field completely\nrepresents wavefront propagation via rays with real (positive as well as\nnegative) valued radiance and (ii) at occluders, a light field composed of\nlight field transformers plus insertion of (ray--based) virtual light sources\nrepresents resultant phase and amplitude of wavefronts. For free--space\npropagation, we analyze different wavefronts and coherence possibilities. For\noccluders, we show that the light field transform is simply based on a\nconvolution followed by a multiplication operation. This formulation brings\npowerful concepts from wave optics to computer vision and graphics. We show\napplications in cubic-phase plate imaging and holographic displays.", 
    "link": "http://arxiv.org/pdf/0907.1545v1", 
    "arxiv-id": "0907.1545v1"
},{
    "category": "cs.CV", 
    "author": "Li Bai", 
    "title": "Multiresolution Elastic Medical Image Registration in Standard Intensity   Scale", 
    "publish": "2009-07-12T22:39:34Z", 
    "summary": "Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images.", 
    "link": "http://arxiv.org/pdf/0907.2075v1", 
    "arxiv-id": "0907.2075v1"
},{
    "category": "cs.CV", 
    "author": "Li Bai", 
    "title": "Registration of Standardized Histological Images in Feature Space", 
    "publish": "2009-07-18T11:28:41Z", 
    "summary": "In this paper, we propose three novel and important methods for the\nregistration of histological images for 3D reconstruction. First, possible\nintensity variations and nonstandardness in images are corrected by an\nintensity standardization process which maps the image scale into a standard\nscale where the similar intensities correspond to similar tissues meaning.\nSecond, 2D histological images are mapped into a feature space where continuous\nvariables are used as high confidence image features for accurate registration.\nThird, we propose an automatic best reference slice selection algorithm that\nimproves reconstruction quality based on both image entropy and mean square\nerror of the registration process. We demonstrate that the choice of reference\nslice has a significant impact on registration error, standardization, feature\nspace and entropy information. After 2D histological slices are registered\nthrough an affine transformation with respect to an automatically chosen\nreference, the 3D volume is reconstructed by co-registering 2D slices\nelastically.", 
    "link": "http://arxiv.org/pdf/0907.3209v1", 
    "arxiv-id": "0907.3209v1"
},{
    "category": "cs.CV", 
    "author": "Li Bai", 
    "title": "Fully Automatic 3D Reconstruction of Histological Images", 
    "publish": "2009-07-18T12:32:27Z", 
    "summary": "In this paper, we propose a computational framework for 3D volume\nreconstruction from 2D histological slices using registration algorithms in\nfeature space. To improve the quality of reconstructed 3D volume, first,\nintensity variations in images are corrected by an intensity standardization\nprocess which maps image intensity scale to a standard scale where similar\nintensities correspond to similar tissues. Second, a subvolume approach is\nproposed for 3D reconstruction by dividing standardized slices into groups.\nThird, in order to improve the quality of the reconstruction process, an\nautomatic best reference slice selection algorithm is developed based on an\niterative assessment of image entropy and mean square error of the registration\nprocess. Finally, we demonstrate that the choice of the reference slice has a\nsignificant impact on registration quality and subsequent 3D reconstruction.", 
    "link": "http://arxiv.org/pdf/0907.3215v1", 
    "arxiv-id": "0907.3215v1"
},{
    "category": "cs.CV", 
    "author": "Li Bai", 
    "title": "Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face   Recognition", 
    "publish": "2009-07-18T13:03:19Z", 
    "summary": "In this paper, the problem of automatic Gabor wavelet selection for face\nrecognition is tackled by introducing an automatic algorithm based on Parallel\nAdaBoosting method. Incorporating mutual information into the algorithm leads\nto the selection procedure not only based on classification accuracy but also\non efficiency. Effective image features are selected by using properly chosen\nGabor wavelets optimised with Parallel AdaBoost method and mutual information\nto get high recognition rates with low computational cost. Experiments are\nconducted using the well-known FERET face database. In proposed framework,\nmemory and computation costs are reduced significantly and high classification\naccuracy is obtained.", 
    "link": "http://arxiv.org/pdf/0907.3218v1", 
    "arxiv-id": "0907.3218v1"
},{
    "category": "cs.CV", 
    "author": "David Helmbold", 
    "title": "Learning Object Location Predictors with Boosting and Grammar-Guided   Feature Extraction", 
    "publish": "2009-07-24T18:01:08Z", 
    "summary": "We present BEAMER: a new spatially exploitative approach to learning object\ndetectors which shows excellent results when applied to the task of detecting\nobjects in greyscale aerial imagery in the presence of ambiguous and noisy\ndata. There are four main contributions used to produce these results. First,\nwe introduce a grammar-guided feature extraction system, enabling the\nexploration of a richer feature space while constraining the features to a\nuseful subset. This is specified with a rule-based generative grammar crafted\nby a human expert. Second, we learn a classifier on this data using a newly\nproposed variant of AdaBoost which takes into account the spatially correlated\nnature of the data. Third, we perform another round of training to optimize the\nmethod of converting the pixel classifications generated by boosting into a\nhigh quality set of (x, y) locations. Lastly, we carefully define three common\nproblems in object detection and define two evaluation criteria that are\ntightly matched to these problems. Major strengths of this approach are: (1) a\nway of randomly searching a broad feature space, (2) its performance when\nevaluated on well-matched evaluation criteria, and (3) its use of the location\nprediction domain to learn object detectors as well as to generate detections\nthat perform well on several tasks: object counting, tracking, and target\ndetection. We demonstrate the efficacy of BEAMER with a comprehensive\nexperimental evaluation on a challenging data set.", 
    "link": "http://arxiv.org/pdf/0907.4354v1", 
    "arxiv-id": "0907.4354v1"
},{
    "category": "cs.CV", 
    "author": "Sana Khanfir", 
    "title": "Automatic local Gabor Features extraction for face recognition", 
    "publish": "2009-07-28T20:02:15Z", 
    "summary": "We present in this paper a biometric system of face detection and recognition\nin color images. The face detection technique is based on skin color\ninformation and fuzzy classification. A new algorithm is proposed in order to\ndetect automatically face features (eyes, mouth and nose) and extract their\ncorrespondent geometrical points. These fiducial points are described by sets\nof wavelet components which are used for recognition. To achieve the face\nrecognition, we use neural networks and we study its performances for different\ninputs. We compare the two types of features used for recognition: geometric\ndistances and Gabor coefficients which can be used either independently or\njointly. This comparison shows that Gabor coefficients are more powerful than\ngeometric distances. We show with experimental results how the importance\nrecognition ratio makes our system an effective tool for automatic face\ndetection and recognition.", 
    "link": "http://arxiv.org/pdf/0907.4984v1", 
    "arxiv-id": "0907.4984v1"
},{
    "category": "cs.CV", 
    "author": "Tomoya Sakai", 
    "title": "Multiple pattern classification by sparse subspace decomposition", 
    "publish": "2009-07-30T12:23:25Z", 
    "summary": "A robust classification method is developed on the basis of sparse subspace\ndecomposition. This method tries to decompose a mixture of subspaces of\nunlabeled data (queries) into class subspaces as few as possible. Each query is\nclassified into the class whose subspace significantly contributes to the\ndecomposed subspace. Multiple queries from different classes can be\nsimultaneously classified into their respective classes. A practical greedy\nalgorithm of the sparse subspace decomposition is designed for the\nclassification. The present method achieves high recognition rate and robust\nperformance exploiting joint sparsity.", 
    "link": "http://arxiv.org/pdf/0907.5321v2", 
    "arxiv-id": "0907.5321v2"
},{
    "category": "cs.CV", 
    "author": "Pengfei Zhang", 
    "title": "Segmentation for radar images based on active contour", 
    "publish": "2009-08-10T18:33:51Z", 
    "summary": "We exam various geometric active contour methods for radar image\nsegmentation. Due to special properties of radar images, we propose our new\nmodel based on modified Chan-Vese functional. Our method is efficient in\nseparating non-meteorological noises from meteorological images.", 
    "link": "http://arxiv.org/pdf/0908.1369v1", 
    "arxiv-id": "0908.1369v1"
},{
    "category": "cs.CV", 
    "author": "Patrick Erik Bradley", 
    "title": "A dyadic solution of relative pose problems", 
    "publish": "2009-08-13T15:41:44Z", 
    "summary": "A hierarchical interval subdivision is shown to lead to a $p$-adic encoding\nof image data. This allows in the case of the relative pose problem in computer\nvision and photogrammetry to derive equations having 2-adic numbers as\ncoefficients, and to use Hensel's lifting method to their solution. This method\nis applied to the linear and non-linear equations coming from eight, seven or\nfive point correspondences. An inherent property of the method is its\nrobustness.", 
    "link": "http://arxiv.org/pdf/0908.1919v3", 
    "arxiv-id": "0908.1919v3"
},{
    "category": "cs.CV", 
    "author": "Mohammad Farajpoor Ahangar", 
    "title": "Handwritten Farsi Character Recognition using Artificial Neural Network", 
    "publish": "2009-08-30T11:55:48Z", 
    "summary": "Neural Networks are being used for character recognition from last many years\nbut most of the work was confined to English character recognition. Till date,\na very little work has been reported for Handwritten Farsi Character\nrecognition. In this paper, we have made an attempt to recognize handwritten\nFarsi characters by using a multilayer perceptron with one hidden layer. The\nerror backpropagation algorithm has been used to train the MLP network. In\naddition, an analysis has been carried out to determine the number of hidden\nnodes to achieve high performance of backpropagation network in the recognition\nof handwritten Farsi characters. The system has been trained using several\ndifferent forms of handwriting provided by both male and female participants of\ndifferent age groups. Finally, this rigorous training results an automatic HCR\nsystem using MLP network. In this work, the experiments were carried out on two\nhundred fifty samples of five writers. The results showed that the MLP networks\ntrained by the error backpropagation algorithm are superior in recognition\naccuracy and memory usage. The result indicates that the backpropagation\nnetwork provides good recognition accuracy of more than 80% of handwritten\nFarsi characters.", 
    "link": "http://arxiv.org/pdf/0908.4386v1", 
    "arxiv-id": "0908.4386v1"
},{
    "category": "cs.CV", 
    "author": "Jean-Luc Starck", 
    "title": "Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models   in Image Segmentation", 
    "publish": "2009-09-02T17:46:08Z", 
    "summary": "By a \"covering\" we mean a Gaussian mixture model fit to observed data.\nApproximations of the Bayes factor can be availed of to judge model fit to the\ndata within a given Gaussian mixture model. Between families of Gaussian\nmixture models, we propose the R\\'enyi quadratic entropy as an excellent and\ntractable model comparison framework. We exemplify this using the segmentation\nof an MRI image volume, based (1) on a direct Gaussian mixture model applied to\nthe marginal distribution function, and (2) Gaussian model fit through k-means\napplied to the 4D multivalued image volume furnished by the wavelet transform.\nVisual preference for one model over another is not immediate. The R\\'enyi\nquadratic entropy allows us to show clearly that one of these modelings is\nsuperior to the other.", 
    "link": "http://arxiv.org/pdf/0909.0481v1", 
    "arxiv-id": "0909.0481v1"
},{
    "category": "cs.CV", 
    "author": "G. Lerman", 
    "title": "Kernel Spectral Curvature Clustering (KSCC)", 
    "publish": "2009-09-09T01:58:23Z", 
    "summary": "Multi-manifold modeling is increasingly used in segmentation and data\nrepresentation tasks in computer vision and related fields. While the general\nproblem, modeling data by mixtures of manifolds, is very challenging, several\napproaches exist for modeling data by mixtures of affine subspaces (which is\noften referred to as hybrid linear modeling). We translate some important\ninstances of multi-manifold modeling to hybrid linear modeling in embedded\nspaces, without explicitly performing the embedding but applying the kernel\ntrick. The resulting algorithm, Kernel Spectral Curvature Clustering, uses\nkernels at two levels - both as an implicit embedding method to linearize\nnonflat manifolds and as a principled method to convert a multiway affinity\nproblem into a spectral clustering one. We demonstrate the effectiveness of the\nmethod by comparing it with other state-of-the-art methods on both synthetic\ndata and a real-world problem of segmenting multiple motions from two\nperspective camera views.", 
    "link": "http://arxiv.org/pdf/0909.1605v1", 
    "arxiv-id": "0909.1605v1"
},{
    "category": "cs.CV", 
    "author": "G. Lerman", 
    "title": "Motion Segmentation by SCC on the Hopkins 155 Database", 
    "publish": "2009-09-09T02:12:22Z", 
    "summary": "We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark\ndatabase of 155 motion sequences, and show that it outperforms all other\nstate-of-the-art methods. The average misclassification rate by SCC is 1.41%\nfor sequences having two motions and 4.85% for three motions.", 
    "link": "http://arxiv.org/pdf/0909.1608v1", 
    "arxiv-id": "0909.1608v1"
},{
    "category": "cs.CV", 
    "author": "Tien Der Yeh", 
    "title": "A Method for Extraction and Recognition of Isolated License Plate   Characters", 
    "publish": "2009-09-22T05:38:32Z", 
    "summary": "A method to extract and recognize isolated characters in license plates is\nproposed. In extraction stage, the proposed method detects isolated characters\nby using Difference-of-Gaussian (DOG) function, The DOG function, similar to\nLaplacian of Gaussian function, was proven to produce the most stable image\nfeatures compared to a range of other possible image functions. The candidate\ncharacters are extracted by doing connected component analysis on different\nscale DOG images. In recognition stage, a novel feature vector named\naccumulated gradient projection vector (AGPV) is used to compare the candidate\ncharacter with the standard ones. The AGPV is calculated by first projecting\npixels of similar gradient orientations onto specific axes, and then\naccumulates the projected gradient magnitudes by each axis. In the experiments,\nthe AGPVs are proven to be invariant from image scaling and rotation, and\nrobust to noise and illumination change.", 
    "link": "http://arxiv.org/pdf/0909.3911v1", 
    "arxiv-id": "0909.3911v1"
},{
    "category": "cs.CV", 
    "author": "Magdy Salama", 
    "title": "Information tracking approach to segmentation of ultrasound imagery of   prostate", 
    "publish": "2009-09-29T22:39:19Z", 
    "summary": "The size and geometry of the prostate are known to be pivotal quantities used\nby clinicians to assess the condition of the gland during prostate cancer\nscreening. As an alternative to palpation, an increasing number of methods for\nestimation of the above-mentioned quantities are based on using imagery data of\nprostate. The necessity to process large volumes of such data creates a need\nfor automatic segmentation tools which would allow the estimation to be carried\nout with maximum accuracy and efficiency. In particular, the use of transrectal\nultrasound (TRUS) imaging in prostate cancer screening seems to be becoming a\nstandard clinical practice due to the high benefit-to-cost ratio of this\nimaging modality. Unfortunately, the segmentation of TRUS images is still\nhampered by relatively low contrast and reduced SNR of the images, thereby\nrequiring the segmentation algorithms to incorporate prior knowledge about the\ngeometry of the gland. In this paper, a novel approach to the problem of\nsegmenting the TRUS images is described. The proposed approach is based on the\nconcept of distribution tracking, which provides a unified framework for\nmodeling and fusing image-related and morphological features of the prostate.\nMoreover, the same framework allows the segmentation to be regularized via\nusing a new type of \"weak\" shape priors, which minimally bias the estimation\nprocedure, while rendering the latter stable and robust.", 
    "link": "http://arxiv.org/pdf/0909.5458v1", 
    "arxiv-id": "0909.5458v1"
},{
    "category": "cs.CV", 
    "author": "O. Michailovich", 
    "title": "Iterative Shrinkage Approach to Restoration of Optical Imagery", 
    "publish": "2009-09-29T22:33:10Z", 
    "summary": "The problem of reconstruction of digital images from their degraded\nmeasurements is regarded as a problem of central importance in various fields\nof engineering and imaging sciences. In such cases, the degradation is\ntypically caused by the resolution limitations of an imaging device in use\nand/or by the destructive influence of measurement noise. Specifically, when\nthe noise obeys a Poisson probability law, standard approaches to the problem\nof image reconstruction are based on using fixed-point algorithms which follow\nthe methodology first proposed by Richardson and Lucy. The practice of using\nthese methods, however, shows that their convergence properties tend to\ndeteriorate at relatively high noise levels. Accordingly, in the present paper,\na novel method for de-noising and/or de-blurring of digital images corrupted by\nPoisson noise is introduced. The proposed method is derived under the\nassumption that the image of interest can be sparsely represented in the domain\nof a linear transform. Consequently, a shrinkage-based iterative procedure is\nproposed, which guarantees the solution to converge to the global maximizer of\nan associated maximum-a-posteriori criterion. It is shown in a series of both\ncomputer-simulated and real-life experiments that the proposed method\noutperforms a number of existing alternatives in terms of stability, precision,\nand computational efficiency.", 
    "link": "http://arxiv.org/pdf/0909.5460v2", 
    "arxiv-id": "0909.5460v2"
},{
    "category": "cs.CV", 
    "author": "Lowik Chanussot", 
    "title": "Modular Traffic Sign Recognition applied to on-vehicle real-time visual   detection of American and European speed limit signs", 
    "publish": "2009-10-07T15:43:01Z", 
    "summary": "We present a new modular traffic signs recognition system, successfully\napplied to both American and European speed limit signs. Our sign detection\nstep is based only on shape-detection (rectangles or circles). This enables it\nto work on grayscale images, contrary to most European competitors, which eases\nrobustness to illumination conditions (notably night operation). Speed sign\ncandidates are classified (or rejected) by segmenting potential digits inside\nthem (which is rather original and has several advantages), and then applying a\nneural digit recognition. The global detection rate is ~90% for both (standard)\nU.S. and E.U. speed signs, with a misclassification rate <1%, and no validated\nfalse alarm in >150 minutes of video. The system processes in real-time ~20\nframes/s on a standard high-end laptop.", 
    "link": "http://arxiv.org/pdf/0910.1295v1", 
    "arxiv-id": "0910.1295v1"
},{
    "category": "cs.CV", 
    "author": "Pascal Fallavollita", 
    "title": "3D/2D Registration of Mapping Catheter Images for Arrhythmia   Interventional Assistance", 
    "publish": "2009-10-09T20:07:11Z", 
    "summary": "Radiofrequency (RF) catheter ablation has transformed treatment for\ntachyarrhythmias and has become first-line therapy for some tachycardias. The\nprecise localization of the arrhythmogenic site and the positioning of the RF\ncatheter over that site are problematic: they can impair the efficiency of the\nprocedure and are time consuming (several hours). Electroanatomic mapping\ntechnologies are available that enable the display of the cardiac chambers and\nthe relative position of ablation lesions. However, these are expensive and use\ncustom-made catheters. The proposed methodology makes use of standard catheters\nand inexpensive technology in order to create a 3D volume of the heart chamber\naffected by the arrhythmia. Further, we propose a novel method that uses a\npriori 3D information of the mapping catheter in order to estimate the 3D\nlocations of multiple electrodes across single view C-arm images. The monoplane\nalgorithm is tested for feasibility on computer simulations and initial canine\ndata.", 
    "link": "http://arxiv.org/pdf/0910.1844v1", 
    "arxiv-id": "0910.1844v1"
},{
    "category": "cs.CV", 
    "author": "Manish Maheshwari", 
    "title": "Color Image Clustering using Block Truncation Algorithm", 
    "publish": "2009-10-09T20:21:23Z", 
    "summary": "With the advancement in image capturing device, the image data been generated\nat high volume. If images are analyzed properly, they can reveal useful\ninformation to the human users. Content based image retrieval address the\nproblem of retrieving images relevant to the user needs from image databases on\nthe basis of low-level visual features that can be derived from the images.\nGrouping images into meaningful categories to reveal useful information is a\nchallenging and important problem. Clustering is a data mining technique to\ngroup a set of unsupervised data based on the conceptual clustering principal:\nmaximizing the intraclass similarity and minimizing the interclass similarity.\nProposed framework focuses on color as feature. Color Moment and Block\nTruncation Coding (BTC) are used to extract features for image dataset.\nExperimental study using K-Means clustering algorithm is conducted to group the\nimage dataset into various clusters.", 
    "link": "http://arxiv.org/pdf/0910.1849v1", 
    "arxiv-id": "0910.1849v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "Fractional differentiation based image processing", 
    "publish": "2009-10-13T12:37:32Z", 
    "summary": "There are many resources useful for processing images, most of them freely\navailable and quite friendly to use. In spite of this abundance of tools, a\nstudy of the processing methods is still worthy of efforts. Here, we want to\ndiscuss the possibilities arising from the use of fractional differential\ncalculus. This calculus evolved in the research field of pure mathematics until\n1920, when applied science started to use it. Only recently, fractional\ncalculus was involved in image processing methods. As we shall see, the\nfractional calculation is able to enhance the quality of images, with\ninteresting possibilities in edge detection and image restoration. We suggest\nalso the fractional differentiation as a tool to reveal faint objects in\nastronomical images.", 
    "link": "http://arxiv.org/pdf/0910.2381v4", 
    "arxiv-id": "0910.2381v4"
},{
    "category": "cs.CV", 
    "author": "J. Konrad", 
    "title": "Behavior Subtraction", 
    "publish": "2009-10-15T16:09:18Z", 
    "summary": "Background subtraction has been a driving engine for many computer vision and\nvideo analytics tasks. Although its many variants exist, they all share the\nunderlying assumption that photometric scene properties are either static or\nexhibit temporal stationarity. While this works in some applications, the model\nfails when one is interested in discovering {\\it changes in scene dynamics}\nrather than those in a static background; detection of unusual pedestrian and\nmotor traffic patterns is but one example. We propose a new model and\ncomputational framework that address this failure by considering stationary\nscene dynamics as a ``background'' with which observed scene dynamics are\ncompared. Central to our approach is the concept of an {\\it event}, that we\ndefine as short-term scene dynamics captured over a time window at a specific\nspatial location in the camera field of view. We compute events by\ntime-aggregating motion labels, obtained by background subtraction, as well as\nobject descriptors (e.g., object size). Subsequently, we characterize events\nprobabilistically, but use a low-memory, low-complexity surrogates in practical\nimplementation. Using these surrogates amounts to {\\it behavior subtraction}, a\nnew algorithm with some surprising properties. As demonstrated here, behavior\nsubtraction is an effective tool in anomaly detection and localization. It is\nresilient to spurious background motion, such as one due to camera jitter, and\nis content-blind, i.e., it works equally well on humans, cars, animals, and\nother objects in both uncluttered and highly-cluttered scenes. Clearly,\ntreating video as a collection of events rather than colored pixels opens new\npossibilities for video analytics.", 
    "link": "http://arxiv.org/pdf/0910.2917v1", 
    "arxiv-id": "0910.2917v1"
},{
    "category": "cs.CV", 
    "author": "Patrick Erik Bradley", 
    "title": "A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting", 
    "publish": "2009-10-26T09:34:29Z", 
    "summary": "A $p$-adic variation of the Ran(dom) Sa(mple) C(onsensus) method for solving\nthe relative pose problem in stereo vision is developped. From two 2-adically\nencoded images a random sample of five pairs of corresponding points is taken,\nand the equations for the essential matrix are solved by lifting solutions\nmodulo 2 to the 2-adic integers. A recently devised $p$-adic hierarchical\nclassification algorithm imitating the known LBG quantisation method classifies\nthe solutions for all the samples after having determined the number of\nclusters using the known intra-inter validity of clusterings. In the successful\ncase, a cluster ranking will determine the cluster containing a 2-adic\napproximation to the \"true\" solution of the problem.", 
    "link": "http://arxiv.org/pdf/0910.4839v2", 
    "arxiv-id": "0910.4839v2"
},{
    "category": "cs.CV", 
    "author": "Oleg Michailovich", 
    "title": "An Iterative Shrinkage Approach to Total-Variation Image Restoration", 
    "publish": "2009-10-26T22:50:18Z", 
    "summary": "The problem of restoration of digital images from their degraded measurements\nplays a central role in a multitude of practically important applications. A\nparticularly challenging instance of this problem occurs in the case when the\ndegradation phenomenon is modeled by an ill-conditioned operator. In such a\ncase, the presence of noise makes it impossible to recover a valuable\napproximation of the image of interest without using some a priori information\nabout its properties. Such a priori information is essential for image\nrestoration, rendering it stable and robust to noise. Particularly, if the\noriginal image is known to be a piecewise smooth function, one of the standard\npriors used in this case is defined by the Rudin-Osher-Fatemi model, which\nresults in total variation (TV) based image restoration. The current arsenal of\nalgorithms for TV-based image restoration is vast. In the present paper, a\ndifferent approach to the solution of the problem is proposed based on the\nmethod of iterative shrinkage (aka iterated thresholding). In the proposed\nmethod, the TV-based image restoration is performed through a recursive\napplication of two simple procedures, viz. linear filtering and soft\nthresholding. Therefore, the method can be identified as belonging to the group\nof first-order algorithms which are efficient in dealing with images of\nrelatively large sizes. Another valuable feature of the proposed method\nconsists in its working directly with the TV functional, rather then with its\nsmoothed versions. Moreover, the method provides a single solution for both\nisotropic and anisotropic definitions of the TV functional, thereby\nestablishing a useful connection between the two formulae.", 
    "link": "http://arxiv.org/pdf/0910.5002v1", 
    "arxiv-id": "0910.5002v1"
},{
    "category": "cs.CV", 
    "author": "P. Subashini", 
    "title": "An Optimal Method For Wake Detection In SAR Images Using Radon   Transformation Combined With Wavelet Filters", 
    "publish": "2009-11-03T03:37:03Z", 
    "summary": "A new fangled method for ship wake detection in synthetic aperture radar\n(SAR) images is explored here. Most of the detection procedure applies the\nRadon transform as its properties outfit more than any other transformation for\nthe detection purpose. But still it holds problems when the transform is\napplied to an image with a high level of noise. Here this paper articulates the\ncombination between the radon transformation and the shrinkage methods which\nincrease the mode of wake detection process. The latter shrinkage method with\nRT maximize the signal to noise ratio hence it leads to most optimal detection\nof lines in the SAR images. The originality mainly works on the denoising\nsegment of the proposed algorithm. Experimental work outs are carried over both\nin simulated and real SAR images. The detection process is more adequate with\nthe proposed method and improves better than the conventional methods.", 
    "link": "http://arxiv.org/pdf/0911.0481v1", 
    "arxiv-id": "0911.0481v1"
},{
    "category": "cs.CV", 
    "author": "S. Thamarai Selvi", 
    "title": "Breast Cancer Detection Using Multilevel Thresholding", 
    "publish": "2009-11-03T04:33:55Z", 
    "summary": "This paper presents an algorithm which aims to assist the radiologist in\nidentifying breast cancer at its earlier stages. It combines several image\nprocessing techniques like image negative, thresholding and segmentation\ntechniques for detection of tumor in mammograms. The algorithm is verified by\nusing mammograms from Mammographic Image Analysis Society. The results obtained\nby applying these techniques are described.", 
    "link": "http://arxiv.org/pdf/0911.0490v1", 
    "arxiv-id": "0911.0490v1"
},{
    "category": "cs.CV", 
    "author": "Roberto Marazzato", 
    "title": "Non-photorealistic image processing: an Impressionist rendering", 
    "publish": "2009-11-25T15:16:53Z", 
    "summary": "The paper describes an image processing for a non-photorealistic rendering.\nThe algorithm is based on a random choice of a set of pixels from those ot the\noriginal image and substitution of them with colour spots. An iterative\nprocedure is applied to cover, at a desired level, the canvas. The resulting\neffect mimics the impressionist painting and Pointillism.", 
    "link": "http://arxiv.org/pdf/0911.4874v2", 
    "arxiv-id": "0911.4874v2"
},{
    "category": "cs.CV", 
    "author": "Hamid Soltanian-Zadeh", 
    "title": "Pigment Melanin: Pattern for Iris Recognition", 
    "publish": "2009-11-29T07:07:54Z", 
    "summary": "Recognition of iris based on Visible Light (VL) imaging is a difficult\nproblem because of the light reflection from the cornea. Nonetheless, pigment\nmelanin provides a rich feature source in VL, unavailable in Near-Infrared\n(NIR) imaging. This is due to biological spectroscopy of eumelanin, a chemical\nnot stimulated in NIR. In this case, a plausible solution to observe such\npatterns may be provided by an adaptive procedure using a variational technique\non the image histogram. To describe the patterns, a shape analysis method is\nused to derive feature-code for each subject. An important question is how much\nthe melanin patterns, extracted from VL, are independent of iris texture in\nNIR. With this question in mind, the present investigation proposes fusion of\nfeatures extracted from NIR and VL to boost the recognition performance. We\nhave collected our own database (UTIRIS) consisting of both NIR and VL images\nof 158 eyes of 79 individuals. This investigation demonstrates that the\nproposed algorithm is highly sensitive to the patterns of cromophores and\nimproves the iris recognition rate.", 
    "link": "http://arxiv.org/pdf/0911.5462v1", 
    "arxiv-id": "0911.5462v1"
},{
    "category": "cs.CV", 
    "author": "Reza Aghaeizadeh Zoroofi", 
    "title": "Sequential Clustering based Facial Feature Extraction Method for   Automatic Creation of Facial Models from Orthogonal Views", 
    "publish": "2009-12-03T08:54:24Z", 
    "summary": "Multiview 3D face modeling has attracted increasing attention recently and\nhas become one of the potential avenues in future video systems. We aim to make\nmore reliable and robust automatic feature extraction and natural 3D feature\nconstruction from 2D features detected on a pair of frontal and profile view\nface images. We propose several heuristic algorithms to minimize possible\nerrors introduced by prevalent nonperfect orthogonal condition and noncoherent\nluminance. In our approach, we first extract the 2D features that are visible\nto both cameras in both views. Then, we estimate the coordinates of the\nfeatures in the hidden profile view based on the visible features extracted in\nthe two orthogonal views. Finally, based on the coordinates of the extracted\nfeatures, we deform a 3D generic model to perform the desired 3D clone\nmodeling. Present study proves the scope of resulted facial models for\npractical applications like face recognition and facial animation.", 
    "link": "http://arxiv.org/pdf/0912.0600v1", 
    "arxiv-id": "0912.0600v1"
},{
    "category": "cs.CV", 
    "author": "Mark Hickman", 
    "title": "Automatic creation of urban velocity fields from aerial video", 
    "publish": "2009-12-07T19:04:41Z", 
    "summary": "In this paper, we present a system for modelling vehicle motion in an urban\nscene from low frame-rate aerial video. In particular, the scene is modelled as\na probability distribution over velocities at every pixel in the image.\n  We describe the complete system for acquiring this model. The video is\ncaptured from a helicopter and stabilized by warping the images to match an\northorectified image of the area. A pixel classifier is applied to the\nstabilized images, and the response is segmented to determine car locations and\norientations. The results are fed in to a tracking scheme which tracks cars for\nthree frames, creating tracklets. This allows the tracker to use a combination\nof velocity, direction, appearance, and acceleration cues to keep only tracks\nlikely to be correct. Each tracklet provides a measurement of the car velocity\nat every point along the tracklet's length, and these are then aggregated to\ncreate a histogram of vehicle velocities at every pixel in the image.\n  The results demonstrate that the velocity probability distribution prior can\nbe used to infer a variety of information about road lane directions, speed\nlimits, vehicle speeds and common trajectories, and traffic bottlenecks, as\nwell as providing a means of describing environmental knowledge about traffic\nrules that can be used in tracking.", 
    "link": "http://arxiv.org/pdf/0912.1310v1", 
    "arxiv-id": "0912.1310v1"
},{
    "category": "cs.CV", 
    "author": "Nathan Brewer", 
    "title": "Matching 2-D Ellipses to 3-D Circles with Application to Vehicle Pose   Estimation", 
    "publish": "2009-12-18T05:58:54Z", 
    "summary": "Finding the three-dimensional representation of all or a part of a scene from\na single two dimensional image is a challenging task. In this paper we propose\na method for identifying the pose and location of objects with circular\nprotrusions in three dimensions from a single image and a 3d representation or\nmodel of the object of interest. To do this, we present a method for\nidentifying ellipses and their properties quickly and reliably with a novel\ntechnique that exploits intensity differences between objects and a geometric\ntechnique for matching an ellipse in 2d to a circle in 3d.\n  We apply these techniques to the specific problem of determining the pose and\nlocation of vehicles, particularly cars, from a single image. We have achieved\nexcellent pose recovery performance on artificially generated car images and\nshow promising results on real vehicle images. We also make use of the ellipse\ndetection method to identify car wheels from images, with a very high\nsuccessful match rate.", 
    "link": "http://arxiv.org/pdf/0912.3589v1", 
    "arxiv-id": "0912.3589v1"
},{
    "category": "cs.CV", 
    "author": "Pornchai Phukpattaranont", 
    "title": "A Novel Feature Extraction for Robust EMG Pattern Recognition", 
    "publish": "2009-12-20T03:49:21Z", 
    "summary": "Varieties of noises are major problem in recognition of Electromyography\n(EMG) signal. Hence, methods to remove noise become most significant in EMG\nsignal analysis. White Gaussian noise (WGN) is used to represent interference\nin this paper. Generally, WGN is difficult to be removed using typical\nfiltering and solutions to remove WGN are limited. In addition, noise removal\nis an important step before performing feature extraction, which is used in\nEMG-based recognition. This research is aimed to present a novel feature that\ntolerate with WGN. As a result, noise removal algorithm is not needed. Two\nnovel mean and median frequencies (MMNF and MMDF) are presented for robust\nfeature extraction. Sixteen existing features and two novelties are evaluated\nin a noisy environment. WGN with various signal-to-noise ratios (SNRs), i.e.\n20-0 dB, was added to the original EMG signal. The results showed that MMNF\nperformed very well especially in weak EMG signal compared with others. The\nerror of MMNF in weak EMG signal with very high noise, 0 dB SNR, is about 5-10\npercent and closed by MMDF and Histogram, whereas the error of other features\nis more than 20 percent. While in strong EMG signal, the error of MMNF is\nbetter than those from other features. Moreover, the combination of MMNF,\nHistrogram of EMG and Willison amplitude is used as feature vector in\nclassification task. The experimental result shows the better recognition\nresult in noisy environment than other success feature candidates. From the\nabove results demonstrate that MMNF can be used for new robust feature\nextraction.", 
    "link": "http://arxiv.org/pdf/0912.3973v2", 
    "arxiv-id": "0912.3973v2"
},{
    "category": "cs.CV", 
    "author": "Ching Y. Suen", 
    "title": "Writer Identification Using Inexpensive Signal Processing Techniques", 
    "publish": "2009-12-30T18:19:53Z", 
    "summary": "We propose to use novel and classical audio and text signal-processing and\notherwise techniques for \"inexpensive\" fast writer identification tasks of\nscanned hand-written documents \"visually\". The \"inexpensive\" refers to the\nefficiency of the identification process in terms of CPU cycles while\npreserving decent accuracy for preliminary identification. This is a\ncomparative study of multiple algorithm combinations in a pattern recognition\npipeline implemented in Java around an open-source Modular Audio Recognition\nFramework (MARF) that can do a lot more beyond audio. We present our\npreliminary experimental findings in such an identification task. We simulate\n\"visual\" identification by \"looking\" at the hand-written document as a whole\nrather than trying to extract fine-grained features out of it prior\nclassification.", 
    "link": "http://arxiv.org/pdf/0912.5502v1", 
    "arxiv-id": "0912.5502v1"
},{
    "category": "cs.CV", 
    "author": "Klaus Obermayer", 
    "title": "Accelerating Competitive Learning Graph Quantization", 
    "publish": "2010-01-06T16:05:25Z", 
    "summary": "Vector quantization(VQ) is a lossy data compression technique from signal\nprocessing for which simple competitive learning is one standard method to\nquantize patterns from the input space. Extending competitive learning VQ to\nthe domain of graphs results in competitive learning for quantizing input\ngraphs. In this contribution, we propose an accelerated version of competitive\nlearning graph quantization (GQ) without trading computational time against\nsolution quality. For this, we lift graphs locally to vectors in order to avoid\nunnecessary calculations of intractable graph distances. In doing so, the\naccelerated version of competitive learning GQ gradually turns locally into a\ncompetitive learning VQ with increasing number of iterations. Empirical results\nshow a significant speedup by maintaining a comparable solution quality.", 
    "link": "http://arxiv.org/pdf/1001.0927v1", 
    "arxiv-id": "1001.0927v1"
},{
    "category": "cs.CV", 
    "author": "Michel Barlaud", 
    "title": "Boosting k-NN for categorization of natural scenes", 
    "publish": "2010-01-08T08:30:51Z", 
    "summary": "The k-nearest neighbors (k-NN) classification rule has proven extremely\nsuccessful in countless many computer vision applications. For example, image\ncategorization often relies on uniform voting among the nearest prototypes in\nthe space of descriptors. In spite of its good properties, the classic k-NN\nrule suffers from high variance when dealing with sparse prototype datasets in\nhigh dimensions. A few techniques have been proposed to improve k-NN\nclassification, which rely on either deforming the nearest neighborhood\nrelationship or modifying the input space. In this paper, we propose a novel\nboosting algorithm, called UNN (Universal Nearest Neighbors), which induces\nleveraged k-NN, thus generalizing the classic k-NN rule. We redefine the voting\nrule as a strong classifier that linearly combines predictions from the k\nclosest prototypes. Weak classifiers are learned by UNN so as to minimize a\nsurrogate risk. A major feature of UNN is the ability to learn which prototypes\nare the most relevant for a given class, thus allowing one for effective data\nreduction. Experimental results on the synthetic two-class dataset of Ripley\nshow that such a filtering strategy is able to reject \"noisy\" prototypes. We\ncarried out image categorization experiments on a database containing eight\nclasses of natural scenes. We show that our method outperforms significantly\nthe classic k-NN classification, while enabling significant reduction of the\ncomputational cost by means of data filtering.", 
    "link": "http://arxiv.org/pdf/1001.1221v1", 
    "arxiv-id": "1001.1221v1"
},{
    "category": "cs.CV", 
    "author": "Dr. V. Radha", 
    "title": "A Topological derivative based image segmentation for sign language   recognition system using isotropic filter", 
    "publish": "2010-01-12T18:18:10Z", 
    "summary": "The need of sign language is increasing radically especially to hearing\nimpaired community. Only few research groups try to automatically recognize\nsign language from video, colored gloves and etc. Their approach requires a\nvalid segmentation of the data that is used for training and of the data that\nis used to be recognized. Recognition of a sign language image sequence is\nchallenging because of the variety of hand shapes and hand motions. Here, this\npaper proposes to apply a combination of image segmentation with restoration\nusing topological derivatives for achieving high recognition accuracy. Image\nquality measures are conceded here to differentiate the methods both\nsubjectively as well as objectively. Experiments show that the additional use\nof the restoration before segmenting the postures significantly improves the\ncorrect rate of hand detection, and that the discrete derivatives yields a high\nrate of discrimination between different static hand postures as well as\nbetween hand postures and the scene background. Eventually, the research is to\ncontribute to the implementation of automated sign language recognition system\nmainly established for the welfare purpose.", 
    "link": "http://arxiv.org/pdf/1001.1968v1", 
    "arxiv-id": "1001.1968v1"
},{
    "category": "cs.CV", 
    "author": "Naomie Salim", 
    "title": "Features Based Text Similarity Detection", 
    "publish": "2010-01-20T07:46:23Z", 
    "summary": "As the Internet help us cross cultural border by providing different\ninformation, plagiarism issue is bound to arise. As a result, plagiarism\ndetection becomes more demanding in overcoming this issue. Different plagiarism\ndetection tools have been developed based on various detection techniques.\nNowadays, fingerprint matching technique plays an important role in those\ndetection tools. However, in handling some large content articles, there are\nsome weaknesses in fingerprint matching technique especially in space and time\nconsumption issue. In this paper, we propose a new approach to detect\nplagiarism which integrates the use of fingerprint matching technique with four\nkey features to assist in the detection process. These proposed features are\ncapable to choose the main point or key sentence in the articles to be\ncompared. Those selected sentence will be undergo the fingerprint matching\nprocess in order to detect the similarity between the sentences. Hence, time\nand space usage for the comparison process is reduced without affecting the\neffectiveness of the plagiarism detection.", 
    "link": "http://arxiv.org/pdf/1001.3487v1", 
    "arxiv-id": "1001.3487v1"
},{
    "category": "cs.CV", 
    "author": "A. A Zaidan", 
    "title": "3D Skull Recognition Using 3D Matching Technique", 
    "publish": "2010-01-20T08:17:26Z", 
    "summary": "Biometrics has become a \"hot\" area. Governments are funding research programs\nfocused on biometrics. In this paper the problem of person recognition and\nverification based on a different biometric application has been addressed. The\nsystem is based on the 3DSkull recognition using 3D matching technique, in fact\nthis paper present several bio-metric approaches in order of assign the weak\npoint in term of used the biometric from the authorize person and insure the\nperson who access the data is the real person. The feature of the simulate\nsystem shows the capability of using 3D matching system as an efficient way to\nidentify the person through his or her skull by match it with database, this\ntechnique grantee fast processing with optimizing the false positive and\nnegative as well .", 
    "link": "http://arxiv.org/pdf/1001.3502v1", 
    "arxiv-id": "1001.3502v1"
},{
    "category": "cs.CV", 
    "author": "M. Madheswaran", 
    "title": "Hybrid Medical Image Classification Using Association Rule Mining with   Decision Tree Algorithm", 
    "publish": "2010-01-20T08:19:48Z", 
    "summary": "The main focus of image mining in the proposed method is concerned with the\nclassification of brain tumor in the CT scan brain images. The major steps\ninvolved in the system are: pre-processing, feature extraction, association\nrule mining and hybrid classifier. The pre-processing step has been done using\nthe median filtering process and edge features have been extracted using canny\nedge detection technique. The two image mining approaches with a hybrid manner\nhave been proposed in this paper. The frequent patterns from the CT scan images\nare generated by frequent pattern tree (FP-Tree) algorithm that mines the\nassociation rules. The decision tree method has been used to classify the\nmedical images for diagnosis. This system enhances the classification process\nto be more accurate. The hybrid method improves the efficiency of the proposed\nmethod than the traditional image mining methods. The experimental result on\nprediagnosed database of brain images showed 97% sensitivity and 95% accuracy\nrespectively. The physicians can make use of this accurate decision tree\nclassification phase for classifying the brain images into normal, benign and\nmalignant for effective medical diagnosis.", 
    "link": "http://arxiv.org/pdf/1001.3503v1", 
    "arxiv-id": "1001.3503v1"
},{
    "category": "cs.CV", 
    "author": "T. R. Gopalakrishnan Nair", 
    "title": "Gradient Based Seeded Region Grow method for CT Angiographic Image   Segmentation", 
    "publish": "2010-01-21T07:15:29Z", 
    "summary": "Segmentation of medical images using seeded region growing technique is\nincreasingly becoming a popular method because of its ability to involve\nhigh-level knowledge of anatomical structures in seed selection process. Region\nbased segmentation of medical images are widely used in varied clinical\napplications like visualization, bone detection, tumor detection and\nunsupervised image retrieval in clinical databases. As medical images are\nmostly fuzzy in nature, segmenting regions based intensity is the most\nchallenging task. In this paper, we discuss about popular seeded region grow\nmethodology used for segmenting anatomical structures in CT Angiography images.\nWe have proposed a gradient based homogeneity criteria to control the region\ngrow process while segmenting CTA images.", 
    "link": "http://arxiv.org/pdf/1001.3735v1", 
    "arxiv-id": "1001.3735v1"
},{
    "category": "cs.CV", 
    "author": "Saylee M. Gharge", 
    "title": "Detection and Demarcation of Tumor using Vector Quantization in MRI   images", 
    "publish": "2010-01-23T19:00:44Z", 
    "summary": "Segmenting a MRI images into homogeneous texture regions representing\ndisparate tissue types is often a useful preprocessing step in the\ncomputer-assisted detection of breast cancer. That is why we proposed new\nalgorithm to detect cancer in mammogram breast cancer images. In this paper we\nproposed segmentation using vector quantization technique. Here we used Linde\nBuzo-Gray algorithm (LBG) for segmentation of MRI images. Initially a codebook\nof size 128 was generated for MRI images. These code vectors were further\nclustered in 8 clusters using same LBG algorithm. These 8 images were displayed\nas a result. This approach does not leads to over segmentation or under\nsegmentation. For the comparison purpose we displayed results of watershed\nsegmentation and Entropy using Gray Level Co-occurrence Matrix along with this\nmethod.", 
    "link": "http://arxiv.org/pdf/1001.4189v1", 
    "arxiv-id": "1001.4189v1"
},{
    "category": "cs.CV", 
    "author": "Michael H. Dickinson", 
    "title": "Multi-camera Realtime 3D Tracking of Multiple Flying Animals", 
    "publish": "2010-01-25T01:40:40Z", 
    "summary": "Automated tracking of animal movement allows analyses that would not\notherwise be possible by providing great quantities of data. The additional\ncapability of tracking in realtime - with minimal latency - opens up the\nexperimental possibility of manipulating sensory feedback, thus allowing\ndetailed explorations of the neural basis for control of behavior. Here we\ndescribe a new system capable of tracking the position and body orientation of\nanimals such as flies and birds. The system operates with less than 40 msec\nlatency and can track multiple animals simultaneously. To achieve these\nresults, a multi target tracking algorithm was developed based on the Extended\nKalman Filter and the Nearest Neighbor Standard Filter data association\nalgorithm. In one implementation, an eleven camera system is capable of\ntracking three flies simultaneously at 60 frames per second using a gigabit\nnetwork of nine standard Intel Pentium 4 and Core 2 Duo computers. This\nmanuscript presents the rationale and details of the algorithms employed and\nshows three implementations of the system. An experiment was performed using\nthe tracking system to measure the effect of visual contrast on the flight\nspeed of Drosophila melanogaster. At low contrasts, speed is more variable and\nfaster on average than at high contrasts. Thus, the system is already a useful\ntool to study the neurobiology and behavior of freely flying animals. If\ncombined with other techniques, such as `virtual reality'-type computer\ngraphics or genetic manipulation, the tracking system would offer a powerful\nnew way to investigate the biology of flying animals.", 
    "link": "http://arxiv.org/pdf/1001.4297v1", 
    "arxiv-id": "1001.4297v1"
},{
    "category": "cs.CV", 
    "author": "S. Sethu Selvi", 
    "title": "Kannada Character Recognition System A Review", 
    "publish": "2010-01-29T08:29:57Z", 
    "summary": "Intensive research has been done on optical character recognition ocr and a\nlarge number of articles have been published on this topic during the last few\ndecades. Many commercial OCR systems are now available in the market, but most\nof these systems work for Roman, Chinese, Japanese and Arabic characters. There\nare no sufficient number of works on Indian language character recognition\nespecially Kannada script among 12 major scripts in India. This paper presents\na review of existing work on printed Kannada script and their results. The\ncharacteristics of Kannada script and Kannada Character Recognition System kcr\nare discussed in detail. Finally fusion at the classifier level is proposed to\nincrease the recognition accuracy.", 
    "link": "http://arxiv.org/pdf/1001.5352v1", 
    "arxiv-id": "1001.5352v1"
},{
    "category": "cs.CV", 
    "author": "S. Arumugam", 
    "title": "Threshold Based Indexing of Commercial Shoe Print to Create Reference   and Recovery Images", 
    "publish": "2010-01-29T09:03:48Z", 
    "summary": "One of the important evidence in a crime scene that is normally overlooked\nbut very important evidence is shoe print as the criminal is normally unaware\nof the mask for this. In this paper we use image processing technique to\nprocess reference shoe images to make it index-able for a search from the\ndatabase the shoe print impressions available in the commercial market. This is\nachieved first by converting the commercially available image through the\nprocess of converting them to gray scale then apply image enhancement and\nrestoration techniques and finally do image segmentation to store the segmented\nparameter as index in the database storage. We use histogram method for image\nenhancement, inverse filtering for image restoration and threshold method for\nindexing. We use global threshold as index of the shoe print. The paper\ndescribes this method and simulation results are included to validate the\nmethod.", 
    "link": "http://arxiv.org/pdf/1001.5359v1", 
    "arxiv-id": "1001.5359v1"
},{
    "category": "cs.CV", 
    "author": "S. D. Khamitkar", 
    "title": "A Comparative Study of Removal Noise from Remote Sensing Image", 
    "publish": "2010-02-05T08:34:39Z", 
    "summary": "This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image.", 
    "link": "http://arxiv.org/pdf/1002.1148v1", 
    "arxiv-id": "1002.1148v1"
},{
    "category": "cs.CV", 
    "author": "Li Bai", 
    "title": "The Influence of Intensity Standardization on Medical Image Registration", 
    "publish": "2010-02-05T17:35:49Z", 
    "summary": "Acquisition-to-acquisition signal intensity variations (non-standardness) are\ninherent in MR images. Standardization is a post processing method for\ncorrecting inter-subject intensity variations through transforming all images\nfrom the given image gray scale into a standard gray scale wherein similar\nintensities achieve similar tissue meanings. The lack of a standard image\nintensity scale in MRI leads to many difficulties in tissue characterizability,\nimage display, and analysis, including image segmentation. This phenomenon has\nbeen documented well; however, effects of standardization on medical image\nregistration have not been studied yet. In this paper, we investigate the\ninfluence of intensity standardization in registration tasks with systematic\nand analytic evaluations involving clinical MR images. We conducted nearly\n20,000 clinical MR image registration experiments and evaluated the quality of\nregistrations both quantitatively and qualitatively. The evaluations show that\nintensity variations between images degrades the accuracy of registration\nperformance. The results imply that the accuracy of image registration not only\ndepends on spatial and geometric similarity but also on the similarity of the\nintensity values for the same tissues in different images.", 
    "link": "http://arxiv.org/pdf/1002.1285v1", 
    "arxiv-id": "1002.1285v1"
},{
    "category": "cs.CV", 
    "author": "Xinjian Chen", 
    "title": "Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical   Images", 
    "publish": "2010-02-05T17:54:36Z", 
    "summary": "This paper investigates, using prior shape models and the concept of ball\nscale (b-scale), ways of automatically recognizing objects in 3D images without\nperforming elaborate searches or optimization. That is, the goal is to place\nthe model in a single shot close to the right pose (position, orientation, and\nscale) in a given image so that the model boundaries fall in the close vicinity\nof object boundaries in the image. This is achieved via the following set of\nkey ideas: (a) A semi-automatic way of constructing a multi-object shape model\nassembly. (b) A novel strategy of encoding, via b-scale, the pose relationship\nbetween objects in the training images and their intensity patterns captured in\nb-scale images. (c) A hierarchical mechanism of positioning the model, in a\none-shot way, in a given image from a knowledge of the learnt pose relationship\nand the b-scale image of the given image to be segmented. The evaluation\nresults on a set of 20 routine clinical abdominal female and male CT data sets\nindicate the following: (1) Incorporating a large number of objects improves\nthe recognition accuracy dramatically. (2) The recognition algorithm can be\nthought as a hierarchical framework such that quick replacement of the model\nassembly is defined as coarse recognition and delineation itself is known as\nfinest recognition. (3) Scale yields useful information about the relationship\nbetween the model assembly and any given image such that the recognition\nresults in a placement of the model close to the actual pose without doing any\nelaborate searches or optimization. (4) Effective object recognition can make\ndelineation most accurate.", 
    "link": "http://arxiv.org/pdf/1002.1288v1", 
    "arxiv-id": "1002.1288v1"
},{
    "category": "cs.CV", 
    "author": "C. Gowri Shankar", 
    "title": "Detection of Microcalcification in Mammograms Using Wavelet Transform   and Fuzzy Shell Clustering", 
    "publish": "2010-02-10T19:22:25Z", 
    "summary": "Microcalcifications in mammogram have been mainly targeted as a reliable\nearliest sign of breast cancer and their early detection is vital to improve\nits prognosis. Since their size is very small and may be easily overlooked by\nthe examining radiologist, computer-based detection output can assist the\nradiologist to improve the diagnostic accuracy. In this paper, we have proposed\nan algorithm for detecting microcalcification in mammogram. The proposed\nmicrocalcification detection algorithm involves mammogram quality enhancement\nusing multirresolution analysis based on the dyadic wavelet transform and\nmicrocalcification detection by fuzzy shell clustering. It may be possible to\ndetect nodular components such as microcalcification accurately by introducing\nshape information. The effectiveness of the proposed algorithm for\nmicrocalcification detection is confirmed by experimental results.", 
    "link": "http://arxiv.org/pdf/1002.2182v1", 
    "arxiv-id": "1002.2182v1"
},{
    "category": "cs.CV", 
    "author": "S. SwarnaParvathi", 
    "title": "Automatic diagnosis of retinal diseases from color retinal images", 
    "publish": "2010-02-11T19:54:08Z", 
    "summary": "Teleophthalmology holds a great potential to improve the quality, access, and\naffordability in health care. For patients, it can reduce the need for travel\nand provide the access to a superspecialist. Ophthalmology lends itself easily\nto telemedicine as it is a largely image based diagnosis. The main goal of the\nproposed system is to diagnose the type of disease in the retina and to\nautomatically detect and segment retinal diseases without human supervision or\ninteraction. The proposed system will diagnose the disease present in the\nretina using a neural network based classifier.The extent of the disease spread\nin the retina can be identified by extracting the textural features of the\nretina. This system will diagnose the following type of diseases: Diabetic\nRetinopathy and Drusen.", 
    "link": "http://arxiv.org/pdf/1002.2408v1", 
    "arxiv-id": "1002.2408v1"
},{
    "category": "cs.CV", 
    "author": "A. Shanmugam", 
    "title": "Medical Image Compression using Wavelet Decomposition for Prediction   Method", 
    "publish": "2010-02-11T20:16:33Z", 
    "summary": "In this paper offers a simple and lossless compression method for compression\nof medical images. Method is based on wavelet decomposition of the medical\nimages followed by the correlation analysis of coefficients. The correlation\nanalyses are the basis of prediction equation for each sub band. Predictor\nvariable selection is performed through coefficient graphic method to avoid\nmulticollinearity problem and to achieve high prediction accuracy and\ncompression rate. The method is applied on MRI and CT images. Results show that\nthe proposed approach gives a high compression rate for MRI and CT images\ncomparing with state of the art methods.", 
    "link": "http://arxiv.org/pdf/1002.2418v1", 
    "arxiv-id": "1002.2418v1"
},{
    "category": "cs.CV", 
    "author": "Syed Golam Rajib", 
    "title": "Supervised Learning of Digital image restoration based on Quantization   Nearest Neighbor algorithm", 
    "publish": "2010-02-21T18:34:10Z", 
    "summary": "In this paper, an algorithm is proposed for Image Restoration. Such algorithm\nis different from the traditional approaches in this area, by utilizing priors\nthat are learned from similar images. Original images and their degraded\nversions by the known degradation operators are utilized for designing the\nQuantization. The code vectors are designed using the blurred images. For each\nsuch vector, the high frequency information obtained from the original images\nis also available. During restoration, the high frequency information of a\ngiven degraded image is estimated from its low frequency information based on\nthe artificial noise. For the restoration problem, a number of techniques are\ndesigned corresponding to various versions of the blurring function. Given a\nnoisy and blurred image, one of the techniques is chosen based on a similarity\nmeasure, therefore providing the identification of the blur. To make the\nrestoration process computationally efficient, the Quantization Nearest\nNeighborhood approaches are utilized.", 
    "link": "http://arxiv.org/pdf/1002.3985v1", 
    "arxiv-id": "1002.3985v1"
},{
    "category": "cs.CV", 
    "author": "Lei Wang", 
    "title": "Scalable Large-Margin Mahalanobis Distance Metric Learning", 
    "publish": "2010-03-02T01:12:34Z", 
    "summary": "For many machine learning algorithms such as $k$-Nearest Neighbor ($k$-NN)\nclassifiers and $ k $-means clustering, often their success heavily depends on\nthe metric used to calculate distances between different data points.\n  An effective solution for defining such a metric is to learn it from a set of\nlabeled training samples. In this work, we propose a fast and scalable\nalgorithm to learn a Mahalanobis distance metric. By employing the principle of\nmargin maximization to achieve better generalization performances, this\nalgorithm formulates the metric learning as a convex optimization problem and a\npositive semidefinite (psd) matrix is the unknown variable. a specialized\ngradient descent method is proposed. our algorithm is much more efficient and\nhas a better performance in scalability compared with existing methods.\nExperiments on benchmark data sets suggest that, compared with state-of-the-art\nmetric learning algorithms, our algorithm can achieve a comparable\nclassification accuracy with reduced computational complexity.", 
    "link": "http://arxiv.org/pdf/1003.0487v1", 
    "arxiv-id": "1003.0487v1"
},{
    "category": "cs.CV", 
    "author": "Mahantapas Kundu", 
    "title": "Text Region Extraction from Business Card Images for Mobile Devices", 
    "publish": "2010-03-02T17:45:26Z", 
    "summary": "Designing a Business Card Reader (BCR) for mobile devices is a challenge to\nthe researchers because of huge deformation in acquired images, multiplicity in\nnature of the business cards and most importantly the computational constraints\nof the mobile devices. This paper presents a text extraction method designed in\nour work towards developing a BCR for mobile devices. At first, the background\nof a camera captured image is eliminated at a coarse level. Then, various rule\nbased techniques are applied on the Connected Components (CC) to filter out the\nnoises and picture regions. The CCs identified as text are then binarized using\nan adaptive but light-weight binarization technique. Experiments show that the\ntext extraction accuracy is around 98% for a wide range of resolutions with\nvarying computation time and memory requirements. The optimum performance is\nachieved for the images of resolution 1024x768 pixels with text extraction\naccuracy of 98.54% and, space and time requirements as 1.1 MB and 0.16 seconds\nrespectively.", 
    "link": "http://arxiv.org/pdf/1003.0642v2", 
    "arxiv-id": "1003.0642v2"
},{
    "category": "cs.CV", 
    "author": "Mahantapas Kundu", 
    "title": "Binarizing Business Card Images for Mobile Devices", 
    "publish": "2010-03-02T18:02:40Z", 
    "summary": "Business card images are of multiple natures as these often contain graphics,\npictures and texts of various fonts and sizes both in background and\nforeground. So, the conventional binarization techniques designed for document\nimages can not be directly applied on mobile devices. In this paper, we have\npresented a fast binarization technique for camera captured business card\nimages. A card image is split into small blocks. Some of these blocks are\nclassified as part of the background based on intensity variance. Then the\nnon-text regions are eliminated and the text ones are skew corrected and\nbinarized using a simple yet adaptive technique. Experiment shows that the\ntechnique is fast, efficient and applicable for the mobile devices.", 
    "link": "http://arxiv.org/pdf/1003.0645v2", 
    "arxiv-id": "1003.0645v2"
},{
    "category": "cs.CV", 
    "author": "Inger Fabris-Rotelli", 
    "title": "Properties of the Discrete Pulse Transform for Multi-Dimensional Arrays", 
    "publish": "2010-03-03T10:58:20Z", 
    "summary": "This report presents properties of the Discrete Pulse Transform on\nmulti-dimensional arrays introduced by the authors two or so years ago. The\nmain result given here in Lemma 2.1 is also formulated in a paper to appear in\nIEEE Transactions on Image Processing. However, the proof, being too technical,\nwas omitted there and hence it appears in full in this publication.", 
    "link": "http://arxiv.org/pdf/1003.0776v1", 
    "arxiv-id": "1003.0776v1"
},{
    "category": "cs.CV", 
    "author": "Dipak Kumar Basu", 
    "title": "An Offline Technique for Localization of License Plates for Indian   Commercial Vehicles", 
    "publish": "2010-03-04T15:57:41Z", 
    "summary": "Automatic License Plate Recognition (ALPR) is a challenging area of research\ndue to its importance to variety of commercial applications. The overall\nproblem may be subdivided into two key modules, firstly, localization of\nlicense plates from vehicle images, and secondly, optical character recognition\nof extracted license plates. In the current work, we have concentrated on the\nfirst part of the problem, i.e., localization of license plate regions from\nIndian commercial vehicles as a significant step towards development of a\ncomplete ALPR system for Indian vehicles. The technique is based on color based\nsegmentation of vehicle images and identification of potential license plate\nregions. True license plates are finally localized based on four spatial and\nhorizontal contrast features. The technique successfully localizes the actual\nlicense plates in 73.4% images.", 
    "link": "http://arxiv.org/pdf/1003.1072v2", 
    "arxiv-id": "1003.1072v2"
},{
    "category": "cs.CV", 
    "author": "Dr. Vinay Kumar Pathak", 
    "title": "Clinical gait data analysis based on Spatio-Temporal features", 
    "publish": "2010-03-07T18:46:12Z", 
    "summary": "Analysing human gait has found considerable interest in recent computer\nvision research. So far, however, contributions to this topic exclusively dealt\nwith the tasks of person identification or activity recognition. In this paper,\nwe consider a different application for gait analysis and examine its use as a\nmeans of deducing the physical well-being of people. The proposed method is\nbased on transforming the joint motion trajectories using wavelets to extract\nspatio-temporal features which are then fed as input to a vector quantiser; a\nself-organising map for classification of walking patterns of individuals with\nand without pathology. We show that our proposed algorithm is successful in\nextracting features that successfully discriminate between individuals with and\nwithout locomotion impairment.", 
    "link": "http://arxiv.org/pdf/1003.1511v1", 
    "arxiv-id": "1003.1511v1"
},{
    "category": "cs.CV", 
    "author": "RM. Chandrasekaran", 
    "title": "Nonlinear Filter Based Image Denoising Using AMF Approach", 
    "publish": "2010-03-09T07:05:47Z", 
    "summary": "This paper proposes a new technique based on nonlinear Adaptive Median filter\n(AMF) for image restoration. Image denoising is a common procedure in digital\nimage processing aiming at the removal of noise, which may corrupt an image\nduring its acquisition or transmission, while retaining its quality. This\nprocedure is traditionally performed in the spatial or frequency domain by\nfiltering. The aim of image enhancement is to reconstruct the true image from\nthe corrupted image. The process of image acquisition frequently leads to\ndegradation and the quality of the digitized image becomes inferior to the\noriginal image. Filtering is a technique for enhancing the image. Linear filter\nis the filtering in which the value of an output pixel is a linear combination\nof neighborhood values, which can produce blur in the image. Thus a variety of\nsmoothing techniques have been developed that are non linear. Median filter is\nthe one of the most popular non-linear filter. When considering a small\nneighborhood it is highly efficient but for large window and in case of high\nnoise it gives rise to more blurring to image. The Centre Weighted Median (CWM)\nfilter has got a better average performance over the median filter [8]. However\nthe original pixel corrupted and noise reduction is substantial under high\nnoise condition. Hence this technique has also blurring affect on the image. To\nillustrate the superiority of the proposed approach by overcoming the existing\nproblem, the proposed new scheme (AMF) Adaptive Median Filter has been\nsimulated along with the standard ones and various performance measures have\nbeen compared.", 
    "link": "http://arxiv.org/pdf/1003.1803v1", 
    "arxiv-id": "1003.1803v1"
},{
    "category": "cs.CV", 
    "author": "Rahul Bhatia", 
    "title": "Facial Gesture Recognition Using Correlation And Mahalanobis Distance", 
    "publish": "2010-03-09T07:39:03Z", 
    "summary": "Augmenting human computer interaction with automated analysis and synthesis\nof facial expressions is a goal towards which much research effort has been\ndevoted recently. Facial gesture recognition is one of the important component\nof natural human-machine interfaces; it may also be used in behavioural\nscience, security systems and in clinical practice. Although humans recognise\nfacial expressions virtually without effort or delay, reliable expression\nrecognition by machine is still a challenge. The face expression recognition\nproblem is challenging because different individuals display the same\nexpression differently. This paper presents an overview of gesture recognition\nin real time using the concepts of correlation and Mahalanobis distance.We\nconsider the six universal emotional categories namely joy, anger, fear,\ndisgust, sadness and surprise.", 
    "link": "http://arxiv.org/pdf/1003.1819v1", 
    "arxiv-id": "1003.1819v1"
},{
    "category": "cs.CV", 
    "author": "K. Lal kishore", 
    "title": "A GA based Window Selection Methodology to Enhance Window based Multi   wavelet transformation and thresholding aided CT image denoising technique", 
    "publish": "2010-03-09T08:09:02Z", 
    "summary": "Image denoising is getting more significance, especially in Computed\nTomography (CT), which is an important and most common modality in medical\nimaging. This is mainly due to that the effectiveness of clinical diagnosis\nusing CT image lies on the image quality. The denoising technique for CT images\nusing window-based Multi-wavelet transformation and thresholding shows the\neffectiveness in denoising, however, a drawback exists in selecting the closer\nwindows in the process of window-based multi-wavelet transformation and\nthresholding. Generally, the windows of the duplicate noisy image that are\ncloser to each window of original noisy image are obtained by the checking them\nsequentially. This leads to the possibility of missing out very closer windows\nand so enhancement is required in the aforesaid process of the denoising\ntechnique. In this paper, we propose a GA-based window selection methodology to\ninclude the denoising technique. With the aid of the GA-based window selection\nmethodology, the windows of the duplicate noisy image that are very closer to\nevery window of the original noisy image are extracted in an effective manner.\nBy incorporating the proposed GA-based window selection methodology, the\ndenoising the CT image is performed effectively. Eventually, a comparison is\nmade between the denoising technique with and without the proposed GA-based\nwindow selection methodology.", 
    "link": "http://arxiv.org/pdf/1003.1826v1", 
    "arxiv-id": "1003.1826v1"
},{
    "category": "cs.CV", 
    "author": "Vibhakar shrimali", 
    "title": "Investigation and Assessment of Disorder of Ultrasound B-mode Images", 
    "publish": "2010-03-09T08:13:37Z", 
    "summary": "Digital image plays a vital role in the early detection of cancers, such as\nprostate cancer, breast cancer, lungs cancer, cervical cancer. Ultrasound\nimaging method is also suitable for early detection of the abnormality of\nfetus. The accurate detection of region of interest in ultrasound image is\ncrucial. Since the result of reflection, refraction and deflection of\nultrasound waves from different types of tissues with different acoustic\nimpedance. Usually, the contrast in ultrasound image is very low and weak edges\nmake the image difficult to identify the fetus region in the ultrasound image.\nSo the analysis of ultrasound image is more challenging one. We try to develop\na new algorithmic approach to solve the problem of non clarity and find\ndisorder of it. Generally there is no common enhancement approach for noise\nreduction. This paper proposes different filtering techniques based on\nstatistical methods for the removal of various noise. The quality of the\nenhanced images is measured by the statistical quantity measures:\nSignal-to-Noise Ratio (SNR), Peak Signal-to-Noise Ratio (PSNR), and Root Mean\nSquare Error (RMSE).", 
    "link": "http://arxiv.org/pdf/1003.1827v1", 
    "arxiv-id": "1003.1827v1"
},{
    "category": "cs.CV", 
    "author": "Syed Sahidul Haque", 
    "title": "Handwritten Arabic Numeral Recognition using a Multi Layer Perceptron", 
    "publish": "2010-03-09T14:56:00Z", 
    "summary": "Handwritten numeral recognition is in general a benchmark problem of Pattern\nRecognition and Artificial Intelligence. Compared to the problem of printed\nnumeral recognition, the problem of handwritten numeral recognition is\ncompounded due to variations in shapes and sizes of handwritten characters.\nConsidering all these, the problem of handwritten numeral recognition is\naddressed under the present work in respect to handwritten Arabic numerals.\nArabic is spoken throughout the Arab World and the fifth most popular language\nin the world slightly before Portuguese and Bengali. For the present work, we\nhave developed a feature set of 88 features is designed to represent samples of\nhandwritten Arabic numerals for this work. It includes 72 shadow and 16 octant\nfeatures. A Multi Layer Perceptron (MLP) based classifier is used here for\nrecognition handwritten Arabic digits represented with the said feature set. On\nexperimentation with a database of 3000 samples, the technique yields an\naverage recognition rate of 94.93% evaluated after three-fold cross validation\nof results. It is useful for applications related to OCR of handwritten Arabic\nDigit and can also be extended to include OCR of handwritten characters of\nArabic alphabet.", 
    "link": "http://arxiv.org/pdf/1003.1891v1", 
    "arxiv-id": "1003.1891v1"
},{
    "category": "cs.CV", 
    "author": "Subhadip Basu", 
    "title": "A comparative study of different feature sets for recognition of   handwritten Arabic numerals using a Multi Layer Perceptron", 
    "publish": "2010-03-09T15:05:37Z", 
    "summary": "The work presents a comparative assessment of seven different feature sets\nfor recognition of handwritten Arabic numerals using a Multi Layer Perceptron\n(MLP) based classifier. The seven feature sets employed here consist of shadow\nfeatures, octant centroids, longest runs, angular distances, effective spans,\ndynamic centers of gravity, and some of their combinations. On experimentation\nwith a database of 3000 samples, the maximum recognition rate of 95.80% is\nobserved with both of two separate combinations of features. One of these\ncombinations consists of shadow and centriod features, i. e. 88 features in\nall, and the other shadow, centroid and longest run features, i. e. 124\nfeatures in all. Out of these two, the former combination having a smaller\nnumber of features is finally considered effective for applications related to\nOptical Character Recognition (OCR) of handwritten Arabic numerals. The work\ncan also be extended to include OCR of handwritten characters of Arabic\nalphabet.", 
    "link": "http://arxiv.org/pdf/1003.1894v1", 
    "arxiv-id": "1003.1894v1"
},{
    "category": "cs.CV", 
    "author": "Roman Kvetnyy", 
    "title": "Pattern recognition using inverse resonance filtration", 
    "publish": "2010-03-16T22:30:12Z", 
    "summary": "An approach to textures pattern recognition based on inverse resonance\nfiltration (IRF) is considered. A set of principal resonance harmonics of\ntextured image signal fluctuations eigen harmonic decomposition (EHD) is used\nfor the IRF design. It was shown that EHD is invariant to textured image linear\nshift. The recognition of texture is made by transfer of its signal into\nunstructured signal which simple statistical parameters can be used for texture\npattern recognition. Anomalous variations of this signal point on foreign\nobjects. Two methods of 2D EHD parameters estimation are considered with the\naccount of texture signal breaks presence. The first method is based on the\nlinear symmetry model that is not sensitive to signal phase jumps. The\ncondition of characteristic polynomial symmetry provides the model stationarity\nand periodicity. Second method is based on the eigenvalues problem of matrices\npencil projection into principal vectors space of singular values decomposition\n(SVD) of 2D correlation matrix. Two methods of classification of retrieval from\ntextured image foreign objects are offered.", 
    "link": "http://arxiv.org/pdf/1003.3266v1", 
    "arxiv-id": "1003.3266v1"
},{
    "category": "cs.CV", 
    "author": "D. Manjula", 
    "title": "Sliding window approach based Text Binarisation from Complex Textual   images", 
    "publish": "2010-03-18T19:01:56Z", 
    "summary": "Text binarisation process classifies individual pixels as text or background\nin the textual images. Binarization is necessary to bridge the gap between\nlocalization and recognition by OCR. This paper presents Sliding window method\nto binarise text from textual images with textured background. Suitable\npreprocessing techniques are applied first to increase the contrast of the\nimage and blur the background noises due to textured background. Then Edges are\ndetected by iterative thresholding. Subsequently formed edge boxes are analyzed\nto remove unwanted edges due to complex background and binarised by sliding\nwindow approach based character size uniformity check algorithm. The proposed\nmethod has been applied on localized region from heterogeneous textual images\nand compared with Otsu, Niblack methods and shown encouraging performance of\nthe proposed method.", 
    "link": "http://arxiv.org/pdf/1003.3654v1", 
    "arxiv-id": "1003.3654v1"
},{
    "category": "cs.CV", 
    "author": "Vitaly Pimenov", 
    "title": "System-theoretic approach to image interest point detection", 
    "publish": "2010-03-21T20:21:09Z", 
    "summary": "Interest point detection is a common task in various computer vision\napplications. Although a big variety of detector are developed so far\ncomputational efficiency of interest point based image analysis remains to be\nthe problem. Current paper proposes a system-theoretic approach to interest\npoint detection. Starting from the analysis of interdependency between detector\nand descriptor it is shown that given a descriptor it is possible to introduce\nto notion of detector redundancy. Furthermore for each detector it is possible\nto construct its irredundant and equivalent modification. Modified detector\npossesses lower computational complexity and is preferable. It is also shown\nthat several known approaches to reduce computational complexity of image\nregistration can be generalized in terms of proposed theory.", 
    "link": "http://arxiv.org/pdf/1003.4021v1", 
    "arxiv-id": "1003.4021v1"
},{
    "category": "cs.CV", 
    "author": "Himanshu Aggarwal", 
    "title": "A Comprehensive Review of Image Enhancement Techniques", 
    "publish": "2010-03-22T03:39:46Z", 
    "summary": "Principle objective of Image enhancement is to process an image so that\nresult is more suitable than original image for specific application. Digital\nimage enhancement techniques provide a multitude of choices for improving the\nvisual quality of images. Appropriate choice of such techniques is greatly\ninfluenced by the imaging modality, task at hand and viewing conditions. This\npaper will provide an overview of underlying concepts, along with algorithms\ncommonly used for image enhancement. The paper focuses on spatial domain\ntechniques for image enhancement, with particular reference to point processing\nmethods and histogram processing.", 
    "link": "http://arxiv.org/pdf/1003.4053v1", 
    "arxiv-id": "1003.4053v1"
},{
    "category": "cs.CV", 
    "author": "M. K. Ghose", 
    "title": "Land-cover Classification and Mapping for Eastern Himalayan State Sikkim", 
    "publish": "2010-03-22T06:49:30Z", 
    "summary": "Area of classifying satellite imagery has become a challenging task in\ncurrent era where there is tremendous growth in settlement i.e. construction of\nbuildings, roads, bridges, dam etc. This paper suggests an improvised k-means\nand Artificial Neural Network (ANN) classifier for land-cover mapping of\nEastern Himalayan state Sikkim. The improvised k-means algorithm shows\nsatisfactory results compared to existing methods that includes k-Nearest\nNeighbor and maximum likelihood classifier. The strength of the Artificial\nNeural Network (ANN) classifier lies in the fact that they are fast and have\ngood recognition rate and it's capability of self-learning compared to other\nclassification algorithms has made it widely accepted. Classifier based on ANN\nshows satisfactory and accurate result in comparison with the classical method.", 
    "link": "http://arxiv.org/pdf/1003.4087v1", 
    "arxiv-id": "1003.4087v1"
},{
    "category": "cs.CV", 
    "author": "Bruno Jedynak", 
    "title": "Active Testing for Face Detection and Localization", 
    "publish": "2010-03-27T00:17:19Z", 
    "summary": "We provide a novel search technique, which uses a hierarchical model and a\nmutual information gain heuristic to efficiently prune the search space when\nlocalizing faces in images. We show exponential gains in computation over\ntraditional sliding window approaches, while keeping similar performance\nlevels.", 
    "link": "http://arxiv.org/pdf/1003.5249v1", 
    "arxiv-id": "1003.5249v1"
},{
    "category": "cs.CV", 
    "author": "Ron Kimmel", 
    "title": "The Video Genome", 
    "publish": "2010-03-27T20:57:47Z", 
    "summary": "Fast evolution of Internet technologies has led to an explosive growth of\nvideo data available in the public domain and created unprecedented challenges\nin the analysis, organization, management, and control of such content. The\nproblems encountered in video analysis such as identifying a video in a large\ndatabase (e.g. detecting pirated content in YouTube), putting together video\nfragments, finding similarities and common ancestry between different versions\nof a video, have analogous counterpart problems in genetic research and\nanalysis of DNA and protein sequences. In this paper, we exploit the analogy\nbetween genetic sequences and videos and propose an approach to video analysis\nmotivated by genomic research. Representing video information as video DNA\nsequences and applying bioinformatic algorithms allows to search, match, and\ncompare videos in large-scale databases. We show an application for\ncontent-based metadata mapping between versions of annotated video.", 
    "link": "http://arxiv.org/pdf/1003.5320v1", 
    "arxiv-id": "1003.5320v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "Tuning CLD Maps", 
    "publish": "2010-03-30T13:58:08Z", 
    "summary": "The Coherence Length Diagram and the related maps have been shown to\nrepresent a useful tool for image analysis. Setting threshold parameters is one\nof the most important issues when dealing with such applications, as they\naffect both the computability, which is outlined by the support map, and the\nappearance of the coherence length diagram itself and of defect maps. A coupled\noptimization analysis, returning a range for the basic (saturation) threshold,\nand a histogram based method, yielding suitable values for a desired map\nappearance, are proposed for an effective control of the analysis process.", 
    "link": "http://arxiv.org/pdf/1003.5821v1", 
    "arxiv-id": "1003.5821v1"
},{
    "category": "cs.CV", 
    "author": "Jamuna Kanta Sing", 
    "title": "Robust multi-camera view face recognition", 
    "publish": "2010-03-30T16:26:39Z", 
    "summary": "This paper presents multi-appearance fusion of Principal Component Analysis\n(PCA) and generalization of Linear Discriminant Analysis (LDA) for multi-camera\nview offline face recognition (verification) system. The generalization of LDA\nhas been extended to establish correlations between the face classes in the\ntransformed representation and this is called canonical covariate. The proposed\nsystem uses Gabor filter banks for characterization of facial features by\nspatial frequency, spatial locality and orientation to make compensate to the\nvariations of face instances occurred due to illumination, pose and facial\nexpression changes. Convolution of Gabor filter bank to face images produces\nGabor face representations with high dimensional feature vectors. PCA and\ncanonical covariate are then applied on the Gabor face representations to\nreduce the high dimensional feature spaces into low dimensional Gabor\neigenfaces and Gabor canonical faces. Reduced eigenface vector and canonical\nface vector are fused together using weighted mean fusion rule. Finally,\nsupport vector machines (SVM) have trained with augmented fused set of features\nand perform the recognition task. The system has been evaluated with UMIST face\ndatabase consisting of multiview faces. The experimental results demonstrate\nthe efficiency and robustness of the proposed system for multi-view face images\nwith high recognition rates. Complexity analysis of the proposed system is also\npresented at the end of the experimental results.", 
    "link": "http://arxiv.org/pdf/1003.5861v1", 
    "arxiv-id": "1003.5861v1"
},{
    "category": "cs.CV", 
    "author": "Subhadip Basu", 
    "title": "Development of a multi-user handwriting recognition system using   Tesseract open source OCR engine", 
    "publish": "2010-03-30T18:22:44Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of lower case\nRoman script using Tesseract open source Optical Character Recognition (OCR)\nengine under Apache License 2.0. Handwritten data samples containing isolated\nand free-flow text were collected from different users. Tesseract is trained\nwith user-specific data samples of both the categories of document pages to\ngenerate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated and free-flow handwritten test samples\ncollected from the designated user. On a three user model, the system is\ntrained with 1844, 1535 and 1113 isolated handwritten character samples\ncollected from three different users and the performance is tested on 1133,\n1186 and 1204 character samples, collected form the test sets of the three\nusers respectively. The user specific character level accuracies were obtained\nas 87.92%, 81.53% and 65.71% respectively. The overall character-level accuracy\nof the system is observed as 78.39%. The system fails to segment 10.96%\ncharacters and erroneously classifies 10.65% characters on the overall dataset.", 
    "link": "http://arxiv.org/pdf/1003.5886v1", 
    "arxiv-id": "1003.5886v1"
},{
    "category": "cs.CV", 
    "author": "Subhadip Basu", 
    "title": "Recognition of Handwritten Roman Script Using Tesseract Open source OCR   Engine", 
    "publish": "2010-03-30T18:35:37Z", 
    "summary": "In the present work, we have used Tesseract 2.01 open source Optical\nCharacter Recognition (OCR) Engine under Apache License 2.0 for recognition of\nhandwriting samples of lower case Roman script. Handwritten isolated and\nfree-flow text samples were collected from multiple users. Tesseract is trained\nto recognize user-specific handwriting samples of both the categories of\ndocument pages. On a single user model, the system is trained with 1844\nisolated handwritten characters and the performance is tested on 1133\ncharacters, taken form the test set. The overall character-level accuracy of\nthe system is observed as 83.5%. The system fails to segment 5.56% characters\nand erroneously classifies 10.94% characters.", 
    "link": "http://arxiv.org/pdf/1003.5891v1", 
    "arxiv-id": "1003.5891v1"
},{
    "category": "cs.CV", 
    "author": "Hisashi Ikeda", 
    "title": "Recognition of Handwritten Textual Annotations using Tesseract Open   Source OCR Engine for information Just In Time (iJIT)", 
    "publish": "2010-03-30T18:48:47Z", 
    "summary": "Objective of the current work is to develop an Optical Character Recognition\n(OCR) engine for information Just In Time (iJIT) system that can be used for\nrecognition of handwritten textual annotations of lower case Roman script.\nTesseract open source OCR engine under Apache License 2.0 is used to develop\nuser-specific handwriting recognition models, viz., the language sets, for the\nsaid system, where each user is identified by a unique identification tag\nassociated with the digital pen. To generate the language set for any user,\nTesseract is trained with labeled handwritten data samples of isolated and\nfree-flow texts of Roman script, collected exclusively from that user. The\ndesigned system is tested on five different language sets with free- flow\nhandwritten annotations as test samples. The system could successfully segment\nand subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80%\nhandwritten characters in the test samples of five different users.", 
    "link": "http://arxiv.org/pdf/1003.5893v1", 
    "arxiv-id": "1003.5893v1"
},{
    "category": "cs.CV", 
    "author": "Subhadip Basu", 
    "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla   Basic Characters and Digits", 
    "publish": "2010-03-30T18:54:57Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset.", 
    "link": "http://arxiv.org/pdf/1003.5897v1", 
    "arxiv-id": "1003.5897v1"
},{
    "category": "cs.CV", 
    "author": "Subhadip Basu", 
    "title": "Recognition of handwritten Roman Numerals using Tesseract open source   OCR engine", 
    "publish": "2010-03-30T18:59:49Z", 
    "summary": "The objective of the paper is to recognize handwritten samples of Roman\nnumerals using Tesseract open source Optical Character Recognition (OCR)\nengine. Tesseract is trained with data samples of different persons to generate\none user-independent language model, representing the handwritten Roman\ndigit-set. The system is trained with 1226 digit samples collected form the\ndifferent users. The performance is tested on two different datasets, one\nconsisting of samples collected from the known users (those who prepared the\ntraining data samples) and the other consisting of handwritten data samples of\nunknown users. The overall recognition accuracy is obtained as 92.1% and 86.59%\non these test datasets respectively.", 
    "link": "http://arxiv.org/pdf/1003.5898v1", 
    "arxiv-id": "1003.5898v1"
},{
    "category": "cs.CV", 
    "author": "Dipak Kumar Basu", 
    "title": "Development of an automated Red Light Violation Detection System (RLVDS)   for Indian vehicles", 
    "publish": "2010-03-31T13:44:29Z", 
    "summary": "Integrated Traffic Management Systems (ITMS) are now implemented in different\ncities in India to primarily address the concerns of road-safety and security.\nAn automated Red Light Violation Detection System (RLVDS) is an integral part\nof the ITMS. In our present work we have designed and developed a complete\nsystem for generating the list of all stop-line violating vehicle images\nautomatically from video snapshots of road-side surveillance cameras. The\nsystem first generates adaptive background images for each camera view,\nsubtracts captured images from the corresponding background images and analyses\npotential occlusions over the stop-line in a traffic signal. Considering\nround-the-clock operations in a real-life test environment, the developed\nsystem could successfully track 92% images of vehicles with violations on the\nstop-line in a \"Red\" traffic signal.", 
    "link": "http://arxiv.org/pdf/1003.6052v2", 
    "arxiv-id": "1003.6052v2"
},{
    "category": "cs.CV", 
    "author": "Dipak Kumar Basu", 
    "title": "A novel scheme for binarization of vehicle images using hierarchical   histogram equalization technique", 
    "publish": "2010-03-31T14:00:16Z", 
    "summary": "Automatic License Plate Recognition system is a challenging area of research\nnow-a-days and binarization is an integral and most important part of it. In\ncase of a real life scenario, most of existing methods fail to properly\nbinarize the image of a vehicle in a congested road, captured through a CCD\ncamera. In the current work we have applied histogram equalization technique\nover the complete image and also over different hierarchy of image\npartitioning. A novel scheme is formulated for giving the membership value to\neach pixel for each hierarchy of histogram equalization. Then the image is\nbinarized depending on the net membership value of each pixel. The technique is\nexhaustively evaluated on the vehicle image dataset as well as the license\nplate dataset, giving satisfactory performances.", 
    "link": "http://arxiv.org/pdf/1003.6059v2", 
    "arxiv-id": "1003.6059v2"
},{
    "category": "cs.CV", 
    "author": "Ali A. Kiaei", 
    "title": "Analysis, Interpretation, and Recognition of Facial Action Units and   Expressions Using Neuro-Fuzzy Modeling", 
    "publish": "2010-04-04T15:20:27Z", 
    "summary": "In this paper an accurate real-time sequence-based system for representation,\nrecognition, interpretation, and analysis of the facial action units (AUs) and\nexpressions is presented. Our system has the following characteristics: 1)\nemploying adaptive-network-based fuzzy inference systems (ANFIS) and temporal\ninformation, we developed a classification scheme based on neuro-fuzzy modeling\nof the AU intensity, which is robust to intensity variations, 2) using both\ngeometric and appearance-based features, and applying efficient dimension\nreduction techniques, our system is robust to illumination changes and it can\nrepresent the subtle changes as well as temporal information involved in\nformation of the facial expressions, and 3) by continuous values of intensity\nand employing top-down hierarchical rule-based classifiers, we can develop\naccurate human-interpretable AU-to-expression converters. Extensive experiments\non Cohn-Kanade database show the superiority of the proposed method, in\ncomparison with support vector machines, hidden Markov models, and neural\nnetwork classifiers. Keywords: biased discriminant analysis (BDA), classifier\ndesign and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy\nmodeling.", 
    "link": "http://arxiv.org/pdf/1004.0512v1", 
    "arxiv-id": "1004.0512v1"
},{
    "category": "cs.CV", 
    "author": "Oleg Michailovich", 
    "title": "Regularized Richardson-Lucy Algorithm for Sparse Reconstruction of   Poissonian Images", 
    "publish": "2010-04-08T01:08:30Z", 
    "summary": "Restoration of digital images from their degraded measurements has always\nbeen a problem of great theoretical and practical importance in numerous\napplications of imaging sciences. A specific solution to the problem of image\nrestoration is generally determined by the nature of degradation phenomenon as\nwell as by the statistical properties of measurement noises. The present study\nis concerned with the case in which the images of interest are corrupted by\nconvolutional blurs and Poisson noises. To deal with such problems, there\nexists a range of solution methods which are based on the principles\noriginating from the fixed-point algorithm of Richardson and Lucy (RL). In this\npaper, we provide conceptual and experimental proof that such methods tend to\nconverge to sparse solutions, which makes them applicable only to those images\nwhich can be represented by a relatively small number of non-zero samples in\nthe spatial domain. Unfortunately, the set of such images is relatively small,\nwhich restricts the applicability of RL-type methods. On the other hand,\nvirtually all practical images admit sparse representations in the domain of a\nproperly designed linear transform. To take advantage of this fact, it is\ntherefore tempting to modify the RL algorithm so as to make it recover\nrepresentation coefficients, rather than the values of their associated image.\nSuch modification is introduced in this paper. Apart from the generality of its\nassumptions, the proposed method is also superior to many established\nreconstruction approaches in terms of estimation accuracy and computational\ncomplexity. This and other conclusions of this study are validated through a\nseries of numerical experiments.", 
    "link": "http://arxiv.org/pdf/1004.1215v1", 
    "arxiv-id": "1004.1215v1"
},{
    "category": "cs.CV", 
    "author": "Ahmed H. Samak", 
    "title": "Signature Recognition using Multi Scale Fourier Descriptor And Wavelet   Transform", 
    "publish": "2010-04-08T02:39:49Z", 
    "summary": "This paper present a novel off-line signature recognition method based on\nmulti scale Fourier Descriptor and wavelet transform . The main steps of\nconstructing a signature recognition system are discussed and experiments on\nreal data sets show that the average error rate can reach 1%. Finally we\ncompare 8 distance measures between feature vectors with respect to the\nrecognition performance.\n  Key words: signature recognition; Fourier Descriptor; Wavelet transform;\npersonal verification", 
    "link": "http://arxiv.org/pdf/1004.1227v1", 
    "arxiv-id": "1004.1227v1"
},{
    "category": "cs.CV", 
    "author": "K. Senthamaraikannan", 
    "title": "A Robust Fuzzy Clustering Technique with Spatial Neighborhood   Information for Effective Medical Image Segmentation", 
    "publish": "2010-04-10T04:04:12Z", 
    "summary": "Medical image segmentation demands an efficient and robust segmentation\nalgorithm against noise. The conventional fuzzy c-means algorithm is an\nefficient clustering algorithm that is used in medical image segmentation. But\nFCM is highly vulnerable to noise since it uses only intensity values for\nclustering the images. This paper aims to develop a novel and efficient fuzzy\nspatial c-means clustering algorithm which is robust to noise. The proposed\nclustering algorithm uses fuzzy spatial information to calculate membership\nvalue. The input image is clustered using proposed ISFCM algorithm. A\ncomparative study has been made between the conventional FCM and proposed\nISFCM. The proposed approach is found to be outperforming the conventional FCM.", 
    "link": "http://arxiv.org/pdf/1004.1679v1", 
    "arxiv-id": "1004.1679v1"
},{
    "category": "cs.CV", 
    "author": "P. Thangaraj", 
    "title": "A New Approach to Lung Image Segmentation using Fuzzy Possibilistic   C-Means Algorithm", 
    "publish": "2010-04-11T08:01:08Z", 
    "summary": "Image segmentation is a vital part of image processing. Segmentation has its\napplication widespread in the field of medical images in order to diagnose\ncurious diseases. The same medical images can be segmented manually. But the\naccuracy of image segmentation using the segmentation algorithms is more when\ncompared with the manual segmentation. In the field of medical diagnosis an\nextensive diversity of imaging techniques is presently available, such as\nradiography, computed tomography (CT) and magnetic resonance imaging (MRI).\nMedical image segmentation is an essential step for most consequent image\nanalysis tasks. Although the original FCM algorithm yields good results for\nsegmenting noise free images, it fails to segment images corrupted by noise,\noutliers and other imaging artifact. This paper presents an image segmentation\napproach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic\nc-means algorithm (FPCM). This approach is a generalized version of standard\nFuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM\ntechnique is eliminated in modifying the standard technique. The Modified FCM\nalgorithm is formulated by modifying the distance measurement of the standard\nFCM algorithm to permit the labeling of a pixel to be influenced by other\npixels and to restrain the noise effect during segmentation. Instead of having\none term in the objective function, a second term is included, forcing the\nmembership to be as high as possible without a maximum limit constraint of one.\nExperiments are conducted on real images to investigate the performance of the\nproposed modified FCM technique in segmenting the medical images. Standard FCM,\nModified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to\nexplore the accuracy of our proposed approach.", 
    "link": "http://arxiv.org/pdf/1004.1768v1", 
    "arxiv-id": "1004.1768v1"
},{
    "category": "cs.CV", 
    "author": "Jamuna Kanta Sing", 
    "title": "Feature Level Fusion of Face and Palmprint Biometrics by Isomorphic   Graph-based Improved K-Medoids Partitioning", 
    "publish": "2010-04-12T07:34:39Z", 
    "summary": "This paper presents a feature level fusion approach which uses the improved\nK-medoids clustering algorithm and isomorphic graph for face and palmprint\nbiometrics. Partitioning around medoids (PAM) algorithm is used to partition\nthe set of n invariant feature points of the face and palmprint images into k\nclusters. By partitioning the face and palmprint images with scale invariant\nfeatures SIFT points, a number of clusters is formed on both the images. Then\non each cluster, an isomorphic graph is drawn. In the next step, the most\nprobable pair of graphs is searched using iterative relaxation algorithm from\nall possible isomorphic graphs for a pair of corresponding face and palmprint\nimages. Finally, graphs are fused by pairing the isomorphic graphs into\naugmented groups in terms of addition of invariant SIFT points and in terms of\ncombining pair of keypoint descriptors by concatenation rule. Experimental\nresults obtained from the extensive evaluation show that the proposed feature\nlevel fusion with the improved K-medoids partitioning algorithm increases the\nperformance of the system with utmost level of accuracy.", 
    "link": "http://arxiv.org/pdf/1004.1886v1", 
    "arxiv-id": "1004.1886v1"
},{
    "category": "cs.CV", 
    "author": "Massimo Tistarelli", 
    "title": "Maximized Posteriori Attributes Selection from Facial Salient Landmarks   for Face Recognition", 
    "publish": "2010-04-12T07:42:09Z", 
    "summary": "This paper presents a robust and dynamic face recognition technique based on\nthe extraction and matching of devised probabilistic graphs drawn on SIFT\nfeatures related to independent face areas. The face matching strategy is based\non matching individual salient facial graph characterized by SIFT features as\nconnected to facial landmarks such as the eyes and the mouth. In order to\nreduce the face matching errors, the Dempster-Shafer decision theory is applied\nto fuse the individual matching scores obtained from each pair of salient\nfacial features. The proposed algorithm is evaluated with the ORL and the IITK\nface databases. The experimental results demonstrate the effectiveness and\npotential of the proposed face recognition technique also in case of partially\noccluded faces.", 
    "link": "http://arxiv.org/pdf/1004.1887v1", 
    "arxiv-id": "1004.1887v1"
},{
    "category": "cs.CV", 
    "author": "Ritu Tiwari", 
    "title": "Offline Handwriting Recognition using Genetic Algorithm", 
    "publish": "2010-04-19T17:49:28Z", 
    "summary": "Handwriting Recognition enables a person to scribble something on a piece of\npaper and then convert it into text. If we look into the practical reality\nthere are enumerable styles in which a character may be written. These styles\ncan be self combined to generate more styles. Even if a small child knows the\nbasic styles a character can be written, he would be able to recognize\ncharacters written in styles intermediate between them or formed by their\nmixture. This motivates the use of Genetic Algorithms for the problem. In order\nto prove this, we made a pool of images of characters. We converted them to\ngraphs. The graph of every character was intermixed to generate styles\nintermediate between the styles of parent character. Character recognition\ninvolved the matching of the graph generated from the unknown character image\nwith the graphs generated by mixing. Using this method we received an accuracy\nof 98.44%.", 
    "link": "http://arxiv.org/pdf/1004.3257v1", 
    "arxiv-id": "1004.3257v1"
},{
    "category": "cs.CV", 
    "author": "V. H. Patil", 
    "title": "Color Image Compression Based On Wavelet Packet Best Tree", 
    "publish": "2010-04-19T18:28:46Z", 
    "summary": "In Image Compression, the researchers' aim is to reduce the number of bits\nrequired to represent an image by removing the spatial and spectral\nredundancies. Recently discrete wavelet transform and wavelet packet has\nemerged as popular techniques for image compression. The wavelet transform is\none of the major processing components of image compression. The result of the\ncompression changes as per the basis and tap of the wavelet used. It is\nproposed that proper selection of mother wavelet on the basis of nature of\nimages, improve the quality as well as compression ratio remarkably. We suggest\nthe novel technique, which is based on wavelet packet best tree based on\nThreshold Entropy with enhanced run-length encoding. This method reduces the\ntime complexity of wavelet packets decomposition as complete tree is not\ndecomposed. Our algorithm selects the sub-bands, which include significant\ninformation based on threshold entropy. The enhanced run length encoding\ntechnique is suggested provides better results than RLE. The result when\ncompared with JPEG-2000 proves to be better.", 
    "link": "http://arxiv.org/pdf/1004.3276v1", 
    "arxiv-id": "1004.3276v1"
},{
    "category": "cs.CV", 
    "author": "Islam H. AlTarawneh", 
    "title": "Signature Region of Interest using Auto cropping", 
    "publish": "2010-04-20T20:04:17Z", 
    "summary": "A new approach for signature region of interest pre-processing was presented.\nIt used new auto cropping preparation on the basis of the image content, where\nthe intensity value of pixel is the source of cropping. This approach provides\nboth the possibility of improving the performance of security systems based on\nsignature images, and also the ability to use only the region of interest of\nthe used image to suit layout design of biometric systems. Underlying the\napproach is a novel segmentation method which identifies the exact region of\nforeground of signature for feature extraction usage. Evaluation results of\nthis approach shows encouraging prospects by eliminating the need for false\nregion isolating, reduces the time cost associated with signature false points\ndetection, and addresses enhancement issues. A further contribution of this\npaper is an automated cropping stage in bio-secure based systems.", 
    "link": "http://arxiv.org/pdf/1004.3549v1", 
    "arxiv-id": "1004.3549v1"
},{
    "category": "cs.CV", 
    "author": "Jun-ichi Inoue", 
    "title": "Simultaneous Bayesian inference of motion velocity fields and   probabilistic models in successive video-frames described by spatio-temporal   MRFs", 
    "publish": "2010-04-21T06:27:47Z", 
    "summary": "We numerically investigate a mean-field Bayesian approach with the assistance\nof the Markov chain Monte Carlo method to estimate motion velocity fields and\nprobabilistic models simultaneously in consecutive digital images described by\nspatio-temporal Markov random fields. Preliminary to construction of our\nprocedure, we find that mean-field variables in the iteration diverge due to\nimproper normalization factor of regularization terms appearing in the\nposterior. To avoid this difficulty, we rescale the regularization term by\nintroducing a scaling factor and optimizing it by means of minimization of the\nmean-square error. We confirm that the optimal scaling factor stabilizes the\nmean-field iterative process of the motion velocity estimation. We next attempt\nto estimate the optimal values of hyper-parameters including the regularization\nterm, which define our probabilistic model macroscopically, by using the\nBoltzmann-machine type learning algorithm based on gradient descent of marginal\nlikelihood (type-II likelihood) with respect to the hyper-parameters. In our\nframework, one can estimate both the probabilistic model (hyper-parameters) and\nmotion velocity fields simultaneously. We find that our motion estimation is\nmuch better than the result obtained by Zhang and Hanouer (1995) in which the\nhyper-parameters are set to some ad-hoc values without any theoretical\njustification.", 
    "link": "http://arxiv.org/pdf/1004.3629v1", 
    "arxiv-id": "1004.3629v1"
},{
    "category": "cs.CV", 
    "author": "Mithun Das Gupta", 
    "title": "Hashing Image Patches for Zooming", 
    "publish": "2010-04-22T18:42:03Z", 
    "summary": "In this paper we present a Bayesian image zooming/super-resolution algorithm\nbased on a patch based representation. We work on a patch based model with\noverlap and employ a Locally Linear Embedding (LLE) based approach as our data\nfidelity term in the Bayesian inference. The image prior imposes continuity\nconstraints across the overlapping patches. We apply an error back-projection\ntechnique, with an approximate cross bilateral filter. The problem of nearest\nneighbor search is handled by a variant of the locality sensitive hashing (LSH)\nscheme. The novelty of our work lies in the speed up achieved by the hashing\nscheme and the robustness and inherent modularity and parallel structure\nachieved by the LLE setup. The ill-posedness of the image reconstruction\nproblem is handled by the introduction of regularization priors which encode\nthe knowledge present in vast collections of natural images. We present\ncomparative results for both run-time as well as visual image quality based\nmeasurements.", 
    "link": "http://arxiv.org/pdf/1004.3980v1", 
    "arxiv-id": "1004.3980v1"
},{
    "category": "cs.CV", 
    "author": "Michael Elad", 
    "title": "Spatially-Adaptive Reconstruction in Computed Tomography Based on   Statistical Learning", 
    "publish": "2010-04-25T19:10:26Z", 
    "summary": "We propose a direct reconstruction algorithm for Computed Tomography, based\non a local fusion of a few preliminary image estimates by means of a non-linear\nfusion rule. One such rule is based on a signal denoising technique which is\nspatially adaptive to the unknown local smoothness. Another, more powerful\nfusion rule, is based on a neural network trained off-line with a high-quality\ntraining set of images. Two types of linear reconstruction algorithms for the\npreliminary images are employed for two different reconstruction tasks. For an\nentire image reconstruction from full projection data, the proposed scheme uses\na sequence of Filtered Back-Projection algorithms with a gradually growing\ncut-off frequency. To recover a Region Of Interest only from local projections,\nstatistically-trained linear reconstruction algorithms are employed. Numerical\nexperiments display the improvement in reconstruction quality when compared to\nlinear reconstruction algorithms.", 
    "link": "http://arxiv.org/pdf/1004.4373v1", 
    "arxiv-id": "1004.4373v1"
},{
    "category": "cs.CV", 
    "author": "Khamitkar S. D", 
    "title": "Deblured Gaussian Blurred Images", 
    "publish": "2010-04-26T09:32:28Z", 
    "summary": "This paper attempts to undertake the study of Restored Gaussian Blurred\nImages. by using four types of techniques of deblurring image as Wiener filter,\nRegularized filter, Lucy Richardson deconvlutin algorithm and Blind\ndeconvlution algorithm with an information of the Point Spread Function (PSF)\ncorrupted blurred image with Different values of Size and Alfa and then\ncorrupted by Gaussian noise. The same is applied to the remote sensing image\nand they are compared with one another, So as to choose the base technique for\nrestored or deblurring image.This paper also attempts to undertake the study of\nrestored Gaussian blurred image with no any information about the Point Spread\nFunction (PSF) by using same four techniques after execute the guess of the\nPSF, the number of iterations and the weight threshold of it. To choose the\nbase guesses for restored or deblurring image of this techniques.", 
    "link": "http://arxiv.org/pdf/1004.4448v1", 
    "arxiv-id": "1004.4448v1"
},{
    "category": "cs.CV", 
    "author": "Er. Anantdeep", 
    "title": "An Efficient Watermarking Algorithm to Improve Payload and Robustness   without Affecting Image Perceptual Quality", 
    "publish": "2010-04-26T10:17:53Z", 
    "summary": "Capacity, Robustness, & Perceptual quality of watermark data are very\nimportant issues to be considered. A lot of research is going on to increase\nthese parameters for watermarking of the digital images, as there is always a\ntradeoff among them. . In this paper an efficient watermarking algorithm to\nimprove payload and robustness without affecting perceptual quality of image\ndata based on DWT is discussed. The aim of the paper is to employ the nested\nwatermarks in wavelet domain which increases the capacity and ultimately the\nrobustness against attacks and selection of different scaling factor values for\nLL & HH bands and during embedding not to create the visible artifacts in the\noriginal image and therefore the original and watermarked image is similar.", 
    "link": "http://arxiv.org/pdf/1004.4467v1", 
    "arxiv-id": "1004.4467v1"
},{
    "category": "cs.CV", 
    "author": "R. K. Fedorov", 
    "title": "Logical methods of object recognition on satellite images using spatial   constraints", 
    "publish": "2010-04-27T13:22:36Z", 
    "summary": "A logical approach to object recognition on image is proposed. The main idea\nof the approach is to perform the object recognition as a logical inference on\na set of rules describing an object shape.", 
    "link": "http://arxiv.org/pdf/1004.4793v1", 
    "arxiv-id": "1004.4793v1"
},{
    "category": "cs.CV", 
    "author": "Gilad Lerman", 
    "title": "Randomized hybrid linear modeling by local best-fit flats", 
    "publish": "2010-05-05T21:46:13Z", 
    "summary": "The hybrid linear modeling problem is to identify a set of d-dimensional\naffine sets in a D-dimensional Euclidean space. It arises, for example, in\nobject tracking and structure from motion. The hybrid linear model can be\nconsidered as the second simplest (behind linear) manifold model of data. In\nthis paper we will present a very simple geometric method for hybrid linear\nmodeling based on selecting a set of local best fit flats that minimize a\nglobal l1 error measure. The size of the local neighborhoods is determined\nautomatically by the Jones' l2 beta numbers; it is proven under certain\ngeometric conditions that good local neighborhoods exist and are found by our\nmethod. We also demonstrate how to use this algorithm for fast determination of\nthe number of affine subspaces. We give extensive experimental evidence\ndemonstrating the state of the art accuracy and speed of the algorithm on\nsynthetic and real hybrid linear data.", 
    "link": "http://arxiv.org/pdf/1005.0858v1", 
    "arxiv-id": "1005.0858v1"
},{
    "category": "cs.CV", 
    "author": "Abdul Ahad Siddiqi", 
    "title": "Multistage Hybrid Arabic/Indian Numeral OCR System", 
    "publish": "2010-05-06T07:25:23Z", 
    "summary": "The use of OCR in postal services is not yet universal and there are still\nmany countries that process mail sorting manually. Automated Arabic/Indian\nnumeral Optical Character Recognition (OCR) systems for Postal services are\nbeing used in some countries, but still there are errors during the mail\nsorting process, thus causing a reduction in efficiency. The need to\ninvestigate fast and efficient recognition algorithms/systems is important so\nas to correctly read the postal codes from mail addresses and to eliminate any\nerrors during the mail sorting stage. The objective of this study is to\nrecognize printed numerical postal codes from mail addresses. The proposed\nsystem is a multistage hybrid system which consists of three different feature\nextraction methods, i.e., binary, zoning, and fuzzy features, and three\ndifferent classifiers, i.e., Hamming Nets, Euclidean Distance, and Fuzzy Neural\nNetwork Classifiers. The proposed system, systematically compares the\nperformance of each of these methods, and ensures that the numerals are\nrecognized correctly. Comprehensive results provide a very high recognition\nrate, outperforming the other known developed methods in literature.", 
    "link": "http://arxiv.org/pdf/1005.0907v1", 
    "arxiv-id": "1005.0907v1"
},{
    "category": "cs.CV", 
    "author": "Phalguni Gupta", 
    "title": "An Efficient Vein Pattern-based Recognition System", 
    "publish": "2010-05-06T09:34:21Z", 
    "summary": "This paper presents an efficient human recognition system based on vein\npattern from the palma dorsa. A new absorption based technique has been\nproposed to collect good quality images with the help of a low cost camera and\nlight source. The system automatically detects the region of interest from the\nimage and does the necessary preprocessing to extract features. A Euclidean\nDistance based matching technique has been used for making the decision. It has\nbeen tested on a data set of 1750 image samples collected from 341 individuals.\nThe accuracy of the verification system is found to be 99.26% with false\nrejection rate (FRR) of 0.03%.", 
    "link": "http://arxiv.org/pdf/1005.0945v1", 
    "arxiv-id": "1005.0945v1"
},{
    "category": "cs.CV", 
    "author": "Pierre Vandergheynst", 
    "title": "Classification via Incoherent Subspaces", 
    "publish": "2010-05-10T08:49:56Z", 
    "summary": "This article presents a new classification framework that can extract\nindividual features per class. The scheme is based on a model of incoherent\nsubspaces, each one associated to one class, and a model on how the elements in\na class are represented in this subspace. After the theoretical analysis an\nalternate projection algorithm to find such a collection is developed. The\nclassification performance and speed of the proposed method is tested on the AR\nand YaleB databases and compared to that of Fisher's LDA and a recent approach\nbased on on $\\ell_1$ minimisation. Finally connections of the presented scheme\nto already existing work are discussed and possible ways of extensions are\npointed out.", 
    "link": "http://arxiv.org/pdf/1005.1471v1", 
    "arxiv-id": "1005.1471v1"
},{
    "category": "cs.CV", 
    "author": "Stefanos Zafeiriou", 
    "title": "On the Subspace of Image Gradient Orientations", 
    "publish": "2010-05-16T00:31:19Z", 
    "summary": "We introduce the notion of Principal Component Analysis (PCA) of image\ngradient orientations. As image data is typically noisy, but noise is\nsubstantially different from Gaussian, traditional PCA of pixel intensities\nvery often fails to estimate reliably the low-dimensional subspace of a given\ndata population. We show that replacing intensities with gradient orientations\nand the $\\ell_2$ norm with a cosine-based distance measure offers, to some\nextend, a remedy to this problem. Our scheme requires the eigen-decomposition\nof a covariance matrix and is as computationally efficient as standard $\\ell_2$\nPCA. We demonstrate some of its favorable properties on robust subspace\nestimation.", 
    "link": "http://arxiv.org/pdf/1005.2715v1", 
    "arxiv-id": "1005.2715v1"
},{
    "category": "cs.CV", 
    "author": "Khamitkar S. D.", 
    "title": "Image Segmentation by Using Threshold Techniques", 
    "publish": "2010-05-21T17:30:08Z", 
    "summary": "This paper attempts to undertake the study of segmentation image techniques\nby using five threshold methods as Mean method, P-tile method, Histogram\nDependent Technique (HDT), Edge Maximization Technique (EMT) and visual\nTechnique and they are compared with one another so as to choose the best\ntechnique for threshold segmentation techniques image. These techniques applied\non three satellite images to choose base guesses for threshold segmentation\nimage.", 
    "link": "http://arxiv.org/pdf/1005.4020v1", 
    "arxiv-id": "1005.4020v1"
},{
    "category": "cs.CV", 
    "author": "Mahantapas Kundu", 
    "title": "Face Synthesis (FASY) System for Generation of a Face Image from Human   Description", 
    "publish": "2010-05-21T18:03:44Z", 
    "summary": "This paper aims at generating a new face based on the human like description\nusing a new concept. The FASY (FAce SYnthesis) System is a Face Database\nRetrieval and new Face generation System that is under development. One of its\nmain features is the generation of the requested face when it is not found in\nthe existing database, which allows a continuous growing of the database also.", 
    "link": "http://arxiv.org/pdf/1005.4034v1", 
    "arxiv-id": "1005.4034v1"
},{
    "category": "cs.CV", 
    "author": "Mahantapas Kundu", 
    "title": "Classification of Polar-Thermal Eigenfaces using Multilayer Perceptron   for Human Face Recognition", 
    "publish": "2010-05-21T18:07:42Z", 
    "summary": "This paper presents a novel approach to handle the challenges of face\nrecognition. In this work thermal face images are considered, which minimizes\nthe affect of illumination changes and occlusion due to moustache, beards,\nadornments etc. The proposed approach registers the training and testing\nthermal face images in polar coordinate, which is capable to handle\ncomplicacies introduced by scaling and rotation. Polar images are projected\ninto eigenspace and finally classified using a multi-layer perceptron. In the\nexperiments we have used Object Tracking and Classification Beyond Visible\nSpectrum (OTCBVS) database benchmark thermal face images. Experimental results\nshow that the proposed approach significantly improves the verification and\nidentification performance and the success rate is 97.05%.", 
    "link": "http://arxiv.org/pdf/1005.4035v1", 
    "arxiv-id": "1005.4035v1"
},{
    "category": "cs.CV", 
    "author": "M. Kundu", 
    "title": "Reduction of Feature Vectors Using Rough Set Theory for Human Face   Recognition", 
    "publish": "2010-05-21T19:13:39Z", 
    "summary": "In this paper we describe a procedure to reduce the size of the input feature\nvector. A complex pattern recognition problem like face recognition involves\nhuge dimension of input feature vector. To reduce that dimension here we have\nused eigenspace projection (also called as Principal Component Analysis), which\nis basically transformation of space. To reduce further we have applied feature\nselection method to select indispensable features, which will remain in the\nfinal feature vectors. Features those are not selected are removed from the\nfinal feature vector considering them as redundant or superfluous. For\nselection of features we have used the concept of reduct and core from rough\nset theory. This method has shown very good performance. It is worth to mention\nthat in some cases the recognition rate increases with the decrease in the\nfeature vector dimension.", 
    "link": "http://arxiv.org/pdf/1005.4044v1", 
    "arxiv-id": "1005.4044v1"
},{
    "category": "cs.CV", 
    "author": "Hanxi Li", 
    "title": "LACBoost and FisherBoost: Optimally Building Cascade Classifiers", 
    "publish": "2010-05-22T04:22:57Z", 
    "summary": "Object detection is one of the key tasks in computer vision. The cascade\nframework of Viola and Jones has become the de facto standard. A classifier in\neach node of the cascade is required to achieve extremely high detection rates,\ninstead of low overall classification error. Although there are a few reported\nmethods addressing this requirement in the context of object detection, there\nis no a principled feature selection method that explicitly takes into account\nthis asymmetric node learning objective. We provide such a boosting algorithm\nin this work. It is inspired by the linear asymmetric classifier (LAC) of Wu et\nal. in that our boosting algorithm optimizes a similar cost function. The new\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on face detection\nsuggest that our proposed boosting algorithms can improve the state-of-the-art\nmethods in detection performance.", 
    "link": "http://arxiv.org/pdf/1005.4103v1", 
    "arxiv-id": "1005.4103v1"
},{
    "category": "cs.CV", 
    "author": "Jian Zhang", 
    "title": "Incremental Training of a Detector Using Online Sparse   Eigen-decomposition", 
    "publish": "2010-05-22T11:05:58Z", 
    "summary": "The ability to efficiently and accurately detect objects plays a very crucial\nrole for many computer vision tasks. Recently, offline object detectors have\nshown a tremendous success. However, one major drawback of offline techniques\nis that a complete set of training data has to be collected beforehand. In\naddition, once learned, an offline detector can not make use of newly arriving\ndata. To alleviate these drawbacks, online learning has been adopted with the\nfollowing objectives: (1) the technique should be computationally and storage\nefficient; (2) the updated classifier must maintain its high classification\naccuracy. In this paper, we propose an effective and efficient framework for\nlearning an adaptive online greedy sparse linear discriminant analysis (GSLDA)\nmodel. Unlike many existing online boosting detectors, which usually apply\nexponential or logistic loss, our online algorithm makes use of LDA's learning\ncriterion that not only aims to maximize the class-separation criterion but\nalso incorporates the asymmetrical property of training data distributions. We\nprovide a better alternative for online boosting algorithms in the context of\ntraining a visual object detector. We demonstrate the robustness and efficiency\nof our methods on handwriting digit and face data sets. Our results confirm\nthat object detection tasks benefit significantly when trained in an online\nmanner.", 
    "link": "http://arxiv.org/pdf/1005.4118v1", 
    "arxiv-id": "1005.4118v1"
},{
    "category": "cs.CV", 
    "author": "K. ThanushKodi", 
    "title": "Classification of LULC Change Detection using Remotely Sensed Data for   Coimbatore City, Tamilnadu, India", 
    "publish": "2010-05-23T18:16:49Z", 
    "summary": "Maps are used to describe far-off places . It is an aid for navigation and\nmilitary strategies. Mapping of the lands are important and the mapping work is\nbased on (i). Natural resource management & development (ii). Information\ntechnology ,(iii). Environmental development ,(iv). Facility management and\n(v). e-governance. The Landuse / Landcover system espoused by almost all\nOrganisations and scientists, engineers and remote sensing community who are\ninvolved in mapping of earth surface features, is a system which is derived\nfrom the united States Geological Survey (USGS) LULC classification system. The\napplication of RS and GIS involves influential of homogeneous zones, drift\nanalysis of land use integration of new area changes or change detection\netc.,National Remote Sensing Agency(NRSA) Govt. of India has devised a\ngeneralized LULC classification system respect to the Indian conditions based\non the various categories of Earth surface features , resolution of available\nsatellite data, capabilities of sensors and present and future applications.\nThe profusion information of the earth surface offered by the high resolution\nsatellite images for remote sensing applications. Using change detection\nmethodologies to extract the target changes in the areas from high resolution\nimages and rapidly updates geodatabase information processing.Traditionally,\nclassification approaches have focused on per-pixel technologies. Pixels within\nareas assumed to be automatically homogeneous are analyzed independently.", 
    "link": "http://arxiv.org/pdf/1005.4216v1", 
    "arxiv-id": "1005.4216v1"
},{
    "category": "cs.CV", 
    "author": "Swati Sheoran", 
    "title": "Application Of Fuzzy System In Segmentation Of MRI Brain Tumor", 
    "publish": "2010-05-24T09:59:08Z", 
    "summary": "Segmentation of images holds an important position in the area of image\nprocessing. It becomes more important whi le typically dealing with medical\nimages where presurgery and post surgery decisions are required for the purpose\nof initiating and speeding up the recovery process. Segmentation of 3-D tumor\nstructures from magnetic resonance images (MRI) is a very challenging problem\ndue to the variability of tumor geometry and intensity patterns. Level set\nevolution combining global smoothness with the flexibility of topology changes\noffers significant advantages over the conventional statistical classification\nfollowed by mathematical morphology. Level set evolution with constant\npropagation needs to be initialized either completely inside or outside the\ntumor and can leak through weak or missing boundary parts. Replacing the\nconstant propagation term by a statistical force overcomes these limitations\nand results in a convergence to a stable solution. Using MR images presenting\ntumors, probabilities for background and tumor regions are calculated from a\npre- and post-contrast difference image and mixture modeling fit of the\nhistogram. The whole image is used for initialization of the level set\nevolution to segment the tumor boundaries.", 
    "link": "http://arxiv.org/pdf/1005.4292v1", 
    "arxiv-id": "1005.4292v1"
},{
    "category": "cs.CV", 
    "author": "Daniel Burfoot", 
    "title": "Compression Rate Method for Empirical Science and Application to   Computer Vision", 
    "publish": "2010-05-27T21:27:43Z", 
    "summary": "This philosophical paper proposes a modified version of the scientific\nmethod, in which large databases are used instead of experimental observations\nas the necessary empirical ingredient. This change in the source of the\nempirical data allows the scientific method to be applied to several aspects of\nphysical reality that previously resisted systematic interrogation. Under the\nnew method, scientific theories are compared by instantiating them as\ncompression programs, and examining the codelengths they achieve on a database\nof measurements related to a phenomenon of interest. Because of the\nimpossibility of compressing random data, \"real world\" data can only be\ncompressed by discovering and exploiting the empirical structure it exhibits.\nThe method also provides a new way of thinking about two longstanding issues in\nthe philosophy of science: the problem of induction and the problem of\ndemarcation.\n  The second part of the paper proposes to reformulate computer vision as an\nempirical science of visual reality, by applying the new method to large\ndatabases of natural images. The immediate goal of the proposed reformulation\nis to repair the chronic difficulties in evaluation experienced by the field of\ncomputer vision. The reformulation should bring a wide range of benefits,\nincluding a substantially increased degree of methodological rigor, the ability\nto justify complex theories without overfitting, a scalable evaluation\nparadigm, and the potential to make systematic progress. A crucial argument is\nthat the change is not especially drastic, because most computer vision tasks\ncan be reformulated as specialized image compression techniques. Finally, a\nconcrete proposal is discussed in which a database is produced by recording\nfrom a roadside video camera, and compression is achieved by developing a\ncomputational understanding of the appearance of moving cars.", 
    "link": "http://arxiv.org/pdf/1005.5181v1", 
    "arxiv-id": "1005.5181v1"
},{
    "category": "cs.CV", 
    "author": "B. Chandra Mohan", 
    "title": "Content Based Image Retrieval Using Exact Legendre Moments and Support   Vector Machine", 
    "publish": "2010-05-29T08:12:16Z", 
    "summary": "Content Based Image Retrieval (CBIR) systems based on shape using invariant\nimage moments, viz., Moment Invariants (MI) and Zernike Moments (ZM) are\navailable in the literature. MI and ZM are good at representing the shape\nfeatures of an image. However, non-orthogonality of MI and poor reconstruction\nof ZM restrict their application in CBIR. Therefore, an efficient and\northogonal moment based CBIR system is needed. Legendre Moments (LM) are\northogonal, computationally faster, and can represent image shape features\ncompactly. CBIR system using Exact Legendre Moments (ELM) for gray scale images\nis proposed in this work. Superiority of the proposed CBIR system is observed\nover other moment based methods, viz., MI and ZM in terms of retrieval\nefficiency and retrieval time. Further, the classification efficiency is\nimproved by employing Support Vector Machine (SVM) classifier. Improved\nretrieval results are obtained over existing CBIR algorithm based on Stacked\nEuler Vector (SERVE) combined with Modified Moment Invariants (MMI).", 
    "link": "http://arxiv.org/pdf/1005.5437v1", 
    "arxiv-id": "1005.5437v1"
},{
    "category": "cs.CV", 
    "author": "Abdelshakour A. Abuzneid", 
    "title": "Detection of Bleeding in Wireless Capsule Endoscopy Images Using Range   Ratio Color", 
    "publish": "2010-05-29T08:25:50Z", 
    "summary": "Wireless Capsule Endoscopy (WCE) is device to detect abnormalities in\ncolon,esophagus,small intestinal and stomach, to distinguish bleeding in WCE\nimages from non bleeding is a hard job by human reviewing and very time\nconsuming. Consequently, automation for classifying bleeding frames not only\nwill expedite the process but will reduce the burden on the doctors. Using the\npurity of the red color we can detect the Bleeding areas in WCE images. But, we\ncould find various intensity of red color values in different parts of the\nsmall intestinal,so it is not enough to depend on the red color feature alone.\nWe select RGB(Red,Green,Blue) because it takes raw level values and it is easy\nto use. In this paper we will put range ratio color for each of R,G,and B.\nTherefore, we divide each image into multiple pixels and apply the range ratio\ncolor condition for each pixel. Then we count the number of the pixels that\nachieved our condition. If the number of pixels grater than zero, then the\nframe is classified as a bleeding type. Otherwise, it is a non-bleeding. Our\nexperimental results show that this method could achieve a very high accuracy\nin detecting bleeding images for the different parts of the small intestinal", 
    "link": "http://arxiv.org/pdf/1005.5439v1", 
    "arxiv-id": "1005.5439v1"
},{
    "category": "cs.CV", 
    "author": "K. R. Radhika", 
    "title": "Biometric Authentication using Nonparametric Methods", 
    "publish": "2010-08-10T11:38:29Z", 
    "summary": "The physiological and behavioral trait is employed to develop biometric\nauthentication systems. The proposed work deals with the authentication of iris\nand signature based on minimum variance criteria. The iris patterns are\npreprocessed based on area of the connected components. The segmented image\nused for authentication consists of the region with large variations in the\ngray level values. The image region is split into quadtree components. The\ncomponents with minimum variance are determined from the training samples. Hu\nmoments are applied on the components. The summation of moment values\ncorresponding to minimum variance components are provided as input vector to\nk-means and fuzzy k-means classifiers. The best performance was obtained for\nMMU database consisting of 45 subjects. The number of subjects with zero False\nRejection Rate [FRR] was 44 and number of subjects with zero False Acceptance\nRate [FAR] was 45. This paper addresses the computational load reduction in\noff-line signature verification based on minimal features using k-means, fuzzy\nk-means, k-nn, fuzzy k-nn and novel average-max approaches. FRR of 8.13% and\nFAR of 10% was achieved using k-nn classifier. The signature is a biometric,\nwhere variations in a genuine case, is a natural expectation. In the genuine\nsignature, certain parts of signature vary from one instance to another. The\nsystem aims to provide simple, fast and robust system using less number of\nfeatures when compared to state of art works.", 
    "link": "http://arxiv.org/pdf/1008.1695v1", 
    "arxiv-id": "1008.1695v1"
},{
    "category": "cs.CV", 
    "author": "Md. Haider Ali", 
    "title": "A Miniature-Based Image Retrieval System", 
    "publish": "2010-08-19T16:38:35Z", 
    "summary": "Due to the rapid development of World Wide Web (WWW) and imaging technology,\nmore and more images are available in the Internet and stored in databases.\nSearching the related images by the querying image is becoming tedious and\ndifficult. Most of the images on the web are compressed by methods based on\ndiscrete cosine transform (DCT) including Joint Photographic Experts\nGroup(JPEG) and H.261. This paper presents an efficient content-based image\nindexing technique for searching similar images using discrete cosine transform\nfeatures. Experimental results demonstrate its superiority with the existing\ntechniques.", 
    "link": "http://arxiv.org/pdf/1008.3346v1", 
    "arxiv-id": "1008.3346v1"
},{
    "category": "cs.CV", 
    "author": "Anton van den Hengel", 
    "title": "Optimally Training a Cascade Classifier", 
    "publish": "2010-08-23T03:06:34Z", 
    "summary": "Cascade classifiers are widely used in real-time object detection. Different\nfrom conventional classifiers that are designed for a low overall\nclassification error rate, a classifier in each node of the cascade is required\nto achieve an extremely high detection rate and moderate false positive rate.\nAlthough there are a few reported methods addressing this requirement in the\ncontext of object detection, there is no a principled feature selection method\nthat explicitly takes into account this asymmetric node learning objective. We\nprovide such an algorithm here. We show a special case of the biased minimax\nprobability machine has the same formulation as the linear asymmetric\nclassifier (LAC) of \\cite{wu2005linear}. We then design a new boosting\nalgorithm that directly optimizes the cost function of LAC. The resulting\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on object detection\nverify the effectiveness of the proposed boosting algorithm as a node\nclassifier in cascade object detection, and show performance better than that\nof the current state-of-the-art.", 
    "link": "http://arxiv.org/pdf/1008.3742v1", 
    "arxiv-id": "1008.3742v1"
},{
    "category": "cs.CV", 
    "author": "Francisco C\u00f3ppola Gonz\u00e1lvez", 
    "title": "Proliferating cell nuclear antigen (PCNA) allows the automatic   identification of follicles in microscopic images of human ovarian tissue", 
    "publish": "2010-08-23T11:37:43Z", 
    "summary": "Human ovarian reserve is defined by the population of nongrowing follicles\n(NGFs) in the ovary. Direct estimation of ovarian reserve involves the\nidentification of NGFs in prepared ovarian tissue. Previous studies involving\nhuman tissue have used hematoxylin and eosin (HE) stain, with NGF populations\nestimated by human examination either of tissue under a microscope, or of\nimages taken of this tissue. In this study we replaced HE with proliferating\ncell nuclear antigen (PCNA), and automated the identification and enumeration\nof NGFs that appear in the resulting microscopic images. We compared the\nautomated estimates to those obtained by human experts, with the \"gold\nstandard\" taken to be the average of the conservative and liberal estimates by\nthree human experts. The automated estimates were within 10% of the \"gold\nstandard\", for images at both 100x and 200x magnifications. Automated analysis\ntook longer than human analysis for several hundred images, not allowing for\nbreaks from analysis needed by humans. Our results both replicate and improve\non those of previous studies involving rodent ovaries, and demonstrate the\nviability of large-scale studies of human ovarian reserve using a combination\nof immunohistochemistry and computational image analysis techniques.", 
    "link": "http://arxiv.org/pdf/1008.3798v1", 
    "arxiv-id": "1008.3798v1"
},{
    "category": "cs.CV", 
    "author": "Zerina Begum", 
    "title": "Comparative Study of Statistical Skin Detection Algorithms for   Sub-Continental Human Images", 
    "publish": "2010-08-25T05:33:04Z", 
    "summary": "Object detection has been a focus of research in human-computer interaction.\nSkin area detection has been a key to different recognitions like face\nrecognition, human motion detection, pornographic and nude image prediction,\netc. Most of the research done in the fields of skin detection has been trained\nand tested on human images of African, Mongolian and Anglo-Saxon ethnic\norigins. Although there are several intensity invariant approaches to skin\ndetection, the skin color of Indian sub-continentals have not been focused\nseparately. The approach of this research is to make a comparative study\nbetween three image segmentation approaches using Indian sub-continental human\nimages, to optimize the detection criteria, and to find some efficient\nparameters to detect the skin area from these images. The experiments observed\nthat HSV color model based approach to Indian sub-continental skin detection is\nmore suitable with considerable success rate of 91.1% true positives and 88.1%\ntrue negatives.", 
    "link": "http://arxiv.org/pdf/1008.4206v1", 
    "arxiv-id": "1008.4206v1"
},{
    "category": "cs.CV", 
    "author": "R. Lakshmipathi", 
    "title": "Weighted Attribute Fusion Model for Face Recognition", 
    "publish": "2010-09-03T10:05:20Z", 
    "summary": "Recognizing a face based on its attributes is an easy task for a human to\nperform as it is a cognitive process. In recent years, Face Recognition is\nachieved with different kinds of facial features which were used separately or\nin a combined manner. Currently, Feature fusion methods and parallel methods\nare the facial features used and performed by integrating multiple feature sets\nat different levels. However, this integration and the combinational methods do\nnot guarantee better result. Hence to achieve better results, the feature\nfusion model with multiple weighted facial attribute set is selected. For this\nfeature model, face images from predefined data set has been taken from\nOlivetti Research Laboratory (ORL) and applied on different methods like\nPrincipal Component Analysis (PCA) based Eigen feature extraction technique,\nDiscrete Cosine Transformation (DCT) based feature extraction technique,\nHistogram Based Feature Extraction technique and Simple Intensity based\nfeatures. The extracted feature set obtained from these methods were compared\nand tested for accuracy. In this work we have developed a model which will use\nthe above set of feature extraction techniques with different levels of weights\nto attain better accuracy. The results show that the selection of optimum\nweight for a particular feature will lead to improvement in recognition rate.", 
    "link": "http://arxiv.org/pdf/1009.0623v2", 
    "arxiv-id": "1009.0623v2"
},{
    "category": "cs.CV", 
    "author": "Fatih Celiker", 
    "title": "Fast Color Space Transformations Using Minimax Approximations", 
    "publish": "2010-09-04T17:44:06Z", 
    "summary": "Color space transformations are frequently used in image processing,\ngraphics, and visualization applications. In many cases, these transformations\nare complex nonlinear functions, which prohibits their use in time-critical\napplications. In this paper, we present a new approach called Minimax\nApproximations for Color-space Transformations (MACT).We demonstrate MACT on\nthree commonly used color space transformations. Extensive experiments on a\nlarge and diverse image set and comparisons with well-known multidimensional\nlookup table interpolation methods show that MACT achieves an excellent balance\namong four criteria: ease of implementation, memory usage, accuracy, and\ncomputational speed.", 
    "link": "http://arxiv.org/pdf/1009.0854v1", 
    "arxiv-id": "1009.0854v1"
},{
    "category": "cs.CV", 
    "author": "Xinsheng Huang", 
    "title": "Effective Pedestrian Detection Using Center-symmetric Local   Binary/Trinary Patterns", 
    "publish": "2010-09-05T05:16:11Z", 
    "summary": "Accurately detecting pedestrians in images plays a critically important role\nin many computer vision applications. Extraction of effective features is the\nkey to this task. Promising features should be discriminative, robust to\nvarious variations and easy to compute. In this work, we present novel\nfeatures, termed dense center-symmetric local binary patterns (CS-LBP) and\npyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for\npedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4}\nmainly captures the texture information. The proposed CS-LBP feature, in\ncontrast, captures the gradient information and some texture information.\nMoreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to\nimplement and computationally efficient, which is desirable for real-time\napplications. Experiments on the INRIA pedestrian dataset show that the dense\nCS-LBP feature with linear supporct vector machines (SVMs) is comparable with\nthe histograms of oriented gradients (HOG) feature with linear SVMs, and the\npyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and\nthe start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection\nkernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP\nfeature and the PHOG feature could significantly improve the detection\nperformance-producing state-of-the-art accuracy on the INRIA pedestrian\ndataset.", 
    "link": "http://arxiv.org/pdf/1009.0892v2", 
    "arxiv-id": "1009.0892v2"
},{
    "category": "cs.CV", 
    "author": "M. Emre Celebi", 
    "title": "Distance Measures for Reduced Ordering Based Vector Filters", 
    "publish": "2010-09-05T23:49:38Z", 
    "summary": "Reduced ordering based vector filters have proved successful in removing\nlong-tailed noise from color images while preserving edges and fine image\ndetails. These filters commonly utilize variants of the Minkowski distance to\norder the color vectors with the aim of distinguishing between noisy and\nnoise-free vectors. In this paper, we review various alternative distance\nmeasures and evaluate their performance on a large and diverse set of images\nusing several effectiveness and efficiency criteria. The results demonstrate\nthat there are in fact strong alternatives to the popular Minkowski metrics.", 
    "link": "http://arxiv.org/pdf/1009.0957v1", 
    "arxiv-id": "1009.0957v1"
},{
    "category": "cs.CV", 
    "author": "M. Emre Celebi", 
    "title": "Real-Time Implementation of Order-Statistics Based Directional Filters", 
    "publish": "2010-09-05T23:53:27Z", 
    "summary": "Vector filters based on order-statistics have proved successful in removing\nimpulsive noise from color images while preserving edges and fine image\ndetails. Among these filters, the ones that involve the cosine distance\nfunction (directional filters) have particularly high computational\nrequirements, which limits their use in time critical applications. In this\npaper, we introduce two methods to speed up these filters. Experiments on a\ndiverse set of color images show that the proposed methods provide substantial\ncomputational gains without significant loss of accuracy.", 
    "link": "http://arxiv.org/pdf/1009.0958v1", 
    "arxiv-id": "1009.0958v1"
},{
    "category": "cs.CV", 
    "author": "Fatih Celiker", 
    "title": "Cost-Effective Implementation of Order-Statistics Based Vector Filters   Using Minimax Approximations", 
    "publish": "2010-09-06T00:02:35Z", 
    "summary": "Vector operators based on robust order statistics have proved successful in\ndigital multichannel imaging applications, particularly color image filtering\nand enhancement, in dealing with impulsive noise while preserving edges and\nfine image details. These operators often have very high computational\nrequirements which limits their use in time-critical applications. This paper\nintroduces techniques to speed up vector filters using the minimax\napproximation theory. Extensive experiments on a large and diverse set of color\nimages show that proposed approximations achieve an excellent balance among\nease of implementation, accuracy, and computational speed.", 
    "link": "http://arxiv.org/pdf/1009.0959v1", 
    "arxiv-id": "1009.0959v1"
},{
    "category": "cs.CV", 
    "author": "Y. Alp Aslandogan", 
    "title": "A Fast Switching Filter for Impulsive Noise Removal from Color Images", 
    "publish": "2010-09-06T00:13:25Z", 
    "summary": "In this paper, we present a fast switching filter for impulsive noise removal\nfrom color images. The filter exploits the HSL color space, and is based on the\npeer group concept, which allows for the fast detection of noise in a\nneighborhood without resorting to pairwise distance computations between each\npixel. Experiments on large set of diverse images demonstrate that the proposed\napproach is not only extremely fast, but also gives excellent results in\ncomparison to various state-of-the-art filters.", 
    "link": "http://arxiv.org/pdf/1009.0961v1", 
    "arxiv-id": "1009.0961v1"
},{
    "category": "cs.CV", 
    "author": "Y. Alp Aslandogan", 
    "title": "Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images", 
    "publish": "2010-09-06T00:22:58Z", 
    "summary": "In this paper, a comprehensive survey of 48 filters for impulsive noise\nremoval from color images is presented. The filters are formulated using a\nuniform notation and categorized into 8 families. The performance of these\nfilters is compared on a large set of images that cover a variety of domains\nusing three effectiveness and one efficiency criteria. In order to ensure a\nfair efficiency comparison, a fast and accurate approximation for the inverse\ncosine function is introduced. In addition, commonly used distance measures\n(Minkowski, angular, and directional-distance) are analyzed and evaluated.\nFinally, suggestions are provided on how to choose a filter given certain\nrequirements.", 
    "link": "http://arxiv.org/pdf/1009.0962v1", 
    "arxiv-id": "1009.0962v1"
},{
    "category": "cs.CV", 
    "author": "H. Peter Soyer", 
    "title": "Automatic Detection of Blue-White Veil and Related Structures in   Dermoscopy Images", 
    "publish": "2010-09-06T10:29:18Z", 
    "summary": "Dermoscopy is a non-invasive skin imaging technique, which permits\nvisualization of features of pigmented melanocytic neoplasms that are not\ndiscernable by examination with the naked eye. One of the most important\nfeatures for the diagnosis of melanoma in dermoscopy images is the blue-white\nveil (irregular, structureless areas of confluent blue pigmentation with an\noverlying white \"ground-glass\" film). In this article, we present a machine\nlearning approach to the detection of blue-white veil and related structures in\ndermoscopy images. The method involves contextual pixel classification using a\ndecision tree classifier. The percentage of blue-white areas detected in a\nlesion combined with a simple shape descriptor yielded a sensitivity of 69.35%\nand a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity\nrises to 78.20% for detection of blue veil in those cases where it is a primary\nfeature for melanoma recognition.", 
    "link": "http://arxiv.org/pdf/1009.1013v1", 
    "arxiv-id": "1009.1013v1"
},{
    "category": "cs.CV", 
    "author": "James M. Grichnik", 
    "title": "An Improved Objective Evaluation Measure for Border Detection in   Dermoscopy Images", 
    "publish": "2010-09-06T10:53:21Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, dermoscopy image analysis has become\nan important research area. One of the most important steps in dermoscopy image\nanalysis is the automated detection of lesion borders. Although numerous\nmethods have been developed for the detection of lesion borders, very few\nstudies were comprehensive in the evaluation of their results. Methods: In this\npaper, we evaluate five recent border detection methods on a set of 90\ndermoscopy images using three sets of dermatologist-drawn borders as the\nground-truth. In contrast to previous work, we utilize an objective measure,\nthe Normalized Probabilistic Rand Index, which takes into account the\nvariations in the ground-truth images. Conclusion: The results demonstrate that\nthe differences between four of the evaluated border detection methods are in\nfact smaller than those predicted by the commonly used XOR measure.", 
    "link": "http://arxiv.org/pdf/1009.1020v1", 
    "arxiv-id": "1009.1020v1"
},{
    "category": "cs.CV", 
    "author": "William V. Stoecker", 
    "title": "Approximate Lesion Localization in Dermoscopy Images", 
    "publish": "2010-09-06T11:01:53Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, automated analysis of dermoscopy\nimages has become an important research area. Border detection is often the\nfirst step in this analysis. Methods: In this article, we present an\napproximate lesion localization method that serves as a preprocessing step for\ndetecting borders in dermoscopy images. In this method, first the black frame\naround the image is removed using an iterative algorithm. The approximate\nlocation of the lesion is then determined using an ensemble of thresholding\nalgorithms. Results: The method is tested on a set of 428 dermoscopy images.\nThe localization error is quantified by a metric that uses dermatologist\ndetermined borders as the ground truth. Conclusion: The results demonstrate\nthat the method presented here achieves both fast and accurate localization of\nlesions in dermoscopy images.", 
    "link": "http://arxiv.org/pdf/1009.1362v1", 
    "arxiv-id": "1009.1362v1"
},{
    "category": "cs.CV", 
    "author": "Vasumathi Narayanan", 
    "title": "Evolutionary Computational Method of Facial Expression Analysis for   Content-based Video Retrieval using 2-Dimensional Cellular Automata", 
    "publish": "2010-09-10T11:25:17Z", 
    "summary": "In this paper, Deterministic Cellular Automata (DCA) based video shot\nclassification and retrieval is proposed. The deterministic 2D Cellular\nautomata model captures the human facial expressions, both spontaneous and\nposed. The determinism stems from the fact that the facial muscle actions are\nstandardized by the encodings of Facial Action Coding System (FACS) and Action\nUnits (AUs). Based on these encodings, we generate the set of evolutionary\nupdate rules of the DCA for each facial expression. We consider a\nPerson-Independent Facial Expression Space (PIFES) to analyze the facial\nexpressions based on Partitioned 2D-Cellular Automata which capture the\ndynamics of facial expressions and classify the shots based on it. Target video\nshot is retrieved by comparing the similar expression is obtained for the query\nframe's face with respect to the key faces expressions in the database video.\nConsecutive key face expressions in the database that are highly similar to the\nquery frame's face, then the key faces are used to generate the set of\nretrieved video shots from the database. A concrete example of its application\nwhich realizes an affective interaction between the computer and the user is\nproposed. In the affective interaction, the computer can recognize the facial\nexpression of any given video shot. This interaction endows the computer with\ncertain ability to adapt to the user's feedback.", 
    "link": "http://arxiv.org/pdf/1009.1983v1", 
    "arxiv-id": "1009.1983v1"
},{
    "category": "cs.CV", 
    "author": "Benoit Macq", 
    "title": "Invariant Spectral Hashing of Image Saliency Graph", 
    "publish": "2010-09-15T20:11:11Z", 
    "summary": "Image hashing is the process of associating a short vector of bits to an\nimage. The resulting summaries are useful in many applications including image\nindexing, image authentication and pattern recognition. These hashes need to be\ninvariant under transformations of the image that result in similar visual\ncontent, but should drastically differ for conceptually distinct contents. This\npaper proposes an image hashing method that is invariant under rotation,\nscaling and translation of the image. The gist of our approach relies on the\ngeometric characterization of salient point distribution in the image. This is\nachieved by the definition of a \"saliency graph\" connecting these points\njointly with an image intensity function on the graph nodes. An invariant hash\nis then obtained by considering the spectrum of this function in the\neigenvector basis of the Laplacian graph, that is, its graph Fourier transform.\nInterestingly, this spectrum is invariant under any relabeling of the graph\nnodes. The graph reveals geometric information of the image, making the hash\nrobust to image transformation, yet distinct for different visual content. The\nefficiency of the proposed method is assessed on a set of MRI 2-D slices and on\na database of faces.", 
    "link": "http://arxiv.org/pdf/1009.3029v1", 
    "arxiv-id": "1009.3029v1"
},{
    "category": "cs.CV", 
    "author": "Zhang Ren", 
    "title": "Asymmetric Totally-corrective Boosting for Real-time Object Detection", 
    "publish": "2010-09-16T02:45:59Z", 
    "summary": "Real-time object detection is one of the core problems in computer vision.\nThe cascade boosting framework proposed by Viola and Jones has become the\nstandard for this problem. In this framework, the learning goal for each node\nis asymmetric, which is required to achieve a high detection rate and a\nmoderate false positive rate. We develop new boosting algorithms to address\nthis asymmetric learning problem. We show that our methods explicitly optimize\nasymmetric loss objectives in a totally corrective fashion. The methods are\ntotally corrective in the sense that the coefficients of all selected weak\nclassifiers are updated at each iteration. In contract, conventional boosting\nlike AdaBoost is stage-wise in that only the current weak classifier's\ncoefficient is updated. At the heart of the totally corrective boosting is the\ncolumn generation technique. Experiments on face detection show that our\nmethods outperform the state-of-the-art asymmetric boosting methods.", 
    "link": "http://arxiv.org/pdf/1009.3078v1", 
    "arxiv-id": "1009.3078v1"
},{
    "category": "cs.CV", 
    "author": "Driss Aboutajdine", 
    "title": "3D-Mesh denoising using an improved vertex based anisotropic diffusion", 
    "publish": "2010-09-23T11:26:37Z", 
    "summary": "This paper deals with an improvement of vertex based nonlinear diffusion for\nmesh denoising. This method directly filters the position of the vertices using\nLaplace, reduced centered Gaussian and Rayleigh probability density functions\nas diffusivities. The use of these PDFs improves the performance of a\nvertex-based diffusion method which are adapted to the underlying mesh\nstructure. We also compare the proposed method to other mesh denoising methods\nsuch as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To\nevaluate these methods of filtering, we use two error metrics. The first is\nbased on the vertices and the second is based on the normals. Experimental\nresults demonstrate the effectiveness of our proposed method in comparison with\nthe existing methods.", 
    "link": "http://arxiv.org/pdf/1009.4581v1", 
    "arxiv-id": "1009.4581v1"
},{
    "category": "cs.CV", 
    "author": "Herv\u00e9 J\u00e9gou", 
    "title": "Balancing clusters to reduce response time variability in large scale   image search", 
    "publish": "2010-09-21T11:31:02Z", 
    "summary": "Many algorithms for approximate nearest neighbor search in high-dimensional\nspaces partition the data into clusters. At query time, in order to avoid\nexhaustive search, an index selects the few (or a single) clusters nearest to\nthe query point. Clusters are often produced by the well-known $k$-means\napproach since it has several desirable properties. On the downside, it tends\nto produce clusters having quite different cardinalities. Imbalanced clusters\nnegatively impact both the variance and the expectation of query response\ntimes. This paper proposes to modify $k$-means centroids to produce clusters\nwith more comparable sizes without sacrificing the desirable properties.\nExperiments with a large scale collection of image descriptors show that our\nalgorithm significantly reduces the variance of response times without\nseriously impacting the search quality.", 
    "link": "http://arxiv.org/pdf/1009.4739v1", 
    "arxiv-id": "1009.4739v1"
},{
    "category": "cs.CV", 
    "author": "Vikram Dhillon", 
    "title": "Modeling Instantaneous Changes In Natural Scenes", 
    "publish": "2010-09-24T03:32:28Z", 
    "summary": "This project aims to create 3d model of the natural world and model changes\nin it instantaneously. A framework for modeling instantaneous changes natural\nscenes in real time using Lagrangian Particle Framework and a fluid-particle\ngrid approach is presented. This project is presented in the form of a\nproof-based system where we show that the design is very much possible but\ncurrently we only have selective scripts that accomplish the given job, a\ncomplete software however is still under work. This research can be divided\ninto 3 distinct sections: the first one discusses a multi-camera rig that can\nmeasure ego-motion accurately up to 88%, how this device becomes the backbone\nof our framework, and some improvements devised to optimize a know framework\nfor depth maps and 3d structure estimation from a single still image called\nmake3d. The second part discusses the fluid-particle framework to model natural\nscenes, presents some algorithms that we are using to accomplish this task and\nwe show how an application of our framework can extend make3d to model natural\nscenes in real time. This part of the research constructs a bridge between\ncomputer vision and computer graphics so that now ideas, answers and intuitions\nthat arose in the domain of computer graphics can now be applied to computer\nvision and natural modeling. The final part of this research improves upon what\nmight become the first general purpose vision system using deep belief\narchitectures and provides another framework to improve the lower bound on\ntraining images for boosting by using a variation of Restricted Boltzmann\nmachines (RBM). We also discuss other applications that might arise from our\nwork in these areas.", 
    "link": "http://arxiv.org/pdf/1009.4757v3", 
    "arxiv-id": "1009.4757v3"
},{
    "category": "cs.CV", 
    "author": "Cristian Sminchisescu", 
    "title": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques", 
    "publish": "2010-09-24T12:32:02Z", 
    "summary": "We propose a mid-level image segmentation framework that combines multiple\nfigure-ground hypothesis (FG) constrained at different locations and scales,\ninto interpretations that tile the entire image. The problem is cast as\noptimization over sets of maximal cliques sampled from the graph connecting\nnon-overlapping, putative figure-ground segment hypotheses. Potential functions\nover cliques combine unary Gestalt-based figure quality scores and pairwise\ncompatibilities among spatially neighboring segments, constrained by\nT-junctions and the boundary interface statistics resulting from projections of\nreal 3d scenes. Learning the model parameters is formulated as rank\noptimization, alternating between sampling image tilings and optimizing their\npotential function parameters. State of the art results are reported on both\nthe Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was\nachieved.", 
    "link": "http://arxiv.org/pdf/1009.4823v1", 
    "arxiv-id": "1009.4823v1"
},{
    "category": "cs.CV", 
    "author": "Mohammad Shamsul Alam", 
    "title": "Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis   Function Networks", 
    "publish": "2010-09-25T05:46:31Z", 
    "summary": "This paper introduces a novel method for human face detection with its\norientation by using wavelet, principle component analysis (PCA) and redial\nbasis networks. The input image is analyzed by two-dimensional wavelet and a\ntwo-dimensional stationary wavelet. The common goals concern are the image\nclearance and simplification, which are parts of de-noising or compression. We\napplied an effective procedure to reduce the dimension of the input vectors\nusing PCA. Radial Basis Function (RBF) neural network is then used as a\nfunction approximation network to detect where either the input image is\ncontained a face or not and if there is a face exists then tell about its\norientation. We will show how RBF can perform well then back-propagation\nalgorithm and give some solution for better regularization of the RBF (GRNN)\nnetwork. Compared with traditional RBF networks, the proposed network\ndemonstrates better capability of approximation to underlying functions, faster\nlearning speed, better size of network, and high robustness to outliers.", 
    "link": "http://arxiv.org/pdf/1009.4974v1", 
    "arxiv-id": "1009.4974v1"
},{
    "category": "cs.CV", 
    "author": "Jian Zhang", 
    "title": "Face Detection with Effective Feature Extraction", 
    "publish": "2010-09-29T03:13:09Z", 
    "summary": "There is an abundant literature on face detection due to its important role\nin many vision applications. Since Viola and Jones proposed the first real-time\nAdaBoost based face detector, Haar-like features have been adopted as the\nmethod of choice for frontal face detection. In this work, we show that simple\nfeatures other than Haar-like features can also be applied for training an\neffective face detector. Since, single feature is not discriminative enough to\nseparate faces from difficult non-faces, we further improve the generalization\nperformance of our simple features by introducing feature co-occurrences. We\ndemonstrate that our proposed features yield a performance improvement compared\nto Haar-like features. In addition, our findings indicate that features play a\ncrucial role in the ability of the system to generalize.", 
    "link": "http://arxiv.org/pdf/1009.5758v1", 
    "arxiv-id": "1009.5758v1"
},{
    "category": "cs.CV", 
    "author": "Margaret H. Dunham", 
    "title": "Visual-hint Boundary to Segment Algorithm for Image Segmentation", 
    "publish": "2010-10-03T15:27:56Z", 
    "summary": "Image segmentation has been a very active research topic in image analysis\narea. Currently, most of the image segmentation algorithms are designed based\non the idea that images are partitioned into a set of regions preserving\nhomogeneous intra-regions and inhomogeneous inter-regions. However, human\nvisual intuition does not always follow this pattern. A new image segmentation\nmethod named Visual-Hint Boundary to Segment (VHBS) is introduced, which is\nmore consistent with human perceptions. VHBS abides by two visual hint rules\nbased on human perceptions: (i) the global scale boundaries tend to be the real\nboundaries of the objects; (ii) two adjacent regions with quite different\ncolors or textures tend to result in the real boundaries between them. It has\nbeen demonstrated by experiments that, compared with traditional image\nsegmentation method, VHBS has better performance and also preserves higher\ncomputational efficiency.", 
    "link": "http://arxiv.org/pdf/1010.0417v1", 
    "arxiv-id": "1010.0417v1"
},{
    "category": "cs.CV", 
    "author": "Yann LeCun", 
    "title": "Convolutional Matching Pursuit and Dictionary Training", 
    "publish": "2010-10-03T16:55:56Z", 
    "summary": "Matching pursuit and K-SVD is demonstrated in the translation invariant\nsetting", 
    "link": "http://arxiv.org/pdf/1010.0422v1", 
    "arxiv-id": "1010.0422v1"
},{
    "category": "cs.CV", 
    "author": "Anne-Sophie Puthon", 
    "title": "Joint interpretation of on-board vision and static GPS cartography for   determination of correct speed limit", 
    "publish": "2010-10-19T12:03:16Z", 
    "summary": "We present here a first prototype of a \"Speed Limit Support\" Advance Driving\nAssistance System (ADAS) producing permanent reliable information on the\ncurrent speed limit applicable to the vehicle. Such a module can be used either\nfor information of the driver, or could even serve for automatic setting of the\nmaximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on\na joint interpretation of cartographic information (for static reference\ninformation) with on-board vision, used for traffic sign detection and\nrecognition (including supplementary sub-signs) and visual road lines\nlocalization (for detection of lane changes). The visual traffic sign detection\npart is quite robust (90% global correct detection and recognition for main\nspeed signs, and 80% for exit-lane sub-signs detection). Our approach for joint\ninterpretation with cartography is original, and logic-based rather than\nprobability-based, which allows correct behaviour even in cases, which do\nhappen, when both vision and cartography may provide the same erroneous\ninformation.", 
    "link": "http://arxiv.org/pdf/1010.3867v1", 
    "arxiv-id": "1010.3867v1"
},{
    "category": "cs.CV", 
    "author": "Bruno B. Gon\u00e7alves", 
    "title": "3-D Rigid Models from Partial Views - Global Factorization", 
    "publish": "2010-10-19T14:45:55Z", 
    "summary": "The so-called factorization methods recover 3-D rigid structure from motion\nby factorizing an observation matrix that collects 2-D projections of features.\nThese methods became popular due to their robustness - they use a large number\nof views, which constrains adequately the solution - and computational\nsimplicity - the large number of unknowns is computed through an SVD, avoiding\nnon-linear optimization. However, they require that all the entries of the\nobservation matrix are known. This is unlikely to happen in practice, due to\nself-occlusion and limited field of view. Also, when processing long videos,\nregions that become occluded often appear again later. Current factorization\nmethods process these as new regions, leading to less accurate estimates of 3-D\nstructure. In this paper, we propose a global factorization method that infers\ncomplete 3-D models directly from the 2-D projections in the entire set of\navailable video frames. Our method decides whether a region that has become\nvisible is a region that was seen before, or a previously unseen region, in a\nglobal way, i.e., by seeking the simplest rigid object that describes well the\nentire set of observations. This global approach increases significantly the\naccuracy of the estimates of the 3-D shape of the scene and the 3-D motion of\nthe camera. Experiments with artificial and real videos illustrate the good\nperformance of our method.", 
    "link": "http://arxiv.org/pdf/1010.3935v1", 
    "arxiv-id": "1010.3935v1"
},{
    "category": "cs.CV", 
    "author": "Pedro M. Q. Aguiar", 
    "title": "Maximum Likelihood Mosaics", 
    "publish": "2010-10-19T15:13:40Z", 
    "summary": "The majority of the approaches to the automatic recovery of a panoramic image\nfrom a set of partial views are suboptimal in the sense that the input images\nare aligned, or registered, pair by pair, e.g., consecutive frames of a video\nclip. These approaches lead to propagation errors that may be very severe,\nparticularly when dealing with videos that show the same region at disjoint\ntime intervals. Although some authors have proposed a post-processing step to\nreduce the registration errors in these situations, there have not been\nattempts to compute the optimal solution, i.e., the registrations leading to\nthe panorama that best matches the entire set of partial views}. This is our\ngoal. In this paper, we use a generative model for the partial views of the\npanorama and develop an algorithm to compute in an efficient way the Maximum\nLikelihood estimate of all the unknowns involved: the parameters describing the\nalignment of all the images and the panorama itself.", 
    "link": "http://arxiv.org/pdf/1010.3947v1", 
    "arxiv-id": "1010.3947v1"
},{
    "category": "cs.CV", 
    "author": "Pedro M. Q. Aguiar", 
    "title": "ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of   Unlabeled Points)", 
    "publish": "2010-10-19T19:48:41Z", 
    "summary": "In image analysis, many tasks require representing two-dimensional (2D)\nshape, often specified by a set of 2D points, for comparison purposes. The\nchallenge of the representation is that it must not only capture the\ncharacteristics of the shape but also be invariant to relevant transformations.\nInvariance to geometric transformations, such as translation, rotation, and\nscale, has received attention in the past, usually under the assumption that\nthe points are previously labeled, i.e., that the shape is characterized by an\nordered set of landmarks. However, in many practical scenarios, the points\ndescribing the shape are obtained from automatic processes, e.g., edge or\ncorner detection, thus without labels or natural ordering. Obviously, the\ncombinatorial problem of computing the correspondences between the points of\ntwo shapes in the presence of the aforementioned geometrical distortions\nbecomes a quagmire when the number of points is large. We circumvent this\nproblem by representing shapes in a way that is invariant to the permutation of\nthe landmarks, i.e., we represent bags of unlabeled 2D points. Within our\nframework, a shape is mapped to an analytic function on the complex plane,\nleading to what we call its analytic signature (ANSIG). To store an ANSIG, it\nsuffices to sample it along a closed contour in the complex plane. We show that\nthe ANSIG is a maximal invariant with respect to the permutation group, i.e.,\nthat different shapes have different ANSIGs and shapes that differ by a\npermutation (or re-labeling) of the landmarks have the same ANSIG. We further\nshow how easy it is to factor out geometric transformations when comparing\nshapes using the ANSIG representation. Finally, we illustrate these\ncapabilities with shape-based image classification experiments.", 
    "link": "http://arxiv.org/pdf/1010.4021v1", 
    "arxiv-id": "1010.4021v1"
},{
    "category": "cs.CV", 
    "author": "Pedro M. Q. Aguiar", 
    "title": "Revisiting Complex Moments For 2D Shape Representation and Image   Normalization", 
    "publish": "2010-10-18T20:12:29Z", 
    "summary": "When comparing 2D shapes, a key issue is their normalization. Translation and\nscale are easily taken care of by removing the mean and normalizing the energy.\nHowever, defining and computing the orientation of a 2D shape is not so simple.\nIn fact, although for elongated shapes the principal axis can be used to define\none of two possible orientations, there is no such tool for general shapes. As\nwe show in the paper, previous approaches fail to compute the orientation of\neven noiseless observations of simple shapes. We address this problem. In the\npaper, we show how to uniquely define the orientation of an arbitrary 2D shape,\nin terms of what we call its Principal Moments. We show that a small subset of\nthese moments suffice to represent the underlying 2D shape and propose a new\nmethod to efficiently compute the shape orientation: Principal Moment Analysis.\nFinally, we discuss how this method can further be applied to normalize\ngrey-level images. Besides the theoretical proof of correctness, we describe\nexperiments demonstrating robustness to noise and illustrating the method with\nreal images.", 
    "link": "http://arxiv.org/pdf/1010.4203v1", 
    "arxiv-id": "1010.4203v1"
},{
    "category": "cs.CV", 
    "author": "Guillermo Sapiro", 
    "title": "Statistical Compressive Sensing of Gaussian Mixture Models", 
    "publish": "2010-10-20T20:22:26Z", 
    "summary": "A new framework of compressive sensing (CS), namely statistical compressive\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution and achieving accurate reconstruction on\naverage, is introduced. For signals following a Gaussian distribution, with\nGaussian or Bernoulli sensing matrices of O(k) measurements, considerably\nsmaller than the O(k log(N/k)) required by conventional CS, where N is the\nsignal dimension, and with an optimal decoder implemented with linear\nfiltering, significantly faster than the pursuit decoders applied in\nconventional CS, the error of SCS is shown tightly upper bounded by a constant\ntimes the k-best term approximation error, with overwhelming probability. The\nfailure probability is also significantly smaller than that of conventional CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the k-best term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For signals following Gaussian mixture models, SCS with a piecewise\nlinear decoder is introduced and shown to produce for real images better\nresults than conventional CS based on sparse models.", 
    "link": "http://arxiv.org/pdf/1010.4314v1", 
    "arxiv-id": "1010.4314v1"
},{
    "category": "cs.CV", 
    "author": "Guillermo Sapiro", 
    "title": "Collaborative Sources Identification in Mixed Signals via Hierarchical   Sparse Modeling", 
    "publish": "2010-10-23T16:47:16Z", 
    "summary": "A collaborative framework for detecting the different sources in mixed\nsignals is presented in this paper. The approach is based on C-HiLasso, a\nconvex collaborative hierarchical sparse model, and proceeds as follows. First,\nwe build a structured dictionary for mixed signals by concatenating a set of\nsub-dictionaries, each one of them learned to sparsely model one of a set of\npossible classes. Then, the coding of the mixed signal is performed by\nefficiently solving a convex optimization problem that combines standard\nsparsity with group and collaborative sparsity. The present sources are\nidentified by looking at the sub-dictionaries automatically selected in the\ncoding. The collaborative filtering in C-HiLasso takes advantage of the\ntemporal/spatial redundancy in the mixed signals, letting collections of\nsamples collaborate in identifying the classes, while allowing individual\nsamples to have different internal sparse representations. This collaboration\nis critical to further stabilize the sparse representation of signals, in\nparticular the class/sub-dictionary selection. The internal sparsity inside the\nsub-dictionaries, as naturally incorporated by the hierarchical aspects of\nC-HiLasso, is critical to make the model consistent with the essence of the\nsub-dictionaries that have been trained for sparse representation of each\nindividual class. We present applications from speaker and instrument\nidentification and texture separation. In the case of audio signals, we use\nsparse modeling to describe the short-term power spectrum envelopes of harmonic\nsounds. The proposed pitch independent method automatically detects the number\nof sources on a recording.", 
    "link": "http://arxiv.org/pdf/1010.4893v1", 
    "arxiv-id": "1010.4893v1"
},{
    "category": "cs.CV", 
    "author": "Loong-Fah Cheong", 
    "title": "Selective Image Super-Resolution", 
    "publish": "2010-10-27T08:58:48Z", 
    "summary": "In this paper we propose a vision system that performs image Super Resolution\n(SR) with selectivity. Conventional SR techniques, either by multi-image fusion\nor example-based construction, have failed to capitalize on the intrinsic\nstructural and semantic context in the image, and performed \"blind\" resolution\nrecovery to the entire image area. By comparison, we advocate example-based\nselective SR whereby selectivity is exemplified in three aspects: region\nselectivity (SR only at object regions), source selectivity (object SR with\ntrained object dictionaries), and refinement selectivity (object boundaries\nrefinement using matting). The proposed system takes over-segmented\nlow-resolution images as inputs, assimilates recent learning techniques of\nsparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to\na framework for joint figure-ground separation and interest object SR. The\nefficiency of our framework is manifested in our experiments with subsets of\nthe VOC2009 and MSRC datasets. We also demonstrate several interesting vision\napplications that can build on our system.", 
    "link": "http://arxiv.org/pdf/1010.5610v1", 
    "arxiv-id": "1010.5610v1"
},{
    "category": "cs.CV", 
    "author": "Amlan Chakrabarti", 
    "title": "Multiple View Reconstruction of Calibrated Images using Singular Value   Decomposition", 
    "publish": "2010-11-02T12:25:04Z", 
    "summary": "Calibration in a multi camera network has widely been studied for over\nseveral years starting from the earlier days of photogrammetry. Many authors\nhave presented several calibration algorithms with their relative advantages\nand disadvantages. In a stereovision system, multiple view reconstruction is a\nchallenging task. However, the total computational procedure in detail has not\nbeen presented before. Here in this work, we are dealing with the problem that,\nwhen a world coordinate point is fixed in space, image coordinates of that 3D\npoint vary for different camera positions and orientations. In computer vision\naspect, this situation is undesirable. That is, the system has to be designed\nin such a way that image coordinate of the world coordinate point will be fixed\nirrespective of the position & orientation of the cameras. We have done it in\nan elegant fashion. Firstly, camera parameters are calculated in its local\ncoordinate system. Then, we use global coordinate data to transfer all local\ncoordinate data of stereo cameras into same global coordinate system, so that\nwe can register everything into this global coordinate system. After all the\ntransformations, when the image coordinate of the world coordinate point is\ncalculated, it gives same coordinate value for all camera positions &\norientations. That is, the whole system is calibrated.", 
    "link": "http://arxiv.org/pdf/1011.0596v1", 
    "arxiv-id": "1011.0596v1"
},{
    "category": "cs.CV", 
    "author": "William V. Stoecker", 
    "title": "Lesion Border Detection in Dermoscopy Images", 
    "publish": "2010-10-30T17:17:02Z", 
    "summary": "Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, computerized analysis of dermoscopy\nimages has become an important research area. One of the most important steps\nin dermoscopy image analysis is the automated detection of lesion borders.\nMethods: In this article, we present a systematic overview of the recent border\ndetection methods in the literature paying particular attention to\ncomputational issues and evaluation aspects. Conclusion: Common problems with\nthe existing approaches include the acquisition, size, and diagnostic\ndistribution of the test image set, the evaluation of the results, and the\ninadequate description of the employed methods. Border determination by\ndermatologists appears to depend upon higher-level knowledge, therefore it is\nlikely that the incorporation of domain knowledge in automated methods will\nenable them to perform better, especially in sets of images with a variety of\ndiagnoses.", 
    "link": "http://arxiv.org/pdf/1011.0640v1", 
    "arxiv-id": "1011.0640v1"
},{
    "category": "cs.CV", 
    "author": "Nathan Brewer", 
    "title": "Featureless 2D-3D Pose Estimation by Minimising an   Illumination-Invariant Loss", 
    "publish": "2010-11-03T23:44:46Z", 
    "summary": "The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision ranging from robotic vision\nto image analysis. Our proposed method of registering a 3D model of a known\nobject on a given 2D photo of the object has numerous advantages over existing\nmethods: It does neither require prior training nor learning, nor knowledge of\nthe camera parameters, nor explicit point correspondences or matching features\nbetween image and model. Unlike techniques that estimate a partial 3D pose (as\nin an overhead view of traffic or machine parts on a conveyor belt), our method\nestimates the complete 3D pose of the object, and works on a single static\nimage from a given view, and under varying and unknown lighting conditions. For\nthis purpose we derive a novel illumination-invariant distance measure between\n2D photo and projected 3D model, which is then minimised to find the best pose\nparameters. Results for vehicle pose detection are presented.", 
    "link": "http://arxiv.org/pdf/1011.1035v1", 
    "arxiv-id": "1011.1035v1"
},{
    "category": "cs.CV", 
    "author": "Thomas Tessamma", 
    "title": "Single Frame Image super Resolution using Learned Directionlets", 
    "publish": "2010-11-10T04:43:44Z", 
    "summary": "In this paper, a new directionally adaptive, learning based, single image\nsuper resolution method using multiple direction wavelet transform, called\nDirectionlets is presented. This method uses directionlets to effectively\ncapture directional features and to extract edge information along different\ndirections of a set of available high resolution images .This information is\nused as the training set for super resolving a low resolution input image and\nthe Directionlet coefficients at finer scales of its high-resolution image are\nlearned locally from this training set and the inverse Directionlet transform\nrecovers the super-resolved high resolution image. The simulation results\nshowed that the proposed approach outperforms standard interpolation techniques\nlike Cubic spline interpolation as well as standard Wavelet-based learning,\nboth visually and in terms of the mean squared error (mse) values. This method\ngives good result with aliased images also.", 
    "link": "http://arxiv.org/pdf/1011.2272v1", 
    "arxiv-id": "1011.2272v1"
},{
    "category": "cs.CV", 
    "author": "Gert J. ter Horst", 
    "title": "Bounded Multivariate Surfaces On Monovariate Internal Functions", 
    "publish": "2010-11-12T19:48:13Z", 
    "summary": "Combining the properties of monovariate internal functions as proposed in\nKolmogorov superimposition theorem, in tandem with the bounds wielded by the\nmultivariate formulation of Chebyshev inequality, a hybrid model is presented,\nthat decomposes images into homogeneous probabilistically bounded multivariate\nsurfaces. Given an image, the model shows a novel way of working on reduced\nimage representation while processing and capturing the interaction among the\nmultidimensional information that describes the content of the same. Further,\nit tackles the practical issues of preventing leakage by bounding the growth of\nsurface and reducing the problem sample size. The model if used, also sheds\nlight on how the Chebyshev parameter relates to the number of pixels and the\ndimensionality of the feature space that associates with a pixel. Initial\nsegmentation results on the Berkeley image segmentation benchmark indicate the\neffectiveness of the proposed decomposition algorithm.", 
    "link": "http://arxiv.org/pdf/1011.3019v1", 
    "arxiv-id": "1011.3019v1"
},{
    "category": "cs.CV", 
    "author": "St\u00e9phane Mallat", 
    "title": "Classification with Scattering Operators", 
    "publish": "2010-11-12T20:15:25Z", 
    "summary": "A scattering vector is a local descriptor including multiscale and\nmulti-direction co-occurrence information. It is computed with a cascade of\nwavelet decompositions and complex modulus. This scattering representation is\nlocally translation invariant and linearizes deformations. A supervised\nclassification algorithm is computed with a PCA model selection on scattering\nvectors. State of the art results are obtained for handwritten digit\nrecognition and texture classification.", 
    "link": "http://arxiv.org/pdf/1011.3023v4", 
    "arxiv-id": "1011.3023v4"
},{
    "category": "cs.CV", 
    "author": "Jaime S. Cardoso", 
    "title": "The Data Replication Method for the Classification with Reject Option", 
    "publish": "2010-11-14T02:48:02Z", 
    "summary": "Classification is one of the most important tasks of machine learning.\nAlthough the most well studied model is the two-class problem, in many\nscenarios there is the opportunity to label critical items for manual revision,\ninstead of trying to automatically classify every item. In this paper we adapt\na paradigm initially proposed for the classification of ordinal data to address\nthe classification problem with reject option. The technique reduces the\nproblem of classifying with reject option to the standard two-class problem.\nThe introduced method is then mapped into support vector machines and neural\nnetworks. Finally, the framework is extended to multiclass ordinal data with\nreject option. An experimental study with synthetic and real data sets,\nverifies the usefulness of the proposed approach.", 
    "link": "http://arxiv.org/pdf/1011.3177v3", 
    "arxiv-id": "1011.3177v3"
},{
    "category": "cs.CV", 
    "author": "Zahra S. Razaee", 
    "title": "A Fuzzy Clustering Model for Fuzzy Data with Outliers", 
    "publish": "2010-11-18T22:20:45Z", 
    "summary": "In this paper a fuzzy clustering model for fuzzy data with outliers is\nproposed. The model is based on Wasserstein distance between interval valued\ndata which is generalized to fuzzy data. In addition, Keller's approach is used\nto identify outliers and reduce their influences. We have also defined a\ntransformation to change our distance to the Euclidean distance. With the help\nof this approach, the problem of fuzzy clustering of fuzzy data is reduced to\nfuzzy clustering of crisp data. In order to show the performance of the\nproposed clustering algorithm, two simulation experiments are discussed.", 
    "link": "http://arxiv.org/pdf/1011.4321v1", 
    "arxiv-id": "1011.4321v1"
},{
    "category": "cs.CV", 
    "author": "Israel Cohen", 
    "title": "Generalized Tree-Based Wavelet Transform", 
    "publish": "2010-11-20T21:32:36Z", 
    "summary": "In this paper we propose a new wavelet transform applicable to functions\ndefined on graphs, high dimensional data and networks. The proposed method\ngeneralizes the Haar-like transform proposed in [1], and it is defined via a\nhierarchical tree, which is assumed to capture the geometry and structure of\nthe input data. It is applied to the data using a modified version of the\ncommon one-dimensional (1D) wavelet filtering and decimation scheme, which can\nemploy different wavelet filters. In each level of this wavelet decomposition\nscheme, a permutation derived from the tree is applied to the approximation\ncoefficients, before they are filtered. We propose a tree construction method\nthat results in an efficient representation of the input function in the\ntransform domain. We show that the proposed transform is more efficient than\nboth the 1D and two-dimensional (2D) separable wavelet transforms in\nrepresenting images. We also explore the application of the proposed transform\nto image denoising, and show that combined with a subimage averaging scheme, it\nachieves denoising results which are similar to those obtained with the K-SVD\nalgorithm.", 
    "link": "http://arxiv.org/pdf/1011.4615v2", 
    "arxiv-id": "1011.4615v2"
},{
    "category": "cs.CV", 
    "author": "Sergios Theodoridis", 
    "title": "Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces", 
    "publish": "2010-11-27T10:24:12Z", 
    "summary": "The goal of this paper is the development of a novel approach for the problem\nof Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces\n(RKHS). The problem is cast as an optimization task in a RKHS, by taking\nadvantage of the celebrated semiparametric Representer Theorem. Examples verify\nthat in the presence of gaussian noise the proposed method performs relatively\nwell compared to wavelet based technics and outperforms them significantly in\nthe presence of impulse or mixed noise.\n  A more detailed version of this work has been published in the IEEE Trans.\nIm. Proc. : P. Bouboulis, K. Slavakis and S. Theodoridis, Adaptive Kernel-based\nImage Denoising employing Semi-Parametric Regularization, IEEE Transactions on\nImage Processing, vol 19(6), 2010, 1465 - 1479.", 
    "link": "http://arxiv.org/pdf/1011.5962v1", 
    "arxiv-id": "1011.5962v1"
},{
    "category": "cs.CV", 
    "author": "Benjamin J. Culpepper", 
    "title": "Learning sparse representations of depth", 
    "publish": "2010-11-30T19:55:21Z", 
    "summary": "This paper introduces a new method for learning and inferring sparse\nrepresentations of depth (disparity) maps. The proposed algorithm relaxes the\nusual assumption of the stationary noise model in sparse coding. This enables\nlearning from data corrupted with spatially varying noise or uncertainty,\ntypically obtained by laser range scanners or structured light depth cameras.\nSparse representations are learned from the Middlebury database disparity maps\nand then exploited in a two-layer graphical model for inferring depth from\nstereo, by including a sparsity prior on the learned features. Since they\ncapture higher-order dependencies in the depth structure, these priors can\ncomplement smoothness priors commonly used in depth inference based on Markov\nRandom Field (MRF) models. Inference on the proposed graph is achieved using an\nalternating iterative optimization technique, where the first layer is solved\nusing an existing MRF-based stereo matching algorithm, then held fixed as the\nsecond layer is solved using the proposed non-stationary sparse coding\nalgorithm. This leads to a general method for improving solutions of state of\nthe art MRF-based depth estimation algorithms. Our experimental results first\nshow that depth inference using learned representations leads to state of the\nart denoising of depth maps obtained from laser range scanners and a time of\nflight camera. Furthermore, we show that adding sparse priors improves the\nresults of two depth estimation methods: the classical graph cut algorithm by\nBoykov et al. and the more recent algorithm of Woodford et al.", 
    "link": "http://arxiv.org/pdf/1011.6656v2", 
    "arxiv-id": "1011.6656v2"
},{
    "category": "cs.CV", 
    "author": "Liam Ellis", 
    "title": "Sparse motion segmentation using multiple six-point consistencies", 
    "publish": "2010-12-09T22:56:02Z", 
    "summary": "We present a method for segmenting an arbitrary number of moving objects in\nimage sequences using the geometry of 6 points in 2D to infer motion\nconsistency. The method has been evaluated on the Hopkins 155 database and\nsurpasses current state-of-the-art methods such as SSC, both in terms of\noverall performance on two and three motions but also in terms of maximum\nerrors. The method works by finding initial clusters in the spatial domain, and\nthen classifying each remaining point as belonging to the cluster that\nminimizes a motion consistency score. In contrast to most other motion\nsegmentation methods that are based on an affine camera model, the proposed\nmethod is fully projective.", 
    "link": "http://arxiv.org/pdf/1012.2138v2", 
    "arxiv-id": "1012.2138v2"
},{
    "category": "cs.CV", 
    "author": "Bernard Buxton", 
    "title": "Affine Invariant, Model-Based Object Recognition Using Robust Metrics   and Bayesian Statistics", 
    "publish": "2010-12-11T21:48:51Z", 
    "summary": "We revisit the problem of model-based object recognition for intensity images\nand attempt to address some of the shortcomings of existing Bayesian methods,\nsuch as unsuitable priors and the treatment of residuals with a non-robust\nerror norm. We do so by using a refor- mulation of the Huber metric and\ncarefully chosen prior distributions. Our proposed method is invariant to\n2-dimensional affine transforma- tions and, because it is relatively easy to\ntrain and use, it is suited for general object matching problems.", 
    "link": "http://arxiv.org/pdf/1012.2491v1", 
    "arxiv-id": "1012.2491v1"
},{
    "category": "cs.CV", 
    "author": "Qinfeng Shi", 
    "title": "Real-time Visual Tracking Using Sparse Representation", 
    "publish": "2010-12-12T23:41:56Z", 
    "summary": "The $\\ell_1$ tracker obtains robustness by seeking a sparse representation of\nthe tracking object via $\\ell_1$ norm minimization \\cite{Xue_ICCV_09_Track}.\nHowever, the high computational complexity involved in the $ \\ell_1 $ tracker\nrestricts its further applications in real time processing scenario. Hence we\npropose a Real Time Compressed Sensing Tracking (RTCST) by exploiting the\nsignal recovery power of Compressed Sensing (CS). Dimensionality reduction and\na customized Orthogonal Matching Pursuit (OMP) algorithm are adopted to\naccelerate the CS tracking. As a result, our algorithm achieves a real-time\nspeed that is up to $6,000$ times faster than that of the $\\ell_1$ tracker.\nMeanwhile, RTCST still produces competitive (sometimes even superior) tracking\naccuracy comparing to the existing $\\ell_1$ tracker. Furthermore, for a\nstationary camera, a further refined tracker is designed by integrating a\nCS-based background model (CSBM). This CSBM-equipped tracker coined as RTCST-B,\noutperforms most state-of-the-arts with respect to both accuracy and\nrobustness. Finally, our experimental results on various video sequences, which\nare verified by a new metric---Tracking Success Probability (TSP), show the\nexcellence of the proposed algorithms.", 
    "link": "http://arxiv.org/pdf/1012.2603v1", 
    "arxiv-id": "1012.2603v1"
},{
    "category": "cs.CV", 
    "author": "Yi Ma", 
    "title": "TILT: Transform Invariant Low-rank Textures", 
    "publish": "2010-12-15T02:55:25Z", 
    "summary": "In this paper, we show how to efficiently and effectively extract a class of\n\"low-rank textures\" in a 3D scene from 2D images despite significant\ncorruptions and warping. The low-rank textures capture geometrically meaningful\nstructures in an image, which encompass conventional local features such as\nedges and corners as well as all kinds of regular, symmetric patterns\nubiquitous in urban environments and man-made objects. Our approach to finding\nthese low-rank textures leverages the recent breakthroughs in convex\noptimization that enable robust recovery of a high-dimensional low-rank matrix\ndespite gross sparse errors. In the case of planar regions with significant\naffine or projective deformation, our method can accurately recover both the\nintrinsic low-rank texture and the precise domain transformation, and hence the\n3D geometry and appearance of the planar regions. Extensive experimental\nresults demonstrate that this new technique works effectively for many regular\nand near-regular patterns or objects that are approximately low-rank, such as\nsymmetrical patterns, building facades, printed texts, and human faces.", 
    "link": "http://arxiv.org/pdf/1012.3216v1", 
    "arxiv-id": "1012.3216v1"
},{
    "category": "cs.CV", 
    "author": "Yang Wang", 
    "title": "Detecting Image Forgeries using Geometric Cues", 
    "publish": "2010-12-17T03:27:54Z", 
    "summary": "This chapter presents a framework for detecting fake regions by using various\nmethods including watermarking technique and blind approaches. In particular,\nwe describe current categories on blind approaches which can be divided into\nfive: pixel-based techniques, format-based techniques, camera-based techniques,\nphysically-based techniques and geometric-based techniques. Then we take a\nsecond look on the geometric-based techniques and further categorize them in\ndetail. In the following section, the state-of-the-art methods involved in the\ngeometric technique are elaborated.", 
    "link": "http://arxiv.org/pdf/1012.3802v1", 
    "arxiv-id": "1012.3802v1"
},{
    "category": "cs.CV", 
    "author": "Michael M. Bronstein", 
    "title": "Diffusion-geometric maximally stable component detection in deformable   shapes", 
    "publish": "2010-12-17T18:23:35Z", 
    "summary": "Maximally stable component detection is a very popular method for feature\nanalysis in images, mainly due to its low computation cost and high\nrepeatability. With the recent advance of feature-based methods in geometric\nshape analysis, there is significant interest in finding analogous approaches\nin the 3D world. In this paper, we formulate a diffusion-geometric framework\nfor stable component detection in non-rigid 3D shapes, which can be used for\ngeometric feature detection and description. A quantitative evaluation of our\nmethod on the SHREC'10 feature detection benchmark shows its potential as a\nsource of high-quality features.", 
    "link": "http://arxiv.org/pdf/1012.3951v1", 
    "arxiv-id": "1012.3951v1"
},{
    "category": "cs.CV", 
    "author": "Nir Sochen", 
    "title": "Affine-invariant diffusion geometry for the analysis of deformable 3D   shapes", 
    "publish": "2010-12-29T13:11:41Z", 
    "summary": "We introduce an (equi-)affine invariant diffusion geometry by which surfaces\nthat go through squeeze and shear transformations can still be properly\nanalyzed. The definition of an affine invariant metric enables us to construct\nan invariant Laplacian from which local and global geometric structures are\nextracted. Applications of the proposed framework demonstrate its power in\ngeneralizing and enriching the existing set of tools for shape analysis.", 
    "link": "http://arxiv.org/pdf/1012.5933v1", 
    "arxiv-id": "1012.5933v1"
},{
    "category": "cs.CV", 
    "author": "Nir Sochen", 
    "title": "Affine-invariant geodesic geometry of deformable 3D shapes", 
    "publish": "2010-12-29T13:33:01Z", 
    "summary": "Natural objects can be subject to various transformations yet still preserve\nproperties that we refer to as invariants. Here, we use definitions of affine\ninvariant arclength for surfaces in R^3 in order to extend the set of existing\nnon-rigid shape analysis tools. In fact, we show that by re-defining the\nsurface metric as its equi-affine version, the surface with its modified metric\ntensor can be treated as a canonical Euclidean object on which most classical\nEuclidean processing and analysis tools can be applied. The new definition of a\nmetric is used to extend the fast marching method technique for computing\ngeodesic distances on surfaces, where now, the distances are defined with\nrespect to an affine invariant arclength. Applications of the proposed\nframework demonstrate its invariance, efficiency, and accuracy in shape\nanalysis.", 
    "link": "http://arxiv.org/pdf/1012.5936v1", 
    "arxiv-id": "1012.5936v1"
},{
    "category": "cs.CV", 
    "author": "Narendra Ahuja", 
    "title": "Modeling Dynamic Swarms", 
    "publish": "2011-02-07T12:29:30Z", 
    "summary": "This paper proposes the problem of modeling video sequences of dynamic swarms\n(DS). We define DS as a large layout of stochastically repetitive spatial\nconfigurations of dynamic objects (swarm elements) whose motions exhibit local\nspatiotemporal interdependency and stationarity, i.e., the motions are similar\nin any small spatiotemporal neighborhood. Examples of DS abound in nature,\ne.g., herds of animals and flocks of birds. To capture the local spatiotemporal\nproperties of the DS, we present a probabilistic model that learns both the\nspatial layout of swarm elements and their joint dynamics that are modeled as\nlinear transformations. To this end, a spatiotemporal neighborhood is\nassociated with each swarm element, in which local stationarity is enforced\nboth spatially and temporally. We assume that the prior on the swarm dynamics\nis distributed according to an MRF in both space and time. Embedding this model\nin a MAP framework, we iterate between learning the spatial layout of the swarm\nand its dynamics. We learn the swarm transformations using ICM, which iterates\nbetween estimating these transformations and updating their distribution in the\nspatiotemporal neighborhoods. We demonstrate the validity of our method by\nconducting experiments on real video sequences. Real sequences of birds, geese,\nrobot swarms, and pedestrians evaluate the applicability of our model to real\nworld data.", 
    "link": "http://arxiv.org/pdf/1102.1292v1", 
    "arxiv-id": "1102.1292v1"
},{
    "category": "cs.CV", 
    "author": "Beiji Zou", 
    "title": "Feature selection via simultaneous sparse approximation for person   specific face verification", 
    "publish": "2011-02-14T11:51:35Z", 
    "summary": "There is an increasing use of some imperceivable and redundant local features\nfor face recognition. While only a relatively small fraction of them is\nrelevant to the final recognition task, the feature selection is a crucial and\nnecessary step to select the most discriminant ones to obtain a compact face\nrepresentation. In this paper, we investigate the sparsity-enforced\nregularization-based feature selection methods and propose a multi-task feature\nselection method for building person specific models for face verification. We\nassume that the person specific models share a common subset of features and\nnovelly reformulated the common subset selection problem as a simultaneous\nsparse approximation problem. To the best of our knowledge, it is the first\ntime to apply the sparsity-enforced regularization methods for person specific\nface verification. The effectiveness of the proposed methods is verified with\nthe challenging LFW face databases.", 
    "link": "http://arxiv.org/pdf/1102.2743v2", 
    "arxiv-id": "1102.2743v2"
},{
    "category": "cs.CV", 
    "author": "V. Zobel", 
    "title": "SHREC 2011: robust feature detection and description benchmark", 
    "publish": "2011-02-21T15:43:19Z", 
    "summary": "Feature-based approaches have recently become very popular in computer vision\nand image analysis applications, and are becoming a promising direction in\nshape retrieval. SHREC'11 robust feature detection and description benchmark\nsimulates the feature detection and description stages of feature-based shape\nretrieval algorithms. The benchmark tests the performance of shape feature\ndetectors and descriptors under a wide variety of transformations. The\nbenchmark allows evaluating how algorithms cope with certain classes of\ntransformations and strength of the transformations that can be dealt with. The\npresent paper is a report of the SHREC'11 robust feature detection and\ndescription benchmark results.", 
    "link": "http://arxiv.org/pdf/1102.4258v1", 
    "arxiv-id": "1102.4258v1"
},{
    "category": "cs.CV", 
    "author": "C. N . Ravi Kumar", 
    "title": "A novel super resolution reconstruction of low reoslution images   progressively using dct and zonal filter based denoising", 
    "publish": "2011-02-28T15:24:06Z", 
    "summary": "Due to the factors like processing power limitations and channel capabilities\nimages are often down sampled and transmitted at low bit rates resulting in a\nlow resolution compressed image. High resolution images can be reconstructed\nfrom several blurred, noisy and down sampled low resolution images using a\ncomputational process know as super resolution reconstruction. Super-resolution\nis the process of combining multiple aliased low-quality images to produce a\nhigh resolution, high-quality image. The problem of recovering a high\nresolution image progressively from a sequence of low resolution compressed\nimages is considered. In this paper we propose a novel DCT based progressive\nimage display algorithm by stressing on the encoding and decoding process. At\nthe encoder we consider a set of low resolution images which are corrupted by\nadditive white Gaussian noise and motion blur. The low resolution images are\ncompressed using 8 by 8 blocks DCT and noise is filtered using our proposed\nnovel zonal filter. Multiframe fusion is performed in order to obtain a single\nnoise free image. At the decoder the image is reconstructed progressively by\ntransmitting the coarser image first followed by the detail image. And finally\na super resolution image is reconstructed by applying our proposed novel\nadaptive interpolation technique. We have performed both objective and\nsubjective analysis of the reconstructed image, and the resultant image has\nbetter super resolution factor, and a higher ISNR and PSNR. A comparative study\ndone with Iterative Back Projection (IBP) and Projection on to Convex Sets\n(POCS),Papoulis Grechberg, FFT based Super resolution Reconstruction shows that\nour method has out performed the previous contributions.", 
    "link": "http://arxiv.org/pdf/1102.5688v1", 
    "arxiv-id": "1102.5688v1"
},{
    "category": "cs.CV", 
    "author": "Mita Nasipuri", 
    "title": "Automatic Detection of Ringworm using Local Binary Pattern (LBP)", 
    "publish": "2011-03-01T10:06:31Z", 
    "summary": "In this paper we present a novel approach for automatic recognition of ring\nworm skin disease based on LBP (Local Binary Pattern) feature extracted from\nthe affected skin images. The proposed method is evaluated by extensive\nexperiments on the skin images collected from internet. The dataset is tested\nusing three different classifiers i.e. Bayesian, MLP and SVM. Experimental\nresults show that the proposed methodology efficiently discriminates between a\nring worm skin and a normal skin. It is a low cost technique and does not\nrequire any special imaging devices.", 
    "link": "http://arxiv.org/pdf/1103.0120v2", 
    "arxiv-id": "1103.0120v2"
},{
    "category": "cs.CV", 
    "author": "Christopher Nimsky", 
    "title": "A Semi-Automatic Graph-Based Approach for Determining the Boundary of   Eloquent Fiber Bundles in the Human Brain", 
    "publish": "2011-03-08T09:39:21Z", 
    "summary": "Diffusion Tensor Imaging (DTI) allows estimating the position, orientation\nand dimension of bundles of nerve pathways. This non-invasive imaging technique\ntakes advantage of the diffusion of water molecules and determines the\ndiffusion coefficients for every voxel of the data set. The identification of\nthe diffusion coefficients and the derivation of information about fiber\nbundles is of major interest for planning and performing neurosurgical\ninterventions. To minimize the risk of neural deficits during brain surgery as\ntumor resection (e.g. glioma), the segmentation and integration of the results\nin the operating room is of prime importance. In this contribution, a robust\nand efficient graph-based approach for segmentating tubular fiber bundles in\nthe human brain is presented. To define a cost function, the fractional\nanisotropy (FA) is used, derived from the DTI data, but this value may differ\nfrom patient to patient. Besides manually definining seed regions describing\nthe structure of interest, additionally a manual definition of the cost\nfunction by the user is necessary. To improve the approach the contribution\nintroduces a solution for automatically determining the cost function by using\ndifferent 3D masks for each individual data set.", 
    "link": "http://arxiv.org/pdf/1103.1475v1", 
    "arxiv-id": "1103.1475v1"
},{
    "category": "cs.CV", 
    "author": "Xin Li", 
    "title": "All Roads Lead To Rome", 
    "publish": "2011-03-08T17:50:56Z", 
    "summary": "This short article presents a class of projection-based solution algorithms\nto the problem considered in the pioneering work on compressed sensing -\nperfect reconstruction of a phantom image from 22 radial lines in the frequency\ndomain. Under the framework of projection-based image reconstruction, we will\nshow experimentally that several old and new tools of nonlinear filtering\n(including Perona-Malik diffusion, nonlinear diffusion, Translation-Invariant\nthresholding and SA-DCT thresholding) all lead to perfect reconstruction of the\nphantom image.", 
    "link": "http://arxiv.org/pdf/1103.1587v2", 
    "arxiv-id": "1103.1587v2"
},{
    "category": "cs.CV", 
    "author": "Christopher Nimsky", 
    "title": "Ray-Based and Graph-Based Methods for Fiber Bundle Boundary Estimation", 
    "publish": "2011-03-10T07:19:23Z", 
    "summary": "Diffusion Tensor Imaging (DTI) provides the possibility of estimating the\nlocation and course of eloquent structures in the human brain. Knowledge about\nthis is of high importance for preoperative planning of neurosurgical\ninterventions and for intraoperative guidance by neuronavigation in order to\nminimize postoperative neurological deficits. Therefore, the segmentation of\nthese structures as closed, three-dimensional object is necessary. In this\ncontribution, two methods for fiber bundle segmentation between two defined\nregions are compared using software phantoms (abstract model and anatomical\nphantom modeling the right corticospinal tract). One method uses evaluation\npoints from sampled rays as candidates for boundary points, the other method\nsets up a directed and weighted (depending on a scalar measure) graph and\nperforms a min-cut for optimal segmentation results. Comparison is done by\nusing the Dice Similarity Coefficient (DSC), a measure for spatial overlap of\ndifferent segmentation results.", 
    "link": "http://arxiv.org/pdf/1103.1952v1", 
    "arxiv-id": "1103.1952v1"
},{
    "category": "cs.CV", 
    "author": "Manesh Kokare", 
    "title": "Off-Line Handwritten Signature Identification Using Rotated Complex   Wavelet Filters", 
    "publish": "2011-03-17T15:52:15Z", 
    "summary": "In this paper, a new method for handwritten signature identification based on\nrotated complex wavelet filters is proposed. We have proposed to use the\nrotated complex wavelet filters (RCWF) and dual tree complex wavelet\ntransform(DTCWT) together to derive signature feature extraction, which\ncaptures information in twelve different directions. In identification phase,\nCanberra distance measure is used. The proposed method is compared with\ndiscrete wavelet transform (DWT). From experimental results it is found that\nsignature identification rate of proposed method is superior over DWT", 
    "link": "http://arxiv.org/pdf/1103.3440v1", 
    "arxiv-id": "1103.3440v1"
},{
    "category": "cs.CV", 
    "author": "P. S. Hiremath", 
    "title": "Automatic Extraction of Open Space Area from High Resolution Urban   Satellite Imagery", 
    "publish": "2011-03-24T10:40:00Z", 
    "summary": "In the 21st century, Aerial and satellite images are information rich. They\nare also complex to analyze. For GIS systems, many features require fast and\nreliable extraction of open space area from high resolution satellite imagery.\nIn this paper we will study efficient and reliable automatic extraction\nalgorithm to find out the open space area from the high resolution urban\nsatellite imagery. This automatic extraction algorithm uses some filters and\nsegmentations and grouping is applying on satellite images. And the result\nimages may use to calculate the total available open space area and the built\nup area. It may also use to compare the difference between present and past\nopen space area using historical urban satellite images of that same projection", 
    "link": "http://arxiv.org/pdf/1103.4723v3", 
    "arxiv-id": "1103.4723v3"
},{
    "category": "cs.CV", 
    "author": "P. S. Hiremath", 
    "title": "Automatic Open Space Area Extraction and Change Detection from High   Resolution Urban Satellite Images", 
    "publish": "2011-03-25T07:02:09Z", 
    "summary": "In this paper, we study efficient and reliable automatic extraction algorithm\nto find out the open space area from the high resolution urban satellite\nimagery, and to detect changes from the extracted open space area during the\nperiod 2003, 2006 and 2008. This automatic extraction and change detection\nalgorithm uses some filters, segmentation and grouping that are applied on\nsatellite images. The resultant images may be used to calculate the total\navailable open space area and the built up area. It may also be used to compare\nthe difference between present and past open space area using historical urban\nsatellite images of that same projection, which is an important geo spatial\ndata management application.", 
    "link": "http://arxiv.org/pdf/1103.4913v1", 
    "arxiv-id": "1103.4913v1"
},{
    "category": "cs.CV", 
    "author": "Amzari Jihadi Ghazali", 
    "title": "Application of Threshold Techniques for Readability Improvement of Jawi   Historical Manuscript Images", 
    "publish": "2011-03-29T12:34:53Z", 
    "summary": "Historical documents such as old books and manuscripts have a high aesthetic\nvalue and highly appreciated. Unfortunately, there are some documents cannot be\nread due to quality problems like faded paper, ink expand, uneven colour tone,\ntorn paper and other elements disruption such as the existence of small spots.\nThe study aims to produce a copy of manuscript that shows clear wordings so\nthey can easily be read and the copy can also be displayed for visitors. 16\nsamples of Jawi historical manuscript with different quality problems were\nobtained from The Royal Museum of Pahang, Malaysia. We applied three\nbinarization techniques; Otsu's method represents global threshold technique;\nSauvola and Niblack method which are categorized as local threshold techniques.\nWe compared the binarized images with the original manuscript to be visually\ninspected by the museum's curator. The unclear features were marked and\nanalyzed. Most of the examined images show that with optimal parameters and\neffective pre processing technique, local thresholding methods are work well\ncompare with the other one. Niblack's and Sauvola's techniques seem to be the\nsuitable approaches for these types of images. Most of binarized images with\nthese two methods show improvement for readability and character recognition.\nFor this research, even the differences of image result were hard to be\ndistinguished by human capabilities, after comparing the time cost and overall\nachievement rate of recognized symbols, Niblack's method is performing better\nthan Sauvola's. We could improve the post processing step by adding edge\ndetection techniques and further enhanced by an innovative image refinement\ntechnique and a formulation of a class proper method.", 
    "link": "http://arxiv.org/pdf/1103.5621v1", 
    "arxiv-id": "1103.5621v1"
},{
    "category": "cs.CV", 
    "author": "Wesley E. Snyder", 
    "title": "Improved Edge Awareness in Discontinuity Preserving Smoothing", 
    "publish": "2011-03-30T01:57:09Z", 
    "summary": "Discontinuity preserving smoothing is a fundamentally important procedure\nthat is useful in a wide variety of image processing contexts. It is directly\nuseful for noise reduction, and frequently used as an intermediate step in\nhigher level algorithms. For example, it can be particularly useful in edge\ndetection and segmentation. Three well known algorithms for discontinuity\npreserving smoothing are nonlinear anisotropic diffusion, bilateral filtering,\nand mean shift filtering. Although slight differences make them each better\nsuited to different tasks, all are designed to preserve discontinuities while\nsmoothing. However, none of them satisfy this goal perfectly: they each have\nexception cases in which smoothing may occur across hard edges. The principal\ncontribution of this paper is the identification of a property we call edge\nawareness that should be satisfied by any discontinuity preserving smoothing\nalgorithm. This constraint can be incorporated into existing algorithms to\nimprove quality, and usually has negligible changes in runtime performance\nand/or complexity. We present modifications necessary to augment diffusion and\nmean shift, as well as a new formulation of the bilateral filter that unifies\nthe spatial and range spaces to achieve edge awareness.", 
    "link": "http://arxiv.org/pdf/1103.5808v1", 
    "arxiv-id": "1103.5808v1"
},{
    "category": "cs.CV", 
    "author": "Wesley E. Snyder", 
    "title": "Internal Constraints of the Trifocal Tensor", 
    "publish": "2011-03-30T21:47:41Z", 
    "summary": "The fundamental matrix and trifocal tensor are convenient algebraic\nrepresentations of the epipolar geometry of two and three view configurations,\nrespectively. The estimation of these entities is central to most\nreconstruction algorithms, and a solid understanding of their properties and\nconstraints is therefore very important. The fundamental matrix has 1 internal\nconstraint which is well understood, whereas the trifocal tensor has 8\nindependent algebraic constraints. The internal tensor constraints can be\nrepresented in many ways, although there is only one minimal and sufficient set\nof 8 constraints known. In this paper, we derive a second set of minimal and\nsufficient constraints that is simpler. We also show how this can be used in a\nnew parameterization of the trifocal tensor. We hope that this increased\nunderstanding of the internal constraints may lead to improved algorithms for\nestimating the trifocal tensor, although the primary contribution is an\nimproved theoretical understanding.", 
    "link": "http://arxiv.org/pdf/1103.6052v1", 
    "arxiv-id": "1103.6052v1"
},{
    "category": "cs.CV", 
    "author": "Ye Ji", 
    "title": "Image Retrieval Method Using Top-surf Descriptor", 
    "publish": "2011-04-04T14:14:47Z", 
    "summary": "This report presents the results and details of a content-based image\nretrieval project using the Top-surf descriptor. The experimental results are\npreliminary, however, it shows the capability of deducing objects from parts of\nthe objects or from the objects that are similar. This paper uses a dataset\nconsisting of 1200 images of which 800 images are equally divided into 8\ncategories, namely airplane, beach, motorbike, forest, elephants, horses, bus\nand building, while the other 400 images are randomly picked from the Internet.\nThe best results achieved are from building category.", 
    "link": "http://arxiv.org/pdf/1104.0579v1", 
    "arxiv-id": "1104.0579v1"
},{
    "category": "cs.CV", 
    "author": "Ran Tao", 
    "title": "Visual Concept Detection and Real Time Object Detection", 
    "publish": "2011-04-04T14:18:51Z", 
    "summary": "Bag-of-words model is implemented and tried on 10-class visual concept\ndetection problem. The experimental results show that \"DURF+ERT+SVM\"\noutperforms \"SIFT+ERT+SVM\" both in detection performance and computation\nefficiency. Besides, combining DURF and SIFT results in even better detection\nperformance. Real-time object detection using SIFT and RANSAC is also tried on\nsimple objects, e.g. drink can, and good result is achieved.", 
    "link": "http://arxiv.org/pdf/1104.0582v1", 
    "arxiv-id": "1104.0582v1"
},{
    "category": "cs.CV", 
    "author": "Gautam Sanyal", 
    "title": "A Statistical Nonparametric Approach of Face Recognition: Combination of   Eigenface & Modified k-Means Clustering", 
    "publish": "2011-04-07T03:17:08Z", 
    "summary": "Facial expressions convey non-verbal cues, which play an important role in\ninterpersonal relations. Automatic recognition of human face based on facial\nexpression can be an important component of natural human-machine interface. It\nmay also be used in behavioural science. Although human can recognize the face\npractically without any effort, but reliable face recognition by machine is a\nchallenge. This paper presents a new approach for recognizing the face of a\nperson considering the expressions of the same human face at different\ninstances of time. This methodology is developed combining Eigenface method for\nfeature extraction and modified k-Means clustering for identification of the\nhuman face. This method endowed the face recognition without using the\nconventional distance measure classifiers. Simulation results show that\nproposed face recognition using perception of k-Means clustering is useful for\nface images with different facial expressions.", 
    "link": "http://arxiv.org/pdf/1104.1237v1", 
    "arxiv-id": "1104.1237v1"
},{
    "category": "cs.CV", 
    "author": "Xiaochun Zhang", 
    "title": "Gaussian Affine Feature Detector", 
    "publish": "2011-04-08T03:15:43Z", 
    "summary": "A new method is proposed to get image features' geometric information. Using\nGaussian as an input signal, a theoretical optimal solution to calculate\nfeature's affine shape is proposed. Based on analytic result of a feature\nmodel, the method is different from conventional iterative approaches. From the\nmodel, feature's parameters such as position, orientation, background\nluminance, contrast, area and aspect ratio can be extracted. Tested with\nsynthesized and benchmark data, the method achieves or outperforms existing\napproaches in term of accuracy, speed and stability. The method can detect\nsmall, long or thin objects precisely, and works well under general conditions,\nsuch as for low contrast, blurred or noisy images.", 
    "link": "http://arxiv.org/pdf/1104.1472v1", 
    "arxiv-id": "1104.1472v1"
},{
    "category": "cs.CV", 
    "author": "J. Das", 
    "title": "Fuzzy Rules and Evidence Theory for Satellite Image Analysis", 
    "publish": "2011-04-08T05:18:15Z", 
    "summary": "Design of a fuzzy rule based classifier is proposed. The performance of the\nclassifier for multispectral satellite image classification is improved using\nDempster- Shafer theory of evidence that exploits information of the\nneighboring pixels. The classifiers are tested rigorously with two known images\nand their performance are found to be better than the results available in the\nliterature. We also demonstrate the improvement of performance while using D-S\ntheory along with fuzzy rule based classifiers over the basic fuzzy rule based\nclassifiers for all the test cases.", 
    "link": "http://arxiv.org/pdf/1104.1485v1", 
    "arxiv-id": "1104.1485v1"
},{
    "category": "cs.CV", 
    "author": "Horst K. Hahn", 
    "title": "Benchmarking the Quality of Diffusion-Weighted Images", 
    "publish": "2011-04-08T12:03:16Z", 
    "summary": "We present a novel method that allows for measuring the quality of\ndiffusion-weighted MR images dependent on the image resolution and the image\nnoise. For this purpose, we introduce a new thresholding technique so that\nnoise and the signal can automatically be estimated from a single data set.\nThus, no user interaction as well as no double acquisition technique, which\nrequires a time-consuming proper geometrical registration, is needed. As a\ncoarser image resolution or slice thickness leads to a higher signal-to-noise\nratio (SNR), our benchmark determines a resolution-independent quality measure\nso that images with different resolutions can be adequately compared. To\nevaluate our method, a set of diffusion-weighted images from different vendors\nis used. It is shown that the quality can efficiently be determined and that\nthe automatically computed SNR is comparable to the SNR which is measured\nmanually in a manually selected region of interest.", 
    "link": "http://arxiv.org/pdf/1104.1556v3", 
    "arxiv-id": "1104.1556v3"
},{
    "category": "cs.CV", 
    "author": "Manesh B. Kokare", 
    "title": "Off-Line Handwritten Signature Retrieval using Curvelet Transforms", 
    "publish": "2011-04-11T13:37:08Z", 
    "summary": "In this paper, a new method for offline handwritten signature retrieval is\nbased on curvelet transform is proposed. Many applications in image processing\nrequire similarity retrieval of an image from a large collection of images. In\nsuch cases, image indexing becomes important for efficient organization and\nretrieval of images. This paper addresses this issue in the context of a\ndatabase of handwritten signature images and describes a system for similarity\nretrieval. The proposed system uses a curvelet based texture features\nextraction. The performance of the system has been tested with an image\ndatabase of 180 signatures. The results obtained indicate that the proposed\nsystem is able to identify signatures with great with accuracy even when a part\nof a signature is missing.", 
    "link": "http://arxiv.org/pdf/1104.1945v1", 
    "arxiv-id": "1104.1945v1"
},{
    "category": "cs.CV", 
    "author": "Kwie Min Wong", 
    "title": "Template-based matching using weight maps", 
    "publish": "2011-04-11T20:32:54Z", 
    "summary": "Template matching is one of the most prevalent pattern recognition methods\nworldwide. It has found uses in most visual concept detection fields. In this\nwork, we investigate methods for improving template matching by adjusting the\nweights of different regions of the template. We compare several weight maps\nand test the methods using the FERET face test set in the context of human eye\ndetection.", 
    "link": "http://arxiv.org/pdf/1104.2059v1", 
    "arxiv-id": "1104.2059v1"
},{
    "category": "cs.CV", 
    "author": "Alwin de Rooij", 
    "title": "GEOMIR2K9 - A Similar Scene Finder", 
    "publish": "2011-04-11T21:17:28Z", 
    "summary": "The main goal of the GEOMIR2K9 project is to create a software program that\nis able to find similar scenic images clustered by geographical location and\nsorted by similarity based only on their visual content. The user should be\nable to input a query image, based on this given query image the program should\nfind relevant visual content and present this to the user in a meaningful way.\nTechnically the goal for the GEOMIR2K9 project is twofold. The first of these\ntwo goals is to create a basic low level visual information retrieval system.\nThis includes feature extraction, post processing of the feature data and\nclassification/ clustering based on similarity with a strong focus on scenic\nimages. The second goal of this project is to provide the user with a novel and\nsuitable interface and visualization method so that the user may interact with\nthe retrieved images in a natural and meaningful way.", 
    "link": "http://arxiv.org/pdf/1104.2069v1", 
    "arxiv-id": "1104.2069v1"
},{
    "category": "cs.CV", 
    "author": "Murat Genctav", 
    "title": "From a Modified Ambrosio-Tortorelli to a Randomized Part Hierarchy Tree", 
    "publish": "2011-04-12T11:20:06Z", 
    "summary": "We demonstrate the possibility of coding parts, features that are higher\nlevel than boundaries, using a modified AT field after augmenting the\ninteraction term of the AT energy with a non-local term and weakening the\nseparation into boundary/not-boundary phases. The iteratively extracted parts\nusing the level curves with double point singularities are organized as a\nproper binary tree. Inconsistencies due to non-generic configurations for level\ncurves as well as due to visual changes such as occlusion are successfully\nhandled once the tree is endowed with a probabilistic structure. The work is a\nstep in establishing the AT function as a bridge between low and high level\nvisual processing.", 
    "link": "http://arxiv.org/pdf/1104.2171v1", 
    "arxiv-id": "1104.2171v1"
},{
    "category": "cs.CV", 
    "author": "Sibel Tari", 
    "title": "Extracting Parts of 2D Shapes Using Local and Global Interactions   Simultaneously", 
    "publish": "2011-04-12T11:33:20Z", 
    "summary": "Perception research provides strong evidence in favor of part based\nrepresentation of shapes in human visual system. Despite considerable\ndifferences among different theories in terms of how part boundaries are found,\nthere is substantial agreement on that the process depends on many local and\nglobal geometric factors. This poses an important challenge from the\ncomputational point of view. In the first part of the chapter, I present a\nnovel decomposition method by taking both local and global interactions within\nthe shape domain into account. At the top of the partitioning hierarchy, the\nshape gets split into two parts capturing, respectively, the gross structure\nand the peripheral structure. The gross structure may be conceived as the least\ndeformable part of the shape which remains stable under visual transformations.\nThe peripheral structure includes limbs, protrusions, and boundary texture.\nSuch a separation is in accord with the behavior of the artists who start with\na gross shape and enrich it with details. The method is particularly\ninteresting from the computational point of view as it does not resort to any\ngeometric notions (e.g. curvature, convexity) explicitly. In the second part of\nthe chapter, I relate the new method to PDE based shape representation schemes.", 
    "link": "http://arxiv.org/pdf/1104.2175v1", 
    "arxiv-id": "1104.2175v1"
},{
    "category": "cs.CV", 
    "author": "Sibel Tari", 
    "title": "An Axis-Based Representation for Recognition", 
    "publish": "2011-04-14T12:52:40Z", 
    "summary": "This paper presents a new axis-based shape representation scheme along with a\nmatching framework to address the problem of generic shape recognition. The\nmain idea is to define the relative spatial arrangement of local symmetry axes\nand their metric properties in a shape centered coordinate frame. The resulting\ndescriptions are invariant to scale, rotation, small changes in viewpoint and\narticulations. Symmetry points are extracted from a surface whose level curves\nroughly mimic the motion by curvature. By increasing the amount of smoothing on\nthe evolving curve, only those symmetry axes that correspond to the most\nprominent parts of a shape are extracted. The representation does not suffer\nfrom the common instability problems of the traditional connected skeletons. It\ncaptures the perceptual qualities of shapes well. Therefore finding the\nsimilarities and the differences among shapes becomes easier. The matching\nprocess gives highly successful results on a diverse database of 2D shapes.", 
    "link": "http://arxiv.org/pdf/1104.2745v1", 
    "arxiv-id": "1104.2745v1"
},{
    "category": "cs.CV", 
    "author": "S. Tari", 
    "title": "Disconnected Skeleton: Shape at its Absolute Scale", 
    "publish": "2011-04-14T13:02:43Z", 
    "summary": "We present a new skeletal representation along with a matching framework to\naddress the deformable shape recognition problem. The disconnectedness arises\nas a result of excessive regularization that we use to describe a shape at an\nattainably coarse scale. Our motivation is to rely on the stable properties of\nthe shape instead of inaccurately measured secondary details. The new\nrepresentation does not suffer from the common instability problems of\ntraditional connected skeletons, and the matching process gives quite\nsuccessful results on a diverse database of 2D shapes. An important difference\nof our approach from the conventional use of the skeleton is that we replace\nthe local coordinate frame with a global Euclidean frame supported by\nadditional mechanisms to handle articulations and local boundary deformations.\nAs a result, we can produce descriptions that are sensitive to any combination\nof changes in scale, position, orientation and articulation, as well as\ninvariant ones.", 
    "link": "http://arxiv.org/pdf/1104.2751v1", 
    "arxiv-id": "1104.2751v1"
},{
    "category": "cs.CV", 
    "author": "Arnaldo Ara\u00fajo", 
    "title": "Hue Histograms to Spatiotemporal Local Features for Action Recognition", 
    "publish": "2011-04-19T13:36:15Z", 
    "summary": "Despite the recent developments in spatiotemporal local features for action\nrecognition in video sequences, local color information has so far been\nignored. However, color has been proved an important element to the success of\nautomated recognition of objects and scenes. In this paper we extend the\nspace-time interest point descriptor STIP to take into account the color\ninformation on the features' neighborhood. We compare the performance of our\ncolor-aware version of STIP (which we have called HueSTIP) with the original\none.", 
    "link": "http://arxiv.org/pdf/1104.3742v1", 
    "arxiv-id": "1104.3742v1"
},{
    "category": "cs.CV", 
    "author": "Eraldo Ribeiro", 
    "title": "A Meshless Method for Variational Nonrigid 2-D Shape Registration", 
    "publish": "2011-04-21T04:48:41Z", 
    "summary": "We present a method for nonrigid registration of 2-D geometric shapes. Our\ncontribution is twofold. First, we extend the classic chamfer-matching energy\nto a variational functional. Secondly, we introduce a meshless deformation\nmodel that can handle significant high-curvature deformations. We represent 2-D\nshapes implicitly using distance transforms, and registration error is defined\nbased on the shape contours' mutual distances. In addition, we model global\nshape deformation as an approximation blended from local deformation fields\nusing partition-of-unity. The global deformation field is regularized by\npenalizing inconsistencies between local fields. The representation can be made\nadaptive to shape's contour, leading to registration that is both flexible and\nefficient. Finally, registration is achieved by minimizing a variational\nchamfer-energy functional combined with the consistency regularizer. We\ndemonstrate the effectiveness of our method on a number of experiments.", 
    "link": "http://arxiv.org/pdf/1104.4168v1", 
    "arxiv-id": "1104.4168v1"
},{
    "category": "cs.CV", 
    "author": "Carsten Gottschlich", 
    "title": "Curved Gabor Filters for Fingerprint Image Enhancement", 
    "publish": "2011-04-21T15:52:39Z", 
    "summary": "Gabor filters play an important role in many application areas for the\nenhancement of various types of images and the extraction of Gabor features.\nFor the purpose of enhancing curved structures in noisy images, we introduce\ncurved Gabor filters which locally adapt their shape to the direction of flow.\nThese curved Gabor filters enable the choice of filter parameters which\nincrease the smoothing power without creating artifacts in the enhanced image.\nIn this paper, curved Gabor filters are applied to the curved ridge and valley\nstructure of low-quality fingerprint images. First, we combine two orientation\nfield estimation methods in order to obtain a more robust estimation for very\nnoisy images. Next, curved regions are constructed by following the respective\nlocal orientation and they are used for estimating the local ridge frequency.\nLastly, curved Gabor filters are defined based on curved regions and they are\napplied for the enhancement of low-quality fingerprint images. Experimental\nresults on the FVC2004 databases show improvements of this approach in\ncomparison to state-of-the-art enhancement methods.", 
    "link": "http://arxiv.org/pdf/1104.4298v2", 
    "arxiv-id": "1104.4298v2"
},{
    "category": "cs.CV", 
    "author": "Anton van den Hengel", 
    "title": "Positive Semidefinite Metric Learning Using Boosting-like Algorithms", 
    "publish": "2011-04-25T10:38:03Z", 
    "summary": "The success of many machine learning and pattern recognition methods relies\nheavily upon the identification of an appropriate distance metric on the input\ndata. It is often beneficial to learn such a metric from the input training\ndata, instead of using a default one such as the Euclidean distance. In this\nwork, we propose a boosting-based technique, termed BoostMetric, for learning a\nquadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance\nmetric requires enforcing the constraint that the matrix parameter to the\nmetric remains positive definite. Semidefinite programming is often used to\nenforce this constraint, but does not scale well and easy to implement.\nBoostMetric is instead based on the observation that any positive semidefinite\nmatrix can be decomposed into a linear combination of trace-one rank-one\nmatrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak\nlearners within an efficient and scalable boosting-based learning process. The\nresulting methods are easy to implement, efficient, and can accommodate various\ntypes of constraints. We extend traditional boosting algorithms in that its\nweak learner is a positive semidefinite matrix with trace and rank being one\nrather than a classifier or regressor. Experiments on various datasets\ndemonstrate that the proposed algorithms compare favorably to those\nstate-of-the-art methods in terms of classification accuracy and running time.", 
    "link": "http://arxiv.org/pdf/1104.4704v2", 
    "arxiv-id": "1104.4704v2"
},{
    "category": "cs.CV", 
    "author": "Debasis Bhattacharyya", 
    "title": "Preprocessing: A Step in Automating Early Detection of Cervical Cancer", 
    "publish": "2011-04-26T18:38:01Z", 
    "summary": "This paper has been withdrawn", 
    "link": "http://arxiv.org/pdf/1104.4989v6", 
    "arxiv-id": "1104.4989v6"
},{
    "category": "cs.CV", 
    "author": "Bertrand Thirion", 
    "title": "A supervised clustering approach for fMRI-based inference of brain   states", 
    "publish": "2011-04-28T06:12:45Z", 
    "summary": "We propose a method that combines signals from many brain regions observed in\nfunctional Magnetic Resonance Imaging (fMRI) to predict the subject's behavior\nduring a scanning session. Such predictions suffer from the huge number of\nbrain regions sampled on the voxel grid of standard fMRI data sets: the curse\nof dimensionality. Dimensionality reduction is thus needed, but it is often\nperformed using a univariate feature selection procedure, that handles neither\nthe spatial structure of the images, nor the multivariate nature of the signal.\nBy introducing a hierarchical clustering of the brain volume that incorporates\nconnectivity constraints, we reduce the span of the possible spatial\nconfigurations to a single tree of nested regions tailored to the signal. We\nthen prune the tree in a supervised setting, hence the name supervised\nclustering, in order to extract a parcellation (division of the volume) such\nthat parcel-based signal averages best predict the target information.\nDimensionality reduction is thus achieved by feature agglomeration, and the\nconstructed features now provide a multi-scale representation of the signal.\nComparisons with reference methods on both simulated and real data show that\nour approach yields higher prediction accuracy than standard voxel-based\napproaches. Moreover, the method infers an explicit weighting of the regions\ninvolved in the regression or classification task.", 
    "link": "http://arxiv.org/pdf/1104.5304v1", 
    "arxiv-id": "1104.5304v1"
},{
    "category": "cs.CV", 
    "author": "Abdul Yazid Mohd Kassim", 
    "title": "An Automated Size Recognition Technique for Acetabular Implant in Total   Hip Replacement", 
    "publish": "2011-04-30T12:07:11Z", 
    "summary": "Preoperative templating in Total Hip Replacement (THR) is a method to\nestimate the optimal size and position of the implant. Today, observational\n(manual) size recognition techniques are still used to find a suitable implant\nfor the patient. Therefore, a digital and automated technique should be\ndeveloped so that the implant size recognition process can be effectively\nimplemented. For this purpose, we have introduced the new technique for\nacetabular implant size recognition in THR preoperative planning based on the\ndiameter of acetabulum size. This technique enables the surgeon to recognise a\ndigital acetabular implant size automatically. Ten randomly selected X-rays of\nunidentified patients were used to test the accuracy and utility of an\nautomated implant size recognition technique. Based on the testing result, the\nnew technique yielded very close results to those obtained by the observational\nmethod in nine studies (90%).", 
    "link": "http://arxiv.org/pdf/1105.0079v1", 
    "arxiv-id": "1105.0079v1"
},{
    "category": "cs.CV", 
    "author": "Ciprian Ilioaei", 
    "title": "Considerations and Results in Multimedia and DVB Application Development   on Philips Nexperia Platform", 
    "publish": "2011-05-04T13:40:16Z", 
    "summary": "This paper presents some experiments regarding applications development on\nhigh performance media processors included in Philips Nexperia Family. The\nPNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded\nto overcome these limitations and to make possible a general-purpose use of\nthis kit. For exemplification two typical applications, important both for\nmultimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio\ndecoding. These original implementations are compared (in speed, memory\nrequirements and costs) with Philips Nexperia Library.", 
    "link": "http://arxiv.org/pdf/1105.0821v1", 
    "arxiv-id": "1105.0821v1"
},{
    "category": "cs.CV", 
    "author": "Vittorio Murino", 
    "title": "A Multiple Component Matching Framework for Person Re-Identification", 
    "publish": "2011-05-12T14:46:01Z", 
    "summary": "Person re-identification consists in recognizing an individual that has\nalready been observed over a network of cameras. It is a novel and challenging\nresearch topic in computer vision, for which no reference framework exists yet.\nDespite this, previous works share similar representations of human body based\non part decomposition and the implicit concept of multiple instances. Building\non these similarities, we propose a Multiple Component Matching (MCM) framework\nfor the person re-identification problem, which is inspired by Multiple\nComponent Learning, a framework recently proposed for object detection. We show\nthat previous techniques for person re-identification can be considered\nparticular implementations of our MCM framework. We then present a novel person\nre-identification technique as a direct, simple implementation of our\nframework, focused in particular on robustness to varying lighting conditions,\nand show that it can attain state of the art performances.", 
    "link": "http://arxiv.org/pdf/1105.2491v2", 
    "arxiv-id": "1105.2491v2"
},{
    "category": "cs.CV", 
    "author": "Patrick Grother", 
    "title": "Face Recognition using 3D Facial Shape and Color Map Information:   Comparison and Combination", 
    "publish": "2011-05-13T18:25:28Z", 
    "summary": "In this paper, we investigate the use of 3D surface geometry for face\nrecognition and compare it to one based on color map information. The 3D\nsurface and color map data are from the CAESAR anthropometric database. We find\nthat the recognition performance is not very different between 3D surface and\ncolor map information using a principal component analysis algorithm. We also\ndiscuss the different techniques for the combination of the 3D surface and\ncolor map information for multi-modal recognition by using different fusion\napproaches and show that there is significant improvement in results. The\neffectiveness of various techniques is compared and evaluated on a dataset with\n200 subjects in two different positions.", 
    "link": "http://arxiv.org/pdf/1105.2797v1", 
    "arxiv-id": "1105.2797v1"
},{
    "category": "cs.CV", 
    "author": "Walter G. Kropatsch", 
    "title": "Invariant Representative Cocycles of Cohomology Generators using   Irregular Graph Pyramids", 
    "publish": "2011-05-18T08:18:42Z", 
    "summary": "Structural pattern recognition describes and classifies data based on the\nrelationships of features and parts. Topological invariants, like the Euler\nnumber, characterize the structure of objects of any dimension. Cohomology can\nprovide more refined algebraic invariants to a topological space than does\nhomology. It assigns `quantities' to the chains used in homology to\ncharacterize holes of any dimension. Graph pyramids can be used to describe\nsubdivisions of the same object at multiple levels of detail. This paper\npresents cohomology in the context of structural pattern recognition and\nintroduces an algorithm to efficiently compute representative cocycles (the\nbasic elements of cohomology) in 2D using a graph pyramid. An extension to\nobtain scanning and rotation invariant cocycles is given.", 
    "link": "http://arxiv.org/pdf/1105.3559v4", 
    "arxiv-id": "1105.3559v4"
},{
    "category": "cs.CV", 
    "author": "Evgeniy Martyushev", 
    "title": "An Algorithmic Solution to the Five-Point Pose Problem Based on the   Cayley Representation of Rotations", 
    "publish": "2011-05-19T09:50:01Z", 
    "summary": "We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial.", 
    "link": "http://arxiv.org/pdf/1105.3828v2", 
    "arxiv-id": "1105.3828v2"
},{
    "category": "cs.CV", 
    "author": "Vanni Rizzo", 
    "title": "A Multiple-Choice Test Recognition System based on the Gamera Framework", 
    "publish": "2011-05-19T10:09:44Z", 
    "summary": "This article describes JECT-OMR, a system that analyzes digital images\nrepresenting scans of multiple-choice tests compiled by students. The system\nperforms a structural analysis of the document in order to get the chosen\nanswer for each question, and it also contains a bar-code decoder, used for the\nidentification of additional information encoded in the document. JECT-OMR was\nimplemented using the Python programming language, and leverages the power of\nthe Gamera framework in order to accomplish its task. The system exhibits an\naccuracy of over 99% in the recognition of marked and non-marked squares\nrepresenting answers, thus making it suitable for real world applications", 
    "link": "http://arxiv.org/pdf/1105.3834v1", 
    "arxiv-id": "1105.3834v1"
},{
    "category": "cs.CV", 
    "author": "Belen Medrano", 
    "title": "Cubical Cohomology Ring of 3D Photographs", 
    "publish": "2011-05-20T22:12:41Z", 
    "summary": "Cohomology and cohomology ring of three-dimensional (3D) objects are\ntopological invariants that characterize holes and their relations. Cohomology\nring has been traditionally computed on simplicial complexes. Nevertheless,\ncubical complexes deal directly with the voxels in 3D images, no additional\ntriangulation is necessary, facilitating efficient algorithms for the\ncomputation of topological invariants in the image context. In this paper, we\npresent formulas to directly compute the cohomology ring of 3D cubical\ncomplexes without making use of any additional triangulation. Starting from a\ncubical complex $Q$ that represents a 3D binary-valued digital picture whose\nforeground has one connected component, we compute first the cohomological\ninformation on the boundary of the object, $\\partial Q$ by an incremental\ntechnique; then, using a face reduction algorithm, we compute it on the whole\nobject; finally, applying the mentioned formulas, the cohomology ring is\ncomputed from such information.", 
    "link": "http://arxiv.org/pdf/1105.4183v1", 
    "arxiv-id": "1105.4183v1"
},{
    "category": "cs.CV", 
    "author": "Debasis Bhattacharyya", 
    "title": "Preprocessing for Automating Early Detection of Cervical Cancer", 
    "publish": "2011-05-22T17:06:59Z", 
    "summary": "Uterine Cervical Cancer is one of the most common forms of cancer in women\nworldwide. Most cases of cervical cancer can be prevented through screening\nprograms aimed at detecting precancerous lesions. During Digital Colposcopy,\ncolposcopic images or cervigrams are acquired in raw form. They contain\nspecular reflections which appear as bright spots heavily saturated with white\nlight and occur due to the presence of moisture on the uneven cervix surface\nand. The cervix region occupies about half of the raw cervigram image. Other\nparts of the image contain irrelevant information, such as equipment, frames,\ntext and non-cervix tissues. This irrelevant information can confuse automatic\nidentification of the tissues within the cervix. Therefore we focus on the\ncervical borders, so that we have a geometric boundary on the relevant image\narea. Our novel technique eliminates the SR, identifies the region of interest\nand makes the cervigram ready for segmentation algorithms.", 
    "link": "http://arxiv.org/pdf/1105.4354v2", 
    "arxiv-id": "1105.4354v2"
},{
    "category": "cs.CV", 
    "author": "Pedro Real", 
    "title": "On the Cohomology of 3D Digital Images", 
    "publish": "2011-05-23T12:06:18Z", 
    "summary": "We propose a method for computing the cohomology ring of three--dimensional\n(3D) digital binary-valued pictures. We obtain the cohomology ring of a 3D\ndigital binary--valued picture $I$, via a simplicial complex K(I)topologically\nrepresenting (up to isomorphisms of pictures) the picture I. The usefulness of\na simplicial description of the \"digital\" cohomology ring of 3D digital\nbinary-valued pictures is tested by means of a small program visualizing the\ndifferent steps of the method. Some examples concerning topological thinning,\nthe visualization of representative (co)cycles of (co)homology generators and\nthe computation of the cup product on the cohomology of simple pictures are\nshowed.", 
    "link": "http://arxiv.org/pdf/1105.4477v1", 
    "arxiv-id": "1105.4477v1"
},{
    "category": "cs.CV", 
    "author": "Pedro Real", 
    "title": "A Tool for Integer Homology Computation: Lambda-At Model", 
    "publish": "2011-05-23T12:40:06Z", 
    "summary": "In this paper, we formalize the notion of lambda-AT-model (where $\\lambda$ is\na non-null integer) for a given chain complex, which allows the computation of\nhomological information in the integer domain avoiding using the Smith Normal\nForm of the boundary matrices. We present an algorithm for computing such a\nmodel, obtaining Betti numbers, the prime numbers p involved in the invariant\nfactors of the torsion subgroup of homology, the amount of invariant factors\nthat are a power of p and a set of representative cycles of generators of\nhomology mod p, for each p. Moreover, we establish the minimum valid lambda for\nsuch a construction, what cuts down the computational costs related to the\ntorsion subgroup. The tools described here are useful to determine topological\ninformation of nD structured objects such as simplicial, cubical or simploidal\ncomplexes and are applicable to extract such an information from digital\npictures.", 
    "link": "http://arxiv.org/pdf/1105.4480v1", 
    "arxiv-id": "1105.4480v1"
},{
    "category": "cs.CV", 
    "author": "Lalitha Rangarajan", 
    "title": "Image Splicing Detection Using Inherent Lens Radial Distortion", 
    "publish": "2011-05-24T09:05:04Z", 
    "summary": "Image splicing is a common form of image forgery. Such alterations may leave\nno visual clues of tampering. In recent works camera characteristics\nconsistency across the image has been used to establish the authenticity and\nintegrity of digital images. Such constant camera characteristic properties are\ninherent from camera manufacturing processes and are unique. The majority of\ndigital cameras are equipped with spherical lens and this introduces radial\ndistortions on images. This aberration is often disturbed and fails to be\nconsistent across the image, when an image is spliced. This paper describes the\ndetection of splicing operation on images by estimating radial distortion from\ndifferent portions of the image using line-based calibration. For the first\ntime, the detection of image splicing through the verification of consistency\nof lens radial distortion has been explored in this paper. The conducted\nexperiments demonstrate the efficacy of our proposed approach for the detection\nof image splicing on both synthetic and real images.", 
    "link": "http://arxiv.org/pdf/1105.4712v1", 
    "arxiv-id": "1105.4712v1"
},{
    "category": "cs.CV", 
    "author": "Yafei Sun", 
    "title": "Neural Networks for Emotion Classification", 
    "publish": "2011-05-30T15:19:55Z", 
    "summary": "It is argued that for the computer to be able to interact with humans, it\nneeds to have the communication skills of humans. One of these skills is the\nability to understand the emotional state of the person. This thesis describes\na neural network-based approach for emotion classification. We learn a\nclassifier that can recognize six basic emotions with an average accuracy of\n77% over the Cohn-Kanade database. The novelty of this work is that instead of\nempirically selecting the parameters of the neural network, i.e. the learning\nrate, activation function parameter, momentum number, the number of nodes in\none layer, etc. we developed a strategy that can automatically select\ncomparatively better combination of these parameters. We also introduce another\nway to perform back propagation. Instead of using the partial differential of\nthe error function, we use optimal algorithm; namely Powell's direction set to\nminimize the error function. We were also interested in construction an\nauthentic emotion databases. This is a very important task because nowadays\nthere is no such database available. Finally, we perform several experiments\nand show that our neural network approach can be successfully used for emotion\nrecognition.", 
    "link": "http://arxiv.org/pdf/1105.6014v1", 
    "arxiv-id": "1105.6014v1"
},{
    "category": "cs.CV", 
    "author": "Erwin M. Bakker", 
    "title": "Alignment of Microtubule Imagery", 
    "publish": "2011-05-30T18:30:51Z", 
    "summary": "This work discusses preliminary work aimed at simulating and visualizing the\ngrowth process of a tiny structure inside the cell---the microtubule.\nDifficulty of recording the process lies in the fact that the tissue\npreparation method for electronic microscopes is highly destructive to live\ncells. Here in this paper, our approach is to take pictures of microtubules at\ndifferent time slots and then appropriately combine these images into a\ncoherent video. Experimental results are given on real data.", 
    "link": "http://arxiv.org/pdf/1105.6060v1", 
    "arxiv-id": "1105.6060v1"
},{
    "category": "cs.CV", 
    "author": "David Suter", 
    "title": "Incremental Top-k List Comparison Approach to Robust Multi-Structure   Model Fitting", 
    "publish": "2011-05-31T13:45:46Z", 
    "summary": "Random hypothesis sampling lies at the core of many popular robust fitting\ntechniques such as RANSAC. In this paper, we propose a novel hypothesis\nsampling scheme based on incremental computation of distances between partial\nrankings (top-$k$ lists) derived from residual sorting information. Our method\nsimultaneously (1) guides the sampling such that hypotheses corresponding to\nall true structures can be quickly retrieved and (2) filters the hypotheses\nsuch that only a small but very promising subset remain. This permits the usage\nof simple agglomerative clustering on the surviving hypotheses for accurate\nmodel selection. The outcome is a highly efficient multi-structure robust\nestimation technique. Experiments on synthetic and real data show the superior\nperformance of our approach over previous methods.", 
    "link": "http://arxiv.org/pdf/1105.6277v1", 
    "arxiv-id": "1105.6277v1"
},{
    "category": "cs.CV", 
    "author": "Nazar Zaki", 
    "title": "A Novel Image Segmentation Enhancement Technique based on Active Contour   and Topological Alignments", 
    "publish": "2011-06-02T06:31:13Z", 
    "summary": "Topological alignments and snakes are used in image processing, particularly\nin locating object boundaries. Both of them have their own advantages and\nlimitations. To improve the overall image boundary detection system, we focused\non developing a novel algorithm for image processing. The algorithm we propose\nto develop will based on the active contour method in conjunction with\ntopological alignments method to enhance the image detection approach. The\nalgorithm presents novel technique to incorporate the advantages of both\nTopological Alignments and snakes. Where the initial segmentation by\nTopological Alignments is firstly transformed into the input of the snake model\nand begins its evolvement to the interested object boundary. The results show\nthat the algorithm can deal with low contrast images and shape cells,\ndemonstrate the segmentation accuracy under weak image boundaries, which\nresponsible for lacking accuracy in image detecting techniques. We have\nachieved better segmentation and boundary detecting for the image, also the\nability of the system to improve the low contrast and deal with over and under\nsegmentation.", 
    "link": "http://arxiv.org/pdf/1106.0371v1", 
    "arxiv-id": "1106.0371v1"
},{
    "category": "cs.CV", 
    "author": "A. Konar", 
    "title": "An efficient circle detection scheme in digital images using ant system   algorithm", 
    "publish": "2011-06-06T05:52:09Z", 
    "summary": "Detection of geometric features in digital images is an important exercise in\nimage analysis and computer vision. The Hough Transform techniques for\ndetection of circles require a huge memory space for data processing hence\nrequiring a lot of time in computing the locations of the data space, writing\nto and searching through the memory space. In this paper we propose a novel and\nefficient scheme for detecting circles in edge-detected grayscale digital\nimages. We use Ant-system algorithm for this purpose which has not yet found\nmuch application in this field. The main feature of this scheme is that it can\ndetect both intersecting as well as non-intersecting circles with a time\nefficiency that makes it useful in real time applications. We build up an ant\nsystem of new type which finds out closed loops in the image and then tests\nthem for circles.", 
    "link": "http://arxiv.org/pdf/1106.0962v1", 
    "arxiv-id": "1106.0962v1"
},{
    "category": "cs.CV", 
    "author": "Valentina E. Balas", 
    "title": "Comparing Haar-Hilbert and Log-Gabor Based Iris Encoders on Bath Iris   Image Database", 
    "publish": "2011-06-12T23:14:05Z", 
    "summary": "This papers introduces a new family of iris encoders which use 2-dimensional\nHaar Wavelet Transform for noise attenuation, and Hilbert Transform to encode\nthe iris texture. In order to prove the usefulness of the newly proposed iris\nencoding approach, the recognition results obtained by using these new encoders\nare compared to those obtained using the classical Log- Gabor iris encoder.\nTwelve tests involving single/multienrollment and conducted on Bath Iris Image\nDatabase are presented here. One of these tests achieves an Equal Error Rate\ncomparable to the lowest value reported so far for this database. New Matlab\ntools for iris image processing are also released together with this paper: a\nsecond version of the Circular Fuzzy Iris Segmentator (CFIS2), a fast Log-Gabor\nencoder and two Haar-Hilbert based encoders.", 
    "link": "http://arxiv.org/pdf/1106.2357v1", 
    "arxiv-id": "1106.2357v1"
},{
    "category": "cs.CV", 
    "author": "Etienne Corvee", 
    "title": "Robust Mobile Object Tracking Based on Multiple Feature Similarity and   Trajectory Filtering", 
    "publish": "2011-06-14T12:45:05Z", 
    "summary": "This paper presents a new algorithm to track mobile objects in different\nscene conditions. The main idea of the proposed tracker includes estimation,\nmulti-features similarity measures and trajectory filtering. A feature set\n(distance, area, shape ratio, color histogram) is defined for each tracked\nobject to search for the best matching object. Its best matching object and its\nstate estimated by the Kalman filter are combined to update position and size\nof the tracked object. However, the mobile object trajectories are usually\nfragmented because of occlusions and misdetections. Therefore, we also propose\na trajectory filtering, named global tracker, aims at removing the noisy\ntrajectories and fusing the fragmented trajectories belonging to a same mobile\nobject. The method has been tested with five videos of different scene\nconditions. Three of them are provided by the ETISEO benchmarking project\n(http://www-sop.inria.fr/orion/ETISEO) in which the proposed tracker\nperformance has been compared with other seven tracking algorithms. The\nadvantages of our approach over the existing state of the art ones are: (i) no\nprior knowledge information is required (e.g. no calibration and no contextual\nmodels are needed), (ii) the tracker is more reliable by combining multiple\nfeature similarities, (iii) the tracker can perform in different scene\nconditions: single/several mobile objects, weak/strong illumination,\nindoor/outdoor scenes, (iv) a trajectory filtering is defined and applied to\nimprove the tracker performance, (v) the tracker performance outperforms many\nalgorithms of the state of the art.", 
    "link": "http://arxiv.org/pdf/1106.2695v1", 
    "arxiv-id": "1106.2695v1"
},{
    "category": "cs.CV", 
    "author": "Mita Nasipuri", 
    "title": "Polar Fusion Technique Analysis for Evaluating the Performances of Image   Fusion of Thermal and Visual Images for Human Face Recognition", 
    "publish": "2011-06-17T12:25:30Z", 
    "summary": "This paper presents a comparative study of two different methods, which are\nbased on fusion and polar transformation of visual and thermal images. Here,\ninvestigation is done to handle the challenges of face recognition, which\ninclude pose variations, changes in facial expression, partial occlusions,\nvariations in illumination, rotation through different angles, change in scale\netc. To overcome these obstacles we have implemented and thoroughly examined\ntwo different fusion techniques through rigorous experimentation. In the first\nmethod log-polar transformation is applied to the fused images obtained after\nfusion of visual and thermal images whereas in second method fusion is applied\non log-polar transformed individual visual and thermal images. After this step,\nwhich is thus obtained in one form or another, Principal Component Analysis\n(PCA) is applied to reduce dimension of the fused images. Log-polar transformed\nimages are capable of handling complicacies introduced by scaling and rotation.\nThe main objective of employing fusion is to produce a fused image that\nprovides more detailed and reliable information, which is capable to overcome\nthe drawbacks present in the individual visual and thermal face images.\nFinally, those reduced fused images are classified using a multilayer\nperceptron neural network. The database used for the experiments conducted here\nis Object Tracking and Classification Beyond Visible Spectrum (OTCBVS) database\nbenchmark thermal and visual face images. The second method has shown better\nperformance, which is 95.71% (maximum) and on an average 93.81% as correct\nrecognition rate.", 
    "link": "http://arxiv.org/pdf/1106.3464v1", 
    "arxiv-id": "1106.3464v1"
},{
    "category": "cs.CV", 
    "author": "Mita Nasipuri", 
    "title": "Next Level of Data Fusion for Human Face Recognition", 
    "publish": "2011-06-17T12:31:30Z", 
    "summary": "This paper demonstrates two different fusion techniques at two different\nlevels of a human face recognition process. The first one is called data fusion\nat lower level and the second one is the decision fusion towards the end of the\nrecognition process. At first a data fusion is applied on visual and\ncorresponding thermal images to generate fused image. Data fusion is\nimplemented in the wavelet domain after decomposing the images through\nDaubechies wavelet coefficients (db2). During the data fusion maximum of\napproximate and other three details coefficients are merged together. After\nthat Principle Component Analysis (PCA) is applied over the fused coefficients\nand finally two different artificial neural networks namely Multilayer\nPerceptron(MLP) and Radial Basis Function(RBF) networks have been used\nseparately to classify the images. After that, for decision fusion based\ndecisions from both the classifiers are combined together using Bayesian\nformulation. For experiments, IRIS thermal/visible Face Database has been used.\nExperimental results show that the performance of multiple classifier system\nalong with decision fusion works well over the single classifier system.", 
    "link": "http://arxiv.org/pdf/1106.3466v1", 
    "arxiv-id": "1106.3466v1"
},{
    "category": "cs.CV", 
    "author": "Mahantapas Kundu", 
    "title": "High Performance Human Face Recognition using Independent High Intensity   Gabor Wavelet Responses: A Statistical Approach", 
    "publish": "2011-06-17T12:42:26Z", 
    "summary": "In this paper, we present a technique by which high-intensity feature vectors\nextracted from the Gabor wavelet transformation of frontal face images, is\ncombined together with Independent Component Analysis (ICA) for enhanced face\nrecognition. Firstly, the high-intensity feature vectors are automatically\nextracted using the local characteristics of each individual face from the\nGabor transformed images. Then ICA is applied on these locally extracted\nhigh-intensity feature vectors of the facial images to obtain the independent\nhigh intensity feature (IHIF) vectors. These IHIF forms the basis of the work.\nFinally, the image classification is done using these IHIF vectors, which are\nconsidered as representatives of the images. The importance behind implementing\nICA along with the high-intensity features of Gabor wavelet transformation is\ntwofold. On the one hand, selecting peaks of the Gabor transformed face images\nexhibit strong characteristics of spatial locality, scale, and orientation\nselectivity. Thus these images produce salient local features that are most\nsuitable for face recognition. On the other hand, as the ICA employs locally\nsalient features from the high informative facial parts, it reduces redundancy\nand represents independent features explicitly. These independent features are\nmost useful for subsequent facial discrimination and associative recall. The\nefficiency of IHIF method is demonstrated by the experiment on frontal facial\nimages dataset, selected from the FERET, FRAV2D, and the ORL database.", 
    "link": "http://arxiv.org/pdf/1106.3467v1", 
    "arxiv-id": "1106.3467v1"
},{
    "category": "cs.CV", 
    "author": "Sabyasachi Pattanaik", 
    "title": "DWT Based Fingerprint Recognition using Non Minutiae Features", 
    "publish": "2011-06-17T15:52:56Z", 
    "summary": "Forensic applications like criminal investigations, terrorist identification\nand National security issues require a strong fingerprint data base and\nefficient identification system. In this paper we propose DWT based Fingerprint\nRecognition using Non Minutiae (DWTFR) algorithm. Fingerprint image is\ndecomposed into multi resolution sub bands of LL, LH, HL and HH by applying 3\nlevel DWT. The Dominant local orientation angle {\\theta} and Coherence are\ncomputed on LL band only. The Centre Area Features and Edge Parameters are\ndetermined on each DWT level by considering all four sub bands. The comparison\nof test fingerprint with database fingerprint is decided based on the Euclidean\nDistance of all the features. It is observed that the values of FAR, FRR and\nTSR are improved compared to the existing algorithm.", 
    "link": "http://arxiv.org/pdf/1106.3517v1", 
    "arxiv-id": "1106.3517v1"
},{
    "category": "cs.CV", 
    "author": "Veerabhadrappa", 
    "title": "Face Identification from Manipulated Facial Images using SIFT", 
    "publish": "2011-06-24T08:30:15Z", 
    "summary": "Editing on digital images is ubiquitous. Identification of deliberately\nmodified facial images is a new challenge for face identification system. In\nthis paper, we address the problem of identification of a face or person from\nheavily altered facial images. In this face identification problem, the input\nto the system is a manipulated or transformed face image and the system reports\nback the determined identity from a database of known individuals. Such a\nsystem can be useful in mugshot identification in which mugshot database\ncontains two views (frontal and profile) of each criminal. We considered only\nfrontal view from the available database for face identification and the query\nimage is a manipulated face generated by face transformation software tool\navailable online. We propose SIFT features for efficient face identification in\nthis scenario. Further comparative analysis has been given with well known\neigenface approach. Experiments have been conducted with real case images to\nevaluate the performance of both methods.", 
    "link": "http://arxiv.org/pdf/1106.4907v1", 
    "arxiv-id": "1106.4907v1"
},{
    "category": "cs.CV", 
    "author": "Mallikarjun Hangarge", 
    "title": "Morphological Reconstruction for Word Level Script Identification", 
    "publish": "2011-06-25T18:16:59Z", 
    "summary": "A line of a bilingual document page may contain text words in regional\nlanguage and numerals in English. For Optical Character Recognition (OCR) of\nsuch a document page, it is necessary to identify different script forms before\nrunning an individual OCR system. In this paper, we have identified a tool of\nmorphological opening by reconstruction of an image in different directions and\nregional descriptors for script identification at word level, based on the\nobservation that every text has a distinct visual appearance. The proposed\nsystem is developed for three Indian major bilingual documents, Kannada, Telugu\nand Devnagari containing English numerals. The nearest neighbour and k-nearest\nneighbour algorithms are applied to classify new word images. The proposed\nalgorithm is tested on 2625 words with various font styles and sizes. The\nresults obtained are quite encouraging", 
    "link": "http://arxiv.org/pdf/1106.5156v2", 
    "arxiv-id": "1106.5156v2"
},{
    "category": "cs.CV", 
    "author": "Daniel J. Mollura", 
    "title": "Learning Shape and Texture Characteristics of CT Tree-in-Bud Opacities   for CAD Systems", 
    "publish": "2011-06-26T03:35:08Z", 
    "summary": "Although radiologists can employ CAD systems to characterize malignancies,\npulmonary fibrosis and other chronic diseases; the design of imaging techniques\nto quantify infectious diseases continue to lag behind. There exists a need to\ncreate more CAD systems capable of detecting and quantifying characteristic\npatterns often seen in respiratory tract infections such as influenza,\nbacterial pneumonia, or tuborculosis. One of such patterns is Tree-in-bud (TIB)\nwhich presents \\textit{thickened} bronchial structures surrounding by clusters\nof \\textit{micro-nodules}. Automatic detection of TIB patterns is a challenging\ntask because of their weak boundary, noisy appearance, and small lesion size.\nIn this paper, we present two novel methods for automatically detecting TIB\npatterns: (1) a fast localization of candidate patterns using information from\nlocal scale of the images, and (2) a M\\\"{o}bius invariant feature extraction\nmethod based on learned local shape and texture properties. A comparative\nevaluation of the proposed methods is presented with a dataset of 39 laboratory\nconfirmed viral bronchiolitis human parainfluenza (HPIV) CTs and 21 normal lung\nCTs. Experimental results demonstrate that the proposed CAD system can achieve\nhigh detection rate with an overall accuracy of 90.96%.", 
    "link": "http://arxiv.org/pdf/1106.5186v1", 
    "arxiv-id": "1106.5186v1"
},{
    "category": "cs.CV", 
    "author": "Anthony Reeves", 
    "title": "Automated segmentation of the pulmonary arteries in low-dose CT by   vessel tracking", 
    "publish": "2011-06-27T17:47:23Z", 
    "summary": "We present a fully automated method for top-down segmentation of the\npulmonary arterial tree in low-dose thoracic CT images. The main basal\npulmonary arteries are identified near the lung hilum by searching for\ncandidate vessels adjacent to known airways, identified by our previously\nreported airway segmentation method. Model cylinders are iteratively fit to the\nvessels to track them into the lungs. Vessel bifurcations are detected by\nmeasuring the rate of change of vessel radii, and child vessels are segmented\nby initiating new trackers at bifurcation points. Validation is accomplished\nusing our novel sparse surface (SS) evaluation metric. The SS metric was\ndesigned to quantify the magnitude of the segmentation error per vessel while\nsignificantly decreasing the manual marking burden for the human user. A total\nof 210 arteries and 205 veins were manually marked across seven test cases.\n134/210 arteries were correctly segmented, with a specificity for arteries of\n90%, and average segmentation error of 0.15 mm. This fully-automated\nsegmentation is a promising method for improving lung nodule detection in\nlow-dose CT screening scans, by separating vessels from surrounding\niso-intensity objects.", 
    "link": "http://arxiv.org/pdf/1106.5460v1", 
    "arxiv-id": "1106.5460v1"
},{
    "category": "cs.CV", 
    "author": "Tomas Koubek", 
    "title": "Augmented Reality Implementation Methods in Mainstream Applications", 
    "publish": "2011-06-28T05:57:37Z", 
    "summary": "Augmented reality has became an useful tool in many areas from space\nexploration to military applications. Although used theoretical principles are\nwell known for almost a decade, the augmented reality is almost exclusively\nused in high budget solutions with a special hardware. However, in last few\nyears we could see rising popularity of many projects focused on deployment of\nthe augmented reality on different mobile devices. Our article is aimed on\ndevelopers who consider development of an augmented reality application for the\nmainstream market. Such developers will be forced to keep the application\nprice, therefore also the development price, at reasonable level. Usage of\nexisting image processing software library could bring a significant cut-down\nof the development costs. In the theoretical part of the article is presented\nan overview of the augmented reality application structure. Further, an\napproach for selection appropriate library as well as the review of the\nexisting software libraries focused in this area is described. The last part of\nthe article outlines our implementation of key parts of the augmented reality\napplication using the OpenCV library.", 
    "link": "http://arxiv.org/pdf/1106.5569v1", 
    "arxiv-id": "1106.5569v1"
},{
    "category": "cs.CV", 
    "author": "Jiri Stastny", 
    "title": "Mobile Augmented Reality Applications", 
    "publish": "2011-06-28T06:08:38Z", 
    "summary": "Augmented reality have undergone considerable improvement in past years. Many\nspecial techniques and hardware devices were developed, but the crucial\nbreakthrough came with the spread of intelligent mobile phones. This enabled\nmass spread of augmented reality applications. However mobile devices have\nlimited hardware capabilities, which narrows down the methods usable for scene\nanalysis. In this article we propose an augmented reality application which is\nusing cloud computing to enable using of more complex computational methods\nsuch as neural networks. Our goal is to create an affordable augmented reality\napplication suitable which will help car designers in by 'virtualizing' car\nmodifications.", 
    "link": "http://arxiv.org/pdf/1106.5571v1", 
    "arxiv-id": "1106.5571v1"
},{
    "category": "cs.CV", 
    "author": "Dr. S. Arumuga Perumal", 
    "title": "Fingerprint: DWT, SVD Based Enhancement and Significant Contrast for   Ridges and Valleys Using Fuzzy Measures", 
    "publish": "2011-06-23T16:25:22Z", 
    "summary": "The performance of the Fingerprint recognition system will be more accurate\nwith respect of enhancement for the fingerprint images. In this paper we\ndevelop a novel method for Fingerprint image contrast enhancement technique\nbased on the discrete wavelet transform (DWT) and singular value decomposition\n(SVD) has been proposed. This technique is compared with conventional image\nequalization techniques such as standard general histogram equalization and\nlocal histogram equalization. An automatic histogram threshold approach based\non a fuzziness measure is presented. Then, using an index of fuzziness, a\nsimilarity process is started to find the threshold point. A significant\ncontrast between ridges and valleys of the best, medium and poor finger image\nfeatures to extract from finger images and get maximum recognition rate using\nfuzzy measures. The experimental results show the recognition of superiority of\nthe proposed method to get maximum performance up gradation to the\nimplementation of this approach.", 
    "link": "http://arxiv.org/pdf/1106.5737v1", 
    "arxiv-id": "1106.5737v1"
},{
    "category": "cs.CV", 
    "author": "Gabriel Cristobal", 
    "title": "Image denoising assessment using anisotropic stack filtering", 
    "publish": "2011-06-29T13:12:56Z", 
    "summary": "In this paper we propose a measure of anisotropy as a quality parameter to\nestimate the amount of noise in noisy images. The anisotropy of an image can be\ndetermined through a directional measure, using an appropriate statistical\ndistribution of the information contained in the image. This new measure is\nachieved through a stack filtering paradigm. First, we define a local\ndirectional entropy, based on the distribution of 0's and 1's in the\nneigborhood of every pixel location of each stack level. Then the entropy\nvariation of this directional entropy is used to define an anisotropic measure.\nThe empirical results have shown that this measure can be regarded as an\nexcellent image noise indicator, which is particularly relevant for quality\nassessment of denoising algorithms. The method has been evaluated with\nartificial and real-world degraded images.", 
    "link": "http://arxiv.org/pdf/1106.5928v1", 
    "arxiv-id": "1106.5928v1"
},{
    "category": "cs.CV", 
    "author": "Sparisoma Viridi", 
    "title": "Automatic Road Lighting System (ARLS) Model Based on Image Processing of   Moving Object", 
    "publish": "2011-07-05T11:06:04Z", 
    "summary": "Using a vehicle toy (in next future called vehicle) as a moving object an\nautomatic road lighting system (ARLS) model is constructed. A digital video\ncamera with 25 fps is used to capture the vehicle motion as it moves in the\ntest segment of the road. Captured images are then processed to calculate\nvehicle speed. This information of the speed together with position of vehicle\nis then used to control the lighting system along the path that passes by the\nvehicle. Length of the road test segment is 1 m, the video camera is positioned\nabout 1.1 m above the test segment, and the vehicle toy dimension is 13 cm\n\\times 9.3 cm. In this model, the maximum speed that ARLS can handle is about\n1.32 m/s, and the highest performance is obtained about 91% at speed 0.93 m/s.", 
    "link": "http://arxiv.org/pdf/1107.0845v4", 
    "arxiv-id": "1107.0845v4"
},{
    "category": "cs.CV", 
    "author": "Ranch Y. Q. Lai", 
    "title": "Online Vehicle Detection For Estimating Traffic Status", 
    "publish": "2011-07-06T08:43:38Z", 
    "summary": "We propose a traffic congestion estimation system based on unsupervised\non-line learning algorithm. The system does not rely on background extraction\nor motion detection. It extracts local features inside detection regions of\nvariable size which are drawn on lanes in advance. The extracted features are\nthen clustered into two classes using K-means and Gaussian Mixture Models(GMM).\nA Bayes classifier is used to detect vehicles according to the previous cluster\ninformation which keeps updated whenever system is running by on-line EM\nalgorithm. Experimental result shows that our system can be adapted to various\ntraffic scenes for estimating traffic status.", 
    "link": "http://arxiv.org/pdf/1107.1058v1", 
    "arxiv-id": "1107.1058v1"
},{
    "category": "cs.CV", 
    "author": "Gururaj Mukarambi", 
    "title": "Spatial Features for Multi-Font/Multi-Size Kannada Numerals and Vowels   Recognition", 
    "publish": "2011-07-06T10:02:42Z", 
    "summary": "This paper presents multi-font/multi-size Kannada numerals and vowels\nrecognition based on spatial features. Directional spatial features viz stroke\ndensity, stroke length and the number of stokes in an image are employed as\npotential features to characterize the printed Kannada numerals and vowels.\nBased on these features 1100 numerals and 1400 vowels are classified with\nMulti-class Support Vector Machines (SVM). The proposed system achieves the\nrecognition accuracy as 98.45% and 90.64% for numerals and vowels respectively.", 
    "link": "http://arxiv.org/pdf/1107.1081v1", 
    "arxiv-id": "1107.1081v1"
},{
    "category": "cs.CV", 
    "author": "Lin Zhouchen", 
    "title": "Analysis and Improvement of Low Rank Representation for Subspace   segmentation", 
    "publish": "2011-07-08T05:44:57Z", 
    "summary": "We analyze and improve low rank representation (LRR), the state-of-the-art\nalgorithm for subspace segmentation of data. We prove that for the noiseless\ncase, the optimization model of LRR has a unique solution, which is the shape\ninteraction matrix (SIM) of the data matrix. So in essence LRR is equivalent to\nfactorization methods. We also prove that the minimum value of the optimization\nmodel of LRR is equal to the rank of the data matrix. For the noisy case, we\nshow that LRR can be approximated as a factorization method that combines noise\nremoval by column sparse robust PCA. We further propose an improved version of\nLRR, called Robust Shape Interaction (RSI), which uses the corrected data as\nthe dictionary instead of the noisy data. RSI is more robust than LRR when the\ncorruption in data is heavy. Experiments on both synthetic and real data\ntestify to the improved robustness of RSI.", 
    "link": "http://arxiv.org/pdf/1107.1561v1", 
    "arxiv-id": "1107.1561v1"
},{
    "category": "cs.CV", 
    "author": "Taras Slipets", 
    "title": "Kunchenko's Polynomials for Template Matching", 
    "publish": "2011-07-11T18:44:17Z", 
    "summary": "This paper reviews Kunchenko's polynomials using as template matching method\nto recognize template in one-dimensional input signal. Kunchenko's polynomials\nmethod is compared with classical methods - cross-correlation and sum of\nsquared differences according to numerical statistical example.", 
    "link": "http://arxiv.org/pdf/1107.2085v1", 
    "arxiv-id": "1107.2085v1"
},{
    "category": "cs.CV", 
    "author": "C. C. Tsouros", 
    "title": "A Variation of the Box-Counting Algorithm Applied to Colour Images", 
    "publish": "2011-07-12T16:21:06Z", 
    "summary": "The box counting method for fractal dimension estimation had not been applied\nto large or colour images thus far due to the processing time required. In this\nletter we present a fast, easy to implement and very easily expandable to any\nnumber of dimensions variation, the box merging method. It is applied here in\nRGB images which are considered as sets in 5-D space.", 
    "link": "http://arxiv.org/pdf/1107.2336v1", 
    "arxiv-id": "1107.2336v1"
},{
    "category": "cs.CV", 
    "author": "Ahmed Elgammal", 
    "title": "Learning Hypergraph Labeling for Feature Matching", 
    "publish": "2011-07-13T14:01:50Z", 
    "summary": "This study poses the feature correspondence problem as a hypergraph node\nlabeling problem. Candidate feature matches and their subsets (usually of size\nlarger than two) are considered to be the nodes and hyperedges of a hypergraph.\nA hypergraph labeling algorithm, which models the subset-wise interaction by an\nundirected graphical model, is applied to label the nodes (feature\ncorrespondences) as correct or incorrect. We describe a method to learn the\ncost function of this labeling algorithm from labeled examples using a\ngraphical model training algorithm. The proposed feature matching algorithm is\ndifferent from the most of the existing learning point matching methods in\nterms of the form of the objective function, the cost function to be learned\nand the optimization method applied to minimize it. The results on standard\ndatasets demonstrate how learning over a hypergraph improves the matching\nperformance over existing algorithms, notably one that also uses higher order\ninformation without learning.", 
    "link": "http://arxiv.org/pdf/1107.2553v1", 
    "arxiv-id": "1107.2553v1"
},{
    "category": "cs.CV", 
    "author": "Nicolaie Popescu-Bodorin", 
    "title": "A Fuzzy View on k-Means Based Signal Quantization with Application in   Iris Segmentation", 
    "publish": "2011-07-13T22:46:58Z", 
    "summary": "This paper shows that the k-means quantization of a signal can be interpreted\nboth as a crisp indicator function and as a fuzzy membership assignment\ndescribing fuzzy clusters and fuzzy boundaries. Combined crisp and fuzzy\nindicator functions are defined here as natural generalizations of the ordinary\ncrisp and fuzzy indicator functions, respectively. An application to iris\nsegmentation is presented together with a demo program.", 
    "link": "http://arxiv.org/pdf/1107.2693v1", 
    "arxiv-id": "1107.2693v1"
},{
    "category": "cs.CV", 
    "author": "Nicolaie Popescu-Bodorin", 
    "title": "Exploring New Directions in Iris Recognition", 
    "publish": "2011-07-13T23:18:57Z", 
    "summary": "A new approach in iris recognition based on Circular Fuzzy Iris Segmentation\n(CFIS) and Gabor Analytic Iris Texture Binary Encoder (GAITBE) is proposed and\ntested here. CFIS procedure is designed to guarantee that similar iris segments\nwill be obtained for similar eye images, despite the fact that the degree of\nocclusion may vary from one image to another. Its result is a circular iris\nring (concentric with the pupil) which approximates the actual iris. GAITBE\nproves better encoding of statistical independence between the iris codes\nextracted from different irides using Hilbert Transform. Irides from University\nof Bath Iris Database are binary encoded on two different lengths (768 / 192\nbytes) and tested in both single-enrollment and multi-enrollment identification\nscenarios. All cases illustrate the capacity of the newly proposed methodology\nto narrow down the distribution of inter-class matching scores, and\nconsequently, to guarantee a steeper descent of the False Accept Rate.", 
    "link": "http://arxiv.org/pdf/1107.2696v1", 
    "arxiv-id": "1107.2696v1"
},{
    "category": "cs.CV", 
    "author": "Gaurav Harit", 
    "title": "Topographic Feature Extraction for Bengali and Hindi Character Images", 
    "publish": "2011-07-14T04:05:23Z", 
    "summary": "Feature selection and extraction plays an important role in different\nclassification based problems such as face recognition, signature verification,\noptical character recognition (OCR) etc. The performance of OCR highly depends\non the proper selection and extraction of feature set. In this paper, we\npresent novel features based on the topography of a character as visible from\ndifferent viewing directions on a 2D plane. By topography of a character we\nmean the structural features of the strokes and their spatial relations. In\nthis work we develop topographic features of strokes visible with respect to\nviews from different directions (e.g. North, South, East, and West). We\nconsider three types of topographic features: closed region, convexity of\nstrokes, and straight line strokes. These features are represented as a\nshape-based graph which acts as an invariant feature set for discriminating\nvery similar type characters efficiently. We have tested the proposed method on\nprinted and handwritten Bengali and Hindi character images. Initial results\ndemonstrate the efficacy of our approach.", 
    "link": "http://arxiv.org/pdf/1107.2723v1", 
    "arxiv-id": "1107.2723v1"
},{
    "category": "cs.CV", 
    "author": "Rami Cohen", 
    "title": "Face Recognition using Curvelet Transform", 
    "publish": "2011-07-14T10:44:01Z", 
    "summary": "Face recognition has been studied extensively for more than 20 years now.\nSince the beginning of 90s the subject has became a major issue. This\ntechnology is used in many important real-world applications, such as video\nsurveillance, smart cards, database security, internet and intranet access.\nThis report reviews recent two algorithms for face recognition which take\nadvantage of a relatively new multiscale geometric analysis tool - Curvelet\ntransform, for facial processing and feature extraction. This transform proves\nto be efficient especially due to its good ability to detect curves and lines,\nwhich characterize the human's face. An algorithm which is based on the two\nalgorithms mentioned above is proposed, and its performance is evaluated on\nthree data bases of faces: AT&T (ORL), Essex Grimace and Georgia-Tech.\nk-nearest neighbour (k-NN) and Support vector machine (SVM) classifiers are\nused, along with Principal Component Analysis (PCA) for dimensionality\nreduction. This algorithm shows good results, and it even outperforms other\nalgorithms in some cases.", 
    "link": "http://arxiv.org/pdf/1107.2781v1", 
    "arxiv-id": "1107.2781v1"
},{
    "category": "cs.CV", 
    "author": "Ha Nhat Tam", 
    "title": "Fingerprint recognition using standardized fingerprint model", 
    "publish": "2011-07-16T03:04:22Z", 
    "summary": "Fingerprint recognition is one of most popular and accuracy Biometric\ntechnologies. Nowadays, it is used in many real applications. However,\nrecognizing fingerprints in poor quality images is still a very complex\nproblem. In recent years, many algorithms, models...are given to improve the\naccuracy of recognition system. This paper discusses on the standardized\nfingerprint model which is used to synthesize the template of fingerprints. In\nthis model, after pre-processing step, we find the transformation between\ntemplates, adjust parameters, synthesize fingerprint, and reduce noises. Then,\nwe use the final fingerprint to match with others in FVC2004 fingerprint\ndatabase (DB4) to show the capability of the model.", 
    "link": "http://arxiv.org/pdf/1107.3194v1", 
    "arxiv-id": "1107.3194v1"
},{
    "category": "cs.CV", 
    "author": "Hai Tran", 
    "title": "Facial Expression Classification Based on Multi Artificial Neural   Network and Two Dimensional Principal Component Analysis", 
    "publish": "2011-07-16T03:15:40Z", 
    "summary": "Facial expression classification is a kind of image classification and it has\nreceived much attention, in recent years. There are many approaches to solve\nthese problems with aiming to increase efficient classification. One of famous\nsuggestions is described as first step, project image to different spaces;\nsecond step, in each of these spaces, images are classified into responsive\nclass and the last step, combine the above classified results into the final\nresult. The advantages of this approach are to reflect fulfill and multiform of\nimage classified. In this paper, we use 2D-PCA and its variants to project the\npattern or image into different spaces with different grouping strategies. Then\nwe develop a model which combines many Neural Networks applied for the last\nstep. This model evaluates the reliability of each space and gives the final\nclassification conclusion. Our model links many Neural Networks together, so we\ncall it Multi Artificial Neural Network (MANN). We apply our proposal model for\n6 basic facial expressions on JAFFE database consisting 213 images posed by 10\nJapanese female models.", 
    "link": "http://arxiv.org/pdf/1107.3195v1", 
    "arxiv-id": "1107.3195v1"
},{
    "category": "cs.CV", 
    "author": "Ali A. Al-Zuky", 
    "title": "Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion   Techniques", 
    "publish": "2011-07-18T01:41:37Z", 
    "summary": "In remote sensing, image fusion technique is a useful tool used to fuse high\nspatial resolution panchromatic images (PAN) with lower spatial resolution\nmultispectral images (MS) to create a high spatial resolution multispectral of\nimage fusion (F) while preserving the spectral information in the multispectral\nimage (MS).There are many PAN sharpening techniques or Pixel-Based image fusion\ntechniques that have been developed to try to enhance the spatial resolution\nand the spectral property preservation of the MS. This paper attempts to\nundertake the study of image fusion, by using two types of pixel-based image\nfusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods\nof Pixel-Based Image Fusion Techniques. The first type includes Brovey\nTransform (BT), Color Normalized Transformation (CN) and Multiplicative Method\n(MLT). The second type include High-Pass Filter Additive Method (HPFA),\nHigh-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and\nThe Wavelet transform-based fusion method (WT). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including Standard Deviation (SD),\nEntropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR),\nNormalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to\nestimate the quality and degree of information improvement of a fused image\nquantitatively.", 
    "link": "http://arxiv.org/pdf/1107.3348v2", 
    "arxiv-id": "1107.3348v2"
},{
    "category": "cs.CV", 
    "author": "Ali A. Al-Zuky", 
    "title": "The IHS Transformations Based Image Fusion", 
    "publish": "2011-07-19T06:18:56Z", 
    "summary": "The IHS sharpening technique is one of the most commonly used techniques for\nsharpening. Different transformations have been developed to transfer a color\nimage from the RGB space to the IHS space. Through literature, it appears that,\nvarious scientists proposed alternative IHS transformations and many papers\nhave reported good results whereas others show bad ones as will as not those\nobtained which the formula of IHS transformation were used. In addition to\nthat, many papers show different formulas of transformation matrix such as IHS\ntransformation. This leads to confusion what is the exact formula of the IHS\ntransformation?. Therefore, the main purpose of this work is to explore\ndifferent IHS transformation techniques and experiment it as IHS based image\nfusion. The image fusion performance was evaluated, in this study, using\nvarious methods to estimate the quality and degree of information improvement\nof a fused image quantitatively.", 
    "link": "http://arxiv.org/pdf/1107.4396v2", 
    "arxiv-id": "1107.4396v2"
},{
    "category": "cs.CV", 
    "author": "Pascal Frossard", 
    "title": "Correlation Estimation from Compressed Images", 
    "publish": "2011-07-23T08:51:17Z", 
    "summary": "This paper addresses the problem of correlation estimation in sets of\ncompressed images. We consider a framework where images are represented under\nthe form of linear measurements due to low complexity sensing or security\nrequirements. We assume that the images are correlated through the displacement\nof visual objects due to motion or viewpoint change and the correlation is\neffectively represented by optical flow or motion field models. The correlation\nis estimated in the compressed domain by jointly processing the linear\nmeasurements. We first show that the correlated images can be efficiently\nrelated using a linear operator. Using this linear relationship we then\ndescribe the dependencies between images in the compressed domain. We further\ncast a regularized optimization problem where the correlation is estimated in\norder to satisfy both data consistency and motion smoothness objectives with a\nGraph Cut algorithm. We analyze in detail the correlation estimation\nperformance and quantify the penalty due to image compression. Extensive\nexperiments in stereo and video imaging applications show that our novel\nsolution stays competitive with methods that implement complex image\nreconstruction steps prior to correlation estimation. We finally use the\nestimated correlation in a novel joint image reconstruction scheme that is\nbased on an optimization problem with sparsity priors on the reconstructed\nimages. Additional experiments show that our correlation estimation algorithm\nleads to an effective reconstruction of pairs of images in distributed image\ncoding schemes that outperform independent reconstruction algorithms by 2 to 4\ndB.", 
    "link": "http://arxiv.org/pdf/1107.4667v2", 
    "arxiv-id": "1107.4667v2"
},{
    "category": "cs.CV", 
    "author": "Anqi Qiu", 
    "title": "Diffeomorphic Metric Mapping of High Angular Resolution Diffusion   Imaging based on Riemannian Structure of Orientation Distribution Functions", 
    "publish": "2011-07-24T15:34:27Z", 
    "summary": "In this paper, we propose a novel large deformation diffeomorphic\nregistration algorithm to align high angular resolution diffusion images\n(HARDI) characterized by orientation distribution functions (ODFs). Our\nproposed algorithm seeks an optimal diffeomorphism of large deformation between\ntwo ODF fields in a spatial volume domain and at the same time, locally\nreorients an ODF in a manner such that it remains consistent with the\nsurrounding anatomical structure. To this end, we first review the Riemannian\nmanifold of ODFs. We then define the reorientation of an ODF when an affine\ntransformation is applied and subsequently, define the diffeomorphic group\naction to be applied on the ODF based on this reorientation. We incorporate the\nRiemannian metric of ODFs for quantifying the similarity of two HARDI images\ninto a variational problem defined under the large deformation diffeomorphic\nmetric mapping (LDDMM) framework. We finally derive the gradient of the cost\nfunction in both Riemannian spaces of diffeomorphisms and the ODFs, and present\nits numerical implementation. Both synthetic and real brain HARDI data are used\nto illustrate the performance of our registration algorithm.", 
    "link": "http://arxiv.org/pdf/1107.4763v1", 
    "arxiv-id": "1107.4763v1"
},{
    "category": "cs.CV", 
    "author": "Michael Werman", 
    "title": "Efficient and Accurate Gaussian Image Filtering Using Running Sums", 
    "publish": "2011-07-25T14:20:34Z", 
    "summary": "This paper presents a simple and efficient method to convolve an image with a\nGaussian kernel. The computation is performed in a constant number of\noperations per pixel using running sums along the image rows and columns. We\ninvestigate the error function used for kernel approximation and its relation\nto the properties of the input signal. Based on natural image statistics we\npropose a quadratic form kernel error function so that the output image l2\nerror is minimized. We apply the proposed approach to approximate the Gaussian\nkernel by linear combination of constant functions. This results in very\nefficient Gaussian filtering method. Our experiments show that the proposed\ntechnique is faster than state of the art methods while preserving a similar\naccuracy.", 
    "link": "http://arxiv.org/pdf/1107.4958v1", 
    "arxiv-id": "1107.4958v1"
},{
    "category": "cs.CV", 
    "author": "Hakan Erdogan", 
    "title": "Confidence-Based Dynamic Classifier Combination For Mean-Shift Tracking", 
    "publish": "2011-07-29T01:08:52Z", 
    "summary": "We introduce a novel tracking technique which uses dynamic confidence-based\nfusion of two different information sources for robust and efficient tracking\nof visual objects. Mean-shift tracking is a popular and well known method used\nin object tracking problems. Originally, the algorithm uses a similarity\nmeasure which is optimized by shifting a search area to the center of a\ngenerated weight image to track objects. Recent improvements on the original\nmean-shift algorithm involves using a classifier that differentiates the object\nfrom its surroundings. We adopt this classifier-based approach and propose an\napplication of a classifier fusion technique within this classifier-based\ncontext in this work. We use two different classifiers, where one comes from a\nbackground modeling method, to generate the weight image and we calculate\ncontributions of the classifiers dynamically using their confidences to\ngenerate a final weight image to be used in tracking. The contributions of the\nclassifiers are calculated by using correlations between histograms of their\nweight images and histogram of a defined ideal weight image in the previous\nframe. We show with experiments that our dynamic combination scheme selects\ngood contributions for classifiers for different cases and improves tracking\naccuracy significantly.", 
    "link": "http://arxiv.org/pdf/1107.5850v2", 
    "arxiv-id": "1107.5850v2"
},{
    "category": "cs.CV", 
    "author": "Lior Wolf", 
    "title": "Leveraging Billions of Faces to Overcome Performance Barriers in   Unconstrained Face Recognition", 
    "publish": "2011-08-04T15:51:19Z", 
    "summary": "We employ the face recognition technology developed in house at face.com to a\nwell accepted benchmark and show that without any tuning we are able to\nconsiderably surpass state of the art results. Much of the improvement is\nconcentrated in the high-valued performance point of zero false positive\nmatches, where the obtained recall rate almost doubles the best reported result\nto date. We discuss the various components and innovations of our system that\nenable this significant performance gap. These components include extensive\nutilization of an accurate 3D reconstructed shape model dealing with challenges\narising from pose and illumination. In addition, discriminative models based on\nbillions of faces are used in order to overcome aging and facial expression as\nwell as low light and overexposure. Finally, we identify a challenging set of\nidentification queries that might provide useful focus for future research.", 
    "link": "http://arxiv.org/pdf/1108.1122v1", 
    "arxiv-id": "1108.1122v1"
},{
    "category": "cs.CV", 
    "author": "Yann LeCun", 
    "title": "Learning Representations by Maximizing Compression", 
    "publish": "2011-08-04T19:00:14Z", 
    "summary": "We give an algorithm that learns a representation of data through\ncompression. The algorithm 1) predicts bits sequentially from those previously\nseen and 2) has a structure and a number of computations similar to an\nautoencoder. The likelihood under the model can be calculated exactly, and\narithmetic coding can be used directly for compression. When training on digits\nthe algorithm learns filters similar to those of restricted boltzman machines\nand denoising autoencoders. Independent samples can be drawn from the model by\na single sweep through the pixels. The algorithm has a good compression\nperformance when compared to other methods that work under random ordering of\npixels.", 
    "link": "http://arxiv.org/pdf/1108.1169v1", 
    "arxiv-id": "1108.1169v1"
},{
    "category": "cs.CV", 
    "author": "R C Tripathi", 
    "title": "Real time face recognition using adaboost improved fast PCA algorithm", 
    "publish": "2011-08-05T15:41:31Z", 
    "summary": "This paper presents an automated system for human face recognition in a real\ntime background world for a large homemade dataset of persons face. The task is\nvery difficult as the real time background subtraction in an image is still a\nchallenge. Addition to this there is a huge variation in human face image in\nterms of size, pose and expression. The system proposed collapses most of this\nvariance. To detect real time human face AdaBoost with Haar cascade is used and\na simple fast PCA and LDA is used to recognize the faces detected. The matched\nface is then used to mark attendance in the laboratory, in our case. This\nbiometric system is a real time attendance system based on the human face\nrecognition with a simple and fast algorithms and gaining a high accuracy\nrate..", 
    "link": "http://arxiv.org/pdf/1108.1353v1", 
    "arxiv-id": "1108.1353v1"
},{
    "category": "cs.CV", 
    "author": "Philip Schniter", 
    "title": "Compressive Imaging using Approximate Message Passing and a Markov-Tree   Prior", 
    "publish": "2011-08-12T14:41:49Z", 
    "summary": "We propose a novel algorithm for compressive imaging that exploits both the\nsparsity and persistence across scales found in the 2D wavelet transform\ncoefficients of natural images. Like other recent works, we model wavelet\nstructure using a hidden Markov tree (HMT) but, unlike other works, ours is\nbased on loopy belief propagation (LBP). For LBP, we adopt a recently proposed\n\"turbo\" message passing schedule that alternates between exploitation of HMT\nstructure and exploitation of compressive-measurement structure. For the\nlatter, we leverage Donoho, Maleki, and Montanari's recently proposed\napproximate message passing (AMP) algorithm. Experiments with a large image\ndatabase suggest that, relative to existing schemes, our turbo LBP approach\nyields state-of-the-art reconstruction performance with substantial reduction\nin complexity.", 
    "link": "http://arxiv.org/pdf/1108.2632v1", 
    "arxiv-id": "1108.2632v1"
},{
    "category": "cs.CV", 
    "author": "Ali A. Al-Zaky", 
    "title": "The Statistical methods of Pixel-Based Image Fusion Techniques", 
    "publish": "2011-08-12T16:51:21Z", 
    "summary": "There are many image fusion methods that can be used to produce\nhigh-resolution mutlispectral images from a high-resolution panchromatic (PAN)\nimage and low-resolution multispectral (MS) of remote sensed images. This paper\nattempts to undertake the study of image fusion techniques with different\nStatistical techniques for image fusion as Local Mean Matching (LMM), Local\nMean and Variance Matching (LMVM), Regression variable substitution (RVS),\nLocal Correlation Modeling (LCM) and they are compared with one another so as\nto choose the best technique, that can be applied on multi-resolution satellite\nimages. This paper also devotes to concentrate on the analytical techniques for\nevaluating the quality of image fusion (F) by using various methods including\nStandard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to\nNoise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation\nIndex (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively.", 
    "link": "http://arxiv.org/pdf/1108.3250v1", 
    "arxiv-id": "1108.3250v1"
},{
    "category": "cs.CV", 
    "author": "Jaakko Astola", 
    "title": "Advanced phase retrieval: maximum likelihood technique with sparse   regularization of phase and amplitude", 
    "publish": "2011-08-15T09:37:15Z", 
    "summary": "Sparse modeling is one of the efficient techniques for imaging that allows\nrecovering lost information. In this paper, we present a novel iterative\nphase-retrieval algorithm using a sparse representation of the object amplitude\nand phase. The algorithm is derived in terms of a constrained maximum\nlikelihood, where the wave field reconstruction is performed using a number of\nnoisy intensity-only observations with a zero-mean additive Gaussian noise. The\ndeveloped algorithm enables the optimal solution for the object wave field\nreconstruction. Our goal is an improvement of the reconstruction quality with\nrespect to the conventional algorithms. Sparse regularization results in\nadvanced reconstruction accuracy, and numerical simulations demonstrate\nsignificant enhancement of imaging.", 
    "link": "http://arxiv.org/pdf/1108.3251v1", 
    "arxiv-id": "1108.3251v1"
},{
    "category": "cs.CV", 
    "author": "Adrian Barbu", 
    "title": "Hierarchical Object Parsing from Structured Noisy Point Clouds", 
    "publish": "2011-08-18T02:11:34Z", 
    "summary": "Object parsing and segmentation from point clouds are challenging tasks\nbecause the relevant data is available only as thin structures along object\nboundaries or other features, and is corrupted by large amounts of noise. To\nhandle this kind of data, flexible shape models are desired that can accurately\nfollow the object boundaries. Popular models such as Active Shape and Active\nAppearance models lack the necessary flexibility for this task, while recent\napproaches such as the Recursive Compositional Models make model\nsimplifications in order to obtain computational guarantees. This paper\ninvestigates a hierarchical Bayesian model of shape and appearance in a\ngenerative setting. The input data is explained by an object parsing layer,\nwhich is a deformation of a hidden PCA shape model with Gaussian prior. The\npaper also introduces a novel efficient inference algorithm that uses informed\ndata-driven proposals to initialize local searches for the hidden variables.\nApplied to the problem of object parsing from structured point clouds such as\nedge detection images, the proposed approach obtains state of the art parsing\nerrors on two standard datasets without using any intensity information.", 
    "link": "http://arxiv.org/pdf/1108.3605v2", 
    "arxiv-id": "1108.3605v2"
},{
    "category": "cs.CV", 
    "author": "Ali A. Al-Zaky", 
    "title": "Multisensor Images Fusion Based on Feature-Level", 
    "publish": "2011-08-20T07:43:46Z", 
    "summary": "Until now, of highest relevance for remote sensing data processing and\nanalysis have been techniques for pixel level image fusion. So, This paper\nattempts to undertake the study of Feature-Level based image fusion. For this\npurpose, feature based fusion techniques, which are usually based on empirical\nor heuristic rules, are employed. Hence, in this paper we consider feature\nextraction (FE) for fusion. It aims at finding a transformation of the original\nspace that would produce such new features, which preserve or improve as much\nas possible. This study introduces three different types of Image fusion\ntechniques including Principal Component Analysis based Feature Fusion (PCA),\nSegment Fusion (SF) and Edge fusion (EF). This paper also devotes to\nconcentrate on the analytical techniques for evaluating the quality of image\nfusion (F) by using various methods including (SD), (En), (CC), (SNR), (NRMSE)\nand (DI) to estimate the quality and degree of information improvement of a\nfused image quantitatively.", 
    "link": "http://arxiv.org/pdf/1108.4098v1", 
    "arxiv-id": "1108.4098v1"
},{
    "category": "cs.CV", 
    "author": "Dong Hoon Lim", 
    "title": "Edge detection based on morphological amoebas", 
    "publish": "2011-08-22T13:49:57Z", 
    "summary": "Detecting the edges of objects within images is critical for quality image\nprocessing. We present an edge-detecting technique that uses morphological\namoebas that adjust their shape based on variation in image contours. We\nevaluate the method both quantitatively and qualitatively for edge detection of\nimages, and compare it to classic morphological methods. Our amoeba-based\nedge-detection system performed better than the classic edge detectors.", 
    "link": "http://arxiv.org/pdf/1108.4315v1", 
    "arxiv-id": "1108.4315v1"
},{
    "category": "cs.CV", 
    "author": "Dr. R Bhavani", 
    "title": "Biometric Authorization System using Gait Biometry", 
    "publish": "2011-08-31T17:22:51Z", 
    "summary": "Human gait, which is a new biometric aimed to recognize individuals by the\nway they walk have come to play an increasingly important role in visual\nsurveillance applications. In this paper a novel hybrid holistic approach is\nproposed to show how behavioural walking characteristics can be used to\nrecognize unauthorized and suspicious persons when they enter a surveillance\narea. Initially background is modelled from the input video captured from\ncameras deployed for security and the foreground moving object in the\nindividual frames are segmented using the background subtraction algorithm.\nThen gait representing spatial, temporal and wavelet components are extracted\nand fused for training and testing multi class support vector machine models\n(SVM). The proposed system is evaluated using side view videos of NLPR\ndatabase. The experimental results demonstrate that the proposed system\nachieves a pleasing recognition rate and also the results indicate that the\nclassification ability of SVM with Radial Basis Function (RBF) is better than\nwith other kernel functions.", 
    "link": "http://arxiv.org/pdf/1108.6294v1", 
    "arxiv-id": "1108.6294v1"
},{
    "category": "cs.CV", 
    "author": "Anup Sar", 
    "title": "An Efficient Codebook Initialization Approach for LBG Algorithm", 
    "publish": "2011-09-01T04:47:08Z", 
    "summary": "In VQ based image compression technique has three major steps namely (i)\nCodebook Design, (ii) VQ Encoding Process and (iii) VQ Decoding Process. The\nperformance of VQ based image compression technique depends upon the\nconstructed codebook. A widely used technique for VQ codebook design is the\nLinde-Buzo-Gray (LBG) algorithm. However the performance of the standard LBG\nalgorithm is highly dependent on the choice of the initial codebook. In this\npaper, we have proposed a simple and very effective approach for codebook\ninitialization for LBG algorithm. The simulation results show that the proposed\nscheme is computationally efficient and gives expected performance as compared\nto the standard LBG algorithm.", 
    "link": "http://arxiv.org/pdf/1109.0090v1", 
    "arxiv-id": "1109.0090v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed Abid", 
    "title": "Automatic Application Level Set Approach in Detection Calcifications in   Mammographic Image", 
    "publish": "2011-09-01T09:51:42Z", 
    "summary": "Breast cancer is considered as one of a major health problem that constitutes\nthe strongest cause behind mortality among women in the world. So, in this\ndecade, breast cancer is the second most common type of cancer, in term of\nappearance frequency, and the fifth most common cause of cancer related death.\nIn order to reduce the workload on radiologists, a variety of CAD systems;\nComputer-Aided Diagnosis (CADi) and Computer-Aided Detection (CADe) have been\nproposed. In this paper, we interested on CADe tool to help radiologist to\ndetect cancer. The proposed CADe is based on a three-step work flow; namely,\ndetection, analysis and classification. This paper deals with the problem of\nautomatic detection of Region Of Interest (ROI) based on Level Set approach\ndepended on edge and region criteria. This approach gives good visual\ninformation from the radiologist. After that, the features extraction using\ntextures characteristics and the vector classification using Multilayer\nPerception (MLP) and k-Nearest Neighbours (KNN) are adopted to distinguish\ndifferent ACR (American College of Radiology) classification. Moreover, we use\nthe Digital Database for Screening Mammography (DDSM) for experiments and these\nresults in term of accuracy varied between 60 % and 70% are acceptable and must\nbe ameliorated to aid radiologist.", 
    "link": "http://arxiv.org/pdf/1109.0138v1", 
    "arxiv-id": "1109.0138v1"
},{
    "category": "cs.CV", 
    "author": "Weichuan Yu", 
    "title": "Moving Object Detection by Detecting Contiguous Outliers in the Low-Rank   Representation", 
    "publish": "2011-09-05T13:08:24Z", 
    "summary": "Object detection is a fundamental step for automated video analysis in many\nvision applications. Object detection in a video is usually performed by object\ndetectors or background subtraction techniques. Often, an object detector\nrequires manually labeled examples to train a binary classifier, while\nbackground subtraction needs a training sequence that contains no objects to\nbuild a background model. To automate the analysis, object detection without a\nseparate training phase becomes a critical task. People have tried to tackle\nthis task by using motion information. But existing motion-based methods are\nusually limited when coping with complex scenarios such as nonrigid motion and\ndynamic background. In this paper, we show that above challenges can be\naddressed in a unified framework named DEtecting Contiguous Outliers in the\nLOw-rank Representation (DECOLOR). This formulation integrates object detection\nand background learning into a single process of optimization, which can be\nsolved by an alternating algorithm efficiently. We explain the relations\nbetween DECOLOR and other sparsity-based methods. Experiments on both simulated\ndata and real sequences demonstrate that DECOLOR outperforms the\nstate-of-the-art approaches and it can work effectively on a wide range of\ncomplex scenarios.", 
    "link": "http://arxiv.org/pdf/1109.0882v2", 
    "arxiv-id": "1109.0882v2"
},{
    "category": "cs.CV", 
    "author": "Zhixun Su", 
    "title": "Toward Designing Intelligent PDEs for Computer Vision: An Optimal   Control Approach", 
    "publish": "2011-09-06T04:26:44Z", 
    "summary": "Many computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually\nrequires high mathematical skills and good insight into the problems. In this\npaper, we consider designing PDEs for various problems arising in computer\nvision and image processing in a lazy manner: \\emph{learning PDEs from real\ndata via data-based optimal control}. We first propose a general intelligent\nPDE system which holds the basic translational and rotational invariance rule\nfor most vision problems. By introducing a PDE-constrained optimal control\nframework, it is possible to use the training data resulting from multiple ways\n(ground truth, results from other methods, and manual results from humans) to\nlearn PDEs for different computer vision tasks. The proposed optimal control\nbased training framework aims at learning a PDE-based regressor to approximate\nthe unknown (and usually nonlinear) mapping of different vision tasks. The\nexperimental results show that the learnt PDEs can solve different vision\nproblems reasonably well. In particular, we can obtain PDEs not only for\nproblems that traditional PDEs work well but also for problems that PDE-based\nmethods have never been tried before, due to the difficulty in describing those\nproblems in a mathematical way.", 
    "link": "http://arxiv.org/pdf/1109.1057v1", 
    "arxiv-id": "1109.1057v1"
},{
    "category": "cs.CV", 
    "author": "Dr. R. Sukanesh", 
    "title": "Automatic Diagnosis of Abnormal Tumor Region from Brain Computed   Tomography Images Using Wavelet Based Statistical Texture Features", 
    "publish": "2011-09-06T05:31:26Z", 
    "summary": "The research work presented in this paper is to achieve the tissue\nclassification and automatically diagnosis the abnormal tumor region present in\nComputed Tomography (CT) images using the wavelet based statistical texture\nanalysis method. Comparative studies of texture analysis method are performed\nfor the proposed wavelet based texture analysis method and Spatial Gray Level\nDependence Method (SGLDM). Our proposed system consists of four phases i)\nDiscrete Wavelet Decomposition (ii) Feature extraction (iii) Feature selection\n(iv) Analysis of extracted texture features by classifier. A wavelet based\nstatistical texture feature set is derived from normal and tumor regions.\nGenetic Algorithm (GA) is used to select the optimal texture features from the\nset of extracted texture features. We construct the Support Vector Machine\n(SVM) based classifier and evaluate the performance of classifier by comparing\nthe classification results of the SVM based classifier with the Back\nPropagation Neural network classifier(BPN). The results of Support Vector\nMachine (SVM), BPN classifiers for the texture analysis methods are evaluated\nusing Receiver Operating Characteristic (ROC) analysis. Experimental results\nshow that the classification accuracy of SVM is 96% for 10 fold cross\nvalidation method. The system has been tested with a number of real Computed\nTomography brain images and has achieved satisfactory results.", 
    "link": "http://arxiv.org/pdf/1109.1067v1", 
    "arxiv-id": "1109.1067v1"
},{
    "category": "cs.CV", 
    "author": "A. V. Dattatreya Rao", 
    "title": "An Automatic Clustering Technique for Optimal Clusters", 
    "publish": "2011-09-06T05:34:28Z", 
    "summary": "This paper proposes a simple, automatic and efficient clustering algorithm,\nnamely, Automatic Merging for Optimal Clusters (AMOC) which aims to generate\nnearly optimal clusters for the given datasets automatically. The AMOC is an\nextension to standard k-means with a two phase iterative procedure combining\ncertain validation techniques in order to find optimal clusters with automation\nof merging of clusters. Experiments on both synthetic and real data have proved\nthat the proposed algorithm finds nearly optimal clustering structures in terms\nof number of clusters, compactness and separation.", 
    "link": "http://arxiv.org/pdf/1109.1068v1", 
    "arxiv-id": "1109.1068v1"
},{
    "category": "cs.CV", 
    "author": "Vijay H Mankar", 
    "title": "Devnagari document segmentation using histogram approach", 
    "publish": "2011-09-06T17:56:58Z", 
    "summary": "Document segmentation is one of the critical phases in machine recognition of\nany language. Correct segmentation of individual symbols decides the accuracy\nof character recognition technique. It is used to decompose image of a sequence\nof characters into sub images of individual symbols by segmenting lines and\nwords. Devnagari is the most popular script in India. It is used for writing\nHindi, Marathi, Sanskrit and Nepali languages. Moreover, Hindi is the third\nmost popular language in the world. Devnagari documents consist of vowels,\nconsonants and various modifiers. Hence proper segmentation of Devnagari word\nis challenging. A simple histogram based approach to segment Devnagari\ndocuments is proposed in this paper. Various challenges in segmentation of\nDevnagari script are also discussed.", 
    "link": "http://arxiv.org/pdf/1109.1247v1", 
    "arxiv-id": "1109.1247v1"
},{
    "category": "cs.CV", 
    "author": "Carsten Rother", 
    "title": "Curvature Prior for MRF-based Segmentation and Shape Inpainting", 
    "publish": "2011-09-07T14:53:51Z", 
    "summary": "Most image labeling problems such as segmentation and image reconstruction\nare fundamentally ill-posed and suffer from ambiguities and noise. Higher order\nimage priors encode high level structural dependencies between pixels and are\nkey to overcoming these problems. However, these priors in general lead to\ncomputationally intractable models. This paper addresses the problem of\ndiscovering compact representations of higher order priors which allow\nefficient inference. We propose a framework for solving this problem which uses\na recently proposed representation of higher order functions where they are\nencoded as lower envelopes of linear functions. Maximum a Posterior inference\non our learned models reduces to minimizing a pairwise function of discrete\nvariables, which can be done approximately using standard methods. Although\nthis is a primarily theoretical paper, we also demonstrate the practical\neffectiveness of our framework on the problem of learning a shape prior for\nimage segmentation and reconstruction. We show that our framework can learn a\ncompact representation that approximates a prior that encourages low curvature\nshapes. We evaluate the approximation accuracy, discuss properties of the\ntrained model, and show various results for shape inpainting and image\nsegmentation.", 
    "link": "http://arxiv.org/pdf/1109.1480v1", 
    "arxiv-id": "1109.1480v1"
},{
    "category": "cs.CV", 
    "author": "Ramesh Raskar", 
    "title": "Progressive versus Random Projections for Compressive Capture of Images,   Lightfields and Higher Dimensional Visual Signals", 
    "publish": "2011-09-09T00:33:10Z", 
    "summary": "Computational photography involves sophisticated capture methods. A new trend\nis to capture projection of higher dimensional visual signals such as videos,\nmulti-spectral data and lightfields on lower dimensional sensors. Carefully\ndesigned capture methods exploit the sparsity of the underlying signal in a\ntransformed domain to reduce the number of measurements and use an appropriate\nreconstruction method. Traditional progressive methods may capture successively\nmore detail using a sequence of simple projection basis, such as DCT or\nwavelets and employ straightforward backprojection for reconstruction.\nRandomized projection methods do not use any specific sequence and use L0\nminimization for reconstruction. In this paper, we analyze the statistical\nproperties of natural images, videos, multi-spectral data and light-fields and\ncompare the effectiveness of progressive and random projections. We define\neffectiveness by plotting reconstruction SNR against compression factor. The\nkey idea is a procedure to measure best-case effectiveness that is fast,\nindependent of specific hardware and independent of the reconstruction\nprocedure. We believe this is the first empirical study to compare different\nlossy capture strategies without the complication of hardware or reconstruction\nambiguity. The scope is limited to linear non-adaptive sensing. The results\nshow that random projections produce significant advantages over other\nprojections only for higher dimensional signals, and suggest more research to\nnascent adaptive and non-linear projection methods.", 
    "link": "http://arxiv.org/pdf/1109.1865v1", 
    "arxiv-id": "1109.1865v1"
},{
    "category": "cs.CV", 
    "author": "Matthew Cook", 
    "title": "Multi-Hypothesis CRF-Segmentation of Neural Tissue in Anisotropic EM   Volumes", 
    "publish": "2011-09-12T12:57:25Z", 
    "summary": "We present an approach for the joint segmentation and grouping of similar\ncomponents in anisotropic 3D image data and use it to segment neural tissue in\nserial sections electron microscopy (EM) images.\n  We first construct a nested set of neuron segmentation hypotheses for each\nslice. A conditional random field (CRF) then allows us to evaluate both the\ncompatibility of a specific segmentation and a specific inter-slice assignment\nof neuron candidates with the underlying observations. The model is solved\noptimally for an entire image stack simultaneously using integer linear\nprogramming (ILP), which yields the maximum a posteriori solution in amortized\nlinear time in the number of slices.\n  We evaluate the performance of our approach on an annotated sample of the\nDrosophila larva neuropil and show that the consideration of different\nsegmentation hypotheses in each slice leads to a significant improvement in the\nsegmentation and assignment accuracy.", 
    "link": "http://arxiv.org/pdf/1109.2449v4", 
    "arxiv-id": "1109.2449v4"
},{
    "category": "cs.CV", 
    "author": "Evgeniy Martyushev", 
    "title": "A Non-Iterative Solution to the Four-Point Three-Views Pose Problem in   Case of Collinear Cameras", 
    "publish": "2011-09-14T16:24:26Z", 
    "summary": "We give a non-iterative solution to a particular case of the four-point\nthree-views pose problem when three camera centers are collinear. Using the\nwell-known Cayley representation of orthogonal matrices, we derive from the\nepipolar constraints a system of three polynomial equations in three variables.\nThe eliminant of that system is a multiple of a 36th degree univariate\npolynomial. The true (unique) solution to the problem can be expressed in terms\nof one of real roots of that polynomial. Experiments on synthetic data confirm\nthat our method is robust enough even in case of planar configurations.", 
    "link": "http://arxiv.org/pdf/1109.3126v1", 
    "arxiv-id": "1109.3126v1"
},{
    "category": "cs.CV", 
    "author": "Mita Nasipuri", 
    "title": "Design of an Optical Character Recognition System for Camera-based   Handheld Devices", 
    "publish": "2011-09-15T11:24:41Z", 
    "summary": "This paper presents a complete Optical Character Recognition (OCR) system for\ncamera captured image/graphics embedded textual documents for handheld devices.\nAt first, text regions are extracted and skew corrected. Then, these regions\nare binarized and segmented into lines and characters. Characters are passed\ninto the recognition module. Experimenting with a set of 100 business card\nimages, captured by cell phone camera, we have achieved a maximum recognition\naccuracy of 92.74%. Compared to Tesseract, an open source desktop-based\npowerful OCR engine, present recognition accuracy is worth contributing.\nMoreover, the developed technique is computationally efficient and consumes low\nmemory so as to be applicable on handheld devices.", 
    "link": "http://arxiv.org/pdf/1109.3317v1", 
    "arxiv-id": "1109.3317v1"
},{
    "category": "cs.CV", 
    "author": "Pedro M. Q. Aguiar", 
    "title": "Connectivity-Enforcing Hough Transform for the Robust Extraction of Line   Segments", 
    "publish": "2011-09-16T14:56:25Z", 
    "summary": "Global voting schemes based on the Hough transform (HT) have been widely used\nto robustly detect lines in images. However, since the votes do not take line\nconnectivity into account, these methods do not deal well with cluttered\nimages. In opposition, the so-called local methods enforce connectivity but\nlack robustness to deal with challenging situations that occur in many\nrealistic scenarios, e.g., when line segments cross or when long segments are\ncorrupted. In this paper, we address the critical limitations of the HT as a\nline segment extractor by incorporating connectivity in the voting process.\nThis is done by only accounting for the contributions of edge points lying in\nincreasingly larger neighborhoods and whose position and directional content\nagree with potential line segments. As a result, our method, which we call\nSTRAIGHT (Segment exTRAction by connectivity-enforcInG HT), extracts the\nlongest connected segments in each location of the image, thus also integrating\ninto the HT voting process the usually separate step of individual segment\nextraction. The usage of the Hough space mapping and a corresponding\nhierarchical implementation make our approach computationally feasible. We\npresent experiments that illustrate, with synthetic and real images, how\nSTRAIGHT succeeds in extracting complete segments in several situations where\ncurrent methods fail.", 
    "link": "http://arxiv.org/pdf/1109.3637v1", 
    "arxiv-id": "1109.3637v1"
},{
    "category": "cs.CV", 
    "author": "Othman Ahmad", 
    "title": "Generalised Object Detection and Semantic Analysis: Casino Example using   Matlab", 
    "publish": "2011-09-17T10:09:02Z", 
    "summary": "Matlab version 7.1 had been used to detect playing cards on a Casino table\nand the suits and ranks of these cards had been identified. The process gives\nan example of an application of computer vision to a problem where rectangular\nobjects are to be detected and the information content of the objects are\nextracted out. In the case of playing cards, it is the suit and rank of each\ncard. The image processing system is done in two passes. Pass 1 detects\nrectangular shapes and template matched with a template of the left and right\nedges of the cards. Pass 2 extracts the suit and rank of the cards by matching\nthe top left portion of the card that contains both rank and suit information,\nwith stored templates of ranks and suits of the playing cards using a series of\nif-then statements.", 
    "link": "http://arxiv.org/pdf/1109.3767v1", 
    "arxiv-id": "1109.3767v1"
},{
    "category": "cs.CV", 
    "author": "Dae-Woong Lee", 
    "title": "On the digital homology groups of digital images", 
    "publish": "2011-09-18T07:48:36Z", 
    "summary": "In this article we study the digital homology groups of digital images which\nare based on the singular homology groups of topological spaces in algebraic\ntopology. Specifically, we define a digitally standard $n$-simplex, a digitally\nsingular $n$-simplex, and the digital homology groups of digital images with\n$k$-adjacency relations. We then construct a covariant functor from a category\nof digital images and digitally continuous functions to the one of abelian\ngroups and group homomorphisms, and investigate some fundamental and\ninteresting properties of digital homology groups of digital images, such as\nthe digital version of the dimension axiom which is one of the\nEilenberg-Steenrod axioms.", 
    "link": "http://arxiv.org/pdf/1109.3850v1", 
    "arxiv-id": "1109.3850v1"
},{
    "category": "cs.CV", 
    "author": "Stefano Soatto", 
    "title": "Detachable Object Detection: Segmentation and Depth Ordering From   Short-Baseline Video", 
    "publish": "2011-09-22T00:55:32Z", 
    "summary": "We describe an approach for segmenting an image into regions that correspond\nto surfaces in the scene that are partially surrounded by the medium. It\nintegrates both appearance and motion statistics into a cost functional, that\nis seeded with occluded regions and minimized efficiently by solving a linear\nprogramming problem. Where a short observation time is insufficient to\ndetermine whether the object is detachable, the results of the minimization can\nbe used to seed a more costly optimization based on a longer sequence of video\ndata. The result is an entirely unsupervised scheme to detect and segment an\narbitrary and unknown number of objects. We test our scheme to highlight the\npotential, as well as limitations, of our approach.", 
    "link": "http://arxiv.org/pdf/1109.4683v1", 
    "arxiv-id": "1109.4683v1"
},{
    "category": "cs.CV", 
    "author": "Klaus Obermayer", 
    "title": "Probabilistic prototype models for attributed graphs", 
    "publish": "2011-09-22T09:26:23Z", 
    "summary": "This contribution proposes a new approach towards developing a class of\nprobabilistic methods for classifying attributed graphs. The key concept is\nrandom attributed graph, which is defined as an attributed graph whose nodes\nand edges are annotated by random variables. Every node/edge has two random\nprocesses associated with it- occurence probability and the probability\ndistribution over the attribute values. These are estimated within the maximum\nlikelihood framework. The likelihood of a random attributed graph to generate\nan outcome graph is used as a feature for classification. The proposed approach\nis fast and robust to noise.", 
    "link": "http://arxiv.org/pdf/1109.4744v1", 
    "arxiv-id": "1109.4744v1"
},{
    "category": "cs.CV", 
    "author": "Sriram Vishwanath", 
    "title": "Sparse Online Low-Rank Projection and Outlier Rejection (SOLO) for 3-D   Rigid-Body Motion Registration", 
    "publish": "2011-09-22T18:41:00Z", 
    "summary": "Motivated by an emerging theory of robust low-rank matrix representation, in\nthis paper, we introduce a novel solution for online rigid-body motion\nregistration. The goal is to develop algorithmic techniques that enable a\nrobust, real-time motion registration solution suitable for low-cost, portable\n3-D camera devices. Assuming 3-D image features are tracked via a standard\ntracker, the algorithm first utilizes Robust PCA to initialize a low-rank shape\nrepresentation of the rigid body. Robust PCA finds the global optimal solution\nof the initialization, while its complexity is comparable to singular value\ndecomposition. In the online update stage, we propose a more efficient\nalgorithm for sparse subspace projection to sequentially project new feature\nobservations onto the shape subspace. The lightweight update stage guarantees\nthe real-time performance of the solution while maintaining good registration\neven when the image sequence is contaminated by noise, gross data corruption,\noutlying features, and missing data. The state-of-the-art accuracy of the\nsolution is validated through extensive simulation and a real-world experiment,\nwhile the system enjoys one to two orders of magnitude speed-up compared to\nwell-established RANSAC solutions. The new algorithm will be released online to\naid peer evaluation.", 
    "link": "http://arxiv.org/pdf/1109.4909v1", 
    "arxiv-id": "1109.4909v1"
},{
    "category": "cs.CV", 
    "author": "Sebanti Sanyal", 
    "title": "Improvements on \"Fast space-variant elliptical filtering using box   splines\"", 
    "publish": "2011-09-23T15:43:21Z", 
    "summary": "It is well-known that box filters can be efficiently computed using\npre-integrations and local finite-differences\n[Crow1984,Heckbert1986,Viola2001]. By generalizing this idea and by combining\nit with a non-standard variant of the Central Limit Theorem, a constant-time or\nO(1) algorithm was proposed in [Chaudhury2010] that allowed one to perform\nspace-variant filtering using Gaussian-like kernels. The algorithm was based on\nthe observation that both isotropic and anisotropic Gaussians could be\napproximated using certain bivariate splines called box splines. The attractive\nfeature of the algorithm was that it allowed one to continuously control the\nshape and size (covariance) of the filter, and that it had a fixed\ncomputational cost per pixel, irrespective of the size of the filter. The\nalgorithm, however, offered a limited control on the covariance and accuracy of\nthe Gaussian approximation. In this work, we propose some improvements by\nappropriately modifying the algorithm in [Chaudhury2010].", 
    "link": "http://arxiv.org/pdf/1109.5114v3", 
    "arxiv-id": "1109.5114v3"
},{
    "category": "cs.CV", 
    "author": "Masato Inoue", 
    "title": "Posterior Mean Super-resolution with a Causal Gaussian Markov Random   Field Prior", 
    "publish": "2011-09-26T06:23:09Z", 
    "summary": "We propose a Bayesian image super-resolution (SR) method with a causal\nGaussian Markov random field (MRF) prior. SR is a technique to estimate a\nspatially high-resolution image from given multiple low-resolution images. An\nMRF model with the line process supplies a preferable prior for natural images\nwith edges. We improve the existing image transformation model, the compound\nMRF model, and its hyperparameter prior model. We also derive the optimal\nestimator -- not the joint maximum a posteriori (MAP) or marginalized maximum\nlikelihood (ML), but the posterior mean (PM) -- from the objective function of\nthe L2-norm (mean square error) -based peak signal-to-noise ratio (PSNR). Point\nestimates such as MAP and ML are generally not stable in ill-posed\nhigh-dimensional problems because of overfitting, while PM is a stable\nestimator because all the parameters in the model are evaluated as\ndistributions. The estimator is numerically determined by using variational\nBayes. Variational Bayes is a widely used method that approximately determines\na complicated posterior distribution, but it is generally hard to use because\nit needs the conjugate prior. We solve this problem with simple Taylor\napproximations. Experimental results have shown that the proposed method is\nmore accurate or comparable to existing methods.", 
    "link": "http://arxiv.org/pdf/1109.5453v4", 
    "arxiv-id": "1109.5453v4"
},{
    "category": "cs.CV", 
    "author": "Jagdish L. Raheja", 
    "title": "ABHIVYAKTI: A Vision Based Intelligent System for Elder and Sick Persons", 
    "publish": "2011-09-29T08:59:29Z", 
    "summary": "This paper describes an intelligent system ABHIVYAKTI, which would be\npervasive in nature and based on the Computer Vision. It would be very easy in\nuse and deployment. Elder and sick people who are not able to talk or walk,\nthey are dependent on other human beings and need continuous monitoring, while\nour system provides flexibility to the sick or elder person to announce his or\nher need to their caretaker by just showing a particular gesture with the\ndeveloped system, if the caretaker is not nearby. This system will use\nfingertip detection techniques for acquiring gesture and Artificial Neural\nNetworks (ANNs) will be used for gesture recognition.", 
    "link": "http://arxiv.org/pdf/1109.6442v2", 
    "arxiv-id": "1109.6442v2"
},{
    "category": "cs.CV", 
    "author": "Sumita Mishra", 
    "title": "A Novel comprehensive method for real time Video Motion Detection   Surveillance", 
    "publish": "2011-09-30T14:48:51Z", 
    "summary": "This article describes a comprehensive system for surveillance and monitoring\napplications. The development of an efficient real time video motion detection\nsystem is motivated by their potential for deployment in the areas where\nsecurity is the main concern. The paper presents a platform for real time video\nmotion detection and subsequent generation of an alarm condition as set by the\nparameters of the control system. The prototype consists of a mobile platform\nmounted with RF camera which provides continuous feedback of the environment.\nThe received visual information is then analyzed by user for appropriate\ncontrol action, thus enabling the user to operate the system from a remote\nlocation. The system is also equipped with the ability to process the image of\nan object and generate control signals which are automatically transmitted to\nthe mobile platform to track the object.", 
    "link": "http://arxiv.org/pdf/1109.6840v1", 
    "arxiv-id": "1109.6840v1"
},{
    "category": "cs.CV", 
    "author": "Yongsheng Gao", 
    "title": "Face Recognition using Optimal Representation Ensemble", 
    "publish": "2011-10-03T04:44:47Z", 
    "summary": "Recently, the face recognizers based on linear representations have been\nshown to deliver state-of-the-art performance. In real-world applications,\nhowever, face images usually suffer from expressions, disguises and random\nocclusions. The problematic facial parts undermine the validity of the\nlinear-subspace assumption and thus the recognition performance deteriorates\nsignificantly. In this work, we address the problem in a\nlearning-inference-mixed fashion. By observing that the linear-subspace\nassumption is more reliable on certain face patches rather than on the holistic\nface, some Bayesian Patch Representations (BPRs) are randomly generated and\ninterpreted according to the Bayes' theory. We then train an ensemble model\nover the patch-representations by minimizing the empirical risk w.r.t the\n\"leave-one-out margins\". The obtained model is termed Optimal Representation\nEnsemble (ORE), since it guarantees the optimality from the perspective of\nEmpirical Risk Minimization. To handle the unknown patterns in test faces, a\nrobust version of BPR is proposed by taking the non-face category into\nconsideration. Equipped with the Robust-BPRs, the inference ability of ORE is\nincreased dramatically and several record-breaking accuracies (99.9% on Yale-B\nand 99.5% on AR) and desirable efficiencies (below 20 ms per face in Matlab)\nare achieved. It also overwhelms other modular heuristics on the faces with\nrandom occlusions, extreme expressions and disguises. Furthermore, to\naccommodate immense BPRs sets, a boosting-like algorithm is also derived. The\nboosted model, a.k.a Boosted-ORE, obtains similar performance to its prototype.\nBesides the empirical superiorities, two desirable features of the proposed\nmethods, namely, the training-determined model-selection and the\ndata-weight-free boosting procedure, are also theoretically verified.", 
    "link": "http://arxiv.org/pdf/1110.0264v1", 
    "arxiv-id": "1110.0264v1"
},{
    "category": "cs.CV", 
    "author": "Javier Movellan", 
    "title": "Discriminately Decreasing Discriminability with Learned Image Filters", 
    "publish": "2011-10-04T06:48:29Z", 
    "summary": "In machine learning and computer vision, input images are often filtered to\nincrease data discriminability. In some situations, however, one may wish to\npurposely decrease discriminability of one classification task (a \"distractor\"\ntask), while simultaneously preserving information relevant to another (the\ntask-of-interest): For example, it may be important to mask the identity of\npersons contained in face images before submitting them to a crowdsourcing site\n(e.g., Mechanical Turk) when labeling them for certain facial attributes.\nAnother example is inter-dataset generalization: when training on a dataset\nwith a particular covariance structure among multiple attributes, it may be\nuseful to suppress one attribute while preserving another so that a trained\nclassifier does not learn spurious correlations between attributes. In this\npaper we present an algorithm that finds optimal filters to give high\ndiscriminability to one task while simultaneously giving low discriminability\nto a distractor task. We present results showing the effectiveness of the\nproposed technique on both simulated data and natural face images.", 
    "link": "http://arxiv.org/pdf/1110.0585v1", 
    "arxiv-id": "1110.0585v1"
},{
    "category": "cs.CV", 
    "author": "Toshiro Kubota", 
    "title": "Non-Gaussian Scale Space Filtering with 2 by 2 Matrix of Linear Filters", 
    "publish": "2011-10-04T23:58:55Z", 
    "summary": "Construction of a scale space with a convolution filter has been studied\nextensively in the past. It has been proven that the only convolution kernel\nthat satisfies the scale space requirements is a Gaussian type. In this paper,\nwe consider a matrix of convolution filters introduced in [1] as a building\nkernel for a scale space, and shows that we can construct a non-Gaussian scale\nspace with a $2\\times 2$ matrix of filters. The paper derives sufficient\nconditions for the matrix of filters for being a scale space kernel, and\npresent some numerical demonstrations.", 
    "link": "http://arxiv.org/pdf/1110.0872v1", 
    "arxiv-id": "1110.0872v1"
},{
    "category": "cs.CV", 
    "author": "Shaikh Anowarul Fattah", 
    "title": "A Face Recognition Scheme using Wavelet Based Dominant Features", 
    "publish": "2011-10-07T11:16:17Z", 
    "summary": "In this paper, a multi-resolution feature extraction algorithm for face\nrecognition is proposed based on two-dimensional discrete wavelet transform\n(2D-DWT), which efficiently exploits the local spatial variations in a face\nimage. For the purpose of feature extraction, instead of considering the entire\nface image, an entropy-based local band selection criterion is developed, which\nselects high-informative horizontal segments from the face image. In order to\ncapture the local spatial variations within these highinformative horizontal\nbands precisely, the horizontal band is segmented into several small spatial\nmodules. Dominant wavelet coefficients corresponding to each local region\nresiding inside those horizontal bands are selected as features. In the\nselection of the dominant coefficients, a threshold criterion is proposed,\nwhich not only drastically reduces the feature dimension but also provides high\nwithin-class compactness and high between-class separability. A principal\ncomponent analysis is performed to further reduce the dimensionality of the\nfeature space. Extensive experimentation is carried out upon standard face\ndatabases and a very high degree of recognition accuracy is achieved by the\nproposed method in comparison to those obtained by some of the existing\nmethods.", 
    "link": "http://arxiv.org/pdf/1110.1485v1", 
    "arxiv-id": "1110.1485v1"
},{
    "category": "cs.CV", 
    "author": "P. I. Santosa", 
    "title": "A Comparative Experiment of Several Shape Methods in Recognizing Plants", 
    "publish": "2011-10-07T12:43:38Z", 
    "summary": "Shape is an important aspects in recognizing plants. Several approaches have\nbeen introduced to identify objects, including plants. Combination of geometric\nfeatures such as aspect ratio, compactness, and dispersion, or moments such as\nmoment invariants were usually used toidentify plants. In this research, a\ncomparative experiment of 4 methods to identify plants using shape features was\naccomplished. Two approaches have never been used in plants identification yet,\nZernike moments and Polar Fourier Transform (PFT), were incorporated. The\nexperimental comparison was done on 52 kinds of plants with various shapes. The\nresult, PFT gave best performance with 64% in accuracy and outperformed the\nother methods.", 
    "link": "http://arxiv.org/pdf/1110.1509v1", 
    "arxiv-id": "1110.1509v1"
},{
    "category": "cs.CV", 
    "author": "Paulus Insap Santosa", 
    "title": "Foliage Plant Retrieval using Polar Fourier Transform, Color Moments and   Vein Features", 
    "publish": "2011-10-07T13:00:03Z", 
    "summary": "This paper proposed a method that combines Polar Fourier Transform, color\nmoments, and vein features to retrieve leaf images based on a leaf image. The\nmethod is very useful to help people in recognizing foliage plants. Foliage\nplants are plants that have various colors and unique patterns in the leaf.\nTherefore, the colors and its patterns are information that should be counted\non in the processing of plant identification. To compare the performance of\nretrieving system to other result, the experiments used Flavia dataset, which\nis very popular in recognizing plants. The result shows that the method gave\nbetter performance than PNN, SVM, and Fourier Transform. The method was also\ntested using foliage plants with various colors. The accuracy was 90.80% for 50\nkinds of plants.", 
    "link": "http://arxiv.org/pdf/1110.1513v1", 
    "arxiv-id": "1110.1513v1"
},{
    "category": "cs.CV", 
    "author": "Stefano Soatto", 
    "title": "Steps Towards a Theory of Visual Information: Active Perception,   Signal-to-Symbol Conversion and the Interplay Between Sensing and Control", 
    "publish": "2011-10-10T14:28:41Z", 
    "summary": "This manuscript describes the elements of a theory of information tailored to\ncontrol and decision tasks and specifically to visual data. The concept of\nActionable Information is described, that relates to a notion of information\nchampioned by J. Gibson, and a notion of \"complete information\" that relates to\nthe minimal sufficient statistics of a complete representation. It is shown\nthat the \"actionable information gap\" between the two can be reduced by\nexercising control on the sensing process. Thus, senging, control and\ninformation are inextricably tied. This has consequences in the so-called\n\"signal-to-symbol barrier\" problem, as well as in the analysis and design of\nactive sensing systems. It has ramifications in vision-based control,\nnavigation, 3-D reconstruction and rendering, as well as detection,\nlocalization, recognition and categorization of objects and scenes in live\nvideo.\n  This manuscript has been developed from a set of lecture notes for a summer\ncourse at the First International Computer Vision Summer School (ICVSS) in\nScicli, Italy, in July of 2008. They were later expanded and amended for\nsubsequent lectures in the same School in July 2009. Starting on November 1,\n2009, they were further expanded for a special topics course, CS269, taught at\nUCLA in the Spring term of 2010.", 
    "link": "http://arxiv.org/pdf/1110.2053v3", 
    "arxiv-id": "1110.2053v3"
},{
    "category": "cs.CV", 
    "author": "J. H. Piater", 
    "title": "Closed-Loop Learning of Visual Control Policies", 
    "publish": "2011-10-10T21:56:36Z", 
    "summary": "In this paper we present a general, flexible framework for learning mappings\nfrom images to actions by interacting with the environment. The basic idea is\nto introduce a feature-based image classifier in front of a reinforcement\nlearning algorithm. The classifier partitions the visual space according to the\npresence or absence of few highly informative local descriptors that are\nincrementally selected in a sequence of attempts to remove perceptual aliasing.\nWe also address the problem of fighting overfitting in such a greedy algorithm.\nFinally, we show how high-level visual features can be generated when the power\nof local descriptors is insufficient for completely disambiguating the aliased\nstates. This is done by building a hierarchy of composite features that consist\nof recursive spatial combinations of visual features. We demonstrate the\nefficacy of our algorithms by solving three visual navigation tasks and a\nvisual version of the classical Car on the Hill control problem.", 
    "link": "http://arxiv.org/pdf/1110.2210v1", 
    "arxiv-id": "1110.2210v1"
},{
    "category": "cs.CV", 
    "author": "Quansheng Liu", 
    "title": "Controlled Total Variation regularization for inverse problems", 
    "publish": "2011-10-14T13:02:36Z", 
    "summary": "This paper provides a new algorithm for solving inverse problems, based on\nthe minimization of the $L^2$ norm and on the control of the Total Variation.\nIt consists in relaxing the role of the Total Variation in the classical Total\nVariation minimization approach, which permits us to get better approximation\nto the inverse problems. The numerical results on the deconvolution problem\nshow that our method outperforms some previous ones.", 
    "link": "http://arxiv.org/pdf/1110.3194v1", 
    "arxiv-id": "1110.3194v1"
},{
    "category": "cs.CV", 
    "author": "Ali A. Al-Zaky", 
    "title": "Studying Satellite Image Quality Based on the Fusion Techniques", 
    "publish": "2011-10-22T13:26:00Z", 
    "summary": "Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. However,\nthe jury is still out on the benefits of a fused image compared to its original\nimages. There is also a lack of measures for assessing the objective quality of\nthe spatial resolution for the fusion methods. Therefore, an objective quality\nof the spatial resolution assessment for fusion images is required. So, this\nstudy attempts to develop a new qualitative assessment to evaluate the spatial\nquality of the pan sharpened images by many spatial quality metrics. Also, this\npaper deals with a comparison of various image fusion techniques based on pixel\nand feature fusion techniques.", 
    "link": "http://arxiv.org/pdf/1110.4970v1", 
    "arxiv-id": "1110.4970v1"
},{
    "category": "cs.CV", 
    "author": "Len Bui", 
    "title": "Face Recognition Based on SVM and 2DPCA", 
    "publish": "2011-10-25T03:54:51Z", 
    "summary": "The paper will present a novel approach for solving face recognition problem.\nOur method combines 2D Principal Component Analysis (2DPCA), one of the\nprominent methods for extracting feature vectors, and Support Vector Machine\n(SVM), the most powerful discriminative method for classification. Experiments\nbased on proposed method have been conducted on two public data sets FERET and\nAT&T; the results show that the proposed method could improve the\nclassification rates.", 
    "link": "http://arxiv.org/pdf/1110.5404v1", 
    "arxiv-id": "1110.5404v1"
},{
    "category": "cs.CV", 
    "author": "Marvin Lindner", 
    "title": "Hand Tracking based on Hierarchical Clustering of Range Data", 
    "publish": "2011-10-25T09:24:25Z", 
    "summary": "Fast and robust hand segmentation and tracking is an essential basis for\ngesture recognition and thus an important component for contact-less\nhuman-computer interaction (HCI). Hand gesture recognition based on 2D video\ndata has been intensively investigated. However, in practical scenarios purely\nintensity based approaches suffer from uncontrollable environmental conditions\nlike cluttered background colors. In this paper we present a real-time hand\nsegmentation and tracking algorithm using Time-of-Flight (ToF) range cameras\nand intensity data. The intensity and range information is fused into one pixel\nvalue, representing its combined intensity-depth homogeneity. The scene is\nhierarchically clustered using a GPU based parallel merging algorithm, allowing\na robust identification of both hands even for inhomogeneous backgrounds. After\nthe detection, both hands are tracked on the CPU. Our tracking algorithm can\ncope with the situation that one hand is temporarily covered by the other hand.", 
    "link": "http://arxiv.org/pdf/1110.5450v1", 
    "arxiv-id": "1110.5450v1"
},{
    "category": "cs.CV", 
    "author": "Oleg V. Michailovich", 
    "title": "A New Similarity Measure for Non-Local Means Filtering of MRI Images", 
    "publish": "2011-10-26T23:14:57Z", 
    "summary": "The acquisition of MRI images offers a trade-off in terms of acquisition\ntime, spatial/temporal resolution and signal-to-noise ratio (SNR). Thus, for\ninstance, increasing the time efficiency of MRI often comes at the expense of\nreduced SNR. This, in turn, necessitates the use of post-processing tools for\nnoise rejection, which makes image de-noising an indispensable component of\ncomputer assistance diagnosis. In the field of MRI, a multitude of image\nde-noising methods have been proposed hitherto. In this paper, the application\nof a particular class of de-noising algorithms - known as non-local mean (NLM)\nfilters - is investigated. Such filters have been recently applied for MRI data\nenhancement and they have been shown to provide more accurate results as\ncompared to many alternative de-noising algorithms. Unfortunately, virtually\nall existing methods for NLM filtering have been derived under the assumption\nof additive white Gaussian (AWG) noise contamination. Since this assumption is\nknown to fail at low values of SNR, an alternative formulation of NLM filtering\nis required, which would take into consideration the correct Rician statistics\nof MRI noise. Accordingly, the contribution of the present paper is two-fold.\nFirst, it points out some principal disadvantages of the earlier methods of NLM\nfiltering of MRI images and suggests means to rectify them. Second, the paper\nintroduces a new similarity measure for NLM filtering of MRI Images, which is\nderived under bona fide statistical assumptions and results in more accurate\nreconstruction of MR scans as compared to alternative NLM approaches. Finally,\nthe utility and viability of the proposed method is demonstrated through a\nseries of numerical experiments using both in silico and in vivo MRI data.", 
    "link": "http://arxiv.org/pdf/1110.5945v1", 
    "arxiv-id": "1110.5945v1"
},{
    "category": "cs.CV", 
    "author": "Hassan Ghassemian", 
    "title": "Graph Regularized Nonnegative Matrix Factorization for Hyperspectral   Data Unmixing", 
    "publish": "2011-11-03T15:46:47Z", 
    "summary": "Spectral unmixing is an important tool in hyperspectral data analysis for\nestimating endmembers and abundance fractions in a mixed pixel. This paper\nexamines the applicability of a recently developed algorithm called graph\nregularized nonnegative matrix factorization (GNMF) for this aim. The proposed\napproach exploits the intrinsic geometrical structure of the data besides\nconsidering positivity and full additivity constraints. Simulated data based on\nthe measured spectral signatures, is used for evaluating the proposed\nalgorithm. Results in terms of abundance angle distance (AAD) and spectral\nangle distance (SAD) show that this method can effectively unmix hyperspectral\ndata.", 
    "link": "http://arxiv.org/pdf/1111.0885v1", 
    "arxiv-id": "1111.0885v1"
},{
    "category": "cs.CV", 
    "author": "Yi Ma", 
    "title": "Sparsity and Robustness in Face Recognition", 
    "publish": "2011-11-03T23:50:36Z", 
    "summary": "This report concerns the use of techniques for sparse signal representation\nand sparse error correction for automatic face recognition. Much of the recent\ninterest in these techniques comes from the paper \"Robust Face Recognition via\nSparse Representation\" by Wright et al. (2009), which showed how, under certain\ntechnical conditions, one could cast the face recognition problem as one of\nseeking a sparse representation of a given input face image in terms of a\n\"dictionary\" of training images and images of individual pixels. In this\nreport, we have attempted to clarify some frequently encountered questions\nabout this work and particularly, on the validity of using sparse\nrepresentation techniques for face recognition.", 
    "link": "http://arxiv.org/pdf/1111.1014v1", 
    "arxiv-id": "1111.1014v1"
},{
    "category": "cs.CV", 
    "author": "M. Mani Roja", 
    "title": "A robust, low-cost approach to Face Detection and Face Recognition", 
    "publish": "2011-11-04T10:36:43Z", 
    "summary": "In the domain of Biometrics, recognition systems based on iris, fingerprint\nor palm print scans etc. are often considered more dependable due to extremely\nlow variance in the properties of these entities with respect to time. However,\nover the last decade data processing capability of computers has increased\nmanifold, which has made real-time video content analysis possible. This shows\nthat the need of the hour is a robust and highly automated Face Detection and\nRecognition algorithm with credible accuracy rate. The proposed Face Detection\nand Recognition system using Discrete Wavelet Transform (DWT) accepts face\nframes as input from a database containing images from low cost devices such as\nVGA cameras, webcams or even CCTV's, where image quality is inferior. Face\nregion is then detected using properties of L*a*b* color space and only Frontal\nFace is extracted such that all additional background is eliminated. Further,\nthis extracted image is converted to grayscale and its dimensions are resized\nto 128 x 128 pixels. DWT is then applied to entire image to obtain the\ncoefficients. Recognition is carried out by comparison of the DWT coefficients\nbelonging to the test image with those of the registered reference image. On\ncomparison, Euclidean distance classifier is deployed to validate the test\nimage from the database. Accuracy for various levels of DWT Decomposition is\nobtained and hence, compared.", 
    "link": "http://arxiv.org/pdf/1111.1090v1", 
    "arxiv-id": "1111.1090v1"
},{
    "category": "cs.CV", 
    "author": "Richard Herrmann", 
    "title": "Covariant fractional extension of the modified Laplace-operator used in   3D-shape recovery", 
    "publish": "2011-11-05T14:09:05Z", 
    "summary": "Extending the Liouville-Caputo definition of a fractional derivative to a\nnonlocal covariant generalization of arbitrary bound operators acting on\nmultidimensional Riemannian spaces an appropriate approach for the 3D shape\nrecovery of aperture afflicted 2D slide sequences is proposed. We demonstrate,\nthat the step from a local to a nonlocal algorithm yields an order of magnitude\nin accuracy and by using the specific fractional approach an additional factor\n2 in accuracy of the derived results.", 
    "link": "http://arxiv.org/pdf/1111.1311v1", 
    "arxiv-id": "1111.1311v1"
},{
    "category": "cs.CV", 
    "author": "Michael M. Bronstein", 
    "title": "Multimodal diff-hash", 
    "publish": "2011-11-07T00:28:37Z", 
    "summary": "Many applications require comparing multimodal data with different structure\nand dimensionality that cannot be compared directly. Recently, there has been\nincreasing interest in methods for learning and efficiently representing such\nmultimodal similarity. In this paper, we present a simple algorithm for\nmultimodal similarity-preserving hashing, trying to map multimodal data into\nthe Hamming space while preserving the intra- and inter-modal similarities. We\nshow that our method significantly outperforms the state-of-the-art method in\nthe field.", 
    "link": "http://arxiv.org/pdf/1111.1461v1", 
    "arxiv-id": "1111.1461v1"
},{
    "category": "cs.CV", 
    "author": "R. M. El-Awady", 
    "title": "Iris Recognition Based on LBP and Combined LVQ Classifier", 
    "publish": "2011-11-07T12:35:29Z", 
    "summary": "Iris recognition is considered as one of the best biometric methods used for\nhuman identification and verification, this is because of its unique features\nthat differ from one person to another, and its importance in the security\nfield. This paper proposes an algorithm for iris recognition and classification\nusing a system based on Local Binary Pattern and histogram properties as a\nstatistical approaches for feature extraction, and Combined Learning Vector\nQuantization Classifier as Neural Network approach for classification, in order\nto build a hybrid model depends on both features. The localization and\nsegmentation techniques are presented using both Canny edge detection and Hough\nCircular Transform in order to isolate an iris from the whole eye image and for\nnoise detection .Feature vectors results from LBP is applied to a Combined LVQ\nclassifier with different classes to determine the minimum acceptable\nperformance, and the result is based on majority voting among several LVQ\nclassifier. Different iris datasets CASIA, MMU1, MMU2, and LEI with different\nextensions and size are presented. Since LBP is working on a grayscale level so\ncolored iris images should be transformed into a grayscale level. The proposed\nsystem gives a high recognition rate 99.87 % on different iris datasets\ncompared with other methods.", 
    "link": "http://arxiv.org/pdf/1111.1562v1", 
    "arxiv-id": "1111.1562v1"
},{
    "category": "cs.CV", 
    "author": "Jason J. Corso", 
    "title": "Efficient Hierarchical Markov Random Fields for Object Detection on a   Mobile Robot", 
    "publish": "2011-11-07T14:46:16Z", 
    "summary": "Object detection and classification using video is necessary for intelligent\nplanning and navigation on a mobile robot. However, current methods can be too\nslow or not sufficient for distinguishing multiple classes. Techniques that\nrely on binary (foreground/background) labels incorrectly identify areas with\nmultiple overlapping objects as single segment. We propose two Hierarchical\nMarkov Random Field models in efforts to distinguish connected objects using\ntiered, binary label sets. Near-realtime performance has been achieved using\nefficient optimization methods which runs up to 11 frames per second on a dual\ncore 2.2 Ghz processor. Evaluation of both models is done using footage taken\nfrom a robot obstacle course at the 2010 Intelligent Ground Vehicle\nCompetition.", 
    "link": "http://arxiv.org/pdf/1111.1599v1", 
    "arxiv-id": "1111.1599v1"
},{
    "category": "cs.CV", 
    "author": "Omar El Beqqali", 
    "title": "New Method for 3D Shape Retrieval", 
    "publish": "2011-11-07T21:24:36Z", 
    "summary": "The recent technological progress in acquisition, modeling and processing of\n3D data leads to the proliferation of a large number of 3D objects databases.\nConsequently, the techniques used for content based 3D retrieval has become\nnecessary. In this paper, we introduce a new method for 3D objects recognition\nand retrieval by using a set of binary images CLI (Characteristic level\nimages). We propose a 3D indexing and search approach based on the similarity\nbetween characteristic level images using Hu moments for it indexing. To\nmeasure the similarity between 3D objects we compute the Hausdorff distance\nbetween a vectors descriptor. The performance of this new approach is evaluated\nat set of 3D object of well known database, is NTU (National Taiwan University)\ndatabase.", 
    "link": "http://arxiv.org/pdf/1111.1752v1", 
    "arxiv-id": "1111.1752v1"
},{
    "category": "cs.CV", 
    "author": "Trac D. Tran", 
    "title": "Discriminative Local Sparse Representations for Robust Face Recognition", 
    "publish": "2011-11-08T16:04:58Z", 
    "summary": "A key recent advance in face recognition models a test face image as a sparse\nlinear combination of a set of training face images. The resulting sparse\nrepresentations have been shown to possess robustness against a variety of\ndistortions like random pixel corruption, occlusion and disguise. This approach\nhowever makes the restrictive (in many scenarios) assumption that test faces\nmust be perfectly aligned (or registered) to the training data prior to\nclassification. In this paper, we propose a simple yet robust local block-based\nsparsity model, using adaptively-constructed dictionaries from local features\nin the training data, to overcome this misalignment problem. Our approach is\ninspired by human perception: we analyze a series of local discriminative\nfeatures and combine them to arrive at the final classification decision. We\npropose a probabilistic graphical model framework to explicitly mine the\nconditional dependencies between these distinct sparse local features. In\nparticular, we learn discriminative graphs on sparse representations obtained\nfrom distinct local slices of a face. Conditional correlations between these\nsparse features are first discovered (in the training phase), and subsequently\nexploited to bring about significant improvements in recognition rates.\nExperimental results obtained on benchmark face databases demonstrate the\neffectiveness of the proposed algorithms in the presence of multiple\nregistration errors (such as translation, rotation, and scaling) as well as\nunder variations of pose and illumination.", 
    "link": "http://arxiv.org/pdf/1111.1947v1", 
    "arxiv-id": "1111.1947v1"
},{
    "category": "cs.CV", 
    "author": "V. Subbiah Bharathi", 
    "title": "A Novel Approach to Texture classification using statistical feature", 
    "publish": "2011-11-10T04:28:08Z", 
    "summary": "Texture is an important spatial feature which plays a vital role in content\nbased image retrieval. The enormous growth of the internet and the wide use of\ndigital data have increased the need for both efficient image database creation\nand retrieval procedure. This paper describes a new approach for texture\nclassification by combining statistical texture features of Local Binary\nPattern and Texture spectrum. Since most significant information of a texture\noften appears in the high frequency channels, the features are extracted by the\ncomputation of LBP and Texture Spectrum and Legendre Moments. Euclidean\ndistance is used for similarity measurement. The experimental result shows that\n97.77% classification accuracy is obtained by the proposed method.", 
    "link": "http://arxiv.org/pdf/1111.2391v1", 
    "arxiv-id": "1111.2391v1"
},{
    "category": "cs.CV", 
    "author": "Martin H\u00fcnniger", 
    "title": "Good Pairs of Adjacency Relations in Arbitrary Dimensions", 
    "publish": "2011-11-16T14:37:07Z", 
    "summary": "In this text we show, that the notion of a \"good pair\" that was introduced in\nthe paper \"Digital Manifolds and the Theorem of Jordan-Brouwer\" has actually\nknown models. We will show, how to choose cubical adjacencies, the\ngeneralizations of the well known 4- and 8-neighborhood to arbitrary\ndimensions, in order to find good pairs. Furthermore, we give another proof for\nthe well known fact that the Khalimsky-topology implies good pairs. The outcome\nis consistent with the known theory as presented by T.Y. Kong, A. Rosenfeld,\nG.T. Herman and M. Khachan et.al and gives new insights in higher dimensions.", 
    "link": "http://arxiv.org/pdf/1111.3818v1", 
    "arxiv-id": "1111.3818v1"
},{
    "category": "cs.CV", 
    "author": "Tran Son Hai", 
    "title": "A Facial Expression Classification System Integrating Canny, Principal   Component Analysis and Artificial Neural Network", 
    "publish": "2011-11-17T10:43:08Z", 
    "summary": "Facial Expression Classification is an interesting research problem in recent\nyears. There are a lot of methods to solve this problem. In this research, we\npropose a novel approach using Canny, Principal Component Analysis (PCA) and\nArtificial Neural Network. Firstly, in preprocessing phase, we use Canny for\nlocal region detection of facial images. Then each of local region's features\nwill be presented based on Principal Component Analysis (PCA). Finally, using\nArtificial Neural Network (ANN)applies for Facial Expression Classification. We\napply our proposal method (Canny_PCA_ANN) for recognition of six basic facial\nexpressions on JAFFE database consisting 213 images posed by 10 Japanese female\nmodels. The experimental result shows the feasibility of our proposal method.", 
    "link": "http://arxiv.org/pdf/1111.4052v1", 
    "arxiv-id": "1111.4052v1"
},{
    "category": "cs.CV", 
    "author": "Mallikarjun Hangarge", 
    "title": "A Single Euler Number Feature for Multi-font Multi-size Kannada Numeral   Recognition", 
    "publish": "2011-11-18T06:34:07Z", 
    "summary": "In this paper a novel approach is proposed based on single Euler number\nfeature which is free from thinning and size normalization for multi-font and\nmulti-size Kannada numeral recognition system. A nearest neighbor\nclassification is used for classification of Kannada numerals by considering\nthe Euclidian distance. A total 1500 numeral images with different font sizes\nbetween (10..84) are tested for algorithm efficiency and the overall the\nclassification accuracy is found to be 99.00% .The said method is thinning\nfree, fast, and showed encouraging results on varying font styles and sizes of\nKannada numerals.", 
    "link": "http://arxiv.org/pdf/1111.4290v1", 
    "arxiv-id": "1111.4290v1"
},{
    "category": "cs.CV", 
    "author": "Mallikarjun Hangarge", 
    "title": "Multi-font Multi-size Kannada Numeral Recognition Based on Structural   Features", 
    "publish": "2011-11-18T06:59:35Z", 
    "summary": "In this paper a fast and novel method is proposed for multi-font multi-size\nKannada numeral recognition which is thinning free and without size\nnormalization approach. The different structural feature are used for numeral\nrecognition namely, directional density of pixels in four directions, water\nreservoirs, maximum profile distances, and fill hole density are used for the\nrecognition of Kannada numerals. A Euclidian minimum distance criterion is used\nto find minimum distances and K-nearest neighbor classifier is used to classify\nthe Kannada numerals by varying the size of numeral image from 16 to 50 font\nsizes for the 20 different font styles from NUDI and BARAHA popular word\nprocessing Kannada software. The total 1150 numeral images are tested and the\noverall accuracy of classification is found to be 100%. The average time taken\nby this method is 0.1476 seconds.", 
    "link": "http://arxiv.org/pdf/1111.4291v1", 
    "arxiv-id": "1111.4291v1"
},{
    "category": "cs.CV", 
    "author": "Israel Cohen", 
    "title": "Redundant Wavelets on Graphs and High Dimensional Data Clouds", 
    "publish": "2011-11-20T08:58:45Z", 
    "summary": "In this paper, we propose a new redundant wavelet transform applicable to\nscalar functions defined on high dimensional coordinates, weighted graphs and\nnetworks. The proposed transform utilizes the distances between the given data\npoints. We modify the filter-bank decomposition scheme of the redundant wavelet\ntransform by adding in each decomposition level linear operators that reorder\nthe approximation coefficients. These reordering operators are derived by\norganizing the tree-node features so as to shorten the path that passes through\nthese points. We explore the use of the proposed transform to image denoising,\nand show that it achieves denoising results that are close to those obtained\nwith the BM3D algorithm.", 
    "link": "http://arxiv.org/pdf/1111.4619v1", 
    "arxiv-id": "1111.4619v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "A self-portrait of young Leonardo", 
    "publish": "2011-11-20T17:41:01Z", 
    "summary": "One of the most famous drawings by Leonardo da Vinci is a self-portrait in\nred chalk, where he looks quite old. In fact, there is a sketch in one of his\nnotebooks, partially covered by written notes, that can be a self-portrait of\nthe artist when he was young. The use of image processing, to remove the\nhandwritten text and improve the image, allows a comparison of the two\nportraits.", 
    "link": "http://arxiv.org/pdf/1111.4654v1", 
    "arxiv-id": "1111.4654v1"
},{
    "category": "cs.CV", 
    "author": "Andrew Pickin", 
    "title": "Facial Asymmetry and Emotional Expression", 
    "publish": "2011-11-20T20:55:07Z", 
    "summary": "This report is about facial asymmetry, its connection to emotional\nexpression, and methods of measuring facial asymmetry in videos of faces. The\nresearch was motivated by two factors: firstly, there was a real opportunity to\ndevelop a novel measure of asymmetry that required minimal human involvement\nand that improved on earlier measures in the literature; and secondly, the\nstudy of the relationship between facial asymmetry and emotional expression is\nboth interesting in its own right, and important because it can inform\nneuropsychological theory and answer open questions concerning emotional\nprocessing in the brain. The two aims of the research were: first, to develop\nan automatic frame-by-frame measure of facial asymmetry in videos of faces that\nimproved on previous measures; and second, to use the measure to analyse the\nrelationship between facial asymmetry and emotional expression, and connect our\nfindings with previous research of the relationship.", 
    "link": "http://arxiv.org/pdf/1111.4676v1", 
    "arxiv-id": "1111.4676v1"
},{
    "category": "cs.CV", 
    "author": "Richard G. Baraniuk", 
    "title": "A Theory for Optical flow-based Transport on Image Manifolds", 
    "publish": "2011-11-22T05:55:25Z", 
    "summary": "An image articulation manifold (IAM) is the collection of images formed when\nan object is articulated in front of a camera. IAMs arise in a variety of image\nprocessing and computer vision applications, where they provide a natural\nlow-dimensional embedding of the collection of high-dimensional images. To date\nIAMs have been studied as embedded submanifolds of Euclidean spaces.\nUnfortunately, their promise has not been realized in practice, because real\nworld imagery typically contains sharp edges that render an IAM\nnon-differentiable and hence non-isometric to the low-dimensional parameter\nspace under the Euclidean metric. As a result, the standard tools from\ndifferential geometry, in particular using linear tangent spaces to transport\nalong the IAM, have limited utility. In this paper, we explore a nonlinear\ntransport operator for IAMs based on the optical flow between images and\ndevelop new analytical tools reminiscent of those from differential geometry\nusing the idea of optical flow manifolds (OFMs). We define a new metric for\nIAMs that satisfies certain local isometry conditions, and we show how to use\nthis metric to develop a new tools such as flow fields on IAMs, parallel flow\nfields, parallel transport, as well as a intuitive notion of curvature. The\nspace of optical flow fields along a path of constant curvature has a natural\nmulti-scale structure via a monoid structure on the space of all flow fields\nalong a path. We also develop lower bounds on approximation errors while\napproximating non-parallel flow fields by parallel flow fields.", 
    "link": "http://arxiv.org/pdf/1111.5108v1", 
    "arxiv-id": "1111.5108v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "An image processing of a Raphael's portrait of Leonardo", 
    "publish": "2011-11-25T15:46:37Z", 
    "summary": "In one of his paintings, the School of Athens, Raphael is depicting Leonardo\nda Vinci as the philosopher Plato. Some image processing tools can help us in\ncomparing this portrait with two Leonardo's portraits, considered as\nself-portraits.", 
    "link": "http://arxiv.org/pdf/1111.6030v2", 
    "arxiv-id": "1111.6030v2"
},{
    "category": "cs.CV", 
    "author": "Boris Escalante-Ram\u00edrez", 
    "title": "Invariant texture analysis through Local Binary Patterns", 
    "publish": "2011-11-30T18:58:53Z", 
    "summary": "In many image processing applications, such as segmentation and\nclassification, the selection of robust features descriptors is crucial to\nimprove the discrimination capabilities in real world scenarios. In particular,\nit is well known that image textures constitute power visual cues for feature\nextraction and classification. In the past few years the local binary pattern\n(LBP) approach, a texture descriptor method proposed by Ojala et al., has\ngained increased acceptance due to its computational simplicity and more\nimportantly for encoding a powerful signature for describing textures. However,\nthe original algorithm presents some limitations such as noise sensitivity and\nits lack of rotational invariance which have led to many proposals or\nextensions in order to overcome such limitations. In this paper we performed a\nquantitative study of the Ojala's original LBP proposal together with other\nrecently proposed LBP extensions in the presence of rotational, illumination\nand noisy changes. In the experiments we have considered two different\ndatabases: Brodatz and CUReT for different sizes of LBP masks. Experimental\nresults demonstrated the effectiveness and robustness of the described texture\ndescriptors for images that are subjected to geometric or radiometric changes.", 
    "link": "http://arxiv.org/pdf/1111.7271v1", 
    "arxiv-id": "1111.7271v1"
},{
    "category": "cs.CV", 
    "author": "David G. Lowe", 
    "title": "Local Naive Bayes Nearest Neighbor for Image Classification", 
    "publish": "2011-12-01T01:19:08Z", 
    "summary": "We present Local Naive Bayes Nearest Neighbor, an improvement to the NBNN\nimage classification algorithm that increases classification accuracy and\nimproves its ability to scale to large numbers of object classes. The key\nobservation is that only the classes represented in the local neighborhood of a\ndescriptor contribute significantly and reliably to their posterior probability\nestimates. Instead of maintaining a separate search structure for each class,\nwe merge all of the reference data together into one search structure, allowing\nquick identification of a descriptor's local neighborhood. We show an increase\nin classification accuracy when we ignore adjustments to the more distant\nclasses and show that the run time grows with the log of the number of classes\nrather than linearly in the number of classes as did the original. This gives a\n100 times speed-up over the original method on the Caltech 256 dataset. We also\nprovide the first head-to-head comparison of NBNN against spatial pyramid\nmethods using a common set of input features. We show that local NBNN\noutperforms all previous NBNN based methods and the original spatial pyramid\nmodel. However, we find that local NBNN, while competitive with, does not beat\nstate-of-the-art spatial pyramid methods that use local soft assignment and\nmax-pooling.", 
    "link": "http://arxiv.org/pdf/1112.0059v1", 
    "arxiv-id": "1112.0059v1"
},{
    "category": "cs.CV", 
    "author": "Tamas Roska", 
    "title": "A Biomimetic Model of the Outer Plexiform Layer by Incorporating   Memristive Devices", 
    "publish": "2011-12-03T13:53:54Z", 
    "summary": "In this paper we present a biorealistic model for the first part of the early\nvision processing by incorporating memristive nanodevices. The architecture of\nthe proposed network is based on the organisation and functioning of the outer\nplexiform layer (OPL) in the vertebrate retina. We demonstrate that memristive\ndevices are indeed a valuable building block for neuromorphic architectures, as\ntheir highly non-linear and adaptive response could be exploited for\nestablishing ultra-dense networks with similar dynamics to their biological\ncounterparts. We particularly show that hexagonal memristive grids can be\nemployed for faithfully emulating the smoothing-effect occurring at the OPL for\nenhancing the dynamic range of the system. In addition, we employ a\nmemristor-based thresholding scheme for detecting the edges of grayscale\nimages, while the proposed system is also evaluated for its adaptation and\nfault tolerance capacity against different light or noise conditions as well as\ndistinct device yields.", 
    "link": "http://arxiv.org/pdf/1112.0655v1", 
    "arxiv-id": "1112.0655v1"
},{
    "category": "cs.CV", 
    "author": "Jean-Michel Morel", 
    "title": "Meaningful Matches in Stereovision", 
    "publish": "2011-12-06T08:06:45Z", 
    "summary": "This paper introduces a statistical method to decide whether two blocks in a\npair of of images match reliably. The method ensures that the selected block\nmatches are unlikely to have occurred \"just by chance.\" The new approach is\nbased on the definition of a simple but faithful statistical \"background model\"\nfor image blocks learned from the image itself. A theorem guarantees that under\nthis model not more than a fixed number of wrong matches occurs (on average)\nfor the whole image. This fixed number (the number of false alarms) is the only\nmethod parameter. Furthermore, the number of false alarms associated with each\nmatch measures its reliability. This \"a contrario\" block-matching method,\nhowever, cannot rule out false matches due to the presence of periodic objects\nin the images. But it is successfully complemented by a parameterless\n\"self-similarity threshold.\" Experimental evidence shows that the proposed\nmethod also detects occlusions and incoherent motions due to vehicles and\npedestrians in non simultaneous stereo.", 
    "link": "http://arxiv.org/pdf/1112.1187v1", 
    "arxiv-id": "1112.1187v1"
},{
    "category": "cs.CV", 
    "author": "Monique Thonnat", 
    "title": "A multi-feature tracking algorithm enabling adaptation to context   variations", 
    "publish": "2011-12-06T09:19:17Z", 
    "summary": "We propose in this paper a tracking algorithm which is able to adapt itself\nto different scene contexts. A feature pool is used to compute the matching\nscore between two detected objects. This feature pool includes 2D, 3D\ndisplacement distances, 2D sizes, color histogram, histogram of oriented\ngradient (HOG), color covariance and dominant color. An offline learning\nprocess is proposed to search for useful features and to estimate their weights\nfor each context. In the online tracking process, a temporal window is defined\nto establish the links between the detected objects. This enables to find the\nobject trajectories even if the objects are misdetected in some frames. A\ntrajectory filter is proposed to remove noisy trajectories. Experimentation on\ndifferent contexts is shown. The proposed tracker has been tested in videos\nbelonging to three public datasets and to the Caretaker European project. The\nexperimental results prove the effect of the proposed feature weight learning,\nand the robustness of the proposed tracker compared to some methods in the\nstate of the art. The contributions of our approach over the state of the art\ntrackers are: (i) a robust tracking algorithm based on a feature pool, (ii) a\nsupervised learning scheme to learn feature weights for each context, (iii) a\nnew method to quantify the reliability of HOG descriptor, (iv) a combination of\ncolor covariance and dominant color features with spatial pyramid distance to\nmanage the case of object occlusion.", 
    "link": "http://arxiv.org/pdf/1112.1200v1", 
    "arxiv-id": "1112.1200v1"
},{
    "category": "cs.CV", 
    "author": "G. Jena", 
    "title": "POCS Based Super-Resolution Image Reconstruction Using an Adaptive   Regularization Parameter", 
    "publish": "2011-12-07T06:29:07Z", 
    "summary": "Crucial information barely visible to the human eye is often embedded in a\nseries of low-resolution images taken of the same scene. Super-resolution\nenables the extraction of this information by reconstructing a single image, at\na high resolution than is present in any of the individual images. This is\nparticularly useful in forensic imaging, where the extraction of minute details\nin an image can help to solve a crime. Super-resolution image restoration has\nbeen one of the most important research areas in recent years which goals to\nobtain a high resolution (HR) image from several low resolutions (LR) blurred,\nnoisy, under sampled and displaced images. Relation of the HR image and LR\nimages can be modeled by a linear system using a transformation matrix and\nadditive noise. However, a unique solution may not be available because of the\nsingularity of transformation matrix. To overcome this problem, POCS method has\nbeen used. However, their performance is not good because the effect of noise\nenergy has been ignored. In this paper, we propose an adaptive regularization\napproach based on the fact that the regularization parameter should be a linear\nfunction of noise variance. The performance of the proposed approach has been\ntested on several images and the obtained results demonstrate the superiority\nof our approach compared with existing methods.", 
    "link": "http://arxiv.org/pdf/1112.1484v1", 
    "arxiv-id": "1112.1484v1"
},{
    "category": "cs.CV", 
    "author": "David Zhang", 
    "title": "Re-initialization Free Level Set Evolution via Reaction Diffusion", 
    "publish": "2011-12-07T08:16:48Z", 
    "summary": "This paper presents a novel reaction-diffusion (RD) method for implicit\nactive contours, which is completely free of the costly re-initialization\nprocedure in level set evolution (LSE). A diffusion term is introduced into\nLSE, resulting in a RD-LSE equation, to which a piecewise constant solution can\nbe derived. In order to have a stable numerical solution of the RD based LSE,\nwe propose a two-step splitting method (TSSM) to iteratively solve the RD-LSE\nequation: first iterating the LSE equation, and then solving the diffusion\nequation. The second step regularizes the level set function obtained in the\nfirst step to ensure stability, and thus the complex and costly\nre-initialization procedure is completely eliminated from LSE. By successfully\napplying diffusion to LSE, the RD-LSE model is stable by means of the simple\nfinite difference method, which is very easy to implement. The proposed RD\nmethod can be generalized to solve the LSE for both variational level set\nmethod and PDE-based level set method. The RD-LSE method shows very good\nperformance on boundary anti-leakage, and it can be readily extended to high\ndimensional level set method. The extensive and promising experimental results\non synthetic and real images validate the effectiveness of the proposed RD-LSE\napproach.", 
    "link": "http://arxiv.org/pdf/1112.1496v3", 
    "arxiv-id": "1112.1496v3"
},{
    "category": "cs.CV", 
    "author": "'Gholamali Rezai-rad'", 
    "title": "Improvement of BM3D Algorithm and Employment to Satellite and CFA Images   Denoising", 
    "publish": "2011-12-11T18:57:10Z", 
    "summary": "This paper proposes a new procedure in order to improve the performance of\nblock matching and 3-D filtering (BM3D) image denoising algorithm. It is\ndemonstrated that it is possible to achieve a better performance than that of\nBM3D algorithm in a variety of noise levels. This method changes BM3D algorithm\nparameter values according to noise level, removes prefiltering, which is used\nin high noise level; therefore Peak Signal-to-Noise Ratio (PSNR) and visual\nquality get improved, and BM3D complexities and processing time are reduced.\nThis improved BM3D algorithm is extended and used to denoise satellite and\ncolor filter array (CFA) images. Output results show that the performance has\nupgraded in comparison with current methods of denoising satellite and CFA\nimages. In this regard this algorithm is compared with Adaptive PCA algorithm,\nthat has led to superior performance for denoising CFA images, on the subject\nof PSNR and visual quality. Also the processing time has decreased\nsignificantly.", 
    "link": "http://arxiv.org/pdf/1112.2386v1", 
    "arxiv-id": "1112.2386v1"
},{
    "category": "cs.CV", 
    "author": "Meirav Galun", 
    "title": "Large Scale Correlation Clustering Optimization", 
    "publish": "2011-12-13T14:28:12Z", 
    "summary": "Clustering is a fundamental task in unsupervised learning. The focus of this\npaper is the Correlation Clustering functional which combines positive and\nnegative affinities between the data points. The contribution of this paper is\ntwo fold: (i) Provide a theoretic analysis of the functional. (ii) New\noptimization algorithms which can cope with large scale problems (>100K\nvariables) that are infeasible using existing methods. Our theoretic analysis\nprovides a probabilistic generative interpretation for the functional, and\njustifies its intrinsic \"model-selection\" capability. Furthermore, we draw an\nanalogy between optimizing this functional and the well known Potts energy\nminimization. This analogy allows us to suggest several new optimization\nalgorithms, which exploit the intrinsic \"model-selection\" capability of the\nfunctional to automatically recover the underlying number of clusters. We\ncompare our algorithms to existing methods on both synthetic and real data. In\naddition we suggest two new applications that are made possible by our\nalgorithms: unsupervised face identification and interactive multi-object\nsegmentation by rough boundary delineation.", 
    "link": "http://arxiv.org/pdf/1112.2903v1", 
    "arxiv-id": "1112.2903v1"
},{
    "category": "cs.CV", 
    "author": "Tsvi Achler", 
    "title": "Supervised Generative Reconstruction: An Efficient Way To Flexibly Store   and Recognize Patterns", 
    "publish": "2011-12-13T18:10:11Z", 
    "summary": "Matching animal-like flexibility in recognition and the ability to quickly\nincorporate new information remains difficult. Limits are yet to be adequately\naddressed in neural models and recognition algorithms. This work proposes a\nconfiguration for recognition that maintains the same function of conventional\nalgorithms but avoids combinatorial problems. Feedforward recognition\nalgorithms such as classical artificial neural networks and machine learning\nalgorithms are known to be subject to catastrophic interference and forgetting.\nModifying or learning new information (associations between patterns and\nlabels) causes loss of previously learned information. I demonstrate using\nmathematical analysis how supervised generative models, with feedforward and\nfeedback connections, can emulate feedforward algorithms yet avoid catastrophic\ninterference and forgetting. Learned information in generative models is stored\nin a more intuitive form that represents the fixed points or solutions of the\nnetwork and moreover displays similar difficulties as cognitive phenomena.\nBrain-like capabilities and limits associated with generative models suggest\nthe brain may perform recognition and store information using a similar\napproach. Because of the central role of recognition, progress understanding\nthe underlying principles may reveal significant insight on how to better study\nand integrate with the brain.", 
    "link": "http://arxiv.org/pdf/1112.2988v2", 
    "arxiv-id": "1112.2988v2"
},{
    "category": "cs.CV", 
    "author": "Motoaki Kawanabe", 
    "title": "Insights from Classifying Visual Concepts with Multiple Kernel Learning", 
    "publish": "2011-12-16T01:06:47Z", 
    "summary": "Combining information from various image features has become a standard\ntechnique in concept recognition tasks. However, the optimal way of fusing the\nresulting kernel functions is usually unknown in practical applications.\nMultiple kernel learning (MKL) techniques allow to determine an optimal linear\ncombination of such similarity matrices. Classical approaches to MKL promote\nsparse mixtures. Unfortunately, so-called 1-norm MKL variants are often\nobserved to be outperformed by an unweighted sum kernel. The contribution of\nthis paper is twofold: We apply a recently developed non-sparse MKL variant to\nstate-of-the-art concept recognition tasks within computer vision. We provide\ninsights on benefits and limits of non-sparse MKL and compare it against its\ndirect competitors, the sum kernel SVM and the sparse MKL. We report empirical\nresults for the PASCAL VOC 2009 Classification and ImageCLEF2010 Photo\nAnnotation challenge data sets. About to be submitted to PLoS ONE.", 
    "link": "http://arxiv.org/pdf/1112.3697v1", 
    "arxiv-id": "1112.3697v1"
},{
    "category": "cs.CV", 
    "author": "Bart\u0142omiej P\u0142aczek", 
    "title": "A real time vehicles detection algorithm for vision based sensors", 
    "publish": "2011-12-17T14:50:50Z", 
    "summary": "A vehicle detection plays an important role in the traffic control at\nsignalised intersections. This paper introduces a vision-based algorithm for\nvehicles presence recognition in detection zones. The algorithm uses linguistic\nvariables to evaluate local attributes of an input image. The image attributes\nare categorised as vehicle, background or unknown features. Experimental\nresults on complex traffic scenes show that the proposed algorithm is effective\nfor a real-time vehicles detection.", 
    "link": "http://arxiv.org/pdf/1112.4060v1", 
    "arxiv-id": "1112.4060v1"
},{
    "category": "cs.CV", 
    "author": "Bart\u0142omiej P\u0142aczek", 
    "title": "Vehicles Recognition Using Fuzzy Descriptors of Image Segments", 
    "publish": "2011-12-17T15:21:22Z", 
    "summary": "In this paper a vision-based vehicles recognition method is presented.\nProposed method uses fuzzy description of image segments for automatic\nrecognition of vehicles recorded in image data. The description takes into\naccount selected geometrical properties and shape coefficients determined for\nsegments of reference image (vehicle model). The proposed method was\nimplemented using reasoning system with fuzzy rules. A vehicles recognition\nalgorithm was developed based on the fuzzy rules describing shape and\narrangement of the image segments that correspond to visible parts of a\nvehicle. An extension of the algorithm with set of fuzzy rules defined for\ndifferent reference images (and various vehicle shapes) enables vehicles\nclassification in traffic scenes. The devised method is suitable for\napplication in video sensors for road traffic control and surveillance systems.", 
    "link": "http://arxiv.org/pdf/1112.4064v1", 
    "arxiv-id": "1112.4064v1"
},{
    "category": "cs.CV", 
    "author": "Driss Aboutajdine", 
    "title": "A Reduced Reference Image Quality Measure Using Bessel K Forms Model for   Tetrolet Coefficients", 
    "publish": "2011-12-18T08:11:59Z", 
    "summary": "In this paper, we introduce a Reduced Reference Image Quality Assessment\n(RRIQA) measure based on the natural image statistic approach. A new adaptive\ntransform called \"Tetrolet\" is applied to both reference and distorted images.\nTo model the marginal distribution of tetrolet coefficients Bessel K Forms\n(BKF) density is proposed. Estimating the parameters of this distribution\nallows to summarize the reference image with a small amount of side\ninformation. Five distortion measures based on the BKF parameters of the\noriginal and processed image are used to predict quality scores. A comparison\nbetween these measures is presented showing a good consistency with human\njudgment.", 
    "link": "http://arxiv.org/pdf/1112.4135v1", 
    "arxiv-id": "1112.4135v1"
},{
    "category": "cs.CV", 
    "author": "Babak Hossein Khalaj", 
    "title": "A Geometric Approach For Fully Automatic Chromosome Segmentation", 
    "publish": "2011-12-18T15:46:18Z", 
    "summary": "A fundamental task in human chromosome analysis is chromosome segmentation.\nSegmentation plays an important role in chromosome karyotyping. The first step\nin segmentation is to remove intrusive objects such as stain debris and other\nnoises. The next step is detection of touching and overlapping chromosomes, and\nthe final step is separation of such chromosomes. Common methods for separation\nbetween touching chromosomes are interactive and require human intervention for\ncorrect separation between touching and overlapping chromosomes. In this paper,\na geometric-based method is used for automatic detection of touching and\noverlapping chromosomes and separating them. The proposed scheme performs\nsegmentation in two phases. In the first phase, chromosome clusters are\ndetected using three geometric criteria, and in the second phase, chromosome\nclusters are separated using a cut-line. Most of earlier methods did not work\nproperly in case of chromosome clusters that contained more than two\nchromosomes. Our method, on the other hand, is quite efficient in separation of\nsuch chromosome clusters. At each step, one separation will be performed and\nthis algorithm is repeated until all individual chromosomes are separated.\nAnother important point about the proposed method is that it uses the geometric\nfeatures of chromosomes which are independent of the type of images and it can\neasily be applied to any type of images such as binary images and does not\nrequire multispectral images as well. We have applied our method to a database\ncontaining 62 touching and partially overlapping chromosomes and a success rate\nof 91.9% is achieved.", 
    "link": "http://arxiv.org/pdf/1112.4164v5", 
    "arxiv-id": "1112.4164v5"
},{
    "category": "cs.CV", 
    "author": "Tomas Werner", 
    "title": "Zero-Temperature Limit of a Convergent Algorithm to Minimize the Bethe   Free Energy", 
    "publish": "2011-12-22T13:10:05Z", 
    "summary": "After the discovery that fixed points of loopy belief propagation coincide\nwith stationary points of the Bethe free energy, several researchers proposed\nprovably convergent algorithms to directly minimize the Bethe free energy.\nThese algorithms were formulated only for non-zero temperature (thus finding\nfixed points of the sum-product algorithm) and their possible extension to zero\ntemperature is not obvious. We present the zero-temperature limit of the\ndouble-loop algorithm by Heskes, which converges a max-product fixed point. The\ninner loop of this algorithm is max-sum diffusion. Under certain conditions,\nthe algorithm combines the complementary advantages of the max-product belief\npropagation and max-sum diffusion (LP relaxation): it yields good approximation\nof both ground states and max-marginals.", 
    "link": "http://arxiv.org/pdf/1112.5298v1", 
    "arxiv-id": "1112.5298v1"
},{
    "category": "cs.CV", 
    "author": "Pascal Frossard", 
    "title": "Discretization of Parametrizable Signal Manifolds", 
    "publish": "2011-12-23T19:08:10Z", 
    "summary": "Transformation-invariant analysis of signals often requires the computation\nof the distance from a test pattern to a transformation manifold. In\nparticular, the estimation of the distances between a transformed query signal\nand several transformation manifolds representing different classes provides\nessential information for the classification of the signal. In many\napplications the computation of the exact distance to the manifold is costly,\nwhereas an efficient practical solution is the approximation of the manifold\ndistance with the aid of a manifold grid. In this paper, we consider a setting\nwith transformation manifolds of known parameterization. We first present an\nalgorithm for the selection of samples from a single manifold that permits to\nminimize the average error in the manifold distance estimation. Then we propose\na method for the joint discretization of multiple manifolds that represent\ndifferent signal classes, where we optimize the transformation-invariant\nclassification accuracy yielded by the discrete manifold representation.\nExperimental results show that sampling each manifold individually by\nminimizing the manifold distance estimation error outperforms baseline sampling\nsolutions with respect to registration and classification accuracy. Performing\nan additional joint optimization on all samples improves the classification\nperformance further. Moreover, given a fixed total number of samples to be\nselected from all manifolds, an asymmetric distribution of samples to different\nmanifolds depending on their geometric structures may also increase the\nclassification accuracy in comparison with the equal distribution of samples.", 
    "link": "http://arxiv.org/pdf/1112.5638v1", 
    "arxiv-id": "1112.5638v1"
},{
    "category": "cs.CV", 
    "author": "Pascal Frossard", 
    "title": "Learning Smooth Pattern Transformation Manifolds", 
    "publish": "2011-12-23T19:13:31Z", 
    "summary": "Manifold models provide low-dimensional representations that are useful for\nprocessing and analyzing data in a transformation-invariant way. In this paper,\nwe study the problem of learning smooth pattern transformation manifolds from\nimage sets that represent observations of geometrically transformed signals. In\norder to construct a manifold, we build a representative pattern whose\ntransformations accurately fit various input images. We examine two objectives\nof the manifold building problem, namely, approximation and classification. For\nthe approximation problem, we propose a greedy method that constructs a\nrepresentative pattern by selecting analytic atoms from a continuous dictionary\nmanifold. We present a DC (Difference-of-Convex) optimization scheme that is\napplicable to a wide range of transformation and dictionary models, and\ndemonstrate its application to transformation manifolds generated by rotation,\ntranslation and anisotropic scaling of a reference pattern. Then, we generalize\nthis approach to a setting with multiple transformation manifolds, where each\nmanifold represents a different class of signals. We present an iterative\nmultiple manifold building algorithm such that the classification accuracy is\npromoted in the learning of the representative patterns. Experimental results\nsuggest that the proposed methods yield high accuracy in the approximation and\nclassification of data compared to some reference methods, while the invariance\nto geometric transformations is achieved due to the transformation manifold\nmodel.", 
    "link": "http://arxiv.org/pdf/1112.5640v5", 
    "arxiv-id": "1112.5640v5"
},{
    "category": "cs.CV", 
    "author": "Lawrence Carin", 
    "title": "Online Adaptive Statistical Compressed Sensing of Gaussian Mixture   Models", 
    "publish": "2011-12-26T21:42:22Z", 
    "summary": "A framework of online adaptive statistical compressed sensing is introduced\nfor signals following a mixture model. The scheme first uses non-adaptive\nmeasurements, from which an online decoding scheme estimates the model\nselection. As soon as a candidate model has been selected, an optimal sensing\nscheme for the selected model continues to apply. The final signal\nreconstruction is calculated from the ensemble of both the non-adaptive and the\nadaptive measurements. For signals generated from a Gaussian mixture model, the\nonline adaptive sensing algorithm is given and its performance is analyzed. On\nboth synthetic and real image data, the proposed adaptive scheme considerably\nreduces the average reconstruction error with respect to standard statistical\ncompressed sensing that uses fully random measurements, at a marginally\nincreased computational complexity.", 
    "link": "http://arxiv.org/pdf/1112.5895v1", 
    "arxiv-id": "1112.5895v1"
},{
    "category": "cs.CV", 
    "author": "Emad Fatemizadeh", 
    "title": "Multispectral Palmprint Recognition Using a Hybrid Feature", 
    "publish": "2011-12-27T18:19:04Z", 
    "summary": "Personal identification problem has been a major field of research in recent\nyears. Biometrics-based technologies that exploit fingerprints, iris, face,\nvoice and palmprints, have been in the center of attention to solve this\nproblem. Palmprints can be used instead of fingerprints that have been of the\nearliest of these biometrics technologies. A palm is covered with the same skin\nas the fingertips but has a larger surface, giving us more information than the\nfingertips. The major features of the palm are palm-lines, including principal\nlines, wrinkles and ridges. Using these lines is one of the most popular\napproaches towards solving the palmprint recognition problem. Another robust\nfeature is the wavelet energy of palms. In this paper we used a hybrid feature\nwhich combines both of these features. %Moreover, multispectral analysis is\napplied to improve the performance of the system. At the end, minimum distance\nclassifier is used to match test images with one of the training samples. The\nproposed algorithm has been tested on a well-known multispectral palmprint\ndataset and achieved an average accuracy of 98.8\\%.", 
    "link": "http://arxiv.org/pdf/1112.5997v3", 
    "arxiv-id": "1112.5997v3"
},{
    "category": "cs.CV", 
    "author": "I. V. Muralikrishna", 
    "title": "Automated PolyU Palmprint sample Registration and Coarse Classification", 
    "publish": "2011-12-29T10:35:01Z", 
    "summary": "Biometric based authentication for secured access to resources has gained\nimportance, due to their reliable, invariant and discriminating features.\nPalmprint is one such biometric entity. Prior to classification and\nidentification registering a sample palmprint is an important activity. In this\npaper we propose a computationally effective method for automated registration\nof samples from PlolyU palmprint database. In our approach we preprocess the\nsample and trace the border to find the nearest point from center of sample.\nAngle between vector representing the nearest point and vector passing through\nthe center is used for automated palm sample registration. The angle of\ninclination between start and end point of heart line and life line is used for\nbasic classification of palmprint samples in left class and right class.", 
    "link": "http://arxiv.org/pdf/1112.6269v1", 
    "arxiv-id": "1112.6269v1"
},{
    "category": "cs.CV", 
    "author": "Sarah Drewes", 
    "title": "Learning joint intensity-depth sparse representations", 
    "publish": "2012-01-03T03:47:09Z", 
    "summary": "This paper presents a method for learning overcomplete dictionaries composed\nof two modalities that describe a 3D scene: image intensity and scene depth. We\npropose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse\nfeatures in two modalities using conic programming and integrate it into a\ntwo-step dictionary learning algorithm. JBP differs from related convex\nalgorithms because it finds joint sparsity models with different atoms and\ndifferent coefficient values for intensity and depth. This is crucial for\nrecovering generative models where the same sparse underlying causes (3D\nfeatures) give rise to different signals (intensity and depth). We give a\ntheoretical bound for the sparse coefficient recovery error obtained by JBP,\nand show experimentally that JBP is far superior to the state of the art Group\nLasso algorithm. When applied to the Middlebury depth-intensity database, our\nlearning algorithm converges to a set of related features, such as pairs of\ndepth and intensity edges or image textures and depth slants. Finally, we show\nthat the learned dictionary and JBP achieve the state of the art depth\ninpainting performance on time-of-flight 3D data.", 
    "link": "http://arxiv.org/pdf/1201.0566v2", 
    "arxiv-id": "1201.0566v2"
},{
    "category": "cs.CV", 
    "author": "Mahmood Amintoosi", 
    "title": "Picture Collage with Genetic Algorithm and Stereo vision", 
    "publish": "2011-11-29T06:24:33Z", 
    "summary": "In this paper, a salient region extraction method for creating picture\ncollage based on stereo vision is proposed. Picture collage is a kind of visual\nimage summary to arrange all input images on a given canvas, allowing overlay,\nto maximize visible visual information. The salient regions of each image are\nfirstly extracted and represented as a depth map. The output picture collage\nshows as many visible salient regions (without being overlaid by others) from\nall images as possible. A very efficient Genetic algorithm is used here for the\noptimization. The experimental results showed the superior performance of the\nproposed method.", 
    "link": "http://arxiv.org/pdf/1201.1417v1", 
    "arxiv-id": "1201.1417v1"
},{
    "category": "cs.CV", 
    "author": "Shanglian Bao", 
    "title": "A United Image Force for Deformable Models and Direct Transforming   Geometric Active Contorus to Snakes by Level Sets", 
    "publish": "2012-01-07T15:58:18Z", 
    "summary": "A uniform distribution of the image force field around the object fasts the\nconvergence speed of the segmentation process. However, to achieve this aim, it\ncauses the force constructed from the heat diffusion model unable to indicate\nthe object boundaries accurately. The image force based on electrostatic field\nmodel can perform an exact shape recovery. First, this study introduces a\nfusion scheme of these two image forces, which is capable of extracting the\nobject boundary with high precision and fast speed. Until now, there is no\nsatisfied analysis about the relationship between Snakes and Geometric Active\nContours (GAC). The second contribution of this study addresses that the GAC\nmodel can be deduced directly from Snakes model. It proves that each term in\nGAC and Snakes is correspondent and has similar function. However, the two\nmodels are expressed using different mathematics. Further, since losing the\nability of rotating the contour, adoption of level sets can limits the usage of\nGAC in some circumstances.", 
    "link": "http://arxiv.org/pdf/1201.1571v3", 
    "arxiv-id": "1201.1571v3"
},{
    "category": "cs.CV", 
    "author": "Dong-Yoon Kim", 
    "title": "Adaptive Noise Reduction Scheme for Salt and Pepper", 
    "publish": "2012-01-10T13:41:56Z", 
    "summary": "In this paper, a new adaptive noise reduction scheme for images corrupted by\nimpulse noise is presented. The proposed scheme efficiently identifies and\nreduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify\npixels which are most likely corrupted by salt and pepper noise that are\ncandidates for further median based noise reduction processing. Directional\nfiltering is then applied after noise reduction to achieve a good tradeoff\nbetween detail preservation and noise removal. The proposed scheme can remove\nsalt and pepper noise with noise density as high as 90% and produce better\nresult in terms of qualitative and quantitative measures of images.", 
    "link": "http://arxiv.org/pdf/1201.2050v1", 
    "arxiv-id": "1201.2050v1"
},{
    "category": "cs.CV", 
    "author": "Babak Seyfe", 
    "title": "Nonparametric Sparse Representation", 
    "publish": "2012-01-13T14:05:59Z", 
    "summary": "This paper suggests a nonparametric scheme to find the sparse solution of the\nunderdetermined system of linear equations in the presence of unknown impulsive\nor non-Gaussian noise. This approach is robust against any variations of the\nnoise model and its parameters. It is based on minimization of rank pseudo norm\nof the residual signal and l_1-norm of the signal of interest, simultaneously.\nWe use the steepest descent method to find the sparse solution via an iterative\nalgorithm. Simulation results show that our proposed method outperforms the\nexistence methods like OMP, BP, Lasso, and BCS whenever the observation vector\nis contaminated with measurement or environmental non-Gaussian noise with\nunknown parameters. Furthermore, for low SNR condition, the proposed method has\nbetter performance in the presence of Gaussian noise.", 
    "link": "http://arxiv.org/pdf/1201.2843v1", 
    "arxiv-id": "1201.2843v1"
},{
    "category": "cs.CV", 
    "author": "Zhao Qiyang", 
    "title": "NegCut: Automatic Image Segmentation based on MRF-MAP", 
    "publish": "2012-01-13T18:18:03Z", 
    "summary": "Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a\nprevailing method in recent interactive image segmentation tools. Although\nmathematically explicit in its computational targets, and impressive for the\nsegmentation quality, MRF-MAP is hard to accomplish without the interactive\ninformation from users. So it is rarely adopted in the automatic style up to\ntoday. In this paper, we present an automatic image segmentation algorithm,\nNegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is\nNP-hard when the probabilistic models are unknown, and then present an\napproximation function in the form of minimum cuts on graphs with negative\nweights. Finally, the binary segmentation is taken from the largest eigenvector\nof the target matrix, with a tuned version of the Lanczos eigensolver. It is\nshown competitive at the segmentation quality in our experiments.", 
    "link": "http://arxiv.org/pdf/1201.2905v2", 
    "arxiv-id": "1201.2905v2"
},{
    "category": "cs.CV", 
    "author": "K. P. Soman", 
    "title": "G-Lets: Signal Processing Using Transformation Groups", 
    "publish": "2012-01-14T07:18:06Z", 
    "summary": "We present an algorithm using transformation groups and their irreducible\nrepresentations to generate an orthogonal basis for a signal in the vector\nspace of the signal. It is shown that multiresolution analysis can be done with\namplitudes using a transformation group. G-lets is thus not a single transform,\nbut a group of linear transformations related by group theory. The algorithm\nalso specifies that a multiresolution and multiscale analysis for each\nresolution is possible in terms of frequencies. Separation of low and high\nfrequency components of each amplitude resolution is facilitated by G-lets.\nUsing conjugacy classes of the transformation group, more than one set of basis\nmay be generated, giving a different perspective of the signal through each\nbasis. Applications for this algorithm include edge detection, feature\nextraction, denoising, face recognition, compression, and more. We analyze this\nalgorithm using dihedral groups as an example. We demonstrate the results with\nan ECG signal and the standard `Lena' image.", 
    "link": "http://arxiv.org/pdf/1201.2995v1", 
    "arxiv-id": "1201.2995v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Automatic system for counting cells with elliptical shape", 
    "publish": "2012-01-15T17:42:07Z", 
    "summary": "This paper presents a new method for automatic quantification of ellipse-like\ncells in images, an important and challenging problem that has been studied by\nthe computer vision community. The proposed method can be described by two main\nsteps. Initially, image segmentation based on the k-means algorithm is\nperformed to separate different types of cells from the background. Then, a\nrobust and efficient strategy is performed on the blob contour for touching\ncells splitting. Due to the contour processing, the method achieves excellent\nresults of detection compared to manual detection performed by specialists.", 
    "link": "http://arxiv.org/pdf/1201.3109v1", 
    "arxiv-id": "1201.3109v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Fractal and Multi-Scale Fractal Dimension analysis: a comparative study   of Bouligand-Minkowski method", 
    "publish": "2012-01-16T03:18:22Z", 
    "summary": "Shape is one of the most important visual attributes to characterize objects,\nplaying a important role in pattern recognition. There are various approaches\nto extract relevant information of a shape. An approach widely used in shape\nanalysis is the complexity, and Fractal Dimension and Multi-Scale Fractal\nDimension are both well-known methodologies to estimate it. This papers\npresents a comparative study between Fractal Dimension and Multi-Scale Fractal\nDimension in a shape analysis context. Through experimental comparison using a\nshape database previously classified, both methods are compared. Different\nparameters configuration of each method are considered and a discussion about\nthe results of each method is also presented.", 
    "link": "http://arxiv.org/pdf/1201.3153v1", 
    "arxiv-id": "1201.3153v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "Variations of images to increase their visibility", 
    "publish": "2012-01-16T12:31:27Z", 
    "summary": "The calculus of variations applied to the image processing requires some\nnumerical models able to perform the variations of images and the extremization\nof appropriate actions. To produce the variations of images, there are several\npossibilities based on the brightness maps. Before a numerical model, I propose\nan experimental approach, based on a tool of Gimp, GNU Image Manipulation\nProgram, in order to visualize how the image variations can be. After the\ndiscussion of this tool, which is able to strongly increase the visibility of\nimages, the variations and a possible functional for the visibility are\nproposed in the framework of a numerical model. The visibility functional is\nanalogous to the fringe visibility of the optical interference.", 
    "link": "http://arxiv.org/pdf/1201.3233v2", 
    "arxiv-id": "1201.3233v2"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Spatiotemporal Gabor filters: a new method for dynamic texture   recognition", 
    "publish": "2012-01-17T20:26:04Z", 
    "summary": "This paper presents a new method for dynamic texture recognition based on\nspatiotemporal Gabor filters. Dynamic textures have emerged as a new field of\ninvestigation that extends the concept of self-similarity of texture image to\nthe spatiotemporal domain. To model a dynamic texture, we convolve the sequence\nof images to a bank of spatiotemporal Gabor filters. For each response, a\nfeature vector is built by calculating the energy statistic. As far as the\nauthors know, this paper is the first to report an effective method for dynamic\ntexture recognition using spatiotemporal Gabor filters. We evaluate the\nproposed method on two challenging databases and the experimental results\nindicate that the proposed method is a robust approach for dynamic texture\nrecognition.", 
    "link": "http://arxiv.org/pdf/1201.3612v1", 
    "arxiv-id": "1201.3612v1"
},{
    "category": "cs.CV", 
    "author": "Adeel Akram", 
    "title": "A Multimodal Biometric System Using Linear Discriminant Analysis For   Improved Performance", 
    "publish": "2012-01-18T08:20:00Z", 
    "summary": "Essentially a biometric system is a pattern recognition system which\nrecognizes a user by determining the authenticity of a specific anatomical or\nbehavioral characteristic possessed by the user. With the ever increasing\nintegration of computers and Internet into daily life style, it has become\nnecessary to protect sensitive and personal data. This paper proposes a\nmultimodal biometric system which incorporates more than one biometric trait to\nattain higher security and to handle failure to enroll situations for some\nusers. This paper is aimed at investigating a multimodal biometric identity\nsystem using Linear Discriminant Analysis as backbone to both facial and speech\nrecognition and implementing such system in real-time using SignalWAVE.", 
    "link": "http://arxiv.org/pdf/1201.3720v1", 
    "arxiv-id": "1201.3720v1"
},{
    "category": "cs.CV", 
    "author": "Sonali. Nimbhorkar", 
    "title": "Image Labeling and Segmentation using Hierarchical Conditional Random   Field Model", 
    "publish": "2012-01-16T07:33:56Z", 
    "summary": "The use of hierarchical Conditional Random Field model deal with the problem\nof labeling images . At the time of labeling a new image, selection of the\nnearest cluster and using the related CRF model to label this image. When one\ngive input image, one first use the CRF model to get initial pixel labels then\nfinding the cluster with most similar images. Then at last relabeling the input\nimage by the CRF model associated with this cluster. This paper presents a\napproach to label and segment specific image having correct information.", 
    "link": "http://arxiv.org/pdf/1201.3803v1", 
    "arxiv-id": "1201.3803v1"
},{
    "category": "cs.CV", 
    "author": "Francisco B. Rodr\u00edguez", 
    "title": "A PCA-Based Super-Resolution Algorithm for Short Image Sequences", 
    "publish": "2012-01-18T15:19:03Z", 
    "summary": "In this paper, we present a novel, learning-based, two-step super-resolution\n(SR) algorithm well suited to solve the specially demanding problem of\nobtaining SR estimates from short image sequences. The first step, devoted to\nincrease the sampling rate of the incoming images, is performed by fitting\nlinear combinations of functions generated from principal components (PC) to\nreproduce locally the sparse projected image data, and using these models to\nestimate image values at nodes of the high-resolution grid. PCs were obtained\nfrom local image patches sampled at sub-pixel level, which were generated in\nturn from a database of high-resolution images by application of a physically\nrealistic observation model. Continuity between local image models is enforced\nby minimizing an adequate functional in the space of model coefficients. The\nsecond step, dealing with restoration, is performed by a linear filter with\ncoefficients learned to restore residual interpolation artifacts in addition to\nlow-resolution blurring, providing an effective coupling between both steps of\nthe method. Results on a demanding five-image scanned sequence of graphics and\ntext are presented, showing the excellent performance of the proposed method\ncompared to several state-of-the-art two-step and Bayesian Maximum a Posteriori\nSR algorithms.", 
    "link": "http://arxiv.org/pdf/1201.3821v1", 
    "arxiv-id": "1201.3821v1"
},{
    "category": "cs.CV", 
    "author": "Jitendra Kumar Niranjan", 
    "title": "A Novel Approach to Fast Image Filtering Algorithm of Infrared Images   based on Intro Sort Algorithm", 
    "publish": "2012-01-19T04:57:36Z", 
    "summary": "In this study we investigate the fast image filtering algorithm based on\nIntro sort algorithm and fast noise reduction of infrared images. Main feature\nof the proposed approach is that no prior knowledge of noise required. It is\ndeveloped based on Stefan- Boltzmann law and the Fourier law. We also\ninvestigate the fast noise reduction approach that has advantage of less\ncomputation load. In addition, it can retain edges, details, text information\neven if the size of the window increases. Intro sort algorithm begins with\nQuick sort and switches to heap sort when the recursion depth exceeds a level\nbased on the number of elements being sorted. This approach has the advantage\nof fast noise reduction by reducing the comparison time. It also significantly\nspeed up the noise reduction process and can apply to real-time image\nprocessing. This approach will extend the Infrared images applications for\nmedicine and video conferencing.", 
    "link": "http://arxiv.org/pdf/1201.3972v1", 
    "arxiv-id": "1201.3972v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Image decomposition with anisotropic diffusion applied to leaf-texture   analysis", 
    "publish": "2012-01-19T18:39:41Z", 
    "summary": "Texture analysis is an important field of investigation that has received a\ngreat deal of interest from computer vision community. In this paper, we\npropose a novel approach for texture modeling based on partial differential\nequation (PDE). Each image $f$ is decomposed into a family of derived\nsub-images. $f$ is split into the $u$ component, obtained with anisotropic\ndiffusion, and the $v$ component which is calculated by the difference between\nthe original image and the $u$ component. After enhancing the texture attribute\n$v$ of the image, Gabor features are computed as descriptors. We validate the\nproposed approach on two texture datasets with high variability. We also\nevaluate our approach on an important real-world application: leaf-texture\nanalysis. Experimental results indicate that our approach can be used to\nproduce higher classification rates and can be successfully employed for\ndifferent texture applications.", 
    "link": "http://arxiv.org/pdf/1201.4139v1", 
    "arxiv-id": "1201.4139v1"
},{
    "category": "cs.CV", 
    "author": "Richard G Baraniuk", 
    "title": "Compressive Acquisition of Dynamic Scenes", 
    "publish": "2012-01-23T23:19:59Z", 
    "summary": "Compressive sensing (CS) is a new approach for the acquisition and recovery\nof sparse signals and images that enables sampling rates significantly below\nthe classical Nyquist rate. Despite significant progress in the theory and\nmethods of CS, little headway has been made in compressive video acquisition\nand recovery. Video CS is complicated by the ephemeral nature of dynamic\nevents, which makes direct extensions of standard CS imaging architectures and\nsignal models difficult. In this paper, we develop a new framework for video CS\nfor dynamic textured scenes that models the evolution of the scene as a linear\ndynamical system (LDS). This reduces the video recovery problem to first\nestimating the model parameters of the LDS from compressive measurements, and\nthen reconstructing the image frames. We exploit the low-dimensional dynamic\nparameters (the state sequence) and high-dimensional static parameters (the\nobservation matrix) of the LDS to devise a novel compressive measurement\nstrategy that measures only the dynamic part of the scene at each instant and\naccumulates measurements over time to estimate the static parameters. This\nenables us to lower the compressive measurement rate considerably. We validate\nour approach with a range of experiments involving both video recovery, sensing\nhyper-spectral data, and classification of dynamic scenes from compressive\ndata. Together, these applications demonstrate the effectiveness of the\napproach.", 
    "link": "http://arxiv.org/pdf/1201.4895v2", 
    "arxiv-id": "1201.4895v2"
},{
    "category": "cs.CV", 
    "author": "Kh. Manglem Singh", 
    "title": "A New Local Adaptive Thresholding Technique in Binarization", 
    "publish": "2012-01-25T10:17:30Z", 
    "summary": "Image binarization is the process of separation of pixel values into two\ngroups, white as background and black as foreground. Thresholding plays a major\nin binarization of images. Thresholding can be categorized into global\nthresholding and local thresholding. In images with uniform contrast\ndistribution of background and foreground like document images, global\nthresholding is more appropriate. In degraded document images, where\nconsiderable background noise or variation in contrast and illumination exists,\nthere exists many pixels that cannot be easily classified as foreground or\nbackground. In such cases, binarization with local thresholding is more\nappropriate. This paper describes a locally adaptive thresholding technique\nthat removes background by using local mean and mean deviation. Normally the\nlocal mean computational time depends on the window size. Our technique uses\nintegral sum image as a prior processing to calculate local mean. It does not\ninvolve calculations of standard deviations as in other local adaptive\ntechniques. This along with the fact that calculations of mean is independent\nof window size speed up the process as compared to other local thresholding\ntechniques.", 
    "link": "http://arxiv.org/pdf/1201.5227v1", 
    "arxiv-id": "1201.5227v1"
},{
    "category": "cs.CV", 
    "author": "Guillermo Sapiro", 
    "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture   Models", 
    "publish": "2012-01-25T22:25:27Z", 
    "summary": "A framework for adaptive and non-adaptive statistical compressive sensing is\ndeveloped, where a statistical model replaces the standard sparsity model of\nclassical compressive sensing. We propose within this framework optimal\ntask-specific sensing protocols specifically and jointly designed for\nclassification and reconstruction. A two-step adaptive sensing paradigm is\ndeveloped, where online sensing is applied to detect the signal class in the\nfirst step, followed by a reconstruction step adapted to the detected class and\nthe observed samples. The approach is based on information theory, here\ntailored for Gaussian mixture models (GMMs), where an information-theoretic\nobjective relationship between the sensed signals and a representation of the\nspecific task of interest is maximized. Experimental results using synthetic\nsignals, Landsat satellite attributes, and natural images of different sizes\nand with different noise levels show the improvements achieved using the\nproposed framework when compared to more standard sensing protocols. The\nunderlying formulation can be applied beyond GMMs, at the price of higher\nmathematical and computational complexity.", 
    "link": "http://arxiv.org/pdf/1201.5404v1", 
    "arxiv-id": "1201.5404v1"
},{
    "category": "cs.CV", 
    "author": "Hossein Khazaei Targhi", 
    "title": "Comparing Methods for segmentation of Microcalcification Clusters in   Digitized Mammograms", 
    "publish": "2012-01-28T09:51:23Z", 
    "summary": "The appearance of microcalcifications in mammograms is one of the early signs\nof breast cancer. So, early detection of microcalcification clusters (MCCs) in\nmammograms can be helpful for cancer diagnosis and better treatment of breast\ncancer. In this paper a computer method has been proposed to support\nradiologists in detection MCCs in digital mammography. First, in order to\nfacilitate and improve the detection step, mammogram images have been enhanced\nwith wavelet transformation and morphology operation. Then for segmentation of\nsuspicious MCCs, two methods have been investigated. The considered methods\nare: adaptive threshold and watershed segmentation. Finally, the detected MCCs\nareas in different algorithms will be compared to find out which segmentation\nmethod is more appropriate for extracting MCCs in mammograms.", 
    "link": "http://arxiv.org/pdf/1201.5938v1", 
    "arxiv-id": "1201.5938v1"
},{
    "category": "cs.CV", 
    "author": "Fernand Meyer", 
    "title": "The watershed concept and its use in segmentation : a brief history", 
    "publish": "2012-02-01T17:00:45Z", 
    "summary": "The watershed is one of the most used tools in image segmentation. We present\nhow its concept is born and developed over time. Its implementation as an\nalgorithm or a hardwired device evolved together with the technology which\nallowed it. We present also how it is used in practice, first together with\nmarkers, and later introduced in a multiscale framework, in order to produce\nnot a unique partition but a complete hierarchy.", 
    "link": "http://arxiv.org/pdf/1202.0216v1", 
    "arxiv-id": "1202.0216v1"
},{
    "category": "cs.CV", 
    "author": "Peter Abeles", 
    "title": "Resolving Implementation Ambiguity and Improving SURF", 
    "publish": "2012-02-02T17:10:56Z", 
    "summary": "Speeded Up Robust Features (SURF) has emerged as one of the more popular\nfeature descriptors and detectors in recent years. Performance and algorithmic\ndetails vary widely between implementations due to SURF's complexity and\nambiguities found in its description. To resolve these ambiguities, a set of\ngeneral techniques for feature stability is defined based on the smoothness\nrule. Additional improvements to SURF are proposed for speed and stability. To\nillustrate the importance of these implementation details, a performance study\nof popular SURF implementations is done. By utilizing all the suggested\nimprovements, it is possible to create a SURF implementation that is several\ntimes faster and more stable.", 
    "link": "http://arxiv.org/pdf/1202.0492v3", 
    "arxiv-id": "1202.0492v3"
},{
    "category": "cs.CV", 
    "author": "Ahmed Helmy", 
    "title": "Comparing Background Subtraction Algorithms and Method of Car Counting", 
    "publish": "2012-01-29T19:19:33Z", 
    "summary": "In this paper, we compare various image background subtraction algorithms\nwith the ground truth of cars counted. We have given a sample of thousand\nimages, which are the snap shots of current traffic as records at various\nintersections and highways. We have also counted an approximate number of cars\nthat are visible in these images. In order to ascertain the accuracy of\nalgorithms to be used for the processing of million images, we compare them on\nmany metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time.", 
    "link": "http://arxiv.org/pdf/1202.0549v1", 
    "arxiv-id": "1202.0549v1"
},{
    "category": "cs.CV", 
    "author": "Manuel Rodr\u00edguez", 
    "title": "Wavelet-based deconvolution of ultrasonic signals in nondestructive   evaluation", 
    "publish": "2012-02-03T05:43:46Z", 
    "summary": "In this paper, the inverse problem of reconstructing reflectivity function of\na medium is examined within a blind deconvolution framework. The ultrasound\npulse is estimated using higher-order statistics, and Wiener filter is used to\nobtain the ultrasonic reflectivity function through wavelet-based models. A new\napproach to the parameter estimation of the inverse filtering step is proposed\nin the nondestructive evaluation field, which is based on the theory of\nFourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be\nviewed as a solution to the open problem of adaptation of the ForWaRD framework\nto perform the convolution kernel estimation and deconvolution\ninterdependently. The results indicate stable solutions of the estimated pulse\nand an improvement in the radio-frequency (RF) signal taking into account its\nsignal-to-noise ratio (SNR) and axial resolution. Simulations and experiments\nshowed that the proposed approach can provide robust and optimal estimates of\nthe reflectivity function.", 
    "link": "http://arxiv.org/pdf/1202.0609v1", 
    "arxiv-id": "1202.0609v1"
},{
    "category": "cs.CV", 
    "author": "A. V. Dattatreya Rao", 
    "title": "Automatic Clustering with Single Optimal Solution", 
    "publish": "2012-02-08T03:26:01Z", 
    "summary": "Determining optimal number of clusters in a dataset is a challenging task.\nThough some methods are available, there is no algorithm that produces unique\nclustering solution. The paper proposes an Automatic Merging for Single Optimal\nSolution (AMSOS) which aims to generate unique and nearly optimal clusters for\nthe given datasets automatically. The AMSOS is iteratively merges the closest\nclusters automatically by validating with cluster validity measure to find\nsingle and nearly optimal clusters for the given data set. Experiments on both\nsynthetic and real data have proved that the proposed algorithm finds single\nand nearly optimal clustering structure in terms of number of clusters,\ncompactness and separation.", 
    "link": "http://arxiv.org/pdf/1202.1587v1", 
    "arxiv-id": "1202.1587v1"
},{
    "category": "cs.CV", 
    "author": "Alina Barbulescu", 
    "title": "Combined Haar-Hilbert and Log-Gabor Based Iris Encoders", 
    "publish": "2012-02-08T13:07:10Z", 
    "summary": "This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris\nrecognition performance leading to a less ambiguous biometric decision\nlandscape in which the overlap between the experimental intra- and interclass\nscore distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and\ncombined Haar-Hilbert and Log-Gabor encoders are tested here both for single\nand dual iris approach. The experimental results confirm that the best\nperformance is obtained for the dual iris approach when the iris code is\ngenerated using the combined Haar-Hilbert and Log-Gabor encoder, and when the\nmatching score fuses the information from both Haar-Hilbert and Log-Gabor\nchannels of the combined encoder.", 
    "link": "http://arxiv.org/pdf/1202.1685v1", 
    "arxiv-id": "1202.1685v1"
},{
    "category": "cs.CV", 
    "author": "Marcus Hutter", 
    "title": "3D Model Assisted Image Segmentation", 
    "publish": "2012-02-09T10:53:11Z", 
    "summary": "The problem of segmenting a given image into coherent regions is important in\nComputer Vision and many industrial applications require segmenting a known\nobject into its components. Examples include identifying individual parts of a\ncomponent for process control work in a manufacturing plant and identifying\nparts of a car from a photo for automatic damage detection. Unfortunately most\nof an object's parts of interest in such applications share the same pixel\ncharacteristics, having similar colour and texture. This makes segmenting the\nobject into its components a non-trivial task for conventional image\nsegmentation algorithms. In this paper, we propose a \"Model Assisted\nSegmentation\" method to tackle this problem. A 3D model of the object is\nregistered over the given image by optimising a novel gradient based loss\nfunction. This registration obtains the full 3D pose from an image of the\nobject. The image can have an arbitrary view of the object and is not limited\nto a particular set of views. The segmentation is subsequently performed using\na level-set based method, using the projected contours of the registered 3D\nmodel as initialisation curves. The method is fully automatic and requires no\nuser interaction. Also, the system does not require any prior training. We\npresent our results on photographs of a real car.", 
    "link": "http://arxiv.org/pdf/1202.1943v1", 
    "arxiv-id": "1202.1943v1"
},{
    "category": "cs.CV", 
    "author": "Manoj Kumar Pal", 
    "title": "Non-parametric convolution based image-segmentation of ill-posed objects   applying context window approach", 
    "publish": "2012-02-09T14:02:26Z", 
    "summary": "Context-dependence in human cognition process is a well-established fact.\nFollowing this, we introduced the image segmentation method that can use\ncontext to classify a pixel on the basis of its membership to a particular\nobject-class of the concerned image. In the broad methodological steps, each\npixel was defined by its context window (CW) surrounding it the size of which\nwas fixed heuristically. CW texture defined by the intensities of its pixels\nwas convoluted with weights optimized through a non-parametric function\nsupported by a backpropagation network. Result of convolution was used to\nclassify them. The training data points (i.e., pixels) were carefully chosen to\ninclude all variety of contexts of types, i) points within the object, ii)\npoints near the edge but inside the objects, iii) points at the border of the\nobjects, iv) points near the edge but outside the objects, v) points near or at\nthe edge of the image frame. Moreover the training data points were selected\nfrom all the images within image-dataset. CW texture information for 1000\npixels from face area and background area of images were captured, out of which\n700 CWs were used as training input data, and remaining 300 for testing. Our\nwork gives the first time foundation of quantitative enumeration of efficiency\nof image-segmentation which is extendable to segment out more than 2 objects\nwithin an image.", 
    "link": "http://arxiv.org/pdf/1202.1990v1", 
    "arxiv-id": "1202.1990v1"
},{
    "category": "cs.CV", 
    "author": "Gil Reese", 
    "title": "Using Covariance Matrices as Feature Descriptors for Vehicle Detection   from a Fixed Camera", 
    "publish": "2012-02-12T13:40:11Z", 
    "summary": "A method is developed to distinguish between cars and trucks present in a\nvideo feed of a highway. The method builds upon previously done work using\ncovariance matrices as an accurate descriptor for regions. Background\nsubtraction and other similar proven image processing techniques are used to\nidentify the regions where the vehicles are most likely to be, and a distance\nmetric comparing the vehicle inside the region to a fixed library of vehicles\nis used to determine the class of vehicle.", 
    "link": "http://arxiv.org/pdf/1202.2528v1", 
    "arxiv-id": "1202.2528v1"
},{
    "category": "cs.CV", 
    "author": "Gabriel Cristobal", 
    "title": "No-reference image quality assessment through the von Mises distribution", 
    "publish": "2012-02-14T12:50:35Z", 
    "summary": "An innovative way of calculating the von Mises distribution (VMD) of image\nentropy is introduced in this paper. The VMD's concentration parameter and some\nfitness parameter that will be later defined, have been analyzed in the\nexperimental part for determining their suitability as a image quality\nassessment measure in some particular distortions such as Gaussian blur or\nadditive Gaussian noise. To achieve such measure, the local R\\'{e}nyi entropy\nis calculated in four equally spaced orientations and used to determine the\nparameters of the von Mises distribution of the image entropy. Considering\ncontextual images, experimental results after applying this model show that the\nbest-in-focus noise-free images are associated with the highest values for the\nvon Mises distribution concentration parameter and the highest approximation of\nimage data to the von Mises distribution model. Our defined von Misses fitness\nparameter experimentally appears also as a suitable no-reference image quality\nassessment indicator for no-contextual images.", 
    "link": "http://arxiv.org/pdf/1202.3021v1", 
    "arxiv-id": "1202.3021v1"
},{
    "category": "cs.CV", 
    "author": "Cristian Sminchisescu", 
    "title": "Generalized Boundaries from Multiple Image Interpretations", 
    "publish": "2012-02-16T20:08:11Z", 
    "summary": "Boundary detection is essential for a variety of computer vision tasks such\nas segmentation and recognition. In this paper we propose a unified formulation\nand a novel algorithm that are applicable to the detection of different types\nof boundaries, such as intensity edges, occlusion boundaries or object category\nspecific boundaries. Our formulation leads to a simple method with\nstate-of-the-art performance and significantly lower computational cost than\nexisting methods. We evaluate our algorithm on different types of boundaries,\nfrom low-level boundaries extracted in natural images, to occlusion boundaries\nobtained using motion cues and RGB-D cameras, to boundaries from\nsoft-segmentation. We also propose a novel method for figure/ground\nsoft-segmentation that can be used in conjunction with our boundary detection\nmethod and improve its accuracy at almost no extra computational cost.", 
    "link": "http://arxiv.org/pdf/1202.3684v1", 
    "arxiv-id": "1202.3684v1"
},{
    "category": "cs.CV", 
    "author": "Renu Ramesh", 
    "title": "A feature extraction technique based on character geometry for character   recognition", 
    "publish": "2012-02-17T11:41:28Z", 
    "summary": "This paper describes a geometry based technique for feature extraction\napplicable to segmentation-based word recognition systems. The proposed system\nextracts the geometric features of the character contour. This features are\nbased on the basic line types that forms the character skeleton. The system\ngives a feature vector as its output. The feature vectors so generated from a\ntraining set, were then used to train a pattern recognition engine based on\nNeural Networks so that the system can be benchmarked.", 
    "link": "http://arxiv.org/pdf/1202.3884v1", 
    "arxiv-id": "1202.3884v1"
},{
    "category": "cs.CV", 
    "author": "Scott A. Hale", 
    "title": "Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin   Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition   of Whale Images on a Network)", 
    "publish": "2012-02-18T21:42:24Z", 
    "summary": "At least two software packages---DARWIN, Eckerd College, and FinScan, Texas\nA&M---exist to facilitate the identification of cetaceans---whales, dolphins,\nporpoises---based upon the naturally occurring features along the edges of\ntheir dorsal fins. Such identification is useful for biological studies of\npopulation, social interaction, migration, etc. The process whereby fin\noutlines are extracted in current fin-recognition software packages is manually\nintensive and represents a major user input bottleneck: it is both time\nconsuming and visually fatiguing. This research aims to develop automated\nmethods (employing unsupervised thresholding and morphological processing\ntechniques) to extract cetacean dorsal fin outlines from digital photographs\nthereby reducing manual user input. Ideally, automatic outline generation will\nimprove the overall user experience and improve the ability of the software to\ncorrectly identify cetaceans. Various transformations from color to gray space\nwere examined to determine which produced a grayscale image in which a suitable\nthreshold could be easily identified. To assist with unsupervised thresholding,\na new metric was developed to evaluate the jaggedness of figures (\"pixelarity\")\nin an image after thresholding. The metric indicates how cleanly a threshold\nsegments background and foreground elements and hence provides a good measure\nof the quality of a given threshold. This research results in successful\nextractions in roughly 93% of images, and significantly reduces user-input\ntime.", 
    "link": "http://arxiv.org/pdf/1202.4107v1", 
    "arxiv-id": "1202.4107v1"
},{
    "category": "cs.CV", 
    "author": "David Zhang", 
    "title": "Regularized Robust Coding for Face Recognition", 
    "publish": "2012-02-20T02:02:26Z", 
    "summary": "Recently the sparse representation based classification (SRC) has been\nproposed for robust face recognition (FR). In SRC, the testing image is coded\nas a sparse linear combination of the training samples, and the representation\nfidelity is measured by the l2-norm or l1-norm of the coding residual. Such a\nsparse coding model assumes that the coding residual follows Gaussian or\nLaplacian distribution, which may not be effective enough to describe the\ncoding residual in practical FR systems. Meanwhile, the sparsity constraint on\nthe coding coefficients makes SRC's computational cost very high. In this\npaper, we propose a new face coding model, namely regularized robust coding\n(RRC), which could robustly regress a given signal with regularized regression\ncoefficients. By assuming that the coding residual and the coding coefficient\nare respectively independent and identically distributed, the RRC seeks for a\nmaximum a posterior solution of the coding problem. An iteratively reweighted\nregularized robust coding (IR3C) algorithm is proposed to solve the RRC model\nefficiently. Extensive experiments on representative face databases demonstrate\nthat the RRC is much more effective and efficient than state-of-the-art sparse\nrepresentation based methods in dealing with face occlusion, corruption,\nlighting and expression changes, etc.", 
    "link": "http://arxiv.org/pdf/1202.4207v2", 
    "arxiv-id": "1202.4207v2"
},{
    "category": "cs.CV", 
    "author": "Qiyang Zhao", 
    "title": "A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP", 
    "publish": "2012-02-20T06:56:26Z", 
    "summary": "Color image segmentation is an important topic in the image processing field.\nMRF-MAP is often adopted in the unsupervised segmentation methods, but their\nperformance are far behind recent interactive segmentation tools supervised by\nuser inputs. Furthermore, the existing related unsupervised methods also suffer\nfrom the low efficiency, and high risk of being trapped in the local optima,\nbecause MRF-MAP is currently solved by iterative frameworks with inaccurate\ninitial color distribution models. To address these problems, the letter\ndesigns an efficient method to calculate the energy functions approximately in\nthe non-iteration style, and proposes a new binary segmentation algorithm based\non the slightly tuned Lanczos eigensolver. The experiments demonstrate that the\nnew algorithm achieves competitive performance compared with two state-of-art\nsegmentation methods.", 
    "link": "http://arxiv.org/pdf/1202.4237v1", 
    "arxiv-id": "1202.4237v1"
},{
    "category": "cs.CV", 
    "author": "J. L. Rossell\u00f3", 
    "title": "Stochastic-Based Pattern Recognition Analysis", 
    "publish": "2012-02-20T23:48:38Z", 
    "summary": "In this work we review the basic principles of stochastic logic and propose\nits application to probabilistic-based pattern-recognition analysis. The\nproposed technique is intrinsically a parallel comparison of input data to\nvarious pre-stored categories using Bayesian techniques. We design smart\npulse-based stochastic-logic blocks to provide an efficient pattern recognition\nanalysis. The proposed rchitecture is applied to a specific navigation problem.\nThe resulting system is orders of magnitude faster than processor-based\nsolutions.", 
    "link": "http://arxiv.org/pdf/1202.4495v1", 
    "arxiv-id": "1202.4495v1"
},{
    "category": "cs.CV", 
    "author": "Yann LeCun", 
    "title": "Fast approximations to structured sparse coding and applications to   object classification", 
    "publish": "2012-02-28T21:27:14Z", 
    "summary": "We describe a method for fast approximation of sparse coding. The input space\nis subdivided by a binary decision tree, and we simultaneously learn a\ndictionary and assignment of allowed dictionary elements for each leaf of the\ntree. We store a lookup table with the assignments and the pseudoinverses for\neach node, allowing for very fast inference. We give an algorithm for learning\nthe tree, the dictionary and the dictionary element assignment, and In the\nprocess of describing this algorithm, we discuss the more general problem of\nlearning the groups in group structured sparse modelling. We show that our\nmethod creates good sparse representations by using it in the object\nrecognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own\nfast version of the SIFT descriptor the whole system runs at 20 frames per\nsecond on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while\nsacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks.", 
    "link": "http://arxiv.org/pdf/1202.6384v1", 
    "arxiv-id": "1202.6384v1"
},{
    "category": "cs.CV", 
    "author": "Alejandro J. Le\u00f3n", 
    "title": "Filling-Based Techniques Applied to Object Projection Feature Estimation", 
    "publish": "2012-02-29T16:10:10Z", 
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting object projection feature estimation techniques are based on\nray-casting from the inner point. These techniques present three main\ndrawbacks: when the inner point is surrounded by edges, rays may not reach\nother relevant areas; as a consequence of that issue, the estimated features\nmay greatly vary depending on the position of the inner point relative to the\nobject projection; and finally, increasing the number of rays being casted and\nthe ray-casting iterations (which would make the results more accurate and\nstable) increases the processing time to the point the tracking cannot be\nperformed on the fly. In this paper, we analyze an intuitive filling-based\nobject projection feature estimation technique that solves the aforementioned\nproblems but is too sensitive to edge miscalculations. Then, we propose a less\ncomputing-intensive modification to that technique that would not be affected\nby the existing techniques issues and would be no more sensitive to edge\nmiscalculations than ray-casting-based techniques.", 
    "link": "http://arxiv.org/pdf/1202.6586v1", 
    "arxiv-id": "1202.6586v1"
},{
    "category": "cs.CV", 
    "author": "Luis Quesada", 
    "title": "Using Barriers to Reduce the Sensitivity to Edge Miscalculations of   Casting-Based Object Projection Feature Estimation", 
    "publish": "2012-03-01T02:32:28Z", 
    "summary": "3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting reliable object projection feature estimation techniques are based on\nray-casting or grid-filling from the inner point. These techniques assume the\nedge image to be accurate. However, in real case scenarios, edge\nmiscalculations may arise from low contrast between the target object and its\nsurroundings or motion blur caused by low frame rates or fast moving target\nobjects. In this paper, we propose a barrier extension to casting-based\ntechniques that mitigates the effect of edge miscalculations.", 
    "link": "http://arxiv.org/pdf/1203.0076v1", 
    "arxiv-id": "1203.0076v1"
},{
    "category": "cs.CV", 
    "author": "B. Thilakavathi", 
    "title": "Image Fusion and Re-Modified SPIHT for Fused Image", 
    "publish": "2012-02-29T17:57:12Z", 
    "summary": "This paper presents the Discrete Wavelet based fusion techniques for\ncombining perceptually important image features. SPIHT (Set Partitioning in\nHierarchical Trees) algorithm is an efficient method for lossy and lossless\ncoding of fused image. This paper presents some modifications on the SPIHT\nalgorithm. It is based on the idea of insignificant correlation of wavelet\ncoefficient among the medium and high frequency sub bands. In RE-MSPIHT\nalgorithm, wavelet coefficients are scaled prior to SPIHT coding based on the\nsub band importance, with the goal of minimizing the MSE.", 
    "link": "http://arxiv.org/pdf/1203.0265v1", 
    "arxiv-id": "1203.0265v1"
},{
    "category": "cs.CV", 
    "author": "Donghui Wang", 
    "title": "A Report on Multilinear PCA Plus Multilinear LDA to Deal with Tensorial   Data: Visual Classification as An Example", 
    "publish": "2012-03-04T15:00:16Z", 
    "summary": "In practical applications, we often have to deal with high order data, such\nas a grayscale image and a video sequence are intrinsically 2nd-order tensor\nand 3rd-order tensor, respectively. For doing clustering or classification of\nthese high order data, it is a conventional way to vectorize these data before\nhand, as PCA or FDA does, which often induce the curse of dimensionality\nproblem. For this reason, experts have developed many methods to deal with the\ntensorial data, such as multilinear PCA, multilinear LDA, and so on. In this\npaper, we still address the problem of high order data representation and\nrecognition, and propose to study the result of merging multilinear PCA and\nmultilinear LDA into one scenario, we name it \\textbf{GDA} for the abbreviation\nof Generalized Discriminant Analysis. To evaluate GDA, we perform a series of\nexperiments, and the experimental results demonstrate our GDA outperforms a\nselection of competing methods such (2D)$^2$PCA, (2D)$^2$LDA, and MDA.", 
    "link": "http://arxiv.org/pdf/1203.0744v1", 
    "arxiv-id": "1203.0744v1"
},{
    "category": "cs.CV", 
    "author": "Masato Inoue", 
    "title": "Posterior Mean Super-Resolution with a Compound Gaussian Markov Random   Field Prior", 
    "publish": "2012-03-04T22:12:54Z", 
    "summary": "This manuscript proposes a posterior mean (PM) super-resolution (SR) method\nwith a compound Gaussian Markov random field (MRF) prior. SR is a technique to\nestimate a spatially high-resolution image from observed multiple\nlow-resolution images. A compound Gaussian MRF model provides a preferable\nprior for natural images that preserves edges. PM is the optimal estimator for\nthe objective function of peak signal-to-noise ratio (PSNR). This estimator is\nnumerically determined by using variational Bayes (VB). We then solve the\nconjugate prior problem on VB and the exponential-order calculation cost\nproblem of a compound Gaussian MRF prior with simple Taylor approximations. In\nexperiments, the proposed method roughly overcomes existing methods.", 
    "link": "http://arxiv.org/pdf/1203.0781v3", 
    "arxiv-id": "1203.0781v3"
},{
    "category": "cs.CV", 
    "author": "Donghui Wang", 
    "title": "Online Discriminative Dictionary Learning for Image Classification Based   on Block-Coordinate Descent Method", 
    "publish": "2012-03-05T10:43:15Z", 
    "summary": "Previous researches have demonstrated that the framework of dictionary\nlearning with sparse coding, in which signals are decomposed as linear\ncombinations of a few atoms of a learned dictionary, is well adept to\nreconstruction issues. This framework has also been used for discrimination\ntasks such as image classification. To achieve better performances of\nclassification, experts develop several methods to learn a discriminative\ndictionary in a supervised manner. However, another issue is that when the data\nbecome extremely large in scale, these methods will be no longer effective as\nthey are all batch-oriented approaches. For this reason, we propose a novel\nonline algorithm for discriminative dictionary learning, dubbed \\textbf{ODDL}\nin this paper. First, we introduce a linear classifier into the conventional\ndictionary learning formulation and derive a discriminative dictionary learning\nproblem. Then, we exploit an online algorithm to solve the derived problem.\nUnlike the most existing approaches which update dictionary and classifier\nalternately via iteratively solving sub-problems, our approach directly\nexplores them jointly. Meanwhile, it can largely shorten the runtime for\ntraining and is also particularly suitable for large-scale classification\nissues. To evaluate the performance of the proposed ODDL approach in image\nrecognition, we conduct some experiments on three well-known benchmarks, and\nthe experimental results demonstrate ODDL is fairly promising for image\nclassification tasks.", 
    "link": "http://arxiv.org/pdf/1203.0856v1", 
    "arxiv-id": "1203.0856v1"
},{
    "category": "cs.CV", 
    "author": "Guillermo Gallego", 
    "title": "Autocalibration with the Minimum Number of Cameras with Known Pixel   Shape", 
    "publish": "2012-03-05T13:18:44Z", 
    "summary": "In 3D reconstruction, the recovery of the calibration parameters of the\ncameras is paramount since it provides metric information about the observed\nscene, e.g., measures of angles and ratios of distances. Autocalibration\nenables the estimation of the camera parameters without using a calibration\ndevice, but by enforcing simple constraints on the camera parameters. In the\nabsence of information about the internal camera parameters such as the focal\nlength and the principal point, the knowledge of the camera pixel shape is\nusually the only available constraint. Given a projective reconstruction of a\nrigid scene, we address the problem of the autocalibration of a minimal set of\ncameras with known pixel shape and otherwise arbitrarily varying intrinsic and\nextrinsic parameters. We propose an algorithm that only requires 5 cameras (the\ntheoretical minimum), thus halving the number of cameras required by previous\nalgorithms based on the same constraint. To this purpose, we introduce as our\nbasic geometric tool the six-line conic variety (SLCV), consisting in the set\nof planes intersecting six given lines of 3D space in points of a conic. We\nshow that the set of solutions of the Euclidean upgrading problem for three\ncameras with known pixel shape can be parameterized in a computationally\nefficient way. This parameterization is then used to solve autocalibration from\nfive or more cameras, reducing the three-dimensional search space to a\ntwo-dimensional one. We provide experiments with real images showing the good\nperformance of the technique.", 
    "link": "http://arxiv.org/pdf/1203.0905v2", 
    "arxiv-id": "1203.0905v2"
},{
    "category": "cs.CV", 
    "author": "St\u00e9phane Mallat", 
    "title": "Invariant Scattering Convolution Networks", 
    "publish": "2012-03-05T17:12:42Z", 
    "summary": "A wavelet scattering network computes a translation invariant image\nrepresentation, which is stable to deformations and preserves high frequency\ninformation for classification. It cascades wavelet transform convolutions with\nnon-linear modulus and averaging operators. The first network layer outputs\nSIFT-type descriptors whereas the next layers provide complementary invariant\ninformation which improves classification. The mathematical analysis of wavelet\nscattering networks explains important properties of deep convolution networks\nfor classification.\n  A scattering representation of stationary processes incorporates higher order\nmoments and can thus discriminate textures having the same Fourier power\nspectrum. State of the art classification results are obtained for handwritten\ndigits and texture discrimination, using a Gaussian kernel SVM and a generative\nPCA classifier.", 
    "link": "http://arxiv.org/pdf/1203.1513v2", 
    "arxiv-id": "1203.1513v2"
},{
    "category": "cs.CV", 
    "author": "John Ngundam", 
    "title": "A comparative evaluation of two algorithms of detection of masses on   mammograms", 
    "publish": "2012-03-08T12:07:27Z", 
    "summary": "In this paper, we implement and carry out the comparison of two methods of\ncomputer-aided-detection of masses on mammograms. The two algorithms basically\nconsist of 3 steps each: segmentation, binarization and noise suppression using\ndifferent techniques for each step. A database of 60 images was used to compare\nthe performance of the two algorithms in terms of general detection efficiency,\nconservation of size and shape of detected masses.", 
    "link": "http://arxiv.org/pdf/1203.1765v1", 
    "arxiv-id": "1203.1765v1"
},{
    "category": "cs.CV", 
    "author": "Thomas Huang", 
    "title": "Substructure and Boundary Modeling for Continuous Action Recognition", 
    "publish": "2012-03-09T04:16:33Z", 
    "summary": "This paper introduces a probabilistic graphical model for continuous action\nrecognition with two novel components: substructure transition model and\ndiscriminative boundary model. The first component encodes the sparse and\nglobal temporal transition prior between action primitives in state-space model\nto handle the large spatial-temporal variations within an action class. The\nsecond component enforces the action duration constraint in a discriminative\nway to locate the transition boundaries between actions more accurately. The\ntwo components are integrated into a unified graphical structure to enable\neffective training and inference. Our comprehensive experimental results on\nboth public and in-house datasets show that, with the capability to incorporate\nadditional information that had not been explicitly or efficiently modeled by\nprevious methods, our proposed algorithm achieved significantly improved\nperformance for continuous action recognition.", 
    "link": "http://arxiv.org/pdf/1203.1985v1", 
    "arxiv-id": "1203.1985v1"
},{
    "category": "cs.CV", 
    "author": "Tessamma Thomas", 
    "title": "Video Object Tracking and Analysis for Computer Assisted Surgery", 
    "publish": "2012-03-12T05:39:34Z", 
    "summary": "Pedicle screw insertion technique has made revolution in the surgical\ntreatment of spinal fractures and spinal disorders. Although X- ray fluoroscopy\nbased navigation is popular, there is risk of prolonged exposure to X- ray\nradiation. Systems that have lower radiation risk are generally quite\nexpensive. The position and orientation of the drill is clinically very\nimportant in pedicle screw fixation. In this paper, the position and\norientation of the marker on the drill is determined using pattern recognition\nbased methods, using geometric features, obtained from the input video sequence\ntaken from CCD camera. A search is then performed on the video frames after\npreprocessing, to obtain the exact position and orientation of the drill.\nAnimated graphics, showing the instantaneous position and orientation of the\ndrill is then overlaid on the processed video for real time drill control and\nnavigation.", 
    "link": "http://arxiv.org/pdf/1203.2404v1", 
    "arxiv-id": "1203.2404v1"
},{
    "category": "cs.CV", 
    "author": "B. Panlal", 
    "title": "Enhancement of Images using Morphological Transformation", 
    "publish": "2012-03-09T13:22:25Z", 
    "summary": "This paper deals with enhancement of images with poor contrast and detection\nof background. Proposes a frame work which is used to detect the background in\nimages characterized by poor contrast. Image enhancement has been carried out\nby the two methods based on the Weber's law notion. The first method employs\ninformation from image background analysis by blocks, while the second\ntransformation method utilizes the opening operation, closing operation, which\nis employed to define the multi-background gray scale images. The complete\nimage processing is done using MATLAB simulation model. Finally, this paper is\norganized as follows as Morphological transformation and Weber's law. Image\nbackground approximation to the background by means of block analysis in\nconjunction with transformations that enhance images with poor lighting. The\nmultibackground notion is introduced by means of the opening by reconstruction\nshows a comparison among several techniques to improve contrast in images.\nFinally, conclusions are presented.", 
    "link": "http://arxiv.org/pdf/1203.2514v1", 
    "arxiv-id": "1203.2514v1"
},{
    "category": "cs.CV", 
    "author": "Christopher Nimsky", 
    "title": "Square-Cut: A Segmentation Algorithm on the Basis of a Rectangle Shape", 
    "publish": "2012-03-13T15:41:14Z", 
    "summary": "We present a rectangle-based segmentation algorithm that sets up a graph and\nperforms a graph cut to separate an object from the background. However,\ngraph-based algorithms distribute the graph's nodes uniformly and equidistantly\non the image. Then, a smoothness term is added to force the cut to prefer a\nparticular shape. This strategy does not allow the cut to prefer a certain\nstructure, especially when areas of the object are indistinguishable from the\nbackground. We solve this problem by referring to a rectangle shape of the\nobject when sampling the graph nodes, i.e., the nodes are distributed\nnonuniformly and non-equidistantly on the image. This strategy can be useful,\nwhen areas of the object are indistinguishable from the background. For\nevaluation, we focus on vertebrae images from Magnetic Resonance Imaging (MRI)\ndatasets to support the time consuming manual slice-by-slice segmentation\nperformed by physicians. The ground truth of the vertebrae boundaries were\nmanually extracted by two clinical experts (neurological surgeons) with several\nyears of experience in spine surgery and afterwards compared with the automatic\nsegmentation results of the proposed scheme yielding an average Dice Similarity\nCoefficient (DSC) of 90.97\\pm62.2%.", 
    "link": "http://arxiv.org/pdf/1203.2839v1", 
    "arxiv-id": "1203.2839v1"
},{
    "category": "cs.CV", 
    "author": "Miguel-Octavio Arias", 
    "title": "Integrated three-dimensional reconstruction using reflectance fields", 
    "publish": "2012-03-14T15:31:16Z", 
    "summary": "A method to obtain three-dimensional data of real-world objects by\nintegrating their material properties is presented. The material properties are\ndefined by capturing the Reflectance Fields of the real-world objects. It is\nshown, unlike conventional reconstruction methods, the method is able to use\nthe reflectance information to recover surface depth for objects having a\nnon-Lambertian surface reflectance. It is, for recovering 3D data of objects\nexhibiting an anisotropic BRDF with an error less than 0.3%.", 
    "link": "http://arxiv.org/pdf/1203.3114v1", 
    "arxiv-id": "1203.3114v1"
},{
    "category": "cs.CV", 
    "author": "Asit Kr. Das", 
    "title": "Single Reduct Generation Based on Relative Indiscernibility of Rough Set   Theory", 
    "publish": "2012-03-14T18:34:05Z", 
    "summary": "In real world everything is an object which represents particular classes.\nEvery object can be fully described by its attributes. Any real world dataset\ncontains large number of attributes and objects. Classifiers give poor\nperformance when these huge datasets are given as input to it for proper\nclassification. So from these huge dataset most useful attributes need to be\nextracted that contribute the maximum to the decision. In the paper, attribute\nset is reduced by generating reducts using the indiscernibility relation of\nRough Set Theory (RST). The method measures similarity among the attributes\nusing relative indiscernibility relation and computes attribute similarity set.\nThen the set is minimized and an attribute similarity table is constructed from\nwhich attribute similar to maximum number of attributes is selected so that the\nresultant minimum set of selected attributes (called reduct) cover all\nattributes of the attribute similarity table. The method has been applied on\nglass dataset collected from the UCI repository and the classification accuracy\nis calculated by various classifiers. The result shows the efficiency of the\nproposed method.", 
    "link": "http://arxiv.org/pdf/1203.3170v1", 
    "arxiv-id": "1203.3170v1"
},{
    "category": "cs.CV", 
    "author": "Angelo Cenedese", 
    "title": "Reconstruction error in a motion capture system", 
    "publish": "2012-03-14T22:46:29Z", 
    "summary": "Marker-based motion capture (MoCap) systems can be composed by several dozens\nof cameras with the purpose of reconstructing the trajectories of hundreds of\ntargets. With a large amount of cameras it becomes interesting to determine the\noptimal reconstruction strategy. For such aim it is of fundamental importance\nto understand the information provided by different camera measurements and how\nthey are combined, i.e. how the reconstruction error changes by considering\ndifferent cameras. In this work, first, an approximation of the reconstruction\nerror variance is derived. The results obtained in some simulations suggest\nthat the proposed strategy allows to obtain a good approximation of the real\nerror variance with significant reduction of the computational time.", 
    "link": "http://arxiv.org/pdf/1203.3230v1", 
    "arxiv-id": "1203.3230v1"
},{
    "category": "cs.CV", 
    "author": "Saida Bouakaz", 
    "title": "Extraction of Facial Feature Points Using Cumulative Histogram", 
    "publish": "2012-03-15T05:20:27Z", 
    "summary": "This paper proposes a novel adaptive algorithm to extract facial feature\npoints automatically such as eyebrows corners, eyes corners, nostrils, nose\ntip, and mouth corners in frontal view faces, which is based on cumulative\nhistogram approach by varying different threshold values. At first, the method\nadopts the Viola-Jones face detector to detect the location of face and also\ncrops the face region in an image. From the concept of the human face\nstructure, the six relevant regions such as right eyebrow, left eyebrow, right\neye, left eye, nose, and mouth areas are cropped in a face image. Then the\nhistogram of each cropped relevant region is computed and its cumulative\nhistogram value is employed by varying different threshold values to create a\nnew filtering image in an adaptive way. The connected component of interested\narea for each relevant filtering image is indicated our respective feature\nregion. A simple linear search algorithm for eyebrows, eyes and mouth filtering\nimages and contour algorithm for nose filtering image are applied to extract\nour desired corner points automatically. The method was tested on a large BioID\nfrontal face database in different illuminations, expressions and lighting\nconditions and the experimental results have achieved average success rates of\n95.27%.", 
    "link": "http://arxiv.org/pdf/1203.3270v1", 
    "arxiv-id": "1203.3270v1"
},{
    "category": "cs.CV", 
    "author": "Basir Shariat Razavi", 
    "title": "Clustering Using Isoperimetric Number of Trees", 
    "publish": "2012-03-19T19:15:25Z", 
    "summary": "In this paper we propose a graph-based data clustering algorithm which is\nbased on exact clustering of a minimum spanning tree in terms of a minimum\nisoperimetry criteria. We show that our basic clustering algorithm runs in $O(n\n\\log n)$ and with post-processing in $O(n^2)$ (worst case) time where $n$ is\nthe size of the data set. We also show that our generalized graph model which\nalso allows the use of potentials at vertices can be used to extract a more\ndetailed pack of information as the {\\it outlier profile} of the data set. In\nthis direction we show that our approach can be used to define the concept of\nan outlier-set in a precise way and we propose approximation algorithms for\nfinding such sets. We also provide a comparative performance analysis of our\nalgorithm with other related ones and we show that the new clustering algorithm\n(without the outlier extraction procedure) behaves quite effectively even on\nhard benchmarks and handmade examples.", 
    "link": "http://arxiv.org/pdf/1203.4204v1", 
    "arxiv-id": "1203.4204v1"
},{
    "category": "cs.CV", 
    "author": "Jingyi Yu", 
    "title": "A Co-Prime Blur Scheme for Data Security in Video Surveillance", 
    "publish": "2012-03-22T02:57:53Z", 
    "summary": "This paper presents a novel Coprime Blurred Pair (CBP) model for visual\ndata-hiding for security in camera surveillance. While most previous approaches\nhave focused on completely encrypting the video stream, we introduce a spatial\nencryption scheme by blurring the image/video contents to create a CBP. Our\ngoal is to obscure detail in public video streams by blurring while allowing\nbehavior to be recognized and to quickly deblur the stream so that details are\navailable if behavior is recognized as suspicious. We create a CBP by blurring\nthe same latent image with two unknown kernels. The two kernels are coprime\nwhen mapped to bivariate polynomials in the z domain. To deblur the CBP we\nfirst use the coprime constraint to approximate the kernels and sample the\nbivariate CBP polynomials in one dimension on the unit circle. At each sample\npoint, we factor the 1D polynomial pair and compose the results into a 2D\nkernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of\nthe kernel matrices to recover the coprime kernels and then the latent video\nstream. It is therefore only possible to deblur the video stream if a user has\naccess to both streams. To improve the practicability of our algorithm, we\nimplement our algorithm using a graphics processing unit (GPU) to decrypt the\nblurred video streams in real-time, and extensive experimental results\ndemonstrate that our new scheme can effectively protect sensitive identity\ninformation in surveillance videos and faithfully reconstruct the unblurred\nvideo stream when two blurred sequences are available.", 
    "link": "http://arxiv.org/pdf/1203.4874v1", 
    "arxiv-id": "1203.4874v1"
},{
    "category": "cs.CV", 
    "author": "Seleman M. Ngwira", 
    "title": "Kernel Density Feature Points Estimator for Content-Based Image   Retrieval", 
    "publish": "2012-03-22T18:47:57Z", 
    "summary": "Research is taking place to find effective algorithms for content-based image\nrepresentation and description. There is a substantial amount of algorithms\navailable that use visual features (color, shape, texture). Shape feature has\nattracted much attention from researchers that there are many shape\nrepresentation and description algorithms in literature. These shape image\nrepresentation and description algorithms are usually not application\nindependent or robust, making them undesirable for generic shape description.\nThis paper presents an object shape representation using Kernel Density Feature\nPoints Estimator (KDFPE). In this method, the density of feature points within\ndefined rings around the centroid of the image is obtained. The KDFPE is then\napplied to the vector of the image. KDFPE is invariant to translation, scale\nand rotation. This method of image representation shows improved retrieval rate\nwhen compared to Density Histogram Feature Points (DHFP) method. Analytic\nanalysis is done to justify our method, which was compared with the DHFP to\nprove its robustness.", 
    "link": "http://arxiv.org/pdf/1203.5078v1", 
    "arxiv-id": "1203.5078v1"
},{
    "category": "cs.CV", 
    "author": "Arnav Bhavsar", 
    "title": "Analysis of Magnification in Depth from Defocus", 
    "publish": "2012-03-28T18:16:46Z", 
    "summary": "In depth from defocus (DFD), when images are captured with different camera\nparameters, a relative magnification is induced between them. Image warping is\na simpler solution to account for magnification than seemingly more accurate\noptical approaches. This work is an investigation into the effects of\nmagnification on the accuracy of DFD. We comment on issues regarding scaling\neffect on relative blur computation. We statistically analyze accountability of\nscale factor, commenting on the bias and efficiency of the estimator that does\nnot consider scale. We also discuss the effect of interpolation errors on blur\nestimation in a warping based solution to handle magnification and carry out\nexperimental analysis to comment on the blur estimation accuracy.", 
    "link": "http://arxiv.org/pdf/1203.6329v2", 
    "arxiv-id": "1203.6329v2"
},{
    "category": "cs.CV", 
    "author": "Vinay Bettadapura", 
    "title": "Face Expression Recognition and Analysis: The State of the Art", 
    "publish": "2012-03-30T05:47:59Z", 
    "summary": "The automatic recognition of facial expressions has been an active research\ntopic since the early nineties. There have been several advances in the past\nfew years in terms of face detection and tracking, feature extraction\nmechanisms and the techniques used for expression classification. This paper\nsurveys some of the published work since 2001 till date. The paper presents a\ntime-line view of the advances made in this field, the applications of\nautomatic face expression recognizers, the characteristics of an ideal system,\nthe databases that have been used and the advances made in terms of their\nstandardization and a detailed summary of the state of the art. The paper also\ndiscusses facial parameterization using FACS Action Units (AUs) and MPEG-4\nFacial Animation Parameters (FAPs) and the recent advances in face detection,\ntracking and feature extraction methods. Notes have also been presented on\nemotions, expressions and facial features, discussion on the six prototypic\nexpressions and the recent studies on expression classifiers. The paper ends\nwith a note on the challenges and the future work. This paper has been written\nin a tutorial style with the intention of helping students and researchers who\nare new to this field.", 
    "link": "http://arxiv.org/pdf/1203.6722v1", 
    "arxiv-id": "1203.6722v1"
},{
    "category": "cs.CV", 
    "author": "Deepesh Srivastava", 
    "title": "Efficient Fruit Defect Detection and Glare removal Algorithm by   anisotropic diffusion and 2D Gabor filter", 
    "publish": "2012-04-03T19:02:54Z", 
    "summary": "This paper focuses on fruit defect detection and glare removal using\nmorphological operations, Glare removal can be considered as an important\npreprocessing step as uneven lighting may introduce it in images, which hamper\nthe results produced through segmentation by Gabor filters .The problem of\nglare in images is very pronounced sometimes due to the unusual reflectance\nfrom the camera sensor or stray light entering, this method counteracts this\nproblem and makes the defect detection much more pronounced. Anisotropic\ndiffusion is used for further smoothening of the images and removing the high\nenergy regions in an image for better defect detection and makes the defects\nmore retrievable. Our algorithm is robust and scalable the employability of a\nparticular mask for glare removal has been checked and proved useful for\ncounteracting.this problem, anisotropic diffusion further enhances the defects\nwith its use further Optimal Gabor filter at various orientations is used for\ndefect detection.", 
    "link": "http://arxiv.org/pdf/1204.0767v2", 
    "arxiv-id": "1204.0767v2"
},{
    "category": "cs.CV", 
    "author": "Hasan Farooq", 
    "title": "Principal Component Analysis-Linear Discriminant Analysis Feature   Extractor for Pattern Recognition", 
    "publish": "2012-04-05T10:48:09Z", 
    "summary": "Robustness of embedded biometric systems is of prime importance with the\nemergence of fourth generation communication devices and advancement in\nsecurity systems This paper presents the realization of such technologies which\ndemands reliable and error-free biometric identity verification systems. High\ndimensional patterns are not permitted due to eigen-decomposition in high\ndimensional image space and degeneration of scattering matrices in small size\nsample. Generalization, dimensionality reduction and maximizing the margins are\ncontrolled by minimizing weight vectors. Results show good pattern by\nmultimodal biometric system proposed in this paper. This paper is aimed at\ninvestigating a biometric identity system using Principal Component Analysis\nand Lindear Discriminant Analysis with K-Nearest Neighbor and implementing such\nsystem in real-time using SignalWAVE.", 
    "link": "http://arxiv.org/pdf/1204.1177v1", 
    "arxiv-id": "1204.1177v1"
},{
    "category": "cs.CV", 
    "author": "Md. Abu Naser Bikas", 
    "title": "A Complete Workflow for Development of Bangla OCR", 
    "publish": "2012-04-05T12:28:11Z", 
    "summary": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required.", 
    "link": "http://arxiv.org/pdf/1204.1198v1", 
    "arxiv-id": "1204.1198v1"
},{
    "category": "cs.CV", 
    "author": "Raquel Urtasun", 
    "title": "Continuous Markov Random Fields for Robust Stereo Estimation", 
    "publish": "2012-04-06T01:40:21Z", 
    "summary": "In this paper we present a novel slanted-plane MRF model which reasons\njointly about occlusion boundaries as well as depth. We formulate the problem\nas the one of inference in a hybrid MRF composed of both continuous (i.e.,\nslanted 3D planes) and discrete (i.e., occlusion boundaries) random variables.\nThis allows us to define potentials encoding the ownership of the pixels that\ncompose the boundary between segments, as well as potentials encoding which\njunctions are physically possible. Our approach outperforms the\nstate-of-the-art on Middlebury high resolution imagery as well as in the more\nchallenging KITTI dataset, while being more efficient than existing slanted\nplane MRF-based methods, taking on average 2 minutes to perform inference on\nhigh resolution imagery.", 
    "link": "http://arxiv.org/pdf/1204.1393v1", 
    "arxiv-id": "1204.1393v1"
},{
    "category": "cs.CV", 
    "author": "Bok Min Goi", 
    "title": "Vision-based Human Gender Recognition: A Survey", 
    "publish": "2012-04-07T08:17:40Z", 
    "summary": "Gender is an important demographic attribute of people. This paper provides a\nsurvey of human gender recognition in computer vision. A review of approaches\nexploiting information from face and whole body (either from a still image or\ngait sequence) is presented. We highlight the challenges faced and survey the\nrepresentative methods of these approaches. Based on the results, good\nperformance have been achieved for datasets captured under controlled\nenvironments, but there is still much work that can be done to improve the\nrobustness of gender recognition under real-life environments.", 
    "link": "http://arxiv.org/pdf/1204.1611v1", 
    "arxiv-id": "1204.1611v1"
},{
    "category": "cs.CV", 
    "author": "karim kalti", 
    "title": "Image segmentation by adaptive distance based on EM algorithm", 
    "publish": "2012-04-07T13:04:24Z", 
    "summary": "This paper introduces a Bayesian image segmentation algorithm based on finite\nmixtures. An EM algorithm is developed to estimate parameters of the Gaussian\nmixtures. The finite mixture is a flexible and powerful probabilistic modeling\ntool. It can be used to provide a model-based clustering in the field of\npattern recognition. However, the application of finite mixtures to image\nsegmentation presents some difficulties; especially it's sensible to noise. In\nthis paper we propose a variant of this method which aims to resolve this\nproblem. Our approach proceeds by the characterization of pixels by two\nfeatures: the first one describes the intrinsic properties of the pixel and the\nsecond characterizes the neighborhood of pixel. Then the classification is made\non the base on adaptive distance which privileges the one or the other features\naccording to the spatial position of the pixel in the image. The obtained\nresults have shown a significant improvement of our approach compared to the\nstandard version of EM algorithm.", 
    "link": "http://arxiv.org/pdf/1204.1629v1", 
    "arxiv-id": "1204.1629v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed Ali Mahjoub", 
    "title": "Automatic liver segmentation method in CT images", 
    "publish": "2012-04-07T13:46:24Z", 
    "summary": "The aim of this work is to develop a method for automatic segmentation of the\nliver based on a priori knowledge of the image, such as location and shape of\nthe liver.", 
    "link": "http://arxiv.org/pdf/1204.1634v1", 
    "arxiv-id": "1204.1634v1"
},{
    "category": "cs.CV", 
    "author": "Adel M. Alimi", 
    "title": "A New Approach for Arabic Handwritten Postal Addresses Recognition", 
    "publish": "2012-04-07T20:45:06Z", 
    "summary": "In this paper, we propose an automatic analysis system for the Arabic\nhandwriting postal addresses recognition, by using the beta elliptical model.\nOur system is divided into different steps: analysis, pre-processing and\nclassification. The first operation is the filtering of image. In the second,\nwe remove the border print, stamps and graphics. After locating the address on\nthe envelope, the address segmentation allows the extraction of postal code and\ncity name separately. The pre-processing system and the modeling approach are\nbased on two basic steps. The first step is the extraction of the temporal\norder in the image of the handwritten trajectory. The second step is based on\nthe use of Beta-Elliptical model for the representation of handwritten script.\nThe recognition system is based on Graph-matching algorithm. Our modeling and\nrecognition approaches were validated by using the postal code and city names\nextracted from the Tunisian postal envelopes data. The recognition rate\nobtained is about 98%.", 
    "link": "http://arxiv.org/pdf/1204.1678v1", 
    "arxiv-id": "1204.1678v1"
},{
    "category": "cs.CV", 
    "author": "S. Vimala", 
    "title": "Multi-Level Coding Efficiency with Improved Quality for Image   Compression based on AMBTC", 
    "publish": "2012-04-08T03:44:13Z", 
    "summary": "In this paper, we have proposed an extended version of Absolute Moment Block\nTruncation Coding (AMBTC) to compress images. Generally the elements of a\nbitplane used in the variants of Block Truncation Coding (BTC) are of size 1\nbit. But it has been extended to two bits in the proposed method. Number of\nstatistical moments preserved to reconstruct the compressed has also been\nraised from 2 to 4. Hence, the quality of the reconstructed images has been\nimproved significantly from 33.62 to 38.12 with the increase in bpp by 1. The\nincreased bpp (3) is further reduced to 1.75in multiple levels: in one level,\nby dropping 4 elements of the bitplane in such a away that the pixel values of\nthe dropped elements can easily be interpolated with out much of loss in the\nquality, in level two, eight elements are dropped and reconstructed later and\nin level three, the size of the statistical moments is reduced. The experiments\nwere carried over standard images of varying intensities. In all the cases, the\nproposed method outperforms the existing AMBTC technique in terms of both PSNR\nand bpp.", 
    "link": "http://arxiv.org/pdf/1204.1704v1", 
    "arxiv-id": "1204.1704v1"
},{
    "category": "cs.CV", 
    "author": "Shaila Subbaraman", 
    "title": "SVD-EBP Algorithm for Iris Pattern Recognition", 
    "publish": "2012-04-10T07:10:06Z", 
    "summary": "This paper proposes a neural network approach based on Error Back Propagation\n(EBP) for classification of different eye images. To reduce the complexity of\nlayered neural network the dimensions of input vectors are optimized using\nSingular Value Decomposition (SVD). The main of this work is to provide for\nbest method for feature extraction and classification. The details of this\ncombined system named as SVD-EBP system, and results thereof are presented in\nthis paper.\n  Keywords- Singular value decomposition(SVD), Error back Propagation(EBP).", 
    "link": "http://arxiv.org/pdf/1204.2062v1", 
    "arxiv-id": "1204.2062v1"
},{
    "category": "cs.CV", 
    "author": "P. D. Khandait", 
    "title": "Automatic facial feature extraction and expression recognition based on   neural network", 
    "publish": "2012-04-10T07:57:53Z", 
    "summary": "In this paper, an approach to the problem of automatic facial feature\nextraction from a still frontal posed image and classification and recognition\nof facial expression and hence emotion and mood of a person is presented. Feed\nforward back propagation neural network is used as a classifier for classifying\nthe expressions of supplied face into seven basic categories like surprise,\nneutral, sad, disgust, fear, happy and angry. For face portion segmentation and\nlocalization, morphological image processing operations are used. Permanent\nfacial features like eyebrows, eyes, mouth and nose are extracted using SUSAN\nedge detection operator, facial geometry, edge projection analysis. Experiments\nare carried out on JAFFE facial expression database and gives better\nperformance in terms of 100% accuracy for training set and 95.26% accuracy for\ntest set.", 
    "link": "http://arxiv.org/pdf/1204.2073v1", 
    "arxiv-id": "1204.2073v1"
},{
    "category": "cs.CV", 
    "author": "Yong Haur Tay", 
    "title": "Image-based Vehicle Classification System", 
    "publish": "2012-04-10T11:59:10Z", 
    "summary": "Electronic toll collection (ETC) system has been a common trend used for toll\ncollection on toll road nowadays. The implementation of electronic toll\ncollection allows vehicles to travel at low or full speed during the toll\npayment, which help to avoid the traffic delay at toll road. One of the major\ncomponents of an electronic toll collection is the automatic vehicle detection\nand classification (AVDC) system which is important to classify the vehicle so\nthat the toll is charged according to the vehicle classes. Vision-based vehicle\nclassification system is one type of vehicle classification system which adopt\ncamera as the input sensing device for the system. This type of system has\nadvantage over the rest for it is cost efficient as low cost camera is used.\nThe implementation of vision-based vehicle classification system requires lower\ninitial investment cost and very suitable for the toll collection trend\nmigration in Malaysia from single ETC system to full-scale multi-lane free flow\n(MLFF). This project includes the development of an image-based vehicle\nclassification system as an effort to seek for a robust vision-based vehicle\nclassification system. The techniques used in the system include\nscale-invariant feature transform (SIFT) technique, Canny's edge detector,\nK-means clustering as well as Euclidean distance matching. In this project, a\nunique way to image description as matching medium is proposed. This\ndistinctiveness of method is analogous to the human DNA concept which is highly\nunique. The system is evaluated on open datasets and return promising results.", 
    "link": "http://arxiv.org/pdf/1204.2114v1", 
    "arxiv-id": "1204.2114v1"
},{
    "category": "cs.CV", 
    "author": "Fernand Meyer", 
    "title": "The steepest watershed: from graphs to images", 
    "publish": "2012-04-10T13:08:34Z", 
    "summary": "The watershed is a powerful tool for segmenting objects whose contours appear\nas crest lines on a gradient image. The watershed transform associates to a\ntopographic surface a partition into catchment basins, defined as attraction\nzones of a drop of water falling on the relief and following a line of steepest\ndescent. Unfortunately, catchment basins may overlap and do not form a\npartition. Moreover, current watershed algorithms, being shortsighted, do not\ncorrectly estimate the steepness of the downwards trajectories and overestimate\nthe overlapping zones of catchment basins. An arbitrary division of these zones\nbetween adjacent catchment basin results in a poor localization of the\ncontours. We propose an algorithm without myopia, which considers the total\nlength of a trajectory for estimating its steepness. We first consider\ntopographic surfaces defined on node weighted graphs. The graphs are pruned in\norder to eliminate all downwards trajectories which are not the steepest. An\niterative algorithm with simple neighborhood operations performs the pruning\nand constructs the catchment basins. The algorithm is then adapted to gray tone\nimages. The graph structure itself is encoded as an image thanks to the fixed\nneighborhood structure of grids. A pair of adaptative erosions and dilations\nprune the graph and extend the catchment basins. As a result one obtains a\nprecise detection of the catchment basins and a graph of the steepest\ntrajectories. A last iterative algorithm allows to follow selected downwards\ntrajectories in order to detect particular structures such as rivers or thalweg\nlines of the topographic surface.", 
    "link": "http://arxiv.org/pdf/1204.2134v1", 
    "arxiv-id": "1204.2134v1"
},{
    "category": "cs.CV", 
    "author": "Mohd Adly Rosly", 
    "title": "Ubiquitous WLAN/Camera Positioning using Inverse Intensity Chromaticity   Space-based Feature Detection and Matching: A Preliminary Result", 
    "publish": "2012-04-10T22:05:34Z", 
    "summary": "This paper present our new intensity chromaticity space-based feature\ndetection and matching algorithm. This approach utilizes hybridization of\nwireless local area network and camera internal sensor which to receive signal\nstrength from a access point and the same time retrieve interest point\ninformation from hallways. This information is combined by model fitting\napproach in order to find the absolute of user target position. No conventional\nsearching algorithm is required, thus it is expected reducing the computational\ncomplexity. Finally we present pre-experimental results to illustrate the\nperformance of the localization system for an indoor environment set-up.", 
    "link": "http://arxiv.org/pdf/1204.2294v1", 
    "arxiv-id": "1204.2294v1"
},{
    "category": "cs.CV", 
    "author": "K. V. N. Sunitha", 
    "title": "Feature Extraction Methods for Color Image Similarity", 
    "publish": "2012-04-11T04:45:51Z", 
    "summary": "Many User interactive systems are proposed all methods are trying to\nimplement as a user friendly and various approaches proposed but most of the\nsystems not reached to the use specifications like user friendly systems with\nuser interest, all proposed method implemented basic techniques some are\nimproved methods also propose but not reaching to the user specifications. In\nthis proposed paper we concentrated on image retrieval system with in early\ndays many user interactive systems performed with basic concepts but such\nsystems are not reaching to the user specifications and not attracted to the\nuser so a lot of research interest in recent years with new specifications,\nrecent approaches have user is interested in friendly interacted methods are\nexpecting, many are concentrated for improvement in all methods. In this\nproposed system we focus on the retrieval of images within a large image\ncollection based on color projections and different mathematical approaches are\nintroduced and applied for retrieval of images. before Appling proposed methods\nimages are sub grouping using threshold values, in this paper R G B color\ncombinations considered for retrieval of images, in proposed methods are\nimplemented and results are included, through results it is observed that we\nobtaining efficient results comparatively previous and existing.", 
    "link": "http://arxiv.org/pdf/1204.2336v1", 
    "arxiv-id": "1204.2336v1"
},{
    "category": "cs.CV", 
    "author": "David Zhang", 
    "title": "Collaborative Representation based Classification for Face Recognition", 
    "publish": "2012-04-11T07:13:20Z", 
    "summary": "By coding a query sample as a sparse linear combination of all training\nsamples and then classifying it by evaluating which class leads to the minimal\ncoding residual, sparse representation based classification (SRC) leads to\ninteresting results for robust face recognition. It is widely believed that the\nl1- norm sparsity constraint on coding coefficients plays a key role in the\nsuccess of SRC, while its use of all training samples to collaboratively\nrepresent the query sample is rather ignored. In this paper we discuss how SRC\nworks, and show that the collaborative representation mechanism used in SRC is\nmuch more crucial to its success of face classification. The SRC is a special\ncase of collaborative representation based classification (CRC), which has\nvarious instantiations by applying different norms to the coding residual and\ncoding coefficient. More specifically, the l1 or l2 norm characterization of\ncoding residual is related to the robustness of CRC to outlier facial pixels,\nwhile the l1 or l2 norm characterization of coding coefficient is related to\nthe degree of discrimination of facial features. Extensive experiments were\nconducted to verify the face recognition accuracy and efficiency of CRC with\ndifferent instantiations.", 
    "link": "http://arxiv.org/pdf/1204.2358v2", 
    "arxiv-id": "1204.2358v2"
},{
    "category": "cs.CV", 
    "author": "Anton van den Hengel", 
    "title": "Non-sparse Linear Representations for Visual Tracking with Online   Reservoir Metric Learning", 
    "publish": "2012-04-13T08:16:41Z", 
    "summary": "Most sparse linear representation-based trackers need to solve a\ncomputationally expensive L1-regularized optimization problem. To address this\nproblem, we propose a visual tracker based on non-sparse linear\nrepresentations, which admit an efficient closed-form solution without\nsacrificing accuracy. Moreover, in order to capture the correlation information\nbetween different feature dimensions, we learn a Mahalanobis distance metric in\nan online fashion and incorporate the learned metric into the optimization\nproblem for obtaining the linear representation. We show that online metric\nlearning using proximity comparison significantly improves the robustness of\nthe tracking, especially on those sequences exhibiting drastic appearance\nchanges. Furthermore, in order to prevent the unbounded growth in the number of\ntraining samples for the metric learning, we design a time-weighted reservoir\nsampling method to maintain and update limited-sized foreground and background\nsample buffers for balancing sample diversity and adaptability. Experimental\nresults on challenging videos demonstrate the effectiveness and robustness of\nthe proposed tracker.", 
    "link": "http://arxiv.org/pdf/1204.2912v1", 
    "arxiv-id": "1204.2912v1"
},{
    "category": "cs.CV", 
    "author": "Asar Ali", 
    "title": "Speech Recognition: Increasing Efficiency of Support Vector Machines", 
    "publish": "2012-04-19T06:10:02Z", 
    "summary": "With the advancement of communication and security technologies, it has\nbecome crucial to have robustness of embedded biometric systems. This paper\npresents the realization of such technologies which demands reliable and\nerror-free biometric identity verification systems. High dimensional patterns\nare not permitted due to eigen-decomposition in high dimensional feature space\nand degeneration of scattering matrices in small size sample. Generalization,\ndimensionality reduction and maximizing the margins are controlled by\nminimizing weight vectors. Results show good pattern by multimodal biometric\nsystem proposed in this paper. This paper is aimed at investigating a biometric\nidentity system using Support Vector Machines(SVMs) and Lindear Discriminant\nAnalysis(LDA) with MFCCs and implementing such system in real-time using\nSignalWAVE.", 
    "link": "http://arxiv.org/pdf/1204.4257v1", 
    "arxiv-id": "1204.4257v1"
},{
    "category": "cs.CV", 
    "author": "Pradeep Singla", 
    "title": "A New Approach of Improving CFA Image for Digital Camera's", 
    "publish": "2012-04-24T15:45:37Z", 
    "summary": "This paper work directly towards the improving the quality of the image for\nthe digital cameras and other visual capturing products. In this Paper, the\nauthors clearly defines the problems occurs in the CFA image. A different\nmethodology for removing the noise is discuses in the paper for color\ncorrection and color balancing of the image. At the same time, the authors also\nproposed a new methodology of providing denoisiing process before the\ndemosaickingfor the improving the image quality of CFA which is much efficient\nthen the other previous defined. The demosaicking process for producing the\ncolors in the image in a best way is also discuss.", 
    "link": "http://arxiv.org/pdf/1204.5416v1", 
    "arxiv-id": "1204.5416v1"
},{
    "category": "cs.CV", 
    "author": "Mehdi Ghasemzadeh", 
    "title": "Robust Head Pose Estimation Using Contourlet Transform", 
    "publish": "2012-04-24T17:08:04Z", 
    "summary": "Estimating pose of the head is an important preprocessing step in many\npattern recognition and computer vision systems such as face recognition. Since\nthe performance of the face recognition systems is greatly affected by the\nposes of the face, how to estimate the accurate pose of the face in human face\nimage is still a challenging problem. In this paper, we represent a novel\nmethod for head pose estimation. To enhance the efficiency of the estimation we\nuse contourlet transform for feature extraction. Contourlet transform is\nmulti-resolution, multi-direction transform. In order to reduce the feature\nspace dimension and obtain appropriate features we use LDA (Linear Discriminant\nAnalysis) and PCA (Principal Component Analysis) to remove ineffcient features.\nThen, we apply different classifiers such as k-nearest neighborhood (knn) and\nminimum distance. We use the public available FERET database to evaluate the\nperformance of proposed method. Simulation results indicate the superior\nrobustness of the proposed method.", 
    "link": "http://arxiv.org/pdf/1204.5431v2", 
    "arxiv-id": "1204.5431v2"
},{
    "category": "cs.CV", 
    "author": "Nicolas Saunier", 
    "title": "Background subtraction based on Local Shape", 
    "publish": "2012-04-27T20:26:34Z", 
    "summary": "We present a novel approach to background subtraction that is based on the\nlocal shape of small image regions. In our approach, an image region centered\non a pixel is mod-eled using the local self-similarity descriptor. We aim at\nobtaining a reliable change detection based on local shape change in an image\nwhen foreground objects are moving. The method first builds a background model\nand compares the local self-similarities between the background model and the\nsubsequent frames to distinguish background and foreground objects.\nPost-processing is then used to refine the boundaries of moving objects.\nResults show that this approach is promising as the foregrounds obtained are\ncom-plete, although they often include shadows.", 
    "link": "http://arxiv.org/pdf/1204.6326v2", 
    "arxiv-id": "1204.6326v2"
},{
    "category": "cs.CV", 
    "author": "Kap Luk Chan", 
    "title": "Active Contour with A Tangential Component", 
    "publish": "2012-04-29T07:17:28Z", 
    "summary": "Conventional edge-based active contours often require the normal component of\nan edge indicator function on the optimal contours to approximate zero, while\nthe tangential component can still be significant. In real images, the full\ngradients of the edge indicator function along the object boundaries are often\nsmall. Hence, the curve evolution of edge-based active contours can terminate\nearly before converging to the object boundaries with a careless contour\ninitialization. We propose a novel Geodesic Snakes (GeoSnakes) active contour\nthat requires the full gradients of the edge indicator to vanish at the optimal\nsolution. Besides, the conventional curve evolution approach for minimizing\nactive contour energy cannot fully solve the Euler-Lagrange (EL) equation of\nour GeoSnakes active contour, causing a Pseudo Stationary Phenomenon (PSP). To\naddress the PSP problem, we propose an auxiliary curve evolution equation,\nnamed the equilibrium flow (EF) equation. Based on the EF and the conventional\ncurve evolution, we obtain a solution to the full EL equation of GeoSnakes\nactive contour. Experimental results validate the proposed geometrical\ninterpretation of the early termination problem, and they also show that the\nproposed method overcomes the problem.", 
    "link": "http://arxiv.org/pdf/1204.6458v1", 
    "arxiv-id": "1204.6458v1"
},{
    "category": "cs.CV", 
    "author": "Ramakrishna Kakarala", 
    "title": "Parametric annealing: a stochastic search method for human pose tracking", 
    "publish": "2012-04-30T07:04:08Z", 
    "summary": "Model based methods to marker-free motion capture have a very high\ncomputational overhead that make them unattractive. In this paper we describe a\nmethod that improves on existing global optimization techniques to tracking\narticulated objects. Our method improves on the state-of-the-art Annealed\nParticle Filter (APF) by reusing samples across annealing layers and by using\nan adaptive parametric density for diffusion. We compare the proposed method\nwith APF on a scalable problem and study how the two methods scale with the\ndimensionality, multi-modality and the range of search. Then we perform\nsensitivity analysis on the parameters of our algorithm and show that it\ntolerates a wide range of parameter settings. We also show results on tracking\nhuman pose from the widely-used Human Eva I dataset. Our results show that the\nproposed method reduces the tracking error despite using less than 50% of the\ncomputational resources as APF. The tracked output also shows a significant\nqualitative improvement over APF as demonstrated through image and video\nresults.", 
    "link": "http://arxiv.org/pdf/1204.6563v2", 
    "arxiv-id": "1204.6563v2"
},{
    "category": "cs.CV", 
    "author": "Deepesh Srivastava", 
    "title": "Elimination of Glass Artifacts and Object Segmentation", 
    "publish": "2012-04-30T14:47:45Z", 
    "summary": "Many images nowadays are captured from behind the glasses and may have\ncertain stains discrepancy because of glass and must be processed to make\ndifferentiation between the glass and objects behind it. This research paper\nproposes an algorithm to remove the damaged or corrupted part of the image and\nmake it consistent with other part of the image and to segment objects behind\nthe glass. The damaged part is removed using total variation inpainting method\nand segmentation is done using kmeans clustering, anisotropic diffusion and\nwatershed transformation. The final output is obtained by interpolation. This\nalgorithm can be useful to applications in which some part of the images are\ncorrupted due to data transmission or needs to segment objects from an image\nfor further processing.", 
    "link": "http://arxiv.org/pdf/1204.6653v1", 
    "arxiv-id": "1204.6653v1"
},{
    "category": "cs.CV", 
    "author": "K B Raja", 
    "title": "DBC based Face Recognition using DWT", 
    "publish": "2012-05-08T09:44:03Z", 
    "summary": "The applications using face biometric has proved its reliability in last\ndecade. In this paper, we propose DBC based Face Recognition using DWT (DBC-\nFR) model. The Poly-U Near Infra Red (NIR) database images are scanned and\ncropped to get only the face part in pre-processing. The face part is resized\nto 100*100 and DWT is applied to derive LL, LH, HL and HH subbands. The LL\nsubband of size 50*50 is converted into 100 cells with 5*5 dimention of each\ncell. The Directional Binary Code (DBC) is applied on each 5*5 cell to derive\n100 features. The Euclidian distance measure is used to compare the features of\ntest image and database images. The proposed algorithm render better percentage\nrecognition rate compared to the existing algorithm.", 
    "link": "http://arxiv.org/pdf/1205.1644v1", 
    "arxiv-id": "1205.1644v1"
},{
    "category": "cs.CV", 
    "author": "V. K. Govindan", 
    "title": "M-FISH Karyotyping - A New Approach Based on Watershed Transform", 
    "publish": "2012-05-09T16:52:23Z", 
    "summary": "Karyotyping is a process in which chromosomes in a dividing cell are properly\nstained, identified and displayed in a standard format, which helps geneticist\nto study and diagnose genetic factors behind various genetic diseases and for\nstudying cancer. M-FISH (Multiplex Fluorescent In-Situ Hybridization) provides\ncolor karyotyping. In this paper, an automated method for M-FISH chromosome\nsegmentation based on watershed transform followed by naive Bayes\nclassification of each region using the features, mean and standard deviation,\nis presented. Also, a post processing step is added to re-classify the small\nchromosome segments to the neighboring larger segment for reducing the chances\nof misclassification. The approach provided improved accuracy when compared to\nthe pixel-by-pixel approach. The approach was tested on 40 images from the\ndataset and achieved an accuracy of 84.21 %.", 
    "link": "http://arxiv.org/pdf/1205.2031v1", 
    "arxiv-id": "1205.2031v1"
},{
    "category": "cs.CV", 
    "author": "Vivek Kr Verma", 
    "title": "Discrimination of English to other Indian languages (Kannada and Hindi)   for OCR system", 
    "publish": "2012-05-10T06:14:51Z", 
    "summary": "India is a multilingual multi-script country. In every state of India there\nare two languages one is state local language and the other is English. For\nexample in Andhra Pradesh, a state in India, the document may contain text\nwords in English and Telugu script. For Optical Character Recognition (OCR) of\nsuch a bilingual document, it is necessary to identify the script before\nfeeding the text words to the OCRs of individual scripts. In this paper, we are\nintroducing a simple and efficient technique of script identification for\nKannada, English and Hindi text words of a printed document. The proposed\napproach is based on the horizontal and vertical projection profile for the\ndiscrimination of the three scripts. The feature extraction is done based on\nthe horizontal projection profile of each text words. We analysed 700 different\nwords of Kannada, English and Hindi in order to extract the discrimination\nfeatures and for the development of knowledge base. We use the horizontal\nprojection profile of each text word and based on the horizontal projection\nprofile we extract the appropriate features. The proposed system is tested on\n100 different document images containing more than 1000 text words of each\nscript and a classification rate of 98.25%, 99.25% and 98.87% is achieved for\nKannada, English and Hindi respectively.", 
    "link": "http://arxiv.org/pdf/1205.2164v1", 
    "arxiv-id": "1205.2164v1"
},{
    "category": "cs.CV", 
    "author": "Ricardo da S. Torres", 
    "title": "Are visual dictionaries generalizable?", 
    "publish": "2012-05-11T18:54:12Z", 
    "summary": "Mid-level features based on visual dictionaries are today a cornerstone of\nsystems for classification and retrieval of images. Those state-of-the-art\nrepresentations depend crucially on the choice of a codebook (visual\ndictionary), which is usually derived from the dataset. In general-purpose,\ndynamic image collections (e.g., the Web), one cannot have the entire\ncollection in order to extract a representative dictionary. However, based on\nthe hypothesis that the dictionary reflects only the diversity of low-level\nappearances and does not capture semantics, we argue that a dictionary based on\na small subset of the data, or even on an entirely different dataset, is able\nto produce a good representation, provided that the chosen images span a\ndiverse enough portion of the low-level feature space. Our experiments confirm\nthat hypothesis, opening the opportunity to greatly alleviate the burden in\ngenerating the codebook, and confirming the feasibility of employing visual\ndictionaries in large-scale dynamic environments.", 
    "link": "http://arxiv.org/pdf/1205.2663v1", 
    "arxiv-id": "1205.2663v1"
},{
    "category": "cs.CV", 
    "author": "John W. Fisher III", 
    "title": "Efficient Topology-Controlled Sampling of Implicit Shapes", 
    "publish": "2012-05-16T19:11:51Z", 
    "summary": "Sampling from distributions of implicitly defined shapes enables analysis of\nvarious energy functionals used for image segmentation. Recent work describes a\ncomputationally efficient Metropolis-Hastings method for accomplishing this\ntask. Here, we extend that framework so that samples are accepted at every\niteration of the sampler, achieving an order of magnitude speed up in\nconvergence. Additionally, we show how to incorporate topological constraints.", 
    "link": "http://arxiv.org/pdf/1205.3766v1", 
    "arxiv-id": "1205.3766v1"
},{
    "category": "cs.CV", 
    "author": "Quansheng Liu", 
    "title": "Optimal Weights Mixed Filter for Removing Mixture of Gaussian and   Impulse Noises", 
    "publish": "2012-05-17T18:15:45Z", 
    "summary": "According to the character of Gaussian, we modify the Rank-Ordered Absolute\nDifferences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian\nand impulse noises (ROADG). It will be more effective to detect impulse noise\nwhen the impulse is mixed with Gaussian noise. Combining rightly the ROADG with\nOptimal Weights Filter (OWF), we obtain a new method to deal with the mixed\nnoise, called Optimal Weights Mixed Filter (OWMF). The simulation results show\nthat the method is effective to remove the mixed noise.", 
    "link": "http://arxiv.org/pdf/1205.3999v1", 
    "arxiv-id": "1205.3999v1"
},{
    "category": "cs.CV", 
    "author": "R. Roselin", 
    "title": "Fuzzy - Rough Feature Selection With \u03a0- Membership Function For   Mammogram Classification", 
    "publish": "2012-05-19T15:19:38Z", 
    "summary": "Breast cancer is the second leading cause for death among women and it is\ndiagnosed with the help of mammograms. Oncologists are miserably failed in\nidentifying the micro calcification at the early stage with the help of the\nmammogram visually. In order to improve the performance of the breast cancer\nscreening, most of the researchers have proposed Computer Aided Diagnosis using\nimage processing. In this study mammograms are preprocessed and features are\nextracted, then the abnormality is identified through the classification. If\nall the extracted features are used, most of the cases are misidentified. Hence\nfeature selection procedure is sought. In this paper, Fuzzy-Rough feature\nselection with {\\pi} membership function is proposed. The selected features are\nused to classify the abnormalities with help of Ant-Miner and Weka tools. The\nexperimental analysis shows that the proposed method improves the mammograms\nclassification accuracy.", 
    "link": "http://arxiv.org/pdf/1205.4336v2", 
    "arxiv-id": "1205.4336v2"
},{
    "category": "cs.CV", 
    "author": "David W. Jacobs", 
    "title": "Spectral Graph Cut from a Filtering Point of View", 
    "publish": "2012-05-20T19:30:26Z", 
    "summary": "Spectral graph theory is well known and widely used in computer vision. In\nthis paper, we analyze image segmentation algorithms that are based on spectral\ngraph theory, e.g., normalized cut, and show that there is a natural connection\nbetween spectural graph theory based image segmentationand and edge preserving\nfiltering. Based on this connection we show that the normalized cut algorithm\nis equivalent to repeated iterations of bilateral filtering. Then, using this\nequivalence we present and implement a fast normalized cut algorithm for image\nsegmentation. Experiments show that our implementation can solve the original\noptimization problem in the normalized cut algorithm 10 to 100 times faster.\nFurthermore, we present a new algorithm called conditioned normalized cut for\nimage segmentation that can easily incorporate color image patches and\ndemonstrate how this segmentation problem can be solved with edge preserving\nfiltering.", 
    "link": "http://arxiv.org/pdf/1205.4450v3", 
    "arxiv-id": "1205.4450v3"
},{
    "category": "cs.CV", 
    "author": "Kannan Balakrishnan", 
    "title": "Gray Level Co-Occurrence Matrices: Generalisation and Some New Features", 
    "publish": "2012-05-22T08:00:45Z", 
    "summary": "Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques\nused for image texture analysis. In this paper we defined a new feature called\ntrace extracted from the GLCM and its implications in texture analysis are\ndiscussed in the context of Content Based Image Retrieval (CBIR). The\ntheoretical extension of GLCM to n-dimensional gray scale images are also\ndiscussed. The results indicate that trace features outperform Haralick\nfeatures when applied to CBIR.", 
    "link": "http://arxiv.org/pdf/1205.4831v1", 
    "arxiv-id": "1205.4831v1"
},{
    "category": "cs.CV", 
    "author": "S. Sreehari", 
    "title": "Neural Network Approach for Eye Detection", 
    "publish": "2012-05-23T05:14:20Z", 
    "summary": "Driving support systems, such as car navigation systems are becoming common\nand they support driver in several aspects. Non-intrusive method of detecting\nFatigue and drowsiness based on eye-blink count and eye directed instruction\ncontrolhelps the driver to prevent from collision caused by drowsy driving. Eye\ndetection and tracking under various conditions such as illumination,\nbackground, face alignment and facial expression makes the problem\ncomplex.Neural Network based algorithm is proposed in this paper to detect the\neyes efficiently. In the proposed algorithm, first the neural Network is\ntrained to reject the non-eye regionbased on images with features of eyes and\nthe images with features of non-eye using Gabor filter and Support Vector\nMachines to reduce the dimension and classify efficiently. In the algorithm,\nfirst the face is segmented using L*a*btransform color space, then eyes are\ndetected using HSV and Neural Network approach. The algorithm is tested on\nnearly 100 images of different persons under different conditions and the\nresults are satisfactory with success rate of 98%.The Neural Network is trained\nwith 50 non-eye images and 50 eye images with different angles using Gabor\nfilter. This paper is a part of research work on \"Development of Non-Intrusive\nsystem for real-time Monitoring and Prediction of Driver Fatigue and\ndrowsiness\" project sponsored by Department of Science & Technology, Govt. of\nIndia, New Delhi at Vignan Institute of Technology and Sciences, Vignan Hills,\nHyderabad.", 
    "link": "http://arxiv.org/pdf/1205.5097v1", 
    "arxiv-id": "1205.5097v1"
},{
    "category": "cs.CV", 
    "author": "Zhouchen Lin", 
    "title": "Linearized Alternating Direction Method with Adaptive Penalty and Warm   Starts for Fast Solving Transform Invariant Low-Rank Textures", 
    "publish": "2012-05-24T07:16:14Z", 
    "summary": "Transform Invariant Low-rank Textures (TILT) is a novel and powerful tool\nthat can effectively rectify a rich class of low-rank textures in 3D scenes\nfrom 2D images despite significant deformation and corruption. The existing\nalgorithm for solving TILT is based on the alternating direction method (ADM).\nIt suffers from high computational cost and is not theoretically guaranteed to\nconverge to a correct solution. In this paper, we propose a novel algorithm to\nspeed up solving TILT, with guaranteed convergence. Our method is based on the\nrecently proposed linearized alternating direction method with adaptive penalty\n(LADMAP). To further reduce computation, warm starts are also introduced to\ninitialize the variables better and cut the cost on singular value\ndecomposition. Extensive experimental results on both synthetic and real data\ndemonstrate that this new algorithm works much more efficiently and robustly\nthan the existing algorithm. It could be at least five times faster than the\nprevious method.", 
    "link": "http://arxiv.org/pdf/1205.5351v2", 
    "arxiv-id": "1205.5351v2"
},{
    "category": "cs.CV", 
    "author": "Jon Sporring", 
    "title": "Locally Orderless Registration", 
    "publish": "2012-05-24T12:56:45Z", 
    "summary": "Image registration is an important tool for medical image analysis and is\nused to bring images into the same reference frame by warping the coordinate\nfield of one image, such that some similarity measure is minimized. We study\nsimilarity in image registration in the context of Locally Orderless Images\n(LOI), which is the natural way to study density estimates and reveals the 3\nfundamental scales: the measurement scale, the intensity scale, and the\nintegration scale.\n  This paper has three main contributions: Firstly, we rephrase a large set of\npopular similarity measures into a common framework, which we refer to as\nLocally Orderless Registration, and which makes full use of the features of\nlocal histograms. Secondly, we extend the theoretical understanding of the\nlocal histograms. Thirdly, we use our framework to compare two state-of-the-art\nintensity density estimators for image registration: The Parzen Window (PW) and\nthe Generalized Partial Volume (GPV), and we demonstrate their differences on a\npopular similarity measure, Normalized Mutual Information (NMI).\n  We conclude, that complicated similarity measures such as NMI may be\nevaluated almost as fast as simple measures such as Sum of Squared Distances\n(SSD) regardless of the choice of PW and GPV. Also, GPV is an asymmetric\nmeasure, and PW is our preferred choice.", 
    "link": "http://arxiv.org/pdf/1205.5425v1", 
    "arxiv-id": "1205.5425v1"
},{
    "category": "cs.CV", 
    "author": "Thomas Schoenemann", 
    "title": "Generalized sequential tree-reweighted message passing", 
    "publish": "2012-05-29T13:06:58Z", 
    "summary": "This paper addresses the problem of approximate MAP-MRF inference in general\ngraphical models. Following [36], we consider a family of linear programming\nrelaxations of the problem where each relaxation is specified by a set of\nnested pairs of factors for which the marginalization constraint needs to be\nenforced. We develop a generalization of the TRW-S algorithm [9] for this\nproblem, where we use a decomposition into junction chains, monotonic w.r.t.\nsome ordering on the nodes. This generalizes the monotonic chains in [9] in a\nnatural way. We also show how to deal with nested factors in an efficient way.\nExperiments show an improvement over min-sum diffusion, MPLP and subgradient\nascent algorithms on a number of computer vision and natural language\nprocessing problems.", 
    "link": "http://arxiv.org/pdf/1205.6352v4", 
    "arxiv-id": "1205.6352v4"
},{
    "category": "cs.CV", 
    "author": "Wang Donghui", 
    "title": "A Brief Summary of Dictionary Learning Based Approach for Classification", 
    "publish": "2012-05-29T15:28:54Z", 
    "summary": "This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches.", 
    "link": "http://arxiv.org/pdf/1205.6391v2", 
    "arxiv-id": "1205.6391v2"
},{
    "category": "cs.CV", 
    "author": "Soumajit Pramanik", 
    "title": "An Unsupervised Dynamic Image Segmentation using Fuzzy Hopfield Neural   Network based Genetic Algorithm", 
    "publish": "2012-05-30T08:10:59Z", 
    "summary": "This paper proposes a Genetic Algorithm based segmentation method that can\nautomatically segment gray-scale images. The proposed method mainly consists of\nspatial unsupervised grayscale image segmentation that divides an image into\nregions. The aim of this algorithm is to produce precise segmentation of images\nusing intensity information along with neighborhood relationships. In this\npaper, Fuzzy Hopfield Neural Network (FHNN) clustering helps in generating the\npopulation of Genetic algorithm which there by automatically segments the\nimage. This technique is a powerful method for image segmentation and works for\nboth single and multiple-feature data with spatial information. Validity index\nhas been utilized for introducing a robust technique for finding the optimum\nnumber of components in an image. Experimental results shown that the algorithm\ngenerates good quality segmented image.", 
    "link": "http://arxiv.org/pdf/1205.6572v1", 
    "arxiv-id": "1205.6572v1"
},{
    "category": "cs.CV", 
    "author": "Tina Kapur", 
    "title": "Template-Cut: A Pattern-Based Segmentation Paradigm", 
    "publish": "2012-05-30T09:44:43Z", 
    "summary": "We present a scale-invariant, template-based segmentation paradigm that sets\nup a graph and performs a graph cut to separate an object from the background.\nTypically graph-based schemes distribute the nodes of the graph uniformly and\nequidistantly on the image, and use a regularizer to bias the cut towards a\nparticular shape. The strategy of uniform and equidistant nodes does not allow\nthe cut to prefer more complex structures, especially when areas of the object\nare indistinguishable from the background. We propose a solution by introducing\nthe concept of a \"template shape\" of the target object in which the nodes are\nsampled non-uniformly and non-equidistantly on the image. We evaluate it on\n2D-images where the object's textures and backgrounds are similar, and large\nareas of the object have the same gray level appearance as the background. We\nalso evaluate it in 3D on 60 brain tumor datasets for neurosurgical planning\npurposes.", 
    "link": "http://arxiv.org/pdf/1205.6605v1", 
    "arxiv-id": "1205.6605v1"
},{
    "category": "cs.CV", 
    "author": "Dr. S Muttan", 
    "title": "Fingerprint Gender Classification using Wavelet Transform and Singular   Value Decomposition", 
    "publish": "2012-05-30T16:26:23Z", 
    "summary": "A novel method of gender Classification from fingerprint is proposed based on\ndiscrete wavelet transform (DWT) and singular value decomposition (SVD). The\nclassification is achieved by extracting the energy computed from all the\nsub-bands of DWT combined with the spatial features of non-zero singular values\nobtained from the SVD of fingerprint images. K nearest neighbor (KNN) used as a\nclassifier. This method is experimented with the internal database of 3570\nfingerprints finger prints in which 1980 were male fingerprints and 1590 were\nfemale fingerprints. Finger-wise gender classification is achieved which is\n94.32% for the left hand little fingers of female persons and 95.46% for the\nleft hand index finger of male persons. Gender classification for any finger of\nmale persons tested is attained as 91.67% and 84.69% for female persons\nrespectively. Overall classification rate is 88.28% has been achieved.", 
    "link": "http://arxiv.org/pdf/1205.6745v1", 
    "arxiv-id": "1205.6745v1"
},{
    "category": "cs.CV", 
    "author": "Hong Yan", 
    "title": "Rapid Feature Extraction for Optical Character Recognition", 
    "publish": "2012-06-01T16:20:41Z", 
    "summary": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection.", 
    "link": "http://arxiv.org/pdf/1206.0238v1", 
    "arxiv-id": "1206.0238v1"
},{
    "category": "cs.CV", 
    "author": "Sahar Bo-saeed", 
    "title": "Optimizing Face Recognition Using PCA", 
    "publish": "2012-06-07T14:51:54Z", 
    "summary": "Principle Component Analysis PCA is a classical feature extraction and data\nrepresentation technique widely used in pattern recognition. It is one of the\nmost successful techniques in face recognition. But it has drawback of high\ncomputational especially for big size database. This paper conducts a study to\noptimize the time complexity of PCA (eigenfaces) that does not affects the\nrecognition performance. The authors minimize the participated eigenvectors\nwhich consequently decreases the computational time. A comparison is done to\ncompare the differences between the recognition time in the original algorithm\nand in the enhanced algorithm. The performance of the original and the enhanced\nproposed algorithm is tested on face94 face database. Experimental results show\nthat the recognition time is reduced by 35% by applying our proposed enhanced\nalgorithm. DET Curves are used to illustrate the experimental results.", 
    "link": "http://arxiv.org/pdf/1206.1515v1", 
    "arxiv-id": "1206.1515v1"
},{
    "category": "cs.CV", 
    "author": "Hanadi H. Al-Fraidi", 
    "title": "Off-Line Arabic Handwriting Character Recognition Using Word   Segmentation", 
    "publish": "2012-06-07T15:07:08Z", 
    "summary": "The ultimate aim of handwriting recognition is to make computers able to read\nand/or authenticate human written texts, with a performance comparable to or\neven better than that of humans. Reading means that the computer is given a\npiece of handwriting and it provides the electronic transcription of that (e.g.\nin ASCII format). Two types of handwriting: on-line and offline. The most\nimportant purpose of off-line handwriting recognition is in protection systems\nand authentication. Arabic Handwriting scripts are much more complicated in\ncomparison to Latin scripts. This paper introduces a simple and novel\nmethodology to authenticate Arabic handwriting characters. Reaching our aim, we\nbuilt our own character database. The research methodology depends on two\nstages: The first is character extraction where preprocessing the word and then\napply segmentation process to obtain the character. The second is the character\nrecognition by matching the characters comprising the word with the letters in\nthe database. Our results ensure character recognition with 81%. We eliminate\nFAR by using similarity percent between 45-55%. Our research is coded using\nMATLAB.", 
    "link": "http://arxiv.org/pdf/1206.1518v1", 
    "arxiv-id": "1206.1518v1"
},{
    "category": "cs.CV", 
    "author": "V. Jawahar Senthil Kumar", 
    "title": "Performance Analysis of Unsymmetrical trimmed median as detector on   image noises and its Fpga implementation", 
    "publish": "2012-06-07T16:49:36Z", 
    "summary": "This Paper Analyze the performance of Unsymmetrical trimmed median, which is\nused as detector for the detection of impulse noise, Gaussian noise and mixed\nnoise is proposed. The proposed algorithm uses a fixed 3x3 window for the\nincreasing noise densities. The pixels in the current window are arranged in\nsorting order using a improved snake like sorting algorithm with reduced\ncomparator. The processed pixel is checked for the occurrence of outliers, if\nthe absolute difference between processed pixels is greater than fixed\nthreshold. Under high noise densities the processed pixel is also noisy hence\nthe median is checked using the above procedure. if found true then the pixel\nis considered as noisy hence the corrupted pixel is replaced by the median of\nthe current processing window. If median is also noisy then replace the\ncorrupted pixel with unsymmetrical trimmed median else if the pixel is termed\nuncorrupted and left unaltered. The proposed algorithm (PA) is tested on\nvarying detail images for various noises. The proposed algorithm effectively\nremoves the high density fixed value impulse noise, low density random valued\nimpulse noise, low density Gaussian noise and lower proportion of mixed noise.\nThe proposed algorithm is targeted on Xc3e5000-5fg900 FPGA using Xilinx 7.1\ncompiler version which requires less number of slices, optimum speed and low\npower when compared to the other median finding architectures.", 
    "link": "http://arxiv.org/pdf/1206.1552v1", 
    "arxiv-id": "1206.1552v1"
},{
    "category": "cs.CV", 
    "author": "Goutam Saha", 
    "title": "A Novel Windowing Technique for Efficient Computation of MFCC for   Speaker Recognition", 
    "publish": "2012-06-12T04:23:38Z", 
    "summary": "In this paper, we propose a novel family of windowing technique to compute\nMel Frequency Cepstral Coefficient (MFCC) for automatic speaker recognition\nfrom speech. The proposed method is based on fundamental property of discrete\ntime Fourier transform (DTFT) related to differentiation in frequency domain.\nClassical windowing scheme such as Hamming window is modified to obtain\nderivatives of discrete time Fourier transform coefficients. It has been\nmathematically shown that the slope and phase of power spectrum are inherently\nincorporated in newly computed cepstrum. Speaker recognition systems based on\nour proposed family of window functions are shown to attain substantial and\nconsistent performance improvement over baseline single tapered Hamming window\nas well as recently proposed multitaper windowing technique.", 
    "link": "http://arxiv.org/pdf/1206.2437v1", 
    "arxiv-id": "1206.2437v1"
},{
    "category": "cs.CV", 
    "author": "Rabab K. Ward", 
    "title": "Image Similarity Using Sparse Representation and Compression Distance", 
    "publish": "2012-06-12T19:30:57Z", 
    "summary": "A new line of research uses compression methods to measure the similarity\nbetween signals. Two signals are considered similar if one can be compressed\nsignificantly when the information of the other is known. The existing\ncompression-based similarity methods, although successful in the discrete one\ndimensional domain, do not work well in the context of images. This paper\nproposes a sparse representation-based approach to encode the information\ncontent of an image using information from the other image, and uses the\ncompactness (sparsity) of the representation as a measure of its\ncompressibility (how much can the image be compressed) with respect to the\nother image. The more sparse the representation of an image, the better it can\nbe compressed and the more it is similar to the other image. The efficacy of\nthe proposed measure is demonstrated through the high accuracies achieved in\nimage clustering, retrieval and classification.", 
    "link": "http://arxiv.org/pdf/1206.2627v2", 
    "arxiv-id": "1206.2627v2"
},{
    "category": "cs.CV", 
    "author": "Laurent Najman", 
    "title": "An efficient hierarchical graph based image segmentation", 
    "publish": "2012-06-13T13:49:23Z", 
    "summary": "Hierarchical image segmentation provides region-oriented scalespace, i.e., a\nset of image segmentations at different detail levels in which the\nsegmentations at finer levels are nested with respect to those at coarser\nlevels. Most image segmentation algorithms, such as region merging algorithms,\nrely on a criterion for merging that does not lead to a hierarchy, and for\nwhich the tuning of the parameters can be difficult. In this work, we propose a\nhierarchical graph based image segmentation relying on a criterion popularized\nby Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic\nimages, showing efficiency, ease of use, and robustness of our method.", 
    "link": "http://arxiv.org/pdf/1206.2807v1", 
    "arxiv-id": "1206.2807v1"
},{
    "category": "cs.CV", 
    "author": "Saumil Srivastava", 
    "title": "Real time facial expression recognition using a novel method", 
    "publish": "2012-05-08T06:54:41Z", 
    "summary": "This paper discusses a novel method for Facial Expression Recognition System\nwhich performs facial expression analysis in a near real time from a live web\ncam feed. Primary objectives were to get results in a near real time with light\ninvariant, person independent and pose invariant way. The system is composed of\ntwo different entities trainer and evaluator. Each frame of video feed is\npassed through a series of steps including haar classifiers, skin detection,\nfeature extraction, feature points tracking, creating a learned Support Vector\nMachine model to classify emotions to achieve a tradeoff between accuracy and\nresult rate. A processing time of 100-120 ms per 10 frames was achieved with\naccuracy of around 60%. We measure our accuracy in terms of variety of\ninteraction and classification scenarios. We conclude by discussing relevance\nof our work to human computer interaction and exploring further measures that\ncan be taken.", 
    "link": "http://arxiv.org/pdf/1206.3559v1", 
    "arxiv-id": "1206.3559v1"
},{
    "category": "cs.CV", 
    "author": "R. N. Kvetnyy", 
    "title": "Blind PSF estimation and methods of deconvolution optimization", 
    "publish": "2012-06-15T20:51:39Z", 
    "summary": "We have shown that the left side null space of the autoregression (AR) matrix\noperator is the lexicographical presentation of the point spread function (PSF)\non condition the AR parameters are common for original and blurred images. The\nmethod of inverse PSF evaluation with regularization functional as the function\nof surface area is offered. The inverse PSF was used for primary image\nestimation. Two methods of original image estimate optimization were designed\nbasing on maximum entropy generalization of sought and blurred images\nconditional probability density and regularization. The first method uses\nbalanced variations of convolution and deconvolution transforms to obtaining\niterative schema of image optimization. The variations balance was defined by\ndynamic regularization basing on condition of iteration process convergence.\nThe regularization has dynamic character because depends on current and\nprevious image estimate variations. The second method implements the\nregularization of deconvolution optimization in curved space with metric\ndefined on image estimate surface. It is basing on target functional invariance\nto fluctuations of optimal argument value. The given iterative schemas have\nfaster convergence in comparison with known ones, so they can be used for\nreconstruction of high resolution images series in real time.", 
    "link": "http://arxiv.org/pdf/1206.3594v1", 
    "arxiv-id": "1206.3594v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "Portraits of Julius Caesar: a proposal for 3D analysis", 
    "publish": "2012-06-21T13:14:59Z", 
    "summary": "Here I suggest the use of a 3D scanning and rendering to create some virtual\ncopies of ancient artifacts to study and compare them. In particular, this\napproach could be interesting for some roman marble busts, two of which are\nportraits of Julius Caesar, and the third is a realistic portrait of a man\nrecently found at Arles, France. The comparison of some images indicates that a\nthree-dimensional visualization is necessary.", 
    "link": "http://arxiv.org/pdf/1206.4866v1", 
    "arxiv-id": "1206.4866v1"
},{
    "category": "cs.CV", 
    "author": "Fran\u00e7ois Bremond", 
    "title": "A generic framework for video understanding applied to group behavior   recognition", 
    "publish": "2012-06-22T06:24:30Z", 
    "summary": "This paper presents an approach to detect and track groups of people in\nvideo-surveillance applications, and to automatically recognize their behavior.\nThis method keeps track of individuals moving together by maintaining a spacial\nand temporal group coherence. First, people are individually detected and\ntracked. Second, their trajectories are analyzed over a temporal window and\nclustered using the Mean-Shift algorithm. A coherence value describes how well\na set of people can be described as a group. Furthermore, we propose a formal\nevent description language. The group events recognition approach is\nsuccessfully validated on 4 camera views from 3 datasets: an airport, a subway,\na shopping center corridor and an entrance hall.", 
    "link": "http://arxiv.org/pdf/1206.5065v1", 
    "arxiv-id": "1206.5065v1"
},{
    "category": "cs.CV", 
    "author": "Ron Parr", 
    "title": "Efficient Selection of Disambiguating Actions for Stereo Vision", 
    "publish": "2012-06-27T16:31:21Z", 
    "summary": "In many domains that involve the use of sensors, such as robotics or sensor\nnetworks, there are opportunities to use some form of active sensing to\ndisambiguate data from noisy or unreliable sensors. These disambiguating\nactions typically take time and expend energy. One way to choose the next\ndisambiguating action is to select the action with the greatest expected\nentropy reduction, or information gain. In this work, we consider active\nsensing in aid of stereo vision for robotics. Stereo vision is a powerful\nsensing technique for mobile robots, but it can fail in scenes that lack strong\ntexture. In such cases, a structured light source, such as vertical laser line\ncan be used for disambiguation. By treating the stereo matching problem as a\nspecially structured HMM-like graphical model, we demonstrate that for a scan\nline with n columns and maximum stereo disparity d, the entropy minimizing aim\npoint for the laser can be selected in O(nd) time - cost no greater than the\nstereo algorithm itself. In contrast, a typical HMM formulation would suggest\nat least O(nd^2) time for the entropy calculation alone.", 
    "link": "http://arxiv.org/pdf/1206.6878v1", 
    "arxiv-id": "1206.6878v1"
},{
    "category": "cs.CV", 
    "author": "G. Geethu Lakshmi", 
    "title": "Anatomical Structure Segmentation in Liver MRI Images", 
    "publish": "2012-07-03T14:32:20Z", 
    "summary": "Segmentation of medical images is a challenging task owing to their\ncomplexity. A standard segmentation problem within Magnetic Resonance Imaging\n(MRI) is the task of labeling voxels according to their tissue type. Image\nsegmentation provides volumetric quantification of liver area and thus helps in\nthe diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice,\nHemochromatosis etc.This work deals with comparison of segmentation by applying\nLevel Set Method,Fuzzy Level Information C-Means Clustering Algorithm and\nGradient Vector Flow Snake Algorithm.The results are compared using the\nparameters such as Number of pixels correctly classified, and percentage of\narea segmented.", 
    "link": "http://arxiv.org/pdf/1207.0805v3", 
    "arxiv-id": "1207.0805v3"
},{
    "category": "cs.CV", 
    "author": "Cheng-Lin Liu", 
    "title": "A Fast Projected Fixed-Point Algorithm for Large Graph Matching", 
    "publish": "2012-07-03T18:20:25Z", 
    "summary": "We propose a fast approximate algorithm for large graph matching. A new\nprojected fixed-point method is defined and a new doubly stochastic projection\nis adopted to derive the algorithm. Previous graph matching algorithms suffer\nfrom high computational complexity and therefore do not have good scalability\nwith respect to graph size. For matching two weighted graphs of $n$ nodes, our\nalgorithm has time complexity only $O(n^3)$ per iteration and space complexity\n$O(n^2)$. In addition to its scalability, our algorithm is easy to implement,\nrobust, and able to match undirected weighted attributed graphs of different\nsizes. While the convergence rate of previous iterative graph matching\nalgorithms is unknown, our algorithm is theoretically guaranteed to converge at\na linear rate. Extensive experiments on large synthetic and real graphs (more\nthan 1,000 nodes) were conducted to evaluate the performance of various\nalgorithms. Results show that in most cases our proposed algorithm achieves\nbetter performance than previous state-of-the-art algorithms in terms of both\nspeed and accuracy in large graph matching. In particular, with high accuracy,\nour algorithm takes only a few seconds (in a PC) to match two graphs of 1,000\nnodes.", 
    "link": "http://arxiv.org/pdf/1207.1114v3", 
    "arxiv-id": "1207.1114v3"
},{
    "category": "cs.CV", 
    "author": "Farshad Tajeripour", 
    "title": "An Innovative Skin Detection Approach Using Color Based Image Retrieval   Technique", 
    "publish": "2012-07-06T08:04:38Z", 
    "summary": "From The late 90th, \"Skin Detection\" becomes one of the major problems in\nimage processing. If \"Skin Detection\" will be done in high accuracy, it can be\nused in many cases as face recognition, Human Tracking and etc. Until now so\nmany methods were presented for solving this problem. In most of these methods,\ncolor space was used to extract feature vector for classifying pixels, but the\nmost of them have not good accuracy in detecting types of skin. The proposed\napproach in this paper is based on \"Color based image retrieval\" (CBIR)\ntechnique. In this method, first by means of CBIR method and image tiling and\nconsidering the relation between pixel and its neighbors, a feature vector\nwould be defined and then with using a training step, detecting the skin in the\ntest stage. The result shows that the presenting approach, in addition to its\nhigh accuracy in detecting type of skin, has no sensitivity to illumination\nintensity and moving face orientation.", 
    "link": "http://arxiv.org/pdf/1207.1551v1", 
    "arxiv-id": "1207.1551v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Analysis of Multi-Scale Fractal Dimension to Classify Human Motion", 
    "publish": "2012-07-06T15:10:49Z", 
    "summary": "In recent years there has been considerable interest in human action\nrecognition. Several approaches have been developed in order to enhance the\nautomatic video analysis. Although some developments have been achieved by the\ncomputer vision community, the properly classification of human motion is still\na hard and challenging task. The objective of this study is to investigate the\nuse of 3D multi-scale fractal dimension to recognize motion patterns in videos.\nIn order to develop a robust strategy for human motion classification, we\nproposed a method where the Fourier transform is used to calculate the\nderivative in which all data points are deemed. Our results shown that\ndifferent accuracy rates can be found for different databases. We believe that\nin specific applications our results are the first step to develop an automatic\nmonitoring system, which can be applied in security systems, traffic\nmonitoring, biology, physical therapy, cardiovascular disease among many\nothers.", 
    "link": "http://arxiv.org/pdf/1207.1649v1", 
    "arxiv-id": "1207.1649v1"
},{
    "category": "cs.CV", 
    "author": "Ali A. Al-Zaky", 
    "title": "Spatial And Spectral Quality Evaluation Based On Edges Regions Of   Satellite Image Fusion", 
    "publish": "2012-07-08T23:06:38Z", 
    "summary": "The Quality of image fusion is an essential determinant of the value of\nprocessing images fusion for many applications. Spatial and spectral qualities\nare the two important indexes that used to evaluate the quality of any fused\nimage. However, the jury is still out of fused image's benefits if it compared\nwith its original images. In addition, there is a lack of measures for\nassessing the objective quality of the spatial resolution for the fusion\nmethods. Therefore, an objective quality of the spatial resolution assessment\nfor fusion images is required. Most important details of the image are in edges\nregions, but most standards of image estimation do not depend upon specifying\nthe edges in the image and measuring their edges. However, they depend upon the\ngeneral estimation or estimating the uniform region, so this study deals with\nnew method proposed to estimate the spatial resolution by Contrast Statistical\nAnalysis (CSA) depending upon calculating the contrast of the edge, non edge\nregions and the rate for the edges regions. Specifying the edges in the image\nis made by using Soble operator with different threshold values. In addition,\nestimating the color distortion added by image fusion based on Histogram\nAnalysis of the edge brightness values of all RGB-color bands and Lcomponent.", 
    "link": "http://arxiv.org/pdf/1207.1922v1", 
    "arxiv-id": "1207.1922v1"
},{
    "category": "cs.CV", 
    "author": "Ronald Umble", 
    "title": "Cups Products in Z2-Cohomology of 3D Polyhedral Complexes", 
    "publish": "2012-07-10T13:40:40Z", 
    "summary": "Let $I=(\\mathbb{Z}^3,26,6,B)$ be a 3D digital image, let $Q(I)$ be the\nassociated cubical complex and let $\\partial Q(I)$ be the subcomplex of $Q(I)$\nwhose maximal cells are the quadrangles of $Q(I)$ shared by a voxel of $B$ in\nthe foreground -- the object under study -- and by a voxel of\n$\\mathbb{Z}^3\\smallsetminus B$ in the background -- the ambient space. We show\nhow to simplify the combinatorial structure of $\\partial Q(I)$ and obtain a 3D\npolyhedral complex $P(I)$ homeomorphic to $\\partial Q(I)$ but with fewer cells.\nWe introduce an algorithm that computes cup products on\n$H^*(P(I);\\mathbb{Z}_2)$ directly from the combinatorics. The computational\nmethod introduced here can be effectively applied to any polyhedral complex\nembedded in $\\mathbb{R}^3$.", 
    "link": "http://arxiv.org/pdf/1207.2346v3", 
    "arxiv-id": "1207.2346v3"
},{
    "category": "cs.CV", 
    "author": "Abdelaziz Elfazziki", 
    "title": "A Multi-Agents Architecture to Learn Vision Operators and their   Parameters", 
    "publish": "2012-07-10T17:56:00Z", 
    "summary": "In a vision system, every task needs that the operators to apply should be\n{\\guillemotleft} well chosen {\\guillemotright} and their parameters should be\nalso {\\guillemotleft} well adjusted {\\guillemotright}. The diversity of\noperators and the multitude of their parameters constitute a big challenge for\nusers. As it is very difficult to make the {\\guillemotleft} right\n{\\guillemotright} choice, lack of a specific rule, many disadvantages appear\nand affect the computation time and especially the quality of results. In this\npaper we present a multi-agent architecture to learn the best operators to\napply and their best parameters for a class of images. Our architecture\nconsists of three types of agents: User Agent, Operator Agent and Parameter\nAgent. The User Agent determines the phases of treatment, a library of\noperators and the possible values of their parameters. The Operator Agent\nconstructs all possible combinations of operators and the Parameter Agent, the\ncore of the architecture, adjusts the parameters of each combination by\ntreating a large number of images. Through the reinforcement learning\nmechanism, our architecture does not consider only the system opportunities but\nalso the user preferences.", 
    "link": "http://arxiv.org/pdf/1207.2426v1", 
    "arxiv-id": "1207.2426v1"
},{
    "category": "cs.CV", 
    "author": "Amrita Biswas", 
    "title": "Face Recognition Algorithms based on Transformed Shape Features", 
    "publish": "2012-07-11T03:45:18Z", 
    "summary": "Human face recognition is, indeed, a challenging task, especially under the\nillumination and pose variations. We examine in the present paper effectiveness\nof two simple algorithms using coiflet packet and Radon transforms to recognize\nhuman faces from some databases of still gray level images, under the\nenvironment of illumination and pose variations. Both the algorithms convert\n2-D gray level training face images into their respective depth maps or\nphysical shape which are subsequently transformed by Coiflet packet and Radon\ntransforms to compute energy for feature extraction. Experiments show that such\ntransformed shape features are robust to illumination and pose variations. With\nthe features extracted, training classes are optimally separated through linear\ndiscriminant analysis (LDA), while classification for test face images is made\nthrough a k-NN classifier, based on L1 norm and Mahalanobis distance measures.\nProposed algorithms are then tested on face images that differ in\nillumination,expression or pose separately, obtained from three\ndatabases,namely, ORL, Yale and Essex-Grimace databases. Results, so obtained,\nare compared with two different existing algorithms.Performance using\nDaubechies wavelets is also examined. It is seen that the proposed Coiflet\npacket and Radon transform based algorithms have significant performance,\nespecially under different illumination conditions and pose variation.\nComparison shows the proposed algorithms are superior.", 
    "link": "http://arxiv.org/pdf/1207.2537v1", 
    "arxiv-id": "1207.2537v1"
},{
    "category": "cs.CV", 
    "author": "Mohammad Reza Mahzoun", 
    "title": "A Novel Approach Coloured Object Tracker with Adaptive Model and   Bandwidth using Mean Shift Algorithm", 
    "publish": "2012-07-11T11:29:36Z", 
    "summary": "The traditional color-based mean-shift tracking algorithm is popular among\ntracking methods due to its simple and efficient procedure, however, the lack\nof dynamism in its target model makes it unsuitable for tracking objects which\nhave changes in their sizes and shapes. In this paper, we propose a fast novel\nthreephase colored object tracker algorithm based on mean shift idea while\nutilizing adaptive model. The proposed method can improve the mentioned\nweaknesses of the original mean-shift algorithm. The experimental results show\nthat the new method is feasible, robust and has acceptable speed in comparison\nwith other algorithms.15 page,", 
    "link": "http://arxiv.org/pdf/1207.2602v1", 
    "arxiv-id": "1207.2602v1"
},{
    "category": "cs.CV", 
    "author": "Zeno Geradts", 
    "title": "Camera identification by grouping images from database, based on shared   noise patterns", 
    "publish": "2012-07-11T13:58:35Z", 
    "summary": "Previous research showed that camera specific noise patterns, so-called\nPRNU-patterns, are extracted from images and related images could be found. In\nthis particular research the focus is on grouping images from a database, based\non a shared noise pattern as an identification method for cameras. Using the\nmethod as described in this article, groups of images, created using the same\ncamera, could be linked from a large database of images. Using MATLAB\nprogramming, relevant image noise patterns are extracted from images much\nquicker than common methods by the use of faster noise extraction filters and\nimprovements to reduce the calculation costs. Relating noise patterns, with a\ncorrelation above a certain threshold value, can quickly be matched. Hereby,\nfrom a database of images, groups of relating images could be linked and the\nmethod could be used to scan a large number of images for suspect noise\npatterns.", 
    "link": "http://arxiv.org/pdf/1207.2641v2", 
    "arxiv-id": "1207.2641v2"
},{
    "category": "cs.CV", 
    "author": "Min Jun Kim", 
    "title": "Tracking Tetrahymena Pyriformis Cells using Decision Trees", 
    "publish": "2012-07-13T01:22:04Z", 
    "summary": "Matching cells over time has long been the most difficult step in cell\ntracking. In this paper, we approach this problem by recasting it as a\nclassification problem. We construct a feature set for each cell, and compute a\nfeature difference vector between a cell in the current frame and a cell in a\nprevious frame. Then we determine whether the two cells represent the same cell\nover time by training decision trees as our binary classifiers. With the output\nof decision trees, we are able to formulate an assignment problem for our cell\nassociation task and solve it using a modified version of the Hungarian\nalgorithm.", 
    "link": "http://arxiv.org/pdf/1207.3127v1", 
    "arxiv-id": "1207.3127v1"
},{
    "category": "cs.CV", 
    "author": "Weiming Hu", 
    "title": "Color Constancy based on Image Similarity via Bilayer Sparse Coding", 
    "publish": "2012-07-13T04:46:19Z", 
    "summary": "Computational color constancy is a very important topic in computer vision\nand has attracted many researchers' attention. Recently, lots of research has\nshown the effects of high level visual content information for illumination\nestimation. However, all of these existing methods are essentially\ncombinational strategies in which image's content analysis is only used to\nguide the combination or selection from a variety of individual illumination\nestimation methods. In this paper, we propose a novel bilayer sparse coding\nmodel for illumination estimation that considers image similarity in terms of\nboth low level color distribution and high level image scene content\nsimultaneously. For the purpose, the image's scene content information is\nintegrated with its color distribution to obtain optimal illumination\nestimation model. The experimental results on two real-world image sets show\nthat our algorithm is superior to other prevailing illumination estimation\nmethods, even better than combinational methods.", 
    "link": "http://arxiv.org/pdf/1207.3142v2", 
    "arxiv-id": "1207.3142v2"
},{
    "category": "cs.CV", 
    "author": "Glauber T. Silva", 
    "title": "Deconvolution of vibroacoustic images using a simulation model based on   a three dimensional point spread function", 
    "publish": "2012-07-13T21:37:04Z", 
    "summary": "Vibro-acoustography (VA) is a medical imaging method based on the\ndifference-frequency generation produced by the mixture of two focused\nultrasound beams. VA has been applied to different problems in medical imaging\nsuch as imaging bones, microcalcifications in the breast, mass lesions, and\ncalcified arteries. The obtained images may have a resolution of 0.7--0.8 mm.\nCurrent VA systems based on confocal or linear array transducers generate\nC-scan images at the beam focal plane. Images on the axial plane are also\npossible, however the system resolution along depth worsens when compared to\nthe lateral one. Typical axial resolution is about 1.0 cm. Furthermore, the\nelevation resolution of linear array systems is larger than that in lateral\ndirection. This asymmetry degrades C-scan images obtained using linear arrays.\nThe purpose of this article is to study VA image restoration based on a 3D\npoint spread function (PSF) using classical deconvolution algorithms: Wiener,\nconstrained least-squares (CLSs), and geometric mean filters. To assess the\nfilters' performance, we use an image quality index that accounts for\ncorrelation loss, luminance and contrast distortion. Results for simulated VA\nimages show that the quality index achieved with the Wiener filter is 0.9 (1\nindicates perfect restoration). This filter yielded the best result in\ncomparison with the other ones. Moreover, the deconvolution algorithms were\napplied to an experimental VA image of a phantom composed of three stretched\n0.5 mm wires. Experiments were performed using transducer driven at two\nfrequencies, 3075 kHz and 3125 kHz, which resulted in the difference-frequency\nof 50 kHz. Restorations with the theoretical line spread function (LSF) did not\nrecover sufficient information to identify the wires in the images. However,\nusing an estimated LSF the obtained results displayed enough information to\nspot the wires in the images.", 
    "link": "http://arxiv.org/pdf/1207.3370v1", 
    "arxiv-id": "1207.3370v1"
},{
    "category": "cs.CV", 
    "author": "Quan Wang", 
    "title": "HMRF-EM-image: Implementation of the Hidden Markov Random Field Model   and its Expectation-Maximization Algorithm", 
    "publish": "2012-07-15T14:50:17Z", 
    "summary": "In this project, we study the hidden Markov random field (HMRF) model and its\nexpectation-maximization (EM) algorithm. We implement a MATLAB toolbox named\nHMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This\ntoolbox also implements edge-prior-preserving image segmentation, and can be\neasily reconfigured for other problems, such as 3D image segmentation.", 
    "link": "http://arxiv.org/pdf/1207.3510v2", 
    "arxiv-id": "1207.3510v2"
},{
    "category": "cs.CV", 
    "author": "Quan Wang", 
    "title": "Kernel Principal Component Analysis and its Applications in Face   Recognition and Active Shape Models", 
    "publish": "2012-07-15T20:28:26Z", 
    "summary": "Principal component analysis (PCA) is a popular tool for linear\ndimensionality reduction and feature extraction. Kernel PCA is the nonlinear\nform of PCA, which better exploits the complicated spatial structure of\nhigh-dimensional features. In this paper, we first review the basic ideas of\nPCA and kernel PCA. Then we focus on the reconstruction of pre-images for\nkernel PCA. We also give an introduction on how PCA is used in active shape\nmodels (ASMs), and discuss how kernel PCA can be applied to improve traditional\nASMs. Then we show some experimental results to compare the performance of\nkernel PCA and standard PCA for classification problems. We also implement the\nkernel PCA-based ASMs, and use it to construct human face models.", 
    "link": "http://arxiv.org/pdf/1207.3538v3", 
    "arxiv-id": "1207.3538v3"
},{
    "category": "cs.CV", 
    "author": "K. P. Soman", 
    "title": "Hierarchical Approach for Total Variation Digital Image Inpainting", 
    "publish": "2012-07-16T04:51:07Z", 
    "summary": "The art of recovering an image from damage in an undetectable form is known\nas inpainting. The manual work of inpainting is most often a very time\nconsuming process. Due to digitalization of this technique, it is automatic and\nfaster. In this paper, after the user selects the regions to be reconstructed,\nthe algorithm automatically reconstruct the lost regions with the help of the\ninformation surrounding them. The existing methods perform very well when the\nregion to be reconstructed is very small, but fails in proper reconstruction as\nthe area increases. This paper describes a Hierarchical method by which the\narea to be inpainted is reduced in multiple levels and Total Variation(TV)\nmethod is used to inpaint in each level. This algorithm gives better\nperformance when compared with other existing algorithms such as nearest\nneighbor interpolation, Inpainting through Blurring and Sobolev Inpainting.", 
    "link": "http://arxiv.org/pdf/1207.3576v2", 
    "arxiv-id": "1207.3576v2"
},{
    "category": "cs.CV", 
    "author": "Sebastian Thrun", 
    "title": "Recovering Articulated Object Models from 3D Range Data", 
    "publish": "2012-07-11T14:48:13Z", 
    "summary": "We address the problem of unsupervised learning of complex articulated object\nmodels from 3D range data. We describe an algorithm whose input is a set of\nmeshes corresponding to different configurations of an articulated object. The\nalgorithm automatically recovers a decomposition of the object into\napproximately rigid parts, the location of the parts in the different object\ninstances, and the articulated object skeleton linking the parts. Our algorithm\nfirst registers allthe meshes using an unsupervised non-rigid technique\ndescribed in a companion paper. It then segments the meshes using a graphical\nmodel that captures the spatial contiguity of parts. The segmentation is done\nusing the EM algorithm, iterating between finding a decomposition of the object\ninto rigid parts, and finding the location of the parts in the object\ninstances. Although the graphical model is densely connected, the object\ndecomposition step can be performed optimally and efficiently, allowing us to\nidentify a large number of object parts while avoiding local maxima. We\ndemonstrate the algorithm on real world datasets, recovering a 15-part\narticulated model of a human puppet from just 7 different puppet\nconfigurations, as well as a 4 part model of a fiexing arm where significant\nnon-rigid deformation was present.", 
    "link": "http://arxiv.org/pdf/1207.4129v1", 
    "arxiv-id": "1207.4129v1"
},{
    "category": "cs.CV", 
    "author": "Manuel Reyes-Gomez", 
    "title": "Probabilistic index maps for modeling natural signals", 
    "publish": "2012-07-12T19:47:14Z", 
    "summary": "One of the major problems in modeling natural signals is that signals with\nvery similar structure may locally have completely different measurements,\ne.g., images taken under different illumination conditions, or the speech\nsignal captured in different environments. While there have been many\nsuccessful attempts to address these problems in application-specific settings,\nwe believe that underlying a large set of problems in signal representation is\na representational deficiency of intensity-derived local measurements that are\nthe basis of most efficient models. We argue that interesting structure in\nsignals is better captured when the signal is de- fined as a matrix whose\nentries are discrete indices to a separate palette of possible measurements. In\norder to model the variability in signal structure, we define a signal class\nnot by a single index map, but by a probability distribution over the index\nmaps, which can be estimated from the data, and which we call probabilistic\nindex maps. The existing algorithm can be adapted to work with this\nrepresentation. Furthermore, the probabilistic index map representation leads\nto algorithms with computational costs proportional to either the size of the\npalette or the log of the size of the palette, making the cost of significantly\nincreased invariance to non-structural changes quite bearable. We illustrate\nthe benefits of the probabilistic index map representation in several\napplications in computer vision and speech processing.", 
    "link": "http://arxiv.org/pdf/1207.4179v1", 
    "arxiv-id": "1207.4179v1"
},{
    "category": "cs.CV", 
    "author": "Heitor S. Ramos", 
    "title": "Assessment of SAR Image Filtering using Adaptive Stack Filters", 
    "publish": "2012-07-18T09:16:07Z", 
    "summary": "Stack filters are a special case of non-linear filters. They have a good\nperformance for filtering images with different types of noise while preserving\nedges and details. A stack filter decomposes an input image into several binary\nimages according to a set of thresholds. Each binary image is then filtered by\na Boolean function, which characterizes the filter. Adaptive stack filters can\nbe designed to be optimal; they are computed from a pair of images consisting\nof an ideal noiseless image and its noisy version. In this work we study the\nperformance of adaptive stack filters when they are applied to Synthetic\nAperture Radar (SAR) images. This is done by evaluating the quality of the\nfiltered images through the use of suitable image quality indexes and by\nmeasuring the classification accuracy of the resulting images.", 
    "link": "http://arxiv.org/pdf/1207.4308v1", 
    "arxiv-id": "1207.4308v1"
},{
    "category": "cs.CV", 
    "author": "Prasanta K. Panigrahi", 
    "title": "Multisegmentation through wavelets: Comparing the efficacy of Daubechies   vs Coiflets", 
    "publish": "2012-07-20T17:37:27Z", 
    "summary": "In this paper, we carry out a comparative study of the efficacy of wavelets\nbelonging to Daubechies and Coiflet family in achieving image segmentation\nthrough a fast statistical algorithm.The fact that wavelets belonging to\nDaubechies family optimally capture the polynomial trends and those of Coiflet\nfamily satisfy mini-max condition, makes this comparison interesting. In the\ncontext of the present algorithm, it is found that the performance of Coiflet\nwavelets is better, as compared to Daubechies wavelet.", 
    "link": "http://arxiv.org/pdf/1207.5007v1", 
    "arxiv-id": "1207.5007v1"
},{
    "category": "cs.CV", 
    "author": "Dr. N. V. Kalyankar", 
    "title": "A Novel Metric Approach Evaluation For The Spatial Enhancement Of   Pan-Sharpened Images", 
    "publish": "2012-07-20T21:30:35Z", 
    "summary": "Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. The\nQuality of image fusion is an essential determinant of the value of processing\nimages fusion for many applications. Spatial and spectral qualities are the two\nimportant indexes that used to evaluate the quality of any fused image.\nHowever, the jury is still out of fused image's benefits if it compared with\nits original images. In addition, there is a lack of measures for assessing the\nobjective quality of the spatial resolution for the fusion methods. So, an\nobjective quality of the spatial resolution assessment for fusion images is\nrequired. Therefore, this paper describes a new approach proposed to estimate\nthe spatial resolution improve by High Past Division Index (HPDI) upon\ncalculating the spatial-frequency of the edge regions of the image and it deals\nwith a comparison of various analytical techniques for evaluating the Spatial\nquality, and estimating the colour distortion added by image fusion including:\nMG, SG, FCC, SD, En, SNR, CC and NRMSE. In addition, this paper devotes to\nconcentrate on the comparison of various image fusion techniques based on pixel\nand feature fusion technique.", 
    "link": "http://arxiv.org/pdf/1207.5064v1", 
    "arxiv-id": "1207.5064v1"
},{
    "category": "cs.CV", 
    "author": "Kap Luk Chan", 
    "title": "Piecewise Linear Patch Reconstruction for Segmentation and Description   of Non-smooth Image Structures", 
    "publish": "2012-07-21T09:38:45Z", 
    "summary": "In this paper, we propose a unified energy minimization model for the\nsegmentation of non-smooth image structures. The energy of piecewise linear\npatch reconstruction is considered as an objective measure of the quality of\nthe segmentation of non-smooth structures. The segmentation is achieved by\nminimizing the single energy without any separate process of feature\nextraction. We also prove that the error of segmentation is bounded by the\nproposed energy functional, meaning that minimizing the proposed energy leads\nto reducing the error of segmentation. As a by-product, our method produces a\ndictionary of optimized orthonormal descriptors for each segmented region. The\nunique feature of our method is that it achieves the simultaneous segmentation\nand description for non-smooth image structures under the same optimization\nframework. The experiments validate our theoretical claims and show the clear\nsuperior performance of our methods over other related methods for segmentation\nof various image textures. We show that our model can be coupled with the\npiecewise smooth model to handle both smooth and non-smooth structures, and we\ndemonstrate that the proposed model is capable of coping with multiple\ndifferent regions through the one-against-all strategy.", 
    "link": "http://arxiv.org/pdf/1207.5113v1", 
    "arxiv-id": "1207.5113v1"
},{
    "category": "cs.CV", 
    "author": "Dhananjay Kumar", 
    "title": "A Survey Of Activity Recognition And Understanding The Behavior In Video   Survelliance", 
    "publish": "2012-07-29T13:07:09Z", 
    "summary": "This paper presents a review of human activity recognition and behaviour\nunderstanding in video sequence. The key objective of this paper is to provide\na general review on the overall process of a surveillance system used in the\ncurrent trend. Visual surveillance system is directed on automatic\nidentification of events of interest, especially on tracking and classification\nof moving objects. The processing step of the video surveillance system\nincludes the following stages: Surrounding model, object representation, object\ntracking, activity recognition and behaviour understanding. It describes\ntechniques that use to define a general set of activities that are applicable\nto a wide range of scenes and environments in video sequence.", 
    "link": "http://arxiv.org/pdf/1207.6774v1", 
    "arxiv-id": "1207.6774v1"
},{
    "category": "cs.CV", 
    "author": "Liujuan Cao", 
    "title": "Visual Vocabulary Learning and Its Application to 3D and Mobile Visual   Search", 
    "publish": "2012-06-29T15:07:26Z", 
    "summary": "In this technical report, we review related works and recent trends in visual\nvocabulary based web image search, object recognition, mobile visual search,\nand 3D object retrieval. Especial focuses would be also given for the recent\ntrends in supervised/unsupervised vocabulary optimization, compact descriptor\nfor visual search, as well as in multi-view based 3D object representation.", 
    "link": "http://arxiv.org/pdf/1207.7244v1", 
    "arxiv-id": "1207.7244v1"
},{
    "category": "cs.CV", 
    "author": "Driss Aboutajdine", 
    "title": "Dimensionality Reduction and Classification Feature Using Mutual   Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm   Based on Minimizing the Error Probability Using the Inequality of Fano", 
    "publish": "2012-10-31T23:30:59Z", 
    "summary": "In the feature classification domain, the choice of data affects widely the\nresults. For the Hyperspectral image, the bands dont all contain the\ninformation; some bands are irrelevant like those affected by various\natmospheric effects, see Figure.4, and decrease the classification accuracy.\nAnd there exist redundant bands to complicate the learning system and product\nincorrect prediction [14]. Even the bands contain enough information about the\nscene they may can't predict the classes correctly if the dimension of space\nimages, see Figure.3, is so large that needs many cases to detect the\nrelationship between the bands and the scene (Hughes phenomenon) [10]. We can\nreduce the dimensionality of hyperspectral images by selecting only the\nrelevant bands (feature selection or subset selection methodology), or\nextracting, from the original bands, new bands containing the maximal\ninformation about the classes, using any functions, logical or numerical\n(feature extraction methodology) [11][9]. Here we focus on the feature\nselection using mutual information. Hyperspectral images have three advantages\nregarding the multispectral images [6],", 
    "link": "http://arxiv.org/pdf/1211.0055v1", 
    "arxiv-id": "1211.0055v1"
},{
    "category": "cs.CV", 
    "author": "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez", 
    "title": "Performance Evaluation of Random Set Based Pedestrian Tracking   Algorithms", 
    "publish": "2012-10-25T23:21:46Z", 
    "summary": "The paper evaluates the error performance of three random finite set based\nmulti-object trackers in the context of pedestrian video tracking. The\nevaluation is carried out using a publicly available video dataset of 4500\nframes (town centre street) for which the ground truth is available. The input\nto all pedestrian tracking algorithms is an identical set of head and body\ndetections, obtained using the Histogram of Oriented Gradients (HOG) detector.\nThe tracking error is measured using the recently proposed OSPA metric for\ntracks, adopted as the only known mathematically rigorous metric for measuring\nthe distance between two sets of tracks. A comparative analysis is presented\nunder various conditions.", 
    "link": "http://arxiv.org/pdf/1211.0191v1", 
    "arxiv-id": "1211.0191v1"
},{
    "category": "cs.CV", 
    "author": "Hua Tian", 
    "title": "Segmentation of ultrasound images of thyroid nodule for assisting fine   needle aspiration cytology", 
    "publish": "2012-11-03T06:55:03Z", 
    "summary": "The incidence of thyroid nodule is very high and generally increases with the\nage. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\nnodule can be completely cured if detected early. Fine needle aspiration\ncytology is a recognized early diagnosis method of thyroid nodule. There are\nstill some limitations in the fine needle aspiration cytology, and the\nultrasound diagnosis of thyroid nodule has become the first choice for\nauxiliary examination of thyroid nodular disease. If we could combine medical\nimaging technology and fine needle aspiration cytology, the diagnostic rate of\nthyroid nodule would be improved significantly. The properties of ultrasound\nwill degrade the image quality, which makes it difficult to recognize the edges\nfor physicians. Image segmentation technique based on graph theory has become a\nresearch hotspot at present. Normalized cut (Ncut) is a representative one,\nwhich is suitable for segmentation of feature parts of medical image. However,\nhow to solve the normalized cut has become a problem, which needs large memory\ncapacity and heavy calculation of weight matrix. It always generates over\nsegmentation or less segmentation which leads to inaccurate in the\nsegmentation. The speckle noise in B ultrasound image of thyroid tumor makes\nthe quality of the image deteriorate. In the light of this characteristic, we\ncombine the anisotropic diffusion model with the normalized cut in this paper.\nAfter the enhancement of anisotropic diffusion model, it removes the noise in\nthe B ultrasound image while preserves the important edges and local details.\nThis reduces the amount of computation in constructing the weight matrix of the\nimproved normalized cut and improves the accuracy of the final segmentation\nresults. The feasibility of the method is proved by the experimental results.", 
    "link": "http://arxiv.org/pdf/1211.0602v1", 
    "arxiv-id": "1211.0602v1"
},{
    "category": "cs.CV", 
    "author": "Driss Aboutajdine", 
    "title": "Application of Symmetric Uncertainty and Mutual Information to   Dimensionality Reduction and Classification of Hyperspectral Images", 
    "publish": "2012-11-03T14:01:29Z", 
    "summary": "Remote sensing is a technology to acquire data for disatant substances,\nnecessary to construct a model knowledge for applications as classification.\nRecently Hyperspectral Images (HSI) becomes a high technical tool that the main\ngoal is to classify the point of a region. The HIS is more than a hundred\nbidirectional measures, called bands (or simply images), of the same region\ncalled Ground Truth Map (GT). But some bands are not relevant because they are\naffected by different atmospheric effects; others contain redundant\ninformation; and high dimensionality of HSI features make the accuracy of\nclassification lower. All these bands can be important for some applications;\nbut for the classification a small subset of these is relevant. The problematic\nrelated to HSI is the dimensionality reduction. Many studies use mutual\ninformation (MI) to select the relevant bands. Others studies use the MI\nnormalized forms, like Symmetric Uncertainty, in medical imagery applications.\nIn this paper we introduce an algorithm based also on MI to select relevant\nbands and it apply the Symmetric Uncertainty coefficient to control redundancy\nand increase the accuracy of classification. This algorithm is feature\nselection tool and a Filter strategy. We establish this study on HSI AVIRIS\n92AV3C. This is an effectiveness, and fast scheme to control redundancy.", 
    "link": "http://arxiv.org/pdf/1211.0613v2", 
    "arxiv-id": "1211.0613v2"
},{
    "category": "cs.CV", 
    "author": "Md. Ahaduzzaman Khan", 
    "title": "Implementation of Radon Transformation for Electrical Impedance   Tomography (EIT)", 
    "publish": "2012-10-16T09:46:12Z", 
    "summary": "Radon Transformation is generally used to construct optical image (like CT\nimage) from the projection data in biomedical imaging. In this paper, the\nconcept of Radon Transformation is implemented to reconstruct Electrical\nImpedance Topographic Image (conductivity or resistivity distribution) of a\ncircular subject. A parallel resistance model of a subject is proposed for\nElectrical Impedance Topography(EIT) or Magnetic Induction Tomography(MIT). A\ncircular subject with embedded circular objects is segmented into equal width\nslices from different angles. For each angle, Conductance and Conductivity of\neach slice is calculated and stored in an array. A back projection method is\nused to generate a two-dimensional image from one-dimensional projections. As a\nback projection method, Inverse Radon Transformation is applied on the\ncalculated conductance and conductivity to reconstruct two dimensional images.\nThese images are compared to the target image. In the time of image\nreconstruction, different filters are used and these images are compared with\neach other and target image.", 
    "link": "http://arxiv.org/pdf/1211.1252v1", 
    "arxiv-id": "1211.1252v1"
},{
    "category": "cs.CV", 
    "author": "Sajid Ali", 
    "title": "Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier   Curve and Statistical Techniques", 
    "publish": "2012-11-07T08:19:04Z", 
    "summary": "Motion capture is the process of recording the movement of objects or people.\nIt is used in military, entertainment, sports, and medical applications, and\nfor validation of computer vision[2] and robotics. In filmmaking and video game\ndevelopment, it refers to recording actions of human actors, and using that\ninformation to animate digital character models in 2D or 3D computer animation.\nWhen it includes face and fingers or captures subtle", 
    "link": "http://arxiv.org/pdf/1211.1482v4", 
    "arxiv-id": "1211.1482v4"
},{
    "category": "cs.CV", 
    "author": "Ravinder Khanna", 
    "title": "Different Operating Systems Compatible for Image Prepress Process in   Color Management: Analysis and Performance Testing", 
    "publish": "2012-11-07T19:52:50Z", 
    "summary": "Image computing has become a real catchphrase over the past few years and the\ninterpretations of the meaning of the term vary greatly. The Imagecomputing\nmarket is currently rapidly evolving with high growth prospects and almost\ndaily announcements of new devices and application platforms, which results in\nan increasing diversification of devices, operating system and development\nplatforms. Compared to more traditional information technology markets like the\none of desktop computing, mobile computing is much less consolidated and\nneither standards nor even industry standards have yet been established. There\nare various platforms and interfaces which may be used to perform the desired\ntasks through the device. We have tried to compare the various mobile operating\nsystems and their trade-offs.", 
    "link": "http://arxiv.org/pdf/1211.1650v1", 
    "arxiv-id": "1211.1650v1"
},{
    "category": "cs.CV", 
    "author": "Joseph P. Noonan", 
    "title": "James-Stein Type Center Pixel Weights for Non-Local Means Image   Denoising", 
    "publish": "2012-11-07T20:10:24Z", 
    "summary": "Non-Local Means (NLM) and variants have been proven to be effective and\nrobust in many image denoising tasks. In this letter, we study the parameter\nselection problem of center pixel weights (CPW) in NLM. Our key contributions\nare: 1) we give a novel formulation of the CPW problem from the statistical\nshrinkage perspective; 2) we introduce the James-Stein type CPWs for NLM; and\n3) we propose a new adaptive CPW that is locally tuned for each image pixel.\nOur experimental results showed that compared to existing CPW solutions, the\nnew proposed CPWs are more robust and effective under various noise levels. In\nparticular, the NLM with the James-Stein type CPWs attain higher means with\nsmaller variances in terms of the peak signal and noise ratio, implying they\nimprove the NLM robustness and make it less sensitive to parameter selection.", 
    "link": "http://arxiv.org/pdf/1211.1656v1", 
    "arxiv-id": "1211.1656v1"
},{
    "category": "cs.CV", 
    "author": "Sherwin Li", 
    "title": "3D Scene Grammar for Parsing RGB-D Pointclouds", 
    "publish": "2012-11-08T03:11:53Z", 
    "summary": "We pose 3D scene-understanding as a problem of parsing in a grammar. A\ngrammar helps us capture the compositional structure of real-word objects,\ne.g., a chair is composed of a seat, a back-rest and some legs. Having multiple\nrules for an object helps us capture structural variations in objects, e.g., a\nchair can optionally also have arm-rests. Finally, having rules to capture\ncomposition at different levels helps us formulate the entire scene-processing\npipeline as a single problem of finding most likely parse-tree---small segments\ncombine to form parts of objects, parts to objects and objects to a scene. We\nattach a generative probability model to our grammar by having a\nfeature-dependent probability function for every rule. We evaluated it by\nextracting labels for every segment and comparing the results with the\nstate-of-the-art segment-labeling algorithm. Our algorithm was outperformed by\nthe state-or-the-art method. But, Our model can be trained very efficiently\n(within seconds), and it scales only linearly in with the number of rules in\nthe grammar. Also, we think that this is an important problem for the 3D vision\ncommunity. So, we are releasing our dataset and related code.", 
    "link": "http://arxiv.org/pdf/1211.1752v1", 
    "arxiv-id": "1211.1752v1"
},{
    "category": "cs.CV", 
    "author": "Maher khemakhem", 
    "title": "A Comparative study of Arabic handwritten characters invariant feature", 
    "publish": "2012-11-08T09:24:21Z", 
    "summary": "This paper is practically interested in the unchangeable feature of Arabic\nhandwritten character. It presents results of comparative study achieved on\ncertain features extraction techniques of handwritten character, based on Hough\ntransform, Fourier transform, Wavelet transform and Gabor Filter. Obtained\nresults show that Hough Transform and Gabor filter are insensible to the\nrotation and translation, Fourier Transform is sensible to the rotation but\ninsensible to the translation, in contrast to Hough Transform and Gabor filter,\nWavelets Transform is sensitive to the rotation as well as to the translation.", 
    "link": "http://arxiv.org/pdf/1211.1800v1", 
    "arxiv-id": "1211.1800v1"
},{
    "category": "cs.CV", 
    "author": "Amit Singer", 
    "title": "Fourier-Bessel rotational invariant eigenimages", 
    "publish": "2012-11-08T20:59:49Z", 
    "summary": "We present an efficient and accurate algorithm for principal component\nanalysis (PCA) of a large set of two dimensional images, and, for each image,\nthe set of its uniform rotations in the plane and its reflection. The algorithm\nstarts by expanding each image, originally given on a Cartesian grid, in the\nFourier-Bessel basis for the disk. Because the images are bandlimited in the\nFourier domain, we use a sampling criterion to truncate the Fourier-Bessel\nexpansion such that the maximum amount of information is preserved without the\neffect of aliasing. The constructed covariance matrix is invariant to rotation\nand reflection and has a special block diagonal structure. PCA is efficiently\ndone for each block separately. This Fourier-Bessel based PCA detects more\nmeaningful eigenimages and has improved denoising capability compared to\ntraditional PCA for a finite number of noisy images.", 
    "link": "http://arxiv.org/pdf/1211.1968v2", 
    "arxiv-id": "1211.1968v2"
},{
    "category": "cs.CV", 
    "author": "Chokri Ben Amar", 
    "title": "Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic   Units for Speech Recognition", 
    "publish": "2012-11-08T22:23:54Z", 
    "summary": "In this paper, we propose a novel architecture of wavelet network called\nMulti-input Multi-output Wavelet Network MIMOWN as a generalization of the old\narchitecture of wavelet network. This newel prototype was applied to speech\nrecognition application especially to model acoustic unit of speech. The\noriginality of our work is the proposal of MIMOWN to model acoustic unit of\nspeech. This approach was proposed to overcome limitation of old wavelet\nnetwork model. The use of the multi-input multi-output architecture will allows\ntraining wavelet network on various examples of acoustic units.", 
    "link": "http://arxiv.org/pdf/1211.2007v1", 
    "arxiv-id": "1211.2007v1"
},{
    "category": "cs.CV", 
    "author": "M. K. Jeyakumar", 
    "title": "Time Complexity Analysis of Binary Space Partitioning Scheme for Image   Compression", 
    "publish": "2012-11-09T03:59:48Z", 
    "summary": "Segmentation-based image coding methods provide high compression ratios when\ncompared with traditional image coding approaches like the transform and sub\nband coding for low bit-rate compression applications. In this paper, a\nsegmentation-based image coding method, namely the Binary Space Partition\nscheme, that divides the desired image using a recursive procedure for coding\nis presented. The BSP approach partitions the desired image recursively by\nusing bisecting lines, selected from a collection of discrete optional lines,\nin a hierarchical manner. This partitioning procedure generates a binary tree,\nwhich is referred to as the BSP-tree representation of the desired image. The\nalgorithm is extremely complex in computation and has high execution time. The\ntime complexity of the BSP scheme is explored in this work.", 
    "link": "http://arxiv.org/pdf/1211.2037v1", 
    "arxiv-id": "1211.2037v1"
},{
    "category": "cs.CV", 
    "author": "P. U. Praveen Kumar", 
    "title": "3D Surface Reconstruction of Underwater Objects", 
    "publish": "2012-11-09T09:17:26Z", 
    "summary": "In this paper, we propose a novel technique to reconstruct 3D surface of an\nunderwater object using stereo images. Reconstructing the 3D surface of an\nunderwater object is really a challenging task due to degraded quality of\nunderwater images. There are various reason of quality degradation of\nunderwater images i.e., non-uniform illumination of light on the surface of\nobjects, scattering and absorption effects. Floating particles present in\nunderwater produces Gaussian noise on the captured underwater images which\ndegrades the quality of images. The degraded underwater images are preprocessed\nby applying homomorphic, wavelet denoising and anisotropic filtering\nsequentially. The uncalibrated rectification technique is applied to\npreprocessed images to rectify the left and right images. The rectified left\nand right image lies on a common plane. To find the correspondence points in a\nleft and right images, we have applied dense stereo matching technique i.e.,\ngraph cut method. Finally, we estimate the depth of images using triangulation\ntechnique. The experimental result shows that the proposed method reconstruct\n3D surface of underwater objects accurately using captured underwater stereo\nimages.", 
    "link": "http://arxiv.org/pdf/1211.2082v1", 
    "arxiv-id": "1211.2082v1"
},{
    "category": "cs.CV", 
    "author": "Kalyan Ghosh", 
    "title": "Localisation of Numerical Date Field in an Indian Handwritten Document", 
    "publish": "2012-11-09T12:59:11Z", 
    "summary": "This paper describes a method to localise all those areas which may\nconstitute the date field in an Indian handwritten document. Spatial patterns\nof the date field are studied from various handwritten documents and an\nalgorithm is developed through statistical analysis to identify those sets of\nconnected components which may constitute the date. Common date patterns\nfollowed in India are considered to classify the date formats in different\nclasses. Reported results demonstrate promising performance of the proposed\napproach", 
    "link": "http://arxiv.org/pdf/1211.2116v1", 
    "arxiv-id": "1211.2116v1"
},{
    "category": "cs.CV", 
    "author": "Ana Fern\u00e1ndez Vila", 
    "title": "NF-SAVO: Neuro-Fuzzy system for Arabic Video OCR", 
    "publish": "2012-11-09T14:57:53Z", 
    "summary": "In this paper we propose a robust approach for text extraction and\nrecognition from video clips which is called Neuro-Fuzzy system for Arabic\nVideo OCR. In Arabic video text recognition, a number of noise components\nprovide the text relatively more complicated to separate from the background.\nFurther, the characters can be moving or presented in a diversity of colors,\nsizes and fonts that are not uniform. Added to this, is the fact that the\nbackground is usually moving making text extraction a more intricate process.\nVideo include two kinds of text, scene text and artificial text. Scene text is\nusually text that becomes part of the scene itself as it is recorded at the\ntime of filming the scene. But artificial text is produced separately and away\nfrom the scene and is laid over it at a later stage or during the post\nprocessing time. The emergence of artificial text is consequently vigilantly\ndirected. This type of text carries with it important information that helps in\nvideo referencing, indexing and retrieval.", 
    "link": "http://arxiv.org/pdf/1211.2150v1", 
    "arxiv-id": "1211.2150v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed A. El-Sayed", 
    "title": "A New Algorithm Based Entropic Threshold for Edge Detection in Images", 
    "publish": "2012-11-12T02:56:08Z", 
    "summary": "Edge detection is one of the most critical tasks in automatic image analysis.\nThere exists no universal edge detection method which works well under all\nconditions. This paper shows the new approach based on the one of the most\nefficient techniques for edge detection, which is entropy-based thresholding.\nThe main advantages of the proposed method are its robustness and its\nflexibility. We present experimental results for this method, and compare\nresults of the algorithm against several leading edge detection methods, such\nas Canny, LOG, and Sobel. Experimental results demonstrate that the proposed\nmethod achieves better result than some classic methods and the quality of the\nedge detector of the output images is robust and decrease the computation time.", 
    "link": "http://arxiv.org/pdf/1211.2500v1", 
    "arxiv-id": "1211.2500v1"
},{
    "category": "cs.CV", 
    "author": "Tarek Abd-El Hafeez", 
    "title": "New Edge Detection Technique based on the Shannon Entropy in Gray Level   Images", 
    "publish": "2012-11-12T03:06:18Z", 
    "summary": "Edge detection is an important field in image processing. Edges characterize\nobject boundaries and are therefore useful for segmentation, registration,\nfeature extraction, and identification of objects in a scene. In this paper, an\napproach utilizing an improvement of Baljit and Amar method which uses Shannon\nentropy other than the evaluation of derivatives of the image in detecting\nedges in gray level images has been proposed. The proposed method can reduce\nthe CPU time required for the edge detection process and the quality of the\nedge detector of the output images is robust. A standard test images, the\nreal-world and synthetic images are used to compare the results of the proposed\nedge detector with the Baljit and Amar edge detector method. In order to\nvalidate the results, the run time of the proposed method and the pervious\nmethod are presented. It has been observed that the proposed edge detector\nworks effectively for different gray scale digital images. The performance\nevaluation of the proposed technique in terms of the measured CPU time and the\nquality of edge detector method are presented. Experimental results demonstrate\nthat the proposed method achieve better result than the relevant classic\nmethod.", 
    "link": "http://arxiv.org/pdf/1211.2502v1", 
    "arxiv-id": "1211.2502v1"
},{
    "category": "cs.CV", 
    "author": "Alon Schclar", 
    "title": "Multi-Sensor Fusion via Reduction of Dimensionality", 
    "publish": "2012-11-13T01:05:42Z", 
    "summary": "Large high-dimensional datasets are becoming more and more popular in an\nincreasing number of research areas. Processing the high dimensional data\nincurs a high computational cost and is inherently inefficient since many of\nthe values that describe a data object are redundant due to noise and inner\ncorrelations. Consequently, the dimensionality, i.e. the number of values that\nare used to describe a data object, needs to be reduced prior to any other\nprocessing of the data. The dimensionality reduction removes, in most cases,\nnoise from the data and reduces substantially the computational cost of\nalgorithms that are applied to the data.\n  In this thesis, a novel coherent integrated methodology is introduced\n(theory, algorithm and applications) to reduce the dimensionality of\nhigh-dimensional datasets. The method constructs a diffusion process among the\ndata coordinates via a random walk. The dimensionality reduction is obtained\nbased on the eigen-decomposition of the Markov matrix that is associated with\nthe random walk. The proposed method is utilized for: (a) segmentation and\ndetection of anomalies in hyper-spectral images; (b) segmentation of\nmulti-contrast MRI images; and (c) segmentation of video sequences.\n  We also present algorithms for: (a) the characterization of materials using\ntheir spectral signatures to enable their identification; (b) detection of\nvehicles according to their acoustic signatures; and (c) classification of\nvascular vessels recordings to detect hyper-tension and cardio-vascular\ndiseases.\n  The proposed methodology and algorithms produce excellent results that\nsuccessfully compete with current state-of-the-art algorithms.", 
    "link": "http://arxiv.org/pdf/1211.2863v1", 
    "arxiv-id": "1211.2863v1"
},{
    "category": "cs.CV", 
    "author": "Hedvig Kjellstrom", 
    "title": "Visual Recognition of Isolated Swedish Sign Language Signs", 
    "publish": "2012-11-16T14:29:31Z", 
    "summary": "We present a method for recognition of isolated Swedish Sign Language signs.\nThe method will be used in a game intended to help children training signing at\nhome, as a complement to training with a teacher. The target group is not\nprimarily deaf children, but children with language disorders. Using sign\nlanguage as a support in conversation has been shown to greatly stimulate the\nspeech development of such children. The signer is captured with an RGB-D\n(Kinect) sensor, which has three advantages over a regular RGB camera. Firstly,\nit allows complex backgrounds to be removed easily. We segment the hands and\nface based on skin color and depth information. Secondly, it helps with the\nresolution of hand over face occlusion. Thirdly, signs take place in 3D; some\naspects of the signs are defined by hand motion vertically to the image plane.\nThis motion can be estimated if the depth is observable. The 3D motion of the\nhands relative to the torso are used as a cue together with the hand shape, and\nHMMs trained with this input are used for classification. To obtain higher\nrobustness towards differences across signers, Fisher Linear Discriminant\nAnalysis is used to find the combinations of features that are most descriptive\nfor each sign, regardless of signer. Experiments show that the system can\ndistinguish signs from a challenging 94 word vocabulary with a precision of up\nto 94% in the signer dependent case and up to 47% in the signer independent\ncase.", 
    "link": "http://arxiv.org/pdf/1211.3901v1", 
    "arxiv-id": "1211.3901v1"
},{
    "category": "cs.CV", 
    "author": "Amit Singer", 
    "title": "Non-Local Patch Regression: Robust Image Denoising in Patch Space", 
    "publish": "2012-11-18T22:36:43Z", 
    "summary": "It was recently demonstrated in [Chaudhury et al.,Non-Local Euclidean\nMedians,2012] that the denoising performance of Non-Local Means (NLM) can be\nimproved at large noise levels by replacing the mean by the robust Euclidean\nmedian. Numerical experiments on synthetic and natural images showed that the\nlatter consistently performed better than NLM beyond a certain noise level, and\nsignificantly so for images with sharp edges. The Euclidean mean and median can\nbe put into a common regression (on the patch space) framework, in which the\nl_2 norm of the residuals is considered in the former, while the l_1 norm is\nconsidered in the latter. The natural question then is what happens if we\nconsider l_p (0<p<1) regression? We investigate this possibility in this paper.", 
    "link": "http://arxiv.org/pdf/1211.4264v1", 
    "arxiv-id": "1211.4264v1"
},{
    "category": "cs.CV", 
    "author": "Changshui Zhang", 
    "title": "Efficient Superimposition Recovering Algorithm", 
    "publish": "2012-11-19T05:44:24Z", 
    "summary": "In this article, we address the issue of recovering latent transparent layers\nfrom superimposition images. Here, we assume we have the estimated\ntransformations and extracted gradients of latent layers. To rapidly recover\nhigh-quality image layers, we propose an Efficient Superimposition Recovering\nAlgorithm (ESRA) by extending the framework of accelerated gradient method. In\naddition, a key building block (in each iteration) in our proposed method is\nthe proximal operator calculating. Here we propose to employ a dual approach\nand present our Parallel Algorithm with Constrained Total Variation (PACTV)\nmethod. Our recovering method not only reconstructs high-quality layers without\ncolor-bias problem, but also theoretically guarantees good convergence\nperformance.", 
    "link": "http://arxiv.org/pdf/1211.4307v1", 
    "arxiv-id": "1211.4307v1"
},{
    "category": "cs.CV", 
    "author": "Pascal Frossard", 
    "title": "Rate-Distortion Analysis of Multiview Coding in a DIBR Framework", 
    "publish": "2012-11-19T17:09:56Z", 
    "summary": "Depth image based rendering techniques for multiview applications have been\nrecently introduced for efficient view generation at arbitrary camera\npositions. Encoding rate control has thus to consider both texture and depth\ndata. Due to different structures of depth and texture images and their\ndifferent roles on the rendered views, distributing the available bit budget\nbetween them however requires a careful analysis. Information loss due to\ntexture coding affects the value of pixels in synthesized views while errors in\ndepth information lead to shift in objects or unexpected patterns at their\nboundaries. In this paper, we address the problem of efficient bit allocation\nbetween textures and depth data of multiview video sequences. We adopt a\nrate-distortion framework based on a simplified model of depth and texture\nimages. Our model preserves the main features of depth and texture images.\nUnlike most recent solutions, our method permits to avoid rendering at encoding\ntime for distortion estimation so that the encoding complexity is not\naugmented. In addition to this, our model is independent of the underlying\ninpainting method that is used at decoder. Experiments confirm our theoretical\nresults and the efficiency of our rate allocation strategy.", 
    "link": "http://arxiv.org/pdf/1211.4499v1", 
    "arxiv-id": "1211.4499v1"
},{
    "category": "cs.CV", 
    "author": "Yanchao Yang", 
    "title": "Matching Through Features and Features Through Matching", 
    "publish": "2012-11-20T15:15:56Z", 
    "summary": "This paper addresses how to construct features for the problem of image\ncorrespondence, in particular, the paper addresses how to construct features so\nas to maintain the right level of invariance versus discriminability. We show\nthat without additional prior knowledge of the 3D scene, the right tradeoff\ncannot be established in a pre-processing step of the images as is typically\ndone in most feature-based matching methods. However, given knowledge of the\nsecond image to match, the tradeoff between invariance and discriminability of\nfeatures in the first image is less ambiguous. This suggests to setup the\nproblem of feature extraction and matching as a joint estimation problem. We\ndevelop a possible mathematical framework, a possible computational algorithm,\nand we give example demonstration on finding correspondence on images related\nby a scene that undergoes large 3D deformation of non-planar objects and camera\nviewpoint change.", 
    "link": "http://arxiv.org/pdf/1211.4771v1", 
    "arxiv-id": "1211.4771v1"
},{
    "category": "cs.CV", 
    "author": "Prasanna K. Lenka", 
    "title": "Cobb Angle Measurement of Scoliosis with Reduced Variability", 
    "publish": "2012-11-22T19:09:29Z", 
    "summary": "Cobb angle, which is a measure of spinal curvature is the standard method for\nquantifying the magnitude of Scoliosis related to spinal deformity in\northopedics. Determining the Cobb angle through manual process is subject to\nhuman errors. In this work, we propose a methodology to measure the magnitude\nof Cobb angle, which appreciably reduces the variability related to its\nmeasurement compared to the related works. The proposed methodology is\nfacilitated by using a suitable new improved version of Non-Local Means for\nimage denoisation and Otsus automatic threshold selection for Canny edge\ndetection. We have selected NLM for preprocessing of the image as it is one of\nthe fine states of art for image denoisation and helps in retaining the image\nquality. Trimmedmean, median are more robust to outliners than mean and\nfollowing this concept we observed that NLM denoising quality performance can\nbe enhanced by using Euclidean trimmed-mean replacing the mean. To prove the\nbetter performance of the Non-Local Euclidean Trimmed-mean denoising filter, we\nhave provided some comparative study results of the proposed denoising\ntechnique with traditional NLM and NonLocal Euclidean Medians. The experimental\nresults for Cobb angle measurement over intra observer and inter observer\nexperimental data reveals the better performance and superiority of the\nproposed approach compared to the related works. MATLAB2009b image processing\ntoolbox was used for the purpose of simulation and verification of the proposed\nmethodology.", 
    "link": "http://arxiv.org/pdf/1211.5355v1", 
    "arxiv-id": "1211.5355v1"
},{
    "category": "cs.CV", 
    "author": "Krzysztof Misztal", 
    "title": "Detection of elliptical shapes via cross-entropy clustering", 
    "publish": "2012-11-24T23:08:15Z", 
    "summary": "The problem of finding elliptical shapes in an image will be considered. We\ndiscuss the solution which uses cross-entropy clustering. The proposed method\nallows the search for ellipses with predefined sizes and position in the space.\nMoreover, it works well for search of ellipsoids in higher dimensions.", 
    "link": "http://arxiv.org/pdf/1211.5712v1", 
    "arxiv-id": "1211.5712v1"
},{
    "category": "cs.CV", 
    "author": "Andrew Habib", 
    "title": "Viewpoint Invariant Object Detector", 
    "publish": "2012-11-30T22:35:19Z", 
    "summary": "Object Detection is the task of identifying the existence of an object class\ninstance and locating it within an image. Difficulties in handling high\nintra-class variations constitute major obstacles to achieving high performance\non standard benchmark datasets (scale, viewpoint, lighting conditions and\norientation variations provide good examples). Suggested model aims at\nproviding more robustness to detecting objects suffering severe distortion due\nto < 60{\\deg} viewpoint changes. In addition, several model computational\nbottlenecks have been resolved leading to a significant increase in the model\nperformance (speed and space) without compromising the resulting accuracy.\nFinally, we produced two illustrative applications showing the potential of the\nobject detection technology being deployed in real life applications; namely\ncontent-based image search and content-based video search.", 
    "link": "http://arxiv.org/pdf/1212.0030v1", 
    "arxiv-id": "1212.0030v1"
},{
    "category": "cs.CV", 
    "author": "Ankit Chaudhary", 
    "title": "Fingertip Detection: A Fast Method with Natural Hand", 
    "publish": "2012-12-01T16:59:07Z", 
    "summary": "Many vision based applications have used fingertips to track or manipulate\ngestures in their applications. Gesture identification is a natural way to pass\nthe signals to the machine, as the human express its feelings most of the time\nwith hand expressions. Here a novel time efficient algorithm has been described\nfor fingertip detection. This method is invariant to hand direction and in\npreprocessing it cuts only hand part from the full image, hence further\ncomputation would be much faster than processing full image. Binary silhouette\nof the input image is generated using HSV color space based skin filter and\nhand cropping done based on intensity histogram of the hand image", 
    "link": "http://arxiv.org/pdf/1212.0134v1", 
    "arxiv-id": "1212.0134v1"
},{
    "category": "cs.CV", 
    "author": "P. U. Praveen Kumar", 
    "title": "An Image Based Technique for Enhancement of Underwater Images", 
    "publish": "2012-12-03T05:57:46Z", 
    "summary": "The underwater images usually suffers from non-uniform lighting, low\ncontrast, blur and diminished colors. In this paper, we proposed an image based\npreprocessing technique to enhance the quality of the underwater images. The\nproposed technique comprises a combination of four filters such as homomorphic\nfiltering, wavelet denoising, bilateral filter and contrast equalization. These\nfilters are applied sequentially on degraded underwater images. The literature\nsurvey reveals that image based preprocessing algorithms uses standard filter\ntechniques with various combinations. For smoothing the image, the image based\npreprocessing algorithms uses the anisotropic filter. The main drawback of the\nanisotropic filter is that iterative in nature and computation time is high\ncompared to bilateral filter. In the proposed technique, in addition to other\nthree filters, we employ a bilateral filter for smoothing the image. The\nexperimentation is carried out in two stages. In the first stage, we have\nconducted various experiments on captured images and estimated optimal\nparameters for bilateral filter. Similarly, optimal filter bank and optimal\nwavelet shrinkage function are estimated for wavelet denoising. In the second\nstage, we conducted the experiments using estimated optimal parameters, optimal\nfilter bank and optimal wavelet shrinkage function for evaluating the proposed\ntechnique. We evaluated the technique using quantitative based criteria such as\na gradient magnitude histogram and Peak Signal to Noise Ratio (PSNR). Further,\nthe results are qualitatively evaluated based on edge detection results. The\nproposed technique enhances the quality of the underwater images and can be\nemployed prior to apply computer vision techniques.", 
    "link": "http://arxiv.org/pdf/1212.0291v1", 
    "arxiv-id": "1212.0291v1"
},{
    "category": "cs.CV", 
    "author": "M. H. M. Krishna Prasad", 
    "title": "Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its   Applications", 
    "publish": "2012-12-03T08:55:52Z", 
    "summary": "Image fusion is the process of integrating multiple images of the same scene\ninto a single fused image to reduce uncertainty and minimizing redundancy while\nextracting all the useful information from the source images. Image fusion\nprocess is required for different applications like medical imaging, remote\nsensing, medical imaging, machine vision, biometrics and military applications\nwhere quality and critical information is required. In this paper, image fusion\nusing fuzzy and neuro fuzzy logic approaches utilized to fuse images from\ndifferent sensors, in order to enhance visualization. The proposed work further\nexplores comparison between fuzzy based image fusion and neuro fuzzy fusion\ntechnique along with quality evaluation indices for image fusion like image\nquality index, mutual information measure, fusion factor, fusion symmetry,\nfusion index, root mean square error, peak signal to noise ratio, entropy,\ncorrelation coefficient and spatial frequency. Experimental results obtained\nfrom fusion process prove that the use of the neuro fuzzy based image fusion\napproach shows better performance in first two test cases while in the third\ntest case fuzzy based image fusion technique gives better results.", 
    "link": "http://arxiv.org/pdf/1212.0318v1", 
    "arxiv-id": "1212.0318v1"
},{
    "category": "cs.CV", 
    "author": "P. Nagabhushan", 
    "title": "GLCM-based chi-square histogram distance for automatic detection of   defects on patterned textures", 
    "publish": "2012-12-03T13:40:41Z", 
    "summary": "Chi-square histogram distance is one of the distance measures that can be\nused to find dissimilarity between two histograms. Motivated by the fact that\ntexture discrimination by human vision system is based on second-order\nstatistics, we make use of histogram of gray-level co-occurrence matrix (GLCM)\nthat is based on second-order statistics and propose a new machine vision\nalgorithm for automatic defect detection on patterned textures. Input defective\nimages are split into several periodic blocks and GLCMs are computed after\nquantizing the gray levels from 0-255 to 0-63 to keep the size of GLCM compact\nand to reduce computation time. Dissimilarity matrix derived from chi-square\ndistances of the GLCMs is subjected to hierarchical clustering to automatically\nidentify defective and defect-free blocks. Effectiveness of the proposed method\nis demonstrated through experiments on defective real-fabric images of 2 major\nwallpaper groups (pmm and p4m groups).", 
    "link": "http://arxiv.org/pdf/1212.0383v1", 
    "arxiv-id": "1212.0383v1"
},{
    "category": "cs.CV", 
    "author": "Mubarak Shah", 
    "title": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild", 
    "publish": "2012-12-03T14:45:31Z", 
    "summary": "We introduce UCF101 which is currently the largest dataset of human actions.\nIt consists of 101 action classes, over 13k clips and 27 hours of video data.\nThe database consists of realistic user uploaded videos containing camera\nmotion and cluttered background. Additionally, we provide baseline action\nrecognition results on this new dataset using standard bag of words approach\nwith overall performance of 44.5%. To the best of our knowledge, UCF101 is\ncurrently the most challenging dataset of actions due to its large number of\nclasses, large number of clips and also unconstrained nature of such clips.", 
    "link": "http://arxiv.org/pdf/1212.0402v1", 
    "arxiv-id": "1212.0402v1"
},{
    "category": "cs.CV", 
    "author": "Luc Joannes", 
    "title": "Compressive Schlieren Deflectometry", 
    "publish": "2012-12-03T16:21:07Z", 
    "summary": "Schlieren deflectometry aims at characterizing the deflections undergone by\nrefracted incident light rays at any surface point of a transparent object. For\nsmooth surfaces, each surface location is actually associated with a sparse\ndeflection map (or spectrum). This paper presents a novel method to\ncompressively acquire and reconstruct such spectra. This is achieved by\naltering the way deflection information is captured in a common Schlieren\nDeflectometer, i.e., the deflection spectra are indirectly observed by the\nprinciple of spread spectrum compressed sensing. These observations are\nrealized optically using a 2-D Spatial Light Modulator (SLM) adjusted to the\ncorresponding sensing basis and whose modulations encode the light deviation\nsubsequently recorded by a CCD camera. The efficiency of this approach is\ndemonstrated experimentally on the observation of few test objects. Further,\nusing a simple parametrization of the deflection spectra we show that relevant\nkey parameters can be directly computed using the measurements, avoiding full\nreconstruction.", 
    "link": "http://arxiv.org/pdf/1212.0433v1", 
    "arxiv-id": "1212.0433v1"
},{
    "category": "cs.CV", 
    "author": "Hassan Ghassemian", 
    "title": "Unmixing of Hyperspectral Data Using Robust Statistics-based NMF", 
    "publish": "2012-12-04T21:59:35Z", 
    "summary": "Mixed pixels are presented in hyperspectral images due to low spatial\nresolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels\nspectra into endmembers spectra and abundance fractions. In this paper using of\nrobust statistics-based nonnegative matrix factorization (RNMF) for spectral\nunmixing of hyperspectral data is investigated. RNMF uses a robust cost\nfunction and iterative updating procedure, so is not sensitive to outliers.\nThis method has been applied to simulated data using USGS spectral library,\nAVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF\nmethod based on SAD and AAD measures. Results demonstrate that this method can\nbe used efficiently for hyperspectral unmixing purposes.", 
    "link": "http://arxiv.org/pdf/1212.0888v1", 
    "arxiv-id": "1212.0888v1"
},{
    "category": "cs.CV", 
    "author": "Xianfeng Gu", 
    "title": "Kernel Estimation from Salient Structure for Robust Motion Deblurring", 
    "publish": "2012-12-05T16:02:43Z", 
    "summary": "Blind image deblurring algorithms have been improving steadily in the past\nyears. Most state-of-the-art algorithms, however, still cannot perform\nperfectly in challenging cases, especially in large blur setting. In this\npaper, we focus on how to estimate a good kernel estimate from a single blurred\nimage based on the image structure. We found that image details caused by\nblurring could adversely affect the kernel estimation, especially when the blur\nkernel is large. One effective way to eliminate these details is to apply image\ndenoising model based on the Total Variation (TV). First, we developed a novel\nmethod for computing image structures based on TV model, such that the\nstructures undermining the kernel estimation will be removed. Second, to\nmitigate the possible adverse effect of salient edges and improve the\nrobustness of kernel estimation, we applied a gradient selection method. Third,\nwe proposed a novel kernel estimation method, which is capable of preserving\nthe continuity and sparsity of the kernel and reducing the noises. Finally, we\ndeveloped an adaptive weighted spatial prior, for the purpose of preserving\nsharp edges in latent image restoration. The effectiveness of our method is\ndemonstrated by experiments on various kinds of challenging examples.", 
    "link": "http://arxiv.org/pdf/1212.1073v2", 
    "arxiv-id": "1212.1073v2"
},{
    "category": "cs.CV", 
    "author": "P. Nagabhushan", 
    "title": "Automatic Detection of Texture Defects Using Texture-Periodicity and   Gabor Wavelets", 
    "publish": "2012-12-06T14:17:21Z", 
    "summary": "In this paper, we propose a machine vision algorithm for automatically\ndetecting defects in textures belonging to 16 out of 17 wallpaper groups using\ntexture-periodicity and a family of Gabor wavelets. Input defective images are\nsubjected to Gabor wavelet transformation in multi-scales and\nmulti-orientations and a resultant image is obtained in L2 norm. The resultant\nimage is split into several periodic blocks and energy of each block is used as\na feature space to automatically identify defective and defect-free blocks\nusing Ward's hierarchical clustering. Experiments on defective fabric images of\nthree major wallpaper groups, namely, pmm, p2 and p4m, show that the proposed\nmethod is robust in finding fabric defects without human intervention and can\nbe used for automatic defect detection in fabric industries.", 
    "link": "http://arxiv.org/pdf/1212.1329v1", 
    "arxiv-id": "1212.1329v1"
},{
    "category": "cs.CV", 
    "author": "Thierry G\u00e9raud", 
    "title": "A fair comparison of many max-tree computation algorithms (Extended   version of the paper submitted to ISMM 2013", 
    "publish": "2012-12-08T17:38:40Z", 
    "summary": "With the development of connected filters for the last decade, many\nalgorithms have been proposed to compute the max-tree. Max-tree allows to\ncompute the most advanced connected operators in a simple way. However, no fair\ncomparison of algorithms has been proposed yet and the choice of an algorithm\nover an other depends on many parameters. Since the need of fast algorithms is\nobvious for production code, we present an in depth comparison of five\nalgorithms and some variations of them in a unique framework. Finally, a\ndecision tree will be proposed to help user in choosing the right algorithm\nwith respect to their data.", 
    "link": "http://arxiv.org/pdf/1212.1819v2", 
    "arxiv-id": "1212.1819v2"
},{
    "category": "cs.CV", 
    "author": "Martin L\u00e4uter", 
    "title": "Fast and Robust Linear Motion Deblurring", 
    "publish": "2012-12-10T23:00:10Z", 
    "summary": "We investigate efficient algorithmic realisations for robust deconvolution of\ngrey-value images with known space-invariant point-spread function, with\nemphasis on 1D motion blur scenarios. The goal is to make deconvolution\nsuitable as preprocessing step in automated image processing environments with\ntight time constraints. Candidate deconvolution methods are selected for their\nrestoration quality, robustness and efficiency. Evaluation of restoration\nquality and robustness on synthetic and real-world test images leads us to\nfocus on a combination of Wiener filtering with few iterations of robust and\nregularised Richardson-Lucy deconvolution. We discuss algorithmic optimisations\nfor specific scenarios. In the case of uniform linear motion blur in coordinate\ndirection, it is possible to achieve real-time performance (less than 50 ms) in\nsingle-threaded CPU computation on images of $256\\times256$ pixels. For more\ngeneral space-invariant blur settings, still favourable computation times are\nobtained. Exemplary parallel implementations demonstrate that the proposed\nmethod also achieves real-time performance for general 1D motion blurs in a\nmulti-threaded CPU setting, and for general 2D blurs on a GPU.", 
    "link": "http://arxiv.org/pdf/1212.2245v1", 
    "arxiv-id": "1212.2245v1"
},{
    "category": "cs.CV", 
    "author": "Antonio Torralba", 
    "title": "Inverting and Visualizing Features for Object Detection", 
    "publish": "2012-12-11T01:59:51Z", 
    "summary": "We introduce algorithms to visualize feature spaces used by object detectors.\nThe tools in this paper allow a human to put on `HOG goggles' and perceive the\nvisual world as a HOG based object detector sees it. We found that these\nvisualizations allow us to analyze object detection systems in new ways and\ngain new insight into the detector's failures. For example, when we visualize\nthe features for high scoring false alarms, we discovered that, although they\nare clearly wrong in image space, they do look deceptively similar to true\npositives in feature space. This result suggests that many of these false\nalarms are caused by our choice of feature space, and indicates that creating a\nbetter learning algorithm or building bigger datasets is unlikely to correct\nthese errors. By visualizing feature spaces, we can gain a more intuitive\nunderstanding of our detection systems.", 
    "link": "http://arxiv.org/pdf/1212.2278v2", 
    "arxiv-id": "1212.2278v2"
},{
    "category": "cs.CV", 
    "author": "J\u00fcrgen Schmidhuber", 
    "title": "A Learning Framework for Morphological Operators using Counter-Harmonic   Mean", 
    "publish": "2012-12-11T17:29:04Z", 
    "summary": "We present a novel framework for learning morphological operators using\ncounter-harmonic mean. It combines concepts from morphology and convolutional\nneural networks. A thorough experimental validation analyzes basic\nmorphological operators dilation and erosion, opening and closing, as well as\nthe much more complex top-hat transform, for which we report a real-world\napplication from the steel industry. Using online learning and stochastic\ngradient descent, our system learns both the structuring element and the\ncomposition of operators. It scales well to large datasets and online settings.", 
    "link": "http://arxiv.org/pdf/1212.2546v1", 
    "arxiv-id": "1212.2546v1"
},{
    "category": "cs.CV", 
    "author": "Mohd Nasir Ismail", 
    "title": "Enhanced skin colour classifier using RGB Ratio model", 
    "publish": "2012-12-12T03:01:00Z", 
    "summary": "Skin colour detection is frequently been used for searching people, face\ndetection, pornographic filtering and hand tracking. The presence of skin or\nnon-skin in digital image can be determined by manipulating pixels colour or\npixels texture. The main problem in skin colour detection is to represent the\nskin colour distribution model that is invariant or least sensitive to changes\nin illumination condition. Another problem comes from the fact that many\nobjects in the real world may possess almost similar skin-tone colour such as\nwood, leather, skin-coloured clothing, hair and sand. Moreover, skin colour is\ndifferent between races and can be different from a person to another, even\nwith people of the same ethnicity. Finally, skin colour will appear a little\ndifferent when different types of camera are used to capture the object or\nscene. The objective in this study is to develop a skin colour classifier based\non pixel-based using RGB ratio model. The RGB ratio model is a newly proposed\nmethod that belongs under the category of an explicitly defined skin region\nmodel. This skin classifier was tested with SIdb dataset and two benchmark\ndatasets; UChile and TDSD datasets to measure classifier performance. The\nperformance of skin classifier was measured based on true positive (TF) and\nfalse positive (FP) indicator. This newly proposed model was compared with\nKovac, Saleh and Swift models. The experimental results showed that the RGB\nratio model outperformed all the other models in term of detection rate. The\nRGB ratio model is able to reduce FP detection that caused by reddish objects\ncolour as well as be able to detect darkened skin and skin covered by shadow.", 
    "link": "http://arxiv.org/pdf/1212.2692v1", 
    "arxiv-id": "1212.2692v1"
},{
    "category": "cs.CV", 
    "author": "Jianxiong Xiao", 
    "title": "Tracking Revisited using RGBD Camera: Baseline and Benchmark", 
    "publish": "2012-12-12T14:02:41Z", 
    "summary": "Although there has been significant progress in the past decade,tracking is\nstill a very challenging computer vision task, due to problems such as\nocclusion and model drift.Recently, the increased popularity of depth sensors\ne.g. Microsoft Kinect has made it easy to obtain depth data at low cost.This\nmay be a game changer for tracking, since depth information can be used to\nprevent model drift and handle occlusion.In this paper, we construct a\nbenchmark dataset of 100 RGBD videos with high diversity, including deformable\nobjects, various occlusion conditions and moving cameras. We propose a very\nsimple but strong baseline model for RGBD tracking, and present a quantitative\ncomparison of several state-of-the-art tracking algorithms.Experimental results\nshow that including depth information and reasoning about occlusion\nsignificantly improves tracking performance. The datasets, evaluation details,\nsource code for the baseline algorithm, and instructions for submitting new\nmodels will be made available online after acceptance.", 
    "link": "http://arxiv.org/pdf/1212.2823v1", 
    "arxiv-id": "1212.2823v1"
},{
    "category": "cs.CV", 
    "author": "Ron Kikinis", 
    "title": "Pituitary Adenoma Volumetry with 3D Slicer", 
    "publish": "2012-12-12T16:12:32Z", 
    "summary": "In this study, we present pituitary adenoma volumetry using the free and open\nsource medical image computing platform for biomedical research: (3D) Slicer.\nVolumetric changes in cerebral pathologies like pituitary adenomas are a\ncritical factor in treatment decisions by physicians and in general the volume\nis acquired manually. Therefore, manual slice-by-slice segmentations in\nmagnetic resonance imaging (MRI) data, which have been obtained at regular\nintervals, are performed. In contrast to this manual time consuming\nslice-by-slice segmentation process Slicer is an alternative which can be\nsignificantly faster and less user intensive. In this contribution, we compare\npure manual segmentations of ten pituitary adenomas with semi-automatic\nsegmentations under Slicer. Thus, physicians drew the boundaries completely\nmanually on a slice-by-slice basis and performed a Slicer-enhanced segmentation\nusing the competitive region-growing based module of Slicer named GrowCut.\nResults showed that the time and user effort required for GrowCut-based\nsegmentations were on average about thirty percent less than the pure manual\nsegmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC)\nbetween the manual and the Slicer-based segmentations to proof that the two are\ncomparable yielding an average DSC of 81.97\\pm3.39%.", 
    "link": "http://arxiv.org/pdf/1212.2860v1", 
    "arxiv-id": "1212.2860v1"
},{
    "category": "cs.CV", 
    "author": "Pierre Vandergheynst", 
    "title": "Robust image reconstruction from multi-view measurements", 
    "publish": "2012-12-13T19:00:17Z", 
    "summary": "We propose a novel method to accurately reconstruct a set of images\nrepresenting a single scene from few linear multi-view measurements. Each\nobserved image is modeled as the sum of a background image and a foreground\none. The background image is common to all observed images but undergoes\ngeometric transformations, as the scene is observed from different viewpoints.\nIn this paper, we assume that these geometric transformations are represented\nby a few parameters, e.g., translations, rotations, affine transformations,\netc.. The foreground images differ from one observed image to another, and are\nused to model possible occlusions of the scene. The proposed reconstruction\nalgorithm estimates jointly the images and the transformation parameters from\nthe available multi-view measurements. The ideal solution of this multi-view\nimaging problem minimizes a non-convex functional, and the reconstruction\ntechnique is an alternating descent method built to minimize this functional.\nThe convergence of the proposed algorithm is studied, and conditions under\nwhich the sequence of estimated images and parameters converges to a critical\npoint of the non-convex functional are provided. Finally, the efficiency of the\nalgorithm is demonstrated using numerical simulations for applications such as\ncompressed sensing or super-resolution.", 
    "link": "http://arxiv.org/pdf/1212.3268v3", 
    "arxiv-id": "1212.3268v3"
},{
    "category": "cs.CV", 
    "author": "Somnath Mukhopadhyay", 
    "title": "A Novel Directional Weighted Minimum Deviation (DWMD) Based Filter for   Removal of Random Valued Impulse Noise", 
    "publish": "2012-12-14T00:13:11Z", 
    "summary": "The most median-based de noising methods works fine for restoring the images\ncorrupted by Randomn Valued Impulse Noise with low noise level but very poor\nwith highly corrupted images. In this paper a directional weighted minimum\ndeviation (DWMD) based filter has been proposed for removal of high random\nvalued impulse noise (RVIN). The proposed approach based on Standard Deviation\n(SD) works in two phases. The first phase detects the contaminated pixels by\ndifferencing between the test pixel and its neighbor pixels aligned with four\nmain directions. The second phase filters only those pixels keeping others\nintact. The filtering scheme is based on minimum standard deviation of the four\ndirectional pixels. Extensive simulations show that the proposed filter not\nonly provide better performance of de noising RVIN but can preserve more\ndetails features even thin lines or dots. This technique shows better\nperformance in terms of PSNR, Image Fidelity and Computational Cost compared to\nthe existing filters.", 
    "link": "http://arxiv.org/pdf/1212.3373v1", 
    "arxiv-id": "1212.3373v1"
},{
    "category": "cs.CV", 
    "author": "Bart ter Haar Romeny", 
    "title": "A Multi-Orientation Analysis Approach to Retinal Vessel Tracking", 
    "publish": "2012-12-14T17:04:03Z", 
    "summary": "This paper presents a method for retinal vasculature extraction based on\nbiologically inspired multi-orientation analysis. We apply multi-orientation\nanalysis via so-called invertible orientation scores, modeling the cortical\ncolumns in the visual system of higher mammals. This allows us to generically\ndeal with many hitherto complex problems inherent to vessel tracking, such as\ncrossings, bifurcations, parallel vessels, vessels of varying widths and\nvessels with high curvature. Our approach applies tracking in invertible\norientation scores via a novel geometrical principle for curve optimization in\nthe Euclidean motion group SE(2). The method runs fully automatically and\nprovides a detailed model of the retinal vasculature, which is crucial as a\nsound basis for further quantitative analysis of the retina, especially in\nscreening applications.", 
    "link": "http://arxiv.org/pdf/1212.3530v5", 
    "arxiv-id": "1212.3530v5"
},{
    "category": "cs.CV", 
    "author": "Yong Haur Tay", 
    "title": "Visual Objects Classification with Sliding Spatial Pyramid Matching", 
    "publish": "2012-12-16T09:10:54Z", 
    "summary": "We present a method for visual object classification using only a single\nfeature, transformed color SIFT with a variant of Spatial Pyramid Matching\n(SPM) that we called Sliding Spatial Pyramid Matching (SSPM), trained with an\nensemble of linear regression (provided by LINEAR) to obtained state of the art\nresult on Caltech-101 of 83.46%. SSPM is a special version of SPM where instead\nof dividing an image into K number of regions, a subwindow of fixed size is\nslide around the image with a fixed step size. For each subwindow, a histogram\nof visual words is generated. To obtained the visual vocabulary, instead of\nperforming K-means clustering, we randomly pick N exemplars from the training\nset and encode them with a soft non-linear mapping method. We then trained 15\nmodels, each with a different visual word size with linear regression. All 15\nmodels are then averaged together to form a single strong model.", 
    "link": "http://arxiv.org/pdf/1212.3767v2", 
    "arxiv-id": "1212.3767v2"
},{
    "category": "cs.CV", 
    "author": "Quan Wang", 
    "title": "GMM-Based Hidden Markov Random Field for Color Image and 3D Volume   Segmentation", 
    "publish": "2012-12-18T22:30:23Z", 
    "summary": "In this project, we first study the Gaussian-based hidden Markov random field\n(HMRF) model and its expectation-maximization (EM) algorithm. Then we\ngeneralize it to Gaussian mixture model-based hidden Markov random field. The\nalgorithm is implemented in MATLAB. We also apply this algorithm to color image\nsegmentation problems and 3D volume segmentation problems.", 
    "link": "http://arxiv.org/pdf/1212.4527v1", 
    "arxiv-id": "1212.4527v1"
},{
    "category": "cs.CV", 
    "author": "Ramakrishna Kakarala", 
    "title": "Perceptually Motivated Shape Context Which Uses Shape Interiors", 
    "publish": "2012-12-19T09:40:09Z", 
    "summary": "In this paper, we identify some of the limitations of current-day shape\nmatching techniques. We provide examples of how contour-based shape matching\ntechniques cannot provide a good match for certain visually similar shapes. To\novercome this limitation, we propose a perceptually motivated variant of the\nwell-known shape context descriptor. We identify that the interior properties\nof the shape play an important role in object recognition and develop a\ndescriptor that captures these interior properties. We show that our method can\neasily be augmented with any other shape matching algorithm. We also show from\nour experiments that the use of our descriptor can significantly improve the\nretrieval rates.", 
    "link": "http://arxiv.org/pdf/1212.4608v1", 
    "arxiv-id": "1212.4608v1"
},{
    "category": "cs.CV", 
    "author": "Yong Haur Tay", 
    "title": "On the Adaptability of Neural Network Image Super-Resolution", 
    "publish": "2012-12-21T07:30:38Z", 
    "summary": "In this paper, we described and developed a framework for Multilayer\nPerceptron (MLP) to work on low level image processing, where MLP will be used\nto perform image super-resolution. Meanwhile, MLP are trained with different\ntypes of images from various categories, hence analyse the behaviour and\nperformance of the neural network. The tests are carried out using qualitative\ntest, in which Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR) and\nStructural Similarity Index (SSIM). The results showed that MLP trained with\nsingle image category can perform reasonably well compared to methods proposed\nby other researchers.", 
    "link": "http://arxiv.org/pdf/1212.5352v1", 
    "arxiv-id": "1212.5352v1"
},{
    "category": "cs.CV", 
    "author": "Jean-Michel Morel", 
    "title": "High-precision camera distortion measurements with a \"calibration harp\"", 
    "publish": "2012-12-22T05:00:01Z", 
    "summary": "This paper addresses the high precision measurement of the distortion of a\ndigital camera from photographs. Traditionally, this distortion is measured\nfrom photographs of a flat pattern which contains aligned elements.\nNevertheless, it is nearly impossible to fabricate a very flat pattern and to\nvalidate its flatness. This fact limits the attainable measurable precisions.\nIn contrast, it is much easier to obtain physically very precise straight lines\nby tightly stretching good quality strings on a frame. Taking literally\n\"plumb-line methods\", we built a \"calibration harp\" instead of the classic flat\npatterns to obtain a high precision measurement tool, demonstrably reaching\n2/100 pixel precisions. The harp is complemented with the algorithms computing\nautomatically from harp photographs two different and complementary lens\ndistortion measurements. The precision of the method is evaluated on images\ncorrected by state-of-the-art distortion correction algorithms, and by popular\nsoftware. Three applications are shown: first an objective and reliable\nmeasurement of the result of any distortion correction. Second, the harp\npermits to control state-of-the art global camera calibration algorithms: It\npermits to select the right distortion model, thus avoiding internal\ncompensation errors inherent to these methods. Third, the method replaces\nmanual procedures in other distortion correction methods, makes them fully\nautomatic, and increases their reliability and precision.", 
    "link": "http://arxiv.org/pdf/1212.5656v1", 
    "arxiv-id": "1212.5656v1"
},{
    "category": "cs.CV", 
    "author": "Suyash P. Awate", 
    "title": "Hierarchical Graphical Models for Multigroup Shape Analysis using   Expectation Maximization with Sampling in Kendall's Shape Space", 
    "publish": "2012-12-22T20:27:22Z", 
    "summary": "This paper proposes a novel framework for multi-group shape analysis relying\non a hierarchical graphical statistical model on shapes within a population.The\nframework represents individual shapes as point setsmodulo translation,\nrotation, and scale, following the notion in Kendall shape space.While\nindividual shapes are derived from their group shape model, each group shape\nmodel is derived from a single population shape model. The hierarchical model\nfollows the natural organization of population data and the top level in the\nhierarchy provides a common frame of reference for multigroup shape analysis,\ne.g. classification and hypothesis testing. Unlike typical shape-modeling\napproaches, the proposed model is a generative model that defines a joint\ndistribution of object-boundary data and the shape-model variables.\nFurthermore, it naturally enforces optimal correspondences during the process\nof model fitting and thereby subsumes the so-called correspondence problem. The\nproposed inference scheme employs an expectation maximization (EM) algorithm\nthat treats the individual and group shape variables as hidden random variables\nand integrates them out before estimating the parameters (population mean and\nvariance and the group variances). The underpinning of the EM algorithm is the\nsampling of pointsets, in Kendall shape space, from their posterior\ndistribution, for which we exploit a highly-efficient scheme based on\nHamiltonian Monte Carlo simulation. Experiments in this paper use the fitted\nhierarchical model to perform (1) hypothesis testing for comparison between\npairs of groups using permutation testing and (2) classification for image\nretrieval. The paper validates the proposed framework on simulated data and\ndemonstrates results on real data.", 
    "link": "http://arxiv.org/pdf/1212.5720v2", 
    "arxiv-id": "1212.5720v2"
},{
    "category": "cs.CV", 
    "author": "Kai Yu", 
    "title": "Large Scale Strongly Supervised Ensemble Metric Learning, with   Applications to Face Verification and Retrieval", 
    "publish": "2012-12-25T22:49:31Z", 
    "summary": "Learning Mahanalobis distance metrics in a high- dimensional feature space is\nvery difficult especially when structural sparsity and low rank are enforced to\nimprove com- putational efficiency in testing phase. This paper addresses both\naspects by an ensemble metric learning approach that consists of sparse block\ndiagonal metric ensembling and join- t metric learning as two consecutive\nsteps. The former step pursues a highly sparse block diagonal metric by\nselecting effective feature groups while the latter one further exploits\ncorrelations between selected feature groups to obtain an accurate and low rank\nmetric. Our algorithm considers all pairwise or triplet constraints generated\nfrom training samples with explicit class labels, and possesses good scala-\nbility with respect to increasing feature dimensionality and growing data\nvolumes. Its applications to face verification and retrieval outperform\nexisting state-of-the-art methods in accuracy while retaining high efficiency.", 
    "link": "http://arxiv.org/pdf/1212.6094v1", 
    "arxiv-id": "1212.6094v1"
},{
    "category": "cs.CV", 
    "author": "H. J. Moukalled", 
    "title": "On Automation and Medical Image Interpretation, With Applications for   Laryngeal Imaging", 
    "publish": "2012-12-31T17:38:02Z", 
    "summary": "Indeed, these are exciting times. We are in the heart of a digital\nrenaissance. Automation and computer technology allow engineers and scientists\nto fabricate processes that amalgamate quality of life. We anticipate much\ngrowth in medical image interpretation and understanding, due to the influx of\ncomputer technologies. This work should serve as a guide to introduce the\nreader to core themes in theoretical computer science, as well as imaging\napplications for understanding vocal-fold vibrations. In this work, we motivate\nthe use of automation, review some mathematical models of computation. We\npresent a proof of a classical problem in image analysis that cannot be\nautomated by means of algorithms. Furthermore, discuss some applications for\nprocessing medical images of the vocal folds, and discuss some of the\nexhilarating directions the art of automation will take vocal-fold image\ninterpretation and quite possibly other areas of biomedical image analysis.", 
    "link": "http://arxiv.org/pdf/1212.6933v3", 
    "arxiv-id": "1212.6933v3"
},{
    "category": "cs.CV", 
    "author": "Prasanta K. Panigrahi", 
    "title": "A Semi-automated Statistical Algorithm for Object Separation", 
    "publish": "2013-01-01T19:51:28Z", 
    "summary": "We explicate a semi-automated statistical algorithm for object identification\nand segregation in both gray scale and color images. The algorithm makes\noptimal use of the observation that definite objects in an image are typically\nrepresented by pixel values having narrow Gaussian distributions about\ncharacteristic mean values. Furthermore, for visually distinct objects, the\ncorresponding Gaussian distributions have negligible overlap with each other\nand hence the Mahalanobis distance between these distributions are large. These\nstatistical facts enable one to sub-divide images into multiple thresholds of\nvariable sizes, each segregating similar objects. The procedure incorporates\nthe sensitivity of human eye to the gray pixel values into the variable\nthreshold size, while mapping the Gaussian distributions into localized\n\\delta-functions, for object separation. The effectiveness of this recursive\nstatistical algorithm is demonstrated using a wide variety of images.", 
    "link": "http://arxiv.org/pdf/1301.0127v3", 
    "arxiv-id": "1301.0127v3"
},{
    "category": "cs.CV", 
    "author": "Murthy K. Srikanta", 
    "title": "Classifier Fusion Method to Recognize Handwritten Kannada Numerals", 
    "publish": "2013-01-02T04:45:44Z", 
    "summary": "Optical Character Recognition (OCR) is one of the important fields in image\nprocessing and pattern recognition domain. Handwritten character recognition\nhas always been a challenging task. Only a little work can be traced towards\nthe recognition of handwritten characters for the south Indian languages.\nKannada is one such south Indian language which is also one of the official\nlanguage of India. Accurate recognition of Kannada characters is a challenging\ntask because of the high degree of similarity between the characters. Hence,\ngood quality features are to be extracted and better classifiers are needed to\nimprove the accuracy of the OCR for Kannada characters. This paper explores the\neffectiveness of feature extraction method like run length count (RLC) and\ndirectional chain code (DCC) for the recognition of handwritten Kannada\nnumerals. In this paper, a classifier fusion method is implemented to improve\nthe recognition rate. For the classifier fusion, we have considered K-nearest\nneighbour (KNN) and Linear classifier (LC). The novelty of this method is to\nachieve better accuracy with few features using classifier fusion approach.\nProposed method achieves an average recognition rate of 96%.", 
    "link": "http://arxiv.org/pdf/1301.0167v1", 
    "arxiv-id": "1301.0167v1"
},{
    "category": "cs.CV", 
    "author": "F. Kunwar", 
    "title": "A Self-Organizing Neural Scheme for Door Detection in Different   Environments", 
    "publish": "2013-01-03T12:04:28Z", 
    "summary": "Doors are important landmarks for indoor mobile robot navigation and also\nassist blind people to independently access unfamiliar buildings. Most existing\nalgorithms of door detection are limited to work for familiar environments\nbecause of restricted assumptions about color, texture and shape. In this paper\nwe propose a novel approach which employs feature based classification and uses\nthe Kohonen Self-Organizing Map (SOM) for the purpose of door detection.\nGeneric and stable features are used for the training of SOM that increase the\nperformance significantly: concavity, bottom-edge intensity profile and door\nedges. To validate the robustness and generalizability of our method, we\ncollected a large dataset of real world door images from a variety of\nenvironments and different lighting conditions. The algorithm achieves more\nthan 95% detection which demonstrates that our door detection method is generic\nand robust with variations of color, texture, occlusions, lighting condition,\nscales, and viewpoints.", 
    "link": "http://arxiv.org/pdf/1301.0432v1", 
    "arxiv-id": "1301.0432v1"
},{
    "category": "cs.CV", 
    "author": "Tele Tan", 
    "title": "Adaptive Foreground and Shadow Detection inImage Sequences", 
    "publish": "2012-12-12T15:59:10Z", 
    "summary": "This paper presents a novel method of foreground segmentation that\ndistinguishes moving objects from their moving cast shadows in monocular image\nsequences. The models of background, edge information, and shadow are set up\nand adaptively updated. A Bayesian belief network is proposed to describe the\nrelationships among the segmentation label, background, intensity, and edge\ninformation. The notion of Markov random field is used to encourage the spatial\nconnectivity of the segmented regions. The solution is obtained by maximizing\nthe posterior possibility density of the segmentation field.", 
    "link": "http://arxiv.org/pdf/1301.0612v1", 
    "arxiv-id": "1301.0612v1"
},{
    "category": "cs.CV", 
    "author": "Banshidhar Majhi", 
    "title": "Stratified SIFT Matching for Human Iris Recognition", 
    "publish": "2013-01-06T12:05:28Z", 
    "summary": "This paper proposes an efficient three fold stratified SIFT matching for iris\nrecognition. The objective is to filter wrongly paired conventional SIFT\nmatches. In Strata I, the keypoints from gallery and probe iris images are\npaired using traditional SIFT approach. Due to high image similarity at\ndifferent regions of iris there may be some impairments. These are detected and\nfiltered by finding gradient of paired keypoints in Strata II. Further, the\nscaling factor of paired keypoints is used to remove impairments in Strata III.\nThe pairs retained after Strata III are likely to be potential matches for iris\nrecognition. The proposed system performs with an accuracy of 96.08% and 97.15%\non publicly available CASIAV3 and BATH databases respectively. This marks\nsignificant improvement of accuracy and FAR over the existing SIFT matching for\niris.", 
    "link": "http://arxiv.org/pdf/1301.0998v1", 
    "arxiv-id": "1301.0998v1"
},{
    "category": "cs.CV", 
    "author": "N. Vaswani", 
    "title": "PaFiMoCS: Particle Filtered Modified-CS and Applications in Visual   Tracking across Illumination Change", 
    "publish": "2013-01-08T01:18:21Z", 
    "summary": "We study the problem of tracking (causally estimating) a time sequence of\nsparse spatial signals with changing sparsity patterns, as well as other\nunknown states, from a sequence of nonlinear observations corrupted by\n(possibly) non-Gaussian noise. In many applications, particularly those in\nvisual tracking, the unknown state can be split into a small dimensional part,\ne.g. global motion, and a spatial signal, e.g. illumination or shape\ndeformation. The spatial signal is often well modeled as being sparse in some\ndomain. For a long sequence, its sparsity pattern can change over time,\nalthough the changes are usually slow. To address the above problem, we propose\na novel solution approach called Particle Filtered Modified-CS (PaFiMoCS). The\nkey idea of PaFiMoCS is to importance sample for the small dimensional state\nvector, while replacing importance sampling by slow sparsity pattern change\nconstrained posterior mode tracking for recovering the sparse spatial signal.\nWe show that the problem of tracking moving objects across spatially varying\nillumination change is an example of the above problem and explain how to\ndesign PaFiMoCS for it. Experiments on both simulated data as well as on real\nvideos with significant illumination changes demonstrate the superiority of the\nproposed algorithm as compared with existing particle filter based tracking\nalgorithms.", 
    "link": "http://arxiv.org/pdf/1301.1374v1", 
    "arxiv-id": "1301.1374v1"
},{
    "category": "cs.CV", 
    "author": "Philipp Ewerling", 
    "title": "A novel processing pipeline for optical multi-touch surfaces", 
    "publish": "2013-01-08T14:48:23Z", 
    "summary": "In this thesis a new approach for touch detection on optical multi-touch\ndevices is proposed that exploits the fact that the camera images reveal not\nonly the actual touch points but also objects above the screen such as the hand\nor arm of a user. The touch processing relies on the Maximally Stable Extremal\nRegions algorithm for finding the users' fingertips in the camera image. The\nhierarchical structure of the generated extremal regions serves as a starting\npoint for agglomerative clustering of the fingertips into hands. Furthermore, a\nheuristic is suggested that supports the identification of individual fingers\nas well as the distinction between left hands and right hands if all five\nfingers of a hand are in contact with the touch surface.\n  The evaluation confirmed that the system is robust against detection errors\nresulting from non-uniform illumination and reliably assigns touch points to\nindividual hands based on the implicitly tracked context information. The\nefficient multi-threaded implementation handles two-handed input from multiple\nusers in real-time.", 
    "link": "http://arxiv.org/pdf/1301.1551v1", 
    "arxiv-id": "1301.1551v1"
},{
    "category": "cs.CV", 
    "author": "Yann LeCun", 
    "title": "Causal graph-based video segmentation", 
    "publish": "2013-01-08T20:56:17Z", 
    "summary": "Numerous approaches in image processing and computer vision are making use of\nsuper-pixels as a pre-processing step. Among the different methods producing\nsuch over-segmentation of an image, the graph-based approach of Felzenszwalb\nand Huttenlocher is broadly employed. One of its interesting properties is that\nthe regions are computed in a greedy manner in quasi-linear time. The algorithm\nmay be trivially extended to video segmentation by considering a video as a 3D\nvolume, however, this can not be the case for causal segmentation, when\nsubsequent frames are unknown. We propose an efficient video segmentation\napproach that computes temporally consistent pixels in a causal manner, filling\nthe need for causal and real time applications.", 
    "link": "http://arxiv.org/pdf/1301.1671v1", 
    "arxiv-id": "1301.1671v1"
},{
    "category": "cs.CV", 
    "author": "Ralf Koetter", 
    "title": "A Factorized Variational Technique for Phase Unwrapping in Markov Random   Fields", 
    "publish": "2013-01-10T16:22:19Z", 
    "summary": "Some types of medical and topographic imaging device produce images in which\nthe pixel values are \"phase-wrapped\", i.e. measured modulus a known scalar.\nPhase unwrapping can be viewed as the problem of inferring the number of shifts\nbetween each and every pair of neighboring pixels, subject to an a priori\npreference for smooth surfaces, and subject to a zero curl constraint, which\nrequires that the shifts must sum to 0 around every loop. We formulate phase\nunwrapping as a mean field inference problem in a Markov network, where the\nprior favors the zero curl constraint. We compare our mean field technique with\nthe least squares method on a synthetic 100x100 image, and give results on a\n512x512 synthetic aperture radar image from Sandia National Laboratories.<Long\nText>", 
    "link": "http://arxiv.org/pdf/1301.2252v1", 
    "arxiv-id": "1301.2252v1"
},{
    "category": "cs.CV", 
    "author": "Clement Farabet", 
    "title": "Clustering Learning for Robotic Vision", 
    "publish": "2013-01-13T20:49:30Z", 
    "summary": "We present the clustering learning technique applied to multi-layer\nfeedforward deep neural networks. We show that this unsupervised learning\ntechnique can compute network filters with only a few minutes and a much\nreduced set of parameters. The goal of this paper is to promote the technique\nfor general-purpose robotic vision systems. We report its use in static image\ndatasets and object tracking datasets. We show that networks trained with\nclustering learning can outperform large networks trained for many hours on\ncomplex datasets.", 
    "link": "http://arxiv.org/pdf/1301.2820v3", 
    "arxiv-id": "1301.2820v3"
},{
    "category": "cs.CV", 
    "author": "Guoping Qiu", 
    "title": "Wavelet-based Scale Saliency", 
    "publish": "2013-01-14T08:36:00Z", 
    "summary": "Both pixel-based scale saliency (PSS) and basis project methods focus on\nmultiscale analysis of data content and structure. Their theoretical relations\nand practical combination are previously discussed. However, no models have\never been proposed for calculating scale saliency on basis-projected\ndescriptors since then. This paper extend those ideas into mathematical models\nand implement them in the wavelet-based scale saliency (WSS). While PSS uses\npixel-value descriptors, WSS treats wavelet sub-bands as basis descriptors. The\npaper discusses different wavelet descriptors: discrete wavelet transform\n(DWT), wavelet packet transform (DWPT), quaternion wavelet transform (QWT) and\nbest basis quaternion wavelet packet transform (QWPTBB). WSS saliency maps of\ndifferent descriptors are generated and compared against other saliency methods\nby both quantitative and quanlitative methods. Quantitative results, ROC\ncurves, AUC values and NSS values are collected from simulations on Bruce and\nKootstra image databases with human eye-tracking data as ground-truth.\nFurthermore, qualitative visual results of saliency maps are analyzed and\ncompared against each other as well as eye-tracking data inclusive in the\ndatabases.", 
    "link": "http://arxiv.org/pdf/1301.2884v1", 
    "arxiv-id": "1301.2884v1"
},{
    "category": "cs.CV", 
    "author": "Itamar Arel", 
    "title": "Recurrent Online Clustering as a Spatio-Temporal Feature Extractor in   DeSTIN", 
    "publish": "2013-01-15T15:34:07Z", 
    "summary": "This paper presents a basic enhancement to the DeSTIN deep learning\narchitecture by replacing the explicitly calculated transition tables that are\nused to capture temporal features with a simpler, more scalable mechanism. This\nmechanism uses feedback of state information to cluster over a space comprised\nof both the spatial input and the current state. The resulting architecture\nachieves state-of-the-art results on the MNIST classification benchmark.", 
    "link": "http://arxiv.org/pdf/1301.3385v2", 
    "arxiv-id": "1301.3385v2"
},{
    "category": "cs.CV", 
    "author": "Kris Gunsalus", 
    "title": "A Geometric Descriptor for Cell-Division Detection", 
    "publish": "2013-01-15T19:18:52Z", 
    "summary": "We describe a method for cell-division detection based on a geometric-driven\ndescriptor that can be represented as a 5-layers processing network, based\nmainly on wavelet filtering and a test for mirror symmetry between pairs of\npixels. After the centroids of the descriptors are computed for a sequence of\nframes, the two-steps piecewise constant function that best fits the sequence\nof centroids determines the frame where the division occurs.", 
    "link": "http://arxiv.org/pdf/1301.3457v2", 
    "arxiv-id": "1301.3457v2"
},{
    "category": "cs.CV", 
    "author": "Roozbeh Mottaghi", 
    "title": "Complexity of Representation and Inference in Compositional Models with   Part Sharing", 
    "publish": "2013-01-16T02:29:15Z", 
    "summary": "This paper describes serial and parallel compositional models of multiple\nobjects with part sharing. Objects are built by part-subpart compositions and\nexpressed in terms of a hierarchical dictionary of object parts. These parts\nare represented on lattices of decreasing sizes which yield an executive\nsummary description. We describe inference and learning algorithms for these\nmodels. We analyze the complexity of this model in terms of computation time\n(for serial computers) and numbers of nodes (e.g., \"neurons\") for parallel\ncomputers. In particular, we compute the complexity gains by part sharing and\nits dependence on how the dictionary scales with the level of the hierarchy. We\nexplore three regimes of scaling behavior where the dictionary size (i)\nincreases exponentially with the level, (ii) is determined by an unsupervised\ncompositional learning algorithm applied to real data, (iii) decreases\nexponentially with scale. This analysis shows that in some regimes the use of\nshared parts enables algorithms which can perform inference in time linear in\nthe number of levels for an exponential number of objects. In other regimes\npart sharing has little advantage for serial computers but can give linear\nprocessing on parallel computers.", 
    "link": "http://arxiv.org/pdf/1301.3560v1", 
    "arxiv-id": "1301.3560v1"
},{
    "category": "cs.CV", 
    "author": "Yann LeCun", 
    "title": "Indoor Semantic Segmentation using depth information", 
    "publish": "2013-01-16T03:31:30Z", 
    "summary": "This work addresses multi-class segmentation of indoor scenes with RGB-D\ninputs. While this area of research has gained much attention recently, most\nworks still rely on hand-crafted features. In contrast, we apply a multiscale\nconvolutional network to learn features directly from the images and the depth\ninformation. We obtain state-of-the-art on the NYU-v2 depth dataset with an\naccuracy of 64.5%. We illustrate the labeling of indoor scenes in videos\nsequences that could be processed in real-time using appropriate hardware such\nas an FPGA.", 
    "link": "http://arxiv.org/pdf/1301.3572v2", 
    "arxiv-id": "1301.3572v2"
},{
    "category": "cs.CV", 
    "author": "Itamar Arel", 
    "title": "Gradient Driven Learning for Pooling in Visual Pipeline Feature   Extraction Models", 
    "publish": "2013-01-16T17:05:57Z", 
    "summary": "Hyper-parameter selection remains a daunting task when building a pattern\nrecognition architecture which performs well, particularly in recently\nconstructed visual pipeline models for feature extraction. We re-formulate\npooling in an existing pipeline as a function of adjustable pooling map weight\nparameters and propose the use of supervised error signals from gradient\ndescent to tune the established maps within the model. This technique allows us\nto learn what would otherwise be a design choice within the model and\nspecialize the maps to aggregate areas of invariance for the task presented.\nPreliminary results show moderate potential gains in classification accuracy\nand highlight areas of importance within the intermediate feature\nrepresentation space.", 
    "link": "http://arxiv.org/pdf/1301.3755v1", 
    "arxiv-id": "1301.3755v1"
},{
    "category": "cs.CV", 
    "author": "Jasmine Seng Kah-Phooi", 
    "title": "Multiscale Discriminant Saliency for Visual Attention", 
    "publish": "2013-01-17T02:12:48Z", 
    "summary": "The bottom-up saliency, an early stage of humans' visual attention, can be\nconsidered as a binary classification problem between center and surround\nclasses. Discriminant power of features for the classification is measured as\nmutual information between features and two classes distribution. The estimated\ndiscrepancy of two feature classes very much depends on considered scale\nlevels; then, multi-scale structure and discriminant power are integrated by\nemploying discrete wavelet features and Hidden markov tree (HMT). With wavelet\ncoefficients and Hidden Markov Tree parameters, quad-tree like label structures\nare constructed and utilized in maximum a posterior probability (MAP) of hidden\nclass variables at corresponding dyadic sub-squares. Then, saliency value for\neach dyadic square at each scale level is computed with discriminant power\nprinciple and the MAP. Finally, across multiple scales is integrated the final\nsaliency map by an information maximization rule. Both standard quantitative\ntools such as NSS, LCC, AUC and qualitative assessments are used for evaluating\nthe proposed multiscale discriminant saliency method (MDIS) against the\nwell-know information-based saliency method AIM on its Bruce Database wity\neye-tracking data. Simulation results are presented and analyzed to verify the\nvalidity of MDIS as well as point out its disadvantages for further research\ndirection.", 
    "link": "http://arxiv.org/pdf/1301.3964v1", 
    "arxiv-id": "1301.3964v1"
},{
    "category": "cs.CV", 
    "author": "Ikram Miled", 
    "title": "Multiple models of Bayesian networks applied to offline recognition of   Arabic handwritten city names", 
    "publish": "2013-01-18T13:26:55Z", 
    "summary": "In this paper we address the problem of offline Arabic handwriting word\nrecognition. Off-line recognition of handwritten words is a difficult task due\nto the high variability and uncertainty of human writing. The majority of the\nrecent systems are constrained by the size of the lexicon to deal with and the\nnumber of writers. In this paper, we propose an approach for multi-writers\nArabic handwritten words recognition using multiple Bayesian networks. First,\nwe cut the image in several blocks. For each block, we compute a vector of\ndescriptors. Then, we use K-means to cluster the low-level features including\nZernik and Hu moments. Finally, we apply four variants of Bayesian networks\nclassifiers (Na\\\"ive Bayes, Tree Augmented Na\\\"ive Bayes (TAN), Forest\nAugmented Na\\\"ive Bayes (FAN) and DBN (dynamic bayesian network) to classify\nthe whole image of tunisian city name. The results demonstrate FAN and DBN\noutperform good recognition rates", 
    "link": "http://arxiv.org/pdf/1301.4377v1", 
    "arxiv-id": "1301.4377v1"
},{
    "category": "cs.CV", 
    "author": "Abdelmajid Ben Hamadou", 
    "title": "Lip Localization and Viseme Classification for Visual Speech Recognition", 
    "publish": "2013-01-19T11:36:53Z", 
    "summary": "The need for an automatic lip-reading system is ever increasing. Infact,\ntoday, extraction and reliable analysis of facial movements make up an\nimportant part in many multimedia systems such as videoconference, low\ncommunication systems, lip-reading systems. In addition, visual information is\nimperative among people with special needs. We can imagine, for example, a\ndependent person ordering a machine with an easy lip movement or by a simple\nsyllable pronunciation. Moreover, people with hearing problems compensate for\ntheir special needs by lip-reading as well as listening to the person with\nwhome they are talking.", 
    "link": "http://arxiv.org/pdf/1301.4558v1", 
    "arxiv-id": "1301.4558v1"
},{
    "category": "cs.CV", 
    "author": "A. Aydin Alatan", 
    "title": "Efficient MRF Energy Propagation for Video Segmentation via Bilateral   Filters", 
    "publish": "2013-01-22T22:26:33Z", 
    "summary": "Segmentation of an object from a video is a challenging task in multimedia\napplications. Depending on the application, automatic or interactive methods\nare desired; however, regardless of the application type, efficient computation\nof video object segmentation is crucial for time-critical applications;\nspecifically, mobile and interactive applications require near real-time\nefficiencies. In this paper, we address the problem of video segmentation from\nthe perspective of efficiency. We initially redefine the problem of video\nobject segmentation as the propagation of MRF energies along the temporal\ndomain. For this purpose, a novel and efficient method is proposed to propagate\nMRF energies throughout the frames via bilateral filters without using any\nglobal texture, color or shape model. Recently presented bi-exponential filter\nis utilized for efficiency, whereas a novel technique is also developed to\ndynamically solve graph-cuts for varying, non-lattice graphs in general linear\nfiltering scenario. These improvements are experimented for both automatic and\ninteractive video segmentation scenarios. Moreover, in addition to the\nefficiency, segmentation quality is also tested both quantitatively and\nqualitatively. Indeed, for some challenging examples, significant time\nefficiency is observed without loss of segmentation quality.", 
    "link": "http://arxiv.org/pdf/1301.5356v3", 
    "arxiv-id": "1301.5356v3"
},{
    "category": "cs.CV", 
    "author": "Joan Lasenby", 
    "title": "ChESS - Quick and Robust Detection of Chess-board Features", 
    "publish": "2013-01-23T13:10:21Z", 
    "summary": "Localization of chess-board vertices is a common task in computer vision,\nunderpinning many applications, but relatively little work focusses on\ndesigning a specific feature detector that is fast, accurate and robust. In\nthis paper the `Chess-board Extraction by Subtraction and Summation' (ChESS)\nfeature detector, designed to exclusively respond to chess-board vertices, is\npresented. The method proposed is robust against noise, poor lighting and poor\ncontrast, requires no prior knowledge of the extent of the chess-board pattern,\nis computationally very efficient, and provides a strength measure of detected\nfeatures. Such a detector has significant application both in the key field of\ncamera calibration, as well as in Structured Light 3D reconstruction. Evidence\nis presented showing its robustness, accuracy, and efficiency in comparison to\nother commonly used detectors both under simulation and in experimental 3D\nreconstruction of flat plate and cylindrical objects", 
    "link": "http://arxiv.org/pdf/1301.5491v1", 
    "arxiv-id": "1301.5491v1"
},{
    "category": "cs.CV", 
    "author": "Pascal Frossard", 
    "title": "Image registration with sparse approximations in parametric dictionaries", 
    "publish": "2013-01-28T19:06:44Z", 
    "summary": "We examine in this paper the problem of image registration from the new\nperspective where images are given by sparse approximations in parametric\ndictionaries of geometric functions. We propose a registration algorithm that\nlooks for an estimate of the global transformation between sparse images by\nexamining the set of relative geometrical transformations between the\nrespective features. We propose a theoretical analysis of our registration\nalgorithm and we derive performance guarantees based on two novel important\nproperties of redundant dictionaries, namely the robust linear independence and\nthe transformation inconsistency. We propose several illustrations and insights\nabout the importance of these dictionary properties and show that common\nproperties such as coherence or restricted isometry property fail to provide\nsufficient information in registration problems. We finally show with\nillustrative experiments on simple visual objects and handwritten digits images\nthat our algorithm outperforms baseline competitor methods in terms of\ntransformation-invariant distance computation and classification.", 
    "link": "http://arxiv.org/pdf/1301.6646v2", 
    "arxiv-id": "1301.6646v2"
},{
    "category": "cs.CV", 
    "author": "Zhilin Zhang", 
    "title": "Robust Face Recognition via Block Sparse Bayesian Learning", 
    "publish": "2013-01-29T07:23:00Z", 
    "summary": "Face recognition (FR) is an important task in pattern recognition and\ncomputer vision. Sparse representation (SR) has been demonstrated to be a\npowerful framework for FR. In general, an SR algorithm treats each face in a\ntraining dataset as a basis function, and tries to find a sparse representation\nof a test face under these basis functions. The sparse representation\ncoefficients then provide a recognition hint. Early SR algorithms are based on\na basic sparse model. Recently, it has been found that algorithms based on a\nblock sparse model can achieve better recognition rates. Based on this model,\nin this study we use block sparse Bayesian learning (BSBL) to find a sparse\nrepresentation of a test face for recognition. BSBL is a recently proposed\nframework, which has many advantages over existing block-sparse-model based\nalgorithms. Experimental results on the Extended Yale B, the AR and the CMU PIE\nface databases show that using BSBL can achieve better recognition rates and\nhigher robustness than state-of-the-art algorithms in most cases.", 
    "link": "http://arxiv.org/pdf/1301.6847v2", 
    "arxiv-id": "1301.6847v2"
},{
    "category": "cs.CV", 
    "author": "Jasmine Kah-Phooi Seng", 
    "title": "Multi-scale Discriminant Saliency with Wavelet-based Hidden Markov Tree   Modelling", 
    "publish": "2013-01-31T15:20:17Z", 
    "summary": "The bottom-up saliency, an early stage of humans' visual attention, can be\nconsidered as a binary classification problem between centre and surround\nclasses. Discriminant power of features for the classification is measured as\nmutual information between distributions of image features and corresponding\nclasses . As the estimated discrepancy very much depends on considered scale\nlevel, multi-scale structure and discriminant power are integrated by employing\ndiscrete wavelet features and Hidden Markov Tree (HMT). With wavelet\ncoefficients and Hidden Markov Tree parameters, quad-tree like label structures\nare constructed and utilized in maximum a posterior probability (MAP) of hidden\nclass variables at corresponding dyadic sub-squares. Then, a saliency value for\neach square block at each scale level is computed with discriminant power\nprinciple. Finally, across multiple scales is integrated the final saliency map\nby an information maximization rule. Both standard quantitative tools such as\nNSS, LCC, AUC and qualitative assessments are used for evaluating the proposed\nmulti-scale discriminant saliency (MDIS) method against the well-know\ninformation based approach AIM on its released image collection with\neye-tracking data. Simulation results are presented and analysed to verify the\nvalidity of MDIS as well as point out its limitation for further research\ndirection.", 
    "link": "http://arxiv.org/pdf/1301.7641v2", 
    "arxiv-id": "1301.7641v2"
},{
    "category": "cs.CV", 
    "author": "Jasmine Kah-Phooi Seng", 
    "title": "Fast non parametric entropy estimation for spatial-temporal saliency   method", 
    "publish": "2013-01-31T16:05:26Z", 
    "summary": "This paper formulates bottom-up visual saliency as center surround\nconditional entropy and presents a fast and efficient technique for the\ncomputation of such a saliency map. It is shown that the new saliency\nformulation is consistent with self-information based saliency,\ndecision-theoretic saliency and Bayesian definition of surprises but also faces\nthe same significant computational challenge of estimating probability density\nin very high dimensional spaces with limited samples. We have developed a fast\nand efficient nonparametric method to make the practical implementation of\nthese types of saliency maps possible. By aligning pixels from the center and\nsurround regions and treating their location coordinates as random variables,\nwe use a k-d partitioning method to efficiently estimating the center surround\nconditional entropy. We present experimental results on two publicly available\neye tracking still image databases and show that the new technique is\ncompetitive with state of the art bottom-up saliency computational methods. We\nhave also extended the technique to compute spatiotemporal visual saliency of\nvideo and evaluate the bottom-up spatiotemporal saliency against eye tracking\ndata on a video taken onboard a moving vehicle with the driver's eye being\ntracked by a head mounted eye-tracker.", 
    "link": "http://arxiv.org/pdf/1301.7661v1", 
    "arxiv-id": "1301.7661v1"
},{
    "category": "cs.CV", 
    "author": "Binjie Qin", 
    "title": "Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for   Nonrigid Image Registration", 
    "publish": "2013-03-03T09:15:25Z", 
    "summary": "Joint saliency map (JSM) [1] was developed to assign high joint saliency\nvalues to the corresponding saliency structures (called Joint Saliency\nStructures, JSSs) but zero or low joint saliency values to the outliers (or\nmismatches) that are introduced by missing correspondence or local large\ndeformations between the reference and moving images to be registered. JSM\nguides the local structure matching in nonrigid registration by emphasizing\nthese JSSs' sparse deformation vectors in adaptive kernel regression of\nhierarchical sparse deformation vectors for iterative dense deformation\nreconstruction. By designing an effective superpixel-based local structure\nscale estimator to compute the reference structure's structure scale, we\nfurther propose to determine the scale (the width) of kernels in the adaptive\nkernel regression through combining the structure scales to JSM-based scales of\nmismatch between the local saliency structures. Therefore, we can adaptively\nselect the sample size of sparse deformation vectors to reconstruct the dense\ndeformation vectors for accurately matching the every local structures in the\ntwo images. The experimental results demonstrate better accuracy of our method\nin aligning two images with missing correspondence and local large deformation\nthan the state-of-the-art methods.", 
    "link": "http://arxiv.org/pdf/1303.0479v2", 
    "arxiv-id": "1303.0479v2"
},{
    "category": "cs.CV", 
    "author": "Andreas Spanias", 
    "title": "Multiple Kernel Sparse Representations for Supervised and Unsupervised   Learning", 
    "publish": "2013-03-03T23:41:34Z", 
    "summary": "In complex visual recognition tasks it is typical to adopt multiple\ndescriptors, that describe different aspects of the images, for obtaining an\nimproved recognition performance. Descriptors that have diverse forms can be\nfused into a unified feature space in a principled manner using kernel methods.\nSparse models that generalize well to the test data can be learned in the\nunified kernel space, and appropriate constraints can be incorporated for\napplication in supervised and unsupervised learning. In this paper, we propose\nto perform sparse coding and dictionary learning in the multiple kernel space,\nwhere the weights of the ensemble kernel are tuned based on graph-embedding\nprinciples such that class discrimination is maximized. In our proposed\nalgorithm, dictionaries are inferred using multiple levels of 1-D subspace\nclustering in the kernel space, and the sparse codes are obtained using a\nsimple levelwise pursuit scheme. Empirical results for object recognition and\nimage clustering show that our algorithm outperforms existing sparse coding\nbased approaches, and compares favorably to other state-of-the-art methods.", 
    "link": "http://arxiv.org/pdf/1303.0582v2", 
    "arxiv-id": "1303.0582v2"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "Omega Model for Human Detection and Counting for application in Smart   Surveillance System", 
    "publish": "2013-03-04T08:01:36Z", 
    "summary": "Driven by the significant advancements in technology and social issues such\nas security management, there is a strong need for Smart Surveillance System in\nour society today. One of the key features of a Smart Surveillance System is\nefficient human detection and counting such that the system can decide and\nlabel events on its own. In this paper we propose a new, novel and robust\nmodel, The Omega Model, for detecting and counting human beings present in the\nscene. The proposed model employs a set of four distinct descriptors for\nidentifying the unique features of the head, neck and shoulder regions of a\nperson. This unique head neck shoulder signature given by the Omega Model\nexploits the challenges such as inter person variations in size and shape of\npeoples head, neck and shoulder regions to achieve robust detection of human\nbeings even under partial occlusion, dynamically changing background and\nvarying illumination conditions. After experimentation we observe and analyze\nthe influences of each of the four descriptors on the system performance and\ncomputation speed and conclude that a weight based decision making system\nproduces the best results. Evaluation results on a number of images indicate\nthe validation of our method in actual situation.", 
    "link": "http://arxiv.org/pdf/1303.0633v1", 
    "arxiv-id": "1303.0633v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "Indian Sign Language Recognition Using Eigen Value Weighted Euclidean   Distance Based Classification Technique", 
    "publish": "2013-03-04T08:06:07Z", 
    "summary": "Sign Language Recognition is one of the most growing fields of research\ntoday. Many new techniques have been developed recently in these fields. Here\nin this paper, we have proposed a system using Eigen value weighted Euclidean\ndistance as a classification technique for recognition of various Sign\nLanguages of India. The system comprises of four parts: Skin Filtering, Hand\nCropping, Feature Extraction and Classification. Twenty four signs were\nconsidered in this paper, each having ten samples, thus a total of two hundred\nforty images was considered for which recognition rate obtained was 97 percent.", 
    "link": "http://arxiv.org/pdf/1303.0634v1", 
    "arxiv-id": "1303.0634v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "Recognition of Facial Expression Using Eigenvector Based Distributed   Features and Euclidean Distance Based Decision Making Technique", 
    "publish": "2013-03-04T08:09:22Z", 
    "summary": "In this paper, an Eigenvector based system has been presented to recognize\nfacial expressions from digital facial images. In the approach, firstly the\nimages were acquired and cropping of five significant portions from the image\nwas performed to extract and store the Eigenvectors specific to the\nexpressions. The Eigenvectors for the test images were also computed, and\nfinally the input facial image was recognized when similarity was obtained by\ncalculating the minimum Euclidean distance between the test image and the\ndifferent expressions.", 
    "link": "http://arxiv.org/pdf/1303.0635v1", 
    "arxiv-id": "1303.0635v1"
},{
    "category": "cs.CV", 
    "author": "K. Raja", 
    "title": "Automatic symmetry based cluster approach for anomalous brain   identification in PET scan image : An Analysis", 
    "publish": "2013-03-04T08:52:45Z", 
    "summary": "Medical image segmentation is referred to the segmentation of known anatomic\nstructures from different medical images. Normally, the medical data researches\nare more complicated and an exclusive structures. This computer aided diagnosis\nis used for assisting doctors in evaluating medical imagery or in recognizing\nabnormal findings in a medical image. To integrate the specialized knowledge\nfor medical data processing is helpful to form a real useful healthcare\ndecision making system. This paper studies the different symmetry based\ndistances applied in clustering algorithms and analyzes symmetry approach for\nPositron Emission Tomography (PET) scan image segmentation. Unlike CT and MRI,\nthe PET scan identifies the structure of blood flow to and from organs. PET\nscan also helps in early diagnosis of cancer and heart, brain and gastro\nintestinal ailments and to detect the progress of treatment. In this paper, the\nscope diagnostic task expands for PET image in various brain functions.", 
    "link": "http://arxiv.org/pdf/1303.0644v1", 
    "arxiv-id": "1303.0644v1"
},{
    "category": "cs.CV", 
    "author": "R. Raja", 
    "title": "Symmetry Based Cluster Approach for Automatic Recognition of the   Epileptic Focus in Brain Using PET Scan Image : An Analysis", 
    "publish": "2013-03-04T09:00:23Z", 
    "summary": "Recognition of epileptic focal point is the important diagnosis when\nscreening the epilepsy patients for latent surgical cures. The accurate\nlocalization is challenging one because of the low spatial resolution images\nwith more noisy data. Positron Emission Tomography (PET) has now replaced the\nissues and caring a high resolution. This paper focuses the research of\nautomated localization of epileptic seizures in brain functional images using\nsymmetry based cluster approach. This approach presents a fully automated\nsymmetry based brain abnormality detection method for PET sequences. PET images\nare spatially normalized to Digital Imaging and Communications in Medicine\n(DICOM) standard and then it has been trained using symmetry based cluster\napproach using Medical Image Processing, Analysis & Visualization (MIPAV) tool.\nThe performance evolution is considered by the metric like accuracy of\ndiagnosis. The obtained result is surely assists the surgeon for the automated\nidentification of seizures focus.", 
    "link": "http://arxiv.org/pdf/1303.0645v1", 
    "arxiv-id": "1303.0645v1"
},{
    "category": "cs.CV", 
    "author": "R. Raja", 
    "title": "Spatial Fuzzy C Means PET Image Segmentation of Neurodegenerative   Disorder", 
    "publish": "2013-03-04T09:08:34Z", 
    "summary": "Nuclear image has emerged as a promising research work in medical field.\nImages from different modality meet its own challenge. Positron Emission\nTomography (PET) image may help to precisely localize disease to assist in\nplanning the right treatment for each case and saving valuable time. In this\npaper, a novel approach of Spatial Fuzzy C Means (PET SFCM) clustering\nalgorithm is introduced on PET scan image datasets. The proposed algorithm is\nincorporated the spatial neighborhood information with traditional FCM and\nupdating the objective function of each cluster. This algorithm is implemented\nand tested on huge data collection of patients with brain neuro degenerative\ndisorder such as Alzheimers disease. It has demonstrated its effectiveness by\ntesting it for real world patient data sets. Experimental results are compared\nwith conventional FCM and K Means clustering algorithm. The performance of the\nPET SFCM provides satisfactory results compared with other two algorithms", 
    "link": "http://arxiv.org/pdf/1303.0647v1", 
    "arxiv-id": "1303.0647v1"
},{
    "category": "cs.CV", 
    "author": "Ron Kikinis", 
    "title": "GBM Volumetry using the 3D Slicer Medical Image Computing Platform", 
    "publish": "2013-03-05T09:40:46Z", 
    "summary": "Volumetric change in glioblastoma multiforme (GBM) over time is a critical\nfactor in treatment decisions. Typically, the tumor volume is computed on a\nslice-by-slice basis using MRI scans obtained at regular intervals. (3D)Slicer\n- a free platform for biomedical research - provides an alternative to this\nmanual slice-by-slice segmentation process, which is significantly faster and\nrequires less user interaction. In this study, 4 physicians segmented GBMs in\n10 patients, once using the competitive region-growing based GrowCut\nsegmentation module of Slicer, and once purely by drawing boundaries completely\nmanually on a slice-by-slice basis. Furthermore, we provide a variability\nanalysis for three physicians for 12 GBMs. The time required for GrowCut\nsegmentation was on an average 61% of the time required for a pure manual\nsegmentation. A comparison of Slicer-based segmentation with manual\nslice-by-slice segmentation resulted in a Dice Similarity Coefficient of 88.43\n+/- 5.23% and a Hausdorff Distance of 2.32 +/- 5.23 mm.", 
    "link": "http://arxiv.org/pdf/1303.0964v1", 
    "arxiv-id": "1303.0964v1"
},{
    "category": "cs.CV", 
    "author": "Conrad Sanderson", 
    "title": "On Robust Face Recognition via Sparse Encoding: the Good, the Bad, and   the Ugly", 
    "publish": "2013-03-07T09:30:10Z", 
    "summary": "In the field of face recognition, Sparse Representation (SR) has received\nconsiderable attention during the past few years. Most of the relevant\nliterature focuses on holistic descriptors in closed-set identification\napplications. The underlying assumption in SR-based methods is that each class\nin the gallery has sufficient samples and the query lies on the subspace\nspanned by the gallery of the same class. Unfortunately, such assumption is\neasily violated in the more challenging face verification scenario, where an\nalgorithm is required to determine if two faces (where one or both have not\nbeen seen before) belong to the same person. In this paper, we first discuss\nwhy previous attempts with SR might not be applicable to verification problems.\nWe then propose an alternative approach to face verification via SR.\nSpecifically, we propose to use explicit SR encoding on local image patches\nrather than the entire face. The obtained sparse signals are pooled via\naveraging to form multiple region descriptors, which are then concatenated to\nform an overall face descriptor. Due to the deliberate loss spatial relations\nwithin each region (caused by averaging), the resulting descriptor is robust to\nmisalignment & various image deformations. Within the proposed framework, we\nevaluate several SR encoding techniques: l1-minimisation, Sparse Autoencoder\nNeural Network (SANN), and an implicit probabilistic technique based on\nGaussian Mixture Models. Thorough experiments on AR, FERET, exYaleB, BANCA and\nChokePoint datasets show that the proposed local SR approach obtains\nconsiderably better and more robust performance than several previous\nstate-of-the-art holistic SR methods, in both verification and closed-set\nidentification problems. The experiments also show that l1-minimisation based\nencoding has a considerably higher computational than the other techniques, but\nleads to higher recognition rates.", 
    "link": "http://arxiv.org/pdf/1303.1624v1", 
    "arxiv-id": "1303.1624v1"
},{
    "category": "cs.CV", 
    "author": "Ricardo Luis Barbosa", 
    "title": "ALPRS - A New Approach for License Plate Recognition using the Sift   Algorithm", 
    "publish": "2013-03-07T12:49:49Z", 
    "summary": "This paper presents a new approach for the automatic license plate\nrecognition, which includes the SIFT algorithm in step to locate the plate in\nthe input image. In this new approach, besides the comparison of the features\nobtained with the SIFT algorithm, the correspondence between the spatial\norientations and the positioning associated with the keypoints is also\nobserved. Afterwards, an algorithm is used for the character recognition of the\nplates, very fast, which makes it possible its application in real time. The\nresults obtained with the proposed approach presented very good success rates,\nso much for locating the characters in the input image, as for their\nrecognition.", 
    "link": "http://arxiv.org/pdf/1303.1667v1", 
    "arxiv-id": "1303.1667v1"
},{
    "category": "cs.CV", 
    "author": "Vladimir Kolmogorov", 
    "title": "Simplifying Energy Optimization using Partial Enumeration", 
    "publish": "2013-03-07T16:59:11Z", 
    "summary": "Energies with high-order non-submodular interactions have been shown to be\nvery useful in vision due to their high modeling power. Optimization of such\nenergies, however, is generally NP-hard. A naive approach that works for small\nproblem instances is exhaustive search, that is, enumeration of all possible\nlabelings of the underlying graph. We propose a general minimization approach\nfor large graphs based on enumeration of labelings of certain small patches.\nThis partial enumeration technique reduces complex high-order energy\nformulations to pairwise Constraint Satisfaction Problems with unary costs\n(uCSP), which can be efficiently solved using standard methods like TRW-S. Our\napproach outperforms a number of existing state-of-the-art algorithms on well\nknown difficult problems (e.g. curvature regularization, stereo,\ndeconvolution); it gives near global minimum and better speed.\n  Our main application of interest is curvature regularization. In the context\nof segmentation, our partial enumeration technique allows to evaluate curvature\ndirectly on small patches using a novel integral geometry approach.", 
    "link": "http://arxiv.org/pdf/1303.1749v2", 
    "arxiv-id": "1303.1749v2"
},{
    "category": "cs.CV", 
    "author": "Tim Polzehl", 
    "title": "Improving Automatic Emotion Recognition from speech using Rhythm and   Temporal feature", 
    "publish": "2013-03-07T17:33:06Z", 
    "summary": "This paper is devoted to improve automatic emotion recognition from speech by\nincorporating rhythm and temporal features. Research on automatic emotion\nrecognition so far has mostly been based on applying features like MFCCs, pitch\nand energy or intensity. The idea focuses on borrowing rhythm features from\nlinguistic and phonetic analysis and applying them to the speech signal on the\nbasis of acoustic knowledge only. In addition to this we exploit a set of\ntemporal and loudness features. A segmentation unit is employed in starting to\nseparate the voiced/unvoiced and silence parts and features are explored on\ndifferent segments. Thereafter different classifiers are used for\nclassification. After selecting the top features using an IGR filter we are\nable to achieve a recognition rate of 80.60 % on the Berlin Emotion Database\nfor the speaker dependent framework.", 
    "link": "http://arxiv.org/pdf/1303.1761v1", 
    "arxiv-id": "1303.1761v1"
},{
    "category": "cs.CV", 
    "author": "Fernand Meyer", 
    "title": "Watersheds on edge or node weighted graphs \"par l'exemple\"", 
    "publish": "2013-03-07T21:15:29Z", 
    "summary": "Watersheds have been defined both for node and edge weighted graphs. We show\nthat they are identical: for each edge (resp.\\ node) weighted graph exists a\nnode (resp. edge) weighted graph with the same minima and catchment basin.", 
    "link": "http://arxiv.org/pdf/1303.1829v1", 
    "arxiv-id": "1303.1829v1"
},{
    "category": "cs.CV", 
    "author": "Nyjin Thomas", 
    "title": "Least-Squares FIR Models of Low-Resolution MR data for Efficient   Phase-Error Compensation with Simultaneous Artefact Removal", 
    "publish": "2013-03-11T06:40:02Z", 
    "summary": "Signal space models in both phase-encode, and frequency-encode directions are\npresented for extrapolation of 2D partial kspace. Using the boxcar\nrepresentation of low-resolution spatial data, and a geometrical representation\nof signal space vectors in both positive and negative phase-encode directions,\na robust predictor is constructed using a series of signal space projections.\nCompared to some of the existing phase-correction methods that require\nacquisition of a pre-determined set of fractional kspace lines, the proposed\npredictor is found to be more efficient, due to its capability of exhibiting an\nequivalent degree of performance using only half the number of fractional\nlines. Robust filtering of noisy data is achieved using a second signal space\nmodel in the frequency-encode direction, bypassing the requirement of a prior\nhighpass filtering operation. The signal space is constructed from Fourier\nTransformed samples of each row in the low-resolution image. A set of FIR\nfilters are estimated by fitting a least squares model to this signal space.\nPartial kspace extrapolation using the FIR filters is shown to result in\nartifact-free reconstruction, particularly in respect of Gibbs ringing and\nstreaking type artifacts.", 
    "link": "http://arxiv.org/pdf/1303.2437v1", 
    "arxiv-id": "1303.2437v1"
},{
    "category": "cs.CV", 
    "author": "Chandrasekar Kesavadas", 
    "title": "Voxel-wise Weighted MR Image Enhancement using an Extended Neighborhood   Filter", 
    "publish": "2013-03-11T06:54:26Z", 
    "summary": "We present an edge preserving and denoising filter for enhancing the features\nin images, which contain an ROI having a narrow spatial extent. Typical\nexamples include angiograms, or ROI spatially distributed in multiple locations\nand contained within an outlying region, such as in multiple-sclerosis. The\nfiltering involves determination of multiplicative weights in the spatial\ndomain using an extended set of neighborhood directions. Equivalently, the\nfiltering operation may be interpreted as a combination of directional filters\nin the frequency domain, with selective weighting for spatial frequencies\ncontained within each direction. The advantages of the proposed filter in\ncomparison to specialized non-linear filters, which operate on diffusion\nprinciple, are illustrated using numerical phantom data. The performance\nevaluation is carried out on simulated images from BrainWeb database for\nmultiple-sclerosis, acute ischemic stroke using clinically acquired FLAIR\nimages and MR angiograms.", 
    "link": "http://arxiv.org/pdf/1303.2439v1", 
    "arxiv-id": "1303.2439v1"
},{
    "category": "cs.CV", 
    "author": "Brian C. Lovell", 
    "title": "A Low-Complexity Algorithm for Static Background Estimation from   Cluttered Image Sequences in Surveillance Contexts", 
    "publish": "2013-03-11T09:57:49Z", 
    "summary": "For the purposes of foreground estimation, the true background model is\nunavailable in many practical circumstances and needs to be estimated from\ncluttered image sequences. We propose a sequential technique for static\nbackground estimation in such conditions, with low computational and memory\nrequirements. Image sequences are analysed on a block-by-block basis. For each\nblock location a representative set is maintained which contains distinct\nblocks obtained along its temporal line. The background estimation is carried\nout in a Markov Random Field framework, where the optimal labelling solution is\ncomputed using iterated conditional modes. The clique potentials are computed\nbased on the combined frequency response of the candidate block and its\nneighbourhood. It is assumed that the most appropriate block results in the\nsmoothest response, indirectly enforcing the spatial continuity of structures\nwithin a scene. Experiments on real-life surveillance videos demonstrate that\nthe proposed method obtains considerably better background estimates (both\nqualitatively and quantitatively) than median filtering and the recently\nproposed \"intervals of stable intensity\" method. Further experiments on the\nWallflower dataset suggest that the combination of the proposed method with a\nforeground segmentation algorithm results in improved foreground segmentation.", 
    "link": "http://arxiv.org/pdf/1303.2465v1", 
    "arxiv-id": "1303.2465v1"
},{
    "category": "cs.CV", 
    "author": "Yuri Boykov", 
    "title": "Joint optimization of fitting & matching in multi-view reconstruction", 
    "publish": "2013-03-11T18:14:42Z", 
    "summary": "Many standard approaches for geometric model fitting are based on pre-matched\nimage features. Typically, such pre-matching uses only feature appearances\n(e.g. SIFT) and a large number of non-unique features must be discarded in\norder to control the false positive rate. In contrast, we solve feature\nmatching and multi-model fitting problems in a joint optimization framework.\nThis paper proposes several fit-&-match energy formulations based on a\ngeneralization of the assignment problem. We developed an efficient solver\nbased on min-cost-max-flow algorithm that finds near optimal solutions. Our\napproach significantly increases the number of detected matches. In practice,\nenergy-based joint fitting & matching allows to increase the distance between\nview-points previously restricted by robustness of local SIFT-matching and to\nimprove the model fitting accuracy when compared to state-of-the-art\nmulti-model fitting techniques.", 
    "link": "http://arxiv.org/pdf/1303.2607v2", 
    "arxiv-id": "1303.2607v2"
},{
    "category": "cs.CV", 
    "author": "Andreas Spanias", 
    "title": "Kernel Sparse Models for Automated Tumor Segmentation", 
    "publish": "2013-03-11T18:33:01Z", 
    "summary": "In this paper, we propose sparse coding-based approaches for segmentation of\ntumor regions from MR images. Sparse coding with data-adapted dictionaries has\nbeen successfully employed in several image recovery and vision problems. The\nproposed approaches obtain sparse codes for each pixel in brain magnetic\nresonance images considering their intensity values and location information.\nSince it is trivial to obtain pixel-wise sparse codes, and combining multiple\nfeatures in the sparse coding setup is not straightforward, we propose to\nperform sparse coding in a high-dimensional feature space where non-linear\nsimilarities can be effectively modeled. We use the training data from\nexpert-segmented images to obtain kernel dictionaries with the kernel K-lines\nclustering procedure. For a test image, sparse codes are computed with these\nkernel dictionaries, and they are used to identify the tumor regions. This\napproach is completely automated, and does not require user intervention to\ninitialize the tumor regions in a test image. Furthermore, a low complexity\nsegmentation approach based on kernel sparse codes, which allows the user to\ninitialize the tumor region, is also presented. Results obtained with both the\nproposed approaches are validated against manual segmentation by an expert\nradiologist, and the proposed methods lead to accurate tumor identification.", 
    "link": "http://arxiv.org/pdf/1303.2610v1", 
    "arxiv-id": "1303.2610v1"
},{
    "category": "cs.CV", 
    "author": "Antonio Ortega", 
    "title": "Bilateral Filter: Graph Spectral Interpretation and Extensions", 
    "publish": "2013-03-11T20:52:57Z", 
    "summary": "In this paper we study the bilateral filter proposed by Tomasi and Manduchi,\nas a spectral domain transform defined on a weighted graph. The nodes of this\ngraph represent the pixels in the image and a graph signal defined on the nodes\nrepresents the intensity values. Edge weights in the graph correspond to the\nbilateral filter coefficients and hence are data adaptive. Spectrum of a graph\nis defined in terms of the eigenvalues and eigenvectors of the graph Laplacian\nmatrix. We use this spectral interpretation to generalize the bilateral filter\nand propose more flexible and application specific spectral designs of\nbilateral-like filters. We show that these spectral filters can be implemented\nwith k-iterative bilateral filtering operations and do not require expensive\ndiagonalization of the Laplacian matrix.", 
    "link": "http://arxiv.org/pdf/1303.2685v1", 
    "arxiv-id": "1303.2685v1"
},{
    "category": "cs.CV", 
    "author": "Mallikarjun Hangarge", 
    "title": "Gaussian Mixture Model for Handwritten Script Identification", 
    "publish": "2013-03-12T02:32:02Z", 
    "summary": "This paper presents a Gaussian Mixture Model (GMM) to identify the script of\nhandwritten words of Roman, Devanagari, Kannada and Telugu scripts. It\nemphasizes the significance of directional energies for identification of\nscript of the word. It is robust to varied image sizes and different styles of\nwriting. A GMM is modeled using a set of six novel features derived from\ndirectional energy distributions of the underlying image. The standard\ndeviation of directional energy distributions are computed by decomposing an\nimage matrix into right and left diagonals. Furthermore, deviation of\nhorizontal and vertical distributions of energies is also built-in to GMM. A\ndataset of 400 images out of 800 (200 of each script) are used for training GMM\nand the remaining is for testing. An exhaustive experimentation is carried out\nat bi-script, tri-script and multi-script level and achieved script\nidentification accuracies in percentage as 98.7, 98.16 and 96.91 respectively.", 
    "link": "http://arxiv.org/pdf/1303.2751v1", 
    "arxiv-id": "1303.2751v1"
},{
    "category": "cs.CV", 
    "author": "Brian C. Lovell", 
    "title": "Combined Learning of Salient Local Descriptors and Distance Metrics for   Image Set Face Verification", 
    "publish": "2013-03-12T06:12:59Z", 
    "summary": "In contrast to comparing faces via single exemplars, matching sets of face\nimages increases robustness and discrimination performance. Recent image set\nmatching approaches typically measure similarities between subspaces or\nmanifolds, while representing faces in a rigid and holistic manner. Such\nrepresentations are easily affected by variations in terms of alignment,\nillumination, pose and expression. While local feature based representations\nare considerably more robust to such variations, they have received little\nattention within the image set matching area. We propose a novel image set\nmatching technique, comprised of three aspects: (i) robust descriptors of face\nregions based on local features, partly inspired by the hierarchy in the human\nvisual system, (ii) use of several subspace and exemplar metrics to compare\ncorresponding face regions, (iii) jointly learning which regions are the most\ndiscriminative while finding the optimal mixing weights for combining metrics.\nFace recognition experiments on LFW, PIE and MOBIO face datasets show that the\nproposed algorithm obtains considerably better performance than several recent\nstate-of-the-art techniques, such as Local Principal Angle and the Kernel\nAffine Hull Method.", 
    "link": "http://arxiv.org/pdf/1303.2783v1", 
    "arxiv-id": "1303.2783v1"
},{
    "category": "cs.CV", 
    "author": "Pedro F. Felzenszwalb", 
    "title": "A Stochastic Grammar for Natural Shapes", 
    "publish": "2013-03-12T11:23:47Z", 
    "summary": "We consider object detection using a generic model for natural shapes. A\ncommon approach for object recognition involves matching object models directly\nto images. Another approach involves building intermediate representations via\na generic grouping processes. We argue that these two processes (model-based\nrecognition and grouping) may use similar computational mechanisms. By defining\na generic model for shapes we can use model-based techniques to implement a\nmid-level vision grouping process.", 
    "link": "http://arxiv.org/pdf/1303.2844v1", 
    "arxiv-id": "1303.2844v1"
},{
    "category": "cs.CV", 
    "author": "Rajmohan Pardeshi", 
    "title": "Statistical Texture Features based Handwritten and Printed Text   Classification in South Indian Documents", 
    "publish": "2013-03-13T04:51:22Z", 
    "summary": "In this paper, we use statistical texture features for handwritten and\nprinted text classification. We primarily aim for word level classification in\nsouth Indian scripts. Words are first extracted from the scanned document. For\neach extracted word, statistical texture features are computed such as mean,\nstandard deviation, smoothness, moment, uniformity, entropy and local range\nincluding local entropy. These feature vectors are then used to classify words\nvia k-NN classifier. We have validated the approach over several different\ndatasets. Scripts like Kannada, Telugu, Malayalam and Hindi i.e., Devanagari\nare primarily employed where an average classification rate of 99.26% is\nachieved. In addition, to provide an extensibility of the approach, we address\nRoman script by using publicly available dataset and interesting results are\nreported.", 
    "link": "http://arxiv.org/pdf/1303.3087v1", 
    "arxiv-id": "1303.3087v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Material quality assessment of silk nanofibers based on swarm   intelligence", 
    "publish": "2013-03-13T13:23:21Z", 
    "summary": "In this paper, we propose a novel approach for texture analysis based on\nartificial crawler model. Our method assumes that each agent can interact with\nthe environment and each other. The evolution process converges to an\nequilibrium state according to the set of rules. For each textured image, the\nfeature vector is composed by signatures of the live agents curve at each time.\nExperimental results revealed that combining the minimum and maximum signatures\ninto one increase the classification rate. In addition, we pioneer the use of\nautonomous agents for characterizing silk fibroin scaffolds. The results\nstrongly suggest that our approach can be successfully employed for texture\nanalysis.", 
    "link": "http://arxiv.org/pdf/1303.3152v1", 
    "arxiv-id": "1303.3152v1"
},{
    "category": "cs.CV", 
    "author": "Brian C. Lovell", 
    "title": "Improved Foreground Detection via Block-based Classifier Cascade with   Probabilistic Decision Integration", 
    "publish": "2013-03-18T05:48:40Z", 
    "summary": "Background subtraction is a fundamental low-level processing task in numerous\ncomputer vision applications. The vast majority of algorithms process images on\na pixel-by-pixel basis, where an independent decision is made for each pixel. A\ngeneral limitation of such processing is that rich contextual information is\nnot taken into account. We propose a block-based method capable of dealing with\nnoise, illumination variations and dynamic backgrounds, while still obtaining\nsmooth contours of foreground objects. Specifically, image sequences are\nanalysed on an overlapping block-by-block basis. A low-dimensional texture\ndescriptor obtained from each block is passed through an adaptive classifier\ncascade, where each stage handles a distinct problem. A probabilistic\nforeground mask generation approach then exploits block overlaps to integrate\ninterim block-level decisions into final pixel-level foreground segmentation.\nUnlike many pixel-based methods, ad-hoc post-processing of foreground masks is\nnot required. Experiments on the difficult Wallflower and I2R datasets show\nthat the proposed approach obtains on average better results (both\nqualitatively and quantitatively) than several prominent methods. We\nfurthermore propose the use of tracking performance as an unbiased approach for\nassessing the practical usefulness of foreground segmentation methods, and show\nthat the proposed approach leads to considerable improvements in tracking\naccuracy on the CAVIAR dataset.", 
    "link": "http://arxiv.org/pdf/1303.4160v1", 
    "arxiv-id": "1303.4160v1"
},{
    "category": "cs.CV", 
    "author": "Vincent Poulain D'Andecy", 
    "title": "Handwritten and Printed Text Separation in Real Document", 
    "publish": "2013-03-19T14:23:24Z", 
    "summary": "The aim of the paper is to separate handwritten and printed text from a real\ndocument embedded with noise, graphics including annotations. Relying on\nrun-length smoothing algorithm (RLSA), the extracted pseudo-lines and\npseudo-words are used as basic blocks for classification. To handle this, a\nmulti-class support vector machine (SVM) with Gaussian kernel performs a first\nlabelling of each pseudo-word including the study of local neighbourhood. It\nthen propagates the context between neighbours so that we can correct possible\nlabelling errors. Considering running time complexity issue, we propose linear\ncomplexity methods where we use k-NN with constraint. When using a kd-tree, it\nis almost linearly proportional to the number of pseudo-words. The performance\nof our system is close to 90%, even when very small learning dataset where\nsamples are basically composed of complex administrative documents.", 
    "link": "http://arxiv.org/pdf/1303.4614v1", 
    "arxiv-id": "1303.4614v1"
},{
    "category": "cs.CV", 
    "author": "Anton van den Hengel", 
    "title": "A Survey of Appearance Models in Visual Object Tracking", 
    "publish": "2013-03-20T01:08:33Z", 
    "summary": "Visual object tracking is a significant computer vision task which can be\napplied to many domains such as visual surveillance, human computer\ninteraction, and video compression. In the literature, researchers have\nproposed a variety of 2D appearance models. To help readers swiftly learn the\nrecent advances in 2D appearance models for visual object tracking, we\ncontribute this survey, which provides a detailed review of the existing 2D\nappearance models. In particular, this survey takes a module-based architecture\nthat enables readers to easily grasp the key points of visual object tracking.\nIn this survey, we first decompose the problem of appearance modeling into two\ndifferent processing stages: visual representation and statistical modeling.\nThen, different 2D appearance models are categorized and discussed with respect\nto their composition modules. Finally, we address several issues of interest as\nwell as the remaining challenges for future research on this topic. The\ncontributions of this survey are four-fold. First, we review the literature of\nvisual representations according to their feature-construction mechanisms\n(i.e., local and global). Second, the existing statistical modeling schemes for\ntracking-by-detection are reviewed according to their model-construction\nmechanisms: generative, discriminative, and hybrid generative-discriminative.\nThird, each type of visual representations or statistical modeling techniques\nis analyzed and discussed from a theoretical or practical viewpoint. Fourth,\nthe existing benchmark resources (e.g., source code and video datasets) are\nexamined in this survey.", 
    "link": "http://arxiv.org/pdf/1303.4803v1", 
    "arxiv-id": "1303.4803v1"
},{
    "category": "cs.CV", 
    "author": "Dr. Firoj Parwej", 
    "title": "The State of the Art Recognize in Arabic Script through Combination of   Online and Offline", 
    "publish": "2013-03-20T04:54:44Z", 
    "summary": "Handwriting recognition refers to the identification of written characters.\nHandwriting recognition has become an acute research area in recent years for\nthe ease of access of computer science. In this paper primarily discussed\nOn-line and Off-line handwriting recognition methods for Arabic words which are\noften used among then across the Middle East and North Africa People. Arabic\nword online handwriting recognition is a very challenging task due to its\ncursive nature. Because of the characteristic of the whole body of the Arabic\nscript, namely connectivity between the characters, thereby the segmentation of\nAn Arabic script is very difficult. In this paper we introduced an Arabic\nscript multiple classifier system for recognizing notes written on a Starboard.\nThis Arabic script multiple classifier system combines one off-line and on-line\nhandwriting recognition systems. The Arabic script recognizers are all based on\nHidden Markov Models but vary in the way of preprocessing and normalization. To\ncombine the Arabic script output sequences of the recognizers, we incrementally\nalign the word sequences using a norm string matching algorithm. The Arabic\nscript combination we could increase the system performance over the excellent\ncharacter recognizer by about 3%. The proposed technique is also the necessary\nstep towards character recognition, person identification, personality\ndetermination where input data is processed from all perspectives.", 
    "link": "http://arxiv.org/pdf/1303.4839v1", 
    "arxiv-id": "1303.4839v1"
},{
    "category": "cs.CV", 
    "author": "Igor Polkovnikov", 
    "title": "Asynchronous Cellular Operations on Gray Images Extracting Topographic   Shape Features and Their Relations", 
    "publish": "2013-03-20T04:59:08Z", 
    "summary": "A variety of operations of cellular automata on gray images is presented. All\noperations are of a wave-front nature finishing in a stable state. They are\nused to extract shape descripting gray objects robust to a variety of pattern\ndistortions. Topographic terms are used: \"lakes\", \"dales\", \"dales of dales\". It\nis shown how mutual object relations like \"above\" can be presented in terms of\ngray image analysis and how it can be used for character classification and for\ngray pattern decomposition. Algorithms can be realized with a parallel\nasynchronous architecture. Keywords: Pattern Recognition, Mathematical\nMorphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis,\nTopographical Shape Descriptors, Asynchronous Parallel Processors, Holes,\nCavities, Concavities, Graphs.", 
    "link": "http://arxiv.org/pdf/1303.4840v1", 
    "arxiv-id": "1303.4840v1"
},{
    "category": "cs.CV", 
    "author": "Gwang-Ho Jong", 
    "title": "On Constructing the Value Function for Optimal Trajectory Problem and   its Application to Image Processing", 
    "publish": "2013-03-20T06:16:55Z", 
    "summary": "We proposed an algorithm for solving Hamilton-Jacobi equation associated to\nan optimal trajectory problem for a vehicle moving inside the pre-specified\ndomain with the speed depending upon the direction of the motion and current\nposition of the vehicle. The dynamics of the vehicle is defined by an ordinary\ndifferential equation, the right hand of which is given by product of control(a\ntime dependent fuction) and a function dependent on trajectory and control. At\nsome unspecified terminal time, the vehicle reaches the boundary of the\npre-specified domain and incurs a terminal cost. We also associate the\ntraveling cost with a type of integral to the trajectory followed by vehicle.\nWe are interested in a numerical method for finding a trajectory that minimizes\nthe sum of the traveling cost and terminal cost. We developed an algorithm\nsolving the value function for general trajectory optimization problem. Our\nalgorithm is closely related to the Tsitsiklis's Fast Marching Method and J. A.\nSethian's OUM and SLF-LLL[1-4] and is a generalization of them. On the basis of\nthese results, We applied our algorithm to the image processing such as\nfingerprint verification.", 
    "link": "http://arxiv.org/pdf/1303.4845v2", 
    "arxiv-id": "1303.4845v2"
},{
    "category": "cs.CV", 
    "author": "Neha S. Satam", 
    "title": "A Robust Rapid Approach to Image Segmentation with Optimal Thresholding   and Watershed Transform", 
    "publish": "2013-03-20T08:15:07Z", 
    "summary": "This paper describes a novel method for partitioning image into meaningful\nsegments. The proposed method employs watershed transform, a well-known image\nsegmentation technique. Along with that, it uses various auxiliary schemes such\nas Binary Gradient Masking, dilation which segment the image in proper way. The\nalgorithm proposed in this paper considers all these methods in effective way\nand takes little time. It is organized in such a manner so that it operates on\ninput image adaptively. Its robustness and efficiency makes it more convenient\nand suitable for all types of images.", 
    "link": "http://arxiv.org/pdf/1303.4866v1", 
    "arxiv-id": "1303.4866v1"
},{
    "category": "cs.CV", 
    "author": "Carlo Schaller", 
    "title": "Cortical Surface Co-Registration based on MRI Images and Photos", 
    "publish": "2013-03-22T19:07:13Z", 
    "summary": "Brain shift, i.e. the change in configuration of the brain after opening the\ndura mater, is a key problem in neuronavigation. We present an approach to\nco-register intra-operative microscope images with pre-operative MRI to adapt\nand optimize intra-operative neuronavigation. The tools are a robust\nclassification of sulci on MRI extracted cortical surfaces, guided user marking\nof most prominent sulci on a microscope image, and the actual variational\nregistration method with a fidelity energy for 3D deformations of the cortical\nsurface combined with a higher order, linear elastica type prior energy.\nFurthermore, the actual registration is validated on an artificial testbed with\nknown ground truth deformation and on real data of a neuro clinical patient.", 
    "link": "http://arxiv.org/pdf/1303.5691v1", 
    "arxiv-id": "1303.5691v1"
},{
    "category": "cs.CV", 
    "author": "Anton van den Hengel", 
    "title": "Asymmetric Pruning for Learning Cascade Detectors", 
    "publish": "2013-03-25T10:01:19Z", 
    "summary": "Cascade classifiers are one of the most important contributions to real-time\nobject detection. Nonetheless, there are many challenging problems arising in\ntraining cascade detectors. One common issue is that the node classifier is\ntrained with a symmetric classifier. Having a low misclassification error rate\ndoes not guarantee an optimal node learning goal in cascade classifiers, i.e.,\nan extremely high detection rate with a moderate false positive rate. In this\nwork, we present a new approach to train an effective node classifier in a\ncascade detector. The algorithm is based on two key observations: 1) Redundant\nweak classifiers can be safely discarded; 2) The final detector should satisfy\nthe asymmetric learning objective of the cascade architecture. To achieve this,\nwe separate the classifier training into two steps: finding a pool of\ndiscriminative weak classifiers/features and training the final classifier by\npruning weak classifiers which contribute little to the asymmetric learning\ncriterion (asymmetric classifier construction). Our model reduction approach\nhelps accelerate the learning time while achieving the pre-determined learning\nobjective. Experimental results on both face and car data sets verify the\neffectiveness of the proposed algorithm. On the FDDB face data sets, our\napproach achieves the state-of-the-art performance, which demonstrates the\nadvantage of our approach.", 
    "link": "http://arxiv.org/pdf/1303.6066v2", 
    "arxiv-id": "1303.6066v2"
},{
    "category": "cs.CV", 
    "author": "Yaoqin Xie", 
    "title": "Performance Evaluation of Edge-Directed Interpolation Methods for Images", 
    "publish": "2013-03-26T12:35:46Z", 
    "summary": "Many interpolation methods have been developed for high visual quality, but\nfail for inability to preserve image structures. Edges carry heavy structural\ninformation for detection, determination and classification. Edge-adaptive\ninterpolation approaches become a center of focus. In this paper, performance\nof four edge-directed interpolation methods comparing with two traditional\nmethods is evaluated on two groups of images. These methods include new\nedge-directed interpolation (NEDI), edge-guided image interpolation (EGII),\niterative curvature-based interpolation (ICBI), directional cubic convolution\ninterpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic.\nMeanwhile, no parameters are mentioned to measure edge-preserving ability of\nedge-adaptive interpolation approaches and we proposed two. One evaluates\naccuracy and the other measures robustness of edge-preservation ability.\nPerformance evaluation is based on six parameters. Objective assessment and\nvisual analysis are illustrated and conclusions are drawn from theoretical\nbackgrounds and practical results.", 
    "link": "http://arxiv.org/pdf/1303.6455v1", 
    "arxiv-id": "1303.6455v1"
},{
    "category": "cs.CV", 
    "author": "S. K. Katiyar", 
    "title": "An N-dimensional approach towards object based classification of   remotely sensed imagery", 
    "publish": "2013-03-26T19:39:20Z", 
    "summary": "Remote sensing techniques are widely used for land cover classification and\nurban analysis. The availability of high resolution remote sensing imagery\nlimits the level of classification accuracy attainable from pixel-based\napproach. In this paper object-based classification scheme based on a\nhierarchical support vector machine is introduced. By combining spatial and\nspectral information, the amount of overlap between classes can be decreased;\nthereby yielding higher classification accuracy and more accurate land cover\nmaps. We have adopted certain automatic approaches based on the advanced\ntechniques as Cellular automata and Genetic Algorithm for kernel and tuning\nparameter selection. Performance evaluation of the proposed methodology in\ncomparison with the existing approaches is performed with reference to the\nBhopal city study area.", 
    "link": "http://arxiv.org/pdf/1303.6619v1", 
    "arxiv-id": "1303.6619v1"
},{
    "category": "cs.CV", 
    "author": "S. K. Katiyar", 
    "title": "An intelligent approach towards automatic shape modeling and object   extraction from satellite images using cellular automata based algorithm", 
    "publish": "2013-03-27T00:33:52Z", 
    "summary": "Automatic feature extraction domain has witnessed the application of many\nintelligent methodologies over past decade; however detection accuracy of these\napproaches were limited as object geometry and contextual knowledge were not\ngiven enough consideration. In this paper, we propose a frame work for accurate\ndetection of features along with automatic interpolation, and interpretation by\nmodeling feature shape as well as contextual knowledge using advanced\ntechniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed\nmethodology has been compared with contemporary methods using different\nstatistical measures. Investigations over various satellite images revealed\nthat considerable success was achieved with the CNN approach. CNN has been\neffective in modeling different complex features effectively and complexity of\nthe approach has been considerably reduced using corset optimization. The\nsystem has dynamically used spectral and spatial information for representing\ncontextual knowledge using CNN-prolog approach. System has been also proved to\nbe effective in providing intelligent interpolation and interpretation of\nrandom features.", 
    "link": "http://arxiv.org/pdf/1303.6711v1", 
    "arxiv-id": "1303.6711v1"
},{
    "category": "cs.CV", 
    "author": "Arun P. V.", 
    "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing", 
    "publish": "2013-03-27T18:57:12Z", 
    "summary": "Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration.", 
    "link": "http://arxiv.org/pdf/1303.6926v1", 
    "arxiv-id": "1303.6926v1"
},{
    "category": "cs.CV", 
    "author": "Dr. S. K. Katiyar", 
    "title": "An investigation towards wavelet based optimization of automatic image   registration techniques", 
    "publish": "2013-03-27T19:02:02Z", 
    "summary": "Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results.", 
    "link": "http://arxiv.org/pdf/1303.6927v1", 
    "arxiv-id": "1303.6927v1"
},{
    "category": "cs.CV", 
    "author": "Marleen de Bruijne", 
    "title": "Geometric tree kernels: Classification of COPD from airway tree geometry", 
    "publish": "2013-03-29T13:25:17Z", 
    "summary": "Methodological contributions: This paper introduces a family of kernels for\nanalyzing (anatomical) trees endowed with vector valued measurements made along\nthe tree. While state-of-the-art graph and tree kernels use combinatorial\ntree/graph structure with discrete node and edge labels, the kernels presented\nin this paper can include geometric information such as branch shape, branch\nradius or other vector valued properties. In addition to being flexible in\ntheir ability to model different types of attributes, the presented kernels are\ncomputationally efficient and some of them can easily be computed for large\ndatasets (N of the order 10.000) of trees with 30-600 branches. Combining the\nkernels with standard machine learning tools enables us to analyze the relation\nbetween disease and anatomical tree structure and geometry. Experimental\nresults: The kernels are used to compare airway trees segmented from low-dose\nCT, endowed with branch shape descriptors and airway wall area percentage\nmeasurements made along the tree. Using kernelized hypothesis testing we show\nthat the geometric airway trees are significantly differently distributed in\npatients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy\nindividuals. The geometric tree kernels also give a significant increase in the\nclassification accuracy of COPD from geometric tree structure endowed with\nairway wall thickness measurements in comparison with state-of-the-art methods,\ngiving further insight into the relationship between airway wall thickness and\nCOPD. Software: Software for computing kernels and statistical tests is\navailable at http://image.diku.dk/aasa/software.php.", 
    "link": "http://arxiv.org/pdf/1303.7390v2", 
    "arxiv-id": "1303.7390v2"
},{
    "category": "cs.CV", 
    "author": "Tizita Nesibu Shewaye", 
    "title": "Age group and gender recognition from human facial images", 
    "publish": "2013-03-29T20:32:04Z", 
    "summary": "This work presents an automatic human gender and age group recognition system\nbased on human facial images. It makes an extensive experiment with row pixel\nintensity valued features and Discrete Cosine Transform (DCT) coefficient\nfeatures with Principal Component Analysis and k-Nearest Neighbor\nclassification to identify the best recognition approach. The final results\nshow approaches using DCT coefficient outperform their counter parts resulting\nin a 99% correct gender recognition rate and 68% correct age group recognition\nrate (considering four distinct age groups) in unseen test images. Detailed\nexperimental settings and obtained results are clearly presented and explained\nin this report.", 
    "link": "http://arxiv.org/pdf/1304.0019v1", 
    "arxiv-id": "1304.0019v1"
},{
    "category": "cs.CV", 
    "author": "Peter Loxley", 
    "title": "The two-dimensional Gabor function adapted to natural image statistics:   An analytical model of simple-cell responses in the early visual system", 
    "publish": "2013-03-29T20:39:53Z", 
    "summary": "The two-dimensional Gabor function is adapted to natural image statistics by\nlearning the joint distribution of the Gabor function parameters. The joint\ndistribution is then approximated to yield an analytical model of simple-cell\nreceptive fields. Adapting a basis of Gabor functions is found to take an order\nof magnitude less computation than learning an equivalent non-parameterized\nbasis. Derived learning rules are shown to be capable of adapting Gabor\nparameters to the statistics of images of man-made and natural environments.\nLearning is found to be most pronounced in three Gabor parameters that\nrepresent the size, aspect-ratio, and spatial frequency of the two-dimensional\nGabor function. These three parameters are characterized by non-uniform\nmarginal distributions with heavy tails -- most likely due to scale invariance\nin natural images -- and all three parameters are strongly correlated:\nresulting in a basis of multiscale Gabor functions with similar aspect-ratios,\nand size-dependent spatial frequencies. The Gabor orientation and phase\nparameters do not appear to gain anything from learning over natural images.\nDifferent tuning strategies are found by controlling learning through the Gabor\nparameter learning rates. Two opposing strategies include well-resolved\norientation and well-resolved spatial frequency. On image reconstruction, a\nbasis of Gabor functions with fitted marginal distributions is shown to\nsignificantly outperform a basis of Gabor functions generated from uniformly\nsampled parameters. An additional increase in performance results when the\nstrong correlations are included. However, the best analytical model does not\nyet achieve the performance of the learned model. A comparison with estimates\nfor biological simple cells shows that the Gabor function adapted to natural\nimage statistics correctly predicts some key receptive field properties.", 
    "link": "http://arxiv.org/pdf/1304.0023v3", 
    "arxiv-id": "1304.0023v3"
},{
    "category": "cs.CV", 
    "author": "E. Iwata", 
    "title": "Stroke-Based Cursive Character Recognition", 
    "publish": "2013-04-01T19:14:27Z", 
    "summary": "Human eye can see and read what is written or displayed either in natural\nhandwriting or in printed format. The same work in case the machine does is\ncalled handwriting recognition. Handwriting recognition can be broken down into\ntwo categories: off-line and on-line. ...", 
    "link": "http://arxiv.org/pdf/1304.0421v1", 
    "arxiv-id": "1304.0421v1"
},{
    "category": "cs.CV", 
    "author": "Chunlong Hu", 
    "title": "Lie Algebrized Gaussians for Image Representation", 
    "publish": "2013-04-03T02:38:01Z", 
    "summary": "We present an image representation method which is derived from analyzing\nGaussian probability density function (\\emph{pdf}) space using Lie group\ntheory. In our proposed method, images are modeled by Gaussian mixture models\n(GMMs) which are adapted from a globally trained GMM called universal\nbackground model (UBM). Then we vectorize the GMMs based on two facts: (1)\ncomponents of image-specific GMMs are closely grouped together around their\ncorresponding component of the UBM due to the characteristic of the UBM\nadaption procedure; (2) Gaussian \\emph{pdf}s form a Lie group, which is a\ndifferentiable manifold rather than a vector space. We map each Gaussian\ncomponent to the tangent vector space (named Lie algebra) of Lie group at the\nmanifold position of UBM. The final feature vector, named Lie algebrized\nGaussians (LAG) is then constructed by combining the Lie algebrized Gaussian\ncomponents with mixture weights. We apply LAG features to scene category\nrecognition problem and observe state-of-the-art performance on 15Scenes\nbenchmark.", 
    "link": "http://arxiv.org/pdf/1304.0823v1", 
    "arxiv-id": "1304.0823v1"
},{
    "category": "cs.CV", 
    "author": "Dai-Gyoung Kim", 
    "title": "Multiscale Hybrid Non-local Means Filtering Using Modified Similarity   Measure", 
    "publish": "2013-04-03T04:24:21Z", 
    "summary": "A new multiscale implementation of non-local means filtering for image\ndenoising is proposed. The proposed algorithm also introduces a modification of\nsimilarity measure for patch comparison. The standard Euclidean norm is\nreplaced by weighted Euclidean norm for patch based comparison. Assuming the\npatch as an oriented surface, notion of normal vector patch is being associated\nwith each patch. The inner product of these normal vector patches is then used\nin weighted Euclidean distance of photometric patches as the weight factor. The\nalgorithm involves two steps: The first step is multiscale implementation of an\naccelerated non-local means filtering in the stationary wavelet domain to\nobtain a refined version of the noisy patches for later comparison. This step\nis inspired by a preselection phase of finding similar patches in various\nnon-local means approaches. The next step is to apply the modified non-local\nmeans filtering to the noisy image using the reference patches obtained in the\nfirst step. These refined patches contain less noise, and consequently the\ncomputation of normal vectors and partial derivatives is more accurate.\nExperimental results indicate equivalent or better performance of proposed\nalgorithm as compared to various state of the art algorithms.", 
    "link": "http://arxiv.org/pdf/1304.0839v1", 
    "arxiv-id": "1304.0839v1"
},{
    "category": "cs.CV", 
    "author": "Brian C. Lovell", 
    "title": "Improved Anomaly Detection in Crowded Scenes via Cell-based Analysis of   Foreground Speed, Size and Texture", 
    "publish": "2013-04-03T09:31:27Z", 
    "summary": "A robust and efficient anomaly detection technique is proposed, capable of\ndealing with crowded scenes where traditional tracking based approaches tend to\nfail. Initial foreground segmentation of the input frames confines the analysis\nto foreground objects and effectively ignores irrelevant background dynamics.\nInput frames are split into non-overlapping cells, followed by extracting\nfeatures based on motion, size and texture from each cell. Each feature type is\nindependently analysed for the presence of an anomaly. Unlike most methods, a\nrefined estimate of object motion is achieved by computing the optical flow of\nonly the foreground pixels. The motion and size features are modelled by an\napproximated version of kernel density estimation, which is computationally\nefficient even for large training datasets. Texture features are modelled by an\nadaptively grown codebook, with the number of entries in the codebook selected\nin an online fashion. Experiments on the recently published UCSD Anomaly\nDetection dataset show that the proposed method obtains considerably better\nresults than three recent approaches: MPPCA, social force, and mixture of\ndynamic textures (MDT). The proposed method is also several orders of magnitude\nfaster than MDT, the next best performing method.", 
    "link": "http://arxiv.org/pdf/1304.0886v1", 
    "arxiv-id": "1304.0886v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "A software for aging faces applied to ancient marble busts", 
    "publish": "2013-04-03T17:34:20Z", 
    "summary": "The study and development of software able to show the effect of aging of\nfaces is one of the tasks of face recognition technologies. Some software\nsolutions are used for investigations, some others to show the effects of drugs\non healthy appearance, however some other applications can be proposed for the\nanalysis of visual arts. Here we use a freely available software, which is\nproviding interesting results, for the comparison of ancient marble busts. An\nanalysis of Augustus busts is proposed.", 
    "link": "http://arxiv.org/pdf/1304.1022v1", 
    "arxiv-id": "1304.1022v1"
},{
    "category": "cs.CV", 
    "author": "Andrew D. A. Maidment", 
    "title": "Integration of spatio-temporal contrast sensitivity with a multi-slice   channelized Hotelling observer", 
    "publish": "2013-04-04T16:24:16Z", 
    "summary": "Barten's model of spatio-temporal contrast sensitivity function of human\nvisual system is embedded in a multi-slice channelized Hotelling observer. This\nis done by 3D filtering of the stack of images with the spatio-temporal\ncontrast sensitivity function and feeding the result (i.e., the perceived image\nstack) to the multi-slice channelized Hotelling observer. The proposed\nprocedure of considering spatio-temporal contrast sensitivity function is\ngeneric in the sense that it can be used with observers other than multi-slice\nchannelized Hotelling observer. Detection performance of the new observer in\ndigital breast tomosynthesis is measured in a variety of browsing speeds, at\ntwo spatial sampling rates, using computer simulations. Our results show a peak\nin detection performance in mid browsing speeds. We compare our results to\nthose of a human observer study reported earlier (I. Diaz et al. SPIE MI 2011).\nThe effects of display luminance, contrast and spatial sampling rate, with and\nwithout considering foveal vision, are also studied. Reported simulations are\nconducted with real digital breast tomosynthesis image stacks, as well as\nstacks from an anthropomorphic software breast phantom (P. Bakic et al. Med\nPhys. 2011). Lesion cases are simulated by inserting single\nmicro-calcifications or masses. Limitations of our methods and ways to improve\nthem are discussed.", 
    "link": "http://arxiv.org/pdf/1304.1419v1", 
    "arxiv-id": "1304.1419v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Multiscale Fractal Descriptors Applied to Texture Classification", 
    "publish": "2013-04-04T22:07:27Z", 
    "summary": "This work proposes the combination of multiscale transform with fractal\ndescriptors employed in the classification of gray-level texture images. We\napply the space-scale transform (derivative + Gaussian filter) over the\nBouligand-Minkowski fractal descriptors, followed by a threshold over the\nfilter response, aiming at attenuating noise effects caused by the final part\nof this response. The method is tested in the classification of a well-known\ndata set (Brodatz) and compared with other classical texture descriptor\ntechniques. The results demonstrate the advantage of the proposed approach,\nachieving a higher success rate with a reduced amount of descriptors.", 
    "link": "http://arxiv.org/pdf/1304.1568v1", 
    "arxiv-id": "1304.1568v1"
},{
    "category": "cs.CV", 
    "author": "Leonidas Guibas", 
    "title": "Spectral Descriptors for Graph Matching", 
    "publish": "2013-04-04T22:19:49Z", 
    "summary": "In this paper, we consider the weighted graph matching problem. Recently,\napproaches to this problem based on spectral methods have gained significant\nattention. We propose two graph spectral descriptors based on the graph\nLaplacian, namely a Laplacian family signature (LFS) on nodes, and a pairwise\nheat kernel distance on edges. We show the stability of both our descriptors\nunder small perturbation of edges and nodes. In addition, we show that our\npairwise heat kernel distance is a noise-tolerant approximation of the\nclassical adjacency matrix-based second order compatibility function. These\nnice properties suggest a descriptor-based matching scheme, for which we set up\nan integer quadratic problem (IQP) and apply an approximate solver to find a\nnear optimal solution. We have tested our matching method on a set of randomly\ngenerated graphs, the widely-used CMU house sequence and a set of real images.\nThese experiments show the superior performance of our selected node signatures\nand edge descriptors for graph matching, as compared with other existing\nsignature-based matchings and adjacency matrix-based matchings.", 
    "link": "http://arxiv.org/pdf/1304.1572v4", 
    "arxiv-id": "1304.1572v4"
},{
    "category": "cs.CV", 
    "author": "Antonio Rodr\u00edguez-S\u00e1nchez", 
    "title": "Proceedings of the 37th Annual Workshop of the Austrian Association for   Pattern Recognition (\u00d6AGM/AAPR), 2013", 
    "publish": "2013-04-06T10:36:25Z", 
    "summary": "This volume represents the proceedings of the 37th Annual Workshop of the\nAustrian Association for Pattern Recognition (\\\"OAGM/AAPR), held May 23-24,\n2013, in Innsbruck, Austria.", 
    "link": "http://arxiv.org/pdf/1304.1876v3", 
    "arxiv-id": "1304.1876v3"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "Facial transformations of ancient portraits: the face of Caesar", 
    "publish": "2013-04-07T09:43:47Z", 
    "summary": "Some software solutions used to obtain the facial transformations can help\ninvestigating the artistic metamorphosis of the ancient portraits of the same\nperson. An analysis with a freely available software of portraitures of Julius\nCaesar is proposed, showing his several \"morphs\". The software helps enhancing\nthe mood the artist added to a portrait.", 
    "link": "http://arxiv.org/pdf/1304.1972v1", 
    "arxiv-id": "1304.1972v1"
},{
    "category": "cs.CV", 
    "author": "M. M. A. Hashem", 
    "title": "Automatic Fingerprint Recognition Using Minutiae Matching Technique for   the Large Fingerprint Database", 
    "publish": "2013-04-08T06:14:48Z", 
    "summary": "Extracting minutiae from fingerprint images is one of the most important\nsteps in automatic fingerprint identification system. Because minutiae matching\nare certainly the most well-known and widely used method for fingerprint\nmatching, minutiae are local discontinuities in the fingerprint pattern. In\nthis paper a fingerprint matching algorithm is proposed using some specific\nfeature of the minutiae points, also the acquired fingerprint image is\nconsidered by minimizing its size by generating a corresponding fingerprint\ntemplate for a large fingerprint database. The results achieved are compared\nwith those obtained through some other methods also shows some improvement in\nthe minutiae detection process in terms of memory and time required.", 
    "link": "http://arxiv.org/pdf/1304.2109v1", 
    "arxiv-id": "1304.2109v1"
},{
    "category": "cs.CV", 
    "author": "Sun Zuolei", 
    "title": "Image Classification by Feature Dimension Reduction and Graph based   Ranking", 
    "publish": "2013-04-09T18:11:08Z", 
    "summary": "Dimensionality reduction (DR) of image features plays an important role in\nimage retrieval and classification tasks. Recently, two types of methods have\nbeen proposed to improve the both the accuracy and efficiency for the\ndimensionality reduction problem. One uses Non-negative matrix factorization\n(NMF) to describe the image distribution on the space of base matrix. Another\none for dimension reduction trains a subspace projection matrix to project\noriginal data space into some low-dimensional subspaces which have deep\narchitecture, so that the low-dimensional codes would be learned. At the same\ntime, the graph based similarity learning algorithm which tries to exploit\ncontextual information for improving the effectiveness of image rankings is\nalso proposed for image class and retrieval problem. In this paper, after above\ntwo methods mentioned are utilized to reduce the high-dimensional features of\nimages respectively, we learn the graph based similarity for the image\nclassification problem. This paper compares the proposed approach with other\napproaches on an image database.", 
    "link": "http://arxiv.org/pdf/1304.2683v1", 
    "arxiv-id": "1304.2683v1"
},{
    "category": "cs.CV", 
    "author": "Gilad Lerman", 
    "title": "A New Approach To Two-View Motion Segmentation Using Global Dimension   Minimization", 
    "publish": "2013-04-10T15:34:08Z", 
    "summary": "We present a new approach to rigid-body motion segmentation from two views.\nWe use a previously developed nonlinear embedding of two-view point\ncorrespondences into a 9-dimensional space and identify the different motions\nby segmenting lower-dimensional subspaces. In order to overcome nonuniform\ndistributions along the subspaces, whose dimensions are unknown, we suggest the\nnovel concept of global dimension and its minimization for clustering subspaces\nwith some theoretical motivation. We propose a fast projected gradient\nalgorithm for minimizing global dimension and thus segmenting motions from\n2-views. We develop an outlier detection framework around the proposed method,\nand we present state-of-the-art results on outlier-free and outlier-corrupted\ntwo-view data for segmenting motion.", 
    "link": "http://arxiv.org/pdf/1304.2999v2", 
    "arxiv-id": "1304.2999v2"
},{
    "category": "cs.CV", 
    "author": "Jianwei Wan", 
    "title": "Rotational Projection Statistics for 3D Local Surface Description and   Object Recognition", 
    "publish": "2013-04-11T04:26:52Z", 
    "summary": "Recognizing 3D objects in the presence of noise, varying mesh resolution,\nocclusion and clutter is a very challenging task. This paper presents a novel\nmethod named Rotational Projection Statistics (RoPS). It has three major\nmodules: Local Reference Frame (LRF) definition, RoPS feature description and\n3D object recognition. We propose a novel technique to define the LRF by\ncalculating the scatter matrix of all points lying on the local surface. RoPS\nfeature descriptors are obtained by rotationally projecting the neighboring\npoints of a feature point onto 2D planes and calculating a set of statistics\n(including low-order central moments and entropy) of the distribution of these\nprojected points. Using the proposed LRF and RoPS descriptor, we present a\nhierarchical 3D object recognition algorithm. The performance of the proposed\nLRF, RoPS descriptor and object recognition algorithm was rigorously tested on\na number of popular and publicly available datasets. Our proposed techniques\nexhibited superior performance compared to existing techniques. We also showed\nthat our method is robust with respect to noise and varying mesh resolution.\nOur RoPS based algorithm achieved recognition rates of 100%, 98.9%, 95.4% and\n96.0% respectively when tested on the Bologna, UWA, Queen's and Ca' Foscari\nVenezia Datasets.", 
    "link": "http://arxiv.org/pdf/1304.3192v1", 
    "arxiv-id": "1304.3192v1"
},{
    "category": "cs.CV", 
    "author": "David Sher", 
    "title": "Developing and Analyzing Boundary Detection Operators Using   Probabilistic Models", 
    "publish": "2013-03-27T19:58:23Z", 
    "summary": "Most feature detectors such as edge detectors or circle finders are\nstatistical, in the sense that they decide at each point in an image about the\npresence of a feature, this paper describes the use of Bayesian feature\ndetectors.", 
    "link": "http://arxiv.org/pdf/1304.3447v1", 
    "arxiv-id": "1304.3447v1"
},{
    "category": "cs.CV", 
    "author": "Ronen Basri", 
    "title": "Single View Depth Estimation from Examples", 
    "publish": "2013-04-14T13:56:14Z", 
    "summary": "We describe a non-parametric, \"example-based\" method for estimating the depth\nof an object, viewed in a single photo. Our method consults a database of\nexample 3D geometries, searching for those which look similar to the object in\nthe photo. The known depths of the selected database objects act as shape\npriors which constrain the process of estimating the object's depth. We show\nhow this process can be performed by optimizing a well defined target\nlikelihood function, via a hard-EM procedure. We address the problem of\nrepresenting the (possibly infinite) variability of viewing conditions with a\nfinite (and often very small) example set, by proposing an on-the-fly example\nupdate scheme. We further demonstrate the importance of non-stationarity in\navoiding misleading examples when estimating structured shapes. We evaluate our\nmethod and present both qualitative as well as quantitative results for\nchallenging object classes. Finally, we show how this same technique may be\nreadily applied to a number of related problems. These include the novel task\nof estimating the occluded depth of an object's backside and the task of\ntailoring custom fitting image-maps for input depths.", 
    "link": "http://arxiv.org/pdf/1304.3915v1", 
    "arxiv-id": "1304.3915v1"
},{
    "category": "cs.CV", 
    "author": "D. Racoceanu", 
    "title": "Multispectral Spatial Characterization: Application to Mitosis Detection   in Breast Cancer Histopathology", 
    "publish": "2013-04-15T10:11:34Z", 
    "summary": "Accurate detection of mitosis plays a critical role in breast cancer\nhistopathology. Manual detection and counting of mitosis is tedious and subject\nto considerable inter- and intra-reader variations. Multispectral imaging is a\nrecent medical imaging technology, proven successful in increasing the\nsegmentation accuracy in other fields. This study aims at improving the\naccuracy of mitosis detection by developing a specific solution using\nmultispectral and multifocal imaging of breast cancer histopathological data.\nWe propose to enable clinical routine-compliant quality of mitosis\ndiscrimination from other objects. The proposed framework includes\ncomprehensive analysis of spectral bands and z-stack focus planes, detection of\nexpected mitotic regions (candidates) in selected focus planes and spectral\nbands, computation of multispectral spatial features for each candidate,\nselection of multispectral spatial features and a study of different\nstate-of-the-art classification methods for candidates classification as\nmitotic or non mitotic figures. This framework has been evaluated on MITOS\nmultispectral medical dataset and achieved 60% detection rate and 57%\nF-Measure. Our results indicate that multispectral spatial features have more\ninformation for mitosis classification in comparison with white spectral band\nfeatures, being therefore a very promising exploration area to improve the\nquality of the diagnosis assistance in histopathology.", 
    "link": "http://arxiv.org/pdf/1304.4041v1", 
    "arxiv-id": "1304.4041v1"
},{
    "category": "cs.CV", 
    "author": "Robert Pless", 
    "title": "Shadow Estimation Method for \"The Episolar Constraint: Monocular Shape   from Shadow Correspondence\"", 
    "publish": "2013-04-15T14:31:21Z", 
    "summary": "Recovering shadows is an important step for many vision algorithms. Current\napproaches that work with time-lapse sequences are limited to simple\nthresholding heuristics. We show these approaches only work with very careful\ntuning of parameters, and do not work well for long-term time-lapse sequences\ntaken over the span of many months. We introduce a parameter-free expectation\nmaximization approach which simultaneously estimates shadows, albedo, surface\nnormals, and skylight. This approach is more accurate than previous methods,\nworks over both very short and very long sequences, and is robust to the\neffects of nonlinear camera response. Finally, we demonstrate that the shadow\nmasks derived through this algorithm substantially improve the performance of\nsun-based photometric stereo compared to earlier shadow mask estimation.", 
    "link": "http://arxiv.org/pdf/1304.4112v1", 
    "arxiv-id": "1304.4112v1"
},{
    "category": "cs.CV", 
    "author": "Odemir Martinez Bruno", 
    "title": "Heterogeneous patterns enhancing static and dynamic texture   classification", 
    "publish": "2013-04-16T17:53:16Z", 
    "summary": "Some mixtures, such as colloids like milk, blood, and gelatin, have\nhomogeneous appearance when viewed with the naked eye, however, to observe them\nat the nanoscale is possible to understand the heterogeneity of its components.\nThe same phenomenon can occur in pattern recognition in which it is possible to\nsee heterogeneous patterns in texture images. However, current methods of\ntexture analysis can not adequately describe such heterogeneous patterns.\nCommon methods used by researchers analyse the image information in a global\nway, taking all its features in an integrated manner. Furthermore, multi-scale\nanalysis verifies the patterns at different scales, but still preserving the\nhomogeneous analysis. On the other hand various methods use textons to\nrepresent the texture, breaking texture down into its smallest unit. To tackle\nthis problem, we propose a method to identify texture patterns not small as\ntextons at distinct scales enhancing the separability among different types of\ntexture. We find sub patterns of texture according to the scale and then group\nsimilar patterns for a more refined analysis. Tests were performed in four\nstatic texture databases and one dynamic one. Results show that our method\nprovides better classification rate compared with conventional approaches both\nin static and in dynamic texture.", 
    "link": "http://arxiv.org/pdf/1304.4535v1", 
    "arxiv-id": "1304.4535v1"
},{
    "category": "cs.CV", 
    "author": "K Singal", 
    "title": "Tracking of Fingertips and Centres of Palm using KINECT", 
    "publish": "2013-04-17T01:20:10Z", 
    "summary": "Hand Gesture is a popular way to interact or control machines and it has been\nimplemented in many applications. The geometry of hand is such that it is hard\nto construct in virtual environment and control the joints but the\nfunctionality and DOF encourage researchers to make a hand like instrument.\nThis paper presents a novel method for fingertips detection and centres of\npalms detection distinctly for both hands using MS KINECT in 3D from the input\nimage. KINECT facilitates us by providing the depth information of foreground\nobjects. The hands were segmented using the depth vector and centres of palms\nwere detected using distance transformation on inverse image. This result would\nbe used to feed the inputs to the robotic hands to emulate human hands\noperation.", 
    "link": "http://arxiv.org/pdf/1304.4662v1", 
    "arxiv-id": "1304.4662v1"
},{
    "category": "cs.CV", 
    "author": "Ankur Gupta", 
    "title": "Automated Switching System for Skin Pixel Segmentation in Varied   Lighting", 
    "publish": "2013-04-17T07:07:52Z", 
    "summary": "In Computer Vision, colour-based spatial techniquesoften assume a static skin\ncolour model. However, skin colour perceived by a camera can change when\nlighting changes. In common real environment multiple light sources impinge on\nthe skin. Moreover, detection techniques may vary when the image under study is\ntaken under different lighting condition than the one that was earlier under\nconsideration. Therefore, for robust skin pixel detection, a dynamic skin\ncolour model that can cope with the changes must be employed. This paper shows\nthat skin pixel detection in a digital colour image can be significantly\nimproved by employing automated colour space switching methods. In the root of\nthe switching technique which is employed in this study, lies the statistical\nmean of value of the skin pixels in the image which in turn has been derived\nfrom the Value, measures as a third component of the HSV. The study is based on\nexperimentations on a set of images where capture time conditions varying from\nhighly illuminated to almost dark.", 
    "link": "http://arxiv.org/pdf/1304.4711v1", 
    "arxiv-id": "1304.4711v1"
},{
    "category": "cs.CV", 
    "author": "Hamid Amiri", 
    "title": "Robust Noise Filtering in Image Sequences", 
    "publish": "2013-04-17T10:55:43Z", 
    "summary": "Image sequences filtering have recently become a very important technical\nproblem especially with the advent of new technology in multimedia and video\nsystems applications. Often image sequences are corrupted by some amount of\nnoise introduced by the image sensor and therefore inherently present in the\nimaging process. The main problem in the image sequences is how to deal with\nspatio-temporal and non stationary signals. In this paper, we propose a robust\nmethod for noise removal of image sequence based on coupled spatial and\ntemporal anisotropic diffusion. The idea is to achieve an adaptive smoothing in\nboth spatial and temporal directions, by solving a nonlinear diffusion\nequation. This allows removing noise while preserving all spatial and temporal\ndiscontinuities", 
    "link": "http://arxiv.org/pdf/1304.4765v1", 
    "arxiv-id": "1304.4765v1"
},{
    "category": "cs.CV", 
    "author": "Jorge L. L\u00f3pez-L\u00f3pez", 
    "title": "Polygon Matching and Indexing Under Affine Transformations", 
    "publish": "2013-04-18T00:40:22Z", 
    "summary": "Given a collection $\\{Z_1,Z_2,\\ldots,Z_m\\}$ of $n$-sided polygons in the\nplane and a query polygon $W$ we give algorithms to find all $Z_\\ell$ such that\n$W=f(Z_\\ell)$ with $f$ an unknown similarity transformation in time independent\nof the size of the collection. If $f$ is a known affine transformation, we show\nhow to find all $Z_\\ell$ such that $W=f(Z_\\ell)$ in $O(n+\\log(m))$ time.\n  For a pair $W,W^\\prime$ of polygons we can find all the pairs\n$Z_\\ell,Z_{\\ell^\\prime}$ such that $W=f(Z_\\ell)$ and\n$W^\\prime=f(Z_{\\ell^\\prime})$ for an unknown affine transformation $f$ in\n$O(m+n)$ time.\n  For the case of triangles we also give bounds for the problem of matching\ntriangles with variable vertices, which is equivalent to affine matching\ntriangles in noisy conditions.", 
    "link": "http://arxiv.org/pdf/1304.4994v1", 
    "arxiv-id": "1304.4994v1"
},{
    "category": "cs.CV", 
    "author": "Monique Thonnat", 
    "title": "Object Tracking in Videos: Approaches and Issues", 
    "publish": "2013-04-18T18:41:47Z", 
    "summary": "Mobile object tracking has an important role in the computer vision\napplications. In this paper, we use a tracked target-based taxonomy to present\nthe object tracking algorithms. The tracked targets are divided into three\ncategories: points of interest, appearance and silhouette of mobile objects.\nAdvantages and limitations of the tracking approaches are also analyzed to find\nthe future directions in the object tracking domain.", 
    "link": "http://arxiv.org/pdf/1304.5212v1", 
    "arxiv-id": "1304.5212v1"
},{
    "category": "cs.CV", 
    "author": "Martin Kleinsteuber", 
    "title": "A Joint Intensity and Depth Co-Sparse Analysis Model for Depth Map   Super-Resolution", 
    "publish": "2013-04-19T06:35:33Z", 
    "summary": "High-resolution depth maps can be inferred from low-resolution depth\nmeasurements and an additional high-resolution intensity image of the same\nscene. To that end, we introduce a bimodal co-sparse analysis model, which is\nable to capture the interdependency of registered intensity and depth\ninformation. This model is based on the assumption that the co-supports of\ncorresponding bimodal image structures are aligned when computed by a suitable\npair of analysis operators. No analytic form of such operators exist and we\npropose a method for learning them from a set of registered training signals.\nThis learning process is done offline and returns a bimodal analysis operator\nthat is universally applicable to natural scenes. We use this to exploit the\nbimodal co-sparse analysis model as a prior for solving inverse problems, which\nleads to an efficient algorithm for depth map super-resolution.", 
    "link": "http://arxiv.org/pdf/1304.5319v1", 
    "arxiv-id": "1304.5319v1"
},{
    "category": "cs.CV", 
    "author": "K. Palaniappan", 
    "title": "Color image denoising by chromatic edges based vector valued diffusion", 
    "publish": "2013-04-20T05:05:53Z", 
    "summary": "In this letter we propose to denoise digital color images via an improved\ngeometric diffusion scheme. By introducing edges detected from all three color\nchannels into the diffusion the proposed scheme avoids color smearing\nartifacts. Vector valued diffusion is used to control the smoothing and the\ngeometry of color images are taken into consideration. Color edge strength\nfunction computed from different planes is introduced and it stops the\ndiffusion spread across chromatic edges. Experimental results indicate that the\nscheme achieves good denoising with edge preservation when compared to other\nrelated schemes.", 
    "link": "http://arxiv.org/pdf/1304.5587v2", 
    "arxiv-id": "1304.5587v2"
},{
    "category": "cs.CV", 
    "author": "Martin Kampel", 
    "title": "A Bag of Visual Words Approach for Symbols-Based Coarse-Grained Ancient   Coin Classification", 
    "publish": "2013-04-23T07:46:11Z", 
    "summary": "The field of Numismatics provides the names and descriptions of the symbols\nminted on the ancient coins. Classification of the ancient coins aims at\nassigning a given coin to its issuer. Various issuers used various symbols for\ntheir coins. We propose to use these symbols for a framework that will coarsely\nclassify the ancient coins. Bag of visual words (BoVWs) is a well established\nvisual recognition technique applied to various problems in computer vision\nlike object and scene recognition. Improvements have been made by incorporating\nthe spatial information to this technique. We apply the BoVWs technique to our\nproblem and use three symbols for coarse-grained classification. We use\nrectangular tiling, log-polar tiling and circular tiling to incorporate spatial\ninformation to BoVWs. Experimental results show that the circular tiling proves\nsuperior to the rest of the methods for our problem.", 
    "link": "http://arxiv.org/pdf/1304.6192v1", 
    "arxiv-id": "1304.6192v1"
},{
    "category": "cs.CV", 
    "author": "Lucas Paletta", 
    "title": "Counting people from above: Airborne video based crowd analysis", 
    "publish": "2013-04-23T09:51:02Z", 
    "summary": "Crowd monitoring and analysis in mass events are highly important\ntechnologies to support the security of attending persons. Proposed methods\nbased on terrestrial or airborne image/video data often fail in achieving\nsufficiently accurate results to guarantee a robust service. We present a novel\nframework for estimating human count, density and motion from video data based\non custom tailored object detection techniques, a regression based density\nestimate and a total variation based optical flow extraction. From the gathered\nfeatures we present a detailed accuracy analysis versus ground truth\nmeasurements. In addition, all information is projected into world coordinates\nto enable a direct integration with existing geo-information systems. The\nresulting human counts demonstrate a mean error of 4% to 9% and thus represent\na most efficient measure that can be robustly applied in security critical\nservices.", 
    "link": "http://arxiv.org/pdf/1304.6213v1", 
    "arxiv-id": "1304.6213v1"
},{
    "category": "cs.CV", 
    "author": "Yi Li", 
    "title": "Learning Visual Symbols for Parsing Human Poses in Images", 
    "publish": "2013-04-23T14:07:19Z", 
    "summary": "Parsing human poses in images is fundamental in extracting critical visual\ninformation for artificial intelligent agents. Our goal is to learn\nself-contained body part representations from images, which we call visual\nsymbols, and their symbol-wise geometric contexts in this parsing process. Each\nsymbol is individually learned by categorizing visual features leveraged by\ngeometric information. In the categorization, we use Latent Support Vector\nMachine followed by an efficient cross validation procedure to learn visual\nsymbols. Then, these symbols naturally define geometric contexts of body parts\nin a fine granularity. When the structure of the compositional parts is a tree,\nwe derive an efficient approach to estimating human poses in images.\nExperiments on two large datasets suggest our approach outperforms state of the\nart methods.", 
    "link": "http://arxiv.org/pdf/1304.6291v1", 
    "arxiv-id": "1304.6291v1"
},{
    "category": "cs.CV", 
    "author": "Firas A. Jassim", 
    "title": "Semi-Optimal Edge Detector based on Simple Standard Deviation with   Adjusted Thresholding", 
    "publish": "2013-04-23T18:53:58Z", 
    "summary": "This paper proposes a novel method which combines both median filter and\nsimple standard deviation to accomplish an excellent edge detector for image\nprocessing. First of all, a denoising process must be applied on the grey scale\nimage using median filter to identify pixels which are likely to be\ncontaminated by noise. The benefit of this step is to smooth the image and get\nrid of the noisy pixels. After that, the simple statistical standard deviation\ncould be computed for each 2X2 window size. If the value of the standard\ndeviation inside the 2X2 window size is greater than a predefined threshold,\nthen the upper left pixel in the 2?2 window represents an edge. The visual\ndifferences between the proposed edge detector and the standard known edge\ndetectors have been shown to support the contribution in this paper.", 
    "link": "http://arxiv.org/pdf/1304.6379v1", 
    "arxiv-id": "1304.6379v1"
},{
    "category": "cs.CV", 
    "author": "Firas A. Jassim", 
    "title": "k-Modulus Method for Image Transformation", 
    "publish": "2013-04-24T21:34:30Z", 
    "summary": "In this paper, we propose a new algorithm to make a novel spatial image\ntransformation. The proposed approach aims to reduce the bit depth used for\nimage storage. The basic technique for the proposed transformation is based of\nthe modulus operator. The goal is to transform the whole image into multiples\nof predefined integer. The division of the whole image by that integer will\nguarantee that the new image surely less in size from the original image. The\nk-Modulus Method could not be used as a stand alone transform for image\ncompression because of its high compression ratio. It could be used as a scheme\nembedded in other image processing fields especially compression. According to\nits high PSNR value, it could be amalgamated with other methods to facilitate\nthe redundancy criterion.", 
    "link": "http://arxiv.org/pdf/1304.6759v1", 
    "arxiv-id": "1304.6759v1"
},{
    "category": "cs.CV", 
    "author": "Robert Sablatnig", 
    "title": "Digit Recognition in Handwritten Weather Records", 
    "publish": "2013-04-25T15:14:42Z", 
    "summary": "This paper addresses the automatic recognition of handwritten temperature\nvalues in weather records. The localization of table cells is based on line\ndetection using projection profiles. Further, a stroke-preserving line removal\nmethod which is based on gradient images is proposed. The presented digit\nrecognition utilizes features which are extracted using a set of filters and a\nSupport Vector Machine classifier. It was evaluated on the MNIST and the USPS\ndataset and our own database with about 17,000 RGB digit images. An accuracy of\n99.36% per digit is achieved for the entire system using a set of 84 weather\nrecords.", 
    "link": "http://arxiv.org/pdf/1304.6933v2", 
    "arxiv-id": "1304.6933v2"
},{
    "category": "cs.CV", 
    "author": "Tomas Pajdla", 
    "title": "Euclidean Upgrade from a Minimal Number of Segments", 
    "publish": "2013-04-25T19:44:26Z", 
    "summary": "In this paper, we propose an algebraic approach to upgrade a projective\nreconstruction to a Euclidean one, and aim at computing the rectifying\nhomography from a minimal number of 9 segments of known length. Constraints are\nderived from these segments which yield a set of polynomial equations that we\nsolve by means of Gr\\\"obner bases. We explain how a solver for such a system of\nequations can be constructed from simplified template data. Moreover, we\npresent experiments that demonstrate that the given problem can be solved in\nthis way.", 
    "link": "http://arxiv.org/pdf/1304.6990v1", 
    "arxiv-id": "1304.6990v1"
},{
    "category": "cs.CV", 
    "author": "Thomas Pock", 
    "title": "A Convex Approach for Image Hallucination", 
    "publish": "2013-04-26T13:10:22Z", 
    "summary": "In this paper we propose a global convex approach for image hallucination.\nAltering the idea of classical multi image super resolution (SU) systems to\nsingle image SU, we incorporate aligned images to hallucinate the output. Our\nwork is based on the paper of Tappen et al. where they use a non-convex model\nfor image hallucination. In comparison we formulate a convex primal\noptimization problem and derive a fast converging primal-dual algorithm with a\nglobal optimal solution. We use a database with face images to incorporate\nhigh-frequency details to the high-resolution output. We show that we can\nachieve state-of-the-art results by using a convex approach.", 
    "link": "http://arxiv.org/pdf/1304.7153v1", 
    "arxiv-id": "1304.7153v1"
},{
    "category": "cs.CV", 
    "author": "Martin Kampel", 
    "title": "Reading Ancient Coin Legends: Object Recognition vs. OCR", 
    "publish": "2013-04-26T14:33:52Z", 
    "summary": "Standard OCR is a well-researched topic of computer vision and can be\nconsidered solved for machine-printed text. However, when applied to\nunconstrained images, the recognition rates drop drastically. Therefore, the\nemployment of object recognition-based techniques has become state of the art\nin scene text recognition applications. This paper presents a scene text\nrecognition method tailored to ancient coin legends and compares the results\nachieved in character and word recognition experiments to a standard OCR\nengine. The conducted experiments show that the proposed method outperforms the\nstandard OCR engine on a set of 180 cropped coin legend words.", 
    "link": "http://arxiv.org/pdf/1304.7184v1", 
    "arxiv-id": "1304.7184v1"
},{
    "category": "cs.CV", 
    "author": "Martin Erler", 
    "title": "Algorithmic Optimisations for Iterative Deconvolution Methods", 
    "publish": "2013-04-26T16:02:40Z", 
    "summary": "We investigate possibilities to speed up iterative algorithms for non-blind\nimage deconvolution. We focus on algorithms in which convolution with the\npoint-spread function to be deconvolved is used in each iteration, and aim at\naccelerating these convolution operations as they are typically the most\nexpensive part of the computation. We follow two approaches: First, for some\npractically important specific point-spread functions, algorithmically\nefficient sliding window or list processing techniques can be used. In some\nconstellations this allows faster computation than via the Fourier domain.\nSecond, as iterations progress, computation of convolutions can be restricted\nto subsets of pixels. For moderate thinning rates this can be done with almost\nno impact on the reconstruction quality. Both approaches are demonstrated in\nthe context of Richardson-Lucy deconvolution but are not restricted to this\nmethod.", 
    "link": "http://arxiv.org/pdf/1304.7211v1", 
    "arxiv-id": "1304.7211v1"
},{
    "category": "cs.CV", 
    "author": "Nebojsa Jojic", 
    "title": "In the sight of my wearable camera: Classifying my visual experience", 
    "publish": "2013-04-26T17:28:13Z", 
    "summary": "We introduce and we analyze a new dataset which resembles the input to\nbiological vision systems much more than most previously published ones. Our\nanalysis leaded to several important conclusions. First, it is possible to\ndisambiguate over dozens of visual scenes (locations) encountered over the\ncourse of several weeks of a human life with accuracy of over 80%, and this\nopens up possibility for numerous novel vision applications, from early\ndetection of dementia to everyday use of wearable camera streams for automatic\nreminders, and visual stream exchange. Second, our experimental results\nindicate that, generative models such as Latent Dirichlet Allocation or\nCounting Grids, are more suitable to such types of data, as they are more\nrobust to overtraining and comfortable with images at low resolution, blurred\nand characterized by relatively random clutter and a mix of objects.", 
    "link": "http://arxiv.org/pdf/1304.7236v1", 
    "arxiv-id": "1304.7236v1"
},{
    "category": "cs.CV", 
    "author": "Patrick van der Smagt", 
    "title": "Convolutional Neural Networks learn compact local image descriptors", 
    "publish": "2013-04-30T10:41:26Z", 
    "summary": "A standard deep convolutional neural network paired with a suitable loss\nfunction learns compact local image descriptors that perform comparably to\nstate-of-the art approaches.", 
    "link": "http://arxiv.org/pdf/1304.7948v2", 
    "arxiv-id": "1304.7948v2"
},{
    "category": "cs.CV", 
    "author": "Yisong Lv", 
    "title": "Registration of Images with Outliers Using Joint Saliency Map", 
    "publish": "2013-03-29T22:30:09Z", 
    "summary": "Mutual information (MI) is a popular similarity measure for image\nregistration, whereby good registration can be achieved by maximizing the\ncompactness of the clusters in the joint histogram. However, MI is sensitive to\nthe \"outlier\" objects that appear in one image but not the other, and also\nsuffers from local and biased maxima. We propose a novel joint saliency map\n(JSM) to highlight the corresponding salient structures in the two images, and\nemphatically group those salient structures into the smoothed compact clusters\nin the weighted joint histogram. This strategy could solve both the outlier and\nthe local maxima problems. Experimental results show that the JSM-MI based\nalgorithm is not only accurate but also robust for registration of challenging\nimage pairs with outliers.", 
    "link": "http://arxiv.org/pdf/1304.8052v1", 
    "arxiv-id": "1304.8052v1"
},{
    "category": "cs.CV", 
    "author": "V. Sivakumar", 
    "title": "Fractal-Based Detection of Microcalcification Clusters in Digital   Mammograms", 
    "publish": "2013-04-30T17:51:27Z", 
    "summary": "In this paper, a novel method for edge detection of microcalcification\nclusters in mammogram images is presented using the concept of Fractal\nDimension and Hurst co-efficient that enables to locate the microcalcifications\nin the mammograms. This technique detects the edges accurately than the ones\nobtained by the conventional Sobel method. Generally, Sobel method detects the\nedges of the regions/objects in an image using the Fudge factor that assumes\nits value as 0.5, by default. In this proposed technique, the Fudge factor is\nsuitably replaced with Hurst Co-efficient, which is computed as the difference\nof Fractal dimension and the topological dimension of a given input image.\nThese two dimensions are image-dependent, and hence the respective Hurst\nco-efficient too varies with respect to images. Hence, the image-dependent\nHurst co-efficient based Sobel method is proved to produce better results than\nthe Fudge factor based Sobel method. The results of the proposed method\nsubstantiate the merit of the proposed technique.", 
    "link": "http://arxiv.org/pdf/1304.8092v1", 
    "arxiv-id": "1304.8092v1"
},{
    "category": "cs.CV", 
    "author": "Z. Jane Wang", 
    "title": "An Adaptive Descriptor Design for Object Recognition in the Wild", 
    "publish": "2013-05-01T23:11:36Z", 
    "summary": "Digital images nowadays have various styles of appearance, in the aspects of\ncolor tones, contrast, vignetting, and etc. These 'picture styles' are directly\nrelated to the scene radiance, image pipeline of the camera, and post\nprocessing functions. Due to the complexity and nonlinearity of these causes,\npopular gradient-based image descriptors won't be invariant to different\npicture styles, which will decline the performance of object recognition. Given\nthat images shared online or created by individual users are taken with a wide\nrange of devices and may be processed by various post processing functions, to\nfind a robust object recognition system is useful and challenging. In this\npaper, we present the first study on the influence of picture styles for object\nrecognition, and propose an adaptive approach based on the kernel view of\ngradient descriptors and multiple kernel learning, without estimating or\nspecifying the styles of images used in training and testing. We conduct\nexperiments on Domain Adaptation data set and Oxford Flower data set. The\nexperiments also include several variants of the flower data set by processing\nthe images with popular photo effects. The results demonstrate that our\nproposed method improve from standard descriptors in all cases.", 
    "link": "http://arxiv.org/pdf/1305.0311v1", 
    "arxiv-id": "1305.0311v1"
},{
    "category": "cs.CV", 
    "author": "Yanjiang Wang", 
    "title": "Dictionary learning based image enhancement for rarity detection", 
    "publish": "2013-05-04T03:14:46Z", 
    "summary": "Image enhancement is an important image processing technique that processes\nimages suitably for a specific application e.g. image editing. The conventional\nsolutions of image enhancement are grouped into two categories which are\nspatial domain processing method and transform domain processing method such as\ncontrast manipulation, histogram equalization, homomorphic filtering. This\npaper proposes a new image enhance method based on dictionary learning.\nParticularly, the proposed method adjusts the image by manipulating the rarity\nof dictionary atoms. Firstly, learn the dictionary through sparse coding\nalgorithms on divided sub-image blocks. Secondly, compute the rarity of\ndictionary atoms on statistics of the corresponding sparse coefficients.\nThirdly, adjust the rarity according to specific application and form a new\ndictionary. Finally, reconstruct the image using the updated dictionary and\nsparse coefficients. Compared with the traditional techniques, the proposed\nmethod enhances image based on the image content not on distribution of pixel\ngrey value or frequency. The advantages of the proposed method lie in that it\nis in better correspondence with the response of the human visual system and\nmore suitable for salient objects extraction. The experimental results\ndemonstrate the effectiveness of the proposed image enhance method.", 
    "link": "http://arxiv.org/pdf/1305.0871v2", 
    "arxiv-id": "1305.0871v2"
},{
    "category": "cs.CV", 
    "author": "Fawzi H. Altaani", 
    "title": "Hybridization of Otsu Method and Median Filter for Color Image   Segmentation", 
    "publish": "2013-05-05T20:49:54Z", 
    "summary": "In this article a novel algorithm for color image segmentation has been\ndeveloped. The proposed algorithm based on combining two existing methods in\nsuch a novel way to obtain a significant method to partition the color image\ninto significant regions. On the first phase, the traditional Otsu method for\ngray channel image segmentation were applied for each of the R,G, and B\nchannels separately to determine the suitable automatic threshold for each\nchannel. After that, the new modified channels are integrated again to\nformulate a new color image. The resulted image suffers from some kind of\ndistortion. To get rid of this distortion, the second phase is arise which is\nthe median filter to smooth the image and increase the segmented regions. This\nprocess looks very significant by the ocular eye. Experimental results were\npresented on a variety of test images to support the proposed algorithm.", 
    "link": "http://arxiv.org/pdf/1305.1052v1", 
    "arxiv-id": "1305.1052v1"
},{
    "category": "cs.CV", 
    "author": "Heinz Mayer", 
    "title": "A Computer Vision System for Attention Mapping in SLAM based 3D Models", 
    "publish": "2013-05-06T12:35:52Z", 
    "summary": "The study of human factors in the frame of interaction studies has been\nrelevant for usability engi-neering and ergonomics for decades. Today, with the\nadvent of wearable eye-tracking and Google glasses, monitoring of human factors\nwill soon become ubiquitous. This work describes a computer vision system that\nenables pervasive mapping and monitoring of human attention. The key\ncontribu-tion is that our methodology enables full 3D recovery of the gaze\npointer, human view frustum and associated human centred measurements directly\ninto an automatically computed 3D model in real-time. We apply RGB-D SLAM and\ndescriptor matching methodologies for the 3D modelling, locali-zation and fully\nautomated annotation of ROIs (regions of interest) within the acquired 3D\nmodel. This innovative methodology will open new avenues for attention studies\nin real world environments, bringing new potential into automated processing\nfor human factors technologies.", 
    "link": "http://arxiv.org/pdf/1305.1163v1", 
    "arxiv-id": "1305.1163v1"
},{
    "category": "cs.CV", 
    "author": "Leslie N. Smith", 
    "title": "How to find real-world applications for compressive sensing", 
    "publish": "2013-05-06T14:00:07Z", 
    "summary": "The potential of compressive sensing (CS) has spurred great interest in the\nresearch community and is a fast growing area of research. However, research\ntranslating CS theory into practical hardware and demonstrating clear and\nsignificant benefits with this hardware over current, conventional imaging\ntechniques has been limited. This article helps researchers to find those niche\napplications where the CS approach provides substantial gain over conventional\napproaches by articulating lessons learned in finding one such application; sea\nskimming missile detection. As a proof of concept, it is demonstrated that a\nsimplified CS missile detection architecture and algorithm provides comparable\nresults to the conventional imaging approach but using a smaller FPA. The\nprimary message is that all of the excitement surrounding CS is necessary and\nappropriate for encouraging our creativity but we all must also take off our\n\"rose colored glasses\" and critically judge our ideas, methods and results\nrelative to conventional imaging approaches.", 
    "link": "http://arxiv.org/pdf/1305.1199v4", 
    "arxiv-id": "1305.1199v4"
},{
    "category": "cs.CV", 
    "author": "Gregory Randall", 
    "title": "A Contrario Selection of Optimal Partitions for Image Segmentation", 
    "publish": "2013-05-06T14:17:11Z", 
    "summary": "We present a novel segmentation algorithm based on a hierarchical\nrepresentation of images. The main contribution of this work is to explore the\ncapabilities of the A Contrario reasoning when applied to the segmentation\nproblem, and to overcome the limitations of current algorithms within that\nframework. This exploratory approach has three main goals.\n  Our first goal is to extend the search space of greedy merging algorithms to\nthe set of all partitions spanned by a certain hierarchy, and to cast the\nsegmentation as a selection problem within this space. In this way we increase\nthe number of tested partitions and thus we potentially improve the\nsegmentation results. In addition, this space is considerably smaller than the\nspace of all possible partitions, thus we still keep the complexity controlled.\n  Our second goal aims to improve the locality of region merging algorithms,\nwhich usually merge pairs of neighboring regions. In this work, we overcome\nthis limitation by introducing a validation procedure for complete partitions,\nrather than for pairs of regions.\n  The third goal is to perform an exhaustive experimental evaluation\nmethodology in order to provide reproducible results.\n  Finally, we embed the selection process on a statistical A Contrario\nframework which allows us to have only one free parameter related to the\ndesired scale.", 
    "link": "http://arxiv.org/pdf/1305.1206v1", 
    "arxiv-id": "1305.1206v1"
},{
    "category": "cs.CV", 
    "author": "Hamid Amiri", 
    "title": "Speckle Noise Reduction in Medical Ultrasound Images", 
    "publish": "2013-05-06T22:25:52Z", 
    "summary": "Ultrasound imaging is an incontestable vital tool for diagnosis, it provides\nin non-invasive manner the internal structure of the body to detect eventually\ndiseases or abnormalities tissues. Unfortunately, the presence of speckle noise\nin these images affects edges and fine details which limit the contrast\nresolution and make diagnostic more difficult. In this paper, we propose a\ndenoising approach which combines logarithmic transformation and a non linear\ndiffusion tensor. Since speckle noise is multiplicative and nonwhite process,\nthe logarithmic transformation is a reasonable choice to convert\nsignaldependent or pure multiplicative noise to an additive one. The key idea\nfrom using diffusion tensor is to adapt the flow diffusion towards the local\norientation by applying anisotropic diffusion along the coherent structure\ndirection of interesting features in the image. To illustrate the effective\nperformance of our algorithm, we present some experimental results on\nsynthetically and real echographic images.", 
    "link": "http://arxiv.org/pdf/1305.1344v1", 
    "arxiv-id": "1305.1344v1"
},{
    "category": "cs.CV", 
    "author": "Umut Uludag", 
    "title": "Standard Fingerprint Databases: Manual Minutiae Labeling and Matcher   Performance Analyses", 
    "publish": "2013-05-07T09:03:38Z", 
    "summary": "Fingerprint verification and identification algorithms based on minutiae\nfeatures are used in many biometric systems today (e.g., governmental e-ID\nprograms, border control, AFIS, personal authentication for portable devices).\nResearchers in industry/academia are now able to utilize many publicly\navailable fingerprint databases (e.g., Fingerprint Verification Competition\n(FVC) & NIST databases) to compare/evaluate their feature extraction and/or\nmatching algorithm performances against those of others. The results from these\nevaluations are typically utilized by decision makers responsible for\nimplementing the cited biometric systems, in selecting/tuning specific sensors,\nfeature extractors and matchers. In this study, for a subset of the cited\npublic fingerprint databases, we report fingerprint minutiae matching results,\nwhich are based on (i) minutiae extracted automatically from fingerprint\nimages, and (ii) minutiae extracted manually by human subjects. By doing so, we\nare able to (i) quantitatively judge the performance differences between these\ntwo cases, (ii) elaborate on performance upper bounds of minutiae matching,\nutilizing what can be termed as \"ground truth\" minutiae features, (iii) analyze\nminutiae matching performance, without coupling it with the minutiae extraction\nperformance beforehand. Further, as we will freely distribute the minutiae\ntemplates, originating from this manual labeling study, in a standard minutiae\ntemplate exchange format (ISO 19794-2), we believe that other researchers in\nthe biometrics community will be able to utilize the associated results &\ntemplates to create their own evaluations pertaining to their fingerprint\nminutiae extractors/matchers.", 
    "link": "http://arxiv.org/pdf/1305.1443v2", 
    "arxiv-id": "1305.1443v2"
},{
    "category": "cs.CV", 
    "author": "C\u00e9line Remi", 
    "title": "A Method for Visuo-Spatial Classification of Freehand Shapes Freely   Sketched", 
    "publish": "2013-05-07T14:02:46Z", 
    "summary": "We present the principle and the main steps of a new method for the\nvisuo-spatial analysis of geometrical sketches recorded online. Visuo-spatial\nanalysis is a necessary step for multi-level analysis. Multi-level analysis\nsimultaneously allows classification, comparison or clustering of the\nconstituent parts of a pattern according to their visuo-spatial properties,\ntheir procedural strategies, their structural or temporal parameters, or any\ncombination of two or more of those parameters. The first results provided by\nthis method concern the comparison of sketches to some perfect patterns of\nsimple geometrical figures and the measure of dissimilarity between real\nsketches. The mean rates of good decision higher than 95% obtained are\npromising in both cases.", 
    "link": "http://arxiv.org/pdf/1305.1520v1", 
    "arxiv-id": "1305.1520v1"
},{
    "category": "cs.CV", 
    "author": "Yen-Hsi Richard Tsai", 
    "title": "Automated polyp detection in colon capsule endoscopy", 
    "publish": "2013-05-08T18:33:28Z", 
    "summary": "Colorectal polyps are important precursors to colon cancer, a major health\nproblem. Colon capsule endoscopy (CCE) is a safe and minimally invasive\nexamination procedure, in which the images of the intestine are obtained via\ndigital cameras on board of a small capsule ingested by a patient. The video\nsequence is then analyzed for the presence of polyps. We propose an algorithm\nthat relieves the labor of a human operator analyzing the frames in the video\nsequence. The algorithm acts as a binary classifier, which labels the frame as\neither containing polyps or not, based on the geometrical analysis and the\ntexture content of the frame. The geometrical analysis is based on a\nsegmentation of an image with the help of a mid-pass filter. The features\nextracted by the segmentation procedure are classified according to an\nassumption that the polyps are characterized as protrusions that are mostly\nround in shape. Thus, we use a best fit ball radius as a decision parameter of\na binary classifier. We present a statistical study of the performance of our\napproach on a data set containing over 18,900 frames from the endoscopic video\nsequences of five adult patients. The algorithm demonstrates a solid\nperformance, achieving 47% sensitivity per frame and over 81% sensitivity per\npolyp at a specificity level of 90%. On average, with a video sequence length\nof 3747 frames, only 367 false positive frames need to be inspected by a human\noperator.", 
    "link": "http://arxiv.org/pdf/1305.1912v4", 
    "arxiv-id": "1305.1912v4"
},{
    "category": "cs.CV", 
    "author": "Hamid Amiri", 
    "title": "Repairing and Inpainting Damaged Images using Diffusion Tensor", 
    "publish": "2013-05-09T22:10:36Z", 
    "summary": "Removing or repairing the imperfections of a digital images or videos is a\nvery active and attractive field of research belonging to the image inpainting\ntechnique. This later has a wide range of applications, such as removing\nscratches in old photographic image, removing text and logos or creating\ncartoon and artistic effects. In this paper, we propose an efficient method to\nrepair a damaged image based on a non linear diffusion tensor. The idea is to\ntrack perfectly the local geometry of the damaged image and allowing diffusion\nonly in the isophotes curves direction. To illustrate the effective performance\nof our method, we present some experimental results on test and real\nphotographic color images", 
    "link": "http://arxiv.org/pdf/1305.2221v1", 
    "arxiv-id": "1305.2221v1"
},{
    "category": "cs.CV", 
    "author": "Yi Li", 
    "title": "Beyond Physical Connections: Tree Models in Human Pose Estimation", 
    "publish": "2013-05-10T07:09:14Z", 
    "summary": "Simple tree models for articulated objects prevails in the last decade.\nHowever, it is also believed that these simple tree models are not capable of\ncapturing large variations in many scenarios, such as human pose estimation.\nThis paper attempts to address three questions: 1) are simple tree models\nsufficient? more specifically, 2) how to use tree models effectively in human\npose estimation? and 3) how shall we use combined parts together with single\nparts efficiently?\n  Assuming we have a set of single parts and combined parts, and the goal is to\nestimate a joint distribution of their locations. We surprisingly find that no\nlatent variables are introduced in the Leeds Sport Dataset (LSP) during\nlearning latent trees for deformable model, which aims at approximating the\njoint distributions of body part locations using minimal tree structure. This\nsuggests one can straightforwardly use a mixed representation of single and\ncombined parts to approximate their joint distribution in a simple tree model.\nAs such, one only needs to build Visual Categories of the combined parts, and\nthen perform inference on the learned latent tree. Our method outperformed the\nstate of the art on the LSP, both in the scenarios when the training images are\nfrom the same dataset and from the PARSE dataset. Experiments on animal images\nfrom the VOC challenge further support our findings.", 
    "link": "http://arxiv.org/pdf/1305.2269v1", 
    "arxiv-id": "1305.2269v1"
},{
    "category": "cs.CV", 
    "author": "Herman De Haan", 
    "title": "Shape Reconstruction and Recognition with Isolated Non-directional Cues", 
    "publish": "2013-05-10T17:35:02Z", 
    "summary": "The paper investigates a hypothesis that our visual system groups visual cues\nbased on how they form a surface, or more specifically triangulation derived\nfrom the visual cues. To test our hypothesis, we compare shape recognition with\nthree different representations of visual cues: a set of isolated dots\ndelineating the outline of the shape, a set of triangles obtained from Delaunay\ntriangulation of the set of dots, and a subset of Delaunay triangles excluding\nthose outside of the shape. Each participant was assigned to one particular\nrepresentation type and increased the number of dots (and consequentially\ntriangles) until the underlying shape could be identified. We compare the\naverage number of dots needed for identification among three types of\nrepresentations. Our hypothesis predicts that the results from the three\nrepresentations will be similar. However, they show statistically significant\ndifferences. The paper also presents triangulation based algorithms for\nreconstruction and recognition of a shape from a set of isolated dots.\nExperiments showed that the algorithms were more effective and perceptually\nagreeable than similar contour based ones. From these experiments, we conclude\nthat triangulation does affect our shape recognition. However, the surface\nbased approach presents a number of computational advantages over the contour\nbased one and should be studied further.", 
    "link": "http://arxiv.org/pdf/1305.2395v1", 
    "arxiv-id": "1305.2395v1"
},{
    "category": "cs.CV", 
    "author": "Fran\u00e7ois Bremond", 
    "title": "Automatic Parameter Adaptation for Multi-object Tracking", 
    "publish": "2013-05-13T07:14:07Z", 
    "summary": "Object tracking quality usually depends on video context (e.g. object\nocclusion level, object density). In order to decrease this dependency, this\npaper presents a learning approach to adapt the tracker parameters to the\ncontext variations. In an offline phase, satisfactory tracking parameters are\nlearned for video context clusters. In the online control phase, once a context\nchange is detected, the tracking parameters are tuned using the learned values.\nThe experimental results show that the proposed approach outperforms the recent\ntrackers in state of the art. This paper brings two contributions: (1) a\nclassification method of video sequences to learn offline tracking parameters,\n(2) a new method to tune online tracking parameters using tracking context.", 
    "link": "http://arxiv.org/pdf/1305.2687v1", 
    "arxiv-id": "1305.2687v1"
},{
    "category": "cs.CV", 
    "author": "Urmila Shrawankar", 
    "title": "Human Mood Detection For Human Computer Interaction", 
    "publish": "2013-05-10T08:58:01Z", 
    "summary": "In this paper we propose an easiest approach for facial expression\nrecognition. Here we are using concept of SVM for Expression Classification.\nMain problem is sub divided in three main modules. First one is Face detection\nin which we are using skin filter and Face segmentation. We are given more\nstress on feature Extraction. This method is effective enough for application\nwhere fast execution is required. Second, Facial Feature Extraction which is\nessential part for expression recognition. In this module we used Edge\nProjection Analysis. Finally extracted features vector is passed towards SVM\nclassifier for Expression Recognition. We are considering six basic Expressions\n(Anger, Fear, Disgust, Joy, Sadness, and Surprise)", 
    "link": "http://arxiv.org/pdf/1305.2827v1", 
    "arxiv-id": "1305.2827v1"
},{
    "category": "cs.CV", 
    "author": "Urmila Shrawankar", 
    "title": "Image Optimization and Prediction", 
    "publish": "2013-05-10T08:43:59Z", 
    "summary": "Image Processing, Optimization and Prediction of an Image play a key role in\nComputer Science. Image processing provides a way to analyze and identify an\nimage .Many areas like medical image processing, Satellite images, natural\nimages and artificial images requires lots of analysis and research on\noptimization. In Image Optimization and Prediction we are combining the\nfeatures of Query Optimization, Image Processing and Prediction . Image\noptimization is used in Pattern analysis, object recognition, in medical Image\nprocessing to predict the type of diseases, in satellite images for predicting\nweather forecast, availability of water or mineral etc. Image Processing,\nOptimization and analysis is a wide open area for research .Lots of research\nhas been conducted in the area of Image analysis and many techniques are\navailable for image analysis but, a single technique is not yet identified for\nimage analysis and prediction .our research is focused on identifying a global\ntechnique for image analysis and Prediction.", 
    "link": "http://arxiv.org/pdf/1305.2828v1", 
    "arxiv-id": "1305.2828v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed Cheriet", 
    "title": "Unsupervised ensemble of experts (EoE) framework for automatic   binarization of document images", 
    "publish": "2013-05-13T20:37:29Z", 
    "summary": "In recent years, a large number of binarization methods have been developed,\nwith varying performance generalization and strength against different\nbenchmarks. In this work, to leverage on these methods, an ensemble of experts\n(EoE) framework is introduced, to efficiently combine the outputs of various\nmethods. The proposed framework offers a new selection process of the\nbinarization methods, which are actually the experts in the ensemble, by\nintroducing three concepts: confidentness, endorsement and schools of experts.\nThe framework, which is highly objective, is built based on two general\nprinciples: (i) consolidation of saturated opinions and (ii) identification of\nschools of experts. After building the endorsement graph of the ensemble for an\ninput document image based on the confidentness of the experts, the saturated\nopinions are consolidated, and then the schools of experts are identified by\nthresholding the consolidated endorsement graph. A variation of the framework,\nin which no selection is made, is also introduced that combines the outputs of\nall experts using endorsement-dependent weights. The EoE framework is evaluated\non the set of participating methods in the H-DIBCO'12 contest and also on an\nensemble generated from various instances of grid-based Sauvola method with\npromising performance.", 
    "link": "http://arxiv.org/pdf/1305.2949v2", 
    "arxiv-id": "1305.2949v2"
},{
    "category": "cs.CV", 
    "author": "Li-Zhi Cheng", 
    "title": "Novel variational model for inpainting in the wavelet domain", 
    "publish": "2013-05-14T03:45:09Z", 
    "summary": "Wavelet domain inpainting refers to the process of recovering the missing\ncoefficients during the image compression or transmission stage. Recently, an\nefficient algorithm framework which is called Bregmanized operator splitting\n(BOS) was proposed for solving the classical variational model of wavelet\ninpainting. However, it is still time-consuming to some extent due to the inner\niteration. In this paper, a novel variational model is established to formulate\nthis reconstruction problem from the view of image decomposition. Then an\nefficient iterative algorithm based on the split-Bregman method is adopted to\ncalculate an optimal solution, and it is also proved to be convergent. Compared\nwith the BOS algorithm the proposed algorithm avoids the inner iteration and\nhence is more simple. Numerical experiments demonstrate that the proposed\nmethod is very efficient and outperforms the current state-of-the-art methods,\nespecially in the computational time.", 
    "link": "http://arxiv.org/pdf/1305.3013v1", 
    "arxiv-id": "1305.3013v1"
},{
    "category": "cs.CV", 
    "author": "Pascal Blais", 
    "title": "A Bag of Words Approach for Semantic Segmentation of Monitored Scenes", 
    "publish": "2013-05-14T15:58:38Z", 
    "summary": "This paper proposes a semantic segmentation method for outdoor scenes\ncaptured by a surveillance camera. Our algorithm classifies each perceptually\nhomogenous region as one of the predefined classes learned from a collection of\nmanually labelled images. The proposed approach combines two different types of\ninformation. First, color segmentation is performed to divide the scene into\nperceptually similar regions. Then, the second step is based on SIFT keypoints\nand uses the bag of words representation of the regions for the classification.\nThe prediction is done using a Na\\\"ive Bayesian Network as a generative\nclassifier. Compared to existing techniques, our method provides more compact\nrepresentations of scene contents and the segmentation result is more\nconsistent with human perception due to the combination of the color\ninformation with the image keypoints. The experiments conducted on a publicly\navailable data set demonstrate the validity of the proposed method.", 
    "link": "http://arxiv.org/pdf/1305.3189v1", 
    "arxiv-id": "1305.3189v1"
},{
    "category": "cs.CV", 
    "author": "Christopher W. Clark", 
    "title": "Bioacoustical Periodic Pulse Train Signal Detection and Classification   using Spectrogram Intensity Binarization and Energy Projection", 
    "publish": "2013-05-14T18:49:52Z", 
    "summary": "The following work outlines an approach for automatic detection and\nrecognition of periodic pulse train signals using a multi-stage process based\non spectrogram edge detection, energy projection and classification. The method\nhas been implemented to automatically detect and recognize pulse train songs of\nminke whales. While the long term goal of this work is to properly identify and\ndetect minke songs from large multi-year datasets, this effort was developed\nusing sounds off the coast of Massachusetts, in the Stellwagen Bank National\nMarine Sanctuary. The detection methodology is presented and evaluated on 232\ncontinuous hours of acoustic recordings and a qualitative analysis of machine\nlearning classifiers and their performance is described. The trained automatic\ndetection and classification system is applied to 120 continuous hours,\ncomprised of various challenges such as broadband and narrowband noises, low\nSNR, and other pulse train signatures. This automatic system achieves a TPR of\n63% for FPR of 0.6% (or 0.87 FP/h), at a Precision (PPV) of 84% and an F1 score\nof 71%.", 
    "link": "http://arxiv.org/pdf/1305.3250v3", 
    "arxiv-id": "1305.3250v3"
},{
    "category": "cs.CV", 
    "author": "Christopher Clark", 
    "title": "Classification for Big Dataset of Bioacoustic Signals Based on Human   Scoring System and Artificial Neural Network", 
    "publish": "2013-05-15T20:53:39Z", 
    "summary": "In this paper, we propose a method to improve sound classification\nperformance by combining signal features, derived from the time-frequency\nspectrogram, with human perception. The method presented herein exploits an\nartificial neural network (ANN) and learns the signal features based on the\nhuman perception knowledge. The proposed method is applied to a large acoustic\ndataset containing 24 months of nearly continuous recordings. The results show\na significant improvement in performance of the detection-classification\nsystem; yielding as much as 20% improvement in true positive rate for a given\nfalse positive rate.", 
    "link": "http://arxiv.org/pdf/1305.3633v2", 
    "arxiv-id": "1305.3633v2"
},{
    "category": "cs.CV", 
    "author": "Christopher Clark", 
    "title": "Bioacoustic Signal Classification Based on Continuous Region Processing,   Grid Masking and Artificial Neural Network", 
    "publish": "2013-05-15T20:59:03Z", 
    "summary": "In this paper, we develop a novel method based on machine-learning and image\nprocessing to identify North Atlantic right whale (NARW) up-calls in the\npresence of high levels of ambient and interfering noise. We apply a continuous\nregion algorithm on the spectrogram to extract the regions of interest, and\nthen use grid masking techniques to generate a small feature set that is then\nused in an artificial neural network classifier to identify the NARW up-calls.\nIt is shown that the proposed technique is effective in detecting and capturing\neven very faint up-calls, in the presence of ambient and interfering noises.\nThe method is evaluated on a dataset recorded in Massachusetts Bay, United\nStates. The dataset includes 20000 sound clips for training, and 10000 sound\nclips for testing. The results show that the proposed technique can achieve an\nerror rate of less than FPR = 4.5% for a 90% true positive rate.", 
    "link": "http://arxiv.org/pdf/1305.3635v2", 
    "arxiv-id": "1305.3635v2"
},{
    "category": "cs.CV", 
    "author": "R. Tchinda", 
    "title": "Analysis Of Interest Points Of Curvelet Coefficients Contributions Of   Microscopic Images And Improvement Of Edges", 
    "publish": "2013-05-16T21:25:54Z", 
    "summary": "This paper focuses on improved edge model based on Curvelet coefficients\nanalysis. Curvelet transform is a powerful tool for multiresolution\nrepresentation of object with anisotropic edge. Curvelet coefficients\ncontributions have been analyzed using Scale Invariant Feature Transform\n(SIFT), commonly used to study local structure in images. The permutation of\nCurvelet coefficients from original image and edges image obtained from\ngradient operator is used to improve original edges. Experimental results show\nthat this method brings out details on edges when the decomposition scale\nincreases.", 
    "link": "http://arxiv.org/pdf/1305.3939v1", 
    "arxiv-id": "1305.3939v1"
},{
    "category": "cs.CV", 
    "author": "Syed Muhammad Arsalan Bashir", 
    "title": "Font Acknowledgment and Character Extraction of Digital and Scanned   Images", 
    "publish": "2013-05-17T13:05:31Z", 
    "summary": "The font recognition and character extraction is of immense importance as\nthese are many scenarios where data are in such a form, which cannot be\nprocessed like in image form or as a hard copy. So the procedure developed in\nthis paper is basically related to identifying the font (Times New Roman, Arial\nand Comic Sans MS) and afterwards recovering the text using simple correlation\nbased method where the binary templates are correlated to the input image text\ncharacters. All of this extraction is done in the presence of a little noise as\nimages may have noisy patterns due to photocopying. The significance of this\nmethod exists in extraction of data from various monitoring (Surveillance)\ncamera footages or even more. The method is developed on Matlab\\c{opyright}\nwhich takes input image and recovers text and font information from it in a\ntext file.", 
    "link": "http://arxiv.org/pdf/1305.4064v1", 
    "arxiv-id": "1305.4064v1"
},{
    "category": "cs.CV", 
    "author": "Joseph P. Noonan", 
    "title": "Blockwise SURE Shrinkage for Non-Local Means", 
    "publish": "2013-05-18T20:45:40Z", 
    "summary": "In this letter, we investigate the shrinkage problem for the non-local means\n(NLM) image denoising. In particular, we derive the closed-form of the optimal\nblockwise shrinkage for NLM that minimizes the Stein's unbiased risk estimator\n(SURE). We also propose a constant complexity algorithm allowing fast blockwise\nshrinkage. Simulation results show that the proposed blockwise shrinkage method\nimproves NLM performance in attaining higher peak signal noise ratio (PSNR) and\nstructural similarity index (SSIM), and makes NLM more robust against parameter\nchanges. Similar ideas can be applicable to other patchwise image denoising\ntechniques.", 
    "link": "http://arxiv.org/pdf/1305.4298v1", 
    "arxiv-id": "1305.4298v1"
},{
    "category": "cs.CV", 
    "author": "Robert Forchheimer", 
    "title": "Object Detection with Pixel Intensity Comparisons Organized in Decision   Trees", 
    "publish": "2013-05-20T14:35:47Z", 
    "summary": "We describe a method for visual object detection based on an ensemble of\noptimized decision trees organized in a cascade of rejectors. The trees use\npixel intensity comparisons in their internal nodes and this makes them able to\nprocess image regions very fast. Experimental analysis is provided through a\nface detection problem. The obtained results are encouraging and demonstrate\nthat the method has practical value. Additionally, we analyse its sensitivity\nto noise and show how to perform fast rotation invariant object detection.\nComplete source code is provided at https://github.com/nenadmarkus/pico.", 
    "link": "http://arxiv.org/pdf/1305.4537v5", 
    "arxiv-id": "1305.4537v5"
},{
    "category": "cs.CV", 
    "author": "Shanmuganathan Raman", 
    "title": "Efficient Image Retargeting for High Dynamic Range Scenes", 
    "publish": "2013-05-20T14:54:56Z", 
    "summary": "Most of the real world scenes have a very high dynamic range (HDR). The\nmobile phone cameras and the digital cameras available in markets are limited\nin their capability in both the range and spatial resolution. Same argument can\nbe posed about the limited dynamic range display devices which also differ in\nthe spatial resolution and aspect ratios.\n  In this paper, we address the problem of displaying the high contrast low\ndynamic range (LDR) image of a HDR scene in a display device which has\ndifferent spatial resolution compared to that of the capturing digital camera.\nThe optimal solution proposed in this work can be employed with any camera\nwhich has the ability to shoot multiple differently exposed images of a scene.\nFurther, the proposed solutions provide the flexibility in the depiction of\nentire contrast of the HDR scene as a LDR image with an user specified spatial\nresolution. This task is achieved through an optimized content aware\nretargeting framework which preserves salient features along with the algorithm\nto combine multi-exposure images. We show the proposed approach performs\nexceedingly well in the generation of high contrast LDR image of varying\nspatial resolution compared to an alternate approach.", 
    "link": "http://arxiv.org/pdf/1305.4544v1", 
    "arxiv-id": "1305.4544v1"
},{
    "category": "cs.CV", 
    "author": "Yonghong Guan", 
    "title": "A novel automatic thresholding segmentation method with local adaptive   thresholds", 
    "publish": "2013-05-22T15:00:43Z", 
    "summary": "A novel method for segmenting bright objects from dark background for\ngrayscale image is proposed. The concept of this method can be stated simply\nas: to pick out the local-thinnest bands on the grayscale grade-map. It turns\nout to be a threshold-based method with local adaptive thresholds, where each\nlocal threshold is determined by requiring the average normal-direction\ngradient on the object boundary to be local minimal. The method is highly\nautomatic and the segmentation mimics a man's natural expectation even the\nobject boundaries are fuzzy.", 
    "link": "http://arxiv.org/pdf/1305.5160v1", 
    "arxiv-id": "1305.5160v1"
},{
    "category": "cs.CV", 
    "author": "Wafaa Kamel Al-Jibory", 
    "title": "Edge Detection in Radar Images Using Weibull Distribution", 
    "publish": "2013-05-24T13:39:18Z", 
    "summary": "Radar images can reveal information about the shape of the surface terrain as\nwell as its physical and biophysical properties. Radar images have long been\nused in geological studies to map structural features that are revealed by the\nshape of the landscape. Radar imagery also has applications in vegetation and\ncrop type mapping, landscape ecology, hydrology, and volcanology. Image\nprocessing is using for detecting for objects in radar images. Edge detection;\nwhich is a method of determining the discontinuities in gray level images; is a\nvery important initial step in Image processing. Many classical edge detectors\nhave been developed over time. Some of the well-known edge detection operators\nbased on the first derivative of the image are Roberts, Prewitt, Sobel which is\ntraditionally implemented by convolving the image with masks. Also Gaussian\ndistribution has been used to build masks for the first and second derivative.\nHowever, this distribution has limit to only symmetric shape. This paper will\nuse to construct the masks, the Weibull distribution which was more general\nthan Gaussian because it has symmetric and asymmetric shape. The constructed\nmasks are applied to images and we obtained good results.", 
    "link": "http://arxiv.org/pdf/1305.5728v1", 
    "arxiv-id": "1305.5728v1"
},{
    "category": "cs.CV", 
    "author": "Fernand Meyer", 
    "title": "Flooding edge or node weighted graphs", 
    "publish": "2013-05-24T14:47:40Z", 
    "summary": "Reconstruction closings have all properties of a physical flooding of a\ntopographic surface. They are precious for simplifying gradient images or,\nfilling unwanted catchment basins, on which a subsequent watershed transform\nextracts the targeted objects. Flooding a topographic surface may be modeled as\nflooding a node weighted graph (TG), with unweighted edges, the node weights\nrepresenting the ground level. The progression of a flooding may also be\nmodeled on the region adjacency graph (RAG) of a topographic surface. On a RAG\neach node represents a catchment basin and edges connect neighboring nodes. The\nedges are weighted by the altitude of the pass point between both adjacent\nregions. The graph is flooded from sources placed at the marker positions and\neach node is assigned to the source by which it has been flooded. The level of\nthe flood is represented on the nodes on each type of graphs. The same flooding\nmay thus be modeled on a TG or on a RAG. We characterize all valid floodings on\nboth types of graphs, as they should verify the laws of hydrostatics. We then\nshow that each flooding of a node weighted graph also is a flooding of an edge\nweighted graph with appropriate edge weights. The highest flooding under a\nceiling function may be interpreted as the shortest distance to the root for\nthe ultrametric flooding distance in an augmented graph. The ultrametric\ndistance between two nodes is the minimal altitude of a flooding for which both\nnodes are flooded. This remark permits to flood edge or node weighted graphs by\nusing shortest path algorithms. It appears that the collection of all lakes of\na RAG has the structure of a dendrogram, on which the highest flooding under a\nceiling function may be rapidly found.", 
    "link": "http://arxiv.org/pdf/1305.5756v1", 
    "arxiv-id": "1305.5756v1"
},{
    "category": "cs.CV", 
    "author": "Antonio J. Rodr\u00edguez S\u00e1nchez", 
    "title": "\u00d6AGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association   for Pattern Recognition", 
    "publish": "2013-05-25T09:30:49Z", 
    "summary": "In this editorial, the organizers summarize facts and background about the\nevent.", 
    "link": "http://arxiv.org/pdf/1305.5905v1", 
    "arxiv-id": "1305.5905v1"
},{
    "category": "cs.CV", 
    "author": "Christoph Schnoerr", 
    "title": "Higher-order Segmentation via Multicuts", 
    "publish": "2013-05-28T07:23:39Z", 
    "summary": "Multicuts enable to conveniently represent discrete graphical models for\nunsupervised and supervised image segmentation, in the case of local energy\nfunctions that exhibit symmetries. The basic Potts model and natural extensions\nthereof to higher-order models provide a prominent class of such objectives,\nthat cover a broad range of segmentation problems relevant to image analysis\nand computer vision. We exhibit a way to systematically take into account such\nhigher-order terms for computational inference. Furthermore, we present results\nof a comprehensive and competitive numerical evaluation of a variety of\ndedicated cutting-plane algorithms. Our approach enables the globally optimal\nevaluation of a significant subset of these models, without compromising\nruntime. Polynomially solvable relaxations are studied as well, along with\nadvanced rounding schemes for post-processing.", 
    "link": "http://arxiv.org/pdf/1305.6387v3", 
    "arxiv-id": "1305.6387v3"
},{
    "category": "cs.CV", 
    "author": "Guillermo Sapiro", 
    "title": "Video Human Segmentation using Fuzzy Object Models and its Application   to Body Pose Estimation of Toddlers for Behavior Studies", 
    "publish": "2013-05-29T19:46:19Z", 
    "summary": "Video object segmentation is a challenging problem due to the presence of\ndeformable, connected, and articulated objects, intra- and inter-object\nocclusions, object motion, and poor lighting. Some of these challenges call for\nobject models that can locate a desired object and separate it from its\nsurrounding background, even when both share similar colors and textures. In\nthis work, we extend a fuzzy object model, named cloud system model (CSM), to\nhandle video segmentation, and evaluate it for body pose estimation of toddlers\nat risk of autism. CSM has been successfully used to model the parts of the\nbrain (cerebrum, left and right brain hemispheres, and cerebellum) in order to\nautomatically locate and separate them from each other, the connected brain\nstem, and the background in 3D MR-images. In our case, the objects are\narticulated parts (2D projections) of the human body, which can deform, cause\nself-occlusions, and move along the video. The proposed CSM extension handles\narticulation by connecting the individual clouds, body parts, of the system\nusing a 2D stickman model. The stickman representation naturally allows us to\nextract 2D body pose measures of arm asymmetry patterns during unsupported gait\nof toddlers, a possible behavioral marker of autism. The results show that our\nmethod can provide insightful knowledge to assist the specialist's observations\nduring real in-clinic assessments.", 
    "link": "http://arxiv.org/pdf/1305.6918v1", 
    "arxiv-id": "1305.6918v1"
},{
    "category": "cs.CV", 
    "author": "David Zhang", 
    "title": "A Local Active Contour Model for Image Segmentation with Intensity   Inhomogeneity", 
    "publish": "2013-05-30T10:14:14Z", 
    "summary": "A novel locally statistical active contour model (ACM) for image segmentation\nin the presence of intensity inhomogeneity is presented in this paper. The\ninhomogeneous objects are modeled as Gaussian distributions of different means\nand variances, and a moving window is used to map the original image into\nanother domain, where the intensity distributions of inhomogeneous objects are\nstill Gaussian but are better separated. The means of the Gaussian\ndistributions in the transformed domain can be adaptively estimated by\nmultiplying a bias field with the original signal within the window. A\nstatistical energy functional is then defined for each local region, which\ncombines the bias field, the level set function, and the constant approximating\nthe true signal of the corresponding object. Experiments on both synthetic and\nreal images demonstrate the superiority of our proposed algorithm to\nstate-of-the-art and representative methods.", 
    "link": "http://arxiv.org/pdf/1305.7053v1", 
    "arxiv-id": "1305.7053v1"
},{
    "category": "cs.CV", 
    "author": "Paul Wilford", 
    "title": "Lensless Imaging by Compressive Sensing", 
    "publish": "2013-05-30T17:56:03Z", 
    "summary": "In this paper, we propose a lensless compressive imaging architecture. The\narchitecture consists of two components, an aperture assembly and a sensor. No\nlens is used. The aperture assembly consists of a two dimensional array of\naperture elements. The transmittance of each aperture element is independently\ncontrollable. The sensor is a single detection element. A compressive sensing\nmatrix is implemented by adjusting the transmittance of the individual aperture\nelements according to the values of the sensing matrix. The proposed\narchitecture is simple and reliable because no lens is used. The architecture\ncan be used for capturing images of visible and other spectra such as infrared,\nor millimeter waves, in surveillance applications for detecting anomalies or\nextracting features such as speed of moving objects. Multiple sensors may be\nused with a single aperture assembly to capture multi-view images\nsimultaneously. A prototype was built by using a LCD panel and a photoelectric\nsensor for capturing images of visible spectrum.", 
    "link": "http://arxiv.org/pdf/1305.7181v1", 
    "arxiv-id": "1305.7181v1"
},{
    "category": "cs.CV", 
    "author": "Feiyun Zhu", 
    "title": "Robust Hyperspectral Unmixing with Correntropy based Metric", 
    "publish": "2013-05-31T06:43:31Z", 
    "summary": "Hyperspectral unmixing is one of the crucial steps for many hyperspectral\napplications. The problem of hyperspectral unmixing has proven to be a\ndifficult task in unsupervised work settings where the endmembers and\nabundances are both unknown. What is more, this task becomes more challenging\nin the case that the spectral bands are degraded with noise. This paper\npresents a robust model for unsupervised hyperspectral unmixing. Specifically,\nour model is developed with the correntropy based metric where the non-negative\nconstraints on both endmembers and abundances are imposed to keep physical\nsignificance. In addition, a sparsity prior is explicitly formulated to\nconstrain the distribution of the abundances of each endmember. To solve our\nmodel, a half-quadratic optimization technique is developed to convert the\noriginal complex optimization problem into an iteratively re-weighted NMF with\nsparsity constraints. As a result, the optimization of our model can adaptively\nassign small weights to noisy bands and give more emphasis on noise-free bands.\nIn addition, with sparsity constraints, our model can naturally generate sparse\nabundances. Experiments on synthetic and real data demonstrate the\neffectiveness of our model in comparison to the related state-of-the-art\nunmixing models.", 
    "link": "http://arxiv.org/pdf/1305.7311v1", 
    "arxiv-id": "1305.7311v1"
},{
    "category": "cs.CV", 
    "author": "Firas A. Jassim", 
    "title": "Image Inpainting by Kriging Interpolation Technique", 
    "publish": "2013-06-01T19:16:43Z", 
    "summary": "Image inpainting is the art of predicting damaged regions of an image. The\nmanual way of image inpainting is a time consuming. Therefore, there must be an\nautomatic digital method for image inpainting that recovers the image from the\ndamaged regions. In this paper, a novel statistical image inpainting algorithm\nbased on Kriging interpolation technique was proposed. Kriging technique\nautomatically fills the damaged region in an image using the information\navailable from its surrounding regions in such away that it uses the spatial\ncorrelation structure of points inside the k-by-k block. Kriging has the\nability to face the challenge of keeping the structure and texture information\nas the size of damaged region heighten. Experimental results showed that,\nKriging has a high PSNR value when recovering a variety of test images from\nscratches and text as damaged regions.", 
    "link": "http://arxiv.org/pdf/1306.0139v1", 
    "arxiv-id": "1306.0139v1"
},{
    "category": "cs.CV", 
    "author": "Jordan Bates", 
    "title": "An Analysis of the Connections Between Layers of Deep Neural Networks", 
    "publish": "2013-06-01T21:37:25Z", 
    "summary": "We present an analysis of different techniques for selecting the connection\nbe- tween layers of deep neural networks. Traditional deep neural networks use\nran- dom connection tables between layers to keep the number of connections\nsmall and tune to different image features. This kind of connection performs\nadequately in supervised deep networks because their values are refined during\nthe training. On the other hand, in unsupervised learning, one cannot rely on\nback-propagation techniques to learn the connections between layers. In this\nwork, we tested four different techniques for connecting the first layer of the\nnetwork to the second layer on the CIFAR and SVHN datasets and showed that the\naccuracy can be im- proved up to 3% depending on the technique used. We also\nshowed that learning the connections based on the co-occurrences of the\nfeatures does not confer an advantage over a random connection table in small\nnetworks. This work is helpful to improve the efficiency of connections between\nthe layers of unsupervised deep neural networks.", 
    "link": "http://arxiv.org/pdf/1306.0152v1", 
    "arxiv-id": "1306.0152v1"
},{
    "category": "cs.CV", 
    "author": "Li Liu", 
    "title": "Distributed Bayesian inference for consistent labeling of tracked   objects in non-overlapping camera networks", 
    "publish": "2013-06-05T03:50:58Z", 
    "summary": "One of the fundamental requirements for visual surveillance using\nnon-overlapping camera networks is the correct labeling of tracked objects on\neach camera in a consistent way,in the sense that the captured tracklets, or\nobservations in this paper, of the same object at different cameras should be\nassigned with the same label. In this paper, we formulate this task as a\nBayesian inference problem and propose a distributed inference framework in\nwhich the posterior distribution of labeling variable corresponding to each\nobservation, conditioned on all history appearance and spatio-temporal evidence\nmade in the whole networks, is calculated based solely on local information\nprocessing on each camera and mutual information exchanging between neighboring\ncameras. In our framework, the number of objects presenting in the monitored\nregion, i.e. the sampling space of labeling variables, does not need to be\nspecified beforehand. Instead, it can be determined automatically on the fly.\nIn addition, we make no assumption about the appearance distribution of a\nsingle object, but use similarity scores between appearance pairs, given by\nadvanced object re-identification algorithm, as appearance likelihood for\ninference. This feature makes our method very flexible and competitive when\nobserving condition undergoes large changes across camera views. To cope with\nthe problem of missing detection, which is critical for distributed inference,\nwe consider an enlarged neighborhood of each camera during inference and use a\nmixture model to describe the higher order spatio-temporal constraints. The\nrobustness of the algorithm against missing detection is improved at the cost\nof slightly increased computation and communication burden at each camera node.\nFinally, we demonstrate the effectiveness of our method through experiments on\nan indoor Office Building dataset and an outdoor Campus Garden dataset.", 
    "link": "http://arxiv.org/pdf/1306.0974v1", 
    "arxiv-id": "1306.0974v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "Recognition of Indian Sign Language in Live Video", 
    "publish": "2013-06-06T05:40:06Z", 
    "summary": "Sign Language Recognition has emerged as one of the important area of\nresearch in Computer Vision. The difficulty faced by the researchers is that\nthe instances of signs vary with both motion and appearance. Thus, in this\npaper a novel approach for recognizing various alphabets of Indian Sign\nLanguage is proposed where continuous video sequences of the signs have been\nconsidered. The proposed system comprises of three stages: Preprocessing stage,\nFeature Extraction and Classification. Preprocessing stage includes skin\nfiltering, histogram matching. Eigen values and Eigen Vectors were considered\nfor feature extraction stage and finally Eigen value weighted Euclidean\ndistance is used to recognize the sign. It deals with bare hands, thus allowing\nthe user to interact with the system in natural way. We have considered 24\ndifferent alphabets in the video sequences and attained a success rate of\n96.25%.", 
    "link": "http://arxiv.org/pdf/1306.1301v1", 
    "arxiv-id": "1306.1301v1"
},{
    "category": "cs.CV", 
    "author": "Rajiv Kumar", 
    "title": "K-Algorithm A Modified Technique for Noise Removal in Handwritten   Documents", 
    "publish": "2013-06-06T16:30:57Z", 
    "summary": "OCR has been an active research area since last few decades. OCR performs the\nrecognition of the text in the scanned document image and converts it into\neditable form. The OCR process can have several stages like pre-processing,\nsegmentation, recognition and post processing. The pre-processing stage is a\ncrucial stage for the success of OCR, which mainly deals with noise removal. In\nthe present paper, a modified technique for noise removal named as K-Algorithm\nhas been proposed, which has two stages as filtering and binarization. The\nproposed technique shows improvised results in comparison to median filtering\ntechnique.", 
    "link": "http://arxiv.org/pdf/1306.1462v1", 
    "arxiv-id": "1306.1462v1"
},{
    "category": "cs.CV", 
    "author": "Xavier Maldague", 
    "title": "Infrared face recognition: a literature review", 
    "publish": "2013-06-07T03:57:53Z", 
    "summary": "Automatic face recognition (AFR) is an area with immense practical potential\nwhich includes a wide range of commercial and law enforcement applications, and\nit continues to be one of the most active research areas of computer vision.\nEven after over three decades of intense research, the state-of-the-art in AFR\ncontinues to improve, benefiting from advances in a range of different fields\nincluding image processing, pattern recognition, computer graphics and\nphysiology. However, systems based on visible spectrum images continue to face\nchallenges in the presence of illumination, pose and expression changes, as\nwell as facial disguises, all of which can significantly decrease their\naccuracy. Amongst various approaches which have been proposed in an attempt to\novercome these limitations, the use of infrared (IR) imaging has emerged as a\nparticularly promising research direction. This paper presents a comprehensive\nand timely review of the literature on this subject.", 
    "link": "http://arxiv.org/pdf/1306.1603v1", 
    "arxiv-id": "1306.1603v1"
},{
    "category": "cs.CV", 
    "author": "Xavier Maldague", 
    "title": "Vesselness features and the inverse compositional AAM for robust face   recognition using thermal IR", 
    "publish": "2013-06-07T05:03:16Z", 
    "summary": "Over the course of the last decade, infrared (IR) and particularly thermal IR\nimaging based face recognition has emerged as a promising complement to\nconventional, visible spectrum based approaches which continue to struggle when\napplied in the real world. While inherently insensitive to visible spectrum\nillumination changes, IR images introduce specific challenges of their own,\nmost notably sensitivity to factors which affect facial heat emission patterns,\ne.g. emotional state, ambient temperature, and alcohol intake. In addition,\nfacial expression and pose changes are more difficult to correct in IR images\nbecause they are less rich in high frequency detail which is an important cue\nfor fitting any deformable model. We describe a novel method which addresses\nthese challenges. To normalize for pose and facial expression changes we\ngenerate a synthetic frontal image of a face in a canonical, neutral facial\nexpression from an image of the face in an arbitrary pose and facial\nexpression. This is achieved by piecewise affine warping which follows active\nappearance model (AAM) fitting. This is the first publication which explores\nthe use of an AAM on thermal IR images; we propose a pre-processing step which\nenhances detail in thermal images, making AAM convergence faster and more\naccurate. To overcome the problem of thermal IR image sensitivity to the\npattern of facial temperature emissions we describe a representation based on\nreliable anatomical features. In contrast to previous approaches, our\nrepresentation is not binary; rather, our method accounts for the reliability\nof the extracted features. This makes the proposed representation much more\nrobust both to pose and scale changes. The effectiveness of the proposed\napproach is demonstrated on the largest public database of thermal IR images of\nfaces on which it achieved 100% identification, significantly outperforming\nprevious methods.", 
    "link": "http://arxiv.org/pdf/1306.1609v1", 
    "arxiv-id": "1306.1609v1"
},{
    "category": "cs.CV", 
    "author": "Ji Won Yoon", 
    "title": "Statistical Denoising for single molecule fluorescence microscopic   images", 
    "publish": "2013-06-07T05:39:48Z", 
    "summary": "Single molecule fluorescence microscopy is a powerful technique for\nuncovering detailed information about biological systems, both in vitro and in\nvivo. In such experiments, the inherently low signal to noise ratios mean that\naccurate algorithms to separate true signal and background noise are essential\nto generate meaningful results. To this end, we have developed a new and robust\nmethod to reduce noise in single molecule fluorescence images by using a\nGaussian Markov Random Field (GMRF) prior in a Bayesian framework. Two\ndifferent strategies are proposed to build the prior - an intrinsic GMRF, with\na stationary relationship between pixels and a heterogeneous intrinsic GMRF,\nwith a differently weighted relationship between pixels classified as molecules\nand background. Testing with synthetic and real experimental fluorescence\nimages demonstrates that the heterogeneous intrinsic GMRF is superior to other\nconventional de-noising approaches.", 
    "link": "http://arxiv.org/pdf/1306.1619v1", 
    "arxiv-id": "1306.1619v1"
},{
    "category": "cs.CV", 
    "author": "Xavier Maldague", 
    "title": "Illumination-invariant face recognition from a single image across   extreme pose using a dual dimension AAM ensemble in the thermal infrared   spectrum", 
    "publish": "2013-06-07T04:17:25Z", 
    "summary": "Over the course of the last decade, infrared (IR) and particularly thermal IR\nimaging based face recognition has emerged as a promising complement to\nconventional, visible spectrum based approaches which continue to struggle when\napplied in practice. While inherently insensitive to visible spectrum\nillumination changes, IR data introduces specific challenges of its own, most\nnotably sensitivity to factors which affect facial heat emission patterns, e.g.\nemotional state, ambient temperature, and alcohol intake. In addition, facial\nexpression and pose changes are more difficult to correct in IR images because\nthey are less rich in high frequency detail which is an important cue for\nfitting any deformable model. In this paper we describe a novel method which\naddresses these major challenges. Specifically, when comparing two thermal IR\nimages of faces, we mutually normalize their poses and facial expressions by\nusing an active appearance model (AAM) to generate synthetic images of the two\nfaces with a neutral facial expression and in the same view (the average of the\ntwo input views). This is achieved by piecewise affine warping which follows\nAAM fitting. A major contribution of our work is the use of an AAM ensemble in\nwhich each AAM is specialized to a particular range of poses and a particular\nregion of the thermal IR face space. Combined with the contributions from our\nprevious work which addressed the problem of reliable AAM fitting in the\nthermal IR spectrum, and the development of a person-specific representation\nrobust to transient changes in the pattern of facial temperature emissions, the\nproposed ensemble framework accurately matches faces across the full range of\nyaw from frontal to profile, even in the presence of scale variation (e.g. due\nto the varying distance of a subject from the camera).", 
    "link": "http://arxiv.org/pdf/1306.1822v1", 
    "arxiv-id": "1306.1822v1"
},{
    "category": "cs.CV", 
    "author": "Heitor S. Ramos", 
    "title": "Speckle Reduction with Adaptive Stack Filters", 
    "publish": "2013-06-08T08:21:06Z", 
    "summary": "Stack filters are a special case of non-linear filters. They have a good\nperformance for filtering images with different types of noise while preserving\nedges and details. A stack filter decomposes an input image into stacks of\nbinary images according to a set of thresholds. Each binary image is then\nfiltered by a Boolean function, which characterizes the filter. Adaptive stack\nfilters can be computed by training using a prototype (ideal) image and its\ncorrupted version, leading to optimized filters with respect to a loss\nfunction. In this work we propose the use of training with selected samples for\nthe estimation of the optimal Boolean function. We study the performance of\nadaptive stack filters when they are applied to speckled imagery, in particular\nto Synthetic Aperture Radar (SAR) images. This is done by evaluating the\nquality of the filtered images through the use of suitable image quality\nindexes and by measuring the classification accuracy of the resulting images.\nWe used SAR images as input, since they are affected by speckle noise that\nmakes classification a difficult task.", 
    "link": "http://arxiv.org/pdf/1306.1894v1", 
    "arxiv-id": "1306.1894v1"
},{
    "category": "cs.CV", 
    "author": "Ognjen Arandjelovic", 
    "title": "Discriminative extended canonical correlation analysis for pattern set   matching", 
    "publish": "2013-06-10T04:41:37Z", 
    "summary": "In this paper we address the problem of matching sets of vectors embedded in\nthe same input space. We propose an approach which is motivated by canonical\ncorrelation analysis (CCA), a statistical technique which has proven successful\nin a wide variety of pattern recognition problems. Like CCA when applied to the\nmatching of sets, our extended canonical correlation analysis (E-CCA) aims to\nextract the most similar modes of variability within two sets. Our first major\ncontribution is the formulation of a principled framework for robust inference\nof such modes from data in the presence of uncertainty associated with noise\nand sampling randomness. E-CCA retains the efficiency and closed form\ncomputability of CCA, but unlike it, does not possess free parameters which\ncannot be inferred directly from data (inherent data dimensionality, and the\nnumber of canonical correlations used for set similarity computation). Our\nsecond major contribution is to show that in contrast to CCA, E-CCA is readily\nadapted to match sets in a discriminative learning scheme which we call\ndiscriminative extended canonical correlation analysis (DE-CCA). Theoretical\ncontributions of this paper are followed by an empirical evaluation of its\npremises on the task of face recognition from sets of rasterized appearance\nimages. The results demonstrate that our approach, E-CCA, already outperforms\nboth CCA and its quasi-discriminative counterpart constrained CCA (C-CCA), for\nall values of their free parameters. An even greater improvement is achieved\nwith the discriminative variant, DE-CCA.", 
    "link": "http://arxiv.org/pdf/1306.2100v1", 
    "arxiv-id": "1306.2100v1"
},{
    "category": "cs.CV", 
    "author": "Ognjen Arandjelovic", 
    "title": "Discriminative k-means clustering", 
    "publish": "2013-06-10T04:59:05Z", 
    "summary": "The k-means algorithm is a partitional clustering method. Over 60 years old,\nit has been successfully used for a variety of problems. The popularity of\nk-means is in large part a consequence of its simplicity and efficiency. In\nthis paper we are inspired by these appealing properties of k-means in the\ndevelopment of a clustering algorithm which accepts the notion of \"positively\"\nand \"negatively\" labelled data. The goal is to discover the cluster structure\nof both positive and negative data in a manner which allows for the\ndiscrimination between the two sets. The usefulness of this idea is\ndemonstrated practically on the problem of face recognition, where the task of\nlearning the scope of a person's appearance should be done in a manner which\nallows this face to be differentiated from others.", 
    "link": "http://arxiv.org/pdf/1306.2102v1", 
    "arxiv-id": "1306.2102v1"
},{
    "category": "cs.CV", 
    "author": "M. Kharinov", 
    "title": "Image segmentation by optimal and hierarchical piecewise constant   approximations", 
    "publish": "2013-06-10T10:35:26Z", 
    "summary": "Piecewise constant image approximations of sequential number of segments or\nclusters of disconnected pixels are treated. The method of majorizing of\noptimal approximation sequence by hierarchical sequence of image approximations\nis proposed. A generalization for multidimensional case of color and\nmultispectral images is foreseen.", 
    "link": "http://arxiv.org/pdf/1306.2159v1", 
    "arxiv-id": "1306.2159v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "Hand Gesture Recognition Based on Karhunen-Loeve Transform", 
    "publish": "2013-06-11T18:03:06Z", 
    "summary": "In this paper, we have proposed a system based on K-L Transform to recognize\ndifferent hand gestures. The system consists of five steps: skin filtering,\npalm cropping, edge detection, feature extraction, and classification. Firstly\nthe hand is detected using skin filtering and palm cropping was performed to\nextract out only the palm portion of the hand. The extracted image was then\nprocessed using the Canny Edge Detection technique to extract the outline\nimages of palm. After palm extraction, the features of hand were extracted\nusing K-L Transform technique and finally the input gesture was recognized\nusing proper classifier. In our system, we have tested for 10 different hand\ngestures, and recognizing rate obtained was 96%. Hence we propose an easy\napproach to recognize different hand gestures.", 
    "link": "http://arxiv.org/pdf/1306.2599v1", 
    "arxiv-id": "1306.2599v1"
},{
    "category": "cs.CV", 
    "author": "Ronan Collobert", 
    "title": "Recurrent Convolutional Neural Networks for Scene Parsing", 
    "publish": "2013-06-12T11:56:57Z", 
    "summary": "Scene parsing is a technique that consist on giving a label to all pixels in\nan image according to the class they belong to. To ensure a good visual\ncoherence and a high class accuracy, it is essential for a scene parser to\ncapture image long range dependencies. In a feed-forward architecture, this can\nbe simply achieved by considering a sufficiently large input context patch,\naround each pixel to be labeled. We propose an approach consisting of a\nrecurrent convolutional neural network which allows us to consider a large\ninput context, while limiting the capacity of the model. Contrary to most\nstandard approaches, our method does not rely on any segmentation methods, nor\nany task-specific features. The system is trained in an end-to-end manner over\nraw pixels, and models complex spatial dependencies with low inference cost. As\nthe context size increases with the built-in recurrence, the system identifies\nand corrects its own errors. Our approach yields state-of-the-art performance\non both the Stanford Background Dataset and the SIFT Flow Dataset, while\nremaining very fast at test time.", 
    "link": "http://arxiv.org/pdf/1306.2795v1", 
    "arxiv-id": "1306.2795v1"
},{
    "category": "cs.CV", 
    "author": "Mostafa Sadeghi", 
    "title": "Optimization of Clustering for Clustering-based Image Denoising", 
    "publish": "2013-06-12T20:23:07Z", 
    "summary": "In this paper, the problem of de-noising of an image contaminated with\nadditive white Gaussian noise (AWGN) is studied. This subject has been\ncontinued to be an open problem in signal processing for more than 50 years. In\nthe present paper, we suggest a method based on global clustering of image\nconstructing blocks. Noting that the type of clustering plays an important role\nin clustering-based de-noising methods, we address two questions about the\nclustering. First, which parts of data should be considered for clustering?\nSecond, what data clustering method is suitable for de-noising? Clustering is\nexploited to learn an over complete dictionary. By obtaining sparse\ndecomposition of the noisy image blocks in terms of the dictionary atoms, the\nde-noised version is achieved. Experimental results show that our dictionary\nlearning framework outperforms traditional dictionary learning methods such as\nK-SVD.", 
    "link": "http://arxiv.org/pdf/1306.2967v3", 
    "arxiv-id": "1306.2967v3"
},{
    "category": "cs.CV", 
    "author": "Hiroyuki Yamamoto", 
    "title": "A Face-like Structure Detection on Planet and Satellite Surfaces using   Image Processing", 
    "publish": "2013-06-13T06:28:07Z", 
    "summary": "This paper demonstrates that face-like structures are everywhere, and can be\nde-tected automatically even with computers. Huge amount of satellite images of\nthe Earth, the Moon, the Mars are explored and many interesting face-like\nstructure are detected. Throughout this fact, we believe that science and\ntechnologies can alert people not to easily become an occultist.", 
    "link": "http://arxiv.org/pdf/1306.3032v1", 
    "arxiv-id": "1306.3032v1"
},{
    "category": "cs.CV", 
    "author": "Beatriz Marcotegui", 
    "title": "Segmentation et Interpr\u00e9tation de Nuages de Points pour la   Mod\u00e9lisation d'Environnements Urbains", 
    "publish": "2013-06-13T11:27:58Z", 
    "summary": "Dans cet article, nous pr\\'esentons une m\\'ethode pour la d\\'etection et la\nclassification d'artefacts au niveau du sol, comme phase de filtrage\npr\\'ealable \\`a la mod\\'elisation d'environnements urbains. La m\\'ethode de\nd\\'etection est r\\'ealis\\'ee sur l'image profondeur, une projection de nuage de\npoints sur un plan image o\\`u la valeur du pixel correspond \\`a la distance du\npoint au plan. En faisant l'hypoth\\`ese que les artefacts sont situ\\'es au sol,\nils sont d\\'etect\\'es par une transformation de chapeau haut de forme par\nremplissage de trous sur l'image de profondeur. Les composantes connexes ainsi\nobtenues, sont ensuite caract\\'eris\\'ees et une analyse des variables est\nutilis\\'ee pour la s\\'election des caract\\'eristiques les plus discriminantes.\nLes composantes connexes sont donc classifi\\'ees en quatre cat\\'egories\n(lampadaires, pi\\'etons, voitures et \"Reste\") \\`a l'aide d'un algorithme\nd'apprentissage supervis\\'e. La m\\'ethode a \\'et\\'e test\\'ee sur des nuages de\npoints de la ville de Paris, en montrant de bons r\\'esultats de d\\'etection et\nde classification dans l'ensemble de donn\\'ees.---In this article, we present a\nmethod for detection and classification of artifacts at the street level, in\norder to filter cloud point, facilitating the urban modeling process. Our\napproach exploits 3D information by using range image, a projection of 3D\npoints onto an image plane where the pixel intensity is a function of the\nmeasured distance between 3D points and the plane. By assuming that the\nartifacts are on the ground, they are detected using a Top-Hat of the hole\nfilling algorithm of range images. Then, several features are extracted from\nthe detected connected components and a stepwise forward variable/model\nselection by using the Wilk's Lambda criterion is performed. Afterward, CCs are\nclassified in four categories (lampposts, pedestrians, cars and others) by\nusing a supervised machine learning method. The proposed method was tested on\ncloud points of Paris, and have shown satisfactory results on the whole\ndataset.", 
    "link": "http://arxiv.org/pdf/1306.3084v1", 
    "arxiv-id": "1306.3084v1"
},{
    "category": "cs.CV", 
    "author": "Kim L. Boyer", 
    "title": "Feature Learning by Multidimensional Scaling and its Applications in   Object Recognition", 
    "publish": "2013-06-14T04:43:40Z", 
    "summary": "We present the MDS feature learning framework, in which multidimensional\nscaling (MDS) is applied on high-level pairwise image distances to learn\nfixed-length vector representations of images. The aspects of the images that\nare captured by the learned features, which we call MDS features, completely\ndepend on what kind of image distance measurement is employed. With properly\nselected semantics-sensitive image distances, the MDS features provide rich\nsemantic information about the images that is not captured by other feature\nextraction techniques. In our work, we introduce the iterated\nLevenberg-Marquardt algorithm for solving MDS, and study the MDS feature\nlearning with IMage Euclidean Distance (IMED) and Spatial Pyramid Matching\n(SPM) distance. We present experiments on both synthetic data and real images\n--- the publicly accessible UIUC car image dataset. The MDS features based on\nSPM distance achieve exceptional performance for the car recognition task.", 
    "link": "http://arxiv.org/pdf/1306.3294v1", 
    "arxiv-id": "1306.3294v1"
},{
    "category": "cs.CV", 
    "author": "Ognjen Arandjelovic", 
    "title": "Matching objects across the textured-smooth continuum", 
    "publish": "2013-06-14T05:52:58Z", 
    "summary": "The problem of 3D object recognition is of immense practical importance, with\nthe last decade witnessing a number of breakthroughs in the state of the art.\nMost of the previous work has focused on the matching of textured objects using\nlocal appearance descriptors extracted around salient image points. The\nrecently proposed bag of boundaries method was the first to address directly\nthe problem of matching smooth objects using boundary features. However, no\nprevious work has attempted to achieve a holistic treatment of the problem by\njointly using textural and shape features which is what we describe herein. Due\nto the complementarity of the two modalities, we fuse the corresponding\nmatching scores and learn their relative weighting in a data specific manner by\noptimizing discriminative performance on synthetically distorted data. For the\ntextural description of an object we adopt a representation in the form of a\nhistogram of SIFT based visual words. Similarly the apparent shape of an object\nis represented by a histogram of discretized features capturing local shape. On\na large public database of a diverse set of objects, the proposed method is\nshown to outperform significantly both purely textural and purely shape based\napproaches for matching across viewpoint variation.", 
    "link": "http://arxiv.org/pdf/1306.3297v1", 
    "arxiv-id": "1306.3297v1"
},{
    "category": "cs.CV", 
    "author": "Ognjen Arandjelovic", 
    "title": "Live-wire 3D medical images segmentation", 
    "publish": "2013-06-14T14:52:10Z", 
    "summary": "This report describes the design, implementation, evaluation and original\nenhancements to the Live-Wire method for 2D and 3D image segmentation.\nLive-Wire 2D employs a semi-automatic paradigm; the user is asked to select a\nfew boundary points of the object to segment, to steer the process in the right\ndirection, while the result is displayed in real time. In our implementation\nsegmentation is extended to three dimensions by performing this process on a\nslice-by-slice basis. User's time and involvement is further reduced by\nallowing him to specify object contours in planes orthogonal to the slices. If\nthese planes are chosen strategically, Live-Wire 3D can perform 2D segmentation\nin the plane of each slice automatically. This report also proposes two\nimprovements to the original method, path heating and a new graph edge feature\nfunction based on variance of path properties along the boundary. We show that\nthese improvements lead up to a 33% reduction in interaction with the user, and\nimproved delineation in presence of strong interfering edges.", 
    "link": "http://arxiv.org/pdf/1306.3415v1", 
    "arxiv-id": "1306.3415v1"
},{
    "category": "cs.CV", 
    "author": "Francesca Odone", 
    "title": "iCub World: Friendly Robots Help Building Good Vision Data-Sets", 
    "publish": "2013-06-15T09:27:17Z", 
    "summary": "In this paper we present and start analyzing the iCub World data-set, an\nobject recognition data-set, we acquired using a Human-Robot Interaction (HRI)\nscheme and the iCub humanoid robot platform. Our set up allows for rapid\nacquisition and annotation of data with corresponding ground truth. While more\nconstrained in its scopes -- the iCub world is essentially a robotics research\nlab -- we demonstrate how the proposed data-set poses challenges to current\nrecognition systems. The iCubWorld data-set is publicly available. The data-set\ncan be downloaded from: http://www.iit.it/en/projects/data-sets.html.", 
    "link": "http://arxiv.org/pdf/1306.3560v1", 
    "arxiv-id": "1306.3560v1"
},{
    "category": "cs.CV", 
    "author": "David Wipf", 
    "title": "Non-Uniform Blind Deblurring with a Spatially-Adaptive Sparse Prior", 
    "publish": "2013-06-17T12:12:22Z", 
    "summary": "Typical blur from camera shake often deviates from the standard uniform\nconvolutional script, in part because of problematic rotations which create\ngreater blurring away from some unknown center point. Consequently, successful\nblind deconvolution requires the estimation of a spatially-varying or\nnon-uniform blur operator. Using ideas from Bayesian inference and convex\nanalysis, this paper derives a non-uniform blind deblurring algorithm with\nseveral desirable, yet previously-unexplored attributes. The underlying\nobjective function includes a spatially adaptive penalty which couples the\nlatent sharp image, non-uniform blur operator, and noise level together. This\ncoupling allows the penalty to automatically adjust its shape based on the\nestimated degree of local blur and image structure such that regions with large\nblur or few prominent edges are discounted. Remaining regions with modest blur\nand revealing edges therefore dominate the overall estimation process without\nexplicitly incorporating structure-selection heuristics. The algorithm can be\nimplemented using a majorization-minimization strategy that is virtually\nparameter free. Detailed theoretical analysis and empirical validation on real\nimages serve to validate the proposed method.", 
    "link": "http://arxiv.org/pdf/1306.3828v1", 
    "arxiv-id": "1306.3828v1"
},{
    "category": "cs.CV", 
    "author": "Jiri Matas", 
    "title": "Two-View Matching with View Synthesis Revisited", 
    "publish": "2013-06-17T13:44:25Z", 
    "summary": "Wide-baseline matching focussing on problems with extreme viewpoint change is\nconsidered. We introduce the use of view synthesis with affine-covariant\ndetectors to solve such problems and show that matching with the Hessian-Affine\nor MSER detectors outperforms the state-of-the-art ASIFT.\n  To minimise the loss of speed caused by view synthesis, we propose the\nMatching On Demand with view Synthesis algorithm (MODS) that uses progressively\nmore synthesized images and more (time-consuming) detectors until reliable\nestimation of geometry is possible. We show experimentally that the MODS\nalgorithm solves problems beyond the state-of-the-art and yet is comparable in\nspeed to standard wide-baseline matchers on simpler problems.\n  Minor contributions include an improved method for tentative correspondence\nselection, applicable both with and without view synthesis and a view synthesis\nsetup greatly improving MSER robustness to blur and scale change that increase\nits running time by 10% only.", 
    "link": "http://arxiv.org/pdf/1306.3855v2", 
    "arxiv-id": "1306.3855v2"
},{
    "category": "cs.CV", 
    "author": "Xi Chen", 
    "title": "Classifying and Visualizing Motion Capture Sequences using Deep Neural   Networks", 
    "publish": "2013-06-17T14:26:52Z", 
    "summary": "The gesture recognition using motion capture data and depth sensors has\nrecently drawn more attention in vision recognition. Currently most systems\nonly classify dataset with a couple of dozens different actions. Moreover,\nfeature extraction from the data is often computational complex. In this paper,\nwe propose a novel system to recognize the actions from skeleton data with\nsimple, but effective, features using deep neural networks. Features are\nextracted for each frame based on the relative positions of joints (PO),\ntemporal differences (TD), and normalized trajectories of motion (NT). Given\nthese features a hybrid multi-layer perceptron is trained, which simultaneously\nclassifies and reconstructs input data. We use deep autoencoder to visualize\nlearnt features, and the experiments show that deep neural networks can capture\nmore discriminative information than, for instance, principal component\nanalysis can. We test our system on a public database with 65 classes and more\nthan 2,000 motion sequences. We obtain an accuracy above 95% which is, to our\nknowledge, the state of the art result for such a large dataset.", 
    "link": "http://arxiv.org/pdf/1306.3874v2", 
    "arxiv-id": "1306.3874v2"
},{
    "category": "cs.CV", 
    "author": "Zeng Jie", 
    "title": "A Novel Block-DCT and PCA Based Image Perceptual Hashing Algorithm", 
    "publish": "2013-06-18T06:58:58Z", 
    "summary": "Image perceptual hashing finds applications in content indexing, large-scale\nimage database management, certification and authentication and digital\nwatermarking. We propose a Block-DCT and PCA based image perceptual hash in\nthis article and explore the algorithm in the application of tamper detection.\nThe main idea of the algorithm is to integrate color histogram and DCT\ncoefficients of image blocks as perceptual feature, then to compress perceptual\nfeatures as inter-feature with PCA, and to threshold to create a robust hash.\nThe robustness and discrimination properties of the proposed algorithm are\nevaluated in detail. Our algorithms first construct a secondary image, derived\nfrom input image by pseudo-randomly extracting features that approximately\ncapture semi-global geometric characteristics. From the secondary image (which\ndoes not perceptually resemble the input), we further extract the final\nfeatures which can be used as a hash value (and can be further suitably\nquantized). In this paper, we use spectral matrix invariants as embodied by\nSingular Value Decomposition. Surprisingly, formation of the secondary image\nturns out be quite important since it not only introduces further robustness,\nbut also enhances the security properties. Indeed, our experiments reveal that\nour hashing algorithms extract most of the geometric information from the\nimages and hence are robust to severe perturbations (e.g. up to %50 cropping by\narea with 20 degree rotations) on images while avoiding misclassification.\nExperimental results show that the proposed image perceptual hash algorithm can\neffectively address the tamper detection problem with advantageous robustness\nand discrimination.", 
    "link": "http://arxiv.org/pdf/1306.4079v1", 
    "arxiv-id": "1306.4079v1"
},{
    "category": "cs.CV", 
    "author": "Jayshree Ghorpade", 
    "title": "An Overview of the Research on Texture Based Plant Leaf Classification", 
    "publish": "2013-06-18T20:38:07Z", 
    "summary": "Plant classification has a broad application prospective in agriculture and\nmedicine, and is especially significant to the biology diversity research. As\nplants are vitally important for environmental protection, it is more important\nto identify and classify them accurately. Plant leaf classification is a\ntechnique where leaf is classified based on its different morphological\nfeatures. The goal of this paper is to provide an overview of different aspects\nof texture based plant leaf classification and related things. At last we will\nbe concluding about the efficient method i.e. the method that gives better\nperformance compared to the other methods.", 
    "link": "http://arxiv.org/pdf/1306.4345v1", 
    "arxiv-id": "1306.4345v1"
},{
    "category": "cs.CV", 
    "author": "Jeffrey Mark Siskind", 
    "title": "Felzenszwalb-Baum-Welch: Event Detection by Changing Appearance", 
    "publish": "2013-06-20T03:22:19Z", 
    "summary": "We propose a method which can detect events in videos by modeling the change\nin appearance of the event participants over time. This method makes it\npossible to detect events which are characterized not by motion, but by the\nchanging state of the people or objects involved. This is accomplished by using\nobject detectors as output models for the states of a hidden Markov model\n(HMM). The method allows an HMM to model the sequence of poses of the event\nparticipants over time, and is effective for poses of humans and inanimate\nobjects. The ability to use existing object-detection methods as part of an\nevent model makes it possible to leverage ongoing work in the object-detection\ncommunity. A novel training method uses an EM loop to simultaneously learn the\ntemporal structure and object models automatically, without the need to specify\neither the individual poses to be modeled or the frames in which they occur.\nThe E-step estimates the latent assignment of video frames to HMM states, while\nthe M-step estimates both the HMM transition probabilities and state output\nmodels, including the object detectors, which are trained on the weighted\nsubset of frames assigned to their state. A new dataset was gathered because\nlittle work has been done on events characterized by changing object pose, and\nsuitable datasets are not available. Our method produced results superior to\nthat of comparison systems on this dataset.", 
    "link": "http://arxiv.org/pdf/1306.4746v1", 
    "arxiv-id": "1306.4746v1"
},{
    "category": "cs.CV", 
    "author": "Sinisa Car", 
    "title": "Computer Aided ECG Analysis - State of the Art and Upcoming Challenges", 
    "publish": "2013-06-21T11:09:18Z", 
    "summary": "In this paper we present current achievements in computer aided ECG analysis\nand their applicability in real world medical diagnosis process. Most of the\ncurrent work is covering problems of removing noise, detecting heartbeats and\nrhythm-based analysis. There are some advancements in particular ECG segments\ndetection and beat classifications but with limited evaluations and without\nclinical approvals. This paper presents state of the art advancements in those\nareas till present day. Besides this short computer science and signal\nprocessing literature review, paper covers future challenges regarding the ECG\nsignal morphology analysis deriving from the medical literature review. Paper\nis concluded with identified gaps in current advancements and testing, upcoming\nchallenges for future research and a bullseye test is suggested for morphology\nanalysis evaluation.", 
    "link": "http://arxiv.org/pdf/1306.5096v1", 
    "arxiv-id": "1306.5096v1"
},{
    "category": "cs.CV", 
    "author": "Andrea Vedaldi", 
    "title": "Fine-Grained Visual Classification of Aircraft", 
    "publish": "2013-06-21T14:31:57Z", 
    "summary": "This paper introduces FGVC-Aircraft, a new dataset containing 10,000 images\nof aircraft spanning 100 aircraft models, organised in a three-level hierarchy.\nAt the finer level, differences between models are often subtle but always\nvisually measurable, making visual recognition challenging but possible. A\nbenchmark is obtained by defining corresponding classification tasks and\nevaluation protocols, and baseline results are presented. The construction of\nthis dataset was made possible by the work of aircraft enthusiasts, a strategy\nthat can extend to the study of number of other object classes. Compared to the\ndomains usually considered in fine-grained visual classification (FGVC), for\nexample animals, aircraft are rigid and hence less deformable. They, however,\npresent other interesting modes of variation, including purpose, size,\ndesignation, structure, historical style, and branding.", 
    "link": "http://arxiv.org/pdf/1306.5151v1", 
    "arxiv-id": "1306.5151v1"
},{
    "category": "cs.CV", 
    "author": "K. Shilpa", 
    "title": "New Approach of Estimating PSNR-B For De-blocked Images", 
    "publish": "2013-06-22T06:12:26Z", 
    "summary": "Measurement of image quality is very crucial to many image processing\napplications. Quality metrics are used to measure the quality of improvement in\nthe images after they are processed and compared with the original images.\nCompression is one of the applications where it is required to monitor the\nquality of decompressed or decoded image. JPEG compression is the lossy\ncompression which is most prevalent technique for image codecs. But it suffers\nfrom blocking artifacts. Various deblocking filters are used to reduce blocking\nartifacts. The efficiency of deblocking filters which improves visual signals\ndegraded by blocking artifacts from compression will also be studied. Objective\nquality metrics like PSNR, SSIM, and PSNRB for analyzing the quality of\ndeblocked images will be studied. We introduce a new approach of PSNR-B for\nanalyzing quality of deblocked images. Simulation results show that new\napproach of PSNR-B called modified PSNR-B. it gives even better results\ncompared to existing well known blockiness specific indices", 
    "link": "http://arxiv.org/pdf/1306.5293v1", 
    "arxiv-id": "1306.5293v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed Cheriet", 
    "title": "A maximal-information color to gray conversion method for document   images: Toward an optimal grayscale representation for document image   binarization", 
    "publish": "2013-06-25T18:41:04Z", 
    "summary": "A novel method to convert color/multi-spectral images to gray-level images is\nintroduced to increase the performance of document binarization methods. The\nmethod uses the distribution of the pixel data of the input document image in a\ncolor space to find a transformation, called the dual transform, which balances\nthe amount of information on all color channels. Furthermore, in order to\nreduce the intensity variations on the gray output, a color reduction\npreprocessing step is applied. Then, a channel is selected as the gray value\nrepresentation of the document image based on the homogeneity criterion on the\ntext regions. In this way, the proposed method can provide a\nluminance-independent contrast enhancement. The performance of the method is\nevaluated against various images from two databases, the ICDAR'03 Robust\nReading, the KAIST and the DIBCO'09 datasets, subjectively and objectively with\npromising results. The ground truth images for the images from the ICDAR'03\nRobust Reading dataset have been created manually by the authors.", 
    "link": "http://arxiv.org/pdf/1306.6058v2", 
    "arxiv-id": "1306.6058v2"
},{
    "category": "cs.CV", 
    "author": "Hossein Ziaei Nafchi", 
    "title": "Persian Heritage Image Binarization Competition (PHIBC 2012)", 
    "publish": "2013-06-26T14:56:00Z", 
    "summary": "The first competition on the binarization of historical Persian documents and\nmanuscripts (PHIBC 2012) has been organized in conjunction with the first\nIranian conference on pattern recognition and image analysis (PRIA 2013). The\nmain objective of PHIBC 2012 is to evaluate performance of the binarization\nmethodologies, when applied on the Persian heritage images. This paper provides\na report on the methodology and performance of the three submitted algorithms\nbased on evaluation measures has been used.", 
    "link": "http://arxiv.org/pdf/1306.6263v2", 
    "arxiv-id": "1306.6263v2"
},{
    "category": "cs.CV", 
    "author": "Aditya Tatu", 
    "title": "Active Contour Models for Manifold Valued Image Segmentation", 
    "publish": "2013-06-26T15:16:54Z", 
    "summary": "Image segmentation is the process of partitioning a image into different\nregions or groups based on some characteristics like color, texture, motion or\nshape etc. Active contours is a popular variational method for object\nsegmentation in images, in which the user initializes a contour which evolves\nin order to optimize an objective function designed such that the desired\nobject boundary is the optimal solution. Recently, imaging modalities that\nproduce Manifold valued images have come up, for example, DT-MRI images, vector\nfields. The traditional active contour model does not work on such images. In\nthis paper, we generalize the active contour model to work on Manifold valued\nimages. As expected, our algorithm detects regions with similar Manifold values\nin the image. Our algorithm also produces expected results on usual gray-scale\nimages, since these are nothing but trivial examples of Manifold valued images.\nAs another application of our general active contour model, we perform texture\nsegmentation on gray-scale images by first creating an appropriate Manifold\nvalued image. We demonstrate segmentation results for manifold valued images\nand texture images.", 
    "link": "http://arxiv.org/pdf/1306.6269v2", 
    "arxiv-id": "1306.6269v2"
},{
    "category": "cs.CV", 
    "author": "Sumukh Bansal", 
    "title": "A Novel Active Contour Model for Texture Segmentation", 
    "publish": "2013-06-28T06:32:42Z", 
    "summary": "Texture is intuitively defined as a repeated arrangement of a basic pattern\nor object in an image. There is no mathematical definition of a texture though.\nThe human visual system is able to identify and segment different textures in a\ngiven image. Automating this task for a computer is far from trivial. There are\nthree major components of any texture segmentation algorithm: (a) The features\nused to represent a texture, (b) the metric induced on this representation\nspace and (c) the clustering algorithm that runs over these features in order\nto segment a given image into different textures. In this paper, we propose an\nactive contour based novel unsupervised algorithm for texture segmentation. We\nuse intensity covariance matrices of regions as the defining feature of\ntextures and find regions that have the most inter-region dissimilar covariance\nmatrices using active contours. Since covariance matrices are symmetric\npositive definite, we use geodesic distance defined on the manifold of\nsymmetric positive definite matrices PD(n) as a measure of dissimlarity between\nsuch matrices. We demonstrate performance of our algorithm on both artificial\nand real texture images.", 
    "link": "http://arxiv.org/pdf/1306.6726v1", 
    "arxiv-id": "1306.6726v1"
},{
    "category": "cs.CV", 
    "author": "Christopher Blackwell", 
    "title": "New Mathematical and Algorithmic Schemes for Pattern Classification with   Application to the Identification of Writers of Important Ancient Documents", 
    "publish": "2013-06-28T13:51:18Z", 
    "summary": "In this paper, a novel approach is introduced for classifying curves into\nproper families, according to their similarity. First, a mathematical quantity\nwe call plane curvature is introduced and a number of propositions are stated\nand proved. Proper similarity measures of two curves are introduced and a\nsubsequent statistical analysis is applied. First, the efficiency of the curve\nfitting process has been tested on 2 shapes datasets of reference. Next, the\nmethodology has been applied to the very important problem of classifying 23\nByzantine codices and 46 Ancient inscriptions to their writers, thus achieving\ncorrect dating of their content. The inscriptions have been attributed to ten\nindividual hands and the Byzantine codices to four writers.", 
    "link": "http://arxiv.org/pdf/1306.6842v1", 
    "arxiv-id": "1306.6842v1"
},{
    "category": "cs.CV", 
    "author": "Hassan Ghassemian", 
    "title": "Hyperspectral Data Unmixing Using GNMF Method and Sparseness Constraint", 
    "publish": "2013-06-29T16:57:44Z", 
    "summary": "Hyperspectral images contain mixed pixels due to low spatial resolution of\nhyperspectral sensors. Mixed pixels are pixels containing more than one\ndistinct material called endmembers. The presence percentages of endmembers in\nmixed pixels are called abundance fractions. Spectral unmixing problem refers\nto decomposing these pixels into a set of endmembers and abundance fractions.\nDue to nonnegativity constraint on abundance fractions, nonnegative matrix\nfactorization methods (NMF) have been widely used for solving spectral unmixing\nproblem. In this paper we have used graph regularized (GNMF) method with\nsparseness constraint to unmix hyperspectral data. This method applied on\nsimulated data using AVIRIS Indian Pines dataset and USGS library and results\nare quantified based on AAD and SAD measures. Results in comparison with other\nmethods show that the proposed method can unmix data more effectively.", 
    "link": "http://arxiv.org/pdf/1307.0129v1", 
    "arxiv-id": "1307.0129v1"
},{
    "category": "cs.CV", 
    "author": "Sheli Sinha Chaudhuri", 
    "title": "Multilevel Threshold Based Gray Scale Image Segmentation using Cuckoo   Search", 
    "publish": "2013-07-01T06:50:23Z", 
    "summary": "Image Segmentation is a technique of partitioning the original image into\nsome distinct classes. Many possible solutions may be available for segmenting\nan image into a certain number of classes, each one having different quality of\nsegmentation. In our proposed method, multilevel thresholding technique has\nbeen used for image segmentation. A new approach of Cuckoo Search (CS) is used\nfor selection of optimal threshold value. In other words, the algorithm is used\nto achieve the best solution from the initial random threshold values or\nsolutions and to evaluate the quality of a solution correlation function is\nused. Finally, MSE and PSNR are measured to understand the segmentation\nquality.", 
    "link": "http://arxiv.org/pdf/1307.0277v1", 
    "arxiv-id": "1307.0277v1"
},{
    "category": "cs.CV", 
    "author": "Pew-Thian Yap", 
    "title": "Regularized Spherical Polar Fourier Diffusion MRI with Optimal   Dictionary Learning", 
    "publish": "2013-07-02T17:47:32Z", 
    "summary": "Compressed Sensing (CS) takes advantage of signal sparsity or compressibility\nand allows superb signal reconstruction from relatively few measurements. Based\non CS theory, a suitable dictionary for sparse representation of the signal is\nrequired. In diffusion MRI (dMRI), CS methods were proposed to reconstruct\ndiffusion-weighted signal and the Ensemble Average Propagator (EAP), and there\nare two kinds of Dictionary Learning (DL) methods: 1) Discrete Representation\nDL (DR-DL), and 2) Continuous Representation DL (CR-DL). DR-DL is susceptible\nto numerical inaccuracy owing to interpolation and regridding errors in a\ndiscretized q-space. In this paper, we propose a novel CR-DL approach, called\nDictionary Learning - Spherical Polar Fourier Imaging (DL-SPFI) for effective\ncompressed-sensing reconstruction of the q-space diffusion-weighted signal and\nthe EAP. In DL-SPFI, an dictionary that sparsifies the signal is learned from\nthe space of continuous Gaussian diffusion signals. The learned dictionary is\nthen adaptively applied to different voxels using a weighted LASSO framework\nfor robust signal reconstruction. The adaptive dictionary is proved to be\noptimal. Compared with the start-of-the-art CR-DL and DR-DL methods proposed by\nMerlet et al. and Bilgic et al., espectively, our work offers the following\nadvantages. First, the learned dictionary is proved to be optimal for Gaussian\ndiffusion signals. Second, to our knowledge, this is the first work to learn a\nvoxel-adaptive dictionary. The importance of the adaptive dictionary in EAP\nreconstruction will be demonstrated theoretically and empirically. Third,\noptimization in DL-SPFI is only performed in a small subspace resided by the\nSPF coefficients, as opposed to the q-space approach utilized by Merlet et al.\nThe experiment results demonstrate the advantages of DL-SPFI over the original\nSPF basis and Bilgic et al.'s method.", 
    "link": "http://arxiv.org/pdf/1307.0776v1", 
    "arxiv-id": "1307.0776v1"
},{
    "category": "cs.CV", 
    "author": "Jalel Akaichi", 
    "title": "Extending UML for Conceptual Modeling of Annotation of Medical Images", 
    "publish": "2013-07-03T08:45:37Z", 
    "summary": "Imaging has occupied a huge role in the management of patients, whether\nhospitalized or not. Depending on the patients clinical problem, a variety of\nimaging modalities were available for use. This gave birth of the annotation of\nmedical image process. The annotation is intended to image analysis and solve\nthe problem of semantic gap. The reason for image annotation is due to increase\nin acquisition of images. Physicians and radiologists feel better while using\nannotation techniques for faster remedy in surgery and medicine due to the\nfollowing reasons: giving details to the patients, searching the present and\npast records from the larger databases, and giving solutions to them in a\nfaster and more accurate way. However, classical conceptual modeling does not\nincorporate the specificity of medical domain specially the annotation of\nmedical image. The design phase is the most important activity in the\nsuccessful building of annotation process. For this reason, we focus in this\npaper on presenting the conceptual modeling of the annotation of medical image\nby defining a new profile using the StarUML extensibility mechanism.", 
    "link": "http://arxiv.org/pdf/1307.0937v1", 
    "arxiv-id": "1307.0937v1"
},{
    "category": "cs.CV", 
    "author": "Z. Chen", 
    "title": "A Unified Framework of Elementary Geometric Transformation   Representation", 
    "publish": "2013-07-03T12:59:53Z", 
    "summary": "As an extension of projective homology, stereohomology is proposed via an\nextension of Desargues theorem and the extended Desargues configuration.\nGeometric transformations such as reflection, translation, central symmetry,\ncentral projection, parallel projection, shearing, central dilation, scaling,\nand so on are all included in stereohomology and represented as\nHouseholder-Chen elementary matrices. Hence all these geometric transformations\nare called elementary. This makes it possible to represent these elementary\ngeometric transformations in homogeneous square matrices independent of a\nparticular choice of coordinate system.", 
    "link": "http://arxiv.org/pdf/1307.0998v3", 
    "arxiv-id": "1307.0998v3"
},{
    "category": "cs.CV", 
    "author": "Toufiq Parag", 
    "title": "Submodularity of a Set Label Disagreement Function", 
    "publish": "2013-07-02T15:25:09Z", 
    "summary": "A set label disagreement function is defined over the number of variables\nthat deviates from the dominant label. The dominant label is the value assumed\nby the largest number of variables within a set of binary variables. The\nsubmodularity of a certain family of set label disagreement function is\ndiscussed in this manuscript. Such disagreement function could be utilized as a\ncost function in combinatorial optimization approaches for problems defined\nover hypergraphs.", 
    "link": "http://arxiv.org/pdf/1307.1303v1", 
    "arxiv-id": "1307.1303v1"
},{
    "category": "cs.CV", 
    "author": "John Wright", 
    "title": "Toward Guaranteed Illumination Models for Non-Convex Objects", 
    "publish": "2013-07-04T18:08:19Z", 
    "summary": "Illumination variation remains a central challenge in object detection and\nrecognition. Existing analyses of illumination variation typically pertain to\nconvex, Lambertian objects, and guarantee quality of approximation in an\naverage case sense. We show that it is possible to build V(vertex)-description\nconvex cone models with worst-case performance guarantees, for non-convex\nLambertian objects. Namely, a natural verification test based on the angle to\nthe constructed cone guarantees to accept any image which is sufficiently\nwell-approximated by an image of the object under some admissible lighting\ncondition, and guarantees to reject any image that does not have a sufficiently\ngood approximation. The cone models are generated by sampling point\nilluminations with sufficient density, which follows from a new perturbation\nbound for point images in the Lambertian model. As the number of point images\nrequired for guaranteed verification may be large, we introduce a new\nformulation for cone preserving dimensionality reduction, which leverages tools\nfrom sparse and low-rank decomposition to reduce the complexity, while\ncontrolling the approximation error with respect to the original cone.", 
    "link": "http://arxiv.org/pdf/1307.1437v1", 
    "arxiv-id": "1307.1437v1"
},{
    "category": "cs.CV", 
    "author": "N. V. Kalyankar", 
    "title": "Major Limitations of Satellite images", 
    "publish": "2013-07-09T13:01:46Z", 
    "summary": "Remote sensing has proven to be a powerful tool for the monitoring of the\nEarth surface to improve our perception of our surroundings has led to\nunprecedented developments in sensor and information technologies. However,\ntechnologies for effective use of the data and for extracting useful\ninformation from the data of Remote sensing are still very limited since no\nsingle sensor combines the optimal spectral, spatial and temporal resolution.\nThis paper briefly reviews the limitations of satellite remote sensing. Also,\nreviews on the problems of image fusion techniques. The conclusion of this,\nAccording to literature, the remote sensing is still the lack of software tools\nfor effective information extraction from remote sensing data. The trade-off in\nspectral and spatial resolution will remain and new advanced data fusion\napproaches are needed to make optimal use of remote sensors for extract the\nmost useful information.", 
    "link": "http://arxiv.org/pdf/1307.2434v1", 
    "arxiv-id": "1307.2434v1"
},{
    "category": "cs.CV", 
    "author": "N. V. Kalyankar", 
    "title": "Image Fusion Technologies In Commercial Remote Sensing Packages", 
    "publish": "2013-07-09T13:14:11Z", 
    "summary": "Several remote sensing software packages are used to the explicit purpose of\nanalyzing and visualizing remotely sensed data, with the developing of remote\nsensing sensor technologies from last ten years. Accord-ing to literature, the\nremote sensing is still the lack of software tools for effective information\nextraction from remote sensing data. So, this paper provides a state-of-art of\nmulti-sensor image fusion technologies as well as review on the quality\nevaluation of the single image or fused images in the commercial remote sensing\npack-ages. It also introduces program (ALwassaiProcess) developed for image\nfusion and classification.", 
    "link": "http://arxiv.org/pdf/1307.2440v1", 
    "arxiv-id": "1307.2440v1"
},{
    "category": "cs.CV", 
    "author": "Shaohua Kevin Zhou", 
    "title": "Semantic Context Forests for Learning-Based Knee Cartilage Segmentation   in 3D MR Images", 
    "publish": "2013-07-11T03:29:51Z", 
    "summary": "The automatic segmentation of human knee cartilage from 3D MR images is a\nuseful yet challenging task due to the thin sheet structure of the cartilage\nwith diffuse boundaries and inhomogeneous intensities. In this paper, we\npresent an iterative multi-class learning method to segment the femoral, tibial\nand patellar cartilage simultaneously, which effectively exploits the spatial\ncontextual constraints between bone and cartilage, and also between different\ncartilages. First, based on the fact that the cartilage grows in only certain\narea of the corresponding bone surface, we extract the distance features of not\nonly to the surface of the bone, but more informatively, to the densely\nregistered anatomical landmarks on the bone surface. Second, we introduce a set\nof iterative discriminative classifiers that at each iteration, probability\ncomparison features are constructed from the class confidence maps derived by\npreviously learned classifiers. These features automatically embed the semantic\ncontext information between different cartilages of interest. Validated on a\ntotal of 176 volumes from the Osteoarthritis Initiative (OAI) dataset, the\nproposed approach demonstrates high robustness and accuracy of segmentation in\ncomparison with existing state-of-the-art MR cartilage segmentation methods.", 
    "link": "http://arxiv.org/pdf/1307.2965v2", 
    "arxiv-id": "1307.2965v2"
},{
    "category": "cs.CV", 
    "author": "D. Meenakshy", 
    "title": "Conversion of Braille to Text in English, Hindi and Tamil Languages", 
    "publish": "2013-07-11T07:24:16Z", 
    "summary": "The Braille system has been used by the visually impaired for reading and\nwriting. Due to limited availability of the Braille text books an efficient\nusage of the books becomes a necessity. This paper proposes a method to convert\na scanned Braille document to text which can be read out to many through the\ncomputer. The Braille documents are pre processed to enhance the dots and\nreduce the noise. The Braille cells are segmented and the dots from each cell\nis extracted and converted in to a number sequence. These are mapped to the\nappropriate alphabets of the language. The converted text is spoken out through\na speech synthesizer. The paper also provides a mechanism to type the Braille\ncharacters through the number pad of the keyboard. The typed Braille character\nis mapped to the alphabet and spoken out. The Braille cell has a standard\nrepresentation but the mapping differs for each language. In this paper mapping\nof English, Hindi and Tamil are considered.", 
    "link": "http://arxiv.org/pdf/1307.2997v1", 
    "arxiv-id": "1307.2997v1"
},{
    "category": "cs.CV", 
    "author": "Christian Heipke", 
    "title": "A two-layer Conditional Random Field for the classification of partially   occluded objects", 
    "publish": "2013-07-11T10:07:19Z", 
    "summary": "Conditional Random Fields (CRF) are among the most popular techniques for\nimage labelling because of their flexibility in modelling dependencies between\nthe labels and the image features. This paper proposes a novel CRF-framework\nfor image labeling problems which is capable to classify partially occluded\nobjects. Our approach is evaluated on aerial near-vertical images as well as on\nurban street-view images and compared with another methods.", 
    "link": "http://arxiv.org/pdf/1307.3043v2", 
    "arxiv-id": "1307.3043v2"
},{
    "category": "cs.CV", 
    "author": "Sucheta Shrivastava", 
    "title": "Contrast Enhancement And Brightness Preservation Using Multi-   Decomposition Histogram Equalization", 
    "publish": "2013-07-11T11:02:57Z", 
    "summary": "Histogram Equalization (HE) has been an essential addition to the Image\nEnhancement world. Enhancement techniques like Classical Histogram Equalization\n(CHE), Adaptive Histogram Equalization (ADHE), Bi-Histogram Equalization (BHE)\nand Recursive Mean Separate Histogram Equalization (RMSHE) methods enhance\ncontrast, however, brightness is not well preserved with these methods, which\ngives an unpleasant look to the final image obtained. Thus, we introduce a\nnovel technique Multi-Decomposition Histogram Equalization (MDHE) to eliminate\nthe drawbacks of the earlier methods. In MDHE, we have decomposed the input\nsixty-four parts, applied CHE in each of the sub-images and then finally\ninterpolated them in correct order. The final image after MDHE results in\ncontrast enhanced and brightness preserved image compared to all other\ntechniques mentioned above. We have calculated the various parameters like\nPSNR, SNR, RMSE, MSE, etc. for every technique. Our results are well supported\nby bar graphs, histograms and the parameter calculations at the end.", 
    "link": "http://arxiv.org/pdf/1307.3054v1", 
    "arxiv-id": "1307.3054v1"
},{
    "category": "cs.CV", 
    "author": "Gordon Kindlmann", 
    "title": "Fuzzy Fibers: Uncertainty in dMRI Tractography", 
    "publish": "2013-07-11T21:01:23Z", 
    "summary": "Fiber tracking based on diffusion weighted Magnetic Resonance Imaging (dMRI)\nallows for noninvasive reconstruction of fiber bundles in the human brain. In\nthis chapter, we discuss sources of error and uncertainty in this technique,\nand review strategies that afford a more reliable interpretation of the\nresults. This includes methods for computing and rendering probabilistic\ntractograms, which estimate precision in the face of measurement noise and\nartifacts. However, we also address aspects that have received less attention\nso far, such as model selection, partial voluming, and the impact of\nparameters, both in preprocessing and in fiber tracking itself. We conclude by\ngiving impulses for future research.", 
    "link": "http://arxiv.org/pdf/1307.3271v1", 
    "arxiv-id": "1307.3271v1"
},{
    "category": "cs.CV", 
    "author": "Shalu Gupta", 
    "title": "Speedy Object Detection based on Shape", 
    "publish": "2013-07-12T12:37:06Z", 
    "summary": "This study is a part of design of an audio system for in-house object\ndetection system for visually impaired, low vision personnel by birth or by an\naccident or due to old age. The input of the system will be scene and output as\naudio. Alert facility is provided based on severity levels of the objects\n(snake, broke glass etc) and also during difficulties. The study proposed\ntechniques to provide speedy detection of objects based on shapes and its\nscale. Features are extraction to have minimum spaces using dynamic scaling.\nFrom a scene, clusters of objects are formed based on the scale and shape.\nSearching is performed among the clusters initially based on the shape, scale,\nmean cluster value and index of object(s). The minimum operation to detect the\npossible shape of the object is performed. In case the object does not have a\nlikely matching shape, scale etc, then the several operations required for an\nobject detection will not perform; instead, it will declared as a new object.\nIn such way, this study finds a speedy way of detecting objects.", 
    "link": "http://arxiv.org/pdf/1307.3439v1", 
    "arxiv-id": "1307.3439v1"
},{
    "category": "cs.CV", 
    "author": "Evgeniy Martyushev", 
    "title": "A Minimal Six-Point Auto-Calibration Algorithm", 
    "publish": "2013-07-14T17:37:36Z", 
    "summary": "A non-iterative auto-calibration algorithm is presented. It deals with a\nminimal set of six scene points in three views taken by a camera with fixed but\nunknown intrinsic parameters. Calibration is based on the image correspondences\nonly. The algorithm is implemented and validated on synthetic image data.", 
    "link": "http://arxiv.org/pdf/1307.3759v1", 
    "arxiv-id": "1307.3759v1"
},{
    "category": "cs.CV", 
    "author": "K. Thangavel", 
    "title": "Mammogram Edge Detection Using Hybrid Soft Computing Methods", 
    "publish": "2013-07-17T06:45:23Z", 
    "summary": "Image segmentation is a crucial step in a wide range of method image\nprocessing systems. It is useful in visualization of the different objects\npresent in the image. In spite of the several methods available in the\nliterature, image segmentation still a challenging problem in most of image\nprocessing applications. The challenge comes from the fuzziness of image\nobjects and the overlapping of the different regions. Detection of edges in an\nimage is a very important step towards understanding image features. There are\nlarge numbers of edge detection operators available, each designed to be\nsensitive to certain types of edges. The Quality of edge detection can be\nmeasured from several criteria objectively. Some criteria are proposed in terms\nof mathematical measurement, some of them are based on application and\nimplementation requirements. Since edges often occur at image locations\nrepresenting object boundaries, edge detection is extensively used in image\nsegmentation when images are divided into areas corresponding to different\nobjects. This can be used specifically for enhancing the tumor area in\nmammographic images. Different methods are available for edge detection like\nRoberts, Sobel, Prewitt, Canny, Log edge operators. In this paper a novel\nalgorithms for edge detection has been proposed for mammographic images. Breast\nboundary, pectoral region and tumor location can be seen clearly by using this\nmethod. For comparison purpose Roberts, Sobel, Prewitt, Canny, Log edge\noperators are used and their results are displayed. Experimental results\ndemonstrate the effectiveness of the proposed approach.", 
    "link": "http://arxiv.org/pdf/1307.4516v1", 
    "arxiv-id": "1307.4516v1"
},{
    "category": "cs.CV", 
    "author": "I. Laurence Aroquiaraj", 
    "title": "Content Based Image Retrieval System using Feature Classification with   Modified KNN Algorithm", 
    "publish": "2013-07-17T18:22:24Z", 
    "summary": "Feature means countenance, remote sensing scene objects with similar\ncharacteristics, associated to interesting scene elements in the image\nformation process. They are classified into three types in image processing,\nthat is low, middle and high. Low level features are color, texture and middle\nlevel feature is shape and high level feature is semantic gap of objects. An\nimage retrieval system is a computer system for browsing, searching and\nretrieving images from a large image database. Content Based Image Retrieval is\na technique which uses visual features of image such as color, shape, texture\nto search user required image from large image database according to user\nrequests in the form of a query. MKNN is an enhancing method of KNN. The\nproposed KNN classification is called MKNN. MKNN contains two parts for\nprocessing, they are validity of the train samples and applying weighted KNN.\nThe validity of each point is computed according to its neighbors. In our\nproposal, Modified K-Nearest Neighbor can be considered a kind of weighted KNN\nso that the query label is approximated by weighting the neighbors of the\nquery.", 
    "link": "http://arxiv.org/pdf/1307.4717v1", 
    "arxiv-id": "1307.4717v1"
},{
    "category": "cs.CV", 
    "author": "B. B. Chaudhuri", 
    "title": "Video Text Localization using Wavelet and Shearlet Transforms", 
    "publish": "2013-07-18T15:58:19Z", 
    "summary": "Text in video is useful and important in indexing and retrieving the video\ndocuments efficiently and accurately. In this paper, we present a new method of\ntext detection using a combined dictionary consisting of wavelets and a\nrecently introduced transform called shearlets. Wavelets provide optimally\nsparse expansion for point-like structures and shearlets provide optimally\nsparse expansions for curve-like structures. By combining these two features we\nhave computed a high frequency sub-band to brighten the text part. Then K-means\nclustering is used for obtaining text pixels from the Standard Deviation (SD)\nof combined coefficient of wavelets and shearlets as well as the union of\nwavelets and shearlets features. Text parts are obtained by grouping\nneighboring regions based on geometric properties of the classified output\nframe of unsupervised K-means classification. The proposed method tested on a\nstandard as well as newly collected database shows to be superior to some\nexisting methods.", 
    "link": "http://arxiv.org/pdf/1307.4990v2", 
    "arxiv-id": "1307.4990v2"
},{
    "category": "cs.CV", 
    "author": "Jarvis D. Haupt", 
    "title": "Automated Defect Localization via Low Rank Plus Outlier Modeling of   Propagating Wavefield Data", 
    "publish": "2013-07-19T00:06:59Z", 
    "summary": "This work proposes an agnostic inference strategy for material diagnostics,\nconceived within the context of laser-based non-destructive evaluation methods,\nwhich extract information about structural anomalies from the analysis of\nacoustic wavefields measured on the structure's surface by means of a scanning\nlaser interferometer. The proposed approach couples spatiotemporal windowing\nwith low rank plus outlier modeling, to identify a priori unknown deviations in\nthe propagating wavefields caused by material inhomogeneities or defects, using\nvirtually no knowledge of the structural and material properties of the medium.\nThis characteristic makes the approach particularly suitable for diagnostics\nscenarios where the mechanical and material models are complex, unknown, or\nunreliable. We demonstrate our approach in a simulated environment using\nbenchmark point and line defect localization problems based on propagating\nflexural waves in a thin plate.", 
    "link": "http://arxiv.org/pdf/1307.5102v1", 
    "arxiv-id": "1307.5102v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "A Novel Equation based Classifier for Detecting Human in Images", 
    "publish": "2013-07-22T05:13:03Z", 
    "summary": "Shape based classification is one of the most challenging tasks in the field\nof computer vision. Shapes play a vital role in object recognition. The basic\nshapes in an image can occur in varying scale, position and orientation. And\nspecially when detecting human, the task becomes more challenging owing to the\nlargely varying size, shape, posture and clothing of human. So, in our work we\ndetect human, based on the head-shoulder shape as it is the most unvarying part\nof human body. Here, firstly a new and a novel equation named as the Omega\nEquation that describes the shape of human head-shoulder is developed and based\non this equation, a classifier is designed particularly for detecting human\npresence in a scene. The classifier detects human by analyzing some of the\ndiscriminative features of the values of the parameters obtained from the Omega\nequation. The proposed method has been tested on a variety of shape dataset\ntaking into consideration the complexities of human head-shoulder shape. In all\nthe experiments the proposed method demonstrated satisfactory results.", 
    "link": "http://arxiv.org/pdf/1307.5591v1", 
    "arxiv-id": "1307.5591v1"
},{
    "category": "cs.CV", 
    "author": "Monique Thonnat", 
    "title": "Online Tracking Parameter Adaptation based on Evaluation", 
    "publish": "2013-07-22T11:09:33Z", 
    "summary": "Parameter tuning is a common issue for many tracking algorithms. In order to\nsolve this problem, this paper proposes an online parameter tuning to adapt a\ntracking algorithm to various scene contexts. In an offline training phase,\nthis approach learns how to tune the tracker parameters to cope with different\ncontexts. In the online control phase, once the tracking quality is evaluated\nas not good enough, the proposed approach computes the current context and\ntunes the tracking parameters using the learned values. The experimental\nresults show that the proposed approach improves the performance of the\ntracking algorithm and outperforms recent state of the art trackers. This paper\nbrings two contributions: (1) an online tracking evaluation, and (2) a method\nto adapt online tracking parameters to scene contexts.", 
    "link": "http://arxiv.org/pdf/1307.5653v1", 
    "arxiv-id": "1307.5653v1"
},{
    "category": "cs.CV", 
    "author": "Thierry Dutoit", 
    "title": "A study of parameters affecting visual saliency assessment", 
    "publish": "2013-07-22T13:01:36Z", 
    "summary": "Since the early 2000s, computational visual saliency has been a very active\nresearch area. Each year, more and more new models are published in the main\ncomputer vision conferences. Nowadays, one of the big challenges is to find a\nway to fairly evaluate all of these models. In this paper, a new framework is\nproposed to assess models of visual saliency. This evaluation is divided into\nthree experiments leading to the proposition of a new evaluation framework.\nEach experiment is based on a basic question: 1) there are two ground truths\nfor saliency evaluation: what are the differences between eye fixations and\nmanually segmented salient regions?, 2) the properties of the salient regions:\nfor example, do large, medium and small salient regions present different\ndifficulties for saliency models? and 3) the metrics used to assess saliency\nmodels: what advantages would there be to mix them with PCA? Statistical\nanalysis is used here to answer each of these three questions.", 
    "link": "http://arxiv.org/pdf/1307.5691v1", 
    "arxiv-id": "1307.5691v1"
},{
    "category": "cs.CV", 
    "author": "Aykut Erdem", 
    "title": "Visual saliency estimation by integrating features using multiple kernel   learning", 
    "publish": "2013-07-22T13:09:12Z", 
    "summary": "In the last few decades, significant achievements have been attained in\npredicting where humans look at images through different computational models.\nHowever, how to determine contributions of different visual features to overall\nsaliency still remains an open problem. To overcome this issue, a recent class\nof models formulates saliency estimation as a supervised learning problem and\naccordingly apply machine learning techniques. In this paper, we also address\nthis challenging problem and propose to use multiple kernel learning (MKL) to\ncombine information coming from different feature dimensions and to perform\nintegration at an intermediate level. Besides, we suggest to use responses of a\nrecently proposed filterbank of object detectors, known as Object-Bank, as\nadditional semantic high-level features. Here we show that our MKL-based\nframework together with the proposed object-specific features provide\nstate-of-the-art performance as compared to SVM or AdaBoost-based saliency\nmodels.", 
    "link": "http://arxiv.org/pdf/1307.5693v1", 
    "arxiv-id": "1307.5693v1"
},{
    "category": "cs.CV", 
    "author": "Lina J. Karam", 
    "title": "Is Bottom-Up Attention Useful for Scene Recognition?", 
    "publish": "2013-07-22T13:38:16Z", 
    "summary": "The human visual system employs a selective attention mechanism to understand\nthe visual world in an eficient manner. In this paper, we show how\ncomputational models of this mechanism can be exploited for the computer vision\napplication of scene recognition. First, we consider saliency weighting and\nsaliency pruning, and provide a comparison of the performance of different\nattention models in these approaches in terms of classification accuracy.\nPruning can achieve a high degree of computational savings without\nsignificantly sacrificing classification accuracy. In saliency weighting,\nhowever, we found that classification performance does not improve. In\naddition, we present a new method to incorporate salient and non-salient\nregions for improved classification accuracy. We treat the salient and\nnon-salient regions separately and combine them using Multiple Kernel Learning.\nWe evaluate our approach using the UIUC sports dataset and find that with a\nsmall training size, our method improves upon the classification accuracy of\nthe baseline bag of features approach.", 
    "link": "http://arxiv.org/pdf/1307.5702v1", 
    "arxiv-id": "1307.5702v1"
},{
    "category": "cs.CV", 
    "author": "B\u007f\u00e4rbel Mertsching", 
    "title": "Saliency-Guided Perceptual Grouping Using Motion Cues in Region-Based   Artificial Visual Attention", 
    "publish": "2013-07-22T13:48:13Z", 
    "summary": "Region-based artificial attention constitutes a framework for bio-inspired\nattentional processes on an intermediate abstraction level for the use in\ncomputer vision and mobile robotics. Segmentation algorithms produce regions of\ncoherently colored pixels. These serve as proto-objects on which the\nattentional processes determine image portions of relevance. A single\nregion---which not necessarily represents a full object---constitutes the focus\nof attention. For many post-attentional tasks, however, such as identifying or\ntracking objects, single segments are not sufficient. Here, we present a\nsaliency-guided approach that groups regions that potentially belong to the\nsame object based on proximity and similarity of motion. We compare our results\nto object selection by thresholding saliency maps and a further\nattention-guided strategy.", 
    "link": "http://arxiv.org/pdf/1307.5710v1", 
    "arxiv-id": "1307.5710v1"
},{
    "category": "cs.CV", 
    "author": "Riccardo Satta", 
    "title": "Appearance Descriptors for Person Re-identification: a Comprehensive   Review", 
    "publish": "2013-07-22T15:41:57Z", 
    "summary": "In video-surveillance, person re-identification is the task of recognising\nwhether an individual has already been observed over a network of cameras.\nTypically, this is achieved by exploiting the clothing appearance, as classical\nbiometric traits like the face are impractical in real-world video surveillance\nscenarios. Clothing appearance is represented by means of low-level\n\\textit{local} and/or \\textit{global} features of the image, usually extracted\naccording to some part-based body model to treat different body parts (e.g.\ntorso and legs) independently. This paper provides a comprehensive review of\ncurrent approaches to build appearance descriptors for person\nre-identification. The most relevant techniques are described in detail, and\ncategorised according to the body models and features used. The aim of this\nwork is to provide a structured body of knowledge and a starting point for\nresearchers willing to conduct novel investigations on this challenging topic.", 
    "link": "http://arxiv.org/pdf/1307.5748v1", 
    "arxiv-id": "1307.5748v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "An Adaptive GMM Approach to Background Subtraction for Application in   Real Time Surveillance", 
    "publish": "2013-07-22T17:59:28Z", 
    "summary": "Efficient security management has become an important parameter in todays\nworld. As the problem is growing, there is an urgent need for the introduction\nof advanced technology and equipment to improve the state-of art of\nsurveillance. In this paper we propose a model for real time background\nsubtraction using AGMM. The proposed model is robust and adaptable to dynamic\nbackground, fast illumination changes, repetitive motion. Also we have\nincorporated a method for detecting shadows using the Horpresert color model.\nThe proposed model can be employed for monitoring areas where movement or entry\nis highly restricted. So on detection of any unexpected events in the scene an\nalarm can be triggered and hence we can achieve real time surveillance even in\nthe absence of constant human monitoring.", 
    "link": "http://arxiv.org/pdf/1307.5800v1", 
    "arxiv-id": "1307.5800v1"
},{
    "category": "cs.CV", 
    "author": "Fang Fang", 
    "title": "6th International Symposium on Attention in Cognitive Systems 2013", 
    "publish": "2013-07-22T12:27:26Z", 
    "summary": "This volume contains the papers accepted at the 6th International Symposium\non Attention in Cognitive Systems (ISACS 2013), held in Beijing, August 5,\n2013. The aim of this symposium is to highlight the central role of attention\non various kinds of performance in cognitive systems processing. It brings\ntogether researchers and developers from both academia and industry, from\ncomputer vision, robotics, perception psychology, psychophysics and\nneuroscience, in order to provide an interdisciplinary forum to present and\ncommunicate on computational models of attention, with the focus on\ninterdependencies with visual cognition. Furthermore, it intends to investigate\nrelevant objectives for performance comparison, to document and to investigate\npromising application domains, and to discuss visual attention with reference\nto other aspects of AI enabled systems.", 
    "link": "http://arxiv.org/pdf/1307.6170v2", 
    "arxiv-id": "1307.6170v2"
},{
    "category": "cs.CV", 
    "author": "Kap Luk Chan", 
    "title": "Matching-Constrained Active Contours", 
    "publish": "2013-07-24T06:18:44Z", 
    "summary": "In object segmentation by active contours, the initial contour is often\nrequired. Conventionally, the initial contour is provided by the user. This\npaper extends the conventional active contour model by incorporating feature\nmatching in the formulation, which gives rise to a novel matching-constrained\nactive contour. The numerical solution to the new optimization model provides\nan automated framework of object segmentation without user intervention. The\nmain idea is to incorporate feature point matching as a constraint in active\ncontour models. To this effect, we obtain a mathematical model of interior\npoints to boundary contour such that matching of interior feature points gives\ncontour alignment, and we formulate the matching score as a constraint to\nactive contour model such that the feature matching of maximum score that gives\nthe contour alignment provides the initial feasible solution to the constrained\noptimization model of segmentation. The constraint also ensures that the\noptimal contour does not deviate too much from the initial contour.\nProjected-gradient descent equations are derived to solve the constrained\noptimization. In the experiments, we show that our method is capable of\nachieving the automatic object segmentation, and it outperforms the related\nmethods.", 
    "link": "http://arxiv.org/pdf/1307.6303v1", 
    "arxiv-id": "1307.6303v1"
},{
    "category": "cs.CV", 
    "author": "Subanar", 
    "title": "Selection Mammogram Texture Descriptors Based on Statistics Properties   Backpropagation Structure", 
    "publish": "2013-07-10T02:42:29Z", 
    "summary": "Computer Aided Diagnosis (CAD) system has been developed for the early\ndetection of breast cancer, one of the most deadly cancer for women. The benign\nof mammogram has different texture from malignant. There are fifty mammogram\nimages used in this work which are divided for training and testing. Therefore,\nthe selection of the right texture to determine the level of accuracy of CAD\nsystem is important. The first and second order statistics are the texture\nfeature extraction methods which can be used on a mammogram. This work\nclassifies texture descriptor into nine groups where the extraction of features\nis classified using backpropagation learning with two types of multi-layer\nperceptron (MLP). The best texture descriptor as selected when the value of\nregression 1 appears in both the MLP-1 and the MLP-2 with the number of epoches\nless than 1000. The results of testing show that the best selected texture\ndescriptor is the second order (combination) using all direction (0, 45, 90 and\n135) that have twenty four descriptors.", 
    "link": "http://arxiv.org/pdf/1307.6542v1", 
    "arxiv-id": "1307.6542v1"
},{
    "category": "cs.CV", 
    "author": "M. A. El-Dosuky", 
    "title": "Veni Vidi Vici, A Three-Phase Scenario For Parameter Space Analysis in   Image Analysis and Visualization", 
    "publish": "2013-07-17T04:49:24Z", 
    "summary": "Automatic analysis of the enormous sets of images is a critical task in life\nsciences. This faces many challenges such as: algorithms are highly\nparameterized, significant human input is intertwined, and lacking a standard\nmeta-visualization approach. This paper proposes an alternative iterative\napproach for optimizing input parameters, saving time by minimizing the user\ninvolvement, and allowing for understanding the workflow of algorithms and\ndiscovering new ones. The main focus is on developing an interactive\nvisualization technique that enables users to analyze the relationships between\nsampled input parameters and corresponding output. This technique is\nimplemented as a prototype called Veni Vidi Vici, or \"I came, I saw, I\nconquered.\" This strategy is inspired by the mathematical formulas of numbering\ncomputable functions and is developed atop ImageJ, a scientific image\nprocessing program. A case study is presented to investigate the proposed\nframework. Finally, the paper explores some potential future issues in the\napplication of the proposed approach in parameter space analysis in\nvisualization.", 
    "link": "http://arxiv.org/pdf/1307.6544v1", 
    "arxiv-id": "1307.6544v1"
},{
    "category": "cs.CV", 
    "author": "D. Arul Pon Daniel", 
    "title": "Automatic Mammogram image Breast Region Extraction and Removal of   Pectoral Muscle", 
    "publish": "2013-07-29T06:42:25Z", 
    "summary": "Currently Mammography is a most effective imaging modality used by\nradiologists for the screening of breast cancer. Finding an accurate, robust\nand efficient breast region segmentation technique still remains a challenging\nproblem in digital mammography. Extraction of the breast profile region and the\nremoval of pectoral muscle are essential pre-processing steps in Computer Aided\nDiagnosis (CAD) system for the diagnosis of breast cancer. Primarily it allows\nthe search for abnormalities to be limited to the region of the breast tissue\nwithout undue influence from the background of the mammogram. The presence of\npectoral muscle in mammograms biases detection procedures, which recommends\nremoving the pectoral muscle during mammogram image pre-processing. The\npresence of pectoral muscle in mammograms may disturb or influence the\ndetection of breast cancer as the pectoral muscle and mammographic parenchymas\nappear similar. The goal of breast region extraction is reducing the image size\nwithout losing anatomic information, it improve the accuracy of the overall CAD\nsystem. The main objective of this study is to propose an automated method to\nidentify the pectoral muscle in Medio-Lateral Oblique (MLO) view mammograms. In\nthis paper, we proposed histogram based 8-neighborhood connected component\nlabelling method for breast region extraction and removal of pectoral muscle.\nThe proposed method is evaluated by using the mean values of accuracy and\nerror. The comparative analysis shows that the proposed method identifies the\nbreast region more accurately.", 
    "link": "http://arxiv.org/pdf/1307.7474v1", 
    "arxiv-id": "1307.7474v1"
},{
    "category": "cs.CV", 
    "author": "Pushmeet Kohli", 
    "title": "Efficient Energy Minimization for Enforcing Statistics", 
    "publish": "2013-07-30T03:46:38Z", 
    "summary": "Energy minimization algorithms, such as graph cuts, enable the computation of\nthe MAP solution under certain probabilistic models such as Markov random\nfields. However, for many computer vision problems, the MAP solution under the\nmodel is not the ground truth solution. In many problem scenarios, the system\nhas access to certain statistics of the ground truth. For instance, in image\nsegmentation, the area and boundary length of the object may be known. In these\ncases, we want to estimate the most probable solution that is consistent with\nsuch statistics, i.e., satisfies certain equality or inequality constraints.\n  The above constrained energy minimization problem is NP-hard in general, and\nis usually solved using Linear Programming formulations, which relax the\nintegrality constraints. This paper proposes a novel method that finds the\ndiscrete optimal solution of such problems by maximizing the corresponding\nLagrangian dual. This method can be applied to any constrained energy\nminimization problem whose unconstrained version is polynomial time solvable,\nand can handle multiple, equality or inequality, and linear or non-linear\nconstraints. We demonstrate the efficacy of our method on the\nforeground/background image segmentation problem, and show that it produces\nimpressive segmentation results with less error, and runs more than 20 times\nfaster than the state-of-the-art LP relaxation based approaches.", 
    "link": "http://arxiv.org/pdf/1307.7800v1", 
    "arxiv-id": "1307.7800v1"
},{
    "category": "cs.CV", 
    "author": "Gerald Fritz", 
    "title": "An Integrated System for 3D Gaze Recovery and Semantic Analysis of Human   Attention", 
    "publish": "2013-07-30T07:18:20Z", 
    "summary": "This work describes a computer vision system that enables pervasive mapping\nand monitoring of human attention. The key contribution is that our methodology\nenables full 3D recovery of the gaze pointer, human view frustum and associated\nhuman centered measurements directly into an automatically computed 3D model in\nreal-time. We apply RGB-D SLAM and descriptor matching methodologies for the 3D\nmodeling, localization and fully automated annotation of ROIs (regions of\ninterest) within the acquired 3D model. This innovative methodology will open\nnew avenues for attention studies in real world environments, bringing new\npotential into automated processing for human factors technologies.", 
    "link": "http://arxiv.org/pdf/1307.7848v1", 
    "arxiv-id": "1307.7848v1"
},{
    "category": "cs.CV", 
    "author": "Shipeng Li", 
    "title": "Hybrid Affinity Propagation", 
    "publish": "2013-07-30T07:30:46Z", 
    "summary": "In this paper, we address a problem of managing tagged images with hybrid\nsummarization. We formulate this problem as finding a few image exemplars to\nrepresent the image set semantically and visually, and solve it in a hybrid way\nby exploiting both visual and textual information associated with images. We\npropose a novel approach, called homogeneous and heterogeneous message\npropagation ($\\text{H}^\\text{2}\\text{MP}$). Similar to the affinity propagation\n(AP) approach, $\\text{H}^\\text{2}\\text{MP}$ reduce the conventional\n\\emph{vector} message propagation to \\emph{scalar} message propagation to make\nthe algorithm more efficient. Beyond AP that can only handle homogeneous data,\n$\\text{H}^\\text{2}\\text{MP}$ generalizes it to exploit extra heterogeneous\nrelations and the generalization is non-trivial as the reduction to scalar\nmessages from vector messages is more challenging. The main advantages of our\napproach lie in 1) that $\\text{H}^\\text{2}\\text{MP}$ exploits visual similarity\nand in addition the useful information from the associated tags, including the\nassociations relation between images and tags and the relations within tags,\nand 2) that the summary is both visually and semantically satisfactory. In\naddition, our approach can also present a textual summary to a tagged image\ncollection, which can be used to automatically generate a textual description.\nThe experimental results demonstrate the effectiveness and efficiency of the\nroposed approach.", 
    "link": "http://arxiv.org/pdf/1307.7851v1", 
    "arxiv-id": "1307.7851v1"
},{
    "category": "cs.CV", 
    "author": "B\u007f\u00e4rbel Mertsching", 
    "title": "A Prototyping Environment for Integrated Artificial Attention Systems", 
    "publish": "2013-07-31T06:24:28Z", 
    "summary": "Artificial visual attention systems aim to support technical systems in\nvisual tasks by applying the concepts of selective attention observed in humans\nand other animals. Such systems are typically evaluated against ground truth\nobtained from human gaze-data or manually annotated test images. When applied\nto robotics, the systems are required to be adaptable to the target system.\nHere, we describe a flexible environment based on a robotic middleware layer\nallowing the development and testing of attention-guided vision systems. In\nsuch a framework, the systems can be tested with input from various sources,\ndifferent attention algorithms at the core, and diverse subsequent tasks.", 
    "link": "http://arxiv.org/pdf/1307.8233v1", 
    "arxiv-id": "1307.8233v1"
},{
    "category": "cs.CV", 
    "author": "Jinyun Yan", 
    "title": "Who and Where: People and Location Co-Clustering", 
    "publish": "2013-07-31T17:53:10Z", 
    "summary": "In this paper, we consider the clustering problem on images where each image\ncontains patches in people and location domains. We exploit the correlation\nbetween people and location domains, and proposed a semi-supervised\nco-clustering algorithm to cluster images. Our algorithm updates the\ncorrelation links at the runtime, and produces clustering in both domains\nsimultaneously. We conduct experiments in a manually collected dataset and a\nFlickr dataset. The result shows that the such correlation improves the\nclustering performance.", 
    "link": "http://arxiv.org/pdf/1307.8405v1", 
    "arxiv-id": "1307.8405v1"
},{
    "category": "cs.CV", 
    "author": "Rama Chellappa", 
    "title": "Compositional Dictionaries for Domain Adaptive Face Recognition", 
    "publish": "2013-08-01T17:27:31Z", 
    "summary": "We present a dictionary learning approach to compensate for the\ntransformation of faces due to changes in view point, illumination, resolution,\netc. The key idea of our approach is to force domain-invariant sparse coding,\ni.e., design a consistent sparse representation of the same face in different\ndomains. In this way, classifiers trained on the sparse codes in the source\ndomain consisting of frontal faces for example can be applied to the target\ndomain (consisting of faces in different poses, illumination conditions, etc)\nwithout much loss in recognition accuracy. The approach is to first learn a\ndomain base dictionary, and then describe each domain shift (identity, pose,\nillumination) using a sparse representation over the base dictionary. The\ndictionary adapted to each domain is expressed as sparse linear combinations of\nthe base dictionary. In the context of face recognition, with the proposed\ncompositional dictionary approach, a face image can be decomposed into sparse\nrepresentations for a given subject, pose and illumination respectively. This\napproach has three advantages: first, the extracted sparse representation for a\nsubject is consistent across domains and enables pose and illumination\ninsensitive face recognition. Second, sparse representations for pose and\nillumination can subsequently be used to estimate the pose and illumination\ncondition of a face image. Finally, by composing sparse representations for\nsubject and the different domains, we can also perform pose alignment and\nillumination normalization. Extensive experiments using two public face\ndatasets are presented to demonstrate the effectiveness of our approach for\nface recognition.", 
    "link": "http://arxiv.org/pdf/1308.0271v2", 
    "arxiv-id": "1308.0271v2"
},{
    "category": "cs.CV", 
    "author": "Guillermo Sapiro", 
    "title": "Learning Robust Subspace Clustering", 
    "publish": "2013-08-01T17:31:37Z", 
    "summary": "We propose a low-rank transformation-learning framework to robustify subspace\nclustering. Many high-dimensional data, such as face images and motion\nsequences, lie in a union of low-dimensional subspaces. The subspace clustering\nproblem has been extensively studied in the literature to partition such\nhigh-dimensional data into clusters corresponding to their underlying\nlow-dimensional subspaces. However, low-dimensional intrinsic structures are\noften violated for real-world observations, as they can be corrupted by errors\nor deviate from ideal models. We propose to address this by learning a linear\ntransformation on subspaces using matrix rank, via its convex surrogate nuclear\nnorm, as the optimization criteria. The learned linear transformation restores\na low-rank structure for data from the same subspace, and, at the same time,\nforces a high-rank structure for data from different subspaces. In this way, we\nreduce variations within the subspaces, and increase separations between the\nsubspaces for more accurate subspace clustering. This proposed learned robust\nsubspace clustering framework significantly enhances the performance of\nexisting subspace clustering methods. To exploit the low-rank structures of the\ntransformed subspaces, we further introduce a subspace clustering technique,\ncalled Robust Sparse Subspace Clustering, which efficiently combines robust PCA\nwith sparse modeling. We also discuss the online learning of the\ntransformation, and learning of the transformation while simultaneously\nreducing the data dimensionality. Extensive experiments using public datasets\nare presented, showing that the proposed approach significantly outperforms\nstate-of-the-art subspace clustering methods.", 
    "link": "http://arxiv.org/pdf/1308.0273v1", 
    "arxiv-id": "1308.0273v1"
},{
    "category": "cs.CV", 
    "author": "Ching-Hui Chen", 
    "title": "Domain-invariant Face Recognition using Learned Low-rank Transformation", 
    "publish": "2013-08-01T17:34:36Z", 
    "summary": "We present a low-rank transformation approach to compensate for face\nvariations due to changes in visual domains, such as pose and illumination. The\nkey idea is to learn discriminative linear transformations for face images\nusing matrix rank as the optimization criteria. The learned linear\ntransformations restore a shared low-rank structure for faces from the same\nsubject, and, at the same time, force a high-rank structure for faces from\ndifferent subjects. In this way, among the transformed faces, we reduce\nvariations caused by domain changes within the classes, and increase\nseparations between the classes for better face recognition across domains.\nExtensive experiments using public datasets are presented to demonstrate the\neffectiveness of our approach for face recognition across domains. The\npotential of the approach for feature extraction in generic object recognition\nand coded aperture design are discussed as well.", 
    "link": "http://arxiv.org/pdf/1308.0275v1", 
    "arxiv-id": "1308.0275v1"
},{
    "category": "cs.CV", 
    "author": "Rama Chellappa", 
    "title": "Sparse Dictionary-based Attributes for Action Recognition and   Summarization", 
    "publish": "2013-08-01T18:25:16Z", 
    "summary": "We present an approach for dictionary learning of action attributes via\ninformation maximization. We unify the class distribution and appearance\ninformation into an objective function for learning a sparse dictionary of\naction attributes. The objective function maximizes the mutual information\nbetween what has been learned and what remains to be learned in terms of\nappearance information and class distribution for each dictionary atom. We\npropose a Gaussian Process (GP) model for sparse representation to optimize the\ndictionary objective function. The sparse coding property allows a kernel with\ncompact support in GP to realize a very efficient dictionary learning process.\nHence we can describe an action video by a set of compact and discriminative\naction attributes. More importantly, we can recognize modeled action categories\nin a sparse feature space, which can be generalized to unseen and unmodeled\naction categories. Experimental results demonstrate the effectiveness of our\napproach in action recognition and summarization.", 
    "link": "http://arxiv.org/pdf/1308.0290v1", 
    "arxiv-id": "1308.0290v1"
},{
    "category": "cs.CV", 
    "author": "Khurom H. Kiyani", 
    "title": "Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes", 
    "publish": "2013-08-01T21:58:33Z", 
    "summary": "In this paper we address the problem of multiple camera calibration in the\npresence of a homogeneous scene, and without the possibility of employing\ncalibration object based methods. The proposed solution exploits salient\nfeatures present in a larger field of view, but instead of employing active\nvision we replace the cameras with stereo rigs featuring a long focal analysis\ncamera, as well as a short focal registration camera. Thus, we are able to\npropose an accurate solution which does not require intrinsic variation models\nas in the case of zooming cameras. Moreover, the availability of the two views\nsimultaneously in each rig allows for pose re-estimation between rigs as often\nas necessary. The algorithm has been successfully validated in an indoor\nsetting, as well as on a difficult scene featuring a highly dense pilgrim crowd\nin Makkah.", 
    "link": "http://arxiv.org/pdf/1308.0365v1", 
    "arxiv-id": "1308.0365v1"
},{
    "category": "cs.CV", 
    "author": "Karen Das", 
    "title": "Head Gesture Recognition using Optical Flow based Classification with   Reinforcement of GMM based Background Subtraction", 
    "publish": "2013-08-05T05:17:26Z", 
    "summary": "This paper describes a technique of real time head gesture recognition\nsystem. The method includes Gaussian mixture model (GMM) accompanied by optical\nflow algorithm which provided us the required information regarding head\nmovement. The proposed model can be implemented in various control system. We\nare also presenting the result and implementation of both mentioned method.", 
    "link": "http://arxiv.org/pdf/1308.0890v1", 
    "arxiv-id": "1308.0890v1"
},{
    "category": "cs.CV", 
    "author": "T. Wiegand", 
    "title": "Image interpolation using Shearlet based iterative refinement", 
    "publish": "2013-08-05T21:33:06Z", 
    "summary": "This paper proposes an image interpolation algorithm exploiting sparse\nrepresentation for natural images. It involves three main steps: (a) obtaining\nan initial estimate of the high resolution image using linear methods like FIR\nfiltering, (b) promoting sparsity in a selected dictionary through iterative\nthresholding, and (c) extracting high frequency information from the\napproximation to refine the initial estimate. For the sparse modeling, a\nshearlet dictionary is chosen to yield a multiscale directional representation.\nThe proposed algorithm is compared to several state-of-the-art methods to\nassess its objective as well as subjective performance. Compared to the cubic\nspline interpolation method, an average PSNR gain of around 0.8 dB is observed\nover a dataset of 200 images.", 
    "link": "http://arxiv.org/pdf/1308.1126v1", 
    "arxiv-id": "1308.1126v1"
},{
    "category": "cs.CV", 
    "author": "Hyuntaek Oh", 
    "title": "Bayesian ensemble learning for image denoising", 
    "publish": "2013-08-06T18:46:18Z", 
    "summary": "Natural images are often affected by random noise and image denoising has\nlong been a central topic in Computer Vision. Many algorithms have been\nintroduced to remove the noise from the natural images, such as Gaussian,\nWiener filtering and wavelet thresholding. However, many of these algorithms\nremove the fine edges and make them blur. Recently, many promising denoising\nalgorithms have been introduced such as Non-local Means, Fields of Experts, and\nBM3D. In this paper, we explore Bayesian method of ensemble learning for image\ndenoising. Ensemble methods seek to combine multiple different algorithms to\nretain the strengths of all methods and the weaknesses of none. Bayesian\nensemble models are Non-local Means and Fields of Experts, the very successful\nrecent algorithms. The Non-local Means presumes that the image contains an\nextensive amount of self-similarity. The approach of the Fields of Experts\nmodel extends traditional Markov Random Field model by learning potential\nfunctions over extended pixel neighborhoods. The two models are implemented and\nimage denoising is performed on natural images. The experimental results\nobtained are used to compare with the single algorithm and discuss the ensemble\nlearning and their approaches. Comparing to the results of Non-local Means and\nFields of Experts, Ensemble learning showed improvement nearly 1dB.", 
    "link": "http://arxiv.org/pdf/1308.1374v1", 
    "arxiv-id": "1308.1374v1"
},{
    "category": "cs.CV", 
    "author": "Ashok Veeraraghavan", 
    "title": "A Framework for the Analysis of Computational Imaging Systems with   Practical Applications", 
    "publish": "2013-08-08T21:21:54Z", 
    "summary": "Over the last decade, a number of Computational Imaging (CI) systems have\nbeen proposed for tasks such as motion deblurring, defocus deblurring and\nmultispectral imaging. These techniques increase the amount of light reaching\nthe sensor via multiplexing and then undo the deleterious effects of\nmultiplexing by appropriate reconstruction algorithms. Given the widespread\nappeal and the considerable enthusiasm generated by these techniques, a\ndetailed performance analysis of the benefits conferred by this approach is\nimportant.\n  Unfortunately, a detailed analysis of CI has proven to be a challenging\nproblem because performance depends equally on three components: (1) the\noptical multiplexing, (2) the noise characteristics of the sensor, and (3) the\nreconstruction algorithm. A few recent papers have performed analysis taking\nmultiplexing and noise characteristics into account. However, analysis of CI\nsystems under state-of-the-art reconstruction algorithms, most of which exploit\nsignal prior models, has proven to be unwieldy. In this paper, we present a\ncomprehensive analysis framework incorporating all three components.\n  In order to perform this analysis, we model the signal priors using a\nGaussian Mixture Model (GMM). A GMM prior confers two unique characteristics.\nFirstly, GMM satisfies the universal approximation property which says that any\nprior density function can be approximated to any fidelity using a GMM with\nappropriate number of mixtures. Secondly, a GMM prior lends itself to\nanalytical tractability allowing us to derive simple expressions for the\n`minimum mean square error' (MMSE), which we use as a metric to characterize\nthe performance of CI systems. We use our framework to analyze several\npreviously proposed CI techniques, giving conclusive answer to the question:\n`How much performance gain is due to use of a signal prior and how much is due\nto multiplexing?", 
    "link": "http://arxiv.org/pdf/1308.1981v3", 
    "arxiv-id": "1308.1981v3"
},{
    "category": "cs.CV", 
    "author": "Jos\u00e9 G. Gerardo Tamez-Pena", 
    "title": "Local image registration a comparison for bilateral registration   mammography", 
    "publish": "2013-08-12T19:29:49Z", 
    "summary": "Early tumor detection is key in reducing the number of breast cancer death\nand screening mammography is one of the most widely available and reliable\nmethod for early detection. However, it is difficult for the radiologist to\nprocess with the same attention each case, due the large amount of images to be\nread. Computer aided detection (CADe) systems improve tumor detection rate; but\nthe current efficiency of these systems is not yet adequate and the correct\ninterpretation of CADe outputs requires expert human intervention. Computer\naided diagnosis systems (CADx) are being designed to improve cancer diagnosis\naccuracy, but they have not been efficiently applied in breast cancer. CADx\nefficiency can be enhanced by considering the natural mirror symmetry between\nthe right and left breast. The objective of this work is to evaluate\nco-registration algorithms for the accurate alignment of the left to right\nbreast for CADx enhancement. A set of mammograms were artificially altered to\ncreate a ground truth set to evaluate the registration efficiency of DEMONs,\nand SPLINE deformable registration algorithms. The registration accuracy was\nevaluated using mean square errors, mutual information and correlation. The\nresults on the 132 images proved that the SPLINE deformable registration\nover-perform the DEMONS on mammography images.", 
    "link": "http://arxiv.org/pdf/1308.2654v1", 
    "arxiv-id": "1308.2654v1"
},{
    "category": "cs.CV", 
    "author": "Alan C. Bovik", 
    "title": "Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual   Image Quality Index", 
    "publish": "2013-08-14T07:25:10Z", 
    "summary": "It is an important task to faithfully evaluate the perceptual quality of\noutput images in many applications such as image compression, image restoration\nand multimedia streaming. A good image quality assessment (IQA) model should\nnot only deliver high quality prediction accuracy but also be computationally\nefficient. The efficiency of IQA metrics is becoming particularly important due\nto the increasing proliferation of high-volume visual data in high-speed\nnetworks. We present a new effective and efficient IQA model, called gradient\nmagnitude similarity deviation (GMSD). The image gradients are sensitive to\nimage distortions, while different local structures in a distorted image suffer\ndifferent degrees of degradations. This motivates us to explore the use of\nglobal variation of gradient based local quality map for overall image quality\nprediction. We find that the pixel-wise gradient magnitude similarity (GMS)\nbetween the reference and distorted images combined with a novel pooling\nstrategy the standard deviation of the GMS map can predict accurately\nperceptual image quality. The resulting GMSD algorithm is much faster than most\nstate-of-the-art IQA methods, and delivers highly competitive prediction\naccuracy.", 
    "link": "http://arxiv.org/pdf/1308.3052v2", 
    "arxiv-id": "1308.3052v2"
},{
    "category": "cs.CV", 
    "author": "N. V. Kalyankar", 
    "title": "Influences Combination of Multi-Sensor Images on Classification Accuracy", 
    "publish": "2013-08-20T21:34:47Z", 
    "summary": "This paper focuses on two main issues; first one is the impact of combination\nof multi-sensor images on the supervised learning classification accuracy using\nsegment Fusion (SF). The second issue attempts to undertake the study of\nsupervised machine learning classification technique of remote sensing images\nby using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD),\nMaximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their\naccuracies have been evaluated on their respected classification to choose the\nbest technique for classification of remote sensing images. QuickBird\nmultispectral data (MS) and panchromatic data (PAN) have been used in this\nstudy to demonstrate the enhancement and accuracy assessment of fused image\nover the original images using ALwassaiProcess software. According to\nexperimental result of this study, is that the test results indicate the\nsupervised classification results of fusion image, which generated better than\nthe MS did. As well as the result with Euclidean classifier is robust and\nprovides better results than the other classifiers do, despite of the popular\nbelief that the maximum-likelihood classifier is the most accurate classifier.", 
    "link": "http://arxiv.org/pdf/1308.4440v1", 
    "arxiv-id": "1308.4440v1"
},{
    "category": "cs.CV", 
    "author": "Siti Mariyam Shamsuddin", 
    "title": "A review on handwritten character and numeral recognition for Roman,   Arabic, Chinese and Indian scripts", 
    "publish": "2013-08-22T15:38:15Z", 
    "summary": "There are a lot of intensive researches on handwritten character recognition\n(HCR) for almost past four decades. The research has been done on some of\npopular scripts such as Roman, Arabic, Chinese and Indian. In this paper we\npresent a review on HCR work on the four popular scripts. We have summarized\nmost of the published paper from 2005 to recent and also analyzed the various\nmethods in creating a robust HCR system. We also added some future direction of\nresearch on HCR.", 
    "link": "http://arxiv.org/pdf/1308.4902v1", 
    "arxiv-id": "1308.4902v1"
},{
    "category": "cs.CV", 
    "author": "Yan Zhang", 
    "title": "Suspicious Object Recognition Method in Video Stream Based on Visual   Attention", 
    "publish": "2013-08-23T07:26:56Z", 
    "summary": "We propose a state of the art method for intelligent object recognition and\nvideo surveillance based on human visual attention. Bottom up and top down\nattention are applied respectively in the process of acquiring interested\nobject(saliency map) and object recognition. The revision of 4 channel PFT\nmethod is proposed for bottom up attention and enhances the speed and accuracy.\nInhibit of return (IOR) is applied in judging the sequence of saliency object\npop out. Euclidean distance of color distribution, object center coordinates\nand speed are considered in judging whether the target is match and suspicious.\nThe extensive tests on videos and images show that our method in video analysis\nhas high accuracy and fast speed compared with traditional method. The method\ncan be applied into many fields such as video surveillance and security.", 
    "link": "http://arxiv.org/pdf/1308.5063v1", 
    "arxiv-id": "1308.5063v1"
},{
    "category": "cs.CV", 
    "author": "Amelia Carolina Sparavigna", 
    "title": "Edge-detection applied to moving sand dunes on Mars", 
    "publish": "2013-08-24T11:07:05Z", 
    "summary": "Here we discuss the application of an edge detection filter, the Sobel filter\nof GIMP, to the recently discovered motion of some sand dunes on Mars. The\nfilter allows a good comparison of an image HiRISE of 2007 and an image of 1999\nrecorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,\nmeasuring therefore the motion of the dunes on a longer period of time than\nthat previously investigated.", 
    "link": "http://arxiv.org/pdf/1308.5315v1", 
    "arxiv-id": "1308.5315v1"
},{
    "category": "cs.CV", 
    "author": "Shabnam Bibi", 
    "title": "Hierarchized block wise image approximation by greedy pursuit strategies", 
    "publish": "2013-08-27T13:57:16Z", 
    "summary": "An approach for effective implementation of greedy selection methodologies,\nto approximate an image partitioned into blocks, is proposed. The method is\nspecially designed for approximating partitions on a transformed image. It\nevolves by selecting, at each iteration step, i) the elements for approximating\neach of the blocks partitioning the image and ii) the hierarchized sequence in\nwhich the blocks are approximated to reach the required global condition on\nsparsity.", 
    "link": "http://arxiv.org/pdf/1308.5876v1", 
    "arxiv-id": "1308.5876v1"
},{
    "category": "cs.CV", 
    "author": "K. Palaniappan", 
    "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active   Contours", 
    "publish": "2013-08-28T04:48:00Z", 
    "summary": "Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.", 
    "link": "http://arxiv.org/pdf/1308.6056v1", 
    "arxiv-id": "1308.6056v1"
},{
    "category": "cs.CV", 
    "author": "Remy Mullot", 
    "title": "Text recognition in both ancient and cartographic documents", 
    "publish": "2013-08-28T20:59:55Z", 
    "summary": "This paper deals with the recognition and matching of text in both\ncartographic maps and ancient documents. The purpose of this work is to find\nsimilar text regions based on statistical and global features. A phase of\nnormalization is done first, in object to well categorize the same quantity of\ninformation. A phase of wordspotting is done next by combining local and global\nfeatures. We make different experiments by combining the different techniques\nof extracting features in order to obtain better results in recognition phase.\nWe applied fontspotting on both ancient documents and cartographic ones. We\nalso applied the wordspotting in which we adopted a new technique which tries\nto compare the images of character and not the entire images words. We present\nthe precision and recall values obtained with three methods for the new method\nof wordspotting applied on characters only.", 
    "link": "http://arxiv.org/pdf/1308.6309v1", 
    "arxiv-id": "1308.6309v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed Adel Alimi", 
    "title": "Categorizing ancient documents", 
    "publish": "2013-08-28T21:09:35Z", 
    "summary": "The analysis of historical documents is still a topical issue given the\nimportance of information that can be extracted and also the importance given\nby the institutions to preserve their heritage. The main idea in order to\ncharacterize the content of the images of ancient documents after attempting to\nclean the image is segmented blocks texts from the same image and tries to find\nsimilar blocks in either the same image or the entire image database. Most\napproaches of offline handwriting recognition proceed by segmenting words into\nsmaller pieces (usually characters) which are recognized separately.\nRecognition of a word then requires the recognition of all characters (OCR)\nthat compose it. Our work focuses mainly on the characterization of classes in\nimages of old documents. We use Som toolbox for finding classes in documents.\nWe applied also fractal dimensions and points of interest to categorize and\nmatch ancient documents.", 
    "link": "http://arxiv.org/pdf/1308.6311v1", 
    "arxiv-id": "1308.6311v1"
},{
    "category": "cs.CV", 
    "author": "Mohamed Adel Alimi", 
    "title": "A proposition of a robust system for historical document images   indexation", 
    "publish": "2013-08-28T21:37:08Z", 
    "summary": "Characterizing noisy or ancient documents is a challenging problem up to now.\nMany techniques have been done in order to effectuate feature extraction and\nimage indexation for such documents. Global approaches are in general less\nrobust and exact than local approaches. That's why, we propose in this paper, a\nhybrid system based on global approach(fractal dimension), and a local one\nbased on SIFT descriptor. The Scale Invariant Feature Transform seems to do\nwell with our application since it's rotation invariant and relatively robust\nto changing illumination.In the first step the calculation of fractal dimension\nis applied to images in order to eliminate images which have distant features\nthan image request characteristics. Next, the SIFT is applied to show which\nimages match well the request. However the average matching time using the\nhybrid approach is better than \"fractal dimension\" and \"SIFT descriptor\" if\nthey are used alone.", 
    "link": "http://arxiv.org/pdf/1308.6319v1", 
    "arxiv-id": "1308.6319v1"
},{
    "category": "cs.CV", 
    "author": "Hong Qiao", 
    "title": "GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure", 
    "publish": "2013-08-29T08:00:20Z", 
    "summary": "In this paper we propose the Graduated NonConvexity and Graduated Concavity\nProcedure (GNCGCP) as a general optimization framework to approximately solve\nthe combinatorial optimization problems on the set of partial permutation\nmatrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC)\nwhich realizes a convex relaxation and graduated concavity (GC) which realizes\na concave relaxation. It is proved that GNCGCP realizes exactly a type of\nconvex-concave relaxation procedure (CCRP), but with a much simpler formulation\nwithout needing convex or concave relaxation in an explicit way. Actually,\nGNCGCP involves only the gradient of the objective function and is therefore\nvery easy to use in practical applications. Two typical NP-hard problems,\n(sub)graph matching and quadratic assignment problem (QAP), are employed to\ndemonstrate its simplicity and state-of-the-art performance.", 
    "link": "http://arxiv.org/pdf/1308.6388v1", 
    "arxiv-id": "1308.6388v1"
},{
    "category": "cs.CV", 
    "author": "Nicolas Paparoditis", 
    "title": "A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of   Urban Facades from Heterogeneous Cartographic Data", 
    "publish": "2013-08-29T08:47:09Z", 
    "summary": "In this paper we present a practical approach for generating an\nocclusion-free textured 3D map of urban facades by the synergistic use of\nterrestrial images, 3D point clouds and area-based information. Particularly in\ndense urban environments, the high presence of urban objects in front of the\nfacades causes significant difficulties for several stages in computational\nbuilding modeling. Major challenges lie on the one hand in extracting complete\n3D facade quadrilateral delimitations and on the other hand in generating\nocclusion-free facade textures. For these reasons, we describe a\nstraightforward approach for completing and recovering facade geometry and\ntextures by exploiting the data complementarity of terrestrial multi-source\nimagery and area-based information.", 
    "link": "http://arxiv.org/pdf/1308.6401v1", 
    "arxiv-id": "1308.6401v1"
},{
    "category": "cs.CV", 
    "author": "David Zhang", 
    "title": "Image Set based Collaborative Representation for Face Recognition", 
    "publish": "2013-08-30T09:08:56Z", 
    "summary": "With the rapid development of digital imaging and communication technologies,\nimage set based face recognition (ISFR) is becoming increasingly important. One\nkey issue of ISFR is how to effectively and efficiently represent the query\nface image set by using the gallery face image sets. The set-to-set distance\nbased methods ignore the relationship between gallery sets, while representing\nthe query set images individually over the gallery sets ignores the correlation\nbetween query set images. In this paper, we propose a novel image set based\ncollaborative representation and classification method for ISFR. By modeling\nthe query set as a convex or regularized hull, we represent this hull\ncollaboratively over all the gallery sets. With the resolved representation\ncoefficients, the distance between the query set and each gallery set can then\nbe calculated for classification. The proposed model naturally and effectively\nextends the image based collaborative representation to an image set based one,\nand our extensive experiments on benchmark ISFR databases show the superiority\nof the proposed method to state-of-the-art ISFR methods under different set\nsizes in terms of both recognition rate and efficiency.", 
    "link": "http://arxiv.org/pdf/1308.6687v1", 
    "arxiv-id": "1308.6687v1"
},{
    "category": "cs.CV", 
    "author": "Olaf Hellwich", 
    "title": "Iterative Bilateral Filtering of Polarimetric SAR Data", 
    "publish": "2013-11-01T12:20:17Z", 
    "summary": "In this paper, we introduce an iterative speckle filtering method for\npolarimetric SAR (PolSAR) images based on the bilateral filter. To locally\nadapt to the spatial structure of images, this filter relies on pixel\nsimilarities in both spatial and radiometric domains. To deal with polarimetric\ndata, we study the use of similarities based on a statistical distance called\nKullback-Leibler divergence as well as two geodesic distances on Riemannian\nmanifolds. To cope with speckle, we propose to progressively refine the result\nthanks to an iterative scheme. Experiments are run over synthetic and\nexperimental data. First, simulations are generated to study the effects of\nfiltering parameters in terms of polarimetric reconstruction error, edge\npreservation and smoothing of homogeneous areas. Comparison with other methods\nshows that our approach compares well to other state of the art methods in the\nextraction of polarimetric information and shows superior performance for edge\nrestoration and noise smoothing. The filter is then applied to experimental\ndata sets from ESAR and FSAR sensors (DLR) at L-band and S-band, respectively.\nThese last experiments show the ability of the filter to restore structures\nsuch as buildings and roads and to preserve boundaries between regions while\nachieving a high amount of smoothing in homogeneous areas.", 
    "link": "http://arxiv.org/pdf/1311.0162v1", 
    "arxiv-id": "1311.0162v1"
},{
    "category": "cs.CV", 
    "author": "M. H. M. Krishna Prasad", 
    "title": "Quality Assessment of Pixel-Level ImageFusion Using Fuzzy Logic", 
    "publish": "2013-11-05T21:13:14Z", 
    "summary": "Image fusion is to reduce uncertainty and minimize redundancy in the output\nwhile maximizing relevant information from two or more images of a scene into a\nsingle composite image that is more informative and is more suitable for visual\nperception or processing tasks like medical imaging, remote sensing, concealed\nweapon detection, weather forecasting, biometrics etc. Image fusion combines\nregistered images to produce a high quality fused image with spatial and\nspectral information. The fused image with more information will improve the\nperformance of image analysis algorithms used in different applications. In\nthis paper, we proposed a fuzzy logic method to fuse images from different\nsensors, in order to enhance the quality and compared proposed method with two\nother methods i.e. image fusion using wavelet transform and weighted average\ndiscrete wavelet transform based image fusion using genetic algorithm (here\nonwards abbreviated as GA) along with quality evaluation parameters image\nquality index (IQI), mutual information measure (MIM), root mean square error\n(RMSE), peak signal to noise ratio (PSNR), fusion factor (FF), fusion symmetry\n(FS) and fusion index (FI) and entropy. The results obtained from proposed\nfuzzy based image fusion approach improves quality of fused image as compared\nto earlier reported methods, wavelet transform based image fusion and weighted\naverage discrete wavelet transform based image fusion using genetic algorithm.", 
    "link": "http://arxiv.org/pdf/1311.1223v1", 
    "arxiv-id": "1311.1223v1"
},{
    "category": "cs.CV", 
    "author": "Jiwen Lu", 
    "title": "Face Recognition via Globality-Locality Preserving Projections", 
    "publish": "2013-11-06T03:16:21Z", 
    "summary": "We present an improved Locality Preserving Projections (LPP) method, named\nGloablity-Locality Preserving Projections (GLPP), to preserve both the global\nand local geometric structures of data. In our approach, an additional\nconstraint of the geometry of classes is imposed to the objective function of\nconventional LPP for respecting some more global manifold structures. Moreover,\nwe formulate a two-dimensional extension of GLPP (2D-GLPP) as an example to\nshow how to extend GLPP with some other statistical techniques. We apply our\nworks to face recognition on four popular face databases, namely ORL, Yale,\nFERET and LFW-A databases, and extensive experimental results demonstrate that\nthe considered global manifold information can significantly improve the\nperformance of LPP and the proposed face recognition methods outperform the\nstate-of-the-arts.", 
    "link": "http://arxiv.org/pdf/1311.1279v1", 
    "arxiv-id": "1311.1279v1"
},{
    "category": "cs.CV", 
    "author": "Vibha Wali", 
    "title": "Biometric Signature Processing & Recognition Using Radial Basis Function   Network", 
    "publish": "2013-11-07T14:37:06Z", 
    "summary": "Automatic recognition of signature is a challenging problem which has\nreceived much attention during recent years due to its many applications in\ndifferent fields. Signature has been used for long time for verification and\nauthentication purpose. Earlier methods were manual but nowadays they are\ngetting digitized. This paper provides an efficient method to signature\nrecognition using Radial Basis Function Network. The network is trained with\nsample images in database. Feature extraction is performed before using them\nfor training. For testing purpose, an image is made to undergo\nrotation-translation-scaling correction and then given to network. The network\nsuccessfully identifies the original image and gives correct output for stored\ndatabase images also. The method provides recognition rate of approximately 80%\nfor 200 samples.", 
    "link": "http://arxiv.org/pdf/1311.1694v1", 
    "arxiv-id": "1311.1694v1"
},{
    "category": "cs.CV", 
    "author": "Yuri Boykov", 
    "title": "Efficient Regularization of Squared Curvature", 
    "publish": "2013-11-07T22:08:24Z", 
    "summary": "Curvature has received increased attention as an important alternative to\nlength based regularization in computer vision. In contrast to length, it\npreserves elongated structures and fine details. Existing approaches are either\ninefficient, or have low angular resolution and yield results with strong block\nartifacts. We derive a new model for computing squared curvature based on\nintegral geometry. The model counts responses of straight line triple cliques.\nThe corresponding energy decomposes into submodular and supermodular pairwise\npotentials. We show that this energy can be efficiently minimized even for high\nangular resolutions using the trust region framework. Our results confirm that\nwe obtain accurate and visually pleasing solutions without strong artifacts at\nreasonable run times.", 
    "link": "http://arxiv.org/pdf/1311.1838v2", 
    "arxiv-id": "1311.1838v2"
},{
    "category": "cs.CV", 
    "author": "Andrew Delong", 
    "title": "Submodularization for Quadratic Pseudo-Boolean Optimization", 
    "publish": "2013-11-08T00:29:44Z", 
    "summary": "Many computer vision problems require optimization of binary non-submodular\nenergies. We propose a general optimization framework based on local submodular\napproximations (LSA). Unlike standard LP relaxation methods that linearize the\nwhole energy globally, our approach iteratively approximates the energies\nlocally. On the other hand, unlike standard local optimization methods (e.g.\ngradient descent or projection techniques) we use non-linear submodular\napproximations and optimize them without leaving the domain of integer\nsolutions. We discuss two specific LSA algorithms based on \"trust region\" and\n\"auxiliary function\" principles, LSA-TR and LSA-AUX. These methods obtain\nstate-of-the-art results on a wide range of applications outperforming many\nstandard techniques such as LBP, QPBO, and TRWS. While our paper is focused on\npairwise energies, our ideas extend to higher-order problems. The code is\navailable online (http://vision.csd.uwo.ca/code/).", 
    "link": "http://arxiv.org/pdf/1311.1856v2", 
    "arxiv-id": "1311.1856v2"
},{
    "category": "cs.CV", 
    "author": "David Zhang", 
    "title": "Fast Tracking via Spatio-Temporal Context Learning", 
    "publish": "2013-11-08T11:29:15Z", 
    "summary": "In this paper, we present a simple yet fast and robust algorithm which\nexploits the spatio-temporal context for visual tracking. Our approach\nformulates the spatio-temporal relationships between the object of interest and\nits local context based on a Bayesian framework, which models the statistical\ncorrelation between the low-level features (i.e., image intensity and position)\nfrom the target and its surrounding regions. The tracking problem is posed by\ncomputing a confidence map, and obtaining the best target location by\nmaximizing an object location likelihood function. The Fast Fourier Transform\nis adopted for fast learning and detection in this work. Implemented in MATLAB\nwithout code optimization, the proposed tracker runs at 350 frames per second\non an i7 machine. Extensive experimental results show that the proposed\nalgorithm performs favorably against state-of-the-art methods in terms of\nefficiency, accuracy and robustness.", 
    "link": "http://arxiv.org/pdf/1311.1939v1", 
    "arxiv-id": "1311.1939v1"
},{
    "category": "cs.CV", 
    "author": "Humberto Sossa", 
    "title": "A new stopping criterion for the mean shift iterative algorithm", 
    "publish": "2013-11-08T16:27:19Z", 
    "summary": "The mean shift iterative algorithm was proposed in 2006, for using the\nentropy as a stopping criterion. From then on, a theoretical base has been\ndeveloped and a group of applications has been carried out using this\nalgorithm. This paper proposes a new stopping criterion for the mean shift\niterative algorithm, where stopping threshold via entropy is used now, but in\nanother way. Many segmentation experiments were carried out by utilizing\nstandard images and it was verified that a better segmentation was reached, and\nthat the algorithm had better stability. An analysis on the convergence,\nthrough a theorem, with the new stopping criterion was carried out. The goal of\nthis paper is to compare the new stopping criterion with the old criterion. For\nthis reason, the obtained results were not compared with other segmentation\napproaches, since with the old stopping criterion were previously carried out.", 
    "link": "http://arxiv.org/pdf/1311.2014v1", 
    "arxiv-id": "1311.2014v1"
},{
    "category": "cs.CV", 
    "author": "Yuri Boykov", 
    "title": "An Experimental Comparison of Trust Region and Level Sets", 
    "publish": "2013-11-08T22:49:07Z", 
    "summary": "High-order (non-linear) functionals have become very popular in segmentation,\nstereo and other computer vision problems. Level sets is a well established\ngeneral gradient descent framework, which is directly applicable to\noptimization of such functionals and widely used in practice. Recently, another\ngeneral optimization approach based on trust region methodology was proposed\nfor regional non-linear functionals. Our goal is a comprehensive experimental\ncomparison of these two frameworks in regard to practical efficiency,\nrobustness to parameters, and optimality. We experiment on a wide range of\nproblems with non-linear constraints on segment volume, appearance and shape.", 
    "link": "http://arxiv.org/pdf/1311.2102v1", 
    "arxiv-id": "1311.2102v1"
},{
    "category": "cs.CV", 
    "author": "Juli\u00e1n Velasco", 
    "title": "Neighborhood filters and the decreasing rearrangement", 
    "publish": "2013-11-09T17:53:22Z", 
    "summary": "Nonlocal filters are simple and powerful techniques for image denoising. In\nthis paper, we give new insights into the analysis of one kind of them, the\nNeighborhood filter, by using a classical although not very common\ntransformation: the decreasing rearrangement of a function (the image).\nIndependently of the dimension of the image, we reformulate the Neighborhood\nfilter and its iterative variants as an integral operator defined in a\none-dimensional space. The simplicity of this formulation allows to perform a\ndetailed analysis of its properties. Among others, we prove that the filter\nbehaves asymptotically as a shock filter combined with a border diffusive term,\nresponsible for the staircaising effect and the loss of contrast.", 
    "link": "http://arxiv.org/pdf/1311.2191v2", 
    "arxiv-id": "1311.2191v2"
},{
    "category": "cs.CV", 
    "author": "Jean Gallier", 
    "title": "Notes on Elementary Spectral Graph Theory. Applications to Graph   Clustering Using Normalized Cuts", 
    "publish": "2013-11-11T16:45:03Z", 
    "summary": "These are notes on the method of normalized graph cuts and its applications\nto graph clustering. I provide a fairly thorough treatment of this deeply\noriginal method due to Shi and Malik, including complete proofs. I include the\nnecessary background on graphs and graph Laplacians. I then explain in detail\nhow the eigenvectors of the graph Laplacian can be used to draw a graph. This\nis an attractive application of graph Laplacians. The main thrust of this paper\nis the method of normalized cuts. I give a detailed account for K = 2 clusters,\nand also for K > 2 clusters, based on the work of Yu and Shi. Three points that\ndo not appear to have been clearly articulated before are elaborated:\n  1. The solutions of the main optimization problem should be viewed as tuples\nin the K-fold cartesian product of projective space RP^{N-1}.\n  2. When K > 2, the solutions of the relaxed problem should be viewed as\nelements of the Grassmannian G(K,N).\n  3. Two possible Riemannian distances are available to compare the closeness\nof solutions: (a) The distance on (RP^{N-1})^K. (b) The distance on the\nGrassmannian.\n  I also clarify what should be the necessary and sufficient conditions for a\nmatrix to represent a partition of the vertices of a graph to be clustered.", 
    "link": "http://arxiv.org/pdf/1311.2492v1", 
    "arxiv-id": "1311.2492v1"
},{
    "category": "cs.CV", 
    "author": "Jitendra Malik", 
    "title": "Rich feature hierarchies for accurate object detection and semantic   segmentation", 
    "publish": "2013-11-11T18:43:49Z", 
    "summary": "Object detection performance, as measured on the canonical PASCAL VOC\ndataset, has plateaued in the last few years. The best-performing methods are\ncomplex ensemble systems that typically combine multiple low-level image\nfeatures with high-level context. In this paper, we propose a simple and\nscalable detection algorithm that improves mean average precision (mAP) by more\nthan 30% relative to the previous best result on VOC 2012---achieving a mAP of\n53.3%. Our approach combines two key insights: (1) one can apply high-capacity\nconvolutional neural networks (CNNs) to bottom-up region proposals in order to\nlocalize and segment objects and (2) when labeled training data is scarce,\nsupervised pre-training for an auxiliary task, followed by domain-specific\nfine-tuning, yields a significant performance boost. Since we combine region\nproposals with CNNs, we call our method R-CNN: Regions with CNN features. We\nalso compare R-CNN to OverFeat, a recently proposed sliding-window detector\nbased on a similar CNN architecture. We find that R-CNN outperforms OverFeat by\na large margin on the 200-class ILSVRC2013 detection dataset. Source code for\nthe complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.", 
    "link": "http://arxiv.org/pdf/1311.2524v5", 
    "arxiv-id": "1311.2524v5"
},{
    "category": "cs.CV", 
    "author": "P. A Nogueira", 
    "title": "Determining Leishmania Infection Levels by Automatic Analysis of   Microscopy Images", 
    "publish": "2013-11-11T21:42:51Z", 
    "summary": "Analysis of microscopy images is one important tool in many fields of\nbiomedical research, as it allows the quantification of a multitude of\nparameters at the cellular level. However, manual counting of these images is\nboth tiring and unreliable and ultimately very time-consuming for biomedical\nresearchers. Not only does this slow down the overall research process, it also\nintroduces counting errors due to a lack of objectivity and consistency\ninherent to the researchers own human nature.\n  This thesis addresses this issue by automatically determining infection\nindexes of macrophages parasite by Leishmania in microscopy images using\ncomputer vision and pattern recognition methodologies. Initially images are\nsubmitted to a pre-processing stage that consists in a normalization of\nillumination conditions. Three algorithms are then applied in parallel to each\nimage. Algorithm A intends to detect macrophage nuclei and consists of\nsegmentation via adaptive multi-threshold, and classification of resulting\nregions using a set of collected features. Algorithm B intends to detect\nparasites and is similar to Algorithm A but the adaptive multi-threshold is\nparameterized with a different constraints vector. Algorithm C intends to\ndetect the macrophages and parasites cytoplasm and consists of a cut-off\nversion of the previous two algorithms, where the classification step is\nskipped. Regions with multiple nuclei or parasites are processed by a voting\nsystem that employs both a Support Vector Machine and a set of region features\nfor determining the number of objects present in each region. The previous vote\nis then taken into account as the number of mixtures to be used in a Gaussian\nMixture Model to decluster the said region. Finally each parasite is assigned\nto, at most, a single macrophage using minimum Euclidean distance to a cell\nnucleus, thus quantifying Leishmania infection levels.", 
    "link": "http://arxiv.org/pdf/1311.2621v1", 
    "arxiv-id": "1311.2621v1"
},{
    "category": "cs.CV", 
    "author": "S. Soatto", 
    "title": "Second-order Shape Optimization for Geometric Inverse Problems in Vision", 
    "publish": "2013-11-11T21:53:28Z", 
    "summary": "We develop a method for optimization in shape spaces, i.e., sets of surfaces\nmodulo re-parametrization. Unlike previously proposed gradient flows, we\nachieve superlinear convergence rates through a subtle approximation of the\nshape Hessian, which is generally hard to compute and suffers from a series of\ndegeneracies. Our analysis highlights the role of mean curvature motion in\ncomparison with first-order schemes: instead of surface area, our approach\npenalizes deformation, either by its Dirichlet energy or total variation.\nLatter regularizer sparks the development of an alternating direction method of\nmultipliers on triangular meshes. Therein, a conjugate-gradients solver enables\nus to bypass formation of the Gaussian normal equations appearing in the course\nof the overall optimization. We combine all of the aforementioned ideas in a\nversatile geometric variation-regularized Levenberg-Marquardt-type method\napplicable to a variety of shape functionals, depending on intrinsic properties\nof the surface such as normal field and curvature as well as its embedding into\nspace. Promising experimental results are reported.", 
    "link": "http://arxiv.org/pdf/1311.2626v5", 
    "arxiv-id": "1311.2626v5"
},{
    "category": "cs.CV", 
    "author": "S. Soatto", 
    "title": "Volumetric Reconstruction Applied to Perceptual Studies of Size and   Weight", 
    "publish": "2013-11-11T22:59:33Z", 
    "summary": "We explore the application of volumetric reconstruction from structured-light\nsensors in cognitive neuroscience, specifically in the quantification of the\nsize-weight illusion, whereby humans tend to systematically perceive smaller\nobjects as heavier. We investigate the performance of two commercial\nstructured-light scanning systems in comparison to one we developed\nspecifically for this application. Our method has two main distinct features:\nFirst, it only samples a sparse series of viewpoints, unlike other systems such\nas the Kinect Fusion. Second, instead of building a distance field for the\npurpose of points-to-surface conversion directly, we pursue a first-order\napproach: the distance function is recovered from its gradient by a screened\nPoisson reconstruction, which is very resilient to noise and yet preserves\nhigh-frequency signal components. Our experiments show that the quality of\nmetric reconstruction from structured light sensors is subject to systematic\nbiases, and highlights the factors that influence it. Our main performance\nindex rates estimates of volume (a proxy of size), for which we review a\nwell-known formula applicable to incomplete meshes. Our code and data will be\nmade publicly available upon completion of the anonymous review process.", 
    "link": "http://arxiv.org/pdf/1311.2642v1", 
    "arxiv-id": "1311.2642v1"
},{
    "category": "cs.CV", 
    "author": "Rob Fergus", 
    "title": "Visualizing and Understanding Convolutional Networks", 
    "publish": "2013-11-12T20:02:22Z", 
    "summary": "Large Convolutional Network models have recently demonstrated impressive\nclassification performance on the ImageNet benchmark. However there is no clear\nunderstanding of why they perform so well, or how they might be improved. In\nthis paper we address both issues. We introduce a novel visualization technique\nthat gives insight into the function of intermediate feature layers and the\noperation of the classifier. We also perform an ablation study to discover the\nperformance contribution from different model layers. This enables us to find\nmodel architectures that outperform Krizhevsky \\etal on the ImageNet\nclassification benchmark. We show our ImageNet model generalizes well to other\ndatasets: when the softmax classifier is retrained, it convincingly beats the\ncurrent state-of-the-art results on Caltech-101 and Caltech-256 datasets.", 
    "link": "http://arxiv.org/pdf/1311.2901v3", 
    "arxiv-id": "1311.2901v3"
},{
    "category": "cs.CV", 
    "author": "V. J. Vijayalakshmi", 
    "title": "An Efficient Method for Recognizing the Low Quality Fingerprint   Verification by Means of Cross Correlation", 
    "publish": "2013-11-13T10:50:14Z", 
    "summary": "In this paper, we propose an efficient method to provide personal\nidentification using fingerprint to get better accuracy even in noisy\ncondition. The fingerprint matching based on the number of corresponding\nminutia pairings, has been in use for a long time, which is not very efficient\nfor recognizing the low quality fingerprints. To overcome this problem,\ncorrelation technique is used. The correlation-based fingerprint verification\nsystem is capable of dealing with low quality images from which no minutiae can\nbe extracted reliably and with fingerprints that suffer from non-uniform shape\ndistortions, also in case of damaged and partial images. Orientation Field\nMethodology (OFM) has been used as a preprocessing module, and it converts the\nimages into a field pattern based on the direction of the ridges, loops and\nbifurcations in the image of a fingerprint. The input image is then Cross\nCorrelated (CC) with all the images in the cluster and the highest correlated\nimage is taken as the output. The result gives a good recognition rate, as the\nproposed scheme uses Cross Correlation of Field Orientation (CCFO = OFM + CC)\nfor fingerprint identification.", 
    "link": "http://arxiv.org/pdf/1311.3076v1", 
    "arxiv-id": "1311.3076v1"
},{
    "category": "cs.CV", 
    "author": "Juli\u00e1n Velasco", 
    "title": "On a non-local spectrogram for denoising one-dimensional signals", 
    "publish": "2013-11-13T19:46:06Z", 
    "summary": "In previous works, we investigated the use of local filters based on partial\ndifferential equations (PDE) to denoise one-dimensional signals through the\nimage processing of time-frequency representations, such as the spectrogram. In\nthis image denoising algorithms, the particularity of the image was hardly\ntaken into account. We turn, in this paper, to study the performance of\nnon-local filters, like Neighborhood or Yaroslavsky filters, in the same\nproblem. We show that, for certain iterative schemes involving the Neighborhood\nfilter, the computational time is drastically reduced with respect to\nYaroslavsky or nonlinear PDE based filters, while the outputs of the filtering\nprocesses are similar. This is heuristically justified by the connection\nbetween the (fast) Neighborhood filter applied to a spectrogram and the\ncorresponding Nonlocal Means filter (accurate) applied to the Wigner-Ville\ndistribution of the signal. This correspondence holds only for time-frequency\nrepresentations of one-dimensional signals, not to usual images, and in this\nsense the particularity of the image is exploited. We compare though a series\nof experiments on synthetic and biomedical signals the performance of local and\nnon-local filters.", 
    "link": "http://arxiv.org/pdf/1311.3269v1", 
    "arxiv-id": "1311.3269v1"
},{
    "category": "cs.CV", 
    "author": "Jason J. Corso", 
    "title": "A Study of Actor and Action Semantic Retention in Video Supervoxel   Segmentation", 
    "publish": "2013-11-13T21:58:55Z", 
    "summary": "Existing methods in the semantic computer vision community seem unable to\ndeal with the explosion and richness of modern, open-source and social video\ncontent. Although sophisticated methods such as object detection or\nbag-of-words models have been well studied, they typically operate on low level\nfeatures and ultimately suffer from either scalability issues or a lack of\nsemantic meaning. On the other hand, video supervoxel segmentation has recently\nbeen established and applied to large scale data processing, which potentially\nserves as an intermediate representation to high level video semantic\nextraction. The supervoxels are rich decompositions of the video content: they\ncapture object shape and motion well. However, it is not yet known if the\nsupervoxel segmentation retains the semantics of the underlying video content.\nIn this paper, we conduct a systematic study of how well the actor and action\nsemantics are retained in video supervoxel segmentation. Our study has human\nobservers watching supervoxel segmentation videos and trying to discriminate\nboth actor (human or animal) and action (one of eight everyday actions). We\ngather and analyze a large set of 640 human perceptions over 96 videos in 3\ndifferent supervoxel scales. Furthermore, we conduct machine recognition\nexperiments on a feature defined on supervoxel segmentation, called supervoxel\nshape context, which is inspired by the higher order processes in human\nperception. Our ultimate findings suggest that a significant amount of\nsemantics have been well retained in the video supervoxel segmentation and can\nbe used for further video analysis.", 
    "link": "http://arxiv.org/pdf/1311.3318v1", 
    "arxiv-id": "1311.3318v1"
},{
    "category": "cs.CV", 
    "author": "Richard Baraniuk", 
    "title": "The STONE Transform: Multi-Resolution Image Enhancement and Real-Time   Compressive Video", 
    "publish": "2013-11-14T07:54:28Z", 
    "summary": "Compressed sensing enables the reconstruction of high-resolution signals from\nunder-sampled data. While compressive methods simplify data acquisition, they\nrequire the solution of difficult recovery problems to make use of the\nresulting measurements. This article presents a new sensing framework that\ncombines the advantages of both conventional and compressive sensing. Using the\nproposed \\stone transform, measurements can be reconstructed instantly at\nNyquist rates at any power-of-two resolution. The same data can then be\n\"enhanced\" to higher resolutions using compressive methods that leverage\nsparsity to \"beat\" the Nyquist limit. The availability of a fast direct\nreconstruction enables compressive measurements to be processed on small\nembedded devices. We demonstrate this by constructing a real-time compressive\nvideo camera.", 
    "link": "http://arxiv.org/pdf/1311.3405v2", 
    "arxiv-id": "1311.3405v2"
},{
    "category": "cs.CV", 
    "author": "Andrea Vedaldi", 
    "title": "Describing Textures in the Wild", 
    "publish": "2013-11-14T19:28:35Z", 
    "summary": "Patterns and textures are defining characteristics of many natural objects: a\nshirt can be striped, the wings of a butterfly can be veined, and the skin of\nan animal can be scaly. Aiming at supporting this analytical dimension in image\nunderstanding, we address the challenging problem of describing textures with\nsemantic attributes. We identify a rich vocabulary of forty-seven texture terms\nand use them to describe a large dataset of patterns collected in the wild.The\nresulting Describable Textures Dataset (DTD) is the basis to seek for the best\ntexture representation for recognizing describable texture attributes in\nimages. We port from object recognition to texture recognition the Improved\nFisher Vector (IFV) and show that, surprisingly, it outperforms specialized\ntexture descriptors not only on our problem, but also in established material\nrecognition datasets. We also show that the describable attributes are\nexcellent texture descriptors, transferring between datasets and tasks; in\nparticular, combined with IFV, they significantly outperform the\nstate-of-the-art by more than 8 percent on both FMD and KTHTIPS-2b benchmarks.\nWe also demonstrate that they produce intuitive descriptions of materials and\nInternet images.", 
    "link": "http://arxiv.org/pdf/1311.3618v2", 
    "arxiv-id": "1311.3618v2"
},{
    "category": "cs.CV", 
    "author": "Holger Winnemoeller", 
    "title": "Recognizing Image Style", 
    "publish": "2013-11-15T03:37:50Z", 
    "summary": "The style of an image plays a significant role in how it is viewed, but style\nhas received little attention in computer vision research. We describe an\napproach to predicting style of images, and perform a thorough evaluation of\ndifferent image features for these tasks. We find that features learned in a\nmulti-layer network generally perform best -- even when trained with object\nclass (not style) labels. Our large-scale learning methods results in the best\npublished performance on an existing dataset of aesthetic ratings and\nphotographic style annotations. We present two novel datasets: 80K Flickr\nphotographs annotated with 20 curated style labels, and 85K paintings annotated\nwith 25 style/genre labels. Our approach shows excellent classification\nperformance on both datasets. We use the learned classifiers to extend\ntraditional tag-based image search to consider stylistic constraints, and\ndemonstrate cross-dataset understanding of style.", 
    "link": "http://arxiv.org/pdf/1311.3715v3", 
    "arxiv-id": "1311.3715v3"
},{
    "category": "cs.CV", 
    "author": "P. Nagabhushan", 
    "title": "Periodicity Extraction using Superposition of Distance Matching Function   and One-dimensional Haar Wavelet Transform", 
    "publish": "2013-11-15T11:02:39Z", 
    "summary": "Periodicity of a texture is one of the important visual characteristics and\nis often used as a measure for textural discrimination at the structural level.\nKnowledge about periodicity of a texture is very essential in the field of\ntexture synthesis and texture compression and also in the design of frieze and\nwall papers. In this paper, we propose a method of periodicity extraction from\nnoisy images based on superposition of distance matching function (DMF) and\nwavelet decomposition without de-noising the test images. Overall DMFs are\nsubjected to single-level Haar wavelet decomposition to obtain approximate and\ndetailed coefficients. Extracted coefficients help in determination of\nperiodicities in row and column directions. We illustrate the usefulness and\nthe effectiveness of the proposed method in a texture synthesis application.", 
    "link": "http://arxiv.org/pdf/1311.3808v1", 
    "arxiv-id": "1311.3808v1"
},{
    "category": "cs.CV", 
    "author": "Rob Fergus", 
    "title": "Blind Deconvolution with Non-local Sparsity Reweighting", 
    "publish": "2013-11-16T07:34:48Z", 
    "summary": "Blind deconvolution has made significant progress in the past decade. Most\nsuccessful algorithms are classified either as Variational or Maximum\na-Posteriori ($MAP$). In spite of the superior theoretical justification of\nvariational techniques, carefully constructed $MAP$ algorithms have proven\nequally effective in practice. In this paper, we show that all successful $MAP$\nand variational algorithms share a common framework, relying on the following\nkey principles: sparsity promotion in the gradient domain, $l_2$ regularization\nfor kernel estimation, and the use of convex (often quadratic) cost functions.\nOur observations lead to a unified understanding of the principles required for\nsuccessful blind deconvolution. We incorporate these principles into a novel\nalgorithm that improves significantly upon the state of the art.", 
    "link": "http://arxiv.org/pdf/1311.4029v2", 
    "arxiv-id": "1311.4029v2"
},{
    "category": "cs.CV", 
    "author": "Sanjeev Sharma", 
    "title": "A Comparative Study of Histogram Equalization Based Image Enhancement   Techniques for Brightness Preservation and Contrast Enhancement", 
    "publish": "2013-11-16T08:10:56Z", 
    "summary": "Histogram Equalization is a contrast enhancement technique in the image\nprocessing which uses the histogram of image. However histogram equalization is\nnot the best method for contrast enhancement because the mean brightness of the\noutput image is significantly different from the input image. There are several\nextensions of histogram equalization has been proposed to overcome the\nbrightness preservation challenge. Contrast enhancement using brightness\npreserving bi-histogram equalization (BBHE) and Dualistic sub image histogram\nequalization (DSIHE) which divides the image histogram into two parts based on\nthe input mean and median respectively then equalizes each sub histogram\nindependently. This paper provides review of different popular histogram\nequalization techniques and experimental study based on the absolute mean\nbrightness error (AMBE), peak signal to noise ratio (PSNR), Structure\nsimilarity index (SSI) and Entropy.", 
    "link": "http://arxiv.org/pdf/1311.4033v1", 
    "arxiv-id": "1311.4033v1"
},{
    "category": "cs.CV", 
    "author": "Tomaso Poggio", 
    "title": "Can a biologically-plausible hierarchy effectively replace face   detection, alignment, and recognition pipelines?", 
    "publish": "2013-11-16T17:49:31Z", 
    "summary": "The standard approach to unconstrained face recognition in natural\nphotographs is via a detection, alignment, recognition pipeline. While that\napproach has achieved impressive results, there are several reasons to be\ndissatisfied with it, among them is its lack of biological plausibility. A\nrecent theory of invariant recognition by feedforward hierarchical networks,\nlike HMAX, other convolutional networks, or possibly the ventral stream,\nimplies an alternative approach to unconstrained face recognition. This\napproach accomplishes detection and alignment implicitly by storing\ntransformations of training images (called templates) rather than explicitly\ndetecting and aligning faces at test time. Here we propose a particular\nlocality-sensitive hashing based voting scheme which we call \"consensus of\ncollisions\" and show that it can be used to approximate the full 3-layer\nhierarchy implied by the theory. The resulting end-to-end system for\nunconstrained face recognition operates on photographs of faces taken under\nnatural conditions, e.g., Labeled Faces in the Wild (LFW), without aligning or\ncropping them, as is normally done. It achieves a drastic improvement in the\nstate of the art on this end-to-end task, reaching the same level of\nperformance as the best systems operating on aligned, closely cropped images\n(no outside training data). It also performs well on two newer datasets,\nsimilar to LFW, but more difficult: LFW-jittered (new here) and SUFR-W.", 
    "link": "http://arxiv.org/pdf/1311.4082v3", 
    "arxiv-id": "1311.4082v3"
},{
    "category": "cs.CV", 
    "author": "Shraey Bhatia", 
    "title": "Comparative Study Of Image Edge Detection Algorithms", 
    "publish": "2013-11-20T06:22:53Z", 
    "summary": "Since edge detection is in the forefront of image processing for object\ndetection, it is crucial to have a good understanding of edge detection\nalgorithms. The reason for this is that edges form the outline of an object. An\nedge is the boundary between an object and the background, and indicates the\nboundary between overlapping objects. This means that if the edges in an image\ncan be identified accurately, all of the objects can be located and basic\nproperties such as area, perimeter, and shape can be measured. Since computer\nvision involves the identification and classification of objects in an image,\nedge detection is an essential tool. We tested two edge detectors that use\ndifferent methods for detecting edges and compared their results under a\nvariety of situations to determine which detector was preferable under\ndifferent sets of conditions.", 
    "link": "http://arxiv.org/pdf/1311.4963v2", 
    "arxiv-id": "1311.4963v2"
},{
    "category": "cs.CV", 
    "author": "Honggang Zhang", 
    "title": "Adaptive Learning of Region-based pLSA Model for Total Scene Annotation", 
    "publish": "2013-11-21T21:36:23Z", 
    "summary": "In this paper, we present a region-based pLSA model to accomplish the task of\ntotal scene annotation. To be more specific, we not only properly generate a\nlist of tags for each image, but also localizing each region with its\ncorresponding tag. We integrate advantages of different existing region-based\nworks: employ efficient and powerful JSEG algorithm for segmentation so that\neach region can easily express meaningful object information; the introduction\nof pLSA model can help better capturing semantic information behind the\nlow-level features. Moreover, we also propose an adaptive padding mechanism to\nautomatically choose the optimal padding strategy for each region, which\ndirectly increases the overall system performance. Finally we conduct 3\nexperiments to verify our ideas on Corel database and demonstrate the\neffectiveness and accuracy of our system.", 
    "link": "http://arxiv.org/pdf/1311.5590v1", 
    "arxiv-id": "1311.5590v1"
},{
    "category": "cs.CV", 
    "author": "Lubomir Bourdev", 
    "title": "PANDA: Pose Aligned Networks for Deep Attribute Modeling", 
    "publish": "2013-11-21T21:43:12Z", 
    "summary": "We propose a method for inferring human attributes (such as gender, hair\nstyle, clothes style, expression, action) from images of people under large\nvariation of viewpoint, pose, appearance, articulation and occlusion.\nConvolutional Neural Nets (CNN) have been shown to perform very well on large\nscale object recognition problems. In the context of attribute classification,\nhowever, the signal is often subtle and it may cover only a small part of the\nimage, while the image is dominated by the effects of pose and viewpoint.\nDiscounting for pose variation would require training on very large labeled\ndatasets which are not presently available. Part-based models, such as poselets\nand DPM have been shown to perform well for this problem but they are limited\nby shallow low-level features. We propose a new method which combines\npart-based models and deep learning by training pose-normalized CNNs. We show\nsubstantial improvement vs. state-of-the-art methods on challenging attribute\nclassification tasks in unconstrained settings. Experiments confirm that our\nmethod outperforms both the best part-based methods on this problem and\nconventional CNNs trained on the full bounding box of the person.", 
    "link": "http://arxiv.org/pdf/1311.5591v2", 
    "arxiv-id": "1311.5591v2"
},{
    "category": "cs.CV", 
    "author": "S L Happy", 
    "title": "Dynamic Model of Facial Expression Recognition based on Eigen-face   Approach", 
    "publish": "2013-11-23T15:40:37Z", 
    "summary": "Emotions are best way of communicating information; and sometimes it carry\nmore information than words. Recently, there has been a huge interest in\nautomatic recognition of human emotion because of its wide spread application\nin security, surveillance, marketing, advertisement, and human-computer\ninteraction. To communicate with a computer in a natural way, it will be\ndesirable to use more natural modes of human communication based on voice,\ngestures and facial expressions. In this paper, a holistic approach for facial\nexpression recognition is proposed which captures the variation in facial\nfeatures in temporal domain and classifies the sequence of images in different\nemotions. The proposed method uses Haar-like features to detect face in an\nimage. The dimensionality of the eigenspace is reduced using Principal\nComponent Analysis (PCA). By projecting the subsequent face images into\nprincipal eigen directions, the variation pattern of the obtained weight vector\nis modeled to classify it into different emotions. Owing to the variations of\nexpressions for different people and its intensity, a person specific method\nfor emotion recognition is followed. Using the gray scale images of the frontal\nface, the system is able to classify four basic emotions such as happiness,\nsadness, surprise, and anger.", 
    "link": "http://arxiv.org/pdf/1311.6007v1", 
    "arxiv-id": "1311.6007v1"
},{
    "category": "cs.CV", 
    "author": "Stefano Soatto", 
    "title": "On the Design and Analysis of Multiple View Descriptors", 
    "publish": "2013-11-23T20:38:50Z", 
    "summary": "We propose an extension of popular descriptors based on gradient orientation\nhistograms (HOG, computed in a single image) to multiple views. It hinges on\ninterpreting HOG as a conditional density in the space of sampled images, where\nthe effects of nuisance factors such as viewpoint and illumination are\nmarginalized. However, such marginalization is performed with respect to a very\ncoarse approximation of the underlying distribution. Our extension leverages on\nthe fact that multiple views of the same scene allow separating intrinsic from\nnuisance variability, and thus afford better marginalization of the latter. The\nresult is a descriptor that has the same complexity of single-view HOG, and can\nbe compared in the same manner, but exploits multiple views to better trade off\ninsensitivity to nuisance variability with specificity to intrinsic\nvariability. We also introduce a novel multi-view wide-baseline matching\ndataset, consisting of a mixture of real and synthetic objects with ground\ntruthed camera motion and dense three-dimensional geometry.", 
    "link": "http://arxiv.org/pdf/1311.6048v1", 
    "arxiv-id": "1311.6048v1"
},{
    "category": "cs.CV", 
    "author": "Zaid Abd Alkareem", 
    "title": "Skin Texture Recognition Using Neural Networks", 
    "publish": "2013-11-23T20:52:05Z", 
    "summary": "Skin recognition is used in many applications ranging from algorithms for\nface detection, hand gesture analysis, and to objectionable image filtering. In\nthis work a skin recognition system was developed and tested. While many skin\nsegmentation algorithms relay on skin color, our work relies on both skin color\nand texture features (features derives from the GLCM) to give a better and more\nefficient recognition accuracy of skin textures. We used feed forward neural\nnetworks to classify input textures images to be skin or non skin textures. The\nsystem gave very encouraging results during the neural network generalization\nface.", 
    "link": "http://arxiv.org/pdf/1311.6049v1", 
    "arxiv-id": "1311.6049v1"
},{
    "category": "cs.CV", 
    "author": "Camille Goudeseune", 
    "title": "Stitched Panoramas from Toy Airborne Video Cameras", 
    "publish": "2013-11-11T20:32:50Z", 
    "summary": "Effective panoramic photographs are taken from vantage points that are high.\nHigh vantage points have recently become easier to reach as the cost of\nquadrotor helicopters has dropped to nearly disposable levels. Although cameras\ncarried by such aircraft weigh only a few grams, their low-quality video can be\nconverted into panoramas of high quality and high resolution. Also, the small\nsize of these aircraft vastly reduces the risks inherent to flight.", 
    "link": "http://arxiv.org/pdf/1311.6500v1", 
    "arxiv-id": "1311.6500v1"
},{
    "category": "cs.CV", 
    "author": "V. Karthikeyan", 
    "title": "Hilditchs Algorithm Based Tamil Character Recognition", 
    "publish": "2013-11-19T08:38:50Z", 
    "summary": "Character identification plays a vital role in the contemporary world of\nImage processing. It can solve many composite problems and makes humans work\neasier. An instance is Handwritten Character detection. Handwritten recognition\nis not a novel expertise, but it has not gained community notice until Now. The\neventual aim of designing Handwritten Character recognition structure with an\naccurateness rate of 100% is pretty illusionary. Tamil Handwritten Character\nrecognition system uses the Neural Networks to distinguish them. Neural Network\nand structural characteristics are used to instruct and recognize written\ncharacters. After training and testing the exactness rate reached 99%. This\ncorrectness rate is extremely high. In this paper we are exploring image\nprocessing through the Hilditch algorithm foundation and structural\ncharacteristics of a character in the image. And we recognized some character\nof the Tamil language, and we are trying to identify all the character of Tamil\nIn our future works.", 
    "link": "http://arxiv.org/pdf/1311.6740v1", 
    "arxiv-id": "1311.6740v1"
},{
    "category": "cs.CV", 
    "author": "Jiri Matas", 
    "title": "Detection of Partially Visible Objects", 
    "publish": "2013-11-24T16:59:19Z", 
    "summary": "An \"elephant in the room\" for most current object detection and localization\nmethods is the lack of explicit modelling of partial visibility due to\nocclusion by other objects or truncation by the image boundary. Based on a\nsliding window approach, we propose a detection method which explicitly models\npartial visibility by treating it as a latent variable. A novel non-maximum\nsuppression scheme is proposed which takes into account the inferred partial\nvisibility of objects while providing a globally optimal solution. The method\ngives more detailed scene interpretations than conventional detectors in that\nwe are able to identify the visible parts of an object. We report improved\naverage precision on the PASCAL VOC 2010 dataset compared to a baseline\ndetector.", 
    "link": "http://arxiv.org/pdf/1311.6758v1", 
    "arxiv-id": "1311.6758v1"
},{
    "category": "cs.CV", 
    "author": "Kate Saenko", 
    "title": "Modeling Radiometric Uncertainty for Vision with Tone-mapped Color   Images", 
    "publish": "2013-11-27T07:39:27Z", 
    "summary": "To produce images that are suitable for display, tone-mapping is widely used\nin digital cameras to map linear color measurements into narrow gamuts with\nlimited dynamic range. This introduces non-linear distortion that must be\nundone, through a radiometric calibration process, before computer vision\nsystems can analyze such photographs radiometrically. This paper considers the\ninherent uncertainty of undoing the effects of tone-mapping. We observe that\nthis uncertainty varies substantially across color space, making some pixels\nmore reliable than others. We introduce a model for this uncertainty and a\nmethod for fitting it to a given camera or imaging pipeline. Once fit, the\nmodel provides for each pixel in a tone-mapped digital photograph a probability\ndistribution over linear scene colors that could have induced it. We\ndemonstrate how these distributions can be useful for visual inference by\nincorporating them into estimation algorithms for a representative set of\nvision tasks.", 
    "link": "http://arxiv.org/pdf/1311.6887v2", 
    "arxiv-id": "1311.6887v2"
},{
    "category": "cs.CV", 
    "author": "Luisa Verdoliva", 
    "title": "A novel framework for image forgery localization", 
    "publish": "2013-11-27T11:06:05Z", 
    "summary": "Image forgery localization is a very active and open research field for the\ndifficulty to handle the large variety of manipulations a malicious user can\nperform by means of more and more sophisticated image editing tools. Here, we\npropose a localization framework based on the fusion of three very different\ntools, based, respectively, on sensor noise, patch-matching, and machine\nlearning. The binary masks provided by these tools are finally fused based on\nsome suitable reliability indexes. According to preliminary experiments on the\ntraining set, the proposed framework provides often a very good localization\naccuracy and sometimes valuable clues for visual scrutiny.", 
    "link": "http://arxiv.org/pdf/1311.6932v1", 
    "arxiv-id": "1311.6932v1"
},{
    "category": "cs.CV", 
    "author": "Luisa Verdoliva", 
    "title": "Image forgery detection based on the fusion of machine learning and   block-matching methods", 
    "publish": "2013-11-27T11:17:55Z", 
    "summary": "Dense local descriptors and machine learning have been used with success in\nseveral applications, like classification of textures, steganalysis, and\nforgery detection. We develop a new image forgery detector building upon some\ndescriptors recently proposed in the steganalysis field suitably merging some\nof such descriptors, and optimizing a SVM classifier on the available training\nset. Despite the very good performance, very small forgeries are hardly ever\ndetected because they contribute very little to the descriptors. Therefore we\nalso develop a simple, but extremely specific, copy-move detector based on\nregion matching and fuse decisions so as to reduce the missing detection rate.\nOverall results appear to be extremely encouraging.", 
    "link": "http://arxiv.org/pdf/1311.6934v1", 
    "arxiv-id": "1311.6934v1"
},{
    "category": "cs.CV", 
    "author": "Nathan Brewer", 
    "title": "A Novel Illumination-Invariant Loss for Monocular 3D Pose Estimation", 
    "publish": "2013-11-28T01:54:50Z", 
    "summary": "The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision. Our proposed method of\nregistering a 3D model of a known object on a given 2D photo of the object has\nnumerous advantages over existing methods. It does not require prior training,\nknowledge of the camera parameters, explicit point correspondences or matching\nfeatures between the image and model. Unlike techniques that estimate a partial\n3D pose (as in an overhead view of traffic or machine parts on a conveyor\nbelt), our method estimates the complete 3D pose of the object. It works on a\nsingle static image from a given view under varying and unknown lighting\nconditions. For this purpose we derive a novel illumination-invariant distance\nmeasure between the 2D photo and projected 3D model, which is then minimised to\nfind the best pose parameters. Results for vehicle pose detection in real\nphotographs are presented.", 
    "link": "http://arxiv.org/pdf/1311.7186v1", 
    "arxiv-id": "1311.7186v1"
},{
    "category": "cs.CV", 
    "author": "Costantine D. Spyropoulos", 
    "title": "Unobtrusive Low Cost Pupil Size Measurements using Web cameras", 
    "publish": "2013-11-28T14:25:43Z", 
    "summary": "Unobtrusive every day health monitoring can be of important use for the\nelderly population. In particular, pupil size may be a valuable source of\ninformation, since, apart from pathological cases, it can reveal the emotional\nstate, the fatigue and the ageing. To allow for unobtrusive monitoring to gain\nacceptance, one should seek for efficient methods of monitoring using com- mon\nlow-cost hardware. This paper describes a method for monitoring pupil sizes\nusing a common web camera in real time. Our method works by first detecting the\nface and the eyes area. Subsequently, optimal iris and sclera location and\nradius, modelled as ellipses, are found using efficient filtering. Finally, the\npupil center and radius is estimated by optimal filtering within the area of\nthe iris. Experimental result show both the efficiency and the effectiveness of\nour approach.", 
    "link": "http://arxiv.org/pdf/1311.7327v1", 
    "arxiv-id": "1311.7327v1"
},{
    "category": "cs.CV", 
    "author": "Tolga Tasdizen", 
    "title": "Scene Labeling with Contextual Hierarchical Models", 
    "publish": "2014-02-04T02:10:01Z", 
    "summary": "Scene labeling is the problem of assigning an object label to each pixel. It\nunifies the image segmentation and object recognition problems. The importance\nof using contextual information in scene labeling frameworks has been widely\nrealized in the field. We propose a contextual framework, called contextual\nhierarchical model (CHM), which learns contextual information in a hierarchical\nframework for scene labeling. At each level of the hierarchy, a classifier is\ntrained based on downsampled input images and outputs of previous levels. Our\nmodel then incorporates the resulting multi-resolution contextual information\ninto a classifier to segment the input image at original resolution. This\ntraining strategy allows for optimization of a joint posterior probability at\nmultiple resolutions through the hierarchy. Contextual hierarchical model is\npurely based on the input image patches and does not make use of any fragments\nor shape examples. Hence, it is applicable to a variety of problems such as\nobject segmentation and edge detection. We demonstrate that CHM outperforms\nstate-of-the-art on Stanford background and Weizmann horse datasets. It also\noutperforms state-of-the-art edge detection methods on NYU depth dataset and\nachieves state-of-the-art on Berkeley segmentation dataset (BSDS 500).", 
    "link": "http://arxiv.org/pdf/1402.0595v1", 
    "arxiv-id": "1402.0595v1"
},{
    "category": "cs.CV", 
    "author": "Paul Wilford", 
    "title": "Signal to Noise Ratio in Lensless Compressive Imaging", 
    "publish": "2014-02-04T16:12:53Z", 
    "summary": "We analyze the signal to noise ratio (SNR) in a lensless compressive imaging\n(LCI) architecture. The architecture consists of a sensor of a single detecting\nelement and an aperture assembly of an array of programmable elements. LCI can\nbe used in conjunction with compressive sensing to capture images in a\ncompressed form of compressive measurements. In this paper, we perform SNR\nanalysis of the LCI and compare it with imaging with a pinhole or a lens. We\nwill show that the SNR in the LCI is independent of the image resolution, while\nthe SNR in either pinhole aperture imaging or lens aperture imaging decreases\nas the image resolution increases. Consequently, the SNR in the LCI is much\nhigher if the image resolution is large enough.", 
    "link": "http://arxiv.org/pdf/1402.0785v1", 
    "arxiv-id": "1402.0785v1"
},{
    "category": "cs.CV", 
    "author": "Ahmad Khajenezhad", 
    "title": "Patchwise Joint Sparse Tracking with Occlusion Detection", 
    "publish": "2014-02-05T09:08:11Z", 
    "summary": "This paper presents a robust tracking approach to handle challenges such as\nocclusion and appearance change. Here, the target is partitioned into a number\nof patches. Then, the appearance of each patch is modeled using a dictionary\ncomposed of corresponding target patches in previous frames. In each frame, the\ntarget is found among a set of candidates generated by a particle filter, via a\nlikelihood measure that is shown to be proportional to the sum of\npatch-reconstruction errors of each candidate. Since the target's appearance\noften changes slowly in a video sequence, it is assumed that the target in the\ncurrent frame and the best candidates of a small number of previous frames,\nbelong to a common subspace. This is imposed using joint sparse representation\nto enforce the target and previous best candidates to have a common sparsity\npattern. Moreover, an occlusion detection scheme is proposed that uses\npatch-reconstruction errors and a prior probability of occlusion, extracted\nfrom an adaptive Markov chain, to calculate the probability of occlusion per\npatch. In each frame, occluded patches are excluded when updating the\ndictionary. Extensive experimental results on several challenging sequences\nshows that the proposed method outperforms state-of-the-art trackers.", 
    "link": "http://arxiv.org/pdf/1402.0978v1", 
    "arxiv-id": "1402.0978v1"
},{
    "category": "cs.CV", 
    "author": "Andrzej Kasi\u0144ski", 
    "title": "Image Acquisition in an Underwater Vision System with NIR and VIS   Illumination", 
    "publish": "2014-02-05T20:18:26Z", 
    "summary": "The paper describes the image acquisition system able to capture images in\ntwo separated bands of light, used to underwater autonomous navigation. The\nchannels are: the visible light spectrum and near infrared spectrum. The\ncharacteristics of natural, underwater environment were also described together\nwith the process of the underwater image creation. The results of an experiment\nwith comparison of selected images acquired in these channels are discussed.", 
    "link": "http://arxiv.org/pdf/1402.1151v1", 
    "arxiv-id": "1402.1151v1"
},{
    "category": "cs.CV", 
    "author": "Tanusree Chatterjee", 
    "title": "An Estimation Method of Measuring Image Quality for Compressed Images of   Human Face", 
    "publish": "2014-02-06T11:58:42Z", 
    "summary": "Nowadays digital image compression and decompression techniques are very much\nimportant. So our aim is to calculate the quality of face and other regions of\nthe compressed image with respect to the original image. Image segmentation is\ntypically used to locate objects and boundaries (lines, curves etc.)in images.\nAfter segmentation the image is changed into something which is more meaningful\nto analyze. Using Universal Image Quality Index(Q),Structural Similarity\nIndex(SSIM) and Gradient-based Structural Similarity Index(G-SSIM) it can be\nshown that face region is less compressed than any other region of the image.", 
    "link": "http://arxiv.org/pdf/1402.1331v1", 
    "arxiv-id": "1402.1331v1"
},{
    "category": "cs.CV", 
    "author": "Jahangir Mohammed", 
    "title": "A Cellular Automata based Optimal Edge Detection Technique using   Twenty-Five Neighborhood Model", 
    "publish": "2014-02-06T13:32:39Z", 
    "summary": "Cellular Automata (CA) are common and most simple models of parallel\ncomputations. Edge detection is one of the crucial task in image processing,\nespecially in processing biological and medical images. CA can be successfully\napplied in image processing. This paper presents a new method for edge\ndetection of binary images based on two dimensional twenty five neighborhood\ncellular automata. The method considers only linear rules of CA for extraction\nof edges under null boundary condition. The performance of this approach is\ncompared with some existing edge detection techniques. This comparison shows\nthat the proposed method to be very promising for edge detection of binary\nimages. All the algorithms and results used in this paper are prepared in\nMATLAB.", 
    "link": "http://arxiv.org/pdf/1402.1348v1", 
    "arxiv-id": "1402.1348v1"
},{
    "category": "cs.CV", 
    "author": "Jeyarajan Thiyagalingam", 
    "title": "Real-time Pedestrian Surveillance with Top View Cumulative Grids", 
    "publish": "2014-02-06T14:09:25Z", 
    "summary": "This manuscript presents an efficient approach to map pedestrian surveillance\nfootage to an aerial view for global assessment of features. The analysis of\nthe footages relies on low level computer vision and enable real-time\nsurveillance. While we neglect object tracking, we introduce cumulative grids\non top view scene flow visualization to highlight situations of interest in the\nfootage. Our approach is tested on multiview footage both from RGB cameras and,\nfor the first time in the field, on RGB-D-sensors.", 
    "link": "http://arxiv.org/pdf/1402.1359v1", 
    "arxiv-id": "1402.1359v1"
},{
    "category": "cs.CV", 
    "author": "Marco Loog", 
    "title": "Quantile Representation for Indirect Immunofluorescence Image   Classification", 
    "publish": "2014-02-06T14:56:55Z", 
    "summary": "In the diagnosis of autoimmune diseases, an important task is to classify\nimages of slides containing several HEp-2 cells. All cells from one slide share\nthe same label, and by classifying cells from one slide independently, some\ninformation on the global image quality and intensity is lost. Considering one\nwhole slide as a collection (a bag) of feature vectors, however, poses the\nproblem of how to handle this bag. A simple, and surprisingly effective,\napproach is to summarize the bag of feature vectors by a few quantile values\nper feature. This characterizes the full distribution of all instances, thereby\nassuming that all instances in a bag are informative. This representation is\nparticularly useful when each bag contains many feature vectors, which is the\ncase in the classification of the immunofluorescence images. Experiments on the\nclassification of indirect immunofluorescence images show the usefulness of\nthis approach.", 
    "link": "http://arxiv.org/pdf/1402.1371v1", 
    "arxiv-id": "1402.1371v1"
},{
    "category": "cs.CV", 
    "author": "Anthony Yezzi", 
    "title": "Tracking via Motion Estimation with Physically Motivated Inter-Region   Constraints", 
    "publish": "2014-02-06T21:27:25Z", 
    "summary": "In this paper, we propose a method for tracking structures (e.g., ventricles\nand myocardium) in cardiac images (e.g., magnetic resonance) by propagating\nforward in time a previous estimate of the structures via a new deformation\nestimation scheme that is motivated by physical constraints of fluid motion.\nThe method employs within structure motion estimation (so that differing\nmotions among different structures are not mixed) while simultaneously\nsatisfying the physical constraint in fluid motion that at the interface\nbetween a fluid and a medium, the normal component of the fluid's motion must\nmatch the normal component of the motion of the medium. We show how to estimate\nthe motion according to the previous considerations in a variational framework,\nand in particular, show that these conditions lead to PDEs with boundary\nconditions at the interface that resemble Robin boundary conditions and induce\ncoupling between structures. We illustrate the use of this motion estimation\nscheme in propagating a segmentation across frames and show that it leads to\nmore accurate segmentation than traditional motion estimation that does not\nmake use of physical constraints. Further, the method is naturally suited to\ninteractive segmentation methods, which are prominently used in practice in\ncommercial applications for cardiac analysis, where typically a segmentation\nfrom the previous frame is used to predict a segmentation in the next frame. We\nshow that our propagation scheme reduces the amount of user interaction by\npredicting more accurate segmentations than commonly used and recent\ninteractive commercial techniques.", 
    "link": "http://arxiv.org/pdf/1402.1503v1", 
    "arxiv-id": "1402.1503v1"
},{
    "category": "cs.CV", 
    "author": "Yi Ma", 
    "title": "Sparse Illumination Learning and Transfer for Single-Sample Face   Recognition with Image Corruption and Misalignment", 
    "publish": "2014-02-08T18:46:28Z", 
    "summary": "Single-sample face recognition is one of the most challenging problems in\nface recognition. We propose a novel algorithm to address this problem based on\na sparse representation based classification (SRC) framework. The new algorithm\nis robust to image misalignment and pixel corruption, and is able to reduce\nrequired gallery images to one sample per class. To compensate for the missing\nillumination information traditionally provided by multiple gallery images, a\nsparse illumination learning and transfer (SILT) technique is introduced. The\nillumination in SILT is learned by fitting illumination examples of auxiliary\nface images from one or more additional subjects with a sparsely-used\nillumination dictionary. By enforcing a sparse representation of the query\nimage in the illumination dictionary, the SILT can effectively recover and\ntransfer the illumination and pose information from the alignment stage to the\nrecognition stage. Our extensive experiments have demonstrated that the new\nalgorithms significantly outperform the state of the art in the single-sample\nregime and with less restrictions. In particular, the single-sample face\nalignment accuracy is comparable to that of the well-known Deformable SRC\nalgorithm using multiple gallery images per class. Furthermore, the face\nrecognition accuracy exceeds those of the SRC and Extended SRC algorithms using\nhand labeled alignment initialization.", 
    "link": "http://arxiv.org/pdf/1402.1879v1", 
    "arxiv-id": "1402.1879v1"
},{
    "category": "cs.CV", 
    "author": "B. B. Chaudhuri", 
    "title": "Direct Processing of Run Length Compressed Document Image for   Segmentation and Characterization of a Specified Block", 
    "publish": "2014-02-09T18:01:12Z", 
    "summary": "Extracting a block of interest referred to as segmenting a specified block in\nan image and studying its characteristics is of general research interest, and\ncould be a challenging if such a segmentation task has to be carried out\ndirectly in a compressed image. This is the objective of the present research\nwork. The proposal is to evolve a method which would segment and extract a\nspecified block, and carry out its characterization without decompressing a\ncompressed image, for two major reasons that most of the image archives contain\nimages in compressed format and decompressing an image indents additional\ncomputing time and space. Specifically in this research work, the proposal is\nto work on run-length compressed document images.", 
    "link": "http://arxiv.org/pdf/1402.1971v2", 
    "arxiv-id": "1402.1971v2"
},{
    "category": "cs.CV", 
    "author": "Yisong Chen", 
    "title": "Foreground segmentation based on multi-resolution and matting", 
    "publish": "2014-02-10T01:22:35Z", 
    "summary": "We propose a foreground segmentation algorithm that does foreground\nextraction under different scales and refines the result by matting. First, the\ninput image is filtered and resampled to 5 different resolutions. Then each of\nthem is segmented by adaptive figure-ground classification and the best\nsegmentation is automatically selected by an evaluation score that maximizes\nthe difference between foreground and background. This segmentation is\nupsampled to the original size, and a corresponding trimap is built.\nClosed-form matting is employed to label the boundary region, and the result is\nrefined by a final figure-ground classification. Experiments show the success\nof our method in treating challenging images with cluttered background and\nadapting to loose initial bounding-box.", 
    "link": "http://arxiv.org/pdf/1402.2013v1", 
    "arxiv-id": "1402.2013v1"
},{
    "category": "cs.CV", 
    "author": "Dinesh Manocha", 
    "title": "Leveraging Long-Term Predictions and Online-Learning in Agent-based   Multiple Person Tracking", 
    "publish": "2014-02-10T02:07:07Z", 
    "summary": "We present a multiple-person tracking algorithm, based on combining particle\nfilters and RVO, an agent-based crowd model that infers collision-free\nvelocities so as to predict pedestrian's motion. In addition to position and\nvelocity, our tracking algorithm can estimate the internal goals (desired\ndestination or desired velocity) of the tracked pedestrian in an online manner,\nthus removing the need to specify this information beforehand. Furthermore, we\nleverage the longer-term predictions of RVO by deriving a higher-order particle\nfilter, which aggregates multiple predictions from different prior time steps.\nThis yields a tracker that can recover from short-term occlusions and spurious\nnoise in the appearance model. Experimental results show that our tracking\nalgorithm is suitable for predicting pedestrians' behaviors online without\nneeding scene priors or hand-annotated goal information, and improves tracking\nin real-world crowded scenes under low frame rates.", 
    "link": "http://arxiv.org/pdf/1402.2016v2", 
    "arxiv-id": "1402.2016v2"
},{
    "category": "cs.CV", 
    "author": "Shiqiang Yang", 
    "title": "Binary Stereo Matching", 
    "publish": "2014-02-10T02:33:39Z", 
    "summary": "In this paper, we propose a novel binary-based cost computation and\naggregation approach for stereo matching problem. The cost volume is\nconstructed through bitwise operations on a series of binary strings. Then this\napproach is combined with traditional winner-take-all strategy, resulting in a\nnew local stereo matching algorithm called binary stereo matching (BSM). Since\ncore algorithm of BSM is based on binary and integer computations, it has a\nhigher computational efficiency than previous methods. Experimental results on\nMiddlebury benchmark show that BSM has comparable performance with\nstate-of-the-art local stereo methods in terms of both quality and speed.\nFurthermore, experiments on images with radiometric differences demonstrate\nthat BSM is more robust than previous methods under these changes, which is\ncommon under real illumination.", 
    "link": "http://arxiv.org/pdf/1402.2020v1", 
    "arxiv-id": "1402.2020v1"
},{
    "category": "cs.CV", 
    "author": "P. M Dhanya", 
    "title": "Handwritten Character Recognition In Malayalam Scripts- A Review", 
    "publish": "2014-02-10T15:41:48Z", 
    "summary": "Handwritten character recognition is one of the most challenging and ongoing\nareas of research in the field of pattern recognition. HCR research is matured\nfor foreign languages like Chinese and Japanese but the problem is much more\ncomplex for Indian languages. The problem becomes even more complicated for\nSouth Indian languages due to its large character set and the presence of\nvowels modifiers and compound characters. This paper provides an overview of\nimportant contributions and advances in offline as well as online handwritten\ncharacter recognition of Malayalam scripts.", 
    "link": "http://arxiv.org/pdf/1402.2188v1", 
    "arxiv-id": "1402.2188v1"
},{
    "category": "cs.CV", 
    "author": "Yeshaiahu Fainman", 
    "title": "Imaging with Rays: Microscopy, Medical Imaging, and Computer Vision", 
    "publish": "2014-02-11T10:26:31Z", 
    "summary": "In this paper we broadly consider techniques which utilize projections on\nrays for data collection, with particular emphasis on optical techniques. We\nformulate a variety of imaging techniques as either special cases or extensions\nof tomographic reconstruction. We then consider how the techniques must be\nextended to describe objects containing occlusion, as with a self-occluding\nopaque object. We formulate the reconstruction problem as a regularized\nnonlinear optimization problem to simultaneously solve for object brightness\nand attenuation, where the attenuation can become infinite. We demonstrate\nvarious simulated examples for imaging opaque objects, including sparse point\nsources, a conventional multiview reconstruction technique, and a\nsuper-resolving technique which exploits occlusion to resolve an image.", 
    "link": "http://arxiv.org/pdf/1402.2426v1", 
    "arxiv-id": "1402.2426v1"
},{
    "category": "cs.CV", 
    "author": "Dibyendu Mukherjee", 
    "title": "A Fast Two Pass Multi-Value Segmentation Algorithm based on Connected   Component Analysis", 
    "publish": "2014-02-11T19:27:05Z", 
    "summary": "Connected component analysis (CCA) has been heavily used to label binary\nimages and classify segments. However, it has not been well-exploited to\nsegment multi-valued natural images. This work proposes a novel multi-value\nsegmentation algorithm that utilizes CCA to segment color images. A user\ndefined distance measure is incorporated in the proposed modified CCA to\nidentify and segment similar image regions. The raw output of the algorithm\nconsists of distinctly labelled segmented regions. The proposed algorithm has a\nunique design architecture that provides several benefits: 1) it can be used to\nsegment any multi-channel multi-valued image; 2) the distance\nmeasure/segmentation criteria can be application-specific and 3) an absolute\nlinear-time implementation allows easy extension for real-time video\nsegmentation. Experimental demonstrations of the aforesaid benefits are\npresented along with the comparison results on multiple datasets with current\nbenchmark algorithms. A number of possible application areas are also\nidentified and results on real-time video segmentation has been presented to\nshow the promise of the proposed method.", 
    "link": "http://arxiv.org/pdf/1402.2606v1", 
    "arxiv-id": "1402.2606v1"
},{
    "category": "cs.CV", 
    "author": "Michal Kawulok", 
    "title": "Real-Time Hand Shape Classification", 
    "publish": "2014-02-11T21:32:48Z", 
    "summary": "The problem of hand shape classification is challenging since a hand is\ncharacterized by a large number of degrees of freedom. Numerous shape\ndescriptors have been proposed and applied over the years to estimate and\nclassify hand poses in reasonable time. In this paper we discuss our parallel\nframework for real-time hand shape classification applicable in real-time\napplications. We show how the number of gallery images influences the\nclassification accuracy and execution time of the parallel algorithm. We\npresent the speedup and efficiency analyses that prove the efficacy of the\nparallel implementation. Noteworthy, different methods can be used at each step\nof our parallel framework. Here, we combine the shape contexts with the\nappearance-based techniques to enhance the robustness of the algorithm and to\nincrease the classification score. An extensive experimental study proves the\nsuperiority of the proposed approach over existing state-of-the-art methods.", 
    "link": "http://arxiv.org/pdf/1402.2673v1", 
    "arxiv-id": "1402.2673v1"
},{
    "category": "cs.CV", 
    "author": "Qi Tian", 
    "title": "Packing and Padding: Coupled Multi-index for Accurate Image Retrieval", 
    "publish": "2014-02-11T22:00:31Z", 
    "summary": "In Bag-of-Words (BoW) based image retrieval, the SIFT visual word has a low\ndiscriminative power, so false positive matches occur prevalently. Apart from\nthe information loss during quantization, another cause is that the SIFT\nfeature only describes the local gradient distribution. To address this\nproblem, this paper proposes a coupled Multi-Index (c-MI) framework to perform\nfeature fusion at indexing level. Basically, complementary features are coupled\ninto a multi-dimensional inverted index. Each dimension of c-MI corresponds to\none kind of feature, and the retrieval process votes for images similar in both\nSIFT and other feature spaces. Specifically, we exploit the fusion of local\ncolor feature into c-MI. While the precision of visual match is greatly\nenhanced, we adopt Multiple Assignment to improve recall. The joint cooperation\nof SIFT and color features significantly reduces the impact of false positive\nmatches.\n  Extensive experiments on several benchmark datasets demonstrate that c-MI\nimproves the retrieval accuracy significantly, while consuming only half of the\nquery time compared to the baseline. Importantly, we show that c-MI is well\ncomplementary to many prior techniques. Assembling these methods, we have\nobtained an mAP of 85.8% and N-S score of 3.85 on Holidays and Ukbench\ndatasets, respectively, which compare favorably with the state-of-the-arts.", 
    "link": "http://arxiv.org/pdf/1402.2681v2", 
    "arxiv-id": "1402.2681v2"
},{
    "category": "cs.CV", 
    "author": "Paul Wilford", 
    "title": "Noise Analysis for Lensless Compressive Imaging", 
    "publish": "2014-02-12T03:12:40Z", 
    "summary": "We analyze the signal to noise ratio (SNR) in a recently proposed lensless\ncompressive imaging architecture. The architecture consists of a sensor of a\nsingle detector element and an aperture assembly of an array of aperture\nelements, each of which has a programmable transmittance. This lensless\ncompressive imaging architecture can be used in conjunction with compressive\nsensing to capture images in a compressed form of compressive measurements. In\nthis paper, we perform noise analysis of this lensless compressive imaging\narchitecture and compare it with pinhole aperture imaging and lens aperture\nimaging. We will show that the SNR in the lensless compressive imaging is\nindependent of the image resolution, while that in either pinhole aperture\nimaging or lens aperture imaging decreases as the image resolution increases.\nConsequently, the SNR in the lensless compressive imaging can be much higher if\nthe image resolution is large enough.", 
    "link": "http://arxiv.org/pdf/1402.2720v1", 
    "arxiv-id": "1402.2720v1"
},{
    "category": "cs.CV", 
    "author": "Dinesh Manocha", 
    "title": "Realtime Multilevel Crowd Tracking using Reciprocal Velocity Obstacles", 
    "publish": "2014-02-11T15:49:53Z", 
    "summary": "We present a novel, realtime algorithm to compute the trajectory of each\npedestrian in moderately dense crowd scenes. Our formulation is based on an\nadaptive particle filtering scheme that uses a multi-agent motion model based\non velocity-obstacles, and takes into account local interactions as well as\nphysical and personal constraints of each pedestrian. Our method dynamically\nchanges the number of particles allocated to each pedestrian based on different\nconfidence metrics. Additionally, we use a new high-definition crowd video\ndataset, which is used to evaluate the performance of different pedestrian\ntracking algorithms. This dataset consists of videos of indoor and outdoor\nscenes, recorded at different locations with 30-80 pedestrians. We highlight\nthe performance benefits of our algorithm over prior techniques using this\ndataset. In practice, our algorithm can compute trajectories of tens of\npedestrians on a multi-core desktop CPU at interactive rates (27-30 frames per\nsecond). To the best of our knowledge, our approach is 4-5 times faster than\nprior methods, which provide similar accuracy.", 
    "link": "http://arxiv.org/pdf/1402.2826v1", 
    "arxiv-id": "1402.2826v1"
},{
    "category": "cs.CV", 
    "author": "Ajmal Mian", 
    "title": "Multispectral Palmprint Encoding and Recognition", 
    "publish": "2014-02-06T06:35:51Z", 
    "summary": "Palmprints are emerging as a new entity in multi-modal biometrics for human\nidentification and verification. Multispectral palmprint images captured in the\nvisible and infrared spectrum not only contain the wrinkles and ridge structure\nof a palm, but also the underlying pattern of veins; making them a highly\ndiscriminating biometric identifier. In this paper, we propose a feature\nencoding scheme for robust and highly accurate representation and matching of\nmultispectral palmprints. To facilitate compact storage of the feature, we\ndesign a binary hash table structure that allows for efficient matching in\nlarge databases. Comprehensive experiments for both identification and\nverification scenarios are performed on two public datasets -- one captured\nwith a contact-based sensor (PolyU dataset), and the other with a contact-free\nsensor (CASIA dataset). Recognition results in various experimental setups show\nthat the proposed method consistently outperforms existing state-of-the-art\nmethods. Error rates achieved by our method (0.003% on PolyU and 0.2% on CASIA)\nare the lowest reported in literature on both dataset and clearly indicate the\nviability of palmprint as a reliable and promising biometric. All source codes\nare publicly available.", 
    "link": "http://arxiv.org/pdf/1402.2941v1", 
    "arxiv-id": "1402.2941v1"
},{
    "category": "cs.CV", 
    "author": "Truong Nguyen", 
    "title": "Improving Streaming Video Segmentation with Early and Mid-Level Visual   Processing", 
    "publish": "2014-02-14T19:37:35Z", 
    "summary": "Despite recent advances in video segmentation, many opportunities remain to\nimprove it using a variety of low and mid-level visual cues. We propose\nimprovements to the leading streaming graph-based hierarchical video\nsegmentation (streamGBH) method based on early and mid level visual processing.\nThe extensive experimental analysis of our approach validates the improvement\nof hierarchical supervoxel representation by incorporating motion and color\nwith effective filtering. We also pose and illuminate some open questions\ntowards intermediate level video analysis as further extension to streamGBH. We\nexploit the supervoxels as an initialization towards estimation of dominant\naffine motion regions, followed by merging of such motion regions in order to\nhierarchically segment a video in a novel motion-segmentation framework which\naims at subsequent applications such as foreground recognition.", 
    "link": "http://arxiv.org/pdf/1402.3557v1", 
    "arxiv-id": "1402.3557v1"
},{
    "category": "cs.CV", 
    "author": "Yilun Wang", 
    "title": "FTVd is beyond Fast Total Variation regularized Deconvolution", 
    "publish": "2014-02-17T02:13:30Z", 
    "summary": "In this paper, we revisit the \"FTVd\" algorithm for Fast Total Variation\nRegularized Deconvolution, which has been widely used in the past few years.\nBoth its original version implemented in the MATLAB software FTVd 3.0 and its\nrelated variant implemented in the latter version FTVd 4.0 are considered\n\\cite{Wang08FTVdsoftware}. We propose that the intermediate results during the\niterations are the solutions of a series of combined Tikhonov and total\nvariation regularized image deconvolution models and therefore some of them\noften have even better image quality than the final solution, which is\ncorresponding to the pure total variation regularized model.", 
    "link": "http://arxiv.org/pdf/1402.3869v2", 
    "arxiv-id": "1402.3869v2"
},{
    "category": "cs.CV", 
    "author": "Noboru Murata", 
    "title": "Sparse Coding Approach for Multi-Frame Image Super Resolution", 
    "publish": "2014-02-17T08:23:35Z", 
    "summary": "An image super-resolution method from multiple observation of low-resolution\nimages is proposed. The method is based on sub-pixel accuracy block matching\nfor estimating relative displacements of observed images, and sparse signal\nrepresentation for estimating the corresponding high-resolution image. Relative\ndisplacements of small patches of observed low-resolution images are accurately\nestimated by a computationally efficient block matching method. Since the\nestimated displacements are also regarded as a warping component of image\ndegradation process, the matching results are directly utilized to generate\nlow-resolution dictionary for sparse image representation. The matching scores\nof the block matching are used to select a subset of low-resolution patches for\nreconstructing a high-resolution patch, that is, an adaptive selection of\ninformative low-resolution images is realized. When there is only one\nlow-resolution image, the proposed method works as a single-frame\nsuper-resolution method. The proposed method is shown to perform comparable or\nsuperior to conventional single- and multi-frame super-resolution methods\nthrough experiments using various real-world datasets.", 
    "link": "http://arxiv.org/pdf/1402.3926v1", 
    "arxiv-id": "1402.3926v1"
},{
    "category": "cs.CV", 
    "author": "Antonio Trsitan-Vega", 
    "title": "Statistical Noise Analysis in SENSE Parallel MRI", 
    "publish": "2014-02-17T17:16:21Z", 
    "summary": "A complete first and second order statistical characterization of noise in\nSENSE reconstructed data is proposed. SENSE acquisitions have usually been\nmodeled as Rician distributed, since the data reconstruction takes place into\nthe spatial domain, where Gaussian noise is assumed. However, this model just\nholds for the first order statistics and obviates other effects induced by\ncoils correlations and the reconstruction interpolation. Those effects are\nproperly taken into account in this study, in order to fully justify a final\nSENSE noise model. As a result, some interesting features of the reconstructed\nimage arise: (1) There is a strong correlation between adjacent lines. (2) The\nresulting distribution is non-stationary and therefore the variance of noise\nwill vary from point to point across the image. Closed equations for the\ncalculation of the variance of noise and the correlation coefficient between\nlines are proposed. The proposed model is totally compatible with g-factor\nformulations.", 
    "link": "http://arxiv.org/pdf/1402.4067v1", 
    "arxiv-id": "1402.4067v1"
},{
    "category": "cs.CV", 
    "author": "Roberto Rodr\u00edguez", 
    "title": "Application of the Ring Theory in the Segmentation of Digital Images", 
    "publish": "2014-02-17T17:16:35Z", 
    "summary": "Ring theory is one of the branches of the abstract algebra that has been\nbroadly used in images. However, ring theory has not been very related with\nimage segmentation. In this paper, we propose a new index of similarity among\nimages using Zn rings and the entropy function. This new index was applied as a\nnew stopping criterion to the Mean Shift Iterative Algorithm with the goal to\nreach a better segmentation. An analysis on the performance of the algorithm\nwith this new stopping criterion is carried out. The obtained results proved\nthat the new index is a suitable tool to compare images.", 
    "link": "http://arxiv.org/pdf/1402.4069v2", 
    "arxiv-id": "1402.4069v2"
},{
    "category": "cs.CV", 
    "author": "B. B. Chaudhuri", 
    "title": "Automatic Detection of Font Size Straight from Run Length Compressed   Text Documents", 
    "publish": "2014-02-18T16:30:59Z", 
    "summary": "Automatic detection of font size finds many applications in the area of\nintelligent OCRing and document image analysis, which has been traditionally\npracticed over uncompressed documents, although in real life the documents\nexist in compressed form for efficient storage and transmission. It would be\nnovel and intelligent if the task of font size detection could be carried out\ndirectly from the compressed data of these documents without decompressing,\nwhich would result in saving of considerable amount of processing time and\nspace. Therefore, in this paper we present a novel idea of learning and\ndetecting font size directly from run-length compressed text documents at line\nlevel using simple line height features, which paves the way for intelligent\nOCRing and document analysis directly from compressed documents. In the\nproposed model, the given mixed-case text documents of different font size are\nsegmented into compressed text lines and the features extracted such as line\nheight and ascender height are used to capture the pattern of font size in the\nform of a regression line, using which the automatic detection of font size is\ndone during the recognition stage. The method is experimented with a dataset of\n50 compressed documents consisting of 780 text lines of single font size and\n375 text lines of mixed font size resulting in an overall accuracy of 99.67%.", 
    "link": "http://arxiv.org/pdf/1402.4388v1", 
    "arxiv-id": "1402.4388v1"
},{
    "category": "cs.CV", 
    "author": "Amira Mohammad Abdel-Mawgoud Saleh", 
    "title": "Enhanced Secure Algorithm for Fingerprint Recognition", 
    "publish": "2014-02-20T09:19:17Z", 
    "summary": "Fingerprint recognition requires a minimal effort from the user, does not\ncapture other information than strictly necessary for the recognition process,\nand provides relatively good performance. A critical step in fingerprint\nidentification system is thinning of the input fingerprint image. The\nperformance of a minutiae extraction algorithm relies heavily on the quality of\nthe thinning algorithm. So, a fast fingerprint thinning algorithm is proposed.\nThe algorithm works directly on the gray-scale image as binarization of\nfingerprint causes many spurious minutiae and also removes many important\nfeatures. The performance of the thinning algorithm is evaluated and\nexperimental results show that the proposed thinning algorithm is both fast and\naccurate. A new minutiae-based fingerprint matching technique is proposed. The\nmain idea is that each fingerprint is represented by a minutiae table of just\ntwo columns in the database. The number of different minutiae types\n(terminations and bifurcations) found in each track of a certain width around\nthe core point of the fingerprint is recorded in this table. Each row in the\ntable represents a certain track, in the first column, the number of\nterminations in each track is recorded, in the second column, the number of\nbifurcations in each track is recorded. The algorithm is rotation and\ntranslation invariant, and needs less storage size. Experimental results show\nthat recognition accuracy is 98%, with Equal Error Rate (EER) of 2%. Finally,\nthe integrity of the data transmission via communication channels must be\nsecure all the way from the scanner to the application. After applying Gaussian\nnoise addition, and JPEG compression with high and moderate quality factors on\nthe watermarked fingerprint images, recognition accuracy decreases slightly to\nreach 96%.", 
    "link": "http://arxiv.org/pdf/1402.4936v1", 
    "arxiv-id": "1402.4936v1"
},{
    "category": "cs.CV", 
    "author": "Erik Bekkers", 
    "title": "Vesselness via Multiple Scale Orientation Scores", 
    "publish": "2014-02-20T11:06:35Z", 
    "summary": "The multi-scale Frangi vesselness filter is an established tool in (retinal)\nvascular imaging. However, it cannot cope with crossings or bifurcations, since\nit only looks for elongated structures. Therefore, we disentangle crossing\nstructures in the image via (multiple scale) invertible orientation scores. The\ndescribed vesselness filter via scale-orientation scores performs considerably\nbetter at enhancing vessels throughout crossings and bifurcations than the\nFrangi version. Both methods are evaluated on a public dataset. Performance is\nmeasured by comparing ground truth data to the segmentation results obtained by\nbasic thresholding and morphological component analysis of the filtered images.", 
    "link": "http://arxiv.org/pdf/1402.4963v4", 
    "arxiv-id": "1402.4963v4"
},{
    "category": "cs.CV", 
    "author": "Zeyun Yu", 
    "title": "Structure Tensor Based Image Interpolation Method", 
    "publish": "2014-02-22T23:58:11Z", 
    "summary": "Feature preserving image interpolation is an active area in image processing\nfield. In this paper a new direct edge directed image super-resolution\nalgorithm based on structure tensors is proposed. Using an isotropic Gaussian\nfilter, the structure tensor at each pixel of the input image is computed and\nthe pixels are classified to three distinct classes; uniform region, corners\nand edges, according to the eigenvalues of the structure tensor. Due to\napplication of the isotropic Gaussian filter, the classification is robust to\nnoise presented in image. Based on the tangent eigenvector of the structure\ntensor, the edge direction is determined and used for interpolation along the\nedges. In comparison to some previous edge directed image interpolation\nmethods, the proposed method achieves higher quality in both subjective and\nobjective aspects. Also the proposed method outperforms previous methods in\ncase of noisy and JPEG compressed images. Furthermore, without the need for\noptimization in the process, the algorithm can achieve higher speed.", 
    "link": "http://arxiv.org/pdf/1402.5564v3", 
    "arxiv-id": "1402.5564v3"
},{
    "category": "cs.CV", 
    "author": "V. Karthikeyan", 
    "title": "A Novel Histogram Based Robust Image Registration Technique", 
    "publish": "2014-02-23T15:24:27Z", 
    "summary": "In this paper, a method for Automatic Image Registration (AIR) through\nhistogram is proposed. Automatic image registration is one of the crucial steps\nin the analysis of remotely sensed data. A new acquired image must be\ntransformed, using image registration techniques, to match the orientation and\nscale of previous related images. This new approach combines several\nsegmentations of the pair of images to be registered. A relaxation parameter on\nthe histogram modes delineation is introduced. It is followed by\ncharacterization of the extracted objects through the objects area, axis ratio,\nand perimeter and fractal dimension. The matched objects are used for rotation\nand translation estimation. It allows for the registration of pairs of images\nwith differences in rotation and translation. This method contributes to\nsubpixel accuracy.", 
    "link": "http://arxiv.org/pdf/1402.5619v1", 
    "arxiv-id": "1402.5619v1"
},{
    "category": "cs.CV", 
    "author": "V. J. Vijayalakshmi", 
    "title": "Localization of License Plate Using Morphological Operations", 
    "publish": "2014-02-23T16:08:09Z", 
    "summary": "It is believed that there are currently millions of vehicles on the roads\nworldwide. The over speed of vehicles,theft of vehicles, disobeying traffic\nrules in public, an unauthorized person entering the restricted area are keep\non increasing. In order restrict against these criminal activities, we need an\nautomatic public security system. Each vehicle has their own Vehicle\nIdentification Number (VIN) as their primary identifier. The VIN is actually a\nLicense Number which states a legal license to participate in the public\ntraffic. The proposed paper is to identify the vehicle with the help of\nvehicles License Plate (LP).LPRS is one the most important part of the\nIntelligent Transportation System (ITS) to locate the LP. In this paper certain\nexisting algorithm drawbacks are overcome by the proposed morphological\noperations for LPRS. Morphological operation is chosen due to its higher\nefficiency, noise filter capacity, accuracy, exact localization of LP and\nspeed.", 
    "link": "http://arxiv.org/pdf/1402.5623v1", 
    "arxiv-id": "1402.5623v1"
},{
    "category": "cs.CV", 
    "author": "Nong Sang", 
    "title": "Exemplar-based Linear Discriminant Analysis for Robust Object Tracking", 
    "publish": "2014-02-24T01:10:09Z", 
    "summary": "Tracking-by-detection has become an attractive tracking technique, which\ntreats tracking as a category detection problem. However, the task in tracking\nis to search for a specific object, rather than an object category as in\ndetection. In this paper, we propose a novel tracking framework based on\nexemplar detector rather than category detector. The proposed tracker is an\nensemble of exemplar-based linear discriminant analysis (ELDA) detectors. Each\ndetector is quite specific and discriminative, because it is trained by a\nsingle object instance and massive negatives. To improve its adaptivity, we\nupdate both object and background models. Experimental results on several\nchallenging video sequences demonstrate the effectiveness and robustness of our\ntracking algorithm.", 
    "link": "http://arxiv.org/pdf/1402.5697v1", 
    "arxiv-id": "1402.5697v1"
},{
    "category": "cs.CV", 
    "author": "Amer Namazi", 
    "title": "A Novel Scheme for Intelligent Recognition of Pornographic Images", 
    "publish": "2014-02-24T11:15:04Z", 
    "summary": "Harmful contents are rising in internet day by day and this motivates the\nessence of more research in fast and reliable obscene and immoral material\nfiltering. Pornographic image recognition is an important component in each\nfiltering system. In this paper, a new approach for detecting pornographic\nimages is introduced. In this approach, two new features are suggested. These\ntwo features in combination with other simple traditional features provide\ndecent difference between porn and non-porn images. In addition, we applied\nfuzzy integral based information fusion to combine MLP (Multi-Layer Perceptron)\nand NF (Neuro-Fuzzy) outputs. To test the proposed method, performance of\nsystem was evaluated over 18354 download images from internet. The attained\nprecision was 93% in TP and 8% in FP on training dataset, and 87% and 5.5% on\ntest dataset. Achieved results verify the performance of proposed system versus\nother related works.", 
    "link": "http://arxiv.org/pdf/1402.5792v3", 
    "arxiv-id": "1402.5792v3"
},{
    "category": "cs.CV", 
    "author": "Oubong Gwun", 
    "title": "Automatic Estimation of Live Coffee Leaf Infection based on Image   Processing Techniques", 
    "publish": "2014-02-24T12:06:40Z", 
    "summary": "Image segmentation is the most challenging issue in computer vision\napplications. And most difficulties for crops management in agriculture are the\nlack of appropriate methods for detecting the leaf damage for pests treatment.\nIn this paper we proposed an automatic method for leaf damage detection and\nseverity estimation of coffee leaf by avoiding defoliation. After enhancing the\ncontrast of the original image using LUT based gamma correction, the image is\nprocessed to remove the background, and the output leaf is clustered using\nFuzzy c-means segmentation in V channel of YUV color space to maximize all leaf\ndamage detection, and finally, the severity of leaf is estimated in terms of\nratio for leaf pixel distribution between the normal and the detected leaf\ndamage. The results in each proposed method was compared to the current\nresearches and the accuracy is obvious either in the background removal or\ndamage detection.", 
    "link": "http://arxiv.org/pdf/1402.5805v1", 
    "arxiv-id": "1402.5805v1"
},{
    "category": "cs.CV", 
    "author": "Xun Qu", 
    "title": "A Novel Face Recognition Method using Nearest Line Projection", 
    "publish": "2014-02-24T15:36:32Z", 
    "summary": "Face recognition is a popular application of pat- tern recognition methods,\nand it faces challenging problems including illumination, expression, and pose.\nThe most popular way is to learn the subspaces of the face images so that it\ncould be project to another discriminant space where images of different\npersons can be separated. In this paper, a nearest line projection algorithm is\ndeveloped to represent the face images for face recognition. Instead of\nprojecting an image to its nearest image, we try to project it to its nearest\nline spanned by two different face images. The subspaces are learned so that\neach face image to its nearest line is minimized. We evaluated the proposed\nalgorithm on some benchmark face image database, and also compared it to some\nother image projection algorithms. The experiment results showed that the\nproposed algorithm outperforms other ones.", 
    "link": "http://arxiv.org/pdf/1402.5859v1", 
    "arxiv-id": "1402.5859v1"
},{
    "category": "cs.CV", 
    "author": "Barbara Caputo", 
    "title": "A Testbed for Cross-Dataset Analysis", 
    "publish": "2014-02-24T19:25:17Z", 
    "summary": "Since its beginning visual recognition research has tried to capture the huge\nvariability of the visual world in several image collections. The number of\navailable datasets is still progressively growing together with the amount of\nsamples per object category. However, this trend does not correspond directly\nto an increasing in the generalization capabilities of the developed\nrecognition systems. Each collection tends to have its specific characteristics\nand to cover just some aspects of the visual world: these biases often narrow\nthe effect of the methods defined and tested separately over each image set.\nOur work makes a first step towards the analysis of the dataset bias problem on\na large scale. We organize twelve existing databases in a unique corpus and we\npresent the visual community with a useful feature repository for future\nresearch.", 
    "link": "http://arxiv.org/pdf/1402.5923v1", 
    "arxiv-id": "1402.5923v1"
},{
    "category": "cs.CV", 
    "author": "Anton van den Hengel", 
    "title": "Large-margin Learning of Compact Binary Image Encodings", 
    "publish": "2014-02-26T00:22:50Z", 
    "summary": "The use of high-dimensional features has become a normal practice in many\ncomputer vision applications. The large dimension of these features is a\nlimiting factor upon the number of data points which may be effectively stored\nand processed, however. We address this problem by developing a novel approach\nto learning a compact binary encoding, which exploits both pair-wise proximity\nand class-label information on training data set. Exploiting this extra\ninformation allows the development of encodings which, although compact,\noutperform the original high-dimensional features in terms of final\nclassification or retrieval performance. The method is general, in that it is\napplicable to both non-parametric and parametric learning methods. This\ngenerality means that the embedded features are suitable for a wide variety of\ncomputer vision tasks, such as image classification and content-based image\nretrieval. Experimental results demonstrate that the new compact descriptor\nachieves an accuracy comparable to, and in some cases better than, the visual\ndescriptor in the original space despite being significantly more compact.\nMoreover, any convex loss function and convex regularization penalty (e.g., $\n\\ell_p $ norm with $ p \\ge 1 $) can be incorporated into the framework, which\nprovides future flexibility.", 
    "link": "http://arxiv.org/pdf/1402.6383v1", 
    "arxiv-id": "1402.6383v1"
},{
    "category": "cs.CV", 
    "author": "U. Rajendra Acharya", 
    "title": "Active spline model: A shape based model-interactive segmentation", 
    "publish": "2014-02-26T01:32:48Z", 
    "summary": "Rarely in literature a method of segmentation cares for the edit after the\nalgorithm delivers. They provide no solution when segmentation goes wrong. We\npropose to formulate point distribution model in terms of\ncentripetal-parameterized Catmull-Rom spline. Such fusion brings interactivity\nto model-based segmentation, so that edit is better handled. When the delivered\nsegment is unsatisfactory, user simply shifts points to vary the curve. We ran\nthe method on three disparate imaging modalities and achieved an average\noverlap of 0.879 for automated lung segmentation on chest radiographs. The edit\nafterward improved the average overlap to 0.945, with a minimum of 0.925. The\nsource code and the demo video are available at http://wp.me/p3vCKy-2S", 
    "link": "http://arxiv.org/pdf/1402.6387v1", 
    "arxiv-id": "1402.6387v1"
},{
    "category": "cs.CV", 
    "author": "Lachlan Fleming", 
    "title": "Deconstruction of compound objects from image sets", 
    "publish": "2014-02-26T05:37:41Z", 
    "summary": "We propose a method to recover the structure of a compound object from\nmultiple silhouettes. Structure is expressed as a collection of 3D primitives\nchosen from a pre-defined library, each with an associated pose. This has\nseveral advantages over a volume or mesh representation both for estimation and\nthe utility of the recovered model. The main challenge in recovering such a\nmodel is the combinatorial number of possible arrangements of parts. We address\nthis issue by exploiting the sparse nature of the problem, and show that our\nmethod scales to objects constructed from large libraries of parts.", 
    "link": "http://arxiv.org/pdf/1402.6416v1", 
    "arxiv-id": "1402.6416v1"
},{
    "category": "cs.CV", 
    "author": "Cheng Suen", 
    "title": "A Novel Method for the Recognition of Isolated Handwritten Arabic   Characters", 
    "publish": "2014-02-26T19:09:09Z", 
    "summary": "There are many difficulties facing a handwritten Arabic recognition system\nsuch as unlimited variation in human handwriting, similarities of distinct\ncharacter shapes, interconnections of neighbouring characters and their\nposition in the word. The typical Optical Character Recognition (OCR) systems\nare based mainly on three stages, preprocessing, features extraction and\nrecognition. This paper proposes new methods for handwritten Arabic character\nrecognition which is based on novel preprocessing operations including\ndifferent kinds of noise removal also different kind of features like\nstructural, Statistical and Morphological features from the main body of the\ncharacter and also from the secondary components. Evaluation of the accuracy of\nthe selected features is made. The system was trained and tested by back\npropagation neural network with CENPRMI dataset. The proposed algorithm\nobtained promising results as it is able to recognize 88% of our test set\naccurately. In Comparable with other related works we find that our result is\nthe highest among other published works.", 
    "link": "http://arxiv.org/pdf/1402.6650v1", 
    "arxiv-id": "1402.6650v1"
},{
    "category": "cs.CV", 
    "author": "Lawrence Carin", 
    "title": "Low-Cost Compressive Sensing for Color Video and Depth", 
    "publish": "2014-02-27T15:15:43Z", 
    "summary": "A simple and inexpensive (low-power and low-bandwidth) modification is made\nto a conventional off-the-shelf color video camera, from which we recover\n{multiple} color frames for each of the original measured frames, and each of\nthe recovered frames can be focused at a different depth. The recovery of\nmultiple frames for each measured frame is made possible via high-speed coding,\nmanifested via translation of a single coded aperture; the inexpensive\ntranslation is constituted by mounting the binary code on a piezoelectric\ndevice. To simultaneously recover depth information, a {liquid} lens is\nmodulated at high speed, via a variable voltage. Consequently, during the\naforementioned coding process, the liquid lens allows the camera to sweep the\nfocus through multiple depths. In addition to designing and implementing the\ncamera, fast recovery is achieved by an anytime algorithm exploiting the\ngroup-sparsity of wavelet/DCT coefficients.", 
    "link": "http://arxiv.org/pdf/1402.6932v1", 
    "arxiv-id": "1402.6932v1"
},{
    "category": "cs.CV", 
    "author": "Hamdi Yalin Yalic", 
    "title": "Visual Saliency Model using SIFT and Comparison of Learning Approaches", 
    "publish": "2014-02-28T08:33:17Z", 
    "summary": "Humans' ability to detect and locate salient objects on images is remarkably\nfast and successful. Performing this process by using eye tracking equipment is\nexpensive and cannot be easily applied, and computer modeling of this human\nbehavior is still a problem to be solved. In our study, one of the largest\npublic eye-tracking databases which has fixation points of 15 observers on 1003\nimages is used. In addition to low, medium and high-level features which have\nbeen used in previous studies, SIFT features extracted from the images are used\nto improve the classification accuracy of the models. A second contribution of\nthis paper is the comparison and statistical analysis of different machine\nlearning methods that can be used to train our model. As a result, a best\nfeature set and learning model to predict where humans look at images, is\ndetermined.", 
    "link": "http://arxiv.org/pdf/1402.7162v1", 
    "arxiv-id": "1402.7162v1"
},{
    "category": "cs.CV", 
    "author": "Qi Tian", 
    "title": "Bayes Merging of Multiple Vocabularies for Scalable Image Retrieval", 
    "publish": "2014-03-03T00:51:29Z", 
    "summary": "The Bag-of-Words (BoW) representation is well applied to recent\nstate-of-the-art image retrieval works. Typically, multiple vocabularies are\ngenerated to correct quantization artifacts and improve recall. However, this\nroutine is corrupted by vocabulary correlation, i.e., overlapping among\ndifferent vocabularies. Vocabulary correlation leads to an over-counting of the\nindexed features in the overlapped area, or the intersection set, thus\ncompromising the retrieval accuracy. In order to address the correlation\nproblem while preserve the benefit of high recall, this paper proposes a Bayes\nmerging approach to down-weight the indexed features in the intersection set.\nThrough explicitly modeling the correlation problem in a probabilistic view, a\njoint similarity on both image- and feature-level is estimated for the indexed\nfeatures in the intersection set.\n  We evaluate our method through extensive experiments on three benchmark\ndatasets. Albeit simple, Bayes merging can be well applied in various merging\ntasks, and consistently improves the baselines on multi-vocabulary merging.\nMoreover, Bayes merging is efficient in terms of both time and memory cost, and\nyields competitive performance compared with the state-of-the-art methods.", 
    "link": "http://arxiv.org/pdf/1403.0284v2", 
    "arxiv-id": "1403.0284v2"
},{
    "category": "cs.CV", 
    "author": "Qi Tian", 
    "title": "Cross-Scale Cost Aggregation for Stereo Matching", 
    "publish": "2014-03-03T05:20:28Z", 
    "summary": "Human beings process stereoscopic correspondence across multiple scales.\nHowever, this bio-inspiration is ignored by state-of-the-art cost aggregation\nmethods for dense stereo correspondence. In this paper, a generic cross-scale\ncost aggregation framework is proposed to allow multi-scale interaction in cost\naggregation. We firstly reformulate cost aggregation from a unified\noptimization perspective and show that different cost aggregation methods\nessentially differ in the choices of similarity kernels. Then, an inter-scale\nregularizer is introduced into optimization and solving this new optimization\nproblem leads to the proposed framework. Since the regularization term is\nindependent of the similarity kernel, various cost aggregation methods can be\nintegrated into the proposed general framework. We show that the cross-scale\nframework is important as it effectively and efficiently expands\nstate-of-the-art cost aggregation methods and leads to significant\nimprovements, when evaluated on Middlebury, KITTI and New Tsukuba datasets.", 
    "link": "http://arxiv.org/pdf/1403.0316v1", 
    "arxiv-id": "1403.0316v1"
},{
    "category": "cs.CV", 
    "author": "Brijesh B. Mehta", 
    "title": "Face Recognition Methods & Applications", 
    "publish": "2014-03-03T16:56:53Z", 
    "summary": "Face recognition presents a challenging problem in the field of image\nanalysis and computer vision. The security of information is becoming very\nsignificant and difficult. Security cameras are presently common in airports,\nOffices, University, ATM, Bank and in any locations with a security system.\nFace recognition is a biometric system used to identify or verify a person from\na digital image. Face Recognition system is used in security. Face recognition\nsystem should be able to automatically detect a face in an image. This involves\nextracts its features and then recognize it, regardless of lighting,\nexpression, illumination, ageing, transformations (translate, rotate and scale\nimage) and pose, which is a difficult task. This paper contains three sections.\nThe first section describes the common methods like holistic matching method,\nfeature extraction method and hybrid methods. The second section describes\napplications with examples and finally third section describes the future\nresearch directions of face recognition.", 
    "link": "http://arxiv.org/pdf/1403.0485v1", 
    "arxiv-id": "1403.0485v1"
},{
    "category": "cs.CV", 
    "author": "Brian C. Lovell", 
    "title": "K-Tangent Spaces on Riemannian Manifolds for Improved Pedestrian   Detection", 
    "publish": "2014-03-05T09:44:41Z", 
    "summary": "For covariance-based image descriptors, taking into account the curvature of\nthe corresponding feature space has been shown to improve discrimination\nperformance. This is often done through representing the descriptors as points\non Riemannian manifolds, with the discrimination accomplished on a tangent\nspace. However, such treatment is restrictive as distances between arbitrary\npoints on the tangent space do not represent true geodesic distances, and hence\ndo not represent the manifold structure accurately. In this paper we propose a\ngeneral discriminative model based on the combination of several tangent\nspaces, in order to preserve more details of the structure. The model can be\nused as a weak learner in a boosting-based pedestrian detection framework.\nExperiments on the challenging INRIA and DaimlerChrysler datasets show that the\nproposed model leads to considerably higher performance than methods based on\nhistograms of oriented gradients as well as previous Riemannian-based\ntechniques.", 
    "link": "http://arxiv.org/pdf/1403.1056v1", 
    "arxiv-id": "1403.1056v1"
},{
    "category": "cs.CV", 
    "author": "Yanjiang Wang", 
    "title": "Multi-view Face Analysis Based on Gabor Features", 
    "publish": "2014-03-06T02:14:20Z", 
    "summary": "Facial analysis has attracted much attention in the technology for\nhuman-machine interface. Different methods of classification based on sparse\nrepresentation and Gabor kernels have been widely applied in the fields of\nfacial analysis. However, most of these methods treat face from a whole view\nstandpoint. In terms of the importance of different facial views, in this\npaper, we present multi-view face analysis based on sparse representation and\nGabor wavelet coefficients. To evaluate the performance, we conduct face\nanalysis experiments including face recognition (FR) and face expression\nrecognition (FER) on JAFFE database. Experiments are conducted from two parts:\n(1) Face images are divided into three facial parts which are forehead, eye and\nmouth. (2) Face images are divided into 8 parts by the orientation of Gabor\nkernels. Experimental results demonstrate that the proposed methods can\nsignificantly boost the performance and perform better than the other methods.", 
    "link": "http://arxiv.org/pdf/1403.1327v1", 
    "arxiv-id": "1403.1327v1"
},{
    "category": "cs.CV", 
    "author": "M. V. Raghunadh", 
    "title": "Illumination,Expression and Occlusion Invariant Pose-Adaptive Face   Recognition System for Real-Time Applications", 
    "publish": "2014-03-06T07:19:24Z", 
    "summary": "Face recognition in real-time scenarios is mainly affected by illumination,\nexpression and pose variations and also by occlusion. This paper presents the\nframework for pose adaptive component-based face recognition system. The\nframework proposed deals with all the above mentioned issues. The steps\ninvolved in the presented framework are (i) facial landmark localisation, (ii)\nfacial component extraction, (iii) pre-processing of facial image (iv) facial\npose estimation (v) feature extraction using Local Binary Pattern Histograms of\neach component followed by (vi) fusion of pose adaptive classification of\ncomponents. By employing pose adaptive classification, the recognition process\nis carried out on some part of database, based on estimated pose, instead of\napplying the recognition process on the whole database. Pre-processing\ntechniques employed to overcome the problems due to illumination variation are\nalso discussed in this paper. Component-based techniques provide better\nrecognition rates when face images are occluded compared to the holistic\nmethods. Our method is simple, feasible and provides better results when\ncompared to other holistic methods.", 
    "link": "http://arxiv.org/pdf/1403.1362v1", 
    "arxiv-id": "1403.1362v1"
},{
    "category": "cs.CV", 
    "author": "Ji-Rong Wen", 
    "title": "Can Image-Level Labels Replace Pixel-Level Labels for Image Parsing", 
    "publish": "2014-03-07T00:39:49Z", 
    "summary": "This paper presents a weakly supervised sparse learning approach to the\nproblem of noisily tagged image parsing, or segmenting all the objects within a\nnoisily tagged image and identifying their categories (i.e. tags). Different\nfrom the traditional image parsing that takes pixel-level labels as strong\nsupervisory information, our noisily tagged image parsing is provided with\nnoisy tags of all the images (i.e. image-level labels), which is a natural\nsetting for social image collections (e.g. Flickr). By oversegmenting all the\nimages into regions, we formulate noisily tagged image parsing as a weakly\nsupervised sparse learning problem over all the regions, where the initial\nlabels of each region are inferred from image-level labels. Furthermore, we\ndevelop an efficient algorithm to solve such weakly supervised sparse learning\nproblem. The experimental results on two benchmark datasets show the\neffectiveness of our approach. More notably, the reported surprising results\nshed some light on answering the question: can image-level labels replace\npixel-level labels (hard to access) as supervisory information for image\nparsing.", 
    "link": "http://arxiv.org/pdf/1403.1626v3", 
    "arxiv-id": "1403.1626v3"
},{
    "category": "cs.CV", 
    "author": "Marc D. Killpack", 
    "title": "Automated Tracking and Estimation for Control of Non-rigid Cloth", 
    "publish": "2014-03-07T04:36:08Z", 
    "summary": "This report is a summary of research conducted on cloth tracking for\nautomated textile manufacturing during a two semester long research course at\nGeorgia Tech. This work was completed in 2009. Advances in current sensing\ntechnology such as the Microsoft Kinect would now allow me to relax certain\nassumptions and generally improve the tracking performance. This is because a\nmajor part of my approach described in this paper was to track features in a 2D\nimage and use these to estimate the cloth deformation. Innovations such as the\nKinect would improve estimation due to the automatic depth information obtained\nwhen tracking 2D pixel locations. Additionally, higher resolution camera images\nwould probably give better quality feature tracking. However, although I would\nuse different technology now to implement this tracker, the algorithm described\nand implemented in this paper is still a viable approach which is why I am\npublishing this as a tech report for reference. In addition, although the\nrelated work is a bit exhaustive, it will be useful to a reader who is new to\nmethods for tracking and estimation as well as modeling of cloth.", 
    "link": "http://arxiv.org/pdf/1403.1653v1", 
    "arxiv-id": "1403.1653v1"
},{
    "category": "cs.CV", 
    "author": "Mukesh Tiwari", 
    "title": "Feature Extraction of ECG Signal Using HHT Algorithm", 
    "publish": "2014-03-07T05:31:57Z", 
    "summary": "This paper describe the features extraction algorithm for electrocardiogram\n(ECG) signal using Huang Hilbert Transform and Wavelet Transform. ECG signal\nfor an individual human being is different due to unique heart structure. The\npurpose of feature extraction of ECG signal would allow successful abnormality\ndetection and efficient prognosis due to heart disorder. Some major important\nfeatures will be extracted from ECG signals such as amplitude, duration,\npre-gradient, post-gradient and so on. Therefore, we need a strong mathematical\nmodel to extract such useful parameter. Here an adaptive mathematical analysis\nmodel is Hilbert-Huang transform (HHT). This new approach, the Hilbert-Huang\ntransform, is implemented to analyze the non-linear and nonstationary data. It\nis unique and different from the existing methods of data analysis and does not\nrequire an a priori functional basis. The effectiveness of the proposed scheme\nis verified through the simulation.", 
    "link": "http://arxiv.org/pdf/1403.1660v1", 
    "arxiv-id": "1403.1660v1"
},{
    "category": "cs.CV", 
    "author": "St\u00e9phane Mallat", 
    "title": "Rigid-Motion Scattering for Texture Classification", 
    "publish": "2014-03-07T08:57:12Z", 
    "summary": "A rigid-motion scattering computes adaptive invariants along translations and\nrotations, with a deep convolutional network. Convolutions are calculated on\nthe rigid-motion group, with wavelets defined on the translation and rotation\nvariables. It preserves joint rotation and translation information, while\nproviding global invariants at any desired scale. Texture classification is\nstudied, through the characterization of stationary processes from a single\nrealization. State-of-the-art results are obtained on multiple texture data\nbases, with important rotation and scaling variabilities.", 
    "link": "http://arxiv.org/pdf/1403.1687v1", 
    "arxiv-id": "1403.1687v1"
},{
    "category": "cs.CV", 
    "author": "Svetlana Lazebnik", 
    "title": "Multi-scale Orderless Pooling of Deep Convolutional Activation Features", 
    "publish": "2014-03-07T19:03:15Z", 
    "summary": "Deep convolutional neural networks (CNN) have shown their promise as a\nuniversal representation for recognition. However, global CNN activations lack\ngeometric invariance, which limits their robustness for classification and\nmatching of highly variable scenes. To improve the invariance of CNN\nactivations without degrading their discriminative power, this paper presents a\nsimple but effective scheme called multi-scale orderless pooling (MOP-CNN).\nThis scheme extracts CNN activations for local patches at multiple scale\nlevels, performs orderless VLAD pooling of these activations at each level\nseparately, and concatenates the result. The resulting MOP-CNN representation\ncan be used as a generic feature for either supervised or unsupervised\nrecognition tasks, from image classification to instance-level retrieval; it\nconsistently outperforms global CNN activations without requiring any joint\ntraining of prediction layers for a particular target dataset. In absolute\nterms, it achieves state-of-the-art results on the challenging SUN397 and MIT\nIndoor Scenes classification datasets, and competitive results on\nILSVRC2012/2013 classification and INRIA Holidays retrieval datasets.", 
    "link": "http://arxiv.org/pdf/1403.1840v3", 
    "arxiv-id": "1403.1840v3"
},{
    "category": "cs.CV", 
    "author": "Kenneth W. Jenkins", 
    "title": "Quality-based Multimodal Classification Using Tree-Structured Sparsity", 
    "publish": "2014-03-08T00:00:15Z", 
    "summary": "Recent studies have demonstrated advantages of information fusion based on\nsparsity models for multimodal classification. Among several sparsity models,\ntree-structured sparsity provides a flexible framework for extraction of\ncross-correlated information from different sources and for enforcing group\nsparsity at multiple granularities. However, the existing algorithm only solves\nan approximated version of the cost functional and the resulting solution is\nnot necessarily sparse at group levels. This paper reformulates the\ntree-structured sparse model for multimodal classification task. An accelerated\nproximal algorithm is proposed to solve the optimization problem, which is an\nefficient tool for feature-level fusion among either homogeneous or\nheterogeneous sources of information. In addition, a (fuzzy-set-theoretic)\npossibilistic scheme is proposed to weight the available modalities, based on\ntheir respective reliability, in a joint optimization problem for finding the\nsparsity codes. This approach provides a general framework for quality-based\nfusion that offers added robustness to several sparsity-based multimodal\nclassification algorithms. To demonstrate their efficacy, the proposed methods\nare evaluated on three different applications - multiview face recognition,\nmultimodal face recognition, and target classification.", 
    "link": "http://arxiv.org/pdf/1403.1902v1", 
    "arxiv-id": "1403.1902v1"
},{
    "category": "cs.CV", 
    "author": "Jaspinder Pal Singh", 
    "title": "Designing an FPGA Synthesizable Computer Vision Algorithm to Detect the   Greening of Potatoes", 
    "publish": "2014-03-08T14:59:46Z", 
    "summary": "Potato quality control has improved in the last years thanks to automation\ntechniques like machine vision, mainly making the classification task between\ndifferent quality degrees faster, safer and less subjective. In our study we\nare going to design a computer vision algorithm for grading of potatoes\naccording to the greening of the surface color of potato. The ratio of green\npixels to the total number of pixels of the potato surface is found. The higher\nthe ratio the worse is the potato. First the image is converted into serial\ndata and then processing is done in RGB colour space. Green part of the potato\nis also shown by de-serializing the output. The same algorithm is then\nsynthesized on FPGA and the result shows thousand times speed improvement in\ncase of hardware synthesis.", 
    "link": "http://arxiv.org/pdf/1403.1974v1", 
    "arxiv-id": "1403.1974v1"
},{
    "category": "cs.CV", 
    "author": "P. Nagabhushan", 
    "title": "Texture Defect Detection in Gradient Space", 
    "publish": "2014-03-09T06:53:13Z", 
    "summary": "In this paper, we propose a machine vision algorithm for automatically\ndetecting defects in patterned textures with the help of gradient space and its\nenergy. Experiments on real fabric images with defects show that the proposed\nmethod can be used for automatic detection of fabric defects in textile\nindustries.", 
    "link": "http://arxiv.org/pdf/1403.2031v1", 
    "arxiv-id": "1403.2031v1"
},{
    "category": "cs.CV", 
    "author": "Zhang Yi", 
    "title": "Subspace Clustering by Exploiting a Low-Rank Representation with a   Symmetric Constraint", 
    "publish": "2014-03-07T10:07:43Z", 
    "summary": "In this paper, we propose a low-rank representation with symmetric constraint\n(LRRSC) method for robust subspace clustering. Given a collection of data\npoints approximately drawn from multiple subspaces, the proposed technique can\nsimultaneously recover the dimension and members of each subspace. LRRSC\nextends the original low-rank representation algorithm by integrating a\nsymmetric constraint into the low-rankness property of high-dimensional data\nrepresentation. The symmetric low-rank representation, which preserves the\nsubspace structures of high-dimensional data, guarantees weight consistency for\neach pair of data points so that highly correlated data points of subspaces are\nrepresented together. Moreover, it can be efficiently calculated by solving a\nconvex optimization problem. We provide a rigorous proof for minimizing the\nnuclear-norm regularized least square problem with a symmetric constraint. The\naffinity matrix for spectral clustering can be obtained by further exploiting\nthe angular information of the principal directions of the symmetric low-rank\nrepresentation. This is a critical step towards evaluating the memberships\nbetween data points. Experimental results on benchmark databases demonstrate\nthe effectiveness and robustness of LRRSC compared with several\nstate-of-the-art subspace clustering algorithms.", 
    "link": "http://arxiv.org/pdf/1403.2330v2", 
    "arxiv-id": "1403.2330v2"
},{
    "category": "cs.CV", 
    "author": "Quansheng Liu", 
    "title": "Removing Mixture of Gaussian and Impulse Noise by Patch-Based Weighted   Means", 
    "publish": "2014-03-11T06:48:58Z", 
    "summary": "We first establish a law of large numbers and a convergence theorem in\ndistribution to show the rate of convergence of the non-local means filter for\nremoving Gaussian noise. We then introduce the notion of degree of similarity\nto measure the role of similarity for the non-local means filter. Based on the\nconvergence theorems, we propose a patch-based weighted means filter for\nremoving impulse noise and its mixture with Gaussian noise by combining the\nessential idea of the trilateral filter and that of the non-local means filter.\nOur experiments show that our filter is competitive compared to recently\nproposed methods.", 
    "link": "http://arxiv.org/pdf/1403.2482v1", 
    "arxiv-id": "1403.2482v1"
},{
    "category": "cs.CV", 
    "author": "M. Ant\u00f3n-Rodr\u00edguez", 
    "title": "Indoor 3D Video Monitoring Using Multiple Kinect Depth-Cameras", 
    "publish": "2014-03-12T12:01:24Z", 
    "summary": "This article describes the design and development of a system for remote\nindoor 3D monitoring using an undetermined number of Microsoft(R) Kinect\nsensors. In the proposed client-server system, the Kinect cameras can be\nconnected to different computers, addressing this way the hardware limitation\nof one sensor per USB controller. The reason behind this limitation is the high\nbandwidth needed by the sensor, which becomes also an issue for the distributed\nsystem TCP/IP communications. Since traffic volume is too high, 3D data has to\nbe compressed before it can be sent over the network. The solution consists in\nselfcoding the Kinect data into RGB images and then using a standard multimedia\ncodec to compress color maps. Information from different sources is collected\ninto a central client computer, where point clouds are transformed to\nreconstruct the scene in 3D. An algorithm is proposed to merge the skeletons\ndetected locally by each Kinect conveniently, so that monitoring of people is\nrobust to self and inter-user occlusions. Final skeletons are labeled and\ntrajectories of every joint can be saved for event reconstruction or further\nanalysis.", 
    "link": "http://arxiv.org/pdf/1403.2895v1", 
    "arxiv-id": "1403.2895v1"
},{
    "category": "cs.CV", 
    "author": "Belen Medrano", 
    "title": "3D Well-composed Polyhedral Complexes", 
    "publish": "2014-03-12T15:44:17Z", 
    "summary": "A binary three-dimensional (3D) image $I$ is well-composed if the boundary\nsurface of its continuous analog is a 2D manifold. Since 3D images are not\noften well-composed, there are several voxel-based methods (\"repairing\"\nalgorithms) for turning them into well-composed ones but these methods either\ndo not guarantee the topological equivalence between the original image and its\ncorresponding well-composed one or involve sub-sampling the whole image.\n  In this paper, we present a method to locally \"repair\" the cubical complex\n$Q(I)$ (embedded in $\\mathbb{R}^3$) associated to $I$ to obtain a polyhedral\ncomplex $P(I)$ homotopy equivalent to $Q(I)$ such that the boundary of every\nconnected component of $P(I)$ is a 2D manifold. The reparation is performed via\na new codification system for $P(I)$ under the form of a 3D grayscale image\nthat allows an efficient access to cells and their faces.", 
    "link": "http://arxiv.org/pdf/1403.2980v1", 
    "arxiv-id": "1403.2980v1"
},{
    "category": "cs.CV", 
    "author": "Yasen Chen", 
    "title": "A Novel Method to Extract Rocks from Mars Images", 
    "publish": "2014-03-13T06:23:09Z", 
    "summary": "In this paper, a novel method is proposed to extract rocks from Martian\nsurface images by using 8 data field. It models the interaction between two\npixels of an image in the context of imagery 9 characteristics. First,\nforeground rocks are differed from background information by binarizing 10\nimage on roughly partitioned images. Second, foreground rocks are grouped into\nclusters by 11 locating the centers and edges of clusters in data field via\nhierarchical grids. Third, the target 12 rocks are discovered for the Mars\nExploration Rover (MER) to keep healthy paths. The 13 experiment with images\ntaken by MER shows the proposed method is practical and potential.", 
    "link": "http://arxiv.org/pdf/1403.3083v2", 
    "arxiv-id": "1403.3083v2"
},{
    "category": "cs.CV", 
    "author": "Nelson Francisco Favilla Ebecken", 
    "title": "Parallel WiSARD object tracker: a ram-based tracking system", 
    "publish": "2014-03-12T21:23:52Z", 
    "summary": "This paper proposes the Parallel WiSARD Object Tracker (PWOT), a new object\ntracker based on the WiSARD weightless neural network that is robust against\nquantization errors. Object tracking in video is an important and challenging\ntask in many applications. Difficulties can arise due to weather conditions,\ntarget trajectory and appearance, occlusions, lighting conditions and noise.\nTracking is a high-level application and requires the object location frame by\nframe in real time. This paper proposes a fast hybrid image segmentation\n(threshold and edge detection) in YcbCr color model and a parallel RAM based\ndiscriminator that improves efficiency when quantization errors occur. The\noriginal WiSARD training algorithm was changed to allow the tracking.", 
    "link": "http://arxiv.org/pdf/1403.3118v1", 
    "arxiv-id": "1403.3118v1"
},{
    "category": "cs.CV", 
    "author": "Chunhong Pan", 
    "title": "Spectral Unmixing via Data-guided Sparsity", 
    "publish": "2014-03-13T03:29:22Z", 
    "summary": "Hyperspectral unmixing, the process of estimating a common set of spectral\nbases and their corresponding composite percentages at each pixel, is an\nimportant task for hyperspectral analysis, visualization and understanding.\nFrom an unsupervised learning perspective, this problem is very\nchallenging---both the spectral bases and their composite percentages are\nunknown, making the solution space too large. To reduce the solution space,\nmany approaches have been proposed by exploiting various priors. In practice,\nthese priors would easily lead to some unsuitable solution. This is because\nthey are achieved by applying an identical strength of constraints to all the\nfactors, which does not hold in practice. To overcome this limitation, we\npropose a novel sparsity based method by learning a data-guided map to describe\nthe individual mixed level of each pixel. Through this data-guided map, the\n$\\ell_{p}(0<p<1)$ constraint is applied in an adaptive manner. Such\nimplementation not only meets the practical situation, but also guides the\nspectral bases toward the pixels under highly sparse constraint. What's more,\nan elegant optimization scheme as well as its convergence proof have been\nprovided in this paper. Extensive experiments on several datasets also\ndemonstrate that the data-guided map is feasible, and high quality unmixing\nresults could be obtained by our method.", 
    "link": "http://arxiv.org/pdf/1403.3155v4", 
    "arxiv-id": "1403.3155v4"
},{
    "category": "cs.CV", 
    "author": "Samuel Peltier", 
    "title": "Removal and Contraction Operations in $n$D Generalized Maps for   Efficient Homology Computation", 
    "publish": "2014-03-14T19:45:56Z", 
    "summary": "In this paper, we show that contraction operations preserve the homology of\n$n$D generalized maps, under some conditions. Removal and contraction\noperations are used to propose an efficient algorithm that compute homology\ngenerators of $n$D generalized maps. Its principle consists in simplifying a\ngeneralized map as much as possible by using removal and contraction\noperations. We obtain a generalized map having the same homology than the\ninitial one, while the number of cells decreased significantly.\n  Keywords: $n$D Generalized Maps; Cellular Homology; Homology Generators;\nContraction and Removal Operations.", 
    "link": "http://arxiv.org/pdf/1403.3683v1", 
    "arxiv-id": "1403.3683v1"
}]