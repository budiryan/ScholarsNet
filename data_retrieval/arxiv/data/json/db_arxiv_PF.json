[{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0103014v1", 
    "title": "Faster-than-light effects and negative group delays in optics and   electronics, and their applications", 
    "arxiv-id": "cs/0103014v1", 
    "author": "Daniel Solli", 
    "publish": "2001-03-12T18:23:57Z", 
    "summary": "Recent manifestations of apparently faster-than-light effects confirmed our\npredictions that the group velocity in transparent optical media can exceed c.\nSpecial relativity is not violated by these phenomena. Moreover, in the\nelectronic domain, the causality principle does not forbid negative group\ndelays of analytic signals in electronic circuits, in which the peak of an\noutput pulse leaves the exit port of a circuit before the peak of the input\npulse enters the input port. Furthermore, pulse distortion for these\nsuperluminal analytic signals can be negligible in both the optical and\nelectronic domains. Here we suggest an extension of these ideas to the\nmicroelectronic domain. The underlying principle is that negative feedback can\nbe used to produce negative group delays. Such negative group delays can be\nused to cancel out the positive group delays due to transistor latency (e.g.,\nthe finite RC rise time of MOSFETS caused by their intrinsic gate capacitance),\nas well as the propagation delays due to the interconnects between transistors.\nUsing this principle, it is possible to speed up computer systems."
},{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0111034v1", 
    "title": "Experiences with advanced CORBA services", 
    "arxiv-id": "cs/0111034v1", 
    "author": "M. Sekoranja", 
    "publish": "2001-11-09T22:33:58Z", 
    "summary": "The Common Object Request Broker Architecture (CORBA) is successfully used in\nmany control systems (CS) for data transfer and device modeling. Communication\nrates below 1 millisecond, high reliability, scalability, language independence\nand other features make it very attractive. For common types of applications\nlike error logging, alarm messaging or slow monitoring, one can benefit from\nstandard CORBA services that are implemented by third parties and save\ntremendous amount of developing time. We have started using few CORBA services\non our previous CORBA-based control system for the light source ANKA [1] and\nuse now several CORBA services for the ALMA Common Software (ACS) [2], the core\nof the control system of the Atacama Large Millimeter Array. Our experiences\nwith the interface repository (IFR), the implementation repository, the naming\nservice, the property service, telecom log service and the notify service from\ndifferent vendors are presented. Performance and scalability benchmarks have\nbeen performed."
},{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0205062v1", 
    "title": "Minimizing Cache Misses in Scientific Computing Using Isoperimetric   Bodies", 
    "arxiv-id": "cs/0205062v1", 
    "author": "Rob F. Van der Wijngaart", 
    "publish": "2002-05-24T00:56:47Z", 
    "summary": "A number of known techniques for improving cache performance in scientific\ncomputations involve the reordering of the iteration space. Some of these\nreorderings can be considered coverings of the iteration space with sets having\nsmall surface-to-volume ratios. Use of such sets may reduce the number of cache\nmisses in computations of local operators having the iteration space as their\ndomain. First, we derive lower bounds on cache misses that any algorithm must\nsuffer while computing a local operator on a grid. Then, we explore coverings\nof iteration spaces of structured and unstructured discretization grid\noperators which allow us to approach these lower bounds. For structured grids\nwe introduce a covering by successive minima tiles based on the interference\nlattice of the grid. We show that the covering has a small surface-to-volume\nratio and present a computer experiment showing actual reduction of the cache\nmisses achieved by using these tiles. For planar unstructured grids we show\nexistence of a covering which reduces the number of cache misses to the level\nof that of structured grids. Next, we introduce a class of multidimensional\ngrids, called starry grids in this paper. These grids represent an abstraction\nof unstructured grids used in, for example, molecular simulations and the\nsolution of partial differential equations. We show that starry grids can be\ncovered by sets having a low surface-to-volume ratio and, hence have the same\ncache efficiency as structured grids. Finally, we present a triangulation of a\nthree-dimensional cube that has the property that any local operator on the\ncorresponding grid must incur a significantly larger number of cache misses\nthan a similar operator on a structured grid of the same size."
},{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0301005v1", 
    "title": "Modelling Delay Jitter in Voice over IP", 
    "arxiv-id": "cs/0301005v1", 
    "author": "R. Sadhu", 
    "publish": "2003-01-09T05:46:32Z", 
    "summary": "It has been suggested in voice over IP that an appropriate choice of the\ndistribution used in modeling the delay jitters, can improve the play-out\nalgorithm. In this paper, we propose a tool using which, one can determine, at\na given instance, which distribution model best explains the jitter\ndistribution. This is done using Expectation Maximization, to choose amongst\npossible distribution models which include, the i.i.d exponential distribution,\nthe gamma distribution etc."
},{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0304015v1", 
    "title": "A Performance Study of Monitoring and Information Services for   Distributed Systems", 
    "arxiv-id": "cs/0304015v1", 
    "author": "Jennifer M. Schopf", 
    "publish": "2003-04-10T14:01:26Z", 
    "summary": "Monitoring and information services form a key component of a distributed\nsystem, or Grid. A quantitative study of such services can aid in understanding\nthe performance limitations, advise in the deployment of the systems, and help\nevaluate future development work. To this end, we study the performance of\nthree monitoring and information services for distributed systems: the Globus\nToolkit's Monitoring and Discovery Service (MDS), the European Data Grid\nRelational Grid Monitoring Architecture (R-GMA), and Hawkeye, part of the\nCondor project. We perform experiments to test their scalability with respect\nto number of users, number of resources, and amount of data collected. Our\nstudy shows that each approach has different behaviors, often due to their\ndifferent design goals. In the four sets of experiments we conducted to\nevaluate the performance of the service components under different\ncircumstances, we found a strong advantage to caching or prefetching the data,\nas well as the need to have primary components at well connected sites due to\nhigh load seen by all systems."
},{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0305054v1", 
    "title": "A Monitoring System for the BaBar INFN Computing Cluster", 
    "arxiv-id": "cs/0305054v1", 
    "author": "V. Melloni", 
    "publish": "2003-05-29T13:29:27Z", 
    "summary": "Monitoring large clusters is a challenging problem. It is necessary to\nobserve a large quantity of devices with a reasonably short delay between\nconsecutive observations. The set of monitored devices may include PCs, network\nswitches, tape libraries and other equipments. The monitoring activity should\nnot impact the performances of the system. In this paper we present PerfMC, a\nmonitoring system for large clusters. PerfMC is driven by an XML configuration\nfile, and uses the Simple Network Management Protocol (SNMP) for data\ncollection. SNMP is a standard protocol implemented by many networked\nequipments, so the tool can be used to monitor a wide range of devices. System\nadministrators can display informations on the status of each device by\nconnecting to a WEB server embedded in PerfMC. The WEB server can produce\ngraphs showing the value of different monitored quantities as a function of\ntime; it can also produce arbitrary XML pages by applying XSL Transformations\nto an internal XML representation of the cluster's status. XSL Transformations\nmay be used to produce HTML pages which can be displayed by ordinary WEB\nbrowsers. PerfMC aims at being relatively easy to configure and operate, and\nhighly efficient. It is currently being used to monitor the Italian\nReprocessing farm for the BaBar experiment, which is made of about 200 dual-CPU\nLinux machines."
},{
    "category": "cs.PF", 
    "doi": "10.1117/12.432562", 
    "link": "http://arxiv.org/pdf/cs/0305060v1", 
    "title": "Performance comparison between iSCSI and other hardware and software   solutions", 
    "arxiv-id": "cs/0305060v1", 
    "author": "Mathias Gug", 
    "publish": "2003-05-30T10:14:02Z", 
    "summary": "We report on our investigations on some technologies that can be used to\nbuild disk servers and networks of disk servers using commodity hardware and\nsoftware solutions. It focuses on the performance that can be achieved by these\nsystems and gives measured figures for different configurations.\n  It is divided into two parts : iSCSI and other technologies and hardware and\nsoftware RAID solutions.\n  The first part studies different technologies that can be used by clients to\naccess disk servers using a gigabit ethernet network. It covers block access\ntechnologies (iSCSI, hyperSCSI, ENBD). Experimental figures are given for\ndifferent numbers of clients and servers.\n  The second part compares a system based on 3ware hardware RAID controllers, a\nsystem using linux software RAID and IDE cards and a system mixing both\nhardware RAID and software RAID. Performance measurements for reading and\nwriting are given for different RAID levels."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0404035v3", 
    "title": "Elements for Response Time Statistics in ERP Transaction Systems", 
    "arxiv-id": "cs/0404035v3", 
    "author": "Andreas Mielke", 
    "publish": "2004-04-16T16:03:05Z", 
    "summary": "We present some measurements and ideas for response time statistics in ERP\nsystems. It is shown that the response time distribution of a given transaction\nin a given system is generically a log-normal distribution or, in some\nsituations, a sum of two or more log-normal distributions. We present some\narguments for this form of the distribution based on heuristic rules for\nresponse times, and we show data from performance measurements in actual\nsystems to support the log-normal form. Deviations of the log-normal form can\noften be traced back to performance problems in the system. Consequences for\nthe interpretation of response time data and for service level agreements are\ndiscussed."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0608102v1", 
    "title": "Analysis of a Reputation System for Mobile Ad-Hoc Networks with Liars", 
    "arxiv-id": "cs/0608102v1", 
    "author": "Jean-Yves Le Boudec", 
    "publish": "2006-08-25T18:12:08Z", 
    "summary": "The application of decentralized reputation systems is a promising approach\nto ensure cooperation and fairness, as well as to address random failures and\nmalicious attacks in Mobile Ad-Hoc Networks. However, they are potentially\nvulnerable to liars. With our work, we provide a first step to analyzing\nrobustness of a reputation system based on a deviation test. Using a mean-field\napproach to our stochastic process model, we show that liars have no impact\nunless their number exceeds a certain threshold (phase transition). We give\nprecise formulae for the critical values and thus provide guidelines for an\noptimal choice of parameters."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0610173v1", 
    "title": "On Degree-Based Decentralized Search in Complex Networks", 
    "arxiv-id": "cs/0610173v1", 
    "author": "Gaoxi Xiao", 
    "publish": "2006-10-31T10:09:51Z", 
    "summary": "Decentralized search aims to find the target node in a large network by using\nonly local information. The applications of it include peer-to-peer file\nsharing, web search and anything else that requires locating a specific target\nin a complex system. In this paper, we examine the degree-based decentralized\nsearch method. Specifically, we evaluate the efficiency of the method in\ndifferent cases with different amounts of available local information. In\naddition, we propose a simple refinement algorithm for significantly shortening\nthe length of the route that has been found. Some insights useful for the\nfuture developments of efficient decentralized search schemes have been\nachieved."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0611087v1", 
    "title": "A Combined LIFO-Priority Scheme for Overload Control of E-commerce Web   Servers", 
    "arxiv-id": "cs/0611087v1", 
    "author": "D. Manjunath", 
    "publish": "2006-11-17T23:43:40Z", 
    "summary": "E-commerce Web-servers often face overload conditions during which\nrevenue-generating requests may be dropped or abandoned due to an increase in\nthe browsing requests. In this paper we present a simple, yet effective,\nmechanism for overload control of E-commerce Web-servers. We develop an\nE-commerce workload model that separates the browsing requests from\nrevenue-generating transaction requests. During overload, we apply LIFO\ndiscipline in the browsing queues and use a dynamic priority model to service\nthem. The transaction queues are given absolute priority over the browsing\nqueues. This is called the LIFO-Pri scheduling discipline. Experimental results\nshow that LIFO-Pri dramatically improves the overall Web-server throughput\nwhile also increasing the completion rate of revenue-generating requests. The\nWeb-server was able to operate at nearly 60% of its maximum capacity even when\noffered load was 1.5 times its capacity. Further, when compared to a single\nqueue FIFO system, there was a seven-fold increase in the number of completed\nrevenue-generating requests during overload."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0612141v1", 
    "title": "Exact Failure Frequency Calculations for Extended Systems", 
    "arxiv-id": "cs/0612141v1", 
    "author": "Christian Tanguy", 
    "publish": "2006-12-28T19:35:56Z", 
    "summary": "This paper shows how the steady-state availability and failure frequency can\nbe calculated in a single pass for very large systems, when the availability is\nexpressed as a product of matrices. We apply the general procedure to\n$k$-out-of-$n$:G and linear consecutive $k$-out-of-$n$:F systems, and to a\nsimple ladder network in which each edge and node may fail. We also give the\nassociated generating functions when the components have identical\navailabilities and failure rates. For large systems, the failure rate of the\nwhole system is asymptotically proportional to its size. This paves the way to\nready-to-use formulae for various architectures, as well as proof that the\ndifferential operator approach to failure frequency calculations is very useful\nand straightforward."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0612143v1", 
    "title": "Exact solutions for the two- and all-terminal reliabilities of a simple   ladder network", 
    "arxiv-id": "cs/0612143v1", 
    "author": "Christian Tanguy", 
    "publish": "2006-12-28T19:43:26Z", 
    "summary": "The exact calculation of network reliability in a probabilistic context has\nbeen a long-standing issue of practical importance, but a difficult one, even\nfor planar graphs, with perfect nodes and with edges of identical reliability\np. Many approaches (determination of bounds, sums of disjoint products\nalgorithms, Monte Carlo evaluations, studies of the reliability polynomials,\netc.) can only provide approximations when the network's size increases. We\nconsider here a ladder graph of arbitrary size corresponding to real-life\nnetwork configurations, and give the exact, analytical solutions for the all-\nand two-terminal reliabilities. These solutions use transfer matrices, in which\nindividual reliabilities of edges and nodes are taken into account. The special\ncase of identical edge and node reliabilities -- p and rho, respectively -- is\nsolved. We show that the zeros of the two-terminal reliability polynomial\nexhibit structures which differ substantially for seemingly similar networks,\nand we compare the sensitivity of various edges. We discuss how the present\nwork may be further extended to lead to a catalog of exactly solvable networks\nin terms of reliability, which could be useful as elementary bricks for a new\nand improved set of bounds or benchmarks in the general case."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2005.05.006", 
    "link": "http://arxiv.org/pdf/cs/0701005v1", 
    "title": "Exact solutions for the two- and all-terminal reliabilities of the   Brecht-Colbourn ladder and the generalized fan", 
    "arxiv-id": "cs/0701005v1", 
    "author": "Christian Tanguy", 
    "publish": "2006-12-30T17:26:42Z", 
    "summary": "The two- and all-terminal reliabilities of the Brecht-Colbourn ladder and the\ngeneralized fan have been calculated exactly for arbitrary size as well as\narbitrary individual edge and node reliabilities, using transfer matrices of\ndimension four at most. While the all-terminal reliabilities of these graphs\nare identical, the special case of identical edge ($p$) and node ($\\rho$)\nreliabilities shows that their two-terminal reliabilities are quite distinct,\nas demonstrated by their generating functions and the locations of the zeros of\nthe reliability polynomials, which undergo structural transitions at $\\rho =\n\\displaystyle {1/2}$."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.newast.2007.05.004", 
    "link": "http://arxiv.org/pdf/cs/0702135v1", 
    "title": "High Performance Direct Gravitational N-body Simulations on Graphics   Processing Units", 
    "arxiv-id": "cs/0702135v1", 
    "author": "Peter Geldof", 
    "publish": "2007-02-23T09:44:17Z", 
    "summary": "We present the results of gravitational direct $N$-body simulations using the\ncommercial graphics processing units (GPU) NVIDIA Quadro FX1400 and GeForce\n8800GTX, and compare the results with GRAPE-6Af special purpose hardware. The\nforce evaluation of the $N$-body problem was implemented in Cg using the GPU\ndirectly to speed-up the calculations. The integration of the equations of\nmotions were, running on the host computer, implemented in C using the 4th\norder predictor-corrector Hermite integrator with block time steps. We find\nthat for a large number of particles ($N \\apgt 10^4$) modern graphics\nprocessing units offer an attractive low cost alternative to GRAPE special\npurpose hardware. A modern GPU continues to give a relatively flat scaling with\nthe number of particles, comparable to that of the GRAPE. Using the same time\nstep criterion the total energy of the $N$-body system was conserved better\nthan to one in $10^6$ on the GPU, which is only about an order of magnitude\nworse than obtained with GRAPE. For $N\\apgt 10^6$ the GeForce 8800GTX was about\n20 times faster than the host computer. Though still about an order of\nmagnitude slower than GRAPE, modern GPU's outperform GRAPE in their low cost,\nlong mean time between failure and the much larger onboard memory; the\nGRAPE-6Af holds at most 256k particles whereas the GeForce 8800GTF can hold 9\nmillion particles in memory."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.newast.2007.05.004", 
    "link": "http://arxiv.org/pdf/cs/0703086v2", 
    "title": "A Technical Report On Grid Benchmarking using SEE V.O", 
    "arxiv-id": "cs/0703086v2", 
    "author": "Fotis Georgatos", 
    "publish": "2007-03-15T21:06:06Z", 
    "summary": "Grids include heterogeneous resources, which are based on different hardware\nand software architectures or components. In correspondence with this diversity\nof the infrastructure, the execution time of any single job, as well as the\ntotal grid performance can both be affected substantially, which can be\ndemonstrated by measurements. Running a simple benchmarking suite can show this\nheterogeneity and give us results about the differences over the grid sites."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.newast.2007.05.004", 
    "link": "http://arxiv.org/pdf/0704.0860v1", 
    "title": "Availability assessment of SunOS/Solaris Unix Systems based on Syslogd   and wtmpx logfiles : a case study", 
    "arxiv-id": "0704.0860v1", 
    "author": "Mohamed Kaaniche", 
    "publish": "2007-04-06T08:24:47Z", 
    "summary": "This paper presents a measurement-based availability assessment study using\nfield data collected during a 4-year period from 373 SunOS/Solaris Unix\nworkstations and servers interconnected through a local area network. We focus\non the estimation of machine uptimes, downtimes and availability based on the\nidentification of failures that caused total service loss. Data corresponds to\nsyslogd event logs that contain a large amount of information about the normal\nactivity of the studied systems as well as their behavior in the presence of\nfailures. It is widely recognized that the information contained in such event\nlogs might be incomplete or imperfect. The solution investigated in this paper\nto address this problem is based on the use of auxiliary sources of data\nobtained from wtmpx files maintained by the SunOS/Solaris Unix operating\nsystem. The results obtained suggest that the combined use of wtmpx and syslogd\nlog files provides more complete information on the state of the target systems\nthat is useful to provide availability estimations that better reflect reality."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.newast.2007.05.004", 
    "link": "http://arxiv.org/pdf/0704.0879v1", 
    "title": "A Hierarchical Approach for Dependability Analysis of a Commercial   Cache-Based RAID Storage Architecture", 
    "arxiv-id": "0704.0879v1", 
    "author": "Rick Karcich", 
    "publish": "2007-04-06T11:46:49Z", 
    "summary": "We present a hierarchical simulation approach for the dependability analysis\nand evaluation of a highly available commercial cache-based RAID storage\nsystem. The archi-tecture is complex and includes several layers of\noverlap-ping error detection and recovery mechanisms. Three ab-straction levels\nhave been developed to model the cache architecture, cache operations, and\nerror detection and recovery mechanism. The impact of faults and errors\noc-curring in the cache and in the disks is analyzed at each level of the\nhierarchy. A simulation submodel is associated with each abstraction level. The\nmodels have been devel-oped using DEPEND, a simulation-based environment for\nsystem-level dependability analysis, which provides facili-ties to inject\nfaults into a functional behavior model, to simulate error detection and\nrecovery mechanisms, and to evaluate quantitative measures. Several fault\nmodels are defined for each submodel to simulate cache component failures, disk\nfailures, transmission errors, and data errors in the cache memory and in the\ndisks. Some of the parame-ters characterizing fault injection in a given\nsubmodel cor-respond to probabilities evaluated from the simulation of the\nlower-level submodel. Based on the proposed method-ology, we evaluate and\nanalyze 1) the system behavior un-der a real workload and high error rate\n(focusing on error bursts), 2) the coverage of the error detection mechanisms\nimplemented in the system and the error latency distribu-tions, and 3) the\naccumulation of errors in the cache and in the disks."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.newast.2007.05.004", 
    "link": "http://arxiv.org/pdf/0705.1915v3", 
    "title": "A Technical Report On Grid Benchmarking using ATLAS V.O", 
    "arxiv-id": "0705.1915v3", 
    "author": "Fotis Georgatos", 
    "publish": "2007-05-14T11:39:52Z", 
    "summary": "Grids include heterogeneous resources, which are based on different hardware\nand software architectures or components. In correspondence with this diversity\nof the infrastructure, the execution time of any single job, as well as the\ntotal grid performance can both be affected substantially, which can be\ndemonstrated by measurements. Running a simple benchmarking suite can show this\nheterogeneity and give us results about the differences over the grid sites."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0710.4633v1", 
    "title": "Nano-Sim: A Step Wise Equivalent Conductance based Statistical Simulator   for Nanotechnology Circuit Design", 
    "arxiv-id": "0710.4633v1", 
    "author": "Janet M. Wang", 
    "publish": "2007-10-25T08:07:46Z", 
    "summary": "New nanotechnology based devices are replacing CMOS devices to overcome CMOS\ntechnology's scaling limitations. However, many such devices exhibit\nnon-monotonic I-V characteristics and uncertain properties which lead to the\nnegative differential resistance (NDR) problem and the chaotic performance.\nThis paper proposes a new circuit simulation approach that can effectively\nsimulate nanotechnology devices with uncertain input sources and negative\ndifferential resistance (NDR) problem. The experimental results show a 20-30\ntimes speedup comparing with existing simulators."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0710.4701v1", 
    "title": "A Prediction Packetizing Scheme for Reducing Channel Traffic in   Transaction-Level Hardware/Software Co-Emulation", 
    "arxiv-id": "0710.4701v1", 
    "author": "Chong-Min Kyung", 
    "publish": "2007-10-25T09:27:03Z", 
    "summary": "This paper presents a scheme for efficient channel usage between simulator\nand accelerator where the accelerator models some RTL sub-blocks in the\naccelerator-based hardware/software co-simulation while the simulator runs\ntransaction-level model of the remaining part of the whole chip being verified.\nWith conventional simulation accelerator, evaluations of simulator and\naccelerator alternate at every valid simulation time, which results in poor\nsimulation performance due to startup overhead of simulator-accelerator channel\naccess. The startup overhead can be reduced by merging multiple transactions on\nthe channel into a single burst traffic. We propose a predictive packetizing\nscheme for reducing channel traffic by merging as many transactions into a\nburst traffic as possible based on 'prediction and rollback.' Under ideal\ncondition with 100% prediction accuracy, the proposed method shows a\nperformance gain of 1500% compared to the conventional one."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0710.4723v1", 
    "title": "Simulation Methodology for Analysis of Substrate Noise Impact on Analog   / RF Circuits Including Interconnect Resistance", 
    "arxiv-id": "0710.4723v1", 
    "author": "S. Donnay", 
    "publish": "2007-10-25T09:37:18Z", 
    "summary": "This paper reports a novel simulation methodology for analysis and prediction\nof substrate noise impact on analog / RF circuits taking into account the role\nof the parasitic resistance of the on-chip interconnect in the impact\nmechanism. This methodology allows investigation of the role of the separate\ndevices (also parasitic devices) in the analog / RF circuit in the overall\nimpact. This way is revealed which devices have to be taken care of (shielding,\ntopology change) to protect the circuit against substrate noise. The developed\nmethodology is used to analyze impact of substrate noise on a 3 GHz LC-tank\nVoltage Controlled Oscillator (VCO) designed in a high-ohmic 0.18 $\\mu$m 1PM6\nCMOS technology. For this VCO (in the investigated frequency range from DC to\n15 MHz) impact is mainly caused by resistive coupling of noise from the\nsubstrate to the non-ideal on-chip ground interconnect, resulting in analog\nground bounce and frequency modulation. Hence, the presented test-case reveals\nthe important role of the on-chip interconnect in the phenomenon of substrate\nnoise impact."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0805.3897v1", 
    "title": "SPARK00: A Benchmark Package for the Compiler Evaluation of   Irregular/Sparse Codes", 
    "arxiv-id": "0805.3897v1", 
    "author": "H. A. G. Wijshoff", 
    "publish": "2008-05-26T08:58:16Z", 
    "summary": "We propose a set of benchmarks that specifically targets a major cause of\nperformance degradation in high performance computing platforms: irregular\naccess patterns. These benchmarks are meant to be used to asses the performance\nof optimizing compilers on codes with a varying degree of irregular access. The\nirregularity caused by the use of pointers and indirection arrays are a major\nchallenge for optimizing compilers. Codes containing such patterns are\nnotoriously hard to optimize but they have a huge impact on the performance of\nmodern architectures, which are under-utilized when encountering irregular\nmemory accesses. In this paper, a set of benchmarks is described that\nexplicitly measures the performance of kernels containing a variety of\ndifferent access patterns found in real world applications. By offering a\nvarying degree of complexity, we provide a platform for measuring the\neffectiveness of transformations. The difference in complexity stems from a\ndifference in traversal patterns, the use of multiple indirections and control\nflow statements. The kernels used cover a variety of different access patterns,\nnamely pointer traversals, indirection arrays, dynamic loop bounds and run-time\ndependent if-conditions. The kernels are small enough to be fully understood\nwhich makes this benchmark set very suitable for the evaluation of\nrestructuring transformations."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0807.0626v1", 
    "title": "Asymptotic Mean Time To Failure and Higher Moments for Large, Recursive   Networks", 
    "arxiv-id": "0807.0626v1", 
    "author": "Christian Tanguy", 
    "publish": "2008-07-03T19:44:36Z", 
    "summary": "This paper deals with asymptotic expressions of the Mean Time To Failure\n(MTTF) and higher moments for large, recursive, and non-repairable systems in\nthe context of two-terminal reliability. Our aim is to extend the well-known\nresults of the series and parallel cases. We first consider several exactly\nsolvable configurations of identical components with exponential failure-time\ndistribution functions to illustrate different (logarithmic or power-law)\nbehaviors as the size of the system, indexed by an integer n, increases. The\ngeneral case is then addressed: it provides a simple interpretation of the\norigin of the power-law exponent and an efficient asymptotic expression for the\ntotal reliability of large, recursive systems. Finally, we assess the influence\nof the non-exponential character of the component reliability on the\nn-dependence of the MTTF."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0807.0629v1", 
    "title": "Exact two-terminal reliability of some directed networks", 
    "arxiv-id": "0807.0629v1", 
    "author": "Christian Tanguy", 
    "publish": "2008-07-03T19:47:11Z", 
    "summary": "The calculation of network reliability in a probabilistic context has long\nbeen an issue of practical and academic importance. Conventional approaches\n(determination of bounds, sums of disjoint products algorithms, Monte Carlo\nevaluations, studies of the reliability polynomials, etc.) only provide\napproximations when the network's size increases, even when nodes do not fail\nand all edges have the same reliability p. We consider here a directed, generic\ngraph of arbitrary size mimicking real-life long-haul communication networks,\nand give the exact, analytical solution for the two-terminal reliability. This\nsolution involves a product of transfer matrices, in which individual\nreliabilities of edges and nodes are taken into account. The special case of\nidentical edge and node reliabilities (p and rho, respectively) is addressed.\nWe consider a case study based on a commonly-used configuration, and assess the\ninfluence of the edges being directed (or not) on various measures of network\nperformance. While the two-terminal reliability, the failure frequency and the\nfailure rate of the connection are quite similar, the locations of complex\nzeros of the two-terminal reliability polynomials exhibit strong differences,\nand various structure transitions at specific values of rho. The present work\ncould be extended to provide a catalog of exactly solvable networks in terms of\nreliability, which could be useful as building blocks for new and improved\nbounds, as well as benchmarks, in the general case."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0807.0993v1", 
    "title": "WCET analysis of multi-level set-associative instruction caches", 
    "arxiv-id": "0807.0993v1", 
    "author": "Isabelle Puaut", 
    "publish": "2008-07-07T11:20:39Z", 
    "summary": "With the advent of increasingly complex hardware in real-time embedded\nsystems (processors with performance enhancing features such as pipelines,\ncache hierarchy, multiple cores), many processors now have a set-associative L2\ncache. Thus, there is a need for considering cache hierarchies when validating\nthe temporal behavior of real-time systems, in particular when estimating\ntasks' worst-case execution times (WCETs). To the best of our knowledge, there\nis only one approach for WCET estimation for systems with cache hierarchies\n[Mueller, 1997], which turns out to be unsafe for set-associative caches. In\nthis paper, we highlight the conditions under which the approach described in\n[Mueller, 1997] is unsafe. A safe static instruction cache analysis method is\nthen presented. Contrary to [Mueller, 1997] our method supports set-associative\nand fully associative caches. The proposed method is experimented on\nmedium-size and large programs. We show that the method is most of the time\ntight. We further show that in all cases WCET estimations are much tighter when\nconsidering the cache hierarchy than when considering only the L1 cache. An\nevaluation of the analysis time is conducted, demonstrating that analysing the\ncache hierarchy has a reasonable computation time."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0808.3100v1", 
    "title": "Optimizing Compiler for Engineering Problems", 
    "arxiv-id": "0808.3100v1", 
    "author": "Petr R. Ivankov", 
    "publish": "2008-08-22T15:27:34Z", 
    "summary": "New information technologies provide a lot of prospects for performance\nimprovement. One of them is \"Dynamic Source Code Generation and Compilation\".\nThis article shows how this way provides high performance for engineering\nproblems."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0811.1151v1", 
    "title": "A Model for Probabilistic Reasoning on Assume/Guarantee Contracts", 
    "arxiv-id": "0811.1151v1", 
    "author": "Beno\u00eet Caillaud", 
    "publish": "2008-11-07T14:33:10Z", 
    "summary": "In this paper, we present a probabilistic adaptation of an Assume/Guarantee\ncontract formalism. For the sake of generality, we assume that the extended\nstate machines used in the contracts and implementations define sets of runs on\na given set of variables, that compose by intersection over the common\nvariables. In order to enable probabilistic reasoning, we consider that the\ncontracts dictate how certain input variables will behave, being either\nnon-deterministic, or probabilistic; the introduction of probabilistic\nvariables leading us to tune the notions of implementation, refinement and\ncomposition. As shown in the report, this probabilistic adaptation of the\nAssume/Guarantee contract theory preserves compositionality and therefore\nallows modular reliability analysis, either with a top-down or a bottom-up\napproach."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0812.0904v1", 
    "title": "An Approximation of the Outage Probability for Multi-hop AF Fixed Gain   Relay", 
    "arxiv-id": "0812.0904v1", 
    "author": "Dong Ku Kim", 
    "publish": "2008-12-04T11:45:48Z", 
    "summary": "In this letter, we present a closed-form approximation of the outage\nprobability for the multi-hop amplify-and-forward (AF) relaying systems with\nfixed gain in Rayleigh fading channel. The approximation is derived from the\noutage event for each hop. The simulation results show the tightness of the\nproposed approximation in low and high signal-to-noise ratio (SNR) region."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0901.0148v1", 
    "title": "Using constraint programming to resolve the multi-source/multi-site data   movement paradigm on the Grid", 
    "arxiv-id": "0901.0148v1", 
    "author": "Michal Sumbera", 
    "publish": "2008-12-31T21:25:32Z", 
    "summary": "In order to achieve both fast and coordinated data transfer to collaborative\nsites as well as to create a distribution of data over multiple sites,\nefficient data movement is one of the most essential aspects in distributed\nenvironment. With such capabilities at hand, truly distributed task scheduling\nwith minimal latencies would be reachable by internationally distributed\ncollaborations (such as ones in HENP) seeking for scavenging or maximizing on\ngeographically spread computational resources. But it is often not all clear\n(a) how to move data when available from multiple sources or (b) how to move\ndata to multiple compute resources to achieve an optimal usage of available\nresources. We present a method of creating a Constraint Programming (CP) model\nconsisting of sites, links and their attributes such as bandwidth for grid\nnetwork data transfer also considering user tasks as part of the objective\nfunction for an optimal solution. We will explore and explain trade-off between\nschedule generation time and divergence from the optimal solution and show how\nto improve and render viable the solution's finding time by using search tree\ntime limit, approximations, restrictions such as symmetry breaking or grouping\nsimilar tasks together, or generating sequence of optimal schedules by\nsplitting the input problem. Results of data transfer simulation for each case\nwill also include a well known Peer-2-Peer model, and time taken to generate a\nschedule as well as time needed for a schedule execution will be compared to a\nCP optimal solution. We will additionally present a possible implementation\naimed to bring a distributed datasets (multiple sources) to a given site in a\nminimal time."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0902.1035v8", 
    "title": "Towards a Statistical Methodology to Evaluate Program Speedups and their   Optimisation Techniques", 
    "arxiv-id": "0902.1035v8", 
    "author": "Sid Touati", 
    "publish": "2009-02-06T09:30:53Z", 
    "summary": "The community of program optimisation and analysis, code performance\nevaluation, parallelisation and optimising compilation has published since many\ndecades hundreds of research and engineering articles in major conferences and\njournals. These articles study efficient algorithms, strategies and techniques\nto accelerate programs execution times, or optimise other performance metrics\n(MIPS, code size, energy/power, MFLOPS, etc.). Many speedups are published, but\nnobody is able to reproduce them exactly. The non-reproducibility of our\nresearch results is a dark point of the art, and we cannot be qualified as {\\it\ncomputer scientists} if we do not provide rigorous experimental methodology.\nThis article provides a first effort towards a correct statistical protocol for\nanalysing and measuring speedups. As we will see, some common mistakes are done\nby the community inside published articles, explaining part of the\nnon-reproducibility of the results. Our current article is not sufficient by\nits own to deliver a complete experimental methodology, further efforts must be\ndone by the community to decide about a common protocol for our future\nexperiences. Anyway, our community should take care about the aspect of\nreproducibility of the results in the future."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0902.3065v1", 
    "title": "The Multi-Branched Method of Moments for Queueing Networks", 
    "arxiv-id": "0902.3065v1", 
    "author": "Giuliano Casale", 
    "publish": "2009-02-18T07:48:34Z", 
    "summary": "We propose a new exact solution algorithm for closed multiclass product-form\nqueueing networks that is several orders of magnitude faster and less memory\nconsuming than established methods for multiclass models, such as the Mean\nValue Analysis (MVA) algorithm. The technique is an important generalization of\nthe recently proposed Method of Moments (MoM) which, differently from MVA,\nrecursively computes higher-order moments of queue-lengths instead of mean\nvalues.\n  The main contribution of this paper is to prove that the information used in\nthe MoM recursion can be increased by considering multiple recursive branches\nthat evaluate models with different number of queues. This reformulation allows\nto formulate a simpler matrix difference equation which leads to large\ncomputational savings with respect to the original MoM recursion. Computational\nanalysis shows several cases where the proposed algorithm is between 1,000 and\n10,000 times faster and less memory consuming than the original MoM, thus\nextending the range of multiclass models where exact solutions are feasible."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0906.1680v1", 
    "title": "Methodology for assessing system performance loss within a proactive   maintenance framework", 
    "arxiv-id": "0906.1680v1", 
    "author": "Beno\u00eet Iung", 
    "publish": "2009-06-09T09:54:49Z", 
    "summary": "Maintenance plays now a critical role in manufacturing for achieving\nimportant cost savings and competitive advantage while preserving product\nconditions. It suggests moving from conventional maintenance practices to\npredictive strategy. Indeed the maintenance action has to be done at the right\ntime based on the system performance and component Remaining Useful Life (RUL)\nassessed by a prognostic process. In that way, this paper proposes a\nmethodology in order to evaluate the performance loss of the system according\nto the degradation of component and the deviations of system input flows. This\nmethodology is supported by the neuro-fuzzy tool ANFIS (Adaptive Neuro-Fuzzy\nInference Systems) that allows to integrate knowledge from two different\nsources: expertise and real data. The feasibility and added value of such\nmethodology is then highlighted through an application case extracted from the\nTELMA platform used for education and research."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0907.3047v1", 
    "title": "Performance of Network and Service Monitoring Frameworks", 
    "arxiv-id": "0907.3047v1", 
    "author": "Olivier Festor", 
    "publish": "2009-07-17T11:35:46Z", 
    "summary": "The efficiency and the performance of anagement systems is becoming a hot\nresearch topic within the networks and services management community. This\nconcern is due to the new challenges of large scale managed systems, where the\nmanagement plane is integrated within the functional plane and where management\nactivities have to carry accurate and up-to-date information. We defined a set\nof primary and secondary metrics to measure the performance of a management\napproach. Secondary metrics are derived from the primary ones and quantifies\nmainly the efficiency, the scalability and the impact of management activities.\nTo validate our proposals, we have designed and developed a benchmarking\nplatform dedicated to the measurement of the performance of a JMX manager-agent\nbased management system. The second part of our work deals with the collection\nof measurement data sets from our JMX benchmarking platform. We mainly studied\nthe effect of both load and the number of agents on the scalability, the impact\nof management activities on the user perceived performance of a managed server\nand the delays of JMX operations when carrying variables values. Our findings\nshow that most of these delays follow a Weibull statistical distribution. We\nused this statistical model to study the behavior of a monitoring algorithm\nproposed in the literature, under heavy tail delays distribution. In this case,\nthe view of the managed system on the manager side becomes noisy and out of\ndate."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0908.1057v1", 
    "title": "Transmission Performance Analysis of Digital Wire and Wireless Optical   Links in Local and Wide Areas Optical Networks", 
    "arxiv-id": "0908.1057v1", 
    "author": "Amina E. M. El Nabawy", 
    "publish": "2009-08-07T13:57:15Z", 
    "summary": "In the present paper, the transmission performance analysis of digital wire\nand wireless optical links in local and wide areas optical networks have been\nmodeled and parametrically investigated over wide range of the affecting\nparameters. Moreover, we have analyzed the basic equations of the comparative\nstudy of the performance of digital fiber optic links with wire and wireless\noptical links. The development of optical wireless communication systems is\naccelerating as a high cost effective to wire fiber optic links. The optical\nwireless technology is used mostly in wide bandwidth data transmission\napplications. Finally, we have investigated the maximum transmission distance\nand data transmission bit rates that can be achieved within digital wire and\nwireless optical links for local and wide areas optical network applications."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0908.4256v1", 
    "title": "Experimental Performances Analysis of Load Balancing Algorithms in IEEE   802.11", 
    "arxiv-id": "0908.4256v1", 
    "author": "Tourki Rached", 
    "publish": "2009-08-28T18:32:22Z", 
    "summary": "In IEEE 802.11, load balancing algorithms (LBA) consider only the associated\nstations to balance the load of the available access points (APs). However,\nalthough the APs are balanced, it causes a bad situation if the AP has a lower\nsignal length (SNR) less than the neighbor APs. So, balance the load and\nassociate one mobile station to an access point without care about the signal\nto noise ratio (SNR) of the AP cause possibly an unforeseen QoS, such as the\nbit rate, the end to end delay, the packet loss. In this way, we study an\nimprovement load balancing algorithm with SNR integration at the selection\npolicy."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0909.1780v1", 
    "title": "uFLIP: Understanding Flash IO Patterns", 
    "arxiv-id": "0909.1780v1", 
    "author": "Philippe Bonnet", 
    "publish": "2009-09-09T18:10:26Z", 
    "summary": "Does the advent of flash devices constitute a radical change for secondary\nstorage? How should database systems adapt to this new form of secondary\nstorage? Before we can answer these questions, we need to fully understand the\nperformance characteristics of flash devices. More specifically, we want to\nestablish what kind of IOs should be favored (or avoided) when designing\nalgorithms and architectures for flash-based systems. In this paper, we focus\non flash IO patterns, that capture relevant distribution of IOs in time and\nspace, and our goal is to quantify their performance. We define uFLIP, a\nbenchmark for measuring the response time of flash IO patterns. We also present\na benchmarking methodology which takes into account the particular\ncharacteristics of flash devices. Finally, we present the results obtained by\nmeasuring eleven flash devices, and derive a set of design hints that should\ndrive the development of flash-based systems on current devices."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.221", 
    "link": "http://arxiv.org/pdf/0910.0819v1", 
    "title": "Performance Evaluation of Wimax Physical Layer under Adaptive Modulation   Techniques and Communication Channels", 
    "arxiv-id": "0910.0819v1", 
    "author": "Md. Zahid Hasan", 
    "publish": "2009-10-05T18:30:05Z", 
    "summary": "Wimax (Worldwide Interoperability for Microwave Access) is a promising\ntechnology which can offer high speed voice, video and data service up to the\ncustomer end. The aim of this paper is the performance evaluation of an Wimax\nsystem under different combinations of digital modulation (BPSK, QPSK, 4 QAM\nand 16 QAM) and different communication channels AWGN and fading channels\n(Rayleigh and Rician). And the Wimax system incorporates Reed Solomon (RS)\nencoder with Convolutional encoder with half and two third rated codes in FEC\nchannel coding. The simulation results of estimated Bit Error Rate (BER)\ndisplays that the implementation of interleaved RS code (255, 239, 8) with two\nthird rated Convolutional code under BPSK modulation technique is highly\neffective to combat in the Wimax communication system. To complete this\nperformance analysis in Wimax based systems, a segment of audio signal is used\nfor analysis. The transmitted audio message is found to have retrieved\neffectively under noisy situation."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/0910.4836v1", 
    "title": "Performance limitations for sparse matrix-vector multiplications on   current multicore environments", 
    "arxiv-id": "0910.4836v1", 
    "author": "Holger Fehske", 
    "publish": "2009-10-26T09:31:38Z", 
    "summary": "The increasing importance of multicore processors calls for a reevaluation of\nestablished numerical algorithms in view of their ability to profit from this\nnew hardware concept. In order to optimize the existent algorithms, a detailed\nknowledge of the different performance-limiting factors is mandatory. In this\ncontribution we investigate sparse matrix-vector multiplication, which is the\ndominant operation in many sparse eigenvalue solvers. Two conceptually\ndifferent storage schemes and computational kernels have been conceived in the\npast to target cache-based and vector architectures, respectively. Starting\nfrom a series of microbenchmarks we apply the gained insight on optimized\nsparse MVM implementations, whose serial and OpenMP-parallel performance we\nreview on state-of-the-art multicore systems."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1001.1860v2", 
    "title": "OMI4papps: Optimisation, Modelling and Implementation for Highly   Parallel Applications", 
    "arxiv-id": "1001.1860v2", 
    "author": "Iris Christadler", 
    "publish": "2010-01-12T12:08:53Z", 
    "summary": "This article reports on first results of the KONWIHR-II project OMI4papps at\nthe Leibniz Supercomputing Centre (LRZ). The first part describes Apex-MAP, a\ntunable synthetic benchmark designed to simulate the performance of typical\nscientific applications. Apex-MAP mimics common memory access patterns and\ndifferent computational intensity of scientific codes. An approach for\nmodelling LRZ's application mix is given whichh makes use of performance\ncounter measurements of real applications running on \"HLRB II\", an SGI Altix\nsystem based on 9728 Intel Montecito dual-cores.\n  The second part will show how the Apex-MAP benchmark could be used to\nsimulate the performance of two mathematical kernels frequently used in\nscientific applications: a dense matrix-matrix multiplication and a sparse\nmatrix-vector multiplication. The performance of both kernels has been\nintensively studied on x86 cores and hardware accelerators. We will compare the\npredicted performance with measured data to validate our Apex-MAP approach."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1001.3756v1", 
    "title": "Fault Tolerant Real Time Systems", 
    "arxiv-id": "1001.3756v1", 
    "author": "T. R. Gopalakrishnan Nair", 
    "publish": "2010-01-21T10:18:43Z", 
    "summary": "Real time systems are systems in which there is a commitment for timely\nresponse by the computer to external stimuli. Real time applications have to\nfunction correctly even in presence of faults. Fault tolerance can be achieved\nby either hardware or software or time redundancy. Safety-critical applications\nhave strict time and cost constraints, which means that not only faults have to\nbe tolerated but also the constraints should be satisfied. Deadline scheduling\nmeans that the taskwith the earliest required response time is processed. The\nmost common scheduling algorithms are :Rate Monotonic(RM) and Earliest deadline\nfirst(EDF).This paper deals with the interaction between the fault tolerant\nstrategy and the EDF real time scheduling strategy."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1002.1149v1", 
    "title": "A Performance Study of GA and LSH in Multiprocessor Job Scheduling", 
    "arxiv-id": "1002.1149v1", 
    "author": "G. Padmavathi", 
    "publish": "2010-02-05T08:39:11Z", 
    "summary": "Multiprocessor task scheduling is an important and computationally difficult\nproblem. This paper proposes a comparison study of genetic algorithm and list\nscheduling algorithm. Both algorithms are naturally parallelizable but have\nheavy data dependencies. Based on experimental results, this paper presents a\ndetailed analysis of the scalability, advantages and disadvantages of each\nalgorithm. Multiprocessors have emerged as a powerful computing means for\nrunning real-time applications, especially where a uni-processor system would\nnot be sufficient enough to execute all the tasks. The high performance and\nreliability of multiprocessors have made them a powerful computing resource.\nSuch computing environment requires an efficient algorithm to determine when\nand on which processor a given task should execute. In multiprocessor systems,\nan efficient scheduling of a parallel program onto the processors that\nminimizes the entire execution time is vital for achieving a high performance.\nThis scheduling problem is known to be NP- Hard. In multiprocessor scheduling\nproblem, a given program is to be scheduled in a given multiprocessor system\nsuch that the program's execution time is minimized. The last job must be\ncompleted as early as possible. Genetic algorithm (GA) is one of the widely\nused techniques for constrained optimization."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1002.1154v1", 
    "title": "Performance Analysis of Software to Hardware Task Migration in Codesign", 
    "arxiv-id": "1002.1154v1", 
    "author": "Imed Bennour", 
    "publish": "2010-02-05T08:51:44Z", 
    "summary": "The complexity of multimedia applications in terms of intensity of\ncomputation and heterogeneity of treated data led the designers to embark them\non multiprocessor systems on chip. The complexity of these systems on one hand\nand the expectations of the consumers on the other hand complicate the\ndesigners job to conceive and supply strong and successful systems in the\nshortest deadlines. They have to explore the different solutions of the design\nspace and estimate their performances in order to deduce the solution that\nrespects their design constraints. In this context, we propose the modeling of\none of the design space possible solutions: the software to hardware task\nmigration. This modeling exploits the synchronous dataflow graphs to take into\naccount the different migration impacts and estimate their performances in\nterms of throughput."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1003.4062v1", 
    "title": "A Rank Based Replacement Policy for Multimedia Server Cache Using   Zipf-Like Law", 
    "arxiv-id": "1003.4062v1", 
    "author": "P Jayarekha", 
    "publish": "2010-03-22T05:13:11Z", 
    "summary": "The cache replacement algorithm plays an important role in the overall\nperformance of Proxy-Server system. In this paper we have proposed VoD cache\nmemory replacement algorithm for a multimedia server system. We propose a Rank\nbased cache replacement policy to manage the cache space in individual proxy\nserver cache. Proposed replacement strategy incorporates in a simple way the\nmost important characteristics of the video and its accesses such as its size,\naccess frequency, recentness of the last access and the cost incurred while\ntransferring the requested video from the server to the proxy. We compare our\nalgorithm with some popular cache replacement algorithm using simulation. The\nvideo objects are ranked based on the access trend by considering the factors\nsuch as size, frequency and cost. Many studies have demonstrated that\nZipf's-like law can govern many features of the VoD and is used to describe the\npopularity of the video. In this paper, we have designed a model, which ranks\nthe video on the basis of its popularity using the Zipf-like law. The video\nwith higher ranking is named \"hot\", while the video with lower ranking is named\n\"cold\". The result show that the proposed rank based algorithm improves cache\nhit ratio, cache byte ratio and average request latencies compared to other\nalgorithms. Our experimental results indicate that Rank based cache replacement\nalgorithm outperforms LRU, LFU and Greedy Dual."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1003.4064v1", 
    "title": "Measuring Bandwidth for Super Computer Workloads", 
    "arxiv-id": "1003.4064v1", 
    "author": "R. S. D. Wahida Banu", 
    "publish": "2010-03-22T05:17:46Z", 
    "summary": "Parallel computing plays a major role in almost all the fields from research\nto major concern problem solving purposes. Many researches are till now\nfocusing towards the area of parallel processing. Nowadays it extends its usage\ntowards the end user application such as GPU as well as multi-core processor\ndevelopment. The bandwidth measurement is essential for resource management and\nfor studying the various performance factors of the existing super computer\nsystems which will be helpful for better system utilization since super\ncomputers are very few and their resources should be properly utilized. In this\npaper the real workload trace of one of the super computers LANL is taken and\nshown how the bandwidth is estimated with the given parameters."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1004.2637v1", 
    "title": "Performance Evaluation of Components Using a Granularity-based Interface   Between Real-Time Calculus and Timed Automata", 
    "arxiv-id": "1004.2637v1", 
    "author": "Matthieu Moy", 
    "publish": "2010-04-15T14:31:32Z", 
    "summary": "To analyze complex and heterogeneous real-time embedded systems, recent works\nhave proposed interface techniques between real-time calculus (RTC) and timed\nautomata (TA), in order to take advantage of the strengths of each technique\nfor analyzing various components. But the time to analyze a state-based\ncomponent modeled by TA may be prohibitively high, due to the state space\nexplosion problem. In this paper, we propose a framework of granularity-based\ninterfacing to speed up the analysis of a TA modeled component. First, we\nabstract fine models to work with event streams at coarse granularity. We\nperform analysis of the component at multiple coarse granularities and then\nbased on RTC theory, we derive lower and upper bounds on arrival patterns of\nthe fine output streams using the causality closure algorithm. Our framework\ncan help to achieve tradeoffs between precision and analysis time."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1004.3109v1", 
    "title": "Applying Stochastic Network Calculus to 802.11 Backlog and Delay   Analysis", 
    "arxiv-id": "1004.3109v1", 
    "author": "Yue Wang", 
    "publish": "2010-04-19T07:13:00Z", 
    "summary": "Stochastic network calculus provides an elegant way to characterize traffic\nand service processes. However, little effort has been made on applying it to\nmulti-access communication systems such as 802.11. In this paper, we take the\nfirst step to apply it to the backlog and delay analysis of an 802.11 wireless\nlocal network. In particular, we address the following questions: In applying\nstochastic network calculus, under what situations can we derive stable backlog\nand delay bounds? How to derive the backlog and delay bounds of an 802.11\nwireless node? And how tight are these bounds when compared with simulations?\nTo answer these questions, we first derive the general stability condition of a\nwireless node (not restricted to 802.11). From this, we give the specific\nstability condition of an 802.11 wireless node. Then we derive the backlog and\ndelay bounds of an 802.11 node based on an existing model of 802.11. We observe\nthat the derived bounds are loose when compared with ns-2 simulations,\nindicating that improvements are needed in the current version of stochastic\nnetwork calculus."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1004.3254v1", 
    "title": "Automatic Mapping Tasks to Cores - Evaluating AMTHA Algorithm in   Multicore Architectures", 
    "arxiv-id": "1004.3254v1", 
    "author": "Emilio Luque", 
    "publish": "2010-04-19T17:42:16Z", 
    "summary": "The AMTHA (Automatic Mapping Task on Heterogeneous Architectures) algorithm\nfor task-to-processors assignment and the MPAHA (Model of Parallel Algorithms\non Heterogeneous Architectures) model are presented. The use of AMTHA is\nanalyzed for multicore processor-based architectures, considering the\ncommunication model among processes in use. The results obtained in the tests\ncarried out are presented, comparing the real execution times on multicores of\na set of synthetic applications with the predictions obtained with AMTHA.\nFinally current lines of research are presented, focusing on clusters of\nmulticores and hybrid programming paradigms."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1004.3560v1", 
    "title": "Comparison of the Performance of Two Service Disciplines for a Shared   Bus Multiprocessor with Private Caches", 
    "arxiv-id": "1004.3560v1", 
    "author": "Lerato Lerato", 
    "publish": "2010-04-20T20:21:18Z", 
    "summary": "In this paper, we compare two analytical models for evaluation of cache\ncoherence overhead of a shared bus multiprocessor with private caches. The\nmodels are based on a closed queuing network with different service\ndisciplines. We find that the priority discipline can be used as a lower-level\nbound. Some numerical results are shown graphically."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1004.4286v2", 
    "title": "Space-efficient scheduling of stochastically generated tasks", 
    "arxiv-id": "1004.4286v2", 
    "author": "Michael Luttenberger", 
    "publish": "2010-04-24T15:17:56Z", 
    "summary": "We study the problem of scheduling tasks for execution by a processor when\nthe tasks can stochastically generate new tasks. Tasks can be of different\ntypes, and each type has a fixed, known probability of generating other tasks.\nWe present results on the random variable S^sigma modeling the maximal space\nneeded by the processor to store the currently active tasks when acting under\nthe scheduler sigma. We obtain tail bounds for the distribution of S^sigma for\nboth offline and online schedulers, and investigate the expected value of\nS^sigma."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-13872-0_2", 
    "link": "http://arxiv.org/pdf/1005.0806v1", 
    "title": "A New Benchmark For Evaluation Of Graph-Theoretic Algorithms", 
    "arxiv-id": "1005.0806v1", 
    "author": "Stephen Poole", 
    "publish": "2010-05-05T18:33:28Z", 
    "summary": "We propose a new graph-theoretic benchmark in this paper. The benchmark is\ndeveloped to address shortcomings of an existing widely-used graph benchmark.\nWe thoroughly studied a large number of traditional and contemporary graph\nalgorithms reported in the literature to have clear understanding of their\nalgorithmic and run-time characteristics. Based on this study, we designed a\nsuite of kernels, each of which represents a specific class of graph\nalgorithms. The kernels are designed to capture the typical run-time behavior\nof target algorithms accurately, while limiting computational and spatial\noverhead to ensure its computation finishes in reasonable time. We expect that\nthe developed benchmark will serve as a much needed tool for evaluating\ndifferent architectures and programming models to run graph algorithms."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijcnc.2010.2201", 
    "link": "http://arxiv.org/pdf/1005.1992v1", 
    "title": "Analyzing the Performance of Active Queue Management Algorithms", 
    "arxiv-id": "1005.1992v1", 
    "author": "Reshma Banu", 
    "publish": "2010-05-12T05:29:40Z", 
    "summary": "Congestion is an important issue which researchers focus on in the\nTransmission Control Protocol (TCP) network environment. To keep the stability\nof the whole network, congestion control algorithms have been extensively\nstudied. Queue management method employed by the routers is one of the\nimportant issues in the congestion control study. Active queue management (AQM)\nhas been proposed as a router-based mechanism for early detection of congestion\ninside the network. In this paper we analyzed several active queue management\nalgorithms with respect to their abilities of maintaining high resource\nutilization, identifying and restricting disproportionate bandwidth usage, and\ntheir deployment complexity. We compare the performance of FRED, BLUE, SFB, and\nCHOKe based on simulation results, using RED and Drop Tail as the evaluation\nbaseline. The characteristics of different algorithms are also discussed and\ncompared. Simulation is done by using Network Simulator(NS2) and the graphs are\ndrawn using X- graph."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijcnc.2010.2201", 
    "link": "http://arxiv.org/pdf/1006.1674v2", 
    "title": "Seeing Through Black Boxes : Tracking Transactions through Queues under   Monitoring Resource Constraints", 
    "arxiv-id": "1006.1674v2", 
    "author": "Dakshi Agrawal", 
    "publish": "2010-06-08T23:45:56Z", 
    "summary": "The problem of optimal allocation of monitoring resources for tracking\ntransactions progressing through a distributed system, modeled as a queueing\nnetwork, is considered. Two forms of monitoring information are considered,\nviz., locally unique transaction identifiers, and arrival and departure\ntimestamps of transactions at each processing queue. The timestamps are assumed\navailable at all the queues but in the absence of identifiers, only enable\nimprecise tracking since parallel processing can result in out-of-order\ndepartures. On the other hand, identifiers enable precise tracking but are not\navailable without proper instrumentation. Given an instrumentation budget, only\na subset of queues can be selected for production of identifiers, while the\nremaining queues have to resort to imprecise tracking using timestamps. The\ngoal is then to optimally allocate the instrumentation budget to maximize the\noverall tracking accuracy. The challenge is that the optimal allocation\nstrategy depends on accuracies of timestamp-based tracking at different queues,\nwhich has complex dependencies on the arrival and service processes, and the\nqueueing discipline. We propose two simple heuristics for allocation by\npredicting the order of timestamp-based tracking accuracies of different\nqueues. We derive sufficient conditions for these heuristics to achieve\noptimality through the notion of stochastic comparison of queues. Simulations\nshow that our heuristics are close to optimality, even when the parameters\ndeviate from these conditions."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSTSP.2010.2056352", 
    "link": "http://arxiv.org/pdf/1006.4824v1", 
    "title": "Decentralized Fair Scheduling in Two-Hop Relay-Assisted Cognitive OFDMA   Systems", 
    "arxiv-id": "1006.4824v1", 
    "author": "Ying Cui", 
    "publish": "2010-06-24T16:19:05Z", 
    "summary": "In this paper, we consider a two-hop relay-assisted cognitive downlink OFDMA\nsystem (named as secondary system) dynamically accessing a spectrum licensed to\na primary network, thereby improving the efficiency of spectrum usage. A\ncluster-based relay-assisted architecture is proposed for the secondary system,\nwhere relay stations are employed for minimizing the interference to the users\nin the primary network and achieving fairness for cell-edge users. Based on\nthis architecture, an asymptotically optimal solution is derived for jointly\ncontrolling data rates, transmission power, and subchannel allocation to\noptimize the average weighted sum goodput where the proportional fair\nscheduling (PFS) is included as a special case. This solution supports\ndecentralized implementation, requires small communication overhead, and is\nrobust against imperfect channel state information at the transmitter (CSIT)\nand sensing measurement. The proposed solution achieves significant throughput\ngains and better user-fairness compared with the existing designs. Finally, we\nderived a simple and asymptotically optimal scheduling solution as well as the\nassociated closed-form performance under the proportional fair scheduling for a\nlarge number of users. The system throughput is shown to be\n$\\mathcal{O}\\left(N(1-q_p)(1-q_p^N)\\ln\\ln K_c\\right)$, where $K_c$ is the\nnumber of users in one cluster, $N$ is the number of subchannels and $q_p$ is\nthe active probability of primary users."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSTSP.2010.2056352", 
    "link": "http://arxiv.org/pdf/1009.1708v1", 
    "title": "On the Performance Evaluation and Analysis of the Hybridised Bittorrent   Protocol with Partial Mobility Characteristics", 
    "arxiv-id": "1009.1708v1", 
    "author": "Constandinos X. Mavromoustakis", 
    "publish": "2010-09-09T08:37:34Z", 
    "summary": "Engaging mobility with file sharing is considered very promising in today's\nrun Anywhere, Anytime, Anything (3As) environments. The Bittorrent file sharing\nprotocol can be rarely combined with the mobility scenario framework since\nresources are not available due to the dynamically changing topology network.\nAs a result, mobility in P2P-oriented file sharing platforms, degrades the\nend-to-end efficiency and the system's performance. This work proposes a new\nhybridized model, which takes into account the mobility characteristics of the\ncombined Bittorrent protocol in a centralized manner enabling partial mobility\ncharacteristics, where the clients of the network use a distinct technique to\ndifferentiate between mobile and static nodes. Many parameters were taken into\nconsideration like the round trip delays, the diffusion process, and the\nseeding techniques, targeting the maximization of the average throughput in the\nclustered swarms containing mobile peers. Partial mobility characteristics are\nset in a peer-tracker and peer-peer communication enhancement schema with\npartial mobility, allowing an optimistic approach to attain high availability\nand throughput response as simulation results show."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSTSP.2010.2056352", 
    "link": "http://arxiv.org/pdf/1009.4733v3", 
    "title": "Forever Young: Aging Control For Smartphones In Hybrid Networks", 
    "arxiv-id": "1009.4733v3", 
    "author": "Yuedong Xu", 
    "publish": "2010-09-23T22:05:58Z", 
    "summary": "The demand for Internet services that require frequent updates through small\nmessages, such as microblogging, has tremendously grown in the past few years.\nAlthough the use of such applications by domestic users is usually free, their\naccess from mobile devices is subject to fees and consumes energy from limited\nbatteries. If a user activates his mobile device and is in range of a service\nprovider, a content update is received at the expense of monetary and energy\ncosts. Thus, users face a tradeoff between such costs and their messages aging.\nThe goal of this paper is to show how to cope with such a tradeoff, by devising\n\\emph{aging control policies}. An aging control policy consists of deciding,\nbased on the current utility of the last message received, whether to activate\nthe mobile device, and if so, which technology to use (WiFi or 3G). We present\na model that yields the optimal aging control policy. Our model is based on a\nMarkov Decision Process in which states correspond to message ages. Using our\nmodel, we show the existence of an optimal strategy in the class of threshold\nstrategies, wherein users activate their mobile devices if the age of their\nmessages surpasses a given threshold and remain inactive otherwise. We then\nconsider strategic content providers (publishers) that offer \\emph{bonus\npackages} to users, so as to incent them to download updates of advertisement\ncampaigns. We provide simple algorithms for publishers to determine optimal\nbonus levels, leveraging the fact that users adopt their optimal aging control\nstrategies. The accuracy of our model is validated against traces from the\nUMass DieselNet bus network."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSTSP.2010.2056352", 
    "link": "http://arxiv.org/pdf/1009.5878v1", 
    "title": "Performance analysis of Xen virtual machines in real-world scenarios", 
    "arxiv-id": "1009.5878v1", 
    "author": "Adrian Heissler", 
    "publish": "2010-09-29T13:28:13Z", 
    "summary": "This paper presents results of the performance benchmarks of the Open Source\nhypervisor Xen. The study focuses on the network related performance as well as\non the application related performance of multiple virtual machines that were\nrunning on the same Xen hypervisor. The comparison was carried out using a\nself-developed benchmark suite that consists of easily available Open Source\ntools. The goal is to measure the performance of the hypervisor in typical\nreal-world application scenarios when used for \"mass virtual hosting\", such as\nhosting solutions of so called virtual private servers for small-to-medium\nsized businesses environments. The results of the benchmarks show, that the\ntested Xen setup offers good performance with respect to network traffic stress\ntests, but only 75% of the performance of the non-virtualized reference\nenvironment. This application performance score decreases as more virtual\nmachines are running simultaneously."
},{
    "category": "cs.PF", 
    "doi": "10.5121/vlsic.2010.1303", 
    "link": "http://arxiv.org/pdf/1009.6218v1", 
    "title": "Low Power Reversible Parallel Binary Adder/Subtractor", 
    "arxiv-id": "1009.6218v1", 
    "author": "K B Raja", 
    "publish": "2010-09-30T18:57:10Z", 
    "summary": "In recent years, Reversible Logic is becoming more and more prominent\ntechnology having its applications in Low Power CMOS, Quantum Computing,\nNanotechnology, and Optical Computing. Reversibility plays an important role\nwhen energy efficient computations are considered. In this paper, Reversible\neight-bit Parallel Binary Adder/Subtractor with Design I, Design II and Design\nIII are proposed. In all the three design approaches, the full Adder and\nSubtractors are realized in a single unit as compared to only full Subtractor\nin the existing design. The performance analysis is verified using number\nreversible gates, Garbage input/outputs and Quantum Cost. It is observed that\nReversible eight-bit Parallel Binary Adder/Subtractor with Design III is\nefficient compared to Design I, Design II and existing design."
},{
    "category": "cs.PF", 
    "doi": "10.5121/vlsic.2010.1303", 
    "link": "http://arxiv.org/pdf/1011.6031v1", 
    "title": "A framework to experiment optimizations for real-time and embedded   software", 
    "arxiv-id": "1011.6031v1", 
    "author": "Olivier Zendra", 
    "publish": "2010-11-28T11:13:40Z", 
    "summary": "Typical constraints on embedded systems include code size limits, upper\nbounds on energy consumption and hard or soft deadlines. To meet these\nrequirements, it may be necessary to improve the software by applying various\nkinds of transformations like compiler optimizations, specific mapping of code\nand data in the available memories, code compression, etc. However, a\ntransformation that aims at improving the software with respect to a given\ncriterion might engender side effects on other criteria and these effects must\nbe carefully analyzed. For this purpose, we have developed a common framework\nthat makes it possible to experiment various code transfor-mations and to\nevaluate their impact of various criteria. This work has been carried out\nwithin the French ANR MORE project."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPS.2011.332", 
    "link": "http://arxiv.org/pdf/1101.0091v1", 
    "title": "Parallel sparse matrix-vector multiplication as a test case for hybrid   MPI+OpenMP programming", 
    "arxiv-id": "1101.0091v1", 
    "author": "Gerhard Wellein", 
    "publish": "2010-12-30T14:21:25Z", 
    "summary": "We evaluate optimized parallel sparse matrix-vector operations for two\nrepresentative application areas on widespread multicore-based cluster\nconfigurations. First the single-socket baseline performance is analyzed and\nmodeled with respect to basic architectural properties of standard multicore\nchips. Going beyond the single node, parallel sparse matrix-vector operations\noften suffer from an unfavorable communication to computation ratio. Starting\nfrom the observation that nonblocking MPI is not able to hide communication\ncost using standard MPI implementations, we demonstrate that explicit overlap\nof communication and computation can be achieved by using a dedicated\ncommunication thread, which may run on a virtual core. We compare our approach\nto pure MPI and the widely used \"vector-like\" hybrid programming strategy."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPS.2011.332", 
    "link": "http://arxiv.org/pdf/1101.5335v1", 
    "title": "Accurate Performance Analysis of Opportunistic Decode-and-Forward   Relaying", 
    "arxiv-id": "1101.5335v1", 
    "author": "Mohamed-Slim Alouni", 
    "publish": "2011-01-10T06:26:56Z", 
    "summary": "In this paper, we investigate an opportunistic relaying scheme where the\nselected relay assists the source-destination (direct) communication. In our\nstudy, we consider a regenerative opportunistic relaying scheme in which the\ndirect path can be considered unusable, and takes into account the effect of\nthe possible erroneously detected and transmitted data at the best relay. We\nfirst derive statistics based on exact probability density function (PDF) of\neach hop. Then, the PDFs are used to determine accurate closed form expressions\nfor end-to-end bit-error rate (BER) of binary phase-shift keying (BPSK)\nmodulation. Furthermore, we evaluate the asymptotical performance analysis and\nthe diversity order is deduced. Finally, we validate our analysis by showing\nthat performance simulation results coincide with our analytical results over\ndifferent network architectures."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPS.2011.332", 
    "link": "http://arxiv.org/pdf/1101.5794v1", 
    "title": "Scheduling in a random environment: stability and asymptotic optimality", 
    "arxiv-id": "1101.5794v1", 
    "author": "I. M. Verloop", 
    "publish": "2011-01-30T17:59:58Z", 
    "summary": "We investigate the scheduling of a common resource between several concurrent\nusers when the feasible transmission rate of each user varies randomly over\ntime. Time is slotted and users arrive and depart upon service completion. This\nmay model for example the flow-level behavior of end-users in a narrowband HDR\nwireless channel (CDMA 1xEV-DO). As performance criteria we consider the\nstability of the system and the mean delay experienced by the users. Given the\ncomplexity of the problem we investigate the fluid-scaled system, which allows\nto obtain important results and insights for the original system: (1) We\ncharacterize for a large class of scheduling policies the stability conditions\nand identify a set of maximum stable policies, giving in each time slot\npreference to users being in their best possible channel condition. We find in\nparticular that many opportunistic scheduling policies like Score-Based,\nProportionally Best or Potential Improvement are stable under the maximum\nstability conditions, whereas the opportunistic scheduler Relative-Best or the\ncmu-rule are not. (2) We show that choosing the right tie-breaking rule is\ncrucial for the performance (e.g. average delay) as perceived by a user. We\nprove that a policy is asymptotically optimal if it is maximum stable and the\ntie-breaking rule gives priority to the user with the highest departure\nprobability. We will refer to such tie-breaking rule as myopic. (3) We derive\nthe growth rates of the number of users in the system in overload settings\nunder various policies, which give additional insights on the performance. (4)\nWe conclude that simple priority-index policies with the myopic tie-breaking\nrule, are stable and asymptotically optimal. All our findings are validated\nwith extensive numerical experiments."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPS.2011.332", 
    "link": "http://arxiv.org/pdf/1103.3225v1", 
    "title": "Measuring NUMA effects with the STREAM benchmark", 
    "arxiv-id": "1103.3225v1", 
    "author": "Lars Bergstrom", 
    "publish": "2011-03-16T16:37:49Z", 
    "summary": "Modern high-end machines feature multiple processor packages, each of which\ncontains multiple independent cores and integrated memory controllers connected\ndirectly to dedicated physical RAM. These packages are connected via a shared\nbus, creating a system with a heterogeneous memory hierarchy. Since this shared\nbus has less bandwidth than the sum of the links to memory, aggregate memory\nbandwidth is higher when parallel threads all access memory local to their\nprocessor package than when they access memory attached to a remote package.\n  But, the impact of this heterogeneous memory architecture is not easily\nunderstood from vendor benchmarks. Even where these measurements are available,\nthey provide only best-case memory throughput. This work presents a series of\nmodifications to the well-known STREAM benchmark to measure the effects of NUMA\non both a 48-core AMD Opteron machine and a 32-core Intel Xeon machine."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPS.2011.332", 
    "link": "http://arxiv.org/pdf/1106.0880v2", 
    "title": "Performance Analysis of Sequential Method for HandOver in Cognitive   Radio Networks", 
    "arxiv-id": "1106.0880v2", 
    "author": "Masoumeh Nasiri-Kenari", 
    "publish": "2011-06-05T06:37:32Z", 
    "summary": "This paper has been withdrawn by the author due to a crucial problem in Lemma\n3. This equation must be changed."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPS.2011.332", 
    "link": "http://arxiv.org/pdf/1106.2380v2", 
    "title": "Mathematical Model for the Optimal Utilization Percentile in M/M/1   Systems: A Contribution about Knees in Performance Curves", 
    "arxiv-id": "1106.2380v2", 
    "author": "Eldamira Buenfil-Alpuche", 
    "publish": "2011-06-13T03:51:59Z", 
    "summary": "Performance curves of queuing systems can be analyzed by separating them into\nthree regions: the flat region, the knee region, and the exponential region.\nPractical considerations, usually locate the knee region between 70-90% of the\ntheoretical maximum utilization. However, there is not a clear agreement about\nwhere the boundaries between regions are, and where exactly the utilization\nknee is located. An open debate about knees in performance curves was\nundertaken at least 20 years ago. This historical debate is mainly divided\nbetween those who claim that a knee in the curve is not a well-defined term in\nmathematics, or it is a subjective and not really meaningful concept, and those\nwho define knees mathematically and consider their relevance and application.\nIn this paper, we present a mathematical model and analysis for identifying the\nthree mentioned regions on performance curves for M/M/1 systems; specifically,\nwe found the knees, or optimal utilization percentiles, at the vertices of the\nhyperbolas that relate response time as a function of utilization. Using these\nresults, we argue that an adaptive and optimal queuing system could be deployed\nby keeping load and throughput within the knee region."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.57.6", 
    "link": "http://arxiv.org/pdf/1107.1202v1", 
    "title": "A Stochastic Broadcast Pi-Calculus", 
    "arxiv-id": "1107.1202v1", 
    "author": "Bo Friis Nielsen", 
    "publish": "2011-07-06T17:54:58Z", 
    "summary": "In this paper we propose a stochastic broadcast PI-calculus which can be used\nto model server-client based systems where synchronization is always governed\nby only one participant. Therefore, there is no need to determine the joint\nsynchronization rates. We also take immediate transitions into account which is\nuseful to model behaviors with no impact on the temporal properties of a\nsystem. Since immediate transitions may introduce non-determinism, we will show\nhow these non-determinism can be resolved, and as result a valid CTMC will be\nobtained finally. Also some practical examples are given to show the\napplication of this calculus."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GLOCOM.2011.6133562", 
    "link": "http://arxiv.org/pdf/1107.4922v1", 
    "title": "On the Performance of Space Shift Keying (SSK) Modulation with Imperfect   Channel Knowledge", 
    "arxiv-id": "1107.4922v1", 
    "author": "Harald Haas", 
    "publish": "2011-07-25T12:33:25Z", 
    "summary": "In this paper, we study the sensitivity and robustness of Space Shift Keying\n(SSK) modulation to imperfect channel knowledge at the receiver. Unlike the\ncommon widespread belief, we show that SSK modulation is more robust to\nimperfect channel knowledge than other state-of-the-art transmission\ntechnologies, and only few training pilots are needed to get reliable enough\nchannel estimates for data detection. More precisely, we focus our attention on\nthe so-called Time-Orthogonal-Signal-Design (TOSD-) SSK modulation scheme,\nwhich is an improved version of SSK modulation offering transmit-diversity\ngains, and provide the following contributions: i) we develop a closed-form\nanalytical framework to compute the Average Bit Error Probability (ABEP) of a\nmismatched detector for TOSD-SSK modulation, which can be used for arbitrary\ntransmit-antenna, receive-antenna, channel fading, and training pilots; ii) we\nperform a comparative study of the performance of TOSD-SSK modulation and the\nAlamouti code under the same imperfect channel knowledge, and show that\nTOSD-SSK modulation is more robust to channel estimation errors; iii) we point\nout that only few pilot pulses are required to get performance very close to\nthe perfect channel knowledge lower-bound; and iv) we verify that transmit- and\nreceive-diversity gains of TOSD-SSK modulation are preserved even for a\nmismatched receiver."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GLOCOM.2011.6133562", 
    "link": "http://arxiv.org/pdf/1110.4245v1", 
    "title": "An Improved Analytical Expression for Write Amplification in NAND Flash", 
    "arxiv-id": "1110.4245v1", 
    "author": "Brian Kurkoski", 
    "publish": "2011-10-19T11:33:43Z", 
    "summary": "Agarwal et al. gave an closed-form expression for write amplification in NAND\nflash memory by finding the probability of a page being valid over the whole\nflash memory. This paper gives an improved analytic expression for write\namplification in NAND flash memory by finding the probability of a page being\ninvalid over the block selected for garbage collection. The improved expression\nuses Lambert W function. Through asymptotic analysis, write amplification is\nshown to depend on overprovisioning factor only, consistent with the previous\nwork. Comparison with numerical simulations shows that the improved expression\nachieves a more accurate prediction of write amplification. For example, when\nthe overprovisioning factor is 0.3, the expression proposed by this paper gives\na write amplification of 2.36 whereas that of the previous work gives 2.17,\nwhen the actual value is 2.35."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TIT.2011.2178150", 
    "link": "http://arxiv.org/pdf/1110.4535v1", 
    "title": "A Survey on Delay-Aware Resource Control for Wireless Systems --- Large   Deviation Theory, Stochastic Lyapunov Drift and Distributed Stochastic   Learning", 
    "arxiv-id": "1110.4535v1", 
    "author": "Shunqing Zhang", 
    "publish": "2011-10-20T14:09:02Z", 
    "summary": "In this tutorial paper, a comprehensive survey is given on several major\nsystematic approaches in dealing with delay-aware control problems, namely the\nequivalent rate constraint approach, the Lyapunov stability drift approach and\nthe approximate Markov Decision Process (MDP) approach using stochastic\nlearning. These approaches essentially embrace most of the existing literature\nregarding delay-aware resource control in wireless systems. They have their\nrelative pros and cons in terms of performance, complexity and implementation\nissues. For each of the approaches, the problem setup, the general solution and\nthe design methodology are discussed. Applications of these approaches to\ndelay-aware resource allocation are illustrated with examples in single-hop\nwireless networks. Furthermore, recent results regarding delay-aware multi-hop\nrouting designs in general multi-hop networks are elaborated. Finally, the\ndelay performance of the various approaches are compared through simulations\nusing an example of the uplink OFDMA systems."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TIT.2011.2178150", 
    "link": "http://arxiv.org/pdf/1110.6544v2", 
    "title": "A Generalized Loss Network Model with Overflow for Capacity Planning of   a Perinatal Network", 
    "arxiv-id": "1110.6544v2", 
    "author": "Thierry J Chaussalet", 
    "publish": "2011-10-29T18:22:36Z", 
    "summary": "We develop a generalized loss network framework for capacity planning of a\nperinatal network in the UK. Decomposing the network by hospitals, each unit is\nanalyzed with a GI/G/c/0 overflow loss network model. A two-moment\napproximation is performed to obtain the steady state solution of the GI/G/c/0\nloss systems, and expressions for rejection probability and overflow\nprobability have been derived. Using the model framework, the number of\nrequired cots can be estimated based on the rejection probability at each level\nof care of the neonatal units in a network. The generalization ensures that the\nmodel can be applied to any perinatal network for renewal arrival and discharge\nprocesses."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TIT.2011.2178150", 
    "link": "http://arxiv.org/pdf/1112.0442v2", 
    "title": "Simple and Effective Dynamic Provisioning for Power-Proportional Data   Centers", 
    "arxiv-id": "1112.0442v2", 
    "author": "Minghua Chen", 
    "publish": "2011-12-02T12:17:22Z", 
    "summary": "Energy consumption represents a significant cost in data center operation. A\nlarge fraction of the energy, however, is used to power idle servers when the\nworkload is low. Dynamic provisioning techniques aim at saving this portion of\nthe energy, by turning off unnecessary servers. In this paper, we explore how\nmuch performance gain can knowing future workload information brings to dynamic\nprovisioning. In particular, we study the dynamic provisioning problem under\nthe cost model that a running server consumes a fixed amount energy per unit\ntime, and develop online solutions with and without future workload information\navailable. We first reveal an elegant structure of the off-line dynamic\nprovisioning problem, which allows us to characterize and achieve the optimal\nsolution in a {}\"divide-and-conquer\" manner. We then exploit this insight to\ndesign three online algorithms with competitive ratios $2-\\alpha$,\n$(e-\\alpha)/(e-1)\\approx1.58-\\alpha/(e-1)$ and $e/(e-1+\\alpha)$, respectively,\nwhere $0\\leq\\alpha\\leq1$ is the fraction of a critical window in which future\nworkload information is available. A fundamental observation is that\n\\emph{future workload information beyond the critical window will not}\n\\emph{improve dynamic provisioning performance}. Our algorithms are\ndecentralized and are simple to implement. We demonstrate their effectiveness\nin simulations using real-world traces. We also compare their performance with\nstate-of-the-art solutions."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TIT.2011.2178150", 
    "link": "http://arxiv.org/pdf/1112.0850v1", 
    "title": "Performance engineering for the Lattice Boltzmann method on GPGPUs:   Architectural requirements and performance results", 
    "arxiv-id": "1112.0850v1", 
    "author": "Gerhard Wellein", 
    "publish": "2011-12-05T07:06:49Z", 
    "summary": "GPUs offer several times the floating point performance and memory bandwidth\nof current standard two socket CPU servers, e.g. NVIDIA C2070 vs. Intel Xeon\nWestmere X5650. The lattice Boltzmann method has been established as a flow\nsolver in recent years and was one of the first flow solvers to be successfully\nported and that performs well on GPUs. We demonstrate advanced optimization\nstrategies for a D3Q19 lattice Boltzmann based incompressible flow solver for\nGPGPUs and CPUs based on NVIDIA CUDA and OpenCL. Since the implemented\nalgorithm is limited by memory bandwidth, we concentrate on improving memory\naccess. Basic data layout issues for optimal data access are explained and\ndiscussed. Furthermore, the algorithmic steps are rearranged to improve\nscattered access of the GPU memory. The importance of occupancy is discussed as\nwell as optimization strategies to improve overall concurrency. We arrive at a\nwell-optimized GPU kernel, which is integrated into a larger framework that can\nhandle single phase fluid flow simulations as well as particle-laden flows. Our\n3D LBM GPU implementation reaches up to 650 MLUPS in single precision and 290\nMLUPS in double precision on an NVIDIA Tesla C2070."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TIT.2011.2178150", 
    "link": "http://arxiv.org/pdf/1112.1041v1", 
    "title": "Stabilization of Branching Queueing Networks", 
    "arxiv-id": "1112.1041v1", 
    "author": "Stefan Kiefer", 
    "publish": "2011-12-05T19:57:44Z", 
    "summary": "Queueing networks are gaining attraction for the performance analysis of\nparallel computer systems. A Jackson network is a set of interconnected\nservers, where the completion of a job at server i may result in the creation\nof a new job for server j. We propose to extend Jackson networks by \"branching\"\nand by \"control\" features. Both extensions are new and substantially expand the\nmodelling power of Jackson networks. On the other hand, the extensions raise\ncomputational questions, particularly concerning the stability of the networks,\ni.e, the ergodicity of the underlying Markov chain. We show for our extended\nmodel that it is decidable in polynomial time if there exists a controller that\nachieves stability. Moreover, if such a controller exists, one can efficiently\ncompute a static randomized controller which stabilizes the network in a very\nstrong sense; in particular, all moments of the queue sizes are finite."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TIT.2011.2178150", 
    "link": "http://arxiv.org/pdf/1112.2822v1", 
    "title": "A Temporal Approach to Stochastic Network Calculus", 
    "arxiv-id": "1112.2822v1", 
    "author": "Min Xie", 
    "publish": "2011-12-13T08:50:47Z", 
    "summary": "Stochastic network calculus is a newly developed theory for stochastic\nservice guarantee analysis of computer networks. In the current stochastic\nnetwork calculus literature, its fundamental models are based on the cumulative\namount of traffic or cumulative amount of service. However, there are network\nscenarios where direct application of such models is difficult. This paper\npresents a temporal approach to stochastic network calculus. The key idea is to\ndevelop models and derive results from the time perspective. Particularly, we\ndefine traffic models and service models based on the cumulative packet\ninter-arrival time and the cumulative packet service time, respectively.\nRelations among these models as well as with the existing models in the\nliterature are established. In addition, we prove the basic properties of the\nproposed models, such as delay bound and backlog bound, output\ncharacterization, concatenation property and superposition property. These\nresults form a temporal stochastic network calculus and compliment the existing\nresults."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijwsc.2011.2303", 
    "link": "http://arxiv.org/pdf/1201.2034v1", 
    "title": "Early Performance Prediction of Web Services", 
    "arxiv-id": "1201.2034v1", 
    "author": "K. Rajani Kanth", 
    "publish": "2012-01-10T11:59:37Z", 
    "summary": "Web Service is an interface which implements business logic. Performance is\nan important quality aspect of Web services because of their distributed\nnature. Predicting the performance of web services during early stages of\nsoftware development is significant. In this paper we model web service using\nUnified Modeling Language, Use Case Diagram, Sequence Diagram, Deployment\nDiagram. We obtain the Performance metrics by simulating the web services model\nusing a simulation tool Simulation of Multi-Tier Queuing Architecture. We have\nidentified the bottle neck resources."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012444795", 
    "link": "http://arxiv.org/pdf/1201.3496v1", 
    "title": "Optimizing the Performance of Streaming Numerical Kernels on the IBM   Blue Gene/P PowerPC 450 Processor", 
    "arxiv-id": "1201.3496v1", 
    "author": "David E. Keyes", 
    "publish": "2012-01-17T12:39:04Z", 
    "summary": "Several emerging petascale architectures use energy-efficient processors with\nvectorized computational units and in-order thread processing. On these\narchitectures the sustained performance of streaming numerical kernels,\nubiquitous in the solution of partial differential equations, represents a\nchallenge despite the regularity of memory access. Sophisticated optimization\ntechniques are required to fully utilize the Central Processing Unit (CPU).\n  We propose a new method for constructing streaming numerical kernels using a\nhigh-level assembly synthesis and optimization framework. We describe an\nimplementation of this method in Python targeting the IBM Blue Gene/P\nsupercomputer's PowerPC 450 core. This paper details the high-level design,\nconstruction, simulation, verification, and analysis of these kernels utilizing\na subset of the CPU's instruction set.\n  We demonstrate the effectiveness of our approach by implementing several\nthree-dimensional stencil kernels over a variety of cached memory scenarios and\nanalyzing the mechanically scheduled variants, including a 27-point stencil\nachieving a 1.7x speedup over the best previously published results."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012444795", 
    "link": "http://arxiv.org/pdf/1203.5040v1", 
    "title": "Minimizing Slowdown in Heterogeneous Size-Aware Dispatching Systems   (full version)", 
    "arxiv-id": "1203.5040v1", 
    "author": "Aleksi Penttinen", 
    "publish": "2012-03-22T16:51:55Z", 
    "summary": "We consider a system of parallel queues where tasks are assigned (dispatched)\nto one of the available servers upon arrival. The dispatching decision is based\non the full state information, i.e., on the sizes of the new and existing jobs.\nWe are interested in minimizing the so-called mean slowdown criterion\ncorresponding to the mean of the sojourn time divided by the processing time.\nAssuming no new jobs arrive, the shortest-processing-time-product (SPTP)\nschedule is known to minimize the slowdown of the existing jobs. The main\ncontribution of this paper is three-fold: 1) To show the optimality of SPTP\nwith respect to slowdown in a single server queue under Poisson arrivals; 2) to\nderive the so-called size-aware value functions for\nM/G/1-FIFO/LIFO/SPTP/SPT/SRPT with general holding costs of which the slowdown\ncriterion is a special case; and 3) to utilize the value functions to derive\nefficient dispatching policies so as to minimize the mean slowdown in a\nheterogeneous server system. The derived policies offer a significantly better\nperformance than e.g., the size-aware-task-assignment with equal load (SITA-E)\nand least-work-left (LWL) policies."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012444795", 
    "link": "http://arxiv.org/pdf/1206.1204v1", 
    "title": "Uncertainty Analysis of the Adequacy Assessment Model of a Distributed   Generation System", 
    "arxiv-id": "1206.1204v1", 
    "author": "Enrico Zio", 
    "publish": "2012-06-06T12:48:25Z", 
    "summary": "Due to the inherent aleatory uncertainties in renewable generators, the\nreliability/adequacy assessments of distributed generation (DG) systems have\nbeen particularly focused on the probabilistic modeling of random behaviors,\ngiven sufficient informative data. However, another type of uncertainty\n(epistemic uncertainty) must be accounted for in the modeling, due to\nincomplete knowledge of the phenomena and imprecise evaluation of the related\ncharacteristic parameters. In circumstances of few informative data, this type\nof uncertainty calls for alternative methods of representation, propagation,\nanalysis and interpretation. In this study, we make a first attempt to\nidentify, model, and jointly propagate aleatory and epistemic uncertainties in\nthe context of DG systems modeling for adequacy assessment. Probability and\npossibility distributions are used to model the aleatory and epistemic\nuncertainties, respectively. Evidence theory is used to incorporate the two\nuncertainties under a single framework. Based on the plausibility and belief\nfunctions of evidence theory, the hybrid propagation approach is introduced. A\ndemonstration is given on a DG system adapted from the IEEE 34 nodes\ndistribution test feeder. Compared to the pure probabilistic approach, it is\nshown that the hybrid propagation is capable of explicitly expressing the\nimprecision in the knowledge on the DG parameters into the final adequacy\nvalues assessed. It also effectively captures the growth of uncertainties with\nhigher DG penetration levels."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012444795", 
    "link": "http://arxiv.org/pdf/1208.0525v2", 
    "title": "An Upper Bound on the Convergence Time for Distributed Binary Consensus", 
    "arxiv-id": "1208.0525v2", 
    "author": "Pan Hui", 
    "publish": "2012-08-02T16:00:45Z", 
    "summary": "The problem addressed in this paper is the analysis of a distributed\nconsensus algorithm for arbitrary networks, proposed by B\\'en\\'ezit et al.. In\nthe initial setting, each node in the network has one of two possible states\n(\"yes\" or \"no\"). Nodes can update their states by communicating with their\nneighbors via a 2-bit message in an asynchronous clock setting. Eventually, all\nnodes reach consensus on the majority states. We use the theory of electric\nnetworks, random walks, and couplings of Markov chains to derive an O(N4 logN)\nupper bound for the expected convergence time on an arbitrary graph of size N."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012444795", 
    "link": "http://arxiv.org/pdf/1209.3315v1", 
    "title": "Storage Workload Modelling by Hidden Markov Models: Application to FLASH   Memory", 
    "arxiv-id": "1209.3315v1", 
    "author": "S. Zertal", 
    "publish": "2012-09-14T20:22:23Z", 
    "summary": "A workload analysis technique is presented that processes data from operation\ntype traces and creates a Hidden Markov Model (HMM) to represent the workload\nthat generated those traces. The HMM can be used to create representative\ntraces for performance models, such as simulators, avoiding the need to\nrepeatedly acquire suitable traces. It can also be used to estimate directly\nthe transition probabilities and rates of a Markov modulated arrival process,\nfor use as input to an analytical performance model of Flash memory. The HMMs\nobtained from industrial workloads are validated by comparing their\nautocorrelation functions and other statistics with those of the corresponding\nmonitored time series. Further, the performance model applications are\nillustrated by numerical examples."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012444795", 
    "link": "http://arxiv.org/pdf/1210.5975v1", 
    "title": "Solid State Disk Object-Based Storage with Trim Commands", 
    "arxiv-id": "1210.5975v1", 
    "author": "Ken Kreutz-Delgado", 
    "publish": "2012-10-10T18:02:33Z", 
    "summary": "This paper presents a model of NAND flash SSD utilization and write\namplification when the ATA/ATAPI SSD Trim command is incorporated into\nobject-based storage under a variety of user workloads, including a uniform\nrandom workload with objects of fixed size and a uniform random workload with\nobjects of varying sizes. We first summarize the existing models for write\namplification in SSDs for workloads with and without the Trim command, then\npropose an alteration of the models that utilizes a framework of object-based\nstorage. The utilization of objects and pages in the SSD is derived, with the\nanalytic results compared to simulation. Finally, the effect of objects on\nwrite amplification and its computation is discussed along with a potential\napplication to optimization of SSD usage through object storage metadata\nservers that allocate object classes of distinct object size."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-32573-1_38", 
    "link": "http://arxiv.org/pdf/1210.6122v1", 
    "title": "Performance Evaluation: Ball-Tree and KD-Tree in the Context of MST", 
    "arxiv-id": "1210.6122v1", 
    "author": "Venkata Jarugumalli", 
    "publish": "2012-10-23T04:09:30Z", 
    "summary": "Now a days many algorithms are invented or being inventing to find the\nsolution for Euclidean Minimum Spanning Tree, EMST, problem, as its\napplicability is increasing in much wide range of fields containing spatial or\nspatio temporal data viz. astronomy which consists of millions of spatial data.\nTo solve this problem, we are presenting a technique by adopting the dual tree\nalgorithm for finding efficient EMST and experimented on a variety of real time\nand synthetic datasets. This paper presents the observed experimental\nobservations and the efficiency of the dual tree framework, in the context of\nkdtree and ball tree on spatial datasets of different dimensions."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-32573-1_38", 
    "link": "http://arxiv.org/pdf/1211.5736v1", 
    "title": "Critical Utility Infrastructural Resilience", 
    "arxiv-id": "1211.5736v1", 
    "author": "Paulo Verissimo", 
    "publish": "2012-11-25T07:53:55Z", 
    "summary": "The paper refers to CRUTIAL, CRitical UTility InfrastructurAL Resilience, a\nEuropean project within the research area of Critical Information\nInfrastructure Protection, with a specific focus on the infrastructures\noperated by power utilities, widely recognized as fundamental to national and\ninternational economy, security and quality of life. Such infrastructures faced\nwith the recent market deregulations and the multiple interdependencies with\nother infrastructures are becoming more and more vulnerable to various threats,\nincluding accidental failures and deliberate sabotage and malicious attacks.\nThe subject of CRUTIAL research are small scale networked ICT systems used to\ncontrol and manage the electric power grid, in which artifacts controlling the\nphysical process of electricity transportation need to be connected with\ncorporate and societal applications performing management and maintenance\nfunctionality. The peculiarity of such ICT-supported systems is that they are\nrelated to the power system dynamics and its emergency conditions. Specific\neffort need to be devoted by the Electric Power community and by the\nInformation Technology community to influence the technological progress in\norder to allow commercial intelligent electronic devices to be effectively\ndeployed for the protection of citizens against cyber threats to electric power\nmanagement and control systems. A well-founded know-how needs to be built\ninside the industrial power sector to allow all the involved stakeholders to\nachieve their service objectives without compromising the resilience properties\nof the logical and physical assets that support the electric power provision."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-32573-1_38", 
    "link": "http://arxiv.org/pdf/1211.5738v1", 
    "title": "Modeling the resilience of large and evolving systems", 
    "arxiv-id": "1211.5738v1", 
    "author": "Karama Kanoun", 
    "publish": "2012-11-25T07:56:54Z", 
    "summary": "This paper summarizes the state of knowledge and ongoing research on methods\nand techniques for resilience evaluation, taking into account the\nresilience-scaling challenges and properties related to the ubiquitous\ncomputerized systems. We mainly focus on quantitative evaluation approaches\nand, in particular, on model-based evaluation techniques that are commonly used\nto evaluate and compare, from the dependability point of view, different\narchitecture alternatives at the design stage. We outline some of the main\nmodeling techniques aiming at mastering the largeness of analytical\ndependability models at the construction level. Actually, addressing the model\nlargeness problem is important with respect to the investigation of the\nscalability of current techniques to meet the complexity challenges of\nubiquitous systems. Finally we present two case studies in which some of the\npresented techniques are applied for modeling web services and General Packet\nRadio Service (GPRS) mobile telephone networks, as prominent examples of large\nand evolving systems."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-32573-1_38", 
    "link": "http://arxiv.org/pdf/1212.1896v2", 
    "title": "Power Consumption Analysis of a Modern Smartphone", 
    "arxiv-id": "1212.1896v2", 
    "author": "Muhammad Yasir Malik", 
    "publish": "2012-12-09T16:00:33Z", 
    "summary": "This paper presents observations about power consumption of a latest\nsmartphone. Modern smartphones are powerful devices with different choices of\ndata connections and other functional modes. This paper provides analysis of\npower utilization for these different operation modes. Also, we present power\nconsumption by vital operating system (OS) components."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICC.2013.6654889", 
    "link": "http://arxiv.org/pdf/1302.5514v1", 
    "title": "Blind Estimation of Primary User Traffic Parameters Under Sensing Errors", 
    "arxiv-id": "1302.5514v1", 
    "author": "Danijela Cabric", 
    "publish": "2013-02-22T08:16:37Z", 
    "summary": "In this work we investigate the bounds on the estimation accuracy of Primary\nUser (PU) traffic parameters with exponentially distributed busy and idle\ntimes. We derive closed-form expressions for the Cramer-Rao bounds on the mean\nsquared estimation error for the blind joint estimation of the PU traffic\nparameters, specifically, the duty cycle, and the mean arrival and departure\nrates. Moreover, we present the corresponding maximum-likelihood estimators for\nthe traffic parameters. In addition, we derive a modified likelihood function\nfor the joint estimation of traffic parameters when spectrum sensing errors are\nconsidered, and we present the impact of spectrum sensing errors on the\nestimation error via simulations. Finally, we consider a duty cycle estimator,\ncommon in traffic estimation literature, that is based on averaging the traffic\nsamples. We derive, in closed-form, the mean squared estimation error of the\nconsidered estimator under spectrum sensing errors."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICC.2013.6654889", 
    "link": "http://arxiv.org/pdf/1303.4114v2", 
    "title": "Sharp Bounds in Stochastic Network Calculus", 
    "arxiv-id": "1303.4114v2", 
    "author": "Jens Schmitt", 
    "publish": "2013-03-17T22:14:36Z", 
    "summary": "The practicality of the stochastic network calculus (SNC) is often questioned\non grounds of potential looseness of its performance bounds. In this paper it\nis uncovered that for bursty arrival processes (specifically Markov-Modulated\nOn-Off (MMOO)), whose amenability to \\textit{per-flow} analysis is typically\nproclaimed as a highlight of SNC, the bounds can unfortunately indeed be very\nloose (e.g., by several orders of magnitude off). In response to this uncovered\nweakness of SNC, the (Standard) per-flow bounds are herein improved by deriving\na general sample-path bound, using martingale based techniques, which\naccommodates FIFO, SP, EDF, and GPS scheduling. The obtained (Martingale)\nbounds gain an exponential decay factor of ${\\mathcal{O}}(e^{-\\alpha n})$ in\nthe number of flows $n$. Moreover, numerical comparisons against simulations\nshow that the Martingale bounds are remarkably accurate for FIFO, SP, and EDF\nscheduling; for GPS scheduling, although the Martingale bounds substantially\nimprove the Standard bounds, they are numerically loose, demanding for\nimprovements in the core SNC analysis of GPS."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICC.2013.6654889", 
    "link": "http://arxiv.org/pdf/1303.4816v2", 
    "title": "Stochastic Modeling of Large-Scale Solid-State Storage Systems:   Analysis, Design Tradeoffs and Optimization", 
    "arxiv-id": "1303.4816v2", 
    "author": "John C. S. Lui", 
    "publish": "2013-03-20T02:46:43Z", 
    "summary": "Solid state drives (SSDs) have seen wide deployment in mobiles, desktops, and\ndata centers due to their high I/O performance and low energy consumption. As\nSSDs write data out-of-place, garbage collection (GC) is required to erase and\nreclaim space with invalid data. However, GC poses additional writes that\nhinder the I/O performance, while SSD blocks can only endure a finite number of\nerasures. Thus, there is a performance-durability tradeoff on the design space\nof GC. To characterize the optimal tradeoff, this paper formulates an\nanalytical model that explores the full optimal design space of any GC\nalgorithm. We first present a stochastic Markov chain model that captures the\nI/O dynamics of large-scale SSDs, and adapt the mean-field approach to derive\nthe asymptotic steady-state performance. We further prove the model convergence\nand generalize the model for all types of workload. Inspired by this model, we\npropose a randomized greedy algorithm (RGA) that can operate along the optimal\ntradeoff curve with a tunable parameter. Using trace-driven simulation on\nDiskSim with SSD add-ons, we demonstrate how RGA can be parameterized to\nrealize the performance-durability tradeoff."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1303.6485v2", 
    "title": "Identifying Compiler Options to Minimise Energy Consumption for Embedded   Platforms", 
    "arxiv-id": "1303.6485v2", 
    "author": "Jeremy Bennett", 
    "publish": "2013-03-26T13:31:34Z", 
    "summary": "This paper presents an analysis of the energy consumption of an extensive\nnumber of the optimisations a modern compiler can perform. Using GCC as a test\ncase, we evaluate a set of ten carefully selected benchmarks for five different\nembedded platforms.\n  A fractional factorial design is used to systematically explore the large\noptimisation space (2^82 possible combinations), whilst still accurately\ndetermining the effects of optimisations and optimisation combinations.\nHardware power measurements on each platform are taken to ensure all\narchitectural effects on the energy consumption are captured.\n  We show that fractional factorial design can find more optimal combinations\nthan relying on built in compiler settings. We explore the relationship between\nrun-time and energy consumption, and identify scenarios where they are and are\nnot correlated.\n  A further conclusion of this study is the structure of the benchmark has a\nlarger effect than the hardware architecture on whether the optimisation will\nbe effective, and that no single optimisation is universally beneficial for\nexecution time or energy consumption."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1308.5174v2", 
    "title": "BEEBS: Open Benchmarks for Energy Measurements on Embedded Platforms", 
    "arxiv-id": "1308.5174v2", 
    "author": "Jeremy Bennett", 
    "publish": "2013-08-23T16:29:27Z", 
    "summary": "This paper presents and justifies an open benchmark suite named BEEBS,\ntargeted at evaluating the energy consumption of embedded processors.\n  We explore the possible sources of energy consumption, then select individual\nbenchmarks from contemporary suites to cover these areas. Version one of BEEBS\nis presented here and contains 10 benchmarks that cover a wide range of typical\nembedded applications. The benchmark suite is portable across diverse\narchitectures and is freely available.\n  The benchmark suite is extensively evaluated, and the properties of its\nconstituent programs are analysed. Using real hardware platforms we show case\nexamples which illustrate the difference in power dissipation between three\nprocessor architectures and their related ISAs. We observe significant\ndifferences in the average instruction dissipation between the architectures of\n4.4x, specifically 170uW/MHz (ARM Cortex-M0), 65uW/MHz (Adapteva Epiphany) and\n88uW/MHz (XMOS XS1-L1)."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1308.6469v1", 
    "title": "Using Chip Multithreading to Speed Up Scenario-Based Design Space   Exploration", 
    "arxiv-id": "1308.6469v1", 
    "author": "P. van Stralen", 
    "publish": "2013-08-29T13:54:39Z", 
    "summary": "To cope with the complex embedded system design, early design space\nexploration (DSE) is used to make design decisions early in the design phase.\nFor early DSE it is crucial that the running time of the exploration is as\nsmall as possible. In this paper, we describe both the porting of our\nscenario-based DSE to the SPARC T3-4 server and the analysis of its performance\nbehavior."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1309.1365v1", 
    "title": "Mixed Polling with Rerouting and Applications", 
    "arxiv-id": "1309.1365v1", 
    "author": "Richard Combes", 
    "publish": "2013-09-05T14:50:33Z", 
    "summary": "Queueing systems with a single server in which customers wait to be served at\na finite number of distinct locations (buffers/queues) are called discrete\npolling systems. Polling systems in which arrivals of users occur anywhere in a\ncontinuum are called continuous polling systems. Often one encounters a\ncombination of the two systems: the users can either arrive in a continuum or\nwait in a finite set (i.e. wait at a finite number of queues). We call these\nsystems mixed polling systems. Also, in some applications, customers are\nrerouted to a new location (for another service) after their service is\ncompleted. In this work, we study mixed polling systems with rerouting. We\nobtain their steady state performance by discretization using the known pseudo\nconservation laws of discrete polling systems. Their stationary expected\nworkload is obtained as a limit of the stationary expected workload of a\ndiscrete system. The main tools for our analysis are: a) the fixed point\nanalysis of infinite dimensional operators and; b) the convergence of Riemann\nsums to an integral.\n  We analyze two applications using our results on mixed polling systems and\ndiscuss the optimal system design. We consider a local area network, in which a\nmoving ferry facilitates communication (data transfer) using a wireless link.\nWe also consider a distributed waste collection system and derive the optimal\ncollection point. In both examples, the service requests can arrive anywhere in\na subset of the two dimensional plane. Namely, some users arrive in a\ncontinuous set while others wait for their service in a finite set. The only\npolling systems that can model these applications are mixed systems with\nrerouting as introduced in this manuscript."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1309.1613v1", 
    "title": "An Aggregation Technique For Large-Scale PEPA Models With Non-Uniform   Populations", 
    "arxiv-id": "1309.1613v1", 
    "author": "Jane Hillston", 
    "publish": "2013-09-06T11:48:02Z", 
    "summary": "Performance analysis based on modelling consists of two major steps: model\nconstruction and model analysis. Formal modelling techniques significantly aid\nmodel construction but can exacerbate model analysis. In particular, here we\nconsider the analysis of large-scale systems which consist of one or more\nentities replicated many times to form large populations. The replication of\nentities in such models can cause their state spaces to grow exponentially to\nthe extent that their exact stochastic analysis becomes computationally\nexpensive or even infeasible.\n  In this paper, we propose a new approximate aggregation algorithm for a class\nof large-scale PEPA models. For a given model, the method quickly checks if it\nsatisfies a syntactic condition, indicating that the model may be solved\napproximately with high accuracy. If so, an aggregated CTMC is generated\ndirectly from the model description. This CTMC can be used for efficient\nderivation of an approximate marginal probability distribution over some of the\nmodel's populations. In the context of a large-scale client-server system, we\ndemonstrate the usefulness of our method."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1309.1894v1", 
    "title": "Software Autotuning for Sustainable Performance Portability", 
    "arxiv-id": "1309.1894v1", 
    "author": "Boyana Norris", 
    "publish": "2013-09-07T18:49:59Z", 
    "summary": "Scientific software applications are increasingly developed by large\ninterdiscplinary teams operating on functional modules organized around a\ncommon software framework, which is capable of integrating new functional\ncapabilities without modifying the core of the framework. In such environment,\nsoftware correctness and modularity take precedence at the expense of code\nperformance, which is an important concern during execution on supercomputing\nfacilities, where the allocation of core-hours is a valuable resource. To\nalleviate the performance problems, we propose automated performance tuning\n(autotuning) of software to extract the maximum performance on a given hardware\nplatform and to enable performance portability across heterogeneous hardware\nplatforms. The resulting code remains generic without committing to a\nparticular software stack and yet is compile-time specializable for maximal\nsustained performance."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1404.4865v2", 
    "title": "On Time-Sensitive Revenue Management and Energy Scheduling in Green Data   Centers", 
    "arxiv-id": "1404.4865v2", 
    "author": "Fei Li", 
    "publish": "2014-04-18T19:34:24Z", 
    "summary": "In this paper, we design an analytically and experimentally better online\nenergy and job scheduling algorithm with the objective of maximizing net profit\nfor a service provider in green data centers. We first study the previously\nknown algorithms and conclude that these online algorithms have provable poor\nperformance against their worst-case scenarios. To guarantee an online\nalgorithm's performance in hindsight, we design a randomized algorithm to\nschedule energy and jobs in the data centers and prove the algorithm's expected\ncompetitive ratio in various settings. Our algorithm is theoretical-sound and\nit outperforms the previously known algorithms in many settings using both real\ntraces and simulated data. An optimal offline algorithm is also implemented as\nan empirical benchmark."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1406.0184v1", 
    "title": "Parallelism Via Concurrency at Multiple Levels", 
    "arxiv-id": "1406.0184v1", 
    "author": "Kamran Latif", 
    "publish": "2014-06-01T17:44:59Z", 
    "summary": "In this paper we examine the key elements determining the best performance of\ncomputing by increasing the frequency of a single chip and to get the minimum\nlatency during execution of the programs to achieve best possible output. It is\nnot enough to provide concurrent improvements in the hardware as Software also\nhave to introduce concurrency in order to exploit the parallelism. The software\nparallelism is defined by the control and data dependency of programs whereas\nHardware refers to the type of parallelism defined by the machine architecture\nand hardware multiplicity."
},{
    "category": "cs.PF", 
    "doi": "10.1093/comjnl/bxt129", 
    "link": "http://arxiv.org/pdf/1406.0285v1", 
    "title": "Block-Structured Supermarket Models", 
    "arxiv-id": "1406.0285v1", 
    "author": "John C. S. Lui", 
    "publish": "2014-06-02T08:14:14Z", 
    "summary": "Supermarket models are a class of parallel queueing networks with an adaptive\ncontrol scheme that play a key role in the study of resource management of,\nsuch as, computer networks, manufacturing systems and transportation networks.\nWhen the arrival processes are non-Poisson and the service times are\nnon-exponential, analysis of such a supermarket model is always limited,\ninteresting, and challenging.\n  This paper describes a supermarket model with non-Poisson inputs: Markovian\nArrival Processes (MAPs) and with non-exponential service times: Phase-type\n(PH) distributions, and provides a generalized matrix-analytic method which is\nfirst combined with the operator semigroup and the mean-field limit. When\ndiscussing such a more general supermarket model, this paper makes some new\nresults and advances as follows: (1) Providing a detailed probability analysis\nfor setting up an infinite-dimensional system of differential vector equations\nsatisfied by the expected fraction vector, where \"the invariance of environment\nfactors\" is given as an important result. (2) Introducing the phase-type\nstructure to the operator semigroup and to the mean-field limit, and a\nLipschitz condition can be obtained by means of a unified matrix-differential\nalgorithm. (3) The matrix-analytic method is used to compute the fixed point\nwhich leads to performance computation of this system. Finally, we use some\nnumerical examples to illustrate how the performance measures of this\nsupermarket model depend on the non-Poisson inputs and on the non-exponential\nservice times. Thus the results of this paper give new highlight on\nunderstanding influence of non-Poisson inputs and of non-exponential service\ntimes on performance measures of more general supermarket models."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.5", 
    "link": "http://arxiv.org/pdf/1406.2069v1", 
    "title": "Patch-based Hybrid Modelling of Spatially Distributed Systems by Using   Stochastic HYPE - ZebraNet as an Example", 
    "arxiv-id": "1406.2069v1", 
    "author": "Cheng Feng", 
    "publish": "2014-06-09T03:48:15Z", 
    "summary": "Individual-based hybrid modelling of spatially distributed systems is usually\nexpensive. Here, we consider a hybrid system in which mobile agents spread over\nthe space and interact with each other when in close proximity. An\nindividual-based model for this system needs to capture the spatial attributes\nof every agent and monitor the interaction between each pair of them. As a\nresult, the cost of simulating this model grows exponentially as the number of\nagents increases. For this reason, a patch-based model with more abstraction\nbut better scalability is advantageous. In a patch-based model, instead of\nrepresenting each agent separately, we model the agents in a patch as an\naggregation. This property significantly enhances the scalability of the model.\nIn this paper, we convert an individual-based model for a spatially distributed\nnetwork system for wild-life monitoring, ZebraNet, to a patch-based stochastic\nHYPE model with accurate performance evaluation. We show the ease and\nexpressiveness of stochastic HYPE for patch-based modelling of hybrid systems.\nMoreover, a mean-field analytical model is proposed as the fluid flow\napproximation of the stochastic HYPE model, which can be used to investigate\nthe average behaviour of the modelled system over an infinite number of\nsimulation runs of the stochastic HYPE model."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.5", 
    "link": "http://arxiv.org/pdf/1406.3084v4", 
    "title": "Exact Solutions for M/M/c/Setup Queues", 
    "arxiv-id": "1406.3084v4", 
    "author": "Tuan Phung-Duc", 
    "publish": "2014-06-12T00:01:54Z", 
    "summary": "Recently multiserver queues with setup times have been extensively studied\nbecause they have applications in power-saving data centers. The most\nchallenging model is the M/M/$c$/Setup queue where a server is turned off when\nit is idle and is turned on if there are some waiting jobs. Recently, Gandhi et\nal.~(SIGMETRICS 2013, QUESTA 2014) present the recursive renewal reward\napproach as a new mathematical tool to analyze the model. In this paper, we\nderive exact solutions for the same model using two alternative methodologies:\ngenerating function approach and matrix analytic method. The former yields\nseveral theoretical insights into the systems while the latter provides an\nexact recursive algorithm to calculate the joint stationary distribution and\nthen some performance measures so as to give new application insights."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.5", 
    "link": "http://arxiv.org/pdf/1406.7527v1", 
    "title": "Dealing with Zero Density Using Piecewise Phase-type Approximation", 
    "arxiv-id": "1406.7527v1", 
    "author": "Vojt\u011bch \u0158eh\u00e1k", 
    "publish": "2014-06-29T17:23:26Z", 
    "summary": "Every probability distribution can be approximated up to a given precision by\na phase-type distribution, i.e. a distribution encoded by a continuous time\nMarkov chain (CTMC). However, an excessive number of states in the\ncorresponding CTMC is needed for some standard distributions, in particular\nmost distributions with regions of zero density such as uniform or shifted\ndistributions. Addressing this class of distributions, we suggest an\nalternative representation by CTMC extended with discrete-time transitions.\nUsing discrete-time transitions we split the density function into multiple\nintervals. Within each interval, we then approximate the density with standard\nphase-type fitting. We provide an experimental evidence that our method\nrequires only a moderate number of states to approximate such distributions\nwith regions of zero density. Furthermore, the usage of CTMC with discrete-time\ntransitions is supported by a number of techniques for their analysis. Thus,\nour results promise an efficient approach to the transient analysis of a class\nof non-Markovian models."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.5", 
    "link": "http://arxiv.org/pdf/1408.5715v1", 
    "title": "Accelerating unstructured finite volume computations on   field-programmable gate arrays", 
    "arxiv-id": "1408.5715v1", 
    "author": "Peter Szolgay", 
    "publish": "2014-08-25T10:40:43Z", 
    "summary": "Accurate simulations of various physical processes on digital computers\nrequires huge computing performance, therefore accelerating these scientific\nand engineering applications has a great importance. Density of programmable\nlogic devices doubles in every 18 months according to Moore's Law. On the\nrecent devices around one hundred double precision floating-point adders and\nmultipliers can be implemented. In the paper an FPGA based framework is\ndescribed to efficiently utilize this huge computing power to accelerate\nsimulation of complex physical spatiotemporal phenomena. Simulating complicated\ngeometries requires unstructured spatial discretization which results in\nirregular memory access patterns severely limiting computing performance. Data\nlocality is improved by mesh node renumbering technique which results in\npredictable memory access pattern. Additionally storing a small window of node\ndata in the on-chip memory of the FPGA can increase data reuse and decrease\nmemory bandwidth requirements. Generation of the floating-point data path and\ncontrol structure of the arithmetic unit containing dozens of operators is a\nvery challenging task when the goal is high operating frequency. Long and high\nfanout control lines and improper placement can severely affect computing\nperformance. In the paper an automatic data path generation and partitioning\nalgorithm is presented to eliminate long delays and aid placement of the\ncircuit. Efficiency and use of the framework is described by a case study\nsolving the Euler equations on an unstructured mesh using finite volume\ntechnique. On the currently available largest FPGA the generated architecture\ncontains three processing elements working in parallel providing 90 times\nspeedup compared to a high performance microprocessor core."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.5", 
    "link": "http://arxiv.org/pdf/1409.0093v2", 
    "title": "Proceedings of the 1st OMNeT++ Community Summit, Hamburg, Germany,   September 2, 2014", 
    "arxiv-id": "1409.0093v2", 
    "author": "Matthias W\u00e4hlisch", 
    "publish": "2014-08-30T09:05:04Z", 
    "summary": "This is the Proceedings of the 1st OMNeT++ Community Summit, which was held\nin Hamburg, Germany, September 2, 2014."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1409.0792v1", 
    "title": "Characterizing and Subsetting Big Data Workloads", 
    "arxiv-id": "1409.0792v1", 
    "author": "Jingwei Li", 
    "publish": "2014-09-01T10:57:16Z", 
    "summary": "Big data benchmark suites must include a diversity of data and workloads to\nbe useful in fairly evaluating big data systems and architectures. However,\nusing truly comprehensive benchmarks poses great challenges for the\narchitecture community. First, we need to thoroughly understand the behaviors\nof a variety of workloads. Second, our usual simulation-based research methods\nbecome prohibitively expensive for big data. As big data is an emerging field,\nmore and more software stacks are being proposed to facilitate the development\nof big data applications, which aggravates hese challenges. In this paper, we\nfirst use Principle Component Analysis (PCA) to identify the most important\ncharacteristics from 45 metrics to characterize big data workloads from\nBigDataBench, a comprehensive big data benchmark suite. Second, we apply a\nclustering technique to the principle components obtained from the PCA to\ninvestigate the similarity among big data workloads, and we verify the\nimportance of including different software stacks for big data benchmarking.\nThird, we select seven representative big data workloads by removing redundant\nones and release the BigDataBench simulation version, which is publicly\navailable from http://prof.ict.ac.cn/BigDataBench/simulatorversion/."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1409.4297v2", 
    "title": "Performance analysis of a 240 thread tournament level MCTS Go program on   the Intel Xeon Phi", 
    "arxiv-id": "1409.4297v2", 
    "author": "Jaap van den Herik", 
    "publish": "2014-09-15T15:37:11Z", 
    "summary": "In 2013 Intel introduced the Xeon Phi, a new parallel co-processor board. The\nXeon Phi is a cache-coherent many-core shared memory architecture claiming\nCPU-like versatility, programmability, high performance, and power efficiency.\nThe first published micro-benchmark studies indicate that many of Intel's\nclaims appear to be true. The current paper is the first study on the Phi of a\ncomplex artificial intelligence application. It contains an open source MCTS\napplication for playing tournament quality Go (an oriental board game). We\nreport the first speedup figures for up to 240 parallel threads on a real\nmachine, allowing a direct comparison to previous simulation studies. After a\nsubstantial amount of work, we observed that performance scales well up to 32\nthreads, largely confirming previous simulation results of this Go program,\nalthough the performance surprisingly deteriorates between 32 and 240 threads.\nFurthermore, we report (1) unexpected performance anomalies between the Xeon\nPhi and Xeon CPU for small problem sizes and small numbers of threads, and (2)\nthat performance is sensitive to scheduling choices. Achieving good performance\non the Xeon Phi for complex programs is not straightforward; it requires a deep\nunderstanding of (1) search patterns, (2) of scheduling, and (3) of the\narchitecture and its many cores and caches. In practice, the Xeon Phi is less\nstraightforward to program for than originally envisioned by Intel."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1409.8602v1", 
    "title": "Cache-aware Performance Modeling and Prediction for Dense Linear Algebra", 
    "arxiv-id": "1409.8602v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2014-09-30T15:41:41Z", 
    "summary": "Countless applications cast their computational core in terms of dense linear\nalgebra operations. These operations can usually be implemented by combining\nthe routines offered by standard linear algebra libraries such as BLAS and\nLAPACK, and typically each operation can be obtained in many alternative ways.\nInterestingly, identifying the fastest implementation -- without executing it\n-- is a challenging task even for experts. An equally challenging task is that\nof tuning each routine to performance-optimal configurations. Indeed, the\nproblem is so difficult that even the default values provided by the libraries\nare often considerably suboptimal; as a solution, normally one has to resort to\nexecuting and timing the routines, driven by some form of parameter search. In\nthis paper, we discuss a methodology to solve both problems: identifying the\nbest performing algorithm within a family of alternatives, and tuning\nalgorithmic parameters for maximum performance; in both cases, we do not\nexecute the algorithms themselves. Instead, our methodology relies on timing\nand modeling the computational kernels underlying the algorithms, and on a\ntechnique for tracking the contents of the CPU cache. In general, our\nperformance predictions allow us to tune dense linear algebra algorithms within\nfew percents from the best attainable results, thus allowing computational\nscientists and code developers alike to efficiently optimize their linear\nalgebra routines and codes."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1501.06223v1", 
    "title": "A Roofline Visualization Framework", 
    "arxiv-id": "1501.06223v1", 
    "author": "Boyana Norris", 
    "publish": "2015-01-26T00:14:20Z", 
    "summary": "The Roofline Model and its derivatives provide an intuitive representation of\nthe best achievable performance on a given architecture. The Roofline Toolkit\nproject is a collaboration among researchers at Argonne National Laboratory,\nLawrence Berkeley National Laboratory, and the University of Oregon and\nconsists of three main parts: hardware characterization, software\ncharacterization, and data manipulation and visualization interface. These\ncomponents address the different aspects of performance data acquisition and\nmanipulation required for performance analysis, modeling and optimization of\ncodes on existing and emerging architectures. In this paper we introduce an\ninitial implementation of the third component, a system for visualizing\nroofline charts and managing roofline performance analysis data. We discuss the\nimplementation and rationale for the integration of the roofline visualization\nsystem into the Eclipse IDE. An overview of our continuing efforts and goals in\nthe development of this project is provided."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1204.6304v1", 
    "title": "Model for Predicting End User Web Page Response Time", 
    "arxiv-id": "1204.6304v1", 
    "author": "Srijith Ravikumar", 
    "publish": "2012-04-27T19:21:30Z", 
    "summary": "Perceived responsiveness of a web page is one of the most important and least\nunderstood metrics of web page design, and is critical for attracting and\nmaintaining a large audience. Web pages can be designed to meet performance\nSLAs early in the product lifecycle if there is a way to predict the apparent\nresponsiveness of a particular page layout. Response time of a web page is\nlargely influenced by page layout and various network characteristics. Since\nthe network characteristics vary widely from country to country, accurately\nmodeling and predicting the perceived responsiveness of a web page from the end\nuser's perspective has traditionally proven very difficult. We propose a model\nfor predicting end user web page response time based on web page, network,\nbrowser download and browser rendering characteristics. We start by\nunderstanding the key parameters that affect perceived response time. We then\nmodel each of these parameters individually using experimental tests and\nstatistical techniques. Finally, we demonstrate the effectiveness of this model\nby conducting an experimental study with Yahoo! web pages in two countries and\ncompare it with 3rd party measurement application."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1207.5217v3", 
    "title": "Hierarchical Performance Modeling for Ranking Dense Linear Algebra   Algorithms", 
    "arxiv-id": "1207.5217v3", 
    "author": "Elmar Peise", 
    "publish": "2012-07-22T12:04:53Z", 
    "summary": "A large class of dense linear algebra operations, such as LU decomposition or\ninversion of a triangular matrix, are usually performed by blocked algorithms.\nFor one such operation, typically, not only one but many algorithmic variants\nexist; depending on computing architecture, libraries and problem size, each\nvariant attains a different performances. We propose methods and tools to rank\nthe algorithmic variants according to their performance for a given scenario\nwithout executing them.\n  For this purpose, we identify the routines upon which the algorithms are\nbuilt. A first tool - the Sampler - measures the performance of these routines.\nUsing the Sampler, a second tool models their performance. The generated models\nare then used to predict the performance of the considered algorithms. For a\ngiven scenario, these predictions allow us to correctly rank the algorithms\naccording to their performance without executing them. With the help of the\nsame tools, algorithmic parameters such as block-size can be optimally tuned."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IISWC.2014.6983058", 
    "link": "http://arxiv.org/pdf/1207.6295v2", 
    "title": "Characterizing the Impact of the Workload on the Value of Dynamic   Resizing in Data Centers", 
    "arxiv-id": "1207.6295v2", 
    "author": "Chuang Lin", 
    "publish": "2012-07-26T15:17:06Z", 
    "summary": "Energy consumption imposes a significant cost for data centers; yet much of\nthat energy is used to maintain excess service capacity during periods of\npredictably low load. Resultantly, there has recently been interest in\ndeveloping designs that allow the service capacity to be dynamically resized to\nmatch the current workload. However, there is still much debate about the value\nof such approaches in real settings. In this paper, we show that the value of\ndynamic resizing is highly dependent on statistics of the workload process. In\nparticular, both slow time-scale non-stationarities of the workload (e.g., the\npeak-to-mean ratio) and the fast time-scale stochasticity (e.g., the burstiness\nof arrivals) play key roles. To illustrate the impact of these factors, we\ncombine optimization-based modeling of the slow time-scale with stochastic\nmodeling of the fast time scale. Within this framework, we provide both\nanalytic and numerical results characterizing when dynamic resizing does (and\ndoes not) provide benefits."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1304.3767v1", 
    "title": "A Taxonomy of Performance Assurance Methodologies and its Application in   High Performance Computer Architectures", 
    "arxiv-id": "1304.3767v1", 
    "author": "Hemant Rotithor", 
    "publish": "2013-04-13T03:48:53Z", 
    "summary": "This paper presents a systematic approach to the complex problem of high\nconfidence performance assurance of high performance architectures based on\nmethods used over several generations of industrial microprocessors. A taxonomy\nis presented for performance assurance through three key stages of a product\nlife cycle-high level performance, RTL performance, and silicon performance.\nThe proposed taxonomy includes two components-independent performance assurance\nspace for each stage and a correlation performance assurance space between\nstages. It provides a detailed insight into the performance assurance space in\nterms of coverage provided taking into account capabilities and limitations of\ntools and methodologies used at each stage. An application of the taxonomy to\ncases described in the literature and to high performance Intel architectures\nis shown. The proposed work should be of interest to manufacturers of high\nperformance microprocessor/chipset architectures and has not been discussed in\nthe literature."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1305.3490v1", 
    "title": "Stationary analysis of the Shortest Queue First service policy", 
    "arxiv-id": "1305.3490v1", 
    "author": "Alain Simonian", 
    "publish": "2013-05-15T14:18:11Z", 
    "summary": "We analyze the so-called Shortest Queue First (SQF) queueing discipline\nwhereby a unique server addresses queues in parallel by serving at any time\nthat queue with the smallest workload. Considering a stationary system composed\nof two parallel queues and assuming Poisson arrivals and general service time\ndistributions, we first establish the functional equations satisfied by the\nLaplace transforms of the workloads in each queue. We further specialize these\nequations to the so-called \"symmetric case\", with same arrival rates and\nidentical exponential service time distributions at each queue; we then obtain\na functional equation $$ M(z) = q(z) \\cdot M \\circ h(z) + L(z) $$ for unknown\nfunction $M$, where given functions $q$, $L$ and $h$ are related to one branch\nof a cubic polynomial equation. We study the analyticity domain of function $M$\nand express it by a series expansion involving all iterates of function $h$.\nThis allows us to determine empty queue probabilities along with the tail of\nthe workload distribution in each queue. This tail appears to be identical to\nthat of the Head-of-Line preemptive priority system, which is the key feature\ndesired for the SQF discipline."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1305.3496v1", 
    "title": "Stationary analysis of the \"Shortest Queue First\" service policy: the   asymmetric case", 
    "arxiv-id": "1305.3496v1", 
    "author": "Alain Simonian", 
    "publish": "2013-05-15T14:39:03Z", 
    "summary": "As a follow-up to a recent paper considering two symmetric queues, the\n\\textit{Shortest Queue First} service discipline is presently analysed for two\ngeneral asymmetric queues. Using the results previously established and\nassuming exponentially distributed service times, the bivariate Laplace\ntransform of workloads in each queue is shown to depend on the solution\n$\\mathbf{M}$ to a two-dimensional functional equation $$ \\mathbf{M} = Q_1 \\cdot\n\\mathbf{M}\\circ h_1 + Q_2 \\cdot \\mathbf{M}\\circ h_2 + \\mathbf{L} $$ with given\nmatrices $Q_1$, $Q_2$ and vector $\\mathbf{L}$ and where functions $h_1$ and\n$h_2$ are defined each on some rational curve; solution $\\mathbf{M}$ can then\nrepresented by a series expansion involving the semi-group $< h_1, h_2 >$\ngenerated by these two functions. The empty queue probabilities along with the\ntail behaviour of the workload distribution at each queue are characterised."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1305.3536v1", 
    "title": "Analysis of a non-work conserving Generalized Processor Sharing queue", 
    "arxiv-id": "1305.3536v1", 
    "author": "Fabrice Guillemin", 
    "publish": "2013-05-15T16:32:59Z", 
    "summary": "We consider in this paper a non work-conserving Generalized Processor Sharing\n(GPS) system composed of two queues with Poisson arrivals and exponential\nservice times. Using general results due to Fayolle \\emph{et al}, we first\nestablish the stability condition for this system. We then determine the\nfunctional equation satisfied by the generating function of the numbers of jobs\nin both queues and the associated Riemann-Hilbert problem. We prove the\nexistence and the uniqueness of the solution. This allows us to completely\ncharacterize the system, in particular to compute the empty queue probability.\nWe finally derive the tail asymptotics of the number of jobs in one queue."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1306.4773v1", 
    "title": "Performance Bounds for Multiclass FIFO in Communication Networks: A   Deterministic Case", 
    "arxiv-id": "1306.4773v1", 
    "author": "Yuming Jiang", 
    "publish": "2013-06-20T07:28:39Z", 
    "summary": "Multiclass FIFO is used in communication networks such as in input-queueing\nrouters/switches and in wireless networks. For the concern of providing service\nguarantees in such networks, it is crucial to have analytical results, e.g.\nbounds, on the performance of multi-class FIFO. Surprisingly, there are few\nsuch results in the literature. This paper is devoted to filling the gap.\nSpecifically, a single hop deterministic case is studied, for which, delay and\nbacklog bounds are derived, in addition to guaranteed rate and service curve\ncharacterizations that may be exploited to extend the analysis to network\ncases."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1307.1217v1", 
    "title": "Toward a Unified Performance and Power Consumption NAND Flash Memory   Model of Embedded and Solid State Secondary Storage Systems", 
    "arxiv-id": "1307.1217v1", 
    "author": "Eric Senn", 
    "publish": "2013-07-04T06:23:19Z", 
    "summary": "This paper presents a set of models dedicated to describe a flash storage\nsubsystem structure, functions, performance and power consumption behaviors.\nThese models cover a large range of today's NAND flash memory applications.\nThey are designed to be implemented in simulation tools allowing to estimate\nand compare performance and power consumption of I/O requests on flash memory\nbased storage systems. Such tools can also help in designing and validating new\nflash storage systems and management mechanisms. This work is integrated in a\nglobal project aiming to build a framework simulating complex flash storage\nhierarchies for performance and power consumption analysis. This tool will be\nhighly configurable and modular with various levels of usage complexity\naccording to the required aim: from a software user point of view for\nsimulating storage systems, to a developer point of view for designing, testing\nand validating new flash storage management systems."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1307.7271v1", 
    "title": "On the Catalyzing Effect of Randomness on the Per-Flow Throughput in   Wireless Networks", 
    "arxiv-id": "1307.7271v1", 
    "author": "Jens Schmitt", 
    "publish": "2013-07-27T15:27:18Z", 
    "summary": "This paper investigates the throughput capacity of a flow crossing a\nmulti-hop wireless network, whose geometry is characterized by general\nrandomness laws including Uniform, Poisson, Heavy-Tailed distributions for both\nthe nodes' densities and the number of hops. The key contribution is to\ndemonstrate \\textit{how} the \\textit{per-flow throughput} depends on the\ndistribution of 1) the number of nodes $N_j$ inside hops' interference sets, 2)\nthe number of hops $K$, and 3) the degree of spatial correlations. The\nrandomness in both $N_j$'s and $K$ is advantageous, i.e., it can yield larger\nscalings (as large as $\\Theta(n)$) than in non-random settings. An interesting\nconsequence is that the per-flow capacity can exhibit the opposite behavior to\nthe network capacity, which was shown to suffer from a logarithmic decrease in\nthe presence of randomness. In turn, spatial correlations along the end-to-end\npath are detrimental by a logarithmic term."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1307.7943v1", 
    "title": "The Implications of Diverse Applications and Scalable Data Sets in   Benchmarking Big Data Systems", 
    "arxiv-id": "1307.7943v1", 
    "author": "Lixin Zhang", 
    "publish": "2013-07-30T12:34:49Z", 
    "summary": "Now we live in an era of big data, and big data applications are becoming\nmore and more pervasive. How to benchmark data center computer systems running\nbig data applications (in short big data systems) is a hot topic. In this\npaper, we focus on measuring the performance impacts of diverse applications\nand scalable volumes of data sets on big data systems. For four typical data\nanalysis applications---an important class of big data applications, we find\ntwo major results through experiments: first, the data scale has a significant\nimpact on the performance of big data systems, so we must provide scalable\nvolumes of data sets in big data benchmarks. Second, for the four applications,\neven all of them use the simple algorithms, the performance trends are\ndifferent with increasing data scales, and hence we must consider not only\nvariety of data sets but also variety of applications in benchmarking big data\nsystems."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijsea.2013.4201", 
    "link": "http://arxiv.org/pdf/1307.8013v1", 
    "title": "Characterizing Data Analysis Workloads in Data Centers", 
    "arxiv-id": "1307.8013v1", 
    "author": "Chunjie Luo", 
    "publish": "2013-07-30T15:23:25Z", 
    "summary": "As the amount of data explodes rapidly, more and more corporations are using\ndata centers to make effective decisions and gain a competitive edge. Data\nanalysis applications play a significant role in data centers, and hence it has\nbecame increasingly important to understand their behaviors in order to further\nimprove the performance of data center computer systems. In this paper, after\ninvestigating three most important application domains in terms of page views\nand daily visitors, we choose eleven representative data analysis workloads and\ncharacterize their micro-architectural characteristics by using hardware\nperformance counters, in order to understand the impacts and implications of\ndata analysis workloads on the systems equipped with modern superscalar\nout-of-order processors. Our study on the workloads reveals that data analysis\napplications share many inherent characteristics, which place them in a\ndifferent class from desktop (SPEC CPU2006), HPC (HPCC), and service workloads,\nincluding traditional server workloads (SPECweb2005) and scale-out service\nworkloads (four among six benchmarks in CloudSuite), and accordingly we give\nseveral recommendations for architecture and system optimizations. On the basis\nof our workload characterization work, we released a benchmark suite named\nDCBench for typical datacenter workloads, including data analysis and service\nworkloads, with an open-source license on our project home page on\nhttp://prof.ict.ac.cn/DCBench. We hope that DCBench is helpful for performing\narchitecture and small-to-medium scale system researches for datacenter\ncomputing."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1312.2949v1", 
    "title": "A Survey of Embedded Software Profiling Methodologies", 
    "arxiv-id": "1312.2949v1", 
    "author": "Arvind Rajwat", 
    "publish": "2013-12-10T05:15:32Z", 
    "summary": "Embedded Systems combine one or more processor cores with dedicated logic\nrunning on an ASIC or FPGA to meet design goals at reasonable cost. It is\nachieved by profiling the application with variety of aspects like performance,\nmemory usage, cache hit versus cache miss, energy consumption, etc. Out of\nthese, performance estimation is more important than others. With ever\nincreasing system complexities, it becomes quite necessary to carry out\nperformance estimation of embedded software implemented in a particular\nprocessor for fast design space exploration. Such profiled data also guides the\ndesigner how to partition the system for Hardware (HW) and Software (SW)\nenvironments. In this paper, we propose a classification for currently\navailable Embedded Software Profiling Tools, and we present different academic\nand industrial approaches in this context. Based on these observations, it will\nbe easy to identify such common principles and needs which are required for a\ntrue Software Profiling Tool for a particular application."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1401.3824v1", 
    "title": "Power Aware Wireless File Downloading: A Constrained Restless Bandit   Approach", 
    "arxiv-id": "1401.3824v1", 
    "author": "Michael J. Neely", 
    "publish": "2014-01-16T04:18:47Z", 
    "summary": "This paper treats power-aware throughput maximization in a multi-user file\ndownloading system. Each user can receive a new file only after its previous\nfile is finished. The file state processes for each user act as coupled Markov\nchains that form a generalized restless bandit system. First, an optimal\nalgorithm is derived for the case of one user. The algorithm maximizes\nthroughput subject to an average power constraint. Next, the one-user algorithm\nis extended to a low complexity heuristic for the multi-user problem. The\nheuristic uses a simple online index policy and its effectiveness is shown via\nsimulation. For simple 3-user cases where the optimal solution can be computed\noffline, the heuristic is shown to be near-optimal for a wide range of\nparameters."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1403.2486v1", 
    "title": "Theoretical Evaluation of Offloading through Wireless LANs", 
    "arxiv-id": "1403.2486v1", 
    "author": "Ryoichi Kawahara", 
    "publish": "2014-03-11T06:55:04Z", 
    "summary": "Offloading of cellular traffic through a wireless local area network (WLAN)\nis theoretically evaluated. First, empirical data sets of the locations of WLAN\ninternet access points are analyzed and an inhomogeneous Poisson process\nconsisting of high, normal, and low density regions is proposed as a spatial\npoint process model for these configurations. Second, performance metrics, such\nas mean available bandwidth for a user and the number of vertical handovers,\nare evaluated for the proposed model through geometric analysis. Explicit\nformulas are derived for the metrics, although they depend on many parameters\nsuch as the number of WLAN access points, the shape of each WLAN coverage\nregion, the location of each WLAN access point, the available bandwidth (bps)\nof the WLAN, and the shape and available bandwidth (bps) of each subregion\nidentified by the channel quality indicator in a cell of the cellular network.\nExplicit formulas strongly suggest that the bandwidth a user experiences does\nnot depend on the user mobility. This is because the bandwidth available by a\nuser who does not move and that available by a user who moves are the same or\napproximately the same as a probabilistic distribution. Numerical examples show\nthat parameters, such as the size of regions where placement of WLAN access\npoints is not allowed and the mean density of WLANs in high density regions,\nhave a large impact on performance metrics. In particular, a homogeneous\nPoisson process model as the WLAN access point location model largely\noverestimates the mean available bandwidth for a user and the number of\nvertical handovers. The overestimated mean available bandwidth is, for example,\nabout 50% in a certain condition."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1405.1916v1", 
    "title": "Asymptotic and Numerical Analysis of Multiserver Retrial Queue with   Guard Channel for Cellular Networks", 
    "arxiv-id": "1405.1916v1", 
    "author": "Tuan Phung-Duc", 
    "publish": "2014-05-08T13:17:09Z", 
    "summary": "This paper considers a retrial queueing model for a base station in cellular\nnetworks where fresh calls and handover calls are available. Fresh calls are\ninitiated from the cell of the base station. On the other hand, a handover call\nhas been connecting to a base station and moves to another one. In order to\nkeep the continuation of the communication, it is desired that an available\nchannel in the new base station is immediately assigned to the handover call.\nTo this end, a channel is reserved as the guard channel for handover calls in\nbase stations. Blocked fresh and handover calls join a virtual orbit and repeat\ntheir attempts in a later time. We assume that a base station can recognize\nretrial calls and give them the same priority as that of handover calls. We\nmodel a base station by a multiserver retrial queue with priority customers for\nwhich a level-dependent QBD process is formulated. We obtain Taylor series\nexpansion for the nonzero elements of the rate matrices of the level-dependent\nQBD. Using the expansion results, we obtain an asymptotic upper bound for the\njoint stationary distribution of the number of busy channels and that of\ncustomers in the orbit. Furthermore, we derive an efficient numerical algorithm\nto calculate the joint stationary distribution."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1407.4777v4", 
    "title": "Optimizing Performance of Continuous-Time Stochastic Systems using   Timeout Synthesis", 
    "arxiv-id": "1407.4777v4", 
    "author": "Vojt\u011bch \u0158eh\u00e1k", 
    "publish": "2014-07-17T19:10:57Z", 
    "summary": "We consider parametric version of fixed-delay continuous-time Markov chains\n(or equivalently deterministic and stochastic Petri nets, DSPN) where\nfixed-delay transitions are specified by parameters, rather than concrete\nvalues. Our goal is to synthesize values of these parameters that, for a given\ncost function, minimise expected total cost incurred before reaching a given\nset of target states. We show that under mild assumptions, optimal values of\nparameters can be effectively approximated using translation to a Markov\ndecision process (MDP) whose actions correspond to discretized values of these\nparameters."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1407.4879v1", 
    "title": "Synthetic Generation of Solar States for Smart Grid: A Multiple Segment   Markov Chain Apptoach", 
    "arxiv-id": "1407.4879v1", 
    "author": "David B. Smith", 
    "publish": "2014-07-18T03:09:59Z", 
    "summary": "The use of photovoltaic (PV) sources is becoming very popular in smart grid\nfor their ecological benefits, with higher scalability and utilization for\nlocal generation and delivery. PV can also potentially avoid the energy losses\nthat are normally associated with long-range grid distribution. The increased\npenetration of solar panels, however, has introduced a need for solar energy\nmodels that are capable of producing realistic synthetic data with small error\nmargins. Such models, for instance, can be used to design the appropriate size\nof energy storage devices or to determine the maximum charging rate of a\nPV-powered electric vehicle (EV) charging station. In this regard, this paper\nproposes a stochastic model for solar generation using a Markov chain approach.\nBased on real data, it is first shown that the solar states are\ninter-dependent, and thus suitable for modeling using a Markov model. Then, the\nprobabilities of transition between states are shown to be heterogeneous over\ndifferent time segments. A model is proposed that captures the inter temporal\ndependency of solar irradiance through segmentation of the Markov chain across\ndifferent times of the day. In the studied model, different state transition\nmatrices are constructed for different time segments, which the proposed\nalgorithm then uses to generate the solar states for different times of the\nday. Numerical examples are provided to show the effectiveness of the proposed\nsynthetic generator."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1410.5561v1", 
    "title": "Towards energy efficiency and maximum computational intensity for   stencil algorithms using wavefront diamond temporal blocking", 
    "arxiv-id": "1410.5561v1", 
    "author": "David Keyes", 
    "publish": "2014-10-21T07:35:32Z", 
    "summary": "We study the impact of tunable parameters on computational intensity (i.e.,\ninverse code balance) and energy consumption of multicore-optimized wavefront\ndiamond temporal blocking (MWD) applied to different stencil-based update\nschemes. MWD combines the concepts of diamond tiling and multicore-aware\nwavefront blocking in order to achieve lower cache size requirements than\nstandard single-core wavefront temporal blocking. We analyze the impact of the\ncache block size on the theoretical and observed code balance, introduce loop\ntiling in the leading dimension to widen the range of applicable diamond sizes,\nand show performance results on a contemporary Intel CPU. The impact of code\nbalance on power dissipation on the CPU and in the DRAM is investigated and\nshows that DRAM power is a decisive factor for energy consumption, which is\nstrongly influenced by the code balance. Furthermore we show that highest\nperformance does not necessarily lead to lowest energy even if the clock speed\nis fixed."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1411.2867v1", 
    "title": "Buffer occupancy asymptotics in rate proportional sharing networks with   heterogeneous long-tailed inputs", 
    "arxiv-id": "1411.2867v1", 
    "author": "Nikolay B. Likhanov", 
    "publish": "2014-11-11T16:13:32Z", 
    "summary": "In this paper, we consider a network of rate proportional processor sharing\nservers in which sessions with long-tailed duration arrive as Poisson\nprocesses. In particular, we assume that a session of type $n$ transmits at a\nrate $r_n$ bits per unit time and lasts for a random time $\\tau_n$ with a\ngeneralized Pareto distribution given by $P \\{\\tau_n > x\\} \\sim \\alpha_n\nx^{-(1+\\beta_n)}$ for large $x$, where $\\alpha_n, \\beta_n > 0$. The weights are\ntaken to be the rates of the flows. The network is assumed to be loop-free with\nrespect to source-destination routes. We characterize the order $O-$asymptotics\nof the complementary buffer occupancy distribution at each node in terms of the\ninput characteristics of the sessions. In particular, we show that the\ndistributions obey a power law whose exponent can be calculated via solving a\nfixed point and deterministic knapsack problem. The paper concludes with some\ncanonical examples."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1411.4759v4", 
    "title": "Modeling LRU caches with Shot Noise request processes", 
    "arxiv-id": "1411.4759v4", 
    "author": "Giovanni Luca Torrisi", 
    "publish": "2014-11-18T08:20:39Z", 
    "summary": "In this paper we analyze Least Recently Used (LRU) caches operating under the\nShot Noise requests Model (SNM). The SNM was recently proposed to better\ncapture the main characteristics of today Video on Demand (VoD) traffic. We\ninvestigate the validity of Che's approximation through an asymptotic analysis\nof the cache eviction time. In particular, we provide a large deviation\nprinciple, a law of large numbers and a central limit theorem for the cache\neviction time, as the cache size grows large. Finally, we derive upper and\nlower bounds for the \"hit\" probability in tandem networks of caches under Che's\napproximation."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1411.7224v1", 
    "title": "Efficient analysis of caching strategies under dynamic content   popularity", 
    "arxiv-id": "1411.7224v1", 
    "author": "Stefano Traverso", 
    "publish": "2014-11-26T13:42:41Z", 
    "summary": "In this paper we develop a novel technique to analyze both isolated and\ninterconnected caches operating under different caching strategies and\nrealistic traffic conditions. The main strength of our approach is the ability\nto consider dynamic contents which are constantly added into the system\ncatalogue, and whose popularity evolves over time according to desired\nprofiles. We do so while preserving the simplicity and computational efficiency\nof models developed under stationary popularity conditions, which are needed to\nanalyze several caching strategies. Our main achievement is to show that the\nimpact of content popularity dynamics on cache performance can be effectively\ncaptured into an analytical model based on a fixed content catalogue (i.e., a\ncatalogue whose size and objects' popularity do not change over time)."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1412.2347v1", 
    "title": "Proceedings of the 5th International Workshop on Adaptive Self-tuning   Computing Systems 2015 (ADAPT'15)", 
    "arxiv-id": "1412.2347v1", 
    "author": "Grigori Fursin", 
    "publish": "2014-12-07T12:21:58Z", 
    "summary": "This is the proceedings of the 5th International Workshop on Adaptive\nSelf-tuning Computing Systems 2015 (ADAPT'15)."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1412.7682v1", 
    "title": "Accelerating Correlation Power Analysis Using Graphics Processing Units", 
    "arxiv-id": "1412.7682v1", 
    "author": "Darshana Jayasinghe", 
    "publish": "2014-12-24T15:10:03Z", 
    "summary": "Correlation Power Analysis (CPA) is a type of power analysis based side\nchannel attack that can be used to derive the secret key of encryption\nalgorithms including DES (Data Encryption Standard) and AES (Advanced\nEncryption Standard). A typical CPA attack on unprotected AES is performed by\nanalysing a few thousand power traces that requires about an hour of\ncomputational time on a general purpose CPU. Due to the severity of this\nsituation, a large number of researchers work on countermeasures to such\nattacks. Verifying that a proposed countermeasure works well requires\nperforming the CPA attack on about 1.5 million power traces. Such processing,\neven for a single attempt of verification on commodity hardware would run for\nseveral days making the verification process infeasible. Modern Graphics\nProcessing Units (GPUs) have support for thousands of light weight threads,\nmaking them ideal for parallelizable algorithms like CPA. While the cost of a\nGPU being lesser than a high performance multicore server, still the GPU\nperformance for this algorithm is many folds better than that of a multicore\nserver. We present an algorithm and its implementation on GPU for CPA on\n128-bit AES that is capable of executing 1300x faster than that on a single\nthreaded CPU and more than 60x faster than that on a 32 threaded multicore\nserver. We show that an attack that would take hours on the multicore server\nwould take even less than a minute on a much cost effective GPU."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1503.06301v1", 
    "title": "Effective Handling of Urgent Jobs - Speed Up Scheduling for Computing   Applications", 
    "arxiv-id": "1503.06301v1", 
    "author": "Kamalakar Karlapalem", 
    "publish": "2015-03-21T13:51:48Z", 
    "summary": "A queue is required when a service provider is not able to handle jobs\narriving over the time. In a highly flexible and dynamic environment, some jobs\nmight demand for faster execution at run-time especially when the resources are\nlimited and the jobs are competing for acquiring resources. A user might demand\nfor speed up (reduced wait time) for some of the jobs present in the queue at\nrun time. In such cases, it is required to accelerate (directly sending the job\nto the server) urgent jobs (requesting for speed up) ahead of other jobs\npresent in the queue for an earlier completion of urgent jobs. Under the\nassumption of no additional resources, such acceleration of jobs would result\nin slowing down of other jobs present in the queue. In this paper, we formulate\nthe problem of Speed Up Scheduling without acquiring any additional resources\nfor the scheduling of on-line speed up requests posed by a user at run-time and\npresent algorithms for the same. We apply the idea of Speed Up Scheduling to\ntwo different domains -Web Scheduling and CPU Scheduling. We demonstrate our\nresults with a simulation based model using trace driven workload and synthetic\ndatasets to show the usefulness of Speed Up scheduling. Speed Up provides a new\nway of addressing urgent jobs, provides a different evaluation criteria for\ncomparing scheduling algorithms and has practical applications."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1503.06382v1", 
    "title": "On the tradeoff of average delay, average service cost, and average   utility for single server queues with monotone policies", 
    "arxiv-id": "1503.06382v1", 
    "author": "Vineeth Bala Sukumaran", 
    "publish": "2015-03-22T04:00:45Z", 
    "summary": "In this thesis, we study the optimal tradeoff of average delay, average\nservice cost, and average utility for single server queueing models, with and\nwithout admission control. The continuous time and discrete time queueing\nmodels that we consider are motivated by cross-layer models for noisy\npoint-to-point links, with random packet arrivals. We study the above tradeoff\nproblem for a class of admissible policies, which are monotone and stationary\nand obtain an asymptotic characterization of the minimum average delay as a\nfunction of the average service cost and average utility constraints."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1503.07693v2", 
    "title": "Communication Patterns in Mean Field Models for Wireless Sensor Networks", 
    "arxiv-id": "1503.07693v2", 
    "author": "Jean-Paul Linnartz", 
    "publish": "2015-03-26T11:38:29Z", 
    "summary": "Wireless sensor networks are usually composed of a large number of nodes, and\nwith the increasing processing power and power consumption efficiency they are\nexpected to run more complex protocols in the future. These pose problems in\nthe field of verification and performance evaluation of wireless networks. In\nthis paper, we tailor the mean-field theory as a modeling technique to analyze\ntheir behavior. We apply this method to the slotted ALOHA protocol, and\nestablish results on the long term trends of the protocol within a very large\nnetwork, specially regarding the stability of ALOHA-type protocols."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1503.07931v1", 
    "title": "Are Markov Models Effective for Storage Reliability Modelling?", 
    "arxiv-id": "1503.07931v1", 
    "author": "K. Gopinath", 
    "publish": "2015-03-27T00:08:13Z", 
    "summary": "Continuous Time Markov Chains (CTMC) have been used extensively to model\nreliability of storage systems. While the exponentially distributed sojourn\ntime of Markov models is widely known to be unrealistic (and it is necessary to\nconsider Weibull-type models for components such as disks), recent work has\nalso highlighted some additional infirmities with the CTMC model, such as the\nability to handle repair times. Due to the memoryless property of these models,\nany failure or repair of one component resets the \"clock\" to zero with any\npartial repair or aging in some other subsystem forgotten. It has therefore\nbeen argued that simulation is the only accurate technique available for\nmodelling the reliability of a storage system with multiple components.\n  We show how both the above problematic aspects can be handled when we\nconsider a careful set of approximations in a detailed model of the system. A\ndetailed model has many states, and the transitions between them and the\ncurrent state captures the \"memory\" of the various components. We model a\nnon-exponential distribution using a sum of exponential distributions, along\nwith the use of a CTMC solver in a probabilistic model checking tool that has\nsupport for reducing large state spaces. Furthermore, it is possible to get\nresults close to what is obtained through simulation and at much lower cost."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1504.00591v2", 
    "title": "Run Time Approximation of Non-blocking Service Rates for Streaming   Systems", 
    "arxiv-id": "1504.00591v2", 
    "author": "Roger D. Chamberlain", 
    "publish": "2015-04-02T15:47:19Z", 
    "summary": "Stream processing is a compute paradigm that promises safe and efficient\nparallelism. Modern big-data problems are often well suited for stream\nprocessing's throughput-oriented nature. Realization of efficient stream\nprocessing requires monitoring and optimization of multiple communications\nlinks. Most techniques to optimize these links use queueing network models or\nnetwork flow models, which require some idea of the actual execution rate of\neach independent compute kernel within the system. What we want to know is how\nfast can each kernel process data independent of other communicating kernels.\nThis is known as the \"service rate\" of the kernel within the queueing\nliterature. Current approaches to divining service rates are static. Modern\nworkloads, however, are often dynamic. Shared cloud systems also present\napplications with highly dynamic execution environments (multiple users,\nhardware migration, etc.). It is therefore desirable to continuously re-tune an\napplication during run time (online) in response to changing conditions. Our\napproach enables online service rate monitoring under most conditions,\nobviating the need for reliance on steady state predictions for what are\nprobably non-steady state phenomena. First, some of the difficulties associated\nwith online service rate determination are examined. Second, the algorithm to\napproximate the online non-blocking service rate is described. Lastly, the\nalgorithm is implemented within the open source RaftLib framework for\nvalidation using a simple microbenchmark as well as two full streaming\napplications."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1504.00825v2", 
    "title": "ALEA: Fine-grain Energy Profiling with Basic Block Sampling", 
    "arxiv-id": "1504.00825v2", 
    "author": "Bronis R. de Supinski", 
    "publish": "2015-04-03T11:57:11Z", 
    "summary": "Energy efficiency is an essential requirement for all contemporary computing\nsystems. We thus need tools to measure the energy consumption of computing\nsystems and to understand how workloads affect it. Significant recent research\neffort has targeted direct power measurements on production computing systems\nusing on-board sensors or external instruments. These direct methods have in\nturn guided studies of software techniques to reduce energy consumption via\nworkload allocation and scaling. Unfortunately, direct energy measurements are\nhampered by the low power sampling frequency of power sensors. The coarse\ngranularity of power sensing limits our understanding of how power is allocated\nin systems and our ability to optimize energy efficiency via workload\nallocation.\n  We present ALEA, a tool to measure power and energy consumption at the\ngranularity of basic blocks, using a probabilistic approach. ALEA provides\nfine-grained energy profiling via statistical sampling, which overcomes the\nlimitations of power sensing instruments. Compared to state-of-the-art energy\nmeasurement tools, ALEA provides finer granularity without sacrificing\naccuracy. ALEA achieves low overhead energy measurements with mean error rates\nbetween 1.4% and 3.5% in 14 sequential and parallel benchmarks tested on both\nIntel and ARM platforms. The sampling method caps execution time overhead at\napproximately 1%. ALEA is thus suitable for online energy monitoring and\noptimization. Finally, ALEA is a user-space tool with a portable,\nmachine-independent sampling method. We demonstrate two use cases of ALEA,\nwhere we reduce the energy consumption of a k-means computational kernel by 37%\nand an ocean modelling code by 33%, compared to high-performance execution\nbaselines, by varying the power optimization strategy between basic blocks."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1504.04074v1", 
    "title": "Power Aware Wireless File Downloading: A Lyapunov Indexing Approach to A   Constrained Restless Bandit Problem", 
    "arxiv-id": "1504.04074v1", 
    "author": "Michael J. Neely", 
    "publish": "2015-04-16T00:43:27Z", 
    "summary": "This paper treats power-aware throughput maxi-mization in a multi-user file\ndownloading system. Each user can receive a new file only after its previous\nfile is finished. The file state processes for each user act as coupled Markov\nchains that form a generalized restless bandit system. First, an optimal\nalgorithm is derived for the case of one user. The algorithm maximizes\nthroughput subject to an average power constraint. Next, the one-user algorithm\nis extended to a low complexity heuristic for the multi-user problem. The\nheuristic uses a simple online index policy. In a special case with no\npower-constraint, the multi-user heuristic is shown to be throughput optimal.\nSimulations are used to demonstrate effectiveness of the heuristic in the\ngeneral case. For simple cases where the optimal solution can be computed\noffline, the heuristic is shown to be near-optimal for a wide range of\nparameters."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1504.07908v1", 
    "title": "Inhomogeneous CTMC Model of a Call Center with Balking and Abandonment", 
    "arxiv-id": "1504.07908v1", 
    "author": "Maciej Rafal Burak", 
    "publish": "2015-04-29T16:03:40Z", 
    "summary": "This paper considers a nonstationary multiserver queuing model with\nabandonment and balking for inbound call centers. We present a continuous time\nMarkov chain (CTMC) model which captures the important characteristics of an\ninbound call center and obtain a numerical solution for its transient state\nprobabilities using uniformization method with steady-state detection.\nKeywords: call center, transient, Markov processes, numerical methods,\nuniformization, abandonment, balking"
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1505.03374v2", 
    "title": "Data dependent energy modelling for worst case energy consumption   analysis", 
    "arxiv-id": "1505.03374v2", 
    "author": "Kerstin Eder", 
    "publish": "2015-05-13T13:21:25Z", 
    "summary": "This paper examines the impact of operand values upon instruction level\nenergy models of embedded processors, to explore whether the requirements for\nsafe worst case energy consumption (WCEC) analysis can be met. WCEC is similar\nto worst case execution time (WCET) analysis, but seeks to determine whether a\ntask can be completed within an energy budget rather than within a deadline.\nExisting energy models that underpin such analysis typically use energy\nmeasurements from random input data, providing average or otherwise unbounded\nestimates not necessarily suitable for worst case analysis.\n  We examine energy consumption distributions of two benchmarks under a range\nof input data on two cache-less embedded architectures, AVR and XS1-L. We find\nthat the worst case can be predicted with a distribution created from random\ndata. We propose a model to obtain energy distributions for instruction\nsequences that can be composed, enabling WCEC analysis on program basic blocks.\nData dependency between instructions is also examined, giving a case where\ndependencies create a bimodal energy distribution. The worst case energy\nprediction remains safe. We conclude that worst-case energy models based on a\nprobabilistic approach are suitable for safe WCEC analysis."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1505.05135v1", 
    "title": "Network Simulator - Vis\u00e3o Geral da Ferramenta de Simula\u00e7\u00e3o de   Redes", 
    "arxiv-id": "1505.05135v1", 
    "author": "Rafael Gon\u00e7alves Bezerra de Ara\u00fajo", 
    "publish": "2015-04-27T18:29:58Z", 
    "summary": "This paper describes NS - Network Simulator, the computer networks simulation\ntool. We offer an overview NS, and also analyze its characteristics and\nfunctions. Finally, we present in detail all steps for preparing a simulation\nof a simple model in NS."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1506.01494v1", 
    "title": "Benchmarking Big Data Systems: State-of-the-Art and Future Directions", 
    "arxiv-id": "1506.01494v1", 
    "author": "Lei Wang", 
    "publish": "2015-06-04T07:48:37Z", 
    "summary": "The great prosperity of big data systems such as Hadoop in recent years makes\nthe benchmarking of these systems become crucial for both research and industry\ncommunities. The complexity, diversity, and rapid evolution of big data systems\ngives rise to various new challenges about how we design generators to produce\ndata with the 4V properties (i.e. volume, velocity, variety and veracity), as\nwell as implement application-specific but still comprehensive workloads.\nHowever, most of the existing big data benchmarks can be described as attempts\nto solve specific problems in benchmarking systems. This article investigates\nthe state-of-the-art in benchmarking big data systems along with the future\nchallenges to be addressed to realize a successful and efficient benchmark."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1506.03997v1", 
    "title": "Short Note on Costs of Floating Point Operations on current x86-64   Architectures: Denormals, Overflow, Underflow, and Division by Zero", 
    "arxiv-id": "1506.03997v1", 
    "author": "Gerhard Wellein", 
    "publish": "2015-06-12T12:09:03Z", 
    "summary": "Simple floating point operations like addition or multiplication on\nnormalized floating point values can be computed by current AMD and Intel\nprocessors in three to five cycles. This is different for denormalized numbers,\nwhich appear when an underflow occurs and the value can no longer be\nrepresented as a normalized floating-point value. Here the costs are about two\nmagnitudes higher."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2011.1203", 
    "link": "http://arxiv.org/pdf/1508.02055v1", 
    "title": "Scalable Reliability Modelling of RAID Storage Subsystems", 
    "arxiv-id": "1508.02055v1", 
    "author": "K. Gopinath", 
    "publish": "2015-03-26T10:02:39Z", 
    "summary": "Reliability modelling of RAID storage systems with its various components\nsuch as RAID controllers, enclosures, expanders, interconnects and disks is\nimportant from a storage system designer's point of view. A model that can\nexpress all the failure characteristics of the whole RAID storage system can be\nused to evaluate design choices, perform cost reliability trade-offs and\nconduct sensitivity analyses. However, including such details makes the\ncomputational models of reliability quickly infeasible.\n  We present a CTMC reliability model for RAID storage systems that scales to\nmuch larger systems than heretofore reported and we try to model all the\ncomponents as accurately as possible. We use several state-space reduction\ntechniques at the user level, such as aggregating all in-series components and\nhierarchical decomposition, to reduce the size of our model. To automate\ncomputation of reliability, we use the PRISM model checker as a CTMC solver\nwhere appropriate. Our modelling techniques using PRISM are more practical (in\nboth time and effort) compared to previously reported Monte-Carlo simulation\ntechniques.\n  Our model for RAID storage systems (that includes, for example, disks,\nexpanders, enclosures) uses Weibull distributions for disks and, where\nappropriate, correlated failure modes for disks, while we use exponential\ndistributions with independent failure modes for all other components. To use\nthe CTMC solver, we approximate the Weibull distribution for a disk using sum\nof exponentials and we confirm that this model gives results that are in\nreasonably good agreement with those from the sequential Monte Carlo simulation\nmethods for RAID disk subsystems reported in literature earlier. Using a\ncombination of scalable techniques, we are able to model and compute\nreliability for fairly large configurations with upto 600 disks using this\nmodel."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2832087.2832092", 
    "link": "http://arxiv.org/pdf/1509.03778v2", 
    "title": "Automatic Loop Kernel Analysis and Performance Modeling With Kerncraft", 
    "arxiv-id": "1509.03778v2", 
    "author": "Gerhard Wellein", 
    "publish": "2015-09-12T20:47:29Z", 
    "summary": "Analytic performance models are essential for understanding the performance\ncharacteristics of loop kernels, which consume a major part of CPU cycles in\ncomputational science. Starting from a validated performance model one can\ninfer the relevant hardware bottlenecks and promising optimization\nopportunities. Unfortunately, analytic performance modeling is often tedious\neven for experienced developers since it requires in-depth knowledge about the\nhardware and how it interacts with the software. We present the \"Kerncraft\"\ntool, which eases the construction of analytic performance models for streaming\nkernels and stencil loop nests. Starting from the loop source code, the problem\nsize, and a description of the underlying hardware, Kerncraft can ideally\npredict the single-core performance and scaling behavior of loops on multicore\nprocessors using the Roofline or the Execution-Cache-Memory (ECM) model. We\ndescribe the operating principles of Kerncraft with its capabilities and\nlimitations, and we show how it may be used to quickly gain insights by\naccelerated analytic modeling."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2832087.2832092", 
    "link": "http://arxiv.org/pdf/1509.06506v1", 
    "title": "Latency Analysis of an Aerial Video Tracking System Using Fiacre and   Tina", 
    "arxiv-id": "1509.06506v1", 
    "author": "Didier Le Botlan", 
    "publish": "2015-09-22T08:40:00Z", 
    "summary": "We describe our experience with modeling a video tracking system used to\ndetect and follow moving targets from an airplane. We provide a formal model\nthat takes into account the real-time properties of the system and use it to\ncompute the worst and best-case end to end latency. We also compute a lower\nbound on the delay between the loss of two frames. Our approach is based on the\nmodel-checking tool Tina, that provides state-space generation and\nmodel-checking algorithms for an extension of Time Petri Nets with data and\npriorities. We propose several models divided in two main categories: first\nTime Petri Net models, which are used to study the behavior of the system in\nthe most basic way; then models based on the Fiacre specification language,\nwhere we take benefit of richer data structures to directly model the buffering\nof video information and the use of an unbounded number of frame identifiers."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2832087.2832092", 
    "link": "http://arxiv.org/pdf/1511.02494v3", 
    "title": "A lightweight optimization selection method for Sparse Matrix-Vector   Multiplication", 
    "arxiv-id": "1511.02494v3", 
    "author": "Nectarios Koziris", 
    "publish": "2015-11-08T15:06:10Z", 
    "summary": "In this paper, we propose an optimization selection methodology for the\nubiquitous sparse matrix-vector multiplication (SpMV) kernel. We propose two\nmodels that attempt to identify the major performance bottleneck of the kernel\nfor every instance of the problem and then select an appropriate optimization\nto tackle it. Our first model requires online profiling of the input matrix in\norder to detect its most prevailing performance issue, while our second model\nonly uses comprehensive structural features of the sparse matrix. Our method\ndelivers high performance stability for SpMV across different platforms and\nsparse matrices, due to its application and architecture awareness. Our\nexperimental results demonstrate that a) our approach is able to distinguish\nand appropriately optimize special matrices in multicore platforms that fall\nout of the standard class of memory bandwidth bound matrices, and b) lead to a\nsignificant performance gain of 29% in a manycore platform compared to an\narchitecture-centric optimization, as a result of the successful selection of\nthe appropriate optimization for the great majority of the matrices. With a\nruntime overhead equivalent to a couple dozen SpMV operations, our approach is\npractical for use in iterative numerical solvers of real-life applications."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2832087.2832092", 
    "link": "http://arxiv.org/pdf/1511.05585v1", 
    "title": "Model-Driven Automatic Tiling with Cache Associativity Lattices", 
    "arxiv-id": "1511.05585v1", 
    "author": "Adrian Tate", 
    "publish": "2015-11-17T21:14:50Z", 
    "summary": "Traditional compiler optimization theory distinguishes three separate classes\nof cache miss -- Cold, Conflict and Capacity. Tiling for cache is typically\nguided by capacity miss counts. Models of cache function have not been\neffectively used to guide cache tiling optimizations due to model error and\nexpense. Instead, heuristic or empirical approaches are used to select tilings.\nWe argue that conflict misses, traditionally neglected or seen as a small\nconstant effect, are the only fundamentally important cache miss category, that\nthey form a solid basis by which caches can become modellable, and that models\nleaning on cache associatvity analysis can be used to generate cache performant\ntilings. We develop a mathematical framework that expresses potential and\nactual cache misses in associative caches using Associativity Lattices. We show\nthese lattices to possess two theoretical advantages over rectangular tiles --\nvolume maximization and miss regularity. We also show that to generate such\nlattice tiles requires, unlike rectangular tiling, no explicit, expensive\nlattice point counting. We also describe an implementation of our lattice\ntiling approach, show that it can be used to give speedups of over 10x versus\nunoptimized code, and despite currently only tiling for one level of cache, can\nalready be competitive with the aggressive compiler optimizations used in\ngeneral purposes compares such as GCC and Intel's ICC. We also show that the\ntiling approach can lead to reasonable automatic parallelism when compared to\nexisting auto-threading compilers."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2832087.2832092", 
    "link": "http://arxiv.org/pdf/1511.08635v1", 
    "title": "HPA: An Opportunistic Approach to Embedded Energy Efficiency", 
    "arxiv-id": "1511.08635v1", 
    "author": "Alberto Dassatti", 
    "publish": "2015-11-27T11:59:41Z", 
    "summary": "Reducing energy consumption is a challenge that is faced on a daily basis by\nteams from the High-Performance Computing as well as the Embedded domain. This\nissue is mostly attacked from an hardware perspective, by devising\narchitectures that put energy efficiency as a primary target, often at the cost\nof processing power. Lately, computing platforms have become more and more\nheterogeneous, but the exploitation of these additional capabilities is so\ncomplex from the application developer's perspective that they are left unused\nmost of the time, resulting therefore in a supplemental waste of energy rather\nthan in faster processing times.\n  In this paper we present a transparent, on-the-fly optimization scheme that\nallows a generic application to automatically exploit the available computing\nunits to partition its computational load. We have called our approach\nHeterogeneous Platform Accelerator (HPA). The idea is to use profiling to\nautomatically select a computing-intensive candidate for acceleration, and then\ndistribute the computations to the different units by off-loading blocks of\ncode to them.\n  Using an NVIDIA Jetson TK1 board, we demonstrate that not only HPA results in\nfaster processing speed, but also in a considerable reduction in the total\nenergy absorbed."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1512.05882v1", 
    "title": "Tandem Queueing Systems Maximum Throughput Problem", 
    "arxiv-id": "1512.05882v1", 
    "author": "Daniela Andone", 
    "publish": "2015-12-18T09:28:16Z", 
    "summary": "In this paper we consider the problem of maximum throughput for tandem\nqueueing system. We modeled this system as a Quasi-Birth-Death process. In\norder to do this we named level the number of customers waiting in the first\nbuffer (including the customer in service) and we called phase the state of the\nremining servers. Using this model we studied the problem of maximum throughput\nof the system: the maximum arrival rate that a given system could support\nbefore becoming saturated, or unstable. We considered different particular\ncases of such systems, which were obtained by modifying the capacity of the\nintermediary buffers, the arrival rate and the service rates. The results of\nthe simulations are presented in our paper and can be summed up in the\nfollowing conclusions: 1. The analytic formula for the maximum throughput of\nthe system tends to become rather complicated when the number of servers\nincrease 2. The maximum throughput of the system converges as the number of\nservers increases 3. The homogeneous case reveals an interesting\ncharacteristic: if we reverse the order of the servers, maximum thruoughput of\nthe system remains unchanged The QBD process used for the case of Poisson\narrivals can be extended to model more general arrival processes."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1602.07978v1", 
    "title": "Contrasting Effects of Replication in Parallel Systems: From Overload to   Underload and Back", 
    "arxiv-id": "1602.07978v1", 
    "author": "Florin Ciucu", 
    "publish": "2016-02-25T16:13:23Z", 
    "summary": "Task replication has recently been advocated as a practical solution to\nreduce latencies in parallel systems. In addition to several convincing\nempirical studies, some others provide analytical results, yet under some\nstrong assumptions such as Poisson arrivals, exponential service times, or\nindependent service times of the replicas themselves, which may lend themselves\nto some contrasting and perhaps contriving behavior. For instance, under the\nsecond assumption, an overloaded system can be stabilized by a replication\nfactor, but can be sent back in overload through further replication. In turn,\nunder the third assumption, strictly larger stability regions of replication\nsystems do not necessarily imply smaller delays.\n  Motivated by the need to dispense with such common and restricting\nassumptions, which may additionally cause unexpected behavior, we develop a\nunified and general theoretical framework to compute tight bounds on the\ndistribution of response times in general replication systems. These results\nimmediately lend themselves to the optimal number of replicas minimizing\nresponse time quantiles, depending on the parameters of the system (e.g., the\ndegree of correlation amongst replicas). As a concrete application of our\nframework, we design a novel replication policy which can improve the stability\nregion of classical fork-join queueing systems by $\\mathcal{O}(\\ln K)$, in the\nnumber of servers $K$."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1603.01313v1", 
    "title": "FastCap: An Efficient and Fair Algorithm for Power Capping in Many-Core   Systems", 
    "arxiv-id": "1603.01313v1", 
    "author": "Ricardo Bianchini", 
    "publish": "2016-03-03T23:21:04Z", 
    "summary": "Future servers will incorporate many active lowpower modes for different\nsystem components, such as cores and memory. Though these modes provide\nflexibility for power management via Dynamic Voltage and Frequency Scaling\n(DVFS), they must be operated in a coordinated manner. Such coordinated control\ncreates a combinatorial space of possible power mode configurations. Given the\nrapid growth of the number of cores, it is becoming increasingly challenging to\nquickly select the configuration that maximizes the performance under a given\npower budget. Prior power capping techniques do not scale well to large numbers\nof cores, and none of those works has considered memory DVFS. In this paper, we\npresent FastCap, our optimization approach for system-wide power capping, using\nboth CPU and memory DVFS. Based on a queuing model, FastCap formulates power\ncapping as a non-linear optimization problem where we seek to maximize the\nsystem performance under a power budget, while promoting fairness across\napplications. Our FastCap algorithm solves the optimization online and\nefficiently (low complexity on the number of cores), using a small set of\nperformance counters as input. To evaluate FastCap, we simulate it for a\nmany-core server running different types of workloads. Our results show that\nFastCap caps power draw accurately, while producing better application\nperformance and fairness than many existing CPU power capping methods (even\nafter they are extended to use of memory DVFS as well)."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1603.01316v2", 
    "title": "Performance Assessment of WhatsApp and IMO on Android Operating System   (Lollipop and KitKat) during VoIP calls using 3G or WiFi", 
    "arxiv-id": "1603.01316v2", 
    "author": "L. P. S. Viana", 
    "publish": "2016-03-04T00:05:18Z", 
    "summary": "This paper assesses the performance of mobile messaging and VoIP connections.\nWe investigate the CPU usage of WhatsApp and IMO under different scenarios.\nThis analysis also enabled a comparison of the performance of these\napplications on two Android operating system (OS) versions: KitKat or Lollipop.\nTwo models of smartphones were considered, viz. Galaxy Note 4 and Galaxy S4.\nThe applications behavior was statistically investigated for both sending and\nreceiving VoIP calls. Connections have been examined over 3G and WiFi. The\nhandset model plays a decisive role in CPU usage of the application. t-tests\nshowed that IMO has a better performance that WhatsApp whatever be the Android\nat a significance level 1%, on Galaxy Note 4. In contrast, WhatsApp requires\nless CPU than IMO on Galaxy S4 whatever be the OS and access (3G/WiFi). Galaxy\nNote 4 using WiFi always outperformed S4 in terms of processing efficiency."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1604.06763v2", 
    "title": "Balanced Fair Resource Sharing in Computer Clusters", 
    "arxiv-id": "1604.06763v2", 
    "author": "C\u00e9line Comte", 
    "publish": "2016-04-22T18:10:10Z", 
    "summary": "We represent a computer cluster as a multi-server queue with some arbitrary\nbipartite graph of compatibilities between jobs and servers. Each server\nprocesses its jobs sequentially in FCFS order. The service rate of a job at any\ngiven time is the sum of the service rates of all servers processing this job.\nWe show that the corresponding queue is quasi-reversible and use this property\nto design a scheduling algorithm achieving balanced fair sharing of the service\ncapacity."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1605.00559v1", 
    "title": "Age-of-Information in the Presence of Error", 
    "arxiv-id": "1605.00559v1", 
    "author": "Longbo Huang", 
    "publish": "2016-05-02T16:45:39Z", 
    "summary": "We consider the peak age-of-information (PAoI) in an M/M/1 queueing system\nwith packet delivery error, i.e., update packets can get lost during\ntransmissions to their destination. We focus on two types of policies, one is\nto adopt Last-Come-First-Served (LCFS) scheduling, and the other is to utilize\nretransmissions, i.e., keep transmitting the most recent packet. Both policies\ncan effectively avoid the queueing delay of a busy channel and ensure a small\nPAoI. Exact PAoI expressions under both policies with different error\nprobabilities are derived, including First-Come-First-Served (FCFS), LCFS with\npreemptive priority, LCFS with non-preemptive priority, Retransmission with\npreemptive priority, and Retransmission with non-preemptive priority. Numerical\nresults obtained from analysis and simulation are presented to validate our\nresults."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1605.02996v1", 
    "title": "Asymptotics of Insensitive Load Balancing and Blocking Phases", 
    "arxiv-id": "1605.02996v1", 
    "author": "Balakrishna Prabhu", 
    "publish": "2016-05-10T13:21:29Z", 
    "summary": "We address the problem of giving robust performance bounds based on the study\nof the asymptotic behavior of the insensitive load balancing schemes when the\nnumber of servers and the load scales jointly. These schemes have the desirable\nproperty that the stationary distribution of the resulting stochastic network\ndepends on the distribution of job sizes only through its mean. It was shown\nthat they give good estimates of performance indicators for systems with finite\nbuffers, generalizing henceforth Erlang's formula whereas optimal policies are\nalready theoretically and computationally out of reach for networks of moderate\nsize. We study a single class of traffic acting on a symmetric set of processor\nsharing queues with finite buffers and we consider the case where the load\nscales with the number of servers. We characterize central limit theorems and\nlarge deviations, the response of symmetric systems under those schemes at\ndifferent scales and show that three amplitudes of deviations can be\nidentified. A central limit scaling takes place for a sub-critical load; for\n$\\rho=1$, the number of free servers scales like $n^{ {\\theta \\over \\theta+1}}$\n($\\theta$ being the buffer depth and $n$ being the number of servers) and is of\norder 1 for super-critical loads. This further implies the existence of\ndifferent phases for the blocking probability, Before a (refined) critical load\n$\\rho_c(n)=1-a n^{- {\\theta \\over \\theta+1}}$, the blocking is exponentially\nsmall and becomes of order $ n^{- {\\theta \\over \\theta+1}}$ at $\\rho_c(n)$.\nThis generalizes the well-known Quality and Efficiency Driven (QED) regime or\nHalfin-Whitt regime for a one-dimensional queue, and leads to a generalized\nstaffing rule for a given target blocking probability."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1605.03068v1", 
    "title": "On Stability and Sojourn Time of Peer-to-Peer Queuing Systems", 
    "arxiv-id": "1605.03068v1", 
    "author": "Xing Li", 
    "publish": "2016-05-10T15:44:54Z", 
    "summary": "Recent development of peer-to-peer (P2P) services (e.g. streaming, file\nsharing, and storage) systems introduces a new type of queue systems that\nreceive little attention before, where both job and server arrive and depart\nrandomly. Current study on these models focuses on the stability condition,\nunder exponential workload assumption. This paper extends existing result in\ntwo aspects. In the first part of the paper we relax the exponential workload\nassumption, and study the stability of systems with general workload\ndistribution. The second part of the paper focuses on the job sojourn time. An\nupper bound and a lower bound for job sojourn time are investigated. We\nevaluate tightness of the bounds by numerical analysis."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1605.05753v1", 
    "title": "Delay Bounds for Multiclass FIFO", 
    "arxiv-id": "1605.05753v1", 
    "author": "Vishal Misra", 
    "publish": "2016-05-18T20:35:11Z", 
    "summary": "FIFO is perhaps the simplest scheduling discipline. For single-class FIFO,\nits delay guarantee performance has been extensively studied: The well-known\nresults include a stochastic delay bound for $GI/GI/1$ by Kingman and a\ndeterministic delay bound for $D/D/1$ by Cruz. However, for multiclass FIFO,\nfew such results are available. To fill the gap, we prove delay bounds for\nmulticlass FIFO in this work, considering both deterministic and stochastic\ncases. Specifically, delay bounds are presented for $D/D/1$, $G/D/1$, $GI/D/1$,\nand $GI/GI/1$, all under multiclass FIFO."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1605.08146v1", 
    "title": "On Pollaczek-Khinchine Formula for Peer-to-Peer Networks", 
    "arxiv-id": "1605.08146v1", 
    "author": "Weisheng Hu", 
    "publish": "2016-05-26T05:19:26Z", 
    "summary": "The performance analysis of peer-to-peer (P2P) networks calls for a new kind\nof queueing model, in which jobs and service stations arrive randomly. Except\nin some simple special cases, in general, the queueing model with varying\nservice rate is mathematically intractable. Motivated by the P-K formula for\nM/G/1 queue, we developed a limiting analysis approach based on the connection\nbetween the fluctuation of service rate and the mean queue length. Considering\nthe two extreme service rates, we proved the conjecture on the lower bound and\nupper bound of mean queue length previously postulated. Furthermore, an\napproximate P-K formula to estimate the mean queue length is derived from the\nconvex combination of these two bounds and the conditional mean queue length\nunder the overload condition. We confirmed the accuracy of our approximation by\nextensive simulation studies with different system parameters. We also verified\nthat all limiting cases of the system behavior are consistent with the\npredictions of our formula."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1606.02900v2", 
    "title": "On Continuous-space Embedding of Discrete-parameter Queuing Systems", 
    "arxiv-id": "1606.02900v2", 
    "author": "Madhav P. Desai", 
    "publish": "2016-06-09T10:45:45Z", 
    "summary": "In simulation-based optimization of queuing systems, the presence of\ndiscrete-valued parameters (such as buffer sizes and the number of servers)\nmakes the optimization difficult. We propose a novel technique for embedding\nsuch discrete parameters into a continuous space, so that optimization can be\nperformed efficiently using continuous-space methods. Unlike spatial\ninterpolation, our embedding technique is based on a randomization of the\nsimulation model. The interpolated value can be computed using a single\nsimulation of this randomized model, irrespective of the number of parameters.\nWe first study the theoretical properties of such a randomization scheme\napplied to M/M/1 and Geom/Geom/1 queues. We prove that the randomization\nproduces valid interpolations of the steady-state performance functions with\nrespect to an integer service-time parameter. We then show that such an\nembedding is possible for more complex queueing networks whose parameters can\ninclude deterministic service times, queue capacities, and the number of\nservers, and empirically demonstrate that the interpolation is well behaved. To\ndemonstrate the utility of the embedding technique, we solve a 6-parameter\nqueuing network optimization problem by embedding the discrete parameters into\na continuous space. The technique produces smooth interpolations of the\nobjective function, and a continuous optimizer applied directly over this\nembedding converges rapidly, producing good solutions."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1607.00714v2", 
    "title": "Stochastic Modeling of Hybrid Cache Systems", 
    "arxiv-id": "1607.00714v2", 
    "author": "John C. S. Lui", 
    "publish": "2016-07-04T01:10:11Z", 
    "summary": "In recent years, there is an increasing demand of big memory systems so to\nperform large scale data analytics. Since DRAM memories are expensive, some\nresearchers are suggesting to use other memory systems such as non-volatile\nmemory (NVM) technology to build large-memory computing systems. However,\nwhether the NVM technology can be a viable alternative (either economically and\ntechnically) to DRAM remains an open question. To answer this question, it is\nimportant to consider how to design a memory system from a \"system\nperspective\", that is, incorporating different performance characteristics and\nprice ratios from hybrid memory devices.\n  This paper presents an analytical model of a \"hybrid page cache system\" so to\nunderstand the diverse design space and performance impact of a hybrid cache\nsystem. We consider (1) various architectural choices, (2) design strategies,\nand (3) configuration of different memory devices. Using this model, we provide\nguidelines on how to design hybrid page cache to reach a good trade-off between\nhigh system throughput (in I/O per sec or IOPS) and fast cache reactivity which\nis defined by the time to fill the cache. We also show how one can configure\nthe DRAM capacity and NVM capacity under a fixed budget. We pick PCM as an\nexample for NVM and conduct numerical analysis. Our analysis indicates that\nincorporating PCM in a page cache system significantly improves the system\nperformance, and it also shows larger benefit to allocate more PCM in page\ncache in some cases. Besides, for the common setting of performance-price ratio\nof PCM, \"flat architecture\" offers as a better choice, but \"layered\narchitecture\" outperforms if PCM write performance can be significantly\nimproved in the future."
},{
    "category": "cs.PF", 
    "doi": "10.13140/RG.2.1.2601.7362", 
    "link": "http://arxiv.org/pdf/1607.04298v4", 
    "title": "Optimal Placement of Cores, Caches and Memory Controllers in Network   On-Chip", 
    "arxiv-id": "1607.04298v4", 
    "author": "Farshid Farhat", 
    "publish": "2016-07-14T20:09:47Z", 
    "summary": "Parallel programming is emerging fast and intensive applications need more\nresources, so there is a huge demand for on-chip multiprocessors. Accessing L1\ncaches beside the cores are the fastest after registers but the size of private\ncaches cannot increase because of design, cost and technology limits. Then\nsplit I-cache and D-cache are used with shared LLC (last level cache). For a\nunified shared LLC, bus interface is not scalable, and it seems that\ndistributed shared LLC (DSLLC) is a better choice. Most of papers assume a\ndistributed shared LLC beside each core in on-chip network. Many works assume\nthat DSLLCs are placed in all cores; however, we will show that this design\nignores the effect of traffic congestion in on-chip network. In fact, our work\nfocuses on optimal placement of cores, DSLLCs and even memory controllers to\nminimize the expected latency based on traffic load in a mesh on-chip network\nwith fixed number of cores and total cache capacity. We try to do some\nanalytical modeling deriving intended cost function and then optimize the mean\ndelay of the on-chip network communication. This work is supposed to be\nverified using some traffic patterns that are run on CSIM simulator."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1608.03676v1", 
    "title": "Coz: Finding Code that Counts with Causal Profiling", 
    "arxiv-id": "1608.03676v1", 
    "author": "Emery D. Berger", 
    "publish": "2016-08-12T04:58:16Z", 
    "summary": "Improving performance is a central concern for software developers. To locate\noptimization opportunities, developers rely on software profilers. However,\nthese profilers only report where programs spent their time: optimizing that\ncode may have no impact on performance. Past profilers thus both waste\ndeveloper time and make it difficult for them to uncover significant\noptimization opportunities.\n  This paper introduces causal profiling. Unlike past profiling approaches,\ncausal profiling indicates exactly where programmers should focus their\noptimization efforts, and quantifies their potential impact. Causal profiling\nworks by running performance experiments during program execution. Each\nexperiment calculates the impact of any potential optimization by virtually\nspeeding up code: inserting pauses that slow down all other code running\nconcurrently. The key insight is that this slowdown has the same relative\neffect as running that line faster, thus \"virtually\" speeding it up.\n  We present Coz, a causal profiler, which we evaluate on a range of\nhighly-tuned applications: Memcached, SQLite, and the PARSEC benchmark suite.\nCoz identifies previously unknown optimization opportunities that are both\nsignificant and targeted. Guided by Coz, we improve the performance of\nMemcached by 9%, SQLite by 25%, and accelerate six PARSEC applications by as\nmuch as 68%; in most cases, these optimizations involve modifying under 10\nlines of code."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1608.03984v2", 
    "title": "Performance prediction of finite-difference solvers for different   computer architectures", 
    "arxiv-id": "1608.03984v2", 
    "author": "Gerard Gorman", 
    "publish": "2016-08-13T13:57:14Z", 
    "summary": "The life-cycle of a partial differential equation (PDE) solver is often\ncharacterized by three development phases: the development of a stable\nnumerical discretization, development of a correct (verified) implementation,\nand the optimization of the implementation for different computer\narchitectures. Often it is only after significant time and effort has been\ninvested that the performance bottlenecks of a PDE solver are fully understood,\nand the precise details varies between different computer architectures. One\nway to mitigate this issue is to establish a reliable performance model that\nallows a numerical analyst to make reliable predictions of how well a numerical\nmethod would perform on a given computer architecture, before embarking upon\npotentially long and expensive implementation and optimization phases. The\navailability of a reliable performance model also saves developer effort as it\nboth informs the developer on what kind of optimisations are beneficial, and\nwhen the maximum expected performance has been reached and optimisation work\nshould stop. We show how discretization of a wave equation can be theoretically\nstudied to understand the performance limitations of the method on modern\ncomputer architectures. We focus on the roofline model, now broadly used in the\nhigh-performance computing community, which considers the achievable\nperformance in terms of the peak memory bandwidth and peak floating point\nperformance of a computer with respect to algorithmic choices. A first\nprinciples analysis of operational intensity for key time-stepping\nfinite-difference algorithms is presented. With this information available at\nthe time of algorithm design, the expected performance on target computer\nsystems can be used as a driver for algorithm design."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1608.04295v1", 
    "title": "Robust benchmarking in noisy environments", 
    "arxiv-id": "1608.04295v1", 
    "author": "Jarrett Revels", 
    "publish": "2016-08-15T15:02:13Z", 
    "summary": "We propose a benchmarking strategy that is robust in the presence of timer\nerror, OS jitter and other environmental fluctuations, and is insensitive to\nthe highly nonideal statistics produced by timing measurements. We construct a\nmodel that explains how these strongly nonideal statistics can arise from\nenvironmental fluctuations, and also justifies our proposed strategy. We\nimplement this strategy in the BenchmarkTools Julia package, where it is used\nin production continuous integration (CI) pipelines for developing the Julia\nlanguage and its ecosystem."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1609.03347v1", 
    "title": "An ECM-based energy-efficiency optimization approach for   bandwidth-limited streaming kernels on recent Intel Xeon processors", 
    "arxiv-id": "1609.03347v1", 
    "author": "Dietmar Fey", 
    "publish": "2016-09-12T11:18:58Z", 
    "summary": "We investigate an approach that uses low-level analysis and the\nexecution-cache-memory (ECM) performance model in combination with tuning of\nhardware parameters to lower energy requirements of memory-bound applications.\nThe ECM model is extended appropriately to deal with software optimizations\nsuch as non-temporal stores. Using incremental steps and the ECM model, we\nanalytically quantify the impact of various single-core optimizations and\npinpoint microarchitectural improvements that are relevant to energy\nconsumption. Using a 2D Jacobi solver as example that can serve as a blueprint\nfor other memory-bound applications, we evaluate our approach on the four most\nrecent Intel Xeon E5 processors (Sandy Bridge-EP, Ivy Bridge-EP, Haswell-EP,\nand Broadwell-EP). We find that chip energy consumption can be reduced in the\nrange of 2.0-2.4$\\times$ on the examined processors."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1610.00560v1", 
    "title": "Poly-Symmetry in Processor-Sharing Networks", 
    "arxiv-id": "1610.00560v1", 
    "author": "Gustavo de Veciana", 
    "publish": "2016-10-03T14:05:04Z", 
    "summary": "We consider a network of processor-sharing queues with state-dependent\nservice rates. These are allocated according to balanced fairness within a\npolymatroid capacity set. Balanced fairness is known to be both insensitive and\nPareto-efficient in such networks, which ensures that the performance metrics,\nwhen computable, will provide robust insights into the real performance of the\nsystem considered. We first show that these performance metrics can be\nevaluated with a complexity that is polynomial in the system size when we allow\nfor some controlled asymmetry, in the sense that the network contains a fixed\nnumber of parts wherein all queues are `exchangeable'. This in turn allows us\nto derive stochastic bounds for a larger class of networks which satisfy less\nrestrictive symmetry assumptions. These results are applied to practical\nexamples of tree data networks and computer clusters."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1610.01267v3", 
    "title": "10-millisecond Computing", 
    "arxiv-id": "1610.01267v3", 
    "author": "Lei Wang", 
    "publish": "2016-10-05T03:55:02Z", 
    "summary": "Despite computation becomes much complex on data with an unprecedented scale,\nwe argue computers or smart devices should and will consistently provide\ninformation and knowledge to human being in the order of a few tens\nmilliseconds. We coin a new term 10-millisecond computing to call attention to\nthis class of workloads. 10-millisecond computing raises many challenges for\nboth software and hardware stacks. In this paper, using a typical\nworkload-memcached on a 40-core server (a main-stream server in near future),\nwe quantitatively measure 10-ms computing's challenges to conventional\noperating systems. For better communication, we propose a simple metric-outlier\nproportion to measure quality of service: for N completed requests or jobs, if\nM jobs or requests' latencies exceed the outlier threshold t, the outlier\nproportion is M/N . For a 1K-scale system running Linux (version 2.6.32), LXC\n(version 0.7.5) or XEN (version 4.0.0), respectively, we surprisingly find that\nso as to reduce the service outlier proportion to 10% (10% users will feel QoS\ndegradation), the outlier proportion of a single server has to be reduced by\n871X, 2372X, 2372X accordingly. Also, we discuss the possible design spaces of\n10-ms computing systems from perspectives of datacenter architectures,\nnetworking, OS and scheduling, and benchmarking."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1610.06307v1", 
    "title": "Breakdown of a Benchmark Score Without Internal Analysis of Benchmarking   Program", 
    "arxiv-id": "1610.06307v1", 
    "author": "Kazuyuki Shudo", 
    "publish": "2016-10-20T07:23:33Z", 
    "summary": "A breakdown of a benchmark score is how much each aspect of the system\nperformance affects the score. Existing methods require internal analysis on\nthe benchmarking program and then involve the following problems: (1) require a\ncertain amount of labor for code analysis, profiling, simulation, and so on and\n(2) require the benchmarking program itself. In this paper, we present a method\nfor breaking down a benchmark score without internal analysis of the\nbenchmarking program. The method utilizes regression analysis of benchmark\nscores on a number of systems. Experimental results with 3 benchmarks on 15\nAndroid smartphones showed that our method could break down those benchmark\nscores even though there is room for improvement in accuracy."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2815400.2815409", 
    "link": "http://arxiv.org/pdf/1611.07409v1", 
    "title": "A Metric for Performance Portability", 
    "arxiv-id": "1611.07409v1", 
    "author": "V. W. Lee", 
    "publish": "2016-11-22T16:50:42Z", 
    "summary": "The term \"performance portability\" has been informally used in computing to\nrefer to a variety of notions which generally include: 1) the ability to run\none application across multiple hardware platforms; and 2) achieving some\nnotional level of performance on these platforms. However, there has been a\nnoticeable lack of consensus on the precise meaning of the term, and authors'\nconclusions regarding their success (or failure) to achieve performance\nportability have thus been subjective. Comparing one approach to performance\nportability with another has generally been marked with vague claims and\nverbose, qualitative explanation of the comparison. This paper presents a\nconcise definition for performance portability, along with a simple metric that\naccurately captures the performance and portability of an application across\ndifferent platforms. The utility of this metric is then demonstrated with a\nretroactive application to previous work."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1612.03709v1", 
    "title": "Geographical Load Balancing across Green Datacenters", 
    "arxiv-id": "1612.03709v1", 
    "author": "Giuseppe Bianchi", 
    "publish": "2016-12-12T14:37:34Z", 
    "summary": "\"Geographic Load Balancing\" is a strategy for reducing the energy cost of\ndata centers spreading across different terrestrial locations. In this paper,\nwe focus on load balancing among micro-datacenters powered by renewable energy\nsources. We model via a Markov Chain the problem of scheduling jobs by\nprioritizing datacenters where renewable energy is currently available. Not\nfinding a convenient closed form solution for the resulting chain, we use mean\nfield techniques to derive an asymptotic approximate model which instead is\nshown to have an extremely simple and intuitive steady state solution. After\nproving, using both theoretical and discrete event simulation results, that the\nsystem performance converges to the asymptotic model for an increasing number\nof datacenters, we exploit the simple closed form model's solution to\ninvestigate relationships and trade-offs among the various system parameters."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1612.05486v3", 
    "title": "Optimizing Stochastic Scheduling in Fork-Join Queueing Models: Bounds   and Applications", 
    "arxiv-id": "1612.05486v3", 
    "author": "Heinz Koeppl", 
    "publish": "2016-12-16T14:37:19Z", 
    "summary": "Fork-Join (FJ) queueing models capture the dynamics of system parallelization\nunder synchronization constraints, for example, for applications such as\nMapReduce, multipath transmission and RAID systems. Arriving jobs are first\nsplit into tasks and mapped to servers for execution, such that a job can only\nleave the system when all of its tasks are executed.\n  In this paper, we provide computable stochastic bounds for the waiting and\nresponse time distributions for heterogeneous FJ systems under general\nparallelization benefit. Our main contribution is a generalized mathematical\nframework for probabilistic server scheduling strategies that are essentially\ncharacterized by a probability distribution over the number of utilized\nservers, and the optimization thereof. We highlight the trade-off between the\nscaling benefit due to parallelization and the FJ inherent synchronization\npenalty. Further, we provide optimal scheduling strategies for arbitrary\nscaling regimes that map to different levels of parallelization benefit. One\nnotable insight obtained from our results is that different applications with\nvarying parallelization benefits result in different optimal strategies.\nFinally, we complement our analytical results by applying them to various\napplications showing the optimality of the proposed scheduling strategies."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1612.05543v1", 
    "title": "A Generalized Performance Evaluation Framework for Parallel Systems with   Output Synchronization", 
    "arxiv-id": "1612.05543v1", 
    "author": "Heinz Koeppl", 
    "publish": "2016-12-16T16:33:34Z", 
    "summary": "Frameworks, such as MapReduce and Hadoop are abundant nowadays. They seek to\nreap benefits of parallelization, albeit subject to a synchronization\nconstraint at the output. Fork-Join (FJ) queuing models are used to analyze\nsuch systems. Arriving jobs are split into tasks each of which is mapped to\nexactly one server. A job leaves the system when all of its tasks are executed.\n  As a metric of performance, we consider waiting times for both\nwork-conserving and non-work conserving server systems under a mathematical\nset-up general enough to take into account possible phase-type behavior of the\nservers, and as suggested by recent evidences, bursty arrivals.\n  To this end, we present a Markov-additive process framework for an FJ system\nand provide computable bounds on tail probabilities of steady-state waiting\ntimes, for both types of servers separately. We apply our results to three\nscenarios, namely, non-renewal (Markov-modulated) arrivals, servers showing\nphase-type behavior, and Markov-modulated arrivals and services. We compare our\nbounds against estimates obtained through simulations and also provide a\ntheoretical conceptualization of provisions in FJ systems. Finally, we\ncalibrate our model with real data traces, and illustrate how our bounds can be\nused to devise provisions."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1612.09532v1", 
    "title": "M/g/c/c state dependent queueing model for road traffic simulation", 
    "arxiv-id": "1612.09532v1", 
    "author": "Nadir Farhi", 
    "publish": "2016-12-04T00:03:23Z", 
    "summary": "In this paper, we present a stochastic queuing model for the road traffic,\nwhich captures the stationary density-flow relationships in both uncongested\nand congestion conditions. The proposed model is based on the $M/g/c/c$ state\ndependent queuing model of Jain and Smith, and is inspired from the\ndeterministic Godunov scheme for the road traffic simulation. We first propose\na reformulation of the $M/g/c/c$ state dependent model that works with\ndensity-flow fundamental diagrams rather than density-speed relationships. We\nthen extend this model in order to consider upstream traffic demand as well as\ndownstream traffic supply. Finally, we calculate the speed and travel time\ndistributions for the $M/g/c/c$ state dependent queuing model and for the\nproposed model, and derive stationary performance measures (expected number of\ncars, blocking probability, expected travel time, and throughput). A comparison\nwith results predicted by the $M/g/c/c$ state dependent queuing model shows\nthat the proposed model correctly represents the dynamics of traffic and gives\ngood performances measures. The results illustrate the good accuracy of the\nproposed model."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1701.05308v1", 
    "title": "GPGPU Performance Estimation with Core and Memory Frequency Scaling", 
    "arxiv-id": "1701.05308v1", 
    "author": "Xiaowen Chu", 
    "publish": "2017-01-19T06:23:00Z", 
    "summary": "Graphics Processing Units (GPUs) support dynamic voltage and frequency\nscaling (DVFS) in order to balance computational performance and energy\nconsumption. However, there still lacks simple and accurate performance\nestimation of a given GPU kernel under different frequency settings on real\nhardware, which is important to decide best frequency configuration for energy\nsaving. This paper reveals a fine-grained model to estimate the execution time\nof GPU kernels with both core and memory frequency scaling. Over a 2.5x range\nof both core and memory frequencies among 12 GPU kernels, our model achieves\naccurate results (within 3.5\\%) on real hardware. Compared with the cycle-level\nsimulators, our model only needs some simple micro-benchmark to extract a set\nof hardware parameters and performance counters of the kernels to produce this\nhigh accuracy."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1701.06004v1", 
    "title": "Light traffic behavior under the power-of-two load balancing strategy:   The case of heterogeneous servers", 
    "arxiv-id": "1701.06004v1", 
    "author": "Armand M. Makowski", 
    "publish": "2017-01-21T10:00:27Z", 
    "summary": "We consider a multi-server queueing system under the power-of-two policy with\nPoisson job arrivals, heterogeneous servers and a general job requirement\ndistribution; each server operates under the first-come first-serve policy and\nthere are no buffer constraints. We analyze the performance of this system in\nlight traffic by evaluating the first two light traffic derivatives of the\naverage job response time. These expressions point to several interesting\nstructural features associated with server heterogeneity in light traffic: For\nunequal capacities, the average job response time is seen to decrease for small\nvalues of the arrival rate, and the more diverse the server speeds, the greater\nthe gain in performance. These theoretical findings are assessed through\nlimited simulations."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1701.06415v1", 
    "title": "Steady state availability general equations of decision and sequential   processes in Continuous Time Markov Chain models", 
    "arxiv-id": "1701.06415v1", 
    "author": "Eduardo M. Vasconcelos", 
    "publish": "2017-01-20T16:21:41Z", 
    "summary": "Continuous Time Markov Chain (CMTC) is widely used to describe and analyze\nsystems in several knowledge areas. Steady state availability is one important\nanalysis that can be made through Markov chain formalism that allows\nresearchers generate equations for several purposes, such as channel capacity\nestimation in wireless networks as well as system performance estimations. The\nproblem with this kind of analysis is the complex process to generating these\nequations. In this letter, we have developed general equations for decision and\nsequential processes of CMTC Models, aiming to help researchers to develop\nsteady state availability equations. We also have developed the general\nequation here termed as Closed Decision Process."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1702.04653v1", 
    "title": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels", 
    "arxiv-id": "1702.04653v1", 
    "author": "Gerhard Wellein", 
    "publish": "2017-01-13T21:20:06Z", 
    "summary": "Achieving optimal program performance requires deep insight into the\ninteraction between hardware and software. For software developers without an\nin-depth background in computer architecture, understanding and fully utilizing\nmodern architectures is close to impossible. Analytic loop performance modeling\nis a useful way to understand the relevant bottlenecks of code execution based\non simple machine models. The Roofline Model and the Execution-Cache-Memory\n(ECM) model are proven approaches to performance modeling of loop nests. In\ncomparison to the Roofline model, the ECM model can also describes the\nsingle-core performance and saturation behavior on a multicore chip. We give an\nintroduction to the Roofline and ECM models, and to stencil performance\nmodeling using layer conditions (LC). We then present Kerncraft, a tool that\ncan automatically construct Roofline and ECM models for loop nests by\nperforming the required code, data transfer, and LC analysis. The layer\ncondition analysis allows to predict optimal spatial blocking factors for loop\nnests. Together with the models it enables an ab-initio estimate of the\npotential benefits of loop blocking optimizations and of useful block sizes. In\ncases where LC analysis is not easily possible, Kerncraft supports a cache\nsimulator as a fallback option. Using a 25-point long-range stencil we\ndemonstrate the usefulness and predictive power of the Kerncraft tool."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1702.04942v1", 
    "title": "Benchmarking the computing resources at the Instituto de Astrof\u00edsica   de Canarias", 
    "arxiv-id": "1702.04942v1", 
    "author": "Juan Carlos Trelles Arjona", 
    "publish": "2017-02-16T12:21:11Z", 
    "summary": "The aim of this study is the characterization of the computing resources used\nby researchers at the \"Instituto de Astrof\\'isica de Canarias\" (IAC). Since\nthere is a huge demand of computing time and we use tools such as HTCondor to\nimplement High Throughput Computing (HTC) across all available PCs, it is\nessential for us to assess in a quantitative way, using objective parameters,\nthe performances of our computing nodes. In order to achieve that, we have run\na set of benchmark tests on a number of different desktop and laptop PC models\namong those used in our institution. In particular, we run the \"Polyhedron\nFortran Benchmarks\" suite, using three different compilers: GNU Fortran\nCompiler, Intel Fortran Compiler and the PGI Fortran Compiler; execution times\nare then normalized to the reference values published by Polyhedron. The same\ntests were run multiple times on a same PCs, and on 3 to 5 PCs of the same\nmodel (whenever possible) to check for repeatability and consistency of the\nresults. We found that in general execution times, for a given PC model, are\nconsistent within an uncertainty of about 10%, and show a gain in CPU speed of\na factor of about 3 between the oldest PCs used at the IAC (7-8 years old) and\nthe newest ones."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/1702.07554v1", 
    "title": "An analysis of core- and chip-level architectural features in four   generations of Intel server processors", 
    "arxiv-id": "1702.07554v1", 
    "author": "Dietmar Fey", 
    "publish": "2017-02-24T12:17:21Z", 
    "summary": "This paper presents a survey of architectural features among four generations\nof Intel server processors (Sandy Bridge, Ivy Bridge, Haswell, and Broad- well)\nwith a focus on performance with floating point workloads. Starting on the core\nlevel and going down the memory hierarchy we cover instruction throughput for\nfloating-point instructions, L1 cache, address generation capabilities, core\nclock speed and its limitations, L2 and L3 cache bandwidth and latency, the\nimpact of Cluster on Die (CoD) and cache snoop modes, and the Uncore clock\nspeed. Using microbenchmarks we study the influence of these factors on code\nperformance. This insight can then serve as input for analytic performance\nmodels. We show that the energy efficiency of the LINPACK and HPCG benchmarks\ncan be improved considerably by tuning the Uncore clock speed without\nsacrificing performance, and that the Graph500 benchmark performance may profit\nfrom a suitable choice of cache snoop mode settings."
},{
    "category": "cs.NI", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/9808004v1", 
    "title": "Differentiated End-to-End Internet Services using a Weighted   Proportional Fair Sharing TCP", 
    "arxiv-id": "cs/9808004v1", 
    "author": "Philippe Oechslin", 
    "publish": "1998-08-25T12:59:21Z", 
    "summary": "In this document we study the application of weighted proportional fairness\nto data flows in the Internet. We let the users set the weights of their\nconnections in order to maximise the utility they get from the network. When\ncombined with a pricing scheme where connections are billed by weight and time,\nsuch a system is known to maximise the total utility of the network. Our study\ncase is a national Web cache server connected to long distance links. We\npropose two ways of weighting TCP connections by manipulating some parameters\nof the protocol and present results from simulations and prototypes. We finally\ndiscuss how proportional fairness could be used to implement an Internet with\ndifferentiated services."
},{
    "category": "cs.DB", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/9809004v1", 
    "title": "Performance / Price Sort", 
    "arxiv-id": "cs/9809004v1", 
    "author": "Chris Nyberg", 
    "publish": "1998-09-02T00:49:25Z", 
    "summary": "NTsort is an external sort on WindowsNT 5.0. It has minimal functionality but\nexcellent price performance. In particular, running on mail-order hardware it\ncan sort 1.5 GB for a penny. For commercially available sorts, Postman Sort\nfrom Robert Ramey Software Development has elapsed time performance comparable\nto NTsort, while using less processor time. It can sort 1.27 GB for a penny\n(12.7 million records.) These sorts set new price-performance records. This\npaper documents this and proposes that the PennySort benchmark be revised to\nPerformance/Price sort: a simple GB/$ sort metric based on a two-pass external\nsort."
},{
    "category": "cs.PL", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/9810010v2", 
    "title": "C++ Templates as Partial Evaluation", 
    "arxiv-id": "cs/9810010v2", 
    "author": "Todd L. Veldhuizen", 
    "publish": "1998-10-09T20:29:43Z", 
    "summary": "This paper explores the relationship between C++ templates and partial\nevaluation. Templates were designed to support generic programming, but\nunintentionally provided the ability to perform compile-time computations and\ncode generation. These features are completely accidental, and as a result\ntheir syntax is awkward. By recasting these features in terms of partial\nevaluation, a much simpler syntax can be achieved. C++ may be regarded as a\ntwo-level language in which types are first-class values. Template\ninstantiation resembles an offline partial evaluator. This paper describes\npreliminary work toward a single mechanism based on Partial Evaluation which\nunifies generic programming, compile-time computation and code generation. The\nlanguage Catat is introduced to illustrate these ideas."
},{
    "category": "cs.CE", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/9902024v1", 
    "title": "Algorithms of Two-Level Parallelization for DSMC of Unsteady Flows in   Molecular Gasdynamics", 
    "arxiv-id": "cs/9902024v1", 
    "author": "Vladimir V. Zakharov", 
    "publish": "1999-02-11T13:13:04Z", 
    "summary": "The general scheme of two-level parallelization (TLP) for direct simulation\nMonte Carlo of unsteady gas flows on shared memory multiprocessor computers has\nbeen described. The high efficient algorithm of parallel independent runs is\nused on the first level. The data parallelization is employed for the second\none. Two versions of TLP algorithm are elaborated with static and dynamic load\nbalancing. The method of dynamic processor reallocation is used for dynamic\nload balancing. Two gasdynamic unsteady problems were used to study speedup and\nefficiency of the algorithms. The conditions of efficient application field for\nthe algorithms have been determined."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0006014v1", 
    "title": "Solaris System Resource Manager: All I Ever Wanted Was My Unfair   Advantage (And Why You Can't Have It!)", 
    "arxiv-id": "cs/0006014v1", 
    "author": "Neil J. Gunther", 
    "publish": "2000-06-08T16:50:24Z", 
    "summary": "Traditional UNIX time-share schedulers attempt to be fair to all users by\nemploying a round-robin style algorithm for allocating CPU time. Unfortunately,\na loophole exists whereby the scheduler can be biased in favor of a greedy user\nrunning many short CPU-time processes. This loophole is not a defect but an\nintrinsic property of the round-robin scheduler that ensures responsiveness to\nthe short CPU demands associated with multiple interactive users. A new\ngeneration of UNIX system resource management software constrains the scheduler\nto be equitable to all users regardless of the number of processes each may be\nrunning. This \"fair-share\" scheduling draws on the concept of pro rating\nresource \"shares\" across users and groups and then dynamically adjusting CPU\nusage to meet those share proportions. The simple notion of statically\nallocating these shares, however, belies the potential consequences for\nperformance as measured by user response time and service level targets. We\ndemonstrate this point by modeling several simple share allocation scenarios\nand analyzing the corresponding performance effects. A brief comparison of\ncommercial system resource management implementations from HP, IBM, and SUN is\nalso given."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0006015v2", 
    "title": "UNIX Resource Managers: Capacity Planning and Resource Issues", 
    "arxiv-id": "cs/0006015v2", 
    "author": "Neil J. Gunther", 
    "publish": "2000-06-08T17:02:51Z", 
    "summary": "The latest implementations of commercial UNIX to offer mainframe style\ncapacity management on enterprise servers include: AIX Workload Manager (WLM),\nHP-UX Process Resource Manager (PRM), Solaris Resource Manager (SRM), as well\nas SGI and Compaq. The ability to manage server capacity is achieved by making\nsignificant modifications to the standard UNIX operating system so that\nprocesses are inherently tied to specific users. Those users, in turn, are\ngranted only a certain fraction of system resources. Resource usage is\nmonitored and compared with each users grant to ensure that the assigned\nentitlement constraints are met. In this paper, we begin by clearing up some of\nthe confusion that has surrounded the motivation and the terminology behind the\nnew technology. The common theme across each of the commercial implementations\nis the introduction of the fair-share scheduler. After reviewing some potential\nperformance pitfalls, we present capacity planning guidelines for migrating to\nautomated UNIX resource management."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0006016v1", 
    "title": "The X-Files: Investigating Alien Performance in a Thin-client World", 
    "arxiv-id": "cs/0006016v1", 
    "author": "Neil J. Gunther", 
    "publish": "2000-06-08T18:08:19Z", 
    "summary": "Many scientific applications use the X11 window environment; an open source\nwindows GUI standard employing a client/server architecture. X11 promotes:\ndistributed computing, thin-client functionality, cheap desktop displays,\ncompatibility with heterogeneous servers, remote services and administration,\nand greater maturity than newer web technologies. This paper details the\nauthor's investigations into close encounters with alien performance in\nX11-based seismic applications running on a 200-node cluster, backed by 2 TB of\nmass storage. End-users cited two significant UFOs (Unidentified Faulty\nOperations) i) long application launch times and ii) poor interactive response\ntimes. The paper is divided into three major sections describing Close\nEncounters of the 1st Kind: citings of UFO experiences, the 2nd Kind: recording\nevidence of a UFO, and the 3rd Kind: contact and analysis. UFOs do exist and\nthis investigation presents a real case study for evaluating workload analysis\nand other diagnostic tools."
},{
    "category": "cs.NI", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0006022v1", 
    "title": "Multicast-based Architecture for IP Mobility: Simulation Analysis and   Comparison with Basic Mobile IP", 
    "arxiv-id": "cs/0006022v1", 
    "author": "Ahmed Helmy", 
    "publish": "2000-06-10T23:53:12Z", 
    "summary": "With the introduction of a newer generation of wireless devices and\ntechnologies, the need for an efficient architecture for IP mobility is\nbecoming more apparent. Several architectures have been proposed to support IP\nmobility. Most studies, however, show that current architectures, in general,\nfall short from satisfying the performance requirements for wireless\napplications, mainly audio. Other studies have shown performance improvement by\nusing multicast to reduce latency and packet loss during handoff. In this\nstudy, we propose a multicast-based architecture to support IP mobility. We\nevaluate our approach through simulation, and we compare it to mainstream\napproaches for IP mobility, mainly, the Mobile IP protocol. Comparison is\nperformed according to the required performance criteria, such as smooth\nhandoff and efficient routing.\n  Our simulation results show significant improvement for the proposed\narchitecture. On average, basic Mobile IP consumes almost twice as much network\nbandwidth, and experiences more than twice as much end-to-end and handoff\ndelays, as does our proposed architecture. Furthermore, we propose an extension\nto Mobile IP to support our architecture with minimal modification."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0007027v1", 
    "title": "Efficient cache use for stencil operations on structured discretization   grids", 
    "arxiv-id": "cs/0007027v1", 
    "author": "Rob F. Van der Wijngaart", 
    "publish": "2000-07-14T17:44:41Z", 
    "summary": "We derive tight bounds on cache misses for evaluation of explicit stencil\noperators on structured grids. Our lower bound is based on the isoperimetrical\nproperty of the discrete octahedron. Our upper bound is based on good surface\nto volume ratio of a parallelepiped spanned by a reduced basis of the inter-\nference lattice of a grid. Measurements show that our algorithm typically\nreduces the number of cache misses by factor of three relative to a compiler\noptimized code. We show that stencil calculations on grids whose interference\nlattice have a short vector feature abnormally high numbers of cache misses. We\ncall such grids unfavorable and suggest to avoid these in computations by\nappropriate padding. By direct measurements on MIPS R10000 we show a good\ncorrelation of abnormally high cache misses and unfavorable three-dimensional\ngrids."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0012010v1", 
    "title": "The Role of Commutativity in Constraint Propagation Algorithms", 
    "arxiv-id": "cs/0012010v1", 
    "author": "Krzysztof R. Apt", 
    "publish": "2000-12-15T14:04:28Z", 
    "summary": "Constraint propagation algorithms form an important part of most of the\nconstraint programming systems. We provide here a simple, yet very general\nframework that allows us to explain several constraint propagation algorithms\nin a systematic way. In this framework we proceed in two steps. First, we\nintroduce a generic iteration algorithm on partial orderings and prove its\ncorrectness in an abstract setting. Then we instantiate this algorithm with\nspecific partial orderings and functions to obtain specific constraint\npropagation algorithms.\n  In particular, using the notions commutativity and semi-commutativity, we\nshow that the {\\tt AC-3}, {\\tt PC-2}, {\\tt DAC} and {\\tt DPC} algorithms for\nachieving (directional) arc consistency and (directional) path consistency are\ninstances of a single generic algorithm. The work reported here extends and\nsimplifies that of Apt \\citeyear{Apt99b}."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0107001v2", 
    "title": "Analysis of Network Traffic in Switched Ethernet Systems", 
    "arxiv-id": "cs/0107001v2", 
    "author": "Peter Harrison", 
    "publish": "2001-07-02T08:21:15Z", 
    "summary": "A 100 Mbps Ethernet link between a college campus and the outside world was\nmonitored with a dedicated PC and the measured data analysed for its\nstatistical properties. Similar measurements were taken at an internal node of\nthe network. The networks in both cases are a full-duplex switched Ethernet.\nInter-event interval histograms and power spectra of the throughput aggregated\nfor 10ms bins were used to analyse the measured traffic. For most investigated\ncases both methods reveal that the traffic behaves according to a power law.\nThe results will be used in later studies to parameterise models for network\ntraffic."
},{
    "category": "cs.DC", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0205004v1", 
    "title": "Weaves: A Novel Direct Code Execution Interface for Parallel High   Performance Scientific Codes", 
    "arxiv-id": "cs/0205004v1", 
    "author": "Naren Ramakrishnan", 
    "publish": "2002-05-04T02:17:09Z", 
    "summary": "Scientific codes are increasingly being used in compositional settings,\nespecially problem solving environments (PSEs). Typical compositional modeling\nframeworks require significant buy-in, in the form of commitment to a\nparticular style of programming (e.g., distributed object components). While\nthis solution is feasible for newer generations of component-based scientific\ncodes, large legacy code bases present a veritable software engineering\nnightmare. We introduce Weaves a novel framework that enables modeling,\ncomposition, direct code execution, performance characterization, adaptation,\nand control of unmodified high performance scientific codes. Weaves is an\nefficient generalized framework for parallel compositional modeling that is a\nproper superset of the threads and processes models of programming. In this\npaper, our focus is on the transparent code execution interface enabled by\nWeaves. We identify design constraints, their impact on implementation\nalternatives, configuration scenarios, and present results from a prototype\nimplementation on Intel x86 architectures."
},{
    "category": "cs.DC", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0209029v1", 
    "title": "A generalization of Amdahl's law and relative conditions of parallelism", 
    "arxiv-id": "cs/0209029v1", 
    "author": "Gianluca Argentini", 
    "publish": "2002-09-25T08:50:18Z", 
    "summary": "In this work I present a generalization of Amdahl's law on the limits of a\nparallel implementation with many processors. In particular I establish some\nmathematical relations involving the number of processors and the dimension of\nthe treated problem, and with these conditions I define, on the ground of the\nreachable speedup, some classes of parallelism for the implementations. I also\nderive a condition for obtaining superlinear speedup. The used mathematical\ntechnics are those of differential calculus. I describe some examples from\nclassical problems offered by the specialized literature on the subject."
},{
    "category": "cs.DC", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0210017v1", 
    "title": "A New Interpretation of Amdahl's Law and Geometric Scalability", 
    "arxiv-id": "cs/0210017v1", 
    "author": "Neil J. Gunther", 
    "publish": "2002-10-17T18:20:08Z", 
    "summary": "The multiprocessor effect refers to the loss of computing cycles due to\nprocessing overhead. Amdahl's law and the Multiprocessing Factor (MPF) are two\nscaling models used in industry and academia for estimating multiprocessor\ncapacity in the presence of this multiprocessor effect. Both models express\ndifferent laws of diminishing returns. Amdahl's law identifies diminishing\nprocessor capacity with a fixed degree of serialization in the workload, while\nthe MPF model treats it as a constant geometric ratio. The utility of both\nmodels for performance evaluation stems from the presence of a single parameter\nthat can be determined easily from a small set of benchmark measurements. This\nutility, however, is marred by a dilemma. The two models produce different\nresults, especially for large processor configurations that are so important\nfor today's applications. The question naturally arises: Which of these two\nmodels is the correct one to use? Ignoring this question merely reduces\ncapacity prediction to arbitrary curve-fitting. Removing the dilemma requires a\ndynamical interpretation of these scaling models. We present a physical\ninterpretation based on queueing theory and show that Amdahl's law corresponds\nto synchronous queueing in a bus model while the MPF model belongs to a Coxian\nserver model. The latter exhibits unphysical effects such as sublinear response\ntimes hence, we caution against its use for large multiprocessor\nconfigurations."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0211024v1", 
    "title": "Narses: A Scalable Flow-Based Network Simulator", 
    "arxiv-id": "cs/0211024v1", 
    "author": "Mary Baker", 
    "publish": "2002-11-20T22:32:56Z", 
    "summary": "Most popular, modern network simulators, such as ns, are targeted towards\nsimulating low-level protocol details. These existing simulators are not\nintended for simulating large distributed applications with many hosts and many\nconcurrent connections over long periods of simulated time. We introduce a new\nsimulator, Narses, targeted towards large distributed applications. The goal of\nNarses is to simulate and validate large applications efficiently using network\nmodels of varying levels of detail. We introduce several simplifying\nassumptions that allow our simulator to scale to the needs of large distributed\napplications while maintaining a reasonable degree of accuracy. Initial results\nshow up to a 45 times speedup while consuming 28% of the memory used by ns.\nNarses maintains a reasonable degree of accuracy -- within 8% on average."
},{
    "category": "cs.DC", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0306073v1", 
    "title": "GridMonitor: Integration of Large Scale Facility Fabric Monitoring with   Meta Data Service in Grid Environment", 
    "arxiv-id": "cs/0306073v1", 
    "author": "Patrick McGuigan", 
    "publish": "2003-06-13T20:16:30Z", 
    "summary": "Grid computing consists of the coordinated use of large sets of diverse,\ngeographically distributed resources for high performance computation.\nEffective monitoring of these computing resources is extremely important to\nallow efficient use on the Grid. The large number of heterogeneous computing\nentities available in Grids makes the task challenging. In this work, we\ndescribe a Grid monitoring system, called GridMonitor, that captures and makes\navailable the most important information from a large computing facility. The\nGrid monitoring system consists of four tiers: local monitoring, archiving,\npublishing and harnessing. This architecture was applied on a large scale linux\nfarm and network infrastructure. It can be used by many higher-level Grid\nservices including scheduling services and resource brokering."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0306090v1", 
    "title": "Worldwide Fast File Replication on Grid Datafarm", 
    "arxiv-id": "cs/0306090v1", 
    "author": "Noriyuki Soda", 
    "publish": "2003-06-14T10:46:34Z", 
    "summary": "The Grid Datafarm architecture is designed for global petascale\ndata-intensive computing. It provides a global parallel filesystem with online\npetascale storage, scalable I/O bandwidth, and scalable parallel processing,\nand it can exploit local I/O in a grid of clusters with tens of thousands of\nnodes. One of features is that it manages file replicas in filesystem metadata\nfor fault tolerance and load balancing.\n  This paper discusses and evaluates several techniques to support\nlong-distance fast file replication. The Grid Datafarm manages a ranked group\nof files as a Gfarm file, each file, called a Gfarm file fragment, being stored\non a filesystem node, or replicated on several filesystem nodes. Each Gfarm\nfile fragment is replicated independently and in parallel using rate-controlled\nHighSpeed TCP with network striping. On a US-Japan testbed with 10,000 km\ndistance, we achieve 419 Mbps using 2 nodes on each side, and 741 Mbps using 4\nnodes out of 893 Mbps with two transpacific networks."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0307058v1", 
    "title": "Efficient Instrumentation for Performance Profiling", 
    "arxiv-id": "cs/0307058v1", 
    "author": "Raimondas Lencevicius", 
    "publish": "2003-07-25T21:45:15Z", 
    "summary": "Performance profiling consists of tracing a software system during execution\nand then analyzing the obtained traces. However, traces themselves affect the\nperformance of the system distorting its execution. Therefore, there is a need\nto minimize the effect of the tracing on the underlying system's performance.\nTo achieve this, the trace set needs to be optimized according to the\nperformance profiling problem being solved. Our position is that such\nminimization can be achieved only by adding the software trace design and\nimplementation to the overall software development process. In such a process,\nthe performance analyst supplies the knowledge of performance measurement\nrequirements, while the software developer supplies the knowledge of the\nsoftware. Both of these are needed for an optimal trace placement."
},{
    "category": "cs.SE", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0310001v1", 
    "title": "A Performance Analysis Tool for Nokia Mobile Phone Software", 
    "arxiv-id": "cs/0310001v1", 
    "author": "Raimondas Lencevicius", 
    "publish": "2003-10-03T21:01:49Z", 
    "summary": "Performance problems are often observed in embedded software systems. The\nreasons for poor performance are frequently not obvious. Bottlenecks can occur\nin any of the software components along the execution path. Therefore it is\nimportant to instrument and monitor the different components contributing to\nthe runtime behavior of an embedded software system. Performance analysis tools\ncan help locate performance bottlenecks in embedded software systems by\nmonitoring the software's execution and producing easily understandable\nperformance data. We maintain and further develop a tool for analyzing the\nperformance of Nokia mobile phone software. The user can select among four\nperformance analysis reports to be generated: average processor load, processor\nutilization, task execution time statistics, and task execution timeline. Each\nof these reports provides important information about where execution time is\nbeing spent. The demo will show how the tool helps to identify performance\nbottlenecks in Nokia mobile phone software and better understand areas of poor\nperformance."
},{
    "category": "cs.NI", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0311035v1", 
    "title": "Improving TCP/IP Performance over Wireless IEEE 802.11 Link", 
    "arxiv-id": "cs/0311035v1", 
    "author": "Mokhtar Aboelaze", 
    "publish": "2003-11-24T04:49:23Z", 
    "summary": "Cellular phones, wireless laptops, personal portable devices that supports\nboth voice and data access are all examples of communicating devices that uses\nwireless communication. Sine TCP/IP (and UDP) is the dominant technology in use\nin the internet, it is expected that they will be used (and they are currently)\nover wireless connections. In this paper, we investigate the performance of the\nTCP (and UDP) over IEEE802.11 wireless MAC protocol. We investigate the\nperformance of the TCP and UDP assuming three different traffic patterns. First\nbulk transmission where the main concern is the throughput. Second real-time\naudio (using UDP) in the existence of bulk TCP transmission where the main\nconcern is the packet loss for audio traffic. Finally web traffic where the\nmain concern is the response time. We also investigate the effect of using\nforward Error Correction (FEC) technique and the MAC sublayer parameters on the\nthroughput and response time."
},{
    "category": "cs.NI", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0311049v1", 
    "title": "Performance of TCP/UDP under Ad Hoc IEEE802.11", 
    "arxiv-id": "cs/0311049v1", 
    "author": "Mokhtar Aboelaze", 
    "publish": "2003-11-27T23:02:48Z", 
    "summary": "TCP is the De facto standard for connection oriented transport layer\nprotocol, while UDP is the De facto standard for transport layer protocol,\nwhich is used with real time traffic for audio and video. Although there have\nbeen many attempts to measure and analyze the performance of the TCP protocol\nin wireless networks, very few research was done on the UDP or the interaction\nbetween TCP and UDP traffic over the wireless link. In this paper, we tudy the\nperformance of TCP and UDP over IEEE802.11 ad hoc network. We used two\ntopologies, a string and a mesh topology. Our work indicates that IEEE802.11 as\na ad-hoc network is not very suitable for bulk transfer using TCP. It also\nindicates that it is much better for real-time audio. Although one has to be\ncareful here since real-time audio does require much less bandwidth than the\nwireless link bandwidth. Careful and detailed studies are needed to further\nclarify that issue."
},{
    "category": "cs.GR", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0312006v1", 
    "title": "Benchmarking and Implementation of Probability-Based Simulations on   Programmable Graphics Cards", 
    "arxiv-id": "cs/0312006v1", 
    "author": "J. Spiletic", 
    "publish": "2003-12-02T15:47:19Z", 
    "summary": "The latest Graphics Processing Units (GPUs) are reported to reach up to\n  200 billion floating point operations per second (200 Gflops) and to have\nprice performance of 0.1 cents per M flop. These facts raise great interest in\nthe plausibility of extending the GPUs' use to non-graphics applications, in\nparticular numerical simulations on structured grids (lattice).\n  We review previous work on using GPUs for non-graphics applications,\nimplement probability-based simulations on the GPU, namely the\n  Ising and percolation models, implement vector operation benchmarks for the\nGPU, and finally compare the CPU's and GPU's performance.\n  A general conclusion from the results obtained is that moving computations\nfrom the CPU to the GPU is feasible, yielding good time and price performance,\nfor certain lattice computations.\n  Preliminary results also show that it is feasible to use them in parallel"
},{
    "category": "cs.CR", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0312035v1", 
    "title": "Analysis of Implementation Hierocrypt-3 algorithm (and its comparison to   Camellia algorithm) using ALTERA devices", 
    "arxiv-id": "cs/0312035v1", 
    "author": "Marcin Rogawski", 
    "publish": "2003-12-17T13:01:18Z", 
    "summary": "Alghoritms: HIEROCRYPT-3, CAMELLIA and ANUBIS, GRAND CRU, NOEKEON, NUSH, Q,\nRC6, SAFER++128, SC2000, SHACAL were requested for the submission of block\nciphers (high level block cipher) to NESSIE (New European Schemes for\nSignatures, Integrity, and Encryption) project. The main purpose of this\nproject was to put forward a portfolio of strong cryptographic primitives of\nvarious types. The NESSIE project was a three year long project and has been\ndivided into two phases. The first was finished in June 2001r. CAMELLIA, RC6,\nSAFER++128 and SHACAL were accepted for the second phase of the evaluation\nprocess. HIEROCRYPT-3 had key schedule problems, and there were attacks for up\nto 3,5 rounds out of 6, at least hardware implementations of this cipher were\nextremely slow [12]. HIEROCRYPT-3 was not selected to Phase II. CAMELLIA was\nselected as an algorithm suggested for future standard. In the paper we present\nthe hardware implementations these two algorithms with 128-bit blocks and\n128-bit keys, using ALTERA devices and their comparisons."
},{
    "category": "cs.DB", 
    "doi": "10.1145/3003977.3003998", 
    "link": "http://arxiv.org/pdf/cs/0403021v1", 
    "title": "A Quick Look at SATA Disk Performance", 
    "arxiv-id": "cs/0403021v1", 
    "author": "Jim Gray", 
    "publish": "2004-03-12T10:42:25Z", 
    "summary": "We have been investigating the use of low-cost, commodity components for\nmulti-terabyte SQL Server databases. Dubbed storage bricks, these servers are\nwhite box PCs containing the largest ATA drives, value-priced AMD or Intel\nprocessors, and inexpensive ECC memory. One issue has been the wiring mess, air\nflow problems, length restrictions, and connector failures created by seven or\nmore parallel ATA (PATA) ribbon cables and drives in]a tower or 3U rack-mount\nchassis. Large capacity Serial ATA (SATA) drives have recently become widely\navailable for the PC environment at a reasonable price. In addition to being\nfaster, the SATA connectors seem more reliable, have a more reasonable length\nrestriction (1m) and allow better airflow. We tested two drive brands along\nwith two RAID controllers to evaluate SATA drive performance and reliablility.\nThis paper documents our results so far."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0403029v1", 
    "title": "Characterization of the Burst Stabilization Protocol for the RR/RR CICQ   Switch", 
    "arxiv-id": "cs/0403029v1", 
    "author": "Kenji Yoshigoe", 
    "publish": "2004-03-17T22:42:52Z", 
    "summary": "Input buffered switches with Virtual Output Queueing (VOQ) can be unstable\nwhen presented with unbalanced loads. Existing scheduling algorithms, including\niSLIP for Input Queued (IQ) switches and Round Robin (RR) for Combined Input\nand Crossbar Queued (CICQ) switches, exhibit instability for some schedulable\nloads. We investigate the use of a queue length threshold and bursting\nmechanism to achieve stability without requiring internal speed-up. An\nanalytical model is developed to prove that the burst stabilization protocol\nachieves stability and to predict the minimum burst value needed as a function\nof offered load. The analytical model is shown to have very good agreement with\nsimulation results. These results show the advantage of the RR/RR CICQ switch\nas a contender for the next generation of high-speed switches."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0403030v1", 
    "title": "Performance Evaluation of Packet-to-Cell Segmentation Schemes in Input   Buffered Packet Switches", 
    "arxiv-id": "cs/0403030v1", 
    "author": "N. J. Gunther", 
    "publish": "2004-03-17T23:02:55Z", 
    "summary": "Most input buffered packet switches internally segment variable-length\npackets into fixed-length cells. The last cell in a segmented packet will\ncontain overhead bytes if the packet length is not evenly divisible by the cell\nlength. Switch speed-up is used to compensate for this overhead. In this paper,\nwe develop an analytical model of a single-server queue where an input stream\nof packets is segmented into cells for service. Analytical models are developed\nfor M/M/1, M/H2/1, and M/E2/1 queues with a discretized (or quantized) service\ntime. These models and simulation using real packet traces are used to evaluate\nthe effect of speed-up on mean queue length. We propose and evaluate a new\nmethod of segmenting a packet trailer and subsequent packet header into a\nsingle cell. This cell merging method reduces the required speed-up. No changes\nto switch-matrix scheduling algorithms are needed. Simulation with a packet\ntrace shows a reduction in the needed speed-up for an iSLIP scheduled input\nbuffered switch."
},{
    "category": "cs.PF", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0404001v1", 
    "title": "On the Practicality of Intrinsic Reconfiguration As a Fault Recovery   Method in Analog Systems", 
    "arxiv-id": "cs/0404001v1", 
    "author": "Garrison W. Greenwood", 
    "publish": "2004-04-01T16:54:42Z", 
    "summary": "Evolvable hardware combines the powerful search capability of evolutionary\nalgorithms with the flexibility of reprogrammable devices, thereby providing a\nnatural framework for reconfiguration. This framework has generated an interest\nin using evolvable hardware for fault-tolerant systems because reconfiguration\ncan effectively deal with hardware faults whenever it is impossible to provide\nspares. But systems cannot tolerate faults indefinitely, which means\nreconfiguration does have a deadline. The focus of previous evolvable hardware\nresearch relating to fault-tolerance has been primarily restricted to restoring\nfunctionality, with no real consideration of time constraints. In this paper we\nare concerned with evolvable hardware performing reconfiguration under deadline\nconstraints. In particular, we investigate reconfigurable hardware that\nundergoes intrinsic evolution. We show that fault recovery done by intrinsic\nreconfiguration has some restrictions, which designers cannot ignore."
},{
    "category": "cs.PF", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0404043v1", 
    "title": "Benchmarking Blunders and Things That Go Bump in the Night", 
    "arxiv-id": "cs/0404043v1", 
    "author": "Neil J. Gunther", 
    "publish": "2004-04-21T20:07:07Z", 
    "summary": "Benchmarking; by which I mean any computer system that is driven by a\ncontrolled workload, is the ultimate in performance testing and simulation.\nAside from being a form of institutionalized cheating, it also offer countless\nopportunities for systematic mistakes in the way the workloads are applied and\nthe resulting measurements interpreted. Right test, wrong conclusion is a\nubiquitous mistake that happens because test engineers tend to treat data as\ndivine. Such reverence is not only misplaced, it's also a sure ticket to\nproduction hell when the application finally goes live. I demonstrate how such\nmistakes can be avoided by means of two war stories that are real WOPRs. (a)\nHow to resolve benchmark flaws over the psychic hotline and (b) How benchmarks\ncan go flat with too much Java juice. In each case I present simple performance\nmodels and show how they can be applied to correctly assess benchmark data."
},{
    "category": "cs.CE", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0406042v1", 
    "title": "Business Process Measures", 
    "arxiv-id": "cs/0406042v1", 
    "author": "Valdis Vitolins", 
    "publish": "2004-06-22T12:19:54Z", 
    "summary": "The paper proposes a new methodology for defining business process measures\nand their computation. The approach is based on metamodeling according to MOF.\nEspecially, a metamodel providing precise definitions of typical process\nmeasures for UML activity diagram-like notation is proposed, including precise\ndefinitions how measures should be aggregated for composite process elements.\nThe proposed approach allows defining values in a natural way, and measurement\nof data, which are of interest to business, without deep investigation into\nspecific technical solutions. This provides new possibilities for business\nprocess measurement, decreasing the gap between technical solutions and asset\nmanagement methodologies."
},{
    "category": "cs.DC", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0407062v1", 
    "title": "Performance Analysis of the Globus Toolkit Monitoring and Discovery   Service, MDS2", 
    "arxiv-id": "cs/0407062v1", 
    "author": "Jennifer M. Schopf", 
    "publish": "2004-07-28T14:07:58Z", 
    "summary": "Monitoring and information services form a key component of a distributed\nsystem, or Grid. A quantitative study of such services can aid in understanding\nthe performance limitations, advise in the deployment of the monitoring system,\nand help evaluate future development work. To this end, we examined the\nperformance of the Globus Toolkit(reg. trdmrk) Monitoring and Discovery Service\n(MDS2) by instrumenting its main services using NetLogger. Our study shows a\nstrong advantage to caching or prefetching the data, as well as the need to\nhave primary components at well-connected sites."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0408002v1", 
    "title": "Roaming Real-Time Applications - Mobility Services in IPv6 Networks", 
    "arxiv-id": "cs/0408002v1", 
    "author": "Matthias W\u00e4hlisch", 
    "publish": "2004-07-31T14:43:23Z", 
    "summary": "Emerging mobility standards within the next generation Internet Protocol,\nIPv6, promise to continuously operate devices roaming between IP networks.\nAssociated with the paradigm of ubiquitous computing and communication, network\ntechnology is on the spot to deliver voice and videoconferencing as a standard\ninternet solution. However, current roaming procedures are too slow, to remain\nseamless for real-time applications. Multicast mobility still waits for a\nconvincing design. This paper investigates the temporal behaviour of mobile\nIPv6 with dedicated focus on topological impacts. Extending the hierarchical\nmobile IPv6 approach we suggest protocol improvements for a continuous\nhandover, which may serve bidirectional multicast communication, as well. Along\nthis line a multicast mobility concept is introduced as a service for clients\nand sources, as they are of dedicated importance in multipoint conferencing\napplications. The mechanisms introduced do not rely on assumptions of any\nspecific multicast routing protocol in use."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCN.2003.1243135", 
    "link": "http://arxiv.org/pdf/cs/0408009v1", 
    "title": "Performance Analysis of Multicast Mobility in a Hierarchical Mobile IP   Proxy Environment", 
    "arxiv-id": "cs/0408009v1", 
    "author": "Matthias W\u00e4hlisch", 
    "publish": "2004-08-03T10:18:54Z", 
    "summary": "Mobility support in IPv6 networks is ready for release as an RFC, stimulating\nmajor discussions on improvements to meet real-time communication requirements.\nSprawling hot spots of IP-only wireless networks at the same time await voice\nand videoconferencing as standard mobile Internet services, thereby adding the\nrequest for multicast support to real-time mobility. This paper briefly\nintroduces current approaches for seamless multicast extensions to Mobile IPv6.\nKey issues of multicast mobility are discussed. Both analytically and in\nsimulations comparisons are drawn between handover performance characteristics,\ndedicating special focus on the M-HMIPv6 approach."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0410012v1", 
    "title": "DiPerF: an automated DIstributed PERformance testing Framework", 
    "arxiv-id": "cs/0410012v1", 
    "author": "Ian Foster", 
    "publish": "2004-10-05T22:38:14Z", 
    "summary": "We present DiPerF, a distributed performance testing framework, aimed at\nsimplifying and automating service performance evaluation. DiPerF coordinates a\npool of machines that test a target service, collects and aggregates\nperformance metrics, and generates performance statistics. The aggregate data\ncollected provide information on service throughput, on service \"fairness\" when\nserving multiple clients concurrently, and on the impact of network latency on\nservice performance. Furthermore, using this data, it is possible to build\npredictive models that estimate a service performance given the service load.\nWe have tested DiPerF on 100+ machines on two testbeds, Grid3 and PlanetLab,\nand explored the performance of job submission services (pre WS GRAM and WS\nGRAM) included with Globus Toolkit 3.2."
},{
    "category": "cs.DC", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0410066v2", 
    "title": "Fast Query Processing by Distributing an Index over CPU Caches", 
    "arxiv-id": "cs/0410066v2", 
    "author": "Gene Cooperman", 
    "publish": "2004-10-25T22:23:17Z", 
    "summary": "Data intensive applications on clusters often require requests quickly be\nsent to the node managing the desired data. In many applications, one must look\nthrough a sorted tree structure to determine the responsible node for accessing\nor storing the data.\n  Examples include object tracking in sensor networks, packet routing over the\ninternet, request processing in publish-subscribe middleware, and query\nprocessing in database systems. When the tree structure is larger than the CPU\ncache, the standard implementation potentially incurs many cache misses for\neach lookup; one cache miss at each successive level of the tree. As the\nCPU-RAM gap grows, this performance degradation will only become worse in the\nfuture.\n  We propose a solution that takes advantage of the growing speed of local area\nnetworks for clusters. We split the sorted tree structure among the nodes of\nthe cluster. We assume that the structure will fit inside the aggregation of\nthe CPU caches of the entire cluster. We then send a word over the network (as\npart of a larger packet containing other words) in order to examine the tree\nstructure in another node's CPU cache. We show that this is often faster than\nthe standard solution, which locally incurs multiple cache misses while\naccessing each successive level of the tree."
},{
    "category": "cs.NI", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0411042v1", 
    "title": "An Empirical Analysis of Internet Protocol Version 6 (IPv6)", 
    "arxiv-id": "cs/0411042v1", 
    "author": "Ioan Raicu", 
    "publish": "2004-11-12T22:31:03Z", 
    "summary": "Although the current Internet Protocol known as IPv4 has served its purpose\nfor over 20 years, its days are numbered. With IPv6 reaching a mature enough\nlevel, there is a need to evaluate the performance benefits or drawbacks that\nthe new IPv6 protocol will have in comparison to the well established IPv4\nprotocol. Theoretically, the overhead between the two different protocols\nshould be directly proportional to the difference in the packet's header size,\nhowever according to our findings, the empirical performance difference between\nIPv4 and IPv6, especially when the transition mechanisms are taken into\nconsideration, is much larger than anticipated. We first examine the\nperformance of each protocol independently. We then examined two transition\nmechanisms which perform the encapsulation at various points in the network:\nhost-to-host and router-to-router (tunneling). Our experiments were conducted\nusing two dual stack (IPv4/IPv6) routers using end nodes running both Windows\n2000 and Solaris 8.0 in order to compare two different IPv6 implementations\nside by side. Our tests were written in C++ and utilized metrics such as\nlatency, throughput, CPU utilization, socket creation time, socket connection\ntime, web server simulation, and a video client/server application for TCP/UDP\nin IPv4/IPv6 under both Windows 2000 and Solaris 8.0. Our empirical evaluation\nproved that IPv6 is not yet a mature enough technology and that it is still\nyears away from having consistent and good enough implementations, as the\nperformance of IPv6 in many cases proved to be significantly worse than IPv4."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0412027v1", 
    "title": "Correlated dynamics in human printing behavior", 
    "arxiv-id": "cs/0412027v1", 
    "author": "Maya Paczuski", 
    "publish": "2004-12-07T15:27:47Z", 
    "summary": "Arrival times of requests to print in a student laboratory were analyzed.\nInter-arrival times between subsequent requests follow a universal scaling law\nrelating time intervals and the size of the request, indicating a scale\ninvariant dynamics with respect to the size. The cumulative distribution of\nfile sizes is well-described by a modified power law often seen in\nnon-equilibrium critical systems. For each user, waiting times between their\nindividual requests show long range dependence and are broadly distributed from\nseconds to weeks. All results are incompatible with Poisson models, and may\nprovide evidence of critical dynamics associated with voluntary thought\nprocesses in the brain."
},{
    "category": "cs.DC", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0502003v1", 
    "title": "Shawn: A new approach to simulating wireless sensor networks", 
    "arxiv-id": "cs/0502003v1", 
    "author": "Stefan Fischer", 
    "publish": "2005-02-01T12:23:26Z", 
    "summary": "We consider the simulation of wireless sensor networks (WSN) using a new\napproach. We present Shawn, an open-source discrete-event simulator that has\nconsiderable differences to all other existing simulators. Shawn is very\npowerful in simulating large scale networks with an abstract point of view. It\nis, to the best of our knowledge, the first simulator to support generic\nhigh-level algorithms as well as distributed protocols on exactly the same\nunderlying networks."
},{
    "category": "cs.DB", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0502009v1", 
    "title": "Performance Considerations for Gigabyte per Second Transcontinental   Disk-to-Disk File Transfers", 
    "arxiv-id": "cs/0502009v1", 
    "author": "Jim Gray", 
    "publish": "2005-02-02T03:26:40Z", 
    "summary": "Moving data from CERN to Pasadena at a gigabyte per second using the next\ngeneration Internet requires good networking and good disk IO. Ten Gbps\nEthernet and OC192 links are in place, so now it is simply a matter of\nprogramming. This report describes our preliminary work and measurements in\nconfiguring the disk subsystem for this effort. Using 24 SATA disks at each\nendpoint we are able to locally read and write an NTFS volume is striped across\n24 disks at 1.2 GBps. A 32-disk stripe delivers 1.7 GBps. Experiments on higher\nperformance and higher-capacity systems deliver up to 3.5 GBps."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0502012v1", 
    "title": "Sequential File Programming Patterns and Performance with .NET", 
    "arxiv-id": "cs/0502012v1", 
    "author": "Jim Gray", 
    "publish": "2005-02-02T04:43:33Z", 
    "summary": "Programming patterns for sequential file access in the .NET Framework are\ndescribed and the performance is measured. The default behavior provides\nexcellent performance on a single disk - 50 MBps both reading and writing.\nUsing large request sizes and doing file pre-allocation when possible have\nquantifiable benefits. When one considers disk arrays, .NET unbuffered IO\ndelivers 800 MBps on a 16-disk array, but buffered IO delivers about 12% of\nthat performance. Consequently, high-performance file and database utilities\nare still forced to use unbuffered IO for maximum sequential performance. The\nreport is accompanied by downloadable source code that demonstrates the\nconcepts and code that was used to obtain these measurements."
},{
    "category": "cs.PL", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0505085v1", 
    "title": "Improving PARMA Trailing", 
    "arxiv-id": "cs/0505085v1", 
    "author": "Peter J. Stuckey", 
    "publish": "2005-05-31T08:23:32Z", 
    "summary": "Taylor introduced a variable binding scheme for logic variables in his PARMA\nsystem, that uses cycles of bindings rather than the linear chains of bindings\nused in the standard WAM representation. Both the HAL and dProlog languages\nmake use of the PARMA representation in their Herbrand constraint solvers.\nUnfortunately, PARMA's trailing scheme is considerably more expensive in both\ntime and space consumption. The aim of this paper is to present several\ntechniques that lower the cost.\n  First, we introduce a trailing analysis for HAL using the classic PARMA\ntrailing scheme that detects and eliminates unnecessary trailings. The\nanalysis, whose accuracy comes from HAL's determinism and mode declarations,\nhas been integrated in the HAL compiler and is shown to produce space\nimprovements as well as speed improvements. Second, we explain how to modify\nthe classic PARMA trailing scheme to halve its trailing cost. This technique is\nillustrated and evaluated both in the context of dProlog and HAL. Finally, we\nexplain the modifications needed by the trailing analysis in order to be\ncombined with our modified PARMA trailing scheme. Empirical evidence shows that\nthe combination is more effective than any of the techniques when used in\nisolation.\n  To appear in Theory and Practice of Logic Programming."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0507073v1", 
    "title": "Software Performance Analysis", 
    "arxiv-id": "cs/0507073v1", 
    "author": "Makan Pourzandi", 
    "publish": "2005-07-29T19:33:13Z", 
    "summary": "The key to speeding up applications is often understanding where the elapsed\ntime is spent, and why. This document reviews in depth the full array of\nperformance analysis tools and techniques available on Linux for this task,\nfrom the traditional tools like gcov and gprof, to the more advanced tools\nstill under development like oprofile and the Linux Trace Toolkit. The focus is\nmore on the underlying data collection and processing algorithms, and their\noverhead and precision, than on the cosmetic details of the graphical user\ninterface frontends."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0508063v1", 
    "title": "Disks, Partitions, Volumes and RAID Performance with the Linux Operating   System", 
    "arxiv-id": "cs/0508063v1", 
    "author": "Michel R. Dagenais", 
    "publish": "2005-08-12T16:13:32Z", 
    "summary": "Block devices in computer operating systems typically correspond to disks or\ndisk partitions, and are used to store files in a filesystem. Disks are not the\nonly real or virtual device which adhere to the block accessible stream of\nbytes block device model. Files, remote devices, or even RAM may be used as a\nvirtual disks. This article examines several common combinations of block\ndevice layers used as virtual disks in the Linux operating system: disk\npartitions, loopback files, software RAID, Logical Volume Manager, and Network\nBlock Devices. It measures their relative performance using different\nfilesystems: Ext2, Ext3, ReiserFS, JFS, XFS,NFS."
},{
    "category": "cs.DM", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0512043v1", 
    "title": "Random Walks with Anti-Correlated Steps", 
    "arxiv-id": "cs/0512043v1", 
    "author": "John Noga", 
    "publish": "2005-12-10T08:04:32Z", 
    "summary": "We conjecture the expected value of random walks with anti-correlated steps\nto be exactly 1. We support this conjecture with 2 plausibility arguments and\nexperimental data. The experimental analysis includes the computation of the\nexpected values of random walks for steps up to 22. The result shows the\nexpected value asymptotically converging to 1."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0601097v2", 
    "title": "Compression Scheme for Faster and Secure Data Transmission Over Internet", 
    "arxiv-id": "cs/0601097v2", 
    "author": "Dr. V. K. Govindan", 
    "publish": "2006-01-23T11:47:06Z", 
    "summary": "Compression algorithms reduce the redundancy in data representation to\ndecrease the storage required for that data. Data compression offers an\nattractive approach to reducing communication costs by using available\nbandwidth effectively. Over the last decade there has been an unprecedented\nexplosion in the amount of digital data transmitted via the Internet,\nrepresenting text, images, video, sound, computer programs, etc. With this\ntrend expected to continue, it makes sense to pursue research on developing\nalgorithms that can most effectively use available network bandwidth by\nmaximally compressing data. It is also important to consider the security\naspects of the data being transmitted while compressing it, as most of the text\ndata transmitted over the Internet is very much vulnerable to a multitude of\nattacks. This paper is focused on addressing this problem of lossless\ncompression of text files with an added security."
},{
    "category": "cs.DC", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0602061v1", 
    "title": "The Computational and Storage Potential of Volunteer Computing", 
    "arxiv-id": "cs/0602061v1", 
    "author": "Gilles Fedak", 
    "publish": "2006-02-16T22:33:04Z", 
    "summary": "\"Volunteer computing\" uses Internet-connected computers, volunteered by their\nowners, as a source of computing power and storage. This paper studies the\npotential capacity of volunteer computing. We analyzed measurements of over\n330,000 hosts participating in a volunteer computing project. These\nmeasurements include processing power, memory, disk space, network throughput,\nhost availability, user-specified limits on resource usage, and host churn. We\nshow that volunteer computing can support applications that are significantly\nmore data-intensive, or have larger memory and storage requirements, than those\nin current projects."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0603099v1", 
    "title": "Benchmark Problems for Constraint Solving", 
    "arxiv-id": "cs/0603099v1", 
    "author": "Tudor Muresan", 
    "publish": "2006-03-26T20:19:59Z", 
    "summary": "Constraint Programming is roughly a new software technology introduced by\nJaffar and Lassez in 1987 for description and effective solving of large,\nparticularly combinatorial, problems especially in areas of planning and\nscheduling. In the following we define three problems for constraint solving\nfrom the domain of electrical networks; based on them we define 43 related\nproblems. For the defined set of problems we benchmarked five systems: ILOG\nOPL, AMPL, GAMS, Mathematica and UniCalc. As expected some of the systems\nperformed very well for some problems while others performed very well on\nothers."
},{
    "category": "cs.NI", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0605030v1", 
    "title": "A Delay Analysis of Maximal Matching Switching with Speedup", 
    "arxiv-id": "cs/0605030v1", 
    "author": "Sanjay Lall", 
    "publish": "2006-05-08T08:04:20Z", 
    "summary": "In this paper we analyze the average queue backlog in a combined input-output\nqueued switch using a maximal size matching scheduling algorithm. We compare\nthis average backlog to the average backlog achieved by an optimal switch. We\nmodel the cell arrival process as independent and identically distributed\nbetween time slots and uniformly distributed among input and output ports. For\nswitches with many input and output ports, the backlog associated with maximal\nsize matching with speedup 3 is no more than 10/3 times the backlog associated\nwith an optimal switch. Moreover, this performance ratio rapidly approaches 2\nas speedup increases."
},{
    "category": "cs.CC", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0606120v1", 
    "title": "On symmetric sandpiles", 
    "arxiv-id": "cs/0606120v1", 
    "author": "Theophilos Pisokas", 
    "publish": "2006-06-29T09:53:05Z", 
    "summary": "A symmetric version of the well-known SPM model for sandpiles is introduced.\nWe prove that the new model has fixed point dynamics. Although there might be\nseveral fixed points, a precise description of the fixed points is given.\nMoreover, we provide a simple closed formula for counting the number of fixed\npoints originated by initial conditions made of a single column of grains."
},{
    "category": "cs.DC", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0607041v1", 
    "title": "Methods for Partitioning Data to Improve Parallel Execution Time for   Sorting on Heterogeneous Clusters", 
    "arxiv-id": "cs/0607041v1", 
    "author": "the SafeScale Collaboration", 
    "publish": "2006-07-10T19:46:47Z", 
    "summary": "The aim of the paper is to introduce general techniques in order to optimize\nthe parallel execution time of sorting on a distributed architectures with\nprocessors of various speeds. Such an application requires a partitioning step.\nFor uniformly related processors (processors speeds are related by a constant\nfactor), we develop a constant time technique for mastering processor load and\nexecution time in an heterogeneous environment and also a technique to deal\nwith unknown cost functions. For non uniformly related processors, we use a\ntechnique based on dynamic programming. Most of the time, the solutions are in\nO(p) (p is the number of processors), independent of the problem size n.\nConsequently, there is a small overhead regarding the problem we deal with but\nit is inherently limited by the knowing of time complexity of the portion of\ncode following the partitioning."
},{
    "category": "cs.CG", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0608063v1", 
    "title": "A Generic Lazy Evaluation Scheme for Exact Geometric Computations", 
    "arxiv-id": "cs/0608063v1", 
    "author": "Andreas Fabri", 
    "publish": "2006-08-15T19:24:02Z", 
    "summary": "We present a generic C++ design to perform efficient and exact geometric\ncomputations using lazy evaluations. Exact geometric computations are critical\nfor the robustness of geometric algorithms. Their efficiency is also critical\nfor most applications, hence the need for delaying the exact computations at\nrun time until they are actually needed. Our approach is generic and extensible\nin the sense that it is possible to make it a library which users can extend to\ntheir own geometric objects or primitives. It involves techniques such as\ngeneric functor adaptors, dynamic polymorphism, reference counting for the\nmanagement of directed acyclic graphs and exception handling for detecting\ncases where exact computations are needed. It also relies on multiple precision\narithmetic as well as interval arithmetic. We apply our approach to the whole\ngeometric kernel of CGAL."
},{
    "category": "cs.PL", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0610028v1", 
    "title": "Memory and compiler optimizations for low-power and -energy", 
    "arxiv-id": "cs/0610028v1", 
    "author": "Olivier Zendra", 
    "publish": "2006-10-05T17:58:36Z", 
    "summary": "Embedded systems become more and more widespread, especially autonomous ones,\nand clearly tend to be ubiquitous. In such systems, low-power and low-energy\nusage get ever more crucial. Furthermore, these issues also become paramount in\n(massively) multi-processors systems, either in one machine or more widely in a\ngrid. The various problems faced pertain to autonomy, power supply\npossibilities, thermal dissipation, or even sheer energy cost. Although it has\nsince long been studied in harware, energy optimization is more recent in\nsoftware. In this paper, we thus aim at raising awareness to low-power and\nlow-energy issues in the language and compilation community. We thus broadly\nbut briefly survey techniques and solutions to this energy issue, focusing on a\nfew specific aspects in the context of compiler optimizations and memory\nmanagement."
},{
    "category": "cs.NI", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0611064v1", 
    "title": "Distributed Link Scheduling with Constant Overhead", 
    "arxiv-id": "cs/0611064v1", 
    "author": "R. Srikant", 
    "publish": "2006-11-14T22:58:32Z", 
    "summary": "This paper proposes a new class of simple, distributed algorithms for\nscheduling in wireless networks. The algorithms generate new schedules in a\ndistributed manner via simple local changes to existing schedules. The class is\nparameterized by integers $k\\geq 1$. We show that algorithm $k$ of our class\nachieves $k/(k+2)$ of the capacity region, for every $k\\geq 1$. The algorithms\nhave small and constant worst-case overheads: in particular, algorithm $k$\ngenerates a new schedule using {\\em (a)} time less than $4k+2$ round-trip times\nbetween neighboring nodes in the network, and {\\em (b)} at most three control\ntransmissions by any given node, for any $k$. The control signals are\nexplicitly specified, and face the same interference effects as normal data\ntransmissions. Our class of distributed wireless scheduling algorithms are the\nfirst ones guaranteed to achieve any fixed fraction of the capacity region\nwhile using small and constant overheads that do not scale with network size.\nThe parameter $k$ explicitly captures the tradeoff between control overhead and\nscheduler throughput performance and provides a tuning knob protocol designers\ncan use to harness this trade-off in practice."
},{
    "category": "cs.PL", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0611093v2", 
    "title": "Effectiveness of Garbage Collection in MIT/GNU Scheme", 
    "arxiv-id": "cs/0611093v2", 
    "author": "Uday Khedker", 
    "publish": "2006-11-20T09:08:40Z", 
    "summary": "Scheme uses garbage collection for heap memory management. Ideally, garbage\ncollectors should be able to reclaim all dead objects, i.e. objects that will\nnot be used in future. However, garbage collectors collect only those dead\nobjects that are not reachable from any program variable. Dead objects that are\nreachable from program variables are not reclaimed.\n  In this paper we describe our experiments to measure the effectiveness of\ngarbage collection in MIT/GNU Scheme. We compute the drag time of objects, i.e.\nthe time for which an object remains in heap memory after its last use. The\nnumber of dead objects and the drag time together indicate opportunities for\nimproving garbage collection. Our experiments reveal that up to 26% of dead\nobjects remain in memory. The average drag time is up to 37% of execution time.\nOverall, we observe memory saving potential ranging from 9% to 65%."
},{
    "category": "cs.NI", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0612048v1", 
    "title": "Queue Model of Leaf Degree Keeping Process in Gnutella Network", 
    "arxiv-id": "cs/0612048v1", 
    "author": "changjia chen", 
    "publish": "2006-12-08T00:44:26Z", 
    "summary": "Leaf degree keeping process of Gnutella is discussed in this paper. Queue\nsystem based on rules of Gnutella protocol are introduced to modeling this\nprocess. The leaf degree distributions resulted from the queue system and from\nour real measurement are compared. The well match of those distributions reveal\nthat the leaf degree distribution in Gnutella network should not be power law\nor power law like as reported before. It is more likely a distribution driven\nby certain queue process specified by the protocol."
},{
    "category": "cs.DC", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0612105v2", 
    "title": "Towards Parallel Computing on the Internet: Applications, Architectures,   Models and Programming Tools", 
    "arxiv-id": "cs/0612105v2", 
    "author": "Aaron Harwood", 
    "publish": "2006-12-21T06:38:21Z", 
    "summary": "The development of Internet wide resources for general purpose parallel\ncomputing poses the challenging task of matching computation and communication\ncomplexity. A number of parallel computing models exist that address this for\ntraditional parallel architectures, and there are a number of emerging models\nthat attempt to do this for large scale Internet-based systems like\ncomputational grids. In this survey we cover the three fundamental aspects --\napplication, architecture and model, and we show how they have been developed\nover the last decade. We also cover programming tools that are currently being\nused for parallel programming in computational grids. The trend in conventional\ncomputational models are to put emphasis on efficient communication between\nparticipating nodes by adapting different types of communication to network\nconditions. Effects of dynamism and uncertainties that arise in large scale\nsystems are evidently important to understand and yet there is currently little\nwork that addresses this from a parallel computing perspective."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0701001v1", 
    "title": "On High Spatial Reuse Link Scheduling in STDMA Wireless Ad Hoc Networks", 
    "arxiv-id": "cs/0701001v1", 
    "author": "Abhay Karandikar", 
    "publish": "2007-01-02T14:14:11Z", 
    "summary": "Graph-based algorithms for point-to-point link scheduling in Spatial reuse\nTime Division Multiple Access (STDMA) wireless ad hoc networks often result in\na significant number of transmissions having low Signal to Interference and\nNoise density Ratio (SINR) at intended receivers, leading to low throughput. To\novercome this problem, we propose a new algorithm for STDMA link scheduling\nbased on a graph model of the network as well as SINR computations. The\nperformance of our algorithm is evaluated in terms of spatial reuse and\ncomputational complexity. Simulation results demonstrate that our algorithm\nachieves better performance than existing algorithms."
},{
    "category": "cs.DB", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0701161v1", 
    "title": "Thousands of DebitCredit Transactions-Per-Second: Easy and Inexpensive", 
    "arxiv-id": "cs/0701161v1", 
    "author": "Charles Levine", 
    "publish": "2007-01-25T23:51:22Z", 
    "summary": "A $2k computer can execute about 8k transactions per second. This is 80x more\nthan one of the largest US bank's 1970's traffic - it approximates the total US\n1970's financial transaction volume. Very modest modern computers can easily\nsolve yesterday's problems."
},{
    "category": "cs.DB", 
    "doi": "10.1109/GRID.2004.21", 
    "link": "http://arxiv.org/pdf/cs/0701162v1", 
    "title": "A Measure of Transaction Processing 20 Years Later", 
    "arxiv-id": "cs/0701162v1", 
    "author": "Jim Gray", 
    "publish": "2007-01-25T23:57:15Z", 
    "summary": "This provides a retrospective of the paper \"A Measure of Transaction\nProcessing\" published in 1985. It shows that transaction processing peak\nperformance and price-peformance have improved about 100,000x respectively and\nthat sort/sequential performance has approximately doubled each year (so a\nmillion fold improvement) even though processor performance plateaued in 1995."
},{
    "category": "cs.PL", 
    "doi": "10.1007/11575467_7", 
    "link": "http://arxiv.org/pdf/cs/0701191v1", 
    "title": "The parallel implementation of the Astr\u00e9e static analyzer", 
    "arxiv-id": "cs/0701191v1", 
    "author": "David Monniaux", 
    "publish": "2007-01-30T15:20:07Z", 
    "summary": "The Astr\\'{e}e static analyzer is a specialized tool that can prove the\nabsence of runtime errors, including arithmetic overflows, in large critical\nprograms. Keeping analysis times reasonable for industrial use is one of the\ndesign objectives. In this paper, we discuss the parallel implementation of the\nanalysis."
},{
    "category": "cs.PL", 
    "doi": "10.1145/781131.781153", 
    "link": "http://arxiv.org/pdf/cs/0701193v1", 
    "title": "A Static Analyzer for Large Safety-Critical Software", 
    "arxiv-id": "cs/0701193v1", 
    "author": "Xavier Rival", 
    "publish": "2007-01-30T16:57:14Z", 
    "summary": "We show that abstract interpretation-based static program analysis can be\nmade efficient and precise enough to formally verify a class of properties for\na family of large programs with few or no false alarms. This is achieved by\nrefinement of a general purpose static analyzer and later adaptation to\nparticular programs of the family by the end-user through parametrization. This\nis applied to the proof of soundness of data manipulation operations at the\nmachine level for periodic synchronous safety critical embedded software. The\nmain novelties are the design principle of static analyzers by refinement and\nadaptation through parametrization, the symbolic manipulation of expressions to\nimprove the precision of abstract transfer functions, the octagon, ellipsoid,\nand decision tree abstract domains, all with sound handling of rounding errors\nin floating point computations, widening strategies (with thresholds, delayed)\nand the automatic determination of the parameters (parametrized packing)."
},{
    "category": "cs.PL", 
    "doi": "10.1145/360204.360211", 
    "link": "http://arxiv.org/pdf/cs/0701195v1", 
    "title": "An Abstract Monte-Carlo Method for the Analysis of Probabilistic   Programs", 
    "arxiv-id": "cs/0701195v1", 
    "author": "David Monniaux", 
    "publish": "2007-01-30T17:14:52Z", 
    "summary": "We introduce a new method, combination of random testing and abstract\ninterpretation, for the analysis of programs featuring both probabilistic and\nnon-probabilistic nondeterminism. After introducing \"ordinary\" testing, we show\nhow to combine testing and abstract interpretation and give formulas linking\nthe precision of the results to the number of iterations. We then discuss\ncomplexity and optimization issues and end with some experimental results."
},{
    "category": "cs.AR", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/cs/0702062v1", 
    "title": "Noise Limited Computational Speed", 
    "arxiv-id": "cs/0702062v1", 
    "author": "Luca Gammaitoni", 
    "publish": "2007-02-11T09:52:12Z", 
    "summary": "In modern transistor based logic gates, the impact of noise on computation\nhas become increasingly relevant since the voltage scaling strategy, aimed at\ndecreasing the dissipated power, has increased the probability of error due to\nthe reduced switching threshold voltages. In this paper we discuss the role of\nnoise in a two state model that mimic the dynamics of standard logic gates and\nshow that the presence of the noise sets a fundamental limit to the computing\nspeed. An optimal idle time interval that minimizes the error probability, is\nderived."
},{
    "category": "cs.DB", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/cs/0703056v3", 
    "title": "Unasssuming View-Size Estimation Techniques in OLAP", 
    "arxiv-id": "cs/0703056v3", 
    "author": "Daniel Lemire", 
    "publish": "2007-03-12T21:42:59Z", 
    "summary": "Even if storage was infinite, a data warehouse could not materialize all\npossible views due to the running time and update requirements. Therefore, it\nis necessary to estimate quickly, accurately, and reliably the size of views.\nMany available techniques make particular statistical assumptions and their\nerror can be quite large. Unassuming techniques exist, but typically assume we\nhave independent hashing for which there is no known practical implementation.\nWe adapt an unassuming estimator due to Gibbons and Tirthapura: its theoretical\nbounds do not make unpractical assumptions. We compare this technique\nexperimentally with stochastic probabilistic counting, LogLog probabilistic\ncounting, and multifractal statistical models. Our experiments show that we can\nreliably and accurately (within 10%, 19 times out 20) estimate view sizes over\nlarge data sets (1.5 GB) within minutes, using almost no memory. However, only\nGibbons-Tirthapura provides universally tight estimates irrespective of the\nsize of the view. For large views, probabilistic counting has a small edge in\naccuracy, whereas the competitive sampling-based method (multifractal) we\ntested is an order of magnitude faster but can sometimes provide poor estimates\n(relative error of 100%). In our tests, LogLog probabilistic counting is not\ncompetitive. Experimental validation on the US Census 1990 data set and on the\nTransaction Processing Performance (TPC H) data set is provided."
},{
    "category": "cs.DB", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/cs/0703058v3", 
    "title": "A Comparison of Five Probabilistic View-Size Estimation Techniques in   OLAP", 
    "arxiv-id": "cs/0703058v3", 
    "author": "Daniel Lemire", 
    "publish": "2007-03-13T17:46:11Z", 
    "summary": "A data warehouse cannot materialize all possible views, hence we must\nestimate quickly, accurately, and reliably the size of views to determine the\nbest candidates for materialization. Many available techniques for view-size\nestimation make particular statistical assumptions and their error can be\nlarge. Comparatively, unassuming probabilistic techniques are slower, but they\nestimate accurately and reliability very large view sizes using little memory.\nWe compare five unassuming hashing-based view-size estimation techniques\nincluding Stochastic Probabilistic Counting and LogLog Probabilistic Counting.\nOur experiments show that only Generalized Counting, Gibbons-Tirthapura, and\nAdaptive Counting provide universally tight estimates irrespective of the size\nof the view; of those, only Adaptive Counting remains constantly fast as we\nincrease the memory budget."
},{
    "category": "cs.PF", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0704.0730v1", 
    "title": "Revisiting the Issues On Netflow Sample and Export Performance", 
    "arxiv-id": "0704.0730v1", 
    "author": "Saleem Bhatti", 
    "publish": "2007-04-05T14:47:25Z", 
    "summary": "The high volume of packets and packet rates of traffic on some router links\nmakes it exceedingly difficult for routers to examine every packet in order to\nkeep detailed statistics about the traffic which is traversing the router.\nSampling is commonly applied on routers in order to limit the load incurred by\nthe collection of information that the router has to undertake when evaluating\nflow information for monitoring purposes. The sampling process in nearly all\ncases is a deterministic process of choosing 1 in every N packets on a\nper-interface basis, and then forming the flow statistics based on the\ncollected sampled statistics. Even though this sampling may not be significant\nfor some statistics, such as packet rate, others can be severely distorted.\nHowever, it is important to consider the sampling techniques and their relative\naccuracy when applied to different traffic patterns. The main disadvantage of\nsampling is the loss of accuracy in the collected trace when compared to the\noriginal traffic stream. To date there has not been a detailed analysis of the\nimpact of sampling at a router in various traffic profiles and flow criteria.\nIn this paper, we assess the performance of the sampling process as used in\nNetFlow in detail, and we discuss some techniques for the compensation of loss\nof monitoring detail."
},{
    "category": "cs.DS", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0704.0788v1", 
    "title": "Optimal Synthesis of Multiple Algorithms", 
    "arxiv-id": "0704.0788v1", 
    "author": "Kerry M. Soileau", 
    "publish": "2007-04-05T19:47:54Z", 
    "summary": "In this paper we give a definition of \"algorithm,\" \"finite algorithm,\"\n\"equivalent algorithms,\" and what it means for a single algorithm to dominate a\nset of algorithms. We define a derived algorithm which may have a smaller mean\nexecution time than any of its component algorithms. We give an explicit\nexpression for the mean execution time (when it exists) of the derived\nalgorithm. We give several illustrative examples of derived algorithms with two\ncomponent algorithms. We include mean execution time solutions for\ntwo-algorithm processors whose joint density of execution times are of several\ngeneral forms. For the case in which the joint density for a two-algorithm\nprocessor is a step function, we give a maximum-likelihood estimation scheme\nwith which to analyze empirical processing time data."
},{
    "category": "cs.PF", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0704.0861v1", 
    "title": "Empirical analysis and statistical modeling of attack processes based on   honeypots", 
    "arxiv-id": "0704.0861v1", 
    "author": "Vincent Nicomette", 
    "publish": "2007-04-06T08:50:34Z", 
    "summary": "Honeypots are more and more used to collect data on malicious activities on\nthe Internet and to better understand the strategies and techniques used by\nattackers to compromise target systems. Analysis and modeling methodologies are\nneeded to support the characterization of attack processes based on the data\ncollected from the honeypots. This paper presents some empirical analyses based\non the data collected from the Leurr{\\'e}.com honeypot platforms deployed on\nthe Internet and presents some preliminary modeling studies aimed at fulfilling\nsuch objectives."
},{
    "category": "cs.PF", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0704.0865v1", 
    "title": "An architecture-based dependability modeling framework using AADL", 
    "arxiv-id": "0704.0865v1", 
    "author": "Mohamed Kaaniche", 
    "publish": "2007-04-06T09:33:06Z", 
    "summary": "For efficiency reasons, the software system designers' will is to use an\nintegrated set of methods and tools to describe specifications and designs, and\nalso to perform analyses such as dependability, schedulability and performance.\nAADL (Architecture Analysis and Design Language) has proved to be efficient for\nsoftware architecture modeling. In addition, AADL was designed to accommodate\nseveral types of analyses. This paper presents an iterative dependency-driven\napproach for dependability modeling using AADL. It is illustrated on a small\nexample. This approach is part of a complete framework that allows the\ngeneration of dependability analysis and evaluation models from AADL models to\nsupport the analysis of software and system architectures, in critical\napplication domains."
},{
    "category": "cs.NI", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0705.1939v1", 
    "title": "Towards Informative Statistical Flow Inversion", 
    "arxiv-id": "0705.1939v1", 
    "author": "Miguel Rio", 
    "publish": "2007-05-14T13:14:33Z", 
    "summary": "A problem which has recently attracted research attention is that of\nestimating the distribution of flow sizes in internet traffic. On high traffic\nlinks it is sometimes impossible to record every packet. Researchers have\napproached the problem of estimating flow lengths from sampled packet data in\ntwo separate ways. Firstly, different sampling methodologies can be tried to\nmore accurately measure the desired system parameters. One such method is the\nsample-and-hold method where, if a packet is sampled, all subsequent packets in\nthat flow are sampled. Secondly, statistical methods can be used to ``invert''\nthe sampled data and produce an estimate of flow lengths from a sample.\n  In this paper we propose, implement and test two variants on the\nsample-and-hold method. In addition we show how the sample-and-hold method can\nbe inverted to get an estimation of the genuine distribution of flow sizes.\nExperiments are carried out on real network traces to compare standard packet\nsampling with three variants of sample-and-hold. The methods are compared for\ntheir ability to reconstruct the genuine distribution of flow sizes in the\ntraffic."
},{
    "category": "cs.DC", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0705.2065v1", 
    "title": "Mean Field Models of Message Throughput in Dynamic Peer-to-Peer Systems", 
    "arxiv-id": "0705.2065v1", 
    "author": "Olga Ohrimenko", 
    "publish": "2007-05-15T01:42:44Z", 
    "summary": "The churn rate of a peer-to-peer system places direct limitations on the rate\nat which messages can be effectively communicated to a group of peers. These\nlimitations are independent of the topology and message transmission latency.\nIn this paper we consider a peer-to-peer network, based on the Engset model,\nwhere peers arrive and depart independently at random. We show how the arrival\nand departure rates directly limit the capacity for message streams to be\nbroadcast to all other peers, by deriving mean field models that accurately\ndescribe the system behavior. Our models cover the unit and more general k\nbuffer cases, i.e. where a peer can buffer at most k messages at any one time,\nand we give results for both single and multi-source message streams. We define\ncoverage rate as peer-messages per unit time, i.e. the rate at which a number\nof peers receive messages, and show that the coverage rate is limited by the\nchurn rate and buffer size. Our theory introduces an Instantaneous Message\nExchange (IME) model and provides a template for further analysis of more\ncomplicated systems. Using the IME model, and assuming random processes, we\nhave obtained very accurate equations of the system dynamics in a variety of\ninteresting cases, that allow us to tune a peer-to-peer system. It remains to\nbe seen if we can maintain this accuracy for general processes and when\napplying a non-instantaneous model."
},{
    "category": "cs.NI", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0705.2819v1", 
    "title": "An Autonomous Distributed Admission Control Scheme for IEEE 802.11 DCF", 
    "arxiv-id": "0705.2819v1", 
    "author": "Varsha Apte", 
    "publish": "2007-05-19T13:54:25Z", 
    "summary": "Admission control as a mechanism for providing QoS requires an accurate\ndescription of the requested flow as well as already admitted flows. Since\n802.11 WLAN capacity is shared between flows belonging to all stations,\nadmission control requires knowledge of all flows in the WLAN. Further,\nestimation of the load-dependent WLAN capacity through analytical model\nrequires inputs about channel data rate, payload size and the number of\nstations. These factors combined point to a centralized admission control\nwhereas for 802.11 DCF it is ideally performed in a distributed manner. The use\nof measurements from the channel avoids explicit inputs about the state of the\nchannel described above. BUFFET, a model based measurement-assisted distributed\nadmission control scheme for DCF proposed in this paper relies on measurements\nto derive model inputs and predict WLAN saturation, thereby maintaining average\ndelay within acceptable limits. Being measurement based, it adapts to a\ncombination of data rates and payload sizes, making it completely autonomous\nand distributed. Performance analysis using OPNET simulations suggests that\nBUFFET is able to ensure average delay under 7ms at a near-optimal throughput."
},{
    "category": "cs.PF", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0705.3015v1", 
    "title": "An Extensible Timing Infrastructure for Adaptive Large-scale   Applications", 
    "arxiv-id": "0705.3015v1", 
    "author": "Erik Schnetter", 
    "publish": "2007-05-21T19:00:25Z", 
    "summary": "Real-time access to accurate and reliable timing information is necessary to\nprofile scientific applications, and crucial as simulations become increasingly\ncomplex, adaptive, and large-scale. The Cactus Framework provides flexible and\nextensible capabilities for timing information through a well designed\ninfrastructure and timing API. Applications built with Cactus automatically\ngain access to built-in timers, such as gettimeofday and getrusage,\nsystem-specific hardware clocks, and high-level interfaces such as PAPI. We\ndescribe the Cactus timer interface, its motivation, and its implementation. We\nthen demonstrate how this timing information can be used by an example\nscientific application to profile itself, and to dynamically adapt itself to a\nchanging environment at run time."
},{
    "category": "cs.DS", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0706.2839v2", 
    "title": "Cache Analysis of Non-uniform Distribution Sorting Algorithms", 
    "arxiv-id": "0706.2839v2", 
    "author": "Rajeev Raman", 
    "publish": "2007-06-19T17:12:47Z", 
    "summary": "We analyse the average-case cache performance of distribution sorting\nalgorithms in the case when keys are independently but not necessarily\nuniformly distributed. The analysis is for both `in-place' and `out-of-place'\ndistribution sorting algorithms and is more accurate than the analysis\npresented in \\cite{RRESA00}. In particular, this new analysis yields tighter\nupper and lower bounds when the keys are drawn from a uniform distribution.\n  We use this analysis to tune the performance of the integer sorting algorithm\nMSB radix sort when it is used to sort independent uniform floating-point\nnumbers (floats). Our tuned MSB radix sort algorithm comfortably outperforms a\ncache-tuned implementations of bucketsort \\cite{RR99} and Quicksort when\nsorting uniform floats from $[0, 1)$."
},{
    "category": "cs.SE", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0706.3984v2", 
    "title": "A Comparison of Push and Pull Techniques for Ajax", 
    "arxiv-id": "0706.3984v2", 
    "author": "Arie van Deursen", 
    "publish": "2007-06-27T09:14:40Z", 
    "summary": "Ajax applications are designed to have high user interactivity and low\nuser-perceived latency. Real-time dynamic web data such as news headlines,\nstock tickers, and auction updates need to be propagated to the users as soon\nas possible. However, Ajax still suffers from the limitations of the Web's\nrequest/response architecture which prevents servers from pushing real-time\ndynamic web data. Such applications usually use a pull style to obtain the\nlatest updates, where the client actively requests the changes based on a\npredefined interval. It is possible to overcome this limitation by adopting a\npush style of interaction where the server broadcasts data when a change occurs\non the server side. Both these options have their own trade-offs. This paper\nexplores the fundamental limits of browser-based applications and analyzes push\nsolutions for Ajax technology. It also shows the results of an empirical study\ncomparing push and pull."
},{
    "category": "cs.DB", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0707.1644v1", 
    "title": "Fast and Simple Relational Processing of Uncertain Data", 
    "arxiv-id": "0707.1644v1", 
    "author": "Dan Olteanu", 
    "publish": "2007-07-11T15:13:39Z", 
    "summary": "This paper introduces U-relations, a succinct and purely relational\nrepresentation system for uncertain databases. U-relations support\nattribute-level uncertainty using vertical partitioning. If we consider\npositive relational algebra extended by an operation for computing possible\nanswers, a query on the logical level can be translated into, and evaluated as,\na single relational algebra query on the U-relation representation. The\ntranslation scheme essentially preserves the size of the query in terms of\nnumber of operations and, in particular, number of joins. Standard techniques\nemployed in off-the-shelf relational database management systems are effective\nfor optimizing and processing queries on U-relations. In our experiments we\nshow that query evaluation on U-relations scales to large amounts of data with\nhigh degrees of uncertainty."
},{
    "category": "cs.MS", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0708.3722v1", 
    "title": "Formally Verified Argument Reduction with a Fused-Multiply-Add", 
    "arxiv-id": "0708.3722v1", 
    "author": "Ren Cang Li", 
    "publish": "2007-08-28T07:15:08Z", 
    "summary": "Cody & Waite argument reduction technique works perfectly for reasonably\nlarge arguments but as the input grows there are no bit left to approximate the\nconstant with enough accuracy. Under mild assumptions, we show that the result\ncomputed with a fused-multiply-add provides a fully accurate result for many\npossible values of the input with a constant almost accurate to the full\nworking precision. We also present an algorithm for a fully accurate second\nreduction step to reach double full accuracy (all the significand bits of two\nnumbers are significant) even in the worst cases of argument reduction. Our\nwork recalls the common algorithms and presents proofs of correctness. All the\nproofs are formally verified using the Coq automatic proof checker."
},{
    "category": "cs.DC", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0709.1024v1", 
    "title": "Computational performance of a parallelized high-order spectral and   mortar element toolbox", 
    "arxiv-id": "0709.1024v1", 
    "author": "Michel O. Deville", 
    "publish": "2007-09-07T08:52:32Z", 
    "summary": "In this paper, a comprehensive performance review of a MPI-based high-order\nspectral and mortar element method C++ toolbox is presented. The focus is put\non the performance evaluation of several aspects with a particular emphasis on\nthe parallel efficiency. The performance evaluation is analyzed and compared to\npredictions given by a heuristic model, the so-called Gamma model. A\ntailor-made CFD computation benchmark case is introduced and used to carry out\nthis review, stressing the particular interest for commodity clusters.\nConclusions are drawn from this extensive series of analyses and modeling\nleading to specific recommendations concerning such toolbox development and\nparallel implementation."
},{
    "category": "cs.PF", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0710.0789v1", 
    "title": "Wireless Local Area Networks with Multiple-Packet Reception Capability", 
    "arxiv-id": "0710.0789v1", 
    "author": "Soung Chang Liew", 
    "publish": "2007-10-03T13:46:01Z", 
    "summary": "Thanks to its simplicity and cost efficiency, wireless local area network\n(WLAN) enjoys unique advantages in providing high-speed and low-cost wireless\nservices in hot spots and indoor environments. Traditional WLAN\nmedium-access-control (MAC) protocols assume that only one station can transmit\nat a time: simultaneous transmissions of more than one station causes the\ndestruction of all packets involved. By exploiting recent advances in PHY-layer\nmultiuser detection (MUD) techniques, it is possible for a receiver to receive\nmultiple packets simultaneously. This paper argues that such multipacket\nreception (MPR) capability can greatly enhance the capacity of future WLANs. In\naddition, it provides the MAC-layer and PHY-layer designs needed to achieve the\nimproved capacity. First, to demonstrate MUD/MPR as a powerful\ncapacity-enhancement technique, we prove a \"super-linearity\" result, which\nstates that the system throughput per unit cost increases as the MPR capability\nincreases. Second, we show that the commonly deployed binary exponential\nbackoff (BEB) algorithm in today's WLAN MAC may not be optimal in an MPR\nsystem, and that the optimal backoff factor increases with the MPR capability:\nthe number of packets that can be received simultaneously. Third, based on the\nabove insights, we design a joint MAC-PHY layer protocol for an IEEE\n802.11-like WLAN that incorporates advanced PHY-layer blind detection and MUD\ntechniques to implement MPR"
},{
    "category": "cs.DC", 
    "doi": "10.1063/1.2817968", 
    "link": "http://arxiv.org/pdf/0710.1455v1", 
    "title": "Superrecursive Features of Interactive Computation", 
    "arxiv-id": "0710.1455v1", 
    "author": "Mark Burgin", 
    "publish": "2007-10-08T01:56:20Z", 
    "summary": "Functioning and interaction of distributed devices and concurrent algorithms\nare analyzed in the context of the theory of algorithms. Our main concern here\nis how and under what conditions algorithmic interactive devices can be more\npowerful than the recursive models of computation, such as Turing machines.\nRealization of such a higher computing power makes these systems\nsuperrecursive. We find here five sources for superrecursiveness in\ninteraction. In addition, we prove that when all of these sources are excluded,\nthe algorithmic interactive system in question is able to perform only\nrecursive computations. These results provide computer scientists with\nnecessary and sufficient conditions for achieving superrecursiveness by\nalgorithmic interactive devices."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.osn.2006.08.001", 
    "link": "http://arxiv.org/pdf/0710.3916v1", 
    "title": "Optimized Design of Survivable MPLS over Optical Transport Networks.   Optical Switching and Networking", 
    "arxiv-id": "0710.3916v1", 
    "author": "Hisao Nakajima", 
    "publish": "2007-10-21T09:40:38Z", 
    "summary": "In this paper we study different options for the survivability implementation\nin MPLS over Optical Transport Networks in terms of network resource usage and\nconfiguration cost. We investigate two approaches to the survivability\ndeployment: single layer and multilayer survivability and present various\nmethods for spare capacity allocation (SCA) to reroute disrupted traffic. The\ncomparative analysis shows the influence of the traffic granularity on the\nsurvivability cost: for high bandwidth LSPs, close to the optical channel\ncapacity, the multilayer survivability outperforms the single layer one,\nwhereas for low bandwidth LSPs the single layer survivability is more\ncost-efficient. For the multilayer survivability we demonstrate that by mapping\nefficiently the spare capacity of the MPLS layer onto the resources of the\noptical layer one can achieve up to 22% savings in the total configuration cost\nand up to 37% in the optical layer cost. Further savings (up to 9 %) in the\nwavelength use can be obtained with the integrated approach to network\nconfiguration over the sequential one, however, at the increase in the\noptimization problem complexity. These results are based on a cost model with\nactual technology pricing and were obtained for networks targeted to a\nnationwide coverage."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.osn.2006.08.001", 
    "link": "http://arxiv.org/pdf/0710.3955v1", 
    "title": "On the Behavior of the Distributed Coordination Function of IEEE 802.11   with Multirate Capability under General Transmission Conditions", 
    "arxiv-id": "0710.3955v1", 
    "author": "M. Mondin", 
    "publish": "2007-10-21T22:59:27Z", 
    "summary": "The aim of this paper is threefold. First, it presents a multi-dimensional\nMarkovian state transition model characterizing the behavior of the IEEE 802.11\nprotocol at the Medium Access Control layer which accounts for packet\ntransmission failures due to channel errors modeling both saturated and\nnon-saturated traffic conditions. Second, it provides a throughput analysis of\nthe IEEE 802.11 protocol at the data link layer in both saturated and\nnon-saturated traffic conditions taking into account the impact of both the\nphysical propagation channel and multirate transmission in Rayleigh fading\nenvironment. The general traffic model assumed is M/M/1/K. Finally, it shows\nthat the behavior of the throughput in non-saturated traffic conditions is a\nlinear combination of two system parameters; the payload size and the packet\nrates, $\\lambda^{(s)}$, of each contending station. The validity interval of\nthe proposed model is also derived.\n  Simulation results closely match the theoretical derivations, confirming the\neffectiveness of the proposed models."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSAC.2007.070608", 
    "link": "http://arxiv.org/pdf/0710.4261v1", 
    "title": "Survivable MPLS Over Optical Transport Networks: Cost and Resource Usage   Analysis", 
    "arxiv-id": "0710.4261v1", 
    "author": "Hisao Nakajima", 
    "publish": "2007-10-23T11:25:44Z", 
    "summary": "In this paper we study different options for the survivability implementation\nin MPLS over Optical Transport Networks (OTN) in terms of network resource\nusage and configuration cost. We investigate two approaches to the\nsurvivability deployment: single layer and multilayer survivability and present\nvarious methods for spare capacity allocation (SCA) to reroute disrupted\ntraffic. The comparative analysis shows the influence of the offered traffic\ngranularity and the physical network structure on the survivability cost: for\nhigh bandwidth LSPs, close to the optical channel capacity, the multilayer\nsurvivability outperforms the single layer one, whereas for low bandwidth LSPs\nthe single layer survivability is more cost-efficient. On the other hand,\nsparse networks of low connectivity parameter use more wavelengths for optical\npath routing and increase the configuration cost, as compared with dense\nnetworks. We demonstrate that by mapping efficiently the spare capacity of the\nMPLS layer onto the resources of the optical layer one can achieve up to 22%\nsavings in the total configuration cost and up to 37% in the optical layer\ncost. Further savings (up to 9 %) in the wavelength use can be obtained with\nthe integrated approach to network configuration over the sequential one,\nhowever, at the increase in the optimization problem complexity. These results\nare based on a cost model with different cost variations, and were obtained for\nnetworks targeted to a nationwide coverage."
},{
    "category": "cs.AR", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0710.4643v1", 
    "title": "Generic Pipelined Processor Modeling and High Performance Cycle-Accurate   Simulator Generation", 
    "arxiv-id": "0710.4643v1", 
    "author": "Nikil Dutt", 
    "publish": "2007-10-25T08:14:40Z", 
    "summary": "Detailed modeling of processors and high performance cycle-accurate\nsimulators are essential for today's hardware and software design. These\nproblems are challenging enough by themselves and have seen many previous\nresearch efforts. Addressing both simultaneously is even more challenging, with\nmany existing approaches focusing on one over another. In this paper, we\npropose the Reduced Colored Petri Net (RCPN) model that has two advantages:\nfirst, it offers a very simple and intuitive way of modeling pipelined\nprocessors; second, it can generate high performance cycle-accurate simulators.\nRCPN benefits from all the useful features of Colored Petri Nets without\nsuffering from their exponential growth in complexity. RCPN processor models\nare very intuitive since they are a mirror image of the processor pipeline\nblock diagram. Furthermore, in our experiments on the generated cycle-accurate\nsimulators for XScale and StrongArm processor models, we achieved an order of\nmagnitude (~15 times) speedup over the popular SimpleScalar ARM simulator."
},{
    "category": "cs.PF", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0712.0811v2", 
    "title": "The Fast Fibonacci Decompression Algorithm", 
    "arxiv-id": "0712.0811v2", 
    "author": "E. El-Qawasmeh", 
    "publish": "2007-12-05T19:55:16Z", 
    "summary": "Data compression has been widely applied in many data processing areas.\nCompression methods use variable-size codes with the shorter codes assigned to\nsymbols or groups of symbols that appear in the data frequently. Fibonacci\ncoding, as a representative of these codes, is used for compressing small\nnumbers. Time consumption of a decompression algorithm is not usually as\nimportant as the time of a compression algorithm. However, efficiency of the\ndecompression may be a critical issue in some cases. For example, a real-time\ncompression of tree data structures follows this issue. Tree's pages are\ndecompressed during every reading from a secondary storage into the main\nmemory. In this case, the efficiency of a decompression algorithm is extremely\nimportant. We have developed a Fast Fibonacci decompression for this purpose.\nOur approach is up to $3.5\\times$ faster than the original implementation."
},{
    "category": "cs.NI", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0712.1854v1", 
    "title": "Back-of-the-Envelope Computation of Throughput Distributions in CSMA   Wireless Networks", 
    "arxiv-id": "0712.1854v1", 
    "author": "B. Wong", 
    "publish": "2007-12-12T01:41:54Z", 
    "summary": "This work started out with our accidental discovery of a pattern of\nthroughput distributions among links in IEEE 802.11 networks from experimental\nresults. This pattern gives rise to an easy computation method, which we term\nback-of-the-envelop (BoE) computation, because for many network configurations,\nvery accurate results can be obtained within minutes, if not seconds, by simple\nhand computation. BoE beats prior methods in terms of both speed and accuracy.\nWhile the computation procedure of BoE is simple, explaining why it works is by\nno means trivial. Indeed the majority of our investigative efforts have been\ndevoted to the construction of a theory to explain BoE. This paper models an\nideal CSMA network as a set of interacting on-off telegraph processes. In\ndeveloping the theory, we discovered a number of analytical techniques and\nobservations that have eluded prior research, such as that the carrier-sensing\ninteractions among links in an ideal CSMA network result in a system state\nevolution that is time-reversible; and that the probability distribution of the\nsystem state is insensitive to the distributions of the \"on\" and \"off\"\ndurations given their means, and is a Markov random field. We believe these\ntheoretical frameworks are useful not just for explaining BoE, but could also\nbe a foundation for a fundamental understanding of how links in CSMA networks\ninteract. Last but not least, because of their basic nature, we surmise that\nsome of the techniques and results developed in this paper may be applicable to\nnot just CSMA networks, but also to other physical and engineering systems\nconsisting of entities interacting with each other in time and space."
},{
    "category": "cs.DC", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0712.2302v2", 
    "title": "Data access optimizations for highly threaded multi-core CPUs with   multiple memory controllers", 
    "arxiv-id": "0712.2302v2", 
    "author": "Gerhard Wellein", 
    "publish": "2007-12-14T08:14:20Z", 
    "summary": "Processor and system architectures that feature multiple memory controllers\nare prone to show bottlenecks and erratic performance numbers on codes with\nregular access patterns. Although such effects are well known in the form of\ncache thrashing and aliasing conflicts, they become more severe when memory\naccess is involved. Using the new Sun UltraSPARC T2 processor as a prototypical\nmulti-core design, we analyze performance patterns in low-level and application\nbenchmarks and show ways to circumvent bottlenecks by careful data layout and\npadding."
},{
    "category": "cs.DC", 
    "doi": "10.1109/DATE.2005.166", 
    "link": "http://arxiv.org/pdf/0712.3389v1", 
    "title": "RZBENCH: Performance evaluation of current HPC architectures using   low-level and application benchmarks", 
    "arxiv-id": "0712.3389v1", 
    "author": "Gerhard Wellein", 
    "publish": "2007-12-20T12:15:26Z", 
    "summary": "RZBENCH is a benchmark suite that was specifically developed to reflect the\nrequirements of scientific supercomputer users at the University of\nErlangen-Nuremberg (FAU). It comprises a number of application and low-level\ncodes under a common build infrastructure that fosters maintainability and\nexpandability. This paper reviews the structure of the suite and briefly\nintroduces the most relevant benchmarks. In addition, some widely known\nstandard benchmark codes are reviewed in order to emphasize the need for a\ncritical review of often-cited performance results. Benchmark data is presented\nfor the HLRB-II at LRZ Munich and a local InfiniBand Woodcrest cluster as well\nas two uncommon system architectures: A bandwidth-optimized InfiniBand cluster\nbased on single socket nodes (\"Port Townsend\") and an early version of Sun's\nhighly threaded T2 architecture (\"Niagara 2\")."
},{
    "category": "cs.GT", 
    "doi": "10.1016/j.peva.2008.07.001", 
    "link": "http://arxiv.org/pdf/0712.3870v3", 
    "title": "Substitute Valuations: Generation and Structure", 
    "arxiv-id": "0712.3870v3", 
    "author": "Bruce Hajek", 
    "publish": "2007-12-22T16:52:39Z", 
    "summary": "Substitute valuations (in some contexts called gross substitute valuations)\nare prominent in combinatorial auction theory. An algorithm is given in this\npaper for generating a substitute valuation through Monte Carlo simulation. In\naddition, the geometry of the set of all substitute valuations for a fixed\nnumber of goods K is investigated. The set consists of a union of polyhedrons,\nand the maximal polyhedrons are identified for K=4. It is shown that the\nmaximum dimension of the maximal polyhedrons increases with K nearly as fast as\ntwo to the power K. Consequently, under broad conditions, if a combinatorial\nalgorithm can present an arbitrary substitute valuation given a list of input\nnumbers, the list must grow nearly as fast as two to the power K."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.peva.2008.07.001", 
    "link": "http://arxiv.org/pdf/0801.0455v1", 
    "title": "A System Theoretic Approach to Bandwidth Estimation", 
    "arxiv-id": "0801.0455v1", 
    "author": "Shahrokh Valaee", 
    "publish": "2008-01-03T00:11:26Z", 
    "summary": "It is shown that bandwidth estimation in packet networks can be viewed in\nterms of min-plus linear system theory. The available bandwidth of a link or\ncomplete path is expressed in terms of a {\\em service curve}, which is a\nfunction that appears in the network calculus to express the service available\nto a traffic flow. The service curve is estimated based on measurements of a\nsequence of probing packets or passive measurements of a sample path of\narrivals. It is shown that existing bandwidth estimation methods can be derived\nin the min-plus algebra of the network calculus, thus providing further\nmathematical justification for these methods. Principal difficulties of\nestimating available bandwidth from measurement of network probes are related\nto potential non-linearities of the underlying network. When networks are\nviewed as systems that operate either in a linear or in a non-linear regime, it\nis argued that probing schemes extract the most information at a point when the\nnetwork crosses from a linear to a non-linear regime. Experiments on the Emulab\ntestbed at the University of Utah evaluate the robustness of the system\ntheoretic interpretation of networks in practice. Multi-node experiments\nevaluate how well the convolution operation of the min-plus algebra provides\nestimates for the available bandwidth of a path from estimates of individual\nlinks."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0801.4592v2", 
    "title": "Understanding the Paradoxical Effects of Power Control on the Capacity   of Wireless Networks", 
    "arxiv-id": "0801.4592v2", 
    "author": "Dah-Ming Chiu", 
    "publish": "2008-01-30T02:51:11Z", 
    "summary": "Recent works show conflicting results: network capacity may increase or\ndecrease with higher transmission power under different scenarios. In this\nwork, we want to understand this paradox. Specifically, we address the\nfollowing questions: (1)Theoretically, should we increase or decrease\ntransmission power to maximize network capacity? (2) Theoretically, how much\nnetwork capacity gain can we achieve by power control? (3) Under realistic\nsituations, how do power control, link scheduling and routing interact with\neach other? Under which scenarios can we expect a large capacity gain by using\nhigher transmission power? To answer these questions, firstly, we prove that\nthe optimal network capacity is a non-decreasing function of transmission\npower. Secondly, we prove that the optimal network capacity can be increased\nunlimitedly by higher transmission power in some network configurations.\nHowever, when nodes are distributed uniformly, the gain of optimal network\ncapacity by higher transmission power is upper-bounded by a positive constant.\nThirdly, we discuss why network capacity in practice may increase or decrease\nwith higher transmission power under different scenarios using carrier sensing\nand the minimum hop-count routing. Extensive simulations are carried out to\nverify our analysis."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0802.1176v2", 
    "title": "Note sur les temps de service r\u00e9siduels dans les syst\u00e8mes type M/G/c", 
    "arxiv-id": "0802.1176v2", 
    "author": "Alexandre Brandwajn", 
    "publish": "2008-02-08T16:40:26Z", 
    "summary": "Approximations for the mean performance indices for the M/G/c queue rely on\nthe approximate computation of the probability that an arriving request has to\nwait for service and of the minimum of residual service times if all servers\nare found busy. Using numerical examples, we investigate properties of these\ntwo quantities. In particular, we show that the minimum of residual service\ntimes depends on higher order properties, beyond the first two moments, of the\nservice time distribution. Improved knowledge of the properties of the two\nquantities studied in this paper provides insight into avenues for improving\nthe accuracy of approximations for the M/G/c queue."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0802.2543v2", 
    "title": "Self-* overload control for distributed web systems", 
    "arxiv-id": "0802.2543v2", 
    "author": "Simone Silvestri", 
    "publish": "2008-02-18T21:18:17Z", 
    "summary": "Unexpected increases in demand and most of all flash crowds are considered\nthe bane of every web application as they may cause intolerable delays or even\nservice unavailability. Proper quality of service policies must guarantee rapid\nreactivity and responsiveness even in such critical situations. Previous\nsolutions fail to meet common performance requirements when the system has to\nface sudden and unpredictable surges of traffic. Indeed they often rely on a\nproper setting of key parameters which requires laborious manual tuning,\npreventing a fast adaptation of the control policies. We contribute an original\nSelf-* Overload Control (SOC) policy. This allows the system to self-configure\na dynamic constraint on the rate of admitted sessions in order to respect\nservice level agreements and maximize the resource utilization at the same\ntime. Our policy does not require any prior information on the incoming traffic\nor manual configuration of key parameters. We ran extensive simulations under a\nwide range of operating conditions, showing that SOC rapidly adapts to time\nvarying traffic and self-optimizes the resource utilization. It admits as many\nnew sessions as possible in observance of the agreements, even under intense\nworkload variations. We compared our algorithm to previously proposed\napproaches highlighting a more stable behavior and a better performance."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0802.3554v3", 
    "title": "Data Traffic Dynamics and Saturation on a Single Link", 
    "arxiv-id": "0802.3554v3", 
    "author": "Reginald D. Smith", 
    "publish": "2008-02-25T03:23:33Z", 
    "summary": "The dynamics of User Datagram Protocol (UDP) traffic over Ethernet between\ntwo computers are analyzed using nonlinear dynamics which shows that there are\ntwo clear regimes in the data flow: free flow and saturated. The two most\nimportant variables affecting this are the packet size and packet flow rate.\nHowever, this transition is due to a transcritical bifurcation rather than\nphase transition in models such as in vehicle traffic or theorized large-scale\ncomputer network congestion. It is hoped this model will help lay the\ngroundwork for further research on the dynamics of networks, especially\ncomputer networks."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0803.1723v2", 
    "title": "Estimation of available bandwidth and measurement infrastructure for   Russian segment of Internet", 
    "arxiv-id": "0803.1723v2", 
    "author": "A. M. Sukhov", 
    "publish": "2008-03-12T08:57:50Z", 
    "summary": "In paper the method for estimation of available bandwidth is supposed which\ndoes not demand the advanced utilities. Our method is based on the measurement\nof network delay $D$ for packets of different sizes $W$. The simple expression\nfor available bandwidth $B_{av} =(W_2-W_1)/(D_2-D_1)$ is substantiated. For the\nexperimental testing the measurement infrastructure for Russian segment of\nInternet was installed in framework of RFBR grant 06-07-89074."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0804.3814v1", 
    "title": "Link Enhancer for Vehicular Wireless ATM Communications", 
    "arxiv-id": "0804.3814v1", 
    "author": "Amrendra Kumar", 
    "publish": "2008-04-24T18:54:11Z", 
    "summary": "Majority of the applications used in defense are voice, video and data\noriented and has strict QoS requirements. One of the technologies that enabled\nthis is Asynchronous Transfer Mode (ATM) networking. Traditional ATM networks\nare wired networks. But Tactical networks are meant to be mobile and this\nnecessitates the use of radio relays for Vehicle-to-Infrastructure (V2I) and\nVehicle-to-Vehicle (V2V) communications. ATM networks assume a physical link\nlayer BER of 10^-9 or better because of the availability of reliable media like\noptical fiber links. But this assumption is no longer valid when ATM switches\nare connected through radio relay where error rates are in the rage of 10^-3.\nThis paper presents the architecture of a Link Enhancer meant to improve the\nBit Error Rate of the Wireless links used for V2I and V2V communications from 1\nin 10^4 to 1 in 10^8"
},{
    "category": "cs.PF", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0805.1968v1", 
    "title": "Heavy-Tailed Limits for Medium Size Jobs and Comparison Scheduling", 
    "arxiv-id": "0805.1968v1", 
    "author": "Jian Tan", 
    "publish": "2008-05-14T05:00:12Z", 
    "summary": "We study the conditional sojourn time distributions of processor sharing\n(PS), foreground background processor sharing (FBPS) and shortest remaining\nprocessing time first (SRPT) scheduling disciplines on an event where the job\nsize of a customer arriving in stationarity is smaller than exactly k>=0 out of\nthe preceding m>=k arrivals. Then, conditioning on the preceding event, the\nsojourn time distribution of this newly arriving customer behaves\nasymptotically the same as if the customer were served in isolation with a\nserver of rate (1-\\rho)/(k+1) for PS/FBPS, and (1-\\rho) for SRPT, respectively,\nwhere \\rho is the traffic intensity. Hence, the introduced notion of\nconditional limits allows us to distinguish the asymptotic performance of the\nstudied schedulers by showing that SRPT exhibits considerably better asymptotic\nbehavior for relatively smaller jobs than PS/FBPS.\n  Inspired by the preceding results, we propose an approximation to the SRPT\ndiscipline based on a novel adaptive job grouping mechanism that uses relative\nsize comparison of a newly arriving job to the preceding m arrivals.\nSpecifically, if the newly arriving job is smaller than k and larger than m-k\nof the previous m jobs, it is routed into class k. Then, the classes of smaller\njobs are served with higher priorities using the static priority scheduling.\nThe good performance of this mechanism, even for a small number of classes m+1,\nis demonstrated using the asymptotic queueing analysis under the heavy-tailed\njob requirements. We also discuss refinements of the comparison grouping\nmechanism that improve the accuracy of job classification at the expense of a\nsmall additional complexity."
},{
    "category": "cs.LO", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0806.1139v1", 
    "title": "Significant Diagnostic Counterexamples in Probabilistic Model Checking", 
    "arxiv-id": "0806.1139v1", 
    "author": "Peter van Rossum", 
    "publish": "2008-06-06T13:09:49Z", 
    "summary": "This paper presents a novel technique for counterexample generation in\nprobabilistic model checking of Markov Chains and Markov Decision Processes.\n(Finite) paths in counterexamples are grouped together in witnesses that are\nlikely to provide similar debugging information to the user. We list five\nproperties that witnesses should satisfy in order to be useful as debugging\naid: similarity, accuracy, originality, significance, and finiteness. Our\nwitnesses contain paths that behave similar outside strongly connected\ncomponents.\n  This papers shows how to compute these witnesses by reducing the problem of\ngenerating counterexamples for general properties over Markov Decision\nProcesses, in several steps, to the easy problem of generating counterexamples\nfor reachability properties over acyclic Markov Chains."
},{
    "category": "cs.DB", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0806.4627v2", 
    "title": "SP2Bench: A SPARQL Performance Benchmark", 
    "arxiv-id": "0806.4627v2", 
    "author": "Christoph Pinkel", 
    "publish": "2008-06-30T15:31:26Z", 
    "summary": "Recently, the SPARQL query language for RDF has reached the W3C\nrecommendation status. In response to this emerging standard, the database\ncommunity is currently exploring efficient storage techniques for RDF data and\nevaluation strategies for SPARQL queries. A meaningful analysis and comparison\nof these approaches necessitates a comprehensive and universal benchmark\nplatform. To this end, we have developed SP^2Bench, a publicly available,\nlanguage-specific SPARQL performance benchmark. SP^2Bench is settled in the\nDBLP scenario and comprises both a data generator for creating arbitrarily\nlarge DBLP-like documents and a set of carefully designed benchmark queries.\nThe generated documents mirror key characteristics and social-world\ndistributions encountered in the original DBLP data set, while the queries\nimplement meaningful requests on top of this data, covering a variety of SPARQL\noperator constellations and RDF access patterns. As a proof of concept, we\napply SP^2Bench to existing engines and discuss their strengths and weaknesses\nthat follow immediately from the benchmark results."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0807.1160v1", 
    "title": "Session Initiation Protocol (SIP) Server Overload Control: Design and   Evaluation", 
    "arxiv-id": "0807.1160v1", 
    "author": "Erich Nahum", 
    "publish": "2008-07-08T03:23:41Z", 
    "summary": "A Session Initiation Protocol (SIP) server may be overloaded by\nemergency-induced call volume, ``American Idol'' style flash crowd effects or\ndenial of service attacks. The SIP server overload problem is interesting\nespecially because the costs of serving or rejecting a SIP session can be\nsimilar. For this reason, the built-in SIP overload control mechanism based on\ngenerating rejection messages cannot prevent the server from entering\ncongestion collapse under heavy load. The SIP overload problem calls for a\npushback control solution in which the potentially overloaded receiving server\nmay notify its upstream sending servers to have them send only the amount of\nload within the receiving server's processing capacity. The pushback framework\ncan be achieved by either a rate-based feedback or a window-based feedback. The\ncenterpiece of the feedback mechanism is the algorithm used to generate load\nregulation information. We propose three new window-based feedback algorithms\nand evaluate them together with two existing rate-based feedback algorithms. We\ncompare the different algorithms in terms of the number of tuning parameters\nand performance under both steady and variable load. Furthermore, we identify\ntwo categories of fairness requirements for SIP overload control, namely,\nuser-centric and provider-centric fairness. With the introduction of a new\ndouble-feed SIP overload control architecture, we show how the algorithms can\nmeet those fairness criteria."
},{
    "category": "cs.PF", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0807.1162v1", 
    "title": "Measurement and Evaluation of ENUM Server Performance", 
    "arxiv-id": "0807.1162v1", 
    "author": "Henning Schulzrinne", 
    "publish": "2008-07-08T03:51:17Z", 
    "summary": "ENUM is a DNS-based protocol standard for mapping E.164 telephone numbers to\nInternet Uniform Resource Identifiers (URIs). It places unique requirements on\nthe existing DNS infrastructure, such as data scalability, query throughput,\nresponse time, and database update rates. This paper measures and evaluates the\nperformance of existing name server implementation as ENUM servers. We compared\nPowerDNS (PDNS), BIND and Navitas. Results show that BIND is not suitable for\nENUM due to its poor scaling property. Both PDNS and Navitas can serve ENUM.\nHowever, Navitas turns out to be highly optimized and clearly outperforms PDNS\nin all aspects we have tested. We also instrumented the PDNS server to identify\nits performance bottleneck and investigated ways to improve it."
},{
    "category": "cs.PF", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0807.1228v1", 
    "title": "Restricted Mobility Improves Delay-Throughput Trade-offs in Mobile   Ad-Hoc Networks", 
    "arxiv-id": "0807.1228v1", 
    "author": "Emilio Leonardi", 
    "publish": "2008-07-08T13:04:05Z", 
    "summary": "In this paper, we analyze asymptotic delay-throughput trade-offs in mobile\nad-hoc networks comprising heterogeneous nodes with restricted mobility. We\nshow that node spatial heterogeneity has the ability to drastically improve\nupon existing scaling laws established under the assumption that nodes are\nidentical and uniformly visit the entire network area. In particular, we\nconsider the situation in which each node moves around its own home-point\naccording to a restricted mobility process which results into a spatial\nstationary distribution that decays as a power law of exponent delta with the\ndistance from the home-point. For such restricted mobility model, we propose a\nnovel class of scheduling and routing schemes, which significantly outperforms\nall delay-throughput results previously obtained in the case of identical\nnodes. In particular, for delta = 2 it is possible to achieve almost constant\ndelay and almost constant per-node throughput (except for a poly-logarithmic\nfactor) as the number of nodes increases, even without resorting to\nsophisticated coding or signal processing techniques."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0808.1062v1", 
    "title": "Optimization of Location Management for PCS Networks with CTRW Mobility   Model", 
    "arxiv-id": "0808.1062v1", 
    "author": "Soung C. Liew", 
    "publish": "2008-08-07T16:32:51Z", 
    "summary": "This paper considers the design of the optimal locationupdate area (LA) of\nthe distance-based scheme for personal communication service (PCS) networks. We\nfocus on the optimization of two design parameters associated with the LA: 1)\ninitial position upon LA update; 2) distance threshold for triggering of LA\nupdate. Based on the popular continuous-time random walk (CTRW) mobility model,\nwe propose a novel analytical framework that uses a diffusion equation to\nminimize the location management cost. In this framework, a number of\nmeasurable physical parameters, such as length of road section, angle between\nroad sections, and road section crossing time, can be integrated into the\nsystem design. This framework allows us to easily evaluate the total cost under\ngeneral call arrival distributions and LA of different shapes. For the\nparticular case of circular LA and small Poisson call-arrival rate, we prove\nthe following: (1) When the drift is weak, the optimal initial position\napproaches the center of the LA; when the drift is strong, it approaches the\nboundary of the LA. (2) Comparing the optimal initial-position and\ncenter-initial-position solutions (which is assumed in most prior work), when\nthe drift is weak, the optimal distance threshold and the minimum total cost\nare roughly equal; when the drift is strong, the optimal distance threshold in\nthe later is about 1.260 times that in the former, and the minimum total cost\nin the later is about 1.587 times that in the former. That is, optimizing on\ninitial position, which previous work did not consider, has the potential of\nreducing the cost measure by 37%."
},{
    "category": "cs.PF", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0808.1431v2", 
    "title": "A General Theory of Computational Scalability Based on Rational   Functions", 
    "arxiv-id": "0808.1431v2", 
    "author": "Neil J. Gunther", 
    "publish": "2008-08-11T00:06:16Z", 
    "summary": "The universal scalability law of computational capacity is a rational\nfunction C_p = P(p)/Q(p) with P(p) a linear polynomial and Q(p) a second-degree\npolynomial in the number of physical processors p, that has been long used for\nstatistical modeling and prediction of computer system performance. We prove\nthat C_p is equivalent to the synchronous throughput bound for a\nmachine-repairman with state-dependent service rate. Simpler rational\nfunctions, such as Amdahl's law and Gustafson speedup, are corollaries of this\nqueue-theoretic bound. C_p is further shown to be both necessary and sufficient\nfor modeling all practical characteristics of computational scalability."
},{
    "category": "cs.NI", 
    "doi": "10.1109/T-WC.2009.080142", 
    "link": "http://arxiv.org/pdf/0808.3747v3", 
    "title": "Forward Correction and Fountain codes in Delay Tolerant Networks", 
    "arxiv-id": "0808.3747v3", 
    "author": "Francesco De Pellegrini", 
    "publish": "2008-08-27T17:33:40Z", 
    "summary": "Delay tolerant Ad-hoc Networks make use of mobility of relay nodes to\ncompensate for lack of permanent connectivity and thus enable communication\nbetween nodes that are out of range of each other. To decrease delivery delay,\nthe information that needs to be delivered is replicated in the network. Our\nobjective in this paper is to study replication mechanisms that include coding\nin order to improve the probability of successful delivery within a given time\nlimit. We propose an analytical approach that allows to quantify tradeoffs\nbetween resources and performance measures (energy and delay). We study the\neffect of coding on the performance of the network while optimizing parameters\nthat govern routing. Our results, based on fluid approximations, are compared\nto simulations which validate the model"
},{
    "category": "cs.NI", 
    "doi": "10.1109/INFCOM.2009.5062022", 
    "link": "http://arxiv.org/pdf/0808.3937v1", 
    "title": "Understanding Fairness and its Impact on Quality of Service in IEEE   802.11", 
    "arxiv-id": "0808.3937v1", 
    "author": "Markus Fidler", 
    "publish": "2008-08-28T15:35:10Z", 
    "summary": "The Distributed Coordination Function (DCF) aims at fair and efficient medium\naccess in IEEE 802.11. In face of its success, it is remarkable that there is\nlittle consensus on the actual degree of fairness achieved, particularly\nbearing its impact on quality of service in mind. In this paper we provide an\naccurate model for the fairness of the DCF. Given M greedy stations we assume\nfairness if a tagged station contributes a share of 1/M to the overall number\nof packets transmitted. We derive the probability distribution of fairness\ndeviations and support our analytical results by an extensive set of\nmeasurements. We find a closed-form expression for the improvement of long-term\nover short-term fairness. Regarding the random countdown values we quantify the\nsignificance of their distribution whereas we discover that fairness is largely\ninsensitive to the distribution parameters. Based on our findings we view the\nDCF as emulating an ideal fair queuing system to quantify the deviations from a\nfair rate allocation. We deduce a stochastic service curve model for the DCF to\npredict packet delays in IEEE 802.11. We show how a station can estimate its\nfair bandwidth share from passive measurements of its traffic arrivals and\ndepartures."
},{
    "category": "cs.PF", 
    "doi": "10.1109/INFCOM.2009.5062022", 
    "link": "http://arxiv.org/pdf/0809.2532v1", 
    "title": "Multidimensional Visualization of Oracle Performance Using Barry007", 
    "arxiv-id": "0809.2532v1", 
    "author": "Neil J. Gunther", 
    "publish": "2008-09-15T14:11:34Z", 
    "summary": "Most generic performance tools display only system-level performance data\nusing 2-dimensional plots or diagrams and this limits the informational detail\nthat can be displayed. Moreover, a modern relational database system, like\nOracle, can concurrently serve thousands of client processes with different\nworkload characteristics, so that generic performance-data displays inevitably\nhide important information. Drawing on our previous work, this paper\ndemonstrates the application of Barry007 multidimensional visualization to the\nanalysis of Oracle end-user, session-level, performance data, showing both\ncollective trends and individual performance anomalies."
},{
    "category": "cs.PF", 
    "doi": "10.1109/INFCOM.2009.5062022", 
    "link": "http://arxiv.org/pdf/0809.2541v1", 
    "title": "Getting in the Zone for Successful Scalability", 
    "arxiv-id": "0809.2541v1", 
    "author": "Neil J. Gunther", 
    "publish": "2008-09-15T14:51:04Z", 
    "summary": "The universal scalability law (USL) is an analytic model used to quantify\napplication scaling. It is universal because it subsumes Amdahl's law and\nGustafson linearized scaling as special cases. Using simulation, we show: (i)\nthat the USL is equivalent to synchronous queueing in a load-dependent machine\nrepairman model and (ii) how USL, Amdahl's law, and Gustafson scaling can be\nregarded as boundaries defining three scalability zones. Typical throughput\nmeasurements lie across all three zones. Simulation scenarios provide deeper\ninsight into queueing effects and thus provide a clearer indication of which\napplication features should be tuned to get into the optimal performance zone."
},{
    "category": "cs.PF", 
    "doi": "10.1109/INFCOM.2009.5062022", 
    "link": "http://arxiv.org/pdf/0810.0135v1", 
    "title": "Occupancy distributions of homogeneous queueing systems under   opportunistic scheduling", 
    "arxiv-id": "0810.0135v1", 
    "author": "Maxim Dashouk", 
    "publish": "2008-10-01T15:02:16Z", 
    "summary": "We analyze opportunistic schemes for transmission scheduling from one of $n$\nhomogeneous queues whose channel states fluctuate independently. Considered\nschemes consist of the LCQ policy, which transmits from a longest connected\nqueue in the entire system, and its low-complexity variants that transmit from\na longest queue within a randomly chosen subset of connected queues. A\nMarkovian model is studied where mean packet transmission time is $n^{-1}$ and\npacket arrival rate is $\\lambda<1$ per queue. Transient and equilibrium\ndistributions of queue occupancies are obtained in the limit as the system size\n$n$ tends to infinity."
},{
    "category": "cs.PF", 
    "doi": "10.1109/INFCOM.2009.5062022", 
    "link": "http://arxiv.org/pdf/0810.0394v1", 
    "title": "Mobility Management Framework", 
    "arxiv-id": "0810.0394v1", 
    "author": "Sandor Imre", 
    "publish": "2008-10-02T11:44:47Z", 
    "summary": "This paper investigates mobility management strategies from the point of view\nof their need of signalling and processing resources on the backbone network\nand load on the air interface. A method is proposed to model the serving\nnetwork and mobile node mobility in order to be able to compare the different\ntypes of mobility management algorithms. To obtain a good description of the\nnetwork we calculate descriptive parameters from given topologies. Most\nmobility approaches derived from existing protocols are analyzed and their\nperformances are numerically compared in various network and mobility\nscenarios. We developed a mobility management framework that is able to give\ngeneral designing guidelines for the next generation mobility managements on\ngiven network, technology and mobility properties. With our model an operator\ncan design the network and tune the parameters to obtain the optimal\nimplementation of course revising existing systems is also possible. We present\na vertical handover decision method as a special application of our model\nframework."
},{
    "category": "cs.NI", 
    "doi": "10.1109/INFCOM.2009.5062022", 
    "link": "http://arxiv.org/pdf/0811.2596v2", 
    "title": "An Enhanced Mathematical Model for Performance Evaluation of Optical   Burst Switched Networks", 
    "arxiv-id": "0811.2596v2", 
    "author": "Hossam M. H. Shalaby", 
    "publish": "2008-11-16T19:10:43Z", 
    "summary": "This paper has been withdrawn by the authors."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0811.3387v2", 
    "title": "Broadcasting in Prefix Space: P2P Data Dissemination with Predictable   Performance", 
    "arxiv-id": "0811.3387v2", 
    "author": "Georg Wittenburg", 
    "publish": "2008-11-20T17:56:17Z", 
    "summary": "A broadcast mode may augment peer-to-peer overlay networks with an efficient,\nscalable data replication function, but may also give rise to a virtual link\nlayer in VPN-type solutions. We introduce a simple broadcasting mechanism that\noperates in the prefix space of distributed hash tables without signaling. This\npaper concentrates on the performance analysis of the prefix flooding scheme.\nStarting from simple models of recursive $k$-ary trees, we analytically derive\ndistributions of hop counts and the replication load. Extensive simulation\nresults are presented further on, based on an implementation within the OverSim\nframework. Comparisons are drawn to Scribe, taken as a general reference model\nfor group communication according to the shared, rendezvous-point-centered\ndistribution paradigm. The prefix flooding scheme thereby confirmed its widely\npredictable performance and consistently outperformed Scribe in all metrics.\nReverse path selection in overlays is identified as a major cause of\nperformance degradation."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0811.3712v1", 
    "title": "Performance Modeling and Evaluation for Information-Driven Networks", 
    "arxiv-id": "0811.3712v1", 
    "author": "Guoqiang Hu", 
    "publish": "2008-11-22T21:29:47Z", 
    "summary": "Information-driven networks include a large category of networking systems,\nwhere network nodes are aware of information delivered and thus can not only\nforward data packets but may also perform information processing. In many\nsituations, the quality of service (QoS) in information-driven networks is\nprovisioned with the redundancy in information. Traditional performance models\ngenerally adopt evaluation measures suitable for packet-oriented service\nguarantee, such as packet delay, throughput, and packet loss rate. These\nperformance measures, however, do not align well with the actual need of\ninformation-driven networks. New performance measures and models for\ninformation-driven networks, despite their importance, have been mainly blank,\nlargely because information processing is clearly application dependent and\ncannot be easily captured within a generic framework. To fill the vacancy, we\npresent a new performance evaluation framework particularly tailored for\ninformation-driven networks, based on the recent development of stochastic\nnetwork calculus. We analyze the QoS with respect to information delivery and\nstudy the scheduling problem with the new performance metrics. Our analytical\nframework can be used to calculate the network capacity in information delivery\nand in the meantime to help transmission scheduling for a large body of systems\nwhere QoS is stochastically guaranteed with the redundancy in information."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0812.0192v2", 
    "title": "A Simple Performance Analysis of a Core Node in an Optical Burst   Switched Network", 
    "arxiv-id": "0812.0192v2", 
    "author": "Hossam M. H. Shalaby", 
    "publish": "2008-12-01T00:55:14Z", 
    "summary": "This paper has been withdrawn"
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0901.1782v1", 
    "title": "A Holistic Approach to Information Distribution in Ad Hoc Networks", 
    "arxiv-id": "0901.1782v1", 
    "author": "Pietro Michiardi", 
    "publish": "2009-01-13T13:12:05Z", 
    "summary": "We investigate the problem of spreading information contents in a wireless ad\nhoc network with mechanisms embracing the peer-to-peer paradigm. In our vision,\ninformation dissemination should satisfy the following requirements: (i) it\nconforms to a predefined distribution and (ii) it is evenly and fairly carried\nby all nodes in their turn. In this paper, we observe the dissemination effects\nwhen the information moves across nodes according to two well-known mobility\nmodels, namely random walk and random direction. Our approach is fully\ndistributed and comes at a very low cost in terms of protocol overhead; in\naddition, simulation results show that the proposed solution can achieve the\naforementioned goals under different network scenarios, provided that a\nsufficient number of information replicas are injected into the network. This\nobservation calls for a further step: in the realistic case where the user\ncontent demand varies over time, we need a content replication/drop strategy to\nadapt the number of information replicas to the changes in the information\nquery rate. We therefore devise a distributed, lightweight scheme that performs\nefficiently in a variety of scenarios."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.0558v1", 
    "title": "Analysis of bandwidth measurement methodologies over WLAN systems", 
    "arxiv-id": "0902.0558v1", 
    "author": "Jordi Domingo-Pascual", 
    "publish": "2009-02-03T17:23:55Z", 
    "summary": "WLAN devices have become a fundamental component of nowadays network\ndeployments. However, even though traditional networking applications run\nmostly unchanged over wireless links, the actual interaction between these\napplications and the dynamics of wireless transmissions is not yet fully\nunderstood. An important example of such applications are bandwidth estimation\ntools. This area has become a mature research topic with well-developed\nresults. Unfortunately recent studies have shown that the application of these\nresults to WLAN links is not straightforward. The main reasons for this is that\nthe assumptions taken to develop bandwidth measurements tools do not hold any\nlonger in the presence of wireless links (e.g. non-FIFO scheduling). This paper\nbuilds from these observations and its main goal is to analyze the interaction\nbetween probe packets and WLAN transmissions in bandwidth estimation processes.\nThe paper proposes an analytical model that better accounts for the\nparticularities of WLAN links. The model is validated through extensive\nexperimentation and simulation and reveals that (1) the distribution of the\ndelay to transmit probing packets is not the same for the whole probing\nsequence, this biases the measurements process and (2) existing tools and\ntechniques point at the achievable throughput rather than the available\nbandwidth or the capacity, as previously assumed."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.0782v2", 
    "title": "A Multiobjective Optimization Framework for Routing in Wireless Ad Hoc   Networks", 
    "arxiv-id": "0902.0782v2", 
    "author": "Jean-Marie Gorce", 
    "publish": "2009-02-04T19:48:42Z", 
    "summary": "Wireless ad hoc networks are seldom characterized by one single performance\nmetric, yet the current literature lacks a flexible framework to assist in\ncharacterizing the design tradeoffs in such networks. In this work, we address\nthis problem by proposing a new modeling framework for routing in ad hoc\nnetworks, which used in conjunction with metaheuristic multiobjective search\nalgorithms, will result in a better understanding of network behavior and\nperformance when multiple criteria are relevant. Our approach is to take a\nholistic view of the network that captures the cross-interactions among\ninterference management techniques implemented at various layers of the\nprotocol stack. The resulting framework is a complex multiobjective\noptimization problem that can be efficiently solved through existing\nmultiobjective search techniques. In this contribution, we present the Pareto\noptimal sets for an example sensor network when delay, robustness and energy\nare considered. The aim of this paper is to present the framework and hence for\nconciseness purposes, the multiobjective optimization search is not developed\nherein."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.1169v1", 
    "title": "Node Weighted Scheduling", 
    "arxiv-id": "0902.1169v1", 
    "author": "Ness B. Shroff", 
    "publish": "2009-02-06T20:34:09Z", 
    "summary": "This paper proposes a new class of online policies for scheduling in\ninput-buffered crossbar switches. Our policies are throughput optimal for a\nlarge class of arrival processes which satisfy strong-law of large numbers.\nGiven an initial configuration and no further arrivals, our policies drain all\npackets in the system in the minimal amount of time (providing an online\nalternative to the batch approach based on Birkhoff-VonNeumann decompositions).\nWe show that it is possible for policies in our class to be throughput optimal\neven if they are not constrained to be maximal in every time slot.\n  Most algorithms for switch scheduling take an edge based approach; in\ncontrast, we focus on scheduling (a large enough set of) the most congested\nports. This alternate approach allows for lower-complexity algorithms, and also\nrequires a non-standard technique to prove throughput-optimality. One algorithm\nin our class, Maximum Vertex-weighted Matching (MVM) has worst-case complexity\nsimilar to Max-size Matching, and in simulations shows slightly better delay\nperformance than Max-(edge)weighted-Matching (MWM)."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.1394v2", 
    "title": "Fundamental delay bounds in peer-to-peer chunk-based real-time streaming   systems", 
    "arxiv-id": "0902.1394v2", 
    "author": "Stefano Salsano", 
    "publish": "2009-02-09T10:05:48Z", 
    "summary": "This paper addresses the following foundational question: what is the maximum\ntheoretical delay performance achievable by an overlay peer-to-peer streaming\nsystem where the streamed content is subdivided into chunks? As shown in this\npaper, when posed for chunk-based systems, and as a consequence of the\nstore-and-forward way in which chunks are delivered across the network, this\nquestion has a fundamentally different answer with respect to the case of\nsystems where the streamed content is distributed through one or more flows\n(sub-streams). To circumvent the complexity emerging when directly dealing with\ndelay, we express performance in term of a convenient metric, called \"stream\ndiffusion metric\". We show that it is directly related to the end-to-end\nminimum delay achievable in a P2P streaming network. In a homogeneous scenario,\nwe derive a performance bound for such metric, and we show how this bound\nrelates to two fundamental parameters: the upload bandwidth available at each\nnode, and the number of neighbors a node may deliver chunks to. In this bound,\nk-step Fibonacci sequences do emerge, and appear to set the fundamental laws\nthat characterize the optimal operation of chunk-based systems."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.1884v1", 
    "title": "A Proof of Concept for Optimizing Task Parallelism by Locality Queues", 
    "arxiv-id": "0902.1884v1", 
    "author": "Georg Hager", 
    "publish": "2009-02-11T13:51:27Z", 
    "summary": "Task parallelism as employed by the OpenMP task construct, although ideal for\ntackling irregular problems or typical producer/consumer schemes, bears some\npotential for performance bottlenecks if locality of data access is important,\nwhich is typically the case for memory-bound code on ccNUMA systems. We present\na programming technique which ameliorates adverse effects of dynamic task\ndistribution by sorting tasks into locality queues, each of which is preferably\nprocessed by threads that belong to the same locality domain. Dynamic\nscheduling is fully preserved inside each domain, and is preferred over\npossible load imbalance even if non-local access is required. The effectiveness\nof the approach is demonstrated using a blocked six-point stencil solver as a\ntoy model."
},{
    "category": "cs.GT", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.2736v1", 
    "title": "Random Fruits on the Zielonka Tree", 
    "arxiv-id": "0902.2736v1", 
    "author": "Florian Horn", 
    "publish": "2009-02-16T14:26:36Z", 
    "summary": "Stochastic games are a natural model for the synthesis of controllers\nconfronted to adversarial and/or random actions. In particular,\n$\\omega$-regular games of infinite length can represent reactive systems which\nare not expected to reach a correct state, but rather to handle a continuous\nstream of events. One critical resource in such applications is the memory used\nby the controller. In this paper, we study the amount of memory that can be\nsaved through the use of randomisation in strategies, and present matching\nupper and lower bounds for stochastic Muller games."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.4527v1", 
    "title": "EXtensible Animator for Mobile Simulations: EXAMS", 
    "arxiv-id": "0902.4527v1", 
    "author": "Nikolaos S. Livathinos", 
    "publish": "2009-02-26T08:03:30Z", 
    "summary": "One of the most widely used simulation environments for mobile wireless\nnetworks is the Network Simulator 2 (NS-2). However NS-2 stores its outcome in\na text file, so there is a need for a visualization tool to animate the\nsimulation of the wireless network. The purpose of this tool is to help the\nresearcher examine in detail how the wireless protocol works both on a network\nand a node basis. It is clear that much of this information is protocol\ndependent and cannot be depicted properly by a general purpose animation\nprocess. Existing animation tools do not provide this level of information\nneither permit the specific protocol to control the animation at all. EXAMS is\nan NS-2 visualization tool for mobile simulations which makes possible the\nportrayal of NS-2 internal information like transmission properties and node\ndata structures. This is mainly possible due to EXAMS extensible architecture\nwhich separates the animation process into a general and a protocol specific\npart. The latter can be developed independently by the protocol designer and\nloaded on demand. These and other useful characteristics of the EXAMS tool can\nbe an invaluable help for a researcher in order to investigate and debug a\nmobile networking protocol."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0902.4822v1", 
    "title": "Lightweight Task Analysis for Cache-Aware Scheduling on Heterogeneous   Clusters", 
    "arxiv-id": "0902.4822v1", 
    "author": "Sverre Jarp", 
    "publish": "2009-02-27T12:47:22Z", 
    "summary": "We present a novel characterization of how a program stresses cache. This\ncharacterization permits fast performance prediction in order to simulate and\nassist task scheduling on heterogeneous clusters. It is based on the estimation\nof stack distance probability distributions. The analysis requires the\nobservation of a very small subset of memory accesses, and yields a reasonable\nto very accurate prediction in constant time."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0903.0035v1", 
    "title": "ScALPEL: A Scalable Adaptive Lightweight Performance Evaluation Library   for application performance monitoring", 
    "arxiv-id": "0903.0035v1", 
    "author": "Srinidhi Varadarajan", 
    "publish": "2009-02-28T04:11:39Z", 
    "summary": "As supercomputers continue to grow in scale and capabilities, it is becoming\nincreasingly difficult to isolate processor and system level causes of\nperformance degradation. Over the last several years, a significant number of\nperformance analysis and monitoring tools have been built/proposed. However,\nthese tools suffer from several important shortcomings, particularly in\ndistributed environments. In this paper we present ScALPEL, a Scalable Adaptive\nLightweight Performance Evaluation Library for application performance\nmonitoring at the functional level. Our approach provides several distinct\nadvantages. First, ScALPEL is portable across a wide variety of architectures,\nand its ability to selectively monitor functions presents low run-time\noverhead, enabling its use for large-scale production applications. Second, it\nis run-time configurable, enabling both dynamic selection of functions to\nprofile as well as events of interest on a per function basis. Third, our\napproach is transparent in that it requires no source code modifications.\nFinally, ScALPEL is implemented as a pluggable unit by reusing existing\nperformance monitoring frameworks such as Perfmon and PAPI and extending them\nto support both sequential and MPI applications."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0903.0096v2", 
    "title": "Modeling Multi-Cell IEEE 802.11 WLANs with Application to Channel   Assignment", 
    "arxiv-id": "0903.0096v2", 
    "author": "Anurag Kumar", 
    "publish": "2009-03-01T02:29:37Z", 
    "summary": "We provide a simple and accurate analytical model for multi-cell\ninfrastructure IEEE 802.11 WLANs. Our model applies if the cell radius, $R$, is\nmuch smaller than the carrier sensing range, $R_{cs}$. We argue that, the\ncondition $R_{cs} >> R$ is likely to hold in a dense deployment of Access\nPoints (APs) where, for every client or station (STA), there is an AP very\nclose to the STA such that the STA can associate with the AP at a high physical\nrate. We develop a scalable cell level model for such WLANs with saturated AP\nand STA queues as well as for TCP-controlled long file downloads. The accuracy\nof our model is demonstrated by comparison with ns-2 simulations. We also\ndemonstrate how our analytical model could be applied in conjunction with a\nLearning Automata (LA) algorithm for optimal channel assignment. Based on the\ninsights provided by our analytical model, we propose a simple decentralized\nalgorithm which provides static channel assignments that are Nash equilibria in\npure strategies for the objective of maximizing normalized network throughput.\nOur channel assignment algorithm requires neither any explicit knowledge of the\ntopology nor any message passing, and provides assignments in only as many\nsteps as there are channels. In contrast to prior work, our approach to channel\nassignment is based on the throughput metric."
},{
    "category": "cs.DM", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0903.0520v1", 
    "title": "MANETS: High mobility can make up for low transmission power", 
    "arxiv-id": "0903.0520v1", 
    "author": "Riccardo Silvestri", 
    "publish": "2009-03-03T12:50:27Z", 
    "summary": "We consider a Mobile Ad-hoc NETworks (MANET) formed by \"n\" nodes that move\nindependently at random over a finite square region of the plane. Nodes\nexchange data if they are at distance at most \"r\" within each other, where r>0\nis the node transmission radius. The \"flooding time\" is the number of time\nsteps required to broadcast a message from a source node to every node of the\nnetwork. Flooding time is an important measure of the speed of information\nspreading in dynamic networks.\n  We derive a nearly-tight upper bound on the flooding time which is a\ndecreasing function of the maximal \"velocity\" of the nodes. It turns out that,\nwhen the node velocity is sufficiently high, even if the node transmission\nradius \"r\" is far below the \"connectivity threshold\", the flooding time does\nnot asymptotically depend on \"r\". This implies that flooding can be very fast\neven though every \"snapshot\" (i.e. the static random geometric graph at any\nfixed time) of the MANET is fully disconnected. Data reach all nodes quickly\ndespite these ones use very low transmission power.\n  Our result is the first analytical evidence of the fact that high, random\nnode mobility strongly speed-up information spreading and, at the same time,\nlet nodes save energy."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0903.2119v1", 
    "title": "Adaptive Mesh Approach for Predicting Algorithm Behavior with   Application to Visibility Culling in Computer Graphics", 
    "arxiv-id": "0903.2119v1", 
    "author": "Martin Ziegler", 
    "publish": "2009-03-12T10:16:13Z", 
    "summary": "We propose a concise approximate description, and a method for efficiently\nobtaining this description, via adaptive random sampling of the performance\n(running time, memory consumption, or any other profileable numerical quantity)\nof a given algorithm on some low-dimensional rectangular grid of inputs. The\nformal correctness is proven under reasonable assumptions on the algorithm\nunder consideration; and the approach's practical benefit is demonstrated by\npredicting for which observer positions and viewing directions an occlusion\nculling algorithm yields a net performance benefit or loss compared to a simple\nbrute force renderer."
},{
    "category": "cs.CR", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0903.3900v1", 
    "title": "Optimized Implementation of Elliptic Curve Based Additive Homomorphic   Encryption for Wireless Sensor Networks", 
    "arxiv-id": "0903.3900v1", 
    "author": "Sorin A. Huss", 
    "publish": "2009-03-23T16:43:01Z", 
    "summary": "When deploying wireless sensor networks (WSNs) in public environments it may\nbecome necessary to secure their data storage and transmission against possible\nattacks such as node-compromise and eavesdropping. The nodes feature only small\ncomputational and energy resources, thus requiring efficient algorithms. As a\nsolution for this problem the TinyPEDS approach was proposed in [7], which\nutilizes the Elliptic Curve ElGamal (EC-ElGamal) cryptosystem for additive\nhomomorphic encryption allowing concealed data aggregation. This work presents\nan optimized implementation of EC-ElGamal on a MicaZ mote, which is a typical\nsensor node platform with 8-bit processor for WSNs. Compared to the best\nprevious result, our implementation is at least 44% faster for fixed-point\nmultiplication. Because most parts of the algorithm are similar to standard\nElliptic Curve algorithms, the results may be reused in other realizations on\nconstrained devices as well."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0903.4898v1", 
    "title": "Asymptotic Optimality of the Static Frequency Caching in the Presence of   Correlated Requests", 
    "arxiv-id": "0903.4898v1", 
    "author": "Ana Radovanovic", 
    "publish": "2009-03-27T20:05:17Z", 
    "summary": "It is well known that the static caching algorithm that keeps the most\nfrequently requested documents in the cache is optimal in case when documents\nare of the same size and requests are independent and equally distributed.\nHowever, it is hard to develop explicit and provably optimal caching algorithms\nwhen requests are statistically correlated. In this paper, we show that keeping\nthe most frequently requested documents in the cache is still optimal for large\ncache sizes even if the requests are strongly correlated."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0904.0771v1", 
    "title": "Effect of cell residence time variance on the performance of an advanced   paging algorithm", 
    "arxiv-id": "0904.0771v1", 
    "author": "Michael E. Theologou", 
    "publish": "2009-04-05T13:38:07Z", 
    "summary": "The use of advanced sequential paging algorithms has been suggested as a\nmeans to reduce the signaling cost in future mobile cellular networks. In a\nproposed algorithm (Koukoutsidis and Theologou, 2003), the system can use the\nadditional information of the last interaction cell combined with a mobility\nmodel to predict the short-term location probabilities at the time of an\nincoming call arrival. The short-term location probabilities reduce the\nuncertainty in mobile user position and thus greatly improve the search. In\nthis paper, an analytical model is derived that allows for a general\ndistribution of cell residence times. By considering a Gamma distribution, we\nstudy the effect of the variance of cell residence times and derive useful\nresults on the performance of the algorithm."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0904.2018v2", 
    "title": "Stochastic Service Guarantee Analysis Based on Time-Domain Models", 
    "arxiv-id": "0904.2018v2", 
    "author": "Y. Jiang", 
    "publish": "2009-04-14T11:47:31Z", 
    "summary": "Stochastic network calculus is a theory for stochastic service guarantee\nanalysis of computer communication networks. In the current stochastic network\ncalculus literature, its traffic and server models are typically based on the\ncumulative amount of traffic and cumulative amount of service respectively.\nHowever, there are network scenarios where the applicability of such models is\nlimited, and hence new ways of modeling traffic and service are needed to\naddress this limitation. This paper presents time-domain models and results for\nstochastic network calculus. Particularly, we define traffic models, which are\nbased on probabilistic lower-bounds on cumulative packet inter-arrival time,\nand server models, which are based on probabilistic upper-bounds on cumulative\npacket service time. In addition, examples demonstrating the use of the\nproposed time-domain models are provided. On the basis of the proposed models,\nthe five basic properties of stochastic network calculus are also proved, which\nimplies broad applicability of the proposed time-domain approach."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0904.4155v5", 
    "title": "Fundamentals of the Backoff Process in 802.11: Dichotomy of the   Aggregation", 
    "arxiv-id": "0904.4155v5", 
    "author": "Yuming Jiang", 
    "publish": "2009-04-27T13:33:06Z", 
    "summary": "This paper discovers fundamental principles of the backoff process that\ngoverns the performance of IEEE 802.11. A simplistic principle founded upon\nregular variation theory is that the backoff time has a truncated Pareto-type\ntail distribution with an exponent of $(\\log \\gamma)/\\log m$ ($m$ is the\nmultiplicative factor and $\\gamma$ is the collision probability). This reveals\nthat the per-node backoff process is heavy-tailed in the strict sense for\n$\\gamma>1/m^2$, and paves the way for the following unifying result.\n  The state-of-the-art theory on the superposition of the heavy-tailed\nprocesses is applied to establish a dichotomy exhibited by the aggregate\nbackoff process, putting emphasis on the importance of time-scale on which we\nview the backoff processes. While the aggregation on normal time-scales leads\nto a Poisson process, it is approximated by a new limiting process possessing\nlong-range dependence (LRD) on coarse time-scales. This dichotomy turns out to\nbe instrumental in formulating short-term fairness, extending existing formulas\nto arbitrary population, and to elucidate the absence of LRD in practical\nsituations. A refined wavelet analysis is conducted to strengthen this\nargument."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0905.0792v1", 
    "title": "Introducing a Performance Model for Bandwidth-Limited Loop Kernels", 
    "arxiv-id": "0905.0792v1", 
    "author": "Georg Hager", 
    "publish": "2009-05-06T10:55:04Z", 
    "summary": "We present a performance model for bandwidth limited loop kernels which is\nfounded on the analysis of modern cache based microarchitectures. This model\nallows an accurate performance prediction and evaluation for existing\ninstruction codes. It provides an in-depth understanding of how performance for\ndifferent memory hierarchy levels is made up. The performance of raw memory\nload, store and copy operations and a stream vector triad are analyzed and\nbenchmarked on three modern x86-type quad-core architectures in order to\ndemonstrate the capabilities of the model."
},{
    "category": "math.PR", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0905.1738v3", 
    "title": "Information Ranking and Power Laws on Trees", 
    "arxiv-id": "0905.1738v3", 
    "author": "Mariana Olvera-Cravioto", 
    "publish": "2009-05-11T23:57:58Z", 
    "summary": "We study the situations when the solution to a weighted stochastic recursion\nhas a power law tail. To this end, we develop two complementary approaches, the\nfirst one extends Goldie's (1991) implicit renewal theorem to cover recursions\non trees; and the second one is based on a direct sample path large deviations\nanalysis of weighted recursive random sums. We believe that these methods may\nbe of independent interest in the analysis of more general weighted branching\nprocesses as well as in the analysis of algorithms."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0906.0557v4", 
    "title": "An Axiomatic Theory of Fairness in Network Resource Allocation", 
    "arxiv-id": "0906.0557v4", 
    "author": "Ashutosh Sabharwal", 
    "publish": "2009-06-02T18:52:24Z", 
    "summary": "We present a set of five axioms for fairness measures in resource allocation.\nA family of fairness measures satisfying the axioms is constructed. Well-known\nnotions such as alpha-fairness, Jain's index, and entropy are shown to be\nspecial cases. Properties of fairness measures satisfying the axioms are\nproven, including Schur-concavity. Among the engineering implications is a\ngeneralized Jain's index that tunes the resolution of the fairness measure, a\nnew understanding of alpha-fair utility functions, and an interpretation of\n\"larger alpha is more fair\". We also construct an alternative set of four\naxioms to capture efficiency objectives and feasibility constraints."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICIW.2009.19", 
    "link": "http://arxiv.org/pdf/0906.1326v1", 
    "title": "Similarity Analysis in Automatic Performance Debugging of SPMD Parallel   Programs", 
    "arxiv-id": "0906.1326v1", 
    "author": "Dan Meng", 
    "publish": "2009-06-07T05:45:57Z", 
    "summary": "Different from sequential programs, parallel programs possess their own\ncharacteristics which are difficult to analyze in the multi-process or\nmulti-thread environment. This paper presents an innovative method to\nautomatically analyze the SPMD programs. Firstly, with the help of clustering\nmethod focusing on similarity analysis, an algorithm is designed to locate\nperformance problems in parallel programs automatically. Secondly a Rough Set\nmethod is used to uncover the performance problem and provide the insight into\nthe micro-level causes. Lastly, we have analyzed a production parallel\napplication to verify the effectiveness of our method and system."
},{
    "category": "cs.DM", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0906.2311v2", 
    "title": "A note on uniform power connectivity in the SINR model", 
    "arxiv-id": "0906.2311v2", 
    "author": "Yvonne-Anne Pignolet", 
    "publish": "2009-06-12T12:20:37Z", 
    "summary": "In this paper we study the connectivity problem for wireless networks under\nthe Signal to Interference plus Noise Ratio (SINR) model. Given a set of radio\ntransmitters distributed in some area, we seek to build a directed strongly\nconnected communication graph, and compute an edge coloring of this graph such\nthat the transmitter-receiver pairs in each color class can communicate\nsimultaneously. Depending on the interference model, more or less colors,\ncorresponding to the number of frequencies or time slots, are necessary. We\nconsider the SINR model that compares the received power of a signal at a\nreceiver to the sum of the strength of other signals plus ambient noise . The\nstrength of a signal is assumed to fade polynomially with the distance from the\nsender, depending on the so-called path-loss exponent $\\alpha$.\n  We show that, when all transmitters use the same power, the number of colors\nneeded is constant in one-dimensional grids if $\\alpha>1$ as well as in\ntwo-dimensional grids if $\\alpha>2$. For smaller path-loss exponents and\ntwo-dimensional grids we prove upper and lower bounds in the order of\n$\\mathcal{O}(\\log n)$ and $\\Omega(\\log n/\\log\\log n)$ for $\\alpha=2$ and\n$\\Theta(n^{2/\\alpha-1})$ for $\\alpha<2$ respectively. If nodes are distributed\nuniformly at random on the interval $[0,1]$, a \\emph{regular} coloring of\n$\\mathcal{O}(\\log n)$ colors guarantees connectivity, while $\\Omega(\\log \\log\nn)$ colors are required for any coloring."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0906.3966v1", 
    "title": "Application of non-uniform laxity to EDF for aperiodic tasks to improve   task utilisation on multicore platforms", 
    "arxiv-id": "0906.3966v1", 
    "author": "A P Shanthi", 
    "publish": "2009-06-22T09:33:17Z", 
    "summary": "This paper proposes a new scheduler applying the concept of non-uniform\nlaxity to Earliest deadline first (EDF) approach for aperiodic tasks. This\nscheduler improves task utilisation (Execution time / deadline) and also\nincreases the number of tasks that are being scheduled. Laxity is a measure of\nthe spare time permitted for the task before it misses its deadline, and is\ncomputed using the expression (deadline - (current time + execution time)).\nWeight decides the priority of the task and is defined by the expression\n(quantum slice time / allocated time)*total core time for the task. Quantum\nslice time is the time actually used, allocated time is the time allocated by\nthe scheduler, and total core time is the time actually reserved by the core\nfor execution of one quantum of the task. Non-uniform laxity enables scheduling\nof tasks that have higher priority before the normal execution of other tasks\nand is computed by multiplying the weight of the task with its laxity. The\nalgorithm presented in the paper has been simulated on Cheddar, a real time\nscheduling tool and also on SESC, an architectural simulator for multicore\nplatforms, for upto 5000 random task sets, and upto 5000 cores. This scheduler\nimproves task utilisation by 35% and the number of tasks being scheduled by\n36%, compared to conventional EDF."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0906.4217v1", 
    "title": "A Performance Analysis of HICCUPS - a Steganographic System for WLAN", 
    "arxiv-id": "0906.4217v1", 
    "author": "Krzysztof Szczypiorski", 
    "publish": "2009-06-23T14:43:07Z", 
    "summary": "The paper presents an analysis of performance features of the HICCUPS (HIdden\nCommunication system for CorrUPted networkS) including the efficiency and the\ncost of the system in WLANs (Wireless Local Area Networks). The analysis relies\non the original CSMA/CA (Carrier Sense Multiple Access with Collision\nAvoidance) 802.11 Markov chain-based model."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0906.4834v1", 
    "title": "Global Stability Analysis for an Internet Congestion Control Model with   a Time-Varying Link Capacity", 
    "arxiv-id": "0906.4834v1", 
    "author": "S. Khorsandi", 
    "publish": "2009-06-26T03:24:12Z", 
    "summary": "In this paper, a global stability analysis is given for a rate-based\ncongestion control system modeled by a nonlinear delayed differential equation.\nThe model determines the dynamics of a single-source single-link network, with\na time-varying capacity of link and a fixed communication delay. We obtain a\nsufficient delay-independent conditions on system parameters under which global\nasymptotic stability of the system is guarantied. The proof is based on an\nextension of Lyapunov-Krasovskii theorem for a class of nonlinear time-delay\nsystems. The numerical simulations for a typical scenario justify the\ntheoretical results."
},{
    "category": "cs.MM", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0906.4936v1", 
    "title": "A New Approach to Manage QoS in Distributed Multimedia Systems", 
    "arxiv-id": "0906.4936v1", 
    "author": "Bruno Sadeg", 
    "publish": "2009-06-26T13:40:38Z", 
    "summary": "Dealing with network congestion is a criterion used to enhance quality of\nservice (QoS) in distributed multimedia systems. The existing solutions for the\nproblem of network congestion ignore scalability considerations because they\nmaintain a separate classification for each video stream. In this paper, we\npropose a new method allowing to control QoS provided to clients according to\nthe network congestion, by discarding some frames when needed. The technique\nproposed, called (m,k)-frame, is scalable with little degradation in\napplication performances. (m,k)-frame method is issued from the notion of\n(m,k)-firm realtime constraints which means that among k invocations of a task,\nm invocations must meet their deadline. Our simulation studies show the\nusefulness of (m,k)-frame method to adapt the QoS to the real conditions in a\nmultimedia application, according to the current system load. Notably, the\nsystem must adjust the QoS provided to active clients1 when their number\nvaries, i.e. dynamic arrival of clients."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0907.2139v1", 
    "title": "Adaptive Point-to-Multipoint Transmission for Multimedia Broadcast   Multicast Services in LTE", 
    "arxiv-id": "0907.2139v1", 
    "author": "J\u00f6rg Huschke", 
    "publish": "2009-07-13T11:21:23Z", 
    "summary": "This paper investigates point-to-multipoint (PTM) transmission supporting\nadaptive modulation and coding (AMC) as well as retransmissions based on\nincremental redundancy. In contrast to the classical PTM transmission which was\nintroduced by the Multimedia Broadcast Multicast Service (MBMS), the\nadaptiveness requires user individual feedback channels that allow the\nreceivers to report their radio conditions and send positive or negative\nacknowledgments (ACK/NACK) for a Layer 1 transport block to the eNodeB. In this\nwork, an adaptive PTM scheme based on feedback from multiple users is presented\nand evaluated. Furthermore, a simple NACK-oriented feedback mechanism is\nintroduced to relieve the feedback channel that is used in the uplink. Finally,\nthe performance of different single-cell MBMS transmission modes is evaluated\nby dynamic radio network simulations. It is shown that adaptive PTM\ntransmission outperforms the conventional MBMS configurations in terms of radio\nresource consumption and user satisfaction rate."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0907.2563v1", 
    "title": "Gossip-based Search in Multipeer Communication Networks", 
    "arxiv-id": "0907.2563v1", 
    "author": "Piet Van Mieghem", 
    "publish": "2009-07-15T12:05:27Z", 
    "summary": "We study a gossip-based algorithm for searching data objects in a multipeer\ncommunication network. All of the nodes in the network are able to communicate\nwith each other. There exists an initiator node that starts a round of searches\nby randomly querying one or more of its neighbors for a desired object. The\nqueried nodes can also be activated and look for the object. We examine several\nbehavioural patterns of nodes with respect to their willingness to cooperate in\nthe search. We derive mathematical models for the search process based on the\nballs and bins model, as well as known approximations for the rumour-spreading\nproblem. All models are validated with simulations. We also evaluate the\nperformance of the algorithm and examine the impact of search parameters."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0907.3710v1", 
    "title": "Throughput metrics and packet delay in TCP/IP networks", 
    "arxiv-id": "0907.3710v1", 
    "author": "A. P. Platonov", 
    "publish": "2009-07-21T17:35:44Z", 
    "summary": "In the paper the method for estimation of throughput metrics like available\nbandwidth and end-t-end capacity is supposed. This method is based on\nmeasurement of network delay $D_i$ for packets of different sizes $W_i$. The\nsimple expression for available bandwidth $B_{av} =(W_2-W_1)/(D_2-D_1)$ is\nsubstantiated. The number of experiments on matching of the results received\nnew and traditional methods is spent. The received results testify to\npossibility of application of new model."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0907.4881v1", 
    "title": "Approximate mechanism for measuring stability of Internet link in   aggregated Internet pipe", 
    "arxiv-id": "0907.4881v1", 
    "author": "Mohamed Imran K R", 
    "publish": "2009-07-28T10:29:31Z", 
    "summary": "In this article we propose a method for measuring internet connection\nstability which is fast and has negligible overhead for the process of its\ncomplexity. This method finds a relative value for representing the stability\nof internet connections and can also be extended for aggregated internet\nconnections. The method is documented with help of a real time implementation\nand results are shared. This proposed measurement scheme uses HTTP GET method\nfor each connections. The normalized responses to identified sites like\ngateways of ISPs, google.com etc are used for calculating current link\nstability. The novelty of the approach is that historic values are used to\ncalculate overall link stability. In this discussion, we also document a method\nto use the calculated values as a dynamic threshold metric. This is used in\nrouting decisions and for load-balancing each of the connections in an\naggregated bandwidth pipe. This scheme is a very popular practice in aggregated\ninternet connections."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0907.5443v1", 
    "title": "Dynamic Bandwidth Management in Distributed VoD based on the User Class   Using Agents", 
    "arxiv-id": "0907.5443v1", 
    "author": "H D Maheshappa", 
    "publish": "2009-07-30T22:53:48Z", 
    "summary": "This paper proposes a dynamic bandwidth management algorithm in which more\nbandwidth is allocated for higher class users and also higher priority is given\nto the videos with higher popularity within a class using agent technology. The\npopularity and weight profile of the videos which is used for efficiently\nallocating bandwidth is periodically updated by a mobile agent. The proposed\napproach allocates more bandwidth for higher class users and gives higher\npriority for higher weight videos [popular videos] so that they can be served\nwith high QoS, reduces the load on the central multimedia server and maximizes\nthe channel utilization between the neighboring proxy servers and the central\nmultimedia server and lower video rejection ratio. The simulation results prove\nthe reduction of load on central multimedia server by load sharing among the\nneighboring proxy servers, maximum bandwidth utilization, and more bandwidth\nallocation for higher class users."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0908.0126v1", 
    "title": "Applicability of a Novel Integer Programming Model for Wireless Sensor   Networks", 
    "arxiv-id": "0908.0126v1", 
    "author": "Andre L. V. Coelho", 
    "publish": "2009-08-02T11:57:15Z", 
    "summary": "This paper presents an applicability analysis over a novel integer\nprogramming model devoted to optimize power consumption efficiency in\nheterogeneous wireless sensor networks. This model is based upon a schedule of\nsensor allocation plans in multiple time intervals subject to coverage and\nconnectivity constraints. By turning off a specific set of redundant sensors in\neach time interval, it is possible to reduce the total energy consumption in\nthe network and, at the same time, avoid partitioning the whole network by\nlosing some strategic sensors too prematurely. Since the network is\nheterogeneous, sensors can sense different phenomena from different demand\npoints, with different sample rates. As the problem instances grows the time\nspent to the execution turns impracticable."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0908.0222v1", 
    "title": "Performance Evaluation of Mesh based Multicast Reactive Routing Protocol   under Black Hole Attack", 
    "arxiv-id": "0908.0222v1", 
    "author": "V. Vasudevan", 
    "publish": "2009-08-03T10:47:42Z", 
    "summary": "A mobile ad-hoc network is an autonomous system of mobile nodes connected by\nwireless links in which nodes cooperate by forwarding packets for each other\nthereby enabling communication beyond direct wireless transmission range. The\nwireless and dynamic nature of ad-hoc networks makes them vulnerable to attacks\nespecially in routing protocols. Providing security in mobile ad-hoc networks\nhas been a major issue over the recent years. One of the prominent mesh base\nreactive multicast routing protocols used in ad-hoc networks is On Demand\nMulticast Routing protocol (ODMRP). The security of ODMRP is compromised by a\nprimary routing attack called black hole attack. In this attack a malicious\nnode advertises itself as having the shortest path to the node whose packets it\nwants to intercept. This paper discusses the impact of black hole attack on\nODMRP under various scenarios. The performance is evaluated using metrics such\nas packet delivery ratio and end to end delay for various numbers of senders\nand receivers via simulation. Simulations are carried out using network\nsimulator ns-2. The results enable us to propose solutions to counter the\neffect of black hole attack."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0908.0893v1", 
    "title": "Nuzzer: A Large-Scale Device-Free Passive Localization System for   Wireless Environments", 
    "arxiv-id": "0908.0893v1", 
    "author": "Moustafa Youssef", 
    "publish": "2009-08-06T15:31:12Z", 
    "summary": "The widespread usage of wireless local area networks and mobile devices has\nfostered the interest in localization systems for wireless environments. The\nmajority of research in the context of wireless-based localization systems has\nfocused on device-based active localization, in which a device is attached to\ntracked entities. Recently, device-free passive localization (DfP) has been\nproposed where the tracked entity is neither required to carry devices nor\nparticipate actively in the localization process. DfP systems are based on the\nfact that RF signals are affected by the presence of people and objects in the\nenvironment. The DfP concept enables a wide range of applications including\nintrusion detection and tracking, border protection, and smart buildings\nautomation. Previous studies have focused on small areas with direct line of\nsight and/or controlled environments. In this paper, we present the design,\nimplementation and analysis of Nuzzer, a large-scale device-free passive\nlocalization system for real environments.\n  Without any additional hardware, it makes use of the already installed\nwireless data networks to monitor and process changes in the received signal\nstrength (RSS) transmitted from access points at one or more monitoring points.\nWe present probabilistic techniques for DfP localization and evaluate their\nperformance in a typical office building, rich in multipath, with an area of\n1500 square meters. Our results show that the Nuzzer system gives device-free\nlocation estimates with less than 2 meters median distance error using only two\nmonitoring laptops and three access points. This indicates the suitability of\nNuzzer to a large number of application domains."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0909.0633v1", 
    "title": "Statistical End-to-end Performance Bounds for Networks under Long Memory   FBM Cross Traffic", 
    "arxiv-id": "0909.0633v1", 
    "author": "Markus Fidler", 
    "publish": "2009-09-03T12:32:46Z", 
    "summary": "Fractional Brownian motion (fBm) emerged as a useful model for self-similar\nand long-range dependent Internet traffic. Approximate performance measures are\nknown from large deviations theory for single queuing systems with fBm through\ntraffic. In this paper we derive end-to-end performance bounds for a through\nflow in a network of tandem queues under fBm cross traffic. To this end, we\nprove a rigorous sample path envelope for fBm that complements previous\napproximate results. We find that both approaches agree in their outcome that\noverflow probabilities for fBm traffic have a Weibullian tail. We employ the\nsample path envelope and the concept of leftover service curves to model the\nremaining service after scheduling fBm cross traffic at a system. Using\ncomposition results for tandem systems from the stochastic network calculus we\nderive end-to-end statistical performance bounds for individual flows in\nnetworks under fBm cross traffic. We discover that these bounds grow in O(n\n(log n)^(1/(2-2H))) for n systems in series where H is the Hurst parameter of\nthe fBm cross traffic. We show numerical results on the impact of the\nvariability and the correlation of fBm traffic on network performance."
},{
    "category": "cs.DB", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0909.1772v1", 
    "title": "Visualizing the robustness of query execution", 
    "arxiv-id": "0909.1772v1", 
    "author": "Janet Wiener", 
    "publish": "2009-09-09T18:09:52Z", 
    "summary": "In database query processing, actual run-time conditions (e.g., actual\nselectivities and actual available memory) very often differ from compile-time\nexpectations of run-time conditions (e.g., estimated predicate selectivities\nand anticipated memory availability). Robustness of query processing can be\ndefined as the ability to handle unexpected conditions. Robustness of query\nexecution, specifically, can be defined as the ability to process a specific\nplan efficiently in an unexpected condition. We focus on query execution\n(run-time), ignoring query optimization (compile-time), in order to complement\nexisting research and to explore untapped potential for improved robustness in\ndatabase query processing.\n  One of our initial steps has been to devise diagrams or maps that show how\nwell plans perform in the face of varying run-time conditions and how\ngracefully a system's query architecture, operators, and their implementation\ndegrade in the face of adverse conditions. In this paper, we show several kinds\nof diagrams with data from three real systems and report on what we have\nlearned both about these visualization techniques and about the three database\nsystems"
},{
    "category": "cs.DB", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0909.1784v1", 
    "title": "Energy Efficiency: The New Holy Grail of Data Management Systems   Research", 
    "arxiv-id": "0909.1784v1", 
    "author": "Parthasarathy Ranganathan", 
    "publish": "2009-09-09T18:10:39Z", 
    "summary": "Energy costs are quickly rising in large-scale data centers and are soon\nprojected to overtake the cost of hardware. As a result, data center operators\nhave recently started turning into using more energy-friendly hardware. Despite\nthe growing body of research in power management techniques, there has been\nlittle work to date on energy efficiency from a data management software\nperspective.\n  In this paper, we argue that hardware-only approaches are only part of the\nsolution, and that data management software will be key in optimizing for\nenergy efficiency. We discuss the problems arising from growing energy use in\ndata centers and the trends that point to an increasing set of opportunities\nfor software-level optimizations. Using two simple experiments, we illustrate\nthe potential of such optimizations, and, motivated by these examples, we\ndiscuss general approaches for reducing energy waste. Lastly, we point out\nexisting places within database systems that are promising for\nenergy-efficiency optimizations and urge the data management systems community\nto shift focus from performance-oriented research to energy-efficient\ncomputing."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0909.2024v1", 
    "title": "A Lightweight Distributed Solution to Content Replication in Mobile   Networks", 
    "arxiv-id": "0909.2024v1", 
    "author": "Marco Fiore", 
    "publish": "2009-09-10T19:43:30Z", 
    "summary": "Performance and reliability of content access in mobile networks is\nconditioned by the number and location of content replicas deployed at the\nnetwork nodes. Facility location theory has been the traditional, centralized\napproach to study content replication: computing the number and placement of\nreplicas in a network can be cast as an uncapacitated facility location\nproblem. The endeavour of this work is to design a distributed, lightweight\nsolution to the above joint optimization problem, while taking into account the\nnetwork dynamics. In particular, we devise a mechanism that lets nodes share\nthe burden of storing and providing content, so as to achieve load balancing,\nand decide whether to replicate or drop the information so as to adapt to a\ndynamic content demand and time-varying topology. We evaluate our mechanism\nthrough simulation, by exploring a wide range of settings and studying\nrealistic content access mechanisms that go beyond the traditional\nassumptionmatching demand points to their closest content replica. Results show\nthat our mechanism, which uses local measurements only, is: (i) extremely\nprecise in approximating an optimal solution to content placement and\nreplication; (ii) robust against network mobility; (iii) flexible in\naccommodating various content access patterns, including variation in time and\nspace of the content demand."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-642-05434-1_12", 
    "link": "http://arxiv.org/pdf/0909.2297v1", 
    "title": "Simulation of Resource Usage in Parallel Evolutionary Peptide   Optimization using JavaSpaces Technology", 
    "arxiv-id": "0909.2297v1", 
    "author": "Andias Wira-Alam", 
    "publish": "2009-09-13T12:36:22Z", 
    "summary": "Peptide Optimization is a highly complex problem and it takes very long time\nof computation. This optimization process uses many software applications in a\ncluster running GNU/Linux Operating System that perform special tasks. The\napplication to organize the whole optimization process had been already\ndeveloped, namely SEPP (System for Evolutionary Pareto Optimization of\nPeptides/Polymers). A single peptide optimization takes a lot of computation\ntime to produce a certain number of individuals. However, it can be accelerated\nby increasing the degree of parallelism as well as the number of nodes\n(processors) in the cluster. In this master thesis, I build a model simulating\nthe interplay of the programs so that the usage of each resource (processor)\ncan be determined and also the approximated time needed for the overall\noptimization process. There are two Evolutionary Algorithms that could be used\nin the optimization, namely Generation-based and Steady-state Evolutionary\nAlgorithm. The results of each Evolutionary Algorithm are shown based on the\nsimulations. Moreover, the results are also compared by using different\nparameters (the degree of parallelism and the number of processors) in the\nsimulation to give an overview of the advantages and the disadvantages of the\nalgorithms in terms of computation time and resource usage. The model is built\nup using JavaSpaces Technology."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TNET.2010.2095880", 
    "link": "http://arxiv.org/pdf/0909.3356v4", 
    "title": "Capacity of Large-scale CSMA Wireless Networks", 
    "arxiv-id": "0909.3356v4", 
    "author": "Soung Chang Liew", 
    "publish": "2009-09-18T05:22:30Z", 
    "summary": "In the literature, asymptotic studies of multi-hop wireless network capacity\noften consider only centralized and deterministic TDMA (time-division\nmulti-access) coordination schemes. There have been fewer studies of the\nasymptotic capacity of large-scale wireless networks based on CSMA\n(carrier-sensing multi-access), which schedules transmissions in a distributed\nand random manner. With the rapid and widespread adoption of CSMA technology, a\ncritical question is that whether CSMA networks can be as scalable as TDMA\nnetworks. To answer this question and explore the capacity of CSMA networks, we\nfirst formulate the models of CSMA protocols to take into account the unique\nCSMA characteristics not captured by existing interference models in the\nliterature. These CSMA models determine the feasible states, and consequently\nthe capacity of CSMA networks. We then study the throughput efficiency of CSMA\nscheduling as compared to TDMA. Finally, we tune the CSMA parameters so as to\nmaximize the throughput to the optimal order. As a result, we show that CSMA\ncan achieve throughput as $\\Omega(\\frac{1}{\\sqrt{n}})$, the same order as\noptimal centralized TDMA, on uniform random networks. Our CSMA scheme makes use\nof an efficient backbone-peripheral routing scheme and a careful design of dual\ncarrier-sensing and dual channel scheme. We also address the implementation\nissues of our CSMA scheme."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TNET.2010.2095880", 
    "link": "http://arxiv.org/pdf/0909.3717v4", 
    "title": "Analytical Models for Energy Consumption in Infrastructure WLAN STAs   Carrying TCP Traffic", 
    "arxiv-id": "0909.3717v4", 
    "author": "Venkata N. Padmanabhan", 
    "publish": "2009-09-21T09:32:27Z", 
    "summary": "We develop analytical models for estimating the energy spent by stations\n(STAs) in infrastructure WLANs when performing TCP controlled file downloads.\nWe focus on the energy spent in radio communication when the STAs are in the\nContinuously Active Mode (CAM), or in the static Power Save Mode (PSM). Our\napproach is to develop accurate models for obtaining the fraction of times the\nSTA radios spend in idling, receiving and transmitting. We discuss two traffic\nmodels for each mode of operation: (i) each STA performs one large file\ndownload, and (ii) the STAs perform short file transfers. We evaluate the rate\nof STA energy expenditure with long file downloads, and show that static PSM is\nworse than just using CAM. For short file downloads we compute the number of\nfile downloads that can be completed with given battery capacity, and show that\nPSM performs better than CAM for this case. We provide a validation of our\nanalytical models using the NS-2 simulator. In contrast to earlier work on\nanalytical modeling of PSM, our models that capture the details of the\ninteractions between the 802.11 MAC in PSM and certain aspects of TCP."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TNET.2010.2095880", 
    "link": "http://arxiv.org/pdf/0909.4934v1", 
    "title": "Characteristics of multithreading models for high-performance IO driven   network applications", 
    "arxiv-id": "0909.4934v1", 
    "author": "Mario Zagar", 
    "publish": "2009-09-27T14:20:46Z", 
    "summary": "In a technological landscape that is quickly moving toward dense multi-CPU\nand multi-core computer systems, where using multithreading is an increasingly\npopular application design decision, it is important to choose a proper model\nfor distributing tasks across multiple threads that will result in the best\nefficiency for the application and the system as a whole. The work described in\nthis paper creates, implements and evaluates various models of distributing\ntasks to CPU threads and investigates their characteristics for use in modern\nhigh-performance network servers. The results presented here comprise a roadmap\nof models for building multithreaded server applications for modern server\nhardware and Unix-like operating systems."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0910.0144v1", 
    "title": "Criticisms of modelling packet traffic using long-range dependence", 
    "arxiv-id": "0910.0144v1", 
    "author": "Miguel Rio", 
    "publish": "2009-10-01T11:46:24Z", 
    "summary": "This paper criticises the notion that long-range dependence is an important\ncontributor to the queuing behaviour of real Internet traffic. The idea is\nquestioned in two different ways. Firstly, a class of models used to simulate\nInternet traffic is shown to have important theoretical flaws. It is shown that\nthis behaviour is inconsistent with the behaviour of real traffic traces.\nSecondly, the notion that long-range correlations significantly affects the\nqueuing performance of traffic is investigated by destroying those correlations\nin real traffic traces (by reordering). It is shown that the longer ranges of\ncorrelations are not important except in one case with an extremely high load."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0910.0316v1", 
    "title": "An Analysis of Energy Consumption on ACK plus Rate Packet in Rate Based   Transport Protocol", 
    "arxiv-id": "0910.0316v1", 
    "author": "K. Thyagarajah", 
    "publish": "2009-10-02T03:28:20Z", 
    "summary": "Rate based transport protocol determines the rate of data transmission\nbetween the sender and receiver and then sends the data according to that rate.\nTo notify the rate to the sender, the receiver sends ACKplusRate packet based\non epoch timer expiry. In this paper, through detailed arguments and simulation\nit is shown that the transmission of ACKplusRate packet based on epoch timer\nexpiry consumes more energy in network with low mobility. To overcome this\nproblem, a new technique called Dynamic Rate Feedback (DRF) is proposed. DRF\nsends ACKplusRate whenever there is a change in rate of (plus or minus) 25\npercent than the previous rate. Based on ns2 simulation DRF is compared with a\nreliable transport protocol for ad hoc network (ATP)"
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0910.1719v1", 
    "title": "High availability using virtualization", 
    "arxiv-id": "0910.1719v1", 
    "author": "Federico Calzolari", 
    "publish": "2009-10-09T12:04:13Z", 
    "summary": "High availability has always been one of the main problems for a data center.\nTill now high availability was achieved by host per host redundancy, a highly\nexpensive method in terms of hardware and human costs. A new approach to the\nproblem can be offered by virtualization. Using virtualization, it is possible\nto achieve a redundancy system for all the services running on a data center.\nThis new approach to high availability allows to share the running virtual\nmachines over the servers up and running, by exploiting the features of the\nvirtualization layer: start, stop and move virtual machines between physical\nhosts. The system (3RC) is based on a finite state machine with hysteresis,\nproviding the possibility to restart each virtual machine over any physical\nhost, or reinstall it from scratch. A complete infrastructure has been\ndeveloped to install operating system and middleware in a few minutes. To\nvirtualize the main servers of a data center, a new procedure has been\ndeveloped to migrate physical to virtual hosts. The whole Grid data center\nSNS-PISA is running at the moment in virtual environment under the high\navailability system. As extension of the 3RC architecture, several storage\nsolutions have been tested to store and centralize all the virtual disks, from\nNAS to SAN, to grant data safety and access from everywhere. Exploiting\nvirtualization and ability to automatically reinstall a host, we provide a sort\nof host on-demand, where the action on a virtual machine is performed only when\na disaster occurs."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0910.4865v1", 
    "title": "Multi-core architectures: Complexities of performance prediction and the   impact of cache topology", 
    "arxiv-id": "0910.4865v1", 
    "author": "Gerhard Wellein", 
    "publish": "2009-10-26T12:48:02Z", 
    "summary": "The balance metric is a simple approach to estimate the performance of\nbandwidth-limited loop kernels. However, applying the method to in-cache\nsituations and modern multi-core architectures yields unsatisfactory results.\nThis paper analyzes the in uence of cache hierarchy design on performance\npredictions for bandwidth-limited loop kernels on current mainstream\nprocessors. We present a diagnostic model with improved predictive power,\ncorrecting the limitations of the simple balance metric. The importance of code\nexecution overhead even in bandwidth-bound situations is emphasized. Finally we\nanalyze the impact of synchronization overhead on multi-threaded performance\nwith a special emphasis on the in uence of cache topology."
},{
    "category": "cs.CC", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0910.5819v2", 
    "title": "Undecidability of performance equivalence of Petri nets", 
    "arxiv-id": "0910.5819v2", 
    "author": "Marcin Poturalski", 
    "publish": "2009-10-30T09:25:43Z", 
    "summary": "We investigate bisimulation equivalence on Petri nets under durational\nsemantics. Our motivation was to verify the conjecture that in durational\nsetting, the bisimulation equivalence checking problem becomes more tractable\nthan in ordinary setting (which is the case, e.g., over communication-free\nnets). We disprove this conjecture in three of four proposed variants of\ndurational semantics. The fourth variant remains an intriguing open problem."
},{
    "category": "cs.CR", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0911.0482v2", 
    "title": "AES Implementation and Performance Evaluation on 8-bit Microcontrollers", 
    "arxiv-id": "0911.0482v2", 
    "author": "Yongtae Shin", 
    "publish": "2009-11-03T03:41:32Z", 
    "summary": "The sensor network is a network technique for the implementation of\nUbiquitous computing environment. It is wireless network environment that\nconsists of the many sensors of lightweight and low power. Though sensor\nnetwork provides various capabilities, it is unable to ensure the secure\nauthentication between nodes. Eventually it causes the losing reliability of\nthe entire network and many secure problems. Therefore, encryption algorithm\nfor the implementation of reliable sensor network environments is required to\nthe applicable sensor network. In this paper, we proposed the solution of\nreliable sensor network to analyze the communication efficiency through\nmeasuring performance of AES encryption algorithm by plaintext size, and cost\nof operation per hop according to the network scale."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0911.0484v1", 
    "title": "GoS Proposal to Improve Trust and Delay of MPLS Flows for MCN Services", 
    "arxiv-id": "0911.0484v1", 
    "author": "Alfonso Gazo Cervero", 
    "publish": "2009-11-03T03:55:01Z", 
    "summary": "In this article, Guarantee of Service (GoS) is defined as a proposal to\nimprove the integration of Mission Critical Networking (MCN) services in the\nInternet, analyzing the congestion impact on those privileged flows with high\nrequirements of trust and delay. Multiprotocol Label Switching (MPLS) is a\ntechnology that offers flow differentiation and QoS in the Internet. Therefore,\nin order to improve network performance in case of congested domains, GoS is\nproposed as a technique that allows the local recovering of lost packets of\nMPLS privileged flows. To fulfill the GoS requirements for integration of MCN\nin MPLS, a minimum set of extensions to RSVPTE has been proposed to provide GoS\ncapable routes. Moreover, we have carried out an analytical study of GoS\nscalability and a performance improvement analysis by means of simulations."
},{
    "category": "cs.SE", 
    "doi": "10.1109/ICCCN.2009.5235309", 
    "link": "http://arxiv.org/pdf/0911.0488v1", 
    "title": "SOAP Serialization Performance Enhancement, Design And Implementation Of   A Middleware", 
    "arxiv-id": "0911.0488v1", 
    "author": "Parinaz Saadat", 
    "publish": "2009-11-03T04:28:27Z", 
    "summary": "The most straightforward way to improve performance of any system is to\ndefine the bottlenecks and think of ways to remove them. Web services are the\ninseparable part of any web application, as a result enhancing performance of\nweb services will have a great effect on the overall performance of the system.\nThe most widely used communication protocol in the web services model, SOAP, is\na simple protocol for the exchange of messages. The serialization of large SOAP\nresponses is a major performance bottleneck in a SOAP message exchange.\nClearly, some web servers can expect to receive many similar messages for a\nparticular web service as they share the same signature. The idea behind this\npaper is to avoid the redundant serialization stage of SOAP responses for\nrequest which have the same call parameters. The technique exploits the\nsimilarities between call parameters to improve web service Response Time by\navoiding redundant serialization of the same response with the help of a\nmiddleware running on top of web server. The middleware will maintain a trie of\nincoming parameters for every set of current requests. This way request\nprocessing and serialization of the response of same requests will be done only\nonce. In a nutshell, to serialize only the different responses is the simplest\nway to avoid extra work done by a serializer. It might worth noting that\nalthough our approach is to utilize the exact repeating portion parameters, the\nmiddleware can be configured to apply changes made to the result set of\nresponse to the serialized response being maintained in a trie to generate\nvalid results."
},{
    "category": "cs.NI", 
    "doi": "10.1109/WiCom.2008.731", 
    "link": "http://arxiv.org/pdf/0911.1504v1", 
    "title": "Throughput Limits of IEEE 802.11 and IEEE 802.15.3", 
    "arxiv-id": "0911.1504v1", 
    "author": "Kyung Sup Kwak", 
    "publish": "2009-11-08T09:59:15Z", 
    "summary": "IEEE 802.11 and IEEE 802.15.3 are wireless standards originally designed for\nwireless local area network (WLAN) and wireless personal area network (WPAN).\nThis paper studies MAC throughput analysis of both standards. We present a\ncomparative analysis of both standards in terms of MAC throughput and bandwidth\nefficiency. Numerical results show that the performance of IEEE 802.15.3\ntranscends IEEE 802.11 in all cases."
},{
    "category": "cs.DB", 
    "doi": "10.1109/WiCom.2008.731", 
    "link": "http://arxiv.org/pdf/0911.1691v3", 
    "title": "Vertical partitioning of relational OLTP databases using integer   programming", 
    "arxiv-id": "0911.1691v3", 
    "author": "Rasmus Resen Amossen", 
    "publish": "2009-11-09T15:03:31Z", 
    "summary": "A way to optimize performance of relational row store databases is to reduce\nthe row widths by vertically partitioning tables into table fractions in order\nto minimize the number of irrelevant columns/attributes read by each\ntransaction. This paper considers vertical partitioning algorithms for\nrelational row-store OLTP databases with an H-store-like architecture, meaning\nthat we would like to maximize the number of single-sited transactions. We\npresent a model for the vertical partitioning problem that, given a schema\ntogether with a vertical partitioning and a workload, estimates the costs\n(bytes read/written by storage layer access methods and bytes transferred\nbetween sites) of evaluating the workload on the given partitioning. The cost\nmodel allows for arbitrarily prioritizing load balancing of sites vs. total\ncost minimization. We show that finding a minimum-cost vertical partitioning in\nthis model is NP-hard and present two algorithms returning solutions in which\nsingle-sitedness of read queries is preserved while allowing column replication\n(which may allow a drastically reduced cost compared to disjoint partitioning).\nThe first algorithm is a quadratic integer program that finds optimal\nminimum-cost solutions with respect to the model, and the second algorithm is a\nmore scalable heuristic based on simulated annealing. Experiments show that the\nalgorithms can reduce the cost of the model objective by 37% when applied to\nthe TPC-C benchmark and the heuristic is shown to obtain solutions with cost\nclose to the ones found using the quadratic program."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TIT.2011.2173713", 
    "link": "http://arxiv.org/pdf/0911.3856v1", 
    "title": "Delay Bounds for Networks with Heavy-Tailed and Self-Similar Traffic", 
    "arxiv-id": "0911.3856v1", 
    "author": "Florin Ciucu", 
    "publish": "2009-11-19T19:27:50Z", 
    "summary": "We provide upper bounds on the end-to-end backlog and delay in a network with\nheavy-tailed and self-similar traffic. The analysis follows a network calculus\napproach where traffic is characterized by envelope functions and service is\ndescribed by service curves. A key contribution of this paper is the derivation\nof a probabilistic sample path bound for heavy-tailed self-similar arrival\nprocesses, which is enabled by a suitable envelope characterization, referred\nto as `htss envelope'. We derive a heavy-tailed service curve for an entire\nnetwork path when the service at each node on the path is characterized by\nheavy-tailed service curves. We obtain backlog and delay bounds for traffic\nthat is characterized by an htss envelope and receives service given by a\nheavy-tailed service curve. The derived performance bounds are non-asymptotic\nin that they do not assume a steady-state, large buffer, or many sources\nregime. We also explore the scale of growth of delays as a function of the\nlength of the path. The appendix contains an analysis for self-similar traffic\nwith a Gaussian tail distribution."
},{
    "category": "cs.PL", 
    "doi": "10.1109/TIT.2011.2173713", 
    "link": "http://arxiv.org/pdf/0911.4047v1", 
    "title": "Efficient Local Unfolding with Ancestor Stacks", 
    "arxiv-id": "0911.4047v1", 
    "author": "M. Hermenegildo", 
    "publish": "2009-11-20T13:44:59Z", 
    "summary": "The most successful unfolding rules used nowadays in the partial evaluation\nof logic programs are based on well quasi orders (wqo) applied over (covering)\nancestors, i.e., a subsequence of the atoms selected during a derivation.\nAncestor (sub)sequences are used to increase the specialization power of\nunfolding while still guaranteeing termination and also to reduce the number of\natoms for which the wqo has to be checked. Unfortunately, maintaining the\nstructure of the ancestor relation during unfolding introduces significant\noverhead. We propose an efficient, practical local unfolding rule based on the\nnotion of covering ancestors which can be used in combination with a wqo and\nallows a stack-based implementation without losing any opportunities for\nspecialization. Using our technique, certain non-leftmost unfoldings are\nallowed as long as local unfolding is performed, i.e., we cover depth-first\nstrategies."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.13.2", 
    "link": "http://arxiv.org/pdf/0912.1899v1", 
    "title": "Markovian Testing Equivalence and Exponentially Timed Internal Actions", 
    "arxiv-id": "0912.1899v1", 
    "author": "Marco Bernardo", 
    "publish": "2009-12-10T01:51:14Z", 
    "summary": "In the theory of testing for Markovian processes developed so far,\nexponentially timed internal actions are not admitted within processes. When\npresent, these actions cannot be abstracted away, because their execution takes\na nonzero amount of time and hence can be observed. On the other hand, they\nmust be carefully taken into account, in order not to equate processes that are\ndistinguishable from a timing viewpoint. In this paper, we recast the\ndefinition of Markovian testing equivalence in the framework of a Markovian\nprocess calculus including exponentially timed internal actions. Then, we show\nthat the resulting behavioral equivalence is a congruence, has a sound and\ncomplete axiomatization, has a modal logic characterization, and can be decided\nin polynomial time."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.13.5", 
    "link": "http://arxiv.org/pdf/0912.1902v1", 
    "title": "Strong, Weak and Branching Bisimulation for Transition Systems and   Markov Reward Chains: A Unifying Matrix Approach", 
    "arxiv-id": "0912.1902v1", 
    "author": "Nikola Tr\u010dka", 
    "publish": "2009-12-10T01:52:07Z", 
    "summary": "We first study labeled transition systems with explicit successful\ntermination. We establish the notions of strong, weak, and branching\nbisimulation in terms of boolean matrix theory, introducing thus a novel and\npowerful algebraic apparatus. Next we consider Markov reward chains which are\nstandardly presented in real matrix theory. By interpreting the obtained matrix\nconditions for bisimulations in this setting, we automatically obtain the\ndefinitions of strong, weak, and branching bisimulation for Markov reward\nchains. The obtained strong and weak bisimulations are shown to coincide with\nsome existing notions, while the obtained branching bisimulation is new, but\nits usefulness is questionable."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.13", 
    "link": "http://arxiv.org/pdf/0912.2128v1", 
    "title": "Proceedings First Workshop on Quantitative Formal Methods: Theory and   Applications", 
    "arxiv-id": "0912.2128v1", 
    "author": "Manuel N\u00fa\u00f1ez", 
    "publish": "2009-12-10T23:40:35Z", 
    "summary": "This volume contains the papers presented at the 1st workshop on Quantitative\nFormal Methods: Theory and Applications, which was held in Eindhoven on 3\nNovember 2009 as part of the International Symposium on Formal Methods 2009.\nThis volume contains the final versions of all contributions accepted for\npresentation at the workshop."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/0912.4506v1", 
    "title": "Multicore-aware parallel temporal blocking of stencil codes for shared   and distributed memory", 
    "arxiv-id": "0912.4506v1", 
    "author": "Gerhard Wellein", 
    "publish": "2009-12-22T20:44:59Z", 
    "summary": "New algorithms and optimization techniques are needed to balance the\naccelerating trend towards bandwidth-starved multicore chips. It is well known\nthat the performance of stencil codes can be improved by temporal blocking,\nlessening the pressure on the memory interface. We introduce a new pipelined\napproach that makes explicit use of shared caches in multicore environments and\nminimizes synchronization and boundary overhead. For clusters of shared-memory\nnodes we demonstrate how temporal blocking can be employed successfully in a\nhybrid shared/distributed-memory environment."
},{
    "category": "cs.DC", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1001.1718v1", 
    "title": "Tiling for Performance Tuning on Different Models of GPUs", 
    "arxiv-id": "1001.1718v1", 
    "author": "Samantha Jenkins", 
    "publish": "2010-01-11T17:52:13Z", 
    "summary": "The strategy of using CUDA-compatible GPUs as a parallel computation solution\nto improve the performance of programs has been more and more widely approved\nduring the last two years since the CUDA platform was released. Its benefit\nextends from the graphic domain to many other computationally intensive\ndomains. Tiling, as the most general and important technique, is widely used\nfor optimization in CUDA programs. New models of GPUs with better compute\ncapabilities have, however, been released, new versions of CUDA SDKs were also\nreleased. These updated compute capabilities must to be considered when\noptimizing using the tiling technique. In this paper, we implement image\ninterpolation algorithms as a test case to discuss how different tiling\nstrategies affect the program's performance. We especially focus on how the\ndifferent models of GPUs affect the tiling's effectiveness by executing the\nsame program on two different models of GPUs equipped testing platforms. The\nresults demonstrate that an optimized tiling strategy on one GPU model is not\nalways a good solution when execute on other GPU models, especially when some\nexternal conditions were changed."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1001.1902v2", 
    "title": "RapidMind: Portability across Architectures and its Limitations", 
    "arxiv-id": "1001.1902v2", 
    "author": "Volker Weinberg", 
    "publish": "2010-01-12T18:11:23Z", 
    "summary": "Recently, hybrid architectures using accelerators like GPGPUs or the Cell\nprocessor have gained much interest in the HPC community. The RapidMind\nMulti-Core Development Platform is a programming environment that allows\ngenerating code which is able to seamlessly run on hardware accelerators like\nGPUs or the Cell processor and multicore CPUs both from AMD and Intel. This\npaper describes the ports of three mathematical kernels to RapidMind which are\nchosen as synthetic benchmarks and representatives of scientific codes.\nPerformance of these kernels has been measured on various RapidMind backends\n(cuda, cell and x86) and compared to other hardware-specific implementations\n(using CUDA, Cell SDK and Intel MKL). The results give an insight in the degree\nof portability of RapidMind code and code performance across different\narchitectures."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1001.2604v1", 
    "title": "On the Model Transform in Stochastic Network Calculus", 
    "arxiv-id": "1001.2604v1", 
    "author": "Jie Li", 
    "publish": "2010-01-15T03:12:55Z", 
    "summary": "Stochastic network calculus requires special care in the search of proper\nstochastic traffic arrival models and stochastic service models. Tradeoff must\nbe considered between the feasibility for the analysis of performance bounds,\nthe usefulness of performance bounds, and the ease of their numerical\ncalculation. In theory, transform between different traffic arrival models and\ntransform between different service models are possible. Nevertheless, the\nimpact of the model transform on performance bounds has not been thoroughly\ninvestigated. This paper is to investigate the effect of the model transform\nand to provide practical guidance in the model selection in stochastic network\ncalculus."
},{
    "category": "cs.DC", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1001.2931v3", 
    "title": "Towards Transactional Load over XtreemFS", 
    "arxiv-id": "1001.2931v3", 
    "author": "Jan Stender", 
    "publish": "2010-01-17T22:14:42Z", 
    "summary": "We propose using trace-based assessment of the performance of distributed\nfile systems (DFS) under transactional IO load. The assessment includes\nsimulations and experiments using the IO traces. Our experiments suggest that\nDFS, and specifically XtreemFS have a good potential to support transactional\nIO load in distributed environments: they demonstrate good performance, high\navailability and scalability, while at the same time opening the way to TCO\nreduction."
},{
    "category": "cs.DC", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1001.4108v2", 
    "title": "A Multi-Stage CUDA Kernel for Floyd-Warshall", 
    "arxiv-id": "1001.4108v2", 
    "author": "Justin W Smith", 
    "publish": "2010-01-23T00:22:33Z", 
    "summary": "We present a new implementation of the Floyd-Warshall All-Pairs Shortest\nPaths algorithm on CUDA. Our algorithm runs approximately 5 times faster than\nthe previously best reported algorithm. In order to achieve this speedup, we\napplied a new technique to reduce usage of on-chip shared memory and allow the\nCUDA scheduler to more effectively hide instruction latency."
},{
    "category": "cs.AI", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1002.0134v1", 
    "title": "Constraint solvers: An empirical evaluation of design decisions", 
    "arxiv-id": "1002.0134v1", 
    "author": "Lars Kotthoff", 
    "publish": "2010-01-31T15:36:36Z", 
    "summary": "This paper presents an evaluation of the design decisions made in four\nstate-of-the-art constraint solvers; Choco, ECLiPSe, Gecode, and Minion. To\nassess the impact of design decisions, instances of the five problem classes\nn-Queens, Golomb Ruler, Magic Square, Social Golfers, and Balanced Incomplete\nBlock Design are modelled and solved with each solver. The results of the\nexperiments are not meant to give an indication of the performance of a solver,\nbut rather investigate what influence the choice of algorithms and data\nstructures has.\n  The analysis of the impact of the design decisions focuses on the different\nways of memory management, behaviour with increasing problem size, and\nspecialised algorithms for specific types of variables. It also briefly\nconsiders other, less significant decisions."
},{
    "category": "cs.NI", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1002.1691v1", 
    "title": "Performance Evaluation of Unicast and Broadcast Mobile Ad hoc Network   Routing Protocols", 
    "arxiv-id": "1002.1691v1", 
    "author": "Nayeema Islam", 
    "publish": "2010-02-08T19:12:53Z", 
    "summary": "Efficient routing mechanism is a challenging issue for group oriented\ncomputing in Mobile Ad Hoc Networks (MANETs). The ability of MANETs to support\nadequate Quality of Service (QoS) for group communication is limited by the\nability of the underlying ad-hoc routing protocols to provide consistent\nbehavior despite the dynamic properties of mobile computing devices. In MANET\nQoS requirements can be quantified in terms of Packet Delivery Ratio (PDR),\nData Latency, Packet Loss Probability, Routing Overhead, Medium Access Control\n(MAC) Overhead and Data Throughput etc. This paper presents an in depth study\nof one to many and many to many communications in MANETs and provides a\ncomparative performance evaluation of unicast and broadcast routing protocols.\nDynamic Source Routing protocol (DSR) is used as unicast protocol and BCAST is\nused to represent broadcast protocol. The performance differentials are\nanalyzed using ns2 network simulator varying multicast group size (number of\ndata senders and data receivers). Both protocols are simulated with identical\ntraffic loads and mobility models. Simulation result shows that BCAST performs\nbetter than DSR in most cases."
},{
    "category": "cs.AR", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1002.1953v1", 
    "title": "Ahb Compatible DDR Sdram Controller Ip Core for Arm Based Soc", 
    "arxiv-id": "1002.1953v1", 
    "author": "C. S. Hemanthkumar", 
    "publish": "2010-02-09T19:47:34Z", 
    "summary": "DDR SDRAM is similar in function to the regular SDRAM but doubles the\nbandwidth of the memory by transferring data on both edges of the clock cycles.\nDDR SDRAM most commonly used in various embedded application like networking,\nimage or video processing, Laptops ete. Now a days many applications needs more\nand more cheap and fast memory. Especially in the field of signal processing,\nrequires significant amount of memory. The most used type of dynamic memory for\nthat purpose is DDR SDRAM. For FPGA design the IC manufacturers are providing\ncommercial memory controller IP cores working only on their products. Main\ndisadvantage is the lack of memory access optimization for random memory access\npatterns. The data path part of those controllers can be used free of charge.\nThis work propose an architecture of a DDR SDRAM controller, which takes\nadvantage of those available and well tested data paths and can be used for any\nFPGA device or ASIC design.(5). In most of the SOC design, DDR SDRAM is\ncommonly used. ARM processor is widely used in SOCs; so that we focused to\nimplement AHB compatible DDR SDRAM controller suitable for ARM based SOC\ndesign."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1002.2450v1", 
    "title": "Modeling the Probability of Failure on LDAP Binding Operations in   Iplanet Web Proxy 3.6 Server", 
    "arxiv-id": "1002.2450v1", 
    "author": "Alejandro Chinea Manrique de Lara", 
    "publish": "2010-02-11T23:20:40Z", 
    "summary": "This paper is devoted to the theoretical analysis of a problem derived from\ninteraction between two Iplanet products: Web Proxy Server and the Directory\nServer. In particular, a probabilistic and stochastic-approximation model is\nproposed to minimize the occurrence of LDAP connection failures in Iplanet Web\nProxy 3.6 Server. The proposed model serves not only to provide a\nparameterization of the aforementioned phenomena, but also to provide\nmeaningful insights illustrating and supporting these theoretical results. In\naddition, we shall also address practical considerations when estimating the\nparameters of the proposed model from experimental data. Finally, we shall\nprovide some interesting results from real-world data collected from our\ncustomers."
},{
    "category": "cs.DC", 
    "doi": "10.1109/IPDPSW.2010.5470813", 
    "link": "http://arxiv.org/pdf/1002.4264v1", 
    "title": "Automatic Performance Debugging of SPMD Parallel Programs", 
    "arxiv-id": "1002.4264v1", 
    "author": "Dan Meng", 
    "publish": "2010-02-23T08:17:43Z", 
    "summary": "Automatic performance debugging of parallel applications usually involves two\nsteps: automatic detection of performance bottlenecks and uncovering their root\ncauses for performance optimization. Previous work fails to resolve this\nchallenging issue in several ways: first, several previous efforts automate\nanalysis processes, but present the results in a confined way that only\nidentifies performance problems with apriori knowledge; second, several tools\ntake exploratory or confirmatory data analysis to automatically discover\nrelevant performance data relationships. However, these efforts do not focus on\nlocating performance bottlenecks or uncovering their root causes. In this\npaper, we design and implement an innovative system, AutoAnalyzer, to\nautomatically debug the performance problems of single program multi-data\n(SPMD) parallel programs. Our system is unique in terms of two dimensions:\nfirst, without any apriori knowledge, we automatically locate bottlenecks and\nuncover their root causes for performance optimization; second, our method is\nlightweight in terms of size of collected and analyzed performance data. Our\ncontribution is three-fold. First, we propose a set of simple performance\nmetrics to represent behavior of different processes of parallel programs, and\npresent two effective clustering and searching algorithms to locate\nbottlenecks. Second, we propose to use the rough set algorithm to automatically\nuncover the root causes of bottlenecks. Third, we design and implement the\nAutoAnalyzer system, and use two production applications to verify the\neffectiveness and correctness of our methods. According to the analysis results\nof AutoAnalyzer, we optimize two parallel programs with performance\nimprovements by minimally 20% and maximally 170%."
},{
    "category": "cs.DC", 
    "doi": "10.1109/DSN.2009.5270321", 
    "link": "http://arxiv.org/pdf/1003.0955v1", 
    "title": "Precise Request Tracing and Performance Debugging for Multi-tier   Services of Black Boxes", 
    "arxiv-id": "1003.0955v1", 
    "author": "Bo Sang", 
    "publish": "2010-03-04T06:51:51Z", 
    "summary": "As more and more multi-tier services are developed from commercial components\nor heterogeneous middleware without the source code available, both developers\nand administrators need a precise request tracing tool to help understand and\ndebug performance problems of large concurrent services of black boxes.\nPrevious work fails to resolve this issue in several ways: they either accept\nthe imprecision of probabilistic correlation methods, or rely on knowledge of\nprotocols to isolate requests in pursuit of tracing accuracy. This paper\nintroduces a tool named PreciseTracer to help debug performance problems of\nmulti-tier services of black boxes. Our contributions are two-fold: first, we\npropose a precise request tracing algorithm for multi-tier services of black\nboxes, which only uses application-independent knowledge; secondly, we present\na component activity graph abstraction to represent causal paths of requests\nand facilitate end-to-end performance debugging. The low overhead and tolerance\nof noise make PreciseTracer a promising tracing tool for using on production\nsystems."
},{
    "category": "cs.DC", 
    "doi": "10.1109/DSN.2009.5270321", 
    "link": "http://arxiv.org/pdf/1003.0958v4", 
    "title": "PhoenixCloud: Provisioning Resources for Heterogeneous Cloud Workloads", 
    "arxiv-id": "1003.0958v4", 
    "author": "Xiutao Zang", 
    "publish": "2010-03-04T03:26:26Z", 
    "summary": "As more and more service providers choose Cloud platforms, a resource\nprovider needs to provision resources and supporting runtime environments (REs)\nfor heterogeneous workloads in different scenarios. Previous work fails to\nresolve this issue in several ways: (1) it fails to pay attention to diverse RE\nrequirements, and does not enable creating coordinated REs on demand; (2) few\nwork investigates coordinated resource provisioning for heterogeneous\nworkloads. In this paper, our contributions are three-fold: (1) we present an\nRE agreement that expresses diverse RE requirements, and build an innovative\nsystem PhoenixCloud that enables a resource provider to create REs on demand\naccording to RE agreements; (2) we propose two coordinated resource\nprovisioning solutions for heterogeneous workloads in two typical Cloud\nscenarios: first, a large organization operates a private Cloud for two\nheterogeneous workloads; second, a large organization or two service providers\nrunning heterogeneous workloads revert to a public Cloud; and (3) A\ncomprehensive evaluation has been performed in experiments. For typical\nworkload traces of parallel batch jobs and Web services, our experiments show\nthat: a) In the first Cloud scenario, when the throughput is almost same like\nthat of a dedicated cluster system, our solution decreases the configuration\nsize of cluster by about 40%; b) in the second scenario, our solution decreases\nnot only the total resource consumption, but also the peak resource consumption\nmaximally to 31% with respect to that of EC2 + RightScale solution."
},{
    "category": "cs.DC", 
    "doi": "10.1109/DSN.2009.5270321", 
    "link": "http://arxiv.org/pdf/1003.0959v1", 
    "title": "Decreasing log data of multi-tier services for effective request tracing", 
    "arxiv-id": "1003.0959v1", 
    "author": "Guanhua Tian", 
    "publish": "2010-03-04T06:54:26Z", 
    "summary": "Previous work shows request tracing systems help understand and debug the\nperformance problems of multi-tier services. However, for large-scale data\ncenters, more than hundreds of thousands of service instances provide online\nservice at the same time. Previous work such as white-box or black box tracing\nsystems will produce large amount of log data, which would be correlated into\nlarge quantities of causal paths for performance debugging. In this paper, we\npropose an innovative algorithm to eliminate valueless logs of multitiers\nservices. Our experiment shows our method filters 84% valueless causal paths\nand is promising to be used in large-scale data centers."
},{
    "category": "cs.DC", 
    "doi": "10.1145/1646468.1646475", 
    "link": "http://arxiv.org/pdf/1003.1168v3", 
    "title": "In Cloud, Do MTC or HTC Service Providers Benefit from the Economies of   Scale?", 
    "arxiv-id": "1003.1168v3", 
    "author": "Lin Yuan", 
    "publish": "2010-03-05T00:10:19Z", 
    "summary": "In this paper, we intend to answer one key question to the success of cloud\ncomputing: in cloud, do many task computing (MTC) or high throughput computing\n(HTC) service providers, which offer the corresponding computing service to end\nusers, benefit from the economies of scale? Our research contributions are\nthree-fold: first, we propose an innovative usage model, called dynamic service\nprovision (DSP) model, for MTC or HTC service providers. In the DSP model, the\nresource provider provides the service of creating and managing runtime\nenvironments for MTC or HTC service providers, and consolidates heterogeneous\nMTC or HTC workloads on the cloud platform; second, according to the DSP model,\nwe design and implement DawningCloud, which provides automatic management for\nheterogeneous workloads; third, a comprehensive evaluation of DawningCloud has\nbeen performed in an emulatation experiment. We found that for typical\nworkloads, in comparison with the previous two cloud solutions, DawningCloud\nsaves the resource consumption maximally by 46.4% (HTC) and 74.9% (MTC) for the\nservice providers, and saves the total resource consumption maximally by 29.7%\nfor the resource provider. At the same time, comparing with the traditional\nsolution that provides MTC or HTC services with dedicated systems, DawningCloud\nis more cost-effective. To this end, we conclude that for typical MTC and HTC\nworkloads, on the cloud platform, MTC and HTC service providers and the\nresource provider can benefit from the economies of scale."
},{
    "category": "cs.NI", 
    "doi": "10.1145/1646468.1646475", 
    "link": "http://arxiv.org/pdf/1004.0263v1", 
    "title": "On Memory Accelerated Signal Processing within Software Defined Radios", 
    "arxiv-id": "1004.0263v1", 
    "author": "Mario Di Dio", 
    "publish": "2010-04-02T00:31:28Z", 
    "summary": "Since J. Mitola's work in 1992, Software Defined Radios (SDRs) have been\nquite a hot topic in wireless systems research. Though many notable\nachievements were reported in the field, the scarcity of computational power on\ngeneral purpose CPUs has always constrained their wide adoption in production\nenvironments. If conveniently applied within an SDR context, classical concepts\nknown in computer science as space/time tradeoffs can be extremely helpful when\ntrying to mitigate this problem. Inspired by and building on those concepts,\nthis paper presents a novel SDR implementation technique which we call Memory\nAcceleration (MA) that makes extensive use of the memory resources available on\na general purpose computing system, in order to accelerate signal computation.\nMA can provide substantial acceleration factors when applied to conventional\nSDRs without reducing their peculiar flexibility. As a practical proof of this,\nan example of MA applied in the real world to the ETSI DVB-T Viterbi decoder is\nprovided. Actually MA is shown able to provide, when applied to such Viterbi\ndecoder, an acceleration factor of 10.4x, with no impact on error correction\nperformances of the decoder and by making no use of any other typical\nperformance enhancement techniques such as low level (Assembler) programming or\nparallel computation, which though remain compatible with MA. Opportunity for\nextending the MA approach to the entire radio system, thus implementing what we\ncall a Memory-Based Software Defined Radio (MB-SDR) is finally considered and\ndiscussed."
},{
    "category": "cs.NI", 
    "doi": "10.1145/1646468.1646475", 
    "link": "http://arxiv.org/pdf/1004.0395v3", 
    "title": "Estimating Self-Sustainability in Peer-to-Peer Swarming Systems", 
    "arxiv-id": "1004.0395v3", 
    "author": "Arun Venkataramani", 
    "publish": "2010-04-02T21:55:11Z", 
    "summary": "Peer-to-peer swarming is one of the \\emph{de facto} solutions for distributed\ncontent dissemination in today's Internet. By leveraging resources provided by\nclients, swarming systems reduce the load on and costs to publishers. However,\nthere is a limit to how much cost savings can be gained from swarming; for\nexample, for unpopular content peers will always depend on the publisher in\norder to complete their downloads. In this paper, we investigate this\ndependence. For this purpose, we propose a new metric, namely \\emph{swarm\nself-sustainability}. A swarm is referred to as self-sustaining if all its\nblocks are collectively held by peers; the self-sustainability of a swarm is\nthe fraction of time in which the swarm is self-sustaining. We pose the\nfollowing question: how does the self-sustainability of a swarm vary as a\nfunction of content popularity, the service capacity of the users, and the size\nof the file? We present a model to answer the posed question. We then propose\nefficient solution methods to compute self-sustainability. The accuracy of our\nestimates is validated against simulation. Finally, we also provide closed-form\nexpressions for the fraction of time that a given number of blocks is\ncollectively held by peers."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1004.1741v1", 
    "title": "Efficient multicore-aware parallelization strategies for iterative   stencil computations", 
    "arxiv-id": "1004.1741v1", 
    "author": "Georg Hager", 
    "publish": "2010-04-10T20:56:21Z", 
    "summary": "Stencil computations consume a major part of runtime in many scientific\nsimulation codes. As prototypes for this class of algorithms we consider the\niterative Jacobi and Gauss-Seidel smoothers and aim at highly efficient\nparallel implementations for cache-based multicore architectures. Temporal\ncache blocking is a known advanced optimization technique, which can reduce the\npressure on the memory bus significantly. We apply and refine this optimization\nfor a recently presented temporal blocking strategy designed to explicitly\nutilize multicore characteristics. Especially for the case of Gauss-Seidel\nsmoothers we show that simultaneous multi-threading (SMT) can yield substantial\nperformance improvements for our optimized algorithm."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1004.4431v3", 
    "title": "LIKWID: A lightweight performance-oriented tool suite for x86 multicore   environments", 
    "arxiv-id": "1004.4431v3", 
    "author": "Gerhard Wellein", 
    "publish": "2010-04-26T08:33:25Z", 
    "summary": "Exploiting the performance of today's processors requires intimate knowledge\nof the microarchitecture as well as an awareness of the ever-growing complexity\nin thread and cache topology. LIKWID is a set of command-line utilities that\naddresses four key problems: Probing the thread and cache topology of a\nshared-memory node, enforcing thread-core affinity on a program, measuring\nperformance counter metrics, and toggling hardware prefetchers. An API for\nusing the performance counting features from user code is also included. We\nclearly state the differences to the widely used PAPI interface. To demonstrate\nthe capabilities of the tool set we show the influence of thread pinning on\nperformance using the well-known OpenMP STREAM triad benchmark, and use the\naffinity and hardware counter tools to study the performance of a stencil code\nspecifically optimized to utilize shared caches on multicore chips."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1005.0178v2", 
    "title": "Analysis of Non-Persistent CSMA Protocols with Exponential Backoff   Scheduling", 
    "arxiv-id": "1005.0178v2", 
    "author": "Tony T. Lee", 
    "publish": "2010-05-03T03:07:59Z", 
    "summary": "This paper studies the performance of Non-persistent CSMA/CA protocols with\nK-Exponential Backoff scheduling algorithms. A multi-queue single-server system\nis proposed to model multiple access networks. The input buffer of each access\nnode is modeled as a Geo/G/1 queue, and the service time distribution of\nhead-of-line packets is derived from the Markov chain of underlying scheduling\nalgorithm. The main results include the complete analysis of the throughput and\ndelay distribution, from which we obtained stable regions with respect to the\nthroughput and bounded mean delay of the Geometric Retransmission and\nExponential Backoff schemes. We show that the throughput stable region of\nGeometric Retransmission will vanish as the number of nodes n \\rightarrow\n\\infty; thus, it is inherently unstable for large n. In contrast to Geometric\nRetransmission, the throughput stable region of Exponential Backoff can be\nobtained for an infinite population. We found that the bounded mean delay\nregion of Geometric Retransmission remains the same as its throughput stable\nregion. Besides, the variance of service time of Exponential Backoff can be\nunbounded due to the capture effect; thus, its bounded delay region is only a\nsub-set of its throughput stable region. Analytical results presented in this\npaper are all verified by simulation."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1005.5241v1", 
    "title": "Simulation de traces r\u00e9elles d'E/S disque de PC", 
    "arxiv-id": "1005.5241v1", 
    "author": "Timsit Claude", 
    "publish": "2010-05-28T08:55:12Z", 
    "summary": "Under Windows operating system, existing I/O benchmarking tools does not\nallow a developer to efficiently define a file access strategy according to the\napplications' constraints. This is essentially due to the fact that the\nexisting tools do allow only a restricted set of I/O workloads that does not\ngenerally correspond to the target applications. To cope with this problem, we\ndesigned and implemented a precise I/O simulator allowing to simulate whatever\nreal I/O trace on a given defined architecture, and in which most of file and\ndisk cache strategies, their interactions and the detailed storage system\narchitecture are implemented. Simulation results on different workloads and\narchitectures show a very high degree of precision. In fact, the mean error\nrate as compared to real measures is of about 6% with a maximum of 10% on\nglobal throughput."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1006.3148v1", 
    "title": "Leveraging shared caches for parallel temporal blocking of stencil codes   on multicore processors and clusters", 
    "arxiv-id": "1006.3148v1", 
    "author": "Gerhard Wellein", 
    "publish": "2010-06-16T07:35:38Z", 
    "summary": "Bandwidth-starved multicore chips have become ubiquitous. It is well known\nthat the performance of stencil codes can be improved by temporal blocking,\nlessening the pressure on the memory interface. We introduce a new pipelined\napproach that makes explicit use of shared caches in multicore environments and\nminimizes synchronization and boundary overhead. Benchmark results are\npresented for three current x86-based microprocessors, showing clearly that our\noptimization works best on designs with high-speed shared caches and low memory\nbandwidth per core. We furthermore demonstrate that simple bandwidth-based\nperformance models are inaccurate for this kind of algorithm and employ a more\nelaborate, synthetic modeling procedure. Finally we show that temporal blocking\ncan be employed successfully in a hybrid shared/distributed-memory environment,\nalbeit with limited benefit at strong scaling."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1006.4228v1", 
    "title": "Sustainable Throughput of Wireless LANs with Multi-Packet Reception   Capability under Bounded Delay-Moment Requirements", 
    "arxiv-id": "1006.4228v1", 
    "author": "Darui Chen", 
    "publish": "2010-06-22T08:40:24Z", 
    "summary": "With the rapid proliferation of broadband wireless services, it is of\nparamount importance to understand how fast data can be sent through a wireless\nlocal area network (WLAN). Thanks to a large body of research following the\nseminal work of Bianchi, WLAN throughput under saturated traffic condition has\nbeen well understood. By contrast, prior investigations on throughput\nperformance under unsaturated traffic condition was largely based on\nphenomenological observations, which lead to a common misconception that WLAN\ncan support a traffic load as high as saturation throughput, if not higher,\nunder non-saturation condition. In this paper, we show through rigorous\nanalysis that this misconception may result in unacceptable quality of service:\nmean packet delay and delay jitter may approach infinity even when the traffic\nload is far below the saturation throughput. Hence, saturation throughput is\nnot a sound measure of WLAN capacity under non-saturation condition. To bridge\nthe gap, we define safe-bounded-mean-delay (SBMD) throughput and\nsafe-bounded-delay-jitter (SBDJ) throughput that reflect the actual network\ncapacity users can enjoy when they require finite mean delay and delay jitter,\nrespectively.\n  Our earlier work proved that in a WLAN with multi-packet reception (MPR)\ncapability, saturation throughput scales super-linearly with the MPR capability\nof the network. This paper extends the investigation to the non-saturation case\nand shows that super-linear scaling also holds for SBMD and SBDJ throughputs.\nOur results here complete the demonstration of MPR as a powerful\ncapacity-enhancement technique for WLAN under both saturation and\nnon-saturation conditions."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jocs.2011.01.010", 
    "link": "http://arxiv.org/pdf/1006.4946v1", 
    "title": "A Virtual Queue Approach for Online Estimation of Loss Probability Based   on MVA Theory", 
    "arxiv-id": "1006.4946v1", 
    "author": "Anne Nevin", 
    "publish": "2010-06-25T09:47:27Z", 
    "summary": "In network quality of service provisioning, premium services generally\nrequire to keep a very small loss probability, which is infeasible to measure\ndirectly. The proposed virtual queue scheme estimates the small packet loss\nprobability of a real queueing system by measuring queue statistics in a set of\nseparate virtual queues. A novel scaling property between the real queue and\nthe virtual queues is deduced on the basis of the maximum variance asymptotic\n(MVA) theory. The new scheme retains the high accuracy and wide applicability\nof the MVA method for aggregated traffic while avoiding the high computational\ncomplexity in a direct application of the original MVA analysis in real time.\nThis makes it suitable for online measurement applications such as network\nperformance monitoring and measurement-based admission control."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1006.5095v1", 
    "title": "Performance Evaluation of Components Using a Granularity-based Interface   Between Real-Time Calculus and Timed Automata", 
    "arxiv-id": "1006.5095v1", 
    "author": "Matthieu Moy", 
    "publish": "2010-06-26T03:03:05Z", 
    "summary": "To analyze complex and heterogeneous real-time embedded systems, recent works\nhave proposed interface techniques between real-time calculus (RTC) and timed\nautomata (TA), in order to take advantage of the strengths of each technique\nfor analyzing various components. But the time to analyze a state-based\ncomponent modeled by TA may be prohibitively high, due to the state space\nexplosion problem. In this paper, we propose a framework of granularity-based\ninterfacing to speed up the analysis of a TA modeled component. First, we\nabstract fine models to work with event streams at coarse granularity. We\nperform analysis of the component at multiple coarse granularities and then\nbased on RTC theory, we derive lower and upper bounds on arrival patterns of\nthe fine output streams using the causality closure algorithm. Our framework\ncan help to achieve tradeoffs between precision and analysis time."
},{
    "category": "math.PR", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1006.5691v4", 
    "title": "A Fluid Limit for an Overloaded X Model Via a Stochastic Averaging   Principle", 
    "arxiv-id": "1006.5691v4", 
    "author": "Ward Whitt", 
    "publish": "2010-06-29T17:55:51Z", 
    "summary": "We prove a many-server heavy-traffic fluid limit for an overloaded Markovian\nqueueing system having two customer classes and two service pools, known in the\ncall-center literature as the X model. The system uses the\nfixed-queue-ratio-with-thresholds (FQR-T) control, which we proposed in a\nrecent paper as a way for one service system to help another in face of an\nunexpected overload. Under FQR-T, customers are served by their own service\npool until a threshold is exceeded. Then, one-way sharing is activated with\ncustomers from one class allowed to be served in both pools. After the control\nis activated, it aims to keep the two queues at a pre-specified fixed ratio.\nFor large systems that fixed ratio is achieved approximately. For the fluid\nlimit, or FWLLN, we consider a sequence of properly scaled X models in overload\noperating under FQR-T. Our proof of the FWLLN follows the compactness approach,\ni.e., we show that the sequence of scaled processes is tight, and then show\nthat all converging subsequences have the specified limit. The characterization\nstep is complicated because the queue-difference processes, which determine the\ncustomer-server assignments, remain stochastically bounded, and need to be\nconsidered without spatial scaling. Asymptotically, these queue-difference\nprocesses operate in a faster time scale than the fluid-scaled processes. In\nthe limit, due to a separation of time scales, the driving processes converge\nto a time-dependent steady state (or local average) of a time-varying\nfast-time-scale process (FTSP). This averaging principle (AP) allows us to\nreplace the driving processes with the long-run average behavior of the FTSP."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1008.0050v1", 
    "title": "A Foundation for Stochastic Bandwidth Estimation of Networks with Random   Service", 
    "arxiv-id": "1008.0050v1", 
    "author": "J\u00f6rg Liebeherr", 
    "publish": "2010-07-31T05:21:12Z", 
    "summary": "We develop a stochastic foundation for bandwidth estimation of networks with\nrandom service, where bandwidth availability is expressed in terms of bounding\nfunctions with a defined violation probability. Exploiting properties of a\nstochastic max-plus algebra and system theory, the task of bandwidth estimation\nis formulated as inferring an unknown bounding function from measurements of\nprobing traffic. We derive an estimation methodology that is based on iterative\nconstant rate probes. Our solution provides evidence for the utility of packet\ntrains for bandwidth estimation in the presence of variable cross traffic.\nTaking advantage of statistical methods, we show how our estimation method can\nbe realized in practice, with adaptive train lengths of probe packets, probing\nrates, and replicated measurements required to achieve both high accuracy and\nconfidence levels. We evaluate our method in a controlled testbed network,\nwhere we show the impact of cross traffic variability on the time-scales of\nservice availability, and provide a comparison with existing bandwidth\nestimation tools."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1008.0227v1", 
    "title": "Fast Mixing of Parallel Glauber Dynamics and Low-Delay CSMA Scheduling", 
    "arxiv-id": "1008.0227v1", 
    "author": "Jean Walrand", 
    "publish": "2010-08-02T05:28:27Z", 
    "summary": "Glauber dynamics is a powerful tool to generate randomized, approximate\nsolutions to combinatorially difficult problems. It has been used to analyze\nand design distributed CSMA (Carrier Sense Multiple Access) scheduling\nalgorithms for multi-hop wireless networks. In this paper we derive bounds on\nthe mixing time of a generalization of Glauber dynamics where multiple links\nare allowed to update their states in parallel and the fugacity of each link\ncan be different. The results can be used to prove that the average queue\nlength (and hence, the delay) under the parallel Glauber dynamics based CSMA\ngrows polynomially in the number of links for wireless networks with\nbounded-degree interference graphs when the arrival rate lies in a fraction of\nthe capacity region. We also show that in specific network topologies, the\nlow-delay capacity region can be further improved."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1008.1571v1", 
    "title": "Scaling Turbo Boost to a 1000 cores", 
    "arxiv-id": "1008.1571v1", 
    "author": "Alexandra Fedorova", 
    "publish": "2010-08-09T19:23:10Z", 
    "summary": "The Intel Core i7 processor code named Nehalem provides a feature named Turbo\nBoost which opportunistically varies the frequencies of the processor's cores.\nThe frequency of a core is determined by core temperature, the number of active\ncores, the estimated power consumption, the estimated current consumption, and\noperating system frequency scaling requests. For a chip multi-processor(CMP)\nthat has a small number of physical cores and a small set of performance\nstates, deciding the Turbo Boost frequency to use on a given core might not be\ndifficult. However, we do not know the complexity of this decision making\nprocess in the context of a large number of cores, scaling to the 100s, as\npredicted by researchers in the field."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1008.1628v4", 
    "title": "Performance Analysis of Markov Modulated 1-Persistent CSMA/CA Protocols   with Exponential Backoff Scheduling", 
    "arxiv-id": "1008.1628v4", 
    "author": "Tony T. Lee", 
    "publish": "2010-08-10T04:15:04Z", 
    "summary": "This paper proposes a Markovian model of 1-persistent CSMA/CA protocols with\nK-Exponential Backoff scheduling algorithms. The input buffer of each access\nnode is modeled as a Geo/G/1 queue, and the service time distribution of each\nindividual head-of-line packet is derived from the Markov chain of the\nunderlying scheduling algorithm. From the queuing model, we derive the\ncharacteristic equation of network throughput and obtain the stable throughput\nand bounded delay regions with respect to the retransmission factor. Our\nresults show that the stable throughput region of the exponential backoff\nscheme exists even for an infinite population. Moreover, we find that the\nbounded delay region of exponential backoff is only a sub-set of its stable\nthroughput region due to the large variance of the service time of input\npackets caused by the capture effect. All analytical results presented in this\npaper are verified by simulations."
},{
    "category": "cs.DS", 
    "doi": "10.4204/EPTCS.28.2", 
    "link": "http://arxiv.org/pdf/1008.2849v2", 
    "title": "Faster Radix Sort via Virtual Memory and Write-Combining", 
    "arxiv-id": "1008.2849v2", 
    "author": "Peter Sanders", 
    "publish": "2010-08-17T08:39:59Z", 
    "summary": "Sorting algorithms are the deciding factor for the performance of common\noperations such as removal of duplicates or database sort-merge joins. This\nwork focuses on 32-bit integer keys, optionally paired with a 32-bit value. We\npresent a fast radix sorting algorithm that builds upon a\nmicroarchitecture-aware variant of counting sort. Taking advantage of virtual\nmemory and making use of write-combining yields a per-pass throughput\ncorresponding to at least 88 % of the system's peak memory bandwidth. Our\nimplementation outperforms Intel's recently published radix sort by a factor of\n1.5. It also compares favorably to the reported performance of an algorithm for\nFermi GPUs when data-transfer overhead is included. These results indicate that\nscalar, bandwidth-sensitive sorting algorithms remain competitive on current\narchitectures. Various other memory-intensive applications can benefit from the\ntechniques described herein."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2010.2315", 
    "link": "http://arxiv.org/pdf/1008.3681v1", 
    "title": "EVM as generic QoS trigger for heterogeneous wieless overlay network", 
    "arxiv-id": "1008.3681v1", 
    "author": "Brahmjit Singh", 
    "publish": "2010-08-22T07:55:24Z", 
    "summary": "Fourth Generation (4G) Wireless System will integrate heterogeneous wireless\noverlay systems i.e. interworking of WLAN/ GSM/ CDMA/ WiMAX/ LTE/ etc with\nguaranteed Quality of Service (QoS) and Experience (QoE).QoS(E) vary from\nnetwork to network and is application sensitive. User needs an optimal mobility\nsolution while roaming in Overlaid wireless environment i.e. user could\nseamlessly transfer his session/ call to a best available network bearing\nguaranteed Quality of Experience. And If this Seamless transfer of session is\nexecuted between two networks having different access standards then it is\ncalled Vertical Handover (VHO). Contemporary VHO decision algorithms are based\non generic QoS metrics viz. SNR, bandwidth, jitter, BER and delay. In this\npaper, Error Vector Magnitude (EVM) is proposed to be a generic QoS trigger for\nVHO execution. EVM is defined as the deviation of inphase/ quadrature (I/Q)\nvalues from ideal signal states and thus provides a measure of signal quality.\nIn 4G Interoperable environment, OFDM is the leading Modulation scheme (more\nprone to multi-path fading). EVM (modulation error) properly characterises the\nwireless link/ channel for accurate VHO decision. EVM depends on the inherent\ntransmission impairments viz. frequency offset, phase noise,\nnon-linear-impairment, skewness etc. for a given wireless link. Paper provides\nan insight to the analytical aspect of EVM & measures EVM (%) for key\nmanagement subframes like association/re-association/disassociation/ probe\nrequest/response frames. EVM relation is explored for different possible\nNAV-Network Allocation Vectors (frame duration). Finally EVM is compared with\nSNR, BER and investigation concludes EVM as a promising QoS trigger for OFDM\nbased emerging wireless standards."
},{
    "category": "cs.SY", 
    "doi": "10.1109/INFCOM.2011.5935204", 
    "link": "http://arxiv.org/pdf/1008.3932v2", 
    "title": "Multiple Timescale Dispatch and Scheduling for Stochastic Reliability in   Smart Grids with Wind Generation Integration", 
    "arxiv-id": "1008.3932v2", 
    "author": "Junshan Zhang", 
    "publish": "2010-08-23T22:35:47Z", 
    "summary": "Integrating volatile renewable energy resources into the bulk power grid is\nchallenging, due to the reliability requirement that at each instant the load\nand generation in the system remain balanced. In this study, we tackle this\nchallenge for smart grid with integrated wind generation, by leveraging\nmulti-timescale dispatch and scheduling. Specifically, we consider smart grids\nwith two classes of energy users - traditional energy users and opportunistic\nenergy users (e.g., smart meters or smart appliances), and investigate pricing\nand dispatch at two timescales, via day-ahead scheduling and realtime\nscheduling. In day-ahead scheduling, with the statistical information on wind\ngeneration and energy demands, we characterize the optimal procurement of the\nenergy supply and the day-ahead retail price for the traditional energy users;\nin realtime scheduling, with the realization of wind generation and the load of\ntraditional energy users, we optimize real-time prices to manage the\nopportunistic energy users so as to achieve systemwide reliability. More\nspecifically, when the opportunistic users are non-persistent, i.e., a subset\nof them leave the power market when the real-time price is not acceptable, we\nobtain closedform solutions to the two-level scheduling problem. For the\npersistent case, we treat the scheduling problem as a multitimescale Markov\ndecision process. We show that it can be recast, explicitly, as a classic\nMarkov decision process with continuous state and action spaces, the solution\nto which can be found via standard techniques. We conclude that the proposed\nmulti-scale dispatch and scheduling with real-time pricing can effectively\naddress the volatility and uncertainty of wind generation and energy demand,\nand has the potential to improve the penetration of renewable energy into smart\ngrids."
},{
    "category": "cs.NI", 
    "doi": "10.1109/INFCOM.2011.5935204", 
    "link": "http://arxiv.org/pdf/1009.0386v1", 
    "title": "Analyzing the performance of probabilistic algorithm in noisy manets", 
    "arxiv-id": "1009.0386v1", 
    "author": "Khalid Kaabneh", 
    "publish": "2010-09-02T10:51:33Z", 
    "summary": "Probabilistic broadcast has been widely used as a flooding optimization\nmechanism to alleviate the effect of broadcast storm problem (BSP) in mobile ad\nhoc networks (MANETs). Many research studies have been carried-out to develop\nand evaluate the performance of this mechanism in an error-free (noiseless)\nenvironment. In reality, wireless communication channels in MANETs are an\nerror-prone and suffer from high packet-loss due to presence of noise, i.e.,\nnoisy environment. In this paper, we propose a simulation model that can be\nused to evaluate the performance of probabilistic broadcast for flooding in\nnoisy environment. In the proposed model, the noise-level is represented by a\ngeneric name, probability of reception (pc) (0<=pc<=1), where pc=1 for\nnoiseless and <1 for noisy environment. The effect of noise is determined\nrandomly by generating a random number \\zeta (0<=\\zeta<1); if \\zeta<=pc means\nthe packet is successfully delivered to the receiving node, otherwise,\nunsuccessful delivery occurs. The proposed model is implemented on a MANET\nsimulator, namely, MANSim. The effect of noise on the performance of\nprobabilistic algorithm was investigated in four scenarios. The main\nconclusions of these scenarios are: the performance of probabilistic algorithm\nsuffers in presence of noise. However, this suffering is less in high density\nnetworks, or if the nodes characterized by high retransmission probability or\nlarge radio transmission range. The nodes' speed has no or insignificant effect\non the performance."
},{
    "category": "cs.NI", 
    "doi": "10.1109/INFCOM.2011.5935204", 
    "link": "http://arxiv.org/pdf/1009.0389v1", 
    "title": "Performance Evaluation of an OMPR Algorithm for Route Discovery in Noisy   MANETs", 
    "arxiv-id": "1009.0389v1", 
    "author": "Rami Jaradat", 
    "publish": "2010-09-02T10:58:42Z", 
    "summary": "It has been revealed in the literature that pure multipoint relaying (MPR)\nalgorithms demonstrate both simplicity and outstanding performance, as compared\nto other flooding algorithms in wireless networks. One drawback of pure MPR\nalgorithms is that the selected forwarding set may not represent the optimum\nselection. In addition, little efforts have been carried-out to investigate the\nperformance of such algorithms in noisy mobile ad hoc networks (MANETs)\nsuffering from high packet-loss and node mobility. In this paper, we develop\nand evaluate the performance of an optimal MPR (OMPR) algorithm for route\ndiscovery in noisy MANETs. The main feature of this new algorithm is that it\ncalculates all possible sets of multipoint relays (MPRs) and then selects the\nset with minimum number of nodes. The algorithm demonstrates an excellent\nperformance when it is compared with other route discovery algorithms as it\nachieves the highest cost-effective reachability."
},{
    "category": "cs.CC", 
    "doi": "10.1109/TC.2011.110", 
    "link": "http://arxiv.org/pdf/1009.4597v2", 
    "title": "On Polynomial Multiplication in Chebyshev Basis", 
    "arxiv-id": "1009.4597v2", 
    "author": "Pascal Giorgi", 
    "publish": "2010-09-23T12:53:25Z", 
    "summary": "In a recent paper Lima, Panario and Wang have provided a new method to\nmultiply polynomials in Chebyshev basis which aims at reducing the total number\nof multiplication when polynomials have small degree. Their idea is to use\nKaratsuba's multiplication scheme to improve upon the naive method but without\nbeing able to get rid of its quadratic complexity. In this paper, we extend\ntheir result by providing a reduction scheme which allows to multiply\npolynomial in Chebyshev basis by using algorithms from the monomial basis case\nand therefore get the same asymptotic complexity estimate. Our reduction allows\nto use any of these algorithms without converting polynomials input to monomial\nbasis which therefore provide a more direct reduction scheme then the one using\nconversions. We also demonstrate that our reduction is efficient in practice,\nand even outperform the performance of the best known algorithm for Chebyshev\nbasis when polynomials have large degree. Finally, we demonstrate a linear time\nequivalence between the polynomial multiplication problem under monomial basis\nand under Chebyshev basis."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TC.2011.110", 
    "link": "http://arxiv.org/pdf/1010.0630v1", 
    "title": "Performance of wireless network coding: motivating small encoding   numbers", 
    "arxiv-id": "1010.0630v1", 
    "author": "Lazaros Gkatzikis", 
    "publish": "2010-10-04T15:44:44Z", 
    "summary": "This paper focuses on a particular transmission scheme called local network\ncoding, which has been reported to provide significant performance gains in\npractical wireless networks. The performance of this scheme strongly depends on\nthe network topology and thus on the locations of the wireless nodes. Also, it\nhas been shown previously that finding the encoding strategy, which achieves\nmaximum performance, requires complex calculations to be undertaken by the\nwireless node in real-time.\n  Both deterministic and random point pattern are explored and using the\nBoolean connectivity model we provide upper bounds for the maximum coding\nnumber, i.e., the number of packets that can be combined such that the\ncorresponding receivers are able to decode. For the models studied, this upper\nbound is of order of $\\sqrt{N}$, where $N$ denotes the (mean) number of\nneighbors. Moreover, achievable coding numbers are provided for grid-like\nnetworks. We also calculate the multiplicative constants that determine the\ngain in case of a small network. Building on the above results, we provide an\nanalytic expression for the upper bound of the efficiency of local network\ncoding. The conveyed message is that it is favorable to reduce computational\ncomplexity by relying only on small encoding numbers since the resulting\nexpected throughput loss is negligible."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TC.2011.110", 
    "link": "http://arxiv.org/pdf/1010.4475v1", 
    "title": "State Dependent Attempt Rate Modeling of Single Cell IEEE~802.11 WLANs   with Homogeneous Nodes and Poisson Packet Arrivals", 
    "arxiv-id": "1010.4475v1", 
    "author": "Anurag Kumar", 
    "publish": "2010-10-21T14:03:18Z", 
    "summary": "Analytical models for IEEE 802.11-based WLANs are invariably based on\napproximations, such as the well-known \\textit{decoupling approximation}\nproposed by Bianchi for modeling single cell WLANs consisting of saturated\nnodes. In this paper, we provide a new approach to model the situation when the\nnodes are not saturated. We study a State Dependent Attempt Rate (SDAR)\napproximation to model $M$ queues (one queue per node) served by the CSMA/CA\nprotocol as standardized in the IEEE 802.11 DCF MAC protocol. The approximation\nis that, when $n$ of the $M$ queues are non-empty, the transmission attempt\nprobability of the $n$ non-empty nodes is given by the long-term transmission\nattempt probability of $n$ \"saturated\" nodes as provided by Bianchi's model.\nThe SDAR approximation reduces a single cell WLAN with non-saturated nodes to a\n\"coupled queue system\". When packets arrive to the $M$ queues according to\nindependent Poisson processes, we provide a Markov model for the coupled queue\nsystem with SDAR service. \\textit{The main contribution of this paper is to\nprovide an analysis of the coupled queue process by studying a lower\ndimensional process, and by introducing a certain conditional independence\napproximation}. We show that the SDAR model of contention provides an accurate\nmodel for the DCF MAC protocol in single cells, and report the simulation\nspeed-ups thus obtained by our \\textit{model-based simulation}."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TC.2011.110", 
    "link": "http://arxiv.org/pdf/1011.0235v1", 
    "title": "Fast Histograms using Adaptive CUDA Streams", 
    "arxiv-id": "1011.0235v1", 
    "author": "Babu Narayanan", 
    "publish": "2010-11-01T01:26:11Z", 
    "summary": "Histograms are widely used in medical imaging, network intrusion detection,\npacket analysis and other stream-based high throughput applications. However,\nwhile porting such software stacks to the GPU, the computation of the histogram\nis a typical bottleneck primarily due to the large impact on kernel speed by\natomic operations. In this work, we propose a stream-based model implemented in\nCUDA, using a new adaptive kernel that can be optimized based on latency hidden\nCPU compute. We also explore the tradeoffs of using the new kernel vis-\\`a-vis\nthe stock NVIDIA SDK kernel, and discuss an intelligent kernel switching method\nfor the stream based on a degeneracy criterion that is adaptively computed from\nthe input stream."
},{
    "category": "cs.AI", 
    "doi": "10.1109/TC.2011.110", 
    "link": "http://arxiv.org/pdf/1011.3595v1", 
    "title": "Optimizing real-time RDF data streams", 
    "arxiv-id": "1011.3595v1", 
    "author": "Joshua Shinavier", 
    "publish": "2010-11-16T07:17:53Z", 
    "summary": "The Resource Description Framework (RDF) provides a common data model for the\nintegration of \"real-time\" social and sensor data streams with the Web and with\neach other. While there exist numerous protocols and data formats for\nexchanging dynamic RDF data, or RDF updates, these options should be examined\ncarefully in order to enable a Semantic Web equivalent of the high-throughput,\nlow-latency streams of typical Web 2.0, multimedia, and gaming applications.\nThis paper contains a brief survey of RDF update formats and a high-level\ndiscussion of both TCP and UDP-based transport protocols for updates. Its main\ncontribution is the experimental evaluation of a UDP-based architecture which\nserves as a real-world example of a high-performance RDF streaming application\nin an Internet-scale distributed environment."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TC.2011.110", 
    "link": "http://arxiv.org/pdf/1011.5317v2", 
    "title": "Performance of CSMA in Multi-Channel Wireless Networks", 
    "arxiv-id": "1011.5317v2", 
    "author": "Mathieu Feuillet", 
    "publish": "2010-11-24T08:42:07Z", 
    "summary": "We analyze the performance of CSMA in multi-channel wireless networks,\naccounting for the random nature of traffic. Specifically, we assess the\nability of CSMA to fully utilize the radio resources and in turn to stabilize\nthe network in a dynamic setting with flow arrivals and departures. We prove\nthat CSMA is optimal in ad-hoc mode but not in infrastructure mode, when all\ndata flows originate from or are destined to some access points, due to the\ninherent bias of CSMA against downlink traffic. We propose a slight\nmodification of CSMA, that we refer to as flow-aware CSMA, which corrects this\nbias and makes the algorithm optimal in all cases. The analysis is based on\nsome time-scale separation assumption which is proved valid in the limit of\nlarge flow sizes."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TNET.2012.2227790", 
    "link": "http://arxiv.org/pdf/1011.5674v3", 
    "title": "Delay-Based Back-Pressure Scheduling in Multihop Wireless Networks", 
    "arxiv-id": "1011.5674v3", 
    "author": "Ness B. Shroff", 
    "publish": "2010-11-25T19:25:41Z", 
    "summary": "Scheduling is a critical and challenging resource allocation mechanism for\nmultihop wireless networks. It is well known that scheduling schemes that favor\nlinks with larger queue length can achieve high throughput performance.\nHowever, these queue-length-based schemes could potentially suffer from large\n(even infinite) packet delays due to the well-known last packet problem,\nwhereby packets belonging to some flows may be excessively delayed due to lack\nof subsequent packet arrivals. Delay-based schemes have the potential to\nresolve this last packet problem by scheduling the link based on the delay the\npacket has encountered. However, characterizing throughput-optimality of these\ndelay-based schemes has largely been an open problem in multihop wireless\nnetworks (except in limited cases where the traffic is single-hop.) In this\npaper, we investigate delay-based scheduling schemes for multihop traffic\nscenarios with fixed routes. We develop a scheduling scheme based on a new\ndelay metric, and show that the proposed scheme achieves optimal throughput\nperformance. Further, we conduct simulations to support our analytical results,\nand show that the delay-based scheduler successfully removes excessive packet\ndelays, while it achieves the same throughput region as the queue-length-based\nscheme."
},{
    "category": "cs.PL", 
    "doi": "10.1109/TNET.2012.2227790", 
    "link": "http://arxiv.org/pdf/1011.6223v3", 
    "title": "Just-In-Time compilation of OCaml byte-code", 
    "arxiv-id": "1011.6223v3", 
    "author": "Benedikt Meurer", 
    "publish": "2010-11-29T13:24:11Z", 
    "summary": "This paper presents various improvements that were applied to OCamlJIT2, a\nJust-In-Time compiler for the OCaml byte-code virtual machine. OCamlJIT2\ncurrently runs on various Unix-like systems with x86 or x86-64 processors. The\nimprovements, including the new x86 port, are described in detail, and\nperformance measures are given, including a direct comparison of OCamlJIT2 to\nOCamlJIT."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TNET.2012.2227790", 
    "link": "http://arxiv.org/pdf/1101.1237v1", 
    "title": "Statistical Analysis of Link Scheduling on Long Paths", 
    "arxiv-id": "1101.1237v1", 
    "author": "Almut Burchard", 
    "publish": "2011-01-06T15:47:59Z", 
    "summary": "We study how the choice of packet scheduling algorithms influences end-to-end\nperformance on long network paths. Taking a network calculus approach, we\nconsider both deterministic and statistical performance metrics. A key enabling\ncontribution for our analysis is a significantly sharpened method for computing\na statistical bound for the service given to a flow by the network as a whole.\nFor a suitably parsimonious traffic model we develop closed-form expressions\nfor end-to-end delays, backlog, and output burstiness. The deterministic\nversions of our bounds yield optimal bounds on end-to-end backlog and output\nburstiness for some schedulers, and are highly accurate for end-to-end delay\nbounds."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TNET.2012.2227790", 
    "link": "http://arxiv.org/pdf/1102.3058v1", 
    "title": "Maximizing Cloud Providers Revenues via Energy Aware Allocation Policies", 
    "arxiv-id": "1102.3058v1", 
    "author": "Ralph Deters", 
    "publish": "2011-02-15T12:56:25Z", 
    "summary": "Cloud providers, like Amazon, offer their data centers' computational and\nstorage capacities for lease to paying customers. High electricity consumption,\nassociated with running a data center, not only reflects on its carbon\nfootprint, but also increases the costs of running the data center itself. This\npaper addresses the problem of maximizing the revenues of Cloud providers by\ntrimming down their electricity costs. As a solution allocation policies which\nare based on the dynamic powering servers on and off are introduced and\nevaluated. The policies aim at satisfying the conflicting goals of maximizing\nthe users' experience while minimizing the amount of consumed electricity. The\nresults of numerical experiments and simulations are described, showing that\nthe proposed scheme performs well under different traffic conditions."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TNET.2012.2227790", 
    "link": "http://arxiv.org/pdf/1102.3059v1", 
    "title": "Profit-Aware Server Allocation for Green Internet Services", 
    "arxiv-id": "1102.3059v1", 
    "author": "Marios Dikaiakos", 
    "publish": "2011-02-15T13:07:53Z", 
    "summary": "A server farm is examined, where a number of servers are used to offer a\nservice to impatient customers. Every completed request generates a certain\namount of profit, running servers consume electricity for power and cooling,\nwhile waiting customers might leave the system before receiving service if they\nexperience excessive delays. A dynamic allocation policy aiming at satisfying\nthe conflicting goals of maximizing the quality of users' experience while\nminimizing the cost for the provider is introduced and evaluated. The results\nof several experiments are described, showing that the proposed scheme performs\nwell under different traffic conditions."
},{
    "category": "cs.NI", 
    "doi": "10.1186/1687-1499-2011-82", 
    "link": "http://arxiv.org/pdf/1102.3232v2", 
    "title": "Modelling on the Guaranteed QoS for Wireless Sensor Networks: A Network   Calculus Approach", 
    "arxiv-id": "1102.3232v2", 
    "author": "Xiaoheng Deng", 
    "publish": "2011-02-16T04:01:19Z", 
    "summary": "Wireless sensor networks (WSNs) became one of the high technology domains\nduring the last ten years. Real-time applications for them make it necessary to\nprovide the guaranteed Quality of Service (QoS). The main contributions of this\npaper are a system skeleton and a guaranteed QoS model that are suitable for\nthe WSNs. To do it, we develop a sensor node model based on virtual buffer\nsharing and present a two-layer scheduling model using the network calculus.\nWith the system skeleton, we develop a guaranteed QoS model, such as the upper\nbounds on buffer queue length/delay/effective bandwidth, and single-hop/\nmulti-hops delay/jitter/effective bandwidth. Numerical results show the system\nskeleton and the guaranteed QoS model are scalable for different types of\nflows, including the self-similar traffic flows, and the parameters of flow\nregulators and service curves of sensor nodes affect them. Our proposal leads\nto buffer dimensioning, guaranteed QoS support and control in the WSNs."
},{
    "category": "cs.DC", 
    "doi": "10.1109/GRID.2010.5697986", 
    "link": "http://arxiv.org/pdf/1102.3272v1", 
    "title": "On Allocation Policies for Power and Performance", 
    "arxiv-id": "1102.3272v1", 
    "author": "Michele Mazzucco", 
    "publish": "2011-02-16T09:25:26Z", 
    "summary": "With the increasing popularity of Internet-based services and applications,\npower efficiency is becoming a major concern for data center operators, as high\nelectricity consumption not only increases greenhouse gas emissions, but also\nincreases the cost of running the server farm itself. In this paper we address\nthe problem of maximizing the revenue of a service provider by means of dynamic\nallocation policies that run the minimum amount of servers necessary to meet\nuser's requirements in terms of performance. The results of several experiments\nexecuted using Wikipedia traces are described, showing that the proposed\nschemes work well, even if the workload is non-stationary. Since any resource\nallocation policy requires the use of forecasting mechanisms, various schemes\nallowing compensating errors in the load forecasts are presented and evaluated."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CCGRID.2010.125", 
    "link": "http://arxiv.org/pdf/1102.3699v1", 
    "title": "Towards Autonomic Service Provisioning Systems", 
    "arxiv-id": "1102.3699v1", 
    "author": "Michele Mazzucco", 
    "publish": "2011-02-17T21:07:38Z", 
    "summary": "This paper discusses our experience in building SPIRE, an autonomic system\nfor service provision. The architecture consists of a set of hosted Web\nServices subject to QoS constraints, and a certain number of servers used to\nrun session-based traffic. Customers pay for having their jobs run, but require\nin turn certain quality guarantees: there are different SLAs specifying charges\nfor running jobs and penalties for failing to meet promised performance\nmetrics. The system is driven by an utility function, aiming at optimizing the\naverage earned revenue per unit time. Demand and performance statistics are\ncollected, while traffic parameters are estimated in order to make dynamic\ndecisions concerning server allocation and admission control. Different utility\nfunctions are introduced and a number of experiments aiming at testing their\nperformance are discussed. Results show that revenues can be dramatically\nimproved by imposing suitable conditions for accepting incoming traffic; the\nproposed system performs well under different traffic settings, and it\nsuccessfully adapts to changes in the operating environment."
},{
    "category": "cs.PF", 
    "doi": "10.1109/CCGRID.2010.125", 
    "link": "http://arxiv.org/pdf/1102.3703v1", 
    "title": "Allocation and Admission Policies for Service Streams", 
    "arxiv-id": "1102.3703v1", 
    "author": "Paul McKee", 
    "publish": "2011-02-17T21:20:06Z", 
    "summary": "A service provisioning system is examined, where a number of servers are used\nto offer different types of services to paying customers. A customer is charged\nfor the execution of a stream of jobs; the number of jobs in the stream and the\nrate of their submission is specified. On the other hand, the provider promises\na certain quality of service (QoS), measured by the average waiting time of the\njobs in the stream. A penalty is paid if the agreed QoS requirement is not met.\nThe objective is to maximize the total average revenue per unit time. Dynamic\npolicies for making server allocation and stream admission decisions are\nintroduced and evaluated. The results of several simulations are described."
},{
    "category": "cs.NI", 
    "doi": "10.1109/CCGRID.2010.125", 
    "link": "http://arxiv.org/pdf/1103.0463v3", 
    "title": "Fitting Square Pegs Through Round Pipes: Unordered Delivery   Wire-Compatible with TCP and TLS", 
    "arxiv-id": "1103.0463v3", 
    "author": "Bryan Ford", 
    "publish": "2011-03-02T15:55:10Z", 
    "summary": "Internet applications increasingly employ TCP not as a stream abstraction,\nbut as a substrate for application-level transports, a use that converts TCP's\nin-order semantics from a convenience blessing to a performance curse. As\nInternet evolution makes TCP's use as a substrate likely to grow, we offer\nMinion, an architecture for backward-compatible out-of-order delivery atop TCP\nand TLS. Small OS API extensions allow applications to manage TCP's send buffer\nand to receive TCP segments out-of-order. Atop these extensions, Minion builds\napplication-level protocols offering true unordered datagram delivery, within\nstreams preserving strict wire-compatibility with unsecured or TLS-secured TCP\nconnections. Minion's protocols can run on unmodified TCP stacks, but benefit\nincrementally when either endpoint is upgraded, for a backward-compatible\ndeployment path. Experiments suggest that Minion can noticeably improve\nperformance of applications such as conferencing, virtual private networking,\nand web browsing, while incurring minimal CPU or bandwidth costs."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CCGRID.2010.125", 
    "link": "http://arxiv.org/pdf/1105.1811v1", 
    "title": "User Mode Memory Page Allocation: A Silver Bullet For Memory Allocation?", 
    "arxiv-id": "1105.1811v1", 
    "author": "Niall Douglas", 
    "publish": "2011-05-09T22:26:15Z", 
    "summary": "This paper proposes a novel solution: the elimination of paged virtual memory\nand partial outsourcing of memory page allocation and manipulation from the\noperating system kernel into the individual process' user space - a user mode\npage allocator - which allows an application to have direct, bare metal access\nto the page mappings used by the hardware Memory Management Unit (MMU) for its\npart of the overall address space. A user mode page allocator based emulation\nof the mmap() abstraction layer of dlmalloc is then benchmarked against the\ntraditional kernel mode implemented mmap() in a series of synthetic Monte-Carlo\nand real world application settings. Given the superb synthetic and positive\nreal world results from the profiling conducted, this paper proposes that with\nproper operating system and API support one could gain a further order higher\nperformance again while keeping allocator performance invariant to the amount\nof memory being allocated or freed i.e. a 100x performance improvement or more\nin some common use cases. It is rare that through a simple and easy to\nimplement API and operating system structure change one can gain a Silver\nBullet with the potential for a second one."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CCGRID.2010.125", 
    "link": "http://arxiv.org/pdf/1105.1815v1", 
    "title": "User Mode Memory Page Management: An old idea applied anew to the memory   wall problem", 
    "arxiv-id": "1105.1815v1", 
    "author": "Niall Douglas", 
    "publish": "2011-05-09T22:39:46Z", 
    "summary": "It is often said that one of the biggest limitations on computer performance\nis memory bandwidth (i.e.\"the memory wall problem\"). In this position paper, I\nargue that if historical trends in computing evolution (where growth in\navailable capacity is exponential and reduction in its access latencies is\nlinear) continue as they have, then this view is wrong - in fact we ought to be\nconcentrating on reducing whole system memory access latencies wherever\npossible, and by \"whole system\" I mean that we ought to look at how software\ncan be unnecessarily wasteful with memory bandwidth due to legacy design\ndecisions. To this end I conduct a feasibility study to determine whether we\nought to virtualise the MMU for each application process such that it has\ndirect access to its own MMU page tables and the memory allocated to a process\nis managed exclusively by the process and not the kernel. I find under typical\nconditions that nearly scale invariant performance to memory allocation size is\npossible such that hundreds of megabytes of memory can be allocated, relocated,\nswapped and deallocated in almost the same time as kilobytes (e.g. allocating\n8Mb is 10x quicker under this experimental allocator than a conventional\nallocator, and resizing a 128Kb block to 256Kb block is 4.5x faster). I find\nthat first time page access latencies are improved tenfold; moreover, because\nthe kernel page fault handler is never called, the lack of cache pollution\nimproves whole application memory access latencies increasing performance by up\nto 2x. Finally, I try binary patching existing applications to use the\nexperimental allocation technique, finding almost universal performance\nimprovements without having to recompile these applications to make better use\nof the new facilities."
},{
    "category": "cs.DB", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1105.2264v1", 
    "title": "Distributed Semantic Web Data Management in HBase and MySQL Cluster", 
    "arxiv-id": "1105.2264v1", 
    "author": "Pearl Brazier", 
    "publish": "2011-05-11T17:46:15Z", 
    "summary": "Various computing and data resources on the Web are being enhanced with\nmachine-interpretable semantic descriptions to facilitate better search,\ndiscovery and integration. This interconnected metadata constitutes the\nSemantic Web, whose volume can potentially grow the scale of the Web. Efficient\nmanagement of Semantic Web data, expressed using the W3C's Resource Description\nFramework (RDF), is crucial for supporting new data-intensive,\nsemantics-enabled applications. In this work, we study and compare two\napproaches to distributed RDF data management based on emerging cloud computing\ntechnologies and traditional relational database clustering technologies. In\nparticular, we design distributed RDF data storage and querying schemes for\nHBase and MySQL Cluster and conduct an empirical comparison of these approaches\non a cluster of commodity machines using datasets and queries from the Third\nProvenance Challenge and Lehigh University Benchmark. Our study reveals\ninteresting patterns in query evaluation, shows that our algorithms are\npromising, and suggests that cloud computing has a great potential for scalable\nSemantic Web data management."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1105.4301v1", 
    "title": "A Methodology for Optimizing Multithreaded System Scalability on   Multi-cores", 
    "arxiv-id": "1105.4301v1", 
    "author": "Stefan Parvu", 
    "publish": "2011-05-22T01:12:11Z", 
    "summary": "We show how to quantify scalability with the Universal Scalability Law (USL)\nby applying it to performance measurements of memcached, J2EE, and Weblogic on\nmulti-core platforms. Since commercial multicores are essentially black-boxes,\nthe accessible performance gains are primarily available at the application\nlevel. We also demonstrate how our methodology can identify the most\nsignificant performance tuning opportunities to optimize application\nscalability, as well as providing an easy means for exploring other aspects of\nthe multi-core system design space."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1105.5062v1", 
    "title": "Reserved or On-Demand Instances? A Revenue Maximization Model for Cloud   Providers", 
    "arxiv-id": "1105.5062v1", 
    "author": "Marlon Dumas", 
    "publish": "2011-05-25T15:22:00Z", 
    "summary": "We examine the problem of managing a server farm in a way that attempts to\nmaximize the net revenue earned by a cloud provider by renting servers to\ncustomers according to a typical Platform-as-a-Service model. The Cloud\nprovider offers its resources to two classes of customers: `premium' and\n`basic'. Premium customers pay upfront fees to reserve servers for a specified\nperiod of time (e.g. a year). Premium customers can submit jobs for their\nreserved servers at any time and pay a fee for the server-hours they use. The\nprovider is liable to pay a penalty every time a `premium' job can not be\nexecuted due to lack of resources. On the other hand, `basic' customers are\nserved on a best-effort basis, and pay a server-hour fee that may be higher\nthan the one paid by premium customers. The provider incurs energy costs when\nrunning servers. Hence, it has an incentive to turn off idle servers. The\nquestion of how to choose the number of servers to allocate to each pool (basic\nand premium) is answered by analyzing a suitable queuing model and maximizing a\nrevenue function. Experimental results show that the proposed scheme adapts to\ndifferent traffic conditions, penalty levels, energy costs and usage fees."
},{
    "category": "cs.CE", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1105.5881v2", 
    "title": "On the random access performance of Cell Broadband Engine with graph   analysis application", 
    "arxiv-id": "1105.5881v2", 
    "author": "David A. Bader", 
    "publish": "2011-05-30T07:07:59Z", 
    "summary": "The Cell Broad Engine (BE) Processor has unique memory access architecture\nbesides its powerful computing engines. Many computing-intensive applications\nhave been ported to Cell/BE successfully. But memory-intensive applications are\nrarely investigated except for several micro benchmarks. Since Cell/BE has\npowerful software visible DMA engine, this paper studies on whether Cell/BE is\nsuit for applica- tions with large amount of random memory accesses. Two\nbenchmarks, GUPS and SSCA#2, are used. The latter is a rather complex one that\nin representative of real world graph analysis applications. We find both\nbenchmarks have good performance on Cell/BE based IBM QS20/22. Com- pared with\n2 conventional multi-processor systems with the same core/thread number, GUPS\nis about 40-80% fast and SSCA#2 about 17-30% fast. The dynamic load balanc- ing\nand software pipeline for optimizing SSCA#2 are intro- duced. Based on the\nexperiment, the potential of Cell/BE for random access is analyzed in detail as\nwell as its limita- tions of memory controller, atomic engine and TLB manage-\nment.Our research shows although more programming effort are needed, Cell/BE\nhas the potencial for irregular memory access applications."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1106.2568v1", 
    "title": "HMTT: A Hybrid Hardware/Software Tracing System for Bridging Memory   Trace's Semantic Gap", 
    "arxiv-id": "1106.2568v1", 
    "author": "Jianping Fan", 
    "publish": "2011-06-13T22:29:08Z", 
    "summary": "Memory trace analysis is an important technology for architecture research,\nsystem software (i.e., OS, compiler) optimization, and application performance\nimprovements. Hardware-snooping is an effective and efficient approach to\nmonitor and collect memory traces. Compared with software-based approaches,\nmemory traces collected by hardware-based approaches are usually lack of\nsemantic information, such as process/function/loop identifiers, virtual\naddress and I/O access. In this paper we propose a hybrid hardware/software\nmechanism which is able to collect memory reference trace as well as semantic\ninformation. Based on this mechanism, we designed and implemented a prototype\nsystem called HMTT (Hybrid Memory Trace Tool) which adopts a DIMMsnooping\nmechanism to snoop on memory bus and a software-controlled tracing mechanism to\ninject semantic information into normal memory trace. To the best of our\nknowledge, the HMTT system is the first hardware tracing system capable of\ncorrelating memory trace with high-level events. Comprehensive validations and\nevaluations show that the HMTT system has both hardware's (e.g., no distortion\nor pollution) and software's advantages (e.g., flexibility and more\ninformation)."
},{
    "category": "hep-lat", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1106.4964v1", 
    "title": "Efficient implementation of the overlap operator on multi-GPUs", 
    "arxiv-id": "1106.4964v1", 
    "author": "Frank X. Lee", 
    "publish": "2011-06-24T13:10:54Z", 
    "summary": "Lattice QCD calculations were one of the first applications to show the\npotential of GPUs in the area of high performance computing. Our interest is to\nfind ways to effectively use GPUs for lattice calculations using the overlap\noperator. The large memory footprint of these codes requires the use of\nmultiple GPUs in parallel. In this paper we show the methods we used to\nimplement this operator efficiently. We run our codes both on a GPU cluster and\na CPU cluster with similar interconnects. We find that to match performance the\nCPU cluster requires 20-30 times more CPU cores than GPUs."
},{
    "category": "math.PR", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1107.1536v1", 
    "title": "The M/M/Infinity Service System with Ranked Servers in Heavy Traffic", 
    "arxiv-id": "1107.1536v1", 
    "author": "Nicholas Pippenger", 
    "publish": "2011-07-07T23:42:26Z", 
    "summary": "We consider an M/M/Infinity service system in which an arriving customer is\nserved by the first idle server in an infinite sequence S_1, S_2, ... of\nservers. We determine the first two terms in the asymptotic expansions of the\nmoments of L as lambda tends to infinity, where L is the index of the server\nS_L serving a newly arriving customer in equilibrium, and lambda is the ratio\nof the arrival rate to the service rate. The leading terms of the moments show\nthat L/lambda tends to a uniform distribution on [0,1]."
},{
    "category": "stat.ME", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1107.2446v1", 
    "title": "An EM Algorithm for Continuous-time Bivariate Markov Chains", 
    "arxiv-id": "1107.2446v1", 
    "author": "Yariv Ephraim", 
    "publish": "2011-07-13T01:34:59Z", 
    "summary": "We study properties and parameter estimation of finite-state homogeneous\ncontinuous-time bivariate Markov chains. Only one of the two processes of the\nbivariate Markov chain is observable. The general form of the bivariate Markov\nchain studied here makes no assumptions on the structure of the generator of\nthe chain, and hence, neither the underlying process nor the observable process\nis necessarily Markov. The bivariate Markov chain allows for simultaneous jumps\nof the underlying and observable processes. Furthermore, the inter-arrival time\nof observed events is phase-type. The bivariate Markov chain generalizes the\nbatch Markovian arrival process as well as the Markov modulated Markov process.\nWe develop an expectation-maximization (EM) procedure for estimating the\ngenerator of a bivariate Markov chain, and we demonstrate its performance. The\nprocedure does not rely on any numerical integration or sampling scheme of the\ncontinuous-time bivariate Markov chain. The proposed EM algorithm is equally\napplicable to multivariate Markov chains."
},{
    "category": "cs.PF", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1107.4851v1", 
    "title": "AWRP: Adaptive Weight Ranking Policy for Improving Cache Performance", 
    "arxiv-id": "1107.4851v1", 
    "author": "Debabrata Swain", 
    "publish": "2011-07-25T06:43:39Z", 
    "summary": "Due to the huge difference in performance between the computer memory and\nprocessor, the virtual memory management plays a vital role in system\nperformance. A Cache memory is the fast memory which is used to compensate the\nspeed difference between the memory and processor. This paper gives an adaptive\nreplacement policy over the traditional policy which has low overhead, better\nperformance and is easy to implement. Simulations show that our algorithm\nperforms better than Least-Recently-Used (LRU), First-In-First-Out (FIFO) and\nClock with Adaptive Replacement (CAR)."
},{
    "category": "cs.DB", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1108.1378v1", 
    "title": "An Efficient Architecture for Information Retrieval in P2P Context Using   Hypergraph", 
    "arxiv-id": "1108.1378v1", 
    "author": "Mohammad Hajjar", 
    "publish": "2011-08-05T18:26:33Z", 
    "summary": "Peer-to-peer (P2P) Data-sharing systems now generate a significant portion of\nInternet traffic. P2P systems have emerged as an accepted way to share enormous\nvolumes of data. Needs for widely distributed information systems supporting\nvirtual organizations have given rise to a new category of P2P systems called\nschema-based. In such systems each peer is a database management system in\nitself, ex-posing its own schema. In such a setting, the main objective is the\nefficient search across peer databases by processing each incoming query\nwithout overly consuming bandwidth. The usability of these systems depends on\nsuccessful techniques to find and retrieve data; however, efficient and\neffective routing of content-based queries is an emerging problem in P2P\nnetworks. This work was attended as an attempt to motivate the use of mining\nalgorithms in the P2P context may improve the significantly the efficiency of\nsuch methods. Our proposed method based respectively on combination of\nclustering with hypergraphs. We use ECCLAT to build approximate clustering and\ndiscovering meaningful clusters with slight overlapping. We use an algorithm\nMTMINER to extract all minimal transversals of a hypergraph (clusters) for\nquery routing. The set of clusters improves the robustness in queries routing\nmechanism and scalability in P2P Network. We compare the performance of our\nmethod with the baseline one considering the queries routing problem. Our\nexperimental results prove that our proposed methods generate impressive levels\nof performance and scalability with with respect to important criteria such as\nresponse time, precision and recall."
},{
    "category": "cs.PF", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1108.1554v1", 
    "title": "A Stochastic Calculus for Network Systems with Renewable Energy Sources", 
    "arxiv-id": "1108.1554v1", 
    "author": "Dimitri Marinakis", 
    "publish": "2011-08-07T16:52:18Z", 
    "summary": "We consider the performance modeling and evaluation of network systems\npowered with renewable energy sources such as solar and wind energy. Such\nenergy sources largely depend on environmental conditions, which are hard to\npredict accurately. As such, it may only make sense to require the network\nsystems to support a soft quality of service (QoS) guarantee, i.e., to\nguarantee a service requirement with a certain high probability. In this paper,\nwe intend to build a solid mathematical foundation to help better understand\nthe stochastic energy constraint and the inherent correlation between QoS and\nthe uncertain energy supply. We utilize a calculus approach to model the\ncumulative amount of charged energy and the cumulative amount of consumed\nenergy. We derive upper and lower bounds on the remaining energy level based on\na stochastic energy charging rate and a stochastic energy discharging rate. By\nbuilding the bridge between energy consumption and task execution (i.e.,\nservice), we study the QoS guarantee under the constraint of uncertain energy\nsources. We further show how performance bounds can be improved if some strong\nassumptions can be made."
},{
    "category": "math.PR", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1108.5356v1", 
    "title": "Analysis of an M/M/1 Queue Using Fixed Order of Search for Arrivals and   Service", 
    "arxiv-id": "1108.5356v1", 
    "author": "Nicholas Pippenger", 
    "publish": "2011-08-26T17:24:38Z", 
    "summary": "We analyze an M/M/1 queue with a service discipline in which customers, upon\narriving when the server is busy, search a sequence of stations for a vacant\nstation at which to wait, and in which the server, upon becoming free when one\nor more customers are waiting, searches the stations in the same order for a\nstation occupied by a customer to serve. We show how to find complete\nasymptotic expansions for all the moments of the waiting time in the heavy\ntraffic limit. We show in particular that the variance of the waiting time for\nthis discipline is more similar to that of last-come-first-served (which has a\npole of order three as the arrival rate approaches the service rate) than that\nof first-come-first-served (which has pole of order two)."
},{
    "category": "cs.PL", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1110.1029v2", 
    "title": "Towards a native toplevel for the OCaml language", 
    "arxiv-id": "1110.1029v2", 
    "author": "Benedikt Meurer", 
    "publish": "2011-10-05T16:05:41Z", 
    "summary": "This paper presents the current state of our work on an interactive toplevel\nfor the OCaml language based on the optimizing native code compiler and\nruntime. Our native toplevel is up to 100 times faster than the default OCaml\ntoplevel, which is based on the byte code compiler and interpreter. It uses\nJust-In-Time techniques to compile toplevel phrases to native code at runtime,\nand currently works with various Unix-like systems running on x86 or x86-64\nprocessors."
},{
    "category": "cs.SE", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1110.1277v1", 
    "title": "Performance improvement of the software development project using the   Value Management approach", 
    "arxiv-id": "1110.1277v1", 
    "author": "Bahia Bejar Ghadhab", 
    "publish": "2011-10-05T07:25:37Z", 
    "summary": "Improving performance and delivering value for customers have become a\ncentral theme in business. The software industry has become an increasingly\nimportant sector for the economy growth in Tunisia. This study aims to show how\nusing Value Management in the Tunisian software industry for project analysis\ngives new insight about true project value and performance. This new approach\nis considered as an appropriate tool for guiding the process of making\ndecisions. It offers tools in order to analyze the service value from the\ncustomer and organization perspectives. The results showed that the VM allows\nto have better performance in the software development project by linking\ncustomer satisfaction and cost analysis. The present case shows to service\nmanagers how they can benchmark project function to reduce their costs and\nimprove resource allocation taking into consideration what customers consider\nimportant during their overall service experience. It can identify best\nprofessional practices, orient decisions to improve service value"
},{
    "category": "cs.PF", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1110.2753v2", 
    "title": "Stability of a Peer-to-Peer Communication System", 
    "arxiv-id": "1110.2753v2", 
    "author": "Bruce Hajek", 
    "publish": "2011-10-12T18:47:23Z", 
    "summary": "This paper focuses on the stationary portion of file download in an\nunstructured peer-to-peer network, which typically follows for many hours after\na flash crowd initiation. The model includes the case that peers can have some\npieces at the time of arrival. The contribution of the paper is to identify how\nmuch help is needed from the seeds, either fixed seeds or peer seeds (which are\npeers remaining in the system after obtaining a complete collection) to\nstabilize the system. The dominant cause for instability is the missing piece\nsyndrome, whereby one piece becomes very rare in the network. It is shown that\nstability can be achieved with only a small amount of help from peer\nseeds--even with very little help from a fixed seed, peers need dwell as peer\nseeds on average only long enough to upload one additional piece. The region of\nstability is insensitive to the piece selection policy. Network coding can\nsubstantially increase the region of stability in case a portion of the new\npeers arrive with randomly coded pieces."
},{
    "category": "cs.PF", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1110.3711v3", 
    "title": "Optimization strategies for parallel CPU and GPU implementations of a   meshfree particle method", 
    "arxiv-id": "1110.3711v3", 
    "author": "Moncho G\u00f3mez-Gesteira", 
    "publish": "2011-10-17T15:54:48Z", 
    "summary": "Much of the current focus in high performance computing (HPC) for\ncomputational fluid dynamics (CFD) deals with grid based methods. However,\nparallel implementations for new meshfree particle methods such as Smoothed\nParticle Hydrodynamics (SPH) are less studied. In this work, we present\noptimizations for both central processing unit (CPU) and graphics processing\nunit (GPU) of a SPH method. These optimization strategies can be further\napplied to many other meshfree methods. The obtained performance for each\narchitecture and a comparison between the most efficient implementations for\nCPU and GPU are shown."
},{
    "category": "cs.NI", 
    "doi": "10.1109/CLOUD.2011.19", 
    "link": "http://arxiv.org/pdf/1110.6265v3", 
    "title": "Understanding BitTorrent Through Real Measurements", 
    "arxiv-id": "1110.6265v3", 
    "author": "Pawel Kopiczko", 
    "publish": "2011-10-28T07:03:15Z", 
    "summary": "In this paper the results of the BitTorrent measurement study are presented.\nTwo sources of BitTorrent data were utilized: meta-data files that describe the\ncontent of resources shared by BitTorrent users and the logs of one of the\ncurrently most popular BitTorrent clients - {\\mu}Torrent. {\\mu}Torrent is\nfounded upon a rather newly released UDP-based {\\mu}TP protocol that is claimed\nto be more efficient than TCP-based clients. Experimental data have been\ncollected for fifteen days from the popular torrent-discovery site\nthepiratebay.org (more than 30,000 torrents were captured and analyzed). During\nthis period the activity and logs of an unmodified version of {\\mu}Torrent\nclient downloading sessions have been also captured. The obtained experimental\nresults are swarm-oriented (not tracker-oriented as has been previously\nresearched), which has allowed us to look at BitTorrent and its users from an\nexchanged resources perspective. Moreover, comparative analysis of the clients'\nconnections with and without {\\mu}TP protocol is carried out to verify to what\nextent {\\mu}TP improves BitTorrent transmissions. To the authors' best\nknowledge, none of the previous studies have addressed these issues."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsea.2011.1504", 
    "link": "http://arxiv.org/pdf/1111.1628v1", 
    "title": "Updatable Queue Protocol Based On TCP For Virtual Reality Environment", 
    "arxiv-id": "1111.1628v1", 
    "author": "Ayad M. Salhieh", 
    "publish": "2011-11-07T16:12:31Z", 
    "summary": "The variance in number and types of tasks required to be implemented within\nDistributed Virtual Environments (DVE) highlights the needs for communication\nprotocols can achieve consistency. In addition, these applications have to\nhandle an increasing number of participants and deal with the difficult problem\nof scalability. Moreover, the real-time requirements of these applications make\nthe scalability problem more difficult to solve. In this paper, we have\nimplemented Updatable Queue Abstraction protocol (UQA) on TCP (TCP-UQA) and\ncompared it with original TCP, UDP, and Updatable Queue Abstraction based on\nUDP (UDP-UQA) protocols. Results showed that TCP-UQA was the best in queue\nmanagement."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsea.2011.1509", 
    "link": "http://arxiv.org/pdf/1111.2996v1", 
    "title": "Performance Evaluation of Different Scheduling Algorithms in WiMAX", 
    "arxiv-id": "1111.2996v1", 
    "author": "Yaser M. Khamayseh", 
    "publish": "2011-11-13T08:18:14Z", 
    "summary": "Worldwide Interoperability for Microwave Access (WiMAX) networks were\nexpected to be the main Broadband Wireless Access (BWA) technology that\nprovided several services such as data, voice, and video services including\ndifferent classes of Quality of Services (QoS), which in turn were defined by\nIEEE 802.16 standard. Scheduling in WiMAX became one of the most challenging\nissues, since it was responsible for distributing available resources of the\nnetwork among all users; this leaded to the demand of constructing and\ndesigning high efficient scheduling algorithms in order to improve the network\nutilization, to increase the network throughput, and to minimize the end-to-end\ndelay. In this study, we presenedt a simulation study to measure the\nperformance of several scheduling algorithms in WiMAX, which were Strict\nPriority algorithm, Round-Robin (RR), Weighted Round Robin (WRR), Weighted Fair\nQueuing (WFQ), Self-Clocked Fair (SCF), and Diff-Serv Algorithm."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijcsea.2011.1509", 
    "link": "http://arxiv.org/pdf/1111.4287v1", 
    "title": "Parametric Estimation of the Ultimate Size of Hypercomputers", 
    "arxiv-id": "1111.4287v1", 
    "author": "Dmitry Zinoviev", 
    "publish": "2011-11-18T05:29:44Z", 
    "summary": "The performance of the emerging petaflops-scale supercomputers of the nearest\nfuture (hypercomputers) will be governed not only by the clock frequency of the\nprocessing nodes or by the width of the system bus, but also by such factors as\nthe overall power consumption and the geometric size. In this paper, we study\nthe influence of such parameters on one of the most important characteristics\nof a general purpose computer - on the degree of multithreading that must be\npresent in an application to make the use of the hypercomputer justifiable. Our\nmajor finding is that for the class of applications with purely random memory\naccess patterns \"super-fast computing\" and \"high-performance computing\" are\nessentially synonyms for \"massively-parallel computing.\""
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsea.2011.1509", 
    "link": "http://arxiv.org/pdf/1111.4511v1", 
    "title": "Greening File Distribution: Centralized or Distributed?", 
    "arxiv-id": "1111.4511v1", 
    "author": "Arturo Azcorra", 
    "publish": "2011-11-18T22:48:05Z", 
    "summary": "Despite file-distribution applications are responsible for a major portion of\nthe current Internet traffic, so far little effort has been dedicated to study\nfile distribution from the point of view of energy efficiency. In this paper,\nwe present a first approach at the problem of energy efficiency for file\ndistribution. Specifically, we first demonstrate that the general problem of\nminimizing energy consumption in file distribution in heterogeneous settings is\nNP-hard. For homogeneous settings, we derive tight lower bounds on energy\nconsumption, and we design a family of algorithms that achieve these bounds.\nOur results prove that collaborative p2p schemes achieve up to 50% energy\nsavings with respect to the best available centralized file distribution\nscheme. Through simulation, we demonstrate that in more realistic cases (e.g.,\nconsidering network congestion, and link variability across hosts) we validate\nthis observation, since our collaborative algorithms always achieve significant\nenergy savings with respect to the power consumption of centralized file\ndistribution systems."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijcsea.2011.1509", 
    "link": "http://arxiv.org/pdf/1111.4624v3", 
    "title": "Sensing Matrix Setting Schemes for Cognitive Networks and Their   Performance Analysis", 
    "arxiv-id": "1111.4624v3", 
    "author": "Masoumeh Nasiri-Kenari", 
    "publish": "2011-11-20T11:26:29Z", 
    "summary": "Powerful spectrum decision schemes enable cognitive radios (CRs) to find\ntransmission opportunities in spectral resources allocated exclusively to the\nprimary users. One of the key effecting factor on the CR network throughput is\nthe spectrum sensing sequence used by each secondary user. In this paper,\nsecondary users' throughput maximization through finding an appropriate sensing\nmatrix (SM) is investigated. To this end, first the average throughput of the\nCR network is evaluated for a given SM. Then, an optimization problem based on\nthe maximization of the network throughput is formulated in order to find the\noptimal SM. As the optimum solution is very complicated, to avoid its major\nchallenges, three novel sub optimum solutions for finding an appropriate SM are\nproposed for various cases including perfect and non-perfect sensing. Despite\nof having less computational complexities as well as lower consumed energies,\nthe proposed solutions perform quite well compared to the optimum solution (the\noptimum SM). The structure and performance of the proposed SM setting schemes\nare discussed in detail and a set of illustrative simulation results is\npresented to validate their efficiencies."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcsea.2011.1509", 
    "link": "http://arxiv.org/pdf/1112.2046v1", 
    "title": "Improving TCP Performance over Wireless Network with Frequent   Disconnections", 
    "arxiv-id": "1112.2046v1", 
    "author": "K. S. Dasgupta", 
    "publish": "2011-12-09T08:36:34Z", 
    "summary": "Presented in this paper is the solution to the problem that arises when the\nTCP/IP protocol suite is used to provide Internet connectivity through mobile\nterminals over emerging 802.11 wireless links. Taking into consideration the\nstrong drive towards wireless Internet access through mobile terminals, the\nproblem of frequent disconnections causing serial timeouts is examined and\nanalyzed, with the help of extensive simulations. After a detailed review of\nwireless link loss recovery mechanism and identification of related problems, a\nnew scheme with modifications at link layer and transport layer is proposed.\nThe proposed modifications which depend on interaction between two layers (i)\nreduce the idle time before transmission at TCP by preventing timeout\noccurrences and (ii) decouple the congestion control from recovery of the\nlosses due to link failure. Results of simulation based experiments demonstrate\nconsiderable performance improvement with the proposed modifications over the\nconventional TCP, when a wireless sender is experiencing frequent link\nfailures."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1201.1695v1", 
    "title": "Some Observations on Optimal Frequency Selection in DVFS-based Energy   Consumption Minimization", 
    "arxiv-id": "1201.1695v1", 
    "author": "Albert Y. Zomaya", 
    "publish": "2012-01-09T06:31:03Z", 
    "summary": "In recent years, the issue of energy consumption in parallel and distributed\ncomputing systems has attracted a great deal of attention. In response to this,\nmany energy-aware scheduling algorithms have been developed primarily using the\ndynamic voltage-frequency scaling (DVFS) capability which has been incorporated\ninto recent commodity processors. Majority of these algorithms involve two\npasses: schedule generation and slack reclamation. The former pass involves the\nredistribution of tasks among DVFS-enabled processors based on a given cost\nfunction that includes makespan and energy consumption; and, while the latter\npass is typically achieved by executing individual tasks with slacks at a lower\nprocessor frequency. In this paper, a new slack reclamation algorithm is\nproposed by approaching the energy reduction problem from a different angle.\nFirstly, the problem of task slack reclamation by using combinations of\nprocessors' frequencies is formulated. Secondly, several proofs are provided to\nshow that (1) if the working frequency set of processor is assumed to be\ncontinues, the optimal energy will be always achieved by using only one\nfrequency, (2) for real processors with a discrete set of working frequencies,\nthe optimal energy is always achieved by using at most two frequencies, and (3)\nthese two frequencies are adjacent/neighbouring when processor energy\nconsumption is a convex function of frequency. Thirdly, a novel algorithm to\nfind the best combination of frequencies to result the optimal energy is\npresented. The presented algorithm has been evaluated based on results obtained\nfrom experiments with three different sets of task graphs: 3000 randomly\ngenerated task graphs, and 600 task graphs for two popular applications\n(Gauss-Jordan and LU decomposition). The results show the superiority of the\nproposed algorithm in comparison with other techniques."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1201.4655v1", 
    "title": "Reengineering multi tiered enterprise business applications for   performance enhancement and reciprocal or rectangular hyperbolic relation of   variation of data transportation time with row pre-fetch size of relational   database drivers", 
    "arxiv-id": "1201.4655v1", 
    "author": "Sridhar Sowmiyanarayanan", 
    "publish": "2012-01-23T09:51:15Z", 
    "summary": "Reengineering multi tiered enterprise business applications for performance\nenhancement and reciprocal or rectangular hyperbolic relation of variation of\ndata transportation time with row pre-fetch size of relational database drivers"
},{
    "category": "cs.SE", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1202.0414v1", 
    "title": "Generating a Performance Stochastic Model from UML Specifications", 
    "arxiv-id": "1202.0414v1", 
    "author": "Mohamed Dbouk", 
    "publish": "2012-02-02T11:42:16Z", 
    "summary": "Since its initiation by Connie Smith, the process of Software Performance\nEngineering (SPE) is becoming a growing concern. The idea is to bring\nperformance evaluation into the software design process. This suitable\nmethodology allows software designers to determine the performance of software\nduring design. Several approaches have been proposed to provide such\ntechniques. Some of them propose to derive from a UML (Unified Modeling\nLanguage) model a performance model such as Stochastic Petri Net (SPN) or\nStochastic process Algebra (SPA) models. Our work belongs to the same category.\nWe propose to derive from a UML model a Stochastic Automata Network (SAN) in\norder to obtain performance predictions. Our approach is more flexible due to\nthe SAN modularity and its high resemblance to UML' state-chart diagram."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1202.1877v2", 
    "title": "Effect of Packet Delay Variation on Video-Voice over DiffServ-MPLS in   IPv4-IPv6 Networks", 
    "arxiv-id": "1202.1877v2", 
    "author": "Adrian Popescu", 
    "publish": "2012-02-09T02:47:14Z", 
    "summary": "Over the last years, we have witnessed a rapid deployment of real-time\napplications on the Internet as well as many research works about Quality of\nService (QoS), in particular IPv4 (Internet Protocol version 4). The inevitable\nexhaustion of the remaining IPv4 address pool has become progressively evident.\nAs the evolution of Internet Protocol (IP) continues, the deployment of IPv6\nQoS is underway. Today, there is limited experience in the deployment of QoS\nfor IPv6 traffic in MPLS backbone networks in conjunction with DiffServ\n(Differentiated Services) support. DiffServ itself does not have the ability to\ncontrol the traffic which has been taken for end-to-end path while a number of\nlinks of the path are congested. In contrast, MPLS Traffic Engineering (TE) is\naccomplished to control the traffic and can set up end-to-end routing path\nbefore data has been forwarded. From the evolution of IPv4 QoS solutions, we\nknow that the integration of DiffServ and MPLS TE satisfies the guaranteed QoS\nrequirement for real-time applications. This paper presents a QoS performance\nstudy of real-time applications such as voice and video conferencing in terms\nof Packet Delay Variation (PDV) over DiffServ with or without MPLS TE in\nIPv4/IPv6 networks using Optimized Network Engineering Tool (OPNET). We also\nstudy the interaction of Expedited Forwarding (EF), Assured Forwarding (AF)\ntraffic aggregation, link congestion, as well as the effect of performance\nmetric such as PDV. The effectiveness of DiffServ and MPLS TE integration in\nIPv4/IPv6 network is illustrated and analyzed. This paper shows that IPv6\nexperiences more PDV than their IPv4 counterparts."
},{
    "category": "cs.NA", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1202.3856v3", 
    "title": "Technical Report on Hypergraph-Partitioning-Based Models and Methods for   Exploiting Cache Locality in Sparse-Matrix Vector Multiplication", 
    "arxiv-id": "1202.3856v3", 
    "author": "Cevdet Aykanat", 
    "publish": "2012-02-17T09:28:24Z", 
    "summary": "The sparse matrix-vector multiplication (SpMxV) is a kernel operation widely\nused in iterative linear solvers. The same sparse matrix is multiplied by a\ndense vector repeatedly in these solvers. Matrices with irregular sparsity\npatterns make it difficult to utilize cache locality effectively in SpMxV\ncomputations. In this work, we investigate single- and multiple-SpMxV\nframeworks for exploiting cache locality in SpMxV computations. For the\nsingle-SpMxV framework, we propose two cache-size-aware top-down\nrow/column-reordering methods based on 1D and 2D sparse matrix partitioning by\nutilizing the column-net and enhancing the row-column-net hypergraph models of\nsparse matrices. The multiple-SpMxV framework depends on splitting a given\nmatrix into a sum of multiple nonzero-disjoint matrices so that the SpMxV\noperation is performed as a sequence of multiple input- and output- dependent\nSpMxV operations. For an effective matrix splitting required in this framework,\nwe propose a cache- size-aware top-down approach based on 2D sparse matrix\npartitioning by utilizing the row-column-net hypergraph model. For this\nframework, we also propose two methods for effective ordering of individual\nSpMxV operations. The primary objective in all of the three methods is to\nmaximize the exploitation of temporal locality. We evaluate the validity of our\nmodels and methods on a wide range of sparse matrices using both cache-miss\nsimulations and actual runs by using OSKI. Experimental results show that\nproposed methods and models outperform state-of-the-art schemes."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1202.4423v1", 
    "title": "On the Reliability of RAID Systems: An Argument for More Check Drives", 
    "arxiv-id": "1202.4423v1", 
    "author": "Marek Rychlik", 
    "publish": "2012-02-16T03:54:13Z", 
    "summary": "In this paper we address issues of reliability of RAID systems. We focus on\n\"big data\" systems with a large number of drives and advanced error correction\nschemes beyond \\RAID{6}. Our RAID paradigm is based on Reed-Solomon codes, and\nthus we assume that the RAID consists of $N$ data drives and $M$ check drives.\nThe RAID fails only if the combined number of failed drives and sector errors\nexceeds $M$, a property of Reed-Solomon codes.\n  We review a number of models considered in the literature and build upon them\nto construct models usable for a large number of data and check drives. We\nattempt to account for a significant number of factors that affect RAID\nreliability, such as drive replacement or lack thereof, mistakes during service\nsuch as replacing the wrong drive, delayed repair, and the finite duration of\nRAID reconstruction. We evaluate the impact of sector failures that do not\nresult in drive replacement.\n  The reader who needs to consider large $M$ and $N$ will find applicable\nmathematical techniques concisely summarized here, and should be able to apply\nthem to similar problems. Most methods are based on the theory of continuous\ntime Markov chains, but we move beyond this framework when we consider the\nfixed time to rebuild broken hard drives, which we model using systems of delay\nand partial differential equations.\n  One universal statement is applicable across various models: increasing the\nnumber of check drives in all cases increases the reliability of the system,\nand is vastly superior to other approaches of ensuring reliability such as\nmirroring."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1202.4880v1", 
    "title": "Performance Evaluation of the Random Replacement Policy for Networks of   Caches", 
    "arxiv-id": "1202.4880v1", 
    "author": "Christian Tanguy", 
    "publish": "2012-02-22T11:08:33Z", 
    "summary": "The overall performance of content distribution networks as well as recently\nproposed information-centric networks rely on both memory and bandwidth\ncapacities. In this framework, the hit ratio is the key performance indicator\nwhich captures the bandwidth / memory tradeoff for a given global\nperformance.This paper focuses on the estimation of the hit ratio in a network\nof caches that employ the Random replacement policy. Assuming that requests are\nindependent and identically distributed, general expressions of miss\nprobabilities for a single Random cache are provided as well as exact results\nfor specific popularity distributions. Moreover, for any Zipf popularity\ndistribution with exponent $\\alpha$ > 1, we obtain asymptotic equivalents for\nthe miss probability in the case of large cache size. We extend the analysis to\nnetworks of Random caches, when the topology is either a line or a homogeneous\ntree. In that case, approximations for miss probabilities across the network\nare derived by assuming that miss events at any node occur independently in\ntime; the obtained results are compared to the same network using the\nLeast-Recently-Used discipline, already addressed in the literature. We further\nanalyze the case of a mixed tandem cache network where the two nodes employ\neither Random or Least-Recently-Used policies. In all scenarios, asymptotic\nformulas and approximations are extensively compared to simulations and shown\nto perform very well. Finally, our results enable us to propose recommendations\nfor cache replacement disciplines in a network dedicated to content\ndistribution. These results also hold for a cache using the First-In-First-Out\npolicy."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1202.5755v2", 
    "title": "Balancing Work and Size with Bounded Buffers", 
    "arxiv-id": "1202.5755v2", 
    "author": "Michael Segal", 
    "publish": "2012-02-26T12:53:15Z", 
    "summary": "We consider the fundamental problem of managing a bounded size queue buffer\nwhere traffic consists of packets of varying size, where each packet requires\nseveral rounds of processing before it can be transmitted from the queue\nbuffer. The goal in such an environment is to maximize the overall size of\npackets that are successfully transmitted. This model is motivated by the\never-growing ubiquity of network processors architectures, which must deal with\nheterogeneously-sized traffic, with heterogeneous processing requirements. Our\nwork addresses the tension between two conflicting algorithmic approaches in\nsuch settings: the tendency to favor packets with fewer processing\nrequirements, thus leading to fast contributions to the accumulated throughput,\nas opposed to preferring packets of larger size, which imply a large increase\nin throughput at each step. We present a model for studying such systems, and\npresent competitive algorithms whose performance depend on the maximum size a\npacket may have, and maximum amount of processing a packet may require. We\nfurther provide lower bounds on algorithms performance in such settings."
},{
    "category": "cs.LO", 
    "doi": "10.1016/j.jpdc.2011.01.004", 
    "link": "http://arxiv.org/pdf/1203.0920v2", 
    "title": "Fluid Model Checking", 
    "arxiv-id": "1203.0920v2", 
    "author": "Jane Hillston", 
    "publish": "2012-03-05T14:00:02Z", 
    "summary": "In this paper we investigate a potential use of fluid approximation\ntechniques in the context of stochastic model checking of CSL formulae. We\nfocus on properties describing the behaviour of a single agent in a (large)\npopulation of agents, exploiting a limit result known also as fast simulation.\nIn particular, we will approximate the behaviour of a single agent with a\ntime-inhomogeneous CTMC which depends on the environment and on the other\nagents only through the solution of the fluid differential equation. We will\nprove the asymptotic correctness of our approach in terms of satisfiability of\nCSL formulae and of reachability probabilities. We will also present a\nprocedure to model check time-inhomogeneous CTMC against CSL formulae."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1203.1757v1", 
    "title": "Performance Analysis for Bandwidth Allocation in IEEE 802.16 Broadband   Wireless Networks using BMAP Queueing", 
    "arxiv-id": "1203.1757v1", 
    "author": "Abdelkrim Haqiq", 
    "publish": "2012-03-08T11:34:52Z", 
    "summary": "This paper presents a performance analysis for the bandwidth allocation in\nIEEE 802.16 broadband wireless access (BWA) networks considering the\npacket-level quality-of-service (QoS) constraints. Adaptive Modulation and\nCoding (AMC) rate based on IEEE 802.16 standard is used to adjust the\ntransmission rate adaptively in each frame time according to channel quality in\norder to obtain multiuser diversity gain. To model the arrival process and the\ntraffic source we use the Batch Markov Arrival Process (BMAP), which enables\nmore realistic and more accurate traffic modelling. We determine analytically\ndifferent performance parameters, such as average queue length, packet dropping\nprobability, queue throughput and average packet delay. Finally, the analytical\nresults are validated numerically."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1203.1778v1", 
    "title": "A Comprehensive Study and Performance Comparison of M-ary Modulation   Schemes for an Efficient Wireless Mobile Communication System", 
    "arxiv-id": "1203.1778v1", 
    "author": "M. Hasnat Kabir", 
    "publish": "2012-03-08T12:51:47Z", 
    "summary": "Wireless communications has become one of the fastest growing areas in our\nmodern life and creates enormous impact on nearly every feature of our daily\nlife. In this paper, the performance of M-ary modulations schemes (MPSK, MQAM,\nMFSK) based wireless communication system on audio signal transmission over\nAdditive Gaussian Noise (AWGN) channel are analyzed in terms of bit error\nprobability as a function of SNR. Based on the results obtained in the present\nstudy, MPSK and MQAM are showing better performance for lower modulation order\nwhereas these are inferior with higher M. The BER value is smaller in MFSK for\nhigher M, but it is worse due to the distortion in the reproduce signal at the\nreceiver end. The lossless reproduction of recorded voice signal can be\nachieved at the receiver end with a lower modulation order."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1203.2195v1", 
    "title": "Performance Evaluation of Realistic Vanet Using Traffic Light Scenario", 
    "arxiv-id": "1203.2195v1", 
    "author": "D. K. Lobiyal", 
    "publish": "2012-03-09T22:10:32Z", 
    "summary": "Vehicular Ad-hoc Networks (VANETs) is attracting considerable attention from\nthe research community and the automotive industry to improve the services of\nIntelligent Transportation System (ITS). As today's transportation system faces\nserious challenges in terms of road safety, efficiency, and environmental\nfriendliness, the idea of so called \"ITS\" has emerged. Due to the expensive\ncost of deployment and complexity of implementing such a system in real world,\nresearch in VANET relies on simulation. This paper attempts to evaluate the\nperformance of VANET in a realistic environment. The paper contributes by\ngenerating a real world road Map of JNU using existing Google Earth and GIS\ntools. Traffic data from a limited region of road Map is collected to capture\nthe realistic mobility. In this work, the entire region has been divided into\nvarious smaller routes. The realistic mobility model used here considers the\ndriver's route choice at the run time. It also studies the clustering effect\ncaused by traffic lights used at the intersection to regulate traffic movement\nat different directions. Finally, the performance of the VANET is evaluated in\nterms of average delivery ratio, packet loss, and router drop as statistical\nmeasures for driver route choice with traffic light scenario. This experiment\nhas provided insight into the performance of vehicular traffic communication\nfor a small realistic scenario."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1203.4054v2", 
    "title": "On Modelling and Prediction of Total CPU Usage for Applications in   MapReduce Environments", 
    "arxiv-id": "1203.4054v2", 
    "author": "Albert Y. Zomaya", 
    "publish": "2012-03-19T09:03:37Z", 
    "summary": "Recently, businesses have started using MapReduce as a popular computation\nframework for processing large amount of data, such as spam detection, and\ndifferent data mining tasks, in both public and private clouds. Two of the\nchallenging questions in such environments are (1) choosing suitable values for\nMapReduce configuration parameters -e.g., number of mappers, number of\nreducers, and DFS block size-, and (2) predicting the amount of resources that\na user should lease from the service provider. Currently, the tasks of both\nchoosing configuration parameters and estimating required resources are solely\nthe users' responsibilities. In this paper, we present an approach to provision\nthe total CPU usage in clock cycles of jobs in MapReduce environment. For a\nMapReduce job, a profile of total CPU usage in clock cycles is built from the\njob past executions with different values of two configuration parameters e.g.,\nnumber of mappers, and number of reducers. Then, a polynomial regression is\nused to model the relation between these configuration parameters and total CPU\nusage in clock cycles of the job. We also briefly study the influence of input\ndata scaling on measured total CPU usage in clock cycles. This derived model\nalong with the scaling result can then be used to provision the total CPU usage\nin clock cycles of the same jobs with different input data size. We validate\nthe accuracy of our models using three realistic applications (WordCount, Exim\nMainLog parsing, and TeraSort). Results show that the predicted total CPU usage\nin clock cycles of generated resource provisioning options are less than 8% of\nthe measured total CPU usage in clock cycles in our 20-node virtual Hadoop\ncluster."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1205.2005v2", 
    "title": "Mixed-mode implementation of PETSc for scalable linear algebra on   multi-core processors", 
    "arxiv-id": "1205.2005v2", 
    "author": "James Southern", 
    "publish": "2012-05-09T14:54:55Z", 
    "summary": "With multi-core processors a ubiquitous building block of modern\nsupercomputers, it is now past time to enable applications to embrace these\ndevelopments in processor design. To achieve exascale performance, applications\nwill need ways of exploiting the new levels of parallelism that are exposed in\nmodern high-performance computers. A typical approach to this is to use\nshared-memory programming techniques to best exploit multi-core nodes along\nwith inter-node message passing. In this paper, we describe the addition of\nOpenMP threaded functionality to the PETSc library. We highlight some issues\nthat hinder good performance of threaded applications on modern processors and\ndescribe how to negate them. The OpenMP branch of PETSc was benchmarked using\nmatrices extracted from Fluidity, a CFD application code, which uses the\nlibrary as its linear solver engine. The overall performance of the mixed-mode\nimplementation is shown to be superior to that of the pure-MPI version."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1205.2678v1", 
    "title": "Evaluation of Proactive, Reactive and Hybrid Ad hoc Routing Protocol for   various Battery models in VANET using Qualnet", 
    "arxiv-id": "1205.2678v1", 
    "author": "Gurpadam Singh", 
    "publish": "2012-02-08T15:00:32Z", 
    "summary": "In VANET high speed is the real characteristics which leads frequent\nbreakdown, interference etc. In this paper we studied various Ad hoc routing\nprotocols, Reactive, Proactive & Hybrid, taking into consideration various\nVANET parameters like speed, altitude etc in real traffic scenario and\nevaluated them for various battery models for energy conservation.. The AODV\nand DYMO (Reactive), OLSR (Proactive) and ZRP (hybrid) protocols are compared\nfor battery models Duracell AA(MX- 1500),Duracell AAA(MN-2400),Duracell\nAAA(MX-2400), Duracell C-MN(MN-1400),Panasonic AA standard using Qualnet as a\nSimulation tool. Since Energy conservation is main focus area nowadays. Hence\nperformance of the protocols with various battery models counts and helps to\nmake a right selection. Varying parameters of VANET shows that in the real\ntraffic scenarios proactive protocol performs more efficiently for energy\nconservation."
},{
    "category": "cs.DB", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1205.2889v1", 
    "title": "A Comparative Study on the Performance of the Top DBMS Systems", 
    "arxiv-id": "1205.2889v1", 
    "author": "Youssef Bassil", 
    "publish": "2012-05-13T17:54:51Z", 
    "summary": "Database management systems are today's most reliable mean to organize data\ninto collections that can be searched and updated. However, many DBMS systems\nare available on the market each having their pros and cons in terms of\nreliability, usability, security, and performance. This paper presents a\ncomparative study on the performance of the top DBMS systems. They are mainly\nMS SQL Server 2008, Oracle 11g, IBM DB2, MySQL 5.5, and MS Access 2010. The\ntesting is aimed at executing different SQL queries with different level of\ncomplexities over the different five DBMSs under test. This would pave the way\nto build a head-to-head comparative evaluation that shows the average execution\ntime, memory usage, and CPU utilization of each DBMS after completion of the\ntest."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1205.3846v1", 
    "title": "A Method for the Characterisation of Observer Effects and its   Application to OML", 
    "arxiv-id": "1205.3846v1", 
    "author": "Thierry Rakotoarivelo", 
    "publish": "2012-05-17T04:27:30Z", 
    "summary": "In all measurement campaigns, one needs to assert that the instrumentation\ntools do not significantly impact the system being monitored. This is critical\nto future claims based on the collected data and is sometimes overseen in\nexperimental studies. We propose a method to evaluate the potential \"observer\neffect\" of an instrumentation system, and apply it to the OMF Measurement\nLibrary (OML). OML allows the instrumentation of almost any software to collect\nany type of measurements. As it is increasingly being used in networking\nresearch, it is important to characterise possible biases it may introduce in\nthe collected metrics. Thus, we study its effect on multiple types of reports\nfrom various applications commonly used in wireless research. To this end, we\ndesigned experiments comparing OML-instrumented software with their original\nflavours. Our analyses of the results from these experiments show that, with an\nappropriate reporting setup, OML has no significant impact on the instrumented\napplications, and may even improve some of their performances in specifics\ncases. We discuss our methodology and the implication of using OML, and provide\nguidelines on instrumenting off-the-shelf software."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijwmn.2012.4110", 
    "link": "http://arxiv.org/pdf/1205.5871v3", 
    "title": "Squeezing out the Cloud via Profit-Maximizing Resource Allocation   Policies", 
    "arxiv-id": "1205.5871v3", 
    "author": "Marlon Dumas", 
    "publish": "2012-05-26T10:37:27Z", 
    "summary": "We study the problem of maximizing the average hourly profit earned by a\nSoftware-as-a-Service (SaaS) provider who runs a software service on behalf of\na customer using servers rented from an Infrastructure-as-a-Service (IaaS)\nprovider. The SaaS provider earns a fee per successful transaction and incurs\ncosts proportional to the number of server-hours it uses. A number of resource\nallocation policies for this or similar problems have been proposed in previous\nwork. However, to the best of our knowledge, these policies have not been\ncomparatively evaluated in a cloud environment. This paper reports on an\nempirical evaluation of three policies using a replica of Wikipedia deployed on\nthe Amazon EC2 cloud. Experimental results show that a policy based on a\nsolution to an optimization problem derived from the SaaS provider's utility\nfunction outperforms well-known heuristics that have been proposed for similar\nproblems. It is also shown that all three policies outperform a \"reactive\"\nallocation approach based on Amazon's auto-scaling feature."
},{
    "category": "cs.NI", 
    "doi": "10.1109/VETECS.2010.5494169", 
    "link": "http://arxiv.org/pdf/1206.0951v1", 
    "title": "A Cross-Layer Design Based on Geographic Information for Cooperative   Wireless Networks", 
    "arxiv-id": "1206.0951v1", 
    "author": "Chin-Liang Wang", 
    "publish": "2012-06-05T16:22:37Z", 
    "summary": "Most of geographic routing approaches in wireless ad hoc and sensor networks\ndo not take into consideration the medium access control (MAC) and physical\nlayers when designing a routing protocol. In this paper, we focus on a\ncross-layer framework design that exploits the synergies between network, MAC,\nand physical layers. In the proposed CoopGeo, we use a beaconless forwarding\nscheme where the next hop is selected through a contention process based on the\ngeographic position of nodes. We optimize this Network-MAC layer interaction\nusing a cooperative relaying technique with a relay selection scheme also based\non geographic information in order to improve the system performance in terms\nof reliability."
},{
    "category": "cs.PF", 
    "doi": "10.1109/VETECS.2010.5494169", 
    "link": "http://arxiv.org/pdf/1206.1264v1", 
    "title": "Heavy Traffic Optimal Resource Allocation Algorithms for Cloud Computing   Clusters", 
    "arxiv-id": "1206.1264v1", 
    "author": "Lei Ying", 
    "publish": "2012-06-06T16:07:58Z", 
    "summary": "Cloud computing is emerging as an important platform for business, personal\nand mobile computing applications. In this paper, we study a stochastic model\nof cloud computing, where jobs arrive according to a stochastic process and\nrequest resources like CPU, memory and storage space. We consider a model where\nthe resource allocation problem can be separated into a routing or load\nbalancing problem and a scheduling problem. We study the\njoin-the-shortest-queue routing and power-of-two-choices routing algorithms\nwith MaxWeight scheduling algorithm. It was known that these algorithms are\nthroughput optimal. In this paper, we show that these algorithms are queue\nlength optimal in the heavy traffic limit."
},{
    "category": "cs.DC", 
    "doi": "10.1109/VETECS.2010.5494169", 
    "link": "http://arxiv.org/pdf/1206.2016v2", 
    "title": "Network Load Analysis and Provisioning of MapReduce Applications", 
    "arxiv-id": "1206.2016v2", 
    "author": "Albert Y. Zomaya", 
    "publish": "2012-06-10T10:39:04Z", 
    "summary": "In this paper, we study the dependency between configuration parameters and\nnetwork load of fixed-size MapReduce applications in shuffle phase and then\npropose an analytical method to model this dependency. Our approach consists of\nthree key phases: profiling, modeling, and prediction. In the first stage, an\napplication is run several times with different sets of MapReduce configuration\nparameters (here number of mappers and number of reducers) to profile the\nnetwork load of the application in the shuffle phase on a given cluster. Then,\nthe relation between these parameters and the network load is modeled by\nmultivariate linear regression. For evaluation, three applications (WordCount,\nExim Mainlog parsing, and TeraSort) are utilized to evaluate our technique on a\n4-node MapReduce private cluster."
},{
    "category": "cs.NI", 
    "doi": "10.1109/VETECS.2010.5494169", 
    "link": "http://arxiv.org/pdf/1206.2129v1", 
    "title": "To Compress or Not To Compress: Processing vs Transmission Tradeoffs for   Energy Constrained Sensor Networking", 
    "arxiv-id": "1206.2129v1", 
    "author": "Michele Rossi", 
    "publish": "2012-06-11T08:41:47Z", 
    "summary": "In the past few years, lossy compression has been widely applied in the field\nof wireless sensor networks (WSN), where energy efficiency is a crucial concern\ndue to the constrained nature of the transmission devices. Often, the common\nthinking among researchers and implementers is that compression is always a\ngood choice, because the major source of energy consumption in a sensor node\ncomes from the transmission of the data. Lossy compression is deemed a viable\nsolution as the imperfect reconstruction of the signal is often acceptable in\nWSN. In this paper, we thoroughly review a number of lossy compression methods\nfrom the literature, and analyze their performance in terms of compression\nefficiency, computational complexity and energy consumption. We consider two\ndifferent scenarios, namely, wireless and underwater communications, and show\nthat signal compression may or may not help in the reduction of the overall\nenergy consumption, depending on factors such as the compression algorithm, the\nsignal statistics and the hardware characteristics, i.e., micro-controller and\ntransmission technology. The lesson that we have learned, is that signal\ncompression may in fact provide some energy savings. However, its usage should\nbe carefully evaluated, as in quite a few cases processing and transmission\ncosts are of the same order of magnitude, whereas, in some other cases, the\nformer may even dominate the latter. In this paper, we show quantitative\ncomparisons to assess these tradeoffs in the above mentioned scenarios.\nFinally, we provide formulas, obtained through numerical fittings, to gauge\ncomputational complexity, overall energy consumption and signal representation\naccuracy for the best performing algorithms as a function of the most relevant\nsystem parameters."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-36949-0_50", 
    "link": "http://arxiv.org/pdf/1206.3738v1", 
    "title": "Best practices for HPM-assisted performance engineering on modern   multicore processors", 
    "arxiv-id": "1206.3738v1", 
    "author": "Gerhard Wellein", 
    "publish": "2012-06-17T09:53:53Z", 
    "summary": "Many tools and libraries employ hardware performance monitoring (HPM) on\nmodern processors, and using this data for performance assessment and as a\nstarting point for code optimizations is very popular. However, such data is\nonly useful if it is interpreted with care, and if the right metrics are chosen\nfor the right purpose. We demonstrate the sensible use of hardware performance\ncounters in the context of a structured performance engineering approach for\napplications in computational science. Typical performance patterns and their\nrespective metric signatures are defined, and some of them are illustrated\nusing case studies. Although these generic concepts do not depend on specific\ntools or environments, we restrict ourselves to modern x86-based multicore\nprocessors and use the likwid-perfctr tool under the Linux OS."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-36949-0_50", 
    "link": "http://arxiv.org/pdf/1208.0505v1", 
    "title": "Criticality of Large Delay Tolerant Networks via Directed Continuum   Percolation in Space-Time", 
    "arxiv-id": "1208.0505v1", 
    "author": "J\u00f6rg Ott", 
    "publish": "2012-08-02T14:38:24Z", 
    "summary": "We study delay tolerant networking (DTN) and in particular, its capacity to\nstore, carry and forward messages so that the messages eventually reach their\nfinal destinations. We approach this broad question in the framework of\npercolation theory. To this end, we assume an elementary mobility model, where\nnodes arrive to an infinite plane according to a Poisson point process, move a\ncertain distance L, and then depart. In this setting, we characterize the mean\ndensity of nodes required to support DTN style networking. In particular, under\nthe given assumptions, we show that DTN is feasible when the mean node degree\nis greater than 4 e(g), where parameter g=L/d is the ratio of the distance L to\nthe transmission range d, and e(g) is the critical reduced number density of\ntilted cylinders in a directed continuum percolation model. By means of Monte\nCarlo simulations, we give numerical values for e(g). The asymptotic behavior\nof e(g) when g tends to infinity is also derived from a fluid flow analysis."
},{
    "category": "cs.DS", 
    "doi": "10.1007/978-3-642-36949-0_50", 
    "link": "http://arxiv.org/pdf/1208.2543v1", 
    "title": "Doing More for Less -- Cache-Aware Parallel Contraction Hierarchies   Preprocessing", 
    "arxiv-id": "1208.2543v1", 
    "author": "Dennis Schieferdecker", 
    "publish": "2012-08-13T10:48:39Z", 
    "summary": "Contraction Hierarchies is a successful speedup-technique to Dijkstra's\nseminal shortest path algorithm that has a convenient trade-off between\npreprocessing and query times. We investigate a shared-memory parallel\nimplementation that uses $O(n+m)$ space for storing the graph and O(1) space\nfor each core during preprocessing. The presented data structures and\nalgorithms consequently exploits cache locality and thus exhibit competitive\npreprocessing times. The presented implementation is especially suitable for\npreprocessing graphs of planet-wide scale in practice. Also, our experiments\nshow that optimal data structures in the PRAM model can be beaten in practice\nby exploiting memory cache hierarchies."
},{
    "category": "cs.PF", 
    "doi": "10.1002/cpe.3180", 
    "link": "http://arxiv.org/pdf/1208.2908v4", 
    "title": "Exploring performance and power properties of modern multicore chips via   simple machine models", 
    "arxiv-id": "1208.2908v4", 
    "author": "Gerhard Wellein", 
    "publish": "2012-08-14T15:51:43Z", 
    "summary": "Modern multicore chips show complex behavior with respect to performance and\npower. Starting with the Intel Sandy Bridge processor, it has become possible\nto directly measure the power dissipation of a CPU chip and correlate this data\nwith the performance properties of the running code. Going beyond a simple\nbottleneck analysis, we employ the recently published Execution-Cache-Memory\n(ECM) model to describe the single- and multi-core performance of streaming\nkernels. The model refines the well-known roofline model, since it can predict\nthe scaling and the saturation behavior of bandwidth-limited loop kernels on a\nmulticore chip. The saturation point is especially relevant for considerations\nof energy consumption. From power dissipation measurements of benchmark\nprograms with vastly different requirements to the hardware, we derive a\nsimple, phenomenological power model for the Sandy Bridge processor. Together\nwith the ECM model, we are able to explain many peculiarities in the\nperformance and power behavior of multicore processors, and derive guidelines\nfor energy-efficient execution of parallel programs. Finally, we show that the\nECM and power models can be successfully used to describe the scaling and power\nbehavior of a lattice-Boltzmann flow solver code."
},{
    "category": "cs.OS", 
    "doi": "10.1002/cpe.3180", 
    "link": "http://arxiv.org/pdf/1208.6391v1", 
    "title": "On Benchmarking Embedded Linux Flash File Systems", 
    "arxiv-id": "1208.6391v1", 
    "author": "Eric Senn", 
    "publish": "2012-08-31T06:32:38Z", 
    "summary": "Due to its attractive characteristics in terms of performance, weight and\npower consumption, NAND flash memory became the main non volatile memory (NVM)\nin embedded systems. Those NVMs also present some specific\ncharacteristics/constraints: good but asymmetric I/O performance, limited\nlifetime, write/erase granularity asymmetry, etc. Those peculiarities are\neither managed in hardware for flash disks (SSDs, SD cards, USB sticks, etc.)\nor in software for raw embedded flash chips. When managed in software, flash\nalgorithms and structures are implemented in a specific flash file system\n(FFS). In this paper, we present a performance study of the most widely used\nFFSs in embedded Linux: JFFS2, UBIFS,and YAFFS. We show some very particular\nbehaviors and large performance disparities for tested FFS operations such as\nmounting, copying, and searching file trees, compression, etc."
},{
    "category": "cs.PF", 
    "doi": "10.1002/cpe.3180", 
    "link": "http://arxiv.org/pdf/1209.1811v2", 
    "title": "Evaluating the SiteStory Transactional Web Archive With the ApacheBench   Tool", 
    "arxiv-id": "1209.1811v2", 
    "author": "Michael L. Nelson", 
    "publish": "2012-09-09T16:39:23Z", 
    "summary": "Conventional Web archives are created by periodically crawling a web site and\narchiving the responses from the Web server. Although easy to implement and\ncommon deployed, this form of archiving typically misses updates and may not be\nsuitable for all preservation scenarios, for example a site that is required\n(perhaps for records compliance) to keep a copy of all pages it has served. In\ncontrast, transactional archives work in conjunction with a Web server to\nrecord all pages that have been served. Los Alamos National Laboratory has\ndeveloped SiteSory, an open-source transactional archive written in Java\nsolution that runs on Apache Web servers, provides a Memento compatible access\ninterface, and WARC file export features. We used the ApacheBench utility on a\npre-release version of to measure response time and content delivery time in\ndifferent environments and on different machines. The performance tests were\ndesigned to determine the feasibility of SiteStory as a production-level\nsolution for high fidelity automatic Web archiving. We found that SiteStory\ndoes not significantly affect content server performance when it is performing\ntransactional archiving. Content server performance slows from 0.076 seconds to\n0.086 seconds per Web page access when the content server is under load, and\nfrom 0.15 seconds to 0.21 seconds when the resource has many embedded and\nchanging resources."
},{
    "category": "cs.IR", 
    "doi": "10.1002/cpe.3180", 
    "link": "http://arxiv.org/pdf/1209.1983v1", 
    "title": "Toward a New Protocol to Evaluate Recommender Systems", 
    "arxiv-id": "1209.1983v1", 
    "author": "Eric Gaussier", 
    "publish": "2012-09-10T13:27:23Z", 
    "summary": "In this paper, we propose an approach to analyze the performance and the\nadded value of automatic recommender systems in an industrial context. We show\nthat recommender systems are multifaceted and can be organized around 4\nstructuring functions: help users to decide, help users to compare, help users\nto discover, help users to explore. A global off line protocol is then proposed\nto evaluate recommender systems. This protocol is based on the definition of\nappropriate evaluation measures for each aforementioned function. The\nevaluation protocol is discussed from the perspective of the usefulness and\ntrust of the recommendation. A new measure called Average Measure of Impact is\nintroduced. This measure evaluates the impact of the personalized\nrecommendation. We experiment with two classical methods, K-Nearest Neighbors\n(KNN) and Matrix Factorization (MF), using the well known dataset: Netflix. A\nsegmentation of both users and items is proposed to finely analyze where the\nalgorithms perform well or badly. We show that the performance is strongly\ndependent on the segments and that there is no clear correlation between the\nRMSE and the quality of the recommendation."
},{
    "category": "cs.NI", 
    "doi": "10.1002/cpe.3180", 
    "link": "http://arxiv.org/pdf/1209.2508v1", 
    "title": "Acquisition probability of multi-user UWB systems in the presence of a   novel synchronization approach", 
    "arxiv-id": "1209.2508v1", 
    "author": "Ridha Bouallegue", 
    "publish": "2012-09-12T07:25:19Z", 
    "summary": "In this paper, to synchronize Ultra Wideband (UWB) systems in ad-hoc\nmulti-user environments, we propose a new timing acquisition approach for\nachieving a good performance despite the difficulties to get there.\nSynchronization constraints are caused by the ultra-short emitted waveforms\nnature of UWB signals. Used in [1, 2] for single-user environments, our timing\nacquisition approach is based on two successive stages or floors. Extended for\nmulti-user environments, the used algorithm is a combination between coarse\nsynchronization based on timing with dirty templates (TDT) acquisition scheme\nand a new fine synchronization scheme developed in [3-6] which conduct to an\nimproved estimate of timing offset. In this work, we develop and test this\nmethod in both data-aided (DA) and non-data-aided (NDA) modes. Simulation\nresults and comparisons are also given to confirm performance improvement of\nour approach (in terms of mean square error and acquisition probability)\ncompared to the original TDT algorithm in multi-user environments, especially\nin the NDA mode."
},{
    "category": "cs.PF", 
    "doi": "10.1002/cpe.3180", 
    "link": "http://arxiv.org/pdf/1209.3253v1", 
    "title": "A framework for the analytical performance assessment of matrix and   tensor-based ESPRIT-type algorithms", 
    "arxiv-id": "1209.3253v1", 
    "author": "Martin Haardt", 
    "publish": "2012-09-14T16:36:49Z", 
    "summary": "In this paper we present a generic framework for the asymptotic performance\nanalysis of subspace-based parameter estimation schemes. It is based on earlier\nresults on an explicit first-order expansion of the estimation error in the\nsignal subspace obtained via an SVD of the noisy observation matrix. We extend\nthese results in a number of aspects. Firstly, we derive an explicit\nfirst-order expansion of the Higher- Order SVD (HOSVD)-based subspace estimate.\nSecondly, we show how to obtain explicit first-order expansions of the\nestimation error of ESPRIT-type algorithms and provide the expressions for\nmatrix-based and tensor-based Standard ESPRIT and Unitary ESPRIT. Thirdly, we\nderive closed-form expressions for the mean square error (MSE) and show that\nthey only depend on the second-order moments of the noise. Hence, we only need\nthe noise to be zero mean and possess finite second order moments. Fourthly, we\ninvestigate the effect of using Structured Least Squares (SLS) to solve the\noverdetermined shift invariance equations in ESPRIT and provide an explicit\nfirst-order expansion as well as a closed-form MSE expression. Finally, we\nsimplify the MSE for the special case of a single source and compute the\nasymptotic efficiency of the investigated ESPRIT-type algorithms in compact\nclosed-form expressions which only depend on the array size and the effective\nSNR. Our results are more general than existing results on the performance\nanalysis of ESPRIT-type algorithms since (a) we do not need any assumptions\nabout the noise except for the mean to be zero and the second-order moments to\nbe finite (in contrast to earlier results that require Gaussianity or\nsecond-order circular symmetry); (b) our results are asymptotic in the\neffective SNR, i.e., we do not require the number of samples to be large; (c)\nwe present a framework that incorporates various ESPRIT-type algorithms in one\nunified manner."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.comnet.2013.08.001", 
    "link": "http://arxiv.org/pdf/1209.3638v2", 
    "title": "Congestion Control of TCP Flows in Internet Routers by Means of Index   Policy", 
    "arxiv-id": "1209.3638v2", 
    "author": "Peter Jacko", 
    "publish": "2012-09-17T12:42:23Z", 
    "summary": "In this paper we address the problem of fast and fair transmission of flows\nin a router, which is a fundamental issue in networks like the Internet. We\nmodel the interaction between a TCP source and a bottleneck queue with the\nobjective of designing optimal packet admission controls in the bottleneck\nqueue. We focus on the relaxed version of the problem obtained by relaxing the\nfixed buffer capacity constraint that must be satisfied at all time epoch. The\nrelaxation allows us to reduce the multi-flow problem into a family of\nsingle-flow problems, for which we can analyze both theoretically and\nnumerically the existence of optimal control policies of special structure. In\nparticular, we show that for a variety of parameters, TCP flows can be\noptimally controlled in routers by so-called index policies, but not always by\nthreshold policies. We have also implemented index policies in Network\nSimulator-3 and tested in a simple topology their applicability in real\nnetworks. The simulation results show that the index policy covers a big range\nof desirable properties with respect to fairness between different versions of\nTCP models, across users with different round-trip-time and minimum buffer\nrequired to achieve full utility of the queue."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPCC.2012.125", 
    "link": "http://arxiv.org/pdf/1209.3721v1", 
    "title": "A Resource Intensive Traffic-Aware Scheme for Cluster-based Energy   Conservation in Wireless Devices", 
    "arxiv-id": "1209.3721v1", 
    "author": "Muneer Bani Yassein", 
    "publish": "2012-09-17T16:59:51Z", 
    "summary": "Wireless traffic that is destined for a certain device in a network, can be\nexploited in order to minimize the availability and delay trade-offs, and\nmitigate the Energy consumption. The Energy Conservation (EC) mechanism can be\nnode-centric by considering the traversed nodal traffic in order to prolong the\nnetwork lifetime. This work describes a quantitative traffic-based approach\nwhere a clustered Sleep-Proxy mechanism takes place in order to enable each\nnode to sleep according to the time duration of the active traffic that each\nnode expects and experiences. Sleep-proxies within the clusters are created\naccording to pairwise active-time comparison, where each node expects during\nthe active periods, a requested traffic. For resource availability and recovery\npurposes, the caching mechanism takes place in case where the node for which\nthe traffic is destined is not available. The proposed scheme uses Role-based\nnodes which are assigned to manipulate the traffic in a cluster, through the\ntime-oriented backward difference traffic evaluation scheme. Simulation study\nis carried out for the proposed backward estimation scheme and the\neffectiveness of the end-to-end EC mechanism taking into account a number of\nmetrics and measures for the effects while incrementing the sleep time duration\nunder the proposed framework. Comparative simulation results show that the\nproposed scheme could be applied to infrastructure-less systems, providing\nenergy-efficient resource exchange with significant minimization in the power\nconsumption of each device."
},{
    "category": "cs.NI", 
    "doi": "10.1109/HPCC.2012.125", 
    "link": "http://arxiv.org/pdf/1209.4527v1", 
    "title": "Delay-Optimal Data Forwarding in Vehicular Sensor Networks", 
    "arxiv-id": "1209.4527v1", 
    "author": "Song Chong", 
    "publish": "2012-09-20T13:38:48Z", 
    "summary": "Vehicular Sensor Network (VSN) is emerging as a new solution for monitoring\nurban environments such as Intelligent Transportation Systems and air\npollution. One of the crucial factors that determine the service quality of\nurban monitoring applications is the delivery delay of sensing data packets in\nthe VSN. In this paper, we study the problem of routing data packets with\nminimum delay in the VSN, by exploiting i) vehicle traffic statistics, ii)\nanycast routing and iii) knowledge of future trajectories of vehicles such as\nbuses. We first introduce a novel road network graph model that incorporates\nthe three factors into the routing metric. We then characterize the packet\ndelay on each edge as a function of the vehicle density, speed and the length\nof the edge. Based on the network model and delay function, we formulate the\npacket routing problem as a Markov Decision Process (MDP) and develop an\noptimal routing policy by solving the MDP. Evaluations using real vehicle\ntraces in a city show that our routing policy significantly improves the delay\nperformance compared to existing routing protocols."
},{
    "category": "cs.NI", 
    "doi": "10.1109/HPCC.2012.125", 
    "link": "http://arxiv.org/pdf/1209.5074v1", 
    "title": "Locating Disruptions on Internet Paths through End-to-End Measurements", 
    "arxiv-id": "1209.5074v1", 
    "author": "Yuming Jiang", 
    "publish": "2012-09-23T15:13:38Z", 
    "summary": "In backbone networks carrying heavy traffic loads, unwanted and unusual\nend-to-end delay changes can happen, though possibly rarely. In order to\nunderstand and manage the network to potentially avoid such abrupt changes, it\nis crucial and challenging to locate where in the network lies the cause of\nsuch delays so that some corresponding actions may be taken. To tackle this\nchallenge, the present paper proposes a simple and novel approach. The proposed\napproach relies only on end-to-end measurements, unlike literature approaches\nthat often require a distributed and possibly complicated monitoring /\nmeasurement infrastructure. Here, the key idea of the proposed approach is to\nmake use of compressed sensing theory to estimate delays on each hop between\nthe two nodes where end-to-end delay measurement is conducted, and infer\ncritical hops that contribute to the abrupt delay increases. To demonstrate its\neffectiveness, the proposed approach is applied to a real network. The results\nare encouraging, showing that the proposed approach is able to locate the hops\nthat have the most significant impact on or contribute the most to abrupt\nincreases on the end-to-end delay."
},{
    "category": "cs.PF", 
    "doi": "10.1109/HPCC.2012.125", 
    "link": "http://arxiv.org/pdf/1210.8421v2", 
    "title": "Distribution of the Number of Retransmissions of Bounded Documents", 
    "arxiv-id": "1210.8421v2", 
    "author": "Evangelia D. Skiani", 
    "publish": "2012-10-31T18:04:47Z", 
    "summary": "Retransmission-based failure recovery represents a primary approach in\nexisting communication networks that guarantees data delivery in the presence\nof channel failures. Recent work has shown that, when data sizes have infinite\nsupport, retransmissions can cause long (-tailed) delays even if all traffic\nand network characteristics are light-tailed. In this paper we investigate the\npractically important case of bounded data units 0 <= L_b <= b under the\ncondition that the hazard functions of the distributions of data sizes and\nchannel statistics are proportional. To this end, we provide an explicit and\nuniform characterization of the entire body of the retransmission distribution\nPr[N_b > n] in both n and b. Our main discovery is that this distribution can\nbe represented as the product of a power law and Gamma distribution. This\nrigorous approximation clearly demonstrates the coupling of a power law\ndistribution, dominating the main body, and the Gamma distribution, determining\nthe exponential tail. Our results are validated via simulation experiments and\ncan be useful for designing retransmission-based systems with the required\nperformance characteristics. From a broader perspective, this study applies to\nany other system, e.g., computing, where restart mechanisms are employed after\na job processing failure."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2013.131118", 
    "link": "http://arxiv.org/pdf/1211.0313v1", 
    "title": "Multiple Antenna Cyclostationary Spectrum Sensing Based on the Cyclic   Correlation Significance Test", 
    "arxiv-id": "1211.0313v1", 
    "author": "Danijela Cabric", 
    "publish": "2012-11-01T21:30:52Z", 
    "summary": "In this paper, we propose and analyze a spectrum sensing method based on\ncyclostationarity specifically targeted for receivers with multiple antennas.\nThis detection method is used for determining the presence or absence of\nprimary users in cognitive radio networks based on the eigenvalues of the\ncyclic covariance matrix of received signals. In particular, the cyclic\ncorrelation significance test is used to detect a specific signal-of-interest\nby exploiting knowledge of its cyclic frequencies. Analytical expressions for\nthe probability of detection and probability of false-alarm under both\nspatially uncorrelated or spatially correlated noise are derived and verified\nby simulation. The detection performance in a Rayleigh flat-fading environment\nis found and verified through simulations. One of the advantages of the\nproposed method is that the detection threshold is shown to be independent of\nboth the number of samples and the noise covariance, effectively eliminating\nthe dependence on accurate noise estimation. The proposed method is also shown\nto provide higher detection probability and better robustness to noise\nuncertainty than existing multiple-antenna cyclostationary-based spectrum\nsensing algorithms under both AWGN as well as a quasi-static Rayleigh fading\nchannel."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2013.131118", 
    "link": "http://arxiv.org/pdf/1211.0557v1", 
    "title": "Stochastic Superoptimization", 
    "arxiv-id": "1211.0557v1", 
    "author": "Alex Aiken", 
    "publish": "2012-11-02T20:23:23Z", 
    "summary": "We formulate the loop-free, binary superoptimization task as a stochastic\nsearch problem. The competing constraints of transformation correctness and\nperformance improvement are encoded as terms in a cost function, and a Markov\nChain Monte Carlo sampler is used to rapidly explore the space of all possible\nprograms to find one that is an optimization of a given target program.\nAlthough our method sacrifices com- pleteness, the scope of programs we are\nable to reason about, and the quality of the programs we produce, far exceed\nthose of existing superoptimizers. Beginning from binaries com- piled by llvm\n-O0 for 64-bit X86, our prototype implemen- tation, STOKE, is able to produce\nprograms which either match or outperform the code sequences produced by gcc\nwith full optimizations enabled, and, in some cases, expert handwritten\nassembly."
},{
    "category": "hep-lat", 
    "doi": "10.1109/JSAC.2013.131118", 
    "link": "http://arxiv.org/pdf/1211.0820v1", 
    "title": "Performance of SSE and AVX Instruction Sets", 
    "arxiv-id": "1211.0820v1", 
    "author": "Seok-Ho Myung", 
    "publish": "2012-11-05T10:39:40Z", 
    "summary": "SSE (streaming SIMD extensions) and AVX (advanced vector extensions) are SIMD\n(single instruction multiple data streams) instruction sets supported by recent\nCPUs manufactured in Intel and AMD. This SIMD programming allows parallel\nprocessing by multiple cores in a single CPU. Basic arithmetic and data\ntransfer operations such as sum, multiplication and square root can be\nprocessed simultaneously. Although popular compilers such as GNU compilers and\nIntel compilers provide automatic SIMD optimization options, one can obtain\nbetter performance by a manual SIMD programming with proper optimization: data\npacking, data reuse and asynchronous data transfer. In particular, linear\nalgebraic operations of vectors and matrices can be easily optimized by the\nSIMD programming. Typical calculations in lattice gauge theory are composed of\nlinear algebraic operations of gauge link matrices and fermion vectors, and so\ncan adopt the manual SIMD programming to improve the performance."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2013.131118", 
    "link": "http://arxiv.org/pdf/1211.1581v1", 
    "title": "Data-parallel programming with Intel Array Building Blocks (ArBB)", 
    "arxiv-id": "1211.1581v1", 
    "author": "Volker Weinberg", 
    "publish": "2012-11-07T16:00:28Z", 
    "summary": "Intel Array Building Blocks is a high-level data-parallel programming\nenvironment designed to produce scalable and portable results on existing and\nupcoming multi- and many-core platforms.\n  We have chosen several mathematical kernels - a dense matrix-matrix\nmultiplication, a sparse matrix-vector multiplication, a 1-D complex FFT and a\nconjugate gradients solver - as synthetic benchmarks and representatives of\nscientific codes and ported them to ArBB. This whitepaper describes the ArBB\nports and presents performance and scaling measurements on the Westmere-EX\nbased system SuperMIG at LRZ in comparison with OpenMP and MKL."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSAC.2013.131118", 
    "link": "http://arxiv.org/pdf/1211.3250v1", 
    "title": "Deriving Pareto-optimal performance bounds for 1 and 2-relay wireless   networks", 
    "arxiv-id": "1211.3250v1", 
    "author": "Jean-Marie Gorce", 
    "publish": "2012-11-14T09:38:24Z", 
    "summary": "This work addresses the problem of deriving fundamental trade-off bounds for\na 1-relay and a 2-relay wireless network when multiple performance criteria are\nof interest. It proposes a simple MultiObjective (MO) performance evaluation\nframework composed of a broadcast and interference-limited network model;\ncapacity, delay and energy performance metrics and an associated MO\noptimization problem. Pareto optimal performance bounds between end-to-end\ndelay and energy for a capacity-achieving network are given for 1-relay and\n2-relay topologies and assessed through simulations. Moreover, we also show in\nthis paper that these bounds are tight since they can be reached by simple\npractical coding strategies performed by the source and the relays. Two\ndifferent types of network coding strategies are investigated. Practical\nperformance bounds for both strategies are compared to the theoretical upper\nbound. Results confirm that the proposed upper bound on delay and energy\nperformance is tight and can be reached with the proposed combined source and\nnetwork coding strategies."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSAC.2013.131118", 
    "link": "http://arxiv.org/pdf/1212.0075v2", 
    "title": "Optimal Power Allocation for Outage Minimization in Fading Channels with   Energy Harvesting Constraints", 
    "arxiv-id": "1212.0075v2", 
    "author": "Shuguang Cui", 
    "publish": "2012-12-01T07:01:57Z", 
    "summary": "This paper studies the optimal power allocation for outage minimization in\npoint-to-point fading channels with the energy-harvesting constraints and\nchannel distribution information (CDI) at the transmitter. Both the cases with\nnon-causal and causal energy state information (ESI) are considered, which\ncorrespond to the energy harvesting rates being known and unknown prior to the\ntransmissions, respectively. For the non-causal ESI case, the average outage\nprobability minimization problem over a finite horizon is shown to be\nnon-convex for a large class of practical fading channels. However, the\nglobally optimal \"offline\" power allocation is obtained by a forward search\nalgorithm with at most $N$ one-dimensional searches, and the optimal power\nprofile is shown to be non-decreasing over time and have an interesting\n\"save-then-transmit\" structure. In particular, for the special case of N=1, our\nresult revisits the classic outage capacity for fading channels with uniform\npower allocation. Moreover, for the case with causal ESI, we propose both the\noptimal and suboptimal \"online\" power allocation algorithms, by applying the\ntechnique of dynamic programming and exploring the structure of optimal offline\nsolutions, respectively."
},{
    "category": "cs.SE", 
    "doi": "10.1007/978-3-642-15654-0", 
    "link": "http://arxiv.org/pdf/1212.4247v1", 
    "title": "Information model for model driven safety requirements management of   complex systems", 
    "arxiv-id": "1212.4247v1", 
    "author": "Nabil Sadou", 
    "publish": "2012-12-18T07:10:26Z", 
    "summary": "The aim of this paper is to propose a rigorous and complete design framework\nfor complex system based on system engineering (SE) principles. The SE standard\nEIA-632 is used to guide the approach. Within this framework, two aspects are\npresented. The first one concerns the integration of safety requirements and\nmanagement in system engineering process. The objective is to help designers\nand engineers in managing safety of complex systems. The second aspect concerns\nmodel driven design through the definition of an information model. This model\nis based on SysML (System Modeling Language) to address requirements definition\nand their traceability towards the solution and the Verification and Validation\n(V&V) elements."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-15654-0", 
    "link": "http://arxiv.org/pdf/1212.4489v1", 
    "title": "Opportunistic Relaying in Wireless Body Area Networks: Coexistence   Performance", 
    "arxiv-id": "1212.4489v1", 
    "author": "David Smith", 
    "publish": "2012-12-18T05:23:49Z", 
    "summary": "In this paper, a cooperative two-hop communication scheme, together with\nopportunistic relaying (OR), is applied within a mobile wireless body area\nnetwork (WBAN). Its effectiveness in interference mitigation is investigated in\na scenario where there are multiple closely-located networks. Due to a typical\nWBAN's nature, no coordination is used among different WBANs. A suitable\ntime-division-multiple-access (TDMA) is adopted as both an intra-network and\nalso an inter-network access scheme. Extensive on-body and off-body channel\ngain measurements are employed to gauge performance, which are overlaid to\nsimulate a realistic WBAN working environment. It is found that opportunistic\nrelaying is able to improve the signal-to-interference-and-noise ratio (SINR)\nthreshold value at outage probability of 10% by an average of 5 dB, and it is\nalso shown that it can reduce level crossing rate (LCR) significantly at a low\nSINR threshold value. Furthermore, this scheme is more efficient when on-body\nchannels fade less slowly."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-15654-0", 
    "link": "http://arxiv.org/pdf/1212.4846v1", 
    "title": "Operational semantics for product-form solution", 
    "arxiv-id": "1212.4846v1", 
    "author": "Maria Grazia Vigliotti", 
    "publish": "2012-12-19T21:00:28Z", 
    "summary": "In this paper we present product-form solutions from the point of view of\nstochastic process algebra. In previous work we have shown how to derive\nproduct-form solutions for a formalism called Labelled Markov Automata (LMA).\nLMA are very useful as their relation with the Continuous Time Markov Chains is\nvery direct. The disadvantage of using LMA is that the proofs of properties are\ncumbersome. In fact, in LMA it is not possible to use the inductive structure\nof the language in a proof. In this paper we consider a simple stochastic\nprocess algebra that has the great advantage of simplifying the proofs. This\nsimple language has been inspired by PEPA, however, detailed analysis of the\nsemantics of cooperation will show the differences between the two formalisms.\nIt will also be shown that the semantics of the cooperation in process algebra\ninfluences the correctness of the derivation of the product-form solutions."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-15654-0", 
    "link": "http://arxiv.org/pdf/1302.1078v1", 
    "title": "Performance Evaluation of Sparse Matrix Multiplication Kernels on Intel   Xeon Phi", 
    "arxiv-id": "1302.1078v1", 
    "author": "Umit V. Catalyurek", 
    "publish": "2013-02-05T16:06:15Z", 
    "summary": "Intel Xeon Phi is a recently released high-performance coprocessor which\nfeatures 61 cores each supporting 4 hardware threads with 512-bit wide SIMD\nregisters achieving a peak theoretical performance of 1Tflop/s in double\nprecision. Many scientific applications involve operations on large sparse\nmatrices such as linear solvers, eigensolver, and graph mining algorithms. The\ncore of most of these applications involves the multiplication of a large,\nsparse matrix with a dense vector (SpMV). In this paper, we investigate the\nperformance of the Xeon Phi coprocessor for SpMV. We first provide a\ncomprehensive introduction to this new architecture and analyze its peak\nperformance with a number of micro benchmarks. Although the design of a Xeon\nPhi core is not much different than those of the cores in modern processors,\nits large number of cores and hyperthreading capability allow many application\nto saturate the available memory bandwidth, which is not the case for many\ncutting-edge processors. Yet, our performance studies show that it is the\nmemory latency not the bandwidth which creates a bottleneck for SpMV on this\narchitecture. Finally, our experiments show that Xeon Phi's sparse kernel\nperformance is very promising and even better than that of cutting-edge general\npurpose processors and GPUs."
},{
    "category": "cs.DC", 
    "doi": "10.1109/Grid.2012.15", 
    "link": "http://arxiv.org/pdf/1302.1954v1", 
    "title": "On a Catalogue of Metrics for Evaluating Commercial Cloud Services", 
    "arxiv-id": "1302.1954v1", 
    "author": "Rainbow Cai", 
    "publish": "2013-02-08T07:10:19Z", 
    "summary": "Given the continually increasing amount of commercial Cloud services in the\nmarket, evaluation of different services plays a significant role in\ncost-benefit analysis or decision making for choosing Cloud Computing. In\nparticular, employing suitable metrics is essential in evaluation\nimplementations. However, to the best of our knowledge, there is not any\nsystematic discussion about metrics for evaluating Cloud services. By using the\nmethod of Systematic Literature Review (SLR), we have collected the de facto\nmetrics adopted in the existing Cloud services evaluation work. The collected\nmetrics were arranged following different Cloud service features to be\nevaluated, which essentially constructed an evaluation metrics catalogue, as\nshown in this paper. This metrics catalogue can be used to facilitate the\nfuture practice and research in the area of Cloud services evaluation.\nMoreover, considering metrics selection is a prerequisite of benchmark\nselection in evaluation implementations, this work also supplements the\nexisting research in benchmarking the commercial Cloud services."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CLOUD.2012.74", 
    "link": "http://arxiv.org/pdf/1302.1957v1", 
    "title": "Towards a Taxonomy of Performance Evaluation of Commercial Cloud   Services", 
    "arxiv-id": "1302.1957v1", 
    "author": "He Zhang", 
    "publish": "2013-02-08T07:20:30Z", 
    "summary": "Cloud Computing, as one of the most promising computing paradigms, has become\nincreasingly accepted in industry. Numerous commercial providers have started\nto supply public Cloud services, and corresponding performance evaluation is\nthen inevitably required for Cloud provider selection or cost-benefit analysis.\nUnfortunately, inaccurate and confusing evaluation implementations can be often\nseen in the context of commercial Cloud Computing, which could severely\ninterfere and spoil evaluation-related comprehension and communication. This\npaper introduces a taxonomy to help profile and standardize the details of\nperformance evaluation of commercial Cloud services. Through a systematic\nliterature review, we constructed the taxonomy along two dimensions by\narranging the atomic elements of Cloud-related performance evaluation. As such,\nthis proposed taxonomy can be employed both to analyze existing evaluation\npractices through decomposition into elements and to design new experiments\nthrough composing elements for evaluating performance of commercial Cloud\nservices. Moreover, through smooth expansion, we can continually adapt this\ntaxonomy to the more general area of evaluation of Cloud Computing."
},{
    "category": "cs.NI", 
    "doi": "10.1109/CLOUD.2012.74", 
    "link": "http://arxiv.org/pdf/1302.3250v4", 
    "title": "Exploiting the Past to Reduce Delay in CSMA Scheduling: A High-order   Markov Chain Approach", 
    "arxiv-id": "1302.3250v4", 
    "author": "Do Young Eun", 
    "publish": "2013-02-13T21:39:34Z", 
    "summary": "Recently several CSMA algorithms based on the Glauber dynamics model have\nbeen proposed for multihop wireless scheduling, as viable solutions to achieve\nthe throughput optimality, yet are simple to implement. However, their delay\nperformances still remain unsatisfactory, mainly due to the nature of the\nunderlying Markov chains that imposes a fundamental constraint on how the link\nstate can evolve over time. In this paper, we propose a new approach toward\nbetter queueing and delay performance, based on our observation that the\nalgorithm needs not be Markovian, as long as it can be implemented in a\ndistributed manner, achieve the same throughput optimality, while offering far\nbetter delay performance for general network topologies. Our approach hinges\nupon utilizing past state information observed by local link and then\nconstructing a high-order Markov chain for the evolution of the feasible link\nschedules. We show in theory and simulation that our proposed algorithm, named\ndelayed CSMA, adds virtually no additional overhead onto the existing\nCSMA-based algorithms, achieves the throughput optimality under the usual\nchoice of link weight as a function of local queue length, and also provides\nmuch better delay performance by effectively `de-correlating' the link state\nprocess (thus removing link starvation) under any arbitrary network topology.\nFrom our extensive simulations we observe that the delay under our algorithm\ncan be often reduced by a factor of 20 over a wide range of scenarios, compared\nto the standard Glauber-dynamics-based CSMA algorithm."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CLOUD.2012.74", 
    "link": "http://arxiv.org/pdf/1302.4085v1", 
    "title": "Comprehensive Resource Measurement and Analysis for HPC Systems with   TACC_Stats", 
    "arxiv-id": "1302.4085v1", 
    "author": "Charng-Da Lu", 
    "publish": "2013-02-17T16:40:10Z", 
    "summary": "High-performance computing (HPC) systems are a complex combination of\nsoftware, processors, memory, networks, and storage systems characterized by\nfrequent disruptive technological advances. Anomalous behavior has to be\nmanually diagnosed and remedied with incomplete and sparse data. It also has\nbeen effort-intensive for users to assess the effectiveness with which they are\nusing the available resources. The data available for system level analyses\nappear from multiple sources and in disparate formats (from Linux \"sysstat\" and\naccounting to scheduler/kernel logs). Sysstat does not resolve its measurements\nby job so that job-oriented analyses require individual measurements. There are\nmany user-oriented performance instrumentation and profiling tools but they\nrequire extensive system knowledge, code changes and recompilation, and thus\nare not widely used. To address this issue, we develop TACC_Stats, a\njob-oriented and logically structured version of the conventional Linux\n\"sysstat/sar\" system-wide performance monitor. We use TACC_Stats-collected data\nfrom a supercomputer \"Ranger\" to demonstrate its effectiveness in two case\nstudies."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CLOUD.2012.74", 
    "link": "http://arxiv.org/pdf/1302.4280v1", 
    "title": "Asynchronous MPI for the Masses", 
    "arxiv-id": "1302.4280v1", 
    "author": "Gerhard Wellein", 
    "publish": "2013-02-18T14:17:37Z", 
    "summary": "We present a simple library which equips MPI implementations with truly\nasynchronous non-blocking point-to-point operations, and which is independent\nof the underlying communication infrastructure. It utilizes the MPI profiling\ninterface (PMPI) and the MPI_THREAD_MULTIPLE thread compatibility level, and\nworks with current versions of Intel MPI, Open MPI, MPICH2, MVAPICH2, Cray MPI,\nand IBM MPI. We show performance comparisons on a commodity InfiniBand cluster\nand two tier-1 systems in Germany, using low-level and application benchmarks.\nIssues of thread/process placement and the peculiarities of different MPI\nimplementations are discussed in detail. We also identify the MPI libraries\nthat already support asynchronous operations. Finally we show how our ideas can\nbe extended to MPI-IO."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CLOUD.2012.74", 
    "link": "http://arxiv.org/pdf/1302.4760v2", 
    "title": "Predicting Intermediate Storage Performance for Workflow Applications", 
    "arxiv-id": "1302.4760v2", 
    "author": "Matei Ripeanu", 
    "publish": "2013-02-19T21:39:16Z", 
    "summary": "Configuring a storage system to better serve an application is a challenging\ntask complicated by a multidimensional, discrete configuration space and the\nhigh cost of space exploration (e.g., by running the application with different\nstorage configurations). To enable selecting the best configuration in a\nreasonable time, we design an end-to-end performance prediction mechanism that\nestimates the turn-around time of an application using storage system under a\ngiven configuration. This approach focuses on a generic object-based storage\nsystem design, supports exploring the impact of optimizations targeting\nworkflow applications (e.g., various data placement schemes) in addition to\nother, more traditional, configuration knobs (e.g., stripe size or replication\nlevel), and models the system operation at data-chunk and control message\nlevel.\n  This paper presents our experience to date with designing and using this\nprediction mechanism. We evaluate this mechanism using micro- as well as\nsynthetic benchmarks mimicking real workflow applications, and a real\napplication.. A preliminary evaluation shows that we are on a good track to\nmeet our objectives: it can scale to model a workflow application run on an\nentire cluster while offering an over 200x speedup factor (normalized by\nresource) compared to running the actual application, and can achieve, in the\nlimited number of scenarios we study, a prediction accuracy that enables\nidentifying the best storage system configuration."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.108.3", 
    "link": "http://arxiv.org/pdf/1302.5171v1", 
    "title": "Software model refactoring based on performance analysis: better working   on software or performance side?", 
    "arxiv-id": "1302.5171v1", 
    "author": "Vittorio Cortellessa", 
    "publish": "2013-02-21T03:59:28Z", 
    "summary": "Several approaches have been introduced in the last few years to tackle the\nproblem of interpreting model-based performance analysis results and\ntranslating them into architectural feedback. Typically the interpretation can\ntake place by browsing either the software model or the performance model. In\nthis paper, we compare two approaches that we have recently introduced for this\ngoal: one based on the detection and solution of performance antipatterns, and\nanother one based on bidirectional model transformations between software and\nperformance models. We apply both approaches to the same example in order to\nillustrate the differences in the obtained performance results. Thereafter, we\nraise the level of abstraction and we discuss the pros and cons of working on\nthe software side and on the performance side."
},{
    "category": "math.PR", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1303.0038v3", 
    "title": "Approximately Optimal Scheduling of an M/G/1 Queue with Heavy Tails", 
    "arxiv-id": "1303.0038v3", 
    "author": "Jean Walrand", 
    "publish": "2013-02-28T22:54:52Z", 
    "summary": "Distributions with a heavy tail are difficult to estimate. If the design of a\nscheduling policy is sensitive to the details of heavy tail distributions of\nthe service times, an approximately optimal solution is difficult to obtain.\nThis paper shows that the optimal scheduling of an M/G/1 queue with heavy\ntailed service times does not present this difficulty and that an approximately\noptimal strategy can be derived by truncating the distributions."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1303.1561v1", 
    "title": "Queuing Theoretic Analysis of Power-performance Tradeoff in   Power-efficient Computing", 
    "arxiv-id": "1303.1561v1", 
    "author": "Nam Sung Kim", 
    "publish": "2013-03-06T22:24:37Z", 
    "summary": "In this paper we study the power-performance relationship of power-efficient\ncomputing from a queuing theoretic perspective. We investigate the interplay of\nseveral system operations including processing speed, system on/off decisions,\nand server farm size. We identify that there are oftentimes \"sweet spots\" in\npower-efficient operations: there exist optimal combinations of processing\nspeed and system settings that maximize power efficiency. For the single server\ncase, a widely deployed threshold mechanism is studied. We show that there\nexist optimal processing speed and threshold value pairs that minimize the\npower consumption. This holds for the threshold mechanism with job batching.\nFor the multi-server case, it is shown that there exist best processing speed\nand server farm size combinations."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1303.1651v2", 
    "title": "Model-guided Performance Analysis of the Sparse Matrix-Matrix   Multiplication", 
    "arxiv-id": "1303.1651v2", 
    "author": "Ulrich Ruede", 
    "publish": "2013-03-07T11:40:27Z", 
    "summary": "Achieving high efficiency with numerical kernels for sparse matrices is of\nutmost importance, since they are part of many simulation codes and tend to use\nmost of the available compute time and resources. In addition, especially in\nlarge scale simulation frameworks the readability and ease of use of\nmathematical expressions are essential components for the continuous\nmaintenance, modification, and extension of software. In this context, the\nsparse matrix-matrix multiplication is of special interest. In this paper we\nthoroughly analyze the single-core performance of sparse matrix-matrix\nmultiplication kernels in the Blaze Smart Expression Template (SET) framework.\nWe develop simple models for estimating the achievable maximum performance, and\nuse them to assess the efficiency of our implementations. Additionally, we\ncompare these kernels with several commonly used SET-based C++ libraries,\nwhich, just as Blaze, aim at combining the requirements of high performance\nwith an elegant user interface. For the different sparse matrix structures\nconsidered here, we show that our implementations are competitive or faster\nthan those of the other SET libraries for most problem sizes on a current Intel\nmulticore processor."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1303.3026v1", 
    "title": "Stochastic Service Curve and Delay Bound Analysis: A Single Node Case", 
    "arxiv-id": "1303.3026v1", 
    "author": "Yuming Jiang", 
    "publish": "2013-03-12T20:59:46Z", 
    "summary": "A packet-switched network node with constant capacity (in bps) is considered,\nwhere packets within each flow are served in the first in first out (FIFO)\nmanner. While this single node system is perhaps the simplest computer\ncommunication system, its stochastic service curve characterization and\nindependent case analysis in the context of stochastic network calculus\n(snetcal) are still basic and many crucial questions surprisingly remain open.\nSpecifically, when the input is a single flow, what stochastic service curve\nand delay bound does the node provide? When the considered flow shares the node\nwith another flow, what stochastic service curve and delay bound does the node\nprovide to the considered flow, and if the two flows are independent, can this\nindependence be made use of and how? The aim of this paper is to provide\nanswers to these fundamental questions."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1303.4538v1", 
    "title": "Optimization of FASTEST-3D for Modern Multicore Systems", 
    "arxiv-id": "1303.4538v1", 
    "author": "Gerhard Wellein", 
    "publish": "2013-03-19T10:18:40Z", 
    "summary": "FASTEST-3D is an MPI-parallel finite-volume flow solver based on\nblock-structured meshes that has been developed at the University of\nErlangen-Nuremberg since the early 1990s. It can be used to solve the laminar\nor turbulent incompressible Navier-Stokes equations. Up to now its scalability\nwas strongly limited by a rather rigid communication infrastructure, which led\nto a dominance of MPI time already at small process counts.\n  This paper describes several optimizations to increase the performance,\nscalability, and flexibility of FASTEST-3D. First, a node-level performance\nanalysis is carried out in order to pinpoint the main bottlenecks and identify\nsweet spots for energy-efficient execution. In addition, a single-precision\nversion of the solver for the linear equation system arising from the\ndiscretization of the governing equations is devised, which significantly\nincreases the single-core performance. Then the communication mechanisms in\nFASTEST-3D are analyzed and a new communication strategy based on non-blocking\ncalls is implemented. Performance results with the revised version show\nsignificantly increased single-node performance and considerably improved\ncommunication patterns along with much better parallel scalability. In this\ncontext we discuss the concept of \"acceptable parallel efficiency\" and how it\ninfluences the real gain of the optimizations. Scaling measurements are carried\nout on a modern petascale system. The obtained improvements are of major\nimportance for the use of FASTEST-3D on current high-performance computer\nclusters and will help to perform simulations with much higher spatial and\ntemporal resolution to tackle turbulent flow in technical applications."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1308.0678v1", 
    "title": "Performance comparison of IEEE 802.11g and IEEE 802.11n in the presence   of interference from 802.15.4 networks", 
    "arxiv-id": "1308.0678v1", 
    "author": "Syed Haani Masood", 
    "publish": "2013-08-03T10:17:12Z", 
    "summary": "In this paper we compare the packet error rate (PER) and maximum throughput\nof IEEE 802.11n and IEEE 802.11g under interference from IEEE 802.15.4 by using\nMATLAB to simulate the IEEE PHY for 802.11n and 802.11g networks."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1308.3123v1", 
    "title": "First experiences with the Intel MIC architecture at LRZ", 
    "arxiv-id": "1308.3123v1", 
    "author": "Momme Allalen", 
    "publish": "2013-08-14T13:46:37Z", 
    "summary": "With the rapidly growing demand for computing power new accelerator based\narchitectures have entered the world of high performance computing since around\n5 years. In particular GPGPUs have recently become very popular, however\nprogramming GPGPUs using programming languages like CUDA or OpenCL is\ncumbersome and error-prone. Trying to overcome these difficulties, Intel\ndeveloped their own Many Integrated Core (MIC) architecture which can be\nprogrammed using standard parallel programming techniques like OpenMP and MPI.\nIn the beginning of 2013, the first production-level cards named Intel Xeon Phi\ncame on the market. LRZ has been considered by Intel as a leading research\ncentre for evaluating coprocessors based on the MIC architecture since 2010\nunder strict NDA. Since the Intel Xeon Phi is now generally available, we can\nshare our experience on programming Intel's new MIC architecture."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1308.3855v1", 
    "title": "Measurement and Prediction of Centrical/Peripheral Network Properties   based on Regression Analysis - A Parametric Foundation for Performance   Self-Management in WSNs", 
    "arxiv-id": "1308.3855v1", 
    "author": "Jens B. Schmitt", 
    "publish": "2013-08-18T12:52:38Z", 
    "summary": "Predicting performance-related behavior of the underlying network structure\nbecomes more and more indispensable in terms of the aspired application outcome\nquality. However, the reliable forecast of QoS metrics like packet transfer\ndelay in wireless network systems is still a challenging task. Even though\nexisting approaches are technically capable of determining such network\nproperties under certain assumptions, they mostly abstract away from primal\naspects that inherently have an essential impact on temporal network\nperformance dynamics. Also, they usually require auxiliary resources to be\nimplemented and deployed along with the actual network components. In the\ncourse of developing a lightweight measurement-based alternative for the\nself-inspection and prediction of volatile performance characteristics in\nenvironments of any kind, we selectively investigate the duration of message\ndelivery and packet loss rate against various parameters peculiar to common\nradio network technologies like Wireless Sensor Networks (WSNs). Our hands-on\nexperiments reveal the relations between the oftentimes underestimated medium\naccess delay and a variety of main influencing factors including packet size,\nbackoff period, and number of neighbor nodes contending for the communication\nmedium. A closed formulation of selected weighted drivers facilitates the\naverage-case prediction of inter-node packet transfer delays for arbitrary\nconfigurations of given network parameters even on resource-scarce WSN devices.\nWe validate our prediction method against basic multi-hop networking scenarios.\nYield field test results proof the basic feasibility and high precision of our\napproach to network property estimation in virtue of self-governed local\nmeasurements and regression-based calculations paving the way for a prospective\nself-management of network properties based upon autonomous distributed\ncoordination."
},{
    "category": "cs.SE", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1309.0534v1", 
    "title": "Machines are benchmarked by code, not algorithms", 
    "arxiv-id": "1309.0534v1", 
    "author": "Raphael 'kena' Poss", 
    "publish": "2013-09-02T20:34:09Z", 
    "summary": "This article highlights how small modifications to either the source code of\na benchmark program or the compilation options may impact its behavior on a\nspecific machine. It argues that for evaluating machines, benchmark providers\nand users be careful to ensure reproducibility of results based on the machine\ncode actually running on the hardware and not just source code. The article\nuses color to grayscale conversion of digital images as a running example."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1309.0718v1", 
    "title": "A General, Tractable and Accurate Model for a Cascade of Caches", 
    "arxiv-id": "1309.0718v1", 
    "author": "A. Detti", 
    "publish": "2013-09-03T15:14:44Z", 
    "summary": "Performance evaluation of caching systems is an old and widely investigated\nresearch topic. The research community is once again actively working on this\ntopic because the Internet is evolving towards new transfer modes, which\nenvisage to cache both contents and instructions within the network. In\nparticular, there is interest in characterizing multi-cache systems, in which\nrequests not satisfied by a cache are forwarded to other caches.\n  In this field, this paper contributes as follows. First, we devise a simple\nbut accurate approximate analysis for caches fed by general \"renewal\" traffic\npatterns. Second, we characterize and model the traffic statistics for the\noutput (miss) stream. Third, we show in the simple example case of tandem\ncaches how the resulting output stream model can be conveniently exploited to\nanalyze the performance of subsequent cache stages. The main novelty of our\nwork stems in the ability to handle traffic patterns beyond the traditional\nindependent reference model, thus permitting simple assessment of cascade of\ncaches as well as improved understanding of the phenomena involved in cache\nhierarchies."
},{
    "category": "cs.OS", 
    "doi": "10.1007/s11134-015-9435-0", 
    "link": "http://arxiv.org/pdf/1309.1714v1", 
    "title": "Flashmon V2: Monitoring Raw NAND Flash Memory I/O Requests on Embedded   Linux", 
    "arxiv-id": "1309.1714v1", 
    "author": "Eric Senn", 
    "publish": "2013-09-06T18:14:04Z", 
    "summary": "This paper presents Flashmon version 2, a tool for monitoring embedded Linux\nNAND flash memory I/O requests. It is designed for embedded boards based\ndevices containing raw flash chips. Flashmon is a kernel module and stands for\n\"flash monitor\". It traces flash I/O by placing kernel probes at the NAND\ndriver level. It allows tracing at runtime the 3 main flash operations: page\nreads / writes and block erasures. Flashmon is (1) generic as it was\nsuccessfully tested on the three most widely used flash file systems that are\nJFFS2, UBIFS and YAFFS, and several NAND chip models. Moreover, it is (2) non\nintrusive, (3) has a controllable memory footprint, and (4) exhibits a low\noverhead (<6%) on the traced system. Finally, it is (5) simple to integrate and\nused as a standalone module or as a built-in function / module in existing\nkernel sources. Monitoring flash memory operations allows a better\nunderstanding of existing flash management systems by studying and analyzing\ntheir behavior. Moreover it is useful in development phase for prototyping and\nvalidating new solutions."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1309.1983v1", 
    "title": "Memory transfer optimization for a lattice Boltzmann solver on Kepler   architecture nVidia GPUs", 
    "arxiv-id": "1309.1983v1", 
    "author": "Alistair Revell", 
    "publish": "2013-09-08T17:37:32Z", 
    "summary": "The Lattice Boltzmann method (LBM) for solving fluid flow is naturally well\nsuited to an efficient implementation for massively parallel computing, due to\nthe prevalence of local operations in the algorithm. This paper presents and\nanalyses the performance of a 3D lattice Boltzmann solver, optimized for third\ngeneration nVidia GPU hardware, also known as `Kepler'. We provide a review of\nprevious optimisation strategies and analyse data read/write times for\ndifferent memory types. In LBM, the time propagation step (known as streaming),\ninvolves shifting data to adjacent locations and is central to parallel\nperformance; here we examine three approaches which make use of different\nhardware options. Two of which make use of `performance enhancing' features of\nthe GPU; shared memory and the new shuffle instruction found in Kepler based\nGPUs. These are compared to a standard transfer of data which relies instead on\noptimised storage to increase coalesced access. It is shown that the more\nsimple approach is most efficient; since the need for large numbers of\nregisters per thread in LBM limits the block size and thus the efficiency of\nthese special features is reduced. Detailed results are obtained for a D3Q19\nLBM solver, which is benchmarked on nVidia K5000M and K20C GPUs. In the latter\ncase the use of a read-only data cache is explored, and peak performance of\nover 1036 Million Lattice Updates Per Second (MLUPS) is achieved. The\nappearance of a periodic bottleneck in the solver performance is also reported,\nbelieved to be hardware related; spikes in iteration-time occur with a\nfrequency of around 11Hz for both GPUs, independent of the size of the problem."
},{
    "category": "cs.AI", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1309.7173v2", 
    "title": "Analysis of Optimization Techniques to Improve User Response Time of Web   Applications and Their Implementation for MOODLE", 
    "arxiv-id": "1309.7173v2", 
    "author": "Priyanka Manchanda", 
    "publish": "2013-09-27T09:27:01Z", 
    "summary": "Analysis of seven optimization techniques grouped under three categories\n(hardware, back-end, and front-end) is done to study the reduction in average\nuser response time for Modular Object Oriented Dynamic Learning Environment\n(Moodle), a Learning Management System which is scripted in PHP5, runs on\nApache web server and utilizes MySQL database software. Before the\nimplementation of these techniques, performance analysis of Moodle is performed\nfor varying number of concurrent users. The results obtained for each\noptimization technique are then reported in a tabular format. The maximum\nreduction in end user response time was achieved for hardware optimization\nwhich requires Moodle server and database to be installed on solid state disk."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1311.0378v1", 
    "title": "Comparative Performance Analysis of Intel Xeon Phi, GPU, and CPU", 
    "arxiv-id": "1311.0378v1", 
    "author": "Joel Saltz", 
    "publish": "2013-11-02T14:00:40Z", 
    "summary": "We investigate and characterize the performance of an important class of\noperations on GPUs and Many Integrated Core (MIC) architectures. Our work is\nmotivated by applications that analyze low-dimensional spatial datasets\ncaptured by high resolution sensors, such as image datasets obtained from whole\nslide tissue specimens using microscopy image scanners. We identify the data\naccess and computation patterns of operations in object segmentation and\nfeature computation categories. We systematically implement and evaluate the\nperformance of these core operations on modern CPUs, GPUs, and MIC systems for\na microscopy image analysis application. Our results show that (1) the data\naccess pattern and parallelization strategy employed by the operations strongly\naffect their performance. While the performance on a MIC of operations that\nperform regular data access is comparable or sometimes better than that on a\nGPU; (2) GPUs are significantly more efficient than MICs for operations and\nalgorithms that irregularly access data. This is a result of the low\nperformance of the latter when it comes to random data access; (3) adequate\ncoordinated execution on MICs and CPUs using a performance aware task\nscheduling strategy improves about 1.29x over a first-come-first-served\nstrategy. The example application attained an efficiency of 84% in an execution\nwith of 192 nodes (3072 CPU cores and 192 MICs)."
},{
    "category": "math.GM", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1311.0960v2", 
    "title": "The abstract Cauchy problem for the non-stationary bulk queue M(t)|M[k,   B]|1", 
    "arxiv-id": "1311.0960v2", 
    "author": "Yong Chol Chon", 
    "publish": "2013-11-05T03:42:19Z", 
    "summary": "We derived state probability equations describing the queue M(t)|M[k, B]|1\nand formulated as an abstract Cauchy problem to investigate by means of the\nsemi-group theory of bounded linear operators in functional analysis. For the\nabstract Cauchy problem of this queue, we determined the eigenfunctions of\nmaximal operator and showed some properties of the Dirichlet operator."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1311.1195v1", 
    "title": "Performance Modeling of BitTorrent Peer-to-Peer File Sharing Networks", 
    "arxiv-id": "1311.1195v1", 
    "author": "Kunjie Xu", 
    "publish": "2013-11-05T20:57:26Z", 
    "summary": "BitTorrent is undoubtedly the most popular P2P file sharing application on\ntoday's Internet. The widespread popularity of BitTorrent has attracted a great\ndeal of attention from networking researchers who conducted various performance\nstudies on it. This paper presents a comprehensive survey of analytical\nperformance modeling techniques for BitTorrent networks. The performance models\nexamined in this study include deterministic models, Markov chain models, fluid\nflow models, and queuing network models. These models evaluate the performance\nmetrics of BitTorrent networks at different regimes with various realistic\nfactors considered. Furthermore, a comparative analysis is conducted on those\nmodeling techniques in the aspects of complexity, accuracy, extensibility, and\nscalability."
},{
    "category": "cs.DS", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1311.1338v1", 
    "title": "Significance Relations for the Benchmarking of Meta-Heuristic Algorithms", 
    "arxiv-id": "1311.1338v1", 
    "author": "Kei Ohnishi", 
    "publish": "2013-11-06T10:20:56Z", 
    "summary": "The experimental analysis of meta-heuristic algorithm performance is usually\nbased on comparing average performance metric values over a set of algorithm\ninstances. When algorithms getting tight in performance gains, the additional\nconsideration of significance of a metric improvement comes into play. However,\nfrom this moment the comparison changes from an absolute to a relative mode.\nHere the implications of this paradigm shift are investigated. Significance\nrelations are formally established. Based on this, a trade-off between\nincreasing cycle-freeness of the relation and small maximum sets can be\nidentified, allowing for the selection of a proper significance level and\nresulting ranking of a set of algorithms. The procedure is exemplified on the\nCEC'05 benchmark of real parameter single objective optimization problems. The\nsignificance relation here is based on awarding ranking points for relative\nperformance gains, similar to the Borda count voting method or the Wilcoxon\nsigned rank test. In the particular CEC'05 case, five ranks for algorithm\nperformance can be clearly identified."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1311.1907v1", 
    "title": "Proactive bottleneck performance analysis in parallel computing using   openMP", 
    "arxiv-id": "1311.1907v1", 
    "author": "Alok Katiyar", 
    "publish": "2013-11-08T09:17:36Z", 
    "summary": "The aim of parallel computing is to increase an application performance by\nexecuting the application on multiple processors. OpenMP is an API that\nsupports multi platform shared memory programming model and shared-memory\nprograms are typically executed by multiple threads. The use of multi threading\ncan enhance the performance of application but its excessive use can degrade\nthe performance. This paper describes a novel approach to avoid bottlenecks in\napplication and provide some techniques to improve performance in OpenMP\napplication. This paper analyzes bottleneck performance as bottleneck inhibits\nperformance. Performance of multi threaded applications is limited by a variety\nof bottlenecks, e.g. critical sections, barriers and so on. This paper provides\nsome tips how to avoid performance bottleneck problems. This paper focuses on\nhow to reduce overheads and overall execution time to get better performance of\napplication."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.0454v1", 
    "title": "Modelling Load Balancing and Carrier Aggregation in Mobile Networks", 
    "arxiv-id": "1402.0454v1", 
    "author": "A. Simonian", 
    "publish": "2014-02-03T18:21:11Z", 
    "summary": "In this paper, we study the performance of multicarrier mobile networks.\nSpecifically, we analyze the flow-level performance of two inter-carrier load\nbalancing schemes and the gain engendered by Carrier Aggregation (CA). CA is\none of the most important features of HSPA+ and LTE-A networks; it allows\ndevices to be served simultaneously by several carriers. We propose two load\nbalancing schemes, namely Join the Fastest Queue (JFQ) and Volume Balancing\n(VB), that allow the traffic of CA and non-CA users to be distributed over the\naggregated carriers. We then evaluate the performance of these schemes by means\nof analytical modeling. We show that the proposed schemes achieve quasi-ideal\nload balancing. We also investigate the impact of mixing traffic of CA and\nnon-CA users in the same cell and show that performance is practically\ninsensitive to the traffic mix."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.0804v1", 
    "title": "A Measurement-based Analysis of the Energy Consumption of Data Center   Servers", 
    "arxiv-id": "1402.0804v1", 
    "author": "Vincenzo Mancuso", 
    "publish": "2014-02-04T17:40:38Z", 
    "summary": "Energy consumption is a growing issue in data centers, impacting their\neconomic viability and their public image. In this work we empirically\ncharacterize the power and energy consumed by different types of servers. In\nparticular, in order to understand the behavior of their energy and power\nconsumption, we perform measurements in different servers. In each of them, we\nexhaustively measure the power consumed by the CPU, the disk, and the network\ninterface under different configurations, identifying the optimal operational\nlevels. One interesting conclusion of our study is that the curve that defines\nthe minimal CPU power as a function of the load is neither linear nor purely\nconvex as has been previously assumed. Moreover, we find that the efficiency of\nthe various server components can be maximized by tuning the CPU frequency and\nthe number of active cores as a function of the system and network load, while\nthe block size of I/O operations should be always maximized by applications. We\nalso show how to estimate the energy consumed by an application as a function\nof some simple parameters, like the CPU load, and the disk and network\nactivity. We validate the proposed approach by accurately estimating the energy\nof a map-reduce computation in a Hadoop platform."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.3549v1", 
    "title": "Characterizing Workload of Web Applications on Virtualized Servers", 
    "arxiv-id": "1402.3549v1", 
    "author": "Krishna Kavi", 
    "publish": "2014-02-14T18:51:38Z", 
    "summary": "With the ever increasing demands of cloud computing services, planning and\nmanagement of cloud resources has become a more and more important issue which\ndirected affects the resource utilization and SLA and customer satisfaction.\nBut before any management strategy is made, a good understanding of\napplications' workload in virtualized environment is the basic fact and\nprinciple to the resource management methods. Unfortunately, little work has\nbeen focused on this area. Lack of raw data could be one reason; another reason\nis that people still use the traditional models or methods shared under\nnon-virtualized environment. The study of applications' workload in virtualized\nenvironment should take on some of its peculiar features comparing to the\nnon-virtualized environment. In this paper, we are open to analyze the workload\ndemands that reflect applications' behavior and the impact of virtualization.\nThe results are obtained from an experimental cloud testbed running web\napplications, specifically the RUBiS benchmark application. We profile the\nworkload dynamics on both virtualized and non-virtualized environments and\ncompare the findings. The experimental results are valuable for us to estimate\nthe performance of applications on computer architectures, to predict SLA\ncompliance or violation based on the projected application workload and to\nguide the decision making to support applications with the right hardware."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.5194v1", 
    "title": "On Big Data Benchmarking", 
    "arxiv-id": "1402.5194v1", 
    "author": "Xiaoyi Lu", 
    "publish": "2014-02-21T03:03:16Z", 
    "summary": "Big data systems address the challenges of capturing, storing, managing,\nanalyzing, and visualizing big data. Within this context, developing benchmarks\nto evaluate and compare big data systems has become an active topic for both\nresearch and industry communities. To date, most of the state-of-the-art big\ndata benchmarks are designed for specific types of systems. Based on our\nexperience, however, we argue that considering the complexity, diversity, and\nrapid evolution of big data systems, for the sake of fairness, big data\nbenchmarks must include diversity of data and workloads. Given this motivation,\nin this paper, we first propose the key requirements and challenges in\ndeveloping big data benchmarks from the perspectives of generating data with 4V\nproperties (i.e. volume, velocity, variety and veracity) of big data, as well\nas generating tests with comprehensive workloads for big data systems. We then\npresent the methodology on big data benchmarking designed to address these\nchallenges. Next, the state-of-the-art are summarized and compared, following\nby our vision for future research directions."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.5391v1", 
    "title": "Exact Simulation for Assemble-To-Order Systems", 
    "arxiv-id": "1402.5391v1", 
    "author": "Emilie Coupechoux", 
    "publish": "2014-02-21T19:40:38Z", 
    "summary": "We develop exact simulation (also known as perfect sampling) algorithms for a\nfamily of assemble-to-order systems. Due to the finite capacity, and coupling\nin demands and replenishments, known solving techniques are inefficient for\nlarger problem instances. We first consider the case with individual\nreplenishments of items, and derive an event based representation of the Markov\nchain that allows applying existing exact simulation techniques, using the\nmonotonicity properties or bounding chains. In the case of joint\nreplenishments, the state space becomes intractable for the existing methods.\nWe propose new exact simulation algorithms, based on aggregation and bounding\nchains, that allow a significant reduction of the state space of the Markov\nchain. We also discuss the coupling times of considered models and provide\nsufficient conditions for linear (in the single server replenishment case) or\nquadratic (many server case) complexity of our algorithms in terms of the total\ncapacity in the system."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.5987v1", 
    "title": "Exact Analysis of TTL Cache Networks: The Case of Caching Policies   driven by Stopping Times", 
    "arxiv-id": "1402.5987v1", 
    "author": "Florin Ciucu", 
    "publish": "2014-02-24T21:19:39Z", 
    "summary": "TTL caching models have recently regained significant research interest,\nlargely due to their ability to fit popular caching policies such as LRU. This\npaper advances the state-of-the-art analysis of TTL-based cache networks by\ndeveloping two exact methods with orthogonal generality and computational\ncomplexity. The first method generalizes existing results for line networks\nunder renewal requests to the broad class of caching policies whereby evictions\nare driven by stopping times. The obtained results are further generalized,\nusing the second method, to feedforward networks with Markov arrival processes\n(MAP) requests. MAPs are particularly suitable for non-line networks because\nthey are closed not only under superposition and splitting, as known, but also\nunder input-output caching operations as proven herein for phase-type TTL\ndistributions. The crucial benefit of the two closure properties is that they\njointly enable the first exact analysis of feedforward networks of TTL caches\nin great generality."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.cpc.2014.06.003", 
    "link": "http://arxiv.org/pdf/1402.7248v3", 
    "title": "Perfect Simulation of $M/G/c$ Queues", 
    "arxiv-id": "1402.7248v3", 
    "author": "Wilfrid S. Kendall", 
    "publish": "2014-02-28T14:01:46Z", 
    "summary": "In this paper we describe a perfect simulation algorithm for the stable\n$M/G/c$ queue. Sigman (2011: Exact Simulation of the Stationary Distribution of\nthe FIFO M/G/c Queue. Journal of Applied Probability, 48A, 209--213) showed how\nto build a dominated CFTP algorithm for perfect simulation of the super-stable\n$M/G/c$ queue operating under First Come First Served discipline, with\ndominating process provided by the corresponding $M/G/1$ queue (using Wolff's\nsample path monotonicity, which applies when service durations are coupled in\norder of initiation of service), and exploiting the fact that the workload\nprocess for the $M/G/1$ queue remains the same under different queueing\ndisciplines, in particular under the Processor Sharing discipline, for which a\ndynamic reversibility property holds. We generalize Sigman's construction to\nthe stable case by comparing the $M/G/c$ queue to a copy run under Random\nAssignment. This allows us to produce a naive perfect simulation algorithm\nbased on running the dominating process back to the time it first empties. We\nalso construct a more efficient algorithm that uses sandwiching by lower and\nupper processes constructed as coupled $M/G/c$ queues started respectively from\nthe empty state and the state of the $M/G/c$ queue under Random Assignment. A\ncareful analysis shows that appropriate ordering relationships can still be\nmaintained, so long as service durations continue to be coupled in order of\ninitiation of service. We summarize statistical checks of simulation output,\nand demonstrate that the mean run-time is finite so long as the second moment\nof the service duration distribution is finite."
},{
    "category": "cs.SE", 
    "doi": "10.4204/EPTCS.147.6", 
    "link": "http://arxiv.org/pdf/1404.0851v1", 
    "title": "A model-driven approach to broaden the detection of software performance   antipatterns at runtime", 
    "arxiv-id": "1404.0851v1", 
    "author": "Catia Trubiani", 
    "publish": "2014-04-03T10:44:30Z", 
    "summary": "Performance antipatterns document bad design patterns that have negative\ninfluence on system performance. In our previous work we formalized such\nantipatterns as logical predicates that predicate on four views: (i) the static\nview that captures the software elements (e.g. classes, components) and the\nstatic relationships among them; (ii) the dynamic view that represents the\ninteraction (e.g. messages) that occurs between the software entities elements\nto provide the system functionalities; (iii) the deployment view that describes\nthe hardware elements (e.g. processing nodes) and the mapping of the software\nentities onto the hardware platform; (iv) the performance view that collects\nspecific performance indices. In this paper we present a lightweight\ninfrastructure that is able to detect performance antipatterns at runtime\nthrough monitoring. The proposed approach precalculates such predicates and\nidentifies antipatterns whose static, dynamic and deployment sub-predicates are\nvalidated by the current system configuration and brings at runtime the\nverification of performance sub-predicates. The proposed infrastructure\nleverages model-driven techniques to generate probes for monitoring the\nperformance sub-predicates and detecting antipatterns at runtime."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.147.6", 
    "link": "http://arxiv.org/pdf/1404.0975v1", 
    "title": "Analysis of Petri Net Models through Stochastic Differential Equations", 
    "arxiv-id": "1404.0975v1", 
    "author": "Gianfranco Balbo", 
    "publish": "2014-04-03T15:34:24Z", 
    "summary": "It is well known, mainly because of the work of Kurtz, that density dependent\nMarkov chains can be approximated by sets of ordinary differential equations\n(ODEs) when their indexing parameter grows very large. This approximation\ncannot capture the stochastic nature of the process and, consequently, it can\nprovide an erroneous view of the behavior of the Markov chain if the indexing\nparameter is not sufficiently high. Important phenomena that cannot be revealed\ninclude non-negligible variance and bi-modal population distributions. A\nless-known approximation proposed by Kurtz applies stochastic differential\nequations (SDEs) and provides information about the stochastic nature of the\nprocess. In this paper we apply and extend this diffusion approximation to\nstudy stochastic Petri nets. We identify a class of nets whose underlying\nstochastic process is a density dependent Markov chain whose indexing parameter\nis a multiplicative constant which identifies the population level expressed by\nthe initial marking and we provide means to automatically construct the\nassociated set of SDEs. Since the diffusion approximation of Kurtz considers\nthe process only up to the time when it first exits an open interval, we extend\nthe approximation by a machinery that mimics the behavior of the Markov chain\nat the boundary and allows thus to apply the approach to a wider set of\nproblems. The resulting process is of the jump-diffusion type. We illustrate by\nexamples that the jump-diffusion approximation which extends to bounded domains\ncan be much more informative than that based on ODEs as it can provide accurate\nquantity distributions even when they are multi-modal and even for relatively\nsmall population levels. Moreover, we show that the method is faster than\nsimulating the original Markov chain."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.147.6", 
    "link": "http://arxiv.org/pdf/1404.2228v3", 
    "title": "Batch Arrival Multiserver Queue with Setup Time", 
    "arxiv-id": "1404.2228v3", 
    "author": "Tuan Phung-Duc", 
    "publish": "2014-04-07T00:57:26Z", 
    "summary": "Queues with setup time are extensively studied because they have application\nin performance evaluation of power-saving data centers. In a data center, there\nare a huge number of servers which consume a large amount of energy. In the\ncurrent technology, an idle server still consumes about 60\\% of its peak\nprocessing a job. Thus, the only way to save energy is to turn off servers\nwhich are not processing a job. However, when there are some waiting jobs, we\nhave to turn on the OFF servers. A server needs some setup time to be active\nduring which it consumes energy but cannot process a job. Therefore, there\nexists a trade-off between power consumption and delay performance. Gandhi et\nal. \\cite{Gandhi10a,Gandhi10} analyze this trade-off using an M/M/$c$ queue\nwith staggered setup (one server in setup at a time). In this paper, using an\nalternative approach, we obtain generating functions for the joint stationary\ndistribution of the number of active servers and that of jobs in the system for\na more general model with batch arrivals and state-dependent setup time. We\nfurther obtain moments for the queue size. Numerical results reveal that\nkeeping the same traffic intensity, the mean power consumption decreases with\nthe mean batch size for the case of fixed batch size. One of the main\ntheoretical contribution is a new conditional decomposition formula showing\nthat the number of waiting customers under the condition that all servers are\nbusy can be decomposed to the sum of two independent random variables where the\nfirst is the same quantity in the corresponding model without setup time while\nthe second is the number of waiting customers before an arbitrary customer."
},{
    "category": "cs.NI", 
    "doi": "10.1109/GLOCOM.2014.7037532", 
    "link": "http://arxiv.org/pdf/1404.3891v4", 
    "title": "Joint Channel Assignment and Opportunistic Routing for Maximizing   Throughput in Cognitive Radio Networks", 
    "arxiv-id": "1404.3891v4", 
    "author": "Li Li", 
    "publish": "2014-04-15T12:39:10Z", 
    "summary": "In this paper, we consider the joint opportunistic routing and channel\nassignment problem in multi-channel multi-radio (MCMR) cognitive radio networks\n(CRNs) for improving aggregate throughput of the secondary users. We first\npresent the nonlinear programming optimization model for this joint problem,\ntaking into account the feature of CRNs-channel uncertainty. Then considering\nthe queue state of a node, we propose a new scheme to select proper forwarding\ncandidates for opportunistic routing. Furthermore, a new algorithm for\ncalculating the forwarding probability of any packet at a node is proposed,\nwhich is used to calculate how many packets a forwarder should send, so that\nthe duplicate transmission can be reduced compared with MAC-independent\nopportunistic routing & encoding (MORE) [11]. Our numerical results show that\nthe proposed scheme performs significantly better that traditional routing and\nopportunistic routing in which channel assignment strategy is employed."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GLOCOM.2014.7037532", 
    "link": "http://arxiv.org/pdf/1404.5121v1", 
    "title": "SleepScale: Runtime Joint Speed Scaling and Sleep States Management for   Power Efficient Data Centers", 
    "arxiv-id": "1404.5121v1", 
    "author": "Nam Sung Kim", 
    "publish": "2014-04-21T06:12:22Z", 
    "summary": "Power consumption in data centers has been growing significantly in recent\nyears. To reduce power, servers are being equipped with increasingly\nsophisticated power management mechanisms. Different mechanisms offer\ndramatically different trade-offs between power savings and performance\npenalties. Considering the complexity, variety, and temporally varying nature\nof the applications hosted in a typical data center, intelligently determining\nwhich power management policy to use and when is a complicated task.\n  In this paper we analyze a system model featuring both performance scaling\nand low-power states. We reveal the interplay between performance scaling and\nlow-power states via intensive simulation and analytic verification. Based on\nthe observations, we present SleepScale, a runtime power management tool\ndesigned to efficiently exploit existing power control mechanisms. At run time,\nSleepScale characterizes power consumption and quality-of-service (QoS) for\neach low-power state and frequency setting, and selects the best policy for a\ngiven QoS constraint. We evaluate SleepScale using workload traces from data\ncenters and achieve significant power savings relative to conventional power\nmanagement strategies."
},{
    "category": "math.PR", 
    "doi": "10.1109/GLOCOM.2014.7037532", 
    "link": "http://arxiv.org/pdf/1404.6924v1", 
    "title": "Separation of timescales in a two-layered network", 
    "arxiv-id": "1404.6924v1", 
    "author": "Bert Zwart", 
    "publish": "2014-04-28T10:45:03Z", 
    "summary": "We investigate a computer network consisting of two layers occurring in, for\nexample, application servers. The first layer incorporates the arrival of jobs\nat a network of multi-server nodes, which we model as a many-server Jackson\nnetwork. At the second layer, active servers at these nodes act now as\ncustomers who are served by a common CPU. Our main result shows a separation of\ntime scales in heavy traffic: the main source of randomness occurs at the\n(aggregate) CPU layer; the interactions between different types of nodes at the\nother layer is shown to converge to a fixed point at a faster time scale; this\nalso yields a state-space collapse property. Apart from these fundamental\ninsights, we also obtain an explicit approximation for the joint law of the\nnumber of jobs in the system, which is provably accurate for heavily loaded\nsystems and performs numerically well for moderately loaded systems. The\nobtained results for the model under consideration can be applied to\nthread-pool dimensioning in application servers, while the technique seems\napplicable to other layered systems too."
},{
    "category": "cs.SE", 
    "doi": "10.4204/EPTCS.154.6", 
    "link": "http://arxiv.org/pdf/1406.2071v1", 
    "title": "Formal and Informal Methods for Multi-Core Design Space Exploration", 
    "arxiv-id": "1406.2071v1", 
    "author": "Oded Maler", 
    "publish": "2014-06-09T03:50:36Z", 
    "summary": "We propose a tool-supported methodology for design-space exploration for\nembedded systems. It provides means to define high-level models of applications\nand multi-processor architectures and evaluate the performance of different\ndeployment (mapping, scheduling) strategies while taking uncertainty into\naccount. We argue that this extension of the scope of formal verification is\nimportant for the viability of the domain."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.6", 
    "link": "http://arxiv.org/pdf/1406.7539v1", 
    "title": "Exploring Task Mappings on Heterogeneous MPSoCs using a Bias-Elitist   Genetic Algorithm", 
    "arxiv-id": "1406.7539v1", 
    "author": "Andy D. Pimentel", 
    "publish": "2014-06-29T19:23:49Z", 
    "summary": "Exploration of task mappings plays a crucial role in achieving high\nperformance in heterogeneous multi-processor system-on-chip (MPSoC) platforms.\nThe problem of optimally mapping a set of tasks onto a set of given\nheterogeneous processors for maximal throughput has been known, in general, to\nbe NP-complete. The problem is further exacerbated when multiple applications\n(i.e., bigger task sets) and the communication between tasks are also\nconsidered. Previous research has shown that Genetic Algorithms (GA) typically\nare a good choice to solve this problem when the solution space is relatively\nsmall. However, when the size of the problem space increases, classic genetic\nalgorithms still suffer from the problem of long evolution times. To address\nthis problem, this paper proposes a novel bias-elitist genetic algorithm that\nis guided by domain-specific heuristics to speed up the evolution process.\nExperimental results reveal that our proposed algorithm is able to handle large\nscale task mapping problems and produces high-quality mapping solutions in only\na short time period."
},{
    "category": "math.PR", 
    "doi": "10.1007/s10626-009-0072-9", 
    "link": "http://arxiv.org/pdf/1408.0110v1", 
    "title": "A Two-Queue Polling Model with Two Priority Levels in the First Queue", 
    "arxiv-id": "1408.0110v1", 
    "author": "Onno Boxma", 
    "publish": "2014-08-01T09:31:44Z", 
    "summary": "In this paper we consider a single-server cyclic polling system consisting of\ntwo queues. Between visits to successive queues, the server is delayed by a\nrandom switch-over time. Two types of customers arrive at the first queue: high\nand low priority customers. For this situation the following service\ndisciplines are considered: gated, globally gated, and exhaustive. We study the\ncycle time distribution, the waiting times for each customer type, the joint\nqueue length distribution at polling epochs, and the steady-state marginal\nqueue length distributions for each customer type."
},{
    "category": "math.PR", 
    "doi": "10.1007/s11134-009-9115-z", 
    "link": "http://arxiv.org/pdf/1408.0124v1", 
    "title": "Mixed Gated/Exhaustive Service in a Polling Model with Priorities", 
    "arxiv-id": "1408.0124v1", 
    "author": "Ivo Adan", 
    "publish": "2014-08-01T10:42:45Z", 
    "summary": "In this paper we consider a single-server polling system with switch-over\ntimes. We introduce a new service discipline, mixed gated/exhaustive service,\nthat can be used for queues with two types of customers: high and low priority\ncustomers. At the beginning of a visit of the server to such a queue, a gate is\nset behind all customers. High priority customers receive priority in the sense\nthat they are always served before any low priority customers. But high\npriority customers have a second advantage over low priority customers. Low\npriority customers are served according to the gated service discipline, i.e.\nonly customers standing in front of the gate are served during this visit. In\ncontrast, high priority customers arriving during the visit period of the queue\nare allowed to pass the gate and all low priority customers before the gate.\n  We study the cycle time distribution, the waiting time distributions for each\ncustomer type, the joint queue length distribution of all priority classes at\nall queues at polling epochs, and the steady-state marginal queue length\ndistributions for each customer type. Through numerical examples we illustrate\nthat the mixed gated/exhaustive service discipline can significantly decrease\nwaiting times of high priority jobs. In many cases there is a minimal negative\nimpact on the waiting times of low priority customers but, remarkably, it turns\nout that in polling systems with larger switch-over times there can be even a\npositive impact on the waiting times of low priority customers."
},{
    "category": "math.PR", 
    "doi": "10.1007/s10479-010-0758-2", 
    "link": "http://arxiv.org/pdf/1408.0131v1", 
    "title": "A Polling Model with Reneging at Polling Instants", 
    "arxiv-id": "1408.0131v1", 
    "author": "Marko Boon", 
    "publish": "2014-08-01T11:16:27Z", 
    "summary": "In this paper we consider a single-server, cyclic polling system with\nswitch-over times and Poisson arrivals. The service disciplines that are\ndiscussed, are exhaustive and gated service. The novel contribution of the\npresent paper is that we consider the reneging of customers at polling\ninstants. In more detail, whenever the server starts or ends a visit to a\nqueue, some of the customers waiting in each queue leave the system before\nhaving received service. The probability that a certain customer leaves the\nqueue, depends on the queue in which the customer is waiting, and on the\nlocation of the server. We show that this system can be analysed by introducing\ncustomer subtypes, depending on their arrival periods, and keeping track of the\nmoment when they abandon the system. In order to determine waiting time\ndistributions, we regard the system as a polling model with varying arrival\nrates, and apply a generalised version of the distributional form of Little's\nlaw. The marginal queue length distribution can be found by conditioning on the\nstate of the system (position of the server, and whether it is serving or\nswitching)."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.peva.2010.12.004", 
    "link": "http://arxiv.org/pdf/1408.0134v1", 
    "title": "Closed-Form Waiting Time Approximations for Polling Systems", 
    "arxiv-id": "1408.0134v1", 
    "author": "Sandra van Wijk", 
    "publish": "2014-08-01T11:24:42Z", 
    "summary": "A typical polling system consists of a number of queues, attended by a single\nserver in a fixed order. The vast majority of papers on polling systems\nfocusses on Poisson arrivals, whereas very few results are available for\ngeneral arrivals. The current study is the first one presenting simple\nclosed-form approximations for the mean waiting times in polling systems with\nrenewal arrival processes, performing well for ALL workloads. The\napproximations are constructed using heavy traffic limits and newly developed\nlight traffic limits. The closed-form approximations may prove to be extremely\nuseful for system design and optimisation in application areas as diverse as\ntelecommunication, maintenance, manufacturing and transportation."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.sorms.2011.01.001", 
    "link": "http://arxiv.org/pdf/1408.0136v1", 
    "title": "Applications of polling systems", 
    "arxiv-id": "1408.0136v1", 
    "author": "Erik Winands", 
    "publish": "2014-08-01T11:35:14Z", 
    "summary": "Since the first paper on polling systems, written by Mack in 1957, a huge\nnumber of papers on this topic has been written. A typical polling system\nconsists of a number of queues, attended by a single server. In several\nsurveys, the most notable ones written by Takagi, detailed and comprehensive\ndescriptions of the mathematical analysis of polling systems are provided. The\ngoal of the present survey paper is to complement these papers by putting the\nemphasis on \\emph{applications} of polling models. We discuss not only the\ncapabilities, but also the limitations of polling models in representing\nvarious applications. The present survey is directed at both academicians and\npractitioners."
},{
    "category": "math.PR", 
    "doi": "10.1017/S0269964812000058", 
    "link": "http://arxiv.org/pdf/1408.0137v1", 
    "title": "Delays at signalised intersections with exhaustive traffic control", 
    "arxiv-id": "1408.0137v1", 
    "author": "Doug Down", 
    "publish": "2014-08-01T11:48:04Z", 
    "summary": "In this paper we study a traffic intersection with vehicle-actuated traffic\nsignal control. Traffic lights stay green until all lanes within a group are\nemptied. Assuming general renewal arrival processes, we derive exact limiting\ndistributions of the delays under Heavy Traffic (HT) conditions. Furthermore,\nwe derive the Light Traffic (LT) limit of the mean delays for intersections\nwith Poisson arrivals, and develop a heuristic adaptation of this limit to\ncapture the LT behaviour for other interarrival-time distributions. We combine\nthe LT and HT results to develop closed-form approximations for the mean delays\nof vehicles in each lane. These closed-form approximations are quite accurate,\nvery insightful and simple to implement."
},{
    "category": "math.PR", 
    "doi": "10.1007/s11134-011-9247-9", 
    "link": "http://arxiv.org/pdf/1408.0142v1", 
    "title": "On open problems in polling systems", 
    "arxiv-id": "1408.0142v1", 
    "author": "Erik Winands", 
    "publish": "2014-08-01T12:00:03Z", 
    "summary": "In the present paper we address two open problems concerning polling systems,\nviz., queueing systems consisting of multiple queues attended by a single\nserver that visits the queues one at a time. The first open problem deals with\na system consisting of two queues, one of which has gated service, while the\nother receives 1-limited service. The second open problem concerns polling\nsystems with general (renewal) arrivals and deterministic switch-over times\nthat become infinitely large. We discuss related, known results for both\nproblems, and the difficulties encountered when trying to solve them."
},{
    "category": "math.PR", 
    "doi": "10.1007/s11134-012-9334-6", 
    "link": "http://arxiv.org/pdf/1408.0146v1", 
    "title": "Waiting times in queueing networks with a single shared server", 
    "arxiv-id": "1408.0146v1", 
    "author": "Erik Winands", 
    "publish": "2014-08-01T12:08:55Z", 
    "summary": "We study a queueing network with a single shared server that serves the\nqueues in a cyclic order. External customers arrive at the queues according to\nindependent Poisson processes. After completing service, a customer either\nleaves the system or is routed to another queue. This model is very generic and\nfinds many applications in computer systems, communication networks,\nmanufacturing systems, and robotics. Special cases of the introduced network\ninclude well-known polling models, tandem queues, systems with a waiting room,\nmulti-stage models with parallel queues, and many others. A complicating factor\nof this model is that the internally rerouted customers do not arrive at the\nvarious queues according to a Poisson process, causing standard techniques to\nfind waiting-time distributions to fail. In this paper we develop a new method\nto obtain exact expressions for the Laplace-Stieltjes transforms of the\nsteady-state waiting-time distributions. This method can be applied to a wide\nvariety of models which lacked an analysis of the waiting-time distribution\nuntil now."
},{
    "category": "math.PR", 
    "doi": "10.1145/2034832.2034843", 
    "link": "http://arxiv.org/pdf/1408.0151v1", 
    "title": "Queueing networks with a single shared server: light and heavy traffic", 
    "arxiv-id": "1408.0151v1", 
    "author": "Erik Winands", 
    "publish": "2014-08-01T12:29:30Z", 
    "summary": "We study a queueing network with a single shared server, that serves the\nqueues in a cyclic order according to the gated service discipline. External\ncustomers arrive at the queues according to independent Poisson processes.\nAfter completing service, a customer either leaves the system or is routed to\nanother queue. This model is very generic and finds many applications in\ncomputer systems, communication networks, manufacturing systems and robotics.\nSpecial cases of the introduced network include well-known polling models and\ntandem queues. We derive exact limits of the mean delays under both\nheavy-traffic and light-traffic conditions. By interpolating between these\nasymptotic regimes, we develop simple closed-form approximations for the mean\ndelays for arbitrary loads."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.peva.2010.01.002", 
    "link": "http://arxiv.org/pdf/1408.0282v1", 
    "title": "A Polling Model with Multiple Priority Levels", 
    "arxiv-id": "1408.0282v1", 
    "author": "Onno Boxma", 
    "publish": "2014-08-01T09:43:15Z", 
    "summary": "In this paper we consider a single-server cyclic polling system. Between\nvisits to successive queues, the server is delayed by a random switch-over\ntime. The order in which customers are served in each queue is determined by a\npriority level that is assigned to each customer at his arrival. For this\nsituation the following service disciplines are considered: gated, exhaustive,\nand globally gated. We study the cycle time distribution, the waiting times for\neach customer type, the joint queue length distribution of all priority classes\nat all queues at polling epochs, and the steady-state marginal queue length\ndistributions for each customer type."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2010.01.002", 
    "link": "http://arxiv.org/pdf/1408.4964v1", 
    "title": "High Level Programming for Heterogeneous Architectures", 
    "arxiv-id": "1408.4964v1", 
    "author": "Mitch Wright", 
    "publish": "2014-08-21T11:23:54Z", 
    "summary": "This work presents an effort to bridge the gap between abstract high level\nprogramming and OpenCL by extending an existing high level Java programming\nframework (APARAPI), based on OpenCL, so that it can be used to program FPGAs\nat a high level of abstraction and increased ease of programmability. We run\nseveral real world algorithms to assess the performance of the framework on\nboth a low end and a high end system. On the low end and high end systems\nrespectively we observed up to 78-80 percent power reduction and 4.8X-5.3X\nspeed increase running NBody simulation, as well as up to 65-80 percent power\nreduction and 6.2X-7X speed increase for a KMeans, MapReduce algorithm running\non top of the Hadoop framework and APARAPI."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2010.01.002", 
    "link": "http://arxiv.org/pdf/1408.6721v2", 
    "title": "Performance Analysis of Linear-Equality-Constrained Least-Squares   Estimation", 
    "arxiv-id": "1408.6721v2", 
    "author": "Kutluy\u0131l Do\u011fan\u00e7ay", 
    "publish": "2014-08-26T15:20:55Z", 
    "summary": "We analyze the performance of a linear-equality-constrained least-squares\n(CLS) algorithm and its relaxed version, called rCLS, that is obtained via the\nmethod of weighting. The rCLS algorithm solves an unconstrained least-squares\nproblem that is augmented by incorporating a weighted form of the linear\nconstraints. As a result, unlike the CLS algorithm, the rCLS algorithm is\namenable to our approach to performance analysis presented here, which is akin\nto the energy-conservation-based methodology. Therefore, we initially inspect\nthe convergence properties and evaluate the precision of estimation as well as\nsatisfaction of the constraints for the rCLS algorithm in both mean and\nmean-square senses. Afterwards, we examine the performance of the CLS algorithm\nby evaluating the limiting performance of the rCLS algorithm as the relaxation\nparameter (weight) approaches infinity. Numerical examples verify the accuracy\nof the theoretical findings."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2010.01.002", 
    "link": "http://arxiv.org/pdf/1409.0820v2", 
    "title": "Network calculus for parallel processing", 
    "arxiv-id": "1409.0820v2", 
    "author": "J. Liebeherr", 
    "publish": "2014-09-02T18:44:48Z", 
    "summary": "In this note, we present preliminary results on the use of \"network calculus\"\nfor parallel processing systems, specifically MapReduce."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1409.0966v1", 
    "title": "Primary User Traffic Classification in Dynamic Spectrum Access Networks", 
    "arxiv-id": "1409.0966v1", 
    "author": "Danijela Cabric", 
    "publish": "2014-09-03T06:52:29Z", 
    "summary": "This paper focuses on analytical studies of the primary user (PU) traffic\nclassification problem. Observing that the gamma distribution can represent\npositively skewed data and exponential distribution (popular in communication\nnetworks performance analysis literature) it is considered here as the PU\ntraffic descriptor. We investigate two PU traffic classifiers utilizing\nperfectly measured PU activity (busy) and inactivity (idle) periods: (i)\nmaximum likelihood classifier (MLC) and (ii) multi-hypothesis sequential\nprobability ratio test classifier (MSPRTC). Then, relaxing the assumption on\nperfect period measurement, we consider a PU traffic observation through\nchannel sampling. For a special case of negligible probability of PU state\nchange in between two samplings, we propose a minimum variance PU busy/idle\nperiod length estimator. Later, relaxing the assumption of the complete\nknowledge of the parameters of the PU period length distribution, we propose\ntwo PU traffic classification schemes: (i) estimate-then-classify (ETC), and\n(ii) average likelihood function (ALF) classifiers considering time domain\nfluctuation of the PU traffic parameters. Numerical results show that both MLC\nand MSPRTC are sensitive to the periods measurement errors when the distance\namong distribution hypotheses is small, and to the distribution parameter\nestimation errors when the distance among hypotheses is large. For PU traffic\nparameters with a partial prior knowledge of the distribution, the ETC\noutperforms ALF when the distance among hypotheses is small, while the opposite\nholds when the distance is large."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1409.3767v1", 
    "title": "DW&C:Dollops Wise Curtail IPv4/IPv6 Transition Mechanism using NS2", 
    "arxiv-id": "1409.3767v1", 
    "author": "H. Annaiah", 
    "publish": "2014-09-11T08:26:23Z", 
    "summary": "BD-SIIT and DSTM are widely deployed IPv4/IPv6 Transition mechanism to\nimprove the performance of the computer network in terms of Throughput,End to\nEnd Delay(EED) and Packet Drop Rate(PDR).In this journal paper we have\nImplemented and Compared the Performance Issues of our newly proposed Dollops\nWise Curtail(DW&C)IPv4/IPv6 Migration Mechanism with BD-SIIT and DSTM in NS2.\nImplementation and Comparison Performance Analysis between Dollops Wise\nCurtail,BD-SIIT and DSTM shows that Dollops Wise Curtail IPv4/IPv6 migration\nalgorithm performance outperforms than BD-SIIT and DSTM.Based on extensive\nsimulations,we show that DW&C algorithm reduces the Packet Drop Rate(PDR),End\nto End Delay(EED) and achieves better Throughput than BD-SIIT and DSTM.In our\nresearch work observation,the performance metrics such as Throughput,EED and\nPLR for DW&C,BD-SIIT and DSTM are measured using TCP,UDP,FTP and CBR Traffics"
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1409.5622v1", 
    "title": "Instability of Sharing Systems in the Presence of Retransmissions", 
    "arxiv-id": "1409.5622v1", 
    "author": "Evangelia D. Skiani", 
    "publish": "2014-09-19T12:26:05Z", 
    "summary": "Retransmissions represent a primary failure recovery mechanism on all layers\nof communication network architecture. Similarly, fair sharing, e.g. processor\nsharing (PS), is a widely accepted approach to resource allocation among\nmultiple users. Recent work has shown that retransmissions in failure-prone,\ne.g. wireless ad hoc, networks can cause heavy tails and long delays. In this\npaper, we discover a new phenomenon showing that PS-based scheduling induces\ncomplete instability with zero throughput in the presence of retransmissions,\nregardless of how low the traffic load may be. This phenomenon occurs even when\nthe job sizes are bounded/fragmented, e.g. deterministic. Our analytical\nresults are further validated via simulation experiments. Moreover, our work\ndemonstrates that scheduling one job at a time, such as first-come-first-serve,\nachieves stability and should be preferred in these systems."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1409.6775v2", 
    "title": "A Queueing Network Approach to the Analysis and Control of   Mobility-On-Demand Systems", 
    "arxiv-id": "1409.6775v2", 
    "author": "Marco Pavone", 
    "publish": "2014-09-23T23:52:36Z", 
    "summary": "This paper presents a queueing network approach to the analysis and control\nof mobility-on-demand (MoD) systems for urban personal transportation. A MoD\nsystem consists of a fleet of vehicles providing one-way car sharing service\nand a team of drivers to rebalance such vehicles. The drivers then rebalance\nthemselves by driving select customers similar to a taxi service. We model the\nMoD system as two coupled closed Jackson networks with passenger loss. We show\nthat the system can be approximately balanced by solving two decoupled linear\nprograms and exactly balanced through nonlinear optimization. The rebalancing\ntechniques are applied to a system sizing example using taxi data in three\nneighborhoods of Manhattan, which suggests that the optimal vehicle-to-driver\nratio in a MoD system is between 3 and 5. Lastly, we formulate a real-time\nclosed-loop rebalancing policy for drivers and demonstrate its stability (in\nterms of customer wait times) for typical system loads."
},{
    "category": "cs.GT", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1409.7195v3", 
    "title": "Tolls and Welfare Optimization for Multiclass Traffic in Multiqueue   Systems", 
    "arxiv-id": "1409.7195v3", 
    "author": "D. Manjunath", 
    "publish": "2014-09-25T09:38:29Z", 
    "summary": "We consider a queueing system with multiple heterogeneous servers serving a\nmulticlass population. The classes are distinguished by the time costs. All\ncustomers have i.i.d. service requirements. Arriving customers do not see the\ninstantaneous queue occupancy. Arrivals are randomly routed to one of the\nservers and the routing probabilities are determined centrally to optimize the\nexpected waiting cost. This is, in general, a difficult optimization problem\nand we obtain the structure of the routing matrix. Next we consider a system in\nwhich each queue charges an admission price. The arrivals are routed randomly\nto minimize an individual objective function that includes the expected waiting\ncost and the admission price. Once again, we obtain the structure of the\nequilibrium routing matrix for this case. Finally, we determine the admission\nprices to make the equilibrium routing probability matrix equal to a given\noptimal routing probability matrix."
},{
    "category": "cs.MS", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1409.8608v1", 
    "title": "On the Performance Prediction of BLAS-based Tensor Contractions", 
    "arxiv-id": "1409.8608v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2014-09-30T15:54:13Z", 
    "summary": "Tensor operations are surging as the computational building blocks for a\nvariety of scientific simulations and the development of high-performance\nkernels for such operations is known to be a challenging task. While for\noperations on one- and two-dimensional tensors there exist standardized\ninterfaces and highly-optimized libraries (BLAS), for higher dimensional\ntensors neither standards nor highly-tuned implementations exist yet. In this\npaper, we consider contractions between two tensors of arbitrary dimensionality\nand take on the challenge of generating high-performance implementations by\nresorting to sequences of BLAS kernels. The approach consists in breaking the\ncontraction down into operations that only involve matrices or vectors. Since\nin general there are many alternative ways of decomposing a contraction, we are\nable to methodically derive a large family of algorithms. The main contribution\nof this paper is a systematic methodology to accurately identify the fastest\nalgorithms in the bunch, without executing them. The goal is instead\naccomplished with the help of a set of cache-aware micro-benchmarks for the\nunderlying BLAS kernels. The predictions we construct from such benchmarks\nallow us to reliably single out the best-performing algorithms in a tiny\nfraction of the time taken by the direct execution of the algorithms."
},{
    "category": "cs.DL", 
    "doi": "10.1109/JSAC.2014.141122", 
    "link": "http://arxiv.org/pdf/1007.0542v1", 
    "title": "Limits of responsiveness concerning human-readable knowledge bases: an   operational analysis", 
    "arxiv-id": "1007.0542v1", 
    "author": "G. C. Pentzaropoulos", 
    "publish": "2010-07-04T11:46:22Z", 
    "summary": "Introduction. The purpose of this work is the evaluation of responsiveness\nwhen remote users communicate with a human-readable knowledge base (KB).\nResponsiveness [R(s)] is considered here as a measure of service quality.\nMethod. The preferred method is operational analysis, a variation of classical\nstochastic theory, which allows for the study of user-system interaction with\nminimal computational effort. Analysis. The analysis is based on well-known\nperformance metrics, such as service ability, elapsed time, and throughput:\nfrom these metrics estimates of R(s) are derived analytically. Results.\nCritical points indicating congestion are obtained: these are limits on the\nnumber of admissible requests and the number of connected users. Also obtained\nis a sufficient condition for achieving flow balance between the KB host and\nthe request-relaying servers. Conclusions. When R(s) is within normal limits,\nusers should appreciate the benefits from using the services offered by their\nKB host. When bottlenecks are formed, R(s) declines, and the whole\ncommunication system heads for saturation. Flow balancing procedures are\nnecessary for the elimination of bottlenecks, which leads to a better resource\nmanagement."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.parco.2011.03.005", 
    "link": "http://arxiv.org/pdf/1007.1388v1", 
    "title": "A Flexible Patch-Based Lattice Boltzmann Parallelization Approach for   Heterogeneous GPU-CPU Clusters", 
    "arxiv-id": "1007.1388v1", 
    "author": "Gerhard Wellein", 
    "publish": "2010-07-08T14:27:05Z", 
    "summary": "Sustaining a large fraction of single GPU performance in parallel\ncomputations is considered to be the major problem of GPU-based clusters. In\nthis article, this topic is addressed in the context of a lattice Boltzmann\nflow solver that is integrated in the WaLBerla software framework. We propose a\nmulti-GPU implementation using a block-structured MPI parallelization, suitable\nfor load balancing and heterogeneous computations on CPUs and GPUs. The\noverhead required for multi-GPU simulations is discussed in detail and it is\ndemonstrated that the kernel performance can be sustained to a large extent.\nWith our GPU implementation, we achieve nearly perfect weak scalability on\nInfiniBand clusters. However, in strong scaling scenarios multi-GPUs make less\nefficient use of the hardware than IBM BG/P and x86 clusters. Hence, a cost\nanalysis must determine the best course of action for a particular simulation\ntask. Additionally, weak scaling results of heterogeneous simulations conducted\non CPUs and GPUs simultaneously are presented using clusters equipped with\nvarying node configurations."
},{
    "category": "cs.SE", 
    "doi": "10.4204/EPTCS.30.7", 
    "link": "http://arxiv.org/pdf/1007.5094v1", 
    "title": "A Compositional Semantics for Stochastic Reo Connectors", 
    "arxiv-id": "1007.5094v1", 
    "author": "Farhad Arbab", 
    "publish": "2010-07-29T00:13:09Z", 
    "summary": "In this paper we present a compositional semantics for the channel-based\ncoordination language Reo which enables the analysis of quality of service\n(QoS) properties of service compositions. For this purpose, we annotate Reo\nchannels with stochastic delay rates and explicitly model data-arrival rates at\nthe boundary of a connector, to capture its interaction with the services that\ncomprise its environment. We propose Stochastic Reo automata as an extension of\nReo automata, in order to compositionally derive a QoS-aware semantics for Reo.\nWe further present a translation of Stochastic Reo automata to Continuous-Time\nMarkov Chains (CTMCs). This translation enables us to use third-party CTMC\nverification tools to do an end-to-end performance analysis of service\ncompositions."
},{
    "category": "cs.PF", 
    "doi": "10.1137/110830125", 
    "link": "http://arxiv.org/pdf/1104.1729v1", 
    "title": "Expression Templates Revisited: A Performance Analysis of the Current ET   Methodology", 
    "arxiv-id": "1104.1729v1", 
    "author": "Ulrich Ruede", 
    "publish": "2011-04-09T17:50:30Z", 
    "summary": "In the last decade, Expression Templates (ET) have gained a reputation as an\nefficient performance optimization tool for C++ codes. This reputation builds\non several ET-based linear algebra frameworks focused on combining both elegant\nand high-performance C++ code. However, on closer examination the assumption\nthat ETs are a performance optimization technique cannot be maintained. In this\npaper we demonstrate and explain the inability of current ET-based frameworks\nto deliver high performance for dense and sparse linear algebra operations, and\nintroduce a new \"smart\" ET implementation that truly allows the combination of\nhigh performance code with the elegance and maintainability of a\ndomain-specific language."
},{
    "category": "cs.DC", 
    "doi": "10.1137/110830125", 
    "link": "http://arxiv.org/pdf/1104.4078v1", 
    "title": "A Note on Parallel Algorithmic Speedup Bounds", 
    "arxiv-id": "1104.4078v1", 
    "author": "Neil J. Gunther", 
    "publish": "2011-04-20T17:22:34Z", 
    "summary": "A parallel program can be represented as a directed acyclic graph. An\nimportant performance bound is the time to execute the critical path through\nthe graph. We show how this performance metric is related to Amdahl speedup and\nthe degree of average parallelism. These bounds formally exclude superlinear\nperformance."
},{
    "category": "cs.NI", 
    "doi": "10.1137/110830125", 
    "link": "http://arxiv.org/pdf/1104.4690v1", 
    "title": "Secured Message Transmission in Mobile AD HOC Networks through   Identification and Removal of Byzantine Failures", 
    "arxiv-id": "1104.4690v1", 
    "author": "Dr. J. Akilandeswari", 
    "publish": "2011-04-25T07:06:05Z", 
    "summary": "The emerging need for mobile ad hoc networks and secured data transmission\nphase is of crucial importance depending upon the environments like military.\nIn this paper, a new way to improve the reliability of message transmission is\npresented. In the open collaborative MANET environment, any node can\nmaliciously or selfishly disrupt and deny communication of other nodes. Dynamic\nchanging topology makes it hard to determine the adversary nodes that affect\nthe communication in MANET. An SMT protocol provides a way to secure message\ntransmission by dispersing the message among several paths with minimal\nredundancy. The multiple routes selected are known as APS -Active Path Set.\nThis paper describes a technique for fault discovery process to identify\nByzantine failures which include nodes that drop, modify, or mis-route packets\nin an attempt to disrupt the routing service. An adaptive probing technique\ndetects a malicious link through binary search and according to the nodes\nbehavior, these links are avoided in the active path by multiplicatively\nincreasing their weights. The proposed scheme provides secure communication\neven with increased number of adversaries."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICPPW.2010.38", 
    "link": "http://arxiv.org/pdf/1104.4874v2", 
    "title": "LIKWID: Lightweight Performance Tools", 
    "arxiv-id": "1104.4874v2", 
    "author": "Gerhard Wellein", 
    "publish": "2011-04-26T09:43:46Z", 
    "summary": "Exploiting the performance of today's microprocessors requires intimate\nknowledge of the microarchitecture as well as an awareness of the ever-growing\ncomplexity in thread and cache topology. LIKWID is a set of command line\nutilities that addresses four key problems: Probing the thread and cache\ntopology of a shared-memory node, enforcing thread-core affinity on a program,\nmeasuring performance counter metrics, and microbenchmarking for reliable upper\nperformance bounds. Moreover, it includes a mpirun wrapper allowing for\nportable thread-core affinity in MPI and hybrid MPI/threaded applications. To\ndemonstrate the capabilities of the tool set we show the influence of thread\naffinity on performance using the well-known OpenMP STREAM triad benchmark, use\nhardware counter tools to study the performance of a stencil code, and finally\nshow how to detect bandwidth problems on ccNUMA-based compute nodes."
},{
    "category": "cs.PF", 
    "doi": "10.1177/1094342012442424", 
    "link": "http://arxiv.org/pdf/1104.5243v2", 
    "title": "Pushing the limits for medical image reconstruction on recent standard   multicore processors", 
    "arxiv-id": "1104.5243v2", 
    "author": "Gerhard Wellein", 
    "publish": "2011-04-27T20:31:11Z", 
    "summary": "Volume reconstruction by backprojection is the computational bottleneck in\nmany interventional clinical computed tomography (CT) applications. Today\nvendors in this field replace special purpose hardware accelerators by standard\nhardware like multicore chips and GPGPUs. Medical imaging algorithms are on the\nverge of employing High Performance Computing (HPC) technology, and are\ntherefore an interesting new candidate for optimization. This paper presents\nlow-level optimizations for the backprojection algorithm, guided by a thorough\nperformance analysis on four generations of Intel multicore processors\n(Harpertown, Westmere, Westmere EX, and Sandy Bridge).\n  We choose the RabbitCT benchmark, a standardized testcase well supported in\nindustry, to ensure transparent and comparable results. Our aim is to provide\nnot only the fastest possible implementation but also compare to performance\nmodels and hardware counter data in order to fully understand the results. We\nseparate the influence of algorithmic optimizations, parallelization, SIMD\nvectorization, and microarchitectural issues and pinpoint problems with current\nSIMD instruction set extensions on standard CPUs (SSE, AVX). The use of\nassembly language is mandatory for best performance. Finally we compare our\nresults to the best GPGPU implementations available for this open competition\nbenchmark."
},{
    "category": "cs.DC", 
    "doi": "10.1177/1094342012442424", 
    "link": "http://arxiv.org/pdf/1104.5392v1", 
    "title": "A Framework for QoS-aware Execution of Workflows over the Cloud", 
    "arxiv-id": "1104.5392v1", 
    "author": "Raffaela Mirandola", 
    "publish": "2011-04-28T13:55:30Z", 
    "summary": "The Cloud Computing paradigm is providing system architects with a new\npowerful tool for building scalable applications. Clouds allow allocation of\nresources on a \"pay-as-you-go\" model, so that additional resources can be\nrequested during peak loads and released after that. However, this flexibility\nasks for appropriate dynamic reconfiguration strategies. In this paper we\ndescribe SAVER (qoS-Aware workflows oVER the Cloud), a QoS-aware algorithm for\nexecuting workflows involving Web Services hosted in a Cloud environment. SAVER\nallows execution of arbitrary workflows subject to response time constraints.\nSAVER uses a passive monitor to identify workload fluctuations based on the\nobserved system response time. The information collected by the monitor is used\nby a planner component to identify the minimum number of instances of each Web\nService which should be allocated in order to satisfy the response time\nconstraint. SAVER uses a simple Queueing Network (QN) model to identify the\noptimal resource allocation. Specifically, the QN model is used to identify\nbottlenecks, and predict the system performance as Cloud resources are\nallocated or released. The parameters used to evaluate the model are those\ncollected by the monitor, which means that SAVER does not require any\nparticular knowledge of the Web Services and workflows being executed. Our\napproach has been validated through numerical simulations, whose results are\nreported in this paper."
},{
    "category": "cs.NI", 
    "doi": "10.1177/1094342012442424", 
    "link": "http://arxiv.org/pdf/1109.0931v2", 
    "title": "An Empirical Study on variants of TCP over AODV routing protocol in   MANET", 
    "arxiv-id": "1109.0931v2", 
    "author": "Md. Rafiqul Islam", 
    "publish": "2011-09-05T15:17:12Z", 
    "summary": "The cardinal concept of TCP development was to carry data within the network\nwhere network congestion plays a vital role to cause packet loss. On the other\nhand, there are several other reasons to lose packets in Mobile Ad Hoc Networks\ndue to fading, interfaces, multi-path routing, malicious node, and black hole.\nAlong with throughput, fairness of TCP protocols is important to establish a\ngood communication. In this paper, an empirical study has been done by\nsimulation and analysis of TCP variations under AODV routing protocol. In our\nsimulation, we studied multiple variations of TCP, such as Reno, New-Reno,\nVegas, and Tahoe. The simulation work has been done in NS2 environment. Based\non the analysis simulation result of we carried out our observations with\nrespect to the behavior of AODV routing protocol for different TCP packets\nunder several QoS metrics such as drop, throughput, delay, and jitter."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1109.4974v2", 
    "title": "Cost of Virtual Machine Live Migration in Clouds: A Performance   Evaluation", 
    "arxiv-id": "1109.4974v2", 
    "author": "Rajkumar Buyya", 
    "publish": "2011-09-22T23:52:18Z", 
    "summary": "Virtualization has become commonplace in modern data centers, often referred\nas \"computing clouds\". The capability of virtual machine live migration brings\nbenefits such as improved performance, manageability and fault tolerance, while\nallowing workload movement with a short service downtime. However, service\nlevels of applications are likely to be negatively affected during a live\nmigration. For this reason, a better understanding of its effects on system\nperformance is desirable. In this paper, we evaluate the effects of live\nmigration of virtual machines on the performance of applications running inside\nXen VMs. Results show that, in most cases, migration overhead is acceptable but\ncannot be disregarded, especially in systems where availability and\nresponsiveness are governed by strict Service Level Agreements. Despite that,\nthere is a high potential for live migration applicability in data centers\nserving modernInternet applications. Our results are based on a workload\ncovering the domain of multi-tier Web 2.0 applications."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1109.5679v1", 
    "title": "Queries mining for efficient routing in P2P communities", 
    "arxiv-id": "1109.5679v1", 
    "author": "Mohammad Hajjar", 
    "publish": "2011-09-26T19:27:21Z", 
    "summary": "Peer-to-peer (P2P) computing is currently attracting enormous attention. In\nP2P systems a very large number of autonomous computing nodes (the peers) pool\ntogether their resources and rely on each other for data and services.\nPeer-to-peer (P2P) Data-sharing systems now generate a significant portion of\nInternet traffic. Examples include P2P systems for network storage, web\ncaching, searching and indexing of relevant documents and distributed\nnetwork-threat analysis. Requirements for widely distributed information\nsystems supporting virtual organizations have given rise to a new category of\nP2P systems called schema-based. In such systems each peer exposes its own\nschema and the main objective is the efficient search across the P2P network by\nprocessing each incoming query without overly consuming bandwidth. The\nusability of these systems depends on effective techniques to find and retrieve\ndata; however, efficient and effective routing of content-based queries is a\nchallenging problem in P2P networks. This work was attended as an attempt to\nmotivate the use of mining algorithms and hypergraphs context to develop two\ndifferent methods that improve significantly the efficiency of P2P\ncommunications. The proposed query routing methods direct the query to a set of\nrelevant peers in such way as to avoid network traffic and bandwidth\nconsumption. We compare the performance of the two proposed methods with the\nbaseline one and our experimental results prove that our proposed methods\ngenerate impressive levels of performance and scalability."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1109.6502v1", 
    "title": "An Empirical Study of UDP (CBR) Packet Performance over AODV Single &   Multi-Channel Parallel Transmission in MANET", 
    "arxiv-id": "1109.6502v1", 
    "author": "Md. Rafiqul Islam", 
    "publish": "2011-09-29T12:15:23Z", 
    "summary": "Mobile Ad-hoc Network is a temporary network which is the cooperative\nengagement of a collection of standalone mobile nodes that are not connected to\nany external network. It is a decentralized network where mobile nodes can be\neasily deployed in almost any environment without sophisticated infrastructure\nsupport. An empirical study has been done for AODV routing protocol under\nsingle channel and multi channel environment using the tool NS2. To compare the\nperformance of AODV in the two environments, the simulation results have been\nanalyzed by graphical manner and trace file based on QoS metrics such as\nthroughput, packet drop, delay and jitter. The simulation result analysis\nverifies the AODV routing protocol performances for single channel and multi\nchannel. After the analysis of the simulation scenario we suggest that use of\nParallel MAC (P-MAC) may enhance the performance for multi channel."
},{
    "category": "cs.DB", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1204.1598v1", 
    "title": "Improving Seek Time for Column Store Using MMH Algorithm", 
    "arxiv-id": "1204.1598v1", 
    "author": "Dr. A. K. Goyal", 
    "publish": "2012-04-07T06:24:53Z", 
    "summary": "Hash based search has, proven excellence on large data warehouses stored in\ncolumn store. Data distribution has significant impact on hash based search. To\nreduce impact of data distribution, we have proposed Memory Managed Hash (MMH)\nalgorithm that uses shift XOR group for Queries and Transactions in column\nstore. Our experiments show that MMH improves read and write throughput by 22%\nfor TPC-H distribution."
},{
    "category": "cs.IR", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1204.1832v2", 
    "title": "Mathematical Modeling of Competitive Group Recommendation Systems with   Application to Peer Review Systems", 
    "arxiv-id": "1204.1832v2", 
    "author": "John C. S. Lui", 
    "publish": "2012-04-09T08:47:58Z", 
    "summary": "In this paper, we present a mathematical model to capture various factors\nwhich may influence the accuracy of a competitive group recommendation system.\nWe apply this model to peer review systems, i.e., conference or research grants\nreview, which is an essential component in our scientific community. We explore\nnumber of important questions, i.e., how will the number of reviews per paper\naffect the accuracy of the overall recommendation? Will the score aggregation\npolicy influence the final recommendation? How reviewers' preference may affect\nthe accuracy of the final recommendation? To answer these important questions,\nwe formally analyze our model. Through this analysis, we obtain the insight on\nhow to design a randomized algorithm which is both computationally efficient\nand asymptotically accurate in evaluating the accuracy of a competitive group\nrecommendation system. We obtain number of interesting observations: i.e., for\na medium tier conference, three reviews per paper is sufficient for a high\naccuracy recommendation. For prestigious conferences, one may need at least\nseven reviews per paper to achieve high accuracy. We also propose a\nheterogeneous review strategy which requires equal or less reviewing workload,\nbut can improve over a homogeneous review strategy in recommendation accuracy\nby as much as 30% . We believe our models and methodology are important\nbuilding blocks to study competitive group recommendation systems."
},{
    "category": "cs.AR", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1204.2772v1", 
    "title": "Effect of Thread Level Parallelism on the Performance of Optimum   Architecture for Embedded Applications", 
    "arxiv-id": "1204.2772v1", 
    "author": "Hojjat Taghdisi", 
    "publish": "2012-04-12T17:07:58Z", 
    "summary": "According to the increasing complexity of network application and internet\ntraffic, network processor as a subset of embedded processors have to process\nmore computation intensive tasks. By scaling down the feature size and emersion\nof chip multiprocessors (CMP) that are usually multi-thread processors, the\nperformance requirements are somehow guaranteed. As multithread processors are\nthe heir of uni-thread processors and there isn't any general design flow to\ndesign a multithread embedded processor, in this paper we perform a\ncomprehensive design space exploration for an optimum uni-thread embedded\nprocessor based on the limited area and power budgets. Finally we run multiple\nthreads on this architecture to find out the maximum thread level parallelism\n(TLP) based on performance per power and area optimum uni-thread architecture."
},{
    "category": "cs.NA", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1204.6255v1", 
    "title": "Revisiting the D-iteration method: runtime comparison", 
    "arxiv-id": "1204.6255v1", 
    "author": "Philippe Raoult", 
    "publish": "2012-04-27T15:48:38Z", 
    "summary": "In this paper, we revisit the D-iteration algorithm in order to better\nexplain different performance results that were observed for the numerical\ncomputation of the eigenvector associated to the PageRank score. We revisit\nhere the practical computation cost based on the execution runtime compared to\nthe theoretical number of iterations."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-642-10665-1_23", 
    "link": "http://arxiv.org/pdf/1207.3876v1", 
    "title": "Cluster Based Hierarchical Routing Protocol for Wireless Sensor Network", 
    "arxiv-id": "1207.3876v1", 
    "author": "Shaikh Enayet Ullah", 
    "publish": "2012-07-17T04:17:19Z", 
    "summary": "The efficient use of energy source in a sensor node is most desirable\ncriteria for prolong the life time of wireless sensor network. In this paper,\nwe propose a two layer hierarchical routing protocol called Cluster Based\nHierarchical Routing Protocol (CBHRP). We introduce a new concept called\nhead-set, consists of one active cluster head and some other associate cluster\nheads within a cluster. The head-set members are responsible for control and\nmanagement of the network. Results show that this protocol reduces energy\nconsumption quite significantly and prolongs the life time of sensor network as\ncompared to LEACH."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-642-33078-0_9", 
    "link": "http://arxiv.org/pdf/1301.1215v1", 
    "title": "A Multi-GPU Programming Library for Real-Time Applications", 
    "arxiv-id": "1301.1215v1", 
    "author": "Martin Uecker", 
    "publish": "2013-01-07T14:50:24Z", 
    "summary": "We present MGPU, a C++ programming library targeted at single-node multi-GPU\nsystems. Such systems combine disproportionate floating point performance with\nhigh data locality and are thus well suited to implement real-time algorithms.\nWe describe the library design, programming interface and implementation\ndetails in light of this specific problem domain. The core concepts of this\nwork are a novel kind of container abstraction and MPI-like communication\nmethods for intra-system communication. We further demonstrate how MGPU is used\nas a framework for porting existing GPU libraries to multi-device\narchitectures. Putting our library to the test, we accelerate an iterative\nnon-linear image reconstruction algorithm for real-time magnetic resonance\nimaging using multiple GPUs. We achieve a speed-up of about 1.7 using 2 GPUs\nand reach a final speed-up of 2.1 with 4 GPUs. These promising results lead us\nto conclude that multi-GPU systems are a viable solution for real-time MRI\nreconstruction as well as signal-processing applications in general."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSYST.2013.2280848", 
    "link": "http://arxiv.org/pdf/1301.3599v1", 
    "title": "Technical Report: Beaconless Geo-Routing Under The Spotlight: Practical   Link Models and Application Scenarios", 
    "arxiv-id": "1301.3599v1", 
    "author": "Mohamed-Slim Alouini", 
    "publish": "2013-01-16T06:41:47Z", 
    "summary": "Analysis and simulation of beaconless geo-routing protocols have been\ntraditionally conducted assuming equal communication ranges for the data and\ncontrol packets. In reality, this is not true since the communication range is\nactually function of the packet length. Control packets are typically much\nshorter than data packets. As a consequence, a substantial discrepancy exists\nin practice between their respective communication ranges. In this paper, we\ndevise a practical link model for computing the effective communication range.\nWe further introduce two simple strategies for bridging the gap between the\ncontrol and data packet communication ranges. Our primary objective in this\npaper is to construct a realistic analytical framework describing the\nend-to-end performance of beaconless geo-routing protocols. Two flagship\nprotocols are selected in this paper for further investigation under the\ndeveloped framework. For a better perspective, the two protocols are actually\ncompared to a hypothetical limit case; one which offers optimal energy and\nlatency performance. Finally, we present four different application scenarios.\nFor each scenario, we highlight the geo-routing protocol which performs the\nbest and discuss the reasons behind it."
},{
    "category": "cs.MM", 
    "doi": "10.1109/BMSB.2012.6264243", 
    "link": "http://arxiv.org/pdf/1301.5793v1", 
    "title": "Video Tester -- A multiple-metric framework for video quality assessment   over IP networks", 
    "arxiv-id": "1301.5793v1", 
    "author": "Juan M. Lopez-Soler", 
    "publish": "2013-01-24T14:31:10Z", 
    "summary": "This paper presents an extensible and reusable framework which addresses the\nproblem of video quality assessment over IP networks. The proposed tool\n(referred to as Video-Tester) supports raw uncompressed video encoding and\ndecoding. It also includes different video over IP transmission methods (i.e.:\nRTP over UDP unicast and multicast, as well as RTP over TCP). In addition, it\nis furnished with a rich set of offline analysis capabilities. Video-Tester\nanalysis includes QoS and bitstream parameters estimation (i.e.: bandwidth,\npacket inter-arrival time, jitter and loss rate, as well as GOP size and\nI-frame loss rate). Our design facilitates the integration of virtually any\nexisting video quality metric thanks to the adopted Python-based modular\napproach. Video-Tester currently provides PSNR, SSIM, ITU-T G.1070 video\nquality metric, DIV and PSNR-based MOS estimations. In order to promote its use\nand extension, Video-Tester is open and publicly available."
},{
    "category": "cs.PF", 
    "doi": "10.1109/BMSB.2012.6264243", 
    "link": "http://arxiv.org/pdf/1304.1863v1", 
    "title": "Stochastic Analysis on RAID Reliability for Solid-State Drives", 
    "arxiv-id": "1304.1863v1", 
    "author": "John C. S. Lui", 
    "publish": "2013-04-06T07:48:02Z", 
    "summary": "Solid-state drives (SSDs) have been widely deployed in desktops and data\ncenters. However, SSDs suffer from bit errors, and the bit error rate is time\ndependent since it increases as an SSD wears down. Traditional storage systems\nmainly use parity-based RAID to provide reliability guarantees by striping\nredundancy across multiple devices, but the effectiveness of RAID in SSDs\nremains debatable as parity updates aggravate the wearing and bit error rates\nof SSDs. In particular, an open problem is that how different parity\ndistributions over multiple devices, such as the even distribution suggested by\nconventional wisdom, or uneven distributions proposed in recent RAID schemes\nfor SSDs, may influence the reliability of an SSD RAID array. To address this\nfundamental problem, we propose the first analytical model to quantify the\nreliability dynamics of an SSD RAID array. Specifically, we develop a\n\"non-homogeneous\" continuous time Markov chain model, and derive the transient\nreliability solution. We validate our model via trace-driven simulations and\nconduct numerical analysis to provide insights into the reliability dynamics of\nSSD RAID arrays under different parity distributions and subject to different\nbit error rates and array configurations. Designers can use our model to decide\nthe appropriate parity distribution based on their reliability requirements."
},{
    "category": "cs.PF", 
    "doi": "10.1109/BMSB.2012.6264243", 
    "link": "http://arxiv.org/pdf/1304.2554v3", 
    "title": "Throughput Optimal Scheduling Policies in Networks of Interacting Queues", 
    "arxiv-id": "1304.2554v3", 
    "author": "Emilio Leonardi", 
    "publish": "2013-04-09T12:37:41Z", 
    "summary": "This report considers a fairly general model of constrained queuing networks\nthat allows us to represent both MMBP (Markov Modulated Bernoulli Processes)\narrivals and time-varying service constraints. We derive a set of sufficient\nconditions for throughput optimality of scheduling policies that encompass and\ngeneralize all the previously obtained results in the field. This leads to the\ndefinition of new classes of (non diagonal) throughput optimal scheduling\npolicies. We prove the stability of queues by extending the traditional\nLyapunov drift criteria methodology."
},{
    "category": "cs.PF", 
    "doi": "10.1109/BMSB.2012.6264243", 
    "link": "http://arxiv.org/pdf/1304.3804v1", 
    "title": "Multithreaded Input-Sensitive Profiling", 
    "arxiv-id": "1304.3804v1", 
    "author": "Romolo Marotta", 
    "publish": "2013-04-13T12:39:34Z", 
    "summary": "Input-sensitive profiling is a recent performance analysis technique that\nmakes it possible to estimate the empirical cost function of individual\nroutines of a program, helping developers understand how performance scales to\nlarger inputs and pinpoint asymptotic bottlenecks in the code. A current\nlimitation of input-sensitive profilers is that they specifically target\nsequential computations, ignoring any communication between threads. In this\npaper we show how to overcome this limitation, extending the range of\napplicability of the original approach to multithreaded applications and to\napplications that operate on I/O streams. We develop new metrics for\nautomatically estimating the size of the input given to each routine\nactivation, addressing input produced by non-deterministic memory stores\nperformed by other threads as well as by the OS kernel (e.g., in response to\nI/O or network operations). We provide real case studies, showing that our\nextension allows it to characterize the behavior of complex applications more\nprecisely than previous approaches. An extensive experimental investigation on\na variety of benchmark suites (including the SPEC OMP2012 and the PARSEC\nbenchmarks) shows that our Valgrind-based input-sensitive profiler incurs an\noverhead comparable to other prominent heavyweight analysis tools, while\ncollecting significantly more performance points from each profiling session\nand correctly characterizing both thread-induced and external input."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BMSB.2012.6264243", 
    "link": "http://arxiv.org/pdf/1304.4524v1", 
    "title": "Investigating Randomly Generated Adjacency Matrices For Their Use In   Modeling Wireless Topologies", 
    "arxiv-id": "1304.4524v1", 
    "author": "Sanjit Kaul", 
    "publish": "2013-04-16T17:23:20Z", 
    "summary": "Generation of realistic topologies plays an important role in determining the\naccuracy and validity of simulation studies. This study presents a discussion\nto justify why, and how often randomly generated adjacency matrices may not not\nconform to wireless topologies in the physical world. Specifically, it shows\nthrough analysis and random trials that, more than 90% of times, a randomly\ngenerated adjacency matrix will not conform to a valid wireless topology, when\nit has more than 3 nodes. By showing that node triplets in the adjacency graph\nneed to adhere to rules of a geometric vector space, the study shows that the\nnumber of randomly chosen node triplets failing consistency checks grow at the\norder of O(base^3), where base is the granularity of the distance metric.\nFurther, the study models and presents a probability estimate with which any\nrandomly generated adjacency matrix would fail realization. This information\ncould be used to design simpler algorithms for generating k-connected wireless\ntopologies."
},{
    "category": "cs.PL", 
    "doi": "10.1109/BMSB.2012.6264243", 
    "link": "http://arxiv.org/pdf/1304.5197v1", 
    "title": "Ball-Larus Path Profiling Across Multiple Loop iterations", 
    "arxiv-id": "1304.5197v1", 
    "author": "Irene Finocchi", 
    "publish": "2013-04-18T17:34:38Z", 
    "summary": "Identifying the hottest paths in the control flow graph of a routine can\ndirect optimizations to portions of the code where most resources are consumed.\nThis powerful methodology, called path profiling, was introduced by Ball and\nLarus in the mid 90s and has received considerable attention in the last 15\nyears for its practical relevance. A shortcoming of Ball-Larus path profiling\nwas the inability to profile cyclic paths, making it difficult to mine\ninteresting execution patterns that span multiple loop iterations. Previous\nresults, based on rather complex algorithms, have attempted to circumvent this\nlimitation at the price of significant performance losses already for a small\nnumber of iterations. In this paper, we present a new approach to multiple\niterations path profiling, based on data structures built on top of the\noriginal Ball-Larus numbering technique. Our approach allows it to profile all\nexecuted paths obtained as a concatenation of up to k Ball-Larus acyclic paths,\nwhere k is a user-defined parameter. An extensive experimental investigation on\na large variety of Java benchmarks on the Jikes RVM shows that, surprisingly,\nour approach can be even faster than Ball-Larus due to fewer operations on\nsmaller hash tables, producing compact representations of cyclic paths even for\nlarge values of k."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1086/671105", 
    "link": "http://arxiv.org/pdf/1304.5302v1", 
    "title": "\"Superluminal\" FITS File Processing on Multiprocessors: Zero Time Endian   Conversion Technique", 
    "arxiv-id": "1304.5302v1", 
    "author": "Satoshi Eguchi", 
    "publish": "2013-04-19T03:29:36Z", 
    "summary": "The FITS is the standard file format in astronomy, and it has been extended\nto agree with astronomical needs of the day. However, astronomical datasets\nhave been inflating year by year. In case of ALMA telescope, a ~ TB scale\n4-dimensional data cube may be produced for one target. Considering that\ntypical Internet bandwidth is a few 10 MB/s at most, the original data cubes in\nFITS format are hosted on a VO server, and the region which a user is\ninterested in should be cut out and transferred to the user (Eguchi et al.,\n2012). The system will equip a very high-speed disk array to process a TB scale\ndata cube in a few 10 seconds, and disk I/O speed, endian conversion and data\nprocessing one will be comparable. Hence to reduce the endian conversion time\nis one of issues to realize our system. In this paper, I introduce a technique\nnamed \"just-in-time endian conversion\", which delays the endian conversion for\neach pixel just before it is really needed, to sweep out the endian conversion\ntime; by applying this method, the FITS processing speed increases 20% for\nsingle threading, and 40% for multi-threading compared to CFITSIO. The speed-up\nby the method tightly relates to modern CPU architecture to improve the\nefficiency of instruction pipelines due to break of \"causality\", a programmed\ninstruction code sequence."
},{
    "category": "cs.PF", 
    "doi": "10.1002/cpe.3489", 
    "link": "http://arxiv.org/pdf/1304.7664v3", 
    "title": "Chip-level and multi-node analysis of energy-optimized lattice-Boltzmann   CFD simulations", 
    "arxiv-id": "1304.7664v3", 
    "author": "Gerhard Wellein", 
    "publish": "2013-04-29T13:59:21Z", 
    "summary": "Memory-bound algorithms show complex performance and energy consumption\nbehavior on multicore processors. We choose the lattice-Boltzmann method (LBM)\non an Intel Sandy Bridge cluster as a prototype scenario to investigate if and\nhow single-chip performance and power characteristics can be generalized to the\nhighly parallel case. First we perform an analysis of a sparse-lattice LBM\nimplementation for complex geometries. Using a single-core performance model,\nwe predict the intra-chip saturation characteristics and the optimal operating\npoint in terms of energy to solution as a function of implementation details,\nclock frequency, vectorization, and number of active cores per chip. We show\nthat high single-core performance and a correct choice of the number of active\ncores per chip are the essential optimizations for lowest energy to solution at\nminimal performance degradation. Then we extrapolate to the MPI-parallel level\nand quantify the energy-saving potential of various optimizations and execution\nmodes, where we find these guidelines to be even more important, especially\nwhen communication overhead is non-negligible. In our setup we could achieve\nenergy savings of 35% in this case, compared to a naive approach. We also\ndemonstrate that a simple non-reflective reduction of the clock speed leaves\nmost of the energy saving potential unused."
},{
    "category": "cond-mat.stat-mech", 
    "doi": "10.1002/cpe.3489", 
    "link": "http://arxiv.org/pdf/1305.3578v2", 
    "title": "Search in Random Media with L\u00e9vy Flights", 
    "arxiv-id": "1305.3578v2", 
    "author": "Omer H. Abdelrahman", 
    "publish": "2013-05-15T18:31:22Z", 
    "summary": "We review some of our work regarding search which has been motivated by a\nvariety of applications in engineering and technology, including traffic\nrouting and security in communication networks, explosive mine detection and\nremoval, tactical operations as well as emergency management. We develop the\nbasic mathematical model representing N searchers that proceed independently,\nand which can be affected by destruction or loss, and time-outs. An approach\nbased on Laplace transform is then developed for the case where the success of\nthe search requires that k out of the N searchers be successful, and we\nestimate the amount of energy expended and the number of searchers that are\nrequired to conduct a successful search in time B, provided B is large.\nFinally, we present an iterative numerical solution approach that allows us to\nanalyse the search time and the energy needed to find an object when the search\nspace is non-homogeneous."
},{
    "category": "nlin.CD", 
    "doi": "10.1007/978-3-642-41398-8_19", 
    "link": "http://arxiv.org/pdf/1305.4924v2", 
    "title": "On the importance of nonlinear modeling in computer performance   prediction", 
    "arxiv-id": "1305.4924v2", 
    "author": "Elizabeth Bradley", 
    "publish": "2013-05-21T19:27:05Z", 
    "summary": "Computers are nonlinear dynamical systems that exhibit complex and sometimes\neven chaotic behavior. The models used in the computer systems community,\nhowever, are linear. This paper is an exploration of that disconnect: when\nlinear models are adequate for predicting computer performance and when they\nare not. Specifically, we build linear and nonlinear models of the processor\nload of an Intel i7-based computer as it executes a range of different\nprograms. We then use those models to predict the processor loads forward in\ntime and compare those forecasts to the true continuations of the time series"
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-642-41398-8_19", 
    "link": "http://arxiv.org/pdf/1305.6249v2", 
    "title": "A class of equivalent idle-time-order-based routing policies for   heterogeneous multi-server systems", 
    "arxiv-id": "1305.6249v2", 
    "author": "Ragavendran Gopalakrishnan", 
    "publish": "2013-05-27T15:07:54Z", 
    "summary": "We consider an M/M/N/K/FCFS system (N>0, K>=N), where the servers operate at\n(possibly) heterogeneous service rates. In this situation, the steady state\nbehavior depends on the routing policy that is used to select which idle server\nserves the next job in queue. We define a class of idle-time-order-based\npolicies (including, for example, Longest Idle Server First (LISF)) and show\nthat all policies in this class result in the same steady state behavior. In\nparticular, they are all equivalent to the naive Random routing policy."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1306.2413v2", 
    "title": "Proceedings 11th International Workshop on Quantitative Aspects of   Programming Languages and Systems", 
    "arxiv-id": "1306.2413v2", 
    "author": "Herbert Wiklicky", 
    "publish": "2013-06-11T03:36:49Z", 
    "summary": "Quantitative aspects of computation are important and sometimes essential in\ncharacterising the behavior and determining the properties of systems. They are\nrelated to the use of physical quantities (storage space, time, bandwidth,\netc.) as well as mathematical quantities (e.g. probability and measures for\nreliability, security and trust). Such quantities play a central role in\ndefining both the model of systems (architecture, language design, semantics)\nand the methodologies and tools for the analysis and verification of system\nproperties. The aim of this workshop is to discuss the explicit use of\nquantitative information such as time and probabilities either directly in the\nmodel or as a tool for the analysis of systems."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1306.2425v1", 
    "title": "Ber Performance Analysis of WiMAX PHY Layer under different channel   conditions", 
    "arxiv-id": "1306.2425v1", 
    "author": "Ranjani S", 
    "publish": "2013-06-11T05:40:23Z", 
    "summary": "This paper gives an introduction on the IEEE 802.16 standard WIMAX or\nWorldwide Interoperability for Microwave Access. The different parts give\ndetails on the architectural specifications of WiMAX networks and also on the\nworking principle of WiMAX networks including its services provided. It also\nprovides brief descriptions on its salient features of this technology and how\nit benefits the networking industry. A brief outline of the basic building\nblocks or equipment of WiMAX architecture is also provided. This paper also\nevaluates the simulation performance of IEEE 802.16 OFDM PHY layer. The\nStanford University Interim (SUI) channel model under varying parameters is\nselected for the wireless channel in the simulation. The performance\nmeasurements and analysis was done in simulation developed in MATLAB."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1306.3302v1", 
    "title": "The Effect of Communication and Synchronization on Amdahl Law in   Multicore Systems", 
    "arxiv-id": "1306.3302v1", 
    "author": "Ran Ginosar", 
    "publish": "2013-06-14T06:20:44Z", 
    "summary": "This work analyses the effects of sequential-to-parallel synchronization and\ninter-core communication on multicore performance, speedup and scaling. A\nmodification of Amdahl law is formulated, to reflect the finding that parallel\nspeedup is lower than originally predicted, due to these effects. In\napplications with high inter-core communication requirements, the workload\nshould be executed on a small number of cores, and applications of high\nsequential-to-parallel synchronization requirements may better be executed by\nthe sequential core, even when f, the Amdahl fraction of parallelization, is\nvery close to 1. To improve the scalability and performance speedup of a\nmulticore, it is as important to address the synchronization and connectivity\nintensities of parallel algorithms as their parallelization factor."
},{
    "category": "math.OC", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1306.3513v2", 
    "title": "A Simple Policy for Multiple Queues with Size-Independent Service Times", 
    "arxiv-id": "1306.3513v2", 
    "author": "Zizhuo Wang", 
    "publish": "2013-06-14T20:55:54Z", 
    "summary": "We consider a service system with two Poisson arrival queues. A server\nchooses which queue to serve at each moment. Once a queue is served, all the\ncustomers will be served within a fixed amount of time. This model is useful in\nstudying airport shuttling or certain online computing systems. We propose a\nsimple yet optimal state-independent policy for this problem which is not only\neasy to implement, but also performs very well."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1307.1743v1", 
    "title": "\"The tail wags the dog\": A study of anomaly detection in commercial   application performance", 
    "arxiv-id": "1307.1743v1", 
    "author": "Pradeep Ray", 
    "publish": "2013-07-06T02:02:57Z", 
    "summary": "The IT industry needs systems management models that leverage available\napplication information to detect quality of service, scalability and health of\nservice. Ideally this technique would be common for varying application types\nwith different n-tier architectures under normal production conditions of\nvarying load, user session traffic, transaction type, transaction mix, and\nhosting environment.\n  This paper shows that a whole of service measurement paradigm utilizing a\nblack box M/M/1 queuing model and auto regression curve fitting of the\nassociated CDF are an accurate model to characterize system performance\nsignatures. This modeling method is also used to detect application slow down\nevents. The technique was shown to work for a diverse range of workloads\nranging from 76 Tx/ 5min to 19,025 Tx/ 5min. The method did not rely on\ncustomizations specific to the n-tier architecture of the systems being\nanalyzed and so the performance anomaly detection technique was shown to be\nplatform and configuration agnostic."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1307.2915v1", 
    "title": "Measuring the Optimality of Hadoop Optimization", 
    "arxiv-id": "1307.2915v1", 
    "author": "Dongwon Lee", 
    "publish": "2013-07-10T20:39:24Z", 
    "summary": "In recent years, much research has focused on how to optimize Hadoop jobs.\nTheir approaches are diverse, ranging from improving HDFS and Hadoop job\nscheduler to optimizing parameters in Hadoop configurations. Despite their\nsuccess in improving the performance of Hadoop jobs, however, very little is\nknown about the limit of their optimization performance. That is, how optimal\nis a given Hadoop optimization? When a Hadoop optimization method X improves\nthe performance of a job by Y %, how do we know if this improvement is as good\nas it can be? To answer this question, in this paper, we first examine the\nideal best case, the lower bound, of running time for Hadoop jobs and develop a\nmeasure to accurately estimate how optimal a given Hadoop optimization is with\nrespect to the lower bound. Then, we demonstrate how one may exploit the\nproposed measure to improve the optimization of Hadoop jobs."
},{
    "category": "cs.MM", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1307.4581v4", 
    "title": "Smart Streaming for Online Video Services", 
    "arxiv-id": "1307.4581v4", 
    "author": "Dah Ming Chiu", 
    "publish": "2013-07-17T11:23:09Z", 
    "summary": "Bandwidth consumption is a significant concern for online video service\nproviders. Practical video streaming systems usually use some form of HTTP\nstreaming (progressive download) to let users download the video at a faster\nrate than the video bitrate. Since users may quit before viewing the complete\nvideo, however, much of the downloaded video will be \"wasted\". To the extent\nthat users' departure behavior can be predicted, we develop smart streaming\nthat can be used to improve user QoE with limited server bandwidth or save\nbandwidth cost with unlimited server bandwidth. Through measurement, we extract\ncertain user behavior properties for implementing such smart streaming, and\ndemonstrate its advantage using prototype implementation as well as\nsimulations."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.117", 
    "link": "http://arxiv.org/pdf/1307.6702v6", 
    "title": "A unified approach to the performance analysis of caching systems", 
    "arxiv-id": "1307.6702v6", 
    "author": "Emilio Leonardi", 
    "publish": "2013-07-25T11:31:17Z", 
    "summary": "We propose a unified methodology to analyse the performance of caches (both\nisolated and interconnected), by extending and generalizing a decoupling\ntechnique originally known as Che's approximation, which provides very accurate\nresults at low computational cost. We consider several caching policies, taking\ninto account the effects of temporal locality. In the case of interconnected\ncaches, our approach allows us to do better than the Poisson approximation\ncommonly adopted in prior work. Our results, validated against simulations and\ntrace-driven experiments, provide interesting insights into the performance of\ncaching systems."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2013.5302", 
    "link": "http://arxiv.org/pdf/1307.6976v1", 
    "title": "Performance study and simulation of an anycast protocol for wireless   mobile ad hoc networks", 
    "arxiv-id": "1307.6976v1", 
    "author": "Reza Azizi", 
    "publish": "2013-07-26T09:45:54Z", 
    "summary": "This paper conducts a detailed simulation study of stateless anycast routing\nin a mobile wireless ad hoc network. The model covers all the fundamental\naspects of such networks with a routing mechanism using a scheme of\norientation-dependent inter-node communication links. The simulation system\nWinsim is used which explicitly represents parallelism of events and processes\nin the network. The purpose of these simulations is to investigate the effect\nof node s maximum speed, and different TTL over the network performance under\ntwo different scenarios. Simulation study investigates five practically\nimportant performance metrics of a wireless mobile ad hoc network and shows the\ndependence of this metrics on the transmission radius, link availability, and\nmaximal possible node speed."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijwmn.2013.5302", 
    "link": "http://arxiv.org/pdf/1307.7584v2", 
    "title": "Towards a System Theoretic Approach to Wireless Network Capacity in   Finite Time and Space", 
    "arxiv-id": "1307.7584v2", 
    "author": "Yong Cui", 
    "publish": "2013-07-29T13:54:57Z", 
    "summary": "In asymptotic regimes, both in time and space (network size), the derivation\nof network capacity results is grossly simplified by brushing aside queueing\nbehavior in non-Jackson networks. This simplifying double-limit model, however,\nlends itself to conservative numerical results in finite regimes. To properly\naccount for queueing behavior beyond a simple calculus based on average rates,\nwe advocate a system theoretic methodology for the capacity problem in finite\ntime and space regimes. This methodology also accounts for spatial correlations\narising in networks with CSMA/CA scheduling and it delivers rigorous\nclosed-form capacity results in terms of probability distributions. Unlike\nnumerous existing asymptotic results, subject to anecdotal practical concerns,\nour transient one can be used in practical settings: for example, to compute\nthe time scales at which multi-hop routing is more advantageous than single-hop\nrouting."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijwmn.2013.5302", 
    "link": "http://arxiv.org/pdf/1310.5842v2", 
    "title": "An Empirical Study of Intel Xeon Phi", 
    "arxiv-id": "1310.5842v2", 
    "author": "Chuanfu Xu", 
    "publish": "2013-10-22T08:53:15Z", 
    "summary": "With at least 50 cores, Intel Xeon Phi is a true many-core architecture.\nFeaturing fairly powerful cores, two cache levels, and very fast\ninterconnections, the Xeon Phi can get a theoretical peak of 1000 GFLOPs and\nover 240 GB/s. These numbers, as well as its flexibility - it can be used both\nas a coprocessor or as a stand-alone processor - are very tempting for parallel\napplications looking for new performance records.\n  In this paper, we present an empirical study of Xeon Phi, stressing its\nperformance limits and relevant performance factors, ultimately aiming to\npresent a simplified view of the machine for regular programmers in search for\nperformance.\n  To do so, we have micro-benchmarked the main hardware components of the\nprocessor - the cores, the memory hierarchies, the ring interconnect, and the\nPCIe connection. We show that, in ideal microbenchmarking conditions, the\nperformance that can be achieved is very close to the theoretical peak, as\ngiven in the official programmer's guide. We have also identified and\nquantified several causes for significant performance penalties. Our findings\nhave been captured in four optimization guidelines, and used to build a\nsimplified programmer's view of Xeon Phi, eventually enable the design and\nprototyping of applications on a functionality-based model of the architecture."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BigData.2013.6691706", 
    "link": "http://arxiv.org/pdf/1310.6546v1", 
    "title": "The Implications from Benchmarking Three Big Data Systems", 
    "arxiv-id": "1310.6546v1", 
    "author": "Wei Yang", 
    "publish": "2013-10-24T10:12:07Z", 
    "summary": "Along with today's data explosion and application diversification, a variety\nof hardware platforms for big data are emerging, attracting interests from both\nindustry and academia. The existing hardware platforms represent a wide range\nof implementation approaches, and different hardware platforms have different\nstrengths. In this paper, we conduct comprehensive evaluations on three\nrepresentative big data systems: Intel Xeon, Atom (low power processors), and\nmany-core Tilera using BigDataBench - a big data benchmark suite. Then we\nexplore the relative performance of the three implementation approaches by\nrunning BigDataBench, and provide strong guidance for the big data systems\nconstruction. Through our experiments, we have inferred that a big data system\nbased on specific hardware has different performance in the context of\ndifferent applications and data volumes. When we construct a system, we should\ntake into account not only the performance or energy consumption of the pure\nhardware, but also the characteristics of applications running on them. Data\nscale, application type and complexity should be considered comprehensively\nwhen researchers or architects plan to choose fundamental components for their\nbig data systems."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BigData.2013.6691706", 
    "link": "http://arxiv.org/pdf/1310.7717v2", 
    "title": "Staying Alive: System Design for Self-Sufficient Sensor Networks", 
    "arxiv-id": "1310.7717v2", 
    "author": "Michele Rossi", 
    "publish": "2013-10-29T09:14:59Z", 
    "summary": "Self-sustainability is a crucial step for modern sensor networks. Here, we\noffer an original and comprehensive framework for autonomous sensor networks\npowered by renewable energy sources. We decompose our design into two nested\noptimization steps: the inner step characterizes the optimal network operating\npoint subject to an average energy consumption constraint, while the outer step\nprovides online energy management policies making the system energetically\nself-sufficient in the presence of unpredictable and intermittent energy\nsources. Our framework sheds new light into the design of pragmatic schemes for\nthe control of energy harvesting sensor networks} and permits to gauge the\nimpact of key sensor network parameters, such as the battery capacity, the\nharvester size, the information transmission rate and the radio duty cycle. We\nanalyze the robustness of the obtained energy management policies in the cases\nwhere the nodes have differing energy inflow statistics and where topology\nchanges may occur, devising effective heuristics. Our energy management\npolicies are finally evaluated considering real solar radiation traces,\nvalidating them against state of the art solutions and describing the impact of\nrelevant design choices in terms of achievable network throughput and battery\nlevel dynamics."
},{
    "category": "cs.AI", 
    "doi": "10.1109/ICIAFS.2012.6419885", 
    "link": "http://arxiv.org/pdf/1312.1003v1", 
    "title": "High Throughput Virtual Screening with Data Level Parallelism in   Multi-core Processors", 
    "arxiv-id": "1312.1003v1", 
    "author": "Roshan Ragel", 
    "publish": "2013-12-04T01:53:33Z", 
    "summary": "Improving the throughput of molecular docking, a computationally intensive\nphase of the virtual screening process, is a highly sought area of research\nsince it has a significant weight in the drug designing process. With such\nimprovements, the world might find cures for incurable diseases like HIV\ndisease and Cancer sooner. Our approach presented in this paper is to utilize a\nmulti-core environment to introduce Data Level Parallelism (DLP) to the\nAutodock Vina software, which is a widely used for molecular docking software.\nAutodock Vina already exploits Instruction Level Parallelism (ILP) in\nmulti-core environments and therefore optimized for such environments. However,\nwith the results we have obtained, it can be clearly seen that our approach has\nenhanced the throughput of the already optimized software by more than six\ntimes. This will dramatically reduce the time consumed for the lead\nidentification phase in drug designing along with the shift in the processor\ntechnology from multi-core to many-core of the current era. Therefore, we\nbelieve that the contribution of this project will effectively make it possible\nto expand the number of small molecules docked against a drug target and\nimproving the chances to design drugs for incurable diseases."
},{
    "category": "cs.PF", 
    "doi": "10.5121/ijesa.2013.3303", 
    "link": "http://arxiv.org/pdf/1312.2306v1", 
    "title": "Dominant block guided optimal cache size estimation to maximize IPC of   embedded software", 
    "arxiv-id": "1312.2306v1", 
    "author": "Arvind Rajawat", 
    "publish": "2013-12-09T05:17:45Z", 
    "summary": "Embedded system software is highly constrained from performance, memory\nfootprint, energy consumption and implementing cost view point. It is always\ndesirable to obtain better Instructions per Cycle. Instruction cache has major\ncontribution in improving IPC. Cache memories are realized on the same chip\nwhere the processor is running. This considerably increases the system cost as\nwell. Hence, it is required to maintain a trade off between cache sizes and\nperformance improvement offered. Determining the number of cache lines and size\nof cache line are important parameters for cache designing. The design space\nfor cache is quite large. It is time taking to execute the given application\nwith different cache sizes on an instruction set simulator to figure out the\noptimal cache size. In this paper, a technique is proposed to identify a number\nof cache lines and cache line size for the L1 instruction cache that will offer\nbest or nearly best IPC. Cache size is derived, at a higher abstraction level,\nfrom basic block analysis in the Low Level Virtual Machine environment. The\ncache size estimated is cross validated by simulating the set of benchmark\napplications with different cache sizes in simple scalar simulator. The\nproposed method seems to be superior in terms of estimation accuracy and\nestimation time as compared to the existing methods for estimation of optimal\ncache size parameters like cache line size, number of cache lines."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2013.5505", 
    "link": "http://arxiv.org/pdf/1312.2884v1", 
    "title": "Advanced Antenna Techniques and High Order Sectorization with Novel   Network Tessellation for Enhancing Macro Cell Capacity in DC-HSDPA Network", 
    "arxiv-id": "1312.2884v1", 
    "author": "Jukka Lempiainen", 
    "publish": "2013-12-10T17:19:28Z", 
    "summary": "Mobile operators commonly use macro cells with traditional wide beam antennas\nfor wider coverage in the cell, but future capacity demands cannot be achieved\nby using them only. It is required to achieve maximum practical capacity from\nmacro cells by employing higher order sectorization and by utilizing all\npossible antenna solutions including smart antennas. This paper presents\nenhanced tessellation for 6-sector sites and proposes novel layout for\n12-sector sites. The main target of this paper is to compare the performance of\nconventional wide beam antenna, switched beam smart antenna, adaptive beam\nantenna and different network layouts in terms of offering better received\nsignal quality and user throughput. Splitting macro cell into smaller micro or\npico cells can improve the capacity of network, but this paper highlights the\nimportance of higher order sectorization and advance antenna techniques to\nattain high Signal to Interference plus Noise Ratio (SINR), along with improved\nnetwork capacity. Monte Carlo simulations at system level were done for Dual\nCell High Speed Downlink Packet Access (DC-HSDPA) technology with multiple\n(five) users per Transmission Time Interval (TTI) at different Intersite\nDistance (ISD). The obtained results validate and estimate the gain of using\nsmart antennas and higher order sectorization with proposed network layout."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijwmn.2013.5505", 
    "link": "http://arxiv.org/pdf/1312.3504v1", 
    "title": "Building An Information System for a Distributed Testbed", 
    "arxiv-id": "1312.3504v1", 
    "author": "Shava Smallen", 
    "publish": "2013-12-12T14:47:50Z", 
    "summary": "This paper describes an information system designed to support the large\nvolume of monitoring information generated by a distributed testbed. This\nmonitoring information is produced by several subsystems and consists of status\nand performance data that needs to be federated, distributed, and stored in a\ntimely and easy to use manner. Our approach differs from existing approaches\nbecause it federates and distributes information at a low architectural level\nvia messaging; a natural match to many of the producers and consumers of\ninformation. In addition, a database is easily layered atop the messaging layer\nfor consumers that want to query and search the information. Finally, a common\nlanguage to represent information in all layers of the information system makes\nit significantly easier for users to consume information. Performance data\nshows that this approach meets the significant needs of FutureGrid and would\nmeet the needs of an experimental infrastructure twice the size of FutureGrid.\nIn addition, this design also meets the needs of existing distributed\nscientific infrastructures."
},{
    "category": "cs.PL", 
    "doi": "10.5121/ijwmn.2013.5505", 
    "link": "http://arxiv.org/pdf/1401.3041v1", 
    "title": "Removing Dynamic Type Tests with Context-Driven Basic Block Versioning", 
    "arxiv-id": "1401.3041v1", 
    "author": "Marc Feeley", 
    "publish": "2014-01-14T00:25:38Z", 
    "summary": "Dynamic typing is an important feature of dynamic programming languages.\nPrimitive operators such as those for performing arithmetic and comparisons\ntypically operate on a wide variety of in put value types, and as such, must\ninternally implement some form of dynamic type dispatch and type checking.\nRemoving such type tests is important for an efficient implementation.\n  In this paper, we examine the effectiveness of a novel approach to reducing\nthe number of dynamically executed type tests called context-driven basic block\nversioning. This simple technique clones and specializes basic blocks in such a\nway as to allow the compiler to accumulate type information while machine code\nis generated, without a separate type analysis pass. The accumulated\ninformation allows the removal of some redundant type tests, particularly in\nperformance-critical paths.\n  We have implemented intraprocedural context-driven basic block versioning in\na JavaScript JIT compiler. For comparison, we have also implemented a classical\nflow-based type analysis operating on the same concrete types. Our results show\nthat basic block versioning performs better on most benchmarks and removes a\nlarge fraction of type tests at the expense of a moderate code size increase.\nWe believe that this technique offers a good tradeoff between implementation\ncomplexity and performance, and is suitable for integration in production JIT\ncompilers."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn.2013.5505", 
    "link": "http://arxiv.org/pdf/1401.3541v1", 
    "title": "Self-Optimizing Mechanisms for EMF Reduction in Heterogeneous Networks", 
    "arxiv-id": "1401.3541v1", 
    "author": "Abdoulaye Tall", 
    "publish": "2014-01-15T10:57:42Z", 
    "summary": "This paper focuses on the exposure to Radio Frequency (RF) Electromagnetic\nFields (EMF) and on optimization methods to reduce it. Within the FP7 LEXNET\nproject, an Exposure Index (EI) has been defined that aggregates the essential\ncomponents that impact exposure to EMF. The EI includes, among other, downlink\n(DL) exposure induced by the base stations (BSs) and access points, the uplink\n(UL) exposure induced by the devices in communication, and the corresponding\nexposure time. Motivated by the EI definition, this paper develops stochastic\napproximation based self-optimizing algorithm that dynamically adapts the\nnetwork to reduce the EI in a heterogeneous network with macro- and small\ncells. It is argued that the increase of the small cells' coverage can, to a\ncertain extent, reduce the EI, but above a certain limit, will deteriorate DL\nQoS. A load balancing algorithm is formulated that adapts the small cell'\ncoverage based on UL loads and a DL QoS indicator. The proof of convergence of\nthe algorithm is provided and its performance in terms of EI reduction is\nillustrated through extensive numerical simulations."
},{
    "category": "cs.SY", 
    "doi": "10.5121/ijwmn.2013.5505", 
    "link": "http://arxiv.org/pdf/1401.4691v1", 
    "title": "An algorithm for calculating steady state probabilities of $M|E_r|c|K$   queueing systems", 
    "arxiv-id": "1401.4691v1", 
    "author": "Georg Pflug", 
    "publish": "2014-01-19T16:25:38Z", 
    "summary": "This paper presents a method for calculating steady state probabilities of\n$M|E_r|c|K$ queueing systems. The infinitesimal generator matrix is used to\ndefine all possible states in the system and their transition probabilities.\nWhile this matrix can be written down immediately for many other $M|PH|c|K$\nqueueing systems with phase-type service times (e.g. Coxian, Hypoexponential,\n\\ldots), it requires a more careful analysis for systems with Erlangian service\ntimes. The constructed matrix may then be used to calculate steady state\nprobabilities using an iterative algorithm. The resulting steady state\nprobabilities can be used to calculate various performance measures, e.g. the\naverage queue length. Additionally, computational issues of the implementation\nare discussed and an example from the field of telecommunication call-center\nqueue length will be outlined to substantiate the applicability of these\nefforts. In the appendix, tables of the average queueing length given a\nspecific number of service channels, traffic density, and system size are\npresented."
},{
    "category": "cs.PF", 
    "doi": "10.7321/jscse.v3.n3.68", 
    "link": "http://arxiv.org/pdf/1401.6020v1", 
    "title": "A Brief Review on Models for Performance Evaluation in DSS Architecture", 
    "arxiv-id": "1401.6020v1", 
    "author": "Anastasios N. Venetsanopoulos", 
    "publish": "2014-01-23T15:51:32Z", 
    "summary": "Distributed Software Systems are used these days by many people in the real\ntime operations and modern enterprise applications. One of the most important\nand essential attributes of measurements for the quality of service of\ndistributed software is performance. Performance models can be employed at\nearly stages of the software development cycle to characterize the quantitative\nbehavior of software systems. In this research, performance models based on\nfuzzy logic approach, queuing network approach and Petri net approach have been\nreviewed briefly. One of the most common ways in performance analysis of\ndistributed software systems is translating the UML diagrams to mathematical\nmodeling languages for the description of distributed systems such as queuing\nnetworks or Petri nets. In this paper, some of these approaches are reviewed\nbriefly. Attributes which are used for performance modeling in the literature\nare mostly machine based. On the other hand, end users and client parameters\nfor performance evaluation are not covered extensively. In this way, future\nresearch could be based on developing hybrid models to capture user decision\nvariables which make system performance evaluation more user driven."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2568058.2568068", 
    "link": "http://arxiv.org/pdf/1401.7494v1", 
    "title": "Comparing the Performance of Different x86 SIMD Instruction Sets for a   Medical Imaging Application on Modern Multi- and Manycore Chips", 
    "arxiv-id": "1401.7494v1", 
    "author": "Gerhard Wellein", 
    "publish": "2014-01-29T12:41:44Z", 
    "summary": "Single Instruction, Multiple Data (SIMD) vectorization is a major driver of\nperformance in current architectures, and is mandatory for achieving good\nperformance with codes that are limited by instruction throughput. We\ninvestigate the efficiency of different SIMD-vectorized implementations of the\nRabbitCT benchmark. RabbitCT performs 3D image reconstruction by back\nprojection, a vital operation in computed tomography applications. The\nunderlying algorithm is a challenge for vectorization because it consists,\napart from a streaming part, also of a bilinear interpolation requiring\nscattered access to image data. We analyze the performance of SSE (128 bit),\nAVX (256 bit), AVX2 (256 bit), and IMCI (512 bit) implementations on recent\nIntel x86 systems. A special emphasis is put on the vector gather\nimplementation on Intel Haswell and Knights Corner microarchitectures. Finally\nwe discuss why GPU implementations perform much better for this specific\nalgorithm."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2568058.2568068", 
    "link": "http://arxiv.org/pdf/1403.3480v1", 
    "title": "Performance Benefits of DataMPI: A Case Study with BigDataBench", 
    "arxiv-id": "1403.3480v1", 
    "author": "Zhiwei Xu", 
    "publish": "2014-03-14T03:06:34Z", 
    "summary": "Apache Hadoop and Spark are gaining prominence in Big Data processing and\nanalytics. Both of them are widely deployed on Internet companies. On the other\nhand, high-performance data analysis requirements are causing academical and\nindustrial communities to adopt state-of-the-art technologies in HPC to solve\nBig Data problems. Recently, we have proposed a key-value pair based\ncommunication library, DataMPI, which is extending MPI to support\nHadoop/Spark-like Big Data Computing jobs. In this paper, we use BigDataBench,\na Big Data benchmark suite, to do comprehensive studies on performance and\nresource utilization characterizations of Hadoop, Spark and DataMPI. From our\nexperiments, we observe that the job execution time of DataMPI has up to 55%\nand 39% speedups compared with those of Hadoop and Spark, respectively. Most of\nthe benefits come from the high-efficiency communication mechanisms in DataMPI.\nWe also notice that the resource (CPU, memory, disk and network I/O)\nutilizations of DataMPI are also more efficient than those of the other two\nframeworks."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2568058.2568068", 
    "link": "http://arxiv.org/pdf/1403.5828v1", 
    "title": "A Survey on Network Tomography with Network Coding", 
    "arxiv-id": "1403.5828v1", 
    "author": "Kui Wu", 
    "publish": "2014-03-24T01:34:35Z", 
    "summary": "The overhead of internal network monitoring motivates techniques of network\ntomography. Network coding (NC) presents a new opportunity for network\ntomography as NC introduces topology-dependent correlation that can be further\nexploited in topology estimation. Compared with traditional methods, network\ntomography with NC has many advantages such as the improvement of tomography\naccuracy and the reduction of complexity in choosing monitoring paths. In this\npaper we first introduce the problem of tomography with NC and then propose the\ntaxonomy criteria to classify various methods. We also present existing\nsolutions and future trend. We expect that our comprehensive review on network\ntomography with NC can serve as a good reference for researchers and\npractitioners working in the area."
},{
    "category": "cs.CE", 
    "doi": "10.1145/2568058.2568068", 
    "link": "http://arxiv.org/pdf/1403.7209v1", 
    "title": "Acceleration of a Full-scale Industrial CFD Application with OP2", 
    "arxiv-id": "1403.7209v1", 
    "author": "David Radford", 
    "publish": "2014-03-27T20:14:24Z", 
    "summary": "Hydra is a full-scale industrial CFD application used for the design of\nturbomachinery at Rolls Royce plc. It consists of over 300 parallel loops with\na code base exceeding 50K lines and is capable of performing complex\nsimulations over highly detailed unstructured mesh geometries. Unlike simpler\nstructured-mesh applications, which feature high speed-ups when accelerated by\nmodern processor architectures, such as multi-core and many-core processor\nsystems, Hydra presents major challenges in data organization and movement that\nneed to be overcome for continued high performance on emerging platforms. We\npresent research in achieving this goal through the OP2 domain-specific\nhigh-level framework. OP2 targets the domain of unstructured mesh problems and\nfollows the design of an active library using source-to-source translation and\ncompilation to generate multiple parallel implementations from a single\nhigh-level application source for execution on a range of back-end hardware\nplatforms. We chart the conversion of Hydra from its original hand-tuned\nproduction version to one that utilizes OP2, and map out the key difficulties\nencountered in the process. To our knowledge this research presents the first\napplication of such a high-level framework to a full scale production code.\nSpecifically we show (1) how different parallel implementations can be achieved\nwith an active library framework, even for a highly complicated industrial\napplication such as Hydra, and (2) how different optimizations targeting\ncontrasting parallel architectures can be applied to the whole application,\nseamlessly, reducing developer effort and increasing code longevity.\nPerformance results demonstrate that not only the same runtime performance as\nthat of the hand-tuned original production code could be achieved, but it can\nbe significantly improved on conventional processor systems. Additionally, we\nachieve further..."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2568058.2568068", 
    "link": "http://arxiv.org/pdf/1403.8006v1", 
    "title": "Cache-aware Parallel Programming for Manycore Processors", 
    "arxiv-id": "1403.8006v1", 
    "author": "Wim Vanderbauwhede", 
    "publish": "2014-03-31T14:13:13Z", 
    "summary": "With rapidly evolving technology, multicore and manycore processors have\nemerged as promising architectures to benefit from increasing transistor\nnumbers. The transition towards these parallel architectures makes today an\nexciting time to investigate challenges in parallel computing. The TILEPro64 is\na manycore accelerator, composed of 64 tiles interconnected via multiple 8x8\nmesh networks. It contains per-tile caches and supports cache-coherent shared\nmemory by default. In this paper we present a programming technique to take\nadvantages of distributed caching facilities in manycore processors. However,\nunlike other work in this area, our approach does not use architecture-specific\nlibraries. Instead, we provide the programmer with a novel technique on how to\nprogram future Non-Uniform Cache Architecture (NUCA) manycore systems, bearing\nin mind their caching organisation. We show that our localised programming\napproach can result in a significant improvement of the parallelisation\nefficiency (speed-up)."
},{
    "category": "cs.DC", 
    "doi": "10.3233/978-1-61499-381-0-63", 
    "link": "http://arxiv.org/pdf/1403.8020v1", 
    "title": "An Efficient Thread Mapping Strategy for Multiprogramming on Manycore   Processors", 
    "arxiv-id": "1403.8020v1", 
    "author": "Wim Vanderbauwhede", 
    "publish": "2014-03-31T14:40:02Z", 
    "summary": "The emergence of multicore and manycore processors is set to change the\nparallel computing world. Applications are shifting towards increased\nparallelism in order to utilise these architectures efficiently. This leads to\na situation where every application creates its desirable number of threads,\nbased on its parallel nature and the system resources allowance. Task\nscheduling in such a multithreaded multiprogramming environment is a\nsignificant challenge. In task scheduling, not only the order of the execution,\nbut also the mapping of threads to the execution resources is of a great\nimportance. In this paper we state and discuss some fundamental rules based on\nresults obtained from selected applications of the BOTS benchmarks on the\n64-core TILEPro64 processor. We demonstrate how previously efficient mapping\npolicies such as those of the SMP Linux scheduler become inefficient when the\nnumber of threads and cores grows. We propose a novel, low-overhead technique,\na heuristic based on the amount of time spent by each CPU doing some useful\nwork, to fairly distribute the workloads amongst the cores in a\nmultiprogramming environment. Our novel approach could be implemented as a\npragma similar to those in the new task-based OpenMP versions, or can be\nincorporated as a distributed thread mapping mechanism in future manycore\nprogramming frameworks. We show that our thread mapping scheme can outperform\nthe native GNU/Linux thread scheduler in both single-programming and\nmultiprogramming environments."
},{
    "category": "cs.PF", 
    "doi": "10.3233/978-1-61499-381-0-63", 
    "link": "http://arxiv.org/pdf/1407.3267v2", 
    "title": "Analysis and Approximation of Dual Tandem Queues with Finite Buffer   Capacity", 
    "arxiv-id": "1407.3267v2", 
    "author": "Ning Zhao", 
    "publish": "2014-07-10T06:49:42Z", 
    "summary": "Tandem queues with finite buffer capacity commonly exist in practical\napplications. By viewing a tandem queue as an integrated system, an innovative\napproach has been developed to analyze its performance through the insight from\nreduction method. In our approach, the starvation at the bottleneck caused by\nservice time randomness is modeled and captured by interruptions. Fundamental\nproperties of tandem queues with finite buffer capacity are examined. We show\nthat in general system service rate of a dual tandem queue with finite buffer\ncapacity is equal or smaller than its bottleneck service rate, and virtual\ninterruptions, which are the extra idle period at the bottleneck caused by the\nnon-bottlenecks, depend on arrival rates. Hence, system service rate is a\nfunction of arrival rate when the buffer capacity of a tandem queue is finite.\nApproximation for the mean queue time of a dual tandem queue has been developed\nthrough the concept of virtual interruptions."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.157.6", 
    "link": "http://arxiv.org/pdf/1407.5393v1", 
    "title": "Program Synthesis and Linear Operator Semantics", 
    "arxiv-id": "1407.5393v1", 
    "author": "Herbert Wiklicky", 
    "publish": "2014-07-21T07:28:08Z", 
    "summary": "For deterministic and probabilistic programs we investigate the problem of\nprogram synthesis and program optimisation (with respect to non-functional\nproperties) in the general setting of global optimisation. This approach is\nbased on the representation of the semantics of programs and program fragments\nin terms of linear operators, i.e. as matrices. We exploit in particular the\nfact that we can automatically generate the representation of the semantics of\nelementary blocks. These can then can be used in order to compositionally\nassemble the semantics of a whole program, i.e. the generator of the\ncorresponding Discrete Time Markov Chain (DTMC). We also utilise a generalised\nversion of Abstract Interpretation suitable for this linear algebraic or\nfunctional analytical framework in order to formulate semantical constraints\n(invariants) and optimisation objectives (for example performance\nrequirements)."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.157.6", 
    "link": "http://arxiv.org/pdf/1407.7448v1", 
    "title": "Parallelism-Aware Memory Interference Delay Analysis for COTS Multicore   Systems", 
    "arxiv-id": "1407.7448v1", 
    "author": "Heechul Yun", 
    "publish": "2014-07-25T08:43:36Z", 
    "summary": "In modern Commercial Off-The-Shelf (COTS) multicore systems, each core can\ngenerate many parallel memory requests at a time. The processing of these\nparallel requests in the DRAM controller greatly affects the memory\ninterference delay experienced by running tasks on the platform. In this paper,\nwe model a modern COTS multicore system which has a nonblocking last-level\ncache (LLC) and a DRAM controller that prioritizes reads over writes. To\nminimize interference, we focus on LLC and DRAM bank partitioned systems. Based\non the model, we propose an analysis that computes a safe upper bound for the\nworst-case memory interference delay. We validated our analysis on a real COTS\nmulticore platform with a set of carefully designed synthetic benchmarks as\nwell as SPEC2006 benchmarks. Evaluation results show that our analysis is more\naccurately capture the worst-case memory interference delay and provides safer\nupper bounds compared to a recently proposed analysis which significantly\nunder-estimate the delay."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.157.6", 
    "link": "http://arxiv.org/pdf/1407.8309v2", 
    "title": "An Alternating Direction Method Approach to Cloud Traffic Management", 
    "arxiv-id": "1407.8309v2", 
    "author": "Baochun Li", 
    "publish": "2014-07-31T08:30:08Z", 
    "summary": "In this paper, we introduce a unified framework for studying various cloud\ntraffic management problems, ranging from geographical load balancing to\nbackbone traffic engineering. We first abstract these real-world problems as a\nmulti-facility resource allocation problem, and then present two distributed\noptimization algorithms by exploiting the special structure of the problem. Our\nalgorithms are inspired by Alternating Direction Method of Multipliers (ADMM),\nenjoying a number of unique features. Compared to dual decomposition, they\nconverge with non-strictly convex objective functions; compared to other\nADMM-type algorithms, they not only achieve faster convergence under weaker\nassumptions, but also have lower computational complexity and lower\nmessage-passing overhead. The simulation results not only confirm these\ndesirable features of our algorithms, but also highlight several additional\nadvantages, such as scalability and fault-tolerance."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.157.6", 
    "link": "http://arxiv.org/pdf/1410.0804v3", 
    "title": "Multi-step Uniformization with Steady-State Detection in Nonstationary   M/M/s Queuing Systems", 
    "arxiv-id": "1410.0804v3", 
    "author": "Maciej Burak", 
    "publish": "2014-10-03T10:13:03Z", 
    "summary": "A new approach to the steady state detection in the uniformization method of\nsolving continuous time Markov chains is introduced. The method is particularly\nuseful in solving inhomogenous CTMC's in multiple steps, where the desired\nerror bound of the whole solution can be distributed not proportionally to the\nlengths of the respective intervals, but rather in a way, that maximizes the\nchances of detecting a steady state. Additionally, the convergence properties\nof the underlying DTMC are used to further enhance the computational savings\ndue to the steady state detection. The method is applied to the problem of\nmodeling a Call Center using inhomogenous CTMC model of a M(t)/M(t)/s(t)\nqueuing system."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.157.6", 
    "link": "http://arxiv.org/pdf/1410.4168v1", 
    "title": "Efficient HTTP based I/O on very large datasets for high performance   computing with the libdavix library", 
    "arxiv-id": "1410.4168v1", 
    "author": "Fabrizio Furano", 
    "publish": "2014-10-15T18:57:12Z", 
    "summary": "Remote data access for data analysis in high performance computing is\ncommonly done with specialized data access protocols and storage systems. These\nprotocols are highly optimized for high throughput on very large datasets,\nmulti-streams, high availability, low latency and efficient parallel I/O. The\npurpose of this paper is to describe how we have adapted a generic protocol,\nthe Hyper Text Transport Protocol (HTTP) to make it a competitive alternative\nfor high performance I/O and data analysis applications in a global computing\ngrid: the Worldwide LHC Computing Grid. In this work, we first analyze the\ndesign differences between the HTTP protocol and the most common high\nperformance I/O protocols, pointing out the main performance weaknesses of\nHTTP. Then, we describe in detail how we solved these issues. Our solutions\nhave been implemented in a toolkit called davix, available through several\nrecent Linux distributions. Finally, we describe the results of our benchmarks\nwhere we compare the performance of davix against a HPC specific protocol for a\ndata analysis use case."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2751205.2751240", 
    "link": "http://arxiv.org/pdf/1410.5010v2", 
    "title": "Quantifying performance bottlenecks of stencil computations using the   Execution-Cache-Memory model", 
    "arxiv-id": "1410.5010v2", 
    "author": "Gerhard Wellein", 
    "publish": "2014-10-18T21:49:45Z", 
    "summary": "Stencil algorithms on regular lattices appear in many fields of computational\nscience, and much effort has been put into optimized implementations. Such\nactivities are usually not guided by performance models that provide estimates\nof expected speedup. Understanding the performance properties and bottlenecks\nby performance modeling enables a clear view on promising optimization\nopportunities. In this work we refine the recently developed\nExecution-Cache-Memory (ECM) model and use it to quantify the performance\nbottlenecks of stencil algorithms on a contemporary Intel processor. This\nincludes applying the model to arrive at single-core performance and\nscalability predictions for typical corner case stencil loop kernels. Guided by\nthe ECM model we accurately quantify the significance of \"layer conditions,\"\nwhich are required to estimate the data traffic through the memory hierarchy,\nand study the impact of typical optimization approaches such as spatial\nblocking, strength reduction, and temporal blocking for their expected\nbenefits. We also compare the ECM model to the widely known Roofline model."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2751205.2751240", 
    "link": "http://arxiv.org/pdf/1410.5102v1", 
    "title": "On Bootstrapping Machine Learning Performance Predictors via Analytical   Models", 
    "arxiv-id": "1410.5102v1", 
    "author": "Paolo Romano", 
    "publish": "2014-10-19T18:32:37Z", 
    "summary": "Performance modeling typically relies on two antithetic methodologies: white\nbox models, which exploit knowledge on system's internals and capture its\ndynamics using analytical approaches, and black box techniques, which infer\nrelations among the input and output variables of a system based on the\nevidences gathered during an initial training phase. In this paper we\ninvestigate a technique, which we name Bootstrapping, which aims at reconciling\nthese two methodologies and at compensating the cons of the one with the pros\nof the other. We thoroughly analyze the design space of this gray box modeling\ntechnique, and identify a number of algorithmic and parametric trade-offs which\nwe evaluate via two realistic case studies, a Key-Value Store and a Total Order\nBroadcast service."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2751205.2751240", 
    "link": "http://arxiv.org/pdf/1410.6952v1", 
    "title": "QoE Modelling, Measurement and Prediction: A Review", 
    "arxiv-id": "1410.6952v1", 
    "author": "Christer \u00c5hlund", 
    "publish": "2014-10-25T19:13:49Z", 
    "summary": "In mobile computing systems, users can access network services anywhere and\nanytime using mobile devices such as tablets and smart phones. These devices\nconnect to the Internet via network or telecommunications operators. Users\nusually have some expectations about the services provided to them by different\noperators. Users' expectations along with additional factors such as cognitive\nand behavioural states, cost, and network quality of service (QoS) may\ndetermine their quality of experience (QoE). If users are not satisfied with\ntheir QoE, they may switch to different providers or may stop using a\nparticular application or service. Thus, QoE measurement and prediction\ntechniques may benefit users in availing personalized services from service\nproviders. On the other hand, it can help service providers to achieve lower\nuser-operator switchover. This paper presents a review of the state-the-art\nresearch in the area of QoE modelling, measurement and prediction. In\nparticular, we investigate and discuss the strengths and shortcomings of\nexisting techniques. Finally, we present future research directions for\ndeveloping novel QoE measurement and prediction techniques"
},{
    "category": "cs.NI", 
    "doi": "10.1145/2751205.2751240", 
    "link": "http://arxiv.org/pdf/1411.0143v1", 
    "title": "Estimating the Spatial Reuse with Configuration Models", 
    "arxiv-id": "1411.0143v1", 
    "author": "Pascal Moyal", 
    "publish": "2014-11-01T17:55:45Z", 
    "summary": "We propose a new methodology to estimate the spatial reuse of CSMA-like\nscheduling. Instead of focusing on spatial configurations of users, we model\nthe interferences between users as a random graph. Using configuration models\nfor random graphs, we show how the properties of the medium access mechanism\nare captured by some deterministic differential equations, when the size of the\ngraph gets large. Performance indicators such as the probability of connection\nof a given node can then be efficiently computed from these equations. We also\nperform simulations to illustrate the results on different types of random\ngraphs. Even on spatial structures, these estimates get very accurate as soon\nas the variance of the interference is not negligible."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2014.28", 
    "link": "http://arxiv.org/pdf/1411.0912v1", 
    "title": "Cloud Benchmarking for Performance", 
    "arxiv-id": "1411.0912v1", 
    "author": "Adam Barker", 
    "publish": "2014-11-04T13:57:24Z", 
    "summary": "How can applications be deployed on the cloud to achieve maximum performance?\nThis question has become significant and challenging with the availability of a\nwide variety of Virtual Machines (VMs) with different performance capabilities\nin the cloud. The above question is addressed by proposing a six step\nbenchmarking methodology in which a user provides a set of four weights that\nindicate how important each of the following groups: memory, processor,\ncomputation and storage are to the application that needs to be executed on the\ncloud. The weights along with cloud benchmarking data are used to generate a\nranking of VMs that can maximise performance of the application. The rankings\nare validated through an empirical analysis using two case study applications;\nthe first is a financial risk application and the second is a molecular\ndynamics simulation, which are both representative of workloads that can\nbenefit from execution on the cloud. Both case studies validate the feasibility\nof the methodology and highlight that maximum performance can be achieved on\nthe cloud by selecting the top ranked VMs produced by the methodology."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2014.28", 
    "link": "http://arxiv.org/pdf/1411.1460v1", 
    "title": "Branch-Avoiding Graph Algorithms", 
    "arxiv-id": "1411.1460v1", 
    "author": "Richard Vuduc", 
    "publish": "2014-11-06T00:36:24Z", 
    "summary": "This paper quantifies the impact of branches and branch mispredictions on the\nsingle-core performance for two classes of graph problems. Specifically, we\nconsider classical algorithms for computing connected components and\nbreadth-first search (BFS). We show that branch mispredictions are costly and\ncan reduce performance by as much as 30%-50%. This insight suggests that one\nshould seek graph algorithms and implementations that avoid branches.\n  As a proof-of-concept, we devise such implementations for both the classic\ntop-down algorithm for BFS and the Shiloach-Vishkin algorithm for connected\ncomponents. We evaluate these implementations on current x86 and ARM-based\nprocessors to show the efficacy of the approach. Our results suggest how both\ncompiler writers and architects might exploit this insight to improve graph\nprocessing systems more broadly and create better systems for such problems."
},{
    "category": "cs.NI", 
    "doi": "10.1109/CloudCom.2014.28", 
    "link": "http://arxiv.org/pdf/1411.1998v1", 
    "title": "Dimensioning of PA for massive MIMO system with load adaptive number of   antennas", 
    "arxiv-id": "1411.1998v1", 
    "author": "Cicek Cavdar", 
    "publish": "2014-10-24T21:00:25Z", 
    "summary": "This paper takes into consideration the non-ideal efficiency characteristics\nof realistic power amplifiers (PAs) along with the daily traffic profile in\norder to investigate the impact of PA dimensioning on the energy efficiency\n(EE) of load adaptive massive MIMO system. A multicellular system has been\nconsidered where each base station (BS) is equipped with a large number of\nantennas to serve many single antenna users. For a given number of users in a\ncell, the optimum number of active antennas maximizing EE has been derived\nwhere total BS downlink power is assumed to be fixed. Under the same\nassumption, the PAs have been dimensioned in a way that maximizes network EE\nnot only for a single time snapshot but over twenty four hours of operation\nwhile considering dynamic efficiency characteristics of the PAs. In order to\nincorporate this daily load profile, each BS has been modeled as an M/G/m/m\nstate dependent queue under the assumption that the network is dimensioned to\nserve a maximum number of users at a time corresponding to 100% cell traffic\nload. This load adaptive system along with the optimized PA dimensioning\nachieves 30% higher energy efficiency compared to a base line system where the\nBSs always run with a fixed number of active antennas which are most energy\nefficient while serving 100% traffic load."
},{
    "category": "cs.PF", 
    "doi": "10.1109/CloudCom.2014.28", 
    "link": "http://arxiv.org/pdf/1411.2047v1", 
    "title": "Investigation of the relationship between code change set n-grams and   change in energy consumption", 
    "arxiv-id": "1411.2047v1", 
    "author": "Stephen Romansky", 
    "publish": "2014-11-07T22:05:16Z", 
    "summary": "The amount of software running on mobile devices is constantly growing as\nconsumers and industry purchase more battery powered devices. On the other\nhand, tools that provide developers with feed- back on how their software\nchanges affect battery life are not widely available. This work employs Green\nMining, the study of the rela- tionship between energy consumption and software\nchangesets, and n-gram language models to evaluate if source code changeset\nperplex- ity correlates with change in energy consumption. A correlation be-\ntween perplexity and change in energy consumption would permit the development\nof a tool that predicts the impact a code changeset may have on a software\napplications energy consumption. The case study results show that there is weak\nto no correlation between cross en- tropy and change in energy consumption.\nTherefore, future areas of investigation are proposed."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2014.28", 
    "link": "http://arxiv.org/pdf/1411.2222v2", 
    "title": "Optimization of Discrete-parameter Multiprocessor Systems using a Novel   Ergodic Interpolation Technique", 
    "arxiv-id": "1411.2222v2", 
    "author": "Madhav P. Desai", 
    "publish": "2014-11-09T12:21:23Z", 
    "summary": "Modern multi-core systems have a large number of design parameters, most of\nwhich are discrete-valued, and this number is likely to keep increasing as chip\ncomplexity rises. Further, the accurate evaluation of a potential design choice\nis computationally expensive because it requires detailed cycle-accurate system\nsimulation. If the discrete parameter space can be embedded into a larger\ncontinuous parameter space, then continuous space techniques can, in principle,\nbe applied to the system optimization problem. Such continuous space techniques\noften scale well with the number of parameters.\n  We propose a novel technique for embedding the discrete parameter space into\nan extended continuous space so that continuous space techniques can be applied\nto the embedded problem using cycle accurate simulation for evaluating the\nobjective function. This embedding is implemented using simulation-based\nergodic interpolation, which, unlike spatial interpolation, produces the\ninterpolated value within a single simulation run irrespective of the number of\nparameters. We have implemented this interpolation scheme in a cycle-based\nsystem simulator. In a characterization study, we observe that the interpolated\nperformance curves are continuous, piece-wise smooth, and have low statistical\nerror. We use the ergodic interpolation-based approach to solve a large\nmulti-core design optimization problem with 31 design parameters. Our results\nindicate that continuous space optimization using ergodic interpolation-based\nembedding can be a viable approach for large multi-core design optimization\nproblems."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2014.28", 
    "link": "http://arxiv.org/pdf/1411.3656v1", 
    "title": "The Implementation of a Real-Time Polyphase Filter", 
    "arxiv-id": "1411.3656v1", 
    "author": "Wes Armour", 
    "publish": "2014-11-12T18:33:21Z", 
    "summary": "In this article we study the suitability of dierent computational\naccelerators for the task of real-time data processing. The algorithm used for\ncomparison is the polyphase filter, a standard tool in signal processing and a\nwell established algorithm. We measure performance in FLOPs and execution time,\nwhich is a critical factor for real-time systems. For our real-time studies we\nhave chosen a data rate of 6.5GB/s, which is the estimated data rate for a\nsingle channel on the SKAs Low Frequency Aperture Array. Our findings how that\nGPUs are the most likely candidate for real-time data processing. GPUs are\nbetter in both performance and power consumption."
},{
    "category": "cs.PF", 
    "doi": "10.5121/csit.2014.41120", 
    "link": "http://arxiv.org/pdf/1411.4733v1", 
    "title": "On The Modeling of OpenFlow-based SDNs: The Single Node Case", 
    "arxiv-id": "1411.4733v1", 
    "author": "Michael Jarschel", 
    "publish": "2014-11-18T04:40:20Z", 
    "summary": "OpenFlow is one of the most commonly used protocols for communication between\nthe controller and the forwarding element in a software defined network (SDN).\nA model based on M/M/1 queues is proposed in [1] to capture the communication\nbetween the forwarding element and the controller. Albeit the model provides\nuseful insight, it is accurate only for the case when the probability of\nexpecting a new flow is small. Secondly, it is not straight forward to extend\nthe model in [1] to more than one forwarding element in the data plane. In this\nwork we propose a model which addresses both these challenges. The model is\nbased on Jackson assumption but with corrections tailored to the OpenFlow based\nSDN network. Performance analysis using the proposed model indicates that the\nmodel is accurate even for the case when the probability of new flow is quite\nlarge. Further we show by a toy example that the model can be extended to more\nthan one node in the data plane."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TMC.2011.60", 
    "link": "http://arxiv.org/pdf/1411.6521v2", 
    "title": "Energy-Efficient Strategies for Cooperative Multi-Channel MAC Protocols", 
    "arxiv-id": "1411.6521v2", 
    "author": "Vikram Srinivasan", 
    "publish": "2014-11-24T16:43:26Z", 
    "summary": "Distributed Information SHaring (DISH) is a new cooperative approach to\ndesigning multi-channel MAC protocols. It aids nodes in their decision making\nprocesses by compensating for their missing information via information sharing\nthrough other neighboring nodes. This approach was recently shown to\nsignificantly boost the throughput of multi-channel MAC protocols. However, a\ncritical issue for ad hoc communication devices, i.e., energy efficiency, has\nyet to be addressed. In this paper, we address this issue by developing simple\nsolutions which (1) reduce the energy consumption (2) without compromising the\nthroughput performance, and meanwhile (3) maximize cost efficiency. We propose\ntwo energy-efficient strategies: in-situ energy conscious DISH which uses\nexisting nodes only, and altruistic DISH which needs additional nodes called\naltruists. We compare five protocols with respect to the strategies and\nidentify altruistic DISH to be the right choice in general: it (1) conserves\n40-80% of energy, (2) maintains the throughput advantage gained from the DISH\napproach, and (3) more than doubles the cost efficiency compared to protocols\nwithout applying the strategy. On the other hand, our study shows that in-situ\nenergy conscious DISH is suitable only in certain limited scenarios."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TMC.2011.60", 
    "link": "http://arxiv.org/pdf/1411.6749v1", 
    "title": "Analyzing DISH for Multi-Channel MAC Protocols in Wireless Networks", 
    "arxiv-id": "1411.6749v1", 
    "author": "Vikram Srinivasan", 
    "publish": "2014-11-25T06:58:51Z", 
    "summary": "For long, node cooperation has been exploited as a data relaying mechanism.\nHowever, the wireless channel allows for much richer interaction between nodes.\nOne such scenario is in a multi-channel environment, where transmitter-receiver\npairs may make incorrect decisions (e.g., in selecting channels) but idle\nneighbors could help by sharing information to prevent undesirable consequences\n(e.g., data collisions). This represents a Distributed Information SHaring\n(DISH) mechanism for cooperation and suggests new ways of designing cooperative\nprotocols. However, what is lacking is a theoretical understanding of this new\nnotion of cooperation. In this paper, we view cooperation as a network resource\nand evaluate the availability of cooperation via a metric, $p_{co}$, the\nprobability of obtaining cooperation. First, we analytically evaluate $p_{co}$\nin the context of multi-channel multi-hop wireless networks. Second, we verify\nour analysis via simulations and the results show that our analysis accurately\ncharacterizes the behavior of $p_{co}$ as a function of underlying network\nparameters. This step also yields important insights into DISH with respect to\nnetwork dynamics. Third, we investigate the correlation between $p_{co}$ and\nnetwork performance in terms of collision rate, packet delay, and throughput.\nThe results indicate a near-linear relationship, which may significantly\nsimplify performance analysis for cooperative networks and suggests that\n$p_{co}$ be used as an appropriate performance indicator itself. Throughout\nthis work, we utilize, as appropriate, three different DISH contexts ---\nmodel-based DISH, ideal DISH, and real DISH --- to explore $p_{co}$."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TMC.2009.138", 
    "link": "http://arxiv.org/pdf/1411.6791v1", 
    "title": "A Metric for DISH Networks: Analysis, Implications, and Applications", 
    "arxiv-id": "1411.6791v1", 
    "author": "Mehul Motani", 
    "publish": "2014-11-25T10:22:06Z", 
    "summary": "In wireless networks, node cooperation has been exploited as a data relaying\nmechanism for decades. However, the wireless channel allows for much richer\ninteraction among nodes. In particular, Distributed Information SHaring (DISH)\nrepresents a new improvement to multi-channel MAC protocol design by using a\ncooperative element at the control plane. In this approach, nodes exchange\ncontrol information to make up for other nodes' insufficient knowledge about\nthe environment, and thereby aid in their decision making. To date, what is\nlacking is a theoretical understanding of DISH. In this paper, we view\ncooperation as a network resource and evaluate the availability of cooperation,\n$p_{co}$. We first analyze $p_{co}$ in the context of a multi-channel multi-hop\nwireless network, and then perform simulations which show that the analysis\naccurately characterizes $p_{co}$ as a function of underlying network\nparameters. Next, we investigate the correlation between $p_{co}$ and network\nmetrics such as collision rate, packet delay, and throughput. We find a\nnear-linear relationship between $p_{co}$ and the metrics, which suggests that\n$p_{co}$ can be used as an appropriate performance indicator itself. Finally,\nwe apply our analysis to solving a channel bandwidth allocation problem, where\nwe derive optimal schemes and provide general guidelines on bandwidth\nallocation for DISH networks."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TMC.2009.138", 
    "link": "http://arxiv.org/pdf/1411.7910v1", 
    "title": "A Flexible Framework for Accurate Simulation of Cloud In-Memory Data   Stores", 
    "arxiv-id": "1411.7910v1", 
    "author": "Sebastiano Peluso", 
    "publish": "2014-11-28T15:38:23Z", 
    "summary": "In-memory (transactional) data stores are recognized as a first-class data\nmanagement technology for cloud platforms, thanks to their ability to match the\nelasticity requirements imposed by the pay-as-you-go cost model. On the other\nhand, defining the well-suited amount of cache servers to be deployed, and the\ndegree of in-memory replication of slices of data, in order to optimize\nreliability/availability and performance tradeoffs, is far from being a trivial\ntask. Yet, it is an essential aspect of the provisioning process of cloud\nplatforms, given that it has an impact on how well cloud resources are actually\nexploited. To cope with the issue of determining optimized configurations of\ncloud in-memory data stores, in this article we present a flexible simulation\nframework offering skeleton simulation models that can be easily specialized in\norder to capture the dynamics of diverse data grid systems, such as those\nrelated to the specific protocol used to provide data consistency and/or\ntransactional guarantees. Besides its flexibility, another peculiar aspect of\nthe framework lies in that it integrates simulation and machine-learning\n(black-box) techniques, the latter being essentially used to capture the\ndynamics of the data-exchange layer (e.g. the message passing layer) across the\ncache servers. This is a relevant aspect when considering that the actual\ndata-transport/networking infrastructure on top of which the data grid is\ndeployed might be unknown, hence being not feasible to be modeled via white-box\n(namely purely simulative) approaches. We also provide an extended experimental\nstudy aimed at validating instances of simulation models supported by our\nframework against execution dynamics of real data grid systems deployed on top\nof either private or public cloud infrastructures."
},{
    "category": "math.PR", 
    "doi": "10.1109/TMC.2009.138", 
    "link": "http://arxiv.org/pdf/1412.2321v1", 
    "title": "On Transitory Queueing", 
    "arxiv-id": "1412.2321v1", 
    "author": "Amy R. Ward", 
    "publish": "2014-12-07T06:04:53Z", 
    "summary": "We introduce a framework and develop a theory of transitory queueing models.\nThese are models that are not only non-stationary and time-varying but also\nhave other features such as the queueing system operates over finite time, or\nonly a finite population arrives. Such models are relevant in many real-world\nsettings, from queues at post-offces, DMV, concert halls and stadia to\nout-patient departments at hospitals. We develop fluid and diffusion limits for\na large class of transitory queueing models. We then introduce three specific\nmodels that fit within this framework, namely, the Delta(i)/GI/1 model, the\nconditioned G/GI/1 model, and an arrival model of scheduled traffic with epoch\nuncertainty. We show that asymptotically these models are distributionally\nequivalent, i.e., they have the same fluid and diffusion limits. We note that\nour framework provides the first ever way of analyzing the standard G/GI/1\nmodel when we condition on the number of arrivals. In obtaining these results,\nwe provide generalizations and extensions of the Glivenko-Cantelli and Donskers\nTheorem for empirical processes with triangular arrays. Our analysis uses the\npopulation acceleration technique that we introduce and develop. This may be\nuseful in analysis of other non-stationary and non-ergodic queuing models."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1412.3624v1", 
    "title": "Dynamic Channel Allocation for Class-Based QoS Provisioning and Call   Admission in Visible Light Communication", 
    "arxiv-id": "1412.3624v1", 
    "author": "Yeong Min Jang", 
    "publish": "2014-12-11T12:15:12Z", 
    "summary": "Provisioning of quality of service (QoS) is a key issue in visible light\ncommunication (VLC) system as well as in other wireless communication systems.\nDue to the fact that QoS requirements are not as strict for all traffic types,\nmore calls of higher priority traffic classes can be accommodated by blocking\nsome more calls of lower priority traffic classes. Diverse types of high data\nrate traffic are supported by existing wireless communication systems while the\nresource is limited. Hence, priority based resource allocation can ensure the\nservice quality for the calls of important traffic class. The fixed guard\nchannels to prioritize any class of calls always reduce the channel\nutilization. In this paper we propose a priority based dynamic channel\nreservation scheme for higher priority calls that does not reduce the channel\nutilization significantly. The number of reserved channels for each of the\nindividual traffic classes is calculated using real-time observation of the\ncall arrival rates of all the traffic classes. The features of the scheme allow\nreduction of the call blocking probability of higher priority calls along with\nthe increase of the channel utilization. The proposed Markov Chain model is\nexpected to be very much effective for the queuing analysis especially for the\npriority scheme of any number of traffic classes. The numerical results show\nthat the proposed scheme is able to attain reasonable call blocking probability\nof higher priority calls without sacrificing channel utilization."
},{
    "category": "cs.SE", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1412.3687v1", 
    "title": "Modelling common cause failures of large digital I&C systems with   coloured Petri nets", 
    "arxiv-id": "1412.3687v1", 
    "author": "Nicolas Villaume", 
    "publish": "2014-12-09T18:06:33Z", 
    "summary": "The purpose of this study is the representation of Common Cause Failures\n(CCF) in large digital systems. The system under study is representative of a\ncontrol system of a nuclear plant. The model for CCF is the generalized Atwood\nmodel. It can represent independent failures, CCF non-lethal for some system\nelements and CCF lethal to all. The Atwood model was modified to \"direct\"\nnon-lethal DCC on certain parts of the system and take into account the\ndifferent possible origins of DCC. Maintenance and repairs are taken into\naccount in the model that is thus dynamic. The main evaluation results are\nprobabilistic, the considered indicator is the probability of failure on demand\n(PFD). A comparison is made between the estimator of the PFD taking into\naccount all the failures and the estimator taking into account only the\ndetected failures."
},{
    "category": "cs.DC", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1412.3906v1", 
    "title": "Easy-to-Use On-the-Fly Binary Program Acceleration on Many-Cores", 
    "arxiv-id": "1412.3906v1", 
    "author": "Christian Plessl", 
    "publish": "2014-12-12T07:44:52Z", 
    "summary": "This paper introduces Binary Acceleration At Runtime (BAAR), an easy-to-use\non-the-fly binary acceleration mechanism which aims to tackle the problem of\nenabling existent software to automatically utilize accelerators at runtime.\nBAAR is based on the LLVM Compiler Infrastructure and has a client-server\narchitecture. The client runs the program to be accelerated in an environment\nwhich allows program analysis and profiling. Program parts which are identified\nas suitable for the available accelerator are exported and sent to the server.\nThe server optimizes these program parts for the accelerator and provides RPC\nexecution for the client. The client transforms its program to utilize\naccelerated execution on the server for offloaded program parts.\n  We evaluate our work with a proof-of-concept implementation of BAAR that uses\nan Intel Xeon Phi 5110P as the acceleration target and performs automatic\noffloading, parallelization and vectorization of suitable program parts. The\npracticality of BAAR for real-world examples is shown based on a study of\nstencil codes. Our results show a speedup of up to 4x without any\ndeveloper-provided hints and 5.77x with hints over the same code compiled with\nthe Intel Compiler at optimization level O2 and running on an Intel Xeon\nE5-2670 machine. Based on our insights gained during implementation and\nevaluation we outline future directions of research, e.g., offloading more\nfine-granular program parts than functions, a more sophisticated communication\nmechanism or introducing on-stack-replacement."
},{
    "category": "cs.DC", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1412.7789v1", 
    "title": "To Use or Not to Use: Graphics Processing Units for Pattern Matching   Algorithms", 
    "arxiv-id": "1412.7789v1", 
    "author": "Dhammika Elkaduwe", 
    "publish": "2014-12-25T05:27:49Z", 
    "summary": "String matching is an important part in today's computer applications and\nAho-Corasick algorithm is one of the main string matching algorithms used to\naccomplish this. This paper discusses that when can the GPUs be used for string\nmatching applications using the Aho-Corasick algorithm as a benchmark. We have\nto identify the best unit to run our string matching algorithm according to the\nperformance of our devices and the applications. Sometimes CPU gives better\nperformance than GPU and sometimes GPU gives better performance than CPU.\nTherefore, identifying this critical point is significant task for researchers\nwho are using GPUs to improve the performance of their string matching\napplications based on string matching algorithms."
},{
    "category": "cs.CE", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1412.8467v1", 
    "title": "A Structured Hardware Software Architecture for Peptide Based Diagnosis   - Sub-string Matching Problem with Limited Tolerance (ICIAfS14)", 
    "arxiv-id": "1412.8467v1", 
    "author": "M. Niranjan", 
    "publish": "2014-12-25T11:44:51Z", 
    "summary": "The problem of inferring proteins from complex peptide samples in shotgun\nproteomic workflow sets extreme demands on computational resources. This is\nexacerbated by the fact that, in general, a given protein cannot be defined by\na fixed sequence of amino acids due to the existence of splice variants and\nisoforms of that protein. Therefore, the problem of protein inference could be\nconsidered as one of identifying sequences of amino acids with some limited\ntolerance. Two problems arise from this: a) due to these variations, the\napplicability of exact string matching methodologies could be questioned and b)\nthe difficulty of defining a reference sequence for a particular set of\nproteins that are functionally indistinguishable, but with some variation in\nfeatures. This paper presents a model-based inference approach that is\ndeveloped and validated to solve the inference problem. Our approach starts\nfrom an examination of the known set of splice variants and isoforms of a\ntarget protein to identify the Greatest Common Stable Substring (GCSS) of amino\nacids and the Substrings Subjects to Limited Variation (SSLV) and their\nrespective locations on the GCSS. Then we define and solve the Sub-string\nMatching Problem with Limited Tolerance (SMPLT). This approach is validated on\nidentified peptides in a labelled and clustered data set from UNIPROT.\nIdentification of Baylisascaris Procyonis infection was used as an application\ninstance that achieved up to 70 times speedup compared to a software only\nsystem. This workflow can be generalised to any inexact multiple pattern\nmatching application by replacing the patterns in a clustered and distributed\nenvironment which permits a distance between member strings to account for\npermitted deviations such as substitutions, insertions and deletions."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1502.01482v2", 
    "title": "Effective RAT Selection Approach for 5G Dense Wireless Networks", 
    "arxiv-id": "1502.01482v2", 
    "author": "Antonio Iera", 
    "publish": "2015-02-05T10:00:35Z", 
    "summary": "Dense Networks (DenseNet) and Multi-Radio Access Technologies (Multi-RATs)\nare considered as key features of the emerging fifth generation (5G) wireless\nsystems. A Multi-RAT DenseNet is characterized by a very dense deployment of\nlow-power base stations (BSs) and by a multi-tier architecture consisting of\nheterogeneous radio access technologies. Such a network aims to guarantee high\ndata-rates, low latency and low energy consumption. Although the usage of a\nMulti RAT DenseNet solves problems such as coverage holes and low performance\nat the cell edge, frequent and unnecessary RAT handovers may occur with a\nconsequent high signaling load. In this work, we propose an effective RAT\nselection algorithm that efficiently manages the RAT handover procedure by\n\\emph{(i)} choosing the most suitable RAT that guarantees high system and user\nperformance, and \\emph{(ii)} reducing unnecessary handover events. In\nparticular, the decision to trigger a handover is based on a new system\nparameter named Reference Base Station Efficiency (RBSE). This parameter takes\ninto account metrics related to both the system and the user: the BS\ntransmitted power, the BS traffic load and the users' spectral efficiency. We\ncompare, by simulation, the proposed scheme with the standardized 3GPP\npolicies. Results show that the proposed RAT selection scheme significantly\nreduces the number of handovers and the end-to-end delay while maintaining high\nsystem throughput and user spectral efficiency."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1502.03455v3", 
    "title": "Dynamic Bandwidth-Efficient BCube Topologies for Virtualized Data Center   Networks", 
    "arxiv-id": "1502.03455v3", 
    "author": "Mohamed Cheriet", 
    "publish": "2015-02-11T21:12:11Z", 
    "summary": "Network virtualization enables computing networks and data center (DC)\nproviders to manage their networking resources in a flexible manner using\nsoftware running on physical computers. In this paper, we address the existing\nissues with the classic DC network topologies in virtualized environment, and\ninvestigate a set of DC network topologies with the capability of providing\ndynamic structures according to the service-level required by the active\ntraffic in a virtual DC network. In particular, we propose three main\napproaches to modify the structure of a classic BCube topology as a topology\nbenchmark, and investigate their associated structural features and maximum\nachievable interconnected bandwidth for different routing scenarios. Finally,\nwe run an extensive simulation program to check the performance of the proposed\nmodified topologies in a simulation environment which considers failure\nanalysis and also traffic congestion. Our simulation experiments, which are\nconsistent to our design goals, show the efficiency of the proposed modified\ntopologies comparing to the classic BCube in terms of bandwidth availability\nand failure resiliency."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s13369-013-0680-4", 
    "link": "http://arxiv.org/pdf/1503.02603v2", 
    "title": "An asymptotically optimal policy and state-space collapse for the   multi-class shared queue", 
    "arxiv-id": "1503.02603v2", 
    "author": "Mark Shifrin", 
    "publish": "2015-03-09T18:26:55Z", 
    "summary": "We consider a multi-class G/G/1 queue with a finite shared buffer. There is\ntask admission and server scheduling control which aims to minimize the cost\nwhich consists of holding and rejection components. We construct a policy that\nis asymptotically optimal in the heavy traffic limit. The policy stems from\nsolution to Harrison-Taksar (HT) free boundary problem and is expressed by a\nsingle free boundary point. We show that the HT problem solution translated\ninto the queuelength processes follows a specific {\\it triangular} form. This\nform implies the queuelength control policy which is different from the known\n$c\\mu$ priority rule and has a novel structure.\n  We exemplify that the probabilistic methods we exploit can be successfully\napplied to solving scheduling and admission problems in cloud computing."
},{
    "category": "cs.DS", 
    "doi": "10.1007/s13389-015-0110-5", 
    "link": "http://arxiv.org/pdf/1503.03465v8", 
    "title": "Faster 64-bit universal hashing using carry-less multiplications", 
    "arxiv-id": "1503.03465v8", 
    "author": "Owen Kaser", 
    "publish": "2015-03-11T19:47:09Z", 
    "summary": "Intel and AMD support the Carry-less Multiplication (CLMUL) instruction set\nin their x64 processors. We use CLMUL to implement an almost universal 64-bit\nhash family (CLHASH). We compare this new family with what might be the fastest\nalmost universal family on x64 processors (VHASH). We find that CLHASH is at\nleast 60% faster. We also compare CLHASH with a popular hash function designed\nfor speed (Google's CityHash). We find that CLHASH is 40% faster than CityHash\non inputs larger than 64 bytes and just as fast otherwise."
},{
    "category": "math.PR", 
    "doi": "10.1007/s13389-015-0110-5", 
    "link": "http://arxiv.org/pdf/1503.05872v3", 
    "title": "Queue Length Behavior in a Switch under the MaxWeight Algorithm", 
    "arxiv-id": "1503.05872v3", 
    "author": "R. Srikant", 
    "publish": "2015-03-19T18:34:13Z", 
    "summary": "We consider a switch operating under the MaxWeight scheduling algorithm,\nunder any traffic pattern such that all the ports are loaded. This system is\ninteresting to study since the queue lengths exhibit a multi-dimensional\nstate-space collapse in the heavy-traffic regime. We use a Lyapunov-type drift\ntechnique to characterize the heavy-traffic behavior of the expectation of the\nsum queue lengths in steady-state, under the assumption that all ports are\nsaturated and all queues receive non-zero traffic. Under these conditions, we\nshow that the heavy-traffic scaled queue length is given by\n$\\left(1-\\frac{1}{2n}\\right)||\\sigma||^2$, where $\\sigma$ is the vector of the\nstandard deviations of arrivals to each port in the heavy-traffic limit. In the\nspecial case of uniform Bernoulli arrivals, the corresponding formula is given\nby $\\left(n-\\frac{3}{2}+\\frac{1}{2n}\\right)$. The result shows that the\nheavy-traffic scaled queue length has optimal scaling with respect to $n,$ thus\nsettling one version of an open conjecture; in fact, it is shown that the\nheavy-traffic queue length is at most within a factor of two from the optimal.\nWe then consider certain asymptotic regimes where the load of the system scales\nsimultaneously with the number of ports. We show that the MaxWeight algorithm\nhas optimal queue length scaling behavior provided that the arrival rate\napproaches capacity sufficiently fast."
},{
    "category": "cs.DC", 
    "doi": "10.1007/s13389-015-0110-5", 
    "link": "http://arxiv.org/pdf/1503.06532v1", 
    "title": "The Feasibility of Using OpenCL Instead of OpenMP for Parallel CPU   Programming", 
    "arxiv-id": "1503.06532v1", 
    "author": "Kamran Karimi", 
    "publish": "2015-03-23T05:15:00Z", 
    "summary": "OpenCL, along with CUDA, is one of the main tools used to program GPGPUs.\nHowever, it allows running the same code on multi-core CPUs too, making it a\nrival for the long-established OpenMP. In this paper we compare OpenCL and\nOpenMP when developing and running compute-heavy code on a CPU. Both ease of\nprogramming and performance aspects are considered. Since, unlike a GPU, no\nmemory copy operation is involved, our comparisons measure the code generation\nquality, as well as thread management efficiency of OpenCL and OpenMP. We\nevaluate the performance of these development tools under two conditions: a\nlarge number of short-running compute-heavy parallel code executions, when more\nthread management is performed, and a small number of long-running parallel\ncode executions, when less thread management is required. The results show that\nOpenCL and OpenMP each win in one of the two conditions. We argue that while\nusing OpenMP requires less setup, OpenCL can be a viable substitute for OpenMP\nfrom a performance point of view, especially when a high number of thread\ninvocations is required. We also provide a number of potential pitfalls to\nwatch for when moving from OpenMP to OpenCL."
},{
    "category": "math.PR", 
    "doi": "10.1007/s13389-015-0110-5", 
    "link": "http://arxiv.org/pdf/1504.01191v1", 
    "title": "On the BMAP_1, BMAP_2/PH/g, c retrial queueing system", 
    "arxiv-id": "1504.01191v1", 
    "author": "Zaiming Liu", 
    "publish": "2015-04-06T02:48:16Z", 
    "summary": "In this paper, we analyze a retrial queueing system with Batch Markovian\nArrival Processes and two types of customers. The rate of individual repeated\nattempts from the orbit is modulated according to a Markov Modulated Poisson\nProcess. Using the theory of multi-dimensional asymptotically quasi-Toeplitz\nMarkov chain, we obtain the stability condition and the algorithm for\ncalculating the stationary state distribution of the system. Main performance\nmeasures are presented. Furthermore, we investigate some optimization problems.\nThe algorithm for determining the optimal number of guard servers and total\nservers is elaborated. Finally, this queueing system is applied to the cellular\nwireless network. Numerical results to illustrate the optimization problems and\nthe impact of retrial on performance measures are provided. We find that the\nperformance measures are mainly affected by the two types of customers'\narrivals and service patterns, but the retrial rate plays a less crucial role."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1504.02324v1", 
    "title": "Designing Installations for Verification of the Model of Active Queue   Management Discipline RED in the GNS3", 
    "arxiv-id": "1504.02324v1", 
    "author": "D. S. Kulyabov", 
    "publish": "2015-04-09T14:26:12Z", 
    "summary": "The problem of RED-module mathematical model results verification, based on\nGNS3 experimental stand, is discussed in this article. The experimental stand\nconsists of virtual Cisco router, traffic generator D-ITG and traffic receiver.\nThe process of construction of such stand is presented. Also, the interaction\nbetween experimental stand and a computer of investigation in order to obtain\nand analyze data from stand is revised. A stochastic model of the traffic\nmanagement RED type module was built. Verification of the model was carried out\non the NS-2 basis. However, we would like to conduct verification on a real\nrouter. As a result was the task of designing an experimental stand. It was\ndecided to verify the clean RED algorithm based on Cisco router. For the\nconstruction of the stand software package GNS3 (Graphical Network Simulator)\nwas chosen. Thus, the purpose of the study is to build on the GNS3 basis a\nvirtual stand consisting of a Cisco router, a traffic generator and a receiver.\nA traffic generator D-ITG (Distributed Internet Traffic Generator) is used as."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1504.04974v1", 
    "title": "Understanding Big Data Analytic Workloads on Modern Processors", 
    "arxiv-id": "1504.04974v1", 
    "author": "Ninghui Sun", 
    "publish": "2015-04-20T08:55:06Z", 
    "summary": "Big data analytics applications play a significant role in data centers, and\nhence it has become increasingly important to understand their behaviors in\norder to further improve the performance of data center computer systems, in\nwhich characterizing representative workloads is a key practical problem. In\nthis paper, after investigating three most impor- tant application domains in\nterms of page views and daily visitors, we chose 11 repre- sentative data\nanalytics workloads and characterized their micro-architectural behaviors by\nusing hardware performance counters, so as to understand the impacts and\nimplications of data analytics workloads on the systems equipped with modern\nsuperscalar out-of-order processors. Our study reveals that big data analytics\napplications themselves share many inherent characteristics, which place them\nin a different class from traditional workloads and scale-out services. To\nfurther understand the characteristics of big data analytics work- loads we\nperformed a correlation analysis of CPI (cycles per instruction) with other\nmicro- architecture level characteristics and an investigation of the big data\nsoftware stack impacts on application behaviors. Our correlation analysis\nshowed that even though big data ana- lytics workloads own notable pipeline\nfront end stalls, the main factors affecting the CPI performance are long\nlatency data accesses rather than the front end stalls. Our software stack\ninvestigation found that the typical big data software stack significantly\ncontributes to the front end stalls and incurs bigger working set. Finally we\ngave several recommen- dations for architects, programmers and big data system\ndesigners with the knowledge acquired from this paper."
},{
    "category": "math.OC", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1504.05103v1", 
    "title": "Optimizing Age-of-Information in a Multi-class Queueing System", 
    "arxiv-id": "1504.05103v1", 
    "author": "Eytan Modiano", 
    "publish": "2015-04-20T16:13:58Z", 
    "summary": "We consider the age-of-information in a multi-class $M/G/1$ queueing system,\nwhere each class generates packets containing status information. Age of\ninformation is a relatively new metric that measures the amount of time that\nelapsed between status updates, thus accounting for both the queueing delay and\nthe delay between packet generation. This gives rise to a tradeoff between\nfrequency of status updates, and queueing delay. In this paper, we study this\ntradeoff in a system with heterogenous users modeled as a multi-class $M/G/1$\nqueue. To this end, we derive the exact peak age-of-Information (PAoI) profile\nof the system, which measures the \"freshness\" of the status information. We\nthen seek to optimize the age of information, by formulating the problem using\nquasiconvex optimization, and obtain structural properties of the optimal\nsolution."
},{
    "category": "cs.CV", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1504.07967v1", 
    "title": "Improved repeatability measures for evaluating performance of feature   detectors", 
    "arxiv-id": "1504.07967v1", 
    "author": "Klaus D. McDonald-Maier", 
    "publish": "2015-04-29T19:01:30Z", 
    "summary": "The most frequently employed measure for performance characterisation of\nlocal feature detectors is repeatability, but it has been observed that this\ndoes not necessarily mirror actual performance. Presented are improved\nrepeatability formulations which correlate much better with the true\nperformance of feature detectors. Comparative results for several\nstate-of-the-art feature detectors are presented using these measures; it is\nfound that Hessian-based detectors are generally superior at identifying\nfeatures when images are subject to various geometric and photometric\ntransformations."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1504.08150v2", 
    "title": "Reward Processes and Performance Simulation in Supermarket Models with   Different Servers", 
    "arxiv-id": "1504.08150v2", 
    "author": "Na Li", 
    "publish": "2015-04-30T10:01:34Z", 
    "summary": "Supermarket models with different servers become a key in modeling resource\nmanagement of stochastic networks, such as, computer networks, manufacturing\nsystems and transportation networks. While these different servers always make\nanalysis of such a supermarket model more interesting, difficult and\nchallenging. This paper provides a new novel method for analyzing the\nsupermarket model with different servers through a multi-dimensional\ncontinuous-time Markov reward processes. Firstly, the utility functions are\nconstructed for expressing a routine selection mechanism that depends on queue\nlengths, on service rates, and on some probabilities of individual preference.\nThen applying the continuous-time Markov reward processes, some segmented\nstochastic integrals of the random reward function are established by means of\nan event-driven technique. Based on this, the mean of the random reward\nfunction in a finite time period is effectively computed by means of the state\njump points of the Markov reward process, and also the mean of the discounted\nrandom reward function in an infinite time period can be calculated through the\nsame event-driven technique. Finally, some simulation experiments are given to\nindicate how the expected queue length of each server depends on the main\nparameters of this supermarket model."
},{
    "category": "cs.DS", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1505.00558v2", 
    "title": "Triple State QuickSort, A replacement for the C/C++ library qsort", 
    "arxiv-id": "1505.00558v2", 
    "author": "Ammar Muqaddas", 
    "publish": "2015-05-04T08:45:38Z", 
    "summary": "An industrial grade Quicksort function along with its new algorithm is\npresented. Compared to 4 other well known implementations of Quicksort, the new\nalgorithm reduces both the number of comparisons and swaps in most cases while\nstaying close to the best of the 4 in worst cases. We trade space for\nperformance, at the price of n/2 temporary extra spaces in the worst case. Run\ntime tests reveal an overall improvement of at least 15.8% compared to the\noverall best of the other 4 functions. Furthermore, our function scores a 32.7%\nrun time improvement against Yaroslavskiy's new Dual Pivot Quicksort. Our\nfunction is pointer based, which is meant as a replacement for the C/C++\nlibrary qsort(). But we also provide an array based function of the same\nalgorithm for easy porting to different programming languages."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1505.02586v1", 
    "title": "Performance analysis of the Kahan-enhanced scalar product on current   multicore processors", 
    "arxiv-id": "1505.02586v1", 
    "author": "Gerhard Wellein", 
    "publish": "2015-05-11T12:34:54Z", 
    "summary": "We investigate the performance characteristics of a numerically enhanced\nscalar product (dot) kernel loop that uses the Kahan algorithm to compensate\nfor numerical errors, and describe efficient SIMD-vectorized implementations on\nrecent Intel processors. Using low-level instruction analysis and the\nexecution-cache-memory (ECM) performance model we pinpoint the relevant\nperformance bottlenecks for single-core and thread-parallel execution, and\npredict performance and saturation behavior. We show that the Kahan-enhanced\nscalar product comes at almost no additional cost compared to the naive\n(non-Kahan) scalar product if appropriate low-level optimizations, notably SIMD\nvectorization and unrolling, are applied. We also investigate the impact of\narchitectural changes across four generations of Intel Xeon processors."
},{
    "category": "math.PR", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1505.03774v1", 
    "title": "Dynamic Allocation Problems in Loss Network Systems with Advanced   Reservation", 
    "arxiv-id": "1505.03774v1", 
    "author": "Cong Shi", 
    "publish": "2015-05-14T16:02:12Z", 
    "summary": "We consider a class of well-known dynamic resource allocation models in loss\nnetwork systems with advanced reservation. The most important performance\nmeasure in any loss network system is to compute its blocking probability,\ni.e., the probability of an arriving customer in equilibrium finds a fully\nutilized system (thereby getting rejected by the system). In this paper, we\nderive upper bounds on the asymptotic blocking probabilities for such systems\nin high-volume regimes. There have been relatively few results on loss network\nsystems with advanced reservation due to its inherent complexity. The\ntheoretical results find applications in a wide class of revenue management\nproblems in systems with reusable resources and advanced reservation, e.g.,\nhotel room, car rental and workforce management. We propose a simple control\npolicy called the improved class selection policy (ICSP) based on solving a\ncontinuous knapsack problem, similar in spirit to the one proposed in Levi and\nRadovanovic (2010). Using our results derived for loss network systems with\nadvanced reservation, we show the ICSP performs asymptotically near-optimal in\nhigh-volume regimes."
},{
    "category": "math.PR", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1505.04996v2", 
    "title": "Critically loaded k-limited polling systems", 
    "arxiv-id": "1505.04996v2", 
    "author": "Erik Winands", 
    "publish": "2015-05-19T13:52:43Z", 
    "summary": "We consider a two-queue polling model with switch-over times and $k$-limited\nservice (serve at most $k_i$ customers during one visit period to queue $i$) in\neach queue. The major benefit of the $k$-limited service discipline is that it\n- besides bounding the cycle time - effectuates prioritization by assigning\ndifferent service limits to different queues. System performance is studied in\nthe heavy-traffic regime, in which one of the queues becomes critically loaded\nwith the other queue remaining stable. By using a singular-perturbation\ntechnique, we rigorously prove heavy-traffic limits for the joint queue-length\ndistribution. Moreover, it is observed that an interchange exists among the\nfirst two moments in service and switch-over times such that the HT limits\nremain unchanged. Not only do the rigorously proven results readily carry over\nto $N$($\\geq2$) queue polling systems, but one can also easily relax the\ndistributional assumptions. The results and insights of this note prove their\nworth in the performance analysis of Wireless Personal Area Networks (WPAN) and\nmobile networks, where different users compete for access to the shared scarce\nresources."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1505.06630v1", 
    "title": "Supercharge me: Boost Router Convergence with SDN", 
    "arxiv-id": "1505.06630v1", 
    "author": "Laurent Vanbever", 
    "publish": "2015-05-25T13:52:19Z", 
    "summary": "Software Defined Networking (SDN) is a promising approach for improving the\nperformance and manageability of future network architectures. However, little\nwork has gone into using SDN to improve the performance and manageability of\nexisting networks without requiring a major overhaul of the existing network\ninfrastructure.\n  In this paper, we show how we can dramatically improve, or supercharge, the\nperformance of existing IP routers by combining them with SDN-enabled equipment\nin a novel way. More particularly, our supercharged solution substantially\nreduces the convergence time of an IP router upon link or node failure without\ninducing any reconfiguration of the IP router itself. Our key insight is to use\nthe SDN controller to precompute backup forwarding entries and immediately\nactivate them upon failure, enabling almost immediate data-plane recovery,\nwhile letting the router converge at its typical slow pace. By boosting\nexisting equipment's performance, we not only increase their lifetime but also\nprovide new incentives for network operators to kickstart SDN deployment.\n  We implemented a fully functional \"supercharger\" and use it to boost the\nconvergence performance of a Cisco Nexus 7k router. Using a FPGA-based traffic\ngenerator, we show that our supercharged router systematically converges within\n~150ms, a 900x reduction with respect to its normal convergence time under\nsimilar conditions."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1506.03551v1", 
    "title": "On the Feasibility of Wireless Interconnects for High-throughput Data   Centers", 
    "arxiv-id": "1506.03551v1", 
    "author": "Hossein Shafiei", 
    "publish": "2015-06-11T06:02:06Z", 
    "summary": "Data Centers (DCs) are required to be scalable to large data sets so as to\naccommodate ever increasing demands of resource-limited embedded and mobile\ndevices. Thanks to the availability of recent high data rate millimeter-wave\nfrequency spectrum such as 60GHz and due to the favorable attributes of this\ntechnology, wireless DC (WDC) exhibits the potentials of being a promising\nsolution especially for small to medium scale DCs. This paper investigates the\nproblem of throughput scalability of WDCs using the established theory of the\nasymptotic throughput of wireless multi-hop networks that are primarily\nproposed for homogeneous traffic conditions. The rate-heterogeneous traffic\ndistribution of a data center however, requires the asymptotic heterogeneous\nthroughput knowledge of a wireless network in order to study the performance\nand feasibility of WDCs for practical purposes. To answer these questions this\npaper presents a lower bound for the throughput scalability of a multi-hop\nrate-heterogeneous network when traffic generation rates of all nodes are\nsimilar, except one node. We demonstrate that the throughput scalability of\nconventional multi-hopping and the spatial reuse of the above bi-rate network\nis inefficient and henceforth develop a speculative 2-partitioning scheme that\nimproves the network throughput scaling potentials. A better lower bound of the\nthroughput is then obtained. Finally, we obtain the throughput scaling of an\ni.i.d. rate-heterogeneous network and obtain its lower bound. Again we propose\na speculative 2-partitioning scheme to achieve a network with higher throughput\nin terms of improved lower bound. All of the obtained results have been\nverified using simulation experiments."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1506.04657v1", 
    "title": "A Non-stationary Service Curve Model for Performance Analysis of   Transient Phases", 
    "arxiv-id": "1506.04657v1", 
    "author": "Markus Fidler", 
    "publish": "2015-06-15T16:33:41Z", 
    "summary": "Steady-state solutions for a variety of relevant queueing systems are known\ntoday, e.g., from queueing theory, effective bandwidths, and network calculus.\nThe behavior during transient phases, on the other hand, is understood to a\nmuch lesser extent as its analysis poses significant challenges. Considering\nthe majority of short-lived flows, transient effects that have diverse causes,\nsuch as TCP slow start, sleep scheduling in wireless networks, or signalling in\ncellular networks, are, however, predominant. This paper contributes a general\nmodel of regenerative service processes to characterize the transient behavior\nof systems. The model leads to a notion of non-stationary service curves that\ncan be conveniently integrated into the framework of the stochastic network\ncalculus. We derive respective models of sleep scheduling and show the\nsignificant impact of transient phases on backlogs and delays. We also consider\nmeasurement methods that estimate the service of an unknown system from\nobservations of selected probe traffic. We find that the prevailing rate\nscanning method does not recover the service during transient phases well. This\nlimitation is fundamental as it is explained by the non-convexity of\nnon-stationary service curves. A second key difficulty is proven to be due to\nthe super-additivity of network service processes. We devise a novel two-phase\nprobing technique that first determines a minimal pattern of probe traffic.\nThis probe is used to obtain an accurate estimate of the unknown transient\nservice."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICUMT.2014.7002164", 
    "link": "http://arxiv.org/pdf/1506.05157v2", 
    "title": "A Decentralized Parallelization-in-Time Approach with Parareal", 
    "arxiv-id": "1506.05157v2", 
    "author": "Beth Wingate", 
    "publish": "2015-06-16T21:46:19Z", 
    "summary": "With steadily increasing parallelism for high-performance architectures,\nsimulations requiring a good strong scalability are prone to be limited in\nscalability with standard spatial-decomposition strategies at a certain amount\nof parallel processors. This can be a show-stopper if the simulation results\nhave to be computed with wallclock time restrictions (e.g.\\,for weather\nforecasts) or as fast as possible (e.g. for urgent computing). Here, the\ntime-dimension is the only one left for parallelization and we focus on\nParareal as one particular parallelization-in-time method.\n  We discuss a software approach for making Parareal parallelization\ntransparent for application developers, hence allowing fast prototyping for\nParareal. Further, we introduce a decentralized Parareal which results in\nautonomous simulation instances which only require communicating with the\nprevious and next simulation instances, hence with strong locality for\ncommunication. This concept is evaluated by a prototypical solver for the\nrotational shallow-water equations which we use as a representative black-box\nsolver."
},{
    "category": "cs.PF", 
    "doi": "10.1017/S0269964816000036", 
    "link": "http://arxiv.org/pdf/1506.06011v1", 
    "title": "A Markovian Analysis of IEEE 802.11 Broadcast Transmission Networks with   Buffering", 
    "arxiv-id": "1506.06011v1", 
    "author": "Paul Muhlethaler", 
    "publish": "2015-06-19T14:12:00Z", 
    "summary": "The purpose of this paper is to analyze the so-called back-off technique of\nthe IEEE 802.11 protocol in broadcast mode with waiting queues. In contrast to\nexisting models, packets arriving when a station (or node) is in back-off state\nare not discarded, but are stored in a buffer of infinite capacity. As in\nprevious studies, the key point of our analysis hinges on the assumption that\nthe time on the channel is viewed as a random succession of transmission slots\n(whose duration corresponds to the length of a packet) and mini-slots during\nwhich the back-o? of the station is decremented. These events occur\nindependently, with given probabilities. The state of a node is represented by\na two-dimensional Markov chain in discrete-time, formed by the back-off counter\nand the number of packets at the station. Two models are proposed both of which\nare shown to cope reasonably well with the physical principles of the protocol.\nThe stabillity (ergodicity) conditions are obtained and interpreted in terms of\nmaximum throughput. Several approximations related to these models are also\ndiscussed."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1506.07742v1", 
    "title": "Performance Characterization of In-Memory Data Analytics on a Modern   Cloud Server", 
    "arxiv-id": "1506.07742v1", 
    "author": "Eduard Ayguade", 
    "publish": "2015-06-25T13:23:54Z", 
    "summary": "In last decade, data analytics have rapidly progressed from traditional\ndisk-based processing to modern in-memory processing. However, little effort\nhas been devoted at enhancing performance at micro-architecture level. This\npaper characterizes the performance of in-memory data analytics using Apache\nSpark framework. We use a single node NUMA machine and identify the bottlenecks\nhampering the scalability of workloads. We also quantify the inefficiencies at\nmicro-architecture level for various data analysis workloads. Through empirical\nevaluation, we show that spark workloads do not scale linearly beyond twelve\nthreads, due to work time inflation and thread level load imbalance. Further,\nat the micro-architecture level, we observe memory bound latency to be the\nmajor cause of work time inflation."
},{
    "category": "cs.PF", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1507.04631v1", 
    "title": "Window Flow Control Systems with Random Service", 
    "arxiv-id": "1507.04631v1", 
    "author": "Almut Burchard", 
    "publish": "2015-07-16T16:06:18Z", 
    "summary": "We present an extension of the window flow control analysis by R. Agrawal\net.al. (Reference [1]), C.-S. Chang (Reference [6]), and C.-S. Chang et. al.\n(Reference [8]) to a system with random service time and fixed feedback delay.\nWe consider two network service models. In the first model, the network service\nprocess itself has no time correlations. The second model addresses a two-state\nMarkov-modulated service."
},{
    "category": "cs.SE", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1507.08187v2", 
    "title": "Dependability Analysis of Control Systems using SystemC and Statistical   Model Checking", 
    "arxiv-id": "1507.08187v2", 
    "author": "Axel Legay", 
    "publish": "2015-07-29T15:36:21Z", 
    "summary": "Stochastic Petri nets are commonly used for modeling distributed systems in\norder to study their performance and dependability. This paper proposes a\nrealization of stochastic Petri nets in SystemC for modeling large embedded\ncontrol systems. Then statistical model checking is used to analyze the\ndependability of the constructed model. Our verification framework allows users\nto express a wide range of useful properties to be verified which is\nillustrated through a case study."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1508.04537v1", 
    "title": "Personalized QoS Prediction of Cloud Services via Learning   Neighborhood-based Model", 
    "arxiv-id": "1508.04537v1", 
    "author": "Yijian Pei", 
    "publish": "2015-08-19T06:32:54Z", 
    "summary": "The explosion of cloud services on the Internet brings new challenges in\nservice discovery and selection. Particularly, the demand for efficient\nquality-of-service (QoS) evaluation is becoming urgently strong. To address\nthis issue, this paper proposes neighborhood-based approach for QoS prediction\nof cloud services by taking advantages of collaborative intelligence. Different\nfrom heuristic collaborative filtering and matrix factorization, we define a\nformal neighborhood-based prediction framework which allows an efficient global\noptimization scheme, and then exploit different baseline estimate component to\nimprove predictive performance. To validate the proposed methods, a large-scale\nQoS-specific dataset which consists of invocation records from 339 service\nusers on 5,825 web services on a world-scale distributed network is used.\nExperimental results demonstrate that the learned neighborhood-based models can\novercome existing difficulties of heuristic collaborative filtering methods and\nachieve superior performance than state-of-the-art prediction methods."
},{
    "category": "cs.SE", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1508.04752v1", 
    "title": "Performance-oriented DevOps: A Research Agenda", 
    "arxiv-id": "1508.04752v1", 
    "author": "Alexander Wert", 
    "publish": "2015-08-18T12:39:05Z", 
    "summary": "DevOps is a trend towards a tighter integration between development (Dev) and\noperations (Ops) teams. The need for such an integration is driven by the\nrequirement to continuously adapt enterprise applications (EAs) to changes in\nthe business environment. As of today, DevOps concepts have been primarily\nintroduced to ensure a constant flow of features and bug fixes into new\nreleases from a functional perspective. In order to integrate a non-functional\nperspective into these DevOps concepts this report focuses on tools,\nactivities, and processes to ensure one of the most important quality\nattributes of a software system, namely performance.\n  Performance describes system properties concerning its timeliness and use of\nresources. Common metrics are response time, throughput, and resource\nutilization. Performance goals for EAs are typically defined by setting upper\nand/or lower bounds for these metrics and specific business transactions. In\norder to ensure that such performance goals can be met, several activities are\nrequired during development and operation of these systems as well as during\nthe transition from Dev to Ops. Activities during development are typically\nsummarized by the term Software Performance Engineering (SPE), whereas\nactivities during operations are called Application Performance Management\n(APM). SPE and APM were historically tackled independently from each other, but\nthe newly emerging DevOps concepts require and enable a tighter integration\nbetween both activity streams. This report presents existing solutions to\nsupport this integration as well as open research challenges in this area."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1508.06830v1", 
    "title": "Coarse-Grain Performance Estimator for Heterogeneous Parallel Computing   Architectures like Zynq All-Programmable SoC", 
    "arxiv-id": "1508.06830v1", 
    "author": "Kees Vissers", 
    "publish": "2015-08-27T12:35:00Z", 
    "summary": "Heterogeneous computing is emerging as a mandatory requirement for\npower-efficient system design. With this aim, modern heterogeneous platforms\nlike Zynq All-Programmable SoC, that integrates ARM-based SMP and programmable\nlogic, have been designed. However, those platforms introduce large design\ncycles consisting on hardware/software partitioning, decisions on granularity\nand number of hardware accelerators, hardware/software integration, bitstream\ngeneration, etc.\n  This paper presents a performance parallel heterogeneous estimation for\nsystems where hardware/software co-design and run-time heterogeneous task\nscheduling are key. The results show that the programmer can quickly decide,\nbased only on her/his OmpSs (OpenMP + extensions) application, which is the\nco-design that achieves nearly optimal heterogeneous parallel performance,\nbased on the methodology presented and considering only synthesis estimation\nresults. The methodology presented reduces the programmer co-design decision\nfrom hours to minutes and shows high potential on hardware/software\nheterogeneous parallel performance estimation on the Zynq All-Programmable SoC."
},{
    "category": "cs.AR", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1508.07126v1", 
    "title": "Performance monitoring for multicore embedded computing systems on FPGAs", 
    "arxiv-id": "1508.07126v1", 
    "author": "Alexandra Fedorova", 
    "publish": "2015-08-28T08:41:38Z", 
    "summary": "When designing modern embedded computing systems, most software programmers\nchoose to use multicore processors, possibly in combination with\ngeneral-purpose graphics processing units (GPGPUs) and/or hardware\naccelerators. They also often use an embedded Linux O/S and run\nmulti-application workloads that may even be multi-threaded. Modern FPGAs are\nlarge enough to combine multicore hard/soft processors with multiple hardware\naccelerators as custom compute units, enabling entire embedded compute systems\nto be implemented on a single FPGA. Furthermore, the large FPGA vendors also\nsupport embedded Linux kernels for both their soft and embedded processors.\nWhen combined with high-level synthesis to generate hardware accelerators using\na C-to-gates flows, the necessary primitives for a framework that can enable\nsoftware designers to use FPGAs as their custom compute platform now exist.\nHowever, in order to ensure that computing resources are integrated and shared\neffectively, software developers need to be able to monitor and debug the\nruntime performance of the applications in their workload. This paper describes\nABACUS, a performance-monitoring framework that can be used to debug the\nexecution behaviours and interactions of multi-application workloads on\nmulticore systems. We also discuss how this framework is extensible for use\nwith hardware accelerators in heterogeneous systems."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1508.07740v1", 
    "title": "Parameter Sensitivity Analysis of the Energy/Frequency Convexity Rule   for Nanometer-scale Application Processors", 
    "arxiv-id": "1508.07740v1", 
    "author": "Pierre Jouvelot", 
    "publish": "2015-08-31T09:41:46Z", 
    "summary": "Both theoretical and experimental evidence are presented in this work in\norder to validate the existence of an Energy/Frequency Convexity Rule, which\nrelates energy consumption and microprocessor frequency for nanometer-scale\nmicroprocessors. Data gathered during several month-long experimental\nacquisition campaigns, supported by several independent publications, suggest\nthat energy consumed is indeed depending on the microprocessor's clock\nfrequency, and, more interestingly, the curve exhibits a clear minimum over the\nprocessor's frequency range. An analytical model for this behavior is presented\nand motivated, which fits well with the experimental data. A parameter\nsensitivity analysis shows how parameters affect the energy minimum in the\nclock frequency space. The conditions are discussed under which this convexity\nrule can be exploited, and when other methods are more effective, with the aim\nof improving the computer system's energy management efficiency. We show that\nthe power requirements of the computer system, besides the microprocessor, and\nthe overhead affect the location of the energy minimum the most. The\nsensitivity analysis of the Energy/Frequency Convexity Rule puts forward a\nnumber of simple guidelines especially for by low-power systems, such as\nbattery-powered and embedded systems, and less likely by high-performance\ncomputer systems."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.02640v7", 
    "title": "On the energy efficiency of client-centric data consistency management   under random read/write access to Big Data with Apache HBase", 
    "arxiv-id": "1509.02640v7", 
    "author": "\u00c1lvaro Garc\u00eda-Recuero", 
    "publish": "2015-09-09T05:44:42Z", 
    "summary": "The total estimated energy bill for data centers in 2010 was \\$11.5 billion,\nand experts estimate that the energy cost of a typical data center doubles\nevery five years. On the other hand, computational developments have started to\nlag behind storage advancements, therein becoming a future bottleneck for the\nongoing data growth which already approaches Exascale levels. We investigate\nthe relationship among data throughput and energy footprint on a large storage\ncluster, with the goal of formalizing it as a metric that reflects the trading\namong consistency and energy. Employing a client-centric consistency approach,\nand while honouring ACID properties of the chosen columnar store for the case\nstudy (Apache HBase), we present the factors involved in the energy consumption\nof the system as well as lessons learned to underpin further design of\nenergy-efficient cluster scale storage systems."
},{
    "category": "cs.DB", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.02822v1", 
    "title": "Exposing Provenance Metadata Using Different RDF Models", 
    "arxiv-id": "1509.02822v1", 
    "author": "Michel Dumontier", 
    "publish": "2015-09-09T15:59:03Z", 
    "summary": "A standard model for exposing structured provenance metadata of scientific\nassertions on the Semantic Web would increase interoperability,\ndiscoverability, reliability, as well as reproducibility for scientific\ndiscourse and evidence-based knowledge discovery. Several Resource Description\nFramework (RDF) models have been proposed to track provenance. However,\nprovenance metadata may not only be verbose, but also significantly redundant.\nTherefore, an appropriate RDF provenance model should be efficient for\npublishing, querying, and reasoning over Linked Data. In the present work, we\nhave collected millions of pairwise relations between chemicals, genes, and\ndiseases from multiple data sources, and demonstrated the extent of redundancy\nof provenance information in the life science domain. We also evaluated the\nsuitability of several RDF provenance models for this crowdsourced data set,\nincluding the N-ary model, the Singleton Property model, and the\nNanopublication model. We examined query performance against three commonly\nused large RDF stores, including Virtuoso, Stardog, and Blazegraph. Our\nexperiments demonstrate that query performance depends on both RDF store as\nwell as the RDF provenance model."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03069v1", 
    "title": "Federating OMNeT++ Simulations with Testbed Environments", 
    "arxiv-id": "1509.03069v1", 
    "author": "Carmelita G\u00f6rg", 
    "publish": "2015-09-10T09:37:03Z", 
    "summary": "We are in the process of developing a system architecture for opportunistic\nand information centric communications. This architecture (called Keetchi),\nmeant for the Internet of Things (IoT) is focussed on enabling applications to\nperform distributed and decentralised communications among smart devices. To\nrealise and evaluate this architecture, we follow a 3-step approach. Our first\napproach of evaluation is the development of a testbed with smart devices\n(mainly smart phones and tablets) deployed with this architecture including the\napplications. The second step is where the architecture is evaluated in large\nscale scenarios with the OMNeT++ simulation environment. The third step is\nwhere the OMNeT++ simulation environment is fed with traces of data collected\nfrom experiments done using the testbed. In realising these environments, we\ndevelop the functionality of this architecture as a common code base that is\nable to operate in the OMNeT++ environment as well as in the smart devices of\nthe testbed (e.g., Android, iOS, Contiki, etc.). This paper presents the\ndetails of the \"Write once, compile anywhere\" (WOCA) code base architecture of\nKeetchi."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03101v1", 
    "title": "uIP Support for the Network Simulation Cradle", 
    "arxiv-id": "1509.03101v1", 
    "author": "Roman Kremmer", 
    "publish": "2015-09-10T11:21:23Z", 
    "summary": "This paper introduces the ongoing integration of Contiki's uIP stack into the\nOMNeT++ port of the Network Simulation Cradle (NSC). The NSC utilizes code from\nreal world stack implementations and allows for an accurate simulation and\ncomparison of different TCP/IP stacks. uIP(v6) provides resource-constrained\ndevices with an RFC-compliant TCP/IP stack and promotes the use of IPv6 in the\nvastly growing field of Internet of Things scenarios. This work-in-progress\nreport discusses our motivation to integrate uIP into the NSC, our chosen\napproach and possible use cases for the simulation of uIP in OMNeT++."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03103v1", 
    "title": "Dynamic Index NAT as a Mobility Solution in OMNeT++", 
    "arxiv-id": "1509.03103v1", 
    "author": "Jochen Seitz", 
    "publish": "2015-09-10T11:24:21Z", 
    "summary": "Mobility in wireless networks causes a major issue from the IP-addressing\nperspective. When a Mobile Node (MN) moves to another subnet, it will probably\nget assigned a new IP address. This causes a routing problem since the MN will\nnot be reachable with its previous IP address known to the other communication\nparty. Real time applications might suffer from connection drops, which is\nrecognized as inconvenience in the currently used service, unless some solution\nis provided. An approach to maintain session continuity while traversing\nheterogeneous networks of different subnet addresses is proposed. Here, a\ncross-layer module is implemented in OMNeT++ with NAT functionality to provide\na seamless handover. A proof of concept is also shown with analogy to the\nMobile IPv6 protocol provided in INET."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03111v1", 
    "title": "Integration of RTMFP in the OMNeT++ Simulation Environment", 
    "arxiv-id": "1509.03111v1", 
    "author": "Erwin P. Rathgeb", 
    "publish": "2015-09-10T11:46:12Z", 
    "summary": "This paper introduces the new Real-Time Media Flow Protocol (RTMFP)\nsimulation model for the INET framework for the OMNeT++ simulation environment.\nRTMFP is a message orientated protocol with a focus on real time peer-to-peer\ncommunication. After Adobe Inc. released the specifications, we were able to\nimplement the protocol in INET and compare its performance to the similar\nStream Control Transmission Protocol (SCTP) with a focus on congestion control\nand flow control mechanisms."
},{
    "category": "cs.DC", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03118v3", 
    "title": "Execution-Cache-Memory Performance Model: Introduction and Validation", 
    "arxiv-id": "1509.03118v3", 
    "author": "Dietmar Fey", 
    "publish": "2015-09-10T12:02:51Z", 
    "summary": "This report serves two purposes: To introduce and validate the\nExecution-Cache-Memory (ECM) performance model and to provide a thorough\nanalysis of current Intel processor architectures with a special emphasis on\nIntel Xeon Haswell-EP. The ECM model is a simple analytical performance model\nwhich focuses on basic architectural resources. The architectural analysis and\nmodel predictions are showcased and validated using a set of elementary\nmicrobenchmarks."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03127v1", 
    "title": "Integration of the Packetdrill Testing Tool in INET", 
    "arxiv-id": "1509.03127v1", 
    "author": "Michael T\u00fcxen", 
    "publish": "2015-09-10T12:45:46Z", 
    "summary": "Google released in 2013 a script-based tool called packetdrill, which allows\nto test transport protocols like UDP and TCP on Linux and BSD-based operating\nsystems. The scripts defining a test-case allow to inject packets to the\nimplementation under test, perform operations at the API controlling the\ntransport protocol and verify the sending of packets, all at specified times.\nThis paper describes a port of packetdrill to the INET framework for the\nOMNeT++ simulation environment providing a simple and powerful method of\ntesting the transport protocols implemented in INET."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03140v1", 
    "title": "Realistic, Extensible DNS and mDNS Models for INET/OMNeT++", 
    "arxiv-id": "1509.03140v1", 
    "author": "Marcel Waldvogel", 
    "publish": "2015-09-10T13:29:09Z", 
    "summary": "The domain name system (DNS) is one of the core services in today's network\nstructures. In local and ad-hoc networks DNS is often enhanced or replaced by\nmDNS. As of yet, no simulation models for DNS and mDNS have been developed for\nINET/OMNeT++. We introduce DNS and mDNS simulation models for OMNeT++, which\nallow researchers to easily prototype and evaluate extensions for these\nprotocols. In addition, we present models for our own experimental extensions,\nnamely Stateless DNS and Privacy-Enhanced mDNS, that are based on the\naforementioned models. Using our models we were able to further improve the\nefficiency of our protocol extensions."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03169v1", 
    "title": "ptp++: A Precision Time Protocol Simulation Model for OMNeT++ / INET", 
    "arxiv-id": "1509.03169v1", 
    "author": "David Tipper", 
    "publish": "2015-09-10T14:21:35Z", 
    "summary": "Precise time synchronization is expected to play a key role in emerging\ndistributed and real-time applications such as the smart grid and Internet of\nThings (IoT) based applications. The Precision Time Protocol (PTP) is currently\nviewed as one of the main synchronization solutions over a packet-switched\nnetwork, which supports microsecond synchronization accuracy. In this paper, we\npresent a PTP simulation model for OMNeT++ INET, which allows to investigate\nthe synchronization accuracy under different network configurations and\nconditions. To show some illustrative simulation results using the developed\nmodule, we investigate on the network load fluctuations and their impacts on\nthe PTP performance by considering a network with class-based\nquality-of-service (QoS) support. The simulation results show that the network\nload significantly affects the network delay symmetry, and investigate a new\ntechnique called class probing to improve the PTP accuracy and mitigate the\nload fluctuation effects."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03176v1", 
    "title": "High Frequency Radio Network Simulation Using OMNeT++", 
    "arxiv-id": "1509.03176v1", 
    "author": "Eric Koski", 
    "publish": "2015-09-10T14:38:46Z", 
    "summary": "Harris Corporation has an interest in making HF radios a suitable medium for\nwireless information networks using standard Internet protocols. Although HF\nradio links have many unique characteristics, HF wireless subnets can be\nsubject to many of the same traffic flow characteristics and topologies as\nexisting line-of-sight (LOS) radio networks, giving rise to similar issues\n(media access, connectivity, routing) which lend themselves to investigation\nthrough simulation. Accordingly, we have undertaken to develop efficient,\nhigh-fidelity simulations of various aspects of HF radio communications and\nnetworking using the OMNeT++ framework. Essential aspects of these simulations\ninclude HF channel models simulating relevant channel attributes such as Signal\nto Noise Ratio, multipath, and Doppler spread; a calibrated physical layer\nmodel reproducing the error statistics (including burst error distributions) of\nthe MIL-STD-188-110B/C HF modem waveforms, both narrowband (3 kHz) and wideband\n(up to 24 kHz) on the simulated HF channels; a model of the NATO STANAG 5066\ndata link protocol; and integration of these models with the OMNeT++ network\nsimulation framework and its INET library of Internet protocol models. This\nsimulation is used to evaluate the impacts of different STANAG 5066\nconfiguration settings on TCP network performance, and to evaluate strategies\nfor optimizing throughput over HF links using TCP Performance Enhancing Proxy\n(PEP) techniques."
},{
    "category": "cs.PF", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03284v2", 
    "title": "Proceedings of the 2nd OMNeT++ Community Summit, IBM Research - Zurich,   Switzerland, September 3-4, 2015", 
    "arxiv-id": "1509.03284v2", 
    "author": "Michael Kirsche", 
    "publish": "2015-09-03T22:09:10Z", 
    "summary": "This is the Proceedings of the 2nd OMNeT++ Community Summit, which was held\nat IBM Research - Zurich, Switzerland on September 3-4, 2015."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03548v1", 
    "title": "MiXiM, PAWiS, and STEAM-Sim Integration - Combining Channel Models,   Energy Awareness, and Real-life Application Code", 
    "arxiv-id": "1509.03548v1", 
    "author": "Andreas Springer", 
    "publish": "2015-09-11T15:17:34Z", 
    "summary": "After a decade of research in the field of wireless sensor networks (WSNs)\nthere are still open issues. WSNs impose several severe requirements regarding\nenergy consumption, processing capabilities, mobility, and robustness of\nwireless transmissions. Simulation has shown to be the most cost-efficient\napproach for evaluation of WSNs, thus a number of simulators are available.\nUnfortunately, these simulation environments typically consider WSNs from a\nspecial point of view. In this work we present the integration of three such\nspecialized frameworks, namely MiXiM, PAWiS, and STEAM-Sim. This integration\ncombines the strengths of the single frameworks such as realistic channel\nmodels, mobility patterns, accurate energy models, and inclusion of real-life\napplication code. The result is a new simulation environment which enables a\nmore general consideration of WSNs. We implemented and verified our proposed\nconcept by means of static and mobile scenarios. As the presented results show,\nthe combined framework gives the same results regarding the functionality and\nenergy consumption as our \"golden model\". Therefore the system integration was\nsuccessful and the framework is ready to be used by the community."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03550v1", 
    "title": "Skip This Paper - RINASim: Your Recursive InterNetwork Architecture   Simulator", 
    "arxiv-id": "1509.03550v1", 
    "author": "Ondrej Rysavy", 
    "publish": "2015-09-11T15:22:41Z", 
    "summary": "Recursive InterNetwork Architecture is a clean-slate approach to how to deal\nwith the current issues of the Internet based on the traditional TCP/IP\nnetworking stack. Instead of using a fixed number of layers with dedicated\nfunctionality, RINA proposes a single generic layer with programmable\nfunctionality that may be recursively stacked. We introduce a brand new\nframework for modeling and simulation of RINA that is intended for OMNeT++."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03553v1", 
    "title": "Implementation of a Wake-up Radio Cross-Layer Protocol in OMNeT++ /   MiXiM", 
    "arxiv-id": "1509.03553v1", 
    "author": "Nour Murad", 
    "publish": "2015-09-11T15:26:37Z", 
    "summary": "This paper presents the DoRa protocol, which is a new cross-layer protocol\nfor handling the double radio of nodes in wake-up radio scenario. The\nimplementation details in OMNET++/MiXiM are also given, with a focus on the\nimplemented MAC layers. The main goal of the DoRa protocol is to reduce energy\nconsumption in wireless sensor network, by taking full advantage of the passive\nwake-up scheme. The performance of the DoRa protocol is then evaluated and\nresults are compared with B-MAC and IEEE 802.15.4 protocols."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03558v1", 
    "title": "Looking into Hardware-in-the-Loop Coupling of OMNeT++ and RoSeNet", 
    "arxiv-id": "1509.03558v1", 
    "author": "Michael Kirsche", 
    "publish": "2015-09-11T15:32:26Z", 
    "summary": "Network emulation using real sensor node hardware is used to increase the\naccuracy of pure network simulations. Coupling OMNeT++ with network emulation\nplatforms and tools introduces new application possibilities for both sides.\nThis work-in-progress report covers our experiences of using OMNeT++ as a test\ndriver for RoSeNet, a network emulation and test platform for low-power\nwireless technologies like IEEE 802.15.4. OMNeT++ and RoSeNet were\ninterconnected to enable a co-simulation of real sensor networks with a MAC\nlayer simulation model. Experiences and insights on this Hardware-in-the-Loop\n(HIL) simulation together with ideas to extend OMNeT++ and to provide a generic\ninterconnection API complete the report."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03559v1", 
    "title": "Implementation of PFC and RCM for RoCEv2 Simulation in OMNeT++", 
    "arxiv-id": "1509.03559v1", 
    "author": "Benjamin Jamroz", 
    "publish": "2015-09-11T15:36:00Z", 
    "summary": "As traffic patterns and network topologies become more and more complicated\nin current enterprise data centers and TOP500 supercomputers, the probability\nof network congestion increases. If no countermeasures are taken, network\ncongestion causes long communication delays and degrades network performance. A\ncongestion control mechanism is often provided to reduce the consequences of\ncongestion. However, it is usually difficult to configure and activate a\ncongestion control mechanism in production clusters and supercomputers due to\nconcerns that it may negatively impact jobs if the mechanism is not\nappropriately configured. Therefore, simulations for these situations are\nnecessary to identify congestion points and sources, and more importantly, to\ndetermine optimal settings that can be utilized to reduce congestion in those\ncomplicated networks. In this paper, we use OMNeT++ to implement the IEEE\n802.1Qbb Priority-based Flow Control (PFC) and RoCEv2 Congestion Management\n(RCM) in order to simulate clusters with RoCEv2 interconnects."
},{
    "category": "cs.PF", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.03573v1", 
    "title": "Invited Abstract: A Simulation Package for Energy Consumption of Content   Delivery Networks (CDNs)", 
    "arxiv-id": "1509.03573v1", 
    "author": "Saeed Bastani", 
    "publish": "2015-09-11T16:03:55Z", 
    "summary": "Content Delivery Networks (CDNs) are becoming an integral part of the future\ngeneration Internet. Traditionally, these networks have been designed with the\ngoals of traffic offload and the improvement of users' quality of experience\n(QoE), but the energy consumption is also becoming an indispensable design\nfactor for CDNs to be a sustainable solution. To study and improve the CDN\narchitectures using this new design metric, we are planning to develop a\ngeneric and flexible simulation package in OMNet++. This package is aimed to\nrender a holistic view about the CDN energy consumption behaviour by\nincorporating the state-of-the-art energy consumption models proposed for the\nindividual elements of CDNs (e.g. servers, routers, wired and wireless links,\nwireless devices, etc.) and for the various Internet contents (web pages,\nfiles, streaming video, etc.)."
},{
    "category": "cs.NI", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1509.06333v1", 
    "title": "Network Capability in Localizing Node Failures via End-to-end Path   Measurements", 
    "arxiv-id": "1509.06333v1", 
    "author": "Kin K. Leung", 
    "publish": "2015-09-21T18:44:53Z", 
    "summary": "We investigate the capability of localizing node failures in communication\nnetworks from binary states (normal/failed) of end-to-end paths. Given a set of\nnodes of interest, uniquely localizing failures within this set requires that\ndifferent observable path states associate with different node failure events.\nHowever, this condition is difficult to test on large networks due to the need\nto enumerate all possible node failures. Our first contribution is a set of\nsufficient/necessary conditions for identifying a bounded number of failures\nwithin an arbitrary node set that can be tested in polynomial time. In addition\nto network topology and locations of monitors, our conditions also incorporate\nconstraints imposed by the probing mechanism used. We consider three probing\nmechanisms that differ according to whether measurement paths are (i)\narbitrarily controllable, (ii) controllable but cycle-free, or (iii)\nuncontrollable (determined by the default routing protocol). Our second\ncontribution is to quantify the capability of failure localization through (1)\nthe maximum number of failures (anywhere in the network) such that failures\nwithin a given node set can be uniquely localized, and (2) the largest node set\nwithin which failures can be uniquely localized under a given bound on the\ntotal number of failures. Both measures in (1-2) can be converted into\nfunctions of a per-node property, which can be computed efficiently based on\nthe above sufficient/necessary conditions. We demonstrate how measures (1-2)\nproposed for quantifying failure localization capability can be used to\nevaluate the impact of various parameters, including topology, number of\nmonitors, and probing mechanisms."
},{
    "category": "stat.CO", 
    "doi": "10.1109/BDCloud.2015.37", 
    "link": "http://arxiv.org/pdf/1510.00041v2", 
    "title": "iotools: High-Performance I/O Tools for R", 
    "arxiv-id": "1510.00041v2", 
    "author": "Simon Urbanek", 
    "publish": "2015-09-30T21:31:42Z", 
    "summary": "The iotools package provides a set of tools for Input/Output (I/O) intensive\ndatasets processing in R (R Core Team, 2014). Efficent parsing methods are\nincluded which minimize copying and avoid the use of intermediate string\nrepresentations whenever possible. Functions for applying chunk-wise operations\nallow for computing on streaming input as well as arbitrarily large files. We\npresent a set of example use cases for iotools, as well as extensive benchmarks\ncomparing comparable functions provided in both core-R as well as other\ncontributed packages."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1510.02238v1", 
    "title": "On the Maximal Shortest Path in a Connected Component in V2V", 
    "arxiv-id": "1510.02238v1", 
    "author": "Hossam Afifi", 
    "publish": "2015-10-08T08:48:28Z", 
    "summary": "In this work, a VANET (Vehicular Ad-hoc NETwork) is considered to operate on\na simple lane, without infrastructure. The arrivals of vehicles are assumed to\nbe general with any traffic and speed assumptions. The vehicles communicate\nthrough the shortest path. In this paper, we study the probability distribution\nof the number of hops on the maximal shortest path in a connected component of\nvehicles. The general formulation is given for any assumption of road traffic.\nThen, it is applied to calculate the z-transform of this distribution for\nmedium and dense networks in the Poisson case. Our model is validated with the\nMadrid road traces of the Universitat Polit\\`ecnica de Catalunya. These results\nmay be useful for example when evaluating diffusion protocols through the\nshortest path in a VANET, where not only the mean but also the other moments\nare needed to derive accurate results."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1510.04488v3", 
    "title": "Performance Analysis of a Heterogeneous Traffic Scheduler using Large   Deviation Principle", 
    "arxiv-id": "1510.04488v3", 
    "author": "Victor C. M. Leung", 
    "publish": "2015-10-15T12:08:10Z", 
    "summary": "In this paper, we study the stability of light traffic achieved by a\nscheduling algorithm which is suitable for heterogeneous traffic networks.\nSince analyzing a scheduling algorithm is intractable using the conventional\nmathematical tool, our goal is to minimize the largest queue-overflow\nprobability achieved by the algorithm. In the large deviation setting, this\nproblem is equivalent to maximizing the asymptotic decay rate of the largest\nqueue-overflow probability. We first derive an upper bound on the decay rate of\nthe queue overflow probability as the queue overflow threshold approaches\ninfinity. Then, we study several structural properties of the minimum-cost-path\nto overflow of the queue with the largest length, which is basically equivalent\nto the decay rate of the largest queue-overflow probability. Given these\nproperties, we prove that the queue with the largest length follows a sample\npath with linear increment. For certain parameter value, the scheduling\nalgorithm is asymptotically optimal in reducing the largest queue length.\nThrough numerical results, we have shown the large deviation properties of the\nqueue length typically used in practice while varying one parameter of the\nalgorithm."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1510.04995v1", 
    "title": "Multi-dimensional intra-tile parallelization for memory-starved stencil   computations", 
    "arxiv-id": "1510.04995v1", 
    "author": "David Keyes", 
    "publish": "2015-10-16T19:43:00Z", 
    "summary": "Optimizing the performance of stencil algorithms has been the subject of\nintense research over the last two decades. Since many stencil schemes have low\narithmetic intensity, most optimizations focus on increasing the temporal data\naccess locality, thus reducing the data traffic through the main memory\ninterface with the ultimate goal of decoupling from this bottleneck. There are,\nhowever, only few approaches that explicitly leverage the shared cache feature\nof modern multicore chips. If every thread works on its private, separate cache\nblock, the available cache space can become too small, and sufficient temporal\nlocality may not be achieved.\n  We propose a flexible multi-dimensional intra-tile parallelization method for\nstencil algorithms on multicore CPUs with a shared outer-level cache. This\nmethod leads to a significant reduction in the required cache space without\nadverse effects from hardware prefetching or TLB shortage. Our \\emph{Girih}\nframework includes an auto-tuner to select optimal parameter configurations on\nthe target hardware. We conduct performance experiments on two contemporary\nIntel processors and compare with the state-of-the-art stencil frameworks PLUTO\nand Pochoir, using four corner-case stencil schemes and a wide range of problem\nsizes. \\emph{Girih} shows substantial performance advantages and best\narithmetic intensity at almost all problem sizes, especially on low-intensity\nstencils with variable coefficients. We study in detail the performance\nbehavior at varying grid size using phenomenological performance modeling. Our\nanalysis of energy consumption reveals that our method can save energy by\nreduced DRAM bandwidth usage even at marginal performance gain. It is thus well\nsuited for future architectures that will be strongly challenged by the cost of\ndata movement, be it in terms of performance or energy consumption."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1510.07986v3", 
    "title": "A Novel Offloading Partitioning Algorithm in Mobile Cloud Computing", 
    "arxiv-id": "1510.07986v3", 
    "author": "Katinka Wolter", 
    "publish": "2015-10-27T17:01:32Z", 
    "summary": "This paper has been withdrawn by the author"
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1510.09185v2", 
    "title": "Analysis of the Energy-Performance Tradeoff for Delayed Mobile   Offloading", 
    "arxiv-id": "1510.09185v2", 
    "author": "Katinka Wolter", 
    "publish": "2015-10-30T18:32:52Z", 
    "summary": "This paper has been withdrawn by the author"
},{
    "category": "cs.NE", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.01088v1", 
    "title": "There is no fast lunch: an examination of the running speed of   evolutionary algorithms in several languages", 
    "arxiv-id": "1511.01088v1", 
    "author": "Israel Blancas", 
    "publish": "2015-11-03T20:34:24Z", 
    "summary": "It is quite usual when an evolutionary algorithm tool or library uses a\nlanguage other than C, C++, Java or Matlab that a reviewer or the audience\nquestions its usefulness based on the speed of those other languages,\npurportedly slower than the aforementioned ones. Despite speed being not\neverything needed to design a useful evolutionary algorithm application, in\nthis paper we will measure the speed for several very basic evolutionary\nalgorithm operations in several languages which use different virtual machines\nand approaches, and prove that, in fact, there is no big difference in speed\nbetween interpreted and compiled languages, and that in some cases, interpreted\nlanguages such as JavaScript or Python can be faster than compiled languages\nsuch as Scala, making them worthy of use for evolutionary algorithm\nexperimentation."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.01232v1", 
    "title": "Power Consumption of Virtualization Technologies: an Empirical   Investigation", 
    "arxiv-id": "1511.01232v1", 
    "author": "Roberto Morabito", 
    "publish": "2015-11-04T07:49:47Z", 
    "summary": "Virtualization is growing rapidly as a result of the increasing number of\nalternative solutions in this area, and of the wide range of application field.\nUntil now, hypervisor-based virtualization has been the de facto solution to\nperform server virtualization. Recently, container-based virtualization - an\nalternative to hypervisors - has gained more attention because of lightweight\ncharacteristics, attracting cloud providers that have already made use of it to\ndeliver their services. However, a gap in the existing research on containers\nexists in the area of power consumption. This paper presents the results of a\nperformance comparison in terms of power consumption of four different\nvirtualization technologies: KVM and Xen, which are based on hypervisor\nvirtualization, Docker and LXC which are based on container virtualization. The\naim of this empirical investigation, carried out by means of a testbed, is to\nunderstand how these technologies react to particular workloads. Our initial\nresults show how, despite of the number of virtual entities running, both kinds\nof virtualization alternatives behave similarly in idle state and in CPU/Memory\nstress test. Contrarily, the results on network performance show differences\nbetween the two technologies."
},{
    "category": "cs.MS", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.03742v2", 
    "title": "GEMMbench: a framework for reproducible and collaborative benchmarking   of matrix multiplication", 
    "arxiv-id": "1511.03742v2", 
    "author": "Anton Lokhmotov", 
    "publish": "2015-11-12T01:02:58Z", 
    "summary": "The generic matrix-matrix multiplication (GEMM) is arguably the most popular\ncomputational kernel of the 20th century. Yet, surprisingly, no common\nmethodology for evaluating GEMM performance has been established over the many\ndecades of using GEMM for comparing architectures, compilers and ninja-class\nprogrammers.\n  We introduce GEMMbench, a framework and methodology for evaluating\nperformance of GEMM implementations. GEMMbench is implemented on top of\nCollective Knowledge (CK), a lightweight framework for reproducible and\ncollaborative R&D in computer systems. Using CK allows the R&D community to\ncrowdsource hand-written and compiler-generated GEMM implementations and to\nstudy their performance across multiple platforms, data sizes and data types.\n  Our initial implementation supports hand-written OpenCL kernels operating on\nmatrices consisting of single- and double-precision floating-point values, and\nproducing single or multiple output elements per work-item (via thread\ncoarsening and vectorization)."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.05771v2", 
    "title": "Toward Transparent Heterogeneous Systems", 
    "arxiv-id": "1511.05771v2", 
    "author": "Alberto Dassatti", 
    "publish": "2015-11-18T13:37:18Z", 
    "summary": "Heterogeneous parallel systems are widely spread nowadays. Despite their\navailability, their usage and adoption are still limited, and even more rarely\nthey are used to full power. Indeed, compelling new technologies are constantly\ndeveloped and keep changing the technological landscape, but each of them\ntargets a limited sub-set of supported devices, and nearly all of them require\nnew programming paradigms and specific toolsets. Software, however, can hardly\nkeep the pace with the growing number of computational capabilities, and\ndevelopers are less and less motivated in learning skills that could quickly\nbecome obsolete. In this paper we present our effort in the direction of a\ntransparent system optimization based on automatic code profiling and\nJust-In-Time compilation, that resulted in a fully-working embedded prototype\ncapable of dynamically detect computing-intensive code blocks and automatically\ndispatch them to different computation units. Experimental results show that\nour system allows gains up to 32x in performance --- after an initial warm-up\nphase --- without requiring any human intervention."
},{
    "category": "math.PR", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.07392v1", 
    "title": "Cache Miss Estimation for Non-Stationary Request Processes", 
    "arxiv-id": "1511.07392v1", 
    "author": "Alain Simonian", 
    "publish": "2015-11-23T20:13:18Z", 
    "summary": "The aim of the paper is to evaluate the miss probability of a Least Recently\nUsed (LRU) cache, when it is offered a non-stationary request process given by\na Poisson cluster point process. First, we construct a probability space using\nPalm theory, describing how to consider a tagged document with respect to the\nrest of the request process. This framework allows us to derive a general\nintegral formula for the expected number of misses of the tagged document.\nThen, we consider the limit when the cache size and the arrival rate go to\ninfinity proportionally, and use the integral formula to derive an asymptotic\nexpansion of the miss probability in powers of the inverse of the cache size.\nThis enables us to quantify and improve the accuracy of the so-called Che\napproximation."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.07423v1", 
    "title": "Minimizing Total Busy Time for Energy-Aware Virtual Machine Allocation   Problems", 
    "arxiv-id": "1511.07423v1", 
    "author": "Nam Thoai", 
    "publish": "2015-11-21T04:53:42Z", 
    "summary": "This paper investigates the energy-aware virtual machine (VM) allocation\nproblems in clouds along characteristics: multiple resources, fixed interval\ntime and non-preemption of virtual machines. Many previous works have been\nproposed to use a minimum number of physical machines, however, this is not\nnecessarily a good solution to minimize total energy consumption in the VM\nplacement with multiple resources, fixed interval time and non-preemption. We\nobserved that minimizing the sum of total busy time of all physical machines\nimplies minimizing total energy consumption of physical machines. In addition\nto, if mapping of a VM onto physical machines have the same total busy time\nthen the best mapping has physical machine's remaining available resource\nminimizing. Based on these observations, we proposed heuristic-based EM\nalgorithm to solve the energy-aware VM allocation with fixed starting time and\nduration time. In addition, this work studies some heuristics for sorting the\nlist of virtual machines (e.g., sorting by the earliest starting time, or\nlatest finishing time, or the longest duration time first, etc.) to allocate\nVM. We evaluate the EM using CloudSim toolkit and jobs log-traces in the\nFeitelson's Parallel Workloads Archive. Simulation's results show that all of\nEM-ST, EM-LFT and EM-LDTF algorithms could reduce total energy consumption\ncompared to state-of-the-art of power-aware VM allocation algorithms. (e.g.\nPower-Aware Best-Fit Decreasing (PABFD) [7]))."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.peva.2015.09.003", 
    "link": "http://arxiv.org/pdf/1511.07658v1", 
    "title": "Efficient Resource Sharing Through GPU Virtualization on Accelerated   High Performance Computing Systems", 
    "arxiv-id": "1511.07658v1", 
    "author": "Tarek El-Ghazawi", 
    "publish": "2015-11-24T11:33:53Z", 
    "summary": "The High Performance Computing (HPC) field is witnessing a widespread\nadoption of Graphics Processing Units (GPUs) as co-processors for conventional\nhomogeneous clusters. The adoption of prevalent Single- Program Multiple-Data\n(SPMD) programming paradigm for GPU-based parallel processing brings in the\nchallenge of resource underutilization, with the asymmetrical\nprocessor/co-processor distribution. In other words, under SPMD, balanced\nCPU/GPU distribution is required to ensure full resource utilization. In this\npaper, we propose a GPU resource virtualization approach to allow underutilized\nmicroprocessors to effi- ciently share the GPUs. We propose an efficient GPU\nsharing scenario achieved through GPU virtualization and analyze the\nperformance potentials through execution models. We further present the\nimplementation details of the virtualization infrastructure, followed by the\nexperimental analyses. The results demonstrate considerable performance gains\nwith GPU virtualization. Furthermore, the proposed solution enables full\nutilization of asymmetrical resources, through efficient GPU sharing among\nmicroprocessors, while incurring low overhead due to the added virtualization\nlayer."
},{
    "category": "cs.NI", 
    "doi": "10.1109/RTSI.2015.7325085", 
    "link": "http://arxiv.org/pdf/1511.08167v1", 
    "title": "Deseeding Energy Consumption of Network Stacks", 
    "arxiv-id": "1511.08167v1", 
    "author": "Arturo Azcorra", 
    "publish": "2015-11-24T17:53:05Z", 
    "summary": "Regular works on energy efficiency strategies for wireless communications are\nbased on classical energy models that account for the wireless card only.\nNevertheless, there is a non-negligible energy toll called \"cross-factor\" that\nencompasses the energy drained while a frame crosses the network stack of an\nOS.\n  This paper addresses the challenge of deepen into the roots of the\ncross-factor, deseed its components and analyse its causes. Energy issues are\ncritical for IoT devices. Thus, this paper conceives and validates a new\ncomprehensive framework that enables us to measure a wide range of wireless\ndevices, as well as multiple devices synchronously. We also present a rigorous\nmethodology to perform whole-device energy measurements in laptops, a more\ngeneric and suitable device to perform energy debugging. Finally, and using\nthis framework, we provide a collection of measurements and insights that\ndeepens our understanding of the cross-factor."
},{
    "category": "cs.NI", 
    "doi": "10.1109/RTSI.2015.7325085", 
    "link": "http://arxiv.org/pdf/1512.07004v1", 
    "title": "Evaluation of Time-Critical Communications for IEC 61850-Substation   Network Architecture", 
    "arxiv-id": "1512.07004v1", 
    "author": "Jean-Marc Thiriet", 
    "publish": "2015-12-22T09:54:54Z", 
    "summary": "Present-day developments, in electrical power transmission and distribution,\nrequire considerations of the status quo. In other meaning, international\nregulations enforce increasing of reliability and reducing of environment\nimpact, correspondingly they motivate developing of dependable systems. Power\ngrids especially intelligent (smart grids) ones become industrial solutions\nthat follow standardized development. The International standardization, in the\nfield of power transmission and distribution, improve technology influences.\nThe rise of dedicated standards for SAS (Substation Automation Systems)\ncommunications, such as the leading International Electro-technical Commission\nstandard IEC 61850, enforces modern technological trends in this field. Within\nthis standard, a constraint of low ETE (End-to-End) latency should be\nrespected, and time-critical status transmission must be achieved. This\nexperimental study emphasis on IEC 61850 SAS communication standard, e.g. IEC\n61850 GOOSE (Generic Object Oriented Substation Events), to implement an\ninvestigational method to determine the protection communication delay. This\nmethod observes GOOSE behaviour by adopting monitoring and analysis\ncapabilities. It is observed by using network test equipment, i.e. SPAN (Switch\nPort Analyser) and TAP (Test Access Point) devices, with on-the-shelf available\nhardware and software solutions."
},{
    "category": "cs.PF", 
    "doi": "10.1109/RTSI.2015.7325085", 
    "link": "http://arxiv.org/pdf/1512.08354v1", 
    "title": "Non-Asymptotic Delay Bounds for (k,l) Fork-Join Systems and Multi-Stage   Fork-Join Networks", 
    "arxiv-id": "1512.08354v1", 
    "author": "Yuming Jiang", 
    "publish": "2015-12-28T09:27:32Z", 
    "summary": "Parallel systems have received increasing attention with numerous recent\napplications such as fork-join systems, load-balancing, and l-out-of-k\nredundancy. Common to these systems is a join or resequencing stage, where\ntasks that have finished service may have to wait for the completion of other\ntasks so that they leave the system in a predefined order. These\nsynchronization constraints make the analysis of parallel systems challenging\nand few explicit results are known. In this work, we model parallel systems\nusing a max-plus approach that enables us to derive statistical bounds of\nwaiting and sojourn times. Taking advantage of max-plus system theory, we also\nshow end-to-end delay bounds for multi-stage fork-join networks. We contribute\nsolutions for basic G|G|1 fork-join systems, parallel systems with\nload-balancing, as well as general (k,l) fork-join systems with redundancy. Our\nresults provide insights into the respective advantages of l-out-of-k\nredundancy vs. load-balancing."
},{
    "category": "cs.NI", 
    "doi": "10.1109/RTSI.2015.7325085", 
    "link": "http://arxiv.org/pdf/1512.08609v1", 
    "title": "Performance Analysis of an Unreliable $M/G/1$ Retrial Queue with Coupled   Switching", 
    "arxiv-id": "1512.08609v1", 
    "author": "Kiseon Kim", 
    "publish": "2015-12-29T07:02:05Z", 
    "summary": "We investigate the stationary characteristics of an $M/G/1$ retrial queue\nwhere the server, subject to active failures, primarily attends incoming calls\nand directs outgoing calls only when idle. On finding the server unavailable\n(busy or failed), inbound calls join the orbit and reattempt for service at\nexponentially-distributed time intervals. The system stability condition and\nprobability generating functions of the number of calls in orbit and system are\nderived and evaluated numerically in the context of mean system size, server\navailability, failure frequency, and orbit waiting time."
},{
    "category": "cs.NI", 
    "doi": "10.1109/RTSI.2015.7325085", 
    "link": "http://arxiv.org/pdf/1601.04749v1", 
    "title": "Constrained Multi-user Multi-server Max-Min Fair Queuing", 
    "arxiv-id": "1601.04749v1", 
    "author": "Yiqiang Zhao", 
    "publish": "2016-01-18T22:55:41Z", 
    "summary": "In this paper, a multi-user multi-server queuing system is studied in which\neach user is constrained to get service from a subset of servers. In the\nstudied system, rate allocation in the sense of max-min fairness results in\nmulti-level fair rates. To achieve such fair rates, we propose $CM^4FQ$\nalgorithm. In this algorithm users are chosen for service on a packet by packet\nbasis. The priority of each user $i$ to be chosen at time $t$ is determined\nbased on a parameter known as service tag (representing the amount of work\ncounted for user $i$ till time $t$). Hence, a free server will choose to serve\nan eligible user with the minimum service tag. Based on such simple selection\ncriterion, $CM^4FQ$ aims at guaranteed fair throughput for each demanding user\nwithout explicit knowledge of each server service rate. We argue that $CM^4FQ$\ncan be applied in a variety of practical queuing systems specially in mobile\ncloud computing architecture."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ICC.2016.7511430", 
    "link": "http://arxiv.org/pdf/1601.05098v4", 
    "title": "M2M Massive Access in LTE: RACH Performance Evaluation in a Smart City   Scenario", 
    "arxiv-id": "1601.05098v4", 
    "author": "Michele Zorzi", 
    "publish": "2016-01-19T21:02:02Z", 
    "summary": "Several studies assert that the random access procedure of the Long Term\nEvolution (LTE) cellular standard may not be effective whenever a massive\nnumber of simultaneous connection attempts are performed by terminals, as may\nhappen in a typical Internet of Things or Smart City scenario. Nevertheless,\nsimulation studies in real deployment scenarios are missing because many\nsystem-level simulators do not implement the LTE random access procedure in\ndetail. In this paper, we propose a patch for the LTE module of ns-3, one of\nthe most prominent open-source network simulators, to improve the accuracy of\nthe routine that simulates the LTE Random Access Channel (RACH). The patched\nversion of the random access procedure is compared with the default one and the\nissues arising from massive simultaneous access from mobile terminals in LTE\nare assessed via a simulation campaign."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICC.2016.7511430", 
    "link": "http://arxiv.org/pdf/1601.07815v1", 
    "title": "Convex Optimization of Real Time SoC", 
    "arxiv-id": "1601.07815v1", 
    "author": "U. Weiser", 
    "publish": "2016-01-28T16:19:39Z", 
    "summary": "Convex optimization methods are employed to optimize a real-time (RT)\nsystem-on-chip (SoC) under a variety of physical resource-driven constraints,\ndemonstrated on an industry MPEG2 encoder SoC. The power optimization is\ncompared to conventional performance-optimization framework, showing a factor\nof two and a half saving in power. Convex optimization is shown to be very\nefficient in a high-level early stage design exploration, guiding computer\narchitects as to the choice of area, voltage, and frequency of the individual\ncomponents of the Chip Multiprocessor (CMP)."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ICC.2016.7511430", 
    "link": "http://arxiv.org/pdf/1602.00586v1", 
    "title": "A Gain Function for Architectural Decision-Making in Scientific   Computing", 
    "arxiv-id": "1602.00586v1", 
    "author": "Bruno Schulze", 
    "publish": "2016-02-01T16:36:58Z", 
    "summary": "Scientific Computing typically requires large computational needs which have\nbeen addressed with High Performance Distributed Computing. It is essential to\nefficiently deploy a number of complex scientific applications, which have\ndifferent characteristics, and so require distinct computational resources too.\nHowever, in many research laboratories, this high performance architecture is\nnot dedicated. So, the architecture must be shared to execute a set of\nscientific applications, with so many different execution times and relative\nimportance to research. Also, the high performance architectures have different\ncharacteristics and costs. When a new infrastructure has to be acquired to meet\nthe needs of this scenario, the decision-making is hard and complex. In this\nwork, we present a Gain Function as a model of an utility function, with which\nit is possible a decision-making with confidence. With the function is possible\nto evaluate the best architectural option taking into account aspects of\napplications and architectures, including the executions time, cost of\narchitecture, the relative importance of each application and also the relative\nimportance of performance and cost on the final evaluation. This paper presents\nthe Gain Function, examples, and a real case showing their applicabilities."
},{
    "category": "cs.AR", 
    "doi": "10.1109/ICC.2016.7511430", 
    "link": "http://arxiv.org/pdf/1602.02517v1", 
    "title": "Energy Efficient Video Fusion with Heterogeneous CPU-FPGA Devices", 
    "arxiv-id": "1602.02517v1", 
    "author": "Tom Sun", 
    "publish": "2016-02-08T10:28:44Z", 
    "summary": "This paper presents a complete video fusion system with hardware acceleration\nand investigates the energy trade-offs between computing in the CPU or the FPGA\ndevice. The video fusion application is based on the Dual-Tree Complex Wavelet\nTransforms (DT-CWT). In this work the transforms are mapped to a hardware\naccelerator using high-level synthesis tools for the FPGA and also vectorized\ncode for the single instruction multiple data (SIMD) engine available in the\nCPU. The accelerated system reduces computation time and energy by a factor of\n2. Moreover, the results show a key finding that the FPGA is not always the\nbest choice for acceleration, and the SIMD engine should be selected when the\nwavelet decomposition reduces the frame size below a certain threshold. This\ndependency on workload size means that an adaptive system that intelligently\nselects between the SIMD engine and the FPGA achieves the most energy and\nperformance efficiency point."
},{
    "category": "cs.AR", 
    "doi": "10.1109/MDAT.2016.2573586", 
    "link": "http://arxiv.org/pdf/1602.04183v3", 
    "title": "Dark Memory and Accelerator-Rich System Optimization in the Dark Silicon   Era", 
    "arxiv-id": "1602.04183v3", 
    "author": "Mark A. Horowitz", 
    "publish": "2016-02-12T19:48:31Z", 
    "summary": "The key challenge to improving performance in the age of Dark Silicon is how\nto leverage transistors when they cannot all be used at the same time. In\nmodern SOCs, these transistors are often used to create specialized\naccelerators which improve energy efficiency for some applications by 10-1000X.\nWhile this might seem like the magic bullet we need, for most CPU applications\nmore energy is dissipated in the memory system than in the processor: these\nlarge gains in efficiency are only possible if the DRAM and memory hierarchy\nare mostly idle. We refer to this desirable state as Dark Memory, and it only\noccurs for applications with an extreme form of locality.\n  To show our findings, we introduce Pareto curves in the energy/op and\nmm$^2$/(ops/s) metric space for compute units, accelerators, and on-chip\nmemory/interconnect. These Pareto curves allow us to solve the power,\nperformance, area constrained optimization problem to determine which\naccelerators should be used, and how to set their design parameters to optimize\nthe system. This analysis shows that memory accesses create a floor to the\nachievable energy-per-op. Thus high performance requires Dark Memory, which in\nturn requires co-design of the algorithm for parallelism and locality, with the\nhardware."
},{
    "category": "cs.DC", 
    "doi": "10.1109/MDAT.2016.2573586", 
    "link": "http://arxiv.org/pdf/1602.04873v1", 
    "title": "A Stochastic Performance Model for Pipelined Krylov Methods", 
    "arxiv-id": "1602.04873v1", 
    "author": "L. Ridgway Scott", 
    "publish": "2016-02-16T00:39:33Z", 
    "summary": "Pipelined Krylov methods seek to ameliorate the latency due to inner products\nnecessary for projection by overlapping it with the computation associated with\nsparse matrix-vector multiplication. We clarify a folk theorem that this can\nonly result in a speedup of $2\\times$ over the naive implementation. Examining\nmany repeated runs, we show that stochastic noise also contributes to the\nlatency, and we model this using an analytical probability distribution. Our\nanalysis shows that speedups greater than $2\\times$ are possible with these\nalgorithms."
},{
    "category": "cs.MS", 
    "doi": "10.1109/MDAT.2016.2573586", 
    "link": "http://arxiv.org/pdf/1602.06763v1", 
    "title": "Recursive Algorithms for Dense Linear Algebra: The ReLAPACK Collection", 
    "arxiv-id": "1602.06763v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2016-02-22T13:21:05Z", 
    "summary": "To exploit both memory locality and the full performance potential of highly\ntuned kernels, dense linear algebra libraries such as LAPACK commonly implement\noperations as blocked algorithms. However, to achieve next-to-optimal\nperformance with such algorithms, significant tuning is required. On the other\nhand, recursive algorithms are virtually tuning free, and yet attain similar\nperformance. In this paper, we first analyze and compare blocked and recursive\nalgorithms in terms of performance, and then introduce ReLAPACK, an open-source\nlibrary of recursive algorithms to seamlessly replace most of LAPACK's blocked\nalgorithms. In many scenarios, ReLAPACK clearly outperforms reference LAPACK,\nand even improves upon the performance of optimizes libraries."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1602.07623v1", 
    "title": "Spatial multi-LRU Caching for Wireless Networks with Coverage Overlaps", 
    "arxiv-id": "1602.07623v1", 
    "author": "Apostolos Avranas", 
    "publish": "2016-02-24T18:08:43Z", 
    "summary": "This article introduces a novel family of decentralised caching policies,\napplicable to wireless networks with finite storage at the edge-nodes\n(stations). These policies are based on the Least-Recently-Used replacement\nprinciple, and are, here, referred to as spatial multi-LRU. Based on these,\ncache inventories are updated in a way that provides content diversity to users\nwho are covered by, and thus have access to, more than one station. Two\nvariations are proposed, namely the multi-LRU-One and -All, which differ in the\nnumber of replicas inserted in the involved caches. By introducing spatial\napproximations, we propose a Che-like method to predict the hit probability,\nwhich gives very accurate results under the Independent Reference Model (IRM).\nIt is shown that the performance of multi-LRU increases the more the\nmulti-coverage areas increase, and it approaches the performance of other\nproposed centralised policies, when multi-coverage is sufficient. For IRM\ntraffic multi-LRU-One outperforms multi-LRU-All, whereas when the traffic\nexhibits temporal locality the -All variation can perform better."
},{
    "category": "cs.NA", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.00491v1", 
    "title": "Wanted: Floating-Point Add Round-off Error instruction", 
    "arxiv-id": "1603.00491v1", 
    "author": "Jason Riedy", 
    "publish": "2016-03-01T21:12:09Z", 
    "summary": "We propose a new instruction (FPADDRE) that computes the round-off error in\nfloating-point addition. We explain how this instruction benefits\nhigh-precision arithmetic operations in applications where double precision is\nnot sufficient. Performance estimates on Intel Haswell, Intel Skylake, and AMD\nSteamroller processors, as well as Intel Knights Corner co-processor,\ndemonstrate that such an instruction would improve the latency of double-double\naddition by up to 55% and increase double-double addition throughput by up to\n103%, with smaller, but non-negligible benefits for double-double\nmultiplication. The new instruction delivers up to 2x speedups on three\nbenchmarks that use high-precision floating-point arithmetic: double-double\nmatrix-matrix multiplication, compensated dot product, and polynomial\nevaluation via the compensated Horner scheme."
},{
    "category": "math.PR", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.01404v1", 
    "title": "Design Heuristic for Parallel Many Server Systems under FCFS-ALIS", 
    "arxiv-id": "1603.01404v1", 
    "author": "Gideon Weiss", 
    "publish": "2016-03-04T10:03:09Z", 
    "summary": "We study a parallel service queueing system with servers of types\n$s_1,\\ldots,s_J$, customers of types $c_1,\\ldots,c_I$, bipartite compatibility\ngraph $\\mathcal{G}$, where arc $(c_i, s_j)$ indicates that server type $s_j$\ncan serve customer type $c_i$, and service policy of first come first served\nFCFS, assign longest idle server ALIS. For a general renewal stream of arriving\ncustomers and general service time distributions, the behavior of such systems\nis very complicated, in particular the calculation of matching rates\n$r_{c_i,s_j}$, the fraction of services of customers of type $c_i$ by servers\nof type $s_j$, is intractable. We suggest through a heuristic argument that if\nthe number of servers becomes large, the matching rates are well approximated\nby matching rates calculated from the tractable FCFS bipartite infinite\nmatching model. We present simulation evidence to support this heuristic\nargument, and show how this can be used to design systems for given performance\nrequirements."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.02094v1", 
    "title": "Delay Bounds in Feed-Forward Networks - A Fast and Accurate Network   Calculus Solution", 
    "arxiv-id": "1603.02094v1", 
    "author": "Jens B. Schmitt", 
    "publish": "2016-03-07T14:53:33Z", 
    "summary": "Guaranteeing accurate worst-case bounds on the end-to-end delay that data\nflows experience in communication networks is required for a variety of\nsafety-critical systems, for instance in avionics. Deterministic Network\nCalculus (DNC) is a widely used method to derive such bounds. The DNC theory\nhas been advanced in recent years to provide ever tighter delay bounds, though\nthis turned out a hard problem in the general feed-forward network case.\nCurrently, the only analysis to achieve tight delay bounds, i.e., best possible\nones, is based on an optimization formulation instead of the usual algebraic\nDNC analysis. However, it has also been shown to be NP-hard and was accompanied\nby a similar, yet relaxed optimization that trades tightness against\ncomputational effort. In our article, we derive a novel, fast algebraic delay\nanalysis that nevertheless retains a high degree of accuracy. We show in\nextensive numerical experiments that our solution enables the analysis of\nlarge-scale networks by reducing the computation time by several orders of\nmagnitude in contrast to the optimization analysis. Moreover, in networks where\noptimization is still feasible, our delay bounds stay within close range,\ndeviating on average by only 1.16% in our experiments."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.02293v1", 
    "title": "What slows you down? Your network or your device?", 
    "arxiv-id": "1603.02293v1", 
    "author": "Ruomei Gao", 
    "publish": "2016-03-07T21:08:53Z", 
    "summary": "This study takes a close look at mobile web performance. The two main\nparameters determining web page load time are the network speed and the\ncomputing power of the end-user device. Based on data from real users, this\npaper quantifies the relative importance of network and device. The findings\nsuggest that increased processing power of latest generation smart phones and\noptimized browsers have a significant impact on web performance; up to 56%\nreduction in median page load time from one generation to the following. The\ncellular networks, on the other hand, have become so mature that the median\npage load time on one fiber-to-the-home network (using wifi for the last meter)\nis only 18-28% faster than cellular and the median page load time on one DSL\nnetwork is 19% slower compared to a well-deployed cellular network."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.02655v1", 
    "title": "Study and evaluation of an Irregular Graph Algorithm on Multicore and   GPU Processor Architectures", 
    "arxiv-id": "1603.02655v1", 
    "author": "Varun Nagpal", 
    "publish": "2016-03-08T20:07:31Z", 
    "summary": "One area of Computing applications which poses significant challenge of\nperformance scalability on Chip Multiprocessors(CMP's) are Irregular\napplications. Such applications have very little computation and unpredictable\nmemory access patterns making them memory-bound in contrast to compute-bound\napplications. Since the gap between processor and memory performance continues\nto exist, difficulty to hide and decrease this gap is one of the important\nfactors which results in poor performance of these applications on CMP's.\n  The goal of this thesis is to overcome many such challenges posed during\nperformance acceleration of an irregular graph algorithm called Triad Census.\nWe accelerated the Triad Census algorithm on two significantly different Chip\nMultiprocessors: Dual-socket Intel Xeon Multicore (8 hardware threads per\nsocket) and 240-processor core NVIDIA Tesla C1060 GPGPU(128 hardware threads\nper core).\n  The experimental results obtained on Intel Multicore Xeon system shows\nperformance speedups (w.r.t baseline sequential) of maximum 56x , average 33x\nand minimum 8.3x for real world graph data sets. On NVIDIA Tesla C1060 GPGPU,\nwe were able to match almost equally the Multicore results - 58.4x maximum,\n32.8x average and 4.2x minimum speedups w.r.t baseline sequential. In terms of\nraw performance, for the graph data set called Patents network, our results on\nIntel Xeon Multicore(16 hw threads) were 1.27x times faster than previous\nresults on Cray XMT(16 hw threads) while results achieved on GPGPU were\ncomparatively slower(0.72x). To the best of our knowledge, this algorithm has\nonly been accelerated on supercomputer class computer named Cray XMT and no\nwork exists that demonstrates performance evaluation and comparison of this\nalgorithm on relatively lower-cost Multicore and GPGPU based platforms."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.02955v1", 
    "title": "A Performance Evaluation of Container Technologies on Internet of Things   Devices", 
    "arxiv-id": "1603.02955v1", 
    "author": "Roberto Morabito", 
    "publish": "2016-03-09T16:40:39Z", 
    "summary": "The use of virtualization technologies in different contexts - such as Cloud\nEnvironments, Internet of Things (IoT), Software Defined Networking (SDN) - has\nrapidly increased during the last years. Among these technologies,\ncontainer-based solutions own characteristics for deploying distributed and\nlightweight applications. This paper presents a performance evaluation of\ncontainer technologies on constrained devices, in this case, on Raspberry Pi.\nThe study shows that, overall, the overhead added by containers is negligible."
},{
    "category": "cs.LO", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.03252v1", 
    "title": "Extension of PRISM by Synthesis of Optimal Timeouts in Fixed-Delay CTMC", 
    "arxiv-id": "1603.03252v1", 
    "author": "Adrian Farmadin", 
    "publish": "2016-03-10T13:20:05Z", 
    "summary": "We present a practically appealing extension of the probabilistic model\nchecker PRISM rendering it to handle fixed-delay continuous-time Markov chains\n(fdCTMCs) with rewards, the equivalent formalism to the deterministic and\nstochastic Petri nets (DSPNs). fdCTMCs allow transitions with fixed-delays (or\ntimeouts) on top of the traditional transitions with exponential rates. Our\nextension supports an evaluation of expected reward until reaching a given set\nof target states. The main contribution is that, considering the fixed-delays\nas parameters, we implemented a synthesis algorithm that computes the\nepsilon-optimal values of the fixed-delays minimizing the expected reward. We\nprovide a performance evaluation of the synthesis on practical examples."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.03820v1", 
    "title": "Faster and Cheaper: Parallelizing Large-Scale Matrix Factorization on   GPUs", 
    "arxiv-id": "1603.03820v1", 
    "author": "Liana Fong", 
    "publish": "2016-03-11T23:27:37Z", 
    "summary": "Matrix factorization (MF) is employed by many popular algorithms, e.g.,\ncollaborative filtering. The emerging GPU technology, with massively multicore\nand high intra-chip memory bandwidth but limited memory capacity, presents an\nopportunity for accelerating MF much further when appropriately exploiting the\nGPU architectural characteristics.\n  This paper presents cuMF, a CUDA-based matrix factorization library that\nimplements memory-optimized alternate least square (ALS) method to solve very\nlarge-scale MF. CuMF uses a variety set of techniques to maximize the\nperformance on either single or multiple GPUs. These techniques include smart\naccess of sparse data leveraging GPU memory hierarchy, using data parallelism\nin conjunction with model parallelism, minimizing the communication overhead\nbetween computing units, and utilizing a novel topology-aware parallel\nreduction scheme.\n  With only a single machine with four Nvidia GPU cards, cuMF can be 6-10 times\nas fast, and 33-100 times as cost-efficient, compared with the state-of-art\ndistributed CPU solutions. Moreover, this cuMF can solve the largest matrix\nfactorization problem ever reported yet in current literature, while\nmaintaining impressively good performance."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1603.07899v2", 
    "title": "Helenos: A Realistic Benchmark for Distributed Transactional Memory", 
    "arxiv-id": "1603.07899v2", 
    "author": "Pawe\u0142 T. Wojciechowski", 
    "publish": "2016-03-25T13:14:23Z", 
    "summary": "Transactional Memory (TM) is an approach to concurrency control that aims to\nmake writing parallel programs both effective and simple. The approach is\nstarted in non-distributed multiprocessor systems, but is gaining popularity in\ndistributed systems to synchronize tasks at large scales. Efficiency and\nscalability are often the key issues in TM research, so performance benchmarks\nare an important part of it. However, while standard TM benchmarks like the\nSTAMP suite and STMBench7 are available and widely accepted, they do not\ntranslate well into distributed systems. Hence, the set of benchmarks usable\nwith distributed TM systems is very limited, and must be padded with\nmicrobenchmarks, whose simplicity and artificial nature often makes them\nuninformative or misleading. Therefore, this paper introduces Helenos, a\nrealistic, complex, and comprehensive distributed TM benchmark based on the\nproblem of the Facebook inbox, an application of the Cassandra distributed\nstore."
},{
    "category": "cs.CR", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1604.00103v2", 
    "title": "Priority Mechanism of Bitcoin and Its Effect on Transaction-Confirmation   Process", 
    "arxiv-id": "1604.00103v2", 
    "author": "Jun Kawahara", 
    "publish": "2016-04-01T02:15:02Z", 
    "summary": "In Bitcoin system, transactions are prioritized according to attributes such\nas the remittance amount and transaction fees, and transactions with low\npriority are likely to wait for confirmation. Because the demand of micro\npayment in Bitcoin is expected to increase due to low remittance cost, it is\nimportant to quantitatively investigate how the priority mechanism of Bitcoin\naffects the transaction-confirmation time. In this paper, we analyze the\ntransaction-confirmation time by queueing theory. We model the transaction\npriority mechanism of Bitcoin as a priority queueing system with batch service,\nderiving the mean transaction-confirmation time. Numerical examples show how\nthe demand of transactions of low remittance amount affects the\ntransaction-confirmation time. We also consider the effect of the maximum block\nsize on the transaction-confirmation time."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1604.01303v2", 
    "title": "C3PO: Computation Congestion Control (PrOactive) - an algorithm for   dynamic diffusion of ephemeral in-network services", 
    "arxiv-id": "1604.01303v2", 
    "author": "Jon Crowcroft", 
    "publish": "2016-04-05T15:38:51Z", 
    "summary": "There is an obvious trend that more and more data and computation are\nmigrating into networks nowadays. Combining mature virtualization technologies\nwith service-centric net- working, we are entering into an era where countless\nservices reside in an ISP network to provide low-latency access. Such services\nare often computation intensive and are dynamically created and destroyed on\ndemands everywhere in the network to perform various tasks. Consequently, these\nephemeral in-network services introduce a new type of congestion in the network\nwhich we refer to as \"computation congestion\". The service load need to be\neffectively distributed on different nodes in order to maintain the\nfuntionality and responsiveness of the network, which calls for a new design\nrather than reusing the centralised scheduler designed for cloud-based\nservices. In this paper, we study both passive and proactive control\nstrategies, based on the proactive control we further propose a fully\ndistributed solution which is low complexity, adaptive, and responsive to\nnetwork dynamics."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1604.01890v1", 
    "title": "Performance analysis of the Kahan-enhanced scalar product on current   multi- and manycore processors", 
    "arxiv-id": "1604.01890v1", 
    "author": "Gerhard Wellein", 
    "publish": "2016-04-07T07:04:19Z", 
    "summary": "We investigate the performance characteristics of a numerically enhanced\nscalar product (dot) kernel loop that uses the Kahan algorithm to compensate\nfor numerical errors, and describe efficient SIMD-vectorized implementations on\nrecent multi- and manycore processors. Using low-level instruction analysis and\nthe execution-cache-memory (ECM) performance model we pinpoint the relevant\nperformance bottlenecks for single-core and thread-parallel execution, and\npredict performance and saturation behavior. We show that the Kahan-enhanced\nscalar product comes at almost no additional cost compared to the naive\n(non-Kahan) scalar product if appropriate low-level optimizations, notably SIMD\nvectorization and unrolling, are applied. The ECM model is extended\nappropriately to accommodate not only modern Intel multicore chips but also the\nIntel Xeon Phi \"Knights Corner\" coprocessor and an IBM POWER8 CPU. This allows\nus to discuss the impact of processor features on the performance across four\nmodern architectures that are relevant for high performance computing."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1604.02097v2", 
    "title": "On the Duration and Intensity of Competitions in Nonlinear P\u00f3lya Urn   Processes with Fitness", 
    "arxiv-id": "1604.02097v2", 
    "author": "Don Towsley", 
    "publish": "2016-04-06T00:35:18Z", 
    "summary": "Cumulative advantage (CA) refers to the notion that accumulated resources\nfoster the accumulation of further resources in competitions, a phenomenon that\nhas been empirically observed in various contexts. The oldest and arguably\nsimplest mathematical model that embodies this general principle is the P\\'olya\nurn process, which finds applications in a myriad of problems. The original\nmodel captures the dynamics of competitions between two equally fit agents\nunder linear CA effects, which can be readily generalized to incorporate\ndifferent fitnesses and nonlinear CA effects. We study two statistics of\ncompetitions under the generalized model, namely duration (i.e., time of the\nlast tie) and intensity (i.e., number of ties). We give rigorous mathematical\ncharacterizations of the tail distributions of both duration and intensity\nunder the various regimes for fitness and nonlinearity, which reveal very\ninteresting behaviors. For example, fitness superiority induces much shorter\ncompetitions in the sublinear regime while much longer competitions in the\nsuperlinear regime. Our findings can shed light on the application of P\\'olya\nurn processes in more general contexts where fitness and nonlinearity may be\npresent."
},{
    "category": "math.OC", 
    "doi": "10.1145/2896377.2901483", 
    "link": "http://arxiv.org/pdf/1604.02727v1", 
    "title": "IPA in the Loop: Control Design for Throughput Regulation in Computer   Processors", 
    "arxiv-id": "1604.02727v1", 
    "author": "Sudhakar Yalamanchili", 
    "publish": "2016-04-10T19:48:59Z", 
    "summary": "A new technique for performance regulation in event-driven systems, recently\nproposed by the authors, consists of an adaptive-gain integral control. The\ngain is adjusted in the control loop by a real-time estimation of the\nderivative of the plant-function with respect to the control input. This\nestimation is carried out by Infinitesimal Perturbation Analysis (IPA). The\nmain motivation comes from applications to throughput regulation in computer\nprocessors, where to-date, testing and assessment of the proposed control\ntechnique has been assessed by simulation. The purpose of this paper is to\nreport on its implementation on a machine, namely an Intel Haswell\nmicroprocessor, and compare its performance to that obtained from cycle-level,\nfull system simulation environment. The intrinsic contribution of the paper to\nthe Workshop on Discrete Event System is in describing the process of taking an\nIPA-based design and simulation to a concrete implementation, thereby providing\na bridge between theory and applications."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s11227-014-1317-4", 
    "link": "http://arxiv.org/pdf/1604.02907v1", 
    "title": "Modeling and predicting measured response time of cloud-based web   services using long-memory time series", 
    "arxiv-id": "1604.02907v1", 
    "author": "Mohammad Kalantari", 
    "publish": "2016-04-11T12:07:20Z", 
    "summary": "Predicting cloud performance from user's perspective is a complex task,\nbecause of several factors involved in providing the service to the consumer.\nIn this work, the response time of 10 real-world services is analyzed. We have\nobserved long memory in terms of the measured response time of the\nCPU-intensive services and statistically verified this observation using\nestimators of the Hurst exponent. Then, na\\\"ive, mean, autoregressive\nintegrated moving average (ARIMA) and autoregressive fractionally integrated\nmoving average (ARFIMA) methods are used to forecast the future values of\nquality of service (QoS) at runtime. Results of the cross-validation over the\n10 datasets show that the long-memory ARFIMA model provides the mean of 37.5 %\nand the maximum of 57.8 % reduction in the forecast error when compared to the\nshort-memory ARIMA model according to the standard error measure of mean\nabsolute percentage error. Our work implies that consideration of the\nlong-range dependence in QoS data can help to improve the selection of services\naccording to their possible future QoS values."
},{
    "category": "cs.DC", 
    "doi": "10.1007/s11227-014-1317-4", 
    "link": "http://arxiv.org/pdf/1604.03470v1", 
    "title": "Ready for Rain? A View from SPEC Research on the Future of Cloud Metrics", 
    "arxiv-id": "1604.03470v1", 
    "author": "Samuel Kounev", 
    "publish": "2016-04-12T16:23:15Z", 
    "summary": "In the past decade, cloud computing has emerged from a pursuit for a\nservice-driven information and communication technology (ICT), into a\nsignifcant fraction of the ICT market. Responding to the growth of the market,\nmany alternative cloud services and their underlying systems are currently\nvying for the attention of cloud users and providers. Thus, benchmarking them\nis needed, to enable cloud users to make an informed choice, and to enable\nsystem DevOps to tune, design, and evaluate their systems. This requires\nfocusing on old and new system properties, possibly leading to the re-design of\nclassic benchmarking metrics, such as expressing performance as throughput and\nlatency (response time), and the design of new, cloud-specififc metrics.\nAddressing this requirement, in this work we focus on four system properties:\n(i) elasticity of the cloud service, to accommodate large variations in the\namount of service requested, (ii) performance isolation between the tenants of\nshared cloud systems, (iii) availability of cloud services and systems, and the\n(iv) operational risk of running a production system in a cloud\nenvironment.Focusing on key metrics, for each of these properties we review the\nstate-of-the-art, then select or propose new metrics together with measurement\napproaches. We see the presented metrics as a foundation towards upcoming,\nindustry-standard, cloud benchmarks.\n  Keywords: Cloud Computing; Metrics; Measurement; Benchmarking; Elasticity;\nIsolation; Performance; Service Level Objective; Availability; Operational\nRisk."
},{
    "category": "cs.NI", 
    "doi": "10.1007/s11227-014-1317-4", 
    "link": "http://arxiv.org/pdf/1604.03823v1", 
    "title": "Analysis of a trunk reservation policy in the framework of fog computing", 
    "arxiv-id": "1604.03823v1", 
    "author": "Guilherme Thompson", 
    "publish": "2016-04-13T15:14:08Z", 
    "summary": "We analyze in this paper a system composed of two data centers with limited\ncapacity in terms of servers. When one request for a single server is blocked\nat the first data center, this request is forwarded to the second one. To\nprotect the single server requests originally assigned to the second data\ncenter, a trunk reservation policy is introduced (i.e., a redirected request is\naccepted only if there is a sufficient number of free servers at the second\ndata center). After rescaling the system by assuming that there are many\nservers in both data centers and high request arrival rates, we are led to\nanalyze a random walk in the quarter plane, which has the particularity of\nhaving non constant reflecting conditions on one boundary of the quarter plane.\nContrary to usual reflected random walks, to compute the stationary\ndistribution of the presented random walk, we have to determine three unknown\nfunctions, one polynomial and two infinite generating functions. We show that\nthe coefficients of the polynomial are solutions to a linear system. After\nsolving this linear system, we are able to compute the two other unknown\nfunctions and the blocking probabilities at both data centers. Numerical\nexperiments are eventually performed to estimate the gain achieved by the trunk\nreservation policy."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11227-014-1317-4", 
    "link": "http://arxiv.org/pdf/1604.04951v1", 
    "title": "A Hybrid Performance Analysis Technique for Distributed Real-Time   Embedded Systems", 
    "arxiv-id": "1604.04951v1", 
    "author": "Soonhoi Ha", 
    "publish": "2016-04-18T01:24:48Z", 
    "summary": "It remains a challenging problem to tightly estimate the worst case response\ntime of an application in a distributed embedded system, especially when there\nare dependencies between tasks. We discovered that the state-of-the art\ntechniques considering task dependencies either fail to obtain a conservative\nbound or produce a loose upper bound. We propose a novel conservative\nperformance analysis, called hybrid performance analysis, combining the\nresponse time analysis technique and the scheduling time bound analysis\ntechnique to compute a tighter bound fast. Through extensive experiments with\nrandomly generated graphs, superior performance of our proposed approach\ncompared with previous methods is confirmed."
},{
    "category": "cs.PF", 
    "doi": "10.1007/s11227-014-1317-4", 
    "link": "http://arxiv.org/pdf/1604.04997v1", 
    "title": "A Unified, Hardware-Fitted, Cross-GPU Performance Model", 
    "arxiv-id": "1604.04997v1", 
    "author": "Andreas Kl\u00f6ckner", 
    "publish": "2016-04-18T05:49:56Z", 
    "summary": "We present a mechanism to symbolically gather performance-relevant operation\ncounts from numerically-oriented subprograms (`kernels') expressed in the Loopy\nprogramming system, and apply these counts in a simple, linear model of kernel\nrun time. We use a series of `performance-instructive' kernels to fit the\nparameters of a unified model to the performance characteristics of GPU\nhardware from multiple hardware generations and vendors. We evaluate the\npredictive power of the model on a broad array of computational kernels\nrelevant to scientific computing. In terms of the geometric mean, our simple,\nvendor- and GPU-type-independent model achieves relative accuracy comparable to\nthat of previously published work using hardware specific models."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1604.08004v1", 
    "title": "An Analytical Solution for Probabilistic Guarantees of Reservation Based   Soft Real-Time Systems", 
    "arxiv-id": "1604.08004v1", 
    "author": "Bernardo Villalba Fr\u00edas", 
    "publish": "2016-04-27T10:08:53Z", 
    "summary": "We show a methodology for the computation of the probability of deadline miss\nfor a periodic real-time task scheduled by a resource reservation algorithm. We\npropose a modelling technique for the system that reduces the computation of\nsuch a probability to that of the steady state probability of an infinite state\nDiscrete Time Markov Chain with a periodic structure. This structure is\nexploited to develop an efficient numeric solution where different\naccuracy/computation time trade-offs can be obtained by operating on the\ngranularity of the model. More importantly we offer a closed form conservative\nbound for the probability of a deadline miss. Our experiments reveal that the\nbound remains reasonably close to the experimental probability in one real-time\napplication of practical interest. When this bound is used for the optimisation\nof the overall Quality of Service for a set of tasks sharing the CPU, it\nproduces a good sub-optimal solution in a small amount of time."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1605.02393v1", 
    "title": "Energy Efficiency in Wireless Sensor Networks", 
    "arxiv-id": "1605.02393v1", 
    "author": "Najmeh Kamyab Pour", 
    "publish": "2016-05-09T00:41:20Z", 
    "summary": "Unlike most of the current research that focuses on a single aspect of WSNs,\nwe present an Energy Driven Architecture (EDA) as a new architecture for\nminimising the total energy consumption of WSNs. EDA as a constituent-based\narchitecture is used to deploy WSNs according to energy dissipation through\ntheir constituents. This view of overall energy consumption in WSNs can be\napplied to optimising and balancing energy consumption and increasing the\nnetwork lifetime. Refer back to the architecture, we introduce a single overall\nmodel and propose a feasible formulation to express the overall energy\nconsumption of a generic wireless sensor network application in terms of its\nenergy constituents. The formulation offers a concrete expression for\nevaluating the performance of WSN application, optimising its constituents\noperations, and designing more energy-efficient applications. The ultimate aim\nis to produce an energy map architecture of a generic WSN application that\ncomprises essential and definable energy constituents and the relationships\nbetween these constituents to explore strategies for minimising the overall\nenergy consumption of the application. Later, parameters affecting energy in\nWSNs are extracted. The dependency between these parameters and the average\nenergy consumption of an application is then investigated. A few statistical\ntools are applied for parameter reduction followed by random forest regression\nto model energy consumption per delivered packet with and without parameter\nreduction to determine the reduction in accuracy due to reduction. Finally, an\nenergy-efficient dynamic topology management algorithm is proposed based on the\nEDA model and the prevalent parameters. The performance of the new topology\nmanagement algorithm, which employs Dijkstra to find energy-efficient lowest\ncost paths among nodes, is compared to similar topology management algorithms."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1605.07083v2", 
    "title": "D-SPACE4Cloud: A Design Tool for Big Data Applications", 
    "arxiv-id": "1605.07083v2", 
    "author": "Danilo Ardagna", 
    "publish": "2016-05-23T16:37:54Z", 
    "summary": "The last years have seen a steep rise in data generation worldwide, with the\ndevelopment and widespread adoption of several software projects targeting the\nBig Data paradigm. Many companies currently engage in Big Data analytics as\npart of their core business activities, nonetheless there are no tools and\ntechniques to support the design of the underlying hardware configuration\nbacking such systems. In particular, the focus in this report is set on Cloud\ndeployed clusters, which represent a cost-effective alternative to on premises\ninstallations. We propose a novel tool implementing a battery of optimization\nand prediction techniques integrated so as to efficiently assess several\nalternative resource configurations, in order to determine the minimum cost\ncluster deployment satisfying QoS constraints. Further, the experimental\ncampaign conducted on real systems shows the validity and relevance of the\nproposed method."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1605.07353v2", 
    "title": "Enhanced Worst-case Timing Analysis of Ring-based Networks with Cyclic   Dependencies using Network Calculus", 
    "arxiv-id": "1605.07353v2", 
    "author": "Jerome Lacan", 
    "publish": "2016-05-24T09:55:06Z", 
    "summary": "The recent research effort towards defining new communication solutions for\ncyber-physical systems (CPS), to guarantee high availability level with limited\ncabling costs and complexity, has renewed the interest in ring-based networks.\nThis topology has been recently used for various networked cyber-physical\nsystems (Net-CPS), e.g., avionics and automotive, with the implementation of\nmany Real Time Ethernet (RTE) profiles. A relevant issue for such networks is\nto prove timing predictability, a key requirement for safety-critical systems.\nWe are interested in this paper in event-triggered ring-based networks, which\nguarantee high resource utilization efficiency and (re)configuration\nflexibility, at the cost of increasing the timing analysis complexity. The\nimplementation of such a communication scheme on top of a ring topology\nactually induces cyclic dependencies, in comparison to time-triggered\nsolutions. To cope with this arising issue of cyclic dependencies, only few\ntechniques have been proposed in the literature, mainly based on Network\nCalculus framework, and consist in analyzing locally the delay upper bound in\neach crossed node, resulting in pessimistic end-to-end delay bounds. Hence, the\nmain contribution in this paper is enhancing the delay bounds tightness of such\nnetworks, through an innovative global analysis based on Network Calculus,\naccounting the flow serialization phenomena along the flow path. An extensive\nanalysis of such a proposal is conducted herein regarding the accuracy of delay\nbounds and its impact on the system performance, i.e., scalability and\nresource-efficiency; and the results highlight its outperformance, in\ncomparison to conventional methods."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1605.07888v1", 
    "title": "A Tighter Real-Time Communication Analysis for Wormhole-Switched   Priority-Preemptive NoCs", 
    "arxiv-id": "1605.07888v1", 
    "author": "Stefan M. Petters", 
    "publish": "2016-05-25T13:59:55Z", 
    "summary": "Simulations and runtime measurements are some of the methods which can be\nused to evaluate whether a given NoC-based platform can accommodate application\nworkload and fulfil its timing requirements. Yet, these techniques are often\ntime-consuming, and hence can evaluate only a limited set of scenarios.\nTherefore, these approaches are not suitable for safety-critical and hard\nreal-time systems, where one of the fundamental requirements is to provide\nstrong guarantees that all timing requirements will always be met, even in the\nworst-case conditions. For such systems the analytic-based real-time analysis\nis the only viable approach.\n  In this paper the focus is on the real-time communication analysis for\nwormhole-switched priority-preemptive NoCs. First, we elaborate on the existing\nanalysis and identify one source of pessimism. Then, we propose an extension to\nthe analysis, which efficiently overcomes this limitation, and allows for a\nless pessimistic analysis. Finally, through a comprehensive experimental\nevaluation, we compare the newly proposed approach against the existing one,\nand also observe how the trends change with different traffic parameters."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1605.08353v1", 
    "title": "User Performance in Small Cells Networks with Inter-Cell Mobility", 
    "arxiv-id": "1605.08353v1", 
    "author": "Alain Simonian", 
    "publish": "2016-05-26T16:23:45Z", 
    "summary": "We analyze the impact of intra-cell mobility on user performance in dense\nnetworks such as that enabled by LTE-A and 5G. To this end, we consider a\nhomogeneous network of small cells and first show how to reduce the evaluation\nof user performance to the case of a single representative cell. We then\npropose simple analytical models that capture mobility through the distribution\nof the residual sojourn time of mobile users in the cell. An approximate model,\nbased on Quasi-Stationary (QS) assumptions, is developed in order to speed up\ncomputation in the Markovian framework. We use these models to derive the\naverage throughput of both mobile and static users, along with the probability\nof handover for mobile users. Numerical evaluation and simulation results are\nprovided to assess the accuracy of the proposed models. We show, in particular,\nthat both classes of users benefit from a throughput gain induced by the\n\"opportunistic\" displacement of mobile users among cells."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.00202v2", 
    "title": "OWL: a Reliable Online Watcher for LTE Control Channel Measurements", 
    "arxiv-id": "1606.00202v2", 
    "author": "Joerg Widmer", 
    "publish": "2016-06-01T10:03:13Z", 
    "summary": "Reliable network measurements are a fundamental component of networking\nresearch as they enable network analysis, system debugging, performance\nevaluation and optimization. In particular, decoding the LTE control channel\nwould give access to the full base station traffic at a 1 ms granularity, thus\nallowing for traffic profiling and accurate measurements. Although a few\nopen-source implementations of LTE are available, they do not provide tools to\nreliably decoding the LTE control channel and, thus, accessing the scheduling\ninformation. In this paper, we present OWL, an Online Watcher for LTE that is\nable to decode all the resource blocks in more than 99% of the system frames,\nsignificantly outperforming existing non-commercial prior decoders. Compared to\nprevious attempts, OWL grounds the decoding procedure on information obtained\nfrom the LTE random access mechanism. This makes it possible to run our\nsoftware on inexpensive hardware coupled with almost any software defined radio\ncapable of sampling the LTE signal with sufficient accuracy."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.00396v1", 
    "title": "DINAMITE: A modern approach to memory performance profiling", 
    "arxiv-id": "1606.00396v1", 
    "author": "Alexandra Fedorova", 
    "publish": "2016-06-01T18:52:53Z", 
    "summary": "Diagnosing and fixing performance problems on multicore machines with deep\nmemory hierarchies is extremely challenging. Certain problems are best\naddressed when we can analyze the entire trace of program execution, e.g.,\nevery memory access. Unfortunately such detailed execution logs are very large\nand cannot be analyzed by direct inspection. We present DINAMITE: a toolkit for\nDynamic INstrumentation and Analysis for MassIve Trace Exploration. DINAMITE is\na collection of tools for end-to-end performance analysis: from the LLVM\ncompiler pass that instruments the program to plug-and-play tools that use a\nmodern data analytics engine Spark Streaming for trace introspection. Using\nDINAMITE we found opportunities to improve data layout in several applications\nthat resulted in 15-20% performance improvements and found a shared-variable\nbottleneck in a popular key-value store, whose elimination improved performance\nby 20x."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.01607v1", 
    "title": "CG-OoO: Energy-Efficient Coarse-Grain Out-of-Order Execution", 
    "arxiv-id": "1606.01607v1", 
    "author": "William J. Dally", 
    "publish": "2016-06-06T03:44:52Z", 
    "summary": "We introduce the Coarse-Grain Out-of-Order (CG- OoO) general purpose\nprocessor designed to achieve close to In-Order processor energy while\nmaintaining Out-of-Order (OoO) performance. CG-OoO is an energy-performance\nproportional general purpose architecture that scales according to the program\nload. Block-level code processing is at the heart of the this architecture;\nCG-OoO speculates, fetches, schedules, and commits code at block-level\ngranularity. It eliminates unnecessary accesses to energy consuming tables, and\nturns large tables into smaller and distributed tables that are cheaper to\naccess. CG-OoO leverages compiler-level code optimizations to deliver efficient\nstatic code, and exploits dynamic instruction-level parallelism and block-level\nparallelism. CG-OoO introduces Skipahead issue, a complexity effective, limited\nout-of-order instruction scheduling model. Through the energy efficiency\ntechniques applied to the compiler and processor pipeline stages, CG-OoO closes\n64% of the average energy gap between the In-Order and Out-of-Order baseline\nprocessors at the performance of the OoO baseline. This makes CG-OoO 1.9x more\nefficient than the OoO on the energy-delay product inverse metric."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.02686v3", 
    "title": "A figure of merit for describing the performance of scaling of   parallelization", 
    "arxiv-id": "1606.02686v3", 
    "author": "J\u00f3zsef V\u00e1s\u00e1rhelyi", 
    "publish": "2016-06-08T18:55:10Z", 
    "summary": "With the spread of multi- and many-core processors more and more typical task\nis to re-implement some source code written originally for a single processor\nto run on more than one cores. Since it is a serious investment, it is\nimportant to decide how much efforts pays off, and whether the resulting\nimplementation has as good performability as it could be. The Amdahl's law\nprovides some theoretical upper limits for the performance gain reachable\nthrough parallelizing the code, but it needs the detailed architectural\nknowledge of the program code, does not consider the housekeeping activity\nneeded for parallelization and cannot tell how the actual stage of\nparallelization implementation performs. The present paper suggests a\nquantitative measure for that goal. This figure of merit is derived\nexperimentally, from measured running time, and number of threads/cores. It can\nbe used to quantify the used parallelization technology, the connection between\nthe computing units, the acceleration technology under the given conditions,\ncommunication method within SoC, or the performance of the software\nteam/compiler."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.03571v1", 
    "title": "Universal Routing in Multi-hop Radio Networks", 
    "arxiv-id": "1606.03571v1", 
    "author": "Dariusz R. Kowalski", 
    "publish": "2016-06-11T08:51:52Z", 
    "summary": "In this article we introduce a new model to study stability in multi-hop\nwireless networks in the framework of adversarial queueing. In such a model, a\nrouting protocol consists of three components: a transmission policy, a\nscheduling policy to select the packet to transmit form a set of packets parked\nat a node, and a hearing control mechanism to coordinate transmissions with\nscheduling. For such a setting, we propose a definition of universal stability\nthat takes into account not only the scheduling policies (as in the standard\nwireline adversarial model), but also the transmission policies. First, we show\nthat any scheduling policy that is unstable in the classical wireline\nadversarial model remains unstable in the multi-hop radio network model, even\nin scenarios free of inter- ferences. Then, we show that both SIS and LIS (two\nwell-known universally stable scheduling policies in the wireline adversarial\nmodel) remain stable in the multi-hop radio network model, provided a proactive\nhearing control is used. In contrast, such scheduling policies turn out to be\nunstable when using a reactive hearing control. However, the scheduling policy\nLIS can be enforced to be universally stable provided ties are resolved in a\npermanent manner. Such a situation doesn't hold in the case of SIS, which\nremains unstable regardless of how ties are resolved. Furthermore, for some\ntransmission policies which we call regular, we also show that all scheduling\npolicies that are universally stable when using proactive hearing control\n(which include SIS and LIS) remain universally stable when using reactive\nhearing control."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.05777v3", 
    "title": "A Distributed Algorithm for Training Augmented Complex Adaptive IIR   Filters", 
    "arxiv-id": "1606.05777v3", 
    "author": "Wael M. Bazzi", 
    "publish": "2016-06-18T16:37:13Z", 
    "summary": "In this paper we consider the problem of decentralized (distributed) adaptive\nlearning, where the aim of the network is to train the coefficients of a widely\nlinear autoregressive moving average (ARMA) model by measurements collected by\nthe nodes. Such a problem arises in many sensor network-based applications such\nas target tracking, fast rerouting, data reduction and data aggregation. We\nassume that each node of the network uses the augmented complex adaptive\ninfinite impulse response (ACAIIR) filter as the learning rule, and nodes\ninteract with each other under an incremental mode of cooperation. Since the\nproposed algorithm (incremental augmented complex IIR (IACA-IIR) algorithm)\nrelies on the augmented complex statistics, it can be used to model both types\nof complex-valued signals (proper and improper signals). To evaluate the\nperformance of the proposed algorithm, we use both synthetic and real-world\ncomplex signals in our simulations. The results exhibit superior performance of\nthe proposed algorithm over the non-cooperative ACAIIR algorithm."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1606.09530v1", 
    "title": "Modeling and Predicting DNS Server Load", 
    "arxiv-id": "1606.09530v1", 
    "author": "Zheng Wang", 
    "publish": "2016-06-30T15:07:31Z", 
    "summary": "The DNS relies on caching to ensure high scalability and good performance. In\noptimizing caching, TTL adjustment provides a means of balancing between query\nload and TTL-dependent performances such as data consistency, load balancing,\nmigration time, etc. To gain the desired balance, TTL adjustment depends on\npredictions of query loads under alternative TTLs. This paper proposes a model\nof DNS server load, which employs the uniform aggregate caching model to\nsimplify the complexity of modeling clients' requests and their caching. A\nmethod of predicting DNS server load is developed using that model. The\nprediction method is solely based on the unilateral measurements or\nobservations at authoritative servers. Without reliance on lots of multi-point\nmeasurements nor distributed measuring facilities, the method is best suited\nfor DNS authoritative operators. The proposed model and prediction method are\nvalidated through extensive simulations. Finally, global sensibility analysis\nis conducted to evaluate the impacts of measurement uncertainties or errors on\nthe predictions."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TPDS.2015.2416732", 
    "link": "http://arxiv.org/pdf/1607.00372v1", 
    "title": "Efficient Timeout Synthesis in Fixed-Delay CTMC Using Policy Iteration", 
    "arxiv-id": "1607.00372v1", 
    "author": "Vojt\u011bch \u0158eh\u00e1k", 
    "publish": "2016-07-01T19:56:19Z", 
    "summary": "We consider the fixed-delay synthesis problem for continuous-time Markov\nchains extended with fixed-delay transitions (fdCTMC). The goal is to\nsynthesize concrete values of the fixed-delays (timeouts) that minimize the\nexpected total cost incurred before reaching a given set of target states. The\nsame problem has been considered and solved in previous works by computing an\noptimal policy in a certain discrete-time Markov decision process (MDP) with a\nhuge number of actions that correspond to suitably discretized values of the\ntimeouts.\n  In this paper, we design a symbolic fixed-delay synthesis algorithm which\navoids the explicit construction of large action spaces. Instead, the algorithm\ncomputes a small sets of \"promising\" candidate actions on demand. The candidate\nactions are selected by minimizing a certain objective function by computing\nits symbolic derivative and extracting a univariate polynomial whose roots are\nprecisely the points where the derivative takes zero value. Since roots of high\ndegree univariate polynomials can be isolated very efficiently using modern\nmathematical software, we achieve not only drastic memory savings but also\nspeedup by three orders of magnitude compared to the previous methods."
},{
    "category": "cs.MS", 
    "doi": "10.1145/2935323.2935328", 
    "link": "http://arxiv.org/pdf/1607.01249v1", 
    "title": "TTC: A Tensor Transposition Compiler for Multiple Architectures", 
    "arxiv-id": "1607.01249v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2016-07-05T13:53:57Z", 
    "summary": "We consider the problem of transposing tensors of arbitrary dimension and\ndescribe TTC, an open source domain-specific parallel compiler. TTC generates\noptimized parallel C++/CUDA C code that achieves a significant fraction of the\nsystem's peak memory bandwidth. TTC exhibits high performance across multiple\narchitectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD\nSteamroller), Intel's Knights Corner as well as different CUDA-based GPUs such\nas NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a\nmeaningful baseline implementation generated by external C++ compilers; the\nresults suggest that a domain-specific compiler can outperform its general\npurpose counterpart significantly: For instance, comparing with Intel's latest\nC++ compiler on the Haswell and Knights Corner architecture, TTC yields\nspeedups of up to $8\\times$ and $32\\times$, respectively. We also showcase\nTTC's support for multiple leading dimensions, making it a suitable candidate\nfor the generation of performance-critical packing functions that are at the\ncore of the ubiquitous BLAS 3 routines."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2935323.2935328", 
    "link": "http://arxiv.org/pdf/1607.04077v1", 
    "title": "Designing a High Performance Parallel Personal Cluster", 
    "arxiv-id": "1607.04077v1", 
    "author": "J. M. Sellier", 
    "publish": "2016-07-14T10:41:52Z", 
    "summary": "Today, many scientific and engineering areas require high performance\ncomputing to perform computationally intensive experiments. For example, many\nadvances in transport phenomena, thermodynamics, material properties,\ncomputational chemistry and physics are possible only because of the\navailability of such large scale computing infrastructures. Yet many challenges\nare still open. The cost of energy consumption, cooling, competition for\nresources have been some of the reasons why the scientific and engineering\ncommunities are turning their interests to the possibility of implementing\nenergy-efficient servers utilizing low-power CPUs for computing-intensive\ntasks. In this paper we introduce a novel approach, which was recently\npresented at Linux Conference Europe 2015, based on the Beowulf concept and\nutilizing single board computers (SBC). We present a low-energy consumption\narchitecture capable to tackle heavily demanding scientific computational\nproblems. Additionally, our goal is to provide a low cost personal solution for\nscientists and engineers. In order to evaluate the performance of the proposed\narchitecture we ran several standard benchmarking tests. Furthermore, we assess\nthe reliability of the machine in real life situations by performing two\nbenchmark tools involving practical TCAD for physicist and engineers in the\nsemiconductor industry."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2935323.2935328", 
    "link": "http://arxiv.org/pdf/1607.05356v2", 
    "title": "How to Emulate Web Traffic Using Standard Load Testing Tools", 
    "arxiv-id": "1607.05356v2", 
    "author": "Neil J. Gunther", 
    "publish": "2016-07-18T23:57:15Z", 
    "summary": "Conventional load-testing tools are based on a fifty-year old time-share\ncomputer paradigm where a finite number of users submit requests and respond in\na synchronized fashion. Conversely, modern web traffic is essentially\nasynchronous and driven by an unknown number of users. This difference presents\na conundrum for testing the performance of modern web applications. Even when\nthe difference is recognized, performance engineers often introduce\nmodifications to their test scripts based on folklore or hearsay published in\nvarious Internet fora, much of which can lead to wrong results. We present a\ncoherent methodology, based on two fundamental principles, for emulating web\ntraffic using a standard load-test environment."
},{
    "category": "cs.CR", 
    "doi": "10.1145/3020003", 
    "link": "http://arxiv.org/pdf/1607.05840v1", 
    "title": "Evaluating the Strength of Genomic Privacy Metrics", 
    "arxiv-id": "1607.05840v1", 
    "author": "Isabel Wagner", 
    "publish": "2016-07-20T07:34:17Z", 
    "summary": "The genome is a unique identifier for human individuals. The genome also\ncontains highly sensitive information, creating a high potential for misuse of\ngenomic data (for example, genetic discrimination). In this paper, I\ninvestigated how genomic privacy can be measured in scenarios where an\nadversary aims to infer a person's genomic markers by constructing probability\ndistributions on the values of genetic variations. I measured the strength of\nprivacy metrics by requiring that metrics are monotonic with increasing\nadversary strength and uncovered serious problems with several existing metrics\ncurrently used to measure genomic privacy. I provide suggestions on metric\nselection, interpretation, and visualization, and illustrate the work flow\nusing a case study on Alzheimer's disease."
},{
    "category": "cs.PF", 
    "doi": "10.1145/3020003", 
    "link": "http://arxiv.org/pdf/1607.08102v1", 
    "title": "Statistical Delay Bound for WirelessHART Networks", 
    "arxiv-id": "1607.08102v1", 
    "author": "James Gross", 
    "publish": "2016-07-27T14:15:26Z", 
    "summary": "In this paper we provide a performance analysis framework for wireless\nindustrial networks by deriving a service curve and a bound on the delay\nviolation probability. For this purpose we use the (min,x) stochastic network\ncalculus as well as a recently presented recursive formula for an end-to-end\ndelay bound of wireless heterogeneous networks. The derived results are mapped\nto WirelessHART networks used in process automation and were validated via\nsimulations. In addition to WirelessHART, our results can be applied to any\nwireless network whose physical layer conforms the IEEE 802.15.4 standard,\nwhile its MAC protocol incorporates TDMA and channel hopping, like e.g.\nISA100.11a or TSCH-based networks. The provided delay analysis is especially\nuseful during the network design phase, offering further research potential\ntowards optimal routing and power management in QoS-constrained wireless\nindustrial networks."
},{
    "category": "cs.DC", 
    "doi": "10.1109/SYNASC.2016.062", 
    "link": "http://arxiv.org/pdf/1607.08344v1", 
    "title": "AUGURY: A time-series based application for the analysis and forecasting   of system and network performance metrics", 
    "arxiv-id": "1607.08344v1", 
    "author": "Manuela Wiesinger-Widi", 
    "publish": "2016-07-28T08:02:29Z", 
    "summary": "This paper presents AUGURY, an application for the analysis of monitoring\ndata from computers, servers or cloud infrastructures. The analysis is based on\nthe extraction of patterns and trends from historical data, using elements of\ntime-series analysis. The purpose of AUGURY is to aid a server administrator by\nforecasting the behaviour and resource usage of specific applications and in\npresenting a status report in a concise manner. AUGURY provides tools for\nidentifying network traffic congestion and peak usage times, and for making\nmemory usage projections. The application data processing specialises in two\ntasks: the parametrisation of the memory usage of individual applications and\nthe extraction of the seasonal component from network traffic data. AUGURY uses\na different underlying assumption for each of these two tasks. With respect to\nthe memory usage, a limited number of single-valued parameters are assumed to\nbe sufficient to parameterize any application being hosted on the server.\nRegarding the network traffic data, long-term patterns, such as hourly or daily\nexist and are being induced by work-time schedules and automatised\nadministrative jobs. In this paper, the implementation of each of the two tasks\nis presented, tested using locally-generated data, and applied to data from\nweather forecasting applications hosted on a web server. This data is used to\ndemonstrate the insight that AUGURY can add to the monitoring of server and\ncloud infrastructures."
},{
    "category": "cs.PF", 
    "doi": "10.1109/SYNASC.2016.062", 
    "link": "http://arxiv.org/pdf/1608.00120v3", 
    "title": "Delay and Backlog Analysis for 60 GHz Wireless Networks", 
    "arxiv-id": "1608.00120v3", 
    "author": "Yongming Huang", 
    "publish": "2016-07-30T13:38:35Z", 
    "summary": "To meet the ever-increasing demands on higher throughput and better network\ndelay performance, 60 GHZ networking is proposed as a promising solution for\nthe next generation of wireless communications. To successfully deploy such\nnetworks, its important to understand their performance first. However, due to\nthe unique fading characteristic of the 60 GHz channel, the characterization of\nthe corresponding service process, offered by the channel, using the\nconventional methodologies may not be tractable. In this work, we provide an\nalternative approach to derive a closed-form expression that characterizes the\ncumulative service process of the 60 GHz channel in terms of the moment\ngenerating function (MGF) of its instantaneous channel capacity. We then use\nthis expression to derive probabilistic upper bounds on the backlog and delay\nthat are experienced by a flow traversing this network, using results from the\nMGF-based network calculus. The computed bounds are validated using simulation.\nWe provide numerical results for different networking scenarios and for\ndifferent traffic and channel parameters and we show that the 60 GHz wireless\nnetwork is capable of satisfying stringent quality-of-Service (QoS)\nrequirements, in terms of network delay and reliability. With this analysis\napproach at hand, a larger scale 60 GHz network design and optimization is\npossible."
},{
    "category": "cs.CR", 
    "doi": "10.1109/SYNASC.2016.062", 
    "link": "http://arxiv.org/pdf/1608.00669v1", 
    "title": "Improving Zero-Day Malware Testing Methodology Using Statistically   Significant Time-Lagged Test Samples", 
    "arxiv-id": "1608.00669v1", 
    "author": "Joshua Saxe", 
    "publish": "2016-08-02T01:33:23Z", 
    "summary": "Enterprise networks are in constant danger of being breached by\ncyber-attackers, but making the decision about what security tools to deploy to\nmitigate this risk requires carefully designed evaluation of security products.\nOne of the most important metrics for a protection product is how well it is\nable to stop malware, specifically on \"zero\"-day malware that has not been seen\nby the security community before. However, evaluating zero-day performance is\ndifficult, because of larger number of previously unseen samples that are\nneeded to properly measure the true and false positive rate, and the challenges\ninvolved in accurately labeling these samples. This paper addresses these\nissues from a statistical and practical perspective. Our contributions include\nfirst showing that the number of benign files needed for proper evaluation is\non the order of a millions, and the number of malware samples needed is on the\norder of tens of thousands. We then propose and justify a time-delay method for\neasily collecting large number of previously unseen, but labeled, samples. This\nenables cheap and accurate evaluation of zero-day true and false positive\nrates. Finally, we propose a more fine-grain labeling of the malware/benignware\nin order to better model the heterogeneous distribution of files on various\nnetworks."
},{
    "category": "cs.NI", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.00855v1", 
    "title": "An Enhanced Buffer Management Scheme for Multimedia Traffic in HSDPA", 
    "arxiv-id": "1608.00855v1", 
    "author": "Khalid Al-Begain", 
    "publish": "2016-08-02T15:00:01Z", 
    "summary": "High Speed Downlink Packet Access (HSDPA) was introduced to UMTS radio access\nsegment to provide higher capacity for new packet switched services. As a\nresult, packet switched sessions with multiple diverse traffic flows such as\nconcurrent voice and data, or video and data being transmitted to the same user\nare a likely commonplace cellular packet data scenario. In HSDPA, Radio Access\nNetwork (RAN) buffer management schemes are essential to support the end-to-end\nQoS of such sessions. Hence in this paper we present the end-to-end performance\nstudy of a proposed RAN buffer management scheme for multi-flow sessions via\ndynamic system-level HSDPA simulations. The scheme is an enhancement of a\nTime-Space Priority (TSP)queuing strategy applied to the Node B MAC-hs buffer\nallocated to an end user with concurrent real-time (RT) and non-real-time (NRT)\nflows during a multi-flow session. The experimental multiflow scenario is a\npacket voice call with concurrent TCP-based file download to the same user.\nResults show that with the proposed enhancements to the TSP-based RAN buffer\nmanagement,end-to-end QoS performance gains accrue to the NRT flow without\ncompromising RT flow QoS of the same end user session."
},{
    "category": "cs.NI", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.01021v1", 
    "title": "Analysis of M2/M2/1/R,N Queuing Model for Multimedia over 3.5G Wireless   Network Downlink", 
    "arxiv-id": "1608.01021v1", 
    "author": "Khalid Al-Begain", 
    "publish": "2016-08-02T22:43:40Z", 
    "summary": "Analysis of an M2/M2/1/R, N queuing model for the multimedia transmission\nover HSDPA/3.5G downlink is presented. The queue models the downlink buffer\nwith source multimedia traffic streams comprising two classes of flows:\nrealtime and non real-time. Time priority is accorded to the real-time flows\nwhile the non real-time flows are given buffer space priority. An analytic\nevaluation of the impact of varying the buffer partition threshold on the QoS\nperformance of both classes of customers is undertaken. The results are\nvalidated with a discrete event simulation model developed in C language.\nFinally, a cost function for the joint optimization of the traffic QoS\nparameters is derived."
},{
    "category": "cs.PF", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.01023v1", 
    "title": "End-to-End QoS Improvement of HSDPA End-User Multi-flow Traffic Using   RAN Buffer Management", 
    "arxiv-id": "1608.01023v1", 
    "author": "Khalid Al-Begain", 
    "publish": "2016-08-02T22:53:13Z", 
    "summary": "High Speed Downlink Packet Access (HSDPA) was introduced to UMTS radio access\nsegment to provide higher capacity for new packet switched services. As a\nresult, packet switched sessions with multiple diverse traffic flows such as\nconcurrentvoice and data, or video and data being transmitted to the same user\nare a likely commonplace cellular packet data scenario. In HSDPA, Radio Access\nNetwork (RAN) buffer management schemes are essential to support the end-to-end\nQoS of such sessions. Hence in this paper we present the end-to-end performance\nstudy of a proposed RAN buffer management scheme for multi-flow sessions via\ndynamic system-level HSDPA simulations. The scheme is an enhancement of a\nTime-Space Priority (TSP)queuing strategy applied to the Node B MAC-hs buffer\nallocated to an end user with concurrent real-time (RT) and non-real-time (NRT)\nflows during a multi-flow session. The experimental multiflow scenario is a\npacket voice call with concurrent TCP-based file download to the same user.\nResults show that with the proposed enhancements to the TSP-based RAN buffer\nmanagement, end-to-end QoS performance gains accrue to the NRT flow without\ncompromising RT flow QoS of the same end user session."
},{
    "category": "cs.PF", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.02191v2", 
    "title": "Power-Minimization under Statistical Delay Constraints for Multi-Hop   Wireless Industrial Networks", 
    "arxiv-id": "1608.02191v2", 
    "author": "James Gross", 
    "publish": "2016-08-07T07:56:22Z", 
    "summary": "The increased deployment of wireless networks for battery-limited industrial\napplications in recent years highlights the need for tractable performance\nanalysis and efficient QoS-aware transmit power management schemes. Modern\nindustrial solutions deploy multi-hop topologies in order to bridge larger\ndistances without necessarily shortening nodes' battery lifetime. This poses a\nsignificant challenge, as multi-hop analysis for heterogeneous wireless\nnetworks does not exist prior to our work. We overcome this challenge by\nextending a newly developed methodology based on (min,x) network calculus and\nprovide a closed-form expression for the end-to-end delay violation probability\nover a cascade of heterogeneous buffered wireless fading channels. We further\ndesign model-based algorithms for power-minimization and network lifetime\nmaximization which compute the optimal transmit power per node, along a\nQoS-constrained path. Our numerical study shows an overall transmit power\nsavings of up to 95% when compared to a fixed power allocation. We also apply\nour algorithm to a realistic WirelessHART network setup and observe that link\nheterogeneity can significantly influence network lifetime when no efficient\npower management is applied. This work is especially useful for battery-powered\nwireless sensor nodes in QoS-constrained applications and offers a solid\nframework for network design and performance analysis of heterogeneous\nmulti-hop wireless industrial networks."
},{
    "category": "cs.PF", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.02800v1", 
    "title": "LITMUS: An Open Extensible Framework for Benchmarking RDF Data   Management Solutions", 
    "arxiv-id": "1608.02800v1", 
    "author": "Maria-Esther Vidal", 
    "publish": "2016-08-09T13:40:59Z", 
    "summary": "Developments in the context of Open, Big, and Linked Data have led to an\nenormous growth of structured data on the Web. To keep up with the pace of\nefficient consumption and management of the data at this rate, many data\nManagement solutions have been developed for specific tasks and applications.\nWe present LITMUS, a framework for benchmarking data management solutions.\nLITMUS goes beyond classical storage benchmarking frameworks by allowing for\nanalysing the performance of frameworks across query languages. In this\nposition paper we present the conceptual architecture of LITMUS as well as the\nconsiderations that led to this architecture."
},{
    "category": "math.PR", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.03070v1", 
    "title": "Optimal routing in two-queue polling systems", 
    "arxiv-id": "1608.03070v1", 
    "author": "A. A. J Lefeber", 
    "publish": "2016-08-10T07:56:36Z", 
    "summary": "We consider a polling system with two queues, exhaustive service, no\nswitch-over times and exponential service times. The waiting cost depends on\nthe position of the queue relative to the server: It costs a customer c per\ntime unit to wait in the busy queue (where the server is) and d per time unit\nin the idle queue (where no server is). Customers arrive according to a Poisson\nprocess. We study the control problem of how arrivals should be routed to the\ntwo queues in order to minimize expected waiting costs and characterize\nindividually and socially optimal routing policies under three scenarios of\navailable information at decision epochs: no, partial and complete information.\nIn the complete information case, we develop a new iterative algorithm to\ndetermine individually optimal policies, and show that such policies can be\ndescribed by a switching curve. We conjecture that a linear switching curve is\nsocially optimal, and prove that this policy is indeed optimal for the fluid\nversion of the two-queue polling system."
},{
    "category": "cs.NI", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.04024v1", 
    "title": "A Non-stationary Service Curve Model for Estimation of Cellular Sleep   Scheduling", 
    "arxiv-id": "1608.04024v1", 
    "author": "Markus Fidler", 
    "publish": "2016-08-13T20:27:59Z", 
    "summary": "While steady-state solutions of backlog and delay have been derived for\nessential wireless systems, the analysis of transient phases still poses\nsignificant challenges. Considering the majority of short-lived and interactive\nflows, transient startup effects, as caused by sleep scheduling in cellular\nnetworks, have, however, a substantial impact on the performance. To facilitate\nreasoning about the transient behavior of systems, this paper contributes a\nnotion of non-stationary service curves. Models of systems with sleep\nscheduling are derived and transient backlogs and delays are analyzed. Further,\nmeasurement methods that estimate the service of an unknown system from\nobservations of selected probe traffic are developed. Fundamental limitations\nof existing measurement methods are explained by the non-convexity of the\ntransient service and further difficulties are shown to be due to the\nsuper-additivity of network service processes. A novel two-phase probing\ntechnique is devised that first determines the shape of a minimal probe and\nsubsequently obtains an accurate estimate of the unknown service. In a\ncomprehensive measurement campaign, the method is used to evaluate the service\nof cellular networks with sleep scheduling (2G, 3G, and 4G), revealing\nconsiderable transient backlog and delay overshoots that persist for long\nrelaxation times."
},{
    "category": "cs.CR", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.04116v2", 
    "title": "An Efficient, Secure and Trusted Channel Protocol for Avionics Wireless   Networks", 
    "arxiv-id": "1608.04116v2", 
    "author": "Serge Chaumette", 
    "publish": "2016-08-14T17:10:07Z", 
    "summary": "Avionics networks rely on a set of stringent reliability and safety\nrequirements. In existing deployments, these networks are based on a wired\ntechnology, which supports these requirements. Furthermore, this technology\nsimplifies the security management of the network since certain assumptions can\nbe safely made, including the inability of an attacker to access the network,\nand the fact that it is almost impossible for an attacker to introduce a node\ninto the network. The proposal for Avionics Wireless Networks (AWNs), currently\nunder development by multiple aerospace working groups, promises a reduction in\nthe complexity of electrical wiring harness design and fabrication, a reduction\nin the total weight of wires, increased customization possibilities, and the\ncapacity to monitor otherwise inaccessible moving or rotating aircraft parts\nsuch as landing gear and some sections of the aircraft engines. While providing\nthese benefits, the AWN must ensure that it provides levels of safety that are\nat minimum equivalent to those offered by the wired equivalent. In this paper,\nwe propose a secure and trusted channel protocol that satisfies the stated\nsecurity and operational requirements for an AWN protocol. There are three main\nobjectives for this protocol. First, the protocol has to provide the assurance\nthat all communicating entities can trust each other, and can trust their\ninternal (secure) software and hardware states. Second, the protocol has to\nestablish a fair key exchange between all communicating entities so as to\nprovide a secure channel. Finally, the third objective is to be efficient for\nboth the initial start-up of the network and when resuming a session after a\ncold and/or warm restart of a node. The proposed protocol is implemented and\nperformance measurements are presented based on this implementation. In\naddition, we formally verify our proposed protocol using CasperFDR."
},{
    "category": "cs.MS", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1608.08658v2", 
    "title": "Devito: automated fast finite difference computation", 
    "arxiv-id": "1608.08658v2", 
    "author": "Gerard Gorman", 
    "publish": "2016-08-30T21:05:21Z", 
    "summary": "Domain specific languages have successfully been used in a variety of fields\nto cleanly express scientific problems as well as to simplify implementation\nand performance opti- mization on different computer architectures. Although a\nlarge number of stencil languages are available, finite differ- ence domain\nspecific languages have proved challenging to design because most practical use\ncases require additional features that fall outside the finite difference\nabstraction. Inspired by the complexity of real-world seismic imaging problems,\nwe introduce Devito, a domain specific language in which high level equations\nare expressed using symbolic expressions from the SymPy package. Complex\nequations are automatically manipulated, optimized, and translated into highly\noptimized C code that aims to perform compa- rably or better than hand-tuned\ncode. All this is transpar- ent to users, who only see concise symbolic\nmathematical expressions."
},{
    "category": "cs.MS", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.03361v1", 
    "title": "Devito: Towards a generic Finite Difference DSL using Symbolic Python", 
    "arxiv-id": "1609.03361v1", 
    "author": "Gerard Gorman", 
    "publish": "2016-09-12T12:15:36Z", 
    "summary": "Domain specific languages (DSL) have been used in a variety of fields to\nexpress complex scientific problems in a concise manner and provide automated\nperformance optimization for a range of computational architectures. As such\nDSLs provide a powerful mechanism to speed up scientific Python computation\nthat goes beyond traditional vectorization and pre-compilation approaches,\nwhile allowing domain scientists to build applications within the comforts of\nthe Python software ecosystem. In this paper we present Devito, a new finite\ndifference DSL that provides optimized stencil computation from high-level\nproblem specifications based on symbolic Python expressions. We demonstrate\nDevito's symbolic API and performance advantages over traditional Python\nacceleration methods before highlighting its use in the scientific context of\nseismic inversion problems."
},{
    "category": "cs.PF", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.04603v1", 
    "title": "Automating Large-Scale Simulation and Data Analysis with OMNeT++:   Lession Learned and Future Perspectives", 
    "arxiv-id": "1609.04603v1", 
    "author": "Giovanni Nardini", 
    "publish": "2016-09-15T12:41:41Z", 
    "summary": "Simulation is widely adopted in the study of modern computer networks. In\nthis context, OMNeT++ provides a set of very effective tools that span from the\ndefinition of the network, to the automation of simulation execution and quick\nresult representation. However, as network models become more and more complex\nto cope with the evolution of network systems, the amount of simulation\nfactors, the number of simulated nodes and the size of results grow\nconsequently, leading to simulations with larger scale. In this work, we\nperform a critical analysis of the tools provided by OMNeT++ in case of such\nlarge-scale simulations. We then propose a unified and flexible software\narchitecture to support simulation automation."
},{
    "category": "cs.NI", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.05198v1", 
    "title": "Stacked-VLAN-Based Modeling of Hybrid ISP Traffic Control Schemes and   Service Plans Exploiting Excess Bandwidth in Shared Access Networks", 
    "arxiv-id": "1609.05198v1", 
    "author": "Kyeong Soo Kim", 
    "publish": "2016-09-16T19:52:29Z", 
    "summary": "The current practice of shaping subscriber traffic using a token bucket\nfilter by Internet service providers may result in a severe waste of network\nresources in shared access networks; except for a short period of time\nproportional to the size of a token bucket, it cannot allocate excess bandwidth\namong active subscribers even when there are only a few active subscribers. To\nbetter utilize the network resources in shared access networks, therefore, we\nrecently proposed and analyzed the performance of access traffic control\nschemes, which can allocate excess bandwidth among active subscribers\nproportional to their token generation rates. Also, to exploit the excess\nbandwidth allocation enabled by the proposed traffic control schemes, we have\nbeen studying flexible yet practical service plans under a hybrid traffic\ncontrol architecture, which are attractive to both an Internet service provider\nand its subscribers in terms of revenue and quality of service. In this paper\nwe report the current status of our modeling of the hybrid traffic control\nschemes and service plans with OMNeT++/INET-HNRL based on IEEE standard 802.1Q\nstacked VLANs."
},{
    "category": "cs.PF", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.05750v1", 
    "title": "Infinite Server Queueing Networks with Deadline Based Routing", 
    "arxiv-id": "1609.05750v1", 
    "author": "Nicholas Bambos", 
    "publish": "2016-09-16T06:09:55Z", 
    "summary": "Motivated by timeouts in Internet services, we consider networks of infinite\nserver queues in which routing decisions are based on deadlines. Specifically,\nat each node in the network, the total service time equals the minimum of\nseveral independent service times (e.g. the minimum of the amount of time\nrequired to complete a transaction and a deadline). Furthermore, routing\ndecisions depend on which of the independent service times achieves the minimum\n(e.g. exceeding a deadline will require the customer to be routed so they can\nre-attempt the transaction). Because current routing decisions are dependent on\npast service times, much of the existing theory on product-form queueing\nnetworks does not apply. In spite of this, we are able to show that such\nnetworks have product-form equilibrium distributions. We verify our analytic\ncharacterization with a simulation of a simple network. We also discuss\nextensions of this work to more general settings."
},{
    "category": "cs.MM", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.06109v1", 
    "title": "FPGA implementation of the procedures for video quality assessment", 
    "arxiv-id": "1609.06109v1", 
    "author": "Kazimierz Wiatr", 
    "publish": "2016-09-20T11:27:16Z", 
    "summary": "Video resolutions used in variety of media are constantly rising. While\nmanufacturers struggle to perfect their screens it also important to ensure\nhigh quality of displayed image. Overall quality can be measured using Mean\nOpinion Score (MOS). Video quality can be affected by miscellaneous artifacts,\nappearing at every stage of video creation and transmission. In this paper we\npresent a solution to calculate four distinct video quality metrics that can be\napplied to a real time video quality assessment system. Our assessment module\nis capable of processing 8K resolution in real time manner set at the level of\n30 frames per second. Throughput of 2.19 GB/s surpasses performance of\npuresoftware solutions. To concentrate on architectural optimization module was\ncreated using high level language."
},{
    "category": "cs.NI", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.07629v1", 
    "title": "Proceedings of the 3rd OMNeT++ Community Summit, Brno University of   Technology - Czech Republic, September 15-16, 2016", 
    "arxiv-id": "1609.07629v1", 
    "author": "Michael Kirsche", 
    "publish": "2016-09-24T14:47:00Z", 
    "summary": "These are the Proceedings of the 3rd OMNeT++ Community Summit, which was held\nat the University of Technology in Brno - Czech Republic - on September 15-16,\n2016."
},{
    "category": "math.PR", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.07996v1", 
    "title": "An Infinite Dimensional Model for A Single Server Priority Queue", 
    "arxiv-id": "1609.07996v1", 
    "author": "Nicholas Bambos", 
    "publish": "2016-09-26T14:49:07Z", 
    "summary": "We consider a Markovian single server queue in which customers are\npreemptively scheduled by exogenously assigned priority levels. The novelty in\nour model is that the priority levels are randomly assigned from a continuous\nprobability measure rather than a discrete one. Because the priority levels are\ndrawn from a continuum, the queue is modeled by a measure-valued stochastic\nprocess. We analyze the steady state behavior of this process and provide\nseveral results. We derive a measure that describes the average distribution of\ncustomer priority levels in the system; we provide a formula for the expected\nsojourn time of a customer as a function of his priority level; and we provide\na formula for the expected waiting time of a customer as a function of his\npriority level. We interpret these quantitative results and give a qualitative\nunderstanding of how the priority levels affect individual customers as well as\nhow they affect the system as a whole. The theoretical analysis is verified by\nsimulation. We also discuss some directions of future work."
},{
    "category": "cs.PF", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.09294v1", 
    "title": "DynIMS: A Dynamic Memory Controller for In-memory Storage on HPC Systems", 
    "arxiv-id": "1609.09294v1", 
    "author": "Pradip K Srimani", 
    "publish": "2016-09-29T10:41:26Z", 
    "summary": "In order to boost the performance of data-intensive computing on HPC systems,\nin-memory computing frameworks, such as Apache Spark and Flink, use local DRAM\nfor data storage. Optimizing the memory allocation to data storage is critical\nto delivering performance to traditional HPC compute jobs and throughput to\ndata-intensive applications sharing the HPC resources. Current practices that\nstatically configure in-memory storage may leave inadequate space for compute\njobs or lose the opportunity to utilize more available space for data-intensive\napplications. In this paper, we explore techniques to dynamically adjust\nin-memory storage and make the right amount of space for compute jobs. We have\ndeveloped a dynamic memory controller, DynIMS, which infers memory demands of\ncompute tasks online and employs a feedback-based control model to adapt the\ncapacity of in-memory storage. We test DynIMS using mixed HPCC and Spark\nworkloads on a HPC cluster. Experimental results show that DynIMS can achieve\nup to 5X performance improvement compared to systems with static memory\nallocations."
},{
    "category": "cs.NI", 
    "doi": "10.1109/NGMAST.2007.4343435", 
    "link": "http://arxiv.org/pdf/1609.09682v1", 
    "title": "Soft Cache Hits and the Impact of Alternative Content Recommendations on   Mobile Edge Caching", 
    "arxiv-id": "1609.09682v1", 
    "author": "Pavlos Sermpezis", 
    "publish": "2016-09-30T11:52:42Z", 
    "summary": "Caching popular content at the edge of future mobile networks has been widely\nconsidered in order to alleviate the impact of the data tsunami on both the\naccess and backhaul networks. A number of interesting techniques have been\nproposed, including femto-caching and \"delayed\" or opportunistic cache access.\nNevertheless, the majority of these approaches suffer from the rather limited\nstorage capacity of the edge caches, compared to the tremendous and rapidly\nincreasing size of the Internet content catalog. We propose to depart from the\nassumption of hard cache misses, common in most existing works, and consider\n\"soft\" cache misses, where if the original content is not available, an\nalternative content that is locally cached can be recommended. Given that\nInternet content consumption is increasingly entertainment-oriented, we believe\nthat a related content could often lead to complete or at least partial user\nsatisfaction, without the need to retrieve the original content over expensive\nlinks. In this paper, we formulate the problem of optimal edge caching with\nsoft cache hits, in the context of delayed access, and analyze the expected\ngains. We then show using synthetic and real datasets of related video contents\nthat promising caching gains could be achieved in practice."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1609.09726v1", 
    "title": "Revisiting 802.11 Rate Adaptation from Energy Consumption's Perspective", 
    "arxiv-id": "1609.09726v1", 
    "author": "Albert Banchs", 
    "publish": "2016-09-30T13:39:54Z", 
    "summary": "Rate adaptation in 802.11 WLANs has received a lot of attention from the\nresearch community, with most of the proposals aiming at maximising throughput\nbased on network conditions. Considering energy consumption, an implicit\nassumption is that optimality in throughput implies optimality in energy\nefficiency, but this assumption has been recently put into question. In this\npaper, we address via analysis and experimentation the relation between\nthroughput performance and energy efficiency in multi-rate 802.11 scenarios. We\ndemonstrate the trade-off between these performance figures, confirming that\nthey may not be simultaneously optimised, and analyse their sensitivity towards\nthe energy consumption parameters of the device. Our results provide the means\nto design novel rate adaptation schemes that takes energy consumption into\naccount."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1610.00149v1", 
    "title": "Data-Unit-Size Distribution Model with Retransmitted Packet Size   Preservation Property and Its Application to Goodput Analysis for   Stop-and-Wait Protocol: Case of Independent Packet Losses", 
    "arxiv-id": "1610.00149v1", 
    "author": "Takashi Ikegawa", 
    "publish": "2016-10-01T15:29:52Z", 
    "summary": "This paper proposes a data-unit-size distribution model to represent the\nretransmitted packet size preservation (RPSP) property in a scenario where\nindependently lost packets are retransmitted by a stop-and-wait protocol. RPSP\nmeans that retransmitted packets with the same sequence number are equal in\nsize to the packet of the original transmission, which is identical to the\npacket generated from a message through the segmentation function, namely,\ngenerated packet. Furthermore, we derive goodput formula using an approach to\nderive the data-unit-size distribution. We investigate the effect of RPSP on\nframe size distributions and goodput in a simple case when no collision happens\nover the bit-error prone wireless network equipped with IEEE 802.11 Distributed\nCoordination Function, which is a typical example of the stop-and-wait\nprotocol. Numerical results show that the effect gets stronger as bit error\nrate increases and the maximum size of the generated packets is larger than the\nmean size for large enough packet retry limits because longer packets will be\nrepeatedly corrupted and retransmitted more times as a result of RPSP."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1610.04260v1", 
    "title": "Cost minimization of network services with buffer and end-to-end   deadline constraints", 
    "arxiv-id": "1610.04260v1", 
    "author": "Johan Eker", 
    "publish": "2016-09-15T11:30:42Z", 
    "summary": "Cloud computing technology provides the means to share physical resources\namong multiple users and data center tenants by exposing them as virtual\nresources. There is a strong industrial drive to use similar technology and\nconcepts to provide timing sensitive services. One such is virtual networking\nservices, so called services chains, which consist of several interconnected\nvirtual network functions. This allows for the capacity to be scaled up and\ndown by adding or removing virtual resources. In this work, we develop a model\nof a service chain and pose the dynamic allocation of resources as an\noptimization problem. We design and present a set of strategies to allot\nvirtual network nodes in an optimal fashion subject to latency and buffer\nconstraints."
},{
    "category": "cs.HC", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1610.04429v1", 
    "title": "Tuning Crowdsourced Human Computation", 
    "arxiv-id": "1610.04429v1", 
    "author": "H. V. Jagadish", 
    "publish": "2016-10-14T12:26:18Z", 
    "summary": "As the use of crowdsourcing increases, it is important to think about\nperformance optimization. For this purpose, it is possible to think about each\nworker as a HPU(Human Processing Unit), and to draw inspiration from\nperformance optimization on traditional computers or cloud nodes with CPUs.\nHowever, as we characterize HPUs in detail for this purpose, we find that there\nare important differences between CPUs and HPUs, leading to the need for\ncompletely new optimization algorithms.\n  In this paper, we study the specific optimization problem of obtaining\nresults fastest for a crowd sourced job with a fixed total budget. In\ncrowdsourcing, jobs are usually broken down into sets of small tasks, which are\nassigned to workers one at a time. We consider three scenarios of increasing\ncomplexity: Identical Round Homogeneous tasks, Multiplex Round Homogeneous\ntasks, and Multiple Round Heterogeneous tasks. For each scenario, we analyze\nthe stochastic behavior of the HPU clock-rate as a function of the remuneration\noffered. After that, we develop an optimum Budget Allocation strategy to\nminimize the latency for job completion. We validate our results through\nextensive simulations and experiments on Amazon Mechanical Turk."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1610.04919v1", 
    "title": "Power Control for Packet Streaming with Head-of-Line Deadlines", 
    "arxiv-id": "1610.04919v1", 
    "author": "Nicholas Bambos", 
    "publish": "2016-10-16T21:33:57Z", 
    "summary": "We consider a mathematical model for streaming media packets (as the\nmotivating key example) from a transmitter buffer to a receiver over a wireless\nlink while controlling the transmitter power (hence, the packet/job processing\nrate). When each packet comes to the head-of-line (HOL) in the buffer, it is\ngiven a deadline $D$ which is the maximum number of times the transmitter can\nattempt retransmission in order to successfully transmit the packet. If this\nnumber of transmission attempts is exhausted, the packet is ejected from the\nbuffer and the next packet comes to the HOL. Costs are incurred in each time\nslot for holding packets in the buffer, expending transmitter power, and\nejecting packets which exceed their deadlines. We investigate how transmission\npower should be chosen so as to minimize the total cost of transmitting the\nitems in the buffer. We formulate the optimal power control problem in a\ndynamic programming framework and then hone in on the special case of fixed\ninterference. For this special case, we are able to provide a precise analytic\ncharacterization of how the power control should vary with the backlog and how\nthe power control should react to approaching deadlines. In particular, we show\nmonotonicity results for how the transmitter should adapt power levels to the\nbacklog and approaching deadlines. We leverage these analytic results from the\nspecial case to build a power control scheme for the general case. Monte Carlo\nsimulations are used to evaluate the performance of the resulting power control\nscheme as compared to the optimal scheme. The resulting power control scheme is\nsub-optimal but it provides a low-complexity approximation of the optimal power\ncontrol. Simulations show that our proposed schemes outperform benchmark\nalgorithms. We also discuss applications of the model to other practical\noperational scenarios."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1610.04982v2", 
    "title": "D2D-U: Device-to-Device Communications in Unlicensed Bands for 5G and   Beyond", 
    "arxiv-id": "1610.04982v2", 
    "author": "Lingyang Song", 
    "publish": "2016-10-17T06:32:03Z", 
    "summary": "Device-to-Device (D2D) communication, which enables direct communication\nbetween nearby mobile devices, is an attractive add-on component to improve\nspectrum efficiency and user experience by reusing licensed cellular spectrum\nin 5G system. In this paper, we propose to enable D2D communication in\nunlicensed spectrum (D2D-U) as an underlay of the uplink LTE network for\nfurther booming the network capacity. A sensing-based protocol is designed to\nsupport the unlicensed channel access for both LTE and D2D users. We further\ninvestigate the subchannel allocation problem to maximize the sum rate of LTE\nand D2D users while taking into account their interference to the existing\nWi-Fi systems. Specifically, we formulate the subchannel allocation as a\nmany-to-many matching problem with externalities, and develop an iterative\nuser-subchannel swap algorithm. Analytical and simulation results show that the\nproposed D2D-U scheme can significantly improve the system sum-rate."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2988287.2989149", 
    "link": "http://arxiv.org/pdf/1610.06309v1", 
    "title": "Non-Asymptotic Delay Bounds for Multi-Server Systems with   Synchronization Constraints", 
    "arxiv-id": "1610.06309v1", 
    "author": "Yuming Jiang", 
    "publish": "2016-10-20T07:39:23Z", 
    "summary": "Multi-server systems have received increasing attention with important\nimplementations such as Google MapReduce, Hadoop, and Spark. Common to these\nsystems are a fork operation, where jobs are first divided into tasks that are\nprocessed in parallel, and a later join operation, where completed tasks wait\nuntil the results of all tasks of a job can be combined and the job leaves the\nsystem. The synchronization constraint of the join operation makes the analysis\nof fork-join systems challenging and few explicit results are known. In this\nwork, we model fork-join systems using a max-plus server model that enables us\nto derive statistical bounds on waiting and sojourn times for general arrival\nand service time processes. We contribute end-to-end delay bounds for\nmulti-stage fork-join networks that grow in $\\mathcal{O}(h \\ln k)$ for $h$\nfork-join stages, each with $k$ parallel servers. We perform a detailed\ncomparison of different multi-server configurations and highlight their pros\nand cons. We also include an analysis of single-queue fork-join systems that\nare non-idling and achieve a fundamental performance gain, and compare these\nresults to both simulation and a live Spark system."
},{
    "category": "cs.MA", 
    "doi": "10.4204/EPTCS.227.3", 
    "link": "http://arxiv.org/pdf/1610.08168v1", 
    "title": "Location Aggregation of Spatial Population CTMC Models", 
    "arxiv-id": "1610.08168v1", 
    "author": "Cheng Feng", 
    "publish": "2016-10-26T05:00:16Z", 
    "summary": "In this paper we focus on spatial Markov population models, describing the\nstochastic evolution of populations of agents, explicitly modelling their\nspatial distribution, representing space as a discrete, finite graph. More\nspecifically, we present a heuristic approach to aggregating spatial locations,\nwhich is designed to preserve the dynamical behaviour of the model whilst\nreducing the computational cost of analysis. Our approach combines stochastic\napproximation ideas (moment closure, linear noise), with computational\nstatistics (spectral clustering) to obtain an efficient aggregation, which is\nexperimentally shown to be reasonably accurate on two case studies: an instance\nof epidemic spreading and a London bike sharing scenario."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1610.08172v1", 
    "title": "Evaluating load balancing policies for performance and energy-efficiency", 
    "arxiv-id": "1610.08172v1", 
    "author": "Boudewijn R. Haverkort", 
    "publish": "2016-10-26T05:00:54Z", 
    "summary": "Nowadays, more and more increasingly hard computations are performed in\nchallenging fields like weather forecasting, oil and gas exploration, and\ncryptanalysis. Many of such computations can be implemented using a computer\ncluster with a large number of servers. Incoming computation requests are then,\nvia a so-called load balancing policy, distributed over the servers to ensure\noptimal performance. Additionally, being able to switch-off some servers during\nlow period of workload, gives potential to reduced energy consumption.\nTherefore, load balancing forms, albeit indirectly, a trade-off between\nperformance and energy consumption. In this paper, we introduce a syntax for\nload-balancing policies to dynamically select a server for each request based\non relevant criteria, including the number of jobs queued in servers, power\nstates of servers, and transition delays between power states of servers. To\nevaluate many policies, we implement two load balancers in: (i) iDSL, a\nlanguage and tool-chain for evaluating service-oriented systems, and (ii) a\nsimulation framework in AnyLogic. Both implementations are successfully\nvalidated by comparison of the results."
},{
    "category": "math.PR", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1611.00745v1", 
    "title": "Optimal Heavy-Traffic Queue Length Scaling in an Incompletely Saturated   Switch", 
    "arxiv-id": "1611.00745v1", 
    "author": "R. Srikant", 
    "publish": "2016-11-02T19:44:13Z", 
    "summary": "We consider an input queued switch operating under the MaxWeight scheduling\nalgorithm. This system is interesting to study because it is a model for\nInternet routers and data center networks. Recently, it was shown that the\nMaxWeight algorithm has optimal heavy-traffic queue length scaling when all\nports are uniformly saturated. Here we consider the case when an arbitrary\nnumber of ports are saturated (which we call the incompletely saturated case),\nand each port is allowed to saturate at a different rate. We use a recently\ndeveloped drift technique to show that the heavy-traffic queue length under the\nMaxWeight scheduling algorithm has optimal scaling with respect to the switch\nsize even in these cases."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1611.02445v1", 
    "title": "Memory layout in GPU implementation of lattice Boltzmann method for   sparse 3D geometries", 
    "arxiv-id": "1611.02445v1", 
    "author": "Roman G. Szafran", 
    "publish": "2016-11-08T09:33:18Z", 
    "summary": "We describe a high-performance implementation of the lattice Boltzmann method\n(LBM) for sparse 3D geometries on graphic processors (GPU). The main\ncontribution of this work is a data layout that allows to minimise the number\nof redundant memory transactions during the propagation step of LBM. We show\nthat by using a uniform mesh of small three-dimensional tiles and a careful\ndata placement it is possible to utilise more than 70% of maximum theoretical\nGPU memory bandwidth for D3Q19 lattice and double precision numbers. The\nperformance of our implementation is thoroughly examined and compared with\nother GPU implementations of LBM. The proposed method performs the best for\nsparse geometries with good spatial locality."
},{
    "category": "cs.CE", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1611.03725v1", 
    "title": "Practical Interpolation for Spectrum Cartography through Local Path Loss   Modeling", 
    "arxiv-id": "1611.03725v1", 
    "author": "Wade Trappe", 
    "publish": "2016-11-10T07:23:43Z", 
    "summary": "A fundamental building block for supporting better utilization of radio\nspectrum involves predicting the impact that an emitter will have at different\ngeographic locations. To this end, fixed sensors can be deployed to spatially\nsample the RF environment over an area of interest, with interpolation methods\nused to infer received power at locations between sensors. This paper describes\na radio map interpolation method that exploits the known properties of most\npath loss models, with the aim of minimizing the RMS errors in predicted\ndB-power. We show that the results come very close to those for ideal Simple\nKriging. Moreover, the method is simpler in terms of real-time computation by\nthe network and it requires no knowledge of the spatial correlation of shadow\nfading. Our analysis of the method is general, but we exemplify it for a\nspecific network geometry, comprising a grid-like pattern of sensors. We also\nprovide comparisons to other widely used interpolation methods."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1611.07556v1", 
    "title": "Cultivating Software Performance in Cloud Computing", 
    "arxiv-id": "1611.07556v1", 
    "author": "Kingsum Chow", 
    "publish": "2016-11-22T22:19:54Z", 
    "summary": "There exist multitudes of cloud performance metrics, including workload\nperformance, application placement, software/hardware optimization,\nscalability, capacity, reliability, agility and so on. In this paper, we\nconsider jointly optimizing the performance of the software applications in the\ncloud. The challenges lie in bringing a diversity of raw data into tidy data\nformat, unifying performance data from multiple systems based on timestamps,\nand assessing the quality of the processed performance data. Even after\nverifying the quality of cloud performance data, additional challenges block\noptimizing cloud computing. In this paper, we identify the challenges of cloud\ncomputing from the perspectives of computing environment, data collection,\nperformance analytics and production environment."
},{
    "category": "cs.DB", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1611.09170v1", 
    "title": "DESP-C++: A Discrete-Event Simulation Package for C++", 
    "arxiv-id": "1611.09170v1", 
    "author": "J\u00e9r\u00f4me Darmont", 
    "publish": "2016-11-28T15:16:42Z", 
    "summary": "DESP-C++ is a C++ discrete-event random simulation engine that has been\ndesigned to be fast, very easy to use and expand, and valid. DESP-C++ is based\non the resource view. Its complete architecture is presented in detail, as well\nas a short \" user manual \". The validity of DESP-C++ is demonstrated by the\nsimulation of three significant models. In each case, the simulation results\nobtained with DESP-C++ match those obtained with a validated simulation\nsoftware: QNAP2. The versatility of DESP-C++ is also illustrated this way,\nsince the modelled systems are very different from each other: a simple\nproduction system, the dining philosopher classical deadlock problem, and a\ncomplex object-oriented database management system."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1611.09774v1", 
    "title": "Serving the Grid: an Experimental Study of Server Clusters as Real-Time   Demand Response Resources", 
    "arxiv-id": "1611.09774v1", 
    "author": "Raghuraman Mudumbai", 
    "publish": "2016-11-29T18:39:04Z", 
    "summary": "Demand response is a crucial technology to allow large-scale penetration of\nintermittent renewable energy sources in the electric grid. This paper is based\non the thesis that datacenters represent especially attractive candidates for\nproviding flexible, real-time demand response services to the grid; they are\ncapable of finely-controllable power consumption, fast power ramp-rates, and\nlarge dynamic range. This paper makes two main contributions: (a) it provides\ndetailed experimental evidence justifying this thesis, and (b) it presents a\ncomparative investigation of three candidate software interfaces for power\ncontrol within the servers. All of these results are based on a series of\nexperiments involving real-time power measurements on a lab-scale server\ncluster. This cluster was specially instrumented for accurate and fast power\nmeasurements on a time-scale of 100 ms or less. Our results provide preliminary\nevidence for the feasibility of large scale demand response using datacenters,\nand motivates future work on exploiting this capability."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1612.00309v1", 
    "title": "Comparison Between IPv4 to IPv6 Transition Techniques", 
    "arxiv-id": "1612.00309v1", 
    "author": "Wagner L Zucchi", 
    "publish": "2016-12-01T15:24:23Z", 
    "summary": "The IPv4 addresses exhaustion demands a protocol transition from IPv4 to\nIPv6. The original transition technique, the dual stack, is not widely deployed\nyet and it demanded the creation of new transition techniques to extend the\ntransition period. This work makes an experimental comparison of techniques\nthat use dual stack with a limited IPv4 address. This limited address might be\na RFC 1918 address with a NAT at the Internet Service Provider (ISP) gateway,\nalso known as Carrier Grade NAT (CGN), or an Address Plus Port (A+P) shared\nIPv4 address. The chosen techniques also consider an IPv6 only ISP network. The\ntransport of the IPv4 packets through the IPv6 only networks may use IPv4\npackets encapsulated on IPv6 packets or a double translation, by making one\nIPv4 to IPv6 translation to enter the IPv6 only network and one IPv6 to IPv4\ntranslation to return to the IPv4 network. The chosen techniques were DS-Lite,\n464XLAT, MAP-E and MAP-T. The first part of the test is to check some of the\nmost common usages of the Internet by a home user and the impacts of the\ntransition techniques on the user experience. The second part is a measured\ncomparison considering bandwidth, jitter and latency introduced by the\ntechniques and processor usage on the network equipment."
},{
    "category": "astro-ph.IM", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1612.00456v1", 
    "title": "Characterising radio telescope software with the Workload   Characterisation Framework", 
    "arxiv-id": "1612.00456v1", 
    "author": "G. Mariani", 
    "publish": "2016-12-01T21:00:05Z", 
    "summary": "We present a modular framework, the Workload Characterisation Framework\n(WCF), that is developed to reproducibly obtain, store and compare key\ncharacteristics of radio astronomy processing software. As a demonstration, we\ndiscuss the experiences using the framework to characterise a LOFAR calibration\nand imaging pipeline."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1612.01868v1", 
    "title": "Broadcast Strategies and Performance Evaluation of IEEE 802.15.4 in   Wireless Body Area Networks WBAN", 
    "arxiv-id": "1612.01868v1", 
    "author": "Maria Potop-Butucaru", 
    "publish": "2016-12-06T15:33:55Z", 
    "summary": "The rapid advances in sensors and ultra-low power wireless communication has\nenabled a new generation of wireless sensor networks: Wireless Body Area\nNetworks (WBAN). To the best of our knowledge the current paper is the first to\naddress broadcast in WBAN. We first analyze several broadcast strategies\ninspired from the area of Delay Tolerant Networks (DTN). The proposed\nstrategies are evaluated via the OMNET++ simulator that we enriched with\nrealistic human body mobility models and channel models issued from the recent\nresearch on biomedical and health informatics. Contrary to the common\nexpectation, our results show that existing research in DTN cannot be\ntransposed without significant modifications in WBANs area. That is, existing\nbroadcast strategies for DTNs do not perform well with human body mobility.\nHowever, our extensive simulations give valuable insights and directions for\ndesigning efficient broadcast in WBAN. Furthermore, we propose a novel\nbroadcast strategy that outperforms the existing ones in terms of end-to-end\ndelay, network coverage and energy consumption. Additionally, we performed\ninvestigations of independent interest related to the ability of all the\nstudied strategies to ensure the total order delivery property when stressed\nwith various packet rates. These investigations open new and challenging\nresearch directions."
},{
    "category": "cs.DS", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1612.02557v1", 
    "title": "Sorting Data on Ultra-Large Scale with RADULS. New Incarnation of Radix   Sort", 
    "arxiv-id": "1612.02557v1", 
    "author": "Agnieszka Debudaj-Grabysz", 
    "publish": "2016-12-08T08:20:48Z", 
    "summary": "The paper introduces RADULS, a new parallel sorter based on radix sort\nalgorithm, intended to organize ultra-large data sets efficiently. For example\n4G 16-byte records can be sorted with 16 threads in less than 15 seconds on\nIntel Xeon-based workstation. The implementation of RADULS is not only highly\noptimized to gain such an excellent performance, but also parallelized in a\ncache friendly manner to make the most of modern multicore architectures.\nBesides, our parallel scheduler launches a few different procedures at runtime,\naccording to the current parameters of the execution, for proper workload\nmanagement. All experiments show RADULS to be superior to competing algorithms."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.227.7", 
    "link": "http://arxiv.org/pdf/1612.04470v1", 
    "title": "Efficient Realization of Householder Transform through   Algorithm-Architecture Co-design for Acceleration of QR Factorization", 
    "arxiv-id": "1612.04470v1", 
    "author": "Ranjani Narayan", 
    "publish": "2016-12-14T03:22:44Z", 
    "summary": "We present efficient realization of Householder Transform (HT) based QR\nfactorization through algorithm-architecture co-design where we achieve\nperformance improvement of 3-90x in-terms of Gflops/watt over state-of-the-art\nmulticore, General Purpose Graphics Processing Units (GPGPUs), Field\nProgrammable Gate Arrays (FPGAs), and ClearSpeed CSX700. Theoretical and\nexperimental analysis of classical HT is performed for opportunities to exhibit\nhigher degree of parallelism where parallelism is quantified as a number of\nparallel operations per level in the Directed Acyclic Graph (DAG) of the\ntransform. Based on theoretical analysis of classical HT, an opportunity\nre-arrange computations in the classical HT is identified that results in\nModified HT (MHT) where it is shown that MHT exhibits 1.33x times higher\nparallelism than classical HT. Experiments in off-the-shelf multicore and\nGeneral Purpose Graphics Processing Units (GPGPUs) for HT and MHT suggest that\nMHT is capable of achieving slightly better or equal performance compared to\nclassical HT based QR factorization realizations in the optimized software\npackages for Dense Linear Algebra (DLA). We implement MHT on a customized\nplatform for Dense Linear Algebra (DLA) and show that MHT achieves 1.3x better\nperformance than native implementation of classical HT on the same accelerator.\nFor custom realization of HT and MHT based QR factorization, we also identify\nmacro operations in the DAGs of HT and MHT that are realized on a\nReconfigurable Data-path (RDP). We also observe that due to re-arrangement in\nthe computations in MHT, custom realization of MHT is capable of achieving 12%\nbetter performance improvement over multicore and GPGPUs than the performance\nimprovement reported by General Matrix Multiplication (GEMM) over highly tuned\nDLA software packages for multicore and GPGPUs which is counter-intuitive."
},{
    "category": "math.OC", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1612.04721v1", 
    "title": "Dissecting demand response mechanisms: the role of consumption forecasts   and personalized offers", 
    "arxiv-id": "1612.04721v1", 
    "author": "Giovanni Neglia", 
    "publish": "2016-12-12T14:51:03Z", 
    "summary": "Demand-Response (DR) programs, whereby users of an electricity network are\nencouraged by economic incentives to rearrange their consumption in order to\nreduce production costs, are envisioned to be a key feature of the smart grid\nparadigm. Several recent works proposed DR mechanisms and used analytical\nmodels to derive optimal incentives. Most of these works, however, rely on a\nmacroscopic description of the population that does not model individual\nchoices of users. In this paper, we conduct a detailed analysis of those models\nand we argue that the macroscopic descriptions hide important assumptions that\ncan jeopardize the mechanisms' implementation (such as the ability to make\npersonalized offers and to perfectly estimate the demand that is moved from a\ntimeslot to another). Then, we start from a microscopic description that\nexplicitly models each user's decision. We introduce four DR mechanisms with\nvarious assumptions on the provider's capabilities. Contrarily to previous\nstudies, we find that the optimization problems that result from our mechanisms\nare complex and can be solved numerically only through a heuristic. We present\nnumerical simulations that compare the different mechanisms and their\nsensitivity to forecast errors. At a high level, our results show that the\nperformance of DR mechanisms under reasonable assumptions on the provider's\ncapabilities are significantly lower than"
},{
    "category": "cs.PF", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1701.01328v1", 
    "title": "An Infinite Dimensional Model for a Many Server Priority Queue", 
    "arxiv-id": "1701.01328v1", 
    "author": "Nicholas Bambos", 
    "publish": "2016-12-07T22:14:56Z", 
    "summary": "We consider a Markovian many server queueing system in which customers are\npreemptively scheduled according to exogenously assigned priority levels. The\npriority levels are randomly assigned from a continuous probability measure\nrather than a discrete one and hence, the queue is modeled by an infinite\ndimensional stochastic process. We analyze the equilibrium behavior of the\nsystem and provide several results. We derive the Radon-Nikodym derivative\n(with respect to Lebesgue measure) of the measure that describes the average\ndistribution of customer priority levels in the system; we provide a formula\nfor the expected sojourn time of a customer as a function of his priority\nlevel; and we provide a formula for the expected waiting time of a customer as\na function of his priority level. We verify our theoretical analysis with\ndiscrete-event simulations. We discuss how each of our results generalizes\nprevious work on infinite dimensional models for single server priority queues."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1701.03831v1", 
    "title": "Delay-Optimal Scheduling for Queueing Systems with Switching Overhead", 
    "arxiv-id": "1701.03831v1", 
    "author": "Xi Liu", 
    "publish": "2017-01-13T21:10:05Z", 
    "summary": "We study the scheduling polices for asymptotically optimal delay in queueing\nsystems with switching overhead. Such systems consist of a single server that\nserves multiple queues, and some capacity is lost whenever the server switches\nto serve a different set of queues. The capacity loss due to this switching\noverhead can be significant in many emerging applications, and needs to be\nexplicitly addressed in the design of scheduling policies. For example, in\n60GHz wireless networks with directional antennas, base stations need to train\nand reconfigure their beam patterns whenever they switch from one client to\nanother. Considerable switching overhead can also be observed in many other\nqueueing systems such as transportation networks and manufacturing systems.\nWhile the celebrated Max-Weight policy achieves asymptotically optimal average\ndelay for systems without switching overhead, it fails to preserve\nthroughput-optimality, let alone delay-optimality, when switching overhead is\ntaken into account. We propose a class of Biased Max-Weight scheduling policies\nthat explicitly takes switching overhead into account. The Biased Max-Weight\npolicy can use either queue length or head-of-line waiting time as an indicator\nof the system status. We prove that our policies not only are\nthroughput-optimal, but also can be made arbitrarily close to the asymptotic\nlower bound on average delay. To validate the performance of the proposed\npolicies, we provide extensive simulation with various system topologies and\ndifferent traffic patterns. We show that the proposed policies indeed achieve\nmuch better delay performance than that of the state-of-the-art policy."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1701.08547v1", 
    "title": "Autotuning GPU Kernels via Static and Predictive Analysis", 
    "arxiv-id": "1701.08547v1", 
    "author": "Allen D. Malony", 
    "publish": "2017-01-30T11:23:42Z", 
    "summary": "Optimizing the performance of GPU kernels is challenging for both human\nprogrammers and code generators. For example, CUDA programmers must set thread\nand block parameters for a kernel, but might not have the intuition to make a\ngood choice. Similarly, compilers can generate working code, but may miss\ntuning opportunities by not targeting GPU models or performing code\ntransformations. Although empirical autotuning addresses some of these\nchallenges, it requires extensive experimentation and search for optimal code\nvariants. This research presents an approach for tuning CUDA kernels based on\nstatic analysis that considers fine-grained code structure and the specific GPU\narchitecture features. Notably, our approach does not require any program runs\nin order to discover near-optimal parameter settings. We demonstrate the\napplicability of our approach in enabling code autotuners such as Orio to\nproduce competitive code variants comparable with empirical-based methods,\nwithout the high cost of experiments."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1702.00629v1", 
    "title": "gearshifft - The FFT Benchmark Suite for Heterogeneous Platforms", 
    "arxiv-id": "1702.00629v1", 
    "author": "Matthias Werner", 
    "publish": "2017-02-02T11:41:32Z", 
    "summary": "Fast Fourier Transforms (FFTs) are exploited in a wide variety of fields\nranging from computer science to natural sciences and engineering. With the\nrising data production bandwidths of modern FFT applications, judging best\nwhich algorithmic tool to apply, can be vital to any scientific endeavor. As\ntailored FFT implementations exist for an ever increasing variety of high\nperformance computer hardware, choosing the best performing FFT implementation\nhas strong implications for future hardware purchase decisions, for resources\nFFTs consume and for possibly decisive financial and time savings ahead of the\ncompetition. This paper therefor presents gearshifft, which is an open-source\nand vendor agnostic benchmark suite to process a wide variety of problem sizes\nand types with state-of-the-art FFT implementations (fftw, clfft and cufft).\ngearshifft provides a reproducible, unbiased and fair comparison on a wide\nvariety of hardware to explore which FFT variant is best for a given problem\nsize."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1702.02968v1", 
    "title": "Comparative benchmarking of cloud computing vendors with High   Performance Linpack", 
    "arxiv-id": "1702.02968v1", 
    "author": "Timur Bazhirov", 
    "publish": "2017-02-09T20:11:26Z", 
    "summary": "We present a comparative analysis of the maximum performance achieved by the\nLinpack benchmark on compute intensive hardware publicly available from\nmultiple cloud providers. We study both performance within a single compute\nnode, and speedup for distributed memory calculations with up to 32 nodes or at\nleast 512 computing cores. We distinguish between hyper-threaded and\nnon-hyper-threaded scenarios and estimate the performance per single computing\ncore. We also compare results with a traditional supercomputing system for\nreference. Our findings provide a way to rank the cloud providers and\ndemonstrate the viability of the cloud for high performance computing\napplications."
},{
    "category": "math.PR", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1702.03444v1", 
    "title": "Steady-state analysis of single exponential vacation in a   $PH/MSP/1/\\infty$ queue using roots", 
    "arxiv-id": "1702.03444v1", 
    "author": "Florin Avram", 
    "publish": "2017-02-11T17:37:57Z", 
    "summary": "We consider an infinite-buffer single-server queue where inter-arrival times\nare phase-type ($PH$), the service is provided according to Markovian service\nprocess $(MSP)$, and the server may take single, exponentially distributed\nvacations when the queue is empty. The proposed analysis is based on roots of\nthe associated characteristic equation of the vector-generating function (VGF)\nof system-length distribution at a pre-arrival epoch. Also, we obtain the\nsteady-state system-length distribution at an arbitrary epoch along with some\nimportant performance measures such as the mean number of customers in the\nsystem and the mean system sojourn time of a customer. Later, we have\nestablished heavy- and light-traffic approximations as well as an approximation\nfor the tail probabilities at pre-arrival epoch based on one root of the\ncharacteristic equation. At the end, we present numerical results in the form\nof tables to show the effect of model parameters on the performance measures."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ACC.2016.7525414", 
    "link": "http://arxiv.org/pdf/1702.07195v1", 
    "title": "First Experiences Optimizing Smith-Waterman on Intel's Knights Landing   Processor", 
    "arxiv-id": "1702.07195v1", 
    "author": "Manuel Prieto-Matias", 
    "publish": "2017-02-23T12:37:54Z", 
    "summary": "The well-known Smith-Waterman (SW) algorithm is the most commonly used method\nfor local sequence alignments. However, SW is very computationally demanding\nfor large protein databases. There exist several implementations that take\nadvantage of computing parallelization on many-cores, FPGAs or GPUs, in order\nto increase the alignment throughtput. In this paper, we have explored SW\nacceleration on Intel KNL processor. The novelty of this architecture requires\nthe revision of previous programming and optimization techniques on many-core\narchitectures. To the best of authors knowledge, this is the first KNL\narchitecture assessment for SW algorithm. Our evaluation, using the renowned\nEnvironmental NR database as benchmark, has shown that multi-threading and SIMD\nexploitation reports competitive performance (351 GCUPS) in comparison with\nother implementations."
},{
    "category": "cs.DC", 
    "doi": "10.1002/cpe.4143", 
    "link": "http://arxiv.org/pdf/1703.02788v1", 
    "title": "Evaluation of DVFS techniques on modern HPC processors and accelerators   for energy-aware applications", 
    "arxiv-id": "1703.02788v1", 
    "author": "Raffaele Tripiccione", 
    "publish": "2017-03-08T11:13:24Z", 
    "summary": "Energy efficiency is becoming increasingly important for computing systems,\nin particular for large scale HPC facilities. In this work we evaluate, from an\nuser perspective, the use of Dynamic Voltage and Frequency Scaling (DVFS)\ntechniques, assisted by the power and energy monitoring capabilities of modern\nprocessors in order to tune applications for energy efficiency. We run selected\nkernels and a full HPC application on two high-end processors widely used in\nthe HPC context, namely an NVIDIA K80 GPU and an Intel Haswell CPU. We evaluate\nthe available trade-offs between energy-to-solution and time-to-solution,\nattempting a function-by-function frequency tuning. We finally estimate the\nbenefits obtainable running the full code on a HPC multi-GPU node, with respect\nto default clock frequency governors. We instrument our code to accurately\nmonitor power consumption and execution time without the need of any additional\nhardware, and we enable it to change CPUs and GPUs clock frequencies while\nrunning. We analyze our results on the different architectures using a simple\nenergy-performance model, and derive a number of energy saving strategies which\ncan be easily adopted on recent high-end HPC systems for generic applications."
},{
    "category": "cs.AI", 
    "doi": "10.1002/cpe.4143", 
    "link": "http://arxiv.org/pdf/1703.06042v1", 
    "title": "A Visual Web Tool to Perform What-If Analysis of Optimization Approaches", 
    "arxiv-id": "1703.06042v1", 
    "author": "Pierre Schaus", 
    "publish": "2017-03-16T12:53:52Z", 
    "summary": "In Operation Research, practical evaluation is essential to validate the\nefficacy of optimization approaches. This paper promotes the usage of\nperformance profiles as a standard practice to visualize and analyze\nexperimental results. It introduces a Web tool to construct and export\nperformance profiles as SVG or HTML files. In addition, the application relies\non a methodology to estimate the benefit of hypothetical solver improvements.\nTherefore, the tool allows one to employ what-if analysis to screen possible\nresearch directions, and identify those having the best potential. The approach\nis showcased on two Operation Research technologies: Constraint Programming and\nMixed Integer Linear Programming."
},{
    "category": "cond-mat.stat-mech", 
    "doi": "10.1002/cpe.4143", 
    "link": "http://arxiv.org/pdf/cond-mat/0002469v1", 
    "title": "Non-equilibrium Surface Growth and Scalability of Parallel Algorithms   for Large Asynchronous Systems", 
    "arxiv-id": "cond-mat/0002469v1", 
    "author": "P. A. Rikvold", 
    "publish": "2000-02-29T23:54:04Z", 
    "summary": "The scalability of massively parallel algorithms is a fundamental question in\ncomputer science. We study the scalability and the efficiency of a conservative\nmassively parallel algorithm for discrete-event simulations where the discrete\nevents are Poisson arrivals. The parallel algorithm is applicable to a wide\nrange of problems, including dynamic Monte Carlo simulations for large\nasynchronous systems with short-range interactions. The evolution of the\nsimulated time horizon is analogous to a growing and fluctuating surface, and\nthe efficiency of the algorithm corresponds to the density of local minima of\nthis surface. In one dimension we find that the steady state of the macroscopic\nlandscape is governed by the Edwards-Wilkinson Hamiltonian, which implies that\nthe algorithm is scalable. Preliminary results for higher-dimensional logical\ntopologies are discussed."
},{
    "category": "cs.NI", 
    "doi": "10.1002/cpe.4143", 
    "link": "http://arxiv.org/pdf/cs/9904016v1", 
    "title": "Brittle System Analysis", 
    "arxiv-id": "cs/9904016v1", 
    "author": "Kirby Vosburgh", 
    "publish": "1999-04-22T15:47:22Z", 
    "summary": "The goal of this paper is to define and analyze systems which exhibit brittle\nbehavior. This behavior is characterized by a sudden and steep decline in\nperformance as the system approaches the limits of tolerance. This can be due\nto input parameters which exceed a specified input, or environmental conditions\nwhich exceed specified operating boundaries. An analogy is made between brittle\ncommmunication systems in particular and materials science."
},{
    "category": "cs.PF", 
    "doi": "10.1002/cpe.4143", 
    "link": "http://arxiv.org/pdf/cs/0012022v1", 
    "title": "Performance and Scalability Models for a Hypergrowth e-Commerce Web Site", 
    "arxiv-id": "cs/0012022v1", 
    "author": "Neil J. Gunther", 
    "publish": "2000-12-26T22:42:39Z", 
    "summary": "The performance of successful Web-based e-commerce services has all the\nallure of a roller-coaster ride: accelerated fiscal growth combined with the\never-present danger of running out of server capacity. This chapter presents a\ncase study based on the author's own capacity planning engagement with one of\nthe hottest e-commerce Web sites in the world. Several spreadsheet techniques\nare presented for forecasting both short-term and long-term trends in the\nconsumption of server capacity. Two new performance metrics are introduced for\nsite planning and procurement: the effective demand, and the doubling period."
},{
    "category": "cs.NI", 
    "doi": "10.1103/PhysRevE.64.046135", 
    "link": "http://arxiv.org/pdf/cs/0103016v1", 
    "title": "Search in Power-Law Networks", 
    "arxiv-id": "cs/0103016v1", 
    "author": "B. A. Huberman", 
    "publish": "2001-03-20T23:46:53Z", 
    "summary": "Many communication and social networks have power-law link distributions,\ncontaining a few nodes which have a very high degree and many with low degree.\nThe high connectivity nodes play the important role of hubs in communication\nand networking, a fact which can be exploited when designing efficient search\nalgorithms. We introduce a number of local search strategies which utilize high\ndegree nodes in power-law graphs and which have costs which scale sub-linearly\nwith the size of the graph. We also demonstrate the utility of these strategies\non the Gnutella peer-to-peer network."
},{
    "category": "cs.PF", 
    "doi": "10.1103/PhysRevE.64.046135", 
    "link": "http://arxiv.org/pdf/cs/0202019v1", 
    "title": "Hypernets -- Good (G)news for Gnutella", 
    "arxiv-id": "cs/0202019v1", 
    "author": "N. J. Gunther", 
    "publish": "2002-02-16T21:46:14Z", 
    "summary": "Criticism of Gnutella network scalability has rested on the bandwidth\nattributes of the original interconnection topology: a Cayley tree. Trees, in\ngeneral, are known to have lower aggregate bandwidth than higher dimensional\ntopologies e.g., hypercubes, meshes and tori. Gnutella was intended to support\nthousands to millions of peers. Studies of interconnection topologies in the\nliterature, however, have focused on hardware implementations which are limited\nby cost to a few thousand nodes. Since the Gnutella network is virtual,\nhyper-topologies are relatively unfettered by such constraints. We present\nperformance models for several plausible hyper-topologies and compare their\nquery throughput up to millions of peers. The virtual hypercube and the virtual\nhypertorus are shown to offer near linear scalability subject to the number of\npeer TCP/IP connections that can be simultaneously kept open."
},{
    "category": "cs.CR", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0402054v3", 
    "title": "On the Security of the Yi-Tan-Siew Chaos-Based Cipher", 
    "arxiv-id": "cs/0402054v3", 
    "author": "Xuanqin Mou", 
    "publish": "2004-02-24T08:28:21Z", 
    "summary": "This paper presents a comprehensive analysis on the security of the\nYi-Tan-Siew chaotic cipher proposed in [IEEE TCAS-I 49(12):1826-1829 (2002)]. A\ndifferential chosen-plaintext attack and a differential chosen-ciphertext\nattack are suggested to break the sub-key K, under the assumption that the time\nstamp can be altered by the attacker, which is reasonable in such attacks.\nAlso, some security Problems about the sub-keys $\\alpha$ and $\\beta$ are\nclarified, from both theoretical and experimental points of view. Further\nanalysis shows that the security of this cipher is independent of the use of\nthe chaotic tent map, once the sub-key $K$ is removed via the proposed\nsuggested differential chosen-plaintext attack."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0409035v1", 
    "title": "Parallel Computing Environments and Methods for Power Distribution   System Simulation", 
    "arxiv-id": "cs/0409035v1", 
    "author": "R. Scott Studham", 
    "publish": "2004-09-18T17:09:26Z", 
    "summary": "The development of cost-effective highperformance parallel computing on\nmulti-processor supercomputers makes it attractive to port excessively time\nconsuming simulation software from personal computers (PC) to super computes.\nThe power distribution system simulator (PDSS) takes a bottom-up approach and\nsimulates load at the appliance level, where detailed thermal models for\nappliances are used. This approach works well for a small power distribution\nsystem consisting of a few thousand appliances. When the number of appliances\nincreases, the simulation uses up the PC memory and its runtime increases to a\npoint where the approach is no longer feasible to model a practical large power\ndistribution system. This paper presents an effort made to port a PC-based\npower distribution system simulator to a 128-processor shared-memory\nsupercomputer. The paper offers an overview of the parallel computing\nenvironment and a description of the modification made to the PDSS model. The\nperformance of the PDSS running on a standalone PC and on the supercomputer is\ncompared. Future research direction of utilizing parallel computing in the\npower distribution system simulation is also addressed."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0411019v1", 
    "title": "Programmable Ethernet Switches and Their Applications", 
    "arxiv-id": "cs/0411019v1", 
    "author": "Tzi-cker Chiueh", 
    "publish": "2004-11-08T20:06:09Z", 
    "summary": "Modern Ethernet switches support many advanced features beyond route learning\nand packet forwarding such as VLAN tagging, IGMP snooping, rate limiting, and\nstatus monitoring, which can be controlled through a programmatic interface.\nTraditionally, these features are mostly used to statically configure a\nnetwork. This paper proposes to apply them as dynamic control mechanisms to\nmaximize physical network link resources, to minimize failure recovery time, to\nenforce QoS requirements, and to support link-layer multicast without\nbroadcasting. With these advanced programmable control mechanisms, standard\nEthernet switches can be used as effective building blocks for\nmetropolitan-area Ethernet networks (MEN), storage-area networks (SAN), and\ncomputation cluster interconnects. We demonstrate the usefulness of this new\nlevel of control over Ethernet switches with a MEN architecture that features\nmulti-fold throughput gains and sub-second failure recovery time."
},{
    "category": "cs.PL", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0501073v1", 
    "title": "Optimal Union-Find in Constraint Handling Rules", 
    "arxiv-id": "cs/0501073v1", 
    "author": "Thom Fruehwirth", 
    "publish": "2005-01-25T13:28:38Z", 
    "summary": "Constraint Handling Rules (CHR) is a committed-choice rule-based language\nthat was originally intended for writing constraint solvers. In this paper we\nshow that it is also possible to write the classic union-find algorithm and\nvariants in CHR. The programs neither compromise in declarativeness nor\nefficiency. We study the time complexity of our programs: they match the\nalmost-linear complexity of the best known imperative implementations. This\nfact is illustrated with experimental results."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0502039v1", 
    "title": "Efficient Parallel Simulations of Asynchronous Cellular Arrays", 
    "arxiv-id": "cs/0502039v1", 
    "author": "Boris D. Lubachevsky", 
    "publish": "2005-02-08T00:32:33Z", 
    "summary": "A definition for a class of asynchronous cellular arrays is proposed. An\nexample of such asynchrony would be independent Poisson arrivals of cell\niterations. The Ising model in the continuous time formulation of Glauber falls\ninto this class. Also proposed are efficient parallel algorithms for simulating\nthese asynchronous cellular arrays. In the algorithms, one or several cells are\nassigned to a processing element (PE), local times for different PEs can be\ndifferent. Although the standard serial algorithm by Metropolis, Rosenbluth,\nRosenbluth, Teller, and Teller can simulate such arrays, it is usually believed\nto be without an efficient parallel counterpart. However, the proposed parallel\nalgorithms contradict this belief proving to be both efficient and able to\nperform the same task as the standard algorithm. The results of experiments\nwith the new algorithms are encouraging: the speed-up is greater than 16 using\n25 PEs on a shared memory MIMD bus computer, and greater than 1900 using 2**14\nPEs on a SIMD computer. The algorithm by Bortz, Kalos, and Lebowitz can be\nincorporated in the proposed parallel algorithms, further contributing to\nspeed-up. [In this paper I invented the update-cites-of-local-time-minima\nparallel simulation scheme. Now the scheme is becoming popular. Many misprints\nof the original 1987 Complex Systems publication are corrected here.-B.L.]"
},{
    "category": "cs.IT", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0507004v2", 
    "title": "An End-to-End Probabilistic Network Calculus with Moment Generating   Functions", 
    "arxiv-id": "cs/0507004v2", 
    "author": "Markus Fidler", 
    "publish": "2005-07-03T20:02:01Z", 
    "summary": "Network calculus is a min-plus system theory for performance evaluation of\nqueuing networks. Its elegance stems from intuitive convolution formulas for\nconcatenation of deterministic servers. Recent research dispenses with the\nworst-case assumptions of network calculus to develop a probabilistic\nequivalent that benefits from statistical multiplexing. Significant\nachievements have been made, owing for example to the theory of effective\nbandwidths, however, the outstanding scalability set up by concatenation of\ndeterministic servers has not been shown.\n  This paper establishes a concise, probabilistic network calculus with moment\ngenerating functions. The presented work features closed-form, end-to-end,\nprobabilistic performance bounds that achieve the objective of scaling linearly\nin the number of servers in series. The consistent application of moment\ngenerating functions put forth in this paper utilizes independence beyond the\nscope of current statistical multiplexing of flows. A relevant additional gain\nis demonstrated for tandem servers with independent cross-traffic."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0511008v1", 
    "title": "Analysis of Stochastic Service Guarantees in Communication Networks: A   Basic Calculus", 
    "arxiv-id": "cs/0511008v1", 
    "author": "Yuming Jiang", 
    "publish": "2005-11-02T14:23:48Z", 
    "summary": "A basic calculus is presented for stochastic service guarantee analysis in\ncommunication networks. Central to the calculus are two definitions,\nmaximum-(virtual)-backlog-centric (m.b.c) stochastic arrival curve and\nstochastic service curve, which respectively generalize arrival curve and\nservice curve in the deterministic network calculus framework. With m.b.c\nstochastic arrival curve and stochastic service curve, various basic results\nare derived under the (min, +) algebra for the general case analysis, which are\ncrucial to the development of stochastic network calculus. These results\ninclude (i) superposition of flows, (ii) concatenation of servers, (iii) output\ncharacterization, (iv) per-flow service under aggregation, and (v) stochastic\nbacklog and delay guarantees. In addition, to perform independent case\nanalysis, stochastic strict server is defined, which uses an ideal service\nprocess and an impairment process to characterize a server. The concept of\nstochastic strict server not only allows us to improve the basic results (i) --\n(v) under the independent case, but also provides a convenient way to find the\nstochastic service curve of a serve. Moreover, an approach is introduced to\nfind the m.b.c stochastic arrival curve of a flow and the stochastic service\ncurve of a server."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0604016v2", 
    "title": "On Conditional Branches in Optimal Search Trees", 
    "arxiv-id": "cs/0604016v2", 
    "author": "Michael B. Baer", 
    "publish": "2006-04-06T00:54:44Z", 
    "summary": "Algorithms for efficiently finding optimal alphabetic decision trees -- such\nas the Hu-Tucker algorithm -- are well established and commonly used. However,\nsuch algorithms generally assume that the cost per decision is uniform and thus\nindependent of the outcome of the decision. The few algorithms without this\nassumption instead use one cost if the decision outcome is ``less than'' and\nanother cost otherwise. In practice, neither assumption is accurate for\nsoftware optimized for today's microprocessors. Such software generally has one\ncost for the more likely decision outcome and a greater cost -- often far\ngreater -- for the less likely decision outcome. This problem and\ngeneralizations thereof are thus applicable to hard coding static decision tree\ninstances in software, e.g., for optimizing program bottlenecks or for\ncompiling switch statements. An O(n^3)-time O(n^2)-space dynamic programming\nalgorithm can solve this optimal binary decision tree problem, and this\napproach has many generalizations that optimize for the behavior of processors\nwith predictive branch capabilities, both static and dynamic. Solutions to this\nformulation are often faster in practice than ``optimal'' decision trees as\nformulated in the literature. Different search paradigms can sometimes yield\neven better performance."
},{
    "category": "cs.AR", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0605039v4", 
    "title": "Fast and Generalized Polynomial Time Memory Consistency Verification", 
    "arxiv-id": "cs/0605039v4", 
    "author": "John C. Huang", 
    "publish": "2006-05-09T05:45:52Z", 
    "summary": "The problem of verifying multi-threaded execution against the memory\nconsistency model of a processor is known to be an NP hard problem. However\npolynomial time algorithms exist that detect almost all failures in such\nexecution. These are often used in practice for microprocessor verification. We\npresent a low complexity and fully parallelized algorithm to check program\nexecution against the processor consistency model. In addition our algorithm is\ngeneral enough to support a number of consistency models without any\ndegradation in performance. An implementation of this algorithm is currently\nused in practice to verify processors in the post silicon stage for multiple\narchitectures."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0608061v5", 
    "title": "Concurrent Processing Memory", 
    "arxiv-id": "cs/0608061v5", 
    "author": "Chengpu Wang", 
    "publish": "2006-08-15T01:42:49Z", 
    "summary": "A theoretical memory with limited processing power and internal connectivity\nat each element is proposed. This memory carries out parallel processing within\nitself to solve generic array problems. The applicability of this in-memory\nfinest-grain massive SIMD approach is studied in some details. For an array of\nN items, it reduces the total instruction cycle count of universal operations\nsuch as insertion/deletion and match finding to ~ 1, local operations such as\nfiltering and template matching to ~ local operation size, and global\noperations such as sum, finding global limit and sorting to ~\\sqroot{N}\ninstruction cycles. It eliminates most streaming activities for data processing\npurpose on the system bus. Yet it remains general-purposed, easy to use, pin\ncompatible with conventional memory, and practical for implementation."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0608069v1", 
    "title": "JiTS: Just-in-Time Scheduling for Real-Time Sensor Data Dissemination", 
    "arxiv-id": "cs/0608069v1", 
    "author": "Kyoung-Don Kang", 
    "publish": "2006-08-16T17:21:40Z", 
    "summary": "We consider the problem of real-time data dissemination in wireless sensor\nnetworks, in which data are associated with deadlines and it is desired for\ndata to reach the sink(s) by their deadlines. To this end, existing real-time\ndata dissemination work have developed packet scheduling schemes that\nprioritize packets according to their deadlines. In this paper, we first\ndemonstrate that not only the scheduling discipline but also the routing\nprotocol has a significant impact on the success of real-time sensor data\ndissemination. We show that the shortest path routing using the minimum number\nof hops leads to considerably better performance than Geographical Forwarding,\nwhich has often been used in existing real-time data dissemination work. We\nalso observe that packet prioritization by itself is not enough for real-time\ndata dissemination, since many high priority packets may simultaneously contend\nfor network resources, deteriorating the network performance. Instead,\nreal-time packets could be judiciously delayed to avoid severe contention as\nlong as their deadlines can be met. Based on this observation, we propose a\nJust-in-Time Scheduling (JiTS) algorithm for scheduling data transmissions to\nalleviate the shortcomings of the existing solutions. We explore several\npolicies for non-uniformly delaying data at different intermediate nodes to\naccount for the higher expected contention as the packet gets closer to the\nsink(s). By an extensive simulation study, we demonstrate that JiTS can\nsignificantly improve the deadline miss ratio and packet drop ratio compared to\nexisting approaches in various situations. Notably, JiTS improves the\nperformance requiring neither lower layer support nor synchronization among the\nsensor nodes."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TCSII.2004.838657", 
    "link": "http://arxiv.org/pdf/cs/0608077v1", 
    "title": "The Effect of Scheduling on Link Capacity in Multi-hopWireless Networks", 
    "arxiv-id": "cs/0608077v1", 
    "author": "Nael Abu-Ghazaleh", 
    "publish": "2006-08-18T16:45:33Z", 
    "summary": "Existing models of Multi-Hop Wireless Networks (MHWNs) assume that\ninterference estimators of link quality such as observed busy time predict the\ncapacity of the links. We show that these estimators do not capture the\nintricate interactions that occur at the scheduling level, which have a large\nimpact on effective link capacity under contention based MAC protocols. We\nobserve that scheduling problems arise only among those interfering sources\nwhose concurrent transmissions cannot be prevented by the MAC protocol's\ncollision management mechanisms; other interfering sources can arbitrate the\nmedium and coexist successfully. Based on this observation, we propose a\nmethodology for rating links and show that it achieves high correlation with\nobserved behavior in simulation. We then use this rating as part of a\nbranch-and-bound framework based on a linear programming formulation for\ntraffic engineering in static MHWNs and show that it achieves considerable\nimprovement in performance relative to interference based models."
},{
    "category": "cs.NI", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0610134v1", 
    "title": "A Markov Chain based method for generating long-range dependence", 
    "arxiv-id": "cs/0610134v1", 
    "author": "Maurice Dodson", 
    "publish": "2006-10-23T13:54:18Z", 
    "summary": "This paper describes a model for generating time series which exhibit the\nstatistical phenomenon known as long-range dependence (LRD). A Markov Modulated\nProcess based upon an infinite Markov chain is described. The work described is\nmotivated by applications in telecommunications where LRD is a known property\nof time-series measured on the internet. The process can generate a time series\nexhibiting LRD with known parameters and is particularly suitable for modelling\ninternet traffic since the time series is in terms of ones and zeros which can\nbe interpreted as data packets and inter-packet gaps. The method is extremely\nsimple computationally and analytically and could prove more tractable than\nother methods described in the literature"
},{
    "category": "cs.PF", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0611037v2", 
    "title": "On Conditional Branches in Optimal Decision Trees", 
    "arxiv-id": "cs/0611037v2", 
    "author": "Michael B. Baer", 
    "publish": "2006-11-09T03:57:33Z", 
    "summary": "The decision tree is one of the most fundamental programming abstractions. A\ncommonly used type of decision tree is the alphabetic binary tree, which uses\n(without loss of generality) ``less than'' versus ''greater than or equal to''\ntests in order to determine one of $n$ outcome events. The process of finding\nan optimal alphabetic binary tree for a known probability distribution on\noutcome events usually has the underlying assumption that the cost (time) per\ndecision is uniform and thus independent of the outcome of the decision. This\nassumption, however, is incorrect in the case of software to be optimized for a\ngiven microprocessor, e.g., in compiling switch statements or in fine-tuning\nprogram bottlenecks. The operation of the microprocessor generally means that\nthe cost for the more likely decision outcome can or will be less -- often far\nless -- than the less likely decision outcome. Here we formulate a variety of\n$O(n^3)$-time $O(n^2)$-space dynamic programming algorithms to solve such\noptimal binary decision tree problems, optimizing for the behavior of\nprocessors with predictive branch capabilities, both static and dynamic. In the\nstatic case, we use existing results to arrive at entropy-based performance\nbounds. Solutions to this formulation are often faster in practice than\n``optimal'' decision trees as formulated in the literature, and, for small\nproblems, are easily worth the extra complexity in finding the better solution.\nThis can be applied in fast implementation of decoding Huffman codes."
},{
    "category": "cs.NI", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0611075v2", 
    "title": "Proportional Fairness in Multi-channel Multi-rate Wireless Networks-Part   I: The Case of Deterministic Channels", 
    "arxiv-id": "cs/0611075v2", 
    "author": "Ying Jun Zhang", 
    "publish": "2006-11-16T03:08:36Z", 
    "summary": "This is Part I of a two-part paper series that studies the use of the\nproportional fairness (PF) utility function as the basis for capacity\nallocation and scheduling in multi-channel multi-rate wireless networks. The\ncontributions of Part I are threefold. (i) First, we lay down the theoretical\nfoundation for PF. Specifically, we present the fundamental properties and\nphysical/economic interpretation of PF. We show by general mathematical\narguments that PF leads to equal airtime allocation to users for the\nsingle-channel case; and equal equivalent airtime allocation to users for the\nmulti-channel case, where the equivalent airtime enjoyed by a user is a\nweighted sum of the airtimes enjoyed by the user on all channels, with the\nweight of a channel being the price or value of that channel. We also establish\nthe Pareto efficiency of PF solutions. (ii) Second, we derive characteristics\nof PF solutions that are useful for the construction of PF-optimization\nalgorithms. We present several PF-optimization algorithms, including a fast\nalgorithm that is amenable to parallel implementation. (iii) Third, we study\nthe use of PF utility for capacity allocation in large-scale WiFi networks\nconsisting of many adjacent wireless LANs. We find that the PF solution\nsimultaneously achieves higher system throughput, better fairness, and lower\noutage probability with respect to the default solution given by today's 802.11\ncommercial products. Part II of this paper series extends our investigation to\nthe time-varying-channel case in which the data rates enjoyed by users over the\nchannels vary dynamically over time"
},{
    "category": "cs.PF", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0611076v2", 
    "title": "Proportional Fairness in Multi-channel Multi-rate Wireless Networks-Part   II: The Case of Time-Varying Channels", 
    "arxiv-id": "cs/0611076v2", 
    "author": "Ying Jun Zhang", 
    "publish": "2006-11-16T03:14:40Z", 
    "summary": "This is Part II of a two-part paper series that studies the use of the\nproportional fairness (PF) utility function as the basis for capacity\nallocation and scheduling in multi-channel multi-rate wireless networks. The\ncontributions of Part II are twofold. (i) First, we extend the problem\nformulation, theoretical results, and algorithms to the case of time-varying\nchannels, where opportunistic capacity allocation and scheduling can be\nexploited to improve system performance. We lay down the theoretical foundation\nfor optimization that \"couples\" the time-varying characteristic of channels\nwith the requirements of the underlying applications into one consideration. In\nparticular, the extent to which opportunistic optimization is possible is not\njust a function of how fast the channel characteristics vary, but also a\nfunction of the elasticity of the underlying applications for delayed capacity\nallocation. (ii) Second, building upon our theoretical framework and results,\nwe study subcarrier allocation and scheduling in orthogonal frequency division\nmultiplexing (OFDM) cellular wireless networks. We introduce the concept of a\nW-normalized Doppler frequency to capture the extent to which opportunistic\nscheduling can be exploited to achieve throughput-fairness performance gain. We\nshow that a \"look-back PF\" scheduling can strike a good balance between system\nthroughput and fairness while taking the underlying application requirements\ninto account."
},{
    "category": "cs.NA", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0611080v1", 
    "title": "A Multi-server Scheduling Framework for Resource Allocation in Wireless   Multi-carrier Networks", 
    "arxiv-id": "cs/0611080v1", 
    "author": "Ying Jun Zhang", 
    "publish": "2006-11-16T12:33:51Z", 
    "summary": "Multiuser resource allocation has recently been recognized as an effective\nmethodology for enhancing the power and spectrum efficiency in OFDM (orthogonal\nfrequency division multiplexing) systems. It is, however, not directly\napplicable to current packet-switched networks, because (i) most existing\npacket-scheduling schemes are based on a single-server model and do not serve\nmultiple users at the same time; and (ii) the conventional separate design of\nMAC (medium access control) packet scheduling and PHY (physical) resource\nallocation yields inefficient resource utilization. In this paper, we propose a\ncross-layer resource allocation algorithm based on a novel multi-server\nscheduling framework to achieve overall high system power efficiency in\npacket-switched OFDM networks. Our contribution is four fold: (i) we propose\nand analyze a MPGPS (multi-server packetized general processor sharing) service\ndiscipline that serves multiple users at the same time and facilitates\nmultiuser resource allocation; (ii) we present a MPGPS-based joint MAC-PHY\nresource allocation scheme that incorporates packet scheduling, subcarrier\nallocation, and power allocation in an integrated framework; (iii) by\ninvestigating the fundamental tradeoff between multiuser-diversity and queueing\nperformance, we present an A-MPGPS (adaptive MPGPS) service discipline that\nstrikes balance between power efficiency and queueing performance; and (iv) we\nextend MPGPS to an O-MPGPS (opportunistic MPGPS) service discipline to further\nenhance the resource utilization efficiency."
},{
    "category": "cs.DC", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0611091v2", 
    "title": "Lossy Bulk Synchronous Parallel Processing Model for Very Large Scale   Grids", 
    "arxiv-id": "cs/0611091v2", 
    "author": "Kotagiri Ramamohanarao", 
    "publish": "2006-11-20T00:20:44Z", 
    "summary": "The performance of a parallel algorithm in a very large scale grid is\nsignificantly influenced by the underlying Internet protocols and\ninter-connectivity. Many grid programming platforms use TCP due to its\nreliability, usually with some optimizations to reduce its costs. However, TCP\ndoes not perform well in a high bandwidth and high delay network environment.\nOn the other hand, UDP is the fastest protocol available because it omits\nconnection setup process, acknowledgments and retransmissions sacrificing\nreliable transfer. Many new bulk data transfer schemes using UDP for data\ntransmission such as RBUDP, Tsunami, and SABUL have been introduced and shown\nto have better performance compared to TCP. In this paper, we consider the use\nof UDP and examine the relationship between packet loss and speedup with\nrespect to the number of grid nodes. Our measurement suggests that packet loss\nrates between 5%-15% on average are not uncommon between PlanetLab nodes that\nare widely distributed over the Internet. We show that transmitting multiple\ncopies of same packet produces higher speedup. We show the minimum number of\npacket duplication required to maximize the possible speedup for a given number\nof nodes using a BSP based model. Our work demonstrates that by using an\nappropriate number of packet copies, we can increase performance of parallel\nprogram."
},{
    "category": "cs.NI", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0701130v1", 
    "title": "On the Correlation of Geographic and Network Proximity at Internet Edges   and its Implications for Mobile Unicast and Multicast Routing", 
    "arxiv-id": "cs/0701130v1", 
    "author": "Ying Zhang", 
    "publish": "2007-01-20T23:06:57Z", 
    "summary": "Significant effort has been invested recently to accelerate handover\noperations in a next generation mobile Internet. Corresponding works for\ndeveloping efficient mobile multicast management are emergent. Both problems\nsimultaneously expose routing complexity between subsequent points of\nattachment as a characteristic parameter for handover performance in access\nnetworks.\n  As continuous mobility handovers necessarily occur between access routers\nlocated in geographic vicinity, this paper investigates on the hypothesis that\ngeographically adjacent edge networks attain a reduced network distances as\ncompared to arbitrary Internet nodes. We therefore evaluate and analyze edge\ndistance distributions in various regions for clustered IP ranges on their\ngeographic location such as a city. We use traceroute to collect packet\nforwarding path and round-trip-time of each intermediate node to scan-wise\nderive an upper bound of the node distances. Results of different scanning\norigins are compared to obtain the best estimation of network distance of each\npair. Our results are compared with corresponding analysis of CAIDA Skitter\ndata, overall leading to fairly stable, reproducible edge distance\ndistributions. As a first conclusion on expected impact on handover performance\nmeasures, our results indicate a general optimum for handover anticipation time\nin 802.11 networks of 25 ms."
},{
    "category": "cs.DC", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/cs/0702157v1", 
    "title": "In Search of Simplicity: A Self-Organizing Multi-Source Multicast   Overlay", 
    "arxiv-id": "cs/0702157v1", 
    "author": "Anne Rogers", 
    "publish": "2007-02-27T19:42:40Z", 
    "summary": "Multicast communication primitives have broad utility as building blocks for\ndistributed applications. The challenge is to create and maintain the\ndistributed structures that support these primitives while accounting for\nvolatile end nodes and variable network characteristics. Most solutions\nproposed to date rely on complex algorithms or global information, thus\nlimiting the scale of deployments and acceptance outside the academic realm.\nThis article introduces a low-complexity, self organizing solution for\nmaintaining multicast trees, that we refer to as UMM (Unstructured Multi-source\nMulticast). UMM uses traditional distributed systems techniques: layering,\nsoft-state, and passive data collection to adapt to the dynamics of the\nphysical network and maintain data dissemination trees. The result is a simple,\nadaptive system with lower overheads than more complex alternatives. We have\nimplemented UMM and evaluated it on a 100-node PlanetLab testbed and on up to\n1024-node emulated ModelNet networks Extensive experimental evaluations\ndemonstrate UMM's low overhead, efficient network usage compared to alternative\nsolutions, and ability to quickly adapt to network changes and to recover from\nfailures."
},{
    "category": "physics.ins-det", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/physics/0405154v1", 
    "title": "The ATLAS Tile Calorimeter Test Beam Monitoring Program", 
    "arxiv-id": "physics/0405154v1", 
    "author": "Chiara Roda", 
    "publish": "2004-05-29T10:05:51Z", 
    "summary": "During 2003 test beam session for ATLAS Tile Calorimeter a monitoring program\nhas been developed to ease the setup of correct running condition and the\nassessment of data quality. The program has been built using the Online\nSoftware services provided by the ATLAS Online Software group. The first part\nof this note contains a brief overview of these services followed by the full\ndescription of Tile Calorimeter monitoring program architecture and features.\nPerformances and future upgrades are discussed in the final part of this note."
},{
    "category": "cs.IT", 
    "doi": "10.1103/PhysRevE.72.026118", 
    "link": "http://arxiv.org/pdf/0704.1070v1", 
    "title": "Differential Diversity Reception of MDPSK over Independent Rayleigh   Channels with Nonidentical Branch Statistics and Asymmetric Fading Spectrum", 
    "arxiv-id": "0704.1070v1", 
    "author": "Pooi Yuen Kam", 
    "publish": "2007-04-09T07:16:39Z", 
    "summary": "This paper is concerned with optimum diversity receiver structure and its\nperformance analysis of differential phase shift keying (DPSK) with\ndifferential detection over nonselective, independent, nonidentically\ndistributed, Rayleigh fading channels. The fading process in each branch is\nassumed to have an arbitrary Doppler spectrum with arbitrary Doppler bandwidth,\nbut to have distinct, asymmetric fading power spectral density characteristic.\nUsing 8-DPSK as an example, the average bit error probability (BEP) of the\noptimum diversity receiver is obtained by calculating the BEP for each of the\nthree individual bits. The BEP results derived are given in exact, explicit,\nclosed-form expressions which show clearly the behavior of the performance as a\nfunction of various system parameters."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0710.2887v1", 
    "title": "Implementation, Compilation, Optimization of Object-Oriented Languages,   Programs and Systems - Report on the Workshop ICOOOLPS'2006 at ECOOP'06", 
    "arxiv-id": "0710.2887v1", 
    "author": "Olivier Zendra", 
    "publish": "2007-10-15T17:53:49Z", 
    "summary": "ICOOOLPS'2006 was the first edition of ECOOP-ICOOOLPS workshop. It intended\nto bring researchers and practitioners both from academia and industry\ntogether, with a spirit of openness, to try and identify and begin to address\nthe numerous and very varied issues of optimization. This succeeded, as can be\nseen from the papers, the attendance and the liveliness of the discussions that\ntook place during and after the workshop, not to mention a few new cooperations\nor postdoctoral contracts. The 22 talented people from different groups who\nparticipated were unanimous to appreciate this first edition and recommend that\nICOOOLPS be continued next year. A community is thus beginning to form, and\nshould be reinforced by a second edition next year, with all the improvements\nthis first edition made emerge."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0710.3283v2", 
    "title": "Effects of Non-Identical Rayleigh Fading on Differential Unitary   Space-Time Modulation", 
    "arxiv-id": "0710.3283v2", 
    "author": "Meixia Tao", 
    "publish": "2007-10-17T12:32:29Z", 
    "summary": "This paper has been withdrawn by the author."
},{
    "category": "cs.DB", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0712.2773v2", 
    "title": "Middleware-based Database Replication: The Gaps between Theory and   Practice", 
    "arxiv-id": "0712.2773v2", 
    "author": "Anastasia Ailamaki", 
    "publish": "2007-12-17T18:42:15Z", 
    "summary": "The need for high availability and performance in data management systems has\nbeen fueling a long running interest in database replication from both academia\nand industry. However, academic groups often attack replication problems in\nisolation, overlooking the need for completeness in their solutions, while\ncommercial teams take a holistic approach that often misses opportunities for\nfundamental innovation. This has created over time a gap between academic\nresearch and industrial practice.\n  This paper aims to characterize the gap along three axes: performance,\navailability, and administration. We build on our own experience developing and\ndeploying replication systems in commercial and academic settings, as well as\non a large body of prior related work. We sift through representative examples\nfrom the last decade of open-source, academic, and commercial database\nreplication systems and combine this material with case studies from real\nsystems deployed at Fortune 500 customers. We propose two agendas, one for\nacademic research and one for industrial R&D, which we believe can bridge the\ngap within 5-10 years. This way, we hope to both motivate and help researchers\nin making the theory and practice of middleware-based database replication more\nrelevant to each other."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0802.1123v2", 
    "title": "Snap-Stabilization in Message-Passing Systems", 
    "arxiv-id": "0802.1123v2", 
    "author": "S\u00e9bastien Tixeuil", 
    "publish": "2008-02-08T10:51:24Z", 
    "summary": "In this paper, we tackle the open problem of snap-stabilization in\nmessage-passing systems. Snap-stabilization is a nice approach to design\nprotocols that withstand transient faults. Compared to the well-known\nself-stabilizing approach, snap-stabilization guarantees that the effect of\nfaults is contained immediately after faults cease to occur. Our contribution\nis twofold: we show that (1) snap-stabilization is impossible for a wide class\nof problems if we consider networks with finite yet unbounded channel capacity;\n(2) snap-stabilization becomes possible in the same setting if we assume\nbounded-capacity channels. We propose three snap-stabilizing protocols working\nin fully-connected networks. Our work opens exciting new research perspectives,\nas it enables the snap-stabilizing paradigm to be implemented in actual\nnetworks."
},{
    "category": "cs.DB", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0802.3448v1", 
    "title": "Sketch-Based Estimation of Subpopulation-Weight", 
    "arxiv-id": "0802.3448v1", 
    "author": "Haim Kaplan", 
    "publish": "2008-02-23T15:25:04Z", 
    "summary": "Summaries of massive data sets support approximate query processing over the\noriginal data. A basic aggregate over a set of records is the weight of\nsubpopulations specified as a predicate over records' attributes. Bottom-k\nsketches are a powerful summarization format of weighted items that includes\npriority sampling and the classic weighted sampling without replacement. They\ncan be computed efficiently for many representations of the data including\ndistributed databases and data streams.\n  We derive novel unbiased estimators and efficient confidence bounds for\nsubpopulation weight. Our estimators and bounds are tailored by distinguishing\nbetween applications (such as data streams) where the total weight of the\nsketched set can be computed by the summarization algorithm without a\nsignificant use of additional resources, and applications (such as sketches of\nnetwork neighborhoods) where this is not the case.\n  Our rigorous derivations are based on clever applications of the\nHorvitz-Thompson estimator, and are complemented by efficient computational\nmethods. We demonstrate their benefit on a wide range of Pareto distributions."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0803.0189v2", 
    "title": "Quiescence of Self-stabilizing Gossiping among Mobile Agents in Graphs", 
    "arxiv-id": "0803.0189v2", 
    "author": "S\u00e9bastien Tixeuil", 
    "publish": "2008-03-03T09:14:21Z", 
    "summary": "This paper considers gossiping among mobile agents in graphs: agents move on\nthe graph and have to disseminate their initial information to every other\nagent. We focus on self-stabilizing solutions for the gossip problem, where\nagents may start from arbitrary locations in arbitrary states.\nSelf-stabilization requires (some of the) participating agents to keep moving\nforever, hinting at maximizing the number of agents that could be allowed to\nstop moving eventually. This paper formalizes the self-stabilizing agent gossip\nproblem, introduces the quiescence number (i.e., the maximum number of\neventually stopping agents) of self-stabilizing solutions and investigates the\nquiescence number with respect to several assumptions related to agent\nanonymity, synchrony, link duplex capacity, and whiteboard capacity."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0803.3338v1", 
    "title": "Performance Evaluation of Multiple TCP connections in iSCSI", 
    "arxiv-id": "0803.3338v1", 
    "author": "K. Gopinath", 
    "publish": "2008-03-23T19:10:00Z", 
    "summary": "Scaling data storage is a significant concern in enterprise systems and\nStorage Area Networks (SANs) are deployed as a means to scale enterprise\nstorage. SANs based on Fibre Channel have been used extensively in the last\ndecade while iSCSI is fast becoming a serious contender due to its reduced\ncosts and unified infrastructure. This work examines the performance of iSCSI\nwith multiple TCP connections. Multiple TCP connections are often used to\nrealize higher bandwidth but there may be no fairness in how bandwidth is\ndistributed. We propose a mechanism to share congestion information across\nmultiple flows in ``Fair-TCP'' for improved performance. Our results show that\nFair-TCP significantly improves the performance for I/O intensive workloads."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0804.4039v2", 
    "title": "Energy and Time Efficient Scheduling of Tasks with Dependencies on   Asymmetric Multiprocessors", 
    "arxiv-id": "0804.4039v2", 
    "author": "Paul G. Spirakis", 
    "publish": "2008-04-25T03:16:21Z", 
    "summary": "In this work we study the problem of scheduling tasks with dependencies in\nmultiprocessor architectures where processors have different speeds. We present\nthe preemptive algorithm \"Save-Energy\" that given a schedule of tasks it post\nprocesses it to improve the energy efficiency without any deterioration of the\nmakespan. In terms of time efficiency, we show that preemptive scheduling in an\nasymmetric system can achieve the same or better optimal makespan than in a\nsymmetric system. Motivited by real multiprocessor systems, we investigate\narchitectures that exhibit limited asymmetry: there are two essentially\ndifferent speeds. Interestingly, this special case has not been studied in the\nfield of parallel computing and scheduling theory; only the general case was\nstudied where processors have $K$ essentially different speeds. We present the\nnon-preemptive algorithm ``Remnants'' that achieves almost optimal makespan. We\nprovide a refined analysis of a recent scheduling method. Based on this\nanalysis, we specialize the scheduling policy and provide an algorithm of $(3 +\no(1))$ expected approximation factor. Note that this improves the previous best\nfactor (6 for two speeds). We believe that our work will convince researchers\nto revisit this well studied scheduling problem for these simple, yet\nrealistic, asymmetric multiprocessor architectures."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0805.2949v1", 
    "title": "Performability Aspects of the Atlas Vo; Using Lmbench Suite", 
    "arxiv-id": "0805.2949v1", 
    "author": "John Kouretis", 
    "publish": "2008-05-19T19:45:31Z", 
    "summary": "The ATLAS Virtual Organization is grid's largest Virtual Organization which\nis currently in full production stage. Hereby a case is being made that a user\nworking within that VO is going to face a wide spectrum of different systems,\nwhose heterogeneity is enough to count as \"orders of magnitude\" according to a\nnumber of metrics; including integer/float operations, memory throughput\n(STREAM) and communication latencies. Furthermore, the spread of performance\ndoes not appear to follow any known distribution pattern, which is demonstrated\nin graphs produced during May 2007 measurements. It is implied that the current\npractice where either \"all-WNs-are-equal\" or, the alternative of SPEC-based\nrating used by LCG/EGEE is an oversimplification which is inappropriate and\nexpensive from an operational point of view, therefore new techniques are\nneeded for optimal grid resources allocation."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0809.1177v1", 
    "title": "Amdahl's and Gustafson-Barsis laws revisited", 
    "arxiv-id": "0809.1177v1", 
    "author": "Andrzej Karbowski", 
    "publish": "2008-09-06T15:06:53Z", 
    "summary": "The paper presents a simple derivation of the Gustafson-Barsis law from the\nAmdahl's law. In the computer literature these two laws describing the speedup\nlimits of parallel applications are derived separately. It is shown, that\ntreating the time of the execution of the sequential part of the application as\na constant, in few lines the Gustafson-Barsis law can be obtained from the\nAmdahl's law and that the popular claim, that Gustafson-Barsis law overthrows\nAmdahl's law is a mistake."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0810.3468v1", 
    "title": "A Call-Graph Profiler for GNU Octave", 
    "arxiv-id": "0810.3468v1", 
    "author": "Leela Velusamy", 
    "publish": "2008-10-20T08:29:21Z", 
    "summary": "We report the design and implementation of a call-graph profiler for GNU\nOctave, a numerical computing platform. GNU Octave simplifies matrix\ncomputation for use in modeling or simulation. Our work provides a call-graph\nprofiler, which is an improvement on the flat profiler. We elaborate design\nconstraints of building a profiler for numerical computation, and benchmark the\nprofiler by comparing it to the rudimentary timer start-stop (tic-toc)\nmeasurements, for a similar set of programs. The profiler code provides clean\ninterfaces to internals of GNU Octave, for other (newer) profiling tools on GNU\nOctave."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0811.3272v3", 
    "title": "Characterizing the Robustness of Complex Networks", 
    "arxiv-id": "0811.3272v3", 
    "author": "Phillip Schumm", 
    "publish": "2008-11-20T07:35:39Z", 
    "summary": "With increasingly ambitious initiatives such as GENI and FIND that seek to\ndesign the future Internet, it becomes imperative to define the characteristics\nof robust topologies, and build future networks optimized for robustness. This\npaper investigates the characteristics of network topologies that maintain a\nhigh level of throughput in spite of multiple attacks. To this end, we select\nnetwork topologies belonging to the main network models and some real world\nnetworks. We consider three types of attacks: removal of random nodes, high\ndegree nodes, and high betweenness nodes. We use elasticity as our robustness\nmeasure and, through our analysis, illustrate that different topologies can\nhave different degrees of robustness. In particular, elasticity can fall as low\nas 0.8% of the upper bound based on the attack employed. This result\nsubstantiates the need for optimized network topology design. Furthermore, we\nimplement a tradeoff function that combines elasticity under the three attack\nstrategies and considers the cost of the network. Our extensive simulations\nshow that, for a given network density, regular and semi-regular topologies can\nhave higher degrees of robustness than heterogeneous topologies, and that link\nredundancy is a sufficient but not necessary condition for robustness."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0902.4481v2", 
    "title": "Stability of Finite Population ALOHA with Variable Packets", 
    "arxiv-id": "0902.4481v2", 
    "author": "Jian Tan", 
    "publish": "2009-02-25T22:59:58Z", 
    "summary": "ALOHA is one of the most basic Medium Access Control (MAC) protocols and\nrepresents a foundation for other more sophisticated distributed and\nasynchronous MAC protocols, e.g., CSMA. In this paper, unlike in the\ntraditional work that focused on mean value analysis, we study the\ndistributional properties of packet transmission delays over an ALOHA channel.\nWe discover a new phenomenon showing that a basic finite population ALOHA model\nwith variable size (exponential) packets is characterized by power law\ntransmission delays, possibly even resulting in zero throughput. These results\nare in contrast to the classical work that shows exponential delays and\npositive throughput for finite population ALOHA with fixed packets.\nFurthermore, we characterize a new stability condition that is entirely derived\nfrom the tail behavior of the packet and backoff distributions that may not be\ndetermined by mean values. The power law effects and the possible instability\nmight be diminished, or perhaps eliminated, by reducing the variability of\npackets. However, we show that even a slotted (synchronized) ALOHA with packets\nof constant size can exhibit power law delays when the number of active users\nis random. From an engineering perspective, our results imply that the\nvariability of packet sizes and number of active users need to be taken into\nconsideration when designing robust MAC protocols, especially for ad-hoc/sensor\nnetworks where other factors, such as link failures and mobility, might further\ncompound the problem."
},{
    "category": "cs.DS", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0903.0034v1", 
    "title": "Measuring Independence of Datasets", 
    "arxiv-id": "0903.0034v1", 
    "author": "Rafail Ostrovsky", 
    "publish": "2009-03-01T01:29:54Z", 
    "summary": "A data stream model represents setting where approximating pairwise, or\n$k$-wise, independence with sublinear memory is of considerable importance. In\nthe streaming model the joint distribution is given by a stream of $k$-tuples,\nwith the goal of testing correlations among the components measured over the\nentire stream. In the streaming model, Indyk and McGregor (SODA 08) recently\ngave exciting new results for measuring pairwise independence. The Indyk and\nMcGregor methods provide $\\log{n}$-approximation under statistical distance\nbetween the joint and product distributions in the streaming model. Indyk and\nMcGregor leave, as their main open question, the problem of improving their\n$\\log n$-approximation for the statistical distance metric.\n  In this paper we solve the main open problem posed by of Indyk and McGregor\nfor the statistical distance for pairwise independence and extend this result\nto any constant $k$. In particular, we present an algorithm that computes an\n$(\\epsilon, \\delta)$-approximation of the statistical distance between the\njoint and product distributions defined by a stream of $k$-tuples. Our\nalgorithm requires $O(({1\\over \\epsilon}\\log({nm\\over \\delta}))^{(30+k)^k})$\nmemory and a single pass over the data stream."
},{
    "category": "math.PR", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0903.2352v3", 
    "title": "A Mean Field Approach for Optimization in Particles Systems and   Applications", 
    "arxiv-id": "0903.2352v3", 
    "author": "Bruno Gaujal", 
    "publish": "2009-03-13T10:42:34Z", 
    "summary": "This paper investigates the limit behavior of Markov Decision Processes\n(MDPs) made of independent particles evolving in a common environment, when the\nnumber of particles goes to infinity. In the finite horizon case or with a\ndiscounted cost and an infinite horizon, we show that when the number of\nparticles becomes large, the optimal cost of the system converges almost surely\nto the optimal cost of a discrete deterministic system (the ``optimal mean\nfield''). Convergence also holds for optimal policies. We further provide\ninsights on the speed of convergence by proving several central limits theorems\nfor the cost and the state of the Markov decision process with explicit\nformulas for the variance of the limit Gaussian laws. Then, our framework is\napplied to a brokering problem in grid computing. The optimal policy for the\nlimit deterministic system is computed explicitly. Several simulations with\ngrowing numbers of processors are reported. They compare the performance of the\noptimal policy of the limit system used in the finite case with classical\npolicies (such as Join the Shortest Queue) by measuring its asymptotic gain as\nwell as the threshold above which it starts outperforming classical policies."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-3-540-71774-4_1", 
    "link": "http://arxiv.org/pdf/0904.4512v1", 
    "title": "Bounds on series-parallel slowdown", 
    "arxiv-id": "0904.4512v1", 
    "author": "Vashti Galpin", 
    "publish": "2009-04-29T01:39:57Z", 
    "summary": "We use activity networks (task graphs) to model parallel programs and\nconsider series-parallel extensions of these networks. Our motivation is\ntwo-fold: the benefits of series-parallel activity networks and the modelling\nof programming constructs, such as those imposed by current parallel computing\nenvironments. Series-parallelisation adds precedence constraints to an activity\nnetwork, usually increasing its makespan (execution time). The slowdown ratio\ndescribes how additional constraints affect the makespan. We disprove an\nexisting conjecture positing a bound of two on the slowdown when workload is\nnot considered. Where workload is known, we conjecture that 4/3 slowdown is\nalways achievable, and prove our conjecture for small networks using max-plus\nalgebra. We analyse a polynomial-time algorithm showing that achieving 4/3\nslowdown is in exp-APX. Finally, we discuss the implications of our results."
},{
    "category": "cs.DC", 
    "doi": "10.1145/1555336.1555338", 
    "link": "http://arxiv.org/pdf/0906.1147v1", 
    "title": "Enabling and Optimizing Pilot Jobs using Xen based Virtual Machines for   the HPC Grid Applications", 
    "arxiv-id": "0906.1147v1", 
    "author": "Kevin Parrott", 
    "publish": "2009-06-05T15:26:14Z", 
    "summary": "The primary motivation for uptake of virtualization have been resource\nisolation, capacity management and resource customization: isolation and\ncapacity management allow providers to isolate users from the site and control\ntheir resources usage while customization allows end-users to easily project\nthe required environment onto a variety of sites. Various approaches have been\ntaken to integrate virtualization with Grid technologies. In this paper, we\npropose an approach that combines virtualization on the existing software\ninfrastructure such as Pilot Jobs with minimum change on the part of resource\nproviders."
},{
    "category": "cs.NI", 
    "doi": "10.1109/CEC.2007.4424955", 
    "link": "http://arxiv.org/pdf/0906.3461v1", 
    "title": "AIS for Misbehavior Detection in Wireless Sensor Networks: Performance   and Design Principles", 
    "arxiv-id": "0906.3461v1", 
    "author": "Helena Szczerbicka", 
    "publish": "2009-06-18T15:31:29Z", 
    "summary": "A sensor network is a collection of wireless devices that are able to monitor\nphysical or environmental conditions. These devices (nodes) are expected to\noperate autonomously, be battery powered and have very limited computational\ncapabilities. This makes the task of protecting a sensor network against\nmisbehavior or possible malfunction a challenging problem. In this document we\ndiscuss performance of Artificial immune systems (AIS) when used as the\nmechanism for detecting misbehavior.\n  We show that (i) mechanism of the AIS have to be carefully applied in order\nto avoid security weaknesses, (ii) the choice of genes and their interaction\nhave a profound influence on the performance of the AIS, (iii) randomly created\ndetectors do not comply with limitations imposed by communications protocols\nand (iv) the data traffic pattern seems not to impact significantly the overall\nperformance.\n  We identified a specific MAC layer based gene that showed to be especially\nuseful for detection; genes measure a network's performance from a node's\nviewpoint. Furthermore, we identified an interesting complementarity property\nof genes; this property exploits the local nature of sensor networks and moves\nthe burden of excessive communication from normally behaving nodes to\nmisbehaving nodes. These results have a direct impact on the design of AIS for\nsensor networks and on engineering of sensor networks."
},{
    "category": "cs.IT", 
    "doi": "10.1109/CEC.2007.4424955", 
    "link": "http://arxiv.org/pdf/0908.1116v1", 
    "title": "Enhanced Algorithm for Link to System level Interface Mapping", 
    "arxiv-id": "0908.1116v1", 
    "author": "Rasool Sadeghi", 
    "publish": "2009-08-07T20:27:49Z", 
    "summary": "The current SINR mechanism does not provide the base station (BS) with any\nknowledge on the frequency selectivity of channel from mobile service\nstation(MSS). This knowledge is important since, contrary to the AWGN channel,\nin a frequency selective channel there is no longer a 1 to 1 relation between\namount of increase in power and amount of improvement in effective SINR 1.\nFurthermore, the relation is dependent on MCS level. This lack of knowledge in\nthe BS side results in larger fade margins, which translates directly to\nreduction in capacity. In this paper we propose a enhanced algorithm on the\nEESM model with weighted beta (\\beta) that provides the BS with sufficient\nknowledge on the channel-dependent relationship between power increase, MCS\nchange and improvement in effective SINR."
},{
    "category": "cs.IT", 
    "doi": "10.1109/CEC.2007.4424955", 
    "link": "http://arxiv.org/pdf/0908.1407v1", 
    "title": "Generalized Analysis of a Distributed Energy Efficient Algorithm for   Change Detection", 
    "arxiv-id": "0908.1407v1", 
    "author": "Vinod Sharma", 
    "publish": "2009-08-10T21:21:00Z", 
    "summary": "An energy efficient distributed Change Detection scheme based on Page's CUSUM\nalgorithm was presented in \\cite{icassp}. In this paper we consider a\nnonparametric version of this algorithm. In the algorithm in \\cite{icassp},\neach sensor runs CUSUM and transmits only when the CUSUM is above some\nthreshold. The transmissions from the sensors are fused at the physical layer.\nThe channel is modeled as a Multiple Access Channel (MAC) corrupted with noise.\nThe fusion center performs another CUSUM to detect the change. In this paper,\nwe generalize the algorithm to also include nonparametric CUSUM and provide a\nunified analysis."
},{
    "category": "physics.soc-ph", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0908.2681v1", 
    "title": "Effects of Diversity and Procrastination in Priority Queuing Theory: the   Different Power Law Regimes", 
    "arxiv-id": "0908.2681v1", 
    "author": "D. Sornette", 
    "publish": "2009-08-19T07:00:12Z", 
    "summary": "Empirical analysis show that, after the update of a browser, the publication\nof the vulnerability of a software, or the discovery of a cyber worm, the\nfraction of computers still using the older version, or being not yet patched,\nor exhibiting worm activity decays as power laws $\\sim 1/t^{\\alpha}$ with $0 <\n\\alpha \\leq 1$ over time scales of years. We present a simple model for this\npersistence phenomenon framed within the standard priority queuing theory, of a\ntarget task which has the lowest priority compared with all other tasks that\nflow on the computer of an individual. We identify a \"time deficit\" control\nparameter $\\beta$ and a bifurcation to a regime where there is a non-zero\nprobability for the target task to never be completed. The distribution of\nwaiting time ${\\cal T}$ till the completion of the target task has the power\nlaw tail $\\sim 1/t^{1/2}$, resulting from a first-passage solution of an\nequivalent Wiener process. Taking into account a diversity of time deficit\nparameters in a population of individuals, the power law tail is changed into\n$1/t^\\alpha$ with $\\alpha\\in(0.5,\\infty)$, including the well-known case $1/t$.\nWe also study the effect of \"procrastination\", defined as the situation in\nwhich the target task may be postponed or delayed even after the individual has\nsolved all other pending tasks. This new regime provides an explanation for\neven slower apparent decay and longer persistence."
},{
    "category": "cs.DB", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0909.1758v1", 
    "title": "Teaching an Old Elephant New Tricks", 
    "arxiv-id": "0909.1758v1", 
    "author": "Nicolas Bruno", 
    "publish": "2009-09-09T18:00:21Z", 
    "summary": "In recent years, column stores (or C-stores for short) have emerged as a\nnovel approach to deal with read-mostly data warehousing applications.\nExperimental evidence suggests that, for certain types of queries, the new\nfeatures of C-stores result in orders of magnitude improvement over traditional\nrelational engines. At the same time, some C-store proponents argue that\nC-stores are fundamentally different from traditional engines, and therefore\ntheir benefits cannot be incorporated into a relational engine short of a\ncomplete rewrite. In this paper we challenge this claim and show that many of\nthe benefits of C-stores can indeed be simulated in traditional engines with no\nchanges whatsoever. We then identify some limitations of our ?pure-simulation?\napproach for the case of more complex queries. Finally, we predict that\ntraditional relational engines will eventually leverage most of the benefits of\nC-stores natively, as is currently happening in other domains such as XML data."
},{
    "category": "cs.DB", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0910.0983v1", 
    "title": "On Metric Skyline Processing by PM-tree", 
    "arxiv-id": "0910.0983v1", 
    "author": "Jakub Lokoc", 
    "publish": "2009-10-06T12:09:52Z", 
    "summary": "The task of similarity search in multimedia databases is usually accomplished\nby range or k nearest neighbor queries. However, the expressing power of these\n\"single-example\" queries fails when the user's delicate query intent is not\navailable as a single example. Recently, the well-known skyline operator was\nreused in metric similarity search as a \"multi-example\" query type. When\napplied on a multi-dimensional database (i.e., on a multi-attribute table), the\ntraditional skyline operator selects all database objects that are not\ndominated by other objects. The metric skyline query adopts the skyline\noperator such that the multiple attributes are represented by distances\n(similarities) to multiple query examples. Hence, we can view the metric\nskyline as a set of representative database objects which are as similar to all\nthe examples as possible and, simultaneously, are semantically distinct. In\nthis paper we propose a technique of processing the metric skyline query by use\nof PM-tree, while we show that our technique significantly outperforms the\noriginal M-tree based implementation in both time and space costs. In\nexperiments we also evaluate the partial metric skyline processing, where only\na controlled number of skyline objects is retrieved."
},{
    "category": "cs.DS", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0910.2582v1", 
    "title": "Scalable Distributed-Memory External Sorting", 
    "arxiv-id": "0910.2582v1", 
    "author": "Johannes Singler", 
    "publish": "2009-10-14T12:18:28Z", 
    "summary": "We engineer algorithms for sorting huge data sets on massively parallel\nmachines. The algorithms are based on the multiway merging paradigm. We first\noutline an algorithm whose I/O requirement is close to a lower bound. Thus, in\ncontrast to naive implementations of multiway merging and all other approaches\nknown to us, the algorithm works with just two passes over the data even for\nthe largest conceivable inputs. A second algorithm reduces communication\noverhead and uses more conventional specifications of the result at the cost of\nslightly increased I/O requirements. An implementation wins the well known\nsorting benchmark in several categories and by a large margin over its\ncompetitors."
},{
    "category": "cs.NI", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0911.0480v2", 
    "title": "Routing Technique Based on Clustering for Data Duplication Prevention in   Wireless Sensor Network", 
    "arxiv-id": "0911.0480v2", 
    "author": "Yongtae Shin", 
    "publish": "2009-11-03T03:29:51Z", 
    "summary": "Wireless Sensor Networks is important to nodes energy consumption for long\nactivity of sensor nodes because nodes that compose sensor network are small\nsize, and battery capacity is limited. For energy consumption decrease of\nsensor nodes, sensor networks routing technique is divided by flat routing and\nhierarchical routing technique. Specially, hierarchical routing technique is\nenergy efficient routing protocol to pare down energy consumption of whole\nsensor nodes and to scatter energy consumption of sensor nodes by forming\ncluster and communicating with cluster head. but though hierarchical routing\ntechnique based on clustering is advantage more than flat routing technique,\nthis is not used for reason that is not realistic. The reason that is not\nrealistic is because hierarchical routing technique does not consider data\ntransmission radius of sensor node in actually. so this paper propose realistic\nrouting technique base on clustering."
},{
    "category": "cs.DC", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0911.2889v1", 
    "title": "Global communications in multiprocessor simulations of flames", 
    "arxiv-id": "0911.2889v1", 
    "author": "V. Karlin", 
    "publish": "2009-11-15T17:10:31Z", 
    "summary": "In this paper we investigate performance of global communications in a\nparticular parallel code. The code simulates dynamics of expansion of premixed\nspherical flames using an asymptotic model of Sivashinsky type and a spectral\nnumerical algorithm. As a result, the code heavily relies on global all-to-all\ninterprocessor communications implementing transposition of the distributed\ndata array in which numerical solution to the problem is stored. This global\ndata interdependence makes interprocessor connectivity of the HPC system as\nimportant as the floating-point power of the processors of which the system is\nbuilt. Our experiments show that efficient numerical simulation of this\nparticular model, with global data interdependence, on modern HPC systems is\npossible. Prospects of performance of more sophisticated models of flame\ndynamics are analysed as well."
},{
    "category": "cs.CR", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0911.4033v1", 
    "title": "Extending Firewall Session Table to Accelerate NAT, QoS Classification   and Routing", 
    "arxiv-id": "0911.4033v1", 
    "author": "Christian Fraboul", 
    "publish": "2009-11-20T12:56:49Z", 
    "summary": "security and QoS are the two most precious objectives for network systems to\nbe attained. Unfortunately, they are in conflict, while QoS tries to minimize\nprocessing delay, strong security protection requires more processing time and\ncause packet delay. This article is a step towards resolving this conflict by\nextending the firewall session table to accelerate NAT, QoS classification, and\nrouting processing time while providing the same level of security protection.\nIndex Terms ? stateful packet filtering; firewall; session/state table; QoS;\nNAT; Routing."
},{
    "category": "cs.CR", 
    "doi": "10.1103/PhysRevE.81.016108", 
    "link": "http://arxiv.org/pdf/0911.4034v2", 
    "title": "Q-ESP: a QoS-compliant Security Protocol to enrich IPSec Framework", 
    "arxiv-id": "0911.4034v2", 
    "author": "Christian Fraboul", 
    "publish": "2009-11-20T12:59:13Z", 
    "summary": "IPSec is a protocol that allows to make secure connections between branch\noffices and allows secure VPN accesses. However, the efforts to improve IPSec\nare still under way; one aspect of this improvement is to take Quality of\nService (QoS) requirements into account. QoS is the ability of the network to\nprovide a service at an assured service level while optimizing the global usage\nof network resources. The QoS level that a flow receives depends on a six-bit\nidentifier in the IP header; the so-called Differentiated Services code point\n(DSCP). Basically, Multi-Field classifiers classify a packet by inspecting\nIP/TCP headers, to decide how the packet should be processed. The current IPSec\nstandard does hardly offer any guidance to do this, because the existing IPSec\nESP security protocol hides much of this information in its encrypted payloads,\npreventing network control devices such as routers and switches from utilizing\nthis information in performing classification appropriately. To solve this\nproblem, we propose a QoS-friendly Encapsulated Security Payload (Q-ESP) as a\nnew IPSec security protocol that provides both security and QoS supports. We\nalso present our NetBSD kernel-based implementation as well as our evaluation\nresults of Q-ESP."
},{
    "category": "cs.FL", 
    "doi": "10.4204/EPTCS.13.1", 
    "link": "http://arxiv.org/pdf/0912.1897v1", 
    "title": "Adaptive Scheduling of Data Paths using Uppaal Tiga", 
    "arxiv-id": "0912.1897v1", 
    "author": "Frits Vaandrager", 
    "publish": "2009-12-10T12:01:37Z", 
    "summary": "We apply Uppaal Tiga to automatically compute adaptive scheduling strategies\nfor an industrial case study dealing with a state-of-the-art image processing\npipeline of a printer. As far as we know, this is the first application of\ntimed automata technology to an industrial scheduling problem with uncertainty\nin job arrivals."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.13.1", 
    "link": "http://arxiv.org/pdf/0912.3852v1", 
    "title": "Sharp utilization thresholds for some real-time scheduling problems", 
    "arxiv-id": "0912.3852v1", 
    "author": "Sathish Gopalakrishnan", 
    "publish": "2009-12-19T01:18:05Z", 
    "summary": "Scheduling policies for real-time systems exhibit threshold behavior that is\nrelated to the utilization of the task set they schedule, and in some cases\nthis threshold is sharp. For the rate monotonic scheduling policy, we show that\nperiodic workload with utilization less than a threshold $U_{RM}^{*}$ can be\nscheduled almost surely and that all workload with utilization greater than\n$U_{RM}^{*}$ is almost surely not schedulable. We study such sharp threshold\nbehavior in the context of processor scheduling using static task priorities,\nnot only for periodic real-time tasks but for aperiodic real-time tasks as\nwell. The notion of a utilization threshold provides a simple schedulability\ntest for most real-time applications. These results improve our understanding\nof scheduling policies and provide an interesting characterization of the\ntypical behavior of policies. The threshold is sharp (small deviations around\nthe threshold cause schedulability, as a property, to appear or disappear) for\nmost policies; this is a happy consequence that can be used to address the\nlimitations of existing utilization-based tests for schedulability. We\ndemonstrate the use of such an approach for balancing power consumption with\nthe need to meet deadlines in web servers."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.13.1", 
    "link": "http://arxiv.org/pdf/1001.2262v1", 
    "title": "Classifying Application Phases in Asymmetric Chip Multiprocessors", 
    "arxiv-id": "1001.2262v1", 
    "author": "M. Analoui", 
    "publish": "2010-01-13T18:47:44Z", 
    "summary": "In present study, in order to improve the performance and reduce the amount\nof power which is dissipated in heterogeneous multicore processors, the ability\nof detecting the program execution phases is investigated. The programs\nexecution intervals have been classified in different phases based on their\nthroughput and the utilization of the cores. The results of implementing the\nphase detection technique are investigated on a single core processor and also\non a multicore processor. To minimize the profiling overhead, an algorithm for\nthe dynamic adjustment of the profiling intervals is presented. It is based on\nthe behavior of the program and reduces the profiling overhead more than three\nfold. The results are obtained from executing multiprocessor benchmarks on a\ngiven processor. In order to show the program phases clearly, throughput and\nutilization of execution intervals are presented on a scatter plot. The results\nare presented for both fixed and variable intervals."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.13.1", 
    "link": "http://arxiv.org/pdf/1002.3493v2", 
    "title": "The Missing Piece Syndrome in Peer-to-Peer Communication", 
    "arxiv-id": "1002.3493v2", 
    "author": "Ji Zhu", 
    "publish": "2010-02-18T17:30:54Z", 
    "summary": "Typical protocols for peer-to-peer file sharing over the Internet divide\nfiles to be shared into pieces. New peers strive to obtain a complete\ncollection of pieces from other peers and from a seed. In this paper we\ninvestigate a problem that can occur if the seeding rate is not large enough.\nThe problem is that, even if the statistics of the system are symmetric in the\npieces, there can be symmetry breaking, with one piece becoming very rare. If\npeers depart after obtaining a complete collection, they can tend to leave\nbefore helping other peers receive the rare piece. Assuming that peers arrive\nwith no pieces, there is a single seed, random peer contacts are made, random\nuseful pieces are downloaded, and peers depart upon receiving the complete\nfile, the system is stable if the seeding rate (in pieces per time unit) is\ngreater than the arrival rate, and is unstable if the seeding rate is less than\nthe arrival rate. The result persists for any piece selection policy that\nselects from among useful pieces, such as rarest first, and it persists with\nthe use of network coding."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.13.1", 
    "link": "http://arxiv.org/pdf/1002.4182v1", 
    "title": "Window-Based Greedy Contention Management for Transactional Memory", 
    "arxiv-id": "1002.4182v1", 
    "author": "Costas Busch", 
    "publish": "2010-02-22T20:02:24Z", 
    "summary": "We consider greedy contention managers for transactional memory for M x N\nexecution windows of transactions with M threads and N transactions per thread.\nAssuming that each transaction conflicts with at most C other transactions\ninside the window, a trivial greedy contention manager can schedule them within\nCN time. In this paper, we show that there are much better schedules. We\npresent and analyze two new randomized greedy contention management algorithms.\nThe first algorithm Offline-Greedy produces a schedule of length O(C + N\nlog(MN)) with high probability, and gives competitive ratio O(log(MN)) for C <=\nN log(MN). The offline algorithm depends on knowing the conflict graph. The\nsecond algorithm Online-Greedy produces a schedule of length O(C log(MN) + N\nlog^2(MN)) with high probability which is only a O(log(NM)) factor worse, but\ndoes not require knowledge of the conflict graph. We also give an adaptive\nversion which achieves similar worst-case performance and C is determined on\nthe fly under execution. Our algorithms provide new tradeoffs for greedy\ntransaction scheduling that parameterize window sizes and transaction conflicts\nwithin the window."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.13.1", 
    "link": "http://arxiv.org/pdf/1003.2084v3", 
    "title": "Asynchronous Bounded Expected Delay Networks", 
    "arxiv-id": "1003.2084v3", 
    "author": "Jun Pang", 
    "publish": "2010-03-10T11:39:08Z", 
    "summary": "The commonly used asynchronous bounded delay (ABD) network models assume a\nfixed bound on message delay. We propose a probabilistic network model, called\nasynchronous bounded expected delay (ABE) model. Instead of a strict bound, the\nABE model requires only a bound on the expected message delay. While the\nconditions of ABD networks restrict the set of possible executions, in ABE\nnetworks all asynchronous executions are possible, but executions with\nextremely long delays are less probable. In contrast to ABD networks, ABE\nnetworks cannot be synchronised efficiently. At the example of an election\nalgorithm, we show that the minimal assumptions of ABE networks are sufficient\nfor the development of efficient algorithms. For anonymous, unidirectional ABE\nrings of known size N we devise a probabilistic leader election algorithm\nhaving average message and time complexity O(N)."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.peva.2010.08.001", 
    "link": "http://arxiv.org/pdf/1003.5068v1", 
    "title": "On the stability of flow-aware CSMA", 
    "arxiv-id": "1003.5068v1", 
    "author": "M. Feuillet", 
    "publish": "2010-03-26T08:06:37Z", 
    "summary": "We consider a wireless network where each flow (instead of each link) runs\nits own CSMA (Carrier Sense Multiple Access) algorithm. Specifically, each flow\nattempts to access the radio channel after some random time and transmits a\npacket if the channel is sensed idle. We prove that, unlike the standard CSMA\nalgorithm, this simple distributed access scheme is optimal in the sense that\nthe network is stable for all traffic intensities in the capacity region of the\nnetwork."
},{
    "category": "cs.DC", 
    "doi": "10.1177/1094342010372928", 
    "link": "http://arxiv.org/pdf/1004.0023v1", 
    "title": "High-Performance Physics Simulations Using Multi-Core CPUs and GPGPUs in   a Volunteer Computing Context", 
    "arxiv-id": "1004.0023v1", 
    "author": "Firas Hamze", 
    "publish": "2010-03-31T22:38:24Z", 
    "summary": "This paper presents two conceptually simple methods for parallelizing a\nParallel Tempering Monte Carlo simulation in a distributed volunteer computing\ncontext, where computers belonging to the general public are used. The first\nmethod uses conventional multi-threading. The second method uses CUDA, a\ngraphics card computing system. Parallel Tempering is described, and challenges\nsuch as parallel random number generation and mapping of Monte Carlo chains to\ndifferent threads are explained. While conventional multi-threading on CPUs is\nwell-established, GPGPU programming techniques and technologies are still\ndeveloping and present several challenges, such as the effective use of a\nrelatively large number of threads. Having multiple chains in Parallel\nTempering allows parallelization in a manner that is similar to the serial\nalgorithm. Volunteer computing introduces important constraints to high\nperformance computing, and we show that both versions of the application are\nable to adapt themselves to the varying and unpredictable computing resources\nof volunteers' computers, while leaving the machines responsive enough to use.\nWe present experiments to show the scalable performance of these two\napproaches, and indicate that the efficiency of the methods increases with\nbigger problem sizes."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1004.0024v1", 
    "title": "Importance of Explicit Vectorization for CPU and GPU Software   Performance", 
    "arxiv-id": "1004.0024v1", 
    "author": "Firas Hamze", 
    "publish": "2010-03-31T22:38:48Z", 
    "summary": "Much of the current focus in high-performance computing is on\nmulti-threading, multi-computing, and graphics processing unit (GPU) computing.\nHowever, vectorization and non-parallel optimization techniques, which can\noften be employed additionally, are less frequently discussed. In this paper,\nwe present an analysis of several optimizations done on both central processing\nunit (CPU) and GPU implementations of a particular computationally intensive\nMetropolis Monte Carlo algorithm. Explicit vectorization on the CPU and the\nequivalent, explicit memory coalescing, on the GPU are found to be critical to\nachieving good performance of this algorithm in both environments. The\nfully-optimized CPU version achieves a 9x to 12x speedup over the original CPU\nversion, in addition to speedup from multi-threading. This is 2x faster than\nthe fully-optimized GPU version."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1004.0534v6", 
    "title": "Impact of Connection Admission Process on the Direct Retry Load   Balancing Algorithm in Cellular Network", 
    "arxiv-id": "1004.0534v6", 
    "author": "Danijela \u010cabri\u0107", 
    "publish": "2010-04-04T21:09:37Z", 
    "summary": "We present an analytical framework for modeling a priority-based load\nbalancing scheme in cellular networks based on a new algorithm called direct\nretry with truncated offloading channel resource pool (DR$_{K}$). The model,\ndeveloped for a baseline case of two cell network, differs in many respects\nfrom previous works on load balancing. Foremost, it incorporates the call\nadmission process, through random access. In specific, the proposed model\nimplements the Physical Random Access Channel used in 3GPP network standards.\nFurthermore, the proposed model allows the differentiation of users based on\ntheir priorities. The quantitative results illustrate that, for example,\ncellular network operators can control the manner in which traffic is offloaded\nbetween neighboring cells by simply adjusting the length of the random access\nphase. Our analysis also allows for the quantitative determination of the\nblocking probability individual users will experience given a specific length\nof random access phase. Furthermore, we observe that the improvement in\nblocking probability per shared channel for load balanced users using DR$_{K}$\nis maximized at an intermediate number of shared channels, as opposed to the\nmaximum number of these shared resources. This occurs because a balance is\nachieved between the number of users requesting connections and those that are\nalready admitted to the network. We also present an extension of our analytical\nmodel to a multi-cell network (by means of an approximation) and an application\nof the proposed load balancing scheme in the context of opportunistic spectrum\naccess."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1004.1680v1", 
    "title": "Magnetohydrodynamics on Heterogeneous architectures: a performance   comparison", 
    "arxiv-id": "1004.1680v1", 
    "author": "Michael Perrone", 
    "publish": "2010-04-10T04:14:15Z", 
    "summary": "We present magneto-hydrodynamic simulation results for heterogeneous systems.\nHeterogeneous architectures combine high floating point performance many-core\nunits hosted in conventional server nodes. Examples include Graphics Processing\nUnits (GPU's) and Cell. They have potentially large gains in performance, at\nmodest power and monetary cost. We implemented a magneto-hydrodynamic (MHD)\nsimulation code on a variety of heterogeneous and multi-core architectures ---\nmulti-core x86, Cell, Nvidia and ATI GPU --- in different languages, FORTRAN,\nC, Cell, CUDA and OpenCL. We present initial performance results for these\nsystems. To our knowledge, this is the widest comparison of heterogeneous\nsystems for MHD simulations. We review the different challenges faced in each\narchitecture, and potential bottlenecks. We conclude that substantial gains in\nperformance over traditional systems are possible, and in particular that is\npossible to extract a greater percentage of peak theoretical performance from\nsome systems when compared to x86 architectures."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1004.4709v4", 
    "title": "Optimal Content Placement for Peer-to-Peer Video-on-Demand Systems", 
    "arxiv-id": "1004.4709v4", 
    "author": "Laurent Massoulie", 
    "publish": "2010-04-27T04:26:40Z", 
    "summary": "In this paper, we address the problem of content placement in peer-to-peer\nsystems, with the objective of maximizing the utilization of peers' uplink\nbandwidth resources. We consider system performance under a many-user\nasymptotic. We distinguish two scenarios, namely \"Distributed Server Networks\"\n(DSN) for which requests are exogenous to the system, and \"Pure P2P Networks\"\n(PP2PN) for which requests emanate from the peers themselves. For both\nscenarios, we consider a loss network model of performance, and determine\nasymptotically optimal content placement strategies in the case of a limited\ncontent catalogue. We then turn to an alternative \"large catalogue\" scaling\nwhere the catalogue size scales with the peer population. Under this scaling,\nwe establish that storage space per peer must necessarily grow unboundedly if\nbandwidth utilization is to be maximized. Relating the system performance to\nproperties of a specific random graph model, we then identify a content\nplacement strategy and a request acceptance policy which jointly maximize\nbandwidth utilization, provided storage space per peer grows unboundedly,\nalthough arbitrarily slowly, with system size."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1005.2581v3", 
    "title": "A Performance Comparison of CUDA and OpenCL", 
    "arxiv-id": "1005.2581v3", 
    "author": "Firas Hamze", 
    "publish": "2010-05-14T17:41:53Z", 
    "summary": "CUDA and OpenCL are two different frameworks for GPU programming. OpenCL is\nan open standard that can be used to program CPUs, GPUs, and other devices from\ndifferent vendors, while CUDA is specific to NVIDIA GPUs. Although OpenCL\npromises a portable language for GPU programming, its generality may entail a\nperformance penalty. In this paper, we use complex, near-identical kernels from\na Quantum Monte Carlo application to compare the performance of CUDA and\nOpenCL. We show that when using NVIDIA compiler tools, converting a CUDA kernel\nto an OpenCL kernel involves minimal modifications. Making such a kernel\ncompile with ATI's build tools involves more modifications. Our performance\ntests measure and compare data transfer times to and from the GPU, kernel\nexecution times, and end-to-end application execution times for both CUDA and\nOpenCL."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1005.2898v1", 
    "title": "Saturation Throughput - Delay Analysis of IEEE 802.11 DCF in Fading   Channel", 
    "arxiv-id": "1005.2898v1", 
    "author": "Boris Spasenovski", 
    "publish": "2010-05-17T12:08:14Z", 
    "summary": "In this paper, we analytically analyzed the impact of an error-prone channel\nover all performance measures in a trafficsaturated IEEE 802.11 WLAN. We\ncalculated station's transmission probability by using the modified Markov\nchain model of the backoff window size that considers the frame-error rates and\nmaximal allowable number of retransmission attempts. The frame error rate has a\nsignificant impact over theoretical throughput, mean frame delay, and discard\nprobability. The peak throughput of a WLAN is insensitive of the maximal number\nof retransmissions. Discard probabilities are insensitive to the station access\nmethod, Basic or RTS/CTS."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jcp.2011.03.041", 
    "link": "http://arxiv.org/pdf/1006.2183v1", 
    "title": "Highly Parallel Sparse Matrix-Matrix Multiplication", 
    "arxiv-id": "1006.2183v1", 
    "author": "John R. Gilbert", 
    "publish": "2010-06-11T02:10:58Z", 
    "summary": "Generalized sparse matrix-matrix multiplication is a key primitive for many\nhigh performance graph algorithms as well as some linear solvers such as\nmultigrid. We present the first parallel algorithms that achieve increasing\nspeedups for an unbounded number of processors. Our algorithms are based on\ntwo-dimensional block distribution of sparse matrices where serial sections use\na novel hypersparse kernel for scalability. We give a state-of-the-art MPI\nimplementation of one of our algorithms. Our experiments show scaling up to\nthousands of processors on a variety of test scenarios."
},{
    "category": "math.PR", 
    "doi": "10.1007/s11134-011-9265-7", 
    "link": "http://arxiv.org/pdf/1006.2313v2", 
    "title": "On the flow-level stability of data networks without congestion control:   the case of linear networks and upstream trees", 
    "arxiv-id": "1006.2313v2", 
    "author": "Mathieu Feuillet", 
    "publish": "2010-06-11T13:50:21Z", 
    "summary": "In this paper, flow models of networks without congestion control are\nconsidered. Users generate data transfers according to some Poisson processes\nand transmit corresponding packet at a fixed rate equal to their access rate\nuntil the entire document is received at the destination; some erasure codes\nare used to make the transmission robust to packet losses. We study the\nstability of the stochastic process representing the number of active flows in\ntwo particular cases: linear networks and upstream trees. For the case of\nlinear networks, we notably use fluid limits and an interesting phenomenon of\n\"time scale separation\" occurs. Bounds on the stability region of linear\nnetworks are given. For the case of upstream trees, underlying monotonic\nproperties are used. Finally, the asymptotic stability of those processes is\nanalyzed when the access rate of the users decreases to 0. An appropriate\nscaling is introduced and used to prove that the stability region of those\nnetworks is asymptotically maximized."
},{
    "category": "math.PR", 
    "doi": "10.1007/s11134-011-9265-7", 
    "link": "http://arxiv.org/pdf/1006.3295v5", 
    "title": "Implicit Renewal Theory and Power Tails on Trees", 
    "arxiv-id": "1006.3295v5", 
    "author": "Mariana Olvera-Cravioto", 
    "publish": "2010-06-16T18:37:30Z", 
    "summary": "We extend Goldie's (1991) Implicit Renewal Theorem to enable the analysis of\nrecursions on weighted branching trees. We illustrate the developed method by\nderiving the power tail asymptotics of the distributions of the solutions R to:\nR =_D sum_{i=1}^N C_i R_i + Q, R =_D max(max_{i=1}^N C_i R_i, Q), and similar\nrecursions, where (Q, N, C_1,..., C_N) is a nonnegative random vector with N in\n{0, 1, 2, 3, ..., infinity}, and {R_i}_{i >= 1} are iid copies of R,\nindependent of (Q, N, C_1,..., C_N); =_D denotes the equality in distribution."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.28.11", 
    "link": "http://arxiv.org/pdf/1006.5104v1", 
    "title": "A new tool for the performance analysis of massively parallel computer   systems", 
    "arxiv-id": "1006.5104v1", 
    "author": "Jeremy Bradley", 
    "publish": "2010-06-26T03:03:55Z", 
    "summary": "We present a new tool, GPA, that can generate key performance measures for\nvery large systems. Based on solving systems of ordinary differential equations\n(ODEs), this method of performance analysis is far more scalable than\nstochastic simulation. The GPA tool is the first to produce higher moment\nanalysis from differential equation approximation, which is essential, in many\ncases, to obtain an accurate performance prediction. We identify so-called\nswitch points as the source of error in the ODE approximation. We investigate\nthe switch point behaviour in several large models and observe that as the\nscale of the model is increased, in general the ODE performance prediction\nimproves in accuracy. In the case of the variance measure, we are able to\njustify theoretically that in the limit of model scale, the ODE approximation\ncan be expected to tend to the actual variance of the model."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.28", 
    "link": "http://arxiv.org/pdf/1006.5107v1", 
    "title": "Proceedings Eighth Workshop on Quantitative Aspects of Programming   Languages", 
    "arxiv-id": "1006.5107v1", 
    "author": "Gethin Norman", 
    "publish": "2010-06-26T03:34:52Z", 
    "summary": "This volume contains the proceedings of the Eighth Workshop on Quantitative\nAspects of Programming Languages (QAPL 2010), held in Paphos, Cyprus, on March\n27-28, 2010. QAPL 2010 is a satellite event of the European Joint Conferences\non Theory and Practice of Software (ETAPS 2010).\n  The workshop theme is on quantitative aspects of computation. These aspects\nare related to the use of physical quantities (storage space, time, bandwidth,\netc.) as well as mathematical quantities (e.g. probability and measures for\nreliability, security and trust), and play an important (sometimes essential)\nrole in characterising the behavior and determining the properties of systems.\nSuch quantities are central to the definition of both the model of systems\n(architecture, language design, semantics) and the methodologies and tools for\nthe analysis and verification of the systems properties.\n  The aim of this workshop is to discuss the explicit use of quantitative\ninformation such as time and probabilities either directly in the model or as a\ntool for the analysis of systems."
},{
    "category": "math.PR", 
    "doi": "10.4204/EPTCS.28", 
    "link": "http://arxiv.org/pdf/1008.1289v1", 
    "title": "An ODE for an Overloaded X Model Involving a Stochastic Averaging   Principle", 
    "arxiv-id": "1008.1289v1", 
    "author": "Ward Whitt", 
    "publish": "2010-08-06T23:05:24Z", 
    "summary": "We study an ordinary differential equation (ODE) arising as the many-server\nheavy-traffic fluid limit of a sequence of overloaded Markovian queueing models\nwith two customer classes and two service pools. The system, known as the X\nmodel in the call-center literature, operates under the\nfixed-queue-ratio-with-thresholds (FQR-T) control, which we proposed in a\nrecent paper as a way for one service system to help another in face of an\nunanticipated overload. Each pool serves only its own class until a threshold\nis exceeded; then one-way sharing is activated with all customer-server\nassignments then driving the two queues toward a fixed ratio. For large\nsystems, that fixed ratio is achieved approximately. The ODE describes system\nperformance during an overload. The control is driven by a queue-difference\nstochastic process, which operates in a faster time scale than the queueing\nprocesses themselves, thus achieving a time-dependent steady state\ninstantaneously in the limit. As a result, for the ODE, the driving process is\nreplaced by its long-run average behavior at each instant of time; i.e., the\nODE involves a heavy-traffic averaging principle (AP)."
},{
    "category": "math.PR", 
    "doi": "10.4204/EPTCS.28", 
    "link": "http://arxiv.org/pdf/1009.0193v1", 
    "title": "An analytical model for evaluating outage and handover probability of   cellular wireless networks", 
    "arxiv-id": "1009.0193v1", 
    "author": "Than-Tung Vu", 
    "publish": "2010-09-01T14:48:02Z", 
    "summary": "We consider stochastic cellular networks where base stations locations form a\nhomogenous Poisson point process and each mobile is attached to the base\nstation that provides the best mean signal power. The mobile is in outage if\nthe SINR falls below some threshold. The handover decision has to be made if\nthe mobile is in outage for some time slots. The outage probability and the\nhandover probability is evaluated in taking into account the effect of path\nloss, shadowing, Rayleigh fast fading, frequency factor reuse and conventional\nbeamforming. The main assumption is that the Rayleigh fast fading changes each\ntime slot while other network components remain static during the period of\nstudy."
},{
    "category": "cs.DS", 
    "doi": "10.4204/EPTCS.28", 
    "link": "http://arxiv.org/pdf/1009.0870v6", 
    "title": "Online Advertisement, Optimization and Stochastic Networks", 
    "arxiv-id": "1009.0870v6", 
    "author": "R. Srikant", 
    "publish": "2010-09-04T20:54:58Z", 
    "summary": "In this paper, we propose a stochastic model to describe how search service\nproviders charge client companies based on users' queries for the keywords\nrelated to these companies' ads by using certain advertisement assignment\nstrategies. We formulate an optimization problem to maximize the long-term\naverage revenue for the service provider under each client's long-term average\nbudget constraint, and design an online algorithm which captures the stochastic\nproperties of users' queries and click-through behaviors. We solve the\noptimization problem by making connections to scheduling problems in wireless\nnetworks, queueing theory and stochastic networks. Unlike prior models, we do\nnot assume that the number of query arrivals is known. Due to the stochastic\nnature of the arrival process considered here, either temporary \"free\" service,\ni.e., service above the specified budget or under-utilization of the budget is\nunavoidable. We prove that our online algorithm can achieve a revenue that is\nwithin $O(\\epsilon)$ of the optimal revenue while ensuring that the overdraft\nor underdraft is $O(1/\\epsilon)$, where $\\epsilon$ can be arbitrarily small.\nWith a view towards practice, we can show that one can always operate strictly\nunder the budget. In addition, we extend our results to a click-through rate\nmaximization model, and also show how our algorithm can be modified to handle\nnon-stationary query arrival processes and clients with short-term contracts.\n  Our algorithm allows us to quantify the effect of errors in click-through\nrate estimation on the achieved revenue. We also show that in the long run, an\nexpected overdraft level of $\\Omega(\\log(1/\\epsilon))$ is unavoidable (a\nuniversal lower bound) under any stationary ad assignment algorithm which\nachieves a long-term average revenue within $O(\\epsilon)$ of the offline\noptimum."
},{
    "category": "cond-mat.mtrl-sci", 
    "doi": "10.4204/EPTCS.28", 
    "link": "http://arxiv.org/pdf/1009.4330v2", 
    "title": "General-purpose molecular dynamics simulations on GPU-based clusters", 
    "arxiv-id": "1009.4330v2", 
    "author": "Paul S. Crozier", 
    "publish": "2010-09-22T11:34:20Z", 
    "summary": "We present a GPU implementation of LAMMPS, a widely-used parallel molecular\ndynamics (MD) software package, and show 5x to 13x single node speedups versus\nthe CPU-only version of LAMMPS. This new CUDA package for LAMMPS also enables\nmulti-GPU simulation on hybrid heterogeneous clusters, using MPI for inter-node\ncommunication, CUDA kernels on the GPU for all methods working with particle\ndata, and standard LAMMPS C++ code for CPU execution. Cell and neighbor list\napproaches are compared for best performance on GPUs, with thread-per-atom and\nblock-per-atom neighbor list variants showing best performance at low and high\nneighbor counts, respectively. Computational performance results of GPU-enabled\nLAMMPS are presented for a variety of materials classes (e.g. biomolecules,\npolymers, metals, semiconductors), along with a speed comparison versus other\navailable GPU-enabled MD software. Finally, we show strong and weak scaling\nperformance on a CPU/GPU cluster using up to 128 dual GPU nodes."
},{
    "category": "cs.DC", 
    "doi": "10.1145/1330555.1330556", 
    "link": "http://arxiv.org/pdf/1009.4841v1", 
    "title": "Dynamic scheduling of virtual machines running hpc workloads in   scientific grids", 
    "arxiv-id": "1009.4841v1", 
    "author": "Markus Schulz", 
    "publish": "2010-09-24T13:57:02Z", 
    "summary": "The primary motivation for uptake of virtualization has been resource\nisolation, capacity management and resource customization allowing resource\nproviders to consolidate their resources in virtual machines. Various\napproaches have been taken to integrate virtualization in to scientific Grids\nespecially in the arena of High Performance Computing (HPC) to run grid jobs in\nvirtual machines, thus enabling better provisioning of the underlying resources\nand customization of the execution environment on runtime. Despite the gains,\nvirtualization layer also incur a performance penalty and its not very well\nunderstood that how such an overhead will impact the performance of systems\nwhere jobs are scheduled with tight deadlines. Since this overhead varies the\ntypes of workload whether they are memory intensive, CPU intensive or network\nI/O bound, and could lead to unpredictable deadline estimation for the running\njobs in the system. In our study, we have attempted to tackle this problem by\ndeveloping an intelligent scheduling technique for virtual machines which\nmonitors the workload types and deadlines, and calculate the system over head\nin real time to maximize number of jobs finishing within their agreed\ndeadlines."
},{
    "category": "cs.DC", 
    "doi": "10.1109/WAINA.2010.107", 
    "link": "http://arxiv.org/pdf/1009.4847v1", 
    "title": "Deadline aware virtual machine scheduler for scientific grids and cloud   computing", 
    "arxiv-id": "1009.4847v1", 
    "author": "Markus Schulz", 
    "publish": "2010-09-24T14:14:39Z", 
    "summary": "Virtualization technology has enabled applications to be decoupled from the\nunderlying hardware providing the benefits of portability, better control over\nexecution environment and isolation. It has been widely adopted in scientific\ngrids and commercial clouds. Since virtualization, despite its benefits incurs\na performance penalty, which could be significant for systems dealing with\nuncertainty such as High Performance Computing (HPC) applications where jobs\nhave tight deadlines and have dependencies on other jobs before they could run.\nThe major obstacle lies in bridging the gap between performance requirements of\na job and performance offered by the virtualization technology if the jobs were\nto be executed in virtual machines. In this paper, we present a novel approach\nto optimize job deadlines when run in virtual machines by developing a\ndeadline-aware algorithm that responds to job execution delays in real time,\nand dynamically optimizes jobs to meet their deadline obligations. Our\napproaches borrowed concepts both from signal processing and statistical\ntechniques, and their comparative performance results are presented later in\nthe paper including the impact on utilization rate of the hardware resources."
},{
    "category": "cs.PF", 
    "doi": "10.1109/WAINA.2010.107", 
    "link": "http://arxiv.org/pdf/1010.0019v1", 
    "title": "Mantis: Predicting System Performance through Program Analysis and   Modeling", 
    "arxiv-id": "1010.0019v1", 
    "author": "Mayur Naik", 
    "publish": "2010-09-30T21:02:04Z", 
    "summary": "We present Mantis, a new framework that automatically predicts program\nperformance with high accuracy. Mantis integrates techniques from programming\nlanguage and machine learning for performance modeling, and is a radical\ndeparture from traditional approaches. Mantis extracts program features, which\nare information about program execution runs, through program instrumentation.\nIt uses machine learning techniques to select features relevant to performance\nand creates prediction models as a function of the selected features. Through\nprogram analysis, it then generates compact code slices that compute these\nfeature values for prediction. Our evaluation shows that Mantis can achieve\nmore than 93% accuracy with less than 10% training data set, which is a\nsignificant improvement over models that are oblivious to program features. The\nsystem generates code slices that are cheap to compute feature values."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TVT.2011.2160210", 
    "link": "http://arxiv.org/pdf/1010.0041v4", 
    "title": "Throughput and Collision Analysis of Multi-Channel Multi-Stage Spectrum   Sensing Algorithms", 
    "arxiv-id": "1010.0041v4", 
    "author": "Danijela \u010cabri\u0107", 
    "publish": "2010-10-01T00:45:03Z", 
    "summary": "Multi-stage sensing is a novel concept that refers to a general class of\nspectrum sensing algorithms that divide the sensing process into a number of\nsequential stages. The number of sensing stages and the sensing technique per\nstage can be used to optimize performance with respect to secondary user\nthroughput and the collision probability between primary and secondary users.\nSo far, the impact of multi-stage sensing on network throughput and collision\nprobability for a realistic network model is relatively unexplored. Therefore,\nwe present the first analytical framework which enables performance evaluation\nof different multi-channel multi-stage spectrum sensing algorithms for\nOpportunistic Spectrum Access networks. The contribution of our work lies in\nstudying the effect of the following parameters on performance: number of\nsensing stages, physical layer sensing techniques and durations per each stage,\nsingle and parallel channel sensing and access, number of available channels,\nprimary and secondary user traffic, buffering of incoming secondary user\ntraffic, as well as MAC layer sensing algorithms. Analyzed performance metrics\ninclude the average secondary user throughput and the average collision\nprobability between primary and secondary users. Our results show that when the\nprobability of primary user mis-detection is constrained, the performance of\nmulti-stage sensing is, in most cases, superior to the single stage sensing\ncounterpart. Besides, prolonged channel observation at the first stage of\nsensing decreases the collision probability considerably, while keeping the\nthroughput at an acceptable level. Finally, in realistic primary user traffic\nscenarios, using two stages of sensing provides a good balance between\nsecondary users throughput and collision probability while meeting successful\ndetection constraints subjected by Opportunistic Spectrum Access communication."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TSP.2011.2161475", 
    "link": "http://arxiv.org/pdf/1010.4920v4", 
    "title": "Jointly Optimal Channel Pairing and Power Allocation for Multichannel   Multihop Relaying", 
    "arxiv-id": "1010.4920v4", 
    "author": "Ben Liang", 
    "publish": "2010-10-24T00:30:15Z", 
    "summary": "We study the problem of channel pairing and power allocation in a\nmultichannel multihop relay network to enhance the end-to-end data rate. Both\namplify-and-forward (AF) and decode-and-forward (DF) relaying strategies are\nconsidered. Given fixed power allocation to the channels, we show that channel\npairing over multiple hops can be decomposed into independent pairing problems\nat each relay, and a sorted-SNR channel pairing strategy is sum-rate optimal,\nwhere each relay pairs its incoming and outgoing channels by their SNR order.\nFor the joint optimization of channel pairing and power allocation under both\ntotal and individual power constraints, we show that the problem can be\ndecoupled into two subproblems solved separately. This separation principle is\nestablished by observing the equivalence between sorting SNRs and sorting\nchannel gains in the jointly optimal solution. It significantly reduces the\ncomputational complexity in finding the jointly optimal solution. It follows\nthat the channel pairing problem in joint optimization can be again decomposed\ninto independent pairing problems at each relay based on sorted channel gains.\nThe solution for optimizing power allocation for DF relaying is also provided,\nas well as an asymptotically optimal solution for AF relaying. Numerical\nresults are provided to demonstrate substantial performance gain of the jointly\noptimal solution over some suboptimal alternatives. It is also observed that\nmore gain is obtained from optimal channel pairing than optimal power\nallocation through judiciously exploiting the variation among multiple\nchannels. Impact of the variation of channel gain, the number of channels, and\nthe number of hops on the performance gain is also studied through numerical\nexamples."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TSP.2011.2161475", 
    "link": "http://arxiv.org/pdf/1010.5608v2", 
    "title": "A Generalized Coupon Collector Problem", 
    "arxiv-id": "1010.5608v2", 
    "author": "Ao Kevin Tang", 
    "publish": "2010-10-27T08:56:31Z", 
    "summary": "This paper provides analysis to a generalized version of the coupon collector\nproblem, in which the collector gets $d$ distinct coupons each run and she\nchooses the one that she has the least so far. On the asymptotic case when the\nnumber of coupons $n$ goes to infinity, we show that on average $\\frac{n\\log\nn}{d} + \\frac{n}{d}(m-1)\\log\\log{n}+O(mn)$ runs are needed to collect $m$ sets\nof coupons. An efficient exact algorithm is also developed for any finite case\nto compute the average needed runs exactly. Numerical examples are provided to\nverify our theoretical predictions."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TWC.2011.11.102209", 
    "link": "http://arxiv.org/pdf/1011.2313v3", 
    "title": "Weighted Centroid Algorithm for Estimating Primary User Location:   Theoretical Analysis and Distributed Implementation", 
    "arxiv-id": "1011.2313v3", 
    "author": "Danijela \u010cabri\u0107", 
    "publish": "2010-11-10T08:38:46Z", 
    "summary": "Information about primary transmitter location is crucial in enabling several\nkey capabilities in cognitive radio networks, including improved\nspatio-temporal sensing, intelligent location-aware routing, as well as aiding\nspectrum policy enforcement. Compared to other proposed non-interactive\nlocalization algorithms, the weighted centroid localization (WCL) scheme uses\nonly the received signal strength information, which makes it simple to\nimplement and robust to variations in the propagation environment. In this\npaper we present the first theoretical framework for WCL performance analysis\nin terms of its localization error distribution parameterized by node density,\nnode placement, shadowing variance, correlation distance and inaccuracy of\nsensor node positioning. Using this analysis, we quantify the robustness of WCL\nto various physical conditions and provide design guidelines, such as node\nplacement and spacing, for the practical deployment of WCL. We also propose a\npower-efficient method for implementing WCL through a distributed cluster-based\nalgorithm, that achieves comparable accuracy with its centralized counterpart."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TWC.2011.11.102209", 
    "link": "http://arxiv.org/pdf/1011.3583v1", 
    "title": "Fast GPGPU Data Rearrangement Kernels using CUDA", 
    "arxiv-id": "1011.3583v1", 
    "author": "Babu Narayanan", 
    "publish": "2010-11-16T04:38:53Z", 
    "summary": "Many high performance-computing algorithms are bandwidth limited, hence the\nneed for optimal data rearrangement kernels as well as their easy integration\ninto the rest of the application. In this work, we have built a CUDA library of\nfast kernels for a set of data rearrangement operations. In particular, we have\nbuilt generic kernels for rearranging m dimensional data into n dimensions,\nincluding Permute, Reorder, Interlace/De-interlace, etc. We have also built\nkernels for generic Stencil computations on a two-dimensional data using\ntemplates and functors that allow application developers to rapidly build\ncustomized high performance kernels. All the kernels built achieve or surpass\nbest-known performance in terms of bandwidth utilization."
},{
    "category": "cond-mat.dis-nn", 
    "doi": "10.1103/PhysRevE.83.036114", 
    "link": "http://arxiv.org/pdf/1012.1813v1", 
    "title": "Enhancing neural-network performance via assortativity", 
    "arxiv-id": "1012.1813v1", 
    "author": "Joaqu\u00edn J. Torres", 
    "publish": "2010-12-08T17:33:04Z", 
    "summary": "The performance of attractor neural networks has been shown to depend\ncrucially on the heterogeneity of the underlying topology. We take this\nanalysis a step further by examining the effect of degree-degree correlations\n-- or assortativity -- on neural-network behavior. We make use of a method\nrecently put forward for studying correlated networks and dynamics thereon,\nboth analytically and computationally, which is independent of how the topology\nmay have evolved. We show how the robustness to noise is greatly enhanced in\nassortative (positively correlated) neural networks, especially if it is the\nhub neurons that store the information."
},{
    "category": "cs.IT", 
    "doi": "10.1109/LCOMM.2011.032811.110316", 
    "link": "http://arxiv.org/pdf/1012.5327v3", 
    "title": "Computationally Efficient Modulation Level Classification Based on   Probability Distribution Distance Functions", 
    "arxiv-id": "1012.5327v3", 
    "author": "Danijela \u010cabri\u0107", 
    "publish": "2010-12-24T00:22:12Z", 
    "summary": "We present a novel modulation level classification (MLC) method based on\nprobability distribution distance functions. The proposed method uses modified\nKuiper and Kolmogorov-Smirnov distances to achieve low computational complexity\nand outperforms the state of the art methods based on cumulants and\ngoodness-of-fit tests. We derive the theoretical performance of the proposed\nMLC method and verify it via simulations. The best classification accuracy,\nunder AWGN with SNR mismatch and phase jitter, is achieved with the proposed\nMLC method using Kuiper distances."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCOMM.2011.032811.110316", 
    "link": "http://arxiv.org/pdf/1101.4211v4", 
    "title": "Throughput-optimal Scheduling in Multi-hop Wireless Networks without   Per-flow Information", 
    "arxiv-id": "1101.4211v4", 
    "author": "Ness B. Shroff", 
    "publish": "2011-01-21T19:32:49Z", 
    "summary": "In this paper, we consider the problem of link scheduling in multi-hop\nwireless networks under general interference constraints. Our goal is to design\nscheduling schemes that do not use per-flow or per-destination information,\nmaintain a single data queue for each link, and exploit only local information,\nwhile guaranteeing throughput optimality. Although the celebrated back-pressure\nalgorithm maximizes throughput, it requires per-flow or per-destination\ninformation. It is usually difficult to obtain and maintain this type of\ninformation, especially in large networks, where there are numerous flows.\nAlso, the back-pressure algorithm maintains a complex data structure at each\nnode, keeps exchanging queue length information among neighboring nodes, and\ncommonly results in poor delay performance. In this paper, we propose\nscheduling schemes that can circumvent these drawbacks and guarantee throughput\noptimality. These schemes use either the readily available hop-count\ninformation or only the local information for each link. We rigorously analyze\nthe performance of the proposed schemes using fluid limit techniques via an\ninductive argument and show that they are throughput-optimal. We also conduct\nsimulations to validate our theoretical results in various settings, and show\nthat the proposed schemes can substantially improve the delay performance in\nmost scenarios."
},{
    "category": "cs.PF", 
    "doi": "10.1109/LCOMM.2011.032811.110316", 
    "link": "http://arxiv.org/pdf/1101.4523v2", 
    "title": "Bandwidth sharing networks with priority scaling", 
    "arxiv-id": "1101.4523v2", 
    "author": "Balakrishna J. Prabhu", 
    "publish": "2011-01-24T13:32:25Z", 
    "summary": "In multi-class communication networks, traffic surges due to one class of\nusers can significantly degrade the performance for other classes. During these\ntransient periods, it is thus of crucial importance to implement priority\nmechanisms that conserve the quality of service experienced by the affected\nclasses, while ensuring that the temporarily unstable class is not entirely\nneglected. In this paper, we examine the complex interaction occurring between\nseveral classes of traffic when classes obtain bandwidth proportionally to\ntheir incoming traffic.\n  We characterize the evolution of the network from the moment the initial\nsurge takes place until the system reaches its equilibrium. Using an\nappropriate scaling, we show that the trajectories of the temporarily unstable\nclass can be described by a differential equation, while those of the stable\nclasses retain their stochastic nature. A stochastic averaging phenomenon\noccurs and the dynamics of the temporarily unstable and the stable classes\ncontinue to influence one another. We further proceed to characterize the\nobtained differential equations and the stability region under this scaling for\nmonotone networks. We illustrate these result on several toy examples and we\nfinally build a penalization rule using these results for a network integrating\nstreaming and elastic traffic."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.46.3", 
    "link": "http://arxiv.org/pdf/1101.4733v1", 
    "title": "An Algebra of Synchronous Scheduling Interfaces", 
    "arxiv-id": "1101.4733v1", 
    "author": "Michael Mendler", 
    "publish": "2011-01-25T06:57:48Z", 
    "summary": "In this paper we propose an algebra of synchronous scheduling interfaces\nwhich combines the expressiveness of Boolean algebra for logical and functional\nbehaviour with the min-max-plus arithmetic for quantifying the non-functional\naspects of synchronous interfaces. The interface theory arises from a\nrealisability interpretation of intuitionistic modal logic (also known as\nCurry-Howard-Isomorphism or propositions-as-types principle). The resulting\nalgebra of interface types aims to provide a general setting for specifying\ntype-directed and compositional analyses of worst-case scheduling bounds. It\ncovers synchronous control flow under concurrent, multi-processing or\nmulti-threading execution and permits precise statements about exactness and\ncoverage of the analyses supporting a variety of abstractions. The paper\nillustrates the expressiveness of the algebra by way of some examples taken\nfrom network flow problems, shortest-path, task scheduling and worst-case\nreaction times in synchronous programming."
},{
    "category": "cs.IT", 
    "doi": "10.4204/EPTCS.46.3", 
    "link": "http://arxiv.org/pdf/1101.5317v1", 
    "title": "A Novel Unified Expression for the Capacity and Bit Error Probability of   Wireless Communication Systems over Generalized Fading Channels", 
    "arxiv-id": "1101.5317v1", 
    "author": "Mohamed-Slim Alouini", 
    "publish": "2011-01-26T17:47:41Z", 
    "summary": "Analysis of the average binary error probabilities (ABEP) and average\ncapacity (AC) of wireless communications systems over generalized fading\nchannels have been considered separately in the past. This paper introduces a\nnovel moment generating function (MGF)-based \\emph{unified expression} for the\nABEP and AC of single and multiple link communication with maximal ratio\ncombining. In addition, this paper proposes the hyper-Fox's H fading model as a\nunified fading distribution of a majority of the well-known generalized fading\nmodels. As such, we offer a generic unified performance expression that can be\neasily calculated and that is applicable to a wide variety of fading scenarios.\nThe mathematical formalism is illustrated with some selected numerical examples\nthat validate the correctness of our newly derived results."
},{
    "category": "cs.IT", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1102.5314v4", 
    "title": "Jointly Optimal Channel and Power Assignment for Dual-Hop Multi-channel   Multi-user Relaying", 
    "arxiv-id": "1102.5314v4", 
    "author": "Ben Liang", 
    "publish": "2011-02-25T19:13:22Z", 
    "summary": "We consider the problem of jointly optimizing channel pairing, channel-user\nassignment, and power allocation, to maximize the weighted sum-rate, in a\nsingle-relay cooperative system with multiple channels and multiple users.\nCommon relaying strategies are considered, and transmission power constraints\nare imposed on both individual transmitters and the aggregate over all\ntransmitters. The joint optimization problem naturally leads to a mixed-integer\nprogram. Despite the general expectation that such problems are intractable, we\nconstruct an efficient algorithm to find an optimal solution, which incurs\ncomputational complexity that is polynomial in the number of channels and the\nnumber of users. We further demonstrate through numerical experiments that the\njointly optimal solution can significantly improve system performance over its\nsuboptimal alternatives."
},{
    "category": "cs.IT", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1103.1305v1", 
    "title": "Generic Approach for Hierarchical Modulation Performance Analysis:   Application to DVB-SH", 
    "arxiv-id": "1103.1305v1", 
    "author": "Marie-Laure Boucheret", 
    "publish": "2011-03-07T15:46:05Z", 
    "summary": "Broadcasting systems have to deal with channel diversity in order to offer\nthe best rate to the users. Hierarchical modulation is a practical solution to\nprovide several rates in function of the channel quality. Unfortunately the\nperformance evaluation of such modulations requires time consuming simulations.\nWe propose in this paper a novel approach based on the channel capacity to\navoid these simulations. The method allows to study the performance in terms of\nspectrum efficiency of hierarchical and also classical modulations combined\nwith error correcting codes. Our method will be applied to the DVB-SH standard\nwhich considers hierarchical modulation as an optional feature."
},{
    "category": "cs.IT", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1103.1742v1", 
    "title": "Generic Approach for Hierarchical Modulation Performance Analysis:   Application to DVB-SH and DVB-S2", 
    "arxiv-id": "1103.1742v1", 
    "author": "Marie-Laure Boucheret", 
    "publish": "2011-03-09T09:31:58Z", 
    "summary": "Broadcasting systems have to deal with channel variability in order to offer\nthe best rate to the users. Hierarchical modulation is a practical solution to\nprovide different rates to the receivers in function of the channel quality.\nUnfortunately, the performance evaluation of such modulations requires time\nconsuming simulations. We propose in this paper a novel approach based on the\nchannel capacity to avoid these simulations. The method allows to study the\nperformance of hierarchical and also classical modulations combined with error\ncorrecting codes. We will also compare hierarchical modulation with time\nsharing strategy in terms of achievable rates and indisponibility. Our work\nwill be applied to the DVB-SH and DVB-S2 standards, which both consider\nhierarchical modulation as an optional feature."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1103.3099v2", 
    "title": "Optimal Power Cost Management Using Stored Energy in Data Centers", 
    "arxiv-id": "1103.3099v2", 
    "author": "Anand Sivasubramaniam", 
    "publish": "2011-03-16T05:37:18Z", 
    "summary": "Since the electricity bill of a data center constitutes a significant portion\nof its overall operational costs, reducing this has become important. We\ninvestigate cost reduction opportunities that arise by the use of uninterrupted\npower supply (UPS) units as energy storage devices. This represents a deviation\nfrom the usual use of these devices as mere transitional fail-over mechanisms\nbetween utility and captive sources such as diesel generators. We consider the\nproblem of opportunistically using these devices to reduce the time average\nelectric utility bill in a data center. Using the technique of Lyapunov\noptimization, we develop an online control algorithm that can optimally exploit\nthese devices to minimize the time average cost. This algorithm operates\nwithout any knowledge of the statistics of the workload or electricity cost\nprocesses, making it attractive in the presence of workload and pricing\nuncertainties. An interesting feature of our algorithm is that its deviation\nfrom optimality reduces as the storage capacity is increased. Our work opens up\na new area in data center power management."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1105.4341v2", 
    "title": "The Chaos of Propagation in a Retrial Supermarket Model", 
    "arxiv-id": "1105.4341v2", 
    "author": "Yang Wang", 
    "publish": "2011-05-22T14:51:29Z", 
    "summary": "When decomposing the total orbit into $N$ sub-orbits (or simply orbits)\nrelated to each of $N$ servers and through comparing the numbers of customers\nin these orbits, we introduce a retrial supermarket model of $N$ identical\nservers, where two probing-server choice numbers are respectively designed for\ndynamically allocating each primary arrival and each retrial arrival into these\norbits when the chosen servers are all busy. Note that the designed purpose of\nthe two choice numbers can effectively improve performance measures of this\nretrial supermarket model.\n  This paper analyzes a simple and basic retrial supermarket model of N\nidentical servers, that is, Poisson arrivals, exponential service and retrial\ntimes. To this end, we first provide a detailed probability computation to set\nup an infinite-dimensional system of differential equations (or mean-field\nequations) satisfied by the expected fraction vector. Then, as N goes to\ninfinity, we apply the operator semigroup to obtaining the mean-field limit (or\nchaos of propagation) for the sequence of Markov processes which express the\nstate of this retrial supermarket model. Specifically, some simple and basic\nconditions for the mean-field limit as well as for the Lipschitz condition are\nestablished through the first two moments of the queue length in any orbit.\nFinally, we show that the fixed point satisfies a system of nonlinear equations\nwhich is an interesting networking generalization of the tail equations given\nin the M/M/1 retrial queue, and also use the fixed point to give performance\nanalysis of this retrial supermarket model through numerical computation."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1105.5481v1", 
    "title": "Performance Acceleration of Kernel Polynomial Method Applying Graphics   Processing Units", 
    "arxiv-id": "1105.5481v1", 
    "author": "Seiji Yunoki", 
    "publish": "2011-05-27T05:53:46Z", 
    "summary": "The Kernel Polynomial Method (KPM) is one of the fast diagonalization methods\nused for simulations of quantum systems in research fields of condensed matter\nphysics and chemistry. The algorithm has a difficulty to be parallelized on a\ncluster computer or a supercomputer due to the fine-gain recursive\ncalculations. This paper proposes an implementation of the KPM on the recent\ngraphics processing units (GPU) where the recursive calculations are able to be\nparallelized in the massively parallel environment. This paper also illustrates\nperformance evaluations regarding the cases when the actual simulation\nparameters are applied, the one for increased intensive calculations and the\none for increased amount of memory usage. Finally, it concludes that the\nperformance on GPU promises very high performance compared to the one on CPU\nand reduces the overall simulation time."
},{
    "category": "cs.NI", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1106.0787v1", 
    "title": "Super-Exponential Solution in Markovian Supermarket Models: Framework   and Challenge", 
    "arxiv-id": "1106.0787v1", 
    "author": "Quan-Lin Li", 
    "publish": "2011-06-04T04:24:26Z", 
    "summary": "Marcel F. Neuts opened a key door in numerical computation of stochastic\nmodels by means of phase-type (PH) distributions and Markovian arrival\nprocesses (MAPs). To celebrate his 75th birthday, this paper reports a more\ngeneral framework of Markovian supermarket models, including a system of\ndifferential equations for the fraction measure and a system of nonlinear\nequations for the fixed point. To understand this framework heuristically, this\npaper gives a detailed analysis for three important supermarket examples: M/G/1\ntype, GI/M/1 type and multiple choices, explains how to derive the system of\ndifferential equations by means of density-dependent jump Markov processes, and\nshows that the fixed point may be simply super-exponential through solving the\nsystem of nonlinear equations. Note that supermarket models are a class of\ncomplicated queueing systems and their analysis can not apply popular queueing\ntheory, it is necessary in the study of supermarket models to summarize such a\nmore general framework which enables us to focus on important research issues.\nOn this line, this paper develops matrix-analytical methods of Markovian\nsupermarket models. We hope this will be able to open a new avenue in\nperformance evaluation of supermarket models by means of matrix-analytical\nmethods."
},{
    "category": "cs.SY", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1106.1424v2", 
    "title": "Fixed-delay Events in Generalized Semi-Markov Processes Revisited", 
    "arxiv-id": "1106.1424v2", 
    "author": "Vojt\u011bch \u0158eh\u00e1k", 
    "publish": "2011-06-07T19:50:59Z", 
    "summary": "We study long run average behavior of generalized semi-Markov processes with\nboth fixed-delay events as well as variable-delay events. We show that allowing\ntwo fixed-delay events and one variable-delay event may cause an unstable\nbehavior of a GSMP. In particular, we show that a frequency of a given state\nmay not be defined for almost all runs (or more generally, an invariant measure\nmay not exist). We use this observation to disprove several results from\nliterature. Next we study GSMP with at most one fixed-delay event combined with\nan arbitrary number of variable-delay events. We prove that such a GSMP always\npossesses an invariant measure which means that the frequencies of states are\nalways well defined and we provide algorithms for approximation of these\nfrequencies. Additionally, we show that the positive results remain valid even\nif we allow an arbitrary number of reasonably restricted fixed-delay events."
},{
    "category": "cs.PF", 
    "doi": "10.1109/JSAC.2012.121026", 
    "link": "http://arxiv.org/pdf/1106.2992v1", 
    "title": "A Characterization of the SPARC T3-4 System", 
    "arxiv-id": "1106.2992v1", 
    "author": "Michiel W. van Tol", 
    "publish": "2011-06-15T15:18:27Z", 
    "summary": "This technical report covers a set of experiments on the 64-core SPARC T3-4\nsystem, comparing it to two similar AMD and Intel systems. Key characteristics\nas maximum integer and floating point arithmetic throughput are measured as\nwell as memory throughput, showing the scalability of the SPARC T3-4 system.\nThe performance of POSIX threads primitives is characterized and compared in\ndetail, such as thread creation and mutex synchronization. Scalability tests\nwith a fine grained multithreaded runtime are performed, showing problems with\natomic CAS operations on such physically highly parallel systems."
},{
    "category": "math.PR", 
    "doi": "10.1214/12-AAP888", 
    "link": "http://arxiv.org/pdf/1106.4582v2", 
    "title": "Decay of tails at equilibrium for FIFO join the shortest queue networks", 
    "arxiv-id": "1106.4582v2", 
    "author": "Balaji Prabhakar", 
    "publish": "2011-06-22T21:11:49Z", 
    "summary": "In join the shortest queue networks, incoming jobs are assigned to the\nshortest queue from among a randomly chosen subset of $D$ queues, in a system\nof $N$ queues; after completion of service at its queue, a job leaves the\nnetwork. We also assume that jobs arrive into the system according to a\nrate-$\\alpha N$ Poisson process, $\\alpha<1$, with rate-1 service at each queue.\nWhen the service at queues is exponentially distributed, it was shown in\nVvedenskaya et al. [Probl. Inf. Transm. 32 (1996) 15-29] that the tail of the\nequilibrium queue size decays doubly exponentially in the limit as\n$N\\rightarrow\\infty$. This is a substantial improvement over the case D=1,\nwhere the queue size decays exponentially. The reasoning in [Probl. Inf.\nTransm. 32 (1996) 15-29] does not easily generalize to jobs with nonexponential\nservice time distributions. A modularized program for treating general service\ntime distributions was introduced in Bramson et al. [In Proc. ACM SIGMETRICS\n(2010) 275-286]. The program relies on an ansatz that asserts, in equilibrium,\nany fixed number of queues become independent of one another as\n$N\\rightarrow\\infty$. This ansatz was demonstrated in several settings in\nBramson et al. [Queueing Syst. 71 (2012) 247-292], including for networks where\nthe service discipline is FIFO and the service time distribution has a\ndecreasing hazard rate. In this article, we investigate the limiting behavior,\nas $N\\rightarrow \\infty$, of the equilibrium at a queue when the service\ndiscipline is FIFO and the service time distribution has a power law with a\ngiven exponent $-\\beta$, for $\\beta>1$. We show under the above ansatz that, as\n$N\\rightarrow\\infty$, the tail of the equilibrium queue size exhibits a wide\nrange of behavior depending on the relationship between $\\beta$ and $D$. In\nparticular, if $\\beta>D/(D-1)$, the tail is doubly exponential and, if\n$\\beta<D/(D-1)$, the tail has a power law. When $\\beta=D/(D-1)$, the tail is\nexponentially distributed."
},{
    "category": "cs.DC", 
    "doi": "10.1214/12-AAP888", 
    "link": "http://arxiv.org/pdf/1106.5694v2", 
    "title": "GPU-Based Heuristic Solver for Linear Sum Assignment Problems Under   Real-time Constraints", 
    "arxiv-id": "1106.5694v2", 
    "author": "Sameh El-Ansary", 
    "publish": "2011-06-28T14:53:58Z", 
    "summary": "In this paper we modify a fast heuristic solver for the Linear Sum Assignment\nProblem (LSAP) for use on Graphical Processing Units (GPUs). The motivating\nscenario is an industrial application for P2P live streaming that is moderated\nby a central node which is periodically solving LSAP instances for assigning\npeers to one another. The central node needs to handle LSAP instances involving\nthousands of peers in as near to real-time as possible. Our findings are\ngeneric enough to be applied in other contexts. Our main result is a parallel\nversion of a heuristic algorithm called Deep Greedy Switching (DGS) on GPUs\nusing the CUDA programming language. DGS sacrifices absolute optimality in\nfavor of low computation time and was designed as an alternative to classical\nLSAP solvers such as the Hungarian and auctioning methods. The contribution of\nthe paper is threefold: First, we present the process of trial and error we\nwent through, in the hope that our experience will be beneficial to adopters of\nGPU programming for similar problems. Second, we show the modifications needed\nto parallelize the DGS algorithm. Third, we show the performance gains of our\napproach compared to both a sequential CPU-based implementation of DGS and a\nparallel GPU-based implementation of the auctioning algorithm."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TIT.2012.2208582", 
    "link": "http://arxiv.org/pdf/1106.6328v3", 
    "title": "On the Asymptotic Validity of the Decoupling Assumption for Analyzing   802.11 MAC Protocol", 
    "arxiv-id": "1106.6328v3", 
    "author": "Yuming Jiang", 
    "publish": "2011-06-30T18:29:54Z", 
    "summary": "Performance evaluation of the 802.11 MAC protocol is classically based on the\ndecoupling assumption, which hypothesizes that the backoff processes at\ndifferent nodes are independent. This decoupling assumption results from mean\nfield convergence and is generally true in transient regime in the asymptotic\nsense (when the number of wireless nodes tends to infinity), but, contrary to\nwidespread belief, may not necessarily hold in stationary regime. The issue is\noften related with the existence and uniqueness of a solution to a fixed point\nequation; however, it was also recently shown that this condition is not\nsufficient; in contrast, a sufficient condition is a global stability property\nof the associated ordinary differential equation. In this paper, we give a\nsimple condition that establishes the asymptotic validity of the decoupling\nassumption for the homogeneous case. We also discuss the heterogeneous and the\ndifferentiated service cases and formulate a new ordinary differential\nequation. We show that the uniqueness of a solution to the associated fixed\npoint equation is not sufficient; we exhibit one case where the fixed point\nequation has a unique solution but the decoupling assumption is not valid in\nthe asymptotic sense in stationary regime."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.57", 
    "link": "http://arxiv.org/pdf/1107.0746v1", 
    "title": "Proceedings Ninth Workshop on Quantitative Aspects of Programming   Languages", 
    "arxiv-id": "1107.0746v1", 
    "author": "Gethin Norman", 
    "publish": "2011-07-04T21:44:01Z", 
    "summary": "This volume contains the proceedings of the Ninth Workshop on Quantitative\nAspects of Programming Languages (QAPL 2011), held in Saarbrucken, Germany,\nApril 1--3, 2011. QAPL 2011 is a satellite event of the European Joint\nConferences on Theory and Practice of Software (ETAPS 2011).\n  The workshop theme is on quantitative aspects of computation. These aspects\nare related to the use of physical quantities (storage space, time, bandwidth,\netc.) as well as mathematical quantities (e.g. probability and measures for\nreliability, security and trust), and play an important (sometimes essential)\nrole in characterising the behavior and determining the properties of systems.\nSuch quantities are central to the definition of both the model of systems\n(architecture, language design, semantics) and the methodologies and tools for\nthe analysis and verification of the systems properties. The aim of this\nworkshop is to discuss the explicit use of quantitative information such as\ntime and probabilities either directly in the model or as a tool for the\nanalysis of systems."
},{
    "category": "cs.IT", 
    "doi": "10.4204/EPTCS.57", 
    "link": "http://arxiv.org/pdf/1107.1525v1", 
    "title": "Accelerating Lossless Data Compression with GPUs", 
    "arxiv-id": "1107.1525v1", 
    "author": "P. Bangalore", 
    "publish": "2011-06-21T22:55:02Z", 
    "summary": "Huffman compression is a statistical, lossless, data compression algorithm\nthat compresses data by assigning variable length codes to symbols, with the\nmore frequently appearing symbols given shorter codes than the less. This work\nis a modification of the Huffman algorithm which permits uncompressed data to\nbe decomposed into indepen- dently compressible and decompressible blocks,\nallowing for concurrent compression and decompression on multiple processors.\nWe create implementations of this modified algorithm on a current NVIDIA GPU\nusing the CUDA API as well as on a current Intel chip and the performance\nresults are compared, showing favorable GPU performance for nearly all tests.\nLastly, we discuss the necessity for high performance data compression in\ntoday's supercomputing ecosystem."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.57", 
    "link": "http://arxiv.org/pdf/1107.3087v1", 
    "title": "Non-equilibrium Information Envelopes and the   Capacity-Delay-Error-Tradeoff of Source Coding", 
    "arxiv-id": "1107.3087v1", 
    "author": "Markus Fidler", 
    "publish": "2011-07-15T15:22:45Z", 
    "summary": "This paper develops an envelope-based approach to establish a link between\ninformation and queueing theory. Unlike classical, equilibrium information\ntheory, information envelopes focus on the dynamics of sources and coders,\nusing functions of time that bound the number of bits generated. In the limit\nthe information envelopes converge to the average behavior and recover the\nentropy of a source, respectively, the average codeword length of a coder. In\ncontrast, on short time scales and for sources with memory it is shown that\nlarge deviations from known equilibrium results occur with non-negligible\nprobability. These can cause significant network delays. Compared to well-known\ntraffic models from queueing theory, information envelopes consider the\nfunctioning of information sources and coders, avoiding a priori assumptions,\nsuch as exponential traffic, or empirical, trace-based traffic models. Using\nresults from the stochastic network calculus, the envelopes yield a\ncharacterization of the operating points of source coders by the triplet of\ncapacity, delay, and error. In the limit, assuming an optimal coder the\nrequired capacity approaches the entropy with arbitrarily small probability of\nerror if infinitely large delays are permitted. We derive a corresponding\ncharacterization of channels and prove that the model has the desirable\nproperty of additivity, that allows analyzing coders and channels separately."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TMM.2014.2300041", 
    "link": "http://arxiv.org/pdf/1108.0187v5", 
    "title": "Analysis of Buffer Starvation with Application to Objective QoE   Optimization of Streaming Services", 
    "arxiv-id": "1108.0187v5", 
    "author": "Tania Jimenez", 
    "publish": "2011-07-31T16:10:57Z", 
    "summary": "Our purpose in this paper is to characterize buffer starvations for streaming\nservices. The buffer is modeled as an M/M/1 queue, plus the consideration of\nbursty arrivals. When the buffer is empty, the service restarts after a certain\namount of packets are \\emph{prefetched}. With this goal, we propose two\napproaches to obtain the \\emph{exact distribution} of the number of buffer\nstarvations, one of which is based on \\emph{Ballot theorem}, and the other uses\nrecursive equations. The Ballot theorem approach gives an explicit result. We\nextend this approach to the scenario with a constant playback rate using\nT\\`{a}kacs Ballot theorem. The recursive approach, though not offering an\nexplicit result, can obtain the distribution of starvations with\nnon-independent and identically distributed (i.i.d.) arrival process in which\nan ON/OFF bursty arrival process is considered in this work. We further compute\nthe starvation probability as a function of the amount of prefetched packets\nfor a large number of files via a fluid analysis. Among many potential\napplications of starvation analysis, we show how to apply it to optimize the\nobjective quality of experience (QoE) of media streaming, by exploiting the\ntradeoff between startup/rebuffering delay and starvations."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.64.3", 
    "link": "http://arxiv.org/pdf/1108.4466v1", 
    "title": "Read Operators and their Expressiveness in Process Algebras", 
    "arxiv-id": "1108.4466v1", 
    "author": "Walter Vogler", 
    "publish": "2011-08-23T01:23:16Z", 
    "summary": "We study two different ways to enhance PAFAS, a process algebra for modelling\nasynchronous timed concurrent systems, with non-blocking reading actions. We\nfirst add reading in the form of a read-action prefix operator. This operator\nis very flexible, but its somewhat complex semantics requires two types of\ntransition relations. We also present a read-set prefix operator with a simpler\nsemantics, but with syntactic restrictions. We discuss the expressiveness of\nread prefixes; in particular, we compare them to read-arcs in Petri nets and\njustify the simple semantics of the second variant by showing that its\nprocesses can be translated into processes of the first with timed-bisimilar\nbehaviour. It is still an open problem whether the first algebra is more\nexpressive than the second; we give a number of laws that are interesting in\ntheir own right, and can help to find a backward translation."
},{
    "category": "cs.DB", 
    "doi": "10.4204/EPTCS.64.3", 
    "link": "http://arxiv.org/pdf/1111.0594v1", 
    "title": "Exploring Oracle RDBMS latches using Solaris DTrace", 
    "arxiv-id": "1111.0594v1", 
    "author": "Andrey Nikolaev", 
    "publish": "2011-11-02T18:20:36Z", 
    "summary": "Rise of hundreds cores technologies bring again to the first plan the problem\nof interprocess synchronization in database engines. Spinlocks are widely used\nin contemporary DBMS to synchronize processes at microsecond timescale. Latches\nare Oracle RDBMS specific spinlocks. The latch contention is common to observe\nin contemporary high concurrency OLTP environments.\n  In contrast to system spinlocks used in operating systems kernels, latches\nwork in user context. Such user level spinlocks are influenced by context\npreemption and multitasking. Until recently there were no direct methods to\nmeasure effectiveness of user spinlocks. This became possible with the\nemergence of Solaris 10 Dynamic Tracing framework. DTrace allows tracing and\nprofiling both OS and user applications.\n  This work investigates the possibilities to diagnose and tune Oracle latches.\nIt explores the contemporary latch realization and spinning-blocking\nstrategies, analyses corresponding statistic counters.\n  A mathematical model developed to estimate analytically the effect of tuning\n_SPIN_COUNT value."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.64.3", 
    "link": "http://arxiv.org/pdf/1111.1926v2", 
    "title": "Performance Analysis of Sequential Method for Handover in Cognitive   Radio Systems", 
    "arxiv-id": "1111.1926v2", 
    "author": "Masoumeh Nasiri-Kenari", 
    "publish": "2011-11-08T14:54:57Z", 
    "summary": "Powerful spectrum handover schemes enable cognitive radios (CRs) to use\ntransmission opportunities in primary users' channels appropriately. In this\npaper, we consider the cognitive access of primary channels by a secondary\nuser. We evaluate the average detection time and the maximum achievable average\nthroughput of the secondary user when the sequential method for hand-over\n(SMHO) is used. We assume that a prior knowledge of the primary users' presence\nand absence probabilities are available. When investigating the maximum\nachievable throughput of the secondary user, we end into an optimization\nproblem, in which the optimum value of sensing time must be selected. In our\noptimization problem, we take into account the spectrum hand over due to false\ndetection of the primary user. We also propose a weighted based hand-over\n(WBHO) scheme in which the impacts of channels conditions and primary users'\npresence probability are considered. This Spectrum handover scheme provides\nhigher average throughput for the SU than the SMHO method. The tradeoff between\nthe maximum achievable throughput and consumed energy is discussed, and finally\nan energy efficient optimization formulation for finding a proper sensing time\nis provided."
},{
    "category": "cs.SE", 
    "doi": "10.4204/EPTCS.73.8", 
    "link": "http://arxiv.org/pdf/1111.3110v1", 
    "title": "Model Checking Probabilistic Real-Time Properties for Service-Oriented   Systems with Service Level Agreements", 
    "arxiv-id": "1111.3110v1", 
    "author": "Holger Giese", 
    "publish": "2011-11-14T06:35:42Z", 
    "summary": "The assurance of quality of service properties is an important aspect of\nservice-oriented software engineering. Notations for so-called service level\nagreements (SLAs), such as the Web Service Level Agreement (WSLA) language,\nprovide a formal syntax to specify such assurances in terms of (legally\nbinding) contracts between a service provider and a customer. On the other\nhand, formal methods for verification of probabilistic real-time behavior have\nreached a level of expressiveness and efficiency which allows to apply them in\nreal-world scenarios. In this paper, we suggest to employ the recently\nintroduced model of Interval Probabilistic Timed Automata (IPTA) for formal\nverification of QoS properties of service-oriented systems. Specifically, we\nshow that IPTA in contrast to Probabilistic Timed Automata (PTA) are able to\ncapture the guarantees specified in SLAs directly. A particular challenge in\nthe analysis of IPTA is the fact that their naive semantics usually yields an\ninfinite set of states and infinitely-branching transitions. However, using\nsymbolic representations, IPTA can be analyzed rather efficiently. We have\ndeveloped the first implementation of an IPTA model checker by extending the\nPRISM tool and show that model checking IPTA is only slightly more expensive\nthan model checking comparable PTA."
},{
    "category": "math.DS", 
    "doi": "10.4204/EPTCS.73.8", 
    "link": "http://arxiv.org/pdf/1111.5710v1", 
    "title": "On Mean Field Convergence and Stationary Regime", 
    "arxiv-id": "1111.5710v1", 
    "author": "Jean-Yves Le Boudec", 
    "publish": "2011-11-24T10:13:13Z", 
    "summary": "Assume that a family of stochastic processes on some Polish space $E$\nconverges to a deterministic process; the convergence is in distribution (hence\nin probability) at every fixed point in time. This assumption holds for a large\nfamily of processes, among which many mean field interaction models and is\nweaker than previously assumed. We show that any limit point of an invariant\nprobability of the stochastic process is an invariant probability of the\ndeterministic process. The results are valid in discrete and in continuous\ntime."
},{
    "category": "cs.PF", 
    "doi": "10.1016/j.amc.2012.05.020", 
    "link": "http://arxiv.org/pdf/1111.6374v2", 
    "title": "Solving Dense Generalized Eigenproblems on Multi-threaded Architectures", 
    "arxiv-id": "1111.6374v2", 
    "author": "Enrique S. Quintana-Ort\u00ed", 
    "publish": "2011-11-28T08:52:04Z", 
    "summary": "We compare two approaches to compute a portion of the spectrum of dense\nsymmetric definite generalized eigenproblems: one is based on the reduction to\ntridiagonal form, and the other on the Krylov-subspace iteration. Two\nlarge-scale applications, arising in molecular dynamics and material science,\nare employed to investigate the contributions of the application, architecture,\nand parallelism of the method to the performance of the solvers. The\nexperimental results on a state-of-the-art 8-core platform, equipped with a\ngraphics processing unit (GPU), reveal that in real applications, iterative\nKrylov-subspace methods can be a competitive approach also for the solution of\ndense problems."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.amc.2012.05.020", 
    "link": "http://arxiv.org/pdf/1111.6756v1", 
    "title": "The Potential of Synergistic Static, Dynamic and Speculative Loop Nest   Optimizations for Automatic Parallelization", 
    "arxiv-id": "1111.6756v1", 
    "author": "Lawrence Rauchwerger", 
    "publish": "2011-11-29T10:40:44Z", 
    "summary": "Research in automatic parallelization of loop-centric programs started with\nstatic analysis, then broadened its arsenal to include dynamic\ninspection-execution and speculative execution, the best results involving\nhybrid static-dynamic schemes. Beyond the detection of parallelism in a\nsequential program, scalable parallelization on many-core processors involves\nhard and interesting parallelism adaptation and mapping challenges. These\nchallenges include tailoring data locality to the memory hierarchy, structuring\nindependent tasks hierarchically to exploit multiple levels of parallelism,\ntuning the synchronization grain, balancing the execution load, decoupling the\nexecution into thread-level pipelines, and leveraging heterogeneous hardware\nwith specialized accelerators. The polyhedral framework allows to model,\nconstruct and apply very complex loop nest transformations addressing most of\nthe parallelism adaptation and mapping challenges. But apart from\nhardware-specific, back-end oriented transformations (if-conversion, trace\nscheduling, value prediction), loop nest optimization has essentially ignored\ndynamic and speculative techniques. Research in polyhedral compilation recently\nreached a significant milestone towards the support of dynamic, data-dependent\ncontrol flow. This opens a large avenue for blending dynamic analyses and\nspeculative techniques with advanced loop nest optimizations. Selecting\nreal-world examples from SPEC benchmarks and numerical kernels, we make a case\nfor the design of synergistic static, dynamic and speculative loop\ntransformation techniques. We also sketch the embedding of dynamic information,\nincluding speculative assumptions, in the heart of affine transformation search\nspaces."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.jocs.2011.01.006", 
    "link": "http://arxiv.org/pdf/1112.4539v1", 
    "title": "Implementation of a Parallel Tree Method on a GPU", 
    "arxiv-id": "1112.4539v1", 
    "author": "Naohito Nakasato", 
    "publish": "2011-12-20T00:59:41Z", 
    "summary": "The kd-tree is a fundamental tool in computer science. Among other\napplications, the application of kd-tree search (by the tree method) to the\nfast evaluation of particle interactions and neighbor search is highly\nimportant, since the computational complexity of these problems is reduced from\nO(N^2) for a brute force method to O(N log N) for the tree method, where N is\nthe number of particles. In this paper, we present a parallel implementation of\nthe tree method running on a graphics processing unit (GPU). We present a\ndetailed description of how we have implemented the tree method on a Cypress\nGPU. An optimization that we found important is localized particle ordering to\neffectively utilize cache memory. We present a number of test results and\nperformance measurements. Our results show that the execution of the tree\ntraversal in a force calculation on a GPU is practical and efficient."
},{
    "category": "cs.DC", 
    "doi": "10.1016/j.jocs.2011.01.006", 
    "link": "http://arxiv.org/pdf/1112.5505v5", 
    "title": "A Study on Using Uncertain Time Series Matching Algorithms in MapReduce   Applications", 
    "arxiv-id": "1112.5505v5", 
    "author": "Reza Moraveji", 
    "publish": "2011-12-23T02:38:42Z", 
    "summary": "In this paper, we study CPU utilization time patterns of several Map-Reduce\napplications. After extracting running patterns of several applications, the\npatterns with their statistical information are saved in a reference database\nto be later used to tweak system parameters to efficiently execute unknown\napplications in future. To achieve this goal, CPU utilization patterns of new\napplications along with its statistical information are compared with the\nalready known ones in the reference database to find/predict their most\nprobable execution patterns. Because of different patterns lengths, the Dynamic\nTime Warping (DTW) is utilized for such comparison; a statistical analysis is\nthen applied to DTWs' outcomes to select the most suitable candidates.\nMoreover, under a hypothesis, another algorithm is proposed to classify\napplications under similar CPU utilization patterns. Three widely used text\nprocessing applications (WordCount, Distributed Grep, and Terasort) and another\napplication (Exim Mainlog parsing) are used to evaluate our hypothesis in\ntweaking system parameters in executing similar applications. Results were very\npromising and showed effectiveness of our approach on 5-node Map-Reduce\nplatform"
},{
    "category": "cs.DC", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1112.5588v2", 
    "title": "Sparse matrix-vector multiplication on GPGPU clusters: A new storage   format and a scalable implementation", 
    "arxiv-id": "1112.5588v2", 
    "author": "Alan R. Bishop", 
    "publish": "2011-12-23T14:03:56Z", 
    "summary": "Sparse matrix-vector multiplication (spMVM) is the dominant operation in many\nsparse solvers. We investigate performance properties of spMVM with matrices of\nvarious sparsity patterns on the nVidia \"Fermi\" class of GPGPUs. A new \"padded\njagged diagonals storage\" (pJDS) format is proposed which may substantially\nreduce the memory overhead intrinsic to the widespread ELLPACK-R scheme. In our\ntest scenarios the pJDS format cuts the overall spMVM memory footprint on the\nGPGPU by up to 70%, and achieves 95% to 130% of the ELLPACK-R performance.\nUsing a suitable performance model we identify performance bottlenecks on the\nnode level that invalidate some types of matrix structures for efficient\nmulti-GPGPU parallelization. For appropriate sparsity patterns we extend\nprevious work on distributed-memory parallel spMVM to demonstrate a scalable\nhybrid MPI-GPGPU code, achieving efficient overlap of communication and\ncomputation."
},{
    "category": "cs.IT", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1201.0662v1", 
    "title": "Transmission capacity of wireless networks", 
    "arxiv-id": "1201.0662v1", 
    "author": "Jeffrey G. Andrews", 
    "publish": "2012-01-03T15:21:48Z", 
    "summary": "Transmission capacity (TC) is a performance metric for wireless networks that\nmeasures the spatial intensity of successful transmissions per unit area,\nsubject to a constraint on the permissible outage probability (where outage\noccurs when the SINR at a receiver is below a threshold). This volume gives a\nunified treatment of the TC framework that has been developed by the authors\nand their collaborators over the past decade. The mathematical framework\nunderlying the analysis (reviewed in Ch. 2) is stochastic geometry: Poisson\npoint processes model the locations of interferers, and (stable) shot noise\nprocesses represent the aggregate interference seen at a receiver. Ch. 3\npresents TC results (exact, asymptotic, and bounds) on a simple model in order\nto illustrate a key strength of the framework: analytical tractability yields\nexplicit performance dependence upon key model parameters. Ch. 4 presents\nenhancements to this basic model --- channel fading, variable link distances,\nand multi-hop. Ch. 5 presents four network design case studies well-suited to\nTC: i) spectrum management, ii) interference cancellation, iii) signal\nthreshold transmission scheduling, and iv) power control. Ch. 6 studies the TC\nwhen nodes have multiple antennas, which provides a contrast vs. classical\nresults that ignore interference."
},{
    "category": "cs.NI", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1201.1090v2", 
    "title": "Distributed Multiuser Sequential Channel Sensing Schemes in Multichannel   Cognitive Radio Networks", 
    "arxiv-id": "1201.1090v2", 
    "author": "Masoumeh Nasiri-Kenari", 
    "publish": "2012-01-05T09:26:40Z", 
    "summary": "This paper has been withdrawn by the author due to a crucial problem\nassociated with Figs. 2 and 3."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1201.5229v1", 
    "title": "Cross-entropy optimisation of importance sampling parameters for   statistical model checking", 
    "arxiv-id": "1201.5229v1", 
    "author": "Sean Sedwards", 
    "publish": "2012-01-25T10:22:58Z", 
    "summary": "Statistical model checking avoids the exponential growth of states associated\nwith probabilistic model checking by estimating properties from multiple\nexecutions of a system and by giving results within confidence bounds. Rare\nproperties are often very important but pose a particular challenge for\nsimulation-based approaches, hence a key objective under these circumstances is\nto reduce the number and length of simulations necessary to produce a given\nlevel of confidence. Importance sampling is a well-established technique that\nachieves this, however to maintain the advantages of statistical model checking\nit is necessary to find good importance sampling distributions without\nconsidering the entire state space.\n  Motivated by the above, we present a simple algorithm that uses the notion of\ncross-entropy to find the optimal parameters for an importance sampling\ndistribution. In contrast to previous work, our algorithm uses a low\ndimensional vector of parameters to define this distribution and thus avoids\nthe often intractable explicit representation of a transition matrix. We show\nthat our parametrisation leads to a unique optimum and can produce many orders\nof magnitude improvement in simulation efficiency. We demonstrate the efficacy\nof our methodology by applying it to models from reliability engineering and\nbiochemistry."
},{
    "category": "cs.PF", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1201.6402v1", 
    "title": "A Note on Disk Drag Dynamics", 
    "arxiv-id": "1201.6402v1", 
    "author": "Neil J. Gunther", 
    "publish": "2012-01-30T23:03:45Z", 
    "summary": "The electrical power consumed by typical magnetic hard disk drives (HDD) not\nonly increases linearly with the number of spindles but, more significantly, it\nincreases as very fast power-laws of speed (RPM) and diameter. Since the\ntheoretical basis for this relationship is neither well-known nor readily\naccessible in the literature, we show how these exponents arise from\naerodynamic disk drag and discuss their import for green storage capacity\nplanning."
},{
    "category": "cs.IT", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1202.4661v1", 
    "title": "Delay Asymptotics with Retransmissions and Incremental Redundancy Codes   over Erasure Channels", 
    "arxiv-id": "1202.4661v1", 
    "author": "Hesham El-Gamal", 
    "publish": "2012-02-20T19:05:12Z", 
    "summary": "Recent studies have shown that retransmissions can cause heavy-tailed\ntransmission delays even when packet sizes are light-tailed. Moreover, the\nimpact of heavy-tailed delays persists even when packets size are upper\nbounded. The key question we study in this paper is how the use of coding\ntechniques to transmit information, together with different system\nconfigurations, would affect the distribution of delay. To investigate this\nproblem, we model the underlying channel as a Markov modulated binary erasure\nchannel, where transmitted bits are either received successfully or erased.\nErasure codes are used to encode information prior to transmission, which\nensures that a fixed fraction of the bits in the codeword can lead to\nsuccessful decoding. We use incremental redundancy codes, where the codeword is\ndivided into codeword trunks and these trunks are transmitted one at a time to\nprovide incremental redundancies to the receiver until the information is\nrecovered. We characterize the distribution of delay under two different\nscenarios: (I) Decoder uses memory to cache all previously successfully\nreceived bits. (II) Decoder does not use memory, where received bits are\ndiscarded if the corresponding information cannot be decoded. In both cases, we\nconsider codeword length with infinite and finite support. From a theoretical\nperspective, our results provide a benchmark to quantify the tradeoff between\nsystem complexity and the distribution of delay."
},{
    "category": "cs.IT", 
    "doi": "10.1109/IPDPSW.2012.211", 
    "link": "http://arxiv.org/pdf/1202.5202v1", 
    "title": "Secure Compressed Reading in Smart Grids", 
    "arxiv-id": "1202.5202v1", 
    "author": "Sidharth Jaggi", 
    "publish": "2012-02-22T11:12:32Z", 
    "summary": "Smart Grids measure energy usage in real-time and tailor supply and delivery\naccordingly, in order to improve power transmission and distribution. For the\ngrids to operate effectively, it is critical to collect readings from\nmassively-installed smart meters to control centers in an efficient and secure\nmanner. In this paper, we propose a secure compressed reading scheme to address\nthis critical issue. We observe that our collected real-world meter data\nexpress strong temporal correlations, indicating they are sparse in certain\ndomains. We adopt Compressed Sensing technique to exploit this sparsity and\ndesign an efficient meter data transmission scheme. Our scheme achieves\nsubstantial efficiency offered by compressed sensing, without the need to know\nbeforehand in which domain the meter data are sparse. This is in contrast to\ntraditional compressed-sensing based scheme where such sparse-domain\ninformation is required a priori. We then design specific dependable scheme to\nwork with our compressed sensing based data transmission scheme to make our\nmeter reading reliable and secure. We provide performance guarantee for the\ncorrectness, efficiency, and security of our proposed scheme. Through analysis\nand simulations, we demonstrate the effectiveness of our schemes and compare\ntheir performance to prior arts."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1002/ggge.20071", 
    "link": "http://arxiv.org/pdf/1202.6522v5", 
    "title": "Efficient Spherical Harmonic Transforms aimed at pseudo-spectral   numerical simulations", 
    "arxiv-id": "1202.6522v5", 
    "author": "Nathana\u00ebl Schaeffer", 
    "publish": "2012-02-29T12:05:12Z", 
    "summary": "In this paper, we report on very efficient algorithms for the spherical\nharmonic transform (SHT). Explicitly vectorized variations of the algorithm\nbased on the Gauss-Legendre quadrature are discussed and implemented in the\nSHTns library which includes scalar and vector transforms. The main\nbreakthrough is to achieve very efficient on-the-fly computations of the\nLegendre associated functions, even for very high resolutions, by taking\nadvantage of the specific properties of the SHT and the advanced capabilities\nof current and future computers. This allows us to simultaneously and\nsignificantly reduce memory usage and computation time of the SHT. We measure\nthe performance and accuracy of our algorithms. Even though the complexity of\nthe algorithms implemented in SHTns are in $O(N^3)$ (where N is the maximum\nharmonic degree of the transform), they perform much better than any third\nparty implementation, including lower complexity algorithms, even for\ntruncations as high as N=1023. SHTns is available at\nhttps://bitbucket.org/nschaeff/shtns as open source software."
},{
    "category": "cs.DB", 
    "doi": "10.1002/ggge.20071", 
    "link": "http://arxiv.org/pdf/1203.0160v2", 
    "title": "Scaling Datalog for Machine Learning on Big Data", 
    "arxiv-id": "1203.0160v2", 
    "author": "Raghu Ramakrishnan", 
    "publish": "2012-03-01T11:43:43Z", 
    "summary": "In this paper, we present the case for a declarative foundation for\ndata-intensive machine learning systems. Instead of creating a new system for\neach specific flavor of machine learning task, or hardcoding new optimizations,\nwe argue for the use of recursive queries to program a variety of machine\nlearning systems. By taking this approach, database query optimization\ntechniques can be utilized to identify effective execution plans, and the\nresulting runtime plans can be executed on a single unified data-parallel query\nprocessing engine. As a proof of concept, we consider two programming\nmodels--Pregel and Iterative Map-Reduce-Update---from the machine learning\ndomain, and show how they can be captured in Datalog, tuned for a specific\ntask, and then compiled into an optimized physical plan. Experiments performed\non a large computing cluster with real data demonstrate that this declarative\napproach can provide very good performance while offering both increased\ngenerality and programming ease."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TSP.2012.2184537", 
    "link": "http://arxiv.org/pdf/1203.1535v2", 
    "title": "Performance Analysis of l_0 Norm Constraint Least Mean Square Algorithm", 
    "arxiv-id": "1203.1535v2", 
    "author": "Jian Wang", 
    "publish": "2012-03-07T16:43:45Z", 
    "summary": "As one of the recently proposed algorithms for sparse system identification,\n$l_0$ norm constraint Least Mean Square ($l_0$-LMS) algorithm modifies the cost\nfunction of the traditional method with a penalty of tap-weight sparsity. The\nperformance of $l_0$-LMS is quite attractive compared with its various\nprecursors. However, there has been no detailed study of its performance. This\npaper presents all-around and throughout theoretical performance analysis of\n$l_0$-LMS for white Gaussian input data based on some reasonable assumptions.\nExpressions for steady-state mean square deviation (MSD) are derived and\ndiscussed with respect to algorithm parameters and system sparsity. The\nparameter selection rule is established for achieving the best performance.\nApproximated with Taylor series, the instantaneous behavior is also derived. In\naddition, the relationship between $l_0$-LMS and some previous arts and the\nsufficient conditions for $l_0$-LMS to accelerate convergence are set up.\nFinally, all of the theoretical results are compared with simulations and are\nshown to agree well in a large range of parameter setting."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TSP.2012.2195660", 
    "link": "http://arxiv.org/pdf/1203.1538v2", 
    "title": "Proof of Convergence and Performance Analysis for Sparse Recovery via   Zero-point Attracting Projection", 
    "arxiv-id": "1203.1538v2", 
    "author": "Laming Chen", 
    "publish": "2012-03-07T16:58:20Z", 
    "summary": "A recursive algorithm named Zero-point Attracting Projection (ZAP) is\nproposed recently for sparse signal reconstruction. Compared with the reference\nalgorithms, ZAP demonstrates rather good performance in recovery precision and\nrobustness. However, any theoretical analysis about the mentioned algorithm,\neven a proof on its convergence, is not available. In this work, a strict proof\non the convergence of ZAP is provided and the condition of convergence is put\nforward. Based on the theoretical analysis, it is further proved that ZAP is\nnon-biased and can approach the sparse solution to any extent, with the proper\nchoice of step-size. Furthermore, the case of inaccurate measurements in noisy\nscenario is also discussed. It is proved that disturbance power linearly\nreduces the recovery precision, which is predictable but not preventable. The\nreconstruction deviation of $p$-compressible signal is also provided. Finally,\nnumerical simulations are performed to verify the theoretical analysis."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TSP.2012.2195660", 
    "link": "http://arxiv.org/pdf/1203.5026v1", 
    "title": "On the Power of Centralization in Distributed Processing", 
    "arxiv-id": "1203.5026v1", 
    "author": "Kuang Xu", 
    "publish": "2012-03-22T16:05:33Z", 
    "summary": "In this thesis, we propose and analyze a multi-server model that captures a\nperformance trade-off between centralized and distributed processing. In our\nmodel, a fraction $p$ of an available resource is deployed in a centralized\nmanner (e.g., to serve a most-loaded station) while the remaining fraction\n$1-p$ is allocated to local servers that can only serve requests addressed\nspecifically to their respective stations.\n  Using a fluid model approach, we demonstrate a surprising phase transition in\nthe steady-state delay, as $p$ changes: in the limit of a large number of\nstations, and when any amount of centralization is available ($p>0$), the\naverage queue length in steady state scales as $\\log_{1/(1-p)} 1/(1-\\lambda)$\nwhen the traffic intensity $\\lambda$ goes to 1. This is exponentially smaller\nthan the usual M/M/1-queue delay scaling of $1/(1-\\lambda)$, obtained when all\nresources are fully allocated to local stations ($p=0$). This indicates a\nstrong qualitative impact of even a small degree of centralization.\n  We prove convergence to a fluid limit, and characterize both the transient\nand steady-state behavior of the finite system, in the limit as the number of\nstations $N$ goes to infinity. We show that the sequence of queue-length\nprocesses converges to a unique fluid trajectory (over any finite time\ninterval, as $N$ approaches infinity, and that this fluid trajectory converges\nto a unique invariant state $v^I$, for which a simple closed-form expression is\nobtained. We also show that the steady-state distribution of the $N$-server\nsystem concentrates on $v^I$ as $N$ goes to infinity."
},{
    "category": "cs.DS", 
    "doi": "10.1109/TSP.2012.2195660", 
    "link": "http://arxiv.org/pdf/1203.5675v1", 
    "title": "Memory Hierarchy Sensitive Graph Layout", 
    "arxiv-id": "1203.5675v1", 
    "author": "Amitabha Roy", 
    "publish": "2012-03-26T14:12:48Z", 
    "summary": "Mining large graphs for information is becoming an increasingly important\nworkload due to the plethora of graph structured data becoming available. An\naspect of graph algorithms that has hitherto not received much interest is the\neffect of memory hierarchy on accesses. A typical system today has multiple\nlevels in the memory hierarchy with differing units of locality; ranging across\ncache lines, TLB entries and DRAM pages. We postulate that it is possible to\nallocate graph structured data in main memory in a way as to improve the\nspatial locality of the data. Previous approaches to improving cache locality\nhave focused only on a single unit of locality, either the cache line or\nvirtual memory page. On the other hand cache oblivious algorithms can optimise\nlayout for all levels of the memory hierarchy but unfortunately need to be\nspecially designed for individual data structures. In this paper we explore\nhierarchical blocking as a technique for closing this gap. We require as input\na specification of the units of locality in the memory hierarchy and lay out\nthe input graph accordingly by copying its nodes using a hierarchy of breadth\nfirst searches. We start with a basic algorithm that is limited to trees and\nthen extend it to arbitrary graphs. Our most efficient version requires only a\nconstant amount of additional space. We have implemented versions of the\nalgorithm in various environments: for C programs interfaced with macros, as an\nextension to the Boost object oriented graph library and finally as a\nmodification to the traversal phase of the semispace garbage collector in the\nJikes Java virtual machine. Our results show significant improvements in the\naccess time to graphs of various structure."
},{
    "category": "cs.MS", 
    "doi": "10.1109/TSP.2012.2195660", 
    "link": "http://arxiv.org/pdf/1205.1098v1", 
    "title": "Reliable Generation of High-Performance Matrix Algebra", 
    "arxiv-id": "1205.1098v1", 
    "author": "Jeremy G. Siek", 
    "publish": "2012-05-05T04:30:14Z", 
    "summary": "Scientific programmers often turn to vendor-tuned Basic Linear Algebra\nSubprograms (BLAS) to obtain portable high performance. However, many numerical\nalgorithms require several BLAS calls in sequence, and those successive calls\nresult in suboptimal performance. The entire sequence needs to be optimized in\nconcert. Instead of vendor-tuned BLAS, a programmer could start with source\ncode in Fortran or C (e.g., based on the Netlib BLAS) and use a\nstate-of-the-art optimizing compiler. However, our experiments show that\noptimizing compilers often attain only one-quarter the performance of\nhand-optimized code. In this paper we present a domain-specific compiler for\nmatrix algebra, the Build to Order BLAS (BTO), that reliably achieves high\nperformance using a scalable search algorithm for choosing the best combination\nof loop fusion, array contraction, and multithreading for data parallelism. The\nBTO compiler generates code that is between 16% slower and 39% faster than\nhand-optimized code."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TSP.2012.2195660", 
    "link": "http://arxiv.org/pdf/1205.1622v1", 
    "title": "Performance Measurement of Cloud Computing Services", 
    "arxiv-id": "1205.1622v1", 
    "author": "Roberd Saragih", 
    "publish": "2012-05-08T08:05:34Z", 
    "summary": "Cloud computing today has now been growing as new technologies and new\nbusiness models. In distributed technology perspective, cloud computing most\nlike client-server services like web-based or web-service but it used virtual\nresources to execute. Currently, cloud computing relies on the use of an\nelastic virtual machine and the use of network for data exchange. We conduct an\nexperimental setup to measure the quality of service received by cloud\ncomputing customers. Experimental setup done by creating a HTTP service that\nruns in the cloud computing infrastructure. We interest to know about the\nimpact of increasing the number of users on the average quality received by\nusers. The qualities received by user measured within two parameters consist of\naverage response times and the number of requests time out. Experimental\nresults of this study show that increasing the number of users has increased\nthe average response time. Similarly, the number of request time out increasing\nwith increasing number of users. It means that the qualities of service\nreceived by user are decreasing also. We found that the impact of the number of\nusers on the quality of service is no longer in linear trend. The results of\nthis study can be used as a reference model for the network operator in\nperforming services in which a certain number of users in order to obtain\noptimal quality services."
},{
    "category": "hep-ph", 
    "doi": "10.1016/j.cpc.2012.09.013", 
    "link": "http://arxiv.org/pdf/1206.0919v2", 
    "title": "Relativistic Hydrodynamics on Graphic Cards", 
    "arxiv-id": "1206.0919v2", 
    "author": "Marcus Bleicher", 
    "publish": "2012-06-05T13:16:36Z", 
    "summary": "We show how to accelerate relativistic hydrodynamics simulations using\ngraphic cards (graphic processing units, GPUs). These improvements are of\nhighest relevance e.g. to the field of high-energetic nucleus-nucleus\ncollisions at RHIC and LHC where (ideal and dissipative) relativistic\nhydrodynamics is used to calculate the evolution of hot and dense QCD matter.\nThe results reported here are based on the Sharp And Smooth Transport Algorithm\n(SHASTA), which is employed in many hydrodynamical models and hybrid simulation\npackages, e.g. the Ultrarelativistic Quantum Molecular Dynamics model (UrQMD).\nWe have redesigned the SHASTA using the OpenCL computing framework to work on\naccelerators like graphic processing units (GPUs) as well as on multi-core\nprocessors. With the redesign of the algorithm the hydrodynamic calculations\nhave been accelerated by a factor 160 allowing for event-by-event calculations\nand better statistics in hybrid calculations."
},{
    "category": "cs.SY", 
    "doi": "10.1016/j.cpc.2012.09.013", 
    "link": "http://arxiv.org/pdf/1206.1099v1", 
    "title": "Power Grid Vulnerability to Geographically Correlated Failures -   Analysis and Control Implications", 
    "arxiv-id": "1206.1099v1", 
    "author": "Gil Zussman", 
    "publish": "2012-06-06T00:39:46Z", 
    "summary": "We consider power line outages in the transmission system of the power grid,\nand specifically those caused by a natural disaster or a large scale physical\nattack. In the transmission system, an outage of a line may lead to overload on\nother lines, thereby eventually leading to their outage. While such cascading\nfailures have been studied before, our focus is on cascading failures that\nfollow an outage of several lines in the same geographical area. We provide an\nanalytical model of such failures, investigate the model's properties, and show\nthat it differs from other models used to analyze cascades in the power grid\n(e.g., epidemic/percolation-based models). We then show how to identify the\nmost vulnerable locations in the grid and perform extensive numerical\nexperiments with real grid data to investigate the various effects of\ngeographically correlated outages and the resulting cascades. These results\nallow us to gain insights into the relationships between various parameters and\nperformance metrics, such as the size of the original event, the final number\nof connected components, and the fraction of demand (load) satisfied after the\ncascade. In particular, we focus on the timing and nature of optimal control\nactions used to reduce the impact of a cascade, in real time. We also compare\nresults obtained by our model to the results of a real cascade that occurred\nduring a major blackout in the San Diego area on Sept. 2011. The analysis and\nresults presented in this paper will have implications both on the design of\nnew power grids and on identifying the locations for shielding, strengthening,\nand monitoring efforts in grid upgrades."
},{
    "category": "astro-ph.IM", 
    "doi": "10.1016/j.cpc.2012.09.013", 
    "link": "http://arxiv.org/pdf/1206.1199v1", 
    "title": "Astrophysical Particle Simulations on Heterogeneous CPU-GPU Systems", 
    "arxiv-id": "1206.1199v1", 
    "author": "Ken'ichi Nomoto", 
    "publish": "2012-06-06T12:23:54Z", 
    "summary": "A heterogeneous CPU-GPU node is getting popular in HPC clusters. We need to\nrethink algorithms and optimization techniques for such system depending on the\nrelative performance of CPU vs. GPU. In this paper, we report a performance\noptimized particle simulation code \"OTOO\", that is based on the octree method,\nfor heterogenous systems. Main applications of OTOO are astrophysical\nsimulations such as N-body models and the evolution of a violent merger of\nstars. We propose optimal task split between CPU and GPU where GPU is only used\nto compute the calculation of the particle force. Also, we describe\noptimization techniques such as control of the force accuracy, vectorized tree\nwalk, and work partitioning among multiple GPUs. We used OTOO for modeling a\nmerger of two white dwarf stars and found that OTOO is powerful and practical\nto simulate the fate of the process."
},{
    "category": "math.NA", 
    "doi": "10.1016/j.cpc.2012.09.013", 
    "link": "http://arxiv.org/pdf/1206.1390v1", 
    "title": "Fault-tolerant linear solvers via selective reliability", 
    "arxiv-id": "1206.1390v1", 
    "author": "Mark Hoemmen", 
    "publish": "2012-06-07T03:18:42Z", 
    "summary": "Energy increasingly constrains modern computer hardware, yet protecting\ncomputations and data against errors costs energy. This holds at all scales,\nbut especially for the largest parallel computers being built and planned\ntoday. As processor counts continue to grow, the cost of ensuring reliability\nconsistently throughout an application will become unbearable. However, many\nalgorithms only need reliability for certain data and phases of computation.\nThis suggests an algorithm and system codesign approach. We show that if the\nsystem lets applications apply reliability selectively, we can develop\nalgorithms that compute the right answer despite faults. These \"fault-tolerant\"\niterative methods either converge eventually, at a rate that degrades\ngracefully with increased fault rate, or return a clear failure indication in\nthe rare case that they cannot converge. Furthermore, they store most of their\ndata unreliably, and spend most of their time in unreliable mode.\n  We demonstrate this for the specific case of detected but uncorrectable\nmemory faults, which we argue are representative of all kinds of faults. We\ndeveloped a cross-layer application / operating system framework that\nintercepts and reports uncorrectable memory faults to the application, rather\nthan killing the application, as current operating systems do. The application\nin turn can mark memory allocations as subject to such faults. Using this\nframework, we wrote a fault-tolerant iterative linear solver using components\nfrom the Trilinos solvers library. Our solver exploits hybrid parallelism (MPI\nand threads). It performs just as well as other solvers if no faults occur, and\nconverges where other solvers do not in the presence of faults. We show\nconvergence results for representative test problems. Near-term future work\nwill include performance tests."
},{
    "category": "cs.DS", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1206.3768v3", 
    "title": "Block Iterative Eigensolvers for Sequences of Correlated Eigenvalue   Problems", 
    "arxiv-id": "1206.3768v3", 
    "author": "Mario Berljafa", 
    "publish": "2012-06-17T17:03:24Z", 
    "summary": "In Density Functional Theory simulations based on the LAPW method, each\nself-consistent field cycle comprises dozens of large dense generalized\neigenproblems. In contrast to real-space methods, eigenpairs solving for\nproblems at distinct cycles have either been believed to be independent or at\nmost very loosely connected. In a recent study [7], it was demonstrated that,\ncontrary to belief, successive eigenproblems in a sequence are strongly\ncorrelated with one another. In particular, by monitoring the subspace angles\nbetween eigenvectors of successive eigenproblems, it was shown that these\nangles decrease noticeably after the first few iterations and become close to\ncollinear. This last result suggests that we can manipulate the eigenvectors,\nsolving for a specific eigenproblem in a sequence, as an approximate solution\nfor the following eigenproblem. In this work we present results that are in\nline with this intuition. We provide numerical examples where opportunely\nselected block iterative eigensolvers benefit from the reuse of eigenvectors by\nachieving a substantial speed-up. The results presented will eventually open\nthe way to a widespread use of block iterative eigensolvers in ab initio\nelectronic structure codes based on the LAPW approach."
},{
    "category": "cs.OH", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1206.6808v1", 
    "title": "A Multi-State Power Model for Adequacy Assessment of Distributed   Generation via Universal Generating Function", 
    "arxiv-id": "1206.6808v1", 
    "author": "Enrico Zio", 
    "publish": "2012-06-28T19:50:53Z", 
    "summary": "The current and future developments of electric power systems are pushing the\nboundaries of reliability assessment to consider distribution networks with\nrenewable generators. Given the stochastic features of these elements, most\nmodeling approaches rely on Monte Carlo simulation. The computational costs\nassociated to the simulation approach force to treating mostly small-sized\nsystems, i.e. with a limited number of lumped components of a given renewable\ntechnology (e.g. wind or solar, etc.) whose behavior is described by a binary\nstate, working or failed. In this paper, we propose an analytical multi-state\nmodeling approach for the reliability assessment of distributed generation\n(DG). The approach allows looking to a number of diverse energy generation\ntechnologies distributed on the system. Multiple states are used to describe\nthe randomness in the generation units, due to the stochastic nature of the\ngeneration sources and of the mechanical degradation/failure behavior of the\ngeneration systems. The universal generating function (UGF) technique is used\nfor the individual component multi-state modeling. A multiplication-type\ncomposition operator is introduced to combine the UGFs for the mechanical\ndegradation and renewable generation source states into the UGF of the\nrenewable generator power output. The overall multi-state DG system UGF is then\nconstructed and classical reliability indices (e.g. loss of load expectation\n(LOLE), expected energy not supplied (EENS)) are computed from the DG system\ngeneration and load UGFs. An application of the model is shown on a DG system\nadapted from the IEEE 34 nodes distribution test feeder."
},{
    "category": "stat.AP", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1208.0788v2", 
    "title": "An Upper Bound on the Convergence Time for Quantized Consensus", 
    "arxiv-id": "1208.0788v2", 
    "author": "Sanjeev R. Kulkarni", 
    "publish": "2012-08-03T16:16:13Z", 
    "summary": "We analyze a class of distributed quantized consen- sus algorithms for\narbitrary networks. In the initial setting, each node in the network has an\ninteger value. Nodes exchange their current estimate of the mean value in the\nnetwork, and then update their estimation by communicating with their neighbors\nin a limited capacity channel in an asynchronous clock setting. Eventually, all\nnodes reach consensus with quantized precision. We start the analysis with a\nspecial case of a distributed binary voting algorithm, then proceed to the\nexpected convergence time for the general quantized consensus algorithm\nproposed by Kashyap et al. We use the theory of electric networks, random\nwalks, and couplings of Markov chains to derive an O(N^3log N) upper bound for\nthe expected convergence time on an arbitrary graph of size N, improving on the\nstate of art bound of O(N^4logN) for binary consensus and O(N^5) for quantized\nconsensus algorithms. Our result is not dependent on graph topology.\nSimulations on special graphs such as star networks, line graphs, lollipop\ngraphs, and Erd\\\"os-R\\'enyi random graphs are performed to validate the\nanalysis. This work has applications to load balancing, coordination of\nautonomous agents, estimation and detection, decision-making networks,\npeer-to-peer systems, etc."
},{
    "category": "cs.LG", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1208.3943v1", 
    "title": "Performance Tuning Of J48 Algorithm For Prediction Of Soil Fertility", 
    "arxiv-id": "1208.3943v1", 
    "author": "Jay Gholap", 
    "publish": "2012-08-20T08:48:40Z", 
    "summary": "Data mining involves the systematic analysis of large data sets, and data\nmining in agricultural soil datasets is exciting and modern research area. The\nproductive capacity of a soil depends on soil fertility. Achieving and\nmaintaining appropriate levels of soil fertility, is of utmost importance if\nagricultural land is to remain capable of nourishing crop production. In this\nresearch, Steps for building a predictive model of soil fertility have been\nexplained.\n  This paper aims at predicting soil fertility class using decision tree\nalgorithms in data mining . Further, it focuses on performance tuning of J48\ndecision tree algorithm with the help of meta-techniques such as attribute\nselection and boosting."
},{
    "category": "cs.OS", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1208.6428v1", 
    "title": "A Hardware Time Manager Implementation for the Xenomai Real-Time Kernel   of Embedded Linux", 
    "arxiv-id": "1208.6428v1", 
    "author": "Jalil Boukhobza", 
    "publish": "2012-08-31T09:04:05Z", 
    "summary": "Nowadays, the use of embedded operating systems in different embedded\nprojects is subject to a tremendous growth. Embedded Linux is becoming one of\nthose most popular EOSs due to its modularity, efficiency, reliability, and\ncost. One way to make it hard real-time is to include a real-time kernel like\nXenomai. One of the key characteristics of a Real-Time Operating System (RTOS)\nis its ability to meet execution time deadlines deterministically. So, the more\nprecise and flexible the time management can be, the better it can handle\nefficiently the determinism for different embedded applications. RTOS time\nprecision is characterized by a specific periodic interrupt service controlled\nby a software time manager. The smaller the period of the interrupt, the better\nthe precision of the RTOS, the more it overloads the CPU, and though reduces\nthe overall efficiency of the RTOS. In this paper, we propose to drastically\nreduce these overheads by migrating the time management service of Xenomai into\na configurable hardware component to relieve the CPU. The hardware component is\nimplemented in a Field Programmable Gate Array coupled to the CPU. This work\nwas achieved in a Master degree project where students could apprehend many\nfields of embedded systems: RTOS programming, hardware design, performance\nevaluation, etc."
},{
    "category": "cs.NI", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1209.0676v1", 
    "title": "Channel Assignment in Dense MC-MR Wireless Networks: Scaling Laws and   Algorithms", 
    "arxiv-id": "1209.0676v1", 
    "author": "William N. Tetteh", 
    "publish": "2012-09-04T15:47:27Z", 
    "summary": "We investigate optimal channel assignment algorithms that maximize per node\nthroughput in dense multichannel multi-radio (MC-MR) wireless networks.\nSpecifically, we consider an MC-MR network where all nodes are within the\ntransmission range of each other. This situation is encountered in many\nreal-life settings such as students in a lecture hall, delegates attending a\nconference, or soldiers in a battlefield. In this scenario, we show that\nintelligent assignment of the available channels results in a significantly\nhigher per node throughput. We first propose a class of channel assignment\nalgorithms, parameterized by T (the number of transceivers per node), that can\nachieve $\\Theta(1/N^{1/T})$ per node throughput using $\\Theta(TN^{1-1/T})$\nchannels. In view of practical constraints on $T$, we then propose another\nalgorithm that can achieve $\\Theta(1/(\\log_2 N)^2)$ per node throughput using\nonly two transceivers per node. Finally, we identify a fundamental relationship\nbetween the achievable per node throughput, the total number of channels used,\nand the network size under any strategy. Using analysis and simulations, we\nshow that our algorithms achieve close to optimal performance at different\noperating points on this curve. Our work has several interesting implications\non the optimal network design for dense MC-MR wireless networks."
},{
    "category": "cs.MS", 
    "doi": "10.1016/j.cpc.2013.06.017", 
    "link": "http://arxiv.org/pdf/1209.2364v2", 
    "title": "Performance Modeling for Dense Linear Algebra", 
    "arxiv-id": "1209.2364v2", 
    "author": "Paolo Bientinesi", 
    "publish": "2012-09-11T16:37:20Z", 
    "summary": "It is well known that the behavior of dense linear algebra algorithms is\ngreatly influenced by factors like target architecture, underlying libraries\nand even problem size; because of this, the accurate prediction of their\nperformance is a real challenge. In this article, we are not interested in\ncreating accurate models for a given algorithm, but in correctly ranking a set\nof equivalent algorithms according to their performance. Aware of the\nhierarchical structure of dense linear algebra routines, we approach the\nproblem by developing a framework for the automatic generation of statistical\nperformance models for BLAS and LAPACK libraries. This allows us to obtain\npredictions through evaluating and combining such models. We demonstrate that\nour approach is successful in both single- and multi-core environments, not\nonly in the ranking of algorithms but also in tuning their parameters."
},{
    "category": "cs.DS", 
    "doi": "10.3390/a5040545", 
    "link": "http://arxiv.org/pdf/1209.4560v1", 
    "title": "Distributing an Exact Algorithm for Maximum Clique: maximising the   costup", 
    "arxiv-id": "1209.4560v1", 
    "author": "Patrick Prosser", 
    "publish": "2012-09-20T15:18:54Z", 
    "summary": "We take an existing implementation of an algorithm for the maximum clique\nproblem and modify it so that we can distribute it over an ad-hoc cluster of\nmachines. Our goal was to achieve a significant speedup in performance with\nminimal development effort, i.e. a maximum costup. We present a simple\nmodification to a state-of-the-art exact algorithm for maximum clique that\nallows us to distribute it across many machines. An empirical study over large\nhard benchmarks shows that speedups of an order of magnitude are routine for 25\nor more machines."
},{
    "category": "cs.IR", 
    "doi": "10.3390/a5040545", 
    "link": "http://arxiv.org/pdf/1209.6449v1", 
    "title": "Fast Packed String Matching for Short Patterns", 
    "arxiv-id": "1209.6449v1", 
    "author": "M. Oguzhan K\u00fclekci", 
    "publish": "2012-09-28T08:28:43Z", 
    "summary": "Searching for all occurrences of a pattern in a text is a fundamental problem\nin computer science with applications in many other fields, like natural\nlanguage processing, information retrieval and computational biology. In the\nlast two decades a general trend has appeared trying to exploit the power of\nthe word RAM model to speed-up the performances of classical string matching\nalgorithms. In this model an algorithm operates on words of length w, grouping\nblocks of characters, and arithmetic and logic operations on the words take one\nunit of time. In this paper we use specialized word-size packed string matching\ninstructions, based on the Intel streaming SIMD extensions (SSE) technology, to\ndesign very fast string matching algorithms in the case of short patterns. From\nour experimental results it turns out that, despite their quadratic worst case\ntime complexity, the new presented algorithms become the clear winners on the\naverage for short patterns, when compared against the most effective algorithms\nknown in literature."
},{
    "category": "cs.SI", 
    "doi": "10.3390/a5040545", 
    "link": "http://arxiv.org/pdf/1209.6615v3", 
    "title": "Scalable Analysis for Large Social Networks: the data-aware mean-field   approach", 
    "arxiv-id": "1209.6615v3", 
    "author": "Peter Groenewegen", 
    "publish": "2012-09-28T19:07:50Z", 
    "summary": "Studies on social networks have proved that endogenous and exogenous factors\ninfluence dynamics. Two streams of modeling exist on explaining the dynamics of\nsocial networks: 1) models predicting links through network properties, and 2)\nmodels considering the effects of social attributes. In this interdisciplinary\nstudy we work to overcome a number of computational limitations within these\ncurrent models. We employ a mean-field model which allows for the construction\nof a population-specific socially informed model for predicting links from both\nnetwork and social properties in large social networks. The model is tested on\na population of conference coauthorship behavior, considering a number of\nparameters from available Web data. We address how large social networks can be\nmodeled preserving both network and social parameters. We prove that the\nmean-field model, using a data-aware approach, allows us to overcome\ncomputational burdens and thus scalability issues in modeling large social\nnetworks in terms of both network and social parameters. Additionally, we\nconfirm that large social networks evolve through both network and\nsocial-selection decisions; asserting that the dynamics of networks cannot\nsingly be studied from a single perspective but must consider effects of social\nparameters."
},{
    "category": "cs.PF", 
    "doi": "10.3390/a5040545", 
    "link": "http://arxiv.org/pdf/1209.6630v2", 
    "title": "Quantum Monte Carlo for large chemical systems: Implementing efficient   strategies for petascale platforms and beyond", 
    "arxiv-id": "1209.6630v2", 
    "author": "William Jalby", 
    "publish": "2012-09-28T19:58:58Z", 
    "summary": "Various strategies to implement efficiently QMC simulations for large\nchemical systems are presented. These include: i.) the introduction of an\nefficient algorithm to calculate the computationally expensive Slater matrices.\nThis novel scheme is based on the use of the highly localized character of\natomic Gaussian basis functions (not the molecular orbitals as usually done),\nii.) the possibility of keeping the memory footprint minimal, iii.) the\nimportant enhancement of single-core performance when efficient optimization\ntools are employed, and iv.) the definition of a universal, dynamic,\nfault-tolerant, and load-balanced computational framework adapted to all kinds\nof computational platforms (massively parallel machines, clusters, or\ndistributed grids). These strategies have been implemented in the QMC=Chem code\ndeveloped at Toulouse and illustrated with numerical applications on small\npeptides of increasing sizes (158, 434, 1056 and 1731 electrons). Using 10k-80k\ncomputing cores of the Curie machine (GENCI-TGCC-CEA, France) QMC=Chem has been\nshown to be capable of running at the petascale level, thus demonstrating that\nfor this machine a large part of the peak performance can be achieved.\nImplementation of large-scale QMC simulations for future exascale platforms\nwith a comparable level of efficiency is expected to be feasible."
},{
    "category": "cs.NI", 
    "doi": "10.1109/WICOM.2007.737", 
    "link": "http://arxiv.org/pdf/1210.0510v1", 
    "title": "PCNM: A New Platform for Cellular Networks Measurements and Optimization", 
    "arxiv-id": "1210.0510v1", 
    "author": "Fr\u00e9d\u00e9ric Cespedes", 
    "publish": "2012-10-01T19:15:19Z", 
    "summary": "In this paper, we present PCNM, a new mobile platform for cellular networks\nmeasurements. PCNM is based on a set of techniques that tailors theoretical\ncalculations and simulations to the real cellular network environment. It\nincludes: (a) modules that measure different parameters of a base station (BS)\nsuch as localization, cells identification, time advance information, reception\nlevel and quality, (b) a new protocol that optimizes the task of network\nmeasurement by monitoring a set of mobile nodes and finally (c) the ability to\nextend an existing cellular network by adding new base stations. We evaluate\nour genetic algorithm used to reduce the nodes mobility and optimize the\nmeasurement extraction of N base stations using k mobile sensors (k >= 1). We\nshow how connecting real measurements (using mobile sensors in a collaborative\nway) to theoretical and prediction methods is of high benefits for cellular\nnetworks maintenance, extension and performances evaluation."
},{
    "category": "cs.IT", 
    "doi": "10.1109/JSAC.2013.130823", 
    "link": "http://arxiv.org/pdf/1210.1326v1", 
    "title": "Wireless Network Coding via Modified 802.11 MAC/PHY: Design and   Implementation on SDR", 
    "arxiv-id": "1210.1326v1", 
    "author": "Hui Liu", 
    "publish": "2012-10-04T08:16:31Z", 
    "summary": "Network coding (NC), in principle, is a Layer-3 innovation that improves\nnetwork throughput in wired networks for multicast/broadcast scenarios. Due to\nthe fundamental differences between wired and wireless networks, extending NC\nto wireless networks generates several new and significant practical\nchallenges. Two-way information exchange (both symmetric and asymmetric).\nNetwork coding (NC), in principle, is a Layer-3 innovation that improves\nnetwork throughput in wired networks for multicast/broadcast scenarios. Due to\nthe fundamental differences between wired and wireless networks, extending NC\nto wireless networks generates several new and significant practical\nchallenges. Two-way information exchange (both symmetric and asymmetric)\nbetween a pair of 802.11 sources/sinks using an intermediate relay node is a\ncanonical scenario for evaluating the effectiveness of Wireless Network Coding\n(WNC) in a practical setting. Our primary objective in this work is to suggest\npragmatic and novel modifications at the MAC and PHY layers of the 802.11\nprotocol stack on a Software Radio (SORA) platform to support WNC and obtain\nachievable throughput estimates via lab-scale experiments. Our results show\nthat network coding (at the MAC or PHY layer) increases system\nthroughput-typically by 20-30%%."
},{
    "category": "cs.IT", 
    "doi": "10.1109/JSAC.2013.130823", 
    "link": "http://arxiv.org/pdf/1210.3835v1", 
    "title": "Exploiting Network Cooperation in Green Wireless Communication", 
    "arxiv-id": "1210.3835v1", 
    "author": "Rui Zhang", 
    "publish": "2012-10-14T20:27:11Z", 
    "summary": "There is a growing interest in energy efficient or so-called \"green\" wireless\ncommunication to reduce the energy consumption in cellular networks. Since\ntoday's wireless terminals are typically equipped with multiple network access\ninterfaces such as Bluetooth, Wi-Fi, and cellular networks, this paper\ninvestigates user terminals cooperating with each other in transmitting their\ndata packets to the base station (BS), by exploiting the multiple network\naccess interfaces, called inter-network cooperation. We also examine the\nconventional schemes without user cooperation and with intra-network\ncooperation for comparison. Given target outage probability and data rate\nrequirements, we analyze the energy consumption of conventional schemes as\ncompared to the proposed inter-network cooperation by taking into account both\nphysical-layer channel impairments (including path loss, fading, and thermal\nnoise) and upper-layer protocol overheads. It is shown that distances between\ndifferent network entities (i.e., user terminals and BS) have a significant\ninfluence on the energy efficiency of proposed inter-network cooperation\nscheme. Specifically, when the cooperating users are close to BS or the users\nare far away from each other, the inter-network cooperation may consume more\nenergy than conventional schemes without user cooperation or with intra-network\ncooperation. However, as the cooperating users move away from BS and the\ninter-user distance is not too large, the inter-network cooperation\nsignificantly reduces the energy consumption over conventional schemes."
},{
    "category": "cs.PF", 
    "doi": "10.1109/GLOCOM.2012.6503326", 
    "link": "http://arxiv.org/pdf/1210.8176v1", 
    "title": "Eigenvalue-based Cyclostationary Spectrum Sensing Using Multiple   Antennas", 
    "arxiv-id": "1210.8176v1", 
    "author": "Danijela Cabric", 
    "publish": "2012-10-30T21:23:57Z", 
    "summary": "In this paper, we propose a signal-selective spectrum sensing method for\ncognitive radio networks and specifically targeted for receivers with\nmultiple-antenna capability. This method is used for detecting the presence or\nabsence of primary users based on the eigenvalues of the cyclic covariance\nmatrix of received signals. In particular, the cyclic correlation significance\ntest is used to detect a specific signal-of-interest by exploiting knowledge of\nits cyclic frequencies. The analytical threshold for achieving constant false\nalarm rate using this detection method is presented, verified through\nsimulations, and shown to be independent of both the number of samples used and\nthe noise variance, effectively eliminating the dependence on accurate noise\nestimation. The proposed method is also shown, through numerical simulations,\nto outperform existing multiple-antenna cyclostationary-based spectrum sensing\nalgorithms under a quasi-static Rayleigh fading channel, in both spatially\ncorrelated and uncorrelated noise environments. The algorithm also has\nsignificantly lower computational complexity than these other approaches."
},{
    "category": "cs.PF", 
    "doi": "10.1109/WCL.2013.012513.120824", 
    "link": "http://arxiv.org/pdf/1210.8191v2", 
    "title": "Performance Indicator for MIMO MMSE Receivers in the Presence of Channel   Estimation Error", 
    "arxiv-id": "1210.8191v2", 
    "author": "Chung-Yu Lou", 
    "publish": "2012-10-30T22:45:46Z", 
    "summary": "We present the derivation of post-processing SNR for\nMinimum-Mean-Squared-Error (MMSE) receivers with imperfect channel estimates,\nand show that it is an accurate indicator of the error rate performance of MIMO\nsystems in the presence of channel estimation error. Simulation results show\nthe tightness of the analysis."
},{
    "category": "math.PR", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1211.0618v3", 
    "title": "Queuing with future information", 
    "arxiv-id": "1211.0618v3", 
    "author": "Kuang Xu", 
    "publish": "2012-11-03T15:44:07Z", 
    "summary": "We study an admissions control problem, where a queue with service rate $1-p$\nreceives incoming jobs at rate $\\lambda\\in(1-p,1)$, and the decision maker is\nallowed to redirect away jobs up to a rate of $p$, with the objective of\nminimizing the time-average queue length. We show that the amount of\ninformation about the future has a significant impact on system performance, in\nthe heavy-traffic regime. When the future is unknown, the optimal average queue\nlength diverges at rate $\\sim\\log_{1/(1-p)}\\frac{1}{1-\\lambda}$, as $\\lambda\\to\n1$. In sharp contrast, when all future arrival and service times are revealed\nbeforehand, the optimal average queue length converges to a finite constant,\n$(1-p)/p$, as $\\lambda\\to1$. We further show that the finite limit of $(1-p)/p$\ncan be achieved using only a finite lookahead window starting from the current\ntime frame, whose length scales as $\\mathcal{O}(\\log\\frac{1}{1-\\lambda})$, as\n$\\lambda\\to1$. This leads to the conjecture of an interesting duality between\nqueuing delay and the amount of information about the future."
},{
    "category": "cs.AI", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1211.0906v2", 
    "title": "Algorithm Runtime Prediction: Methods & Evaluation", 
    "arxiv-id": "1211.0906v2", 
    "author": "Kevin Leyton-Brown", 
    "publish": "2012-11-05T16:15:16Z", 
    "summary": "Perhaps surprisingly, it is possible to predict how long an algorithm will\ntake to run on a previously unseen input, using machine learning techniques to\nbuild a model of the algorithm's runtime as a function of problem-specific\ninstance features. Such models have important applications to algorithm\nanalysis, portfolio-based algorithm selection, and the automatic configuration\nof parameterized algorithms. Over the past decade, a wide variety of techniques\nhave been studied for building such models. Here, we describe extensions and\nimprovements of existing models, new families of models, and -- perhaps most\nimportantly -- a much more thorough treatment of algorithm parameters as model\ninputs. We also comprehensively describe new and existing features for\npredicting algorithm runtime for propositional satisfiability (SAT), travelling\nsalesperson (TSP) and mixed integer programming (MIP) problems. We evaluate\nthese innovations through the largest empirical analysis of its kind, comparing\nto a wide range of runtime modelling techniques from the literature. Our\nexperiments consider 11 algorithms and 35 instance distributions; they also\nspan a very wide range of SAT, MIP, and TSP instances, with the least\nstructured having been generated uniformly at random and the most structured\nhaving emerged from real industrial applications. Overall, we demonstrate that\nour new models yield substantially better runtime predictions than previous\napproaches in terms of their generalization to new problem instances, to new\nalgorithms from a parameterized space, and to both simultaneously."
},{
    "category": "cs.SY", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1211.1643v2", 
    "title": "Hybrid Behaviour of Markov Population Models", 
    "arxiv-id": "1211.1643v2", 
    "author": "Luca Bortolussi", 
    "publish": "2012-11-07T19:30:47Z", 
    "summary": "We investigate the behaviour of population models written in Stochastic\nConcurrent Constraint Programming (sCCP), a stochastic extension of Concurrent\nConstraint Programming. In particular, we focus on models from which we can\ndefine a semantics of sCCP both in terms of Continuous Time Markov Chains\n(CTMC) and in terms of Stochastic Hybrid Systems, in which some populations are\napproximated continuously, while others are kept discrete. We will prove the\ncorrectness of the hybrid semantics from the point of view of the limiting\nbehaviour of a sequence of models for increasing population size. More\nspecifically, we prove that, under suitable regularity conditions, the sequence\nof CTMC constructed from sCCP programs for increasing population size converges\nto the hybrid system constructed by means of the hybrid semantics. We\ninvestigate in particular what happens for sCCP models in which some\ntransitions are guarded by boolean predicates or in the presence of\ninstantaneous transitions."
},{
    "category": "cs.DC", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1211.2292v1", 
    "title": "Hybrid MPI-OpenMP Paradigm on SMP Clusters: MPEG-2 Encoder and N-Body   Simulation", 
    "arxiv-id": "1211.2292v1", 
    "author": "Shigeru Oyanagi", 
    "publish": "2012-11-10T05:51:06Z", 
    "summary": "Clusters of SMP nodes provide support for a wide diversity of parallel\nprogramming paradigms. Combining both shared memory and message passing\nparallelizations within the same application, the hybrid MPI-OpenMP paradigm is\nan emerging trend for parallel programming to fully exploit distributed\nshared-memory architecture. In this paper, we improve the performance of MPEG-2\nencoder and n-body simulation by employing the hybrid MPI-OpenMP programming\nparadigm on SMP clusters. The hierarchical image data structure of the MPEG\nbit-stream is eminently suitable for the hybrid model to achieve multiple\nlevels of parallelism: MPI for parallelism at the group of pictures level\nacross SMP nodes and OpenMP for parallelism within pictures at the slice level\nwithin each SMP node. Similarly, the work load of the force calculation which\naccounts for upwards of 90% of the cycles in typical computations in the n-body\nsimulation is shared among OpenMP threads after ORB domain decomposition among\nMPI processes. Besides, loop scheduling of OpenMP threads is adopted with\nappropriate chunk size to provide better load balance of work, leading to\nenhanced performance. With the n-body simulation, experimental results\ndemonstrate that the hybrid MPI-OpenMP program outperforms the corresponding\npure MPI program by average factors of 1.52 on a 4-way cluster and 1.21 on a\n2-way cluster. Likewise, the hybrid model offers a performance improvement of\n18% compared to the MPI model for the MPEG-2 encoder."
},{
    "category": "cs.DC", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1211.2293v1", 
    "title": "Performance Evaluation of Treecode Algorithm for N-Body Simulation Using   GridRPC System", 
    "arxiv-id": "1211.2293v1", 
    "author": "Shigeru Oyanagi", 
    "publish": "2012-11-10T06:08:36Z", 
    "summary": "This paper is aimed at improving the performance of the treecode algorithm\nfor N-Body simulation by employing the NetSolve GridRPC programming model to\nexploit the use of multiple clusters. N-Body is a classical problem, and\nappears in many areas of science and engineering, including astrophysics,\nmolecular dynamics, and graphics. In the simulation of N-Body, the specific\nroutine for calculating the forces on the bodies which accounts for upwards of\n90% of the cycles in typical computations is eminently suitable for obtaining\nparallelism with GridRPC calls. It is divided among the compute nodes by\nsimultaneously calling multiple GridRPC requests to them. The performance of\nthe GridRPC implementation is then compared to that of the MPI version and\nhybrid MPI-OpenMP version for the treecode algorithm on individual clusters."
},{
    "category": "cs.DS", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1212.0703v2", 
    "title": "The Cost of Address Translation", 
    "arxiv-id": "1212.0703v2", 
    "author": "Kurt Mehlhorn", 
    "publish": "2012-12-04T12:55:21Z", 
    "summary": "Modern computers are not random access machines (RAMs). They have a memory\nhierarchy, multiple cores, and virtual memory. In this paper, we address the\ncomputational cost of address translation in virtual memory. Starting point for\nour work is the observation that the analysis of some simple algorithms (random\nscan of an array, binary search, heapsort) in either the RAM model or the EM\nmodel (external memory model) does not correctly predict growth rates of actual\nrunning times. We propose the VAT model (virtual address translation) to\naccount for the cost of address translations and analyze the algorithms\nmentioned above and others in the model. The predictions agree with the\nmeasurements. We also analyze the VAT-cost of cache-oblivious algorithms."
},{
    "category": "cs.NI", 
    "doi": "10.1214/13-AAP973", 
    "link": "http://arxiv.org/pdf/1212.1638v4", 
    "title": "Achieving Optimal Throughput and Near-Optimal Asymptotic Delay   Performance in Multi-Channel Wireless Networks with Low Complexity: A   Practical Greedy Scheduling Policy", 
    "arxiv-id": "1212.1638v4", 
    "author": "Ness B. Shroff", 
    "publish": "2012-12-07T16:05:42Z", 
    "summary": "In this paper, we focus on the scheduling problem in multi-channel wireless\nnetworks, e.g., the downlink of a single cell in fourth generation (4G)\nOFDM-based cellular networks. Our goal is to design practical scheduling\npolicies that can achieve provably good performance in terms of both throughput\nand delay, at a low complexity. While a class of $O(n^{2.5} \\log n)$-complexity\nhybrid scheduling policies are recently developed to guarantee both\nrate-function delay optimality (in the many-channel many-user asymptotic\nregime) and throughput optimality (in the general non-asymptotic setting),\ntheir practical complexity is typically high. To address this issue, we develop\na simple greedy policy called Delay-based Server-Side-Greedy (D-SSG) with a\n\\lower complexity $2n^2+2n$, and rigorously prove that D-SSG not only achieves\nthroughput optimality, but also guarantees near-optimal asymptotic delay\nperformance. Specifically, we show that the rate-function attained by D-SSG for\nany delay-violation threshold $b$, is no smaller than the maximum achievable\nrate-function by any scheduling policy for threshold $b-1$. Thus, we are able\nto achieve a reduction in complexity (from $O(n^{2.5} \\log n)$ of the hybrid\npolicies to $2n^2 + 2n$) with a minimal drop in the delay performance. More\nimportantly, in practice, D-SSG generally has a substantially lower complexity\nthan the hybrid policies that typically have a large constant factor hidden in\nthe $O(\\cdot)$ notation. Finally, we conduct numerical simulations to validate\nour theoretical results in various scenarios. The simulation results show that\nD-SSG not only guarantees a near-optimal rate-function, but also empirically is\nvirtually indistinguishable from delay-optimal policies."
},{
    "category": "cs.IT", 
    "doi": "10.1109/LSP.2013.2251880", 
    "link": "http://arxiv.org/pdf/1212.5374v1", 
    "title": "A Blind Time-Reversal Detector in the Presence of Channel Correlation", 
    "arxiv-id": "1212.5374v1", 
    "author": "Olav Tirkkonen", 
    "publish": "2012-12-21T09:52:43Z", 
    "summary": "A blind target detector using the time reversal transmission is proposed in\nthe presence of channel correlation. We calculate the exact moments of the test\nstatistics involved. The derived moments are used to construct an accurate\napproximative Likelihood Ratio Test (LRT) based on multivariate Edgeworth\nexpansion. Performance gain over an existing detector is observed in scenarios\nwith channel correlation and relatively strong target signal."
},{
    "category": "cs.DB", 
    "doi": "10.1109/LSP.2013.2251880", 
    "link": "http://arxiv.org/pdf/1212.6640v1", 
    "title": "Exploring mutexes, the Oracle RDBMS retrial spinlocks", 
    "arxiv-id": "1212.6640v1", 
    "author": "Andrey Nikolaev", 
    "publish": "2012-12-29T15:29:26Z", 
    "summary": "Spinlocks are widely used in database engines for processes synchronization.\nKGX mutexes is new retrial spinlocks appeared in contemporary Oracle versions\nfor submicrosecond synchronization. The mutex contention is frequently observed\nin highly concurrent OLTP environments.\n  This work explores how Oracle mutexes operate, spin, and sleep. It develops\npredictive mathematical model and discusses parameters and statistics related\nto mutex performance tuning, as well as results of contention experiments."
},{
    "category": "cs.IT", 
    "doi": "10.1109/LSP.2013.2251880", 
    "link": "http://arxiv.org/pdf/1302.4225v1", 
    "title": "Impact of Pointing Errors on the Performance of Mixed RF/FSO Dual-Hop   Transmission Systems", 
    "arxiv-id": "1302.4225v1", 
    "author": "Mohamed-Slim Alouini", 
    "publish": "2013-02-18T11:11:38Z", 
    "summary": "In this work, the performance analysis of a dual-hop relay transmission\nsystem composed of asymmetric radio-frequency (RF)/free-space optical (FSO)\nlinks with pointing errors is presented. More specifically, we build on the\nsystem model presented in [1] to derive new exact closed-form expressions for\nthe cumulative distribution function, probability density function, moment\ngenerating function, and moments of the end-to-end signal-to-noise ratio in\nterms of the Meijer's G function. We then capitalize on these results to offer\nnew exact closed-form expressions for the higher-order amount of fading,\naverage error rate for binary and M-ary modulation schemes, and the ergodic\ncapacity, all in terms of Meijer's G functions. Our new analytical results were\nalso verified via computer-based Monte-Carlo simulation results."
},{
    "category": "stat.ML", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1302.4773v1", 
    "title": "Optimal Discriminant Functions Based On Sampled Distribution Distance   for Modulation Classification", 
    "arxiv-id": "1302.4773v1", 
    "author": "Danijela Cabric", 
    "publish": "2013-02-19T22:59:44Z", 
    "summary": "In this letter, we derive the optimal discriminant functions for modulation\nclassification based on the sampled distribution distance. The proposed method\nclassifies various candidate constellations using a low complexity approach\nbased on the distribution distance at specific testpoints along the cumulative\ndistribution function. This method, based on the Bayesian decision criteria,\nasymptotically provides the minimum classification error possible given a set\nof testpoints. Testpoint locations are also optimized to improve classification\nperformance. The method provides significant gains over existing approaches\nthat also use the distribution of the signal features."
},{
    "category": "cs.DC", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1303.3632v1", 
    "title": "Statistical Regression to Predict Total Cumulative CPU Usage of   MapReduce Jobs", 
    "arxiv-id": "1303.3632v1", 
    "author": "Albert Y. Zomaya", 
    "publish": "2013-03-14T22:40:32Z", 
    "summary": "Recently, businesses have started using MapReduce as a popular computation\nframework for processing large amount of data, such as spam detection, and\ndifferent data mining tasks, in both public and private clouds. Two of the\nchallenging questions in such environments are (1) choosing suitable values for\nMapReduce configuration parameters e.g., number of mappers, number of reducers,\nand DFS block size, and (2) predicting the amount of resources that a user\nshould lease from the service provider. Currently, the tasks of both choosing\nconfiguration parameters and estimating required resources are solely the users\nresponsibilities. In this paper, we present an approach to provision the total\nCPU usage in clock cycles of jobs in MapReduce environment. For a MapReduce\njob, a profile of total CPU usage in clock cycles is built from the job past\nexecutions with different values of two configuration parameters e.g., number\nof mappers, and number of reducers. Then, a polynomial regression is used to\nmodel the relation between these configuration parameters and total CPU usage\nin clock cycles of the job. We also briefly study the influence of input data\nscaling on measured total CPU usage in clock cycles. This derived model along\nwith the scaling result can then be used to provision the total CPU usage in\nclock cycles of the same jobs with different input data size. We validate the\naccuracy of our models using three realistic applications (WordCount, Exim\nMainLog parsing, and TeraSort). Results show that the predicted total CPU usage\nin clock cycles of generated resource provisioning options are less than 8% of\nthe measured total CPU usage in clock cycles in our 20-node virtual Hadoop\ncluster."
},{
    "category": "cs.DC", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1308.2058v1", 
    "title": "RBioCloud: A Light-weight Framework for Bioconductor and R-based Jobs on   the Cloud", 
    "arxiv-id": "1308.2058v1", 
    "author": "Adam Barker", 
    "publish": "2013-08-09T09:20:02Z", 
    "summary": "Large-scale ad hoc analytics of genomic data is popular using the\nR-programming language supported by 671 software packages provided by\nBioconductor. More recently, analytical jobs are benefitting from on-demand\ncomputing and storage, their scalability and their low maintenance cost, all of\nwhich are offered by the cloud. While Biologists and Bioinformaticists can take\nan analytical job and execute it on their personal workstations, it remains\nchallenging to seamlessly execute the job on the cloud infrastructure without\nextensive knowledge of the cloud dashboard. How analytical jobs can not only\nwith minimum effort be executed on the cloud, but also how both the resources\nand data required by the job can be managed is explored in this paper. An\nopen-source light-weight framework for executing R-scripts using Bioconductor\npackages, referred to as `RBioCloud', is designed and developed. RBioCloud\noffers a set of simple command-line tools for managing the cloud resources, the\ndata and the execution of the job. Three biological test cases validate the\nfeasibility of RBioCloud. The framework is publicly available from\nhttp://www.rbiocloud.com."
},{
    "category": "cs.DC", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1308.2066v1", 
    "title": "Parallel Simulations for Analysing Portfolios of Catastrophic Event Risk", 
    "arxiv-id": "1308.2066v1", 
    "author": "Blesson Varghese", 
    "publish": "2013-08-09T09:43:51Z", 
    "summary": "At the heart of the analytical pipeline of a modern quantitative\ninsurance/reinsurance company is a stochastic simulation technique for\nportfolio risk analysis and pricing process referred to as Aggregate Analysis.\nSupport for the computation of risk measures including Probable Maximum Loss\n(PML) and the Tail Value at Risk (TVAR) for a variety of types of complex\nproperty catastrophe insurance contracts including Cat eXcess of Loss (XL), or\nPer-Occurrence XL, and Aggregate XL, and contracts that combine these measures\nis obtained in Aggregate Analysis.\n  In this paper, we explore parallel methods for aggregate risk analysis. A\nparallel aggregate risk analysis algorithm and an engine based on the algorithm\nis proposed. This engine is implemented in C and OpenMP for multi-core CPUs and\nin C and CUDA for many-core GPUs. Performance analysis of the algorithm\nindicates that GPUs offer an alternative HPC solution for aggregate risk\nanalysis that is cost effective. The optimised algorithm on the GPU performs a\n1 million trial aggregate simulation with 1000 catastrophic events per trial on\na typical exposure set and contract structure in just over 20 seconds which is\napproximately 15x times faster than the sequential counterpart. This can\nsufficiently support the real-time pricing scenario in which an underwriter\nanalyses different contractual terms and pricing while discussing a deal with a\nclient over the phone."
},{
    "category": "math.PR", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1308.4227v1", 
    "title": "A Computational Framework for the Mixing Times in the QBD Processes with   Infinitely-Many Levels", 
    "arxiv-id": "1308.4227v1", 
    "author": "Jing Cao", 
    "publish": "2013-08-20T04:36:39Z", 
    "summary": "In this paper, we develop some matrix Poisson's equations satisfied by the\nmean and variance of the mixing time in an irreducible positive-recurrent\ndiscrete-time Markov chain with infinitely-many levels, and provide a\ncomputational framework for the solution to the matrix Poisson's equations by\nmeans of the UL-type of $RG$-factorization as well as the generalized inverses.\nIn an important special case: the level-dependent QBD processes, we provide a\ndetailed computation for the mean and variance of the mixing time. Based on\nthis, we give new highlight on computation of the mixing time in the\nblock-structured Markov chains with infinitely-many levels through the\nmatrix-analytic method."
},{
    "category": "cs.PF", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1309.0052v2", 
    "title": "Accelerating a Cloud-Based Software GNSS Receiver", 
    "arxiv-id": "1309.0052v2", 
    "author": "M. Haris Afzal", 
    "publish": "2013-08-31T01:18:14Z", 
    "summary": "In this paper we discuss ways to reduce the execution time of a software\nGlobal Navigation Satellite System (GNSS) receiver that is meant for offline\noperation in a cloud environment. Client devices record satellite signals they\nreceive, and send them to the cloud, to be processed by this software. The goal\nof this project is for each client request to be processed as fast as possible,\nbut also to increase total system throughput by making sure as many requests as\npossible are processed within a unit of time. The characteristics of our\napplication provided both opportunities and challenges for increasing\nperformance. We describe the speedups we obtained by enabling the software to\nexploit multi-core CPUs and GPGPUs. We mention which techniques worked for us\nand which did not. To increase throughput, we describe how we control the\nresources allocated to each invocation of the software to process a client\nrequest, such that multiple copies of the application can run at the same time.\nWe use the notion of effective running time to measure the system's throughput\nwhen running multiple instances at the same time, and show how we can determine\nwhen the system's computing resources have been saturated."
},{
    "category": "cs.CE", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1309.0551v1", 
    "title": "Optimizing the performance of Lattice Gauge Theory simulations with   Streaming SIMD extensions", 
    "arxiv-id": "1309.0551v1", 
    "author": "Shyam Srinivasan", 
    "publish": "2013-09-02T21:52:49Z", 
    "summary": "Two factors, which affect simulation quality are the amount of computing\npower and implementation. The Streaming SIMD (single instruction multiple data)\nextensions (SSE) present a technique for influencing both by exploiting the\nprocessor's parallel functionalism. In this paper, we show how SSE improves\nperformance of lattice gauge theory simulations. We identified two significant\ntrends through an analysis of data from various runs. The speed-ups were higher\nfor single precision than double precision floating point numbers. Notably,\nthough the use of SSE significantly improved simulation time, it did not\ndeliver the theoretical maximum. There are a number of reasons for this:\narchitectural constraints imposed by the FSB speed, the spatial and temporal\npatterns of data retrieval, ratio of computational to non-computational\ninstructions, and the need to interleave miscellaneous instructions with\ncomputational instructions. We present a model for analyzing the SSE\nperformance, which could help factor in the bottlenecks or weaknesses in the\nimplementation, the computing architecture, and the mapping of software to the\ncomputing substrate while evaluating the improvement in efficiency. The model\nor framework would be useful in evaluating the use of other computational\nframeworks, and in predicting the benefits that can be derived from future\nhardware or architectural improvements."
},{
    "category": "math.OC", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1309.1110v1", 
    "title": "When Backpressure Meets Predictive Scheduling", 
    "arxiv-id": "1309.1110v1", 
    "author": "Xin Liu", 
    "publish": "2013-09-04T17:17:49Z", 
    "summary": "Motivated by the increasing popularity of learning and predicting human user\nbehavior in communication and computing systems, in this paper, we investigate\nthe fundamental benefit of predictive scheduling, i.e., predicting and\npre-serving arrivals, in controlled queueing systems. Based on a lookahead\nwindow prediction model, we first establish a novel equivalence between the\npredictive queueing system with a \\emph{fully-efficient} scheduling scheme and\nan equivalent queueing system without prediction. This connection allows us to\nanalytically demonstrate that predictive scheduling necessarily improves system\ndelay performance and can drive it to zero with increasing prediction power. We\nthen propose the \\textsf{Predictive Backpressure (PBP)} algorithm for achieving\noptimal utility performance in such predictive systems. \\textsf{PBP}\nefficiently incorporates prediction into stochastic system control and avoids\nthe great complication due to the exponential state space growth in the\nprediction window size. We show that \\textsf{PBP} can achieve a utility\nperformance that is within $O(\\epsilon)$ of the optimal, for any $\\epsilon>0$,\nwhile guaranteeing that the system delay distribution is a\n\\emph{shifted-to-the-left} version of that under the original Backpressure\nalgorithm. Hence, the average packet delay under \\textsf{PBP} is strictly\nbetter than that under Backpressure, and vanishes with increasing prediction\nwindow size. This implies that the resulting utility-delay tradeoff with\npredictive scheduling beats the known optimal $[O(\\epsilon),\nO(\\log(1/\\epsilon))]$ tradeoff for systems without prediction."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1309.5686v1", 
    "title": "On the tradeoff of average delay and average power for fading   point-to-point links with monotone policies", 
    "arxiv-id": "1309.5686v1", 
    "author": "Utpal Mukherji", 
    "publish": "2013-09-23T02:48:00Z", 
    "summary": "We consider a fading point-to-point link with packets arriving randomly at\nrate $\\lambda$ per slot to the transmitter queue. We assume that the\ntransmitter can control the number of packets served in a slot by varying the\ntransmit power for the slot. We restrict to transmitter scheduling policies\nthat are monotone and stationary, i.e., the number of packets served is a\nnon-decreasing function of the queue length at the beginning of the slot for\nevery slot fade state. For such policies, we obtain asymptotic lower bounds for\nthe minimum average delay of the packets, when average transmitter power is a\nsmall positive quantity $V$ more than the minimum average power required for\ntransmitter queue stability. We show that the minimum average delay grows\neither to a finite value or as $\\Omega\\brap{\\log(1/V)}$ or $\\Omega\\brap{1/V}$\nwhen $V \\downarrow 0$, for certain sets of values of $\\lambda$. These sets are\ndetermined by the distribution of fading gain, the maximum number of packets\nwhich can be transmitted in a slot, and the transmit power function of the\nfading gain and the number of packets transmitted that is assumed. We identify\na case where the above behaviour of the tradeoff differs from that obtained\nfrom a previously considered approximate model, in which the random queue\nlength process is assumed to evolve on the non-negative real line, and the\ntransmit power function is strictly convex. We also consider a fading\npoint-to-point link, where the transmitter, in addition to controlling the\nnumber of packets served, can also control the number of packets admitted in\nevery slot. Our approach, which uses bounds on the stationary probability\ndistribution of the queue length, also leads to an intuitive explanation of the\nasymptotic behaviour of average delay in the regime where $V \\downarrow 0$."
},{
    "category": "cs.IT", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1309.5802v2", 
    "title": "Lower Bound on the BER of a Decode-and-Forward Relay Network Under Chaos   Shift Keying Communication System", 
    "arxiv-id": "1309.5802v2", 
    "author": "Francois Gagnon", 
    "publish": "2013-09-18T15:49:48Z", 
    "summary": "This paper carries out the first-ever investigation of the analysis of a\ncooperative Decode-and-Forward (DF) relay network with Chaos Shift Keying (CSK)\nmodulation. The performance analysis of DF-CSK in this paper takes into account\nthe dynamical nature of chaotic signal, which is not similar to a conventional\nbinary modulation performance computation methodology. The expression of a\nlower bound bit error rate (BER) is derived in order to investigate the\nperformance of the cooperative system under independently and identically\ndistributed (i.i.d.) Gaussian fading wireless environments. The effect of the\nnon-periodic nature of chaotic sequence leading to a non constant bit energy of\nthe considered modulation is also investigated. A computation approach of the\nBER expression based on the probability density function of the bit energy of\nthe chaotic sequence, channel distribution, and number of relays is presented.\nSimulation results prove the accuracy of our BER computation methodology."
},{
    "category": "cs.PF", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1311.0486v1", 
    "title": "On the optimal tradeoff of average service cost rate, average utility   rate, and average delay for the state dependent M/M/1 queue", 
    "arxiv-id": "1311.0486v1", 
    "author": "Utpal Mukherji", 
    "publish": "2013-11-03T16:07:43Z", 
    "summary": "The optimal tradeoff between average service cost rate, average utility rate,\nand average delay is addressed for a state dependent M/M/1 queueing model, with\ncontrollable queue length dependent service rates and arrival rates. For a\nmodel with a constant arrival rate $\\lambda$ for all queue lengths, we obtain\nan asymptotic characterization of the minimum average delay, when the average\nservice cost rate is a small positive quantity, $V$, more than the minimum\naverage service cost rate required for queue stability. We show that depending\non the value of the arrival rate $\\lambda$, the assumed service cost rate\nfunction, and the possible values of the service rates, the minimum average\ndelay either: a) increases only to a finite value, b) increases without bound\nas $\\log\\frac{1}{V}$, c) increases without bound as $\\frac{1}{V}$, or d)\nincreases without bound as $\\frac{1}{\\sqrt{V}}$, when $V \\downarrow 0$. We then\nextend our analysis to (i) a complementary problem, where the tradeoff of\naverage utility rate and average delay is analysed for a M/M/1 queueing model,\nwith controllable queue length dependent arrival rates, but a constant service\nrate $\\mu$ for all queue lengths, and (ii) a M/M/1 queueing model, with\ncontrollable queue length dependent service rates and arrival rates, for which\nwe obtain an asymptotic characterization of the minimum average delay under\nconstraints on both the average service cost rate as well as the average\nutility rate. The results that we obtain are useful in obtaining intuition as\nwell guidance for the derivation of similar asymptotic lower bounds, such as\nthe Berry-Gallager asymptotic lower bound, for discrete time queueing models."
},{
    "category": "cs.NI", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1311.2851v1", 
    "title": "When Do Redundant Requests Reduce Latency ?", 
    "arxiv-id": "1311.2851v1", 
    "author": "Kannan Ramchandran", 
    "publish": "2013-11-07T02:43:11Z", 
    "summary": "Several systems possess the flexibility to serve requests in more than one\nway. For instance, a distributed storage system storing multiple replicas of\nthe data can serve a request from any of the multiple servers that store the\nrequested data, or a computational task may be performed in a compute-cluster\nby any one of multiple processors. In such systems, the latency of serving the\nrequests may potentially be reduced by sending \"redundant requests\": a request\nmay be sent to more servers than needed, and it is deemed served when the\nrequisite number of servers complete service. Such a mechanism trades off the\npossibility of faster execution of at least one copy of the request with the\nincrease in the delay due to an increased load on the system. Due to this\ntradeoff, it is unclear when redundant requests may actually help. Several\nrecent works empirically evaluate the latency performance of redundant requests\nin diverse settings.\n  This work aims at an analytical study of the latency performance of redundant\nrequests, with the primary goals of characterizing under what scenarios sending\nredundant requests will help (and under what scenarios they will not help), as\nwell as designing optimal redundant-requesting policies. We first present a\nmodel that captures the key features of such systems. We show that when service\ntimes are i.i.d. memoryless or \"heavier\", and when the additional copies of\nalready-completed jobs can be removed instantly, redundant requests reduce the\naverage latency. On the other hand, when service times are \"lighter\" or when\nservice times are memoryless and removal of jobs is not instantaneous, then not\nhaving any redundancy in the requests is optimal under high loads. Our results\nhold for arbitrary arrival processes."
},{
    "category": "cs.OS", 
    "doi": "10.1109/LCOMM.2013.082113.131131", 
    "link": "http://arxiv.org/pdf/1311.3686v1", 
    "title": "Performance Evaluation of Java File Security System (JFSS)", 
    "arxiv-id": "1311.3686v1", 
    "author": "Dr. R. K. Tuteja", 
    "publish": "2013-11-13T10:53:02Z", 
    "summary": "Security is a critical issue of the modern file and storage systems, it is\nimperative to protect the stored data from unauthorized access. We have\ndeveloped a file security system named as Java File Security System (JFSS) [1]\nthat guarantee the security to files on the demand of all users. It has been\ndeveloped on Java platform. Java has been used as programming language in order\nto provide portability, but it enforces some performance limitations. It is\ndeveloped in FUSE (File System in User space) [3]. Many efforts have been done\nover the years for developing file systems in user space (FUSE). All have their\nown merits and demerits. In this paper we have evaluated the performance of\nJava File Security System (JFSS). Over and over again, the increased security\ncomes at the expense of user convenience, performance or compatibility with\nother systems. JFSS system performance evaluations show that encryption\noverheads are modest as compared to security."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1311.3928v1", 
    "title": "HS06 Benchmark for an ARM Server", 
    "arxiv-id": "1311.3928v1", 
    "author": "Stefan Kluth", 
    "publish": "2013-11-15T17:17:21Z", 
    "summary": "We benchmarked an ARM cortex-A9 based server system with a four-core CPU\nrunning at 1.1 GHz. The system used Ubuntu 12.04 as operating system and the\nHEPSPEC 2006 (HS06) benchmarking suite was compiled natively with gcc-4.4 on\nthe system. The benchmark was run for various settings of the relevant gcc\ncompiler options. We did not find significant influence from the compiler\noptions on the benchmark result. The final HS06 benchmark result is 10.4."
},{
    "category": "cs.DC", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1311.5740v1", 
    "title": "Distributed Multiscale Computing with MUSCLE 2, the Multiscale Coupling   Library and Environment", 
    "arxiv-id": "1311.5740v1", 
    "author": "Alfons G. Hoekstra", 
    "publish": "2013-11-22T13:02:15Z", 
    "summary": "We present the Multiscale Coupling Library and Environment: MUSCLE 2. This\nmultiscale component-based execution environment has a simple to use Java, C++,\nC, Python and Fortran API, compatible with MPI, OpenMP and threading codes. We\ndemonstrate its local and distributed computing capabilities and compare its\nperformance to MUSCLE 1, file copy, MPI, MPWide, and GridFTP. The local\nthroughput of MPI is about two times higher, so very tightly coupled code\nshould use MPI as a single submodel of MUSCLE 2; the distributed performance of\nGridFTP is lower, especially for small messages. We test the performance of a\ncanal system model with MUSCLE 2, where it introduces an overhead as small as\n5% compared to MPI."
},{
    "category": "cs.DC", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1311.5806v2", 
    "title": "Analysis of Load Balancing in Large Heterogeneous Processor Sharing   Systems", 
    "arxiv-id": "1311.5806v2", 
    "author": "Ravi R. Mazumdar", 
    "publish": "2013-11-22T16:44:35Z", 
    "summary": "We analyze randomized dynamic load balancing schemes for multi-server\nprocessor sharing systems when the number of servers in the system is large and\nthe servers have heterogeneous service rates. In particular, we focus on the\nclassical power-of-two load balancing scheme and a variant of it in which a\nnewly arrived job is assigned to the server having the least instantaneous\nLagrange shadow cost among two randomly chosen servers. The instantaneous\nLagrange shadow cost at a server is given by the ratio of the number of\nunfinished jobs at the server to the capacity of the server. Two different\napproaches of analysis are presented for each scheme. For exponential job\nlength distribution, the analysis is done using the mean field approach and for\nmore general job length distributions the analysis is carried out assuming an\nasymptotic independence property. Analytical expressions to compute mean\nsojourn time of jobs are found for both schemes. Asymptotic insensitivity of\nthe schemes to the type of job length distribution is established. Numerical\nresults are presented to validate the theoretical results and to show that,\nunlike the homogeneous scenario, the power-of-two type schemes considered in\nthis paper may not always result in better behaviour in terms of the mean\nsojourn time of jobs."
},{
    "category": "cs.DC", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1402.1285v1", 
    "title": "Constructing Performance Models for Dense Linear Algebra Algorithms on   Cray XE Systems", 
    "arxiv-id": "1402.1285v1", 
    "author": "Mar\u00eda J. Mart\u00edn", 
    "publish": "2014-02-06T09:16:38Z", 
    "summary": "Hiding or minimizing the communication cost is key in order to obtain good\nperformance on large-scale systems. While communication overlapping attempts to\nhide communications cost, 2.5D communication avoiding algorithms improve\nperformance scalability by reducing the volume of data transfers at the cost of\nextra memory usage. Both approaches can be used together or separately and the\nbest choice depends on the machine, the algorithm and the problem size. Thus,\nthe development of performance models is crucial to determine the best option\nfor each scenario. In this paper, we present a methodology for constructing\nperformance models for parallel numerical routines on Cray XE systems. Our\nmodels use portable benchmarks that measure computational cost and network\ncharacteristics, as well as performance degradation caused by simultaneous\naccesses to the network. We validate our methodology by constructing the\nperformance models for the 2D and 2.5D approaches, with and without\noverlapping, of two matrix multiplication algorithms (Cannon's and SUMMA),\ntriangular solve (TRSM) and Cholesky. We compare the estimations provided by\nthese models with the experimental results using up to 24,576 cores of a Cray\nXE6 system and predict the performance of the algorithms on larger systems.\nResults prove that the estimations significantly improve when taking into\naccount network contention."
},{
    "category": "cs.MS", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1402.5897v1", 
    "title": "A Study on the Influence of Caching: Sequences of Dense Linear Algebra   Kernels", 
    "arxiv-id": "1402.5897v1", 
    "author": "Paolo Bientinesi", 
    "publish": "2014-02-21T12:23:19Z", 
    "summary": "It is universally known that caching is critical to attain high- performance\nimplementations: In many situations, data locality (in space and time) plays a\nbigger role than optimizing the (number of) arithmetic floating point\noperations. In this paper, we show evidence that at least for linear algebra\nalgorithms, caching is also a crucial factor for accurate performance modeling\nand performance prediction."
},{
    "category": "cs.PF", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1404.2266v1", 
    "title": "Enhanced Cluster Computing Performance Through Proportional Fairness", 
    "arxiv-id": "1404.2266v1", 
    "author": "James Roberts", 
    "publish": "2014-04-08T09:44:11Z", 
    "summary": "The performance of cluster computing depends on how concurrent jobs share\nmultiple data center resource types like CPU, RAM and disk storage. Recent\nresearch has discussed efficiency and fairness requirements and identified a\nnumber of desirable scheduling objectives including so-called dominant resource\nfairness (DRF). We argue here that proportional fairness (PF), long recognized\nas a desirable objective in sharing network bandwidth between ongoing flows, is\npreferable to DRF. The superiority of PF is manifest under the realistic\nmodelling assumption that the population of jobs in progress is a stochastic\nprocess. In random traffic the strategy-proof property of DRF proves\nunimportant while PF is shown by analysis and simulation to offer a\nsignificantly better efficiency-fairness tradeoff."
},{
    "category": "cs.PF", 
    "doi": "10.1088/1742-6596/513/6/062025", 
    "link": "http://arxiv.org/pdf/1404.4547v3", 
    "title": "Control of parallel non-observable queues: asymptotic equivalence and   optimality of periodic policies", 
    "arxiv-id": "1404.4547v3", 
    "author": "Tommaso Nesti", 
    "publish": "2014-04-17T14:56:53Z", 
    "summary": "We consider a queueing system composed of a dispatcher that routes\ndeterministically jobs to a set of non-observable queues working in parallel.\nIn this setting, the fundamental problem is which policy should the dispatcher\nimplement to minimize the stationary mean waiting time of the incoming jobs. We\npresent a structural property that holds in the classic scaling of the system\nwhere the network demand (arrival rate of jobs) grows proportionally with the\nnumber of queues. Assuming that each queue of type $r$ is replicated $k$ times,\nwe consider a set of policies that are periodic with period $k \\sum_r p_r$ and\nsuch that exactly $p_r$ jobs are sent in a period to each queue of type $r$.\nWhen $k\\to\\infty$, our main result shows that all the policies in this set are\nequivalent, in the sense that they yield the same mean stationary waiting time,\nand optimal, in the sense that no other policy having the same aggregate\narrival rate to \\emph{all} queues of a given type can do better in minimizing\nthe stationary mean waiting time. This property holds in a strong probabilistic\nsense. Furthermore, the limiting mean waiting time achieved by our policies is\na convex function of the arrival rate in each queue, which facilitates the\ndevelopment of a further optimization aimed at solving the fundamental problem\nabove for large systems."
},{
    "category": "cs.PF", 
    "doi": "10.1142/S0218539314500120", 
    "link": "http://arxiv.org/pdf/1404.5406v1", 
    "title": "Degradation Analysis of Probabilistic Parallel Choice Systems", 
    "arxiv-id": "1404.5406v1", 
    "author": "Shrisha Rao", 
    "publish": "2014-04-22T07:40:51Z", 
    "summary": "Degradation analysis is used to analyze the useful lifetimes of systems,\ntheir failure rates, and various other system parameters like mean time to\nfailure (MTTF), mean time between failures (MTBF), and the system failure rate\n(SFR). In many systems, certain possible parallel paths of execution that have\ngreater chances of success are preferred over others. Thus we introduce here\nthe concept of probabilistic parallel choice. We use binary and $n$-ary\nprobabilistic choice operators in describing the selections of parallel paths.\nThese binary and $n$-ary probabilistic choice operators are considered so as to\nrepresent the complete system (described as a series-parallel system) in terms\nof the probabilities of selection of parallel paths and their relevant\nparameters. Our approach allows us to derive new and generalized formulae for\nsystem parameters like MTTF, MTBF, and SFR. We use a generalized exponential\ndistribution, allowing distinct installation times for individual components,\nand use this model to derive expressions for such system parameters."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISPDC.2014.11", 
    "link": "http://arxiv.org/pdf/1404.6218v3", 
    "title": "A Parallel Task-based Approach to Linear Algebra", 
    "arxiv-id": "1404.6218v3", 
    "author": "Wim Vanderbauwhede", 
    "publish": "2014-04-24T18:39:30Z", 
    "summary": "Processors with large numbers of cores are becoming commonplace. In order to\ntake advantage of the available resources in these systems, the programming\nparadigm has to move towards increased parallelism. However, increasing the\nlevel of concurrency in the program does not necessarily lead to better\nperformance. Parallel programming models have to provide flexible ways of\ndefining parallel tasks and at the same time, efficiently managing the created\ntasks. OpenMP is a widely accepted programming model for shared-memory\narchitectures. In this paper we highlight some of the drawbacks in the OpenMP\ntasking approach, and propose an alternative model based on the Glasgow\nParallel Reduction Machine (GPRM) programming framework. As the main focus of\nthis study, we deploy our model to solve a fundamental linear algebra problem,\nLU factorisation of sparse matrices. We have used the SparseLU benchmark from\nthe BOTS benchmark suite, and compared the results obtained from our model to\nthose of the OpenMP tasking approach. The TILEPro64 system has been used to run\nthe experiments. The results are very promising, not only because of the\nperformance improvement for this particular problem, but also because they\nverify the task management efficiency, stability, and flexibility of our model,\nwhich can be applied to solve problems in future many-core systems."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ISPDC.2014.11", 
    "link": "http://arxiv.org/pdf/1406.1352v2", 
    "title": "Approximate analysis of biological systems by hybrid switching jump   diffusion", 
    "arxiv-id": "1406.1352v2", 
    "author": "Roberta Sirovich", 
    "publish": "2014-06-05T12:03:30Z", 
    "summary": "In this paper we consider large state space continuous time Markov chains\n(MCs) arising in the field of systems biology. For density dependent families\nof MCs that represent the interaction of large groups of identical objects,\nKurtz has proposed two kinds of approximations. One is based on ordinary\ndifferential equations, while the other uses a diffusion process. The\ncomputational cost of the deterministic approximation is significantly lower,\nbut the diffusion approximation retains stochasticity and is able to reproduce\nrelevant random features like variance, bimodality, and tail behavior. In a\nrecent paper, for particular stochastic Petri net models, we proposed a jump\ndiffusion approximation that aims at being applicable beyond the limits of\nKurtz's diffusion approximation, namely when the process reaches the boundary\nwith non-negligible probability. Other limitations of the diffusion\napproximation in its original form are that it can provide inaccurate results\nwhen the number of objects in some groups is often or constantly low and that\nit can be applied only to pure density dependent Markov chains. In order to\novercome these drawbacks, in this paper we propose to apply the jump-diffusion\napproximation only to those components of the model that are in density\ndependent form and are associated with high population levels. The remaining\ncomponents are treated as discrete quantities. The resulting process is a\nhybrid switching jump diffusion. We show that the stochastic differential\nequations that characterize this process can be derived automatically both from\nthe description of the original Markov chains or starting from a higher level\ndescription language, like stochastic Petri nets. The proposed approach is\nillustrated on three models: one modeling the so called crazy clock reaction,\none describing viral infection kinetics and the last considering transcription\nregulation."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.154", 
    "link": "http://arxiv.org/pdf/1406.1567v1", 
    "title": "Proceedings Twelfth International Workshop on Quantitative Aspects of   Programming Languages and Systems", 
    "arxiv-id": "1406.1567v1", 
    "author": "Luca Bortolussi", 
    "publish": "2014-06-06T01:50:20Z", 
    "summary": "This volume contains the proceedings of the Twelfth Workshop on Quantitative\nAspects of Programming Languages and Systems (QAPL 2014), held in Grenoble,\nFrance, on 12 and 13 April, 2014. QAPL 2014 was a satellite event of the\nEuropean Joint Conferences on Theory and Practice of Software (ETAPS). The\ncentral theme of the workshop is that of quantitative aspects of computation.\nThese aspects are related to the use of physical quantities (storage space,\ntime, bandwidth, etc.) as well as mathematical quantities (e.g. probability and\nmeasures for reliability, security and trust), and play an important (sometimes\nessential) role in characterising the behaviour and determining the properties\nof systems. Such quantities are central to the definition of both the model of\nsystems (architecture, language design, semantics) and the methodologies and\ntools for the analysis and verification of the systems properties. The aim of\nthis workshop is to discuss the explicit use of quantitative information such\nas time and probabilities either directly in the model or as a tool for the\nanalysis of systems."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1406.2067v1", 
    "title": "Extended Differential Aggregations in Process Algebra for Performance   and Biology", 
    "arxiv-id": "1406.2067v1", 
    "author": "Mirco Tribastone", 
    "publish": "2014-06-09T03:47:53Z", 
    "summary": "We study aggregations for ordinary differential equations induced by fluid\nsemantics for Markovian process algebra which can capture the dynamics of\nperformance models and chemical reaction networks. Whilst previous work has\nrequired perfect symmetry for exact aggregation, we present approximate fluid\nlumpability, which makes nearby processes perfectly symmetric after a\nperturbation of their parameters. We prove that small perturbations yield\nnearby differential trajectories. Numerically, we show that many heterogeneous\nprocesses can be aggregated with negligible errors."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1406.7285v1", 
    "title": "Near-Optimal Virtual Machine Packing Based on Resource Requirement of   Service Demands Using Pattern Clustering", 
    "arxiv-id": "1406.7285v1", 
    "author": "Saeed Sharifian", 
    "publish": "2014-06-27T19:56:15Z", 
    "summary": "Upon the expansion of Cloud Computing and the positive outlook of\norganizations with regard to the movements towards using cloud computing and\ntheir expanding utilization of such valuable processing method, as well as the\nsolutions provided by the cloud infrastructure providers with regard to the\nreduction of the costs of processing resources, the problem of organizing\nresources in a cloud environment gained a high importance. One of the major\npreoccupations of the minds of cloud infrastructure clients is their lack of\nknowledge on the quantity of their required processing resources in different\nperiods of time. The managers and technicians are trying to make the most use\nof scalability and the flexibility of the resources in cloud computing. The\nmain challenge is with calculating the amount of the required processing\nresources per moment with regard to the quantity of incoming requests of the\nservice. Through deduction of the accurate amount of these items, one can have\nan accurate estimation of the requests per moment. This paper aims at\nintroducing a model for automatic scaling of the cloud resources that would\nreduce the cost of renting the resources for the clients of cloud\ninfrastructure. Thus, first we start with a thorough explanation of the\nproposal and the major components of the model. Then through calculating the\nincomings of the model through clustering and introducing the way that each of\nthese components work in different phases,..."
},{
    "category": "cs.CE", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1408.4965v1", 
    "title": "A Domain Specific Approach to Heterogeneous Computing: From Availability   to Accessibility", 
    "arxiv-id": "1408.4965v1", 
    "author": "Wayne Luk", 
    "publish": "2014-08-21T11:32:53Z", 
    "summary": "We advocate a domain specific software development methodology for\nheterogeneous computing platforms such as Multicore CPUs, GPUs and FPGAs. We\nargue that three specific benefits are realised from adopting such an approach:\nportable, efficient implementations across heterogeneous platforms; domain\nspecific metrics of quality that characterise platforms in a form software\ndevelopers will understand; automatic, optimal partitioning across the\navailable computing resources. These three benefits allow a development\nmethodology for software developers where they describe their computational\nproblems in a single, easy to understand form, and after a modeling procedure\non the available resources, select how they would like to trade between various\ndomain specific metrics. Our work on the Forward Financial Framework ($F^3$)\ndemonstrates this methodology in practise. We are able to execute a range of\ncomputational finance option pricing tasks efficiently upon a wide range of\nCPU, GPU and FPGA computing platforms. We can also create accurate financial\ndomain metric models of walltime latency and statistical confidence.\nFurthermore, we believe that we can support automatic, optimal partitioning\nusing this execution and modelling capability."
},{
    "category": "cs.MS", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1409.0669v1", 
    "title": "Performance Portability Study of Linear Algebra Kernels in OpenCL", 
    "arxiv-id": "1409.0669v1", 
    "author": "Ansgar J\u00fcngel", 
    "publish": "2014-09-02T11:21:13Z", 
    "summary": "The performance portability of OpenCL kernel implementations for common\nmemory bandwidth limited linear algebra operations across different hardware\ngenerations of the same vendor as well as across vendors is studied. Certain\ncombinations of kernel implementations and work sizes are found to exhibit good\nperformance across compute kernels, hardware generations, and, to a lesser\ndegree, vendors. As a consequence, it is demonstrated that the optimization of\na single kernel is often sufficient to obtain good performance for a large\nclass of more complicated operations."
},{
    "category": "cs.IT", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1409.1300v1", 
    "title": "Quality of Service Improvement for High-Speed Railway Communications", 
    "arxiv-id": "1409.1300v1", 
    "author": "Bo Ai", 
    "publish": "2014-09-04T02:14:03Z", 
    "summary": "With the fast development of high-speed railways, a call for fulfilling the\nnotion of communication at \"anytime, anywhere\" for high-speed train passengers\nin the Train Operating Control System is on the way. In order to make a\nrealization of that, new railway wireless communication networks are needed.\nThe most promising one is the Long Term Evolution for Railway which will\nprovide broadband access, fast handover, and reliable communication for high\nmobility users. However, with the increase of speed, the system is subjected to\nhigh bit error rate, Doppler frequency shift and handover failure just like\nother system does. This paper is trying to solve these problems by employing\nMIMO technique. Specifically, the goal is to provide higher data rate, higher\nreliability, less delay, and other relative quality of services for passengers.\nMIMO performance analysis, resource allocation, and access control for handover\nand various services in a two-hop model are proposed in this paper. Analytical\nresults and simulation results show that the proposed model and schemes perform\nwell in improving the system performances."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1409.3463v1", 
    "title": "Heavy Traffic Limits for GI/H/n Queues: Theory and Application", 
    "arxiv-id": "1409.3463v1", 
    "author": "Prasun Sinha", 
    "publish": "2014-09-11T14:53:47Z", 
    "summary": "We consider a GI/H/n queueing system. In this system, there are multiple\nservers in the queue. The inter-arrival time is general and independent, and\nthe service time follows hyper-exponential distribution. Instead of stochastic\ndifferential equations, we propose two heavy traffic limits for this system,\nwhich can be easily applied in practical systems. In applications, we show how\nto use these heavy traffic limits to design a power efficient cloud computing\nenvironment based on different QoS requirements."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1409.5327v1", 
    "title": "Store-Forward and its implications for Proportional Scheduling", 
    "arxiv-id": "1409.5327v1", 
    "author": "N. S. Walton", 
    "publish": "2014-09-17T19:45:20Z", 
    "summary": "The Proportional Scheduler was recently proposed as a scheduling algorithm\nfor multi-hop switch networks. For these networks, the BackPressure scheduler\nis the classical benchmark. For networks with fixed routing, the Proportional\nScheduler is maximum stable, myopic and, furthermore, will alleviate certain\nscaling issued found in BackPressure for large networks. Nonetheless, the\nequilibrium and delay properties of the Proportional Scheduler has not been\nfully characterized.\n  In this article, we postulate on the equilibrium behaviour of the\nProportional Scheduler though the analysis of an analogous rule called the\nStore-Forward allocation. It has been shown that Store-Forward has\nasymptotically allocates according to the Proportional Scheduler. Further, for\nStore-Forward networks, numerous equilibrium quantities are explicitly\ncalculable. For FIFO networks under Store-Forward, we calculate the policies\nstationary distribution and end-to-end route delay. We discuss network\ntopologies when the stationary distribution is product-form, a phenomenon which\nwe call \\emph{product form resource pooling}. We extend this product form\nnotion to independent set scheduling on perfect graphs, where we show that\nnon-neighbouring queues are statistically independent. Finally, we analyse the\nlarge deviations behaviour of the equilibrium distribution of Store-Forward\nnetworks in order to construct Lyapunov functions for FIFO switch networks."
},{
    "category": "cs.PF", 
    "doi": "10.4204/EPTCS.154.3", 
    "link": "http://arxiv.org/pdf/1409.5567v1", 
    "title": "Rank-Aware Dynamic Migrations and Adaptive Demotions for DRAM Power   Management", 
    "arxiv-id": "1409.5567v1", 
    "author": "Minyi Guo", 
    "publish": "2014-09-19T09:30:49Z", 
    "summary": "Modern DRAM architectures allow a number of low-power states on individual\nmemory ranks for advanced power management. Many previous studies have taken\nadvantage of demotions on low-power states for energy saving. However, most of\nthe demotion schemes are statically performed on a limited number of\npre-selected low-power states, and are suboptimal for different workloads and\nmemory architectures. Even worse, the idle periods are often too short for\neffective power state transitions, especially for memory intensive\napplications. Wrong decisions on power state transition incur significant\nenergy and delay penalties. In this paper, we propose a novel memory system\ndesign named RAMZzz with rank-aware energy saving optimizations including\ndynamic page migrations and adaptive demotions. Specifically, we group the\npages with similar access locality into the same rank with dynamic page\nmigrations. Ranks have their hotness: hot ranks are kept busy for high\nutilization and cold ranks can have more lengthy idle periods for power state\ntransitions. We further develop adaptive state demotions by considering all\nlow-power states for each rank and a prediction model to estimate the\npower-down timeout among states. We experimentally compare our algorithm with\nother energy saving policies with cycle-accurate simulation. Experiments with\nbenchmark workloads show that RAMZzz achieves significant improvement on\nenergy-delay2 and energy consumption over other energy saving techniques."
},{
    "category": "cs.MS", 
    "doi": "10.1016/j.parco.2015.05.004", 
    "link": "http://arxiv.org/pdf/1409.5757v1", 
    "title": "Intel Cilk Plus for Complex Parallel Algorithms: \"Enormous Fast Fourier   Transform\" (EFFT) Library", 
    "arxiv-id": "1409.5757v1", 
    "author": "Andrey Vladimirov", 
    "publish": "2014-09-19T18:48:58Z", 
    "summary": "In this paper we demonstrate the methodology for parallelizing the\ncomputation of large one-dimensional discrete fast Fourier transforms (DFFTs)\non multi-core Intel Xeon processors. DFFTs based on the recursive Cooley-Tukey\nmethod have to control cache utilization, memory bandwidth and vector hardware\nusage, and at the same time scale across multiple threads or compute nodes. Our\nmethod builds on single-threaded Intel Math Kernel Library (MKL) implementation\nof DFFT, and uses the Intel Cilk Plus framework for thread parallelism. We\ndemonstrate the ability of Intel Cilk Plus to handle parallel recursion with\nnested loop-centric parallelism without tuning the code to the number of cores\nor cache metrics. The result of our work is a library called EFFT that performs\n1D DFTs of size 2^N for N>=21 faster than the corresponding Intel MKL parallel\nDFT implementation by up to 1.5x, and faster than FFTW by up to 2.5x. The code\nof EFFT is available for free download under the GPLv3 license. This work\nprovides a new efficient DFFT implementation, and at the same time demonstrates\nan educational example of how computer science problems with complex parallel\npatterns can be optimized for high performance using the Intel Cilk Plus\nframework."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijesa.2014.4401", 
    "link": "http://arxiv.org/pdf/1501.01370v1", 
    "title": "A Case Study: Task Scheduling Methodologies for High Speed Computing   Systems", 
    "arxiv-id": "1501.01370v1", 
    "author": "Arvind Rajawat", 
    "publish": "2015-01-07T05:51:19Z", 
    "summary": "High Speed computing meets ever increasing real-time computational demands\nthrough the leveraging of flexibility and parallelism. The flexibility is\nachieved when computing platform designed with heterogeneous resources to\nsupport multifarious tasks of an application where as task scheduling brings\nparallel processing. The efficient task scheduling is critical to obtain\noptimized performance in heterogeneous computing Systems (HCS). In this paper,\nwe brought a review of various application scheduling models which provide\nparallelism for homogeneous and heterogeneous computing systems. In this paper,\nwe made a review of various scheduling methodologies targeted to high speed\ncomputing systems and also prepared summary chart. The comparative study of\nscheduling methodologies for high speed computing systems has been carried out\nbased on the attributes of platform & application as well. The attributes are\nexecution time, nature of task, task handling capability, type of host &\ncomputing platform. Finally a summary chart has been prepared and it\ndemonstrates that the need of developing scheduling methodologies for\nHeterogeneous Reconfigurable Computing Systems (HRCS) which is an emerging high\nspeed computing platform for real time applications."
},{
    "category": "cs.IT", 
    "doi": "10.5121/ijesa.2014.4401", 
    "link": "http://arxiv.org/pdf/1501.02516v1", 
    "title": "Beam-searching and Transmission Scheduling in Millimeter Wave   Communications", 
    "arxiv-id": "1501.02516v1", 
    "author": "Carlo Fischione", 
    "publish": "2015-01-12T01:06:14Z", 
    "summary": "Millimeter wave (mmW) wireless networks are capable to support multi-gigabit\ndata rates, by using directional communications with narrow beams. However,\nexisting mmW communications standards are hindered by two problems: deafness\nand single link scheduling. The deafness problem, that is, a misalignment\nbetween transmitter and receiver beams, demands a time consuming beam-searching\noperation, which leads to an alignment-throughput tradeoff. Moreover, the\nexisting mmW standards schedule a single link in each time slot and hence do\nnot fully exploit the potential of mmW communications, where directional\ncommunications allow multiple concurrent transmissions. These two problems are\naddressed in this paper, where a joint beamwidth selection and power allocation\nproblem is formulated by an optimization problem for short range mmW networks\nwith the objective of maximizing effective network throughput. This\noptimization problem allows establishing the fundamental alignment-throughput\ntradeoff, however it is computationally complex and requires exact knowledge of\nnetwork topology, which may not be available in practice. Therefore, two\nstandard-compliant approximation solution algorithms are developed, which rely\non underestimation and overestimation of interference. The first one exploits\ndirectionality to maximize the reuse of available spectrum and thereby\nincreases the network throughput, while imposing almost no computational\ncomplexity. The second one is a more conservative approach that protects all\nactive links from harmful interference, yet enhances the network throughput by\n100% compared to the existing standards. Extensive performance analysis\nprovides useful insights on the directionality level and the number of\nconcurrent transmissions that should be pursued. Interestingly, extremely\nnarrow beams are in general not optimal."
},{
    "category": "cs.IT", 
    "doi": "10.1109/ICC.2015.7249031", 
    "link": "http://arxiv.org/pdf/1501.03307v1", 
    "title": "Binary Systematic Network Coding for Progressive Packet Decoding", 
    "arxiv-id": "1501.03307v1", 
    "author": "Andrea Tassi", 
    "publish": "2015-01-14T10:52:10Z", 
    "summary": "We consider binary systematic network codes and investigate their capability\nof decoding a source message either in full or in part. We carry out a\nprobability analysis, derive closed-form expressions for the decoding\nprobability and show that systematic network coding outperforms conventional\nnetwork coding. We also develop an algorithm based on Gaussian elimination that\nallows progressive decoding of source packets. Simulation results show that the\nproposed decoding algorithm can achieve the theoretical optimal performance.\nFurthermore, we demonstrate that systematic network codes equipped with the\nproposed algorithm are good candidates for progressive packet recovery owing to\ntheir overall decoding delay characteristics."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICC.2015.7249031", 
    "link": "http://arxiv.org/pdf/1501.04552v1", 
    "title": "Solving the Klein-Gordon equation using Fourier spectral methods: A   benchmark test for computer performance", 
    "arxiv-id": "1501.04552v1", 
    "author": "J. Vienne", 
    "publish": "2015-01-19T16:48:00Z", 
    "summary": "The cubic Klein-Gordon equation is a simple but non-trivial partial\ndifferential equation whose numerical solution has the main building blocks\nrequired for the solution of many other partial differential equations. In this\nstudy, the library 2DECOMP&FFT is used in a Fourier spectral scheme to solve\nthe Klein-Gordon equation and strong scaling of the code is examined on\nthirteen different machines for a problem size of 512^3. The results are useful\nin assessing likely performance of other parallel fast Fourier transform based\nprograms for solving partial differential equations. The problem is chosen to\nbe large enough to solve on a workstation, yet also of interest to solve\nquickly on a supercomputer, in particular for parametric studies. Unlike other\nhigh performance computing benchmarks, for this problem size, the time to\nsolution will not be improved by simply building a bigger supercomputer."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ICC.2015.7249031", 
    "link": "http://arxiv.org/pdf/1007.4853v2", 
    "title": "Performance bounds in wormhole routing, a network calculus approach", 
    "arxiv-id": "1007.4853v2", 
    "author": "Bruno Gaujal", 
    "publish": "2010-07-27T23:47:58Z", 
    "summary": "We present a model of performance bound calculus on feedforward networks\nwhere data packets are routed under wormhole routing discipline. We are\ninterested in determining maximum end-to-end delays and backlogs of messages or\npackets going from a source node to a destination node, through a given virtual\npath in the network. Our objective here is to give a network calculus approach\nfor calculating the performance bounds. First we propose a new concept of\ncurves that we call packet curves. The curves permit to model constraints on\npacket lengths of a given data flow, when the lengths are allowed to be\ndifferent. Second, we use this new concept to propose an approach for\ncalculating residual services for data flows served under non preemptive\nservice disciplines. Third, we model a binary switch (with two input ports and\ntwo output ports), where data is served under wormhole discipline. We present\nour approach for computing the residual services and deduce the worst case\nbounds for flows passing through a wormhole binary switch. Finally, we\nillustrate this approach in numerical examples, and show how to extend it to\nfeedforward networks."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1007.5080v3", 
    "title": "Analysis Framework for Opportunistic Spectrum OFDMA and its Application   to the IEEE 802.22 Standard", 
    "arxiv-id": "1007.5080v3", 
    "author": "Danijela \u010cabri\u0107", 
    "publish": "2010-07-28T22:25:55Z", 
    "summary": "We present an analytical model that enables throughput evaluation of\nOpportunistic Spectrum Orthogonal Frequency Division Multiple Access (OS-OFDMA)\nnetworks. The core feature of the model, based on a discrete time Markov chain,\nis the consideration of different channel and subchannel allocation strategies\nunder different Primary and Secondary user types, traffic and priority levels.\nThe analytical model also assesses the impact of different spectrum sensing\nstrategies on the throughput of OS-OFDMA network. The analysis applies to the\nIEEE 802.22 standard, to evaluate the impact of two-stage spectrum sensing\nstrategy and varying temporal activity of wireless microphones on the IEEE\n802.22 throughput. Our study suggests that OS-OFDMA with subchannel notching\nand channel bonding could provide almost ten times higher throughput compared\nwith the design without those options, when the activity and density of\nwireless microphones is very high. Furthermore, we confirm that OS-OFDMA\nimplementation without subchannel notching, used in the IEEE 802.22, is able to\nsupport real-time and non-real-time quality of service classes, provided that\nwireless microphones temporal activity is moderate (with approximately one\nwireless microphone per 3,000 inhabitants with light urban population density\nand short duty cycles). Finally, two-stage spectrum sensing option improves\nOS-OFDMA throughput, provided that the length of spectrum sensing at every\nstage is optimized using our model."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1104.0118v1", 
    "title": "A Comparative Study of Relaying Schemes with Decode-and-Forward over   Nakagami-m Fading Channels", 
    "arxiv-id": "1104.0118v1", 
    "author": "Paschalis C. Sofotasios", 
    "publish": "2011-04-01T09:37:13Z", 
    "summary": "Utilizing relaying techniques to improve performance of wireless systems is a\npromising avenue. However, it is crucial to understand what type of relaying\nschemes should be used for achieving different performance objectives under\nrealistic fading conditions. In this paper, we present a general framework for\nmodelling and evaluating the performance of relaying schemes based on the\ndecode-and-forward (DF) protocol over independent and not necessarily\nidentically distributed (INID) Nakagami-m fading channels. In particular, we\npresent closed-form expressions for the statistics of the instantaneous output\nsignal-to-noise ratio of four significant relaying schemes with DF; two based\non repetitive transmission and the other two based on relay selection (RS).\nThese expressions are then used to obtain closed-form expressions for the\noutage probability and the average symbol error probability for several\nmodulations of all considered relaying schemes over INID Nakagami-m fading.\nImportantly, it is shown that when the channel state information for RS is\nperfect, RS-based transmission schemes always outperform repetitive ones.\nFurthermore, when the direct link between the source and the destination nodes\nis sufficiently strong, relaying may not result in any gains and in this case\nit should be switched-off."
},{
    "category": "cs.NI", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1104.2156v2", 
    "title": "Structural Analysis of Network Traffic Matrix via Relaxed Principal   Component Pursuit", 
    "arxiv-id": "1104.2156v2", 
    "author": "Xiaowen Dong", 
    "publish": "2011-04-12T09:57:05Z", 
    "summary": "The network traffic matrix is widely used in network operation and\nmanagement. It is therefore of crucial importance to analyze the components and\nthe structure of the network traffic matrix, for which several mathematical\napproaches such as Principal Component Analysis (PCA) were proposed. In this\npaper, we first argue that PCA performs poorly for analyzing traffic matrix\nthat is polluted by large volume anomalies, and then propose a new\ndecomposition model for the network traffic matrix. According to this model, we\ncarry out the structural analysis by decomposing the network traffic matrix\ninto three sub-matrices, namely, the deterministic traffic, the anomaly traffic\nand the noise traffic matrix, which is similar to the Robust Principal\nComponent Analysis (RPCA) problem previously studied in [13]. Based on the\nRelaxed Principal Component Pursuit (Relaxed PCP) method and the Accelerated\nProximal Gradient (APG) algorithm, we present an iterative approach for\ndecomposing a traffic matrix, and demonstrate its efficiency and flexibility by\nexperimental results. Finally, we further discuss several features of the\ndeterministic and noise traffic. Our study develops a novel method for the\nproblem of structural analysis of the traffic matrix, which is robust against\npollution of large volume anomalies."
},{
    "category": "physics.comp-ph", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1104.2499v2", 
    "title": "OpenCL/OpenGL approach for studying active Brownian motion", 
    "arxiv-id": "1104.2499v2", 
    "author": "Micha\u0142 \u017babicki", 
    "publish": "2011-04-13T14:12:15Z", 
    "summary": "This work presents a methodology for studying active Brownian dynamics on\nratchet potentials using interoperating OpenCL and OpenGL frameworks.\nPrograming details along with optimization issues are discussed, followed by a\ncom- parison of performance on different devices. Time of visualization using\nOpenGL sharing buffer with OpenCL has been tested against another technique\nwhich, while using OpenGL, does not share memory buffer with OpenCL. Both\nmethods have been compared with visualizing data to an external software -\ngnuplot. OpenCL/OpenGL interoperating method has been found the most\nappropriate to visualize any large set of data for which calculation itself is\nnot very long."
},{
    "category": "cs.DC", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1104.4518v2", 
    "title": "Parallel Breadth-First Search on Distributed Memory Systems", 
    "arxiv-id": "1104.4518v2", 
    "author": "Kamesh Madduri", 
    "publish": "2011-04-22T23:42:40Z", 
    "summary": "Data-intensive, graph-based computations are pervasive in several scientific\napplications, and are known to to be quite challenging to implement on\ndistributed memory systems. In this work, we explore the design space of\nparallel algorithms for Breadth-First Search (BFS), a key subroutine in several\ngraph algorithms. We present two highly-tuned parallel approaches for BFS on\nlarge parallel systems: a level-synchronous strategy that relies on a simple\nvertex-based partitioning of the graph, and a two-dimensional sparse\nmatrix-partitioning-based approach that mitigates parallel communication\noverhead. For both approaches, we also present hybrid versions with intra-node\nmultithreading. Our novel hybrid two-dimensional algorithm reduces\ncommunication times by up to a factor of 3.5, relative to a common vertex based\napproach. Our experimental study identifies execution regimes in which these\napproaches will be competitive, and we demonstrate extremely high performance\non leading distributed-memory parallel systems. For instance, for a 40,000-core\nparallel execution on Hopper, an AMD Magny-Cours based system, we achieve a BFS\nperformance rate of 17.8 billion edge visits per second on an undirected graph\nof 4.3 billion vertices and 68.7 billion edges with skewed degree distribution."
},{
    "category": "cs.IT", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1104.4927v1", 
    "title": "Serial Concatenation of RS Codes with Kite Codes: Performance Analysis,   Iterative Decoding and Design", 
    "arxiv-id": "1104.4927v1", 
    "author": "Xiaoyi Zhang", 
    "publish": "2011-04-26T14:05:51Z", 
    "summary": "In this paper, we propose a new ensemble of rateless forward error correction\n(FEC) codes. The proposed codes are serially concatenated codes with\nReed-Solomon (RS) codes as outer codes and Kite codes as inner codes. The inner\nKite codes are a special class of prefix rateless low-density parity-check\n(PRLDPC) codes, which can generate potentially infinite (or as many as\nrequired) random-like parity-check bits. The employment of RS codes as outer\ncodes not only lowers down error-floors but also ensures (with high\nprobability) the correctness of successfully decoded codewords. In addition to\nthe conventional two-stage decoding, iterative decoding between the inner code\nand the outer code are also implemented to improve the performance further. The\nperformance of the Kite codes under maximum likelihood (ML) decoding is\nanalyzed by applying a refined Divsalar bound to the ensemble weight\nenumerating functions (WEF). We propose a simulation-based optimization method\nas well as density evolution (DE) using Gaussian approximations (GA) to design\nthe Kite codes. Numerical results along with semi-analytic bounds show that the\nproposed codes can approach Shannon limits with extremely low error-floors. It\nis also shown by simulation that the proposed codes performs well within a wide\nrange of signal-to-noise-ratios (SNRs)."
},{
    "category": "cs.PL", 
    "doi": "10.1109/TVT.2012.2188550", 
    "link": "http://arxiv.org/pdf/1109.1421v1", 
    "title": "Profiling parallel Mercury programs with ThreadScope", 
    "arxiv-id": "1109.1421v1", 
    "author": "Zoltan Somogyi", 
    "publish": "2011-09-07T11:20:46Z", 
    "summary": "The behavior of parallel programs is even harder to understand than the\nbehavior of sequential programs. Parallel programs may suffer from any of the\nperformance problems affecting sequential programs, as well as from several\nproblems unique to parallel systems. Many of these problems are quite hard (or\neven practically impossible) to diagnose without help from specialized tools.\nWe present a proposal for a tool for profiling the parallel execution of\nMercury programs, a proposal whose implementation we have already started. This\ntool is an adaptation and extension of the ThreadScope profiler that was first\nbuilt to help programmers visualize the execution of parallel Haskell programs."
},{
    "category": "cs.DC", 
    "doi": "10.1137/110848244", 
    "link": "http://arxiv.org/pdf/1109.3739v2", 
    "title": "Parallel Sparse Matrix-Matrix Multiplication and Indexing:   Implementation and Experiments", 
    "arxiv-id": "1109.3739v2", 
    "author": "John Gilbert", 
    "publish": "2011-09-16T23:25:28Z", 
    "summary": "Generalized sparse matrix-matrix multiplication (or SpGEMM) is a key\nprimitive for many high performance graph algorithms as well as for some linear\nsolvers, such as algebraic multigrid. Here we show that SpGEMM also yields\nefficient algorithms for general sparse-matrix indexing in distributed memory,\nprovided that the underlying SpGEMM implementation is sufficiently flexible and\nscalable. We demonstrate that our parallel SpGEMM methods, which use\ntwo-dimensional block data distributions with serial hypersparse kernels, are\nindeed highly flexible, scalable, and memory-efficient in the general case.\nThis algorithm is the first to yield increasing speedup on an unbounded number\nof processors; our experiments show scaling up to thousands of processors in a\nvariety of test scenarios."
},{
    "category": "cs.RO", 
    "doi": "10.1137/110848244", 
    "link": "http://arxiv.org/pdf/1204.0958v1", 
    "title": "Robust methods for LTE and WiMAX dimensioning", 
    "arxiv-id": "1204.0958v1", 
    "author": "Thanh-Tung Vu", 
    "publish": "2012-04-04T14:26:08Z", 
    "summary": "This paper proposes an analytic model for dimensioning OFDMA based networks\nlike WiMAX and LTE systems. In such a system, users require a number of\nsubchannels which depends on their \\SNR, hence of their position and the\nshadowing they experience. The system is overloaded when the number of required\nsubchannels is greater than the number of available subchannels. We give an\nexact though not closed expression of the loss probability and then give an\nalgorithmic method to derive the number of subchannels which guarantees a loss\nprobability less than a given threshold. We show that Gaussian approximation\nlead to optimistic values and are thus unusable. We then introduce Edgeworth\nexpansions with error bounds and show that by choosing the right order of the\nexpansion, one can have an approximate dimensioning value easy to compute but\nwith guaranteed performance. As the values obtained are highly dependent from\nthe parameters of the system, which turned to be rather undetermined, we\nprovide a procedure based on concentration inequality for Poisson functionals,\nwhich yields to conservative dimensioning. This paper relies on recent results\non concentration inequalities and establish new results on Edgeworth\nexpansions."
},{
    "category": "cs.NI", 
    "doi": "10.1137/110848244", 
    "link": "http://arxiv.org/pdf/1204.5281v1", 
    "title": "Stochastic Analysis of Mean Interference for RTS/CTS Mechanism", 
    "arxiv-id": "1204.5281v1", 
    "author": "Wenyi Zhang", 
    "publish": "2012-04-24T06:59:37Z", 
    "summary": "The RTS/CTS handshake mechanism in WLAN is studied using stochastic geometry.\nThe effect of RTS/CTS is treated as a thinning procedure for a spatially\ndistributed point process that models the potential transceivers in a WLAN, and\nthe resulting concurrent transmission processes are described. Exact formulas\nfor the intensity of the concurrent transmission processes and the mean\ninterference experienced by a typical receiver are established. The analysis\nyields useful results for understanding how the design parameters of RTS/CTS\naffect the network interference."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.85", 
    "link": "http://arxiv.org/pdf/1207.0559v1", 
    "title": "Proceedings 10th Workshop on Quantitative Aspects of Programming   Languages and Systems", 
    "arxiv-id": "1207.0559v1", 
    "author": "Mieke Massink", 
    "publish": "2012-07-03T01:24:57Z", 
    "summary": "This volume contains the proceedings of the Tenth Workshop on Quantitative\nAspects of Programming Languages (QAPL 2012), held in Tallin, Estonia, on March\n31 and April 1, 2012. QAPL 2012 is a satellite event of the European Joint\nConferences on Theory and Practice of Software (ETAPS 2012). The workshop theme\nis on quantitative aspects of computation. These aspects are related to the use\nof physical quantities (storage space, time, bandwidth, etc.) as well as\nmathematical quantities (e.g. probability and measures for reliability,\nsecurity and trust), and play an important (sometimes essential) role in\ncharacterising the behavior and determining the properties of systems. Such\nquantities are central to the definition of both the model of systems\n(architecture, language design, semantics) and the methodologies and tools for\nthe analysis and verification of the systems properties. The aim of this\nworkshop is to discuss the explicit use of quantitative information such as\ntime and probabilities either directly in the model or as a tool for the\nanalysis of systems."
},{
    "category": "cs.SY", 
    "doi": "10.4204/EPTCS.85.8", 
    "link": "http://arxiv.org/pdf/1207.0873v1", 
    "title": "Hybrid performance modelling of opportunistic networks", 
    "arxiv-id": "1207.0873v1", 
    "author": "Jane Hillston", 
    "publish": "2012-07-04T01:25:04Z", 
    "summary": "We demonstrate the modelling of opportunistic networks using the process\nalgebra stochastic HYPE. Network traffic is modelled as continuous flows,\ncontact between nodes in the network is modelled stochastically, and\ninstantaneous decisions are modelled as discrete events. Our model describes a\nnetwork of stationary video sensors with a mobile ferry which collects data\nfrom the sensors and delivers it to the base station. We consider different\nmobility models and different buffer sizes for the ferries. This case study\nillustrates the flexibility and expressive power of stochastic HYPE. We also\ndiscuss the software that enables us to describe stochastic HYPE models and\nsimulate them."
},{
    "category": "cs.PF", 
    "doi": "10.1109/TWC.2013.012513.120966", 
    "link": "http://arxiv.org/pdf/1207.1469v1", 
    "title": "Cramer-Rao Bounds for Joint RSS/DoA-Based Primary-User Localization in   Cognitive Radio Networks", 
    "arxiv-id": "1207.1469v1", 
    "author": "Danijela Cabric", 
    "publish": "2012-07-05T21:47:33Z", 
    "summary": "Knowledge about the location of licensed primary-users (PU) could enable\nseveral key features in cognitive radio (CR) networks including improved\nspatio-temporal sensing, intelligent location-aware routing, as well as aiding\nspectrum policy enforcement. In this paper we consider the achievable accuracy\nof PU localization algorithms that jointly utilize received-signal-strength\n(RSS) and direction-of-arrival (DoA) measurements by evaluating the Cramer-Rao\nBound (CRB). Previous works evaluate the CRB for RSS-only and DoA-only\nlocalization algorithms separately and assume DoA estimation error variance is\na fixed constant or rather independent of RSS. We derive the CRB for joint\nRSS/DoA-based PU localization algorithms based on the mathematical model of DoA\nestimation error variance as a function of RSS, for a given CR placement. The\nbound is compared with practical localization algorithms and the impact of\nseveral key parameters, such as number of nodes, number of antennas and\nsamples, channel shadowing variance and correlation distance, on the achievable\naccuracy are thoroughly analyzed and discussed. We also derive the closed-form\nasymptotic CRB for uniform random CR placement, and perform theoretical and\nnumerical studies on the required number of CRs such that the asymptotic CRB\ntightly approximates the numerical integration of the CRB for a given\nplacement."
},{
    "category": "cs.MS", 
    "doi": "10.1109/TWC.2013.012513.120966", 
    "link": "http://arxiv.org/pdf/1207.1746v1", 
    "title": "A Generic Library for Stencil Computations", 
    "arxiv-id": "1207.1746v1", 
    "author": "Ugo Varetto", 
    "publish": "2012-07-06T23:30:06Z", 
    "summary": "In this era of diverse and heterogeneous computer architectures, the\nprogrammability issues, such as productivity and portable efficiency, are\ncrucial to software development and algorithm design. One way to approach the\nproblem is to step away from traditional sequential programming languages and\nmove toward domain specific programming environments to balance between\nexpressivity and efficiency. In order to demonstrate this principle, we\ndeveloped a domain specific C++ generic library for stencil computations, like\nPDE solvers. The library features high level constructs to specify computation\nand allows the development of parallel stencil computations with very limited\neffort. The high abstraction constructs (like do_all and do_reduce) make the\nprogram shorter and cleaner with increased contextual information for better\nperformance exploitation. The results show good performance from Windows\nmulticores, to HPC clusters and machines with accelerators, like GPUs."
},{
    "category": "cs.IT", 
    "doi": "10.5121/ijmnct.2012.2301", 
    "link": "http://arxiv.org/pdf/1207.3868v1", 
    "title": "Impact of Different Spreading Codes Using FEC on DWT Based MC-CDMA   System", 
    "arxiv-id": "1207.3868v1", 
    "author": "Shaikh Enayet Ullah", 
    "publish": "2012-07-17T03:46:43Z", 
    "summary": "The effect of different spreading codes in DWT based MC-CDMA wireless\ncommunication system is investigated. In this paper, we present the Bit Error\nRate (BER) performance of different spreading codes (Walsh-Hadamard code,\nOrthogonal gold code and Golay complementary sequences) using Forward Error\nCorrection (FEC) of the proposed system. The data is analyzed and is compared\namong different spreading codes in both coded and uncoded cases. It is found\nvia computer simulation that the performance of the proposed coded system is\nmuch better than that of the uncoded system irrespective of the spreading codes\nand all the spreading codes show approximately similar nature for both coded\nand uncoded in all modulation schemes."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcnc.2012.4303", 
    "link": "http://arxiv.org/pdf/1207.3869v1", 
    "title": "Automated Inference System for End-To-End Diagnosis of Network   Performance Issues in Client-Terminal Devices", 
    "arxiv-id": "1207.3869v1", 
    "author": "Jonathan C. Li", 
    "publish": "2012-07-17T03:51:57Z", 
    "summary": "Traditional network diagnosis methods of Client-Terminal Device (CTD)\nproblems tend to be laborintensive, time consuming, and contribute to increased\ncustomer dissatisfaction. In this paper, we propose an automated solution for\nrapidly diagnose the root causes of network performance issues in CTD. Based on\na new intelligent inference technique, we create the Intelligent Automated\nClient Diagnostic (IACD) system, which only relies on collection of\nTransmission Control Protocol (TCP) packet traces. Using soft-margin Support\nVector Machine (SVM) classifiers, the system (i) distinguishes link problems\nfrom client problems and (ii) identifies characteristics unique to the specific\nfault to report the root cause. The modular design of the system enables\nsupport for new access link and fault types. Experimental evaluation\ndemonstrated the capability of the IACD system to distinguish between faulty\nand healthy links and to diagnose the client faults with 98% accuracy. The\nsystem can perform fault diagnosis independent of the user's specific TCP\nimplementation, enabling diagnosis of diverse range of client devices"
},{
    "category": "cs.IT", 
    "doi": "10.5121/ijcnc.2012.4303", 
    "link": "http://arxiv.org/pdf/1207.3871v1", 
    "title": "Performance Analysis of Wavelet Based MC-CDMA System with Implementation   of Various Antenna Diversity Schemes", 
    "arxiv-id": "1207.3871v1", 
    "author": "Sk. Enayet Ullah", 
    "publish": "2012-07-17T03:57:58Z", 
    "summary": "The impact of using wavelet based technique on the performance of a MC-CDMA\nwireless communication system has been investigated. The system under proposed\nstudy incorporates Walsh Hadamard codes to discriminate the message signal for\nindividual user. A computer program written in Mathlab source code is developed\nand this simulation study is made with implementation of various antenna\ndiversity schemes and fading (Rayleigh and Rician) channel. Computer simulation\nresults demonstrate that the proposed wavelet based MC-CDMA system outperforms\nin Alamouti (two transmit antenna and one receive antenna) under AWGN and\nRician channel."
},{
    "category": "cs.IT", 
    "doi": "10.5121/ijcnc.2012.4303", 
    "link": "http://arxiv.org/pdf/1207.3875v1", 
    "title": "Transmission of Voice Signal: BER Performance Analysis of Different FEC   Schemes Based OFDM System over Various Channels", 
    "arxiv-id": "1207.3875v1", 
    "author": "Sheikh Enayet Ullah", 
    "publish": "2012-07-17T04:12:31Z", 
    "summary": "In this paper, we investigate the impact of Forward Error Correction (FEC)\ncodes namely Cyclic Redundancy Code and Convolution Code on the performance of\nOFDM wireless communication system for speech signal transmission over both\nAWGN and fading (Rayleigh and Rician) channels in term of Bit Error\nProbability. The simulation has been done in conjunction with QPSK digital\nmodulation and compared with uncoded resultstal modulation. In the fading\nchannels, it is found via computer simulation that the performance of the\nConvolution interleaved based OFDM systems outperform than that of CRC\ninterleaved OFDM system as well as uncoded OFDM channels."
},{
    "category": "cs.IT", 
    "doi": "10.5121/ijdps.2011.2205", 
    "link": "http://arxiv.org/pdf/1207.3882v1", 
    "title": "WEP: An Energy Efficient Protocol for Cluster Based Heterogeneous   Wireless Sensor Network", 
    "arxiv-id": "1207.3882v1", 
    "author": "Shaikh Enayet Ullah", 
    "publish": "2012-07-17T05:25:56Z", 
    "summary": "We develop an energy-efficient routing protocol in order to enhance the\nstability period of wireless sensor networks. This protocol is called weighted\nelection protocol (WEP). It introduces a scheme to combine clustering strategy\nwith chain routing algorithm for satisfy both energy and stable period\nconstrains under heterogeneous environment in WSNs. Simulation results show\nthat new one performs better than LEACH, SEP and HEARP in terms of stability\nperiod and network lifetime. It is also found that longer stability period\nstrongly depend on higher values of extra energy during its heterogeneous\nsettings."
},{
    "category": "cs.IT", 
    "doi": "10.5121/ijcseit.2012.2103", 
    "link": "http://arxiv.org/pdf/1207.3884v1", 
    "title": "Effect of Interleaved FEC Code on Wavelet Based MC-CDMA System with   Alamouti STBC in Different Modulation Schemes", 
    "arxiv-id": "1207.3884v1", 
    "author": "Sheikh Enayet Ullah", 
    "publish": "2012-07-17T05:34:09Z", 
    "summary": "In this paper, the impact of Forward Error Correction (FEC) code namely\nTrellis code with interleaver on the performance of wavelet based MC-CDMA\nwireless communication system with the implementation of Alamouti antenna\ndiversity scheme has been investigated in terms of Bit Error Rate (BER) as a\nfunction of Signal-to-Noise Ratio (SNR) per bit. Simulation of the system under\nproposed study has been done in M-ary modulation schemes (MPSK, MQAM and DPSK)\nover AWGN and Rayleigh fading channel incorporating Walsh Hadamard code as\northogonal spreading code to discriminate the message signal for individual\nuser. It is observed via computer simulation that the performance of the\ninterleaved coded based proposed system outperforms than that of the uncoded\nsystem in all modulation schemes over Rayleigh fading channel."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijcseit.2012.2103", 
    "link": "http://arxiv.org/pdf/1301.2750v3", 
    "title": "Load-aware Channel Selection for 802.11 WLANs with Limited Measurement", 
    "arxiv-id": "1301.2750v3", 
    "author": "Bjorn Landfeldt", 
    "publish": "2013-01-13T07:49:26Z", 
    "summary": "It has been known that load unaware channel selection in 802.11 networks\nresults in high level interference, and can significantly reduce the network\nthroughput. In current implementation, the only way to determine the traffic\nload on a channel is to measure that channel for a certain duration of time.\nTherefore, in order to find the best channel with the minimum load all channels\nhave to be measured, which is costly and can cause unacceptable communication\ninterruptions between the AP and the stations. In this paper, we propose a\nlearning based approach which aims to find the channel with the minimum load by\nmeasuring only limited number of channels. Our method uses Gaussian Process\nRegressing to accurately track the traffic load on each channel based on the\nprevious measured load. We confirm the performance of our algorithm by using\nexperimental data, and show that the time consumed for the load measurement can\nbe reduced up to 46% compared to the case where all channels are monitored."
}]