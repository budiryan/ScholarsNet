[{
    "category": "cs.OS", 
    "doi": "10.1016/j.sigpro.2008.01.004", 
    "link": "http://arxiv.org/pdf/cs/0111035v1", 
    "other_authors": "Till Straumann", 
    "title": "Open Source Real Time Operating Systems Overview", 
    "arxiv-id": "cs/0111035v1", 
    "author": "Till Straumann", 
    "publish": "2001-11-10T03:30:11Z", 
    "summary": "Modern control systems applications are often built on top of a real time\noperating system (RTOS) which provides the necessary hardware abstraction as\nwell as scheduling, networking and other services. Several open source RTOS\nsolutions are publicly available, which is very attractive, both from an\neconomic (no licensing fees) as well as from a technical (control over the\nsource code) point of view. This contribution gives an overview of the RTLinux\nand RTEMS systems (architecture, development environment, API etc.). Both\nsystems feature most popular CPUs, several APIs (including Posix), networking,\nportability and optional commercial support. Some performance figures are\npresented, focusing on interrupt latency and context switching delay."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/cs/0411080v1", 
    "other_authors": "C. A. G. Assis, E. S. T. Fernandes, V. C. Barbosa", 
    "title": "Modeling the input history of programs for improved instruction-memory   performance", 
    "arxiv-id": "cs/0411080v1", 
    "author": "V. C. Barbosa", 
    "publish": "2004-11-23T16:52:26Z", 
    "summary": "When a program is loaded into memory for execution, the relative position of\nits basic blocks is crucial, since loading basic blocks that are unlikely to be\nexecuted first places them high in the instruction-memory hierarchy only to be\ndislodged as the execution goes on. In this paper we study the use of Bayesian\nnetworks as models of the input history of a program. The main point is the\ncreation of a probabilistic model that persists as the program is run on\ndifferent inputs and at each new input refines its own parameters in order to\nreflect the program's input history more accurately. As the model is thus\ntuned, it causes basic blocks to be reordered so that, upon arrival of the next\ninput for execution, loading the basic blocks into memory automatically takes\ninto account the input history of the program. We report on extensive\nexperiments, whose results demonstrate the efficacy of the overall approach in\nprogressively lowering the execution times of a program on identical inputs\nplaced randomly in a sequence of varied inputs. We provide results on selected\nSPEC CINT2000 programs and also evaluate our approach as compared to the gcc\nlevel-3 optimization and to Pettis-Hansen reordering."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/cs/0502027v1", 
    "other_authors": "Kevin Lai", 
    "title": "Markets are Dead, Long Live Markets", 
    "arxiv-id": "cs/0502027v1", 
    "author": "Kevin Lai", 
    "publish": "2005-02-04T22:48:31Z", 
    "summary": "Researchers have long proposed using economic approaches to resource\nallocation in computer systems. However, few of these proposals became\noperational, let alone commercial. Questions persist about the economic\napproach regarding its assumptions, value, applicability, and relevance to\nsystem design. The goal of this paper is to answer these questions. We find\nthat market-based resource allocation is useful, and more importantly, that\nmechanism design and system design should be integrated to produce systems that\nare both economically and computationally efficient."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/cs/0511010v1", 
    "other_authors": "Nadir Kiyanclar", 
    "title": "A Survey of Virtualization Techniques Focusing on Secure On-Demand   Cluster Computing", 
    "arxiv-id": "cs/0511010v1", 
    "author": "Nadir Kiyanclar", 
    "publish": "2005-11-02T19:52:58Z", 
    "summary": "Virtualization, a technique once used to multiplex the resources of\nhigh-priced mainframe hardware, is seeing a resurgence in applicability with\nthe increasing computing power of commodity computers. By inserting a layer of\nsoftware between the machine and traditional operating systems, this technology\nallows access to a shared computing medium in a manner that is secure,\nresource-controlled, and efficient. These properties are attractive in the\nfield of on-demand computing, where the fine-grained subdivision of resources\nprovided by virtualized systems allows potentially higher utilization of\ncomputing resources.\n  It this work, we survey a number of virtual machine systems with the goal of\nfinding an appropriate candidate to serve as the basis for the On-Demand Secure\nCluster Computing project at the National Center for Supercomputing\nApplications. Contenders are reviewed on a number of desirable properties\nincluding portability and security. We conclude with a comparison and\njustification of our choice."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/cs/0611055v1", 
    "other_authors": "Christophe Rippert, Alexandre Courbot, Gilles Grimaud", 
    "title": "A Low-Footprint Class Loading Mechanism for Embedded Java Virtual   Machines", 
    "arxiv-id": "cs/0611055v1", 
    "author": "Gilles Grimaud", 
    "publish": "2006-11-14T10:11:34Z", 
    "summary": "This paper shows that it is possible to dramatically reduce the memory\nconsumption of classes loaded in an embedded Java virtual machine without\nreducing its functionalities. We describe how to pack the constant pool by\ndeleting entries which are only used during the class loading process. We\npresent some benchmarks which demonstrate the efficiency of this mechanism. We\nfinally suggest some additional optimizations which can be applied if some\nrestrictions to the functionalities of the virtual machine can be tolerated."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/cs/0612079v2", 
    "other_authors": "Steffen Gr\u00f8nneberg", 
    "title": "Executing the same binary on several operating systems", 
    "arxiv-id": "cs/0612079v2", 
    "author": "Steffen Gr\u00f8nneberg", 
    "publish": "2006-12-16T21:37:00Z", 
    "summary": "We notice a way to execute a binary file on Windows and ELF-based systems. It\ncan be used to create software installers and other applications not exceeding\n64 kilo bytes."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0710.4635v1", 
    "other_authors": "Tadashi Takeuchi", 
    "title": "OS Debugging Method Using a Lightweight Virtual Machine Monitor", 
    "arxiv-id": "0710.4635v1", 
    "author": "Tadashi Takeuchi", 
    "publish": "2007-10-25T08:09:07Z", 
    "summary": "Demands for implementing original OSs that can achieve high I/O performance\non PC/AT compatible hardware have recently been increasing, but conventional OS\ndebugging environments have not been able to simultaneously assure their\nstability, be easily customized to new OSs and new I/O devices, and assure\nefficient execution of I/O operations. We therefore developed a novel OS\ndebugging method using a lightweight virtual machine. We evaluated this\ndebugging method experimentally and confirmed that it can transfer data about\n5.4 times as fast as the conventional virtual machine monitor."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0710.4746v1", 
    "other_authors": "M. Abdelsalam Hassan, Keishi Sakanushi, Yoshinori Takeuchi, Masaharu Imai", 
    "title": "RTK-Spec TRON: A Simulation Model of an ITRON Based RTOS Kernel in   SystemC", 
    "arxiv-id": "0710.4746v1", 
    "author": "Masaharu Imai", 
    "publish": "2007-10-25T09:47:35Z", 
    "summary": "This paper presents the methodology and the modeling constructs we have\ndeveloped to capture the real time aspects of RTOS simulation models in a\nSystem Level Design Language (SLDL) like SystemC. We describe these constructs\nand show how they are used to build a simulation model of an RTOS kernel\ntargeting the $\\mu$-ITRON OS specification standard."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0712.2958v2", 
    "other_authors": "Vincent N\u00e9lis, Jo\u00ebl Goossens, Nicolas Navet, Raymond Devillers, Dragomir Milojevic", 
    "title": "Power-Aware Real-Time Scheduling upon Identical Multiprocessor Platforms", 
    "arxiv-id": "0712.2958v2", 
    "author": "Dragomir Milojevic", 
    "publish": "2007-12-18T13:42:45Z", 
    "summary": "In this paper, we address the power-aware scheduling of sporadic\nconstrained-deadline hard real-time tasks using dynamic voltage scaling upon\nmultiprocessor platforms. We propose two distinct algorithms. Our first\nalgorithm is an off-line speed determination mechanism which provides an\nidentical speed for each processor. That speed guarantees that all deadlines\nare met if the jobs are scheduled using EDF. The second algorithm is an on-line\nand adaptive speed adjustment mechanism which reduces the energy consumption\nwhile the system is running."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0801.4292v1", 
    "other_authors": "Liliana Cucu, Jo\u00ebl Goossens", 
    "title": "Exact Feasibility Tests for Real-Time Scheduling of Periodic Tasks upon   Multiprocessor Platforms", 
    "arxiv-id": "0801.4292v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2008-01-28T14:30:34Z", 
    "summary": "In this paper we study the global scheduling of periodic task systems upon\nmultiprocessor platforms. We first show two very general properties which are\nwell-known for uniprocessor platforms and which remain for multiprocessor\nplatforms: (i) under few and not so restrictive assumptions, we show that\nfeasible schedules of periodic task systems are periodic from some point with a\nperiod equal to the least common multiple of task periods and (ii) for the\nspecific case of synchronous periodic task systems, we show that feasible\nschedules repeat from the origin. We then present our main result: we\ncharacterize, for task-level fixed-priority schedulers and for asynchronous\nconstrained or arbitrary deadline periodic task models, upper bounds of the\nfirst time instant where the schedule repeats. We show that job-level\nfixed-priority schedulers are predictable upon unrelated multiprocessor\nplatforms. For task-level fixed-priority schedulers, based on the upper bounds\nand the predictability property, we provide for asynchronous constrained or\narbitrary deadline periodic task sets, exact feasibility tests. Finally, for\nthe job-level fixed-priority EDF scheduler, for which such an upper bound\nremains unknown, we provide an exact feasibility test as well."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0805.0200v2", 
    "other_authors": "Jo\u00ebl Goossens", 
    "title": "(m,k)-firm constraints and DBP scheduling: impact of the initial   k-sequence and exact schedulability test", 
    "arxiv-id": "0805.0200v2", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2008-05-02T09:32:03Z", 
    "summary": "In this paper we study the scheduling of (m,k)-firm synchronous periodic task\nsystems using the Distance Based Priority (DBP) scheduler. We first show three\nphenomena: (i) choosing, for each task, the initial k-sequence 1^k is not\noptimal, (ii) we can even start the scheduling from a (fictive) error state (in\nregard to the initial k-sequence) and (iii) the period of feasible\nDBP-schedules is not necessarily the task hyper-period. We then show that any\nfeasible DBP-schedule is periodic and we upper-bound the length of that period.\nLastly, based on our periodicity result we provide an exact schedulability\ntest."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0805.3237v1", 
    "other_authors": "S. Collette, L. Cucu, J. Goossens", 
    "title": "Integrating Job Parallelism in Real-Time Scheduling Theory", 
    "arxiv-id": "0805.3237v1", 
    "author": "J. Goossens", 
    "publish": "2008-05-21T09:38:15Z", 
    "summary": "We investigate the global scheduling of sporadic, implicit deadline,\nreal-time task systems on multiprocessor platforms. We provide a task model\nwhich integrates job parallelism. We prove that the time-complexity of the\nfeasibility problem of these systems is linear relatively to the number of\n(sporadic) tasks for a fixed number of processors. We propose a scheduling\nalgorithm theoretically optimal (i.e., preemptions and migrations neglected).\nMoreover, we provide an exact feasibility utilization bound. Lastly, we propose\na technique to limit the number of migrations and preemptions."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0809.1132v1", 
    "other_authors": "Vandy Berten, Chi-Ju Chang, Tei-Wei Kuo", 
    "title": "Managing Varying Worst Case Execution Times on DVS Platforms", 
    "arxiv-id": "0809.1132v1", 
    "author": "Tei-Wei Kuo", 
    "publish": "2008-09-06T04:38:34Z", 
    "summary": "Energy efficient real-time task scheduling attracted a lot of attention in\nthe past decade. Most of the time, deterministic execution lengths for tasks\nwere considered, but this model fits less and less with the reality, especially\nwith the increasing number of multimedia applications. It's why a lot of\nresearch is starting to consider stochastic models, where execution times are\nonly known stochastically. However, authors consider that they have a pretty\nmuch precise knowledge about the properties of the system, especially regarding\nto the worst case execution time (or worst case execution cycles, WCEC).\n  In this work, we try to relax this hypothesis, and assume that the WCEC can\nvary. We propose miscellaneous methods to react to such a situation, and give\nmany simulation results attesting that with a small effort, we can provide very\ngood results, allowing to keep a low deadline miss rate as well as an energy\nconsumption similar to clairvoyant algorithms."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0809.4082v1", 
    "other_authors": "Vandy Berten, Jo\u00ebl Goossens", 
    "title": "Multiprocessor Global Scheduling on Frame-Based DVFS Systems", 
    "arxiv-id": "0809.4082v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2008-09-24T06:10:39Z", 
    "summary": "In this ongoing work, we are interested in multiprocessor energy efficient\nsystems, where task durations are not known in advance, but are know\nstochastically. More precisely, we consider global scheduling algorithms for\nframe-based multiprocessor stochastic DVFS (Dynamic Voltage and Frequency\nScaling) systems. Moreover, we consider processors with a discrete set of\navailable frequencies."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0809.5238v1", 
    "other_authors": "Vincent N\u00e9lis, Jo\u00ebl Goossens", 
    "title": "Mode Change Protocol for Multi-Mode Real-Time Systems upon Identical   Multiprocessors", 
    "arxiv-id": "0809.5238v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2008-09-30T15:55:04Z", 
    "summary": "In this paper, we propose a synchronous protocol without periodicity for\nscheduling multi-mode real-time systems upon identical multiprocessor\nplatforms. Our proposal can be considered to be a multiprocessor extension of\nthe uniprocessor protocol called \"Minimal Single Offset protocol\"."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0906.0268v1", 
    "other_authors": "Vincent Nelis, Joel Goossens", 
    "title": "MORA: an Energy-Aware Slack Reclamation Scheme for Scheduling Sporadic   Real-Time Tasks upon Multiprocessor Platforms", 
    "arxiv-id": "0906.0268v1", 
    "author": "Joel Goossens", 
    "publish": "2009-06-01T12:10:10Z", 
    "summary": "In this paper, we address the global and preemptive energy-aware scheduling\nproblem of sporadic constrained-deadline tasks on DVFS-identical multiprocessor\nplatforms. We propose an online slack reclamation scheme which profits from the\ndiscrepancy between the worst- and actual-case execution time of the tasks by\nslowing down the speed of the processors in order to save energy. Our algorithm\ncalled MORA takes into account the application-specific consumption profile of\nthe tasks. We demonstrate that MORA does not jeopardize the system\nschedulability and we show by performing simulations that it can save up to 32%\nof energy (in average) compared to execution without using any energy-aware\nalgorithm."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0908.3519v1", 
    "other_authors": "Liliana Cucu-Grosjean, Jo\u00ebl Goossens", 
    "title": "Predictability of Fixed-Job Priority Schedulers on Heterogeneous   Multiprocessor Real-Time Systems", 
    "arxiv-id": "0908.3519v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2009-08-25T12:46:56Z", 
    "summary": "The multiprocessor Fixed-Job Priority (FJP) scheduling of real-time systems\nis studied. An important property for the schedulability analysis, the\npredictability (regardless to the execution times), is studied for\nheterogeneous multiprocessor platforms. Our main contribution is to show that\nany FJP schedulers are predictable on unrelated platforms. A convenient\nconsequence is the fact that any FJP schedulers are predictable on uniform\nmultiprocessors."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0912.0606v1", 
    "other_authors": "C. Yaashuwanth, Dr. R. Ramesh", 
    "title": "A New Scheduling Algorithms For Real Time Tasks", 
    "arxiv-id": "0912.0606v1", 
    "author": "Dr. R. Ramesh", 
    "publish": "2009-12-03T09:06:59Z", 
    "summary": "The main objective of this paper is to develop the two different ways in\nwhich round robin architecture is modified and made suitable to be implemented\nin real time and embedded systems. The scheduling algorithm plays a significant\nrole in the design of real time embedded systems. Simple round robin\narchitecture is not efficient to be implemented in embedded systems because of\nhigher context switch rate, larger waiting time and larger response time.\nMissing of deadlines will degrade the system performance in soft real time\nsystems. The main objective of this paper is to develop the scheduling\nalgorithm which removes the drawbacks in simple round robin architecture. A\ncomparison with round robin architecture to the proposed architectures has been\nmade. It is observed that the proposed architectures solves the problems\nencountered in round robin architecture in soft real time by decreasing the\nnumber of context switches waiting time and response time thereby increasing\nthe system throughput."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/0912.0926v2", 
    "other_authors": "Amittai Aviram, Bryan Ford", 
    "title": "Deterministic Consistency: A Programming Model for Shared Memory   Parallelism", 
    "arxiv-id": "0912.0926v2", 
    "author": "Bryan Ford", 
    "publish": "2009-12-04T20:10:12Z", 
    "summary": "The difficulty of developing reliable parallel software is generating\ninterest in deterministic environments, where a given program and input can\nyield only one possible result. Languages or type systems can enforce\ndeterminism in new code, and runtime systems can impose synthetic schedules on\nlegacy parallel code. To parallelize existing serial code, however, we would\nlike a programming model that is naturally deterministic without language\nrestrictions or artificial scheduling. We propose \"deterministic consistency\",\na parallel programming model as easy to understand as the \"parallel assignment\"\nconstruct in sequential languages such as Perl and JavaScript, where concurrent\nthreads always read their inputs before writing shared outputs. DC supports\ncommon data- and task-parallel synchronization abstractions such as fork/join\nand barriers, as well as non-hierarchical structures such as producer/consumer\npipelines and futures. A preliminary prototype suggests that software-only\nimplementations of DC can run applications written for popular parallel\nenvironments such as OpenMP with low (<10%) overhead for some applications."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1001.3727v1", 
    "other_authors": "A. Christy Persya, T. R. Gopalakrishnan Nair", 
    "title": "Fault Tolerance in Real Time Multiprocessors - Embedded Systems", 
    "arxiv-id": "1001.3727v1", 
    "author": "T. R. Gopalakrishnan Nair", 
    "publish": "2010-01-21T06:02:41Z", 
    "summary": "All real time tasks which are termed as critical tasks by nature have to\ncomplete its execution before its deadline, even in presence of faults. The\nmost popularly used real time task assignment algorithms are First Fit (FF),\nBest Fit (BF), Bin Packing (BP).The common task scheduling algorithms are Rate\nMonotonic (RM), Earliest Deadline First (EDF) etc.All the current approaches\ndeal with either fault tolerance or criticality in real time. In this paper we\nhave proposed an integrated approach with a new algorithm, called SASA (Sorting\nAnd Sequential Assignment) which maps the real time task assignment with task\nschedule and fault tolerance"
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1003.1336v2", 
    "other_authors": "Peter Fornai, Antal Ivanyi", 
    "title": "FIFO anomaly is unbounded", 
    "arxiv-id": "1003.1336v2", 
    "author": "Antal Ivanyi", 
    "publish": "2010-03-05T20:34:44Z", 
    "summary": "Virtual memory of computers is usually implemented by demand paging. For some\npage replacement algorithms the number of page faults may increase as the\nnumber of page frames increases. Belady, Nelson and Shedler constructed\nreference strings for which page replacement algorithm FIFO produces near twice\nmore page faults in a larger memory than in a smaller one. They formulated the\nconjecture that 2 is a general bound. We prove that this ratio can be\narbitrarily large."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1003.4088v1", 
    "other_authors": "Richa Gupta, Sanjiv Tokekar", 
    "title": "Proficient Pair of Replacement Algorithms on L1 and L2 Cache for Merge   Sort", 
    "arxiv-id": "1003.4088v1", 
    "author": "Sanjiv Tokekar", 
    "publish": "2010-03-22T06:52:12Z", 
    "summary": "Memory hierarchy is used to compete the processors speed. Cache memory is the\nfast memory which is used to conduit the speed difference of memory and\nprocessor. The access patterns of Level 1 cache (L1) and Level 2 cache (L2) are\ndifferent, when CPU not gets the desired data in L1 then it accesses L2. Thus\nthe replacement algorithm which works efficiently on L1 may not be as efficient\non L2. Similarly various applications such as Matrix Multiplication, Web, Fast\nFourier Transform (FFT) etc will have varying access pattern. Thus same\nreplacement algorithm for all types of application may not be efficient. This\npaper works for getting an efficient pair of replacement algorithm on L1 and L2\nfor the algorithm Merge Sort. With the memory reference string of Merge Sort,\nwe have analyzed the behavior of various existing replacement algorithms on L1.\nThe existing replacement algorithms which are taken into consideration are:\nLeast Recently Used (LRU), Least Frequently Used (LFU) and First In First Out\n(FIFO). After Analyzing the memory reference pattern of Merge Sort, we have\nproposed a Partition Based Replacement algorithm (PBR_L1)) on L1 Cache.\nFurthermore we have analyzed various pairs of algorithms on L1 and L2\nrespectively, resulting in finding a suitable pair of replacement algorithms.\nSimulation on L1 shows, among the considered existing replacement algorithms\nFIFO is performing better than others. While the proposed replacement algorithm\nPBR_L1 is working about 1.7% to 44 % better than FIFO for various cache sizes."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1003.5525v1", 
    "other_authors": "C. A. Middelburg", 
    "title": "Searching publications on operating systems", 
    "arxiv-id": "1003.5525v1", 
    "author": "C. A. Middelburg", 
    "publish": "2010-03-29T12:51:23Z", 
    "summary": "This note concerns a search for publications in which one can find statements\nthat explain the concept of an operating system, reasons for introducing\noperating systems, a formalization of the concept of an operating system or\ntheory about operating systems based on such a formalization. It reports on the\nway in which the search has been carried out and the outcome of the search. The\noutcome includes not only what the search was meant for, but also some added\nbonuses."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1004.3687v1", 
    "other_authors": "Patrick Meumeu Yomsi, Vincent Nelis, Jo\u00ebl Goossens", 
    "title": "Scheduling Multi-Mode Real-Time Systems upon Uniform Multiprocessor   Platforms", 
    "arxiv-id": "1004.3687v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2010-04-21T12:31:53Z", 
    "summary": "In this paper, we address the scheduling problem of multi-mode real-time\nsystems upon uniform multiprocessor platforms. We propose two transition\nprotocols, specified together with their schedulability test, and provide the\nreader with two distinct upper bounds for the length of the transient phases\nduring mode transitions, respectively for the cases where jobs priorities are\nknown and unknown beforehand."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1004.3715v1", 
    "other_authors": "Irina Lupu, Pierre Courbin, Laurent George, Jo\u00ebl Goossens", 
    "title": "Multi-Criteria Evaluation of Partitioning Schemes for Real-Time Systems", 
    "arxiv-id": "1004.3715v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2010-04-21T14:24:13Z", 
    "summary": "In this paper we study the partitioning approach for multiprocessor real-time\nscheduling. This approach seems to be the easiest since, once the partitioning\nof the task set has been done, the problem reduces to well understood\nuniprocessor issues. Meanwhile, there is no optimal and polynomial solution to\npartition tasks on processors. In this paper we analyze partitioning algorithms\nfrom several points of view such that for a given task set and specific\nconstraints (processor number, task set type, etc.) we should be able to\nidentify the best heuristic and the best schedulability test. We also analyze\nthe influence of the heuristics on the performance of the uniprocessor tests\nand the impact of a specific task order on the schedulability. A study on\nperformance difference between Fixed Priority schedulers and EDF in the case of\npartitioning scheduling is also considered."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1006.0813v1", 
    "other_authors": "J. A. Bergstra, C. A. Middelburg", 
    "title": "On the definition of a theoretical concept of an operating system", 
    "arxiv-id": "1006.0813v1", 
    "author": "C. A. Middelburg", 
    "publish": "2010-06-04T09:03:39Z", 
    "summary": "We dwell on how a definition of a theoretical concept of an operating system,\nsuitable to be incorporated in a mathematical theory of operating systems,\ncould look like. This is considered a valuable preparation for the development\nof a mathematical theory of operating systems."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1006.2104v1", 
    "other_authors": "Spits Warnars H. L. H", 
    "title": "Perbandingan Shell Unix", 
    "arxiv-id": "1006.2104v1", 
    "author": "Spits Warnars H. L. H", 
    "publish": "2010-06-10T18:13:36Z", 
    "summary": "Is it possible for an Information Technology [IT] product to be both mature\nand state-of-theart at the same time? In the case of the UNIX system, the\nanswer is an unqualified \"Yes.\" The UNIX system has continued to develop over\nthe past twenty-five years. In millions of installations running on nearly\nevery hardware platform made, the UNIX system has earned its reputation for\nstability and scalability. Over the years, UNIX system suppliers have steadily\nassimilated new technologies so that UNIX systems today provide more\nfunctionality as any other operating system."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1006.2617v1", 
    "other_authors": "Jo\u00ebl Goossens, Vandy Berten", 
    "title": "Gang FTP scheduling of periodic and parallel rigid real-time tasks", 
    "arxiv-id": "1006.2617v1", 
    "author": "Vandy Berten", 
    "publish": "2010-06-14T07:17:14Z", 
    "summary": "In this paper we consider the scheduling of periodic and parallel rigid\ntasks. We provide (and prove correct) an exact schedulability test for Fixed\nTask Priority (FTP) Gang scheduler sub-classes: Parallelism Monotonic, Idling,\nLimited Gang, and Limited Slack Reclaiming. Additionally, we study the\npredictability of our schedulers: we show that Gang FJP schedulers are not\npredictable and we identify several sub-classes which are actually predictable.\nMoreover, we extend the definition of rigid, moldable and malleable jobs to\nrecurrent tasks."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1006.2637v1", 
    "other_authors": "Fran\u00e7ois Dorin, Patrick Meumeu Yomsi, Jo\u00ebl Goossens, Pascal Richard", 
    "title": "Semi-Partitioned Hard Real-Time Scheduling with Restricted Migrations   upon Identical Multiprocessor Platforms", 
    "arxiv-id": "1006.2637v1", 
    "author": "Pascal Richard", 
    "publish": "2010-06-14T08:51:05Z", 
    "summary": "Algorithms based on semi-partitioned scheduling have been proposed as a\nviable alternative between the two extreme ones based on global and partitioned\nscheduling. In particular, allowing migration to occur only for few tasks which\ncannot be assigned to any individual processor, while most tasks are assigned\nto specific processors, considerably reduces the runtime overhead compared to\nglobal scheduling on the one hand, and improve both the schedulability and the\nsystem utilization factor compared to partitioned scheduling on the other hand.\nIn this paper, we address the preemptive scheduling problem of hard real-time\nsystems composed of sporadic constrained-deadline tasks upon identical\nmultiprocessor platforms. We propose a new algorithm and a scheduling paradigm\nbased on the concept of semi-partitioned scheduling with restricted migrations\nin which jobs are not allowed to migrate, but two subsequent jobs of a task can\nbe assigned to different processors by following a periodic strategy."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1011.1735v1", 
    "other_authors": "George Anderson, Tshilidzi Marwala, Fulufhelo V. Nelwamondo", 
    "title": "Use of Data Mining in Scheduler Optimization", 
    "arxiv-id": "1011.1735v1", 
    "author": "Fulufhelo V. Nelwamondo", 
    "publish": "2010-11-08T09:07:54Z", 
    "summary": "The operating system's role in a computer system is to manage the various\nresources. One of these resources is the Central Processing Unit. It is managed\nby a component of the operating system called the CPU scheduler. Schedulers are\noptimized for typical workloads expected to run on the platform. However, a\nsingle scheduler may not be appropriate for all workloads. That is, a scheduler\nmay schedule a workload such that the completion time is minimized, but when\nanother type of workload is run on the platform, scheduling and therefore\ncompletion time will not be optimal; a different scheduling algorithm, or a\ndifferent set of parameters, may work better. Several approaches to solving\nthis problem have been proposed. The objective of this survey is to summarize\nthe approaches based on data mining, which are available in the literature. In\naddition to solutions that can be directly utilized for solving this problem,\nwe are interested in data mining research in related areas that have potential\nfor use in operating system scheduling. We also explain general technical\nissues involved in scheduling in modern computers, including parallel\nscheduling issues related to multi-core CPUs. We propose a taxonomy that\nclassifies the scheduling approaches we discuss into different categories."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1101.1466v1", 
    "other_authors": "Sudipta Das, Lawrence Jenkins, Debasis Sengupta", 
    "title": "Comparison of Loss ratios of different scheduling algorithms", 
    "arxiv-id": "1101.1466v1", 
    "author": "Debasis Sengupta", 
    "publish": "2011-01-06T10:28:58Z", 
    "summary": "It is well known that in a firm real time system with a renewal arrival\nprocess, exponential service times and independent and identically distributed\ndeadlines till the end of service of a job, the earliest deadline first (EDF)\nscheduling policy has smaller loss ratio (expected fraction of jobs, not\ncompleted) than any other service time independent scheduling policy, including\nthe first come first served (FCFS). Various modifications to the EDF and FCFS\npolicies have been proposed in the literature, with a view to improving\nperformance. In this article, we compare the loss ratios of these two policies\nalong with some of the said modifications, as well as their counterparts with\ndeterministic deadlines. The results include some formal inequalities and some\ncounter-examples to establish non-existence of an order. A few relations\ninvolving loss ratios are posed as conjectures, and simulation results in\nsupport of these are reported. These results lead to a complete picture of\ndominance and non-dominance relations between pairs of scheduling policies, in\nterms of loss ratios."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1102.2094v1", 
    "other_authors": "Vincent Nelis, Patrick Meumeu Yomsi, Bj\u00f6rn Andersson, Jo\u00ebl Goossens", 
    "title": "Global Scheduling of Multi-Mode Real-Time Applications upon   Multiprocessor Platforms", 
    "arxiv-id": "1102.2094v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2011-02-10T12:15:58Z", 
    "summary": "Multi-mode real-time systems are those which support applications with\ndifferent modes of operation, where each mode is characterized by a specific\nset of tasks. At run-time, such systems can, at any time, be requested to\nswitch from its current operating mode to another mode (called \"new mode\") by\nreplacing the current set of tasks with that of the new-mode. Thereby, ensuring\nthat all the timing requirements are met not only requires that a\nschedulability test is performed on the tasks of each mode but also that (i) a\nprotocol for transitioning from one mode to another is specified and (ii) a\nschedulability test for each transition is performed. We propose two distinct\nprotocols that manage the mode transitions upon uniform and identical\nmultiprocessor platforms at run-time, each specific to distinct task\nrequirements. For each protocol, we formally establish schedulability analyses\nthat indicate beforehand whether all the timing requirements will be met during\nany mode transition of the system. This is performed assuming both\nFixed-Task-Priority and Fixed-Job-Priority schedulers."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1103.1717v1", 
    "other_authors": "Matthieu Moy", 
    "title": "Efficient and Playful Tools to Teach Unix to New Students", 
    "arxiv-id": "1103.1717v1", 
    "author": "Matthieu Moy", 
    "publish": "2011-03-09T07:25:00Z", 
    "summary": "Teaching Unix to new students is a common tasks in many higher schools. This\npaper presents an approach to such course where the students progress\nautonomously with the help of the teacher. The traditional textbook is\ncomplemented with a wiki, and the main thread of the course is a game, in the\nform of a treasure hunt. The course finishes with a lab exam, where students\nhave to perform practical manipulations similar to the ones performed during\nthe treasure hunt. The exam is graded fully automatically. This paper discusses\nthe motivations and advantages of the approach, and gives an overall view of\nthe tools we developed. The tools are available from the web, and open-source,\nhence re-usable outside the Ensimag."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1103.2336v1", 
    "other_authors": "Nabil Litayem, Ahmed Ben Achballah, Slim Ben Saoud", 
    "title": "Building XenoBuntu Linux Distribution for Teaching and Prototyping   Real-Time Operating Systems", 
    "arxiv-id": "1103.2336v1", 
    "author": "Slim Ben Saoud", 
    "publish": "2011-03-11T18:36:38Z", 
    "summary": "This paper describes the realization of a new Linux distribution based on\nUbuntu Linux and Xenomai Real-Time framework. This realization is motivated by\nthe eminent need of real-time systems in modern computer science courses. The\nmajority of the technical choices are made after qualitative comparison. The\nmain goal of this distribution is to offer standard Operating Systems (OS) that\ninclude Xenomai infrastructure and the essential tools to begin hard real-time\napplication development inside a convivial desktop environment. The released\nlive/installable DVD can be adopted to emulate several classic RTOS Application\nProgram Interfaces (APIs), directly use and understand real-time Linux in\nconvivial desktop environment and prototyping real-time embedded applications."
},{
    "category": "cs.OS", 
    "doi": "10.1093/comjnl/bxl044", 
    "link": "http://arxiv.org/pdf/1103.3831v1", 
    "other_authors": "H. S. Behera, Rakesh Mohanty, Debashree Nayak", 
    "title": "A New Proposed Dynamic Quantum with Re-Adjusted Round Robin Scheduling   Algorithm and Its Performance Analysis", 
    "arxiv-id": "1103.3831v1", 
    "author": "Debashree Nayak", 
    "publish": "2011-03-20T06:45:16Z", 
    "summary": "Scheduling is the central concept used frequently in Operating System. It\nhelps in choosing the processes for execution. Round Robin (RR) is one of the\nmost widely used CPU scheduling algorithm. But, its performance degrades with\nrespect to context switching, which is an overhead and it occurs during each\nscheduling. Overall performance of the system depends on choice of an optimal\ntime quantum, so that context switching can be reduced. In this paper, we have\nproposed a new variant of RR scheduling algorithm, known as Dynamic Quantum\nwith Readjusted Round Robin (DQRRR) algorithm. We have experimentally shown\nthat performance of DQRRR is better than RR by reducing number of context\nswitching, average waiting time and average turn around time."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1103.3832v1", 
    "other_authors": "H. S. Behera, Simpi Patel, Bijayalakshmi Panda", 
    "title": "A New Dynamic Round Robin and SRTN Algorithm with Variable Original Time   Slice and Intelligent Time Slice for Soft Real Time Systems", 
    "arxiv-id": "1103.3832v1", 
    "author": "Bijayalakshmi Panda", 
    "publish": "2011-03-20T06:56:27Z", 
    "summary": "The main objective of the paper is to improve the Round Robin (RR) algorithm\nusing dynamic ITS by coalescing it with Shortest Remaining Time Next (SRTN)\nalgorithm thus reducing the average waiting time, average turnaround time and\nthe number of context switches. The original time slice has been calculated for\neach process based on its burst time.This is mostly suited for soft real time\nsystems where meeting of deadlines is desirable to increase its performance.\nThe advantage is that processes that are closer to their remaining completion\ntime will get more chances to execute and leave the ready queue. This will\nreduce the number of processes in the ready queue by knocking out short jobs\nrelatively faster in a hope to reduce the average waiting time, turn around\ntime and number of context switches. This paper improves the algorithm [8] and\nthe experimental analysis shows that the proposed algorithm performs better\nthan algorithm [6] and [8] when the processes are having an increasing order,\ndecreasing order and random order of burst time."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1105.1736v1", 
    "other_authors": "Rakesh Mohanty, H. S. Behera, Khusbu Patwari, Monisha Dash, M. Lakshmi Prasanna", 
    "title": "Priority Based Dynamic Round Robin (PBDRR) Algorithm with Intelligent   Time Slice for Soft Real Time Systems", 
    "arxiv-id": "1105.1736v1", 
    "author": "M. Lakshmi Prasanna", 
    "publish": "2011-05-09T17:29:03Z", 
    "summary": "In this paper, a new variant of Round Robin (RR) algorithm is proposed which\nis suitable for soft real time systems. RR algorithm performs optimally in\ntimeshared systems, but it is not suitable for soft real time systems. Because\nit gives more number of context switches, larger waiting time and larger\nresponse time. We have proposed a novel algorithm, known as Priority Based\nDynamic Round Robin Algorithm(PBDRR),which calculates intelligent time slice\nfor individual processes and changes after every round of execution. The\nproposed scheduling algorithm is developed by taking dynamic time quantum\nconcept into account. Our experimental results show that our proposed algorithm\nperforms better than algorithm in [8] in terms of reducing the number of\ncontext switches, average waiting time and average turnaround time."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1105.5080v1", 
    "other_authors": "Irina Iulia Lupu, Jo\u00ebl Goossens", 
    "title": "Scheduling of Hard Real-Time Multi-Thread Periodic Tasks", 
    "arxiv-id": "1105.5080v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2011-05-25T16:15:35Z", 
    "summary": "In this paper we study the scheduling of parallel and real-time recurrent\ntasks. Firstly, we propose a new parallel task model which allows recurrent\ntasks to be composed of several threads, each thread requires a single\nprocessor for execution and can be scheduled simultaneously. Secondly, we\ndefine several kinds of real-time schedulers that can be applied to our\nparallel task model. We distinguish between two scheduling classes:\nhierarchical schedulers and global thread schedulers. We present and prove\ncorrect an exact schedulability test for each class. Lastly, we also evaluate\nthe performance of our scheduling paradigm in comparison with Gang scheduling\nby means of simulations."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1110.5793v1", 
    "other_authors": "Vandy Berten, Jo\u00ebl Goossens", 
    "title": "Sufficient FTP Schedulability Test for the Non-Cyclic Generalized   Multiframe Task Model", 
    "arxiv-id": "1110.5793v1", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2011-10-26T13:53:41Z", 
    "summary": "Our goal is to provide a sufficient schedulability test -ideally polynomial-\nfor the scheduling of Non-Cyclic Generalized Multiframe Task Model using\nFixed-Task-Priority schedulers. We report two first results: (i) we present and\nprove correct the critical instant for the Non-Cyclic Generalized Multiframe\nTask Model then (ii) we propose an algorithm which provides a sufficient (but\npseudo-polynomial) schedulability test."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1112.4451v2", 
    "other_authors": "Abhijat Vichare", 
    "title": "What is an OS?", 
    "arxiv-id": "1112.4451v2", 
    "author": "Abhijat Vichare", 
    "publish": "2011-12-19T20:07:54Z", 
    "summary": "While the engineering of operating systems is well understood, their formal\nstructure and properties are not. The latter needs a clear definition of the\npurpose of an OS and an identification of the core. In this paper I offer\ndefinitions of the OS, processes and files, and present a few useful\nprinciples. The principles allow us to identify work like closure and\ncontinuation algorithms, in programming languages that is useful for the OS\nproblem. The definitions and principles should yield a symbolic, albeit\nsemiquantitative, framework that encompasses practice. Towards that end I\nspecialise the definitions to describe conventional OSes and identify the core\noperations for a single computer OS that can be used to express their\nalgorithms. The assumptions underlying the algorithms offer the design space\nframework. The paging and segmentation algorithms for conventional OSes are\nextracted from the framework as a check. Among the insights the emerge is that\nan OS is a constructive proof of equivalence between models of computation.\nClear and useful definitions and principles are the first step towards a fully\nquantitative structure of an OS."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1112.5136v1", 
    "other_authors": "Ye Li, Matthew Danish, Richard West", 
    "title": "Quest-V: A Virtualized Multikernel for High-Confidence Systems", 
    "arxiv-id": "1112.5136v1", 
    "author": "Richard West", 
    "publish": "2011-12-21T19:02:12Z", 
    "summary": "This paper outlines the design of `Quest-V', which is implemented as a\ncollection of separate kernels operating together as a distributed system on a\nchip. Quest-V uses virtualization techniques to isolate kernels and prevent\nlocal faults from affecting remote kernels. This leads to a high-confidence\nmultikernel approach, where failures of system subcomponents do not render the\nentire system inoperable. A virtual machine monitor for each kernel keeps track\nof shadow page table mappings that control immutable memory access\ncapabilities. This ensures a level of security and fault tolerance in\nsituations where a service in one kernel fails, or is corrupted by a malicious\nattack. Communication is supported between kernels using shared memory regions\nfor message passing. Similarly, device driver data structures are shareable\nbetween kernels to avoid the need for complex I/O virtualization, or\ncommunication with a dedicated kernel responsible for I/O. In Quest-V, device\ninterrupts are delivered directly to a kernel, rather than via a monitor that\ndetermines the destination. Apart from bootstrapping each kernel, handling\nfaults and managing shadow page tables, the monitors are not needed. This\ndiffers from conventional virtual machine systems in which a central monitor,\nor hypervisor, is responsible for scheduling and management of host resources\namongst a set of guest kernels. In this paper we show how Quest-V can implement\nnovel fault isolation and recovery techniques that are not possible with\nconventional systems. We also show how the costs of using virtualization for\nisolation of system services does not add undue overheads to the overall system\nperformance."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1302.1747v1", 
    "other_authors": "Nathan Fisher, Jo\u00ebl Goossens, Pradeep M. Hettiarachchi, Antonio Paolillo", 
    "title": "Energy Minimization for Parallel Real-Time Systems with Malleable Jobs   and Homogeneous Frequencies", 
    "arxiv-id": "1302.1747v1", 
    "author": "Antonio Paolillo", 
    "publish": "2013-02-07T13:52:09Z", 
    "summary": "In this work, we investigate the potential utility of parallelization for\nmeeting real-time constraints and minimizing energy. We consider malleable Gang\nscheduling of implicit-deadline sporadic tasks upon multiprocessors. We first\nshow the non-necessity of dynamic voltage/frequency regarding optimality of our\nscheduling problem. We adapt the canonical schedule for DVFS multiprocessor\nplatforms and propose a polynomial-time optimal processor/frequency-selection\nalgorithm. We evaluate the performance of our algorithm via simulations using\nparameters obtained from a hardware testbed implementation. Our algorithm has\nup to a 60 watt decrease in power consumption over the optimal non-parallel\napproach."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1302.5109v1", 
    "other_authors": "Marco Sironi, Francesco Tisato", 
    "title": "Capturing Information Flows inside Android and Qemu Environments", 
    "arxiv-id": "1302.5109v1", 
    "author": "Francesco Tisato", 
    "publish": "2013-02-20T15:50:29Z", 
    "summary": "The smartphone market has grown so wide that it assumed a strategic\nrelevance. Today the most common smartphone OSs are Google's Android and\nApple's iOS. The former is particularly interesting due to its open source\nnature, that allows everyone to deeply inspect every aspect of the OS. Android\nsource code is also bundled with an hardware emulator, based on the open source\nsoftware Qemu, that allows the user to run the Android OS without the need of a\nphysical device. We first present a procedure to extract information flows from\na generic system. We then focus on Android and Qemu architectures and their\nlogging infrastructures. Finally, we detail what happens inside an Android\ndevice in a particular scenario: the system boot."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1302.5502v1", 
    "other_authors": "Srimugunthan, K. Gopinath, Giridhar Appaji Nag Yasa", 
    "title": "LFTL: A multi-threaded FTL for a Parallel IO Flash Card under Linux", 
    "arxiv-id": "1302.5502v1", 
    "author": "Giridhar Appaji Nag Yasa", 
    "publish": "2013-02-22T07:32:48Z", 
    "summary": "New PCI-e flash cards and SSDs supporting over 100,000 IOPs are now\navailable, with several usecases in the design of a high performance storage\nsystem. By using an array of flash chips, arranged in multiple banks, large\ncapacities are achieved. Such multi-banked architecture allow parallel read,\nwrite and erase operations. In a raw PCI-e flash card, such parallelism is\ndirectly available to the software layer. In addition, the devices have\nrestrictions such as, pages within a block can only be written sequentially.\nThe devices also have larger minimum write sizes (greater than 4KB). Current\nflash translation layers (FTLs) in Linux are not well suited for such devices\ndue to the high device speeds, architectural restrictions as well as other\nfactors such as high lock contention. We present a FTL for Linux that takes\ninto account the hardware restrictions, that also exploits the parallelism to\nachieve high speeds. We also consider leveraging the parallelism for garbage\ncollection by scheduling the garbage collection activities on idle banks. We\npropose and evaluate an adaptive method to vary the amount of garbage\ncollection according to the current I/O load on the device."
},{
    "category": "cs.OS", 
    "doi": "10.5120/2037-2648", 
    "link": "http://arxiv.org/pdf/1308.1199v1", 
    "other_authors": "Abhijat Vichare", 
    "title": "Intensional view of General Single Processor Operating Systems", 
    "arxiv-id": "1308.1199v1", 
    "author": "Abhijat Vichare", 
    "publish": "2013-08-06T07:54:19Z", 
    "summary": "Operating systems are currently viewed ostensively. As a result they mean\ndifferent things to different people. The ostensive character makes it is hard\nto understand OSes formally. An intensional view can enable better formal work,\nand also offer constructive support for some important problems, e.g. OS\narchitecture. This work argues for an intensional view of operating systems. It\nproposes to overcome the current ostensive view by defining an OS based on\nformal models of computation, and also introduces some principles. Together\nthese are used to develop a framework of algorithms of single processor OS\nstructure using an approach similar to function level programming. In this\nabridged paper we illustrate the essential approach, discuss some advantages\nand limitations and point out some future possibilities."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1402.0631v1", 
    "other_authors": "S. R. Bhalgama, C. C. Kavar, S. S. Parmar", 
    "title": "LWRP: Low Power Consumption Weighting Replacement Policy using Buffer   Memory", 
    "arxiv-id": "1402.0631v1", 
    "author": "S. S. Parmar", 
    "publish": "2014-02-04T06:26:34Z", 
    "summary": "As the performance gap between memory and processors has increased, then it\nleads to the poor performance. Efficient virtual memory can overcome this\nproblem. And the efficiency of virtual memory depends on the replacement policy\nused for cache. In this paper, our algorithm not only based on the time to last\naccess and frequency index but, we also consider the power consumption. We show\nthat Low Power Consumption Weighting Replacement Policy (LWRP) has better\nperformance and low power consumption."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1402.4929v1", 
    "other_authors": "Asen Petkov Iliev", 
    "title": "Formal Description of Components in Operating Systems", 
    "arxiv-id": "1402.4929v1", 
    "author": "Asen Petkov Iliev", 
    "publish": "2014-02-20T08:33:02Z", 
    "summary": "The contemporary development of hardware components is a prerequisite for\nincreasing the concentration of computing power. System software is developing\nat a much slower pace. To use available resources efficiently modeling is\nrequired. Formalization of elements, present in the material, provides the\nbasis for modeling. Examples are presented to demonstrate the efficiency of the\nconcept."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1104.3523v1", 
    "other_authors": "Paul Regnier, George Lima, Ernesto Massa", 
    "title": "An Optimal Real-Time Scheduling Approach: From Multiprocessor to   Uniprocessor", 
    "arxiv-id": "1104.3523v1", 
    "author": "Ernesto Massa", 
    "publish": "2011-04-18T15:39:21Z", 
    "summary": "An optimal solution to the problem of scheduling real-time tasks on a set of\nidentical processors is derived. The described approach is based on solving an\nequivalent uniprocessor real-time scheduling problem. Although there are other\nscheduling algorithms that achieve optimality, they usually impose prohibitive\npreemption costs. Unlike these algorithms, it is observed through simulation\nthat the proposed approach produces no more than three preemptions points per\njob."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1204.0197v1", 
    "other_authors": "Youssef Bassil", 
    "title": "Windows And Linux Operating Systems From A Security Perspective", 
    "arxiv-id": "1204.0197v1", 
    "author": "Youssef Bassil", 
    "publish": "2012-04-01T11:05:34Z", 
    "summary": "Operating systems are vital system software that, without them, humans would\nnot be able to manage and use computer systems. In essence, an operating system\nis a collection of software programs whose role is to manage computer resources\nand provide an interface for client applications to interact with the different\ncomputer hardware. Most of the commercial operating systems available today on\nthe market have buggy code and they exhibit security flaws and vulnerabilities.\nIn effect, building a trusted operating system that can mostly resist attacks\nand provide a secure computing environment to protect the important assets of a\ncomputer is the goal of every operating system manufacturer. This paper deeply\ninvestigates the various security features of the two most widespread and\nsuccessful operating systems, Microsoft Windows and Linux. The different\nsecurity features, designs, and components of the two systems are to be covered\nelaborately, pin-pointing the key similarities and differences between them. In\ndue course, a head-to-head comparison is to be drawn for each security aspect,\nexposing the advantage of one system over the other."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1207.1591v1", 
    "other_authors": "P. Radha Krishna Reddy, Ashim Roy, G. Sireesha, Ismatha Begum, S. Siva Ramaiah", 
    "title": "A Secure Dynamic Job Scheduling on Smart Grid using RSA Algorithm", 
    "arxiv-id": "1207.1591v1", 
    "author": "S. Siva Ramaiah", 
    "publish": "2012-07-06T11:48:24Z", 
    "summary": "Grid computing is a computation methodology using group of clusters connected\nover high-speed networks that involves coordinating and sharing computational\npower, data storage and network resources. Integrating a set of clusters of\nworkstations into one large computing environment can improve the availability\nof computing power. The goal of scheduling is to achieve highest possible\nsystem throughput and to match the application need with the available\ncomputing resources. A secure scheduling model is presented, that performs job\ngrouping activity at runtime. In a Grid environment, security is necessary\nbecause grid is a dynamic environment and participates are independent bodies\nwith different policies, objectives and requirements. Authentication should be\nverified for Grid resource owners as well as resource requesters before they\nare allowed to join in scheduling activities. In order to achieve secure\nresource and job scheduling including minimum processing time and maximum\nresource utilization, A Secure Resource by using RSA algorithm on Networking\nand Job Scheduling model with Job Grouping strategy(JGS) in Grid Computing has\nbeen proposed. The result shows significant improvement in the processing time\nof jobs and resource utilization as compared to dynamic job grouping (DJG)\nbased scheduling on smart grids (SG)."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1307.4165v1", 
    "other_authors": "Neetu Goel, R. B. Garg", 
    "title": "A Comparative Study of CPU Scheduling Algorithms", 
    "arxiv-id": "1307.4165v1", 
    "author": "R. B. Garg", 
    "publish": "2013-07-16T05:21:34Z", 
    "summary": "Developing CPU scheduling algorithms and understanding their impact in\npractice can be difficult and time consuming due to the need to modify and test\noperating system kernel code and measure the resulting performance on a\nconsistent workload of real applications. As processor is the important\nresource, CPU scheduling becomes very important in accomplishing the operating\nsystem (OS) design goals. The intention should be allowed as many as possible\nrunning processes at all time in order to make best use of CPU. This paper\npresents a state diagram that depicts the comparative study of various\nscheduling algorithms for a single CPU and shows which algorithm is best for\nthe particular situation. Using this representation, it becomes much easier to\nunderstand what is going on inside the system and why a different set of\nprocesses is a candidate for the allocation of the CPU at different time. The\nobjective of the study is to analyze the high efficient CPU scheduler on design\nof the high quality scheduling algorithms which suits the scheduling goals. Key\nWords:-Scheduler, State Diagrams, CPU-Scheduling, Performance"
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1307.4167v1", 
    "other_authors": "Neetu Goel, R. B. Garg", 
    "title": "An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm", 
    "arxiv-id": "1307.4167v1", 
    "author": "R. B. Garg", 
    "publish": "2013-07-16T05:25:16Z", 
    "summary": "The main objective of this paper is to improve the Round Robin scheduling\nalgorithm using the dynamic time slice concept. CPU scheduling becomes very\nimportant in accomplishing the operating system (OS) design goals. The\nintention should be allowed as many as possible running processes at all time\nin order to make best use of CPU. CPU scheduling has strong effect on resource\nutilization as well as overall performance of the system. Round Robin algorithm\nperforms optimally in time-shared systems, but it is not suitable for soft real\ntime systems, because it gives more number of context switches, larger waiting\ntime and larger response time. In this paper, a new CPU scheduling algorithm\ncalled An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm is\nproposed, which calculates intelligent time slice and changes after every round\nof execution. The suggested algorithm was evaluated on some CPU scheduling\nobjectives and it was observed that this algorithm gave good performance as\ncompared to the other existing CPU scheduling algorithms."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/0803.4308v2", 
    "other_authors": "Vandy Berten, Chi-Ju Chang, Tei-Wei Kuo", 
    "title": "Discrete Frequency Selection of Frame-Based Stochastic Real-Time Tasks", 
    "arxiv-id": "0803.4308v2", 
    "author": "Tei-Wei Kuo", 
    "publish": "2008-03-30T09:26:38Z", 
    "summary": "Energy-efficient real-time task scheduling has been actively explored in the\npast decade. Different from the past work, this paper considers schedulability\nconditions for stochastic real-time tasks. A schedulability condition is first\npresented for frame-based stochastic real-time tasks, and several algorithms\nare also examined to check the schedulability of a given strategy. An approach\nis then proposed based on the schedulability condition to adapt a\ncontinuous-speed-based method to a discrete-speed system. The approach is able\nto stay as close as possible to the continuous-speed-based method, but still\nguaranteeing the schedulability. It is shown by simulations that the energy\nsaving can be more than 20% for some system configurations"
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/0806.0132v1", 
    "other_authors": "Feng Xia, Yu-Chu Tian, Youxian Sun, Jinxiang Dong", 
    "title": "Control-theoretic dynamic voltage scaling for embedded controllers", 
    "arxiv-id": "0806.0132v1", 
    "author": "Jinxiang Dong", 
    "publish": "2008-06-01T08:30:10Z", 
    "summary": "For microprocessors used in real-time embedded systems, minimizing power\nconsumption is difficult due to the timing constraints. Dynamic voltage scaling\n(DVS) has been incorporated into modern microprocessors as a promising\ntechnique for exploring the trade-off between energy consumption and system\nperformance. However, it remains a challenge to realize the potential of DVS in\nunpredictable environments where the system workload cannot be accurately\nknown. Addressing system-level power-aware design for DVS-enabled embedded\ncontrollers, this paper establishes an analytical model for the DVS system that\nencompasses multiple real-time control tasks. From this model, a feedback\ncontrol based approach to power management is developed to reduce dynamic power\nconsumption while achieving good application performance. With this approach,\nthe unpredictability and variability of task execution times can be attacked.\nThanks to the use of feedback control theory, predictable performance of the\nDVS system is achieved, which is favorable to real-time applications. Extensive\nsimulations are conducted to evaluate the performance of the proposed approach."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/0806.1381v1", 
    "other_authors": "Feng Xia, Guosong Tian, Youxian Sun", 
    "title": "Feedback Scheduling: An Event-Driven Paradigm", 
    "arxiv-id": "0806.1381v1", 
    "author": "Youxian Sun", 
    "publish": "2008-06-09T07:23:28Z", 
    "summary": "Embedded computing systems today increasingly feature resource constraints\nand workload variability, which lead to uncertainty in resource availability.\nThis raises great challenges to software design and programming in multitasking\nenvironments. In this paper, the emerging methodology of feedback scheduling is\nintroduced to address these challenges. As a closed-loop approach to resource\nmanagement, feedback scheduling promises to enhance the flexibility and\nresource efficiency of various software programs through dynamically\ndistributing available resources among concurrent tasks based on feedback\ninformation about the actual usage of the resources. With emphasis on the\nbehavioral design of feedback schedulers, we describe a general framework of\nfeedback scheduling in the context of real-time control applications. A simple\nyet illustrative feedback scheduling algorithm is given. From a programming\nperspective, we describe how to modify the implementation of control tasks to\nfacilitate the application of feedback scheduling. An event-driven paradigm\nthat combines time-triggered and event-triggered approaches is proposed for\nprogramming of the feedback scheduler. Simulation results argue that the\nproposed event-driven paradigm yields better performance than time-triggered\nparadigm in dynamic environments where the workload varies irregularly and\nunpredictably."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1012.2831v2", 
    "other_authors": "Mian Dong, Lin Zhong", 
    "title": "Sesame: Self-Constructive System Energy Modeling for Battery-Powered   Mobile Systems", 
    "arxiv-id": "1012.2831v2", 
    "author": "Lin Zhong", 
    "publish": "2010-12-13T18:47:10Z", 
    "summary": "System energy models are important for energy optimization and management in\nmobile systems. However, existing system energy models are built in lab with\nthe help from a second computer. Not only are they labor-intensive; but also\nthey will not adequately account for the great diversity in the hardware and\nusage of mobile systems. Moreover, existing system energy models are intended\nfor energy estimation for time intervals of one second or longer; they do not\nprovide the required rate for fine-grain use such as per-application energy\naccounting.\n  In this work, we study a self-modeling paradigm in which a mobile system\nautomatically generates its energy model without any external assistance. Our\nsolution, Se-same, leverages the possibility of self power measurement through\nthe smart battery interface and employs a suite of novel techniques to achieve\naccuracy and rate much higher than that of the smart battery interface.\n  We report the implementation and evaluation of Se-same on a laptop and a\nsmartphone. The experiment results show that Sesame generates system energy\nmodels of 95% accuracy at one estimation per second and 88% accuracy at one\nestimation per 10ms, without any external assistance. A five-day field studies\nwith four laptop and four smartphones users further demonstrate the\neffectiveness, efficiency, and noninvasiveness of Sesame."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1012.3452v1", 
    "other_authors": "Mohammad R Nikseresht, Anil Somayaji, Anil Maheshwari", 
    "title": "Customer Appeasement Scheduling", 
    "arxiv-id": "1012.3452v1", 
    "author": "Anil Maheshwari", 
    "publish": "2010-12-15T20:38:40Z", 
    "summary": "Almost all of the current process scheduling algorithms which are used in\nmodern operating systems (OS) have their roots in the classical scheduling\nparadigms which were developed during the 1970's. But modern computers have\ndifferent types of software loads and user demands. We think it is important to\nrun what the user wants at the current moment. A user can be a human, sitting\nin front of a desktop machine, or it can be another machine sending a request\nto a server through a network connection. We think that OS should become\nintelligent to distinguish between different processes and allocate resources,\nincluding CPU, to those processes which need them most. In this work, as a\nfirst step to make the OS aware of the current state of the system, we consider\nprocess dependencies and interprocess communications. We are developing a\nmodel, which considers the need to satisfy interactive users and other possible\nremote users or customers, by making scheduling decisions based on process\ndependencies and interprocess communications. Our simple proof of concept\nimplementation and experiments show the effectiveness of this approach in the\nreal world applications. Our implementation does not require any change in the\nsoftware applications nor any special kind of configuration in the system,\nMoreover, it does not require any additional information about CPU needs of\napplications nor other resource requirements. Our experiments show significant\nperformance improvement for real world applications. For example, almost\nconstant average response time for Mysql data base server and constant frame\nrate for mplayer under different simulated load values."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1012.4045v1", 
    "other_authors": "George Anderson, Tshilidzi Marwala, Fulufhelo Vincent Nelwamondo", 
    "title": "Application of Global and One-Dimensional Local Optimization to   Operating System Scheduler Tuning", 
    "arxiv-id": "1012.4045v1", 
    "author": "Fulufhelo Vincent Nelwamondo", 
    "publish": "2010-12-18T00:51:57Z", 
    "summary": "This paper describes a study of comparison of global and one-dimensional\nlocal optimization methods to operating system scheduler tuning. The operating\nsystem scheduler we use is the Linux 2.6.23 Completely Fair Scheduler (CFS)\nrunning in simulator (LinSched). We have ported the Hackbench scheduler\nbenchmark to this simulator and use this as the workload. The global\noptimization approach we use is Particle Swarm Optimization (PSO). We make use\nof Response Surface Methodology (RSM) to specify optimal parameters for our PSO\nimplementation. The one-dimensional local optimization approach we use is the\nGolden Section method. In order to use this approach, we convert the scheduler\ntuning problem from one involving setting of three parameters to one involving\nthe manipulation of one parameter. Our results show that the global\noptimization approach yields better response but the one- dimensional\noptimization approach converges to a solution faster than the global\noptimization approach."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1012.5695v1", 
    "other_authors": "Santhi Baskaran, P. Thambidurai", 
    "title": "Dynamic Scheduling of Skippable Periodic Tasks with Energy Efficiency in   Weakly Hard Real-Time System", 
    "arxiv-id": "1012.5695v1", 
    "author": "P. Thambidurai", 
    "publish": "2010-12-28T04:35:02Z", 
    "summary": "Energy consumption is a critical design issue in real-time systems,\nespecially in battery- operated systems. Maintaining high performance, while\nextending the battery life between charges is an interesting challenge for\nsystem designers. Dynamic Voltage Scaling (DVS) allows a processor to\ndynamically change speed and voltage at run time, thereby saving energy by\nspreading run cycles into idle time. Knowing when to use full power and when\nnot, requires the cooperation of the operating system scheduler. Usually,\nhigher processor voltage and frequency leads to higher system throughput while\nenergy reduction can be obtained using lower voltage and frequency. Instead of\nlowering processor voltage and frequency as much as possible, energy efficient\nreal-time scheduling adjusts voltage and frequency according to some\noptimization criteria, such as low energy consumption or high throughput, while\nit meets the timing constraints of the real-time tasks. As the quantity and\nfunctional complexity of battery powered portable devices continues to raise,\nenergy efficient design of such devices has become increasingly important. Many\nreal-time scheduling algorithms have been developed recently to reduce energy\nconsumption in the portable devices that use DVS capable processors. Three\nalgorithms namely Red Tasks Only (RTO), Blue When Possible (BWP) and Red as\nLate as Possible (RLP) are proposed in the literature to schedule the real-time\ntasks in Weakly-hard real-time systems. This paper proposes optimal slack\nmanagement algorithms to make the above existing weakly hard real-time\nscheduling algorithms energy efficient using DVS and DPD techniques."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1012.5929v1", 
    "other_authors": "Jo\u00ebl Goossens, Patrick Meumeu Yomsi", 
    "title": "Exact Schedulability Test for global-EDF Scheduling of Periodic Hard   Real-Time Tasks on Identical Multiprocessors", 
    "arxiv-id": "1012.5929v1", 
    "author": "Patrick Meumeu Yomsi", 
    "publish": "2010-12-29T12:41:13Z", 
    "summary": "In this paper we consider the scheduling problem of hard real-time systems\ncomposed of periodic constrained-deadline tasks upon identical multiprocessor\nplatforms. We assume that tasks are scheduled by using the global-EDF\nscheduler. We establish an exact schedulability test for this scheduler by\nexploiting on the one hand its predictability property and by providing on the\nother hand a feasibility interval so that if it is possible to find a valid\nschedule for all the jobs contained in this interval, then the whole system\nwill be stamped feasible. In addition, we show by means of a counterexample\nthat the feasibility interval, and thus the schedulability test, proposed by\nLeung [Leung 1989] is incorrect and we show which arguments are actually\nincorrect."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1107.4786v1", 
    "other_authors": "Roya Golchay, Fr\u00e9d\u00e9ric Le Mou\u00ebl, St\u00e9phane Fr\u00e9not, Julien Ponge", 
    "title": "Towards Bridging IoT and Cloud Services: Proposing Smartphones as Mobile   and Autonomic Service Gateways", 
    "arxiv-id": "1107.4786v1", 
    "author": "Julien Ponge", 
    "publish": "2011-07-24T19:39:02Z", 
    "summary": "Computing is currently getting at the same time incredibly in the small with\nsensors/actuators embedded in our every- day objects and also greatly in the\nlarge with data and ser- vice clouds accessible anytime, anywhere. This\nInternet of Things is physically closed to the user but suffers from weak\nrun-time execution environments. Cloud Environments provide powerful data\nstorage and computing power but can not be easily accessed and integrate the\nfinal-user context- awareness. We consider smartphones are set to become the\nuniversal interface between these two worlds. In this position paper, we\npropose a middleware approach where smartphones provide service gateways to\nbridge the gap between IoT services and Cloud services. Since smartphones are\nmobile gateways, they should be able to (re)configure themself according to\ntheir place, things discovered around, and their own resources such battery.\nSeveral issues are discussed: collaborative event-based context management,\nadaptive and opportunistic service deployment and invocation, multi-criteria\n(user- and performance-oriented) optimization decision algorithm."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1109.2638v1", 
    "other_authors": "Nitin Garg, Ed Zhu, Fabiano C. Botelho", 
    "title": "Light-weight Locks", 
    "arxiv-id": "1109.2638v1", 
    "author": "Fabiano C. Botelho", 
    "publish": "2011-09-12T21:49:38Z", 
    "summary": "In this paper, we propose a new approach to building synchronization\nprimitives, dubbed \"lwlocks\" (short for light-weight locks). The primitives are\noptimized for small memory footprint while maintaining efficient performance in\nlow contention scenarios. A read-write lwlock occupies 4 bytes, a mutex\noccupies 4 bytes (2 if deadlock detection is not required), and a condition\nvariable occupies 4 bytes. The corresponding primitives of the popular pthread\nlibrary occupy 56 bytes, 40 bytes and 48 bytes respectively on the x86-64\nplatform. The API for lwlocks is similar to that of the pthread library but\ncovering only the most common use cases. Lwlocks allow explicit control of\nqueuing and scheduling decisions in contention situations and support\n\"asynchronous\" or \"deferred blocking\" acquisition of locks. Asynchronous\nlocking helps in working around the constraints of lock-ordering which\notherwise limits concurrency. The small footprint of lwlocks enables the\nconstruction of data structures with very fine-grained locking, which in turn\nis crucial for lowering contention and supporting highly concurrent access to a\ndata structure. Currently, the Data Domain File System uses lwlocks for its\nin-memory inode cache as well as in a generic doubly-linked concurrent list\nwhich forms the building block for more sophisticated structures."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1109.3075v1", 
    "other_authors": "Rakesh Mohanty, Manas Das, M. Lakshmi Prasanna, Sudhashree", 
    "title": "Design and Performance Evaluation of A New Proposed Fittest Job First   Dynamic Round Robin(FJFDRR) Scheduling Algorithm", 
    "arxiv-id": "1109.3075v1", 
    "author": "Sudhashree", 
    "publish": "2011-09-14T13:26:07Z", 
    "summary": "In this paper, we have proposed a new variant of Round Robin scheduling\nalgorithm by executing the processes according to the new calculated Fit Factor\nf and using the concept of dynamic time quantum. We have compared the\nperformance of our proposed Fittest Job First Dynamic Round Robin(FJFDRR)\nalgorithm with the Priority Based Static Round Robin(PBSRR) algorithm.\nExperimental results show that our proposed algorithm performs better than\nPBSRR in terms of reducing the number of context switches, average waiting time\nand average turnaround time."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1109.3076v1", 
    "other_authors": "H. S. Behera, Rakesh Mohanty, Sabyasachi Sahu, Sourav Kumar Bhoi", 
    "title": "Comparative performance analysis of multi dynamic time quantum Round   Robin(MDTQRR) algorithm with arrival time", 
    "arxiv-id": "1109.3076v1", 
    "author": "Sourav Kumar Bhoi", 
    "publish": "2011-09-14T13:32:55Z", 
    "summary": "CPU being considered a primary computer resource, its scheduling is central\nto operating-system design. A thorough performance evaluation of various\nscheduling algorithms manifests that Round Robin Algorithm is considered as\noptimal in time shared environment because the static time is equally shared\namong the processes. We have proposed an efficient technique in the process\nscheduling algorithm by using dynamic time quantum in Round Robin. Our approach\nis based on the calculation of time quantum twice in single round robin cycle.\nTaking into consideration the arrival time, we implement the algorithm.\nExperimental analysis shows better performance of this improved algorithm over\nthe Round Robin algorithm and the Shortest Remaining Burst Round Robin\nalgorithm. It minimizes the overall number of context switches, average waiting\ntime and average turn-around time. Consequently the throughput and CPU\nutilization is better."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1111.5348v1", 
    "other_authors": "Abbas Noon, Ali Kalakech, Seifedine Kadry", 
    "title": "A New Round Robin Based Scheduling Algorithm for Operating Systems:   Dynamic Quantum Using the Mean Average", 
    "arxiv-id": "1111.5348v1", 
    "author": "Seifedine Kadry", 
    "publish": "2011-11-22T21:44:25Z", 
    "summary": "Round Robin, considered as the most widely adopted CPU scheduling algorithm,\nundergoes severe problems directly related to quantum size. If time quantum\nchosen is too large, the response time of the processes is considered too high.\nOn the other hand, if this quantum is too small, it increases the overhead of\nthe CPU. In this paper, we propose a new algorithm, called AN, based on a new\napproach called dynamic-time-quantum; the idea of this approach is to make the\noperating systems adjusts the time quantum according to the burst time of the\nset of waiting processes in the ready queue. Based on the simulations and\nexperiments, we show that the new proposed algorithm solves the fixed time\nquantum problem and increases the performance of Round Robin."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1202.4030v1", 
    "other_authors": "Shashi Shekhar, Michael Dietz, Dan S. Wallach", 
    "title": "AdSplit: Separating smartphone advertising from applications", 
    "arxiv-id": "1202.4030v1", 
    "author": "Dan S. Wallach", 
    "publish": "2012-02-17T22:33:12Z", 
    "summary": "A wide variety of smartphone applications today rely on third-party\nadvertising services, which provide libraries that are linked into the hosting\napplication. This situation is undesirable for both the application author and\nthe advertiser. Advertising libraries require additional permissions, resulting\nin additional permission requests to users. Likewise, a malicious application\ncould simulate the behavior of the advertising library, forging the user's\ninteraction and effectively stealing money from the advertiser. This paper\ndescribes AdSplit, where we extended Android to allow an application and its\nadvertising to run as separate processes, under separate user-ids, eliminating\nthe need for applications to request permissions on behalf of their advertising\nlibraries.\n  We also leverage mechanisms from Quire to allow the remote server to validate\nthe authenticity of client-side behavior. In this paper, we quantify the degree\nof permission bloat caused by advertising, with a study of thousands of\ndownloaded apps. AdSplit automatically recompiles apps to extract their ad\nservices, and we measure minimal runtime overhead. We also observe that most ad\nlibraries just embed an HTML widget within and describe how AdSplit can be\ndesigned with this in mind to avoid any need for ads to have native code."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V7P142", 
    "link": "http://arxiv.org/pdf/1205.0124v1", 
    "other_authors": "Jagbeer Singh, Satyendra Prasad Singh", 
    "title": "Schedulability Test for Soft Real-Time Systems under Multiprocessor   Environment by using an Earliest Deadline First Scheduling Algorithm", 
    "arxiv-id": "1205.0124v1", 
    "author": "Satyendra Prasad Singh", 
    "publish": "2012-05-01T09:17:43Z", 
    "summary": "This paper deals with the study of Earliest Deadline First (EDF) which is an\noptimal scheduling algorithm for uniprocessor real time systems use for\nscheduling the periodic task in soft real-time multiprocessor systems. In hard\nreal-time systems, a significant disparity exists EDF-based schemes and RMA\nscheduling (which is the only known way of optimally scheduling recurrent\nreal-time tasks on multiprocessors): on M processors, all known EDF variants\nhave utilization-based schedulability bounds of approximately M/2, while RMA\nalgorithms can fully utilize all processors. This is unfortunate because EDF\nbased algorithms entail lower scheduling and task migration overheads. In work\non hard real-time systems, it has been shown that this disparity in\nSchedulability can be lessened by placing caps on per task utilizations. Our\nmain contribution is a new EDF based scheme that ensures bounded deadline\ntardiness. In this scheme, per-task utilizations must be focused,but overall\nutilization need not be stricted. Our scheme should enable a wide range of soft\nreal-time applications to be scheduled with no constraints on total\nutilization. Also propose techniques and heuristics that can be used to reduce\ntardiness as well as increase the efficiency of task."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2012.2215", 
    "link": "http://arxiv.org/pdf/1205.1687v1", 
    "other_authors": "Sumit Sharma, Rohitt Sharma, Paramjit Singh, Aditya Mahajan", 
    "title": "Age Based User Interface in Mobile Operating System", 
    "arxiv-id": "1205.1687v1", 
    "author": "Aditya Mahajan", 
    "publish": "2012-05-08T13:12:27Z", 
    "summary": "This paper proposes the creation of different interfaces in the mobile\noperating system for different age groups. The different age groups identified\nare kids, elderly people and all others. The motive behind creating different\ninterfaces is to make the smartphones of today's world usable to all age\ngroups."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2012.2215", 
    "link": "http://arxiv.org/pdf/1205.6423v1", 
    "other_authors": "Plawan Kumar Rath, G. N. Anil", 
    "title": "Proposed Challenges And Areas of Concern in Operating System Research   and Development", 
    "arxiv-id": "1205.6423v1", 
    "author": "G. N. Anil", 
    "publish": "2012-05-29T17:10:29Z", 
    "summary": "Computers are a very important part of our lives and the major reason why\nthey have been such a success is because of the excellent graphical operating\nsystems that run on these powerful machines. As the computer hardware is\nbecoming more and more powerful, it is also vital to keep the software updated\nin order to utilize the hardware of the system efficiently and make it faster\nand smarter. This paper highlights some core issues that if dealt with in the\noperating system level would make use of the full potential of the computer\nhardware and provide an excellent user experience."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2012.2215", 
    "link": "http://arxiv.org/pdf/1206.0396v1", 
    "other_authors": "Elsayed Saad, Medhat Awadalla, Mohamed Shalan, Abdullah Elewi", 
    "title": "Energy-Aware Task Partitioning on Heterogeneous Multiprocessor Platforms", 
    "arxiv-id": "1206.0396v1", 
    "author": "Abdullah Elewi", 
    "publish": "2012-06-02T18:22:37Z", 
    "summary": "Efficient task partitioning plays a crucial role in achieving high\nperformance at multiprocessor plat forms. This paper addresses the problem of\nenergy-aware static partitioning of periodic real-time tasks on heterogeneous\nmultiprocessor platforms. A Particle Swarm Optimization variant based on\nMin-min technique for task partitioning is proposed. The proposed approach aims\nto minimize the overall energy consumption, meanwhile avoid deadline\nviolations. An energy-aware cost function is proposed to be considered in the\nproposed approach. Extensive simulations and comparisons are conducted in order\nto validate the effectiveness of the proposed technique. The achieved results\ndemonstrate that the proposed partitioning scheme significantly surpasses\nprevious approaches in terms of both number of iterations and energy savings."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2012.2215", 
    "link": "http://arxiv.org/pdf/1208.6390v1", 
    "other_authors": "Pierre Olivier, Jalil Boukhobza, Eric Senn", 
    "title": "Performance Evaluation of Flash File Systems", 
    "arxiv-id": "1208.6390v1", 
    "author": "Eric Senn", 
    "publish": "2012-08-31T06:31:48Z", 
    "summary": "Today, flash memory are strongly used in the embedded system domain. NAND\nflash memories are the building block of main secondary storage systems. Such\nmemories present many benefits in terms of data density, I/O performance, shock\nresistance and power consumption. Nevertheless, flash does not come without\nconstraints: the write / erase granularity asymmetry and the limited lifetime\nbring the need for specific management. This can be done through the operating\nsystem using dedicated Flash File Systems (FFSs). In this document, we present\ngeneral concepts about FFSs, and implementations example that are JFFS2, YAFFS2\nand UBIFS, the most commonly used flash file systems. Then we give performance\nevaluation results for these FFSs."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2012.2215", 
    "link": "http://arxiv.org/pdf/1209.4600v1", 
    "other_authors": "Kamlesh Sharma, T. V. Prasad", 
    "title": "Classification Of Heterogeneous Operating System", 
    "arxiv-id": "1209.4600v1", 
    "author": "T. V. Prasad", 
    "publish": "2012-09-19T03:59:12Z", 
    "summary": "Operating system is a bridge between system and user. An operating system\n(OS) is a software program that manages the hardware and software resources of\na computer. The OS performs basic tasks, such as controlling and allocating\nmemory, prioritizing the processing of instructions, controlling input and\noutput devices, facilitating networking, and managing files. It is difficult to\npresent a complete as well as deep account of operating systems developed till\ndate. So, this paper tries to overview only a subset of the available operating\nsystems and its different categories. OS are being developed by a large number\nof academic and commercial organizations for the last several decades. This\npaper, therefore, concentrates on the different categories of OS with special\nemphasis to those that had deep impact on the evolution process. The aim of\nthis paper is to provide a brief timely commentary on the different categories\nimportant operating systems available today."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2012.2215", 
    "link": "http://arxiv.org/pdf/1210.6447v1", 
    "other_authors": "S. Yashvir, Om Prakash", 
    "title": "Disk Scheduling: Selection of Algorithm", 
    "arxiv-id": "1210.6447v1", 
    "author": "Om Prakash", 
    "publish": "2012-10-24T07:56:48Z", 
    "summary": "The objective of this paper is to take some aspects of disk scheduling and\nscheduling algorithms. The disk scheduling is discussed with a sneak peak in\ngeneral and selection of algorithm in particular."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1211.4840v1", 
    "other_authors": "Mohamed Farag", 
    "title": "Multicore Dynamic Kernel Modules Attachment Technique for Kernel   Performance Enhancement", 
    "arxiv-id": "1211.4840v1", 
    "author": "Mohamed Farag", 
    "publish": "2012-11-20T19:38:00Z", 
    "summary": "Traditional monolithic kernels dominated kernel structures for long time\nalong with small sized kernels,few hardware companies and limited kernel\nfunctionalities. Monolithic kernel structure was not applicable when the number\nof hardware companies increased and kernel services consumed by different users\nfor many purposes. One of the biggest disadvantages of the monolithic kernels\nis the inflexibility due to the need to include all the available modules in\nkernel compilation causing high time consuming. Lately, new kernel structure\nwas introduced through multicore operating systems. Unfortunately, many\nmulticore operating systems such as barrelfish and FOS are experimental. This\npaper aims to simulate the performance of multicore hybrid kernels through\ndynamic kernel module customized attachment/ deattachment for multicore\nmachines. In addition, this paper proposes a new technique for loading dynamic\nkernel modules based on the user needs and machine capabilities."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1212.1787v1", 
    "other_authors": "Rohan Garg, Komal Sodha, Gene Cooperman", 
    "title": "A Generic Checkpoint-Restart Mechanism for Virtual Machines", 
    "arxiv-id": "1212.1787v1", 
    "author": "Gene Cooperman", 
    "publish": "2012-12-08T12:56:49Z", 
    "summary": "It is common today to deploy complex software inside a virtual machine (VM).\nSnapshots provide rapid deployment, migration between hosts, dependability\n(fault tolerance), and security (insulating a guest VM from the host). Yet, for\neach virtual machine, the code for snapshots is laboriously developed on a\nper-VM basis. This work demonstrates a generic checkpoint-restart mechanism for\nvirtual machines. The mechanism is based on a plugin on top of an unmodified\nuser-space checkpoint-restart package, DMTCP. Checkpoint-restart is\ndemonstrated for three virtual machines: Lguest, user-space QEMU, and KVM/QEMU.\nThe plugins for Lguest and KVM/QEMU require just 200 lines of code. The Lguest\nkernel driver API is augmented by 40 lines of code. DMTCP checkpoints\nuser-space QEMU without any new code. KVM/QEMU, user-space QEMU, and DMTCP need\nno modification. The design benefits from other DMTCP features and plugins.\nExperiments demonstrate checkpoint and restart in 0.2 seconds using forked\ncheckpointing, mmap-based fast-restart, and incremental Btrfs-based snapshots."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1212.3502v1", 
    "other_authors": "Shri Prakash Dwivedi", 
    "title": "Adaptive Scheduling in Real-Time Systems Through Period Adjustment", 
    "arxiv-id": "1212.3502v1", 
    "author": "Shri Prakash Dwivedi", 
    "publish": "2012-12-14T15:33:45Z", 
    "summary": "Real time system technology traditionally developed for safety critical\nsystems, has now been extended to support multimedia systems and virtual\nreality. A large number of real-time application, related to multimedia and\nadaptive control system, require more flexibility than classical real-time\ntheory usually permits. This paper proposes an efficient adaptive scheduling\nframework in real-time systems based on period adjustment. Under this model\nperiodic task can change their execution rates based on their importance value\nto keep the system underloaded. We propose Period_Adjust algorithm, which\nconsider the tasks whose periods are bounded as well as the tasks whose periods\nare not bounded."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1304.3557v1", 
    "other_authors": "Radhwan Y Ameen, Asmaa Y. Hamo", 
    "title": "Survey of Server Virtualization", 
    "arxiv-id": "1304.3557v1", 
    "author": "Asmaa Y. Hamo", 
    "publish": "2013-04-12T07:33:42Z", 
    "summary": "Virtualization is a term that refers to the abstraction of computer\nresources. The purpose of virtual computing environment is to improve resource\nutilization by providing a unified integrated operating platform for users and\napplications based on aggregation of heterogeneous and autonomous resources.\nMore recently, virtualization at all levels (system, storage, and network)\nbecame important again as a way to improve system security, reliability and\navailability, reduce costs, and provide greater flexibility. Virtualization has\nrapidly become a go-to technology for increasing efficiency in the data center.\nWith virtualization technologies providing tremendous flexibility, even\ndisparate architectures may be deployed on a single machine without\ninterference This paper explains the basics of server virtualization and\naddresses pros and cons of virtualization"
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1304.3771v1", 
    "other_authors": "Ardalan Amiri Sani, Sreekumar Nair, Lin Zhong, Quinn Jacobson", 
    "title": "Making I/O Virtualization Easy with Device Files", 
    "arxiv-id": "1304.3771v1", 
    "author": "Quinn Jacobson", 
    "publish": "2013-04-13T04:04:08Z", 
    "summary": "Personal computers have diverse and fast-evolving I/O devices, making their\nI/O virtualization different from that of servers and data centers. In this\npaper, we present our recent endeavors in simplifying I/O virtualization for\npersonal computers. Our key insight is that many operating systems, including\nUnix-like ones, abstract I/O devices as device files. There is a small and\nstable set of operations on device files, therefore, I/O virtualization at the\ndevice file boundary requires a one-time effort to support various I/O devices.\n  We present devirtualization, our design of I/O virtualization at the device\nfile boundary and its implementation for Linux/x86 systems. We are able to\nvirtualize various GPUs, input devices, cameras, and audio devices with fewer\nthan 4900 LoC, of which only about 300 are specific to I/O device classes. Our\nmeasurements show that devirtualized devices achieve interactive performance\nindistinguishable from native ones by human users, even when running 3D HD\ngames."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1304.6067v1", 
    "other_authors": "J\u00fcrgen Teich, Wolfgang Schr\u00f6der-Preikschat, Andreas Herkersdorf", 
    "title": "Invasive Computing - Common Terms and Granularity of Invasion", 
    "arxiv-id": "1304.6067v1", 
    "author": "Andreas Herkersdorf", 
    "publish": "2013-04-22T19:29:05Z", 
    "summary": "Future MPSoCs with 1000 or more processor cores on a chip require new means\nfor resource-aware programming in order to deal with increasing imperfections\nsuch as process variation, fault rates, aging effects, and power as well as\nthermal problems. On the other hand, predictable program executions are\nthreatened if not impossible if no proper means of resource isolation and\nexclusive use may be established on demand. In view of these problems and\nmenaces, invasive computing enables an application programmer to claim for\nprocessing resources and spread computations to claimed processors dynamically\nat certain points of the program execution.\n  Such decisions may be depending on the degree of application parallelism and\nthe state of the underlying resources such as utilization, load, and\ntemperature, but also with the goal to provide predictable program execution on\nMPSoCs by claiming processing resources exclusively as the default and thus\neliminating interferences and creating the necessary isolation between multiple\nconcurrently running applications. For achieving this goal, invasive computing\nintroduces new programming constructs for resource-aware programming that\nmeanwhile, for testing purpose, have been embedded into the parallel computing\nlanguage X10 as developed by IBM using a library-based approach.\n  This paper presents major ideas and common terms of invasive computing as\ninvestigated by the DFG Transregional Collaborative Research Centre TR89.\nMoreoever, a reflection is given on the granularity of resources that may be\nrequested by invasive programs."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1304.7001v1", 
    "other_authors": "Deepika Bhatia, Urmila Shrawankar", 
    "title": "Network Control Systems RTAI framework A Review", 
    "arxiv-id": "1304.7001v1", 
    "author": "Urmila Shrawankar", 
    "publish": "2013-04-25T11:10:38Z", 
    "summary": "With the advancement in the automation industry, to perform complex remote\noperations is required. Advancements in the networking technology has led to\nthe development of different architectures to implement control from a large\ndistance. In various control applications of the modern industry, the agents,\nsuch as sensors, actuators, and controllers are basically geographically\ndistributed. For efficient working of a control application, all of the agents\nhave to exchange information through a communication media. At present, an\nincreasing number of distributed control systems are based on platforms made up\nof conventional PCs running open-source real-time operating systems. Often,\nthese systems needed to have networked devices supporting synchronized\noperations with respect to each node. A framework is studied that relies on\nstandard software and protocol as RTAI, EtherCAT, RTnet and IEEE 1588. RTAI and\nits various protocols are studied in network control systems environment."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1305.3345v1", 
    "other_authors": "Weibin Sun, Robert Ricci", 
    "title": "Augmenting Operating Systems With the GPU", 
    "arxiv-id": "1305.3345v1", 
    "author": "Robert Ricci", 
    "publish": "2013-05-15T02:53:19Z", 
    "summary": "The most popular heterogeneous many-core platform, the CPU+GPU combination,\nhas received relatively little attention in operating systems research. This\nplatform is already widely deployed: GPUs can be found, in some form, in most\ndesktop and laptop PCs. Used for more than just graphics processing, modern\nGPUs have proved themselves versatile enough to be adapted to other\napplications as well. Though GPUs have strengths that can be exploited in\nsystems software, this remains a largely untapped resource. We argue that\naugmenting the OS kernel with GPU computing power opens the door to a number of\nnew opportunities. GPUs can be used to speed up some kernel functions, make\nother scale better, and make it feasible to bring some computation-heavy\nfunctionality into the kernel. We present our framework for using the GPU as a\nco-processor from an OS kernel, and demonstrate a prototype in Linux."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1305.3849v1", 
    "other_authors": "Emmanuel Grolleau, Jo\u00ebl Goossens, Liliana Cucu-Grosjean", 
    "title": "On the periodic behavior of real-time schedulers on identical   multiprocessor platforms", 
    "arxiv-id": "1305.3849v1", 
    "author": "Liliana Cucu-Grosjean", 
    "publish": "2013-05-16T15:54:12Z", 
    "summary": "This paper is proposing a general periodicity result concerning any\ndeterministic and memoryless scheduling algorithm (including\nnon-work-conserving algorithms), for any context, on identical multiprocessor\nplatforms. By context we mean the hardware architecture (uniprocessor,\nmulticore), as well as task constraints like critical sections, precedence\nconstraints, self-suspension, etc. Since the result is based only on the\nreleases and deadlines, it is independent from any other parameter. Note that\nwe do not claim that the given interval is minimal, but it is an upper bound\nfor any cycle of any feasible schedule provided by any deterministic and\nmemoryless scheduler."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4405", 
    "link": "http://arxiv.org/pdf/1306.1316v1", 
    "other_authors": "Jo\u00ebl Goossens, Pascal Richard", 
    "title": "Partitioned scheduling of multimode multiprocessor real-time systems   with temporal isolation", 
    "arxiv-id": "1306.1316v1", 
    "author": "Pascal Richard", 
    "publish": "2013-06-06T06:57:57Z", 
    "summary": "We consider the partitioned scheduling problem of multimode real-time systems\nupon identical multiprocessor platforms. During the execution of a multimode\nsystem, the system can change from one mode to another such that the current\ntask set is replaced with a new one. In this paper, we consider a synchronous\ntransition protocol in order to take into account mode-independent tasks, i.e.,\ntasks of which the execution pattern must not be jeopardized by the mode\nchanges. We propose two methods for handling mode changes in partitioned\nscheduling. The first method is offline/optimal and computes a static\nallocation of tasks schedulable and respecting both tasks and transition\ndeadlines (if any). The second approach is subject to a sufficient condition in\norder to ensure online First Fit based allocation to satisfy the timing\nconstraints."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1309.3096v1", 
    "other_authors": "Neetu Goel, R. B. Garg", 
    "title": "Simulation of an Optimum Multilevel Dynamic Round Robin Scheduling   Algorithm", 
    "arxiv-id": "1309.3096v1", 
    "author": "R. B. Garg", 
    "publish": "2013-09-12T10:26:10Z", 
    "summary": "CPU scheduling has valiant effect on resource utilization as well as overall\nquality of the system. Round Robin algorithm performs optimally in time shared\nsystems, but it performs more number of context switches, larger waiting time\nand larger response time. In order to simulate the behavior of various CPU\nscheduling algorithms and to improve Round Robin scheduling algorithm using\ndynamic time slice concept, in this paper we produce the implementation of new\nCPU scheduling algorithm called An Optimum Multilevel Dynamic Round Robin\nScheduling (OMDRRS), which calculates intelligent time slice and warps after\nevery round of execution. The results display the robustness of this software,\nespecially for academic, research and experimental use, as well as proving the\ndesirability and efficiency of the probabilistic algorithm over the other\nexisting techniques and it is observed that this OMDRRS projects good\nperformance as compared to the other existing CPU scheduling algorithms."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1310.6298v1", 
    "other_authors": "Ye Li, Richard West, Eric Missimer", 
    "title": "The Quest-V Separation Kernel for Mixed Criticality Systems", 
    "arxiv-id": "1310.6298v1", 
    "author": "Eric Missimer", 
    "publish": "2013-10-23T17:14:25Z", 
    "summary": "Multi- and many-core processors are becoming increasingly popular in embedded\nsystems. Many of these processors now feature hardware virtualization\ncapabilities, such as the ARM Cortex A15, and x86 processors with Intel VT-x or\nAMD-V support. Hardware virtualization offers opportunities to partition\nphysical resources, including processor cores, memory and I/O devices amongst\nguest virtual machines. Mixed criticality systems and services can then\nco-exist on the same platform in separate virtual machines. However,\ntraditional virtual machine systems are too expensive because of the costs of\ntrapping into hypervisors to multiplex and manage machine physical resources on\nbehalf of separate guests. For example, hypervisors are needed to schedule\nseparate VMs on physical processor cores. In this paper, we discuss the design\nof the Quest-V separation kernel, that partitions services of different\ncriticalities in separate virtual machines, or sandboxes. Each sandbox\nencapsulates a subset of machine physical resources that it manages without\nrequiring intervention of a hypervisor. Moreover, a hypervisor is not needed\nfor normal operation, except to bootstrap the system and establish\ncommunication channels between sandboxes."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1310.6301v1", 
    "other_authors": "Ye Li, Eric Missimer, Richard West", 
    "title": "Predictable Migration and Communication in the Quest-V Multikernel", 
    "arxiv-id": "1310.6301v1", 
    "author": "Richard West", 
    "publish": "2013-10-23T17:29:42Z", 
    "summary": "Quest-V is a system we have been developing from the ground up, with\nobjectives focusing on safety, predictability and efficiency. It is designed to\nwork on emerging multicore processors with hardware virtualization support.\nQuest-V is implemented as a \"distributed system on a chip\" and comprises\nmultiple sandbox kernels. Sandbox kernels are isolated from one another in\nseparate regions of physical memory, having access to a subset of processing\ncores and I/O devices. This partitioning prevents system failures in one\nsandbox affecting the operation of other sandboxes. Shared memory channels\nmanaged by system monitors enable inter-sandbox communication.\n  The distributed nature of Quest-V means each sandbox has a separate physical\nclock, with all event timings being managed by per-core local timers. Each\nsandbox is responsible for its own scheduling and I/O management, without\nrequiring intervention of a hypervisor.\n  In this paper, we formulate bounds on inter-sandbox communication in the\nabsence of a global scheduler or global system clock. We also describe how\naddress space migration between sandboxes can be guaranteed without violating\nservice constraints. Experimental results on a working system show the\nconditions under which Quest-V performs real-time communication and migration."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1310.6349v1", 
    "other_authors": "Richard West, Ye Li, Eric Missimer", 
    "title": "Quest-V: A Virtualized Multikernel for Safety-Critical Real-Time Systems", 
    "arxiv-id": "1310.6349v1", 
    "author": "Eric Missimer", 
    "publish": "2013-10-23T17:35:03Z", 
    "summary": "Modern processors are increasingly featuring multiple cores, as well as\nsupport for hardware virtualization. While these processors are common in\ndesktop and server-class computing, they are less prevalent in embedded and\nreal-time systems. However, smartphones and tablet PCs are starting to feature\nmulticore processors with hardware virtualization. If the trend continues, it\nis possible that future real-time systems will feature more sophisticated\nprocessor architectures. Future automotive or avionics systems, for example,\ncould replace complex networks of uniprocessors with consolidated services on a\nsmaller number of multicore processors. Likewise, virtualization could be used\nto isolate services and increase the availability of a system even when\nfailures occur.\n  This paper investigates whether advances in modern processor technologies\noffer new opportunities to rethink the design of real-time operating systems.\nWe describe some of the design principles behind Quest-V, which is being used\nas an exploratory vehicle for real-time system design on multicore processors\nwith hardware virtualization capabilities. While not all embedded systems\nshould assume such features, a case can be made that more robust,\nsafety-critical systems can be built to use hardware virtualization without\nincurring significant overheads."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1312.1810v1", 
    "other_authors": "Brijender Kahanwal, Tejinder Pal Singh, Ruchira Bhargava, Girish Pal Singh", 
    "title": "File System - A Component of Operating System", 
    "arxiv-id": "1312.1810v1", 
    "author": "Girish Pal Singh", 
    "publish": "2013-12-06T09:18:04Z", 
    "summary": "The file system provides the mechanism for online storage and access to file\ncontents, including data and programs. This paper covers the high-level details\nof file systems, as well as related topics such as the disk cache, the file\nsystem interface to the kernel, and the user-level APIs that use the features\nof the file system. It will give you a thorough understanding of how a file\nsystem works in general. The main component of the operating system is the file\nsystem. It is used to create, manipulate, store, and retrieve data. At the\nhighest level, a file system is a way to manage information on a secondary\nstorage medium. There are so many layers under and above the file system. All\nthe layers are to be fully described here. This paper will give the explanatory\nknowledge of the file system designers and the researchers in the area. The\ncomplete path from the user process to secondary storage device is to be\nmentioned. File system is the area where the researchers are doing lot of job\nand there is always a need to do more work. The work is going on for the\nefficient, secure, energy saving techniques for the file systems. As we know\nthat the hardware is going to be fast in performance and low-priced day by day.\nThe software is not built to comeback with the hardware technology. So there is\na need to do research in this area to bridge the technology gap."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1312.1822v1", 
    "other_authors": "Brijender Kahanwal, Tejinder Pal Singh", 
    "title": "Towards the Framework of the File Systems Performance Evaluation   Techniques and the Taxonomy of Replay Traces", 
    "arxiv-id": "1312.1822v1", 
    "author": "Tejinder Pal Singh", 
    "publish": "2013-12-06T10:20:38Z", 
    "summary": "This is the era of High Performance Computing (HPC). There is a great demand\nof the best performance evaluation techniques for the file and storage systems.\nThe task of evaluation is both necessary and hard. It gives in depth analysis\nof the target system and that becomes the decision points for the users. That\nis also helpful for the inventors or developers to find out the bottleneck in\ntheir systems. In this paper many performance evaluation techniques are\ndescribed for file and storage system evaluation and the main stress is given\non the important one that is replay traces. A survey has been done for the\nperformance evaluation techniques used by the researchers and on the replay\ntraces. And the taxonomy of the replay traces is described. The some of the\npopular replay traces are just like, Tracefs [1], //Trace [2], Replayfs [3] and\nVFS Interceptor [12]. At last we have concluded all the features that must be\nconsidered when we are going to develop the new tool for the replay traces. The\ncomplete work of this paper shows that the storage system developers must care\nabout all the techniques which can be used for the performance evaluation of\nthe file systems. So they can develop highly efficient future file and storage\nsystems."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1312.4509v1", 
    "other_authors": "Lilia Zaourar, Mathieu Jan, Maurice Pitel", 
    "title": "Cache-aware static scheduling for hard real-time multicore systems based   on communication affinities", 
    "arxiv-id": "1312.4509v1", 
    "author": "Maurice Pitel", 
    "publish": "2013-12-16T20:32:52Z", 
    "summary": "The growing need for continuous processing capabilities has led to the\ndevelopment of multicore systems with a complex cache hierarchy. Such multicore\nsystems are generally designed for improving the performance in average case,\nwhile hard real-time systems must consider worst-case scenarios. An open\nchallenge is therefore to efficiently schedule hard real-time tasks on a\nmulticore architecture. In this work, we propose a mathematical formulation for\ncomputing a static scheduling that minimize L1 data cache misses between hard\nreal-time tasks on a multicore architecture using communication affinities."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1312.4931v1", 
    "other_authors": "Ardalan Amiri Sani, Kevin Boos, Min Hong Yun, Lin Zhong", 
    "title": "Rio: A System Solution for Sharing I/O between Mobile Systems", 
    "arxiv-id": "1312.4931v1", 
    "author": "Lin Zhong", 
    "publish": "2013-12-17T20:43:33Z", 
    "summary": "Mobile systems are equipped with a diverse collection of I/O devices,\nincluding cameras, microphones, sensors, and modems. There exist many novel use\ncases for allowing an application on one mobile system to utilize I/O devices\nfrom another. This paper presents Rio, an I/O sharing solution that supports\nunmodified applications and exposes all the functionality of an I/O device for\nsharing. Rio's design is common to many classes of I/O devices, thus\nsignificantly reducing the engineering effort to support new I/O devices. Our\nimplementation of Rio on Android consists of 6700 total lines of code and\nsupports four I/O classes with fewer than 450 class-specific lines of code. Rio\nalso supports I/O sharing between mobile systems of different form factors,\nincluding smartphones and tablets. We show that Rio achieves performance close\nto that of local I/O for audio, sensors, and modems, but suffers noticeable\nperformance degradation for camera due to network throughput limitations\nbetween the two systems, which is likely to be alleviated by emerging wireless\nstandards."
},{
    "category": "cs.OS", 
    "doi": "10.5120/13263-0743", 
    "link": "http://arxiv.org/pdf/1312.6650v2", 
    "other_authors": "Samaneh Kazemi Nafchi, Rohan Garg, Gene Cooperman", 
    "title": "Transparent Checkpoint-Restart for Hardware-Accelerated 3D Graphics", 
    "arxiv-id": "1312.6650v2", 
    "author": "Gene Cooperman", 
    "publish": "2013-12-23T19:19:40Z", 
    "summary": "Providing fault-tolerance for long-running GPU-intensive jobs requires\napplication-specific solutions, and often involves saving the state of complex\ndata structures spread among many graphics libraries. This work describes a\nmechanism for transparent GPU-independent checkpoint-restart of 3D graphics.\nThe approach is based on a record-prune-replay paradigm: all OpenGL calls\nrelevant to the graphics driver state are recorded; calls not relevant to the\ninternal driver state as of the last graphics frame prior to checkpoint are\ndiscarded; and the remaining calls are replayed on restart. A previous approach\nfor OpenGL 1.5, based on a shadow device driver, required more than 78,000\nlines of OpenGL-specific code. In contrast, the new approach, based on\nrecord-prune-replay, is used to implement the same case in just 4,500 lines of\ncode. The speed of this approach varies between 80 per cent and nearly 100 per\ncent of the speed of the native hardware acceleration for OpenGL 1.5, as\nmeasured when running the ioquake3 game under Linux. This approach has also\nbeen extended to demonstrate checkpointing of OpenGL 3.0 for the first time,\nwith a demonstration for PyMol, for molecular visualization."
},{
    "category": "cs.OS", 
    "doi": "10.5120/5010-7329", 
    "link": "http://arxiv.org/pdf/1403.0334v1", 
    "other_authors": "Sourav Kumar Bhoi, Sanjaya Kumar Panda, Imran Hossain Faruk", 
    "title": "Design and Performance Evaluation of an Optimized Disk Scheduling   Algorithm (ODSA)", 
    "arxiv-id": "1403.0334v1", 
    "author": "Imran Hossain Faruk", 
    "publish": "2014-03-03T08:13:29Z", 
    "summary": "Management of disk scheduling is a very important aspect of operating system.\nPerformance of the disk scheduling completely depends on how efficient is the\nscheduling algorithm to allocate services to the request in a better manner.\nMany algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.) are developed in the\nrecent years in order to optimize the system disk I/O performance. By reducing\nthe average seek time and transfer time, we can improve the performance of disk\nI/O operation. In our proposed algorithm, Optimize Disk Scheduling Algorithm\n(ODSA) is taking less average seek time and transfer time as compare to other\ndisk scheduling algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.), which\nenhances the efficiency of the disk performance in a better manner."
},{
    "category": "cs.OS", 
    "doi": "10.5120/10667-5445", 
    "link": "http://arxiv.org/pdf/1403.0335v1", 
    "other_authors": "Sanjaya Kumar Panda, Debasis Dash, Jitendra Kumar Rout", 
    "title": "A Group based Time Quantum Round Robin Algorithm using Min-Max Spread   Measure", 
    "arxiv-id": "1403.0335v1", 
    "author": "Jitendra Kumar Rout", 
    "publish": "2014-03-03T08:27:29Z", 
    "summary": "Round Robin (RR) Scheduling is the basis of time sharing environment. It is\nthe combination of First Come First Served (FCFS) scheduling algorithm and\npreemption among processes. It is basically used in a time sharing operating\nsystem. It switches from one process to another process in a time interval. The\ntime interval or Time Quantum (TQ) is fixed for all available processes. So,\nthe larger process suffers from Context Switches (CS). To increase efficiency,\nwe have to select different TQ for processes. The main objective of RR is to\nreduce the CS, maximize the utilization of CPU and minimize the turn around and\nthe waiting time. In this paper, we have considered different TQ for a group of\nprocesses. It reduces CS as well as enhancing the performance of RR algorithm.\nTQ can be calculated using min-max dispersion measure. Our experimental\nanalysis shows that Group Based Time Quantum (GBTQ) RR algorithm performs\nbetter than existing RR algorithm with respect to Average Turn Around Time\n(ATAT), Average Waiting Time (AWT) and CS."
},{
    "category": "cs.OS", 
    "doi": "10.5120/10667-5445", 
    "link": "http://arxiv.org/pdf/1403.5010v1", 
    "other_authors": "Kexing Xing, Decheng Zuo, Haiying Zhou, Hou Kun-Mean", 
    "title": "Task & Resource Self-adaptive Embedded Real-time Operating System   Microkernel for Wireless Sensor Nodes", 
    "arxiv-id": "1403.5010v1", 
    "author": "Hou Kun-Mean", 
    "publish": "2014-03-20T00:34:00Z", 
    "summary": "Wireless Sensor Networks (WSNs) are used in many application fields, such as\nmilitary, healthcare, environment surveillance, etc. The WSN OS based on\nevent-driven model doesn't support real-time and multi-task application types\nand the OSs based on thread-driven model consume much energy because of\nfrequent context switch. Due to the high-dense and large-scale deployment of\nsensor nodes, it is very difficult to collect sensor nodes to update their\nsoftware. Furthermore, the sensor nodes are vulnerable to security attacks\nbecause of the characteristics of broadcast communication and unattended\napplication. This paper presents a task and resource self-adaptive embedded\nreal-time microkernel, which proposes hybrid programming model and offers a\ntwo-level scheduling strategy to support real-time multi-task correspondingly.\nA communication scheme, which takes the \"tuple\" space and \"IN/OUT\" primitives\nfrom \"LINDA\", is proposed to support some collaborative and distributed tasks.\nIn addition, this kernel implements a run-time over-the-air updating mechanism\nand provides a security policy to avoid the attacks and ensure the reliable\noperation of nodes. The performance evaluation is proposed and the experiential\nresults show this kernel is task-oriented and resource-aware and can be used\nfor the applications of event-driven and real-time multi-task."
},{
    "category": "cs.OS", 
    "doi": "10.5120/10667-5445", 
    "link": "http://arxiv.org/pdf/1403.5976v1", 
    "other_authors": "Brijender Kahanwal", 
    "title": "File System Design Approaches", 
    "arxiv-id": "1403.5976v1", 
    "author": "Brijender Kahanwal", 
    "publish": "2014-03-21T05:31:33Z", 
    "summary": "In this article, the file system development design approaches are discussed.\nThe selection of the file system design approach is done according to the needs\nof the developers what are the needed requirements and specifications for the\nnew design. It allowed us to identify where our proposal fitted in with\nrelation to current and past file system development. Our experience with file\nsystem development is limited so the research served to identify the different\ntechniques that can be used. The variety of file systems encountered show what\nan active area of research file system development is. The file systems may be\nfrom one of the two fundamental categories. In one category, the file system is\ndeveloped in user space and runs as a user process. Another file system may be\ndeveloped in the kernel space and runs as a privileged process. Another one is\nthe mixed approach in which we can take the advantages of both aforesaid\napproaches. Each development option has its own pros and cons. In this article,\nthese design approaches are discussed."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.145.6", 
    "link": "http://arxiv.org/pdf/1404.0088v1", 
    "other_authors": "Youcheng Sun, Giuseppe Lipari, \u00c9tienne Andr\u00e9, Laurent Fribourg", 
    "title": "Toward Parametric Timed Interfaces for Real-Time Components", 
    "arxiv-id": "1404.0088v1", 
    "author": "Laurent Fribourg", 
    "publish": "2014-04-01T00:40:01Z", 
    "summary": "We propose here a framework to model real-time components consisting of\nconcurrent real-time tasks running on a single processor, using parametric\ntimed automata. Our framework is generic and modular, so as to be easily\nadapted to different schedulers and more complex task models. We first perform\na parametric schedulability analysis of the components using the inverse\nmethod. We show that the method unfortunately does not provide satisfactory\nresults when the task periods are consid- ered as parameters. After identifying\nand explaining the problem, we present a solution adapting the model by making\nuse of the worst-case scenario in schedulability analysis. We show that the\nanalysis with the inverse method always converges on the modified model when\nthe system load is strictly less than 100%. Finally, we show how to use our\nparametric analysis for the generation of timed interfaces in compositional\nsystem design."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.145.6", 
    "link": "http://arxiv.org/pdf/1404.1637v1", 
    "other_authors": "Yauhen Klimiankou", 
    "title": "An Enhanced Multi-Pager Environment Support for Second Generation   Microkernels", 
    "arxiv-id": "1404.1637v1", 
    "author": "Yauhen Klimiankou", 
    "publish": "2014-04-06T23:53:01Z", 
    "summary": "The main objective of this paper is to present a mechanism of enhanced paging\nsupport for the second generation microkernels in the form of explicit support\nof multi-pager environment for the tasks running in the system. Proposed\nmechanism is based on the intra-kernel high granularity pagers assignments per\nvirtual address space, which allow efficient and simple dispatching of page\nfaults to the appropriate pagers. The paging is one of the major features of\nthe virtual memory, which is extensively used by advanced operating systems to\nprovide an illusion of elastic memory. Original and present second generation\nmicrokernels provide only limited, inflexible and unnatural support for paging.\nFurthermore, facilities provided by current solutions for multi-pager support\non the runtime level introduce an overhead in terms of mode switches and thread\ncontext switches which can be significantly reduced. Limited paging support\nlimits the attractiveness of the second generation microkernel based systems\nuse in real-life applications, in which processes usually have concurrent\nservicing of multiple paging servers. The purpose of this paper is to present a\nfacilities for the efficient and flexible support of multi-pager environments\nfor the second generation microkernels. A comparison of the proposed solution\nto the present architecture L4 + L4Re has been made and overhead of the page\nfault handling critical path has been evaluated. Proposed solution is simple\nenough and provides a natural and flexible support of multi-pager environments\nfor second generation microkernels in efficient way. It introduces a third less\noverhead in terms of the mode switches and thread context switches in\ncomparison to the present L4 + L4Re solution implemented in the Fiasco.OC."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.145.6", 
    "link": "http://arxiv.org/pdf/1404.5869v1", 
    "other_authors": "Sanjaya Kumar Panda, Sourav Kumar Bhoi", 
    "title": "An Effective Round Robin Algorithm using Min-Max Dispersion Measure", 
    "arxiv-id": "1404.5869v1", 
    "author": "Sourav Kumar Bhoi", 
    "publish": "2014-04-23T15:55:50Z", 
    "summary": "Round Robin (RR) scheduling algorithm is a preemptive scheduling algorithm.\nIt is designed especially for time sharing Operating System (OS). In RR\nscheduling algorithm the CPU switches between the processes when the static\nTime Quantum (TQ) expires. RR scheduling algorithm is considered as the most\nwidely used scheduling algorithm in research because the TQ is equally shared\namong the processes. In this paper a newly proposed variant of RR algorithm\ncalled Min-Max Round Robin (MMRR) scheduling algorithm is presented. The idea\nof this MMRR is to make the TQ repeatedly adjusted using Min-Max dispersion\nmeasure in accordance with remaining CPU burst time. Our experimental analysis\nshows that MMRR performs much better than RR algorithm in terms of average\nturnaround time, average waiting time and number of context switches."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.145.6", 
    "link": "http://arxiv.org/pdf/1404.6087v1", 
    "other_authors": "Sourav Kumar Bhoi, Sanjaya Kumar Panda, Debashee Tarai", 
    "title": "Enhancing CPU Performance using Subcontrary Mean Dynamic Round Robin   (SMDRR) Scheduling Algorithm", 
    "arxiv-id": "1404.6087v1", 
    "author": "Debashee Tarai", 
    "publish": "2014-04-24T11:06:06Z", 
    "summary": "Round Robin (RR) Algorithm is considered as optimal in time shared\nenvironment because the static time is equally shared among the processes. If\nthe time quantum taken is static then it undergoes degradation of the CPU\nperformance and leads to so many context switches. In this paper, we have\nproposed a new effective dynamic RR algorithm SMDRR (Subcontrary Mean Dynamic\nRound Robin) based on dynamic time quantum where we use the subcontrary mean or\nharmonic mean to find the time quantum. The idea of this approach is to make\nthe time quantum repeatedly adjusted according to the burst time of the\ncurrently running processes. Our experimental analysis shows that SMDRR\nperforms better than RR algorithm in terms of reducing the number of context\nswitches, average turnaround time and average waiting time."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.145.6", 
    "link": "http://arxiv.org/pdf/1405.2912v1", 
    "other_authors": "Mario Kicherer, Wolfgang Karl", 
    "title": "Heterogeneity-aware Fault Tolerance using a Self-Organizing Runtime   System", 
    "arxiv-id": "1405.2912v1", 
    "author": "Wolfgang Karl", 
    "publish": "2014-05-12T16:41:23Z", 
    "summary": "Due to the diversity and implicit redundancy in terms of processing units and\ncompute kernels, off-the-shelf heterogeneous systems offer the opportunity to\ndetect and tolerate faults during task execution in hardware as well as in\nsoftware. To automatically leverage this diversity, we introduce an extension\nof an online-learning runtime system that combines the benefits of the existing\nperformance-oriented task mapping with task duplication, a diversity-oriented\nmapping strategy and heterogeneity-aware majority voter. This extension uses a\nnew metric to dynamically rate the remaining benefit of unreliable processing\nunits and a memory management mechanism for automatic data transfers and\ncheckpointing in the host and device memories."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.145.6", 
    "link": "http://arxiv.org/pdf/1405.7322v1", 
    "other_authors": "Guangmo Tong, Cong Liu", 
    "title": "Supporting Soft Real-Time Sporadic Task Systems on Heterogeneous   Multiprocessors with No Utilization Loss", 
    "arxiv-id": "1405.7322v1", 
    "author": "Cong Liu", 
    "publish": "2014-05-28T18:28:45Z", 
    "summary": "Heterogeneous multicore architectures are becoming increasingly popular due\nto their potential of achieving high performance and energy efficiency compared\nto the homogeneous multicore architectures. In such systems, the real-time\nscheduling problem becomes more challenging in that processors have different\nspeeds. A job executing on a processor with speed $x$ for $t$ time units\ncompletes $(x \\cdot t)$ units of execution. Prior research on heterogeneous\nmultiprocessor real-time scheduling has focused on hard real-time systems,\nwhere, significant processing capacity may have to be sacrificed in the\nworst-case to ensure that all deadlines are met. As meeting hard deadlines is\noverkill for many soft real-time systems in practice, this paper shows that on\nsoft real-time heterogeneous multiprocessors, bounded response times can be\nensured for globally-scheduled sporadic task systems with no utilization loss.\nA GEDF-based scheduling algorithm, namely GEDF-H, is presented and response\ntime bounds are established under both preemptive and non-preemptive GEDF-H\nscheduling. Extensive experiments show that the magnitude of the derived\nresponse time bound is reasonable, often smaller than three task periods. To\nthe best of our knowledge, this paper is the first to show that soft real-time\nsporadic task systems can be supported on heterogeneous multiprocessors without\nutilization loss, and with reasonable predicted response time."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1408.0990v1", 
    "other_authors": "M. V. Panduranga Rao, K. C. Shet", 
    "title": "Assessment of Response Time for New Multi Level Feedback Queue Scheduler", 
    "arxiv-id": "1408.0990v1", 
    "author": "K. C. Shet", 
    "publish": "2014-08-02T19:56:24Z", 
    "summary": "Response time is one of the characteristics of scheduler, happens to be a\nprominent attribute of any CPU scheduling algorithm. The proposed New Multi\nLevel Feedback Queue [NMLFQ] Scheduler is compared with dynamic, real time,\nDependent Activity Scheduling Algorithm (DASA) and Lockes Best Effort\nScheduling Algorithm (LBESA). We abbreviated beneficial result of NMLFQ\nscheduler in comparison with dynamic best effort schedulers with respect to\nresponse time."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1411.3777v1", 
    "other_authors": "Ardalan Amiri Sani, Lin Zhong, Dan S. Wallach", 
    "title": "Glider: A GPU Library Driver for Improved System Security", 
    "arxiv-id": "1411.3777v1", 
    "author": "Dan S. Wallach", 
    "publish": "2014-11-14T02:30:08Z", 
    "summary": "Legacy device drivers implement both device resource management and\nisolation. This results in a large code base with a wide high-level interface\nmaking the driver vulnerable to security attacks. This is particularly\nproblematic for increasingly popular accelerators like GPUs that have large,\ncomplex drivers. We solve this problem with library drivers, a new driver\narchitecture. A library driver implements resource management as an untrusted\nlibrary in the application process address space, and implements isolation as a\nkernel module that is smaller and has a narrower lower-level interface (i.e.,\ncloser to hardware) than a legacy driver. We articulate a set of device and\nplatform hardware properties that are required to retrofit a legacy driver into\na library driver. To demonstrate the feasibility and superiority of library\ndrivers, we present Glider, a library driver implementation for two GPUs of\npopular brands, Radeon and Intel. Glider reduces the TCB size and attack\nsurface by about 35% and 84% respectively for a Radeon HD 6450 GPU and by about\n38% and 90% respectively for an Intel Ivy Bridge GPU. Moreover, it incurs no\nperformance cost. Indeed, Glider outperforms a legacy driver for applications\nrequiring intensive interactions with the device driver, such as applications\nusing the OpenGL immediate mode API."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1501.07084v3", 
    "other_authors": "Jian-Jia Chen, Wen-Hung Huang, Cong Liu", 
    "title": "k2U: A General Framework from k-Point Effective Schedulability Analysis   to Utilization-Based Tests", 
    "arxiv-id": "1501.07084v3", 
    "author": "Cong Liu", 
    "publish": "2015-01-28T12:38:20Z", 
    "summary": "To deal with a large variety of workloads in different application domains in\nreal-time embedded systems, a number of expressive task models have been\ndeveloped. For each individual task model, researchers tend to develop\ndifferent types of techniques for deriving schedulability tests with different\ncomputation complexity and performance. In this paper, we present a general\nschedulability analysis framework, namely the k2U framework, that can be\npotentially applied to analyze a large set of real-time task models under any\nfixed-priority scheduling algorithm, on both uniprocessor and multiprocessor\nscheduling. The key to k2U is a k-point effective schedulability test, which\ncan be viewed as a \"blackbox\" interface. For any task model, if a corresponding\nk-point effective schedulability test can be constructed, then a sufficient\nutilization-based test can be automatically derived. We show the generality of\nk2U by applying it to different task models, which results in new and improved\ntests compared to the state-of-the-art.\n  Analogously, a similar concept by testing only k points with a different\nformulation has been studied by us in another framework, called k2Q, which\nprovides quadratic bounds or utilization bounds based on a different\nformulation of schedulability test. With the quadratic and hyperbolic forms,\nk2Q and k2U frameworks can be used to provide many quantitive features to be\nmeasured, like the total utilization bounds, speed-up factors, etc., not only\nfor uniprocessor scheduling but also for multiprocessor scheduling. These\nframeworks can be viewed as a \"blackbox\" interface for schedulability tests and\nresponse-time analysis."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1502.01509v1", 
    "other_authors": "Camille Coti, Nicolas Greneche", 
    "title": "OS-level Failure Injection with SystemTap", 
    "arxiv-id": "1502.01509v1", 
    "author": "Nicolas Greneche", 
    "publish": "2015-02-05T11:36:45Z", 
    "summary": "Failure injection in distributed systems has been an important issue to\nexperiment with robust, resilient distributed systems. In order to reproduce\nreal-life conditions, parts of the application must be killed without letting\nthe operating system close the existing network communications in a \"clean\"\nway. When a process is simply killed, the OS closes them. SystemTap is a an\ninfrastructure that probes the Linux kernel's internal calls. If processes are\nkilled at kernel-level, they can be destroyed without letting the OS do\nanything else. In this paper, we present a kernel-level failure injection\nsystem based on SystemTap. We present how it can be used to implement\ndeterministic and probabilistic failure scenarios."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1502.02287v1", 
    "other_authors": "Heechul Yun, Santosh Gondi, Siddhartha Biswas", 
    "title": "Protecting Memory-Performance Critical Sections in Soft Real-Time   Applications", 
    "arxiv-id": "1502.02287v1", 
    "author": "Siddhartha Biswas", 
    "publish": "2015-02-08T19:09:36Z", 
    "summary": "Soft real-time applications such as multimedia applications often show bursty\nmemory access patterns---regularly requiring a high memory bandwidth for a\nshort duration of time. Such a period is often critical for timely data\nprocessing. Hence, we call it a memory-performance critical section.\nUnfortunately, in multicore architecture, non-real-time applications on\ndifferent cores may also demand high memory bandwidth at the same time, which\ncan substantially increase the time spent on the memory performance critical\nsections.\n  In this paper, we present BWLOCK, user-level APIs and a memory bandwidth\ncontrol mechanism that can protect such memory performance critical sections of\nsoft real-time applications. BWLOCK provides simple lock like APIs to declare\nmemory-performance critical sections. If an application enters a\nmemory-performance critical section, the memory bandwidth control system then\ndynamically limit other cores' memory access rates to protect memory\nperformance of the application until the critical section finishes.\n  From case studies with real-world soft real-time applications, we found (1)\nsuch memory-performance critical sections do exist and are often easy to\nidentify; and (2) applying BWLOCK for memory critical sections significantly\nimprove performance of the soft real-time applications at a small or no cost in\nthroughput of non real-time applications."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1504.02517v2", 
    "other_authors": "Tuhin Borgohain, Uday Kumar, Sugata Sanyal", 
    "title": "Survey of Operating Systems for the IoT Environment", 
    "arxiv-id": "1504.02517v2", 
    "author": "Sugata Sanyal", 
    "publish": "2015-04-09T23:17:01Z", 
    "summary": "This paper is a comprehensive survey of the various operating systems\navailable for the Internet of Things environment. At first the paper introduces\nthe various aspects of the operating systems designed for the IoT environment\nwhere resource constraint poses a huge problem for the operation of the general\nOS designed for the various computing devices. The latter part of the paper\ndescribes the various OS available for the resource constraint IoT environment\nalong with the various platforms each OS supports, the software development\nkits available for the development of applications in the respective OS along\nwith the various protocols implemented in these OS for the purpose of\ncommunication and networking."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1504.04640v2", 
    "other_authors": "Dave Dice, Tim Harris, Alex Kogan, Yossi Lev", 
    "title": "The Influence of Malloc Placement on TSX Hardware Transactional Memory", 
    "arxiv-id": "1504.04640v2", 
    "author": "Yossi Lev", 
    "publish": "2015-04-17T21:13:07Z", 
    "summary": "The hardware transactional memory (HTM) implementation in Intel's i7-4770\n\"Haswell\" processor tracks the transactional read-set in the L1 (level-1), L2\n(level-2) and L3 (level-3) caches and the write-set in the L1 cache.\nDisplacement or eviction of read-set entries from the cache hierarchy or\nwrite-set entries from the L1 results in abort. We show that the placement\npolicies of dynamic storage allocators -- such as those found in common\n\"malloc\" implementations -- can influence the L1 conflict miss rate in the L1.\nConflict misses -- sometimes called mapping misses -- arise because of less\nthan ideal associativity and represent imbalanced distribution of active memory\nblocks over the set of available L1 indices. Under transactional execution\nconflict misses may manifest as aborts, representing wasted or futile effort\ninstead of a simple stall as would occur in normal execution mode.\n  Furthermore, when HTM is used for transactional lock elision (TLE),\npersistent aborts arising from conflict misses can force the offending thread\nthrough the so-called \"slow path\". The slow path is undesirable as the thread\nmust acquire the lock and run the critical section in normal execution mode,\nprecluding the concurrent execution of threads in the \"fast path\" that monitor\nthat same lock and run their critical sections in transactional mode. For a\ngiven lock, multiple threads can concurrently use the transactional fast path,\nbut at most one thread can use the non-transactional slow path at any given\ntime. Threads in the slow path preclude safe concurrent fast path execution.\nAborts rising from placement policies and L1 index imbalance can thus result in\nloss of concurrency and reduced aggregate throughput."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1504.07070v2", 
    "other_authors": "Weiyi Wu, Bryan Ford", 
    "title": "Deterministically Deterring Timing Attacks in Deterland", 
    "arxiv-id": "1504.07070v2", 
    "author": "Bryan Ford", 
    "publish": "2015-04-27T13:08:26Z", 
    "summary": "The massive parallelism and resource sharing embodying today's cloud business\nmodel not only exacerbate the security challenge of timing channels, but also\nundermine the viability of defenses based on resource partitioning. We propose\nhypervisor-enforced timing mitigation to control timing channels in cloud\nenvironments. This approach closes \"reference clocks\" internal to the cloud by\nimposing a deterministic view of time on guest code, and uses timing mitigators\nto pace I/O and rate-limit potential information leakage to external observers.\nOur prototype hypervisor is the first system to mitigate timing-channel leakage\nacross full-scale existing operating systems such as Linux and applications in\narbitrary languages. Mitigation incurs a varying performance cost, depending on\nworkload and tunable leakage-limiting parameters, but this cost may be\njustified for security-critical cloud applications and data."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1505.05269v1", 
    "other_authors": "Alok Ranjan, H. B. Sahu, Prasant Misra", 
    "title": "A Survey Report on Operating Systems for Tiny Networked Sensors", 
    "arxiv-id": "1505.05269v1", 
    "author": "Prasant Misra", 
    "publish": "2015-05-20T07:47:20Z", 
    "summary": "Wireless sensor network (WSN) has attracted researchers worldwide to explore\nthe research opportunities, with application mainly in health monitoring,\nindustry automation, battlefields, home automation and environmental\nmonitoring. A WSN is highly resource constrained in terms of energy,\ncomputation and memory. WSNs deployment ranges from the normal working\nenvironment up to hostile and hazardous environment such as in volcano\nmonitoring and underground mines. These characteristics of WSNs hold additional\nset of challenges in front of the operating system designer. The objective of\nthis survey is to highlight the features and weakness of the opearting system\navailable for WSNs, with the focus on the current application demands. The\npaper also discusses the operating system design issues in terms of\narchitecture, programming model, scheduling and memory management and support\nfor real time applications."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1506.07566v1", 
    "other_authors": "Da Zheng, Randal Burns, Alexander S. Szalay", 
    "title": "Optimize Unsynchronized Garbage Collection in an SSD Array", 
    "arxiv-id": "1506.07566v1", 
    "author": "Alexander S. Szalay", 
    "publish": "2015-06-24T21:14:27Z", 
    "summary": "Solid state disks (SSDs) have advanced to outperform traditional hard drives\nsignificantly in both random reads and writes. However, heavy random writes\ntrigger fre- quent garbage collection and decrease the performance of SSDs. In\nan SSD array, garbage collection of individ- ual SSDs is not synchronized,\nleading to underutilization of some of the SSDs.\n  We propose a software solution to tackle the unsyn- chronized garbage\ncollection in an SSD array installed in a host bus adaptor (HBA), where\nindividual SSDs are exposed to an operating system. We maintain a long I/O\nqueue for each SSD and flush dirty pages intelligently to fill the long I/O\nqueues so that we hide the performance imbalance among SSDs even when there are\nfew parallel application writes. We further define a policy of select- ing\ndirty pages to flush and a policy of taking out stale flush requests to reduce\nthe amount of data written to SSDs. We evaluate our solution in a real system.\nExperi- ments show that our solution fully utilizes all SSDs in an array under\nrandom write-heavy workloads. It improves I/O throughput by up to 62% under\nrandom workloads of mixed reads and writes when SSDs are under active garbage\ncollection. It causes little extra data writeback and increases the cache hit\nrate."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1508.06356v2", 
    "other_authors": "Yan Cui, Quan Chen, Junfeng Yang", 
    "title": "EOS: Automatic In-vivo Evolution of Kernel Policies for Better   Performance", 
    "arxiv-id": "1508.06356v2", 
    "author": "Junfeng Yang", 
    "publish": "2015-08-26T03:43:38Z", 
    "summary": "Today's monolithic kernels often implement a small, fixed set of policies\nsuch as disk I/O scheduling policies, while exposing many parameters to let\nusers select a policy or adjust the specific setting of the policy. Ideally,\nthe parameters exposed should be flexible enough for users to tune for good\nperformance, but in practice, users lack domain knowledge of the parameters and\nare often stuck with bad, default parameter settings.\n  We present EOS, a system that bridges the knowledge gap between kernel\ndevelopers and users by automatically evolving the policies and parameters in\nvivo on users' real, production workloads. It provides a simple policy\nspecification API for kernel developers to programmatically describe how the\npolicies and parameters should be tuned, a policy cache to make in-vivo tuning\neasy and fast by memorizing good parameter settings for past workloads, and a\nhierarchical search engine to effectively search the parameter space.\nEvaluation of EOS on four main Linux subsystems shows that it is easy to use\nand effectively improves each subsystem's performance."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1508.06367v2", 
    "other_authors": "Piyus Kedia, Sorav Bansal", 
    "title": "A Software-only Mechanism for Device Passthrough and Sharing", 
    "arxiv-id": "1508.06367v2", 
    "author": "Sorav Bansal", 
    "publish": "2015-08-26T05:20:50Z", 
    "summary": "Network processing elements in virtual machines, also known as Network\nFunction Virtualization (NFV) often face CPU bottlenecks at the virtualization\ninterface. Even highly optimized paravirtual device interfaces fall short of\nthe throughput requirements of modern devices. Passthrough devices, together\nwith SR-IOV support for multiple device virtual functions (VF) and IOMMU\nsupport, mitigate this problem somewhat, by allowing a VM to directly control a\ndevice partition bypassing the virtualization stack. However, device\npassthrough requires high-end (expensive and power-hungry) hardware, places\nscalability limits on consolidation ratios, and does not support efficient\nswitching between multiple VMs on the same host.\n  We present a paravirtual interface that securely exposes an I/O device\ndirectly to the guest OS running inside the VM, and yet allows that device to\nbe securely shared among multiple VMs and the host. Compared to the best-known\nparavirtualization interfaces, our paravirtual interface supports up to 2x\nhigher throughput, and is closer in performance to device passthrough. Unlike\ndevice passthrough however, we do not require SR-IOV or IOMMU support, and\nallow fine-grained dynamic resource allocation, significantly higher\nconsolidation ratios, and seamless VM migration. Our security mechanism is\nbased on a novel approach called dynamic binary opcode subtraction."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1509.07694v1", 
    "other_authors": "Victor Yodaiken", 
    "title": "Folding a Tree into a Map", 
    "arxiv-id": "1509.07694v1", 
    "author": "Victor Yodaiken", 
    "publish": "2015-09-25T12:37:09Z", 
    "summary": "Analysis of the retrieval architecture of the highly influential UNIX file\nsystem (\\cite{Ritchie}\\cite{multicsfs}) provides insight into design methods,\nconstraints, and possible alternatives. The basic architecture can be\nunderstood in terms of function composition and recursion by anyone with some\nmathematical maturity. Expertise in operating system coding or in any\nspecialized \"formal method\" is not required."
},{
    "category": "cs.OS", 
    "doi": "10.14445/22312803/IJCTT-V13P124", 
    "link": "http://arxiv.org/pdf/1510.02552v1", 
    "other_authors": "Haryono Haryono", 
    "title": "Multitasking Programming of OBDH Satellite Based On PC-104", 
    "arxiv-id": "1510.02552v1", 
    "author": "Haryono Haryono", 
    "publish": "2015-10-09T02:58:40Z", 
    "summary": "On Board Data Handling (OBDH) has functions to monitor, control, acquire,\nanalyze, take a decision, and execute the command. OBDH should organize the\ntask between sub system. OBDH like a heart which has a vital function. Because\nthe function is seriously important therefore designing and implementing the\nOBDH should be carefully, in order to have a good reliability. Many OBDHs have\nbeen made to support the satellite mission using primitive programming. In\nhandling the data from various input, OBDH should always be available to all\nsub systems, when the tasks are many, it is not easy to program using primitive\nprogramming. Sometimes the data become corrupt because the data which come to\nthe OBDH is in the same time. Therefore it is required to have a way to handle\nthe data safely and also easy in programming perspective. In this research,\nOBDH is programmed using multi tasking programming perspective has been\ncreated. The Operating System (OS) has been implemented so that can run the\ntasks simultaneously. The OS is prepared by configuring the Linux Kernel for\nthe specific processor, creating Root File System (RFS), installing the\nBusyBox. In order to do the above method, preparing the environment in our\nmachine has been done, they are installing the Cross Tool Chain, U-Boot,\nGNU-Linux Kernel Source etc. After that, programming using c code with\nmultitasking programming can be implemented. By using above method, it is found\nthat programming is easier and the corruption data because of reentrancy can be\nminimized. Keywords- Operating System, PC-104, Kernel, C Programming"
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1511.02498v1", 
    "other_authors": "Amar Ranjan Dash, Sandipta Kumar Sahu, Sanjay Kumar Samantra, Sradhanjali Sabat", 
    "title": "Characteristic specific prioritized dynamic average burst round robin   scheduling for uniprocessor and multiprocessor environment", 
    "arxiv-id": "1511.02498v1", 
    "author": "Sradhanjali Sabat", 
    "publish": "2015-11-08T15:44:59Z", 
    "summary": "CPU scheduling is one of the most crucial operations performed by operating\nsystems. Different conventional algorithms like FCFS, SJF, Priority, and RR\n(Round Robin) are available for CPU Scheduling. The effectiveness of Priority\nand Round Robin scheduling algorithm completely depends on selection of\npriority features of processes and on the choice of time quantum. In this paper\na new CPU scheduling algorithm has been proposed, named as CSPDABRR\n(Characteristic specific Prioritized Dynamic Average Burst Round Robin), that\nuses seven priority features for calculating priority of processes and uses\ndynamic time quantum instead of static time quantum used in RR. The performance\nof the proposed algorithm is experimentally compared with traditional RR and\nPriority scheduling algorithm in both uni-processor and multi-processor\nenvironment. The results of our approach presented in this paper demonstrate\nimproved performance in terms of average waiting time, average turnaround time,\nand optimal priority feature."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1512.00727v2", 
    "other_authors": "Gil Einziger, Roy Friedman, Ben Manes", 
    "title": "TinyLFU: A Highly Efficient Cache Admission Policy", 
    "arxiv-id": "1512.00727v2", 
    "author": "Ben Manes", 
    "publish": "2015-12-02T15:05:46Z", 
    "summary": "This paper proposes to use a frequency based cache admission policy in order\nto boost the effectiveness of caches subject to skewed access distributions.\nGiven a newly accessed item and an eviction candidate from the cache, our\nscheme decides, based on the recent access history, whether it is worth\nadmitting the new item into the cache at the expense of the eviction candidate.\n  Realizing this concept is enabled through a novel approximate LFU structure\ncalled TinyLFU, which maintains an approximate representation of the access\nfrequency of a large sample of recently accessed items. TinyLFU is very compact\nand light-weight as it builds upon Bloom filter theory.\n  We study the properties of TinyLFU through simulations of both synthetic\nworkloads as well as multiple real traces from several sources. These\nsimulations demonstrate the performance boost obtained by enhancing various\nreplacement policies with the TinyLFU eviction policy. Also, a new combined\nreplacement and eviction policy scheme nicknamed W-TinyLFU is presented.\nW-TinyLFU is demonstrated to obtain equal or better hit-ratios than other state\nof the art replacement policies on these traces. It is the only scheme to\nobtain such good results on all traces."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1512.01978v1", 
    "other_authors": "Giuseppe Lipari, Luigi Palopoli", 
    "title": "Real-Time scheduling: from hard to soft real-time systems", 
    "arxiv-id": "1512.01978v1", 
    "author": "Luigi Palopoli", 
    "publish": "2015-12-07T11:05:05Z", 
    "summary": "Real-time systems are traditionally classified into hard real-time and soft\nreal-time: in the first category we have safety critical real-time systems\nwhere missing a deadline can have catastrophic consequences, whereas in the\nsecond class we find systems or which we need to optimise the Quality of\nservice provided to the user. However, the frontier between these two classes\nis thinner than one may think, and many systems that were considered as hard\nreal-time in the past should now be reconsidered under a different light. In\nthis paper we shall first recall the fundamental notion of time-predictability\nand criticality, in order to understand where the real-time deadlines that we\nuse in our theoretical models come from. We shall then introduce the model of a\nsoft real-time system and present one popular method for scheduling hard and\nsoft real-time tasks, the resource reservation framework. Finally, we shall\nshow how resource reservation techniques can be successfully applied to the\ndesign of classical control systems, thus adding robustness to the system and\nincreasing resource utilisation and performance."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1512.01984v2", 
    "other_authors": "Luca Abeni, Giuseppe Lipari, Andrea Parri, Youcheng Sun", 
    "title": "Parallel and sequential reclaiming in multicore real-time global   scheduling", 
    "arxiv-id": "1512.01984v2", 
    "author": "Youcheng Sun", 
    "publish": "2015-12-07T11:16:43Z", 
    "summary": "When integrating hard, soft and non-real-time tasks in general purpose\noperating systems, it is necessary to provide temporal isolation so that the\ntiming properties of one task do not depend on the behaviour of the others.\nHowever, strict budget enforcement can lead to inefficient use of the\ncomputational resources in the presence of tasks with variable workload. Many\nresource reclaiming algorithms have been proposed in the literature for single\nprocessor scheduling, but not enough work exists for global scheduling in\nmultiprocessor systems. In this report, we propose two reclaiming algorithms\nfor multiprocessor global scheduling and we prove their correctness."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1512.06908v1", 
    "other_authors": "Yan Cui", 
    "title": "Research on Scalability of Operating Systems on Multicore Processors", 
    "arxiv-id": "1512.06908v1", 
    "author": "Yan Cui", 
    "publish": "2015-12-21T23:35:42Z", 
    "summary": "Large number of cores and hardware resource sharing are two characteristics\non multicore processors, which bring new challenges for the design of operating\nsystems. How to locate and analyze the speedup restrictive factors in operating\nsystems, how to simulate and avoid the phenomenon that speedup decreases with\nthe number of cores because of lock contention (i.e., lock thrashing) and how\nto avoid the contention of shared resources such as the last level cache are\nkey challenges for the operating system scalability research on multicore\nsystems."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1512.07351v1", 
    "other_authors": "Yao Guo, Junyang Lu", 
    "title": "Energy-aware Fixed-Priority Multi-core Scheduling for Real-time Systems", 
    "arxiv-id": "1512.07351v1", 
    "author": "Junyang Lu", 
    "publish": "2015-12-23T04:39:00Z", 
    "summary": "Multi-core processors are becoming more and more popular in embedded and\nreal-time systems. While fixed-priority scheduling with task-splitting in\nreal-time systems are widely applied, current approaches have not taken into\nconsideration energy-aware aspects such as dynamic voltage/frequency scheduling\n(DVS). In this paper, we propose two strategies to apply dynamic voltage\nscaling (DVS) to fixed-priority scheduling algorithms with task-splitting for\nperiodic real-time tasks on multi-core processors. The first strategy\ndetermines voltage scales for each processor after scheduling (Static DVS),\nwhich ensures all tasks meet the timing requirements on synchronization. The\nsecond strategy adaptively determines the frequency of each task before\nscheduling (Adaptive DVS) according to the total utilization of task-set and\nnumber of cores available. The combination of frequency pre-allocation and\ntask-splitting makes it possible to maximize energy savings with DVS.\nSimulation results show that it is possible to achieve significant energy\nsavings with DVS while preserving the schedulability requirements of real-time\nschedulers for multi-core processors."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1512.07654v3", 
    "other_authors": "Eric Missimer, Katherine Zhao, Richard West", 
    "title": "Mixed-Criticality Scheduling with I/O", 
    "arxiv-id": "1512.07654v3", 
    "author": "Richard West", 
    "publish": "2015-12-23T22:41:04Z", 
    "summary": "This paper addresses the problem of scheduling tasks with different\ncriticality levels in the presence of I/O requests. In mixed-criticality\nscheduling, higher criticality tasks are given precedence over those of lower\ncriticality when it is impossible to guarantee the schedulability of all tasks.\nWhile mixed-criticality scheduling has gained attention in recent years, most\napproaches typically assume a periodic task model. This assumption does not\nalways hold in practice, especially for real-time and embedded systems that\nperform I/O. For example, many tasks block on I/O requests until devices signal\ntheir completion via interrupts; both the arrival of interrupts and the waking\nof blocked tasks can be aperiodic. In our prior work, we developed a scheduling\ntechnique in the Quest real-time operating system, which integrates the\ntime-budgeted management of I/O operations with Sporadic Server scheduling of\ntasks. This paper extends our previous scheduling approach with support for\nmixed-criticality tasks and I/O requests on the same processing core. Results\nshow the effective schedulability of different task sets in the presence of I/O\nrequests is superior in our approach compared to traditional methods that\nmanage I/O using techniques such as Sporadic Servers."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1603.05636v1", 
    "other_authors": "Harshal Sheth, Aashish Welling", 
    "title": "An Implementation and Analysis of a Kernel Network Stack in Go with the   CSP Style", 
    "arxiv-id": "1603.05636v1", 
    "author": "Aashish Welling", 
    "publish": "2016-03-17T19:43:36Z", 
    "summary": "Modern operating system kernels are written in lower-level languages such as\nC. Although the low-level functionalities of C are often useful within kernels,\nthey also give rise to several classes of bugs. Kernels written in higher level\nlanguages avoid many of these potential problems, at the possible cost of\ndecreased performance. This research evaluates the advantages and disadvantages\nof a kernel written in a higher level language. To do this, the network stack\nsubsystem of the kernel was implemented in Go with the Communicating Sequential\nProcesses (CSP) style. Go is a high-level programming language that supports\nthe CSP style, which recommends splitting large tasks into several smaller ones\nrunning in independent \"threads\". Modules for the major networking protocols,\nincluding Ethernet, ARP, IPv4, ICMP, UDP, and TCP, were implemented. In this\nstudy, the implemented Go network stack, called GoNet, was compared to a\nrepresentative network stack written in C. The GoNet code is more readable and\ngenerally performs better than that of its C stack counterparts. From this, it\ncan be concluded that Go with CSP style is a viable alternative to C for the\nlanguage of kernel implementations."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1604.01378v2", 
    "other_authors": "Gang Lu, Jianfeng Zhan, Chongkang Tan, Xinlong Lin, Lei Wang, Defei Kong, Tianshu Hao, Fei Tang", 
    "title": "\"Isolate First, Then Share\": a New OS Architecture for the Worst-case   Performance", 
    "arxiv-id": "1604.01378v2", 
    "author": "Fei Tang", 
    "publish": "2016-04-05T19:33:27Z", 
    "summary": "Previous OS abstractions and structures are mainly proposed for the average\nperformance. The shift toward server side computing calls for new OS structures\nfor the worst-case performance. This paper presents the \"isolate first, then\nshare\" OS architecture. We decompose the OS into the supervisor and several\nsubOSes running in parallel: a subOS directly manages physical resources\nwithout intervention from the supervisor (isolate resources first), while the\nsupervisor can create, destroy, resize a subOS on-the-fly (then share). SubOSes\nand supervisor have confined state sharing (isolate states first), but fast\ninter-subOS communication mechanisms are provided on demand (then share).\n  We present the first implementation-RainForest, which supports unmodified\nLinux applications binaries. Our comprehensive evaluations show RainForest\noutperforms Linux with three different kernels, LXC, Xen, and Barrelfish in\nterms of reducing tail latency. The RainForest source code is soon available."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsea.2015.5501", 
    "link": "http://arxiv.org/pdf/1604.02171v1", 
    "other_authors": "Giuseppe Petracca, Ahmad Atamli, Yuqiong Sun, Jens Grossklags, Trent Jaeger", 
    "title": "Aware: Controlling App Access to I/O Devices on Mobile Platforms", 
    "arxiv-id": "1604.02171v1", 
    "author": "Trent Jaeger", 
    "publish": "2016-04-07T20:38:51Z", 
    "summary": "Smartphones' cameras, microphones, and device displays enable users to\ncapture and view memorable moments of their lives. However, adversaries can\ntrick users into authorizing malicious apps that exploit weaknesses in current\nmobile platforms to misuse such on-board I/O devices to stealthily capture\nphotos, videos, and screen content without the users' consent. Contemporary\nmobile operating systems fail to prevent such misuse of I/O devices by\nauthorized apps due to lack of binding between users' interactions and accesses\nto I/O devices performed by these apps. In this paper, we propose Aware, a\nsecurity framework for authorizing app requests to perform operations using I/O\ndevices, which binds app requests with user intentions to make all uses of\ncertain I/O devices explicit. We evaluate our defense mechanisms through\nlaboratory-based experimentation and a user study, involving 74 human subjects,\nwhose ability to identify undesired operations targeting I/O devices increased\nsignificantly. Without Aware, only 18% of the participants were able to\nidentify attacks from tested RAT apps. Aware systematically blocks all the\nattacks in absence of user consent and supports users in identifying 82% of\nsocial-engineering attacks tested to hijack approved requests, including some\nmore sophisticated forms of social engineering not yet present in available\nRATs. Aware introduces only 4.79% maximum performance overhead over operations\ntargeting I/O devices. Aware shows that a combination of system defenses and\nuser interface can significantly strengthen defenses for controlling the use of\non-board I/O devices."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcseit.2015.5102", 
    "link": "http://arxiv.org/pdf/1605.00362v1", 
    "other_authors": "Amar Ranjan Dash, Sandipta kumar Sahu, Sanjay Kumar Samantra", 
    "title": "An optimized round robin cpu scheduling algorithm with dynamic time   quantum", 
    "arxiv-id": "1605.00362v1", 
    "author": "Sanjay Kumar Samantra", 
    "publish": "2016-05-02T06:24:43Z", 
    "summary": "CPU scheduling is one of the most crucial operations performed by operating\nsystem. Different algorithms are available for CPU scheduling amongst them RR\n(Round Robin) is considered as optimal in time shared environment. The\neffectiveness of Round Robin completely depends on the choice of time quantum.\nIn this paper a new CPU scheduling algorithm has been proposed, named as DABRR\n(Dynamic Average Burst Round Robin). That uses dynamic time quantum instead of\nstatic time quantum used in RR. The performance of the proposed algorithm is\nexperimentally compared with traditional RR and some existing variants of RR.\nThe results of our approach presented in this paper demonstrate improved\nperformance in terms of average waiting time, average turnaround time, and\ncontext switching."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcseit.2015.5102", 
    "link": "http://arxiv.org/pdf/1605.01168v1", 
    "other_authors": "Junaid Shuja, Abdullah Gani, Sajjad A. Madani", 
    "title": "A Qualitative Comparison of MPSoC Mobile and Embedded Virtualization   Techniques", 
    "arxiv-id": "1605.01168v1", 
    "author": "Sajjad A. Madani", 
    "publish": "2016-05-04T07:36:46Z", 
    "summary": "Virtualization is generally adopted in server and desktop environments to\nprovide for fault tolerance, resource management, and energy efficiency.\nVirtualization enables parallel execution of multiple operating systems (OSs)\nwhile sharing the hardware resources. Virtualization was previously not deemed\nas feasible technology for mobile and embedded devices due to their limited\nprocessing and memory resource. However, the enterprises are advocating Bring\nYour Own Device (BYOD) applications that enable co-existence of heterogeneous\nOSs on a single mobile device. Moreover, embedded device require virtualization\nfor logical isolation of secure and general purpose OSs on a single device. In\nthis paper, we investigate the processor architectures in the mobile and\nembedded space while examining their formal visualizability. We also compare\nthe virtualization solutions enabling coexistence of multiple OSs in Multicore\nProcessor System-on-Chip (MPSoC) mobile and embedded systems. We advocate that\nvirtualization is necessary to manage resource in MPSoC designs and to enable\nBYOD, security, and logical isolation use cases."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcseit.2015.5102", 
    "link": "http://arxiv.org/pdf/1605.05810v1", 
    "other_authors": "SungWon Chung", 
    "title": "The Design of the NetBSD I/O Subsystems", 
    "arxiv-id": "1605.05810v1", 
    "author": "SungWon Chung", 
    "publish": "2016-05-19T05:03:00Z", 
    "summary": "This book describes the source code of the NetBSD Operating System Release\n1.6 in SUN UltraSPARC 64-bit platform by annotating related excerpts from\nreferences and user manuals on the NetBSD Operating System. The goal of this\nbook is to provide necessary information to understand the operation and the\nimplementation of I/O subsystems in the kernel as well as to design and\nimplement a new filesystem on the NetBSD platform."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcseit.2015.5102", 
    "link": "http://arxiv.org/pdf/1606.00111v2", 
    "other_authors": "Anna Lyons, Gernot Heiser", 
    "title": "It's Time: OS Mechanisms for Enforcing Asymmetric Temporal Integrity", 
    "arxiv-id": "1606.00111v2", 
    "author": "Gernot Heiser", 
    "publish": "2016-06-01T04:29:58Z", 
    "summary": "Mixed-criticality systems combine real-time components of different levels of\ncriticality, i.e. severity of failure, on the same processor, in order to\nobtain good resource utilisation. They must guarantee deadlines of\nhighly-critical tasks at the expense of lower-criticality ones in the case of\noverload. Present operating systems provide inadequate support for this kind of\nsystem, which is of growing importance in avionics and other verticals. We\npresent an approach that provides the required asymmetric integrity and its\nimplementation in the high-assurance seL4 microkernel."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcseit.2015.5102", 
    "link": "http://arxiv.org/pdf/1608.05654v1", 
    "other_authors": "Min Hong Yun, Songtao He, Lin Zhong", 
    "title": "POLYPATH: Supporting Multiple Tradeoffs for Interaction Latency", 
    "arxiv-id": "1608.05654v1", 
    "author": "Lin Zhong", 
    "publish": "2016-08-19T16:23:24Z", 
    "summary": "Modern mobile systems use a single input-to-display path to serve all\napplications. In meeting the visual goals of all applications, the path has a\nlatency inadequate for many important interactions. To accommodate the\ndifferent latency requirements and visual constraints by different\ninteractions, we present POLYPATH, a system design in which application\ndevelopers (and users) can choose from multiple path designs for their\napplication at any time. Because a POLYPATH system asks for two or more path\ndesigns, we present a novel fast path design, called Presto. Presto reduces\nlatency by judiciously allowing frame drops and tearing.\n  We report an Android 5-based prototype of POLYPATH with two path designs:\nAndroid legacy and Presto. Using this prototype, we quantify the effectiveness,\noverhead, and user experience of POLYPATH, especially Presto, through both\nobjective measurements and subjective user assessment. We show that Presto\nreduces the latency of legacy touchscreen drawing applications by almost half;\nand more importantly, this reduction is orthogonal to that of other popular\napproaches and is achieved without any user-noticeable negative visual effect.\nWhen combined with touch prediction, Presto is able to reduce the touch latency\nbelow 10 ms, a remarkable achievement without any hardware support."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcseit.2015.5102", 
    "link": "http://arxiv.org/pdf/1608.08051v2", 
    "other_authors": "Zhiyong Shan, Tzi-cker Chiueh, Xin Wang", 
    "title": "Duplication of Windows Services", 
    "arxiv-id": "1608.08051v2", 
    "author": "Xin Wang", 
    "publish": "2016-08-13T22:14:47Z", 
    "summary": "OS-level virtualization techniques virtualize system resources at the system\ncall interface, has the distinct advantage of smaller run-time resource\nrequirements as compared to HAL-level virtualization techniques, and thus forms\nan important building block for virtualizing parallel and distributed\napplications such as a HPC clusters. Because the Windows operating system puts\ncertain critical functionalities in privileged user-level system service\nprocesses, a complete OS-level virtualization solution for the Windows platform\nrequires duplication of such Windows service as Remote Procedure Call Server\nService (RPCSS). As many implementation details of the Windows system services\nare proprietary, duplicating Windows system services becomes the key technical\nchallenge for virtualizing the Windows platform at the OS level. Moreover, as a\ncore component of cloud computing, IIS web server-related services need to be\nduplicated in containers (i.e., OS-level virtual machines), but so far there is\nno such scheme. In this paper, we thoroughly identify all issues that affect\nservice duplication, and then propose the first known methodology to\nsystematically duplicate both system and ordinary Windows services. Our\nexperiments show that the methodology can duplicate a set of system and\nordinary services on different versions of Windows OS."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1609.00875v1", 
    "other_authors": "Zhiyong Shan", 
    "title": "Compatible and Usable Mandatory Access Control for Good-enough OS   Security", 
    "arxiv-id": "1609.00875v1", 
    "author": "Zhiyong Shan", 
    "publish": "2016-09-03T23:09:11Z", 
    "summary": "OS compromise is one of the most serious computer security problems today,\nbut still not being resolved. Although people proposed different kinds of\nmethods, they could not be accepted by most users who are non-expert due to the\nlack of compatibility and usability. In this paper, we introduce a kind of new\nmandatory access control model, named CUMAC, that aims to achieve good-enough\nsecurity, high compatibility and usability. It has two novel features. One is\naccess control based on tracing potential intrusion that can reduce false\nnegatives and facilitate security configuration, in order to improve both\ncompatibility and usability; the other is automatically figuring out all of the\ncompatibility exceptions that usually incurs incompatible problems. The\nexperiments performed on the prototype show that CUMAC can defense attacks from\nnetwork, mobile disk and local untrustable users while keeping good\ncompatibility and usability."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1609.04781v1", 
    "other_authors": "Zhiyong Shan, Yang Yu, Tzi-cker Chiueh", 
    "title": "Confining Windows Inter-Process Communications for OS-Level Virtual   Machine", 
    "arxiv-id": "1609.04781v1", 
    "author": "Tzi-cker Chiueh", 
    "publish": "2016-09-15T19:18:12Z", 
    "summary": "As OS-level virtualization technology usually imposes little overhead on\nvirtual machine start-up and running, it provides an excellent choice for\nbuilding intrusion/fault tolerant applications that require redundancy and\nfrequent invocation. When developing Windows OS-level virtual machine, however,\npeople will inevitably face the challenge of confining Windows Inter-Process\nCommunications (IPC). As IPC on Windows platform is more complex than UNIX\nstyle OS and most of the programs on Windows are not open-source, it is\ndifficult to discover all of the performed IPCs and confine them. In this\npaper, we propose three general principles to confine IPC on Windows OS and a\nnovel IPC confinement mechanism based on the principles. With the mechanism,\nfor the first time from the literature, we successfully virtualized RPC System\nService (RPCSS) and Internet Information Server (IIS) on Feather-weight Virtual\nMachine (FVM). Experimental results demonstrate that multiple IIS web server\ninstances can simultaneously run on single Windows OS with much less\nperformance overhead than other popular VM technology, offering a good basis\nfor constructing dependable system."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1609.04785v1", 
    "other_authors": "Zhiyong Shan, Tzi-cker Chiueh, Xin Wang", 
    "title": "Virtualizing System and Ordinary Services in Windows-based OS-Level   Virtual Machines", 
    "arxiv-id": "1609.04785v1", 
    "author": "Xin Wang", 
    "publish": "2016-09-15T19:21:22Z", 
    "summary": "OS-level virtualization incurs smaller start-up and run-time overhead than\nHAL-based virtualization and thus forms an important building block for\ndeveloping fault-tolerant and intrusion-tolerant applications. A complete\nimplementation of OS-level virtualization on the Windows platform requires\nvirtualization of Windows services, such as system services like the Remote\nProcedure Call Server Service (RPCSS), because they are essentially extensions\nof the kernel. As Windows system services work very differently from their\ncounterparts on UNIX-style OS, i.e., daemons, and many of their implementation\ndetails are proprietary, virtualizing Windows system services turned out to be\nthe most challenging technical barrier for OS-level virtualization for the\nWindows platform. In this paper, we describe a general technique to virtualize\nWindows services, and demonstrate its effectiveness by applying it to\nsuccessfully virtualize a set of important Windows system services and ordinary\nservices on different versions of Windows OS, including RPCSS, DcomLaunch, IIS\nservice group, Tlntsvr, MySQL, Apache2.2, CiSvc, ImapiService, etc."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1609.08154v1", 
    "other_authors": "Zhiyong Shan, Yu-fang Sun", 
    "title": "Implementing RBAC model in An Operating System Kernel", 
    "arxiv-id": "1609.08154v1", 
    "author": "Yu-fang Sun", 
    "publish": "2016-09-26T17:36:18Z", 
    "summary": "In this paper, the implementation of an operating system oriented RBAC model\nis discussed. Firstly, on the basis of RBAC96 model, a new RBAC model named OSR\nis presented. Secondly, the OSR model is enforced in RFSOS kernel by the way of\nintegrating GFAC method and Capability mechanism together. All parts of the OSR\nimplementation are described in detail."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1609.08372v2", 
    "other_authors": "Kevin Elphinstone, Amirreza Zarrabi, Adrian Danis, Yanyan Shen, Gernot Heiser", 
    "title": "An Evaluation of Coarse-Grained Locking for Multicore Microkernels", 
    "arxiv-id": "1609.08372v2", 
    "author": "Gernot Heiser", 
    "publish": "2016-09-27T12:21:02Z", 
    "summary": "The trade-off between coarse- and fine-grained locking is a well understood\nissue in operating systems. Coarse-grained locking provides lower overhead\nunder low contention, fine-grained locking provides higher scalability under\ncontention, though at the expense of implementation complexity and re- duced\nbest-case performance.\n  We revisit this trade-off in the context of microkernels and tightly-coupled\ncores with shared caches and low inter-core migration latencies. We evaluate\nperformance on two architectures: x86 and ARM MPCore, in the former case also\nutilising transactional memory (Intel TSX). Our thesis is that on such\nhardware, a well-designed microkernel, with short system calls, can take\nadvantage of coarse-grained locking on modern hardware, avoid the run-time and\ncomplexity cost of multiple locks, enable formal verification, and still\nachieve scalability comparable to fine-grained locking."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1610.08129v1", 
    "other_authors": "Asaf Cidon, Daniel Rushton, Stephen M. Rumble, Ryan Stutsman", 
    "title": "Memshare: a Dynamic Multi-tenant Memory Key-value Cache", 
    "arxiv-id": "1610.08129v1", 
    "author": "Ryan Stutsman", 
    "publish": "2016-10-26T00:37:34Z", 
    "summary": "Web application performance is heavily reliant on the hit rate of\nmemory-based caches. Current DRAM-based web caches statically partition their\nmemory across multiple applications sharing the cache. This causes under\nutilization of memory which negatively impacts cache hit rates. We present\nMemshare, a novel web memory cache that dynamically manages memory across\napplications. Memshare provides a resource sharing model that guarantees\nprivate memory to different applications while dynamically allocating the\nremaining shared memory to optimize overall hit rate. Today's high cost of DRAM\nstorage and the availability of high performance CPU and memory bandwidth, make\nweb caches memory capacity bound. Memshare's log-structured design allows it to\nprovide significantly higher hit rates and dynamically partition memory among\napplications at the expense of increased CPU and memory bandwidth consumption.\nIn addition, Memshare allows applications to use their own eviction policy for\ntheir objects, independent of other applications. We implemented Memshare and\nran it on a week-long trace from a commercial memcached provider. We\ndemonstrate that Memshare increases the combined hit rate of the applications\nin the trace by an 6.1% (from 84.7% hit rate to 90.8% hit rate) and reduces the\ntotal number of misses by 39.7% without affecting system throughput or latency.\nEven for single-tenant applications, Memshare increases the average hit rate of\nthe current state-of-the-art memory cache by an additional 2.7% on our\nreal-world trace."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1612.06830v1", 
    "other_authors": "Jessica Nettelblad, Carl Nettelblad", 
    "title": "CannyFS: Opportunistically Maximizing I/O Throughput Exploiting the   Transactional Nature of Batch-Mode Data Processing", 
    "arxiv-id": "1612.06830v1", 
    "author": "Carl Nettelblad", 
    "publish": "2016-12-20T20:14:35Z", 
    "summary": "We introduce a user mode file system, CannyFS, that hides latency by assuming\nall I/O operations will succeed. The user mode process will in turn report\nerrors, allowing proper cleanup and a repeated attempt to take place. We\ndemonstrate benefits for the model tasks of extracting archives and removing\ndirectory trees in a real-life HPC environment, giving typical reductions in\ntime use of over 80%.\n  This approach can be considered a view of HPC jobs and their I/O activity as\ntransactions. In general, file systems lack clearly defined transaction\nsemantics. Over time, the competing trends to add cache and maintain data\nintegrity have resulted in different practical tradeoffs.\n  High-performance computing is a special case where overall throughput demands\nare high. Latency can also be high, with non-local storage. In addition, a\ntheoretically possible I/O error (like permission denied, loss of connection,\nexceeding disk quota) will frequently warrant the resubmission of a full job or\ntask, rather than traditional error reporting or handling. Therefore,\nopportunistically treating each I/O operation as successful, and part of a\nlarger transaction, can speed up some applications that do not leverage\nasynchronous I/O."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/1702.02588v1", 
    "other_authors": "Assaf Eisenman, Asaf Cidon, Evgenya Pergament, Or Haimovich, Ryan Stutsman, Mohammad Alizadeh, Sachin Katti", 
    "title": "Flashield: a Key-value Cache that Minimizes Writes to Flash", 
    "arxiv-id": "1702.02588v1", 
    "author": "Sachin Katti", 
    "publish": "2017-02-08T19:21:13Z", 
    "summary": "As its price per bit drops, SSD is increasingly becoming the default storage\nmedium for cloud application databases. However, it has not become the\npreferred storage medium for key-value caches, even though SSD offers more than\n10x lower price per bit and sufficient performance compared to DRAM. This is\nbecause key-value caches need to frequently insert, update and evict small\nobjects. This causes excessive writes and erasures on flash storage, since\nflash only supports writes and erasures of large chunks of data. These\nexcessive writes and erasures significantly shorten the lifetime of flash,\nrendering it impractical to use for key-value caches. We present Flashield, a\nhybrid key-value cache that uses DRAM as a \"filter\" to minimize writes to SSD.\nFlashield performs light-weight machine learning profiling to predict which\nobjects are likely to be read frequently before getting updated; these objects,\nwhich are prime candidates to be stored on SSD, are written to SSD in large\nchunks sequentially. In order to efficiently utilize the cache's available\nmemory, we design a novel in-memory index for the variable-sized objects stored\non flash that requires only 4 bytes per object in DRAM. We describe Flashield's\ndesign and implementation and, we evaluate it on a real-world cache trace.\nCompared to state-of-the-art systems that suffer a write amplification of 2.5x\nor more, Flashield maintains a median write amplification of 0.5x without any\nloss of hit rate or throughput."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/9809006v1", 
    "other_authors": "Werner Vogels, Dan Dumitriu, Ken Birman, Rod Gamache, Mike Massa, Rob Short, John Vert, Joe Barrera", 
    "title": "The Design and Architecture of the Microsoft Cluster Service -- A   Practical Approach to High-Availability and Scalability", 
    "arxiv-id": "cs/9809006v1", 
    "author": "Joe Barrera", 
    "publish": "1998-09-02T17:11:54Z", 
    "summary": "Microsoft Cluster Service (MSCS) extends the Win-dows NT operating system to\nsupport high-availability services. The goal is to offer an execution\nenvironment where off-the-shelf server applications can continue to operate,\neven in the presence of node failures. Later ver-sions of MSCS will provide\nscalability via a node and application management system that allows\napplications to scale to hundreds of nodes. This paper provides a de-tailed\ndescription of the MSCS architecture and the de-sign decisions that have driven\nthe implementation of the service. The paper also describes how some major\nappli-cations use the MSCS features, and describes features added to make it\neasier to implement and manage fault-tolerant applications on MSCS."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/9812011v1", 
    "other_authors": "Erik T. Mueller, Johanna D. Moore, Gerald J. Popek", 
    "title": "A nested transaction mechanism for LOCUS", 
    "arxiv-id": "cs/9812011v1", 
    "author": "Gerald J. Popek", 
    "publish": "1998-12-10T16:49:04Z", 
    "summary": "A working implementation of nested transactions has been produced for LOCUS,\nan integrated distributed operating system which provides a high degree of\nnetwork transparency. Several aspects of our mechanism are novel. First, the\nmechanism allows a transaction to access objects directly without regard to the\nlocation of the object. Second, processes running on behalf of a single\ntransaction may be located at many sites. Thus there is no need to invoke a new\ntransaction to perform processing or access objects at a remote site. Third,\nunlike other environments, LOCUS allows replication of data objects at more\nthan one site in the network, and this capability is incorporated into the\ntransaction mechanism. If the copy of an object that is currently being\naccessed becomes unavailable, it is possible to continue work by using another\none of the replicated copies. Finally, an efficient orphan removal algorithm is\npresented, and the problem of providing continued operation during network\npartitions is addressed in detail."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/9903004v4", 
    "other_authors": "Denvil Smith", 
    "title": "A Flit Level Simulator for Wormhole Routing", 
    "arxiv-id": "cs/9903004v4", 
    "author": "Denvil Smith", 
    "publish": "1999-03-04T02:13:35Z", 
    "summary": "Wormhole routing, the latest switching technique to be utilized by massively\nparallel computers, enjoys the distinct advantage of a low latency when\ncompared to other switching techniques. This low latency is due to the nearly\ndistance insensitive routing traits in the absence of channel contention. The\nlow latency of wormhole routing brings about a liability of this switching\ntechnique, a chance of deadlock. Deadlock is a concern in wormhole routed\nnetworks due to the fact a message does not release its allocated resources\nuntil all flits of a message have completely traversed the router in which\nthese resources are associated. The deadlock condition is addressed in the\nrouting algorithm. Simulation tools are currently needed that will aid in the\nsize and number of resources necessary to obtain the optimum utilization of\nnetwork resources for an algorithm. Some of these resources include the\ntopology of the network along with the number of nodes for the topology, the\nsize of the message, and the number and size of buffers at each router."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/9903014v1", 
    "other_authors": "Thomas Kistler, Michael Franz", 
    "title": "Perpetual Adaptation of Software to Hardware: An Extensible Architecture   for Providing Code Optimization as a Central System Service", 
    "arxiv-id": "cs/9903014v1", 
    "author": "Michael Franz", 
    "publish": "1999-03-22T21:24:35Z", 
    "summary": "We present an open architecture for just-in-time code generation and dynamic\ncode optimization that is flexible, customizable, and extensible. While\nprevious research has primarily investigated functional aspects of such a\nsystem, architectural aspects have so far remained unexplored. In this paper,\nwe argue that these properties are important to generate optimal code for a\nvariety of hardware architectures and different processor generations within\nprocessor families. These properties are also important to make system-level\ncode generation useful in practice."
},{
    "category": "cs.DC", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/9904020v1", 
    "other_authors": "Walter Eaves", 
    "title": "ODP channel objects that provide services transparently for distributing   processing systems", 
    "arxiv-id": "cs/9904020v1", 
    "author": "Walter Eaves", 
    "publish": "1999-04-26T21:13:00Z", 
    "summary": "This paper describes an architecture for a distributing processing system\nthat would allow remote procedure calls to invoke other services as messages\nare passed between clients and servers. It proposes that an additional class of\ndata processing objects be located in the software communications channel. The\nobjects in this channel would then be used to enforce protocols on\nclient-server applications without any additional effort by the application\nprogrammers. For example, services such as key-management, time-stamping,\nsequencing and encryption can be implemented at different levels of the\nsoftware communications stack to provide a complete authentication service. A\ndistributing processing environment could be used to control broadband network\ndata delivery. Architectures and invocation semantics are discussed, Example\nclasses and interfaces for channel objects are given in the Java programming\nlanguage."
},{
    "category": "cs.OS", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/0003064v1", 
    "other_authors": "Oleg Kiselyov", 
    "title": "A network file system over HTTP: remote access and modification of files   and \"files\"", 
    "arxiv-id": "cs/0003064v1", 
    "author": "Oleg Kiselyov", 
    "publish": "2000-03-15T19:20:53Z", 
    "summary": "The goal of the present HTTPFS project is to enable access to remote files,\ndirectories, and other containers through an HTTP pipe. HTTPFS system permits\nretrieval, creation and modification of these resources as if they were regular\nfiles and directories on a local filesystem. The remote host can be any UNIX or\nWin9x/WinNT box that is capable of running a Perl CGI script and accessible\neither directly or via a web proxy or a gateway. HTTPFS runs entirely in user\nspace.\n  The current implementation fully supports reading as well as creating,\nwriting, appending, and truncating of files on a remote HTTP host. HTTPFS\nprovides an isolation level for concurrent file access stronger than the one\nmandated by POSIX file system semantics, closer to that of AFS. Both an API\nwith familiar open(), read(), write(), close(), etc. calls, and an interactive\ninterface, via the popular Midnight Commander file browser, are provided."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/0006014v1", 
    "other_authors": "Neil J. Gunther", 
    "title": "Solaris System Resource Manager: All I Ever Wanted Was My Unfair   Advantage (And Why You Can't Have It!)", 
    "arxiv-id": "cs/0006014v1", 
    "author": "Neil J. Gunther", 
    "publish": "2000-06-08T16:50:24Z", 
    "summary": "Traditional UNIX time-share schedulers attempt to be fair to all users by\nemploying a round-robin style algorithm for allocating CPU time. Unfortunately,\na loophole exists whereby the scheduler can be biased in favor of a greedy user\nrunning many short CPU-time processes. This loophole is not a defect but an\nintrinsic property of the round-robin scheduler that ensures responsiveness to\nthe short CPU demands associated with multiple interactive users. A new\ngeneration of UNIX system resource management software constrains the scheduler\nto be equitable to all users regardless of the number of processes each may be\nrunning. This \"fair-share\" scheduling draws on the concept of pro rating\nresource \"shares\" across users and groups and then dynamically adjusting CPU\nusage to meet those share proportions. The simple notion of statically\nallocating these shares, however, belies the potential consequences for\nperformance as measured by user response time and service level targets. We\ndemonstrate this point by modeling several simple share allocation scenarios\nand analyzing the corresponding performance effects. A brief comparison of\ncommercial system resource management implementations from HP, IBM, and SUN is\nalso given."
},{
    "category": "cs.PF", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/0006015v2", 
    "other_authors": "Neil J. Gunther", 
    "title": "UNIX Resource Managers: Capacity Planning and Resource Issues", 
    "arxiv-id": "cs/0006015v2", 
    "author": "Neil J. Gunther", 
    "publish": "2000-06-08T17:02:51Z", 
    "summary": "The latest implementations of commercial UNIX to offer mainframe style\ncapacity management on enterprise servers include: AIX Workload Manager (WLM),\nHP-UX Process Resource Manager (PRM), Solaris Resource Manager (SRM), as well\nas SGI and Compaq. The ability to manage server capacity is achieved by making\nsignificant modifications to the standard UNIX operating system so that\nprocesses are inherently tied to specific users. Those users, in turn, are\ngranted only a certain fraction of system resources. Resource usage is\nmonitored and compared with each users grant to ensure that the assigned\nentitlement constraints are met. In this paper, we begin by clearing up some of\nthe confusion that has surrounded the motivation and the terminology behind the\nnew technology. The common theme across each of the commercial implementations\nis the introduction of the fair-share scheduler. After reviewing some potential\nperformance pitfalls, we present capacity planning guidelines for migrating to\nautomated UNIX resource management."
},{
    "category": "cs.NI", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/0104012v1", 
    "other_authors": "David G. Andersen, Deepak Bansal, Dorothy Curtis, Srinivasan Seshan, Hari Balakrishnan", 
    "title": "System Support for Bandwidth Management and Content Adaptation in   Internet Applications", 
    "arxiv-id": "cs/0104012v1", 
    "author": "Hari Balakrishnan", 
    "publish": "2001-04-07T17:17:14Z", 
    "summary": "This paper describes the implementation and evaluation of an operating system\nmodule, the Congestion Manager (CM), which provides integrated network flow\nmanagement and exports a convenient programming interface that allows\napplications to be notified of, and adapt to, changing network conditions. We\ndescribe the API by which applications interface with the CM, and the\narchitectural considerations that factored into the design. To evaluate the\narchitecture and API, we describe our implementations of TCP; a streaming\nlayered audio/video application; and an interactive audio application using the\nCM, and show that they achieve adaptive behavior without incurring much\nend-system overhead. All flows including TCP benefit from the sharing of\ncongestion information, and applications are able to incorporate new\nfunctionality such as congestion control and adaptive behavior."
},{
    "category": "cs.PL", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/0210031v1", 
    "other_authors": "Srinidhi Varadarajan", 
    "title": "The Weaves Reconfigurable Programming Framework", 
    "arxiv-id": "cs/0210031v1", 
    "author": "Srinidhi Varadarajan", 
    "publish": "2002-10-31T01:51:00Z", 
    "summary": "This research proposes a language independent intra-process framework for\nobject based composition of unmodified code modules. Intuitively, the two major\nprogramming models, threads and processes, can be considered as extremes along\na sharing axis. Multiple threads through a process share all global state,\nwhereas instances of a process (or independent processes) share no global\nstate. Weaves provide the generalized framework that allows arbitrary\n(selective) sharing of state between multiple control flows through a process.\nThe Weaves framework supports multiple independent components in a single\nprocess, with flexible state sharing and scheduling, all of which is achieved\nwithout requiring any modification to existing code bases. Furthermore, the\nframework allows dynamic instantiation of code modules and control flows\nthrough them. In effect, weaves create intra-process modules (similar to\nobjects in OOP) from code written in any language. The Weaves paradigm allows\nobjects to be arbitrarily shared, it is a true superset of both processes as\nwell as threads, with code sharing and fast context switching time similar to\nthreads. Weaves does not require any special support from either the language\nor application code, practically any code can be weaved. Weaves also include\nsupport for fast automatic checkpointing and recovery with no application\nsupport. This paper presents the elements of the Weaves framework and results\nfrom our implementation that works by reverse-analyzing source-code independent\nELF object files. The current implementation has been validated over Sweep3D, a\nbenchmark for 3D discrete ordinates neutron transport [Koch et al., 1992], and\na user-level port of the Linux 2.4 family kernel TCP/IP protocol stack."
},{
    "category": "cs.SE", 
    "doi": "10.1109/ISECS.2009.29", 
    "link": "http://arxiv.org/pdf/cs/0302033v1", 
    "other_authors": "Sampsa Fabritius, Raimondas Lencevicius, Edu Metz, Alexander Ran", 
    "title": "Experimental Software Schedulability Estimation For Varied Processor   Frequencies", 
    "arxiv-id": "cs/0302033v1", 
    "author": "Alexander Ran", 
    "publish": "2003-02-24T22:03:30Z", 
    "summary": "This paper describes a new approach to experimentally estimate the\napplication schedulability for various processor frequencies. We use additional\nworkload generated by an artificial high priority routine to simulate the\nfrequency decrease of a processor. Then we estimate the schedulability of\napplications at different frequencies. The results of such estimation can be\nused to determine the frequencies and control algorithms of dynamic voltage\nscaling/dynamic frequency scaling (DVS/DFS) implementations. The paper presents\na general problem description, the proposed schedulability estimation method,\nits analysis and evaluation."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0309044v1", 
    "other_authors": "V. C. Barbosa", 
    "title": "The combinatorics of resource sharing", 
    "arxiv-id": "cs/0309044v1", 
    "author": "V. C. Barbosa", 
    "publish": "2003-09-23T13:57:01Z", 
    "summary": "We discuss general models of resource-sharing computations, with emphasis on\nthe combinatorial structures and concepts that underlie the various deadlock\nmodels that have been proposed, the design of algorithms and deadlock-handling\npolicies, and concurrency issues. These structures are mostly graph-theoretic\nin nature, or partially ordered sets for the establishment of priorities among\nprocesses and acquisition orders on resources. We also discuss graph-coloring\nconcepts as they relate to resource sharing."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0403013v1", 
    "other_authors": "George Candea", 
    "title": "Predictable Software -- A Shortcut to Dependable Computing ?", 
    "arxiv-id": "cs/0403013v1", 
    "author": "George Candea", 
    "publish": "2004-03-11T04:01:51Z", 
    "summary": "Many dependability techniques expect certain behaviors from the underlying\nsubsystems and fail in chaotic ways if these expectations are not met. Under\nexpected circumstances, however, software tends to work quite well. This paper\nsuggests that, instead of fixing elusive bugs or rewriting software, we improve\nthe predictability of conditions faced by our programs. This approach might be\na cheaper and faster way to improve dependability of software. After\nidentifying some of the common triggers of unpredictability, the paper\ndescribes three engineering principles that hold promise in combating\nunpredictability, suggests a way to benchmark predictability, and outlines a\nbrief research agenda."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0406005v3", 
    "other_authors": "George Candea, Shinichi Kawamoto, Yuichi Fujiki, Greg Friedman, Armando Fox", 
    "title": "Microreboot -- A Technique for Cheap Recovery", 
    "arxiv-id": "cs/0406005v3", 
    "author": "Armando Fox", 
    "publish": "2004-06-02T21:54:50Z", 
    "summary": "A significant fraction of software failures in large-scale Internet systems\nare cured by rebooting, even when the exact failure causes are unknown.\nHowever, rebooting can be expensive, causing nontrivial service disruption or\ndowntime even when clusters and failover are employed. In this work we separate\nprocess recovery from data recovery to enable microrebooting -- a fine-grain\ntechnique for surgically recovering faulty application components, without\ndisturbing the rest of the application.\n  We evaluate microrebooting in an Internet auction system running on an\napplication server. Microreboots recover most of the same failures as full\nreboots, but do so an order of magnitude faster and result in an order of\nmagnitude savings in lost work. This cheap form of recovery engenders a new\napproach to high availability: microreboots can be employed at the slightest\nhint of failure, prior to node failover in multi-node clusters, even when\nmistakes in failure detection are likely; failure and recovery can be masked\nfrom end users through transparent call-level retries; and systems can be\nrejuvenated by parts, without ever being shut down."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0409034v1", 
    "other_authors": "Paul Stanton", 
    "title": "Securing Data in Storage: A Review of Current Research", 
    "arxiv-id": "cs/0409034v1", 
    "author": "Paul Stanton", 
    "publish": "2004-09-17T21:51:24Z", 
    "summary": "Protecting data from malicious computer users continues to grow in\nimportance. Whether preventing unauthorized access to personal photographs,\nensuring compliance with federal regulations, or ensuring the integrity of\ncorporate secrets, all applications require increased security to protect data\nfrom talented intruders. Specifically, as more and more files are preserved on\ndisk the requirement to provide secure storage has increased in importance.\nThis paper presents a survey of techniques for securely storing data, including\ntheoretical approaches, prototype systems, and existing systems currently\navailable. Due to the wide variety of potential solutions available and the\nvariety of techniques to arrive at a particular solution, it is important to\nreview the entire field prior to selecting an implementation that satisfies\nparticular requirements. This paper provides an overview of the prominent\ncharacteristics of several systems to provide a foundation for making an\ninformed decision. Initially, the paper establishes a set of criteria for\nevaluating a storage solution based on confidentiality, integrity,\navailability, and performance. Then, using these criteria, the paper explains\nthe relevant characteristics of select storage systems and provides a\ncomparison of the major differences."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0410007v2", 
    "other_authors": "Ignatios Souvatzis", 
    "title": "A Shared Write-protected Root Filesystem for a Group of Networked   Clients", 
    "arxiv-id": "cs/0410007v2", 
    "author": "Ignatios Souvatzis", 
    "publish": "2004-10-04T14:49:00Z", 
    "summary": "A method to boot a cluster of diskless network clients from a single\nwrite-protected NFS root file system is shown. The problems encountered when\nfirst implementing the setup and their solution are discussed. Finally, the\nsetup is briefly compared to using a kernel-embedded root file system."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0412038v1", 
    "other_authors": "Kevin Lai, Lars Rasmusson, Eytan Adar, Stephen Sorkin, Li Zhang, Bernardo A. Huberman", 
    "title": "Tycoon: an Implementation of a Distributed, Market-based Resource   Allocation System", 
    "arxiv-id": "cs/0412038v1", 
    "author": "Bernardo A. Huberman", 
    "publish": "2004-12-09T01:20:39Z", 
    "summary": "Distributed clusters like the Grid and PlanetLab enable the same statistical\nmultiplexing efficiency gains for computing as the Internet provides for\nnetworking. One major challenge is allocating resources in an economically\nefficient and low-latency way. A common solution is proportional share, where\nusers each get resources in proportion to their pre-defined weight. However,\nthis does not allow users to differentiate the value of their jobs. This leads\nto economic inefficiency. In contrast, systems that require reservations impose\na high latency (typically minutes to hours) to acquire resources.\n  We present Tycoon, a market based distributed resource allocation system\nbased on proportional share. The key advantages of Tycoon are that it allows\nusers to differentiate the value of their jobs, its resource acquisition\nlatency is limited only by communication delays, and it imposes no manual\nbidding overhead on users. We present experimental results using a prototype\nimplementation of our design."
},{
    "category": "cs.HC", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0412074v1", 
    "other_authors": "Elizabeth Haubert", 
    "title": "Threats of Human Error in a High-Performance Storage System: Problem   Statement and Case Study", 
    "arxiv-id": "cs/0412074v1", 
    "author": "Elizabeth Haubert", 
    "publish": "2004-12-17T15:38:19Z", 
    "summary": "System administration is a difficult, often tedious, job requiring many\nskilled laborers. The data that is protected by system administrators is often\nvalued at or above the value of the institution maintaining that data. A number\nof ethnographic studies have confirmed the skill of these operators, and the\ndifficulty of providing adequate tools. In an effort to minimize the\nmaintenance costs, an increasing portion of system administration is subject to\nautomation - particularly simple, routine tasks such as data backup. While such\ntools reduce the risk of errors from carelessness, the same tools may result in\nreduced skill and system familiarity in experienced workers. Care should be\ntaken to ensure that operators maintain system awareness without placing the\noperator in a passive, monitoring role."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0502012v1", 
    "other_authors": "Peter Kukol, Jim Gray", 
    "title": "Sequential File Programming Patterns and Performance with .NET", 
    "arxiv-id": "cs/0502012v1", 
    "author": "Jim Gray", 
    "publish": "2005-02-02T04:43:33Z", 
    "summary": "Programming patterns for sequential file access in the .NET Framework are\ndescribed and the performance is measured. The default behavior provides\nexcellent performance on a single disk - 50 MBps both reading and writing.\nUsing large request sizes and doing file pre-allocation when possible have\nquantifiable benefits. When one considers disk arrays, .NET unbuffered IO\ndelivers 800 MBps on a 16-disk array, but buffered IO delivers about 12% of\nthat performance. Consequently, high-performance file and database utilities\nare still forced to use unbuffered IO for maximum sequential performance. The\nreport is accompanied by downloadable source code that demonstrates the\nconcepts and code that was used to obtain these measurements."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0502090v1", 
    "other_authors": "A. Streit, D. Erwin, Th. Lippert, D. Mallmann, R. Menday, M. Rambadt, M. Riedel, M. Romberg, B. Schuller, Ph. Wieder", 
    "title": "UNICORE - From Project Results to Production Grids", 
    "arxiv-id": "cs/0502090v1", 
    "author": "Ph. Wieder", 
    "publish": "2005-02-24T14:13:56Z", 
    "summary": "The UNICORE Grid-technology provides a seamless, secure and intuitive access\nto distributed Grid resources. In this paper we present the recent evolution\nfrom project results to production Grids. At the beginning UNICORE was\ndeveloped as a prototype software in two projects funded by the German research\nministry (BMBF). Over the following years, in various European-funded projects,\nUNICORE evolved to a full-grown and well-tested Grid middleware system, which\ntoday is used in daily production at many supercomputing centers worldwide.\nBeyond this production usage, the UNICORE technology serves as a solid basis in\nmany European and International research projects, which use existing UNICORE\ncomponents to implement advanced features, high level services, and support for\napplications from a growing range of domains. In order to foster these ongoing\ndevelopments, UNICORE is available as open source under BSD licence at\nSourceForge, where new releases are published on a regular basis. This paper is\na review of the UNICORE achievements so far and gives a glimpse on the UNICORE\nroadmap."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0503074v1", 
    "other_authors": "Sameer Tilak, Bhanu Pisupati, Kenneth Chiu, Geoffrey Brown, Nael Abu-Ghazaleh", 
    "title": "A File System Abstraction for Sense and Respond Systems", 
    "arxiv-id": "cs/0503074v1", 
    "author": "Nael Abu-Ghazaleh", 
    "publish": "2005-03-28T15:32:43Z", 
    "summary": "The heterogeneity and resource constraints of sense-and-respond systems pose\nsignificant challenges to system and application development. In this paper, we\npresent a flexible, intuitive file system abstraction for organizing and\nmanaging sense-and-respond systems based on the Plan 9 design principles. A key\nfeature of this abstraction is the ability to support multiple views of the\nsystem via filesystem namespaces. Constructed logical views present an\napplication-specific representation of the network, thus enabling high-level\nprogramming of the network. Concurrently, structural views of the network\nenable resource-efficient planning and execution of tasks. We present and\nmotivate the design using several examples, outline research challenges and our\nresearch plan to address them, and describe the current state of\nimplementation."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0507073v1", 
    "other_authors": "Michel R. Dagenais, Karim Yaghmour, Charles Levert, Makan Pourzandi", 
    "title": "Software Performance Analysis", 
    "arxiv-id": "cs/0507073v1", 
    "author": "Makan Pourzandi", 
    "publish": "2005-07-29T19:33:13Z", 
    "summary": "The key to speeding up applications is often understanding where the elapsed\ntime is spent, and why. This document reviews in depth the full array of\nperformance analysis tools and techniques available on Linux for this task,\nfrom the traditional tools like gcov and gprof, to the more advanced tools\nstill under development like oprofile and the Linux Trace Toolkit. The focus is\nmore on the underlying data collection and processing algorithms, and their\noverhead and precision, than on the cosmetic details of the graphical user\ninterface frontends."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0508063v1", 
    "other_authors": "Michel R. Dagenais", 
    "title": "Disks, Partitions, Volumes and RAID Performance with the Linux Operating   System", 
    "arxiv-id": "cs/0508063v1", 
    "author": "Michel R. Dagenais", 
    "publish": "2005-08-12T16:13:32Z", 
    "summary": "Block devices in computer operating systems typically correspond to disks or\ndisk partitions, and are used to store files in a filesystem. Disks are not the\nonly real or virtual device which adhere to the block accessible stream of\nbytes block device model. Files, remote devices, or even RAM may be used as a\nvirtual disks. This article examines several common combinations of block\ndevice layers used as virtual disks in the Linux operating system: disk\npartitions, loopback files, software RAID, Logical Volume Manager, and Network\nBlock Devices. It measures their relative performance using different\nfilesystems: Ext2, Ext3, ReiserFS, JFS, XFS,NFS."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0601068v1", 
    "other_authors": "Sorav Bansal", 
    "title": "Checkbochs: Use Hardware to Check Software", 
    "arxiv-id": "cs/0601068v1", 
    "author": "Sorav Bansal", 
    "publish": "2006-01-14T23:21:31Z", 
    "summary": "In this paper, we present a system called Checkbochs, a machine simulator\nthat checks rules about its guest operating system and applications at the\nhardware level. The properties to be checked can be implemented as `plugins' in\nthe Checkbochs simulator. Some of the properties that were checked using\nCheckbochs include null-pointer checks, format-string vulnerabilities,\nuser/kernel pointer checks, and race-conditions. On implementing these checks,\nwe were able to uncover previously-unknown bugs in widely used Linux\ndistributions. We also tested our tools on undergraduate coursework, and found\nnumerous bugs."
},{
    "category": "cs.NI", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0603075v1", 
    "other_authors": "Bryan Ford", 
    "title": "Unmanaged Internet Protocol: Taming the Edge Network Management Crisis", 
    "arxiv-id": "cs/0603075v1", 
    "author": "Bryan Ford", 
    "publish": "2006-03-18T17:11:04Z", 
    "summary": "Though appropriate for core Internet infrastructure, the Internet Protocol is\nunsuited to routing within and between emerging ad-hoc edge networks due to its\ndependence on hierarchical, administratively assigned addresses. Existing\nad-hoc routing protocols address the management problem but do not scale to\nInternet-wide networks. The promise of ubiquitous network computing cannot be\nfulfilled until we develop an Unmanaged Internet Protocol (UIP), a scalable\nrouting protocol that manages itself automatically. UIP must route within and\nbetween constantly changing edge networks potentially containing millions or\nbillions of nodes, and must still function within edge networks disconnected\nfrom the main Internet, all without imposing the administrative burden of\nhierarchical address assignment. Such a protocol appears challenging but\nfeasible. We propose an architecture based on self-certifying, cryptographic\nnode identities and a routing algorithm adapted from distributed hash tables."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0607049v2", 
    "other_authors": "Pierre Parrend, St\u00e9phane Fr\u00e9not", 
    "title": "Secure Component Deployment in the OSGi(tm) Release 4 Platform", 
    "arxiv-id": "cs/0607049v2", 
    "author": "St\u00e9phane Fr\u00e9not", 
    "publish": "2006-07-11T18:54:21Z", 
    "summary": "Last years have seen a dramatic increase in the use of component platforms,\nnot only in classical application servers, but also more and more in the domain\nof Embedded Systems. The OSGi(tm) platform is one of these platforms dedicated\nto lightweight execution environments, and one of the most prominent. However,\nnew platforms also imply new security flaws, and a lack of both knowledge and\ntools for protecting the exposed systems. This technical report aims at\nfostering the understanding of security mechanisms in component deployment. It\nfocuses on securing the deployment of components. It presents the cryptographic\nmechanisms necessary for signing OSGi(tm) bundles, as well as the detailed\nprocess of bundle signature and validation. We also present the SFelix\nplatform, which is a secure extension to Felix OSGi(tm) framework\nimplementation. It includes our implementation of the bundle signature process,\nas specified by OSGi(tm) Release 4 Security Layer. Moreover, a tool for signing\nand publishing bundles, SFelix JarSigner, has been developed to conveniently\nintegrate bundle signature in the bundle deployment process."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0701021v2", 
    "other_authors": "Franco Milicchio", 
    "title": "The Unix KISS: A Case Study", 
    "arxiv-id": "cs/0701021v2", 
    "author": "Franco Milicchio", 
    "publish": "2007-01-04T09:45:28Z", 
    "summary": "In this paper we show that the initial philosophy used in designing and\ndeveloping UNIX in early times has been forgotten due to \"fast practices\". We\nquestion the leitmotif that microkernels, though being by design adherent to\nthe KISS principle, have a number of context switches higher than their\nmonolithic counterparts, running a test suite and verify the results with\nstandard statistical validation tests. We advocate a wiser distribution of\nshared libraries by statistically analyzing the weight of each shared object in\na typical UNIX system, showing that the majority of shared libraries exist in a\ncommon space for no real evidence of need. Finally we examine the UNIX heritage\nwith an historical point of view, noticing how habits swiftly replaced the\nintents of the original authors, moving the focus from the earliest purpose of\nis avoiding complications, keeping a system simple to use and maintain."
},{
    "category": "cs.DC", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/cs/0701037v3", 
    "other_authors": "Jason Ansel, Kapil Arya, Gene Cooperman", 
    "title": "DMTCP: Transparent Checkpointing for Cluster Computations and the   Desktop", 
    "arxiv-id": "cs/0701037v3", 
    "author": "Gene Cooperman", 
    "publish": "2007-01-06T11:36:50Z", 
    "summary": "DMTCP (Distributed MultiThreaded CheckPointing) is a transparent user-level\ncheckpointing package for distributed applications. Checkpointing and restart\nis demonstrated for a wide range of over 20 well known applications, including\nMATLAB, Python, TightVNC, MPICH2, OpenMPI, and runCMS. RunCMS runs as a 680 MB\nimage in memory that includes 540 dynamic libraries, and is used for the CMS\nexperiment of the Large Hadron Collider at CERN. DMTCP transparently\ncheckpoints general cluster computations consisting of many nodes, processes,\nand threads; as well as typical desktop applications. On 128 distributed cores\n(32 nodes), checkpoint and restart times are typically 2 seconds, with\nnegligible run-time overhead. Typical checkpoint times are reduced to 0.2\nseconds when using forked checkpointing. Experimental results show that\ncheckpoint time remains nearly constant as the number of nodes increases on a\nmedium-size cluster.\n  DMTCP automatically accounts for fork, exec, ssh, mutexes/semaphores, TCP/IP\nsockets, UNIX domain sockets, pipes, ptys (pseudo-terminals), terminal modes,\nownership of controlling terminals, signal handlers, open file descriptors,\nshared open file descriptors, I/O (including the readline library), shared\nmemory (via mmap), parent-child process relationships, pid virtualization, and\nother operating system artifacts. By emphasizing an unprivileged, user-space\napproach, compatibility is maintained across Linux kernels from 2.6.9 through\nthe current 2.6.28. Since DMTCP is unprivileged and does not require special\nkernel modules or kernel patches, DMTCP can be incorporated and distributed as\na checkpoint-restart module within some larger package."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0705.2786v1", 
    "other_authors": "Joachim J. Wlodarz", 
    "title": "Virtualization: A double-edged sword", 
    "arxiv-id": "0705.2786v1", 
    "author": "Joachim J. Wlodarz", 
    "publish": "2007-05-19T00:02:24Z", 
    "summary": "Virtualization became recently a hot topic once again, after being dormant\nfor more than twenty years. In the meantime, it has been almost forgotten, that\nvirtual machines are not so perfect isolating environments as it seems, when\nlooking at the principles. These lessons were already learnt earlier when the\nfirst virtualized systems have been exposed to real life usage.\n  Contemporary virtualization software enables instant creation and destruction\nof virtual machines on a host, live migration from one host to another,\nexecution history manipulation, etc. These features are very useful in\npractice, but also causing headaches among security specialists, especially in\ncurrent hostile network environments.\n  In the present contribution we discuss the principles, potential benefits and\nrisks of virtualization in a deja vu perspective, related to previous\nexperiences with virtualization in the mainframe era."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0706.2748v2", 
    "other_authors": "Yvan Royon, St\u00e9phane Fr\u00e9not", 
    "title": "A Survey of Unix Init Schemes", 
    "arxiv-id": "0706.2748v2", 
    "author": "St\u00e9phane Fr\u00e9not", 
    "publish": "2007-06-19T09:44:36Z", 
    "summary": "In most modern operating systems, init (as in \"initialization\") is the\nprogram launched by the kernel at boot time. It runs as a daemon and typically\nhas PID 1. Init is responsible for spawning all other processes and scavenging\nzombies. It is also responsible for reboot and shutdown operations. This\ndocument describes existing solutions that implement the init process and/or\ninit scripts in Unix-like systems. These solutions range from the legacy and\nstill-in-use BSD and SystemV schemes, to recent and promising schemes from\nUbuntu, Apple, Sun and independent developers. Our goal is to highlight their\nfocus and compare their sets of features."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0706.3812v3", 
    "other_authors": "Pierre Parrend, St\u00e9phane Fr\u00e9not", 
    "title": "Java Components Vulnerabilities - An Experimental Classification   Targeted at the OSGi Platform", 
    "arxiv-id": "0706.3812v3", 
    "author": "St\u00e9phane Fr\u00e9not", 
    "publish": "2007-06-26T12:36:37Z", 
    "summary": "The OSGi Platform finds a growing interest in two different applications\ndomains: embedded systems, and applications servers. However, the security\nproperties of this platform are hardly studied, which is likely to hinder its\nuse in production systems. This is all the more important that the dynamic\naspect of OSGi-based applications, that can be extended at runtime, make them\nvulnerable to malicious code injection. We therefore perform a systematic audit\nof the OSGi platform so as to build a vulnerability catalog that intends to\nreference OSGi Vulnerabilities originating in the Core Specification, and in\nbehaviors related to the use of the Java language. Standard Services are not\nconsidered. To support this audit, a Semi-formal Vulnerability Pattern is\ndefined, that enables to uniquely characterize fundamental properties for each\nvulnerability, to include verbose description in the pattern, to reference\nknown security protections, and to track the implementation status of the\nproof-of-concept OSGi Bundles that exploit the vulnerability. Based on the\nanalysis of the catalog, a robust OSGi Platform is built, and recommendations\nare made to enhance the OSGi Specifications."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0709.4558v1", 
    "other_authors": "Jeremy Lee", 
    "title": "Practical Multiwriter Lock-Free Queues for \"Hard Real-Time\" Systems   without CAS", 
    "arxiv-id": "0709.4558v1", 
    "author": "Jeremy Lee", 
    "publish": "2007-09-28T09:04:27Z", 
    "summary": "FIFO queues with a single reader and writer can be insufficient for \"hard\nreal-time\" systems where interrupt handlers require wait-free guarantees when\nwriting to message queues. We present an algorithm which elegantly and\npractically solves this problem on small processors that are often found in\nembedded systems. The algorithm does not require special CPU instructions (such\nas atomic CAS), and therefore is more robust than many existing methods that\nsuffer the ABA problem associated with swing pointers. The algorithm gives\n\"first-in, almost first-out\" guarantees under pathological interrupt\nconditions, which manifests as arbitrary \"shoving\" among nearly-simultaneous\narrivals at the end of the queue."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0805.4680v3", 
    "other_authors": "Lamia Benmouffok, Jean-Michel Busca, Joan Manuel Marqu\u00e8s, Marc Shapiro, Pierre Sutra, Georgios Tsoukalas", 
    "title": "Telex: Principled System Support for Write-Sharing in Collaborative   Applications", 
    "arxiv-id": "0805.4680v3", 
    "author": "Georgios Tsoukalas", 
    "publish": "2008-05-30T07:01:51Z", 
    "summary": "The Telex system is designed for sharing mutable data in a distributed\nenvironment, particularly for collaborative applications. Users operate on\ntheir local, persistent replica of shared documents; they can work disconnected\nand suffer no network latency. The Telex approach to detect and correct\nconflicts is application independent, based on an action-constraint graph (ACG)\nthat summarises the concurrency semantics of applications. The ACG is stored\nefficiently in a multilog structure that eliminates contention and is optimised\nfor locality. Telex supports multiple applications and multi-document updates.\nThe Telex system clearly separates system logic (which includes replication,\nviews, undo, security, consistency, conflicts, and commitment) from application\nlogic. An example application is a shared calendar for managing multi-user\nmeetings; the system detects meeting conflicts and resolves them consistently."
},{
    "category": "cs.OS", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0808.0920v1", 
    "other_authors": "Mahesh Arumugam", 
    "title": "A Distributed and Deterministic TDMA Algorithm for   Write-All-With-Collision Model", 
    "arxiv-id": "0808.0920v1", 
    "author": "Mahesh Arumugam", 
    "publish": "2008-08-06T20:33:56Z", 
    "summary": "Several self-stabilizing time division multiple access (TDMA) algorithms are\nproposed for sensor networks. In addition to providing a collision-free\ncommunication service, such algorithms enable the transformation of programs\nwritten in abstract models considered in distributed computing literature into\na model consistent with sensor networks, i.e., write all with collision (WAC)\nmodel. Existing TDMA slot assignment algorithms have one or more of the\nfollowing properties: (i) compute slots using a randomized algorithm, (ii)\nassume that the topology is known upfront, and/or (iii) assign slots\nsequentially. If these algorithms are used to transform abstract programs into\nprograms in WAC model then the transformed programs are probabilistically\ncorrect, do not allow the addition of new nodes, and/or converge in a\nsequential fashion. In this paper, we propose a self-stabilizing deterministic\nTDMA algorithm where a sensor is aware of only its neighbors. We show that the\nslots are assigned to the sensors in a concurrent fashion and starting from\narbitrary initial states, the algorithm converges to states where\ncollision-free communication among the sensors is restored. Moreover, this\nalgorithm facilitates the transformation of abstract programs into programs in\nWAC model that are deterministically correct."
},{
    "category": "cs.PL", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0810.0372v1", 
    "other_authors": "Filipe Cabecinhas, Nuno Lopes, Renato Crisostomo, Luis Veiga", 
    "title": "Optimizing Binary Code Produced by Valgrind (Project Report on Virtual   Execution Environments Course - AVExe)", 
    "arxiv-id": "0810.0372v1", 
    "author": "Luis Veiga", 
    "publish": "2008-10-02T09:41:52Z", 
    "summary": "Valgrind is a widely used framework for dynamic binary instrumentation and\nits mostly known by its memcheck tool. Valgrind's code generation module is far\nfrom producing optimal code. In addition it has many backends for different CPU\narchitectures, which difficults code optimization in an architecture\nindependent way. Our work focused on identifying sub-optimal code produced by\nValgrind and optimizing it."
},{
    "category": "cs.DM", 
    "doi": "10.1007/978-1-4757-3609-0_2", 
    "link": "http://arxiv.org/pdf/0810.1316v1", 
    "other_authors": "Victor Yodaiken", 
    "title": "The meaning of concurrent programs", 
    "arxiv-id": "0810.1316v1", 
    "author": "Victor Yodaiken", 
    "publish": "2008-10-07T23:03:29Z", 
    "summary": "The semantics of assignment and mutual exclusion in concurrent and\nmulti-core/multi-processor systems is presented with attention to low level\narchitectural features in an attempt to make the presentation realistic.\nRecursive functions on event sequences are used to define state dependent\nfunctions and variables in ordinary (non-formal-method) algebra."
},{
    "category": "cs.SE", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/0902.1610v1", 
    "other_authors": "Roberto Di Cosmo, Stefano Zacchiroli, Paulo Trezentos", 
    "title": "Package upgrades in FOSS distributions: details and challenges", 
    "arxiv-id": "0902.1610v1", 
    "author": "Paulo Trezentos", 
    "publish": "2009-02-10T09:14:59Z", 
    "summary": "The upgrade problems faced by Free and Open Source Software distributions\nhave characteristics not easily found elsewhere. We describe the structure of\npackages and their role in the upgrade process. We show that state of the art\npackage managers have shortcomings inhibiting their ability to cope with\nfrequent upgrade failures. We survey current countermeasures to such failures,\nargue that they are not satisfactory, and sketch alternative solutions."
},{
    "category": "cs.AR", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/0910.4052v1", 
    "other_authors": "Andrei I. Yafimau", 
    "title": "Virtual-Threading: Advanced General Purpose Processors Architecture", 
    "arxiv-id": "0910.4052v1", 
    "author": "Andrei I. Yafimau", 
    "publish": "2009-10-21T11:31:14Z", 
    "summary": "The paper describes the new computers architecture, the main features of\nwhich has been claimed in the Russian Federation patent 2312388 and in the US\npatent application 11/991331. This architecture is intended to effective\nsupport of the General Purpose Parallel Computing (GPPC), the essence of which\nis extremely frequent switching of threads between states of activity and\nstates of viewed in the paper the algorithmic latency. To emphasize the same\nimpact of the architectural latency and the algorithmic latency upon GPPC, is\nintroduced the new notion of the generalized latency and is defined its\nquantitative measure - the Generalized Latency Tolerance (GLT). It is shown\nthat a well suited for GPPC implementation architecture should have high level\nof GLT and is described such architecture, which is called the Virtual-Threaded\nMachine. This architecture originates a processor virtualization in the\ndirection of activities virtualization, which is orthogonal to the well-known\ndirection of memory virtualization. The key elements of the architecture are 1)\nthe distributed fine grain representation of the architectural register file,\nwhich elements are hardware swapped through levels of a microarchitectural\nmemory, 2) the prioritized fine grain direct hardware multiprogramming, 3) the\naccess controlled virtual addressing and 4) the hardware driven semaphores. The\ncomposition of these features lets to introduce new styles of operating system\n(OS) programming, which is free of interruptions, and of applied programming\nwith a very rare using the OS services."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/0910.5046v1", 
    "other_authors": "Ana Maria Visan, Artem Polyakov, Praveen S. Solanki, Kapil Arya, Tyler Denniston, Gene Cooperman", 
    "title": "Temporal Debugging using URDB", 
    "arxiv-id": "0910.5046v1", 
    "author": "Gene Cooperman", 
    "publish": "2009-10-27T17:31:02Z", 
    "summary": "A new style of temporal debugging is proposed. The new URDB debugger can\nemploy such techniques as temporal search for finding an underlying fault that\nis causing a bug. This improves on the standard iterative debugging style,\nwhich iteratively re-executes a program under debugger control in the search\nfor the underlying fault. URDB acts as a meta-debugger, with current support\nfor four widely used debuggers: gdb, MATLAB, python, and perl. Support for a\nnew debugger can be added in a few hours. Among its points of novelty are: (i)\nthe first reversible debuggers for MATLAB, python, and perl; (ii) support for\ntoday's multi-core architectures; (iii) reversible debugging of multi-process\nand distributed computations; and (iv) temporal search on changes in program\nexpressions. URDB gains its reversibility and temporal abilities through the\nfast checkpoint-restart capability of DMTCP (Distributed MultiThreaded\nCheckPointing). The recently enhanced DMTCP also adds ptrace support, enabling\none to freeze, migrate, and replicate debugging sessions."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/0910.5577v1", 
    "other_authors": "Ilkka Norros, Hannu Reittu, Timo Eirola", 
    "title": "On the stability of two-chunk file-sharing systems", 
    "arxiv-id": "0910.5577v1", 
    "author": "Timo Eirola", 
    "publish": "2009-10-29T08:38:32Z", 
    "summary": "We consider five different peer-to-peer file sharing systems with two chunks,\nwith the aim of finding chunk selection algorithms that have provably stable\nperformance with any input rate and assuming non-altruistic peers who leave the\nsystem immediately after downloading the second chunk. We show that many\nalgorithms that first looked promising lead to unstable or oscillating\nbehavior. However, we end up with a system with desirable properties. Most of\nour rigorous results concern the corresponding deterministic large system\nlimits, but in two simplest cases we provide proofs for the stochastic systems\nalso."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/0912.4062v1", 
    "other_authors": "Emil Vassev", 
    "title": "Process Description of COM Object Life Cycle", 
    "arxiv-id": "0912.4062v1", 
    "author": "Emil Vassev", 
    "publish": "2009-12-20T23:49:25Z", 
    "summary": "The objective of this article is to provide for the reader a basic\ndescription of all the steps involved in the COM object life-cycle process. COM\nis a software technology and process performer. The first section briefly\nintroduces the Component Object Model (COM), considering the process of the COM\nobject life cycle as the baseline of all COM issues. The second part describes\nin detail the basic steps of the process - client request, server location,\nobject creation, interaction, and disconnection. A brief description is given\nfor the components involved in each step. Finally, the third section provides a\nbrief conclusion summarizing all the process steps."
},{
    "category": "cs.DC", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/1001.0196v1", 
    "other_authors": "Edward Walker", 
    "title": "A distributed file system for a wide-area high performance computing   infrastructure", 
    "arxiv-id": "1001.0196v1", 
    "author": "Edward Walker", 
    "publish": "2010-01-01T00:34:59Z", 
    "summary": "We describe our work in implementing a wide-area distributed file system for\nthe NSF TeraGrid. The system, called XUFS, allows private distributed name\nspaces to be created for transparent access to personal files across over 9000\ncomputer nodes. XUFS builds on many principles from prior distributed file\nsystems research, but extends key design goals to support the workflow of\ncomputational science researchers. Specifically, XUFS supports file access from\nthe desktop to the wide-area network seamlessly, survives transient\ndisconnected operations robustly, and demonstrates comparable or better\nthroughput than some current high performance file systems on the wide-area\nnetwork."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/1001.4115v3", 
    "other_authors": "Shelby Funk, Vincent Nelis, Joel Goossens, Dragomir Milojevic, Geoffrey Nelissen", 
    "title": "On the Design of an Optimal Multiprocessor Real-Time Scheduling   Algorithm under Practical Considerations (Extended Version)", 
    "arxiv-id": "1001.4115v3", 
    "author": "Geoffrey Nelissen", 
    "publish": "2010-01-25T08:09:27Z", 
    "summary": "This research addresses the multiprocessor scheduling problem of hard\nreal-time systems, and it especially focuses on optimal and global schedulers\nwhen practical constraints are taken into account. First, we propose an\nimprovement of the optimal algorithm BF. We formally prove that our adaptation\nis (i) optimal, i.e., it always generates a feasible schedule as long as such a\nschedule exists, and (ii) valid, i.e., it complies with the all the\nrequirements. We also show that it outperforms BF by providing a computing\ncomplexity of O(n), where n is the number of tasks to be scheduled. Next, we\npropose a schedulability analysis which indicates a priori whether the\nreal-time application can be scheduled by our improvement of BF without missing\nany deadline. This analysis is, to the best of our knowledge, the first such\ntest for multiprocessors that takes into account all the main overheads\ngenerated by the Operating System."
},{
    "category": "cs.CR", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/1002.0298v1", 
    "other_authors": "Jayanthkumar Kannan, Petros Maniatis, Byung-Gon Chun", 
    "title": "A Data Capsule Framework For Web Services: Providing Flexible Data   Access Control To Users", 
    "arxiv-id": "1002.0298v1", 
    "author": "Byung-Gon Chun", 
    "publish": "2010-02-01T18:31:06Z", 
    "summary": "This paper introduces the notion of a secure data capsule, which refers to an\nencapsulation of sensitive user information (such as a credit card number)\nalong with code that implements an interface suitable for the use of such\ninformation (such as charging for purchases) by a service (such as an online\nmerchant). In our capsule framework, users provide their data in the form of\nsuch capsules to web services rather than raw data. Capsules can be deployed in\na variety of ways, either on a trusted third party or the user's own computer\nor at the service itself, through the use of a variety of hardware or software\nmodules, such as a virtual machine monitor or trusted platform module: the only\nrequirement is that the deployment mechanism must ensure that the user's data\nis only accessed via the interface sanctioned by the user. The framework\nfurther allows an user to specify policies regarding which services or machines\nmay host her capsule, what parties are allowed to access the interface, and\nwith what parameters. The combination of interface restrictions and policy\ncontrol lets us bound the impact of an attacker who compromises the service to\ngain access to the user's capsule or a malicious insider at the service itself."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/1002.3329v1", 
    "other_authors": "M. Tarighi, S. A. Motamedi, S. Sharifian", 
    "title": "A new model for virtual machine migration in virtualized cluster server   based on Fuzzy Decision Making", 
    "arxiv-id": "1002.3329v1", 
    "author": "S. Sharifian", 
    "publish": "2010-02-17T17:52:17Z", 
    "summary": "In this paper, we show that performance of the virtualized cluster servers\ncould be improved through intelligent decision over migration time of Virtual\nMachines across heterogeneous physical nodes of a cluster server. The cluster\nserves a variety range of services from Web Service to File Service. Some of\nthem are CPU-Intensive while others are RAM-Intensive and so on. Virtualization\nhas many advantages such as less hardware cost, cooling cost, more\nmanageability. One of the key benefits is better load balancing by using of VM\nmigration between hosts. To migrate, we must know which virtual machine needs\nto be migrated and when this relocation has to be done and, moreover, which\nhost must be destined. To relocate VMs from overloaded servers to underloaded\nones, we need to sort nodes from the highest volume to the lowest. There are\nsome models to finding the most overloaded node, but they have some\nshortcomings. The focus of this paper is to present a new method to migrate VMs\nbetween cluster nodes using TOPSIS algorithm - one of the most efficient Multi\nCriteria Decision Making techniques- to make more effective decision over whole\nactive servers of the Cluster and find the most loaded serversTo evaluate the\nperformance improvement resulted from this model, we used cluster Response time\nand Unbalanced Factor."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1490283.1490292", 
    "link": "http://arxiv.org/pdf/1003.5303v2", 
    "other_authors": "Amittai Aviram, Sen Hu, Bryan Ford, Ramakrishna Gummadi", 
    "title": "Determinating Timing Channels in Compute Clouds", 
    "arxiv-id": "1003.5303v2", 
    "author": "Ramakrishna Gummadi", 
    "publish": "2010-03-27T14:44:01Z", 
    "summary": "Timing side-channels represent an insidious security challenge for cloud\ncomputing, because: (a) massive parallelism in the cloud makes timing channels\npervasive and hard to control; (b) timing channels enable one customer to steal\ninformation from another without leaving a trail or raising alarms; (c) only\nthe cloud provider can feasibly detect and report such attacks, but the\nprovider's incentives are not to; and (d) resource partitioning schemes for\ntiming channel control undermine statistical sharing efficiency, and, with it,\nthe cloud computing business model. We propose a new approach to timing channel\ncontrol, using provider-enforced deterministic execution instead of resource\npartitioning to eliminate timing channels within a shared cloud domain.\nProvider-enforced determinism prevents execution timing from affecting the\nresults of a compute task, however large or parallel, ensuring that a task's\noutputs leak no timing information apart from explicit timing inputs and total\ncompute duration. Experiments with a prototype OS for deterministic cloud\ncomputing suggest that such an approach may be practical and efficient. The OS\nsupports deterministic versions of familiar APIs such as processes, threads,\nshared memory, and file systems, and runs coarse-grained parallel tasks as\nefficiently and scalably as current timing channel-ridden systems."
},{
    "category": "cs.OS", 
    "doi": "10.1145/1858996.1859085", 
    "link": "http://arxiv.org/pdf/1006.5845v1", 
    "other_authors": "Aristide Fattori, Roberto Paleari, Lorenzo Martignoni, Mattia Monga", 
    "title": "Dynamic and Transparent Analysis of Commodity Production Systems", 
    "arxiv-id": "1006.5845v1", 
    "author": "Mattia Monga", 
    "publish": "2010-06-30T13:01:58Z", 
    "summary": "We propose a framework that provides a programming interface to perform\ncomplex dynamic system-level analyses of deployed production systems. By\nleveraging hardware support for virtualization available nowadays on all\ncommodity machines, our framework is completely transparent to the system under\nanalysis and it guarantees isolation of the analysis tools running on its top.\nThus, the internals of the kernel of the running system needs not to be\nmodified and the whole platform runs unaware of the framework. Moreover, errors\nin the analysis tools do not affect the running system and the framework. This\nis accomplished by installing a minimalistic virtual machine monitor and\nmigrating the system, as it runs, into a virtual machine. In order to\ndemonstrate the potentials of our framework we developed an interactive kernel\ndebugger, nicknamed HyperDbg. HyperDbg can be used to debug any critical kernel\ncomponent, and even to single step the execution of exception and interrupt\nhandlers."
},{
    "category": "cs.DC", 
    "doi": "10.1145/1858996.1859085", 
    "link": "http://arxiv.org/pdf/1009.3088v2", 
    "other_authors": "Byung-Gon Chun, Sunghwan Ihm, Petros Maniatis, Mayur Naik", 
    "title": "CloneCloud: Boosting Mobile Device Applications Through Cloud Clone   Execution", 
    "arxiv-id": "1009.3088v2", 
    "author": "Mayur Naik", 
    "publish": "2010-09-16T04:43:46Z", 
    "summary": "Mobile applications are becoming increasingly ubiquitous and provide ever\nricher functionality on mobile devices. At the same time, such devices often\nenjoy strong connectivity with more powerful machines ranging from laptops and\ndesktops to commercial clouds. This paper presents the design and\nimplementation of CloneCloud, a system that automatically transforms mobile\napplications to benefit from the cloud. The system is a flexible application\npartitioner and execution runtime that enables unmodified mobile applications\nrunning in an application-level virtual machine to seamlessly off-load part of\ntheir execution from mobile devices onto device clones operating in a\ncomputational cloud. CloneCloud uses a combination of static analysis and\ndynamic profiling to optimally and automatically partition an application so\nthat it migrates, executes in the cloud, and re-integrates computation in a\nfine-grained manner that makes efficient use of resources. Our evaluation shows\nthat CloneCloud can achieve up to 21.2x speedup of smartphone applications we\ntested and it allows different partitioning for different inputs and networks."
},{
    "category": "cs.DC", 
    "doi": "10.1002/net.21537", 
    "link": "http://arxiv.org/pdf/1010.4411v1", 
    "other_authors": "Fabiano de S. Oliveira, Valmir C. Barbosa", 
    "title": "Revisiting deadlock prevention: a probabilistic approach", 
    "arxiv-id": "1010.4411v1", 
    "author": "Valmir C. Barbosa", 
    "publish": "2010-10-21T10:12:59Z", 
    "summary": "We revisit the deadlock-prevention problem by focusing on priority digraphs\ninstead of the traditional wait-for digraphs. This has allowed us to formulate\ndeadlock prevention in terms of prohibiting the occurrence of directed cycles\neven in the most general of wait models (the so-called AND-OR model, in which\nprohibiting wait-for directed cycles is generally overly restrictive). For a\nparticular case in which the priority digraphs are somewhat simplified, we\nintroduce a Las Vegas probabilistic mechanism for resource granting and analyze\nits key aspects in detail."
},{
    "category": "cs.DC", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1011.3087v1", 
    "other_authors": "Hongtao Huang, Feng Xia, Jijie Wang, Siyu Lei, Guowei Wu", 
    "title": "Leakage-Aware Reallocation for Periodic Real-Time Tasks on Multicore   Processors", 
    "arxiv-id": "1011.3087v1", 
    "author": "Guowei Wu", 
    "publish": "2010-11-13T02:17:29Z", 
    "summary": "It is an increasingly important issue to reduce the energy consumption of\ncomputing systems. In this paper, we consider partition based energy-aware\nscheduling of periodic real-time tasks on multicore processors. The scheduling\nexploits dynamic voltage scaling (DVS) and core sleep scheduling to reduce both\ndynamic and leakage energy consumption. If the overhead of core state switching\nis non-negligible, however, the performance of this scheduling strategy in\nterms of energy efficiency might degrade. To achieve further energy saving, we\nextend the static task scheduling with run-time task reallocation. The basic\nidea is to aggregate idle time among cores so that as many cores as possible\ncould be put into sleep in a way that the overall energy consumption is\nreduced. Simulation results show that the proposed approach results in up to\n20% energy saving over traditional leakage-aware DVS."
},{
    "category": "cs.OS", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1103.2348v1", 
    "other_authors": "Felix Xiaozhu Lin, Zhen Wang, Robert LiKamWa, Lin Zhong", 
    "title": "Transparent Programming of Heterogeneous Smartphones for Sensing", 
    "arxiv-id": "1103.2348v1", 
    "author": "Lin Zhong", 
    "publish": "2011-03-11T19:12:15Z", 
    "summary": "Sensing on smartphones is known to be power-hungry. It has been shown that\nthis problem can be solved by adding an ultra low-power processor to execute\nsimple, frequent sensor data processing. While very effective in saving energy,\nthis resulting heterogeneous, distributed architecture poses a significant\nchallenge to application development.\n  We present Reflex, a suite of runtime and compilation techniques to conceal\nthe heterogeneous, distributed nature from developers. The Reflex automatically\ntransforms the developer's code for distributed execution with the help of the\nReflex runtime. To create a unified system illusion, Reflex features a novel\nsoftware distributed shared memory (DSM) design that leverages the extreme\narchitectural asymmetry between the low-power processor and the powerful\ncentral processor to achieve both energy efficiency and performance.\n  We report a complete realization of Reflex for heterogeneous smartphones with\nMaemo/Linux as the central kernel. Using a tri-processor hardware prototype and\nsensing applications reported in recent literature, we evaluate the Reflex\nrealization for programming transparency, energy efficiency, and performance.\nWe show that Reflex supports a programming style that is very close to\ncontemporary smartphone programming. It allows existing sensing applications to\nbe ported with minor source code changes. Reflex reduces the system power in\nsensing by up to 83%, and its runtime system only consumes 10% local memory on\na typical ultra-low power processor."
},{
    "category": "cs.OS", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1105.1811v1", 
    "other_authors": "Niall Douglas", 
    "title": "User Mode Memory Page Allocation: A Silver Bullet For Memory Allocation?", 
    "arxiv-id": "1105.1811v1", 
    "author": "Niall Douglas", 
    "publish": "2011-05-09T22:26:15Z", 
    "summary": "This paper proposes a novel solution: the elimination of paged virtual memory\nand partial outsourcing of memory page allocation and manipulation from the\noperating system kernel into the individual process' user space - a user mode\npage allocator - which allows an application to have direct, bare metal access\nto the page mappings used by the hardware Memory Management Unit (MMU) for its\npart of the overall address space. A user mode page allocator based emulation\nof the mmap() abstraction layer of dlmalloc is then benchmarked against the\ntraditional kernel mode implemented mmap() in a series of synthetic Monte-Carlo\nand real world application settings. Given the superb synthetic and positive\nreal world results from the profiling conducted, this paper proposes that with\nproper operating system and API support one could gain a further order higher\nperformance again while keeping allocator performance invariant to the amount\nof memory being allocated or freed i.e. a 100x performance improvement or more\nin some common use cases. It is rare that through a simple and easy to\nimplement API and operating system structure change one can gain a Silver\nBullet with the potential for a second one."
},{
    "category": "cs.OS", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1105.1815v1", 
    "other_authors": "Niall Douglas", 
    "title": "User Mode Memory Page Management: An old idea applied anew to the memory   wall problem", 
    "arxiv-id": "1105.1815v1", 
    "author": "Niall Douglas", 
    "publish": "2011-05-09T22:39:46Z", 
    "summary": "It is often said that one of the biggest limitations on computer performance\nis memory bandwidth (i.e.\"the memory wall problem\"). In this position paper, I\nargue that if historical trends in computing evolution (where growth in\navailable capacity is exponential and reduction in its access latencies is\nlinear) continue as they have, then this view is wrong - in fact we ought to be\nconcentrating on reducing whole system memory access latencies wherever\npossible, and by \"whole system\" I mean that we ought to look at how software\ncan be unnecessarily wasteful with memory bandwidth due to legacy design\ndecisions. To this end I conduct a feasibility study to determine whether we\nought to virtualise the MMU for each application process such that it has\ndirect access to its own MMU page tables and the memory allocated to a process\nis managed exclusively by the process and not the kernel. I find under typical\nconditions that nearly scale invariant performance to memory allocation size is\npossible such that hundreds of megabytes of memory can be allocated, relocated,\nswapped and deallocated in almost the same time as kilobytes (e.g. allocating\n8Mb is 10x quicker under this experimental allocator than a conventional\nallocator, and resizing a 128Kb block to 256Kb block is 4.5x faster). I find\nthat first time page access latencies are improved tenfold; moreover, because\nthe kernel page fault handler is never called, the lack of cache pollution\nimproves whole application memory access latencies increasing performance by up\nto 2x. Finally, I try binary patching existing applications to use the\nexperimental allocation technique, finding almost universal performance\nimprovements without having to recompile these applications to make better use\nof the new facilities."
},{
    "category": "cs.OS", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1105.5055v2", 
    "other_authors": "Markus Lindstr\u00f6m, Gilles Geeraerts, Jo\u00ebl Goossens", 
    "title": "A faster exact multiprocessor schedulability test for sporadic tasks", 
    "arxiv-id": "1105.5055v2", 
    "author": "Jo\u00ebl Goossens", 
    "publish": "2011-05-25T15:02:01Z", 
    "summary": "Baker and Cirinei introduced an exact but naive algorithm, based on solving a\nstate reachability problem in a finite automaton, to check whether sets of\nsporadic hard real-time tasks are schedulable on identical multiprocessor\nplatforms. However, the algorithm suffered from poor performance due to the\nexponential size of the automaton relative to the size of the task set. In this\npaper, we successfully apply techniques developed by the formal verification\ncommunity, specifically antichain algorithms, by defining and proving the\ncorrectness of a simulation relation on Baker and Cirinei's automaton. We show\nour improved algorithm yields dramatically improved performance for the\nschedulability test and opens for many further improvements."
},{
    "category": "cs.DC", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1302.0621v3", 
    "other_authors": "Chun-Ho Ng, Patrick P. C. Lee", 
    "title": "RevDedup: A Reverse Deduplication Storage System Optimized for Reads to   Latest Backups", 
    "arxiv-id": "1302.0621v3", 
    "author": "Patrick P. C. Lee", 
    "publish": "2013-02-04T09:09:38Z", 
    "summary": "Scaling up the backup storage for an ever-increasing volume of virtual\nmachine (VM) images is a critical issue in virtualization environments. While\ndeduplication is known to effectively eliminate duplicates for VM image\nstorage, it also introduces fragmentation that will degrade read performance.\nWe propose RevDedup, a deduplication system that optimizes reads to latest VM\nimage backups using an idea called reverse deduplication. In contrast with\nconventional deduplication that removes duplicates from new data, RevDedup\nremoves duplicates from old data, thereby shifting fragmentation to old data\nwhile keeping the layout of new data as sequential as possible. We evaluate our\nRevDedup prototype using microbenchmark and real-world workloads. For a 12-week\nspan of real-world VM images from 160 users, RevDedup achieves high\ndeduplication efficiency with around 97% of saving, and high backup and read\nthroughput on the order of 1GB/s. RevDedup also incurs small metadata overhead\nin backup/read operations."
},{
    "category": "cs.DC", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1302.1306v1", 
    "other_authors": "Youcheng Sun, Romain Soulat, Giuseppe Lipari, \u00c9tienne Andr\u00e9, Laurent Fribourg", 
    "title": "Parametric Schedulability Analysis of Fixed Priority Real-Time   Distributed Systems", 
    "arxiv-id": "1302.1306v1", 
    "author": "Laurent Fribourg", 
    "publish": "2013-02-06T10:06:39Z", 
    "summary": "Parametric analysis is a powerful tool for designing modern embedded systems,\nbecause it permits to explore the space of design parameters, and to check the\nrobustness of the system with respect to variations of some uncontrollable\nvariable. In this paper, we address the problem of parametric schedulability\nanalysis of distributed real-time systems scheduled by fixed priority. In\nparticular, we propose two different approaches to parametric analysis: the\nfirst one is a novel technique based on classical schedulability analysis,\nwhereas the second approach is based on model checking of Parametric Timed\nAutomata (PTA).\n  The proposed analytic method extends existing sensitivity analysis for single\nprocessors to the case of a distributed system, supporting preemptive and\nnon-preemptive scheduling, jitters and unconstrained deadlines. Parametric\nTimed Automata are used to model all possible behaviours of a distributed\nsystem, and therefore it is a necessary and sufficient analysis. Both\ntechniques have been implemented in two software tools, and they have been\ncompared with classical holistic analysis on two meaningful test cases. The\nresults show that the analytic method provides results similar to classical\nholistic analysis in a very efficient way, whereas the PTA approach is slower\nbut covers the entire space of solutions."
},{
    "category": "cs.PL", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1308.0698v1", 
    "other_authors": "Meisam Booshehri, Abbas Malekpour, Peter Luksch", 
    "title": "An Improving Method for Loop Unrolling", 
    "arxiv-id": "1308.0698v1", 
    "author": "Peter Luksch", 
    "publish": "2013-08-03T14:09:23Z", 
    "summary": "In this paper we review main ideas mentioned in several other papers which\ntalk about optimization techniques used by compilers. Here we focus on loop\nunrolling technique and its effect on power consumption, energy usage and also\nits impact on program speed up by achieving ILP (Instruction-level\nparallelism). Concentrating on superscalar processors, we discuss the idea of\ngeneralized loop unrolling presented by J.C. Hang and T. Leng and then we\npresent a new method to traverse a linked list to get a better result of loop\nunrolling in that case. After that we mention the results of some experiments\ncarried out on a Pentium 4 processor (as an instance of super scalar\narchitecture). Furthermore, the results of some other experiments on\nsupercomputer (the Alliat FX/2800 System) containing superscalar node\nprocessors would be mentioned. These experiments show that loop unrolling has a\nslight measurable effect on energy usage as well as power consumption. But it\ncould be an effective way for program speed up."
},{
    "category": "cs.DC", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1308.2881v1", 
    "other_authors": "Holger Machens, Volker Turau", 
    "title": "Opacity of Memory Management in Software Transactional Memory", 
    "arxiv-id": "1308.2881v1", 
    "author": "Volker Turau", 
    "publish": "2013-08-13T14:37:51Z", 
    "summary": "Opacity of Transactional Memory is proposed to be established by incremental\nvalidation. Quiescence in terms of epoch-based memory reclamation is applied to\ndeal with doomed transactions causing memory access violations. This method\nunfortunately involves increased memory consumption and does not cover\nreclamations outside of transactions. This paper introduces a different method\nwhich combines incremental validation with elements of sandboxing to solve\nthese issues."
},{
    "category": "cs.OS", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1104.2110v1", 
    "other_authors": "Heechul Yun, Cheolgi Kim, Lui Sha", 
    "title": "Deterministic Real-time Thread Scheduling", 
    "arxiv-id": "1104.2110v1", 
    "author": "Lui Sha", 
    "publish": "2011-04-12T04:06:34Z", 
    "summary": "Race condition is a timing sensitive problem. A significant source of timing\nvariation comes from nondeterministic hardware interactions such as cache\nmisses. While data race detectors and model checkers can check races, the\nenormous state space of complex software makes it difficult to identify all of\nthe races and those residual implementation errors still remain a big\nchallenge. In this paper, we propose deterministic real-time scheduling methods\nto address scheduling nondeterminism in uniprocessor systems. The main idea is\nto use timing insensitive deterministic events, e.g, an instruction counter, in\nconjunction with a real-time clock to schedule threads. By introducing the\nconcept of Worst Case Executable Instructions (WCEI), we guarantee both\ndeterminism and real-time performance."
},{
    "category": "cs.OS", 
    "doi": "10.1109/FCST.2010.105", 
    "link": "http://arxiv.org/pdf/1407.0122v1", 
    "other_authors": "Kazi Sakib, M. S. Hasan, M. A. Hossain", 
    "title": "Effects of Hard Real-Time Constraints in Implementing the Myopic   Scheduling Algorithm", 
    "arxiv-id": "1407.0122v1", 
    "author": "M. A. Hossain", 
    "publish": "2014-07-01T07:23:10Z", 
    "summary": "Myopic is a hard real-time process scheduling algorithm that selects a\nsuitable process based on a heuristic function from a subset (Window)of all\nready processes instead of choosing from all available processes, like original\nheuristic scheduling algorithm. Performance of the algorithm significantly\ndepends on the chosen heuristic function that assigns weight to different\nparameters like deadline, earliest starting time, processing time etc. and the\nsizeof the Window since it considers only k processes from n processes (where,\nk<= n). This research evaluates the performance of the Myopic algorithm for\ndifferent parameters to demonstrate the merits and constraints of the\nalgorithm. A comparative performance of the impact of window size in\nimplementing the Myopic algorithm is presented and discussed through a set of\nexperiments."
},{
    "category": "cs.SE", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1407.4346v1", 
    "other_authors": "Nicolas Palix, Ga\u00ebl Thomas, Suman Saha, Christophe Calv\u00e8s, Gilles Muller, Julia L. Lawall", 
    "title": "Faults in Linux 2.6", 
    "arxiv-id": "1407.4346v1", 
    "author": "Julia L. Lawall", 
    "publish": "2014-07-16T15:35:47Z", 
    "summary": "In August 2011, Linux entered its third decade. Ten years before, Chou et al.\npublished a study of faults found by applying a static analyzer to Linux\nversions 1.0 through 2.4.1. A major result of their work was that the drivers\ndirectory contained up to 7 times more of certain kinds of faults than other\ndirectories. This result inspired numerous efforts on improving the reliability\nof driver code. Today, Linux is used in a wider range of environments, provides\na wider range of services, and has adopted a new development and release model.\nWhat has been the impact of these changes on code quality? To answer this\nquestion, we have transported Chou et al.'s experiments to all versions of\nLinux 2.6; released between 2003 and 2011. We find that Linux has more than\ndoubled in size during this period, but the number of faults per line of code\nhas been decreasing. Moreover, the fault rate of drivers is now below that of\nother directories, such as arch. These results can guide further development\nand research efforts for the decade to come. To allow updating these results as\nLinux evolves, we define our experimental protocol and make our checkers\navailable."
},{
    "category": "cs.OS", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/0806.1768v1", 
    "other_authors": "Ted Herman, Morten Mjelde", 
    "title": "Local Read-Write Operations in Sensor Networks", 
    "arxiv-id": "0806.1768v1", 
    "author": "Morten Mjelde", 
    "publish": "2008-06-11T00:03:00Z", 
    "summary": "Designing protocols and formulating convenient programming units of\nabstraction for sensor networks is challenging due to communication errors and\nplatform constraints. This paper investigates properties and implementation\nreliability for a \\emph{local read-write} abstraction. Local read-write is\ninspired by the class of read-modify-write operations defined for shared-memory\nmultiprocessor architectures. The class of read-modify-write operations is\nimportant in solving consensus and related synchronization problems for\nconcurrency control. Local read-write is shown to be an atomic abstraction for\nsynchronizing neighborhood states in sensor networks. The paper compares local\nread-write to similar lightweight operations in wireless sensor networks, such\nas read-all, write-all, and a transaction-based abstraction: for some\noptimistic scenarios, local read-write is a more efficient neighborhood\noperation. A partial implementation is described, which shows that three\noutcomes characterize operation response: success, failure, and cancel. A\nfailure response indicates possible inconsistency for the operation result,\nwhich is the result of a timeout event at the operation's initiator. The paper\npresents experimental results on operation performance with different timeout\nvalues and situations of no contention, with some tests also on various\nneighborhood sizes."
},{
    "category": "cs.OS", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/0807.3933v1", 
    "other_authors": "Fr\u00e9d\u00e9ric Le Mou\u00ebl, Noha Ibrahim, St\u00e9phane Fr\u00e9not", 
    "title": "Interface Matching and Combining Techniques for Services Integration", 
    "arxiv-id": "0807.3933v1", 
    "author": "St\u00e9phane Fr\u00e9not", 
    "publish": "2008-07-24T17:51:07Z", 
    "summary": "The development of many highly dynamic environments, like pervasive\nenvironments, introduces the possibility to use geographically close-related\nservices. Dynamically integrating and unintegrating these services in running\napplications is a key challenge for this use. In this article, we classify\nservice integration issues according to interfaces exported by services and\ninternal combining techniques. We also propose a contextual integration\nservice, IntegServ, and an interface, Integrable, for developing services."
},{
    "category": "cs.DB", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/0909.1763v1", 
    "other_authors": "Ragib Hasan, Radu Sion, Marianne Winslett", 
    "title": "Remembrance: The Unbearable Sentience of Being Digital", 
    "arxiv-id": "0909.1763v1", 
    "author": "Marianne Winslett", 
    "publish": "2009-09-09T18:09:06Z", 
    "summary": "We introduce a world vision in which data is endowed with memory. In this\ndata-centric systems paradigm, data items can be enabled to retain all or some\nof their previous values. We call this ability \"remembrance\" and posit that it\nempowers significant leaps in the security, availability, and general\noperational dimensions of systems. With the explosion in cheap, fast memories\nand storage, large-scale remembrance will soon become practical. Here, we\nintroduce and explore the advantages of such a paradigm and the challenges in\nmaking it a reality."
},{
    "category": "cs.OS", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/0909.5064v1", 
    "other_authors": "Norbert B\u00e1tfai", 
    "title": "A Conceivable Origin of Machine Consciousness in the IDLE process", 
    "arxiv-id": "0909.5064v1", 
    "author": "Norbert B\u00e1tfai", 
    "publish": "2009-09-28T10:54:48Z", 
    "summary": "In this short paper, we would like to call professional community's attention\nto a daring idea that is surely unhelpful, but is exciting for programmers and\nanyway conflicts with the trend of energy consumption in computer systems."
},{
    "category": "cs.OS", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1005.3450v1", 
    "other_authors": "Amittai Aviram, Shu-Chun Weng, Sen Hu, Bryan Ford", 
    "title": "Efficient System-Enforced Deterministic Parallelism", 
    "arxiv-id": "1005.3450v1", 
    "author": "Bryan Ford", 
    "publish": "2010-05-19T14:17:56Z", 
    "summary": "Deterministic execution offers many benefits for debugging, fault tolerance,\nand security. Running parallel programs deterministically is usually difficult\nand costly, however - especially if we desire system-enforced determinism,\nensuring precise repeatability of arbitrarily buggy or malicious software.\nDeterminator is a novel operating system that enforces determinism on both\nmultithreaded and multi-process computations. Determinator's kernel provides\nonly single-threaded, \"shared-nothing\" address spaces interacting via\ndeterministic synchronization. An untrusted user-level runtime uses distributed\ncomputing techniques to emulate familiar abstractions such as Unix processes,\nfile systems, and shared memory multithreading. The system runs parallel\napplications deterministically both on multicore PCs and across nodes in a\ncluster. Coarse-grained parallel benchmarks perform and scale comparably to -\nsometimes better than - conventional systems, though determinism is costly for\nfine-grained parallel applications."
},{
    "category": "cs.SE", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1005.5045v1", 
    "other_authors": "Mario Bravetti", 
    "title": "File Managing and Program Execution in Web Operating Systems", 
    "arxiv-id": "1005.5045v1", 
    "author": "Mario Bravetti", 
    "publish": "2010-05-27T12:28:51Z", 
    "summary": "Web Operating Systems can be seen as an extension of traditional Operating\nSystems where the addresses used to manage files and execute programs (via the\nbasic load/execution mechanism) are extended from local filesystem path-names\nto URLs. A first consequence is that, similarly as in traditional web\ntechnologies, executing a program at a given URL, can be done in two\nmodalities: either the execution is performed client-side at the invoking\nmachine (and relative URL addressing in the executed program set to refer to\nthe invoked URL) or it is performed server-side at the machine addressed by the\ninvoked URL (as, e.g., for a web service). Moreover in this context, user\nidentification for access to programs and files and workflow-based composition\nof service programs is naturally based on token/session-like mechanisms. We\npropose a middleware based on client-server protocols and on a set primitives,\nfor managing files/resources and executing programs (in the form of\nclient-side/server-side components/services) in Web Operating Systems. We\nformally define the semantics of such middleware via a process algebraic\napproach."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1005.5241v1", 
    "other_authors": "Jalil Boukhobza, Timsit Claude", 
    "title": "Simulation de traces r\u00e9elles d'E/S disque de PC", 
    "arxiv-id": "1005.5241v1", 
    "author": "Timsit Claude", 
    "publish": "2010-05-28T08:55:12Z", 
    "summary": "Under Windows operating system, existing I/O benchmarking tools does not\nallow a developer to efficiently define a file access strategy according to the\napplications' constraints. This is essentially due to the fact that the\nexisting tools do allow only a restricted set of I/O workloads that does not\ngenerally correspond to the target applications. To cope with this problem, we\ndesigned and implemented a precise I/O simulator allowing to simulate whatever\nreal I/O trace on a given defined architecture, and in which most of file and\ndisk cache strategies, their interactions and the detailed storage system\narchitecture are implemented. Simulation results on different workloads and\narchitectures show a very high degree of precision. In fact, the mean error\nrate as compared to real measures is of about 6% with a maximum of 10% on\nglobal throughput."
},{
    "category": "cs.PF", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1008.1571v1", 
    "other_authors": "Ananth Narayan S, Somsubhra Sharangi, Alexandra Fedorova", 
    "title": "Scaling Turbo Boost to a 1000 cores", 
    "arxiv-id": "1008.1571v1", 
    "author": "Alexandra Fedorova", 
    "publish": "2010-08-09T19:23:10Z", 
    "summary": "The Intel Core i7 processor code named Nehalem provides a feature named Turbo\nBoost which opportunistically varies the frequencies of the processor's cores.\nThe frequency of a core is determined by core temperature, the number of active\ncores, the estimated power consumption, the estimated current consumption, and\noperating system frequency scaling requests. For a chip multi-processor(CMP)\nthat has a small number of physical cores and a small set of performance\nstates, deciding the Turbo Boost frequency to use on a given core might not be\ndifficult. However, we do not know the complexity of this decision making\nprocess in the context of a large number of cores, scaling to the 100s, as\npredicted by researchers in the field."
},{
    "category": "cs.NI", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1012.3071v1", 
    "other_authors": "Ahmad Rahmati, Clay Shepard, Chad Tossell, Angela Nicoara, Lin Zhong, Phil Kortum, Jatinder Singh", 
    "title": "Seamless Flow Migration on Smartphones without Network Support", 
    "arxiv-id": "1012.3071v1", 
    "author": "Jatinder Singh", 
    "publish": "2010-12-14T16:10:08Z", 
    "summary": "This paper addresses the following question: Is it possible to migrate TCP/IP\nflows between different networks on modern mobile devices, without\ninfrastructure support or protocol changes? To answer this question, we make\nthree research contributions. (i) We report a comprehensive characterization of\nIP traffic on smartphones using traces collected from 27 iPhone 3GS users for\nthree months. (ii) Driven by the findings from the characterization, we devise\ntwo novel system mechanisms for mobile devices to sup-port seamless flow\nmigration without network support, and extensively evaluate their effectiveness\nusing our field collected traces of real-life usage. Wait-n-Migrate leverages\nthe fact that most flows are short lived. It establishes new flows on newly\navailable networks but allows pre-existing flows on the old network to\nterminate naturally, effectively decreasing, or even eliminating, connectivity\ngaps during network switches. Resumption Agent takes advantage of the\nfunctionality integrated into many modern protocols to securely resume flows\nwithout application intervention. When combined, Wait-n-Migrate and Resumption\nAgent provide an unprecedented opportunity to immediately deploy performance\nand efficiency-enhancing policies that leverage multiple networks to improve\nthe performance, efficiency, and connectivity of mobile devices. (iii) Finally,\nwe report an iPhone 3GS based implementation of these two system mechanisms and\nshow that their overhead is negligible. Furthermore, we employ an example\nnetwork switching policy, called AutoSwitch, to demonstrate their performance.\nAutoSwitch improves the Wi-Fi user experience by intelligently migrating TCP\nflows between Wi-Fi and cellular networks. Through traces and field\nmeasurements, we show that AutoSwitch reduces the number of user disruptions by\nan order of magnitude."
},{
    "category": "cs.DC", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1106.2766v1", 
    "other_authors": "Lu\u00eds Nogueira, Lu\u00eds Miguel Pinho", 
    "title": "Supporting Parallelism in Server-based Multiprocessor Systems", 
    "arxiv-id": "1106.2766v1", 
    "author": "Lu\u00eds Miguel Pinho", 
    "publish": "2011-06-14T17:26:21Z", 
    "summary": "Developing an efficient server-based real-time scheduling solution that\nsupports dynamic task-level parallelism is now relevant to even the desktop and\nembedded domains and no longer only to the high performance computing market\nniche. This paper proposes a novel approach that combines the constant\nbandwidth server abstraction with a work-stealing load balancing scheme which,\nwhile ensuring isolation among tasks, enables a task to be executed on more\nthan one processor at a given time instant."
},{
    "category": "cs.PL", 
    "doi": "10.1145/2619090", 
    "link": "http://arxiv.org/pdf/1107.2003v2", 
    "other_authors": "Qi Guo, Yunji Chen, Tianshi chen, Ling Li", 
    "title": "Efficient Deterministic Replay Using Complete Race Detection", 
    "arxiv-id": "1107.2003v2", 
    "author": "Ling Li", 
    "publish": "2011-07-11T11:51:06Z", 
    "summary": "Data races can significantly affect the executions of multi-threaded\nprograms. Hence, one has to recur the results of data races to\ndeterministically replay a multi-threaded program. However, data races are\nconcealed in enormous number of memory operations in a program. Due to the\ndifficulty of accurately identifying data races, previous multi-threaded\ndeterministic record/replay schemes for commodity multi-processor system give\nup to record data races directly. Consequently, they either record all shared\nmemory operations, which brings remarkable slowdown to the production run, or\nrecord the synchronization only, which introduces significant efforts to\nreplay.\n  Inspired by the advances in data race detection, we propose an efficient\nsoftware-only deterministic replay scheme for commodity multi-processor\nsystems, which is named RacX. The key insight of RacX is as follows: although\nit is NP-hard to accurately identify the existence of data races between a pair\nof memory operations, we can find out all potential data races in a\nmulti-threaded program, in which the false positives can be reduced to a small\namount with our automatic false positive reduction techniques. As a result,\nRacX can efficiently monitor all potential data races to deterministically\nreplay a multi-threaded program.\n  To evaluate RacX, we have carried out experiments over a number of well-known\nmulti-threaded programs from SPLASH-2 benchmark suite and large-scale\ncommercial programs. RacX can precisely recur production runs of these programs\nwith value determinism. Averagely, RacX causes only about 1.21%, 1.89%, 2.20%,\nand 8.41% slowdown to the original run during recording (for 2-, 4-, 8- and\n16-thread programs, respectively). The soundness, efficiency, scalability, and\nportability of RacX well demonstrate its superiority."
},{
    "category": "cs.OS", 
    "doi": "10.1073/pnas.1115960108", 
    "link": "http://arxiv.org/pdf/1111.5251v1", 
    "other_authors": "Miguel A. Fortuna, Juan A. Bonachela, Simon A. Levin", 
    "title": "Evolution of a Modular Software Network", 
    "arxiv-id": "1111.5251v1", 
    "author": "Simon A. Levin", 
    "publish": "2011-11-22T17:00:50Z", 
    "summary": "\"Evolution behaves like a tinkerer\" (Francois Jacob, Science, 1977). Software\nsystems provide a unique opportunity to understand biological processes using\nconcepts from network theory. The Debian GNU/Linux operating system allows us\nto explore the evolution of a complex network in a novel way. The modular\ndesign detected during its growth is based on the reuse of existing code in\norder to minimize costs during programming. The increase of modularity\nexperienced by the system over time has not counterbalanced the increase in\nincompatibilities between software packages within modules. This negative\neffect is far from being a failure of design. A random process of package\ninstallation shows that the higher the modularity the larger the fraction of\npackages working properly in a local computer. The decrease in the relative\nnumber of conflicts between packages from different modules avoids a failure in\nthe functionality of one package spreading throughout the entire system. Some\npotential analogies with the evolutionary and ecological processes determining\nthe structure of ecological networks of interacting species are discussed."
},{
    "category": "cs.CR", 
    "doi": "10.1073/pnas.1115960108", 
    "link": "http://arxiv.org/pdf/1202.5282v2", 
    "other_authors": "Mohammad Iftekhar Husain, Lokesh Mandvekar, Chunming Qiao, Ramalingam Sridhar", 
    "title": "How to Bypass Verified Boot Security in Chromium OS", 
    "arxiv-id": "1202.5282v2", 
    "author": "Ramalingam Sridhar", 
    "publish": "2012-02-23T20:12:00Z", 
    "summary": "Verified boot is an interesting feature of Chromium OS that supposedly can\ndetect any modification in the root file system (rootfs) by a dedicated\nadversary. However, by exploiting a design flaw in verified boot, we show that\nan adversary can replace the original rootfs by a malicious rootfs containing\nexploits such as a spyware or keylogger and still pass the verified boot\nprocess. The exploit is based on the fact that a dedicated adversary can\nreplace the rootfs and the corresponding verification information in the\nbootloader. We experimentally demonstrate an attack using both the base and\ndeveloper version of Chromium OS in which the adversary installs a spyware in\nthe target system to send cached user data to the attacker machine in plain\ntext which are otherwise encrypted, and thus inaccessible. We also demonstrate\ntechniques to mitigate this vulnerability."
},{
    "category": "cs.AR", 
    "doi": "10.1073/pnas.1115960108", 
    "link": "http://arxiv.org/pdf/1206.6213v1", 
    "other_authors": "Javier Merino, Valentin Puente, Jos\u00e9 \u00c1ngel Gregorio", 
    "title": "The Necessity for Hardware QoS Support for Server Consolidation and   Cloud Computing", 
    "arxiv-id": "1206.6213v1", 
    "author": "Jos\u00e9 \u00c1ngel Gregorio", 
    "publish": "2012-06-27T09:33:06Z", 
    "summary": "Chip multiprocessors (CMPs) are ubiquitous in most of today's computing\nfields. Although they provide noticeable benefits in terms of performance, cost\nand power efficiency, they also introduce some new issues. In this paper we\nanalyze how the interference from Virtual Private Servers running in other\ncores is a significant component of performance unpredictability and can\nthreaten the attainment of cloud computing. Even if virtualization is used, the\nsharing of the on-chip section of the memory hierarchy by different cores makes\nperformance isolation strongly dependent on what is running elsewhere in the\nsystem. We will show in three actual computing systems, based on Sun UltraSparc\nT1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art\nvirtualization techniques are unable to guarantee performance isolation in a\nrepresentative workload such as SPECweb2005. In an especially conceived near\nworst-case scenario, it is possible to reduce the performance achieved by a\nSolaris Zones consolidated server for this suite of benchmarks in a Sun Fire\nT1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by\na Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%. For\nall systems under study, off-chip bandwidth is shown to be the most critical\nresource."
},{
    "category": "cs.OS", 
    "doi": "10.1073/pnas.1115960108", 
    "link": "http://arxiv.org/pdf/1208.6391v1", 
    "other_authors": "Pierre Olivier, Jalil Boukhobza, Eric Senn", 
    "title": "On Benchmarking Embedded Linux Flash File Systems", 
    "arxiv-id": "1208.6391v1", 
    "author": "Eric Senn", 
    "publish": "2012-08-31T06:32:38Z", 
    "summary": "Due to its attractive characteristics in terms of performance, weight and\npower consumption, NAND flash memory became the main non volatile memory (NVM)\nin embedded systems. Those NVMs also present some specific\ncharacteristics/constraints: good but asymmetric I/O performance, limited\nlifetime, write/erase granularity asymmetry, etc. Those peculiarities are\neither managed in hardware for flash disks (SSDs, SD cards, USB sticks, etc.)\nor in software for raw embedded flash chips. When managed in software, flash\nalgorithms and structures are implemented in a specific flash file system\n(FFS). In this paper, we present a performance study of the most widely used\nFFSs in embedded Linux: JFFS2, UBIFS,and YAFFS. We show some very particular\nbehaviors and large performance disparities for tested FFS operations such as\nmounting, copying, and searching file trees, compression, etc."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CCEM.2012.6354601", 
    "link": "http://arxiv.org/pdf/1208.6406v1", 
    "other_authors": "Piyus Kedia, Sorav Bansal, Deepak Deshpande, Sreekanth Iyer", 
    "title": "Building Resilient Cloud Over Unreliable Commodity Infrastructure", 
    "arxiv-id": "1208.6406v1", 
    "author": "Sreekanth Iyer", 
    "publish": "2012-08-31T06:53:14Z", 
    "summary": "Cloud Computing has emerged as a successful computing paradigm for\nefficiently utilizing managed compute infrastructure such as high speed\nrack-mounted servers, connected with high speed networking, and reliable\nstorage. Usually such infrastructure is dedicated, physically secured and has\nreliable power and networking infrastructure. However, much of our idle compute\ncapacity is present in unmanaged infrastructure like idle desktops, lab\nmachines, physically distant server machines, and laptops. We present a scheme\nto utilize this idle compute capacity on a best-effort basis and provide high\navailability even in face of failure of individual components or facilities.\n  We run virtual machines on the commodity infrastructure and present a cloud\ninterface to our end users. The primary challenge is to maintain availability\nin the presence of node failures, network failures, and power failures. We run\nmultiple copies of a Virtual Machine (VM) redundantly on geographically\ndispersed physical machines to achieve availability. If one of the running\ncopies of a VM fails, we seamlessly switchover to another running copy. We use\nVirtual Machine Record/Replay capability to implement this redundancy and\nswitchover. In current progress, we have implemented VM Record/Replay for\nuniprocessor machines over Linux/KVM and are currently working on VM\nRecord/Replay on shared-memory multiprocessor machines. We report initial\nexperimental results based on our implementation."
},{
    "category": "cs.CR", 
    "doi": "10.1109/CCEM.2012.6354601", 
    "link": "http://arxiv.org/pdf/1209.0687v1", 
    "other_authors": "Alessandro Armando, Alessio Merlo, Luca Verderame", 
    "title": "Security Issues in the Android Cross-Layer Architecture", 
    "arxiv-id": "1209.0687v1", 
    "author": "Luca Verderame", 
    "publish": "2012-09-04T16:16:20Z", 
    "summary": "The security of Android has been recently challenged by the discovery of a\nnumber of vulnerabilities involving different layers of the Android stack. We\nargue that such vulnerabilities are largely related to the interplay among\nlayers composing the Android stack. Thus, we also argue that such interplay has\nbeen underestimated from a security point-of-view and a systematic analysis of\nthe Android interplay has not been carried out yet. To this aim, in this paper\nwe provide a simple model of the Android cross-layer interactions based on the\nconcept of flow, as a basis for analyzing the Android interplay. In particular,\nour model allows us to reason about the security implications associated with\nthe cross-layer interactions in Android, including a recently discovered\nvulnerability that allows a malicious application to make Android devices\ntotally unresponsive. We used the proposed model to carry out an empirical\nassessment of some flows within the Android cross-layered architecture. Our\nexperiments indicate that little control is exercised by the Android Security\nFramework (ASF) over cross-layer interactions in Android. In particular, we\nobserved that the ASF lacks in discriminating the originator of a flow and\nsensitive security issues arise between the Android stack and the Linux kernel,\nthereby indicating that the attack surface of the Android platform is wider\nthan expected."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CCEM.2012.6354601", 
    "link": "http://arxiv.org/pdf/1210.1039v1", 
    "other_authors": "Julien Ponge, Fr\u00e9d\u00e9ric Le Mou\u00ebl", 
    "title": "JooFlux: Hijacking Java 7 InvokeDynamic To Support Live Code   Modifications", 
    "arxiv-id": "1210.1039v1", 
    "author": "Fr\u00e9d\u00e9ric Le Mou\u00ebl", 
    "publish": "2012-10-03T09:15:19Z", 
    "summary": "Changing functional and non-functional software implementation at runtime is\nuseful and even sometimes critical both in development and production\nenvironments. JooFlux is a JVM agent that allows both the dynamic replacement\nof method implementations and the application of aspect advices. It works by\ndoing bytecode transformation to take advantage of the new invokedynamic\ninstruction added in Java SE 7 to help implementing dynamic languages for the\nJVM. JooFlux can be managed using a JMX agent so as to operate dynamic\nmodifications at runtime, without resorting to a dedicated domain-specific\nlanguage. We compared JooFlux with existing AOP platforms and dynamic\nlanguages. Results demonstrate that JooFlux performances are close to the Java\nones --- with most of the time a marginal overhead, and sometimes a gain ---\nwhere AOP platforms and dynamic languages present significant overheads. This\npaves the way for interesting future evolutions and applications of JooFlux."
},{
    "category": "cs.SY", 
    "doi": "10.1109/CCEM.2012.6354601", 
    "link": "http://arxiv.org/pdf/1210.2882v1", 
    "other_authors": "Oumair Naseer, Rana Atif Ali Khan", 
    "title": "Online Adaptive Fault Tolerant based Feedback Control Scheduling   Algorithm for Multiprocessor Embedded Systems", 
    "arxiv-id": "1210.2882v1", 
    "author": "Rana Atif Ali Khan", 
    "publish": "2012-10-10T12:13:30Z", 
    "summary": "Since some years ago, use of Feedback Control Scheduling Algorithm (FCSA) in\nthe control scheduling co-design of multiprocessor embedded system has\nincreased. FCSA provides Quality of Service (QoS) in terms of overall system\nperformance and resource allocation in open and unpredictable environment. FCSA\nuses quality control feedback loop to keep CPU utilization under desired\nunitization bound by avoiding overloading and deadline miss ratio. Integrated\nFault tolerance (FT) based FCSA design methodology guarantees that the Safety\nCritical (SC) tasks will meet their deadlines in the presence of faults.\nHowever, current FCSA design model does not provide the optimal solution with\ndynamic load fluctuation. This paper presented a novel methodology of designing\nan online adaptive fault tolerant based feedback control algorithm for\nmultiprocessor embedded systems. This procedure is important for control\nscheduling co-design for multiprocessor embedded systems."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijcsit.2012.4510", 
    "link": "http://arxiv.org/pdf/1211.4839v1", 
    "other_authors": "Mohamed Farag", 
    "title": "An Insight View of Kernel Visual Debugger in System Boot up", 
    "arxiv-id": "1211.4839v1", 
    "author": "Mohamed Farag", 
    "publish": "2012-11-20T19:33:08Z", 
    "summary": "For many years, developers could not figure out the mystery of OS kernels.\nThe main source of this mystery is the interaction between operating systems\nand hardware while system's boot up and kernel initialization. In addition,\nmany operating system kernels differ in their behavior toward many situations.\nFor instance, kernels act differently in racing conditions, kernel\ninitialization and process scheduling. For such operations, kernel debuggers\nwere designed to help in tracing kernel behavior and solving many kernel bugs.\nThe importance of kernel debuggers is not limited to kernel code tracing but\nalso, they can be used in verification and performance comparisons. However,\ndevelopers had to be aware of debugger commands thus introducing some\ndifficulties to non-expert programmers. Later, several visual kernel debuggers\nwere presented to make it easier for programmers to trace their kernel code and\nanalyze kernel behavior. Nowadays, several kernel debuggers exist for solving\nthis mystery but only very few support line-by-line debugging at run-time. In\nthis paper, a generic approach for operating system source code debugging in\ngraphical mode with line-by-line tracing support is proposed. In the context of\nthis approach, system boot up and evaluation of two operating system schedulers\nfrom several points of views will be discussed."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.102.3", 
    "link": "http://arxiv.org/pdf/1211.6185v1", 
    "other_authors": "Sidney Amani, Peter Chubb, Alastair F. Donaldson, Alexander Legg, Leonid Ryzhyk, Yanjin Zhu", 
    "title": "Automatic Verification of Message-Based Device Drivers", 
    "arxiv-id": "1211.6185v1", 
    "author": "Yanjin Zhu", 
    "publish": "2012-11-27T02:36:10Z", 
    "summary": "We develop a practical solution to the problem of automatic verification of\nthe interface between device drivers and the OS. Our solution relies on a\ncombination of improved driver architecture and verification tools. It supports\ndrivers written in C and can be implemented in any existing OS, which sets it\napart from previous proposals for verification-friendly drivers. Our\nLinux-based evaluation shows that this methodology amplifies the power of\nexisting verification tools in detecting driver bugs, making it possible to\nverify properties beyond the reach of traditional techniques."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.102.14", 
    "link": "http://arxiv.org/pdf/1211.6196v1", 
    "other_authors": "Christel Baier, Marcus Daum, Benjamin Engel, Hermann H\u00e4rtig, Joachim Klein, Sascha Kl\u00fcppelholz, Steffen M\u00e4rcker, Hendrik Tews, Marcus V\u00f6lp", 
    "title": "Chiefly Symmetric: Results on the Scalability of Probabilistic Model   Checking for Operating-System Code", 
    "arxiv-id": "1211.6196v1", 
    "author": "Marcus V\u00f6lp", 
    "publish": "2012-11-27T02:37:28Z", 
    "summary": "Reliability in terms of functional properties from the safety-liveness\nspectrum is an indispensable requirement of low-level operating-system (OS)\ncode. However, with evermore complex and thus less predictable hardware,\nquantitative and probabilistic guarantees become more and more important.\nProbabilistic model checking is one technique to automatically obtain these\nguarantees. First experiences with the automated quantitative analysis of\nlow-level operating-system code confirm the expectation that the naive\nprobabilistic model checking approach rapidly reaches its limits when\nincreasing the numbers of processes. This paper reports on our work-in-progress\nto tackle the state explosion problem for low-level OS-code caused by the\nexponential blow-up of the model size when the number of processes grows. We\nstudied the symmetry reduction approach and carried out our experiments with a\nsimple test-and-test-and-set lock case study as a representative example for a\nwide range of protocols with natural inter-process dependencies and long-run\nproperties. We quickly see a state-space explosion for scenarios where\ninter-process dependencies are insignificant. However, once inter-process\ndependencies dominate the picture models with hundred and more processes can be\nconstructed and analysed."
},{
    "category": "cs.DS", 
    "doi": "10.4204/EPTCS.102.14", 
    "link": "http://arxiv.org/pdf/1212.2778v1", 
    "other_authors": "Vincenzo Bonifaci, Alberto Marchetti-Spaccamela, Sebastian Stiller, Andreas Wiese", 
    "title": "Feasibility Tests for Recurrent Real-Time Tasks in the Sporadic DAG   Model", 
    "arxiv-id": "1212.2778v1", 
    "author": "Andreas Wiese", 
    "publish": "2012-12-12T11:37:48Z", 
    "summary": "A model has been proposed in [Baruah et al., in Proceedings of the IEEE\nReal-Time Systems Symposium 2012] for representing recurrent\nprecedence-constrained tasks to be executed on multiprocessor platforms, where\neach recurrent task is modeled by a directed acyclic graph (DAG), a period, and\na relative deadline. Each vertex of the DAG represents a sequential job, while\nthe edges of the DAG represent precedence constraints between these jobs. All\nthe jobs of the DAG are released simultaneously and have to be completed within\nsome specified relative deadline. The task may release jobs in this manner an\nunbounded number of times, with successive releases occurring at least the\nspecified period apart. The feasibility problem is to determine whether such a\nrecurrent task can be scheduled to always meet all deadlines on a specified\nnumber of dedicated processors.\n  The case of a single task has been considered in [Baruah et al., 2012]. The\nmain contribution of this paper is to consider the case of multiple tasks. We\nshow that EDF has a speedup bound of 2-1/m, where m is the number of\nprocessors. Moreover, we present polynomial and pseudopolynomial schedulability\ntests, of differing effectiveness, for determining whether a set of sporadic\nDAG tasks can be scheduled by EDF to meet all deadlines on a specified number\nof processors."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.102.14", 
    "link": "http://arxiv.org/pdf/1212.6354v1", 
    "other_authors": "Sajjad Haider, Mehboob Yasin, Naveed Hussain, Muhammad Imran", 
    "title": "LNOS - Live Network Operating System", 
    "arxiv-id": "1212.6354v1", 
    "author": "Muhammad Imran", 
    "publish": "2012-12-27T11:55:43Z", 
    "summary": "Operating Systems exists since existence of computers, and have been evolving\ncontinuously from time to time. In this paper we have reviewed a relatively new\nor unexplored topic of Live OS. From networking perspective, Live OS is used\nfor establishing Clusters, Firewalls and as Network security assessment tool\netc. Our proposed concept is that a Live OS can be established or configured\nfor an organizations specific network requirements with respect to their\nservers. An important server failure due to hardware or software could take\ntime for remedy of the problem, so for that situation a preconfigured server in\nthe form of Live OS on CD/DVD/USB can be used as an immediate solution. In a\nnetwork of ten nodes, we stopped the server machine and with necessary\nadjustments, Live OS replaced the server in less than five minutes. Live OS in\na network environment is a quick replacement of the services that are failed\ndue to server failure (hardware or software). It is a cost effective solution\nfor low budget networks. The life of Live OS starts when we boot it from\nCD/DVD/USB and remains in action for that session. As soon as the machine is\nrebooted, any work done for that session is gone, (in case we do not store any\ninformation on permanent storage media). Live CD/DVD/USB is normally used on\nsystems where we do not have Operating Systems installed. A Live OS can also be\nused on systems where we already have an installed OS. On the basis of\nfunctionality a Live OS can be used for many purposes and has some typical\nadvantages that are not available on other operating systems. Vendors are\nreleasing different distributions of Live OS and is becoming their sole\nidentity in a particular domain like Networks, Security, Education or\nEntertainment etc. There can be many aspects of Live OS, but Linux based Live\nOS and their use in the field of networks is the main focus of this paper."
},{
    "category": "cs.OS", 
    "doi": "10.5120/10145-4978", 
    "link": "http://arxiv.org/pdf/1301.4800v1", 
    "other_authors": "Omar Kermia", 
    "title": "Schedulability Analysis of Distributed Real-Time Applications under   Dependence and Several Latency Constraints", 
    "arxiv-id": "1301.4800v1", 
    "author": "Omar Kermia", 
    "publish": "2013-01-21T10:00:22Z", 
    "summary": "This paper focuses on the analysis of real-time non preemptive multiprocessor\nscheduling with precedence and several latency constraints. It aims to specify\na schedulability condition which enables a designer to check a priori -without\nexecuting or simulating- if its scheduling of tasks will hold the precedences\nbetween tasks as well as several latency constraints imposed on determined\npairs of tasks. It is shown that the required analysis is closely linked to the\ntopological structure of the application graph. More precisely, it depends on\nthe configuration of tasks paths subject to latency constraints. As a result of\nthe study, a sufficient schedulability condition is introduced for precedences\nand latency constraints in the hardest configuration in term of complexity with\nan optimal number of processors in term of applications parallelism. In\naddition, the proposed conditions provides a practical lower bounds for general\ncases. Performances results and comparisons with an optimal approach\ndemonstrate the effectiveness of the proposed approach."
},{
    "category": "cs.OS", 
    "doi": "10.5120/10145-4978", 
    "link": "http://arxiv.org/pdf/1305.2553v1", 
    "other_authors": "Jun Wang, Xi Xiong, Peng Liu", 
    "title": "Practical Fine-grained Privilege Separation in Multithreaded   Applications", 
    "arxiv-id": "1305.2553v1", 
    "author": "Peng Liu", 
    "publish": "2013-05-12T02:44:15Z", 
    "summary": "An inherent security limitation with the classic multithreaded programming\nmodel is that all the threads share the same address space and, therefore, are\nimplicitly assumed to be mutually trusted. This assumption, however, does not\ntake into consideration of many modern multithreaded applications that involve\nmultiple principals which do not fully trust each other. It remains challenging\nto retrofit the classic multithreaded programming model so that the security\nand privilege separation in multi-principal applications can be resolved.\n  This paper proposes ARBITER, a run-time system and a set of security\nprimitives, aimed at fine-grained and data-centric privilege separation in\nmultithreaded applications. While enforcing effective isolation among\nprincipals, ARBITER still allows flexible sharing and communication between\nthreads so that the multithreaded programming paradigm can be preserved. To\nrealize controlled sharing in a fine-grained manner, we created a novel\nabstraction named ARBITER Secure Memory Segment (ASMS) and corresponding OS\nsupport. Programmers express security policies by labeling data and principals\nvia ARBITER's API following a unified model. We ported a widely-used, in-memory\ndatabase application (memcached) to ARBITER system, changing only around 100\nLOC. Experiments indicate that only an average runtime overhead of 5.6% is\ninduced to this security enhanced version of application."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CCGrid.2013.14", 
    "link": "http://arxiv.org/pdf/1306.0846v1", 
    "other_authors": "Gary A. McGilvary, Adam Barker, Ashley Lloyd, Malcolm Atkinson", 
    "title": "V-BOINC: The Virtualization of BOINC", 
    "arxiv-id": "1306.0846v1", 
    "author": "Malcolm Atkinson", 
    "publish": "2013-06-04T16:27:30Z", 
    "summary": "The Berkeley Open Infrastructure for Network Computing (BOINC) is an open\nsource client-server middleware system created to allow projects with large\ncomputational requirements, usually set in the scientific domain, to utilize a\ntechnically unlimited number of volunteer machines distributed over large\nphysical distances. However various problems exist deploying applications over\nthese heterogeneous machines using BOINC: applications must be ported to each\nmachine architecture type, the project server must be trusted to supply\nauthentic applications, applications that do not regularly checkpoint may lose\nexecution progress upon volunteer machine termination and applications that\nhave dependencies may find it difficult to run under BOINC.\n  To solve such problems we introduce virtual BOINC, or V-BOINC, where virtual\nmachines are used to run computations on volunteer machines. Application\ndevelopers can then compile their applications on a single architecture,\ncheckpointing issues are solved through virtualization API's and many security\nconcerns are addressed via the virtual machine's sandbox environment. In this\npaper we focus on outlining a unique approach on how virtualization can be\nintroduced into BOINC and demonstrate that V-BOINC offers acceptable\ncomputational performance when compared to regular BOINC. Finally we show that\napplications with dependencies can easily run under V-BOINC in turn increasing\nthe computational potential volunteer computing offers to the general public\nand project developers."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CCGrid.2013.14", 
    "link": "http://arxiv.org/pdf/1309.1714v1", 
    "other_authors": "Pierre Olivier, Jalil Boukhobza, Eric Senn", 
    "title": "Flashmon V2: Monitoring Raw NAND Flash Memory I/O Requests on Embedded   Linux", 
    "arxiv-id": "1309.1714v1", 
    "author": "Eric Senn", 
    "publish": "2013-09-06T18:14:04Z", 
    "summary": "This paper presents Flashmon version 2, a tool for monitoring embedded Linux\nNAND flash memory I/O requests. It is designed for embedded boards based\ndevices containing raw flash chips. Flashmon is a kernel module and stands for\n\"flash monitor\". It traces flash I/O by placing kernel probes at the NAND\ndriver level. It allows tracing at runtime the 3 main flash operations: page\nreads / writes and block erasures. Flashmon is (1) generic as it was\nsuccessfully tested on the three most widely used flash file systems that are\nJFFS2, UBIFS and YAFFS, and several NAND chip models. Moreover, it is (2) non\nintrusive, (3) has a controllable memory footprint, and (4) exhibits a low\noverhead (<6%) on the traced system. Finally, it is (5) simple to integrate and\nused as a standalone module or as a built-in function / module in existing\nkernel sources. Monitoring flash memory operations allows a better\nunderstanding of existing flash management systems by studying and analyzing\ntheir behavior. Moreover it is useful in development phase for prototyping and\nvalidating new solutions."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CCGrid.2013.14", 
    "link": "http://arxiv.org/pdf/1310.1588v1", 
    "other_authors": "Sasa Paporovic", 
    "title": "Impacting the bioscience progress by backporting software for Bio-Linux", 
    "arxiv-id": "1310.1588v1", 
    "author": "Sasa Paporovic", 
    "publish": "2013-10-06T14:27:59Z", 
    "summary": "In year 2006 Bio-Linux with the work of Tim Booth and team gives its rising\nand provide an operating system that was and still specialized in providing a\nbioinformatic specific software environment for the working needs in this\ncorner of bioscience. It is shown that Bio-Linux is affected by a 2 year\nrelease cycle and with this the final releases of Bio-Linux will not have the\nlatest bioinformatic software on board. The paper shows how to get around this\nhuge time gap and bring new software for Bio-Linux on board through a process\nthat is called backporting. A summary of within the work to this paper just\nbackported bioinformatic tools is given. A describtion of a workflow for\ncontinuously integration of the newest bioinformatic tools gives an outlook to\nfurther concrete planned developments and the influence of speeding up\nscientific progress."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1310.2148v1", 
    "other_authors": "Gary A. McGilvary, Josep Rius, \u00cd\u00f1igo Goiri, Francesc Solsona, Adam Barker, Malcolm Atkinson", 
    "title": "C2MS: Dynamic Monitoring and Management of Cloud Infrastructures", 
    "arxiv-id": "1310.2148v1", 
    "author": "Malcolm Atkinson", 
    "publish": "2013-10-03T22:49:06Z", 
    "summary": "Server clustering is a common design principle employed by many organisations\nwho require high availability, scalability and easier management of their\ninfrastructure. Servers are typically clustered according to the service they\nprovide whether it be the application(s) installed, the role of the server or\nserver accessibility for example. In order to optimize performance, manage load\nand maintain availability, servers may migrate from one cluster group to\nanother making it difficult for server monitoring tools to continuously monitor\nthese dynamically changing groups. Server monitoring tools are usually\nstatically configured and with any change of group membership requires manual\nreconfiguration; an unreasonable task to undertake on large-scale cloud\ninfrastructures.\n  In this paper we present the Cloudlet Control and Management System (C2MS); a\nsystem for monitoring and controlling dynamic groups of physical or virtual\nservers within cloud infrastructures. The C2MS extends Ganglia - an open source\nscalable system performance monitoring tool - by allowing system administrators\nto define, monitor and modify server groups without the need for server\nreconfiguration. In turn administrators can easily monitor group and individual\nserver metrics on large-scale dynamic cloud infrastructures where roles of\nservers may change frequently. Furthermore, we complement group monitoring with\na control element allowing administrator-specified actions to be performed over\nservers within service groups as well as introduce further customized\nmonitoring metrics. This paper outlines the design, implementation and\nevaluation of the C2MS."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1311.3322v1", 
    "other_authors": "Thanh Do, Haryadi S. Gunawi", 
    "title": "Impact of Limpware on HDFS: A Probabilistic Estimation", 
    "arxiv-id": "1311.3322v1", 
    "author": "Haryadi S. Gunawi", 
    "publish": "2013-11-13T22:05:58Z", 
    "summary": "With the advent of cloud computing, thousands of machines are connected and\nmanaged collectively. This era is confronted with a new challenge: performance\nvariability, primarily caused by large-scale management issues such as hardware\nfailures, software bugs, and configuration mistakes. In our previous work we\nhighlighted one overlooked cause: limpware - hardware whose performance\ndegrades significantly compared to its specification. We showed that limpware\ncan cause severe impact in current scale-out systems. In this report, we\nquantify how often these scenarios happen in Hadoop Distributed File System."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1312.3665v2", 
    "other_authors": "David Isaac Wolinsky, Bryan Ford", 
    "title": "Managing NymBoxes for Identity and Tracking Protection", 
    "arxiv-id": "1312.3665v2", 
    "author": "Bryan Ford", 
    "publish": "2013-12-12T22:38:08Z", 
    "summary": "Despite the attempts of well-designed anonymous communication tools to\nprotect users from tracking or identification, flaws in surrounding software\n(such as web browsers) and mistakes in configuration may leak the user's\nidentity. We introduce Nymix, an anonymity-centric operating system\narchitecture designed \"top-to-bottom\" to strengthen identity- and\ntracking-protection. Nymix's core contribution is OS support for nym-browsing:\nindependent, parallel, and ephemeral web sessions. Each web session, or\npseudonym, runs in a unique virtual machine (VM) instance evolving from a\ncommon base state with support for long-lived sessions which can be anonymously\nstored to the cloud, avoiding de-anonymization despite potential confiscation\nor theft. Nymix allows a user to safely browse the Web using various different\ntransports simultaneously through a pluggable communication model that supports\nTor, Dissent, and a private browsing mode. In evaluations, Nymix consumes 600\nMB per nymbox and loads within 15 to 25 seconds."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1312.3938v3", 
    "other_authors": "Jiajun Cao, Gregory Kerr, Kapil Arya, Gene Cooperman", 
    "title": "Transparent Checkpoint-Restart over InfiniBand", 
    "arxiv-id": "1312.3938v3", 
    "author": "Gene Cooperman", 
    "publish": "2013-12-13T20:53:39Z", 
    "summary": "InfiniBand is widely used for low-latency, high-throughput cluster computing.\nSaving the state of the InfiniBand network as part of distributed checkpointing\nhas been a long-standing challenge for researchers. Because of a lack of a\nsolution, typical MPI implementations have included custom checkpoint-restart\nservices that \"tear down\" the network, checkpoint each node as if the node were\na standalone computer, and then re-connect the network again. We present the\nfirst example of transparent, system-initiated checkpoint-restart that directly\nsupports InfiniBand. The new approach is independent of any particular Linux\nkernel, thus simplifying the current practice of using a kernel-based module,\nsuch as BLCR. This direct approach results in checkpoints that are found to be\nfaster than with the use of a checkpoint-restart service. The generality of\nthis approach is shown not only by checkpointing an MPI computation, but also a\nnative UPC computation (Berkeley Unified Parallel C), which does not use MPI.\nScalability is shown by checkpointing 2,048 MPI processes across 128 nodes\n(with 16 cores per node). In addition, a cost-effective debugging approach is\nalso enabled, in which a checkpoint image from an InfiniBand-based production\ncluster is copied to a local Ethernet-based cluster, where it can be restarted\nand an interactive debugger can be attached to it. This work is based on a\nplugin that extends the DMTCP (Distributed MultiThreaded CheckPointing)\ncheckpoint-restart package."
},{
    "category": "cs.CR", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1401.6726v1", 
    "other_authors": "Earlence Fernandes, Alexander Crowell, Ajit Aluri, Atul Prakash", 
    "title": "Anception: Application Virtualization For Android", 
    "arxiv-id": "1401.6726v1", 
    "author": "Atul Prakash", 
    "publish": "2014-01-27T03:01:33Z", 
    "summary": "The problem of malware has become significant on Android devices. Library\noperating systems and application virtualization are both possible solutions\nfor confining malware. Unfortunately, such solutions do not exist for Android.\nDesigning mechanisms for application virtualization is a significant chal-\nlenge for several reasons: (1) graphics performance is important due to\npopularity of games and (2) applications with the same UID can share state.\nThis paper presents Anception, the first flexible application virtualization\nframework for Android. It is imple- mented as a modification to the Android\nkernel and supports application virtualization that addresses the above\nrequirements. Anception is able to confine many types of malware while\nsupporting unmodified Android applications. Our Anception- based system\nexhibits up to 3.9% overhead on various 2D/3D benchmarks, and 1.8% overhead on\nthe SunSpider benchmark."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1405.2913v1", 
    "other_authors": "Bj\u00f6rn D\u00f6bel, Robert Muschner, Hermann H\u00e4rtig", 
    "title": "Resource-Aware Replication on Heterogeneous Multicores: Challenges and   Opportunities", 
    "arxiv-id": "1405.2913v1", 
    "author": "Hermann H\u00e4rtig", 
    "publish": "2014-05-12T16:41:49Z", 
    "summary": "Decreasing hardware feature sizes and increasing heterogeneity in multicore\nhardware require software that can adapt to these platforms' properties. We\nimplemented ROMAIN, an OS service providing redundant multithreading on top of\nthe FIASCO.OC microkernel to address the increasing unreliability of hardware.\nIn this paper we review challenges and opportunities for ROMAIN to adapt to\nsuch multicore platforms in order to decrease execution overhead, resource\nrequirements, and vulnerability against faults."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1405.5651v1", 
    "other_authors": "Francesco Gadaleta, Nick Nikiforakis, Yves Younan, Wouter Joosen", 
    "title": "Hello rootKitty: A lightweight invariance-enforcing framework", 
    "arxiv-id": "1405.5651v1", 
    "author": "Wouter Joosen", 
    "publish": "2014-05-22T07:52:45Z", 
    "summary": "In monolithic operating systems, the kernel is the piece of code that\nexecutes with the highest privileges and has control over all the software\nrunning on a host. A successful attack against an operating system's kernel\nmeans a total and complete compromise of the running system. These attacks\nusually end with the installation of a rootkit, a stealthy piece of software\nrunning with kernel privileges. When a rootkit is present, no guarantees can be\nmade about the correctness, privacy or isolation of the operating system.\n  In this paper we present \\emph{Hello rootKitty}, an invariance-enforcing\nframework which takes advantage of current virtualization technology to protect\na guest operating system against rootkits. \\emph{Hello rootKitty} uses the idea\nof invariance to detect maliciously modified kernel data structures and restore\nthem to their original legitimate values. Our prototype has negligible\nperformance and memory overhead while effectively protecting commodity\noperating systems from modern rootkits."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1406.1133v1", 
    "other_authors": "Jos\u00e9 Marinho, Stefan M. Petters", 
    "title": "Timing Analysis for DAG-based and GFP Scheduled Tasks", 
    "arxiv-id": "1406.1133v1", 
    "author": "Stefan M. Petters", 
    "publish": "2014-06-04T18:18:37Z", 
    "summary": "Modern embedded systems have made the transition from single-core to\nmulti-core architectures, providing performance improvement via parallelism\nrather than higher clock frequencies. DAGs are considered among the most\ngeneric task models in the real-time domain and are well suited to exploit this\nparallelism. In this paper we provide a schedulability test using response-time\nanalysis exploiting exploring and bounding the self interference of a DAG task.\nAdditionally we bound the interference a high priority task has on lower\npriority ones."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1406.6037v1", 
    "other_authors": "Sreepathi Pai, R. Govindarajan, Matthew J. Thazhuthaveetil", 
    "title": "Preemptive Thread Block Scheduling with Online Structural Runtime   Prediction for Concurrent GPGPU Kernels", 
    "arxiv-id": "1406.6037v1", 
    "author": "Matthew J. Thazhuthaveetil", 
    "publish": "2014-06-23T19:44:03Z", 
    "summary": "Recent NVIDIA Graphics Processing Units (GPUs) can execute multiple kernels\nconcurrently. On these GPUs, the thread block scheduler (TBS) uses the FIFO\npolicy to schedule their thread blocks. We show that FIFO leaves performance to\nchance, resulting in significant loss of performance and fairness. To improve\nperformance and fairness, we propose use of the preemptive Shortest Remaining\nTime First (SRTF) policy instead. Although SRTF requires an estimate of runtime\nof GPU kernels, we show that such an estimate of the runtime can be easily\nobtained using online profiling and exploiting a simple observation on GPU\nkernels' grid structure. Specifically, we propose a novel Structural Runtime\nPredictor. Using a simple Staircase model of GPU kernel execution, we show that\nthe runtime of a kernel can be predicted by profiling only the first few thread\nblocks. We evaluate an online predictor based on this model on benchmarks from\nERCBench, and find that it can estimate the actual runtime reasonably well\nafter the execution of only a single thread block. Next, we design a thread\nblock scheduler that is both concurrent kernel-aware and uses this predictor.\nWe implement the SRTF policy and evaluate it on two-program workloads from\nERCBench. SRTF improves STP by 1.18x and ANTT by 2.25x over FIFO. When compared\nto MPMax, a state-of-the-art resource allocation policy for concurrent kernels,\nSRTF improves STP by 1.16x and ANTT by 1.3x. To improve fairness, we also\npropose SRTF/Adaptive which controls resource usage of concurrently executing\nkernels to maximize fairness. SRTF/Adaptive improves STP by 1.12x, ANTT by\n2.23x and Fairness by 2.95x compared to FIFO. Overall, our implementation of\nSRTF achieves system throughput to within 12.64% of Shortest Job First (SJF, an\noracle optimal scheduling policy), bridging 49% of the gap between FIFO and\nSJF."
},{
    "category": "cs.CR", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1410.7747v1", 
    "other_authors": "Xinyang Ge, Hayawardh Vijayakumar, Trent Jaeger", 
    "title": "Sprobes: Enforcing Kernel Code Integrity on the TrustZone Architecture", 
    "arxiv-id": "1410.7747v1", 
    "author": "Trent Jaeger", 
    "publish": "2014-10-28T19:20:34Z", 
    "summary": "Many smartphones now deploy conventional operating systems, so the rootkit\nattacks so prevalent on desktop and server systems are now a threat to\nsmartphones. While researchers have advocated using virtualization to detect\nand prevent attacks on operating systems (e.g., VM introspection and trusted\nvirtual domains), virtualization is not practical on smartphone systems due to\nthe lack of virtualization support and/or the expense of virtualization.\nCurrent smartphone processors do have hardware support for running a protected\nenvironment, such as the ARM TrustZone extensions, but such hardware does not\ncontrol the operating system operations sufficiently to enable VM\nintrospection. In particular, a conventional operating system running with\nTrustZone still retains full control of memory management, which a rootkit can\nuse to prevent traps on sensitive instructions or memory accesses necessary for\neffective introspection. In this paper, we present SPROBES, a novel primitive\nthat enables introspection of operating systems running on ARM TrustZone\nhardware. Using SPROBES, an introspection mechanism protected by TrustZone can\ninstrument individual operating system instructions of its choice, receiving an\nunforgeable trap whenever any SPROBE is executed. The key challenge in\ndesigning SPROBES is preventing the rootkit from removing them, but we identify\na set of five invariants whose enforcement is sufficient to restrict rootkits\nto execute only approved, SPROBE-injected kernel code. We implemented a\nproof-of-concept version of SPROBES for the ARM Fast Models emulator,\ndemonstrating that in Linux kernel 2.6.38, only 12 SPROBES are sufficient to\nenforce all five of these invariants. With SPROBES we show that it is possible\nto leverage the limited TrustZone extensions to limit conventional kernel\nexecution to approved code comprehensively."
},{
    "category": "cs.CR", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1410.7754v1", 
    "other_authors": "Daniel Defreez, Bhargava Shastry, Hao Chen, Jean-Pierre Seifert", 
    "title": "A First Look at Firefox OS Security", 
    "arxiv-id": "1410.7754v1", 
    "author": "Jean-Pierre Seifert", 
    "publish": "2014-10-28T19:23:26Z", 
    "summary": "With Firefox OS, Mozilla is making a serious push for an HTML5-based mobile\nplatform. In order to assuage security concerns over providing hardware access\nto web applications, Mozilla has introduced a number of mechanisms that make\nthe security landscape of Firefox OS distinct from both the desktop web and\nother mobile operating systems. From an application security perspective, the\ntwo most significant of these mechanisms are the the introduction of a default\nContent Security Policy and code review in the market. This paper describes how\nlightweight static analysis can augment these mechanisms to find\nvulnerabilities which have otherwise been missed. We provide examples of\nprivileged applications in the market that contain vulnerabilities that can be\nautomatically detected.\n  In addition to these findings, we show some of the challenges that occur when\ndesktop software is repurposed for a mobile operating system. In particular, we\nargue that the caching of certificate overrides across applications--a known\nproblem in Firefox OS--generates a counter-intuitive user experience that\ndetracts from the security of the system."
},{
    "category": "cs.DB", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1504.01666v1", 
    "other_authors": "Niv Dayan, Philippe Bonnet", 
    "title": "Garbage Collection Techniques for Flash-Resident Page-Mapping FTLs", 
    "arxiv-id": "1504.01666v1", 
    "author": "Philippe Bonnet", 
    "publish": "2015-04-07T16:58:31Z", 
    "summary": "Storage devices based on flash memory have replaced hard disk drives (HDDs)\ndue to their superior performance, increasing density, and lower power\nconsumption. Unfortunately, flash memory is subject to challenging\nidiosyncrasies like erase-before-write and limited block lifetime. These\nconstraints are handled by a flash translation layer (FTL), which performs\nout-of-place updates, wear-leveling and garbage-collection behind the scene,\nwhile offering the application a virtualization of the physical address space.\n  A class of relevant FTLs employ a flash-resident page-associative mapping\ntable from logical to physical addresses, with a smaller RAM-resident cache for\nfrequently mapped entries. In this paper, we address the problem of performing\ngarbage-collection under such FTLs. We observe two problems. Firstly,\nmaintaining the metadata needed to perform garbage-collection under these\nschemes is problematic, because at write-time we do not necessarily know the\nphysical address of the before-image. Secondly, the size of this metadata must\nremain small, because it makes RAM unavailable for caching frequently accessed\nentries. We propose two complementary techniques, called Lazy Gecko and\nLogarithmic Gecko, which address these issues. Lazy Gecko works well when RAM\nis plentiful enough to store the GC metadata. Logarithmic Gecko works well when\nRAM isn't plentiful and efficiently stores the GC metadata in flash. Thus,\nthese techniques are applicable to a wide range of flash devices with varying\namounts of embedded RAM."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1504.06833v1", 
    "other_authors": "Joel Reed, Jeremy Archuleta, Michael J. Brim, Joshua Lothian", 
    "title": "Evaluating Dynamic File Striping For Lustre", 
    "arxiv-id": "1504.06833v1", 
    "author": "Joshua Lothian", 
    "publish": "2015-04-26T14:44:00Z", 
    "summary": "We define dynamic striping as the ability to assign different Lustre striping\ncharacteristics to contiguous segments of a file as it grows. In this paper, we\nevaluate the effects of dynamic striping using a watermark-based strategy where\nthe stripe count or width is increased once a file's size exceeds one of the\nchosen watermarks. To measure the performance of this strategy we used a\nmodified version of the IOR benchmark, a netflow analysis workload, and the\nblastn algorithm from NCBI BLAST. The results indicate that dynamic striping is\nbeneficial to tasks with unpredictable data file size and large sequential\nreads, but are less conclusive for workloads with significant random read\nphases."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1504.06836v1", 
    "other_authors": "Michael J. Brim, Joshua K. Lothian", 
    "title": "Monitoring Extreme-scale Lustre Toolkit", 
    "arxiv-id": "1504.06836v1", 
    "author": "Joshua K. Lothian", 
    "publish": "2015-04-26T14:57:05Z", 
    "summary": "We discuss the design and ongoing development of the Monitoring Extreme-scale\nLustre Toolkit (MELT), a unified Lustre performance monitoring and analysis\ninfrastructure that provides continuous, low-overhead summary information on\nthe health and performance of Lustre, as well as on-demand, in- depth problem\ndiagnosis and root-cause analysis. The MELT infrastructure leverages a\ndistributed overlay network to enable monitoring of center-wide Lustre\nfilesystems where clients are located across many network domains. We preview\ninteractive command-line utilities that help administrators and users to\nobserve Lustre performance at various levels of resolution, from individual\nservers or clients to whole filesystems, including job-level reporting.\nFinally, we discuss our future plans for automating the root-cause analysis of\ncommon Lustre performance problems."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1504.07481v1", 
    "other_authors": "Blake Caldwell", 
    "title": "Improving Block-level Efficiency with scsi-mq", 
    "arxiv-id": "1504.07481v1", 
    "author": "Blake Caldwell", 
    "publish": "2015-04-28T14:05:59Z", 
    "summary": "Current generation solid-state storage devices are exposing a new bottlenecks\nin the SCSI and block layers of the Linux kernel, where IO throughput is\nlimited by lock contention, inefficient interrupt handling, and poor memory\nlocality. To address these limitations, the Linux kernel block layer underwent\na major rewrite with the blk-mq project to move from a single request queue to\na multi-queue model. The Linux SCSI subsystem rework to make use of this new\nmodel, known as scsi-mq, has been merged into the Linux kernel and work is\nunderway for dm-multipath support in the upcoming Linux 4.0 kernel. These\npieces were necessary to make use of the multi-queue block layer in a Lustre\nparallel filesystem with high availability requirements. We undertook adding\nsupport of the 3.18 kernel to Lustre with scsi-mq and dm-multipath patches to\nevaluate the potential of these efficiency improvements. In this paper we\nevaluate the block-level performance of scsi-mq with backing storage hardware\nrepresentative of a HPC-targerted Lustre filesystem. Our findings show that\nSCSI write request latency is reduced by as much as 13.6%. Additionally, when\nprofiling the CPU usage of our prototype Lustre filesystem, we found that CPU\nidle time increased by a factor of 7 with Linux 3.18 and blk-mq as compared to\na standard 2.6.32 Linux kernel. Our findings demonstrate increased efficiency\nof the multi-queue block layer even with disk-based caching storage arrays used\nin existing parallel filesystems."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1505.01448v1", 
    "other_authors": "Thomas Leibovici", 
    "title": "Taking back control of HPC file systems with Robinhood Policy Engine", 
    "arxiv-id": "1505.01448v1", 
    "author": "Thomas Leibovici", 
    "publish": "2015-05-06T18:14:56Z", 
    "summary": "Today, the largest Lustre file systems store billions of entries. On such\nsystems, classic tools based on namespace scanning become unusable. Operations\nsuch as managing file lifetime, scheduling data copies, and generating overall\nfilesystem statistics become painful as they require collecting, sorting and\naggregating information for billions of records. Robinhood Policy Engine is an\nopen source software developed to address these challenges. It makes it\npossible to schedule automatic actions on huge numbers of filesystem entries.\nIt also gives a synthetic understanding of file systems contents by providing\noverall statistics about data ownership, age and size profiles. Even if it can\nbe used with any POSIX filesystem, Robinhood supports Lustre specific features\nlike OSTs, pools, HSM, ChangeLogs, and DNE. It implements specific support for\nthese features, and takes advantage of them to manage Lustre file systems\nefficiently."
},{
    "category": "cs.DC", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1505.01765v1", 
    "other_authors": "Teng Wang, Sarp Oral, Michael Pritchard, Kevin Vasko, Weikuan Yu", 
    "title": "Development of a Burst Buffer System for Data-Intensive Applications", 
    "arxiv-id": "1505.01765v1", 
    "author": "Weikuan Yu", 
    "publish": "2015-05-07T16:31:21Z", 
    "summary": "Modern parallel filesystems such as Lustre are designed to provide high,\nscalable I/O bandwidth in response to growing I/O requirements; however, the\nbursty I/O characteristics of many data-intensive scientific applications make\nit difficult for back-end parallel filesystems to efficiently handle I/O\nrequests. A burst buffer system, through which data can be temporarily buffered\nvia high-performance storage mediums, allows for gradual flushing of data to\nback-end filesystems. In this paper, we explore issues surrounding the\ndevelopment of a burst buffer system for data-intensive scientific\napplications. Our initial results demonstrate that utilizing a burst buffer\nsystem on top of the Lustre filesystem shows promise for dealing with the\nintense I/O traffic generated by application checkpointing."
},{
    "category": "cs.DS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1505.02155v3", 
    "other_authors": "Jian-Jia Chen, Wen-Hung Huang, Cong Liu", 
    "title": "Evaluate and Compare Two Utilization-Based Schedulability-Test   Frameworks for Real-Time Systems", 
    "arxiv-id": "1505.02155v3", 
    "author": "Cong Liu", 
    "publish": "2015-05-08T19:52:46Z", 
    "summary": "This report summarizes two general frameworks, namely k2Q and k2U, that have\nbeen recently developed by us. The purpose of this report is to provide\ndetailed evaluations and comparisons of these two frameworks. These two\nframeworks share some similar characteristics, but they are useful for\ndifferent application cases. These two frameworks together provide\ncomprehensive means for the users to automatically convert the pseudo\npolynomial-time tests (or even exponential-time tests) into polynomial-time\ntests with closed mathematical forms. With the quadratic and hyperbolic forms,\nk2Q and k2U frameworks can be used to provide many quantitive features to be\nmeasured and evaluated, like the total utilization bounds, speed-up factors,\netc., not only for uniprocessor scheduling but also for multiprocessor\nscheduling. These frameworks can be viewed as \"blackbox\" interfaces for\nproviding polynomial-time schedulability tests and response time analysis for\nreal-time applications. We have already presented their advantages for being\napplied in some models in the previous papers. However, it was not possible to\npresent a more comprehensive comparison between these two frameworks. We hope\nthis report can help the readers and users clearly understand the difference of\nthese two frameworks, their unique characteristics, and their advantages. We\ndemonstrate their differences and properties by using the traditional sporadic\nrealtime task models in uniprocessor scheduling and multiprocessor global\nscheduling."
},{
    "category": "cs.OS", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1506.01449v4", 
    "other_authors": "Sebastian Angel, Riad S. Wahby, Max Howald, Joshua B. Leners, Michael Spilo, Zhen Sun, Andrew J. Blumberg, Michael Walfish", 
    "title": "Defending against malicious peripherals with Cinch", 
    "arxiv-id": "1506.01449v4", 
    "author": "Michael Walfish", 
    "publish": "2015-06-04T02:11:27Z", 
    "summary": "Malicious peripherals designed to attack their host computers are a growing\nproblem. Inexpensive and powerful peripherals that attach to plug-and-play\nbuses have made such attacks easy to mount. Making matters worse, commodity\noperating systems lack coherent defenses, and users are often unaware of the\nscope of the problem. We present Cinch, a pragmatic response to this threat.\nCinch uses virtualization to attach peripheral devices to a logically separate,\nuntrusted machine, and includes an interposition layer between the untrusted\nmachine and the protected one. This layer regulates interaction with devices\naccording to user-configured policies. Cinch integrates with existing OSes,\nenforces policies that thwart real-world attacks, and has low overhead."
},{
    "category": "cs.PL", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1508.04753v1", 
    "other_authors": "Kim T. Briggs, Baoguo Zhou, Gerhard W. Dueck", 
    "title": "Cold Object Identification in the Java Virtual Machine", 
    "arxiv-id": "1508.04753v1", 
    "author": "Gerhard W. Dueck", 
    "publish": "2015-08-18T19:50:17Z", 
    "summary": "Many Java applications instantiate objects within the Java heap that are\npersistent but seldom if ever referenced by the application. Examples include\nstrings, such as error messages, and collections of value objects that are\npreloaded for fast access but they may include objects that are seldom\nreferenced. This paper describes a stack-based framework for detecting these\n\"cold\" objects at runtime, with a view to marshaling and sequestering them in\ndesignated regions of the heap where they may be preferentially paged out to a\nbacking store, thereby freeing physical memory pages for occupation by more\nactive objects. Furthermore, we evaluate the correctness and efficiency of\nstack-based approach with an Access Barrier. The experimental results from a\nseries of SPECjvm2008 benchmarks are presented."
},{
    "category": "cs.CR", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1508.05228v1", 
    "other_authors": "Wolfgang Schmidt, Michael Hanspach, J\u00f6rg Keller", 
    "title": "A Case Study on Covert Channel Establishment via Software Caches in   High-Assurance Computing Systems", 
    "arxiv-id": "1508.05228v1", 
    "author": "J\u00f6rg Keller", 
    "publish": "2015-08-21T09:59:27Z", 
    "summary": "Covert channels can be utilized to secretly deliver information from high\nprivileged processes to low privileged processes in the context of a\nhigh-assurance computing system. In this case study, we investigate the\npossibility of covert channel establishment via software caches in the context\nof a framework for component-based operating systems. While component-based\noperating systems offer security through the encapsulation of system service\nprocesses, complete isolation of these processes is not reasonably feasible.\nThis limitation is practically demonstrated with our concept of a specific\ncovert timing channel based on file system caching. The stability of the covert\nchannel is evaluated and a methodology to disrupt the covert channel\ntransmission is presented. While these kinds of attacks are not limited to\nhigh-assurance computing systems, our study practically demonstrates that even\nsecurity-focused computing systems with a minimal trusted computing base are\nvulnerable for such kinds of attacks and careful design decisions are necessary\nfor secure operating system architectures."
},{
    "category": "cs.AR", 
    "doi": "10.1109/CloudCom.2013.45", 
    "link": "http://arxiv.org/pdf/1508.07127v1", 
    "other_authors": "Chun-Hsian Huang, Kwuan-Wei Tseng, Chih-Cheng Lin, Fang-Yu Lin, Pao-Ann Hsiung", 
    "title": "Virtualization Architecture for NoC-based Reconfigurable Systems", 
    "arxiv-id": "1508.07127v1", 
    "author": "Pao-Ann Hsiung", 
    "publish": "2015-08-28T08:45:35Z", 
    "summary": "We propose a virtualization architecture for NoC-based reconfigurable\nsystems. The motivation of this work is to develop a service-oriented\narchitecture that includes Partial Reconfigurable Region as a Service (PRRaaS)\nand Processing Element as a Service (PEaaS) for software applications.\nAccording to the requirements of software applications, new PEs can be created\non-demand by (re)configuring the logic resource of the PRRs in the FPGA, while\nthe configured PEs can also be virtualized to support multiple application\ntasks at the same time. As a result, such a two-level virtualization mechanism,\nincluding the gate-level virtualization and the PE-level virtualization,\nenables an SoC to be dynamically adapted to changing application requirements.\nTherefore, more software applications can be performed, and system performance\ncan be further enhanced."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.196.1", 
    "link": "http://arxiv.org/pdf/1511.04169v1", 
    "other_authors": "Sidney Amani, Toby Murray", 
    "title": "Specifying a Realistic File System", 
    "arxiv-id": "1511.04169v1", 
    "author": "Toby Murray", 
    "publish": "2015-11-13T06:27:39Z", 
    "summary": "We present the most interesting elements of the correctness specification of\nBilbyFs, a performant Linux flash file system. The BilbyFs specification\nsupports asynchronous writes, a feature that has been overlooked by several\nfile system verification projects, and has been used to verify the correctness\nof BilbyFs's fsync() C implementation. It makes use of nondeterminism to be\nconcise and is shallowly-embedded in higher-order logic."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1511.04170v1", 
    "other_authors": "June Andronick, Corey Lewis, Carroll Morgan", 
    "title": "Controlled Owicki-Gries Concurrency: Reasoning about the Preemptible   eChronos Embedded Operating System", 
    "arxiv-id": "1511.04170v1", 
    "author": "Carroll Morgan", 
    "publish": "2015-11-13T06:27:48Z", 
    "summary": "We introduce a controlled concurrency framework, derived from the\nOwicki-Gries method, for describing a hardware interface in detail sufficient\nto support the modelling and verification of small, embedded operating systems\n(OS's) whose run-time responsiveness is paramount. Such real-time systems run\nwith interrupts mostly enabled, including during scheduling. That differs from\nmany other successfully modelled and verified OS's that typically reduce the\ncomplexity of concurrency by running on uniprocessor platforms and by switching\ninterrupts off as much as possible. Our framework builds on the traditional\nOwicki-Gries method, for its fine-grained concurrency is needed for\nhigh-performance system code. We adapt it to support explicit concurrency\ncontrol, by providing a simple, faithful representation of the hardware\ninterface that allows software to control the degree of interleaving between\nuser code, OS code, interrupt handlers and a scheduler that controls context\nswitching. We then apply this framework to model the interleaving behavior of\nthe eChronos OS, a preemptible real-time OS for embedded micro-controllers. We\ndiscuss the accuracy and usability of our approach when instantiated to model\nthe eChronos OS. Both our framework and the eChronos model are formalised in\nthe Isabelle/HOL theorem prover, taking advantage of the high level of\nautomation in modern reasoning tools."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1601.03027v1", 
    "other_authors": "Michael Roland, Michael H\u00f6lzl", 
    "title": "Open Mobile API: Accessing the UICC on Android Devices", 
    "arxiv-id": "1601.03027v1", 
    "author": "Michael H\u00f6lzl", 
    "publish": "2016-01-12T20:46:07Z", 
    "summary": "This report gives an overview of secure element integration into Android\ndevices. It focuses on the Open Mobile API as an open interface to access\nsecure elements from Android applications. The overall architecture of the Open\nMobile API is described and current Android devices are analyzed with regard to\nthe availability of this API. Moreover, this report summarizes our efforts of\nreverse engineering the stock ROM of a Samsung Galaxy S3 in order to analyze\nthe integration of the Open Mobile API and the interface that is used to\nperform APDU-based communication with the UICC (Universal Integrated Circuit\nCard). It further provides a detailed explanation on how to integrate this\nfunctionality into CyanogenMod (an after-market firmware for Android devices)."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1601.05851v1", 
    "other_authors": "Roberto di Pietro, Federico Franzoni, Flavio Lombardi", 
    "title": "HyBIS: Windows Guest Protection through Advanced Memory Introspection", 
    "arxiv-id": "1601.05851v1", 
    "author": "Flavio Lombardi", 
    "publish": "2016-01-22T01:22:53Z", 
    "summary": "Effectively protecting the Windows OS is a challenging task, since most\nimplementation details are not publicly known. Windows has always been the main\ntarget of malwares that have exploited numerous bugs and vulnerabilities.\nRecent trusted boot and additional integrity checks have rendered the Windows\nOS less vulnerable to kernel-level rootkits. Nevertheless, guest Windows\nVirtual Machines are becoming an increasingly interesting attack target. In\nthis work we introduce and analyze a novel Hypervisor-Based Introspection\nSystem (HyBIS) we developed for protecting Windows OSes from malware and\nrootkits. The HyBIS architecture is motivated and detailed, while targeted\nexperimental results show its effectiveness. Comparison with related work\nhighlights main HyBIS advantages such as: effective semantic introspection,\nsupport for 64-bit architectures and for latest Windows (8.x and 10), advanced\nmalware disabling capabilities. We believe the research effort reported here\nwill pave the way to further advances in the security of Windows OSes."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1604.00320v1", 
    "other_authors": "Giuseppe Petracca, Yuqiong Sun, Ahmad Atamli, Trent Jaeger", 
    "title": "AuDroid: Preventing Attacks on Audio Channels in Mobile Devices", 
    "arxiv-id": "1604.00320v1", 
    "author": "Trent Jaeger", 
    "publish": "2016-04-01T16:32:47Z", 
    "summary": "Voice control is a popular way to operate mobile devices, enabling users to\ncommunicate requests to their devices. However, adversaries can leverage voice\ncontrol to trick mobile devices into executing commands to leak secrets or to\nmodify critical information. Contemporary mobile operating systems fail to\nprevent such attacks because they do not control access to the speaker at all\nand fail to control when untrusted apps may use the microphone, enabling\nauthorized apps to create exploitable communication channels. In this paper, we\npropose a security mechanism that tracks the creation of audio communication\nchannels explicitly and controls the information flows over these channels to\nprevent several types of attacks.We design and implement AuDroid, an extension\nto the SELinux reference monitor integrated into the Android operating system\nfor enforcing lattice security policies over the dynamically changing use of\nsystem audio resources. To enhance flexibility, when information flow errors\nare detected, the device owner, system apps and services are given the\nopportunity to resolve information flow errors using known methods, enabling\nAuDroid to run many configurations safely. We evaluate our approach on 17\nwidely-used apps that make extensive use of the microphone and speaker, finding\nthat AuDroid prevents six types of attack scenarios on audio channels while\npermitting all 17 apps to run effectively. AuDroid shows that it is possible to\nprevent attacks using audio channels without compromising functionality or\nintroducing significant performance overhead."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1606.04386v1", 
    "other_authors": "Jian-Jia Chen, Bj\u00f6rn B. Brandenburg", 
    "title": "A Note on the Period Enforcer Algorithm for Self-Suspending Tasks", 
    "arxiv-id": "1606.04386v1", 
    "author": "Bj\u00f6rn B. Brandenburg", 
    "publish": "2016-06-14T14:22:25Z", 
    "summary": "The period enforcer algorithm for self-suspending real-time tasks is a\ntechnique for suppressing the \"back-to-back\" scheduling penalty associated with\ndeferred execution. Originally proposed in 1991, the algorithm has attracted\nrenewed interest in recent years. This note revisits the algorithm in the light\nof recent developments in the analysis of self-suspending tasks, carefully\nre-examines and explains its underlying assumptions and limitations, and points\nout three observations that have not been made in the literature to date: (i)\nperiod enforcement is not strictly superior (compared to the base case without\nenforcement) as it can cause deadline misses in self-suspending task sets that\nare schedulable without enforcement; (ii) to match the assumptions underlying\nthe analysis of the period enforcer, a schedulability analysis of\nself-suspending tasks subject to period enforcement requires a task set\ntransformation for which no solution is known in the general case, and which is\nsubject to exponential time complexity (with current techniques) in the limited\ncase of a single self-suspending task; and (iii) the period enforcer algorithm\nis incompatible with all existing analyses of suspension-based locking\nprotocols, and can in fact cause ever-increasing suspension times until a\ndeadline is missed."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1607.07995v2", 
    "other_authors": "Jiajun Cao, Kapil Arya, Rohan Garg, Shawn Matott, Dhabaleswar K. Panda, Hari Subramoni, J\u00e9r\u00f4me Vienne, Gene Cooperman", 
    "title": "System-level Scalable Checkpoint-Restart for Petascale Computing", 
    "arxiv-id": "1607.07995v2", 
    "author": "Gene Cooperman", 
    "publish": "2016-07-27T07:46:13Z", 
    "summary": "Fault tolerance for the upcoming exascale generation has long been an area of\nactive research. One of the components of a fault tolerance strategy is\ncheckpointing. Petascale-level checkpointing is demonstrated through a new\nmechanism for virtualization of the InfiniBand UD (unreliable datagram) mode,\nand for updating the remote address on each UD-based send, due to lack of a\nfixed peer. Note that InfiniBand UD is required to support modern MPI\nimplementations. An extrapolation from the current results to future SSD-based\nstorage systems provides evidence that the current approach will remain\npractical in the exascale generation. This transparent checkpointing approach\nis evaluated using a framework of the DMTCP checkpointing package. Results are\nshown for HPCG (linear algebra), NAMD (molecular dynamics), and the NAS NPB\nbenchmarks. In tests up to 32,752 MPI processes on 32,752 CPU cores,\ncheckpointing of a computation with a 38 TB memory footprint in 11 minutes is\ndemonstrated. Runtime overhead is reduced to less than 1%. The approach is also\nevaluated across three widely used MPI implementations."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1608.04303v1", 
    "other_authors": "R\u0103zvan Deaconescu, Luke Deshotels, Mihai Bucicoiu, William Enck, Lucas Davi, Ahmad-Reza Sadeghi", 
    "title": "SandBlaster: Reversing the Apple Sandbox", 
    "arxiv-id": "1608.04303v1", 
    "author": "Ahmad-Reza Sadeghi", 
    "publish": "2016-08-15T15:26:22Z", 
    "summary": "In order to limit the damage of malware on Mac OS X and iOS, Apple uses\nsandboxing, a kernel-level security layer that provides tight constraints for\nsystem calls. Particularly used for Apple iOS, sandboxing prevents apps from\nexecuting potentially dangerous actions, by defining rules in a sandbox\nprofile. Investigating Apple's built-in sandbox profiles is difficult as they\nare compiled and stored in binary format. We present SandBlaster, a software\nbundle that is able to reverse/decompile Apple binary sandbox profiles to their\noriginal human readable SBPL (SandBox Profile Language) format. We use\nSandBlaster to reverse all built-in Apple iOS binary sandbox profiles for iOS\n7, 8 and 9. Our tool is, to the best of our knowledge, the first to provide a\nfull reversing of the Apple sandbox, shedding light into the inner workings of\nApple sandbox profiles and providing essential support for security researchers\nand professionals interested in Apple security mechanisms."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1609.00100v2", 
    "other_authors": "Zhiyong Shan", 
    "title": "Suspicious-Taint-Based Access Control for Protecting OS from Network   Attacks", 
    "arxiv-id": "1609.00100v2", 
    "author": "Zhiyong Shan", 
    "publish": "2016-09-01T03:45:39Z", 
    "summary": "Today, security threats to operating systems largely come from network.\nTraditional discretionary access control mechanism alone can hardly defeat\nthem. Although traditional mandatory access control models can effectively\nprotect the security of OS, they have problems of being incompatible with\napplication software and complex in administration. In this paper, we propose a\nnew model, Suspicious-Taint-Based Access Control (STBAC) model, for defeating\nnetwork attacks while being compatible, simple and maintaining good system\nperformance. STBAC regards the processes using Non-Trustable-Communications as\nthe starting points of suspicious taint, traces the activities of the\nsuspiciously tainted processes by taint rules, and forbids the suspiciously\ntainted processes to illegally access vital resources by protection rules. Even\nin the cases when some privileged processes are subverted, STBAC can still\nprotect vital resources from being compromised by the intruder. We implemented\nthe model in the Linux kernel and evaluated it through experiments. The\nevaluation showed that STBAC could protect vital resources effectively without\nsignificant impact on compatibility and performance."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1609.02067v1", 
    "other_authors": "Gennady Pekhimenko", 
    "title": "Practical Data Compression for Modern Memory Hierarchies", 
    "arxiv-id": "1609.02067v1", 
    "author": "Gennady Pekhimenko", 
    "publish": "2016-09-07T16:53:40Z", 
    "summary": "In this thesis, we describe a new, practical approach to integrating\nhardware-based data compression within the memory hierarchy, including on-chip\ncaches, main memory, and both on-chip and off-chip interconnects. This new\napproach is fast, simple, and effective in saving storage space. A key insight\nin our approach is that access time (including decompression latency) is\ncritical in modern memory hierarchies. By combining inexpensive hardware\nsupport with modest OS support, our holistic approach to compression achieves\nsubstantial improvements in performance and energy efficiency across the memory\nhierarchy. Using this new approach, we make several major contributions in this\nthesis. First, we propose a new compression algorithm, Base-Delta-Immediate\nCompression (BDI), that achieves high compression ratio with very low\ncompression/decompression latency. BDI exploits the existing low dynamic range\nof values present in many cache lines to compress them to smaller sizes using\nBase+Delta encoding. Second, we observe that the compressed size of a cache\nblock can be indicative of its reuse. We use this observation to develop a new\ncache insertion policy for compressed caches, the Size-based Insertion Policy\n(SIP), which uses the size of a compressed block as one of the metrics to\npredict its potential future reuse. Third, we propose a new main memory\ncompression framework, Linearly Compressed Pages (LCP), that significantly\nreduces the complexity and power cost of supporting main memory compression. We\ndemonstrate that any compression algorithm can be adapted to fit the\nrequirements of LCP, and that LCP can be efficiently integrated with the\nexisting cache compression designs, avoiding extra compression/decompression."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1611.07862v1", 
    "other_authors": "Bobby Powers, John Vilk, Emery D. Berger", 
    "title": "Browsix: Bridging the Gap Between Unix and the Browser", 
    "arxiv-id": "1611.07862v1", 
    "author": "Emery D. Berger", 
    "publish": "2016-11-23T16:23:40Z", 
    "summary": "Applications written to run on conventional operating systems typically\ndepend on OS abstractions like processes, pipes, signals, sockets, and a shared\nfile system. Porting these applications to the web currently requires extensive\nrewriting or hosting significant portions of code server-side because browsers\npresent a nontraditional runtime environment that lacks OS functionality.\n  This paper presents Browsix, a framework that bridges the considerable gap\nbetween conventional operating systems and the browser, enabling unmodified\nprograms expecting a Unix-like environment to run directly in the browser.\nBrowsix comprises two core parts: (1) a JavaScript-only system that makes core\nUnix features (including pipes, concurrent processes, signals, sockets, and a\nshared file system) available to web applications; and (2) extended JavaScript\nruntimes for C, C++, Go, and Node.js that support running programs written in\nthese languages as processes in the browser. Browsix supports running a POSIX\nshell, making it straightforward to connect applications together via pipes.\n  We illustrate Browsix's capabilities via case studies that demonstrate how it\neases porting legacy applications to the browser and enables new functionality.\nWe demonstrate a Browsix-enabled LaTeX editor that operates by executing\nunmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can\nrender documents in seconds, making it fast enough to be practical. We further\ndemonstrate how Browsix lets us port a client-server application to run\nentirely in the browser for disconnected operation. Creating these applications\nrequired less than 50 lines of glue code and no code modifications,\ndemonstrating how easily Browsix can be used to build sophisticated web\napplications from existing parts without modification."
},{
    "category": "cs.AR", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1612.00445v1", 
    "other_authors": "Javier Picorel, Djordje Jevdjic, Babak Falsafi", 
    "title": "Near-Memory Address Translation", 
    "arxiv-id": "1612.00445v1", 
    "author": "Babak Falsafi", 
    "publish": "2016-12-01T17:45:18Z", 
    "summary": "Memory and logic integration on the same chip is becoming increasingly cost\neffective, creating the opportunity to offload data-intensive functionality to\nprocessing units placed inside memory chips. The introduction of memory-side\nprocessing units (MPUs) into conventional systems faces virtual memory as the\nfirst big showstopper: without efficient hardware support for address\ntranslation MPUs have highly limited applicability. Unfortunately, conventional\ntranslation hardware (i.e., TLBs, MMU caches, and page table walkers) incurs\ndramatic overheads due to the limited reach, increasingly high miss penalty,\nand high translation coherence cost incurred with rapidly growing aggregate\nmemory size.\n  In this paper, we are the first to show that the historically important\nflexibility to map any virtual page to any page frame is unnecessary in today's\nservers. We find that while limiting the associativity of the\nvirtual-to-physical mapping incurs no penalty, it can break the\ntranslate-then-fetch serialization if combined with careful data placement in\nthe MPU's memory, allowing for translation and data fetch to proceed\nindependently and in parallel. We propose the Distributed Inverted Page Table\n(DIPTA), a near-memory structure in which the smallest memory partition keeps\nthe translation information for its data share, ensuring that the translation\ncompletes together with the data fetch. DIPTA completely eliminates the\nconventional translation hardware, as well as the performance overhead of\ntranslation, achieving speedups of up to 4.95x and 2.44x over conventional\ntranslation using 4KB and 1GB pages respectively, and obviating the need for\ntranslation-related broadcasts."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.196.2", 
    "link": "http://arxiv.org/pdf/1703.00897v1", 
    "other_authors": "Rohan Garg, Kapil Arya, Jiajun Cao, Gene Cooperman, Jeff Evans, Ankit Garg, Neil A. Rosenberg, K. Suresh", 
    "title": "Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation", 
    "arxiv-id": "1703.00897v1", 
    "author": "K. Suresh", 
    "publish": "2017-03-02T18:52:45Z", 
    "summary": "Checkpoint-restart is now a mature technology. It allows a user to save and\nlater restore the state of a running process. The new plugin model for the\nupcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is\ndescribed here. This plugin model allows a target application to disconnect\nfrom the hardware emulator at checkpoint time and then re-connect to a possibly\ndifferent hardware emulator at the time of restart. The DMTCP plugin model is\nimportant in allowing three distinct parties to seamlessly inter-operate. The\nthree parties are: the EDA designer, who is concerned with formal verification\nof a circuit design; the DMTCP developers, who are concerned with providing\ntransparent checkpointing during the circuit emulation; and the hardware\nemulator vendor, who provides a plugin library that responds to checkpoint,\nrestart, and other events.\n  The new plugin model is an example of process-level virtualization:\nvirtualization of external abstractions from within a process. This capability\nis motivated by scenarios for testing circuit models with the help of a\nhardware emulator. The plugin model enables a three-way collaboration: allowing\na circuit designer and emulator vendor to each contribute separate proprietary\nplugins while sharing an open source software framework from the DMTCP\ndevelopers. This provides a more flexible platform, where different fault\ninjection models based on plugins can be designed within the DMTCP\ncheckpointing framework. After initialization, one restarts from a checkpointed\nstate under the control of the desired plugin. This restart saves the time\nspent in simulating the initialization phase, while enabling fault injection\nexactly at the region of interest. Upon restart, one can inject faults or\notherwise modify the remainder of the simulation. The work concludes with a\nbrief survey of checkpointing and process-level virtualization."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/1703.06571v1", 
    "other_authors": "Reto Achermann, Lukas Humbel, David Cock, Timothy Roscoe", 
    "title": "Formalizing Memory Accesses and Interrupts", 
    "arxiv-id": "1703.06571v1", 
    "author": "Timothy Roscoe", 
    "publish": "2017-03-20T02:47:57Z", 
    "summary": "The hardware/software boundary in modern heterogeneous multicore computers is\nincreasingly complex, and diverse across different platforms. A single memory\naccess by a core or DMA engine traverses multiple hardware translation and\ncaching steps, and the destination memory cell or register often appears at\ndifferent physical addresses for different cores. Interrupts pass through a\ncomplex topology of interrupt controllers and remappers before delivery to one\nor more cores, each with specific constraints on their configurations. System\nsoftware must not only correctly understand the specific hardware at hand, but\nalso configure it appropriately at runtime. We propose a formal model of\naddress spaces and resources in a system that allows us to express and verify\ninvariants of the system's runtime configuration, and illustrate (and motivate)\nit with several real platforms we have encountered in the process of OS\nimplementation."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/cs/9905002v1", 
    "other_authors": "Burkhard D. Burow", 
    "title": "DRAFT : Task System and Item Architecture (TSIA)", 
    "arxiv-id": "cs/9905002v1", 
    "author": "Burkhard D. Burow", 
    "publish": "1999-05-05T01:43:13Z", 
    "summary": "During its execution, a task is independent of all other tasks. For an\napplication which executes in terms of tasks, the application definition can be\nfree of the details of the execution. Many projects have demonstrated that a\ntask system (TS) can provide such an application with a parallel, distributed,\nheterogeneous, adaptive, dynamic, real-time, interactive, reliable, secure or\nother execution. A task consists of items and thus the application is defined\nin terms of items. An item architecture (IA) can support arrays, routines and\nother structures of items, thus allowing for a structured application\ndefinition. Taking properties from many projects, the support can extend\nthrough to currying, application defined types, conditional items, streams and\nother definition elements. A task system and item architecture (TSIA) thus\npromises unprecedented levels of support for application execution and\ndefinition."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/cs/9908002v1", 
    "other_authors": "Burkhard D. Burow", 
    "title": "After Compilers and Operating Systems : The Third Advance in Application   Support", 
    "arxiv-id": "cs/9908002v1", 
    "author": "Burkhard D. Burow", 
    "publish": "1999-08-03T14:50:09Z", 
    "summary": "After compilers and operating systems, TSIAs are the third advance in\napplication support. A compiler supports a high level application definition in\na programming language. An operating system supports a high level interface to\nthe resources used by an application execution. A Task System and Item\nArchitecture (TSIA) provides an application with a transparent reliable,\ndistributed, heterogeneous, adaptive, dynamic, real-time, interactive,\nparallel, secure or other execution. In addition to supporting the application\nexecution, a TSIA also supports the application definition. This run-time\nsupport for the definition is complementary to the compile-time support of a\ncompiler. For example, this allows a language similar to Fortran or C to\ndeliver features promised by functional computing. While many TSIAs exist, they\npreviously have not been recognized as such and have served only a particular\ntype of application. Existing TSIAs and other projects demonstrate that TSIAs\nare feasible for most applications. As the next paradigm for application\nsupport, the TSIA simplifies and unifies existing computing practice and\nresearch. By solving many outstanding problems, the TSIA opens many, many new\nopportunities for computing."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/cs/0403007v1", 
    "other_authors": "George Candea, Armando Fox", 
    "title": "End-User Effects of Microreboots in Three-Tiered Internet Systems", 
    "arxiv-id": "cs/0403007v1", 
    "author": "Armando Fox", 
    "publish": "2004-03-06T02:52:17Z", 
    "summary": "Microreboots restart fine-grained components of software systems \"with a\nclean slate,\" and only take a fraction of the time needed for full system\nreboot. Microreboots provide an application-generic recovery technique for\nInternet services, which can be supported entirely in middleware and requires\nno changes to the applications or any a priori knowledge of application\nsemantics.\n  This paper investigates the effect of microreboots on end-users of an\neBay-like online auction application; we find that microreboots are nearly as\neffective as full reboots, but are significantly less disruptive in terms of\ndowntime and lost work. In our experiments, microreboots reduced the number of\nfailed user requests by 65% and the perceived downtime by 78% compared to a\nserver process restart. We also show how to replace user-visible transient\nfailures with transparent call-retry, at the cost of a slight increase in\nend-user-visible latency during recovery. Due to their low cost, microreboots\ncan be used aggressively, even when their necessity is less than certain, hence\nadding to the reduced recovery time a reduction in the fault detection time,\nwhich further improves availability."
},{
    "category": "cs.DL", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/cs/0508130v1", 
    "other_authors": "Mary Baker, Mehul Shah, David S. H. Rosenthal, Mema Roussopoulos, Petros Maniatis, TJ Giuli, Prashanth Bungale", 
    "title": "A Fresh Look at the Reliability of Long-term Digital Storage", 
    "arxiv-id": "cs/0508130v1", 
    "author": "Prashanth Bungale", 
    "publish": "2005-08-31T01:44:35Z", 
    "summary": "Many emerging Web services, such as email, photo sharing, and web site\narchives, need to preserve large amounts of quickly-accessible data\nindefinitely into the future. In this paper, we make the case that these\napplications' demands on large scale storage systems over long time horizons\nrequire us to re-evaluate traditional storage system designs. We examine\nthreats to long-lived data from an end-to-end perspective, taking into account\nnot just hardware and software faults but also faults due to humans and\norganizations. We present a simple model of long-term storage failures that\nhelps us reason about the various strategies for addressing these threats in a\ncost-effective manner. Using this model we show that the most important\nstrategies for increasing the reliability of long-term storage are detecting\nlatent faults quickly, automating fault repair to make it faster and cheaper,\nand increasing the independence of data replicas."
},{
    "category": "cs.PL", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/cs/0603021v1", 
    "other_authors": "Joy Mukherjee, Srinidhi Varadarajan", 
    "title": "Language Support for Optional Functionality", 
    "arxiv-id": "cs/0603021v1", 
    "author": "Srinidhi Varadarajan", 
    "publish": "2006-03-06T00:46:09Z", 
    "summary": "We recommend a programming construct - availability check - for programs that\nneed to automatically adjust to presence or absence of segments of code. The\nidea is to check the existence of a valid definition before a function call is\ninvoked. The syntax is that of a simple 'if' statement. The vision is to enable\ncustomization of application functionality through addition or removal of\noptional components, but without requiring complete re-building. Focus is on\nC-like compiled procedural languages and UNIX-based systems. Essentially, our\napproach attempts to combine the flexibility of dynamic libraries with the\nusability of utility (dependency) libraries. We outline the benefits over\nprevalent strategies mainly in terms of development complexity, crudely\nmeasured as lesser lines of code. We also allude to performance and flexibility\nfacets. A Preliminary implementation and figures from early experimental\nevaluation are presented."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.244.4", 
    "link": "http://arxiv.org/pdf/cs/0603076v1", 
    "other_authors": "Bryan Ford, Jacob Strauss, Chris Lesniewski-Laas, Sean Rhea, Frans Kaashoek, Robert Morris", 
    "title": "User-Relative Names for Globally Connected Personal Devices", 
    "arxiv-id": "cs/0603076v1", 
    "author": "Robert Morris", 
    "publish": "2006-03-18T17:27:22Z", 
    "summary": "Nontechnical users who own increasingly ubiquitous network-enabled personal\ndevices such as laptops, digital cameras, and smart phones need a simple,\nintuitive, and secure way to share information and services between their\ndevices. User Information Architecture, or UIA, is a novel naming and\npeer-to-peer connectivity architecture addressing this need. Users assign UIA\nnames by \"introducing\" devices to each other on a common local-area network,\nbut these names remain securely bound to their target as devices migrate.\nMultiple devices owned by the same user, once introduced, automatically merge\ntheir namespaces to form a distributed \"personal cluster\" that the owner can\naccess or modify from any of his devices. Instead of requiring users to\nallocate globally unique names from a central authority, UIA enables users to\nassign their own \"user-relative\" names both to their own devices and to other\nusers. With UIA, for example, Alice can always access her iPod from any of her\nown personal devices at any location via the name \"ipod\", and her friend Bob\ncan access her iPod via a relative name like \"ipod.Alice\"."
},{
    "category": "cs.DC", 
    "doi": "10.1007/11780823_17", 
    "link": "http://arxiv.org/pdf/cs/0611116v1", 
    "other_authors": "Mikhail Nesterenko, S\u00e9bastien Tixeuil", 
    "title": "Discovering Network Topology in the Presence of Byzantine Faults", 
    "arxiv-id": "cs/0611116v1", 
    "author": "S\u00e9bastien Tixeuil", 
    "publish": "2006-11-22T18:25:43Z", 
    "summary": "We study the problem of Byzantine-robust topology discovery in an arbitrary\nasynchronous network. We formally state the weak and strong versions of the\nproblem. The weak version requires that either each node discovers the topology\nof the network or at least one node detects the presence of a faulty node. The\nstrong version requires that each node discovers the topology regardless of\nfaults. We focus on non-cryptographic solutions to these problems. We explore\ntheir bounds. We prove that the weak topology discovery problem is solvable\nonly if the connectivity of the network exceeds the number of faults in the\nsystem. Similarly, we show that the strong version of the problem is solvable\nonly if the network connectivity is more than twice the number of faults. We\npresent solutions to both versions of the problem. The presented algorithms\nmatch the established graph connectivity bounds. The algorithms do not require\nthe individual nodes to know either the diameter or the size of the network.\nThe message complexity of both programs is low polynomial with respect to the\nnetwork size. We describe how our solutions can be extended to add the property\nof termination, handle topology changes and perform neighborhood discovery."
},{
    "category": "cs.DC", 
    "doi": "10.1007/11780823_17", 
    "link": "http://arxiv.org/pdf/cs/0611117v1", 
    "other_authors": "Mark Miyashita, Mikhail Nesterenko", 
    "title": "2FACE: Bi-Directional Face Traversal for Efficient Geometric Routing", 
    "arxiv-id": "cs/0611117v1", 
    "author": "Mikhail Nesterenko", 
    "publish": "2006-11-22T19:28:31Z", 
    "summary": "We propose bi-directional face traversal algorithm $2FACE$ to shorten the\npath the message takes to reach the destination in geometric routing. Our\nalgorithm combines the practicality of the best single-direction traversal\nalgorithms with the worst case message complexity of $O(|E|)$, where $E$ is the\nnumber of network edges. We apply $2FACE$ to a variety of geometric routing\nalgorithms. Our simulation results indicate that bi-directional face traversal\ndecreases the latency of message delivery two to three times compared to single\ndirection face traversal. The thus selected path approaches the shortest\npossible route. This gain in speed comes with a similar message overhead\nincrease. We describe an algorithm which compensates for this message overhead\nby recording the preferable face traversal direction. Thus, if a source has\nseveral messages to send to the destination, the subsequent messages follow the\nshortest route. Our simulation results show that with most geometric routing\nalgorithms the message overhead of finding the short route by bi-directional\nface traversal is compensated within two to four repeat messages."
},{
    "category": "cs.PF", 
    "doi": "10.1007/11780823_17", 
    "link": "http://arxiv.org/pdf/0912.3852v1", 
    "other_authors": "Sathish Gopalakrishnan", 
    "title": "Sharp utilization thresholds for some real-time scheduling problems", 
    "arxiv-id": "0912.3852v1", 
    "author": "Sathish Gopalakrishnan", 
    "publish": "2009-12-19T01:18:05Z", 
    "summary": "Scheduling policies for real-time systems exhibit threshold behavior that is\nrelated to the utilization of the task set they schedule, and in some cases\nthis threshold is sharp. For the rate monotonic scheduling policy, we show that\nperiodic workload with utilization less than a threshold $U_{RM}^{*}$ can be\nscheduled almost surely and that all workload with utilization greater than\n$U_{RM}^{*}$ is almost surely not schedulable. We study such sharp threshold\nbehavior in the context of processor scheduling using static task priorities,\nnot only for periodic real-time tasks but for aperiodic real-time tasks as\nwell. The notion of a utilization threshold provides a simple schedulability\ntest for most real-time applications. These results improve our understanding\nof scheduling policies and provide an interesting characterization of the\ntypical behavior of policies. The threshold is sharp (small deviations around\nthe threshold cause schedulability, as a property, to appear or disappear) for\nmost policies; this is a happy consequence that can be used to address the\nlimitations of existing utilization-based tests for schedulability. We\ndemonstrate the use of such an approach for balancing power consumption with\nthe need to meet deadlines in web servers."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/1010.5571v1", 
    "other_authors": "Matthieu Lemerre, Vincent David, Christophe Aussagu\u00e8s, Guy Vidal-Naquet", 
    "title": "An Introduction to Time-Constrained Automata", 
    "arxiv-id": "1010.5571v1", 
    "author": "Guy Vidal-Naquet", 
    "publish": "2010-10-27T05:04:38Z", 
    "summary": "We present time-constrained automata (TCA), a model for hard real-time\ncomputation in which agents behaviors are modeled by automata and constrained\nby time intervals.\n  TCA actions can have multiple start time and deadlines, can be aperiodic, and\nare selected dynamically following a graph, the time-constrained automaton.\nThis allows expressing much more precise time constraints than classical\nperiodic or sporadic model, while preserving the ease of scheduling and\nanalysis.\n  We provide some properties of this model as well as their scheduling\nsemantics. We show that TCA can be automatically derived from source-code, and\noptimally scheduled on single processors using a variant of EDF. We explain how\ntime constraints can be used to guarantee communication determinism by\nconstruction, and to study when possible agent interactions happen."
},{
    "category": "cs.DC", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/1105.3232v1", 
    "other_authors": "Sokol Kosta, Andrius Aucinas, Pan Hui, Richard Mortier, Xinwen Zhang", 
    "title": "Unleashing the Power of Mobile Cloud Computing using ThinkAir", 
    "arxiv-id": "1105.3232v1", 
    "author": "Xinwen Zhang", 
    "publish": "2011-05-16T21:45:54Z", 
    "summary": "Smartphones have exploded in popularity in recent years, becoming ever more\nsophisticated and capable. As a result, developers worldwide are building\nincreasingly complex applications that require ever increasing amounts of\ncomputational power and energy. In this paper we propose ThinkAir, a framework\nthat makes it simple for developers to migrate their smartphone applications to\nthe cloud. ThinkAir exploits the concept of smartphone virtualization in the\ncloud and provides method level computation offloading. Advancing on previous\nworks, it focuses on the elasticity and scalability of the server side and\nenhances the power of mobile cloud computing by parallelizing method execution\nusing multiple Virtual Machine (VM) images. We evaluate the system using a\nrange of benchmarks starting from simple micro-benchmarks to more complex\napplications. First, we show that the execution time and energy consumption\ndecrease two orders of magnitude for the N-queens puzzle and one order of\nmagnitude for a face detection and a virus scan application, using cloud\noffloading. We then show that if a task is parallelizable, the user can request\nmore than one VM to execute it, and these VMs will be provided dynamically. In\nfact, by exploiting parallelization, we achieve a greater reduction on the\nexecution time and energy consumption for the previous applications. Finally,\nwe use a memory-hungry image combiner tool to demonstrate that applications can\ndynamically request VMs with more computational power in order to meet their\ncomputational requirements."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/1110.4623v1", 
    "other_authors": "Jeff A. Stuart, John D. Owens", 
    "title": "Efficient Synchronization Primitives for GPUs", 
    "arxiv-id": "1110.4623v1", 
    "author": "John D. Owens", 
    "publish": "2011-10-20T19:43:58Z", 
    "summary": "In this paper, we revisit the design of synchronization\nprimitives---specifically barriers, mutexes, and semaphores---and how they\napply to the GPU. Previous implementations are insufficient due to the\ndiscrepancies in hardware and programming model of the GPU and CPU. We create\nnew implementations in CUDA and analyze the performance of spinning on the GPU,\nas well as a method of sleeping on the GPU, by running a set of memory-system\nbenchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class\nGPUs from NVIDIA. From our results we define higher-level principles that are\nvalid for generic many-core processors, the most important of which is to limit\nthe number of atomic accesses required for a synchronization operation because\natomic accesses are slower than regular memory accesses. We use the results of\nthe benchmarks to critique existing synchronization algorithms and guide our\nnew implementations, and then define an abstraction of GPUs to classify any GPU\nbased on the behavior of the memory system. We use this abstraction to create\nsuitable implementations of the primitives specifically targeting the GPU, and\nanalyze the performance of these algorithms on Tesla and Fermi. We then predict\nperformance on future GPUs based on characteristics of the abstraction. We also\nexamine the roles of spin waiting and sleep waiting in each primitive and how\ntheir performance varies based on the machine abstraction, then give a set of\nguidelines for when each strategy is useful based on the characteristics of the\nGPU and expected contention."
},{
    "category": "cs.RO", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/1302.5521v1", 
    "other_authors": "Mikael Moghadam, David Johan Christensen, David Brandt, Ulrik Pagh Schultz", 
    "title": "Towards Python-based Domain-specific Languages for Self-reconfigurable   Modular Robotics Research", 
    "arxiv-id": "1302.5521v1", 
    "author": "Ulrik Pagh Schultz", 
    "publish": "2013-02-22T09:01:24Z", 
    "summary": "This paper explores the role of operating system and high-level languages in\nthe development of software and domain-specific languages (DSLs) for\nself-reconfigurable robotics. We review some of the current trends in\nself-reconfigurable robotics and describe the development of a software system\nfor ATRON II which utilizes Linux and Python to significantly improve software\nabstraction and portability while providing some basic features which could\nprove useful when using Python, either stand-alone or via a DSL, on a\nself-reconfigurable robot system. These features include transparent socket\ncommunication, module identification, easy software transfer and reliable\nmodule-to-module communication. The end result is a software platform for\nmodular robots that where appropriate builds on existing work in operating\nsystems, virtual machines, middleware and high-level languages."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/1407.4245v1", 
    "other_authors": "Elena Reshetova, Janne Karhunen, Thomas Nyman, N. Asokan", 
    "title": "Security of OS-level virtualization technologies: Technical report", 
    "arxiv-id": "1407.4245v1", 
    "author": "N. Asokan", 
    "publish": "2014-07-16T10:03:51Z", 
    "summary": "The need for flexible, low-overhead virtualization is evident on many fronts\nranging from high-density cloud servers to mobile devices. During the past\ndecade OS-level virtualization has emerged as a new, efficient approach for\nvirtualization, with implementations in multiple different Unix-based systems.\nDespite its popularity, there has been no systematic study of OS-level\nvirtualization from the point of view of security. In this report, we conduct a\ncomparative study of several OS-level virtualization systems, discuss their\nsecurity and identify some gaps in current solutions."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/0803.3230v2", 
    "other_authors": "Avik Chaudhuri, Prasad Naldurg, Sriram Rajamani", 
    "title": "A Type System for Data-Flow Integrity on Windows Vista", 
    "arxiv-id": "0803.3230v2", 
    "author": "Sriram Rajamani", 
    "publish": "2008-03-21T21:28:16Z", 
    "summary": "The Windows Vista operating system implements an interesting model of\nmulti-level integrity. We observe that in this model, trusted code can be\nblamed for any information-flow attack; thus, it is possible to eliminate such\nattacks by static analysis of trusted code. We formalize this model by\ndesigning a type system that can efficiently enforce data-flow integrity on\nWindows Vista. Typechecking guarantees that objects whose contents are\nstatically trusted never contain untrusted values, regardless of what untrusted\ncode runs in the environment. Some of Windows Vista's runtime access checks are\nnecessary for soundness; others are redundant and can be optimized away."
},{
    "category": "cs.NI", 
    "doi": "10.4204/EPTCS.38.9", 
    "link": "http://arxiv.org/pdf/0803.3338v1", 
    "other_authors": "Bhargava Kumar K, Ganesh M. Narayan, K. Gopinath", 
    "title": "Performance Evaluation of Multiple TCP connections in iSCSI", 
    "arxiv-id": "0803.3338v1", 
    "author": "K. Gopinath", 
    "publish": "2008-03-23T19:10:00Z", 
    "summary": "Scaling data storage is a significant concern in enterprise systems and\nStorage Area Networks (SANs) are deployed as a means to scale enterprise\nstorage. SANs based on Fibre Channel have been used extensively in the last\ndecade while iSCSI is fast becoming a serious contender due to its reduced\ncosts and unified infrastructure. This work examines the performance of iSCSI\nwith multiple TCP connections. Multiple TCP connections are often used to\nrealize higher bandwidth but there may be no fairness in how bandwidth is\ndistributed. We propose a mechanism to share congestion information across\nmultiple flows in ``Fair-TCP'' for improved performance. Our results show that\nFair-TCP significantly improves the performance for I/O intensive workloads."
},{
    "category": "cs.OS", 
    "doi": "10.1109/MAHSS.2005.1542862", 
    "link": "http://arxiv.org/pdf/0803.3632v1", 
    "other_authors": "Mikhail Nesterenko, Adnan Vora", 
    "title": "Void Traversal for Guaranteed Delivery in Geometric Routing", 
    "arxiv-id": "0803.3632v1", 
    "author": "Adnan Vora", 
    "publish": "2008-03-25T20:52:17Z", 
    "summary": "Geometric routing algorithms like GFG (GPSR) are lightweight, scalable\nalgorithms that can be used to route in resource-constrained ad hoc wireless\nnetworks. However, such algorithms run on planar graphs only. To efficiently\nconstruct a planar graph, they require a unit-disk graph. To make the topology\nunit-disk, the maximum link length in the network has to be selected\nconservatively. In practical setting this leads to the designs where the node\ndensity is rather high. Moreover, the network diameter of a planar subgraph is\ngreater than the original graph, which leads to longer routes. To remedy this\nproblem, we propose a void traversal algorithm that works on arbitrary\ngeometric graphs. We describe how to use this algorithm for geometric routing\nwith guaranteed delivery and compare its performance with GFG."
},{
    "category": "cs.DC", 
    "doi": "10.1109/MAHSS.2005.1542862", 
    "link": "http://arxiv.org/pdf/0903.2525v1", 
    "other_authors": "Rodrigo N. Calheiros, Rajiv Ranjan, Cesar A. F. De Rose, Rajkumar Buyya", 
    "title": "CloudSim: A Novel Framework for Modeling and Simulation of Cloud   Computing Infrastructures and Services", 
    "arxiv-id": "0903.2525v1", 
    "author": "Rajkumar Buyya", 
    "publish": "2009-03-14T04:28:55Z", 
    "summary": "Cloud computing focuses on delivery of reliable, secure, fault-tolerant,\nsustainable, and scalable infrastructures for hosting Internet-based\napplication services. These applications have different composition,\nconfiguration, and deployment requirements. Quantifying the performance of\nscheduling and allocation policy on a Cloud infrastructure (hardware, software,\nservices) for different application and service models under varying load,\nenergy performance (power consumption, heat dissipation), and system size is an\nextremely challenging problem to tackle. To simplify this process, in this\npaper we propose CloudSim: a new generalized and extensible simulation\nframework that enables seamless modelling, simulation, and experimentation of\nemerging Cloud computing infrastructures and management services. The\nsimulation framework has the following novel features: (i) support for\nmodelling and instantiation of large scale Cloud computing infrastructure,\nincluding data centers on a single physical computing node and java virtual\nmachine; (ii) a self-contained platform for modelling data centers, service\nbrokers, scheduling, and allocations policies; (iii) availability of\nvirtualization engine, which aids in creation and management of multiple,\nindependent, and co-hosted virtualized services on a data center node; and (iv)\nflexibility to switch between space-shared and time-shared allocation of\nprocessing cores to virtualized services."
},{
    "category": "cs.PF", 
    "doi": "10.1109/MAHSS.2005.1542862", 
    "link": "http://arxiv.org/pdf/1106.2992v1", 
    "other_authors": "Michiel W. van Tol", 
    "title": "A Characterization of the SPARC T3-4 System", 
    "arxiv-id": "1106.2992v1", 
    "author": "Michiel W. van Tol", 
    "publish": "2011-06-15T15:18:27Z", 
    "summary": "This technical report covers a set of experiments on the 64-core SPARC T3-4\nsystem, comparing it to two similar AMD and Intel systems. Key characteristics\nas maximum integer and floating point arithmetic throughput are measured as\nwell as memory throughput, showing the scalability of the SPARC T3-4 system.\nThe performance of POSIX threads primitives is characterized and compared in\ndetail, such as thread creation and mutex synchronization. Scalability tests\nwith a fine grained multithreaded runtime are performed, showing problems with\natomic CAS operations on such physically highly parallel systems."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijwmn", 
    "link": "http://arxiv.org/pdf/1111.1930v1", 
    "other_authors": "A. A. Boudhir, M. Bouhorma, M. Ben Ahmed, Elbrak Said", 
    "title": "The UWB Solution for Multimedia Traffic in Wireless Sensor Networks", 
    "arxiv-id": "1111.1930v1", 
    "author": "Elbrak Said", 
    "publish": "2011-11-08T15:03:26Z", 
    "summary": "Several researches are focused on the QoS (Quality of Service) and Energy\nconsumption in wireless Multimedia Sensor Networks. Those research projects\ninvest in theory and practice in order to extend the spectrum of use of norms,\nstandards and technologies which are emerged in wireless communications. The\nperformance of these technologies is strongly related to domains of use and\nlimitations of their characteristics. In this paper, we give a comparison of\nZigBee technology, most widely used in sensor networks, and UWB (Ultra Wide\nBand) which presents itself as competitor that present in these work better\nresults for audiovisual applications with medium-range and high throughput."
},{
    "category": "cs.ET", 
    "doi": "10.5121/ijwmn", 
    "link": "http://arxiv.org/pdf/1111.5880v1", 
    "other_authors": "Fumin Zhang, Zhenwu Shi, Shayok Mukhopadhyay", 
    "title": "Robustness Analysis for Battery Supported Cyber-Physical Systems", 
    "arxiv-id": "1111.5880v1", 
    "author": "Shayok Mukhopadhyay", 
    "publish": "2011-11-25T02:10:11Z", 
    "summary": "This paper establishes a novel analytical approach to quantify robustness of\nscheduling and battery management for battery supported cyber-physical systems.\nA dynamic schedulability test is introduced to determine whether tasks are\nschedulable within a finite time window. The test is used to measure robustness\nof a real-time scheduling algorithm by evaluating the strength of computing\ntime perturbations that break schedulability at runtime. Robustness of battery\nmanagement is quantified analytically by an adaptive threshold on the state of\ncharge. The adaptive threshold significantly reduces the false alarm rate for\nbattery management algorithms to decide when a battery needs to be replaced."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijwmn", 
    "link": "http://arxiv.org/pdf/1208.6428v1", 
    "other_authors": "Pierre Olivier, Jalil Boukhobza", 
    "title": "A Hardware Time Manager Implementation for the Xenomai Real-Time Kernel   of Embedded Linux", 
    "arxiv-id": "1208.6428v1", 
    "author": "Jalil Boukhobza", 
    "publish": "2012-08-31T09:04:05Z", 
    "summary": "Nowadays, the use of embedded operating systems in different embedded\nprojects is subject to a tremendous growth. Embedded Linux is becoming one of\nthose most popular EOSs due to its modularity, efficiency, reliability, and\ncost. One way to make it hard real-time is to include a real-time kernel like\nXenomai. One of the key characteristics of a Real-Time Operating System (RTOS)\nis its ability to meet execution time deadlines deterministically. So, the more\nprecise and flexible the time management can be, the better it can handle\nefficiently the determinism for different embedded applications. RTOS time\nprecision is characterized by a specific periodic interrupt service controlled\nby a software time manager. The smaller the period of the interrupt, the better\nthe precision of the RTOS, the more it overloads the CPU, and though reduces\nthe overall efficiency of the RTOS. In this paper, we propose to drastically\nreduce these overheads by migrating the time management service of Xenomai into\na configurable hardware component to relieve the CPU. The hardware component is\nimplemented in a Field Programmable Gate Array coupled to the CPU. This work\nwas achieved in a Master degree project where students could apprehend many\nfields of embedded systems: RTOS programming, hardware design, performance\nevaluation, etc."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.102.5", 
    "link": "http://arxiv.org/pdf/1211.6187v1", 
    "other_authors": "Gidon Ernst, Gerhard Schellhorn, Dominik Haneberg, J\u00f6rg Pf\u00e4hler, Wolfgang Reif", 
    "title": "A Formal Model of a Virtual Filesystem Switch", 
    "arxiv-id": "1211.6187v1", 
    "author": "Wolfgang Reif", 
    "publish": "2012-11-27T02:36:24Z", 
    "summary": "This work presents a formal model that is part of our effort to construct a\nverified file system for Flash memory. To modularize the verification we factor\nout generic aspects into a common component that is inspired by the Linux\nVirtual Filesystem Switch (VFS) and provides POSIX compatible operations. It\nrelies on an abstract specification of its internal interface to concrete file\nsystem implementations (AFS). We proved that preconditions of AFS are respected\nand that the state is kept consistent. The model can be made executable and\nmounted into the Linux directory tree using FUSE."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.102.8", 
    "link": "http://arxiv.org/pdf/1211.6190v1", 
    "other_authors": "Hendrik Tews, Marcus V\u00f6lp, Tjark Weber", 
    "title": "On the Use of Underspecified Data-Type Semantics for Type Safety in   Low-Level Code", 
    "arxiv-id": "1211.6190v1", 
    "author": "Tjark Weber", 
    "publish": "2012-11-27T02:36:45Z", 
    "summary": "In recent projects on operating-system verification, C and C++ data types are\noften formalized using a semantics that does not fully specify the precise byte\nencoding of objects. It is well-known that such an underspecified data-type\nsemantics can be used to detect certain kinds of type errors. In general,\nhowever, underspecified data-type semantics are unsound: they assign\nwell-defined meaning to programs that have undefined behavior according to the\nC and C++ language standards.\n  A precise characterization of the type-correctness properties that can be\nenforced with underspecified data-type semantics is still missing. In this\npaper, we identify strengths and weaknesses of underspecified data-type\nsemantics for ensuring type safety of low-level systems code. We prove\nsufficient conditions to detect certain classes of type errors and, finally,\nidentify a trade-off between the complexity of underspecified data-type\nsemantics and their type-checking capabilities."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1301.2649v1", 
    "other_authors": "Amirreza Zarrabi", 
    "title": "Dynamic Transparent General Purpose Process Migration For Linux", 
    "arxiv-id": "1301.2649v1", 
    "author": "Amirreza Zarrabi", 
    "publish": "2013-01-12T05:31:57Z", 
    "summary": "Process migration refers to the act of transferring a process in the middle\nof its execution from one machine to another in a network. In this paper, we\nproposed a process migration framework for Linux OS. It is a multilayer\narchitecture to confine every functionality independent section of the system\nin separate layer. This architecture is capable of supporting diverse\napplications due to generic user space interface and dynamic structure that can\nbe modified according to demands."
},{
    "category": "cs.DS", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1304.6007v1", 
    "other_authors": "Enoch Peserico", 
    "title": "Paging with dynamic memory capacity", 
    "arxiv-id": "1304.6007v1", 
    "author": "Enoch Peserico", 
    "publish": "2013-04-22T16:23:24Z", 
    "summary": "We study a generalization of the classic paging problem that allows the\namount of available memory to vary over time - capturing a fundamental property\nof many modern computing realities, from cloud computing to multi-core and\nenergy-optimized processors. It turns out that good performance in the\n\"classic\" case provides no performance guarantees when memory capacity\nfluctuates: roughly speaking, moving from static to dynamic capacity can mean\nthe difference between optimality within a factor 2 in space and time, and\nsuboptimality by an arbitrarily large factor. More precisely, adopting the\ncompetitive analysis framework, we show that some online paging algorithms,\ndespite having an optimal (h,k)-competitive ratio when capacity remains\nconstant, are not (3,k)-competitive for any arbitrarily large k in the presence\nof minimal capacity fluctuations. In this light it is surprising that several\nclassic paging algorithms perform remarkably well even if memory capacity\nchanges adversarially - even without taking those changes into explicit\naccount! In particular, we prove that LFD still achieves the minimum number of\nfaults, and that several classic online algorithms such as LRU have a \"dynamic\"\n(h,k)-competitive ratio that is the best one can achieve without knowledge of\nfuture page requests, even if one had perfect knowledge of future capacity\nfluctuations (an exact characterization of this ratio shows it is almost,\nalbeit not quite, equal to the \"classic\" ratio k/(k-h+1)). In other words, with\ncareful management, knowing/predicting future memory resources appears far less\ncrucial to performance than knowing/predicting future data accesses."
},{
    "category": "cs.SE", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1310.0901v1", 
    "other_authors": "Thomas M. Baumann, Jose Gracia", 
    "title": "Cudagrind: A Valgrind Extension for CUDA", 
    "arxiv-id": "1310.0901v1", 
    "author": "Jose Gracia", 
    "publish": "2013-10-03T05:51:48Z", 
    "summary": "Valgrind, and specifically the included tool Memcheck, offers an easy and\nreliable way for checking the correctness of memory operations in programs.\nThis works in an unintrusive way where Valgrind translates the program into\nintermediate code and executes it on an emulated CPU. The heavy weight tool\nMemcheck uses this to keep a full shadow copy of the memory used by a program\nand tracking accesses to it. This allows the detection of memory leaks and\nchecking the validity of accesses.\n  Though suited for a wide variety of programs, this approach still fails when\naccelerator based programming models are involved. The code running on these\ndevices is separate from the code running on the host. Access to memory on the\ndevice and starting of kernels is being handled by an API provided by the\ndriver being used. Hence Valgrind is unable to understand and instrument\noperations being run on the device.\n  To circumvent this limitation a new set of wrapper functions have been\nintroduced. These wrap a subset of the CUDA Driver API function that is\nresponsible for (de-)allocation memory regions on the device and the respective\nmemory copy operations. This allows to check whether memory is fully allocated\nduring a transfer and, through the functionality provided by Valgrind, whether\nthe memory transfered to the device from the host is defined and addressable.\nThrough this technique it is possible to detect a number of common programming\nmistakes, which are very difficult to debug by other means. The combination of\nthese wrappers together with the Valgrind tool Memcheck is being called\nCudagrind."
},{
    "category": "cs.LO", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1311.2362v1", 
    "other_authors": "Hendra Gunadi, Alwen Tiu", 
    "title": "Efficient Runtime Monitoring with Metric Temporal Logic: A Case Study in   the Android Operating System", 
    "arxiv-id": "1311.2362v1", 
    "author": "Alwen Tiu", 
    "publish": "2013-11-11T06:21:29Z", 
    "summary": "We present a design and an implementation of a security policy specification\nlanguage based on metric linear-time temporal logic (MTL). MTL features\ntemporal operators that are indexed by time intervals, allowing one to specify\ntiming-dependent security policies. The design of the language is driven by the\nproblem of runtime monitoring of applications in mobile devices. A main case\nthe study is the privilege escalation attack in the Android operating system,\nwhere an app gains access to certain resource or functionalities that are not\nexplicitly granted to it by the user, through indirect control flow. To capture\nthese attacks, we extend MTL with recursive definitions, that are used to\nexpress call chains betwen apps. We then show how the metric operators of MTL,\nin combination with recursive definitions, can be used to specify policies to\ndetect privilege escalation, under various fine grained constraints. We present\na new algorithm, extending that of linear time temporal logic, for monitoring\nsafety policies written in our specification language. The monitor does not\nneed to store the entire history of events generated by the apps, something\nthat is crucial for practical implementations. We modified the Android OS\nkernel to allow us to insert our generated monitors modularly. We have tested\nthe modified OS on an actual device, and show that it is effective in detecting\npolicy violations."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1311.3686v1", 
    "other_authors": "Brijender Kahanwal, Dr. Tejinder Pal Singh, Dr. R. K. Tuteja", 
    "title": "Performance Evaluation of Java File Security System (JFSS)", 
    "arxiv-id": "1311.3686v1", 
    "author": "Dr. R. K. Tuteja", 
    "publish": "2013-11-13T10:53:02Z", 
    "summary": "Security is a critical issue of the modern file and storage systems, it is\nimperative to protect the stored data from unauthorized access. We have\ndeveloped a file security system named as Java File Security System (JFSS) [1]\nthat guarantee the security to files on the demand of all users. It has been\ndeveloped on Java platform. Java has been used as programming language in order\nto provide portability, but it enforces some performance limitations. It is\ndeveloped in FUSE (File System in User space) [3]. Many efforts have been done\nover the years for developing file systems in user space (FUSE). All have their\nown merits and demerits. In this paper we have evaluated the performance of\nJava File Security System (JFSS). Over and over again, the increased security\ncomes at the expense of user convenience, performance or compatibility with\nother systems. JFSS system performance evaluations show that encryption\noverheads are modest as compared to security."
},{
    "category": "cs.NI", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1312.5892v1", 
    "other_authors": "Florian Schmidt, David Orlea, Klaus Wehrle", 
    "title": "Support for Error Tolerance in the Real-Time Transport Protocol", 
    "arxiv-id": "1312.5892v1", 
    "author": "Klaus Wehrle", 
    "publish": "2013-12-20T11:11:54Z", 
    "summary": "Streaming applications often tolerate bit errors in their received data well.\nThis is contrasted by the enforcement of correctness of the packet headers and\npayload by network protocols. We investigate a solution for the Real-time\nTransport Protocol (RTP) that is tolerant to errors by accepting erroneous\ndata. It passes potentially corrupted stream data payloads to the codecs. If\nerrors occur in the header, our solution recovers from these by leveraging the\nknown state and expected header values for each stream. The solution is fully\nreceiver-based and incrementally deployable, and as such requires neither\nsupport from the sender nor changes to the RTP specification. Evaluations show\nthat our header error recovery scheme can recover from almost all errors, with\nvirtually no erroneous recoveries, up to bit error rates of about 10%."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1401.6100v1", 
    "other_authors": "K. Eric Harper, Thijmen de Gooijer", 
    "title": "Performance Impact of Lock-Free Algorithms on Multicore Communication   APIs", 
    "arxiv-id": "1401.6100v1", 
    "author": "Thijmen de Gooijer", 
    "publish": "2014-01-09T00:04:41Z", 
    "summary": "Data race conditions in multi-tasking software applications are prevented by\nserializing access to shared memory resources, ensuring data consistency and\ndeterministic behavior. Traditionally tasks acquire and release locks to\nsynchronize operations on shared memory. Unfortunately, lock management can add\nsignificant processing overhead especially for multicore deployments where\ntasks on different cores convoy in queues waiting to acquire a lock.\nImplementing more than one lock introduces the risk of deadlock and using\nspinlocks constrains which cores a task can run on. The better alternative is\nto eliminate locks and validate that real-time properties are met, which is not\ndirectly considered in many embedded applications. Removing the locks is\nnon-trivial and packaging lock-free algorithms for developers reduces the\npossibility of concurrency defects. This paper details how a multicore\ncommunication API implementation is enhanced to support lock-free messaging and\nthe impact this has on data exchange latency between tasks. Throughput and\nlatency are compared on Windows and Linux between lock-based and lock-free\nimplementations for data exchange of messages, packets, and scalars. A model of\nthe lock-free exchange predicts performance at the system architecture level\nand provides a stop criterion for the refactoring. The results show that\nmigration from single to multicore hardware architectures degrades lock-based\nperformance, and increases lock-free performance."
},{
    "category": "cs.CR", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1403.1165v1", 
    "other_authors": "Michael Hanspach, J\u00f6rg Keller", 
    "title": "A Taxonomy for Attack Patterns on Information Flows in Component-Based   Operating Systems", 
    "arxiv-id": "1403.1165v1", 
    "author": "J\u00f6rg Keller", 
    "publish": "2014-03-05T15:43:57Z", 
    "summary": "We present a taxonomy and an algebra for attack patterns on component-based\noperating systems. In a multilevel security scenario, where isolation of\npartitions containing data at different security classifications is the primary\nsecurity goal and security breaches are mainly defined as undesired disclosure\nor modification of classified data, strict control of information flows is the\nultimate goal. In order to prevent undesired information flows, we provide a\nclassification of information flow types in a component-based operating system\nand, by this, possible patterns to attack the system. The systematic\nconsideration of informations flows reveals a specific type of operating system\ncovert channel, the covert physical channel, which connects two former isolated\npartitions by emitting physical signals into the computer's environment and\nreceiving them at another interface."
},{
    "category": "cs.DC", 
    "doi": "10.5121/ijgca.2012.3402", 
    "link": "http://arxiv.org/pdf/1405.2281v1", 
    "other_authors": "Frank Hannig, J\u00fcrgen Teich", 
    "title": "Proceedings of the First Workshop on Resource Awareness and Adaptivity   in Multi-Core Computing (Racing 2014)", 
    "arxiv-id": "1405.2281v1", 
    "author": "J\u00fcrgen Teich", 
    "publish": "2014-05-08T07:09:55Z", 
    "summary": "This volume contains the papers accepted at the 1st Workshop on Resource\nAwareness and Adaptivity in Multi-Core Computing (Racing 2014), held in\nPaderborn, Germany, May 29-30, 2014. Racing 2014 was co-located with the IEEE\nEuropean Test Symposium (ETS)."
},{
    "category": "cs.CR", 
    "doi": "10.1007/978-3-319-05302-8_25", 
    "link": "http://arxiv.org/pdf/1406.5569v1", 
    "other_authors": "Ashkan Rahimian, Raha Ziarati, Stere Preda, Mourad Debbabi", 
    "title": "On the Reverse Engineering of the Citadel Botnet", 
    "arxiv-id": "1406.5569v1", 
    "author": "Mourad Debbabi", 
    "publish": "2014-06-21T02:04:56Z", 
    "summary": "Citadel is an advanced information-stealing malware which targets financial\ninformation. This malware poses a real threat against the confidentiality and\nintegrity of personal and business data. A joint operation was recently\nconducted by the FBI and the Microsoft Digital Crimes Unit in order to take\ndown Citadel command-and-control servers. The operation caused some disruption\nin the botnet but has not stopped it completely. Due to the complex structure\nand advanced anti-reverse engineering techniques, the Citadel malware analysis\nprocess is both challenging and time-consuming. This allows cyber criminals to\ncarry on with their attacks while the analysis is still in progress. In this\npaper, we present the results of the Citadel reverse engineering and provide\nadditional insight into the functionality, inner workings, and open source\ncomponents of the malware. In order to accelerate the reverse engineering\nprocess, we propose a clone-based analysis methodology. Citadel is an offspring\nof a previously analyzed malware called Zeus; thus, using the former as a\nreference, we can measure and quantify the similarities and differences of the\nnew variant. Two types of code analysis techniques are provided in the\nmethodology, namely assembly to source code matching and binary clone\ndetection. The methodology can help reduce the number of functions requiring\nmanual analysis. The analysis results prove that the approach is promising in\nCitadel malware analysis. Furthermore, the same approach is applicable to\nsimilar malware analysis scenarios."
},{
    "category": "cs.SE", 
    "doi": "10.1007/978-3-319-05302-8_25", 
    "link": "http://arxiv.org/pdf/1408.4715v1", 
    "other_authors": "Hugo A. Andrade, Simon Hogg, Stephan Ahrends", 
    "title": "Making FPGAs Accessible to Scientists and Engineers as Domain Expert   Software Programmers with LabVIEW", 
    "arxiv-id": "1408.4715v1", 
    "author": "Stephan Ahrends", 
    "publish": "2014-08-20T16:39:15Z", 
    "summary": "In this paper we present a graphical programming framework, LabVIEW, and\nassociated language and libraries, as well as programming techniques and\npatterns that we have found useful in making FPGAs accessible to scientists and\nengineers as domain expert software programmers."
},{
    "category": "cs.PF", 
    "doi": "10.1007/978-3-319-05302-8_25", 
    "link": "http://arxiv.org/pdf/1409.5567v1", 
    "other_authors": "Yanchao Lu, Donghong Wu, Bingsheng He, Xueyan Tang, Jianliang Xu, Minyi Guo", 
    "title": "Rank-Aware Dynamic Migrations and Adaptive Demotions for DRAM Power   Management", 
    "arxiv-id": "1409.5567v1", 
    "author": "Minyi Guo", 
    "publish": "2014-09-19T09:30:49Z", 
    "summary": "Modern DRAM architectures allow a number of low-power states on individual\nmemory ranks for advanced power management. Many previous studies have taken\nadvantage of demotions on low-power states for energy saving. However, most of\nthe demotion schemes are statically performed on a limited number of\npre-selected low-power states, and are suboptimal for different workloads and\nmemory architectures. Even worse, the idle periods are often too short for\neffective power state transitions, especially for memory intensive\napplications. Wrong decisions on power state transition incur significant\nenergy and delay penalties. In this paper, we propose a novel memory system\ndesign named RAMZzz with rank-aware energy saving optimizations including\ndynamic page migrations and adaptive demotions. Specifically, we group the\npages with similar access locality into the same rank with dynamic page\nmigrations. Ranks have their hotness: hot ranks are kept busy for high\nutilization and cold ranks can have more lengthy idle periods for power state\ntransitions. We further develop adaptive state demotions by considering all\nlow-power states for each rank and a prediction model to estimate the\npower-down timeout among states. We experimentally compare our algorithm with\nother energy saving policies with cycle-accurate simulation. Experiments with\nbenchmark workloads show that RAMZzz achieves significant improvement on\nenergy-delay2 and energy consumption over other energy saving techniques."
},{
    "category": "cs.CR", 
    "doi": "10.4204/EPTCS.165", 
    "link": "http://arxiv.org/pdf/1410.3226v1", 
    "other_authors": "Joaquin Garcia-Alfaro, G\u00fcrkan G\u00fcr", 
    "title": "Proceedings 2014 International Workshop on Advanced Intrusion Detection   and Prevention", 
    "arxiv-id": "1410.3226v1", 
    "author": "G\u00fcrkan G\u00fcr", 
    "publish": "2014-10-13T08:51:40Z", 
    "summary": "This volume contains the proceedings of the 2014 International Advanced\nIntrusion Detection and Prevention (AIDP'14) Workshop, held in Marrakesh,\nMorocco, on the 5th of June 2014, in conjunction with the 29th IFIP TC-11 SEC\n2014 International Conference. It includes a revised version of the papers\nselected for presentation at the work- shop."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.165", 
    "link": "http://arxiv.org/pdf/1410.3463v1", 
    "other_authors": "Lavanya Sita Tekumalla, Chiranjib Bhattacharyya", 
    "title": "Mining Block I/O Traces for Cache Preloading with Sparse Temporal   Non-parametric Mixture of Multivariate Poisson", 
    "arxiv-id": "1410.3463v1", 
    "author": "Chiranjib Bhattacharyya", 
    "publish": "2014-10-13T14:26:28Z", 
    "summary": "Existing caching strategies, in the storage domain, though well suited to\nexploit short range spatio-temporal patterns, are unable to leverage long-range\nmotifs for improving hitrates. Motivated by this, we investigate novel Bayesian\nnon-parametric modeling(BNP) techniques for count vectors, to capture long\nrange correlations for cache preloading, by mining Block I/O traces. Such\ntraces comprise of a sequence of memory accesses that can be aggregated into\nhigh-dimensional sparse correlated count vector sequences.\n  While there are several state of the art BNP algorithms for clustering and\ntheir temporal extensions for prediction, there has been no work on exploring\nthese for correlated count vectors. Our first contribution addresses this gap\nby proposing a DP based mixture model of Multivariate Poisson (DP-MMVP) and its\ntemporal extension(HMM-DP-MMVP) that captures the full covariance structure of\nmultivariate count data. However, modeling full covariance structure for count\nvectors is computationally expensive, particularly for high dimensional data.\nHence, we exploit sparsity in our count vectors, and as our main contribution,\nintroduce the Sparse DP mixture of multivariate Poisson(Sparse-DP-MMVP),\ngeneralizing our DP-MMVP mixture model, also leading to more efficient\ninference. We then discuss a temporal extension to our model for cache\npreloading.\n  We take the first step towards mining historical data, to capture long range\npatterns in storage traces for cache preloading. Experimentally, we show a\ndramatic improvement in hitrates on benchmark traces and lay the groundwork for\nfurther research in storage domain to reduce latencies using data mining\ntechniques to capture long range motifs."
},{
    "category": "cs.OS", 
    "doi": "10.5121/ijesa.2014.4401", 
    "link": "http://arxiv.org/pdf/1501.01370v1", 
    "other_authors": "Mahendra Vucha, Arvind Rajawat", 
    "title": "A Case Study: Task Scheduling Methodologies for High Speed Computing   Systems", 
    "arxiv-id": "1501.01370v1", 
    "author": "Arvind Rajawat", 
    "publish": "2015-01-07T05:51:19Z", 
    "summary": "High Speed computing meets ever increasing real-time computational demands\nthrough the leveraging of flexibility and parallelism. The flexibility is\nachieved when computing platform designed with heterogeneous resources to\nsupport multifarious tasks of an application where as task scheduling brings\nparallel processing. The efficient task scheduling is critical to obtain\noptimized performance in heterogeneous computing Systems (HCS). In this paper,\nwe brought a review of various application scheduling models which provide\nparallelism for homogeneous and heterogeneous computing systems. In this paper,\nwe made a review of various scheduling methodologies targeted to high speed\ncomputing systems and also prepared summary chart. The comparative study of\nscheduling methodologies for high speed computing systems has been carried out\nbased on the attributes of platform & application as well. The attributes are\nexecution time, nature of task, task handling capability, type of host &\ncomputing platform. Finally a summary chart has been prepared and it\ndemonstrates that the need of developing scheduling methodologies for\nHeterogeneous Reconfigurable Computing Systems (HRCS) which is an emerging high\nspeed computing platform for real time applications."
},{
    "category": "cs.NI", 
    "doi": "10.5220/0005237600050014", 
    "link": "http://arxiv.org/pdf/1504.03875v1", 
    "other_authors": "K\u00e9vin Roussel, Ye-Qiong Song, Olivier Zendra", 
    "title": "RIOT OS Paves the Way for Implementation of High-Performance MAC   Protocols", 
    "arxiv-id": "1504.03875v1", 
    "author": "Olivier Zendra", 
    "publish": "2015-04-15T12:05:59Z", 
    "summary": "Implementing new, high-performance MAC protocols requires real-time features,\nto be able to synchronize correctly between different unrelated devices. Such\nfeatures are highly desirable for operating wireless sensor networks (WSN) that\nare designed to be part of the Internet of Things (IoT). Unfortunately, the\noperating systems commonly used in this domain cannot provide such features. On\nthe other hand, \"bare-metal\" development sacrifices portability, as well as the\nmul-titasking abilities needed to develop the rich applications that are useful\nin the domain of the Internet of Things. We describe in this paper how we\nhelped solving these issues by contributing to the development of a port of\nRIOT OS on the MSP430 microcontroller, an architecture widely used in\nIoT-enabled motes. RIOT OS offers rich and advanced real-time features,\nespecially the simultaneous use of as many hardware timers as the underlying\nplatform (microcontroller) can offer. We then demonstrate the effectiveness of\nthese features by presenting a new implementation, on RIOT OS, of S-CoSenS, an\nefficient MAC protocol that uses very low processing power and energy."
},{
    "category": "cs.DC", 
    "doi": "10.5220/0005237600050014", 
    "link": "http://arxiv.org/pdf/1506.02822v2", 
    "other_authors": "Ludovic Court\u00e8s, Ricardo Wurmus", 
    "title": "Reproducible and User-Controlled Software Environments in HPC with Guix", 
    "arxiv-id": "1506.02822v2", 
    "author": "Ricardo Wurmus", 
    "publish": "2015-06-09T08:30:23Z", 
    "summary": "Support teams of high-performance computing (HPC) systems often find\nthemselves between a rock and a hard place: on one hand, they understandably\nadministrate these large systems in a conservative way, but on the other hand,\nthey try to satisfy their users by deploying up-to-date tool chains as well as\nlibraries and scientific software. HPC system users often have no guarantee\nthat they will be able to reproduce results at a later point in time, even on\nthe same system-software may have been upgraded, removed, or recompiled under\ntheir feet, and they have little hope of being able to reproduce the same\nsoftware environment elsewhere. We present GNU Guix and the functional package\nmanagement paradigm and show how it can improve reproducibility and sharing\namong researchers with representative use cases."
},{
    "category": "cs.OS", 
    "doi": "10.5220/0005237600050014", 
    "link": "http://arxiv.org/pdf/1510.05567v2", 
    "other_authors": "Mason Thammawichai, Eric C. Kerrigan", 
    "title": "Energy-Efficient Scheduling for Homogeneous Multiprocessor Systems", 
    "arxiv-id": "1510.05567v2", 
    "author": "Eric C. Kerrigan", 
    "publish": "2015-10-19T16:26:47Z", 
    "summary": "We present a number of novel algorithms, based on mathematical optimization\nformulations, in order to solve a homogeneous multiprocessor scheduling\nproblem, while minimizing the total energy consumption. In particular, for a\nsystem with a discrete speed set, we propose solving a tractable linear\nprogram. Our formulations are based on a fluid model and a global scheduling\nscheme, i.e. tasks are allowed to migrate between processors. The new methods\nare compared with three global energy/feasibility optimal workload allocation\nformulations. Simulation results illustrate that our methods achieve both\nfeasibility and energy optimality and outperform existing methods for\nconstrained deadline tasksets. Specifically, the results provided by our\nalgorithm can achieve up to an 80% saving compared to an algorithm without a\nfrequency scaling scheme and up to 70% saving compared to a constant frequency\nscaling scheme for some simulated tasksets. Another benefit is that our\nalgorithms can solve the scheduling problem in one step instead of using a\nrecursive scheme. Moreover, our formulations can solve a more general class of\nscheduling problems, i.e. any periodic real-time taskset with arbitrary\ndeadline. Lastly, our algorithms can be applied to both online and offline\nscheduling schemes."
},{
    "category": "cs.LO", 
    "doi": "10.4204/EPTCS.196", 
    "link": "http://arxiv.org/pdf/1511.02528v1", 
    "other_authors": "Rob van Glabbeek, Jan Friso Groote, Peter H\u00f6fner", 
    "title": "Proceedings Workshop on Models for Formal Analysis of Real Systems", 
    "arxiv-id": "1511.02528v1", 
    "author": "Peter H\u00f6fner", 
    "publish": "2015-11-08T21:12:17Z", 
    "summary": "This volume contains the proceedings of MARS 2015, the first workshop on\nModels for Formal Analysis of Real Systems, held on November 23, 2015 in Suva,\nFiji, as an affiliated workshop of LPAR 2015, the 20th International Conference\non Logic for Programming, Artificial Intelligence and Reasoning.\n  The workshop emphasises modelling over verification. It aims at discussing\nthe lessons learned from making formal methods for the verification and\nanalysis of realistic systems. Examples are:\n  (1) Which formalism is chosen, and why?\n  (2) Which abstractions have to be made and why?\n  (3) How are important characteristics of the system modelled?\n  (4) Were there any complications while modelling the system?\n  (5) Which measures were taken to guarantee the accuracy of the model?\n  We invited papers that present full models of real systems, which may lay the\nbasis for future comparison and analysis. An aim of the workshop is to present\ndifferent modelling approaches and discuss pros and cons for each of them.\nAlternative formal descriptions of the systems presented at this workshop are\nencouraged, which should foster the development of improved specification\nformalisms."
},{
    "category": "cs.CY", 
    "doi": "10.4204/EPTCS.196", 
    "link": "http://arxiv.org/pdf/1603.03635v1", 
    "other_authors": "Emmanuel Baccelli, Kaspar Schleiser", 
    "title": "Powering the Internet of Things with RIOT: Why? How? What is RIOT?", 
    "arxiv-id": "1603.03635v1", 
    "author": "Kaspar Schleiser", 
    "publish": "2016-03-11T14:10:18Z", 
    "summary": "The crucial importance of software platforms was highlighted by recent events\nboth at the political level (e.g. renewed calls for digital data and operating\nsystem \"sovereignty\", following E. Snowden's revelations) and at the business\nlevel (e.g. Android generated a new industry worth tens of billions of euros\nyearly). In the Internet of Things, which is expected to generate business at\nvery large scale, but also to threaten even more individual privacy, such\naspects will be exacerbated. The need for an operating system like RIOT stems\nfrom this context, and this short article outlines RIOT's main non-technical\naspects, as well as its key technical characteristics."
},{
    "category": "cs.OS", 
    "doi": "10.4204/EPTCS.196", 
    "link": "http://arxiv.org/pdf/1606.02635v1", 
    "other_authors": "Mason Thammawichai, Eric C. Kerrigan", 
    "title": "Feedback Scheduling for Energy-Efficient Real-Time Homogeneous   Multiprocessor Systems", 
    "arxiv-id": "1606.02635v1", 
    "author": "Eric C. Kerrigan", 
    "publish": "2016-06-08T16:52:03Z", 
    "summary": "Real-time scheduling algorithms proposed in the literature are often based on\nworst-case estimates of task parameters. The performance of an open-loop scheme\ncan be degraded significantly if there are uncertainties in task parameters,\nsuch as the execution times of the tasks. Therefore, to cope with such a\nsituation, a closed-loop scheme, where feedback is exploited to adjust the\nsystem parameters, can be applied. We propose an optimal control framework that\ntakes advantage of feeding back information of finished tasks to solve a\nreal-time multiprocessor scheduling problem with uncertainty in task execution\ntimes, with the objective of minimizing the total energy consumption.\nSpecifically, we propose a linear programming based algorithm to solve a\nworkload partitioning problem and adopt McNaughton's wrap around algorithm to\nfind the task execution order. The simulation results illustrate that our\nfeedback scheduling algorithm can save energy by as much as 40% compared to an\nopen-loop method for two processor models, i.e. a PowerPC 405LP and an XScale\nprocessor."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/1606.05794v1", 
    "other_authors": "Mike Jones, Bill Arcand, Bill Bergeron, David Bestor, Chansup Byun, Lauren Milechin, Vijay Gadepally, Matt Hubbell, Jeremy Kepner, Pete Michaleas, Julie Mullen, Andy Prout, Tony Rosa, Siddharth Samsi, Charles Yee, Albert Reuther", 
    "title": "Scalability of VM Provisioning Systems", 
    "arxiv-id": "1606.05794v1", 
    "author": "Albert Reuther", 
    "publish": "2016-06-18T18:55:42Z", 
    "summary": "Virtual machines and virtualized hardware have been around for over half a\ncentury. The commoditization of the x86 platform and its rapidly growing\nhardware capabilities have led to recent exponential growth in the use of\nvirtualization both in the enterprise and high performance computing (HPC). The\nstartup time of a virtualized environment is a key performance metric for high\nperformance computing in which the runtime of any individual task is typically\nmuch shorter than the lifetime of a virtualized service in an enterprise\ncontext. In this paper, a methodology for accurately measuring the startup\nperformance on an HPC system is described. The startup performance overhead of\nthree of the most mature, widely deployed cloud management frameworks\n(OpenStack, OpenNebula, and Eucalyptus) is measured to determine their\nsuitability for workloads typically seen in an HPC environment. A 10x\nperformance difference is observed between the fastest (Eucalyptus) and the\nslowest (OpenNebula) framework. This time difference is primarily due to delays\nin waiting on networking in the cloud-init portion of the startup. The\nmethodology and measurements presented should facilitate the optimization of\nstartup across a variety of virtualization environments."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/1607.07763v1", 
    "other_authors": "Mason Thammawichai, Eric C. Kerrigan", 
    "title": "Energy-Efficient Real-Time Scheduling for Two-Type Heterogeneous   Multiprocessors", 
    "arxiv-id": "1607.07763v1", 
    "author": "Eric C. Kerrigan", 
    "publish": "2016-07-15T14:52:57Z", 
    "summary": "We propose three novel mathematical optimization formulations that solve the\nsame two-type heterogeneous multiprocessor scheduling problem for a real-time\ntaskset with hard constraints. Our formulations are based on a global\nscheduling scheme and a fluid model. The first formulation is a mixed-integer\nnonlinear program, since the scheduling problem is intuitively considered as an\nassignment problem. However, by changing the scheduling problem to first\ndetermine a task workload partition and then to find the execution order of all\ntasks, the computation time can be significantly reduced. Specifically, the\nworkload partitioning problem can be formulated as a continuous nonlinear\nprogram for a system with continuous operating frequency, and as a continuous\nlinear program for a practical system with a discrete speed level set. The task\nordering problem can be solved by an algorithm with a complexity that is linear\nin the total number of tasks. The work is evaluated against existing global\nenergy/feasibility optimal workload allocation formulations. The results\nillustrate that our algorithms are both feasibility optimal and energy optimal\nfor both implicit and constrained deadline tasksets. Specifically, our\nalgorithm can achieve up to 40% energy saving for some simulated tasksets with\nconstrained deadlines. The benefit of our formulation compared with existing\nwork is that our algorithms can solve a more general class of scheduling\nproblems due to incorporating a scheduling dynamic model in the formulations\nand allowing for a time-varying speed profile. Moreover, our algorithms can be\napplied to both online and offline scheduling schemes."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/1608.00571v1", 
    "other_authors": "Blake A. Hechtman, Andrew D. Hilton, Daniel J. Sorin", 
    "title": "TREES: A CPU/GPU Task-Parallel Runtime with Explicit Epoch   Synchronization", 
    "arxiv-id": "1608.00571v1", 
    "author": "Daniel J. Sorin", 
    "publish": "2016-08-01T15:33:14Z", 
    "summary": "We have developed a task-parallel runtime system, called TREES, that is\ndesigned for high performance on CPU/GPU platforms. On platforms with multiple\nCPUs, Cilk's \"work-first\" principle underlies how task-parallel applications\ncan achieve performance, but work-first is a poor fit for GPUs. We build upon\nwork-first to create the \"work-together\" principle that addresses the specific\nstrengths and weaknesses of GPUs. The work-together principle extends\nwork-first by stating that (a) the overhead on the critical path should be paid\nby the entire system at once and (b) work overheads should be paid\nco-operatively. We have implemented the TREES runtime in OpenCL, and we\nexperimentally evaluate TREES applications on a CPU/GPU platform."
},{
    "category": "cs.LO", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/1610.03052v1", 
    "other_authors": "Lihao Liang, Paul E. McKenney, Daniel Kroening, Tom Melham", 
    "title": "Verification of the Tree-Based Hierarchical Read-Copy Update in the   Linux Kernel", 
    "arxiv-id": "1610.03052v1", 
    "author": "Tom Melham", 
    "publish": "2016-10-10T19:59:32Z", 
    "summary": "Read-Copy Update (RCU) is a scalable, high-performance Linux-kernel\nsynchronization mechanism that runs low-overhead readers concurrently with\nupdaters. Production-quality RCU implementations for multi-core systems are\ndecidedly non-trivial. Giving the ubiquity of Linux, a rare \"million-year\" bug\ncan occur several times per day across the installed base. Stringent validation\nof RCU's complex behaviors is thus critically important. Exhaustive testing is\ninfeasible due to the exponential number of possible executions, which suggests\nuse of formal verification.\n  Previous verification efforts on RCU either focus on simple implementations\nor use modeling languages, the latter requiring error-prone manual translation\nthat must be repeated frequently due to regular changes in the Linux kernel's\nRCU implementation. In this paper, we first describe the implementation of Tree\nRCU in the Linux kernel. We then discuss how to construct a model directly from\nTree RCU's source code in C, and use the CBMC model checker to verify its\nsafety and liveness properties. To our best knowledge, this is the first\nverification of a significant part of RCU's source code, and is an important\nstep towards integration of formal verification into the Linux kernel's\nregression test suite."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/1701.03709v1", 
    "other_authors": "Christof Schlaak, Maher Fakih, Ralf Stemmer", 
    "title": "Power and Execution Time Measurement Methodology for SDF Applications on   FPGA-based MPSoCs", 
    "arxiv-id": "1701.03709v1", 
    "author": "Ralf Stemmer", 
    "publish": "2017-01-13T16:15:53Z", 
    "summary": "Timing and power consumption play an important role in the design of embedded\nsystems. Furthermore, both properties are directly related to the safety\nrequirements of many embedded systems. With regard to availability\nrequirements, power considerations are of uttermost importance for battery\noperated systems. Validation of timing and power requires observability of\nthese properties. In many cases this is difficult, because the observability is\neither not possible or requires big extra effort in the system validation\nprocess. In this paper, we present a measurement-based approach for the joint\ntiming and power analysis of Synchronous Dataflow (SDF) applications running on\na shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a\nproof-of-concept, we implement an MPSoC system with configurable power and\ntiming measurement interfaces inside a Field Programmable Gate Array (FPGA).\nOur experiments demonstrate the viability of our approach being able of\naccurately analyzing different mappings of image processing applications (Sobel\nfilter and JPEG encoder) on an FPGA-based MPSoC implementation."
},{
    "category": "cs.SE", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/1703.02925v1", 
    "other_authors": "Guilherme Avelino, Leonardo Passos, Andre Hora, Marco Tulio Valente", 
    "title": "Assessing Code Authorship: The Case of the Linux Kernel", 
    "arxiv-id": "1703.02925v1", 
    "author": "Marco Tulio Valente", 
    "publish": "2017-03-08T17:26:02Z", 
    "summary": "Code authorship is a key information in large-scale open source systems.\nAmong others, it allows maintainers to assess division of work and identify key\ncollaborators. Interestingly, open-source communities lack guidelines on how to\nmanage authorship. This could be mitigated by setting to build an empirical\nbody of knowledge on how authorship-related measures evolve in successful\nopen-source communities. Towards that direction, we perform a case study on the\nLinux kernel. Our results show that: (a) only a small portion of developers (26\n%) makes significant contributions to the code base; (b) the distribution of\nthe number of files per author is highly skewed --- a small group of top\nauthors (3 %) is responsible for hundreds of files, while most authors (75 %)\nare responsible for at most 11 files; (c) most authors (62 %) have a specialist\nprofile; (d) authors with a high number of co-authorship connections tend to\ncollaborate with others with less connections."
},{
    "category": "cs.DC", 
    "doi": "10.1109/HPEC.2016.7761629", 
    "link": "http://arxiv.org/pdf/cs/0504051v1", 
    "other_authors": "Tassos S. Argyros, David R. Cheriton", 
    "title": "A Scalable Stream-Oriented Framework for Cluster Applications", 
    "arxiv-id": "cs/0504051v1", 
    "author": "David R. Cheriton", 
    "publish": "2005-04-13T16:37:59Z", 
    "summary": "This paper presents a stream-oriented architecture for structuring cluster\napplications. Clusters that run applications based on this architecture can\nscale to tenths of thousands of nodes with significantly less performance loss\nor reliability problems. Our architecture exploits the stream nature of the\ndata flow and reduces congestion through load balancing, hides latency behind\ndata pushes and transparently handles node failures. In our ongoing work, we\nare developing an implementation for this architecture and we are able to run\nsimple data mining applications on a cluster simulator."
},{
    "category": "cs.OS", 
    "doi": "10.1109/SISW.2007.7", 
    "link": "http://arxiv.org/pdf/0803.2365v1", 
    "other_authors": "V Sriram, Ganesh Narayan, K Gopinath", 
    "title": "SAFIUS - A secure and accountable filesystem over untrusted storage", 
    "arxiv-id": "0803.2365v1", 
    "author": "K Gopinath", 
    "publish": "2008-03-16T18:24:13Z", 
    "summary": "We describe SAFIUS, a secure accountable file system that resides over an\nuntrusted storage. SAFIUS provides strong security guarantees like\nconfidentiality, integrity, prevention from rollback attacks, and\naccountability. SAFIUS also enables read/write sharing of data and provides the\nstandard UNIX-like interface for applications. To achieve accountability with\ngood performance, it uses asynchronous signatures; to reduce the space required\nfor storing these signatures, a novel signature pruning mechanism is used.\nSAFIUS has been implemented on a GNU/Linux based system modifying OpenGFS.\nPreliminary performance studies show that SAFIUS has a tolerable overhead for\nproviding secure storage: while it has an overhead of about 50% of OpenGFS in\ndata intensive workloads (due to the overhead of performing\nencryption/decryption in software), it is comparable (or better in some cases)\nto OpenGFS in metadata intensive workloads."
},{
    "category": "cs.DC", 
    "doi": "10.12837/2013T01", 
    "link": "http://arxiv.org/pdf/1305.1459v1", 
    "other_authors": "Pier Stanislao Paolucci, Iuliana Bacivarov, Gert Goossens, Rainer Leupers, Fr\u00e9d\u00e9ric Rousseau, Christoph Schumacher, Lothar Thiele, Piero Vicini", 
    "title": "EURETILE 2010-2012 summary: first three years of activity of the   European Reference Tiled Experiment", 
    "arxiv-id": "1305.1459v1", 
    "author": "Piero Vicini", 
    "publish": "2013-05-07T10:22:31Z", 
    "summary": "This is the summary of first three years of activity of the EURETILE FP7\nproject 247846. EURETILE investigates and implements brain-inspired and\nfault-tolerant foundational innovations to the system architecture of massively\nparallel tiled computer architectures and the corresponding programming\nparadigm. The execution targets are a many-tile HW platform, and a many-tile\nsimulator. A set of SW process - HW tile mapping candidates is generated by the\nholistic SW tool-chain using a combination of analytic and bio-inspired\nmethods. The Hardware dependent Software is then generated, providing OS\nservices with maximum efficiency/minimal overhead. The many-tile simulator\ncollects profiling data, closing the loop of the SW tool chain. Fine-grain\nparallelism inside processes is exploited by optimized intra-tile compilation\ntechniques, but the project focus is above the level of the elementary tile.\nThe elementary HW tile is a multi-processor, which includes a fault tolerant\nDistributed Network Processor (for inter-tile communication) and ASIP\naccelerators. Furthermore, EURETILE investigates and implements the innovations\nfor equipping the elementary HW tile with high-bandwidth, low-latency\nbrain-like inter-tile communication emulating 3 levels of connection hierarchy,\nnamely neural columns, cortical areas and cortex, and develops a dedicated\ncortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking\nNeural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages\non the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES\nIntegrated Project (2006-2009)."
},{
    "category": "cs.DC", 
    "doi": "10.12837/2013T01", 
    "link": "http://arxiv.org/pdf/1604.07371v1", 
    "other_authors": "Robert Grandl, Srikanth Kandula, Sriram Rao, Aditya Akella, Janardhan Kulkarni", 
    "title": "Do the Hard Stuff First: Scheduling Dependent Computations in   Data-Analytics Clusters", 
    "arxiv-id": "1604.07371v1", 
    "author": "Janardhan Kulkarni", 
    "publish": "2016-04-25T19:20:18Z", 
    "summary": "We present a scheduler that improves cluster utilization and job completion\ntimes by packing tasks having multi-resource requirements and\ninter-dependencies. While the problem is algorithmically very hard, we achieve\nnear-optimality on the job DAGs that appear in production clusters at a large\nenterprise and in benchmarks such as TPC-DS. A key insight is that carefully\nhandling the long-running tasks and those with tough-to-pack resource needs\nwill produce good-enough schedules. However, which subset of tasks to treat\ncarefully is not clear (and intractable to discover). Hence, we offer a search\nprocedure that evaluates various possibilities and outputs a preferred schedule\norder over tasks. An online component enforces the schedule orders desired by\nthe various jobs running on the cluster. In addition, it packs tasks, overbooks\nthe fungible resources and guarantees bounded unfairness for a variety of\ndesirable fairness schemes. Relative to the state-of-the art schedulers, we\nspeed up 50% of the jobs by over 30% each."
},{
    "category": "cs.DC", 
    "doi": "10.12837/2013T01", 
    "link": "http://arxiv.org/pdf/0907.4622v1", 
    "other_authors": "Christian Vecchiola, Xingchen Chu, Rajkumar Buyya", 
    "title": "Aneka: A Software Platform for .NET-based Cloud Computing", 
    "arxiv-id": "0907.4622v1", 
    "author": "Rajkumar Buyya", 
    "publish": "2009-07-26T02:19:42Z", 
    "summary": "Aneka is a platform for deploying Clouds developing applications on top of\nit. It provides a runtime environment and a set of APIs that allow developers\nto build .NET applications that leverage their computation on either public or\nprivate clouds. One of the key features of Aneka is the ability of supporting\nmultiple programming models that are ways of expressing the execution logic of\napplications by using specific abstractions. This is accomplished by creating a\ncustomizable and extensible service oriented runtime environment represented by\na collection of software containers connected together. By leveraging on these\narchitecture advanced services including resource reservation, persistence,\nstorage management, security, and performance monitoring have been implemented.\nOn top of this infrastructure different programming models can be plugged to\nprovide support for different scenarios as demonstrated by the engineering,\nlife science, and industry applications."
}]